[{"id": "2009.00052", "submitter": "Khalifa Es-Sebaiy", "authors": "Rachid Belfadli, Khalifa Es-Sebaiy, Fatima-Ezzahra Farah", "title": "Statistical analysis of the non-ergodic fractional Ornstein-Uhlenbeck\n  process with periodic mean", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a periodic, mean-reverting Ornstein-Uhlenbeck process\n$X=\\{X_t,t\\geq0\\}$ of the form $d X_{t}=\\left(L(t)+\\alpha X_{t}\\right) d t+\ndB^H_{t}, \\quad t \\geq 0$, where $L(t)=\\sum_{i=1}^{p}\\mu_i\\phi_i (t)$ is a\nperiodic parametric function, and $\\{B^H_t,t\\geq0\\}$ is a fractional Brownian\nmotion of Hurst parameter $\\frac12\\leq H<1$. In the \"ergodic\" case $\\alpha<0$,\nthe parametric estimation of $(\\mu_1,\\ldots,\\mu_p,\\alpha)$ based on\ncontinuous-time observation of $X$ has been considered in Dehling et al.\n\\cite{DFK}, and in Dehling et al. \\cite{DFW} for $H=\\frac12$, and\n$\\frac12<H<1$, respectively. In this paper we consider the \"non-ergodic\" case\n$\\alpha>0$, and for all $\\frac12\\leq H<1$. We analyze the strong consistency\nand the asymptotic distribution for the estimator of\n$(\\mu_1,\\ldots,\\mu_p,\\alpha)$ when the whole trajectory of $X$ is observed.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 18:36:03 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Belfadli", "Rachid", ""], ["Es-Sebaiy", "Khalifa", ""], ["Farah", "Fatima-Ezzahra", ""]]}, {"id": "2009.00339", "submitter": "Xiao Fang", "authors": "Xiao Fang, Yuta Koike", "title": "Large-dimensional Central Limit Theorem with Fourth-moment Error Bounds\n  on Convex Sets and Balls", "comments": "42 pages. We corrected a mistake in v1. Now the d=o(n) rate is proved\n  only for centered balls", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove the large-dimensional Gaussian approximation of a sum of $n$\nindependent random vectors in $\\mathbb{R}^d$ together with fourth-moment error\nbounds on convex sets and Euclidean balls. We show that compared with classical\nthird-moment bounds, our bounds have near-optimal dependence on $n$ and can\nachieve improved dependence on the dimension $d$. For centered balls, we obtain\nan additional error bound that has a sub-optimal dependence on $n$, but\nrecovers the known result of the validity of the Gaussian approximation if and\nonly if $d=o(n)$. We discuss an application to the bootstrap. We prove our main\nresults using Stein's method.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 10:49:00 GMT"}, {"version": "v2", "created": "Tue, 2 Mar 2021 11:09:20 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Fang", "Xiao", ""], ["Koike", "Yuta", ""]]}, {"id": "2009.00389", "submitter": "Xiucai Ding", "authors": "Xiucai Ding and Fan Yang", "title": "Edge statistics of large dimensional deformed rectangular matrices", "comments": "72 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the edge statistics of large dimensional deformed rectangular\nmatrices of the form $Y_t=Y+\\sqrt{t}X,$ where $Y$ is a $p \\times n$\ndeterministic signal matrix whose rank is comparable to $n$, $X$ is a $p\\times\nn$ random noise matrix with centered i.i.d. entries with variance $n^{-1}$, and\n$t>0$ gives the noise level. This model is referred to as the\ninterference-plus-noise matrix in the study of massive multiple-input\nmultiple-output (MIMO) system, which belongs to the category of the so-called\nsignal-plus-noise model. For the case $t=1$, the spectral statistics of this\nmodel have been studied to a certain extent in the literature. In this paper,\nwe study the singular value and singular vector statistics of $Y_t$ around the\nright-most edge of the singular value spectrum in the harder regime\n$n^{-2/3}\\ll t \\ll 1$. This regime is harder than the $t=1$ case, because on\none hand, the edge behavior of the empirical spectral distribution (ESD) of\n$YY^\\top$ has a strong effect on the edge statistics of $Y_tY_t^\\top$ since\n$t\\ll 1$ is \"small\", while on the other hand, the edge statistics of $Y_t$ is\nalso not merely a perturbation of those of $Y$ since $t\\gg n^{-2/3}$ is\n\"large\". Under certain regularity assumptions on $Y,$ we prove the edge\nuniversality, eigenvalues rigidity and eigenvector delocalization for the\nmatrices $Y_tY_t^\\top$ and $Y_t^\\top Y_t$. These results can be used to\nestimate and infer the massive MIMO system. To prove the main results, we\nanalyze the edge behavior of the asymptotic ESD for $Y_tY_t^\\top$, and\nestablish some sharp local laws on the resolvent of $Y_tY_t^\\top$. These\nresults can be of independent interest, and used as useful inputs for many\nother problems regarding the spectral statistics of $Y_t$.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 12:44:57 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Ding", "Xiucai", ""], ["Yang", "Fan", ""]]}, {"id": "2009.00503", "submitter": "Sara Algeri", "authors": "Sara Algeri", "title": "Informative Goodness-of-Fit for Multivariate Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST physics.data-an stat.AP stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This article introduces an informative goodness-of-fit (iGOF) approach to\nstudy multivariate distributions. When the null model is rejected, iGOF allows\nus to identify the underlying sources of mismodeling and naturally equips\npractitioners with additional insights on the nature of the deviations from the\ntrue distribution. The informative character of the procedure is achieved by\nexploiting smooth tests and random fields theory to facilitate the analysis of\nmultivariate data. Simulation studies show that iGOF enjoys high power for\ndifferent types of alternatives. The methods presented here directly address\nthe problem of background mismodeling arising in physics and astronomy. It is\nin these areas that the motivation of this work is rooted.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 15:04:30 GMT"}, {"version": "v2", "created": "Wed, 2 Sep 2020 15:13:17 GMT"}, {"version": "v3", "created": "Thu, 1 Oct 2020 16:19:56 GMT"}, {"version": "v4", "created": "Wed, 14 Apr 2021 21:38:46 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Algeri", "Sara", ""]]}, {"id": "2009.00646", "submitter": "Yijun Zuo", "authors": "Yijun Zuo", "title": "Finite sample breakdown point of multivariate regression depth median", "comments": "20 pages, 4 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.OT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Depth induced multivariate medians (multi-dimensional maximum depth\nestimators) in regression serve as robust alternatives to the traditional least\nsquares and least absolute deviations estimators. The induced median\n($\\bs{\\beta}^*_{RD}$) from regression depth (RD) of Rousseeuw and Hubert (1999)\n(RH99) is one of the most prevailing estimators in regression.\n  The maximum regression depth median possesses outstanding robustness similar\nto the univariate location counterpart. Indeed, the %maximum depth estimator\ninduced from $\\mbox{RD}$, $\\bs{\\beta}^*_{RD}$ can, asymptotically, resist up to\n$33\\%$ contamination without breakdown, in contrast to the $0\\%$ for the\ntraditional estimators %(i.e. they could break down by a single bad point) (see\nVan Aelst and Rousseeuw, 2000) (VAR00). The results from VAR00 are pioneering\nand innovative, yet they are limited to regression symmetric populations and\nthe $\\epsilon$-contamination and maximum bias model.\n  With finite fixed sample size practice, the most prevailing measure of\nrobustness for estimators is the finite sample breakdown point (FSBP) (Donoho\n(1982), Donoho and Huber (1983)). A lower bound (LB) of the FSBP for the\n$\\bs{\\beta}^*_{RD}$, which is not sharp, was given in RH99 (in a corollary of a\nconjecture).\n  An exact FSBP (or even a sharper LB) for the $\\bs{\\beta}^*_{RD}$ remained\nopen in the last two decades. This article establishes a sharper lower and\nupper bounds of (and an exact) FSBP for the $\\bs{\\beta}^*_{RD}$, revealing an\nintrinsic connection between the regression depth of $\\bs{\\beta}^*_{RD}$ and\nits FSBP. This justifies the employment of the $\\bs{\\beta}^*_{RD}$ as a robust\nalternative to the traditional estimators and demonstrating the necessity and\nthe merit of using the FSBP in finite sample real practice instead of an\nasymptotic breakdown value.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 18:15:50 GMT"}, {"version": "v2", "created": "Wed, 7 Jul 2021 01:54:43 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Zuo", "Yijun", ""]]}, {"id": "2009.00848", "submitter": "Hien Nguyen", "authors": "Hien Duy Nguyen", "title": "Universal Inference with Composite Likelihoods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wasserman et al. (2020, PNAS, vol. 117, pp. 16880-16890) constructed\nestimator agnostic and finite-sample valid confidence sets and hypothesis\ntests, using split-data likelihood ratio-based statistics. We demonstrate that\nthe same approach extends to the use of split-data composite likelihood ratios\nas well, and thus establish universal methods for conducting multivariate\ninference when the data generating process is only known up to marginal and\nconditional relationships between the coordinates. Always-valid sequential\ninference is also considered.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 06:53:53 GMT"}, {"version": "v2", "created": "Sat, 5 Sep 2020 10:45:21 GMT"}, {"version": "v3", "created": "Fri, 18 Sep 2020 13:48:59 GMT"}, {"version": "v4", "created": "Wed, 23 Sep 2020 05:42:25 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Nguyen", "Hien Duy", ""]]}, {"id": "2009.00936", "submitter": "Hajo Holzmann", "authors": "Katharina Proksch, Nicolai Bissantz and Hajo Holzmann", "title": "Simultaneous inference for Berkson errors-in-variables regression under\n  fixed design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In various applications of regression analysis, in addition to errors in the\ndependent observations also errors in the predictor variables play a\nsubstantial role and need to be incorporated in the statistical modeling\nprocess. In this paper we consider a nonparametric measurement error model of\nBerkson type with fixed design regressors and centered random errors, which is\nin contrast to much existing work in which the predictors are taken as random\nobservations with random noise. Based on an estimator that takes the error in\nthe predictor into account and on a suitable Gaussian approximation, we derive\n%uniform confidence statements for the function of interest. In particular, we\nprovide finite sample bounds on the coverage error of uniform confidence bands,\nwhere we circumvent the use of extreme-value theory and rather rely on recent\nresults on anti-concentration of Gaussian processes. In a simulation study we\ninvestigate the performance of the uniform confidence sets for finite samples.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 10:29:36 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Proksch", "Katharina", ""], ["Bissantz", "Nicolai", ""], ["Holzmann", "Hajo", ""]]}, {"id": "2009.01551", "submitter": "Yunxiao Chen", "authors": "Yunxiao Chen, Zhiliang Ying and Haoran Zhang", "title": "Unfolding-Model-Based Visualization: Theory, Method and Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multidimensional unfolding methods are widely used for visualizing item\nresponse data. Such methods project respondents and items simultaneously onto a\nlow-dimensional Euclidian space, in which respondents and items are represented\nby ideal points, with person-person, item-item, and person-item similarities\nbeing captured by the Euclidian distances between the points. In this paper, we\nstudy the visualization of multidimensional unfolding from a statistical\nperspective. We cast multidimensional unfolding into an estimation problem,\nwhere the respondent and item ideal points are treated as parameters to be\nestimated. An estimator is then proposed for the simultaneous estimation of\nthese parameters. Asymptotic theory is provided for the recovery of the ideal\npoints, shedding lights on the validity of model-based visualization. An\nalternating projected gradient descent algorithm is proposed for the parameter\nestimation. We provide two illustrative examples, one on users' movie rating\nand the other on senate roll call voting.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 09:49:38 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Chen", "Yunxiao", ""], ["Ying", "Zhiliang", ""], ["Zhang", "Haoran", ""]]}, {"id": "2009.01800", "submitter": "Maria Longobardi Prof.Dr.", "authors": "S. Daneshi, A. Nezakati, S.Tahmasebi, M.Longobardi", "title": "Inaccuracy measures for concomitants of GOS in Morgenstern family", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this paper, we obtain a measure of inaccuracy between rth concomitant of\ngeneralized order statistic and the parent random variable in Morgenstern\nfamily. Applications of this result are given for concomitants of order\nstatistics and record values. We also study some results of cumulative past\ninaccuracy (CPI) between the distribution function of rth concomitant of order\nstatistic (record value) and the distribution function of parent random\nvariable. Finally, we discuss on a problem of estimating the CPI by means of\nthe empirical CPI in concomitants of generalized order statistics.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 16:59:58 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Daneshi", "S.", ""], ["Nezakati", "A.", ""], ["Tahmasebi", "S.", ""], ["Longobardi", "M.", ""]]}, {"id": "2009.01893", "submitter": "Rui Zhang", "authors": "Alexander Shapiro, Yao Xie, Rui Zhang", "title": "On characteristic rank for matrix and tensor completion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this lecture note, we discuss a fundamental concept, referred to as the\n{\\it characteristic rank}, which suggests a general framework for\ncharacterizing the basic properties of various low-dimensional models used in\nsignal processing. Below, we illustrate this framework using two examples:\nmatrix and three-way tensor completion problems, and consider basic properties\ninclude identifiability of a matrix or tensor, given partial observations. In\nthis note, we consider cases without observation noise to illustrate the\nprinciple.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 19:24:46 GMT"}, {"version": "v2", "created": "Wed, 11 Nov 2020 17:47:16 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Shapiro", "Alexander", ""], ["Xie", "Yao", ""], ["Zhang", "Rui", ""]]}, {"id": "2009.01961", "submitter": "Sheng Zhang", "authors": "Sheng Zhang, Xiu Yang, Samy Tindel, Guang Lin", "title": "Augmented Gaussian Random Field: Theory and Computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the novel augmented Gaussian random field (AGRF), which is a\nuniversal framework incorporating the data of observable and derivatives of any\norder. Rigorous theory is established. We prove that under certain conditions,\nthe observable and its derivatives of any order are governed by a single\nGaussian random field, which is the aforementioned AGRF. As a corollary, the\nstatement ``the derivative of a Gaussian process remains a Gaussian process''\nis validated, since the derivative is represented by a part of the AGRF.\nMoreover, a computational method corresponding to the universal AGRF framework\nis constructed. Both noiseless and noisy scenarios are considered. Formulas of\nthe posterior distributions are deduced in a nice closed form. A significant\nadvantage of our computational method is that the universal AGRF framework\nprovides a natural way to incorporate arbitrary order derivatives and deal with\nmissing data. We use four numerical examples to demonstrate the effectiveness\nof the computational method. The numerical examples are composite function,\ndamped harmonic oscillator, Korteweg-De Vries equation, and Burgers' equation.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 23:42:14 GMT"}, {"version": "v2", "created": "Thu, 29 Oct 2020 19:24:54 GMT"}, {"version": "v3", "created": "Fri, 19 Mar 2021 18:59:36 GMT"}, {"version": "v4", "created": "Wed, 16 Jun 2021 18:57:56 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Zhang", "Sheng", ""], ["Yang", "Xiu", ""], ["Tindel", "Samy", ""], ["Lin", "Guang", ""]]}, {"id": "2009.01983", "submitter": "Didong Li", "authors": "Didong Li, Yulong Lu, Emmanuel Chevallier, David B. Dunson", "title": "Density estimation and modeling on symmetric spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.DG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many applications, data and/or parameters are supported on non-Euclidean\nmanifolds. It is important to take into account the geometric structure of\nmanifolds in statistical analysis to avoid misleading results. Although there\nhas been a considerable focus on simple and specific manifolds, there is a lack\nof general and easy-to-implement statistical methods for density estimation and\nmodeling on manifolds. In this article, we consider a very broad class of\nmanifolds: non-compact Riemannian symmetric spaces. For this class, we provide\na very general mathematical result for easily calculating volume changes of the\nexponential and logarithm map between the tangent space and the manifold. This\nallows one to define statistical models on the tangent space, push these models\nforward onto the manifold, and easily calculate induced distributions by\nJacobians. To illustrate the statistical utility of this theoretical result, we\nprovide a general method to construct distributions on symmetric spaces. In\nparticular, we define the log-Gaussian distribution as an analogue of the\nmultivariate Gaussian distribution in Euclidean space. With these new kernels\non symmetric spaces, we also consider the problem of density estimation. Our\nproposed approach can use any existing density estimation approach designed for\nEuclidean spaces and push it forward to the manifold with an easy-to-calculate\nadjustment. We provide theorems showing that the induced density estimators on\nthe manifold inherit the statistical optimality properties of the parent\nEuclidean density estimator; this holds for both frequentist and Bayesian\nnonparametric methods. We illustrate the theory and practical utility of the\nproposed approach on the space of positive definite matrices.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 02:25:13 GMT"}, {"version": "v2", "created": "Tue, 8 Sep 2020 23:39:24 GMT"}, {"version": "v3", "created": "Sat, 19 Sep 2020 17:59:26 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Li", "Didong", ""], ["Lu", "Yulong", ""], ["Chevallier", "Emmanuel", ""], ["Dunson", "David B.", ""]]}, {"id": "2009.01995", "submitter": "Zhenting Sun", "authors": "Zhenting Sun", "title": "Instrument Validity for Heterogeneous Causal Effects", "comments": "A revised version", "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides a general framework for testing instrument validity in\nheterogeneous causal effect models. We first generalize the testable\nimplications of the instrument validity assumption provided by Balke and Pearl\n(1997), Imbens and Rubin (1997), and Heckman and Vytlacil (2005). The\ngeneralization involves the cases where the treatment can be multivalued (and\nordered) or unordered, and there can be conditioning covariates. Based on these\ntestable implications, we propose a nonparametric test which is proved to be\nasymptotically size controlled and consistent. Because of the nonstandard\nnature of the problem in question, the test statistic is constructed based on a\nnonsmooth map, which causes technical complications. We provide an extended\ncontinuous mapping theorem and an extended delta method, which may be of\nindependent interest, to establish the asymptotic distribution of the test\nstatistic under null. We then extend the bootstrap method proposed by Fang and\nSantos (2018) to approximate this asymptotic distribution and construct a\ncritical value for the test. Compared to the test proposed by Kitagawa (2015),\nour test can be applied in more general settings and may achieve power\nimprovement. Evidence that the test performs well on finite samples is provided\nvia simulations. We revisit the empirical study of Card (1993) and use their\ndata to demonstrate application of the proposed test in practice. We show that\na valid instrument for a multivalued treatment may not remain valid if the\ntreatment is coarsened.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 03:31:41 GMT"}, {"version": "v2", "created": "Mon, 15 Feb 2021 12:28:37 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Sun", "Zhenting", ""]]}, {"id": "2009.02003", "submitter": "Ethan Fang", "authors": "Yining Wang, Yi Chen, Ethan X. Fang, Zhaoran Wang and Runze Li", "title": "Nearly Dimension-Independent Sparse Linear Bandit over Small Action\n  Spaces via Best Subset Selection", "comments": "54 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the stochastic contextual bandit problem under the high\ndimensional linear model. We focus on the case where the action space is finite\nand random, with each action associated with a randomly generated contextual\ncovariate. This setting finds essential applications such as personalized\nrecommendation, online advertisement, and personalized medicine. However, it is\nvery challenging as we need to balance exploration and exploitation. We propose\ndoubly growing epochs and estimating the parameter using the best subset\nselection method, which is easy to implement in practice. This approach\nachieves $ \\tilde{\\mathcal{O}}(s\\sqrt{T})$ regret with high probability, which\nis nearly independent in the ``ambient'' regression model dimension $d$. We\nfurther attain a sharper $\\tilde{\\mathcal{O}}(\\sqrt{sT})$ regret by using the\n\\textsc{SupLinUCB} framework and match the minimax lower bound of\nlow-dimensional linear stochastic bandit problems. Finally, we conduct\nextensive numerical experiments to demonstrate the applicability and robustness\nof our algorithms empirically.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 04:10:39 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Wang", "Yining", ""], ["Chen", "Yi", ""], ["Fang", "Ethan X.", ""], ["Wang", "Zhaoran", ""], ["Li", "Runze", ""]]}, {"id": "2009.02029", "submitter": "Francesco Buono", "authors": "Narayanaswamy Balakrishnan, Francesco Buono and Maria Longobardi", "title": "On cumulative entropies in terms of moments of order statistics", "comments": "13 pages, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT stat.TH", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this paper relations among some kinds of cumulative entropies and moments\nof order statistics are presented. By using some characterizations and the\nsymmetry of a non negative and absolutely continuous random variable X, lower\nand upper bounds for entropies are obtained and examples are given.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 07:15:45 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Balakrishnan", "Narayanaswamy", ""], ["Buono", "Francesco", ""], ["Longobardi", "Maria", ""]]}, {"id": "2009.02056", "submitter": "Francesco Buono", "authors": "Osman Kamari and Francesco Buono", "title": "On extropy of past lifetime distribution", "comments": null, "journal-ref": null, "doi": "10.1007/s11587-020-00488-7", "report-no": null, "categories": "math.ST stat.TH", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Recently Qiu et al. (2017) have introduced residual extropy as measure of\nuncertainty in residual lifetime distributions analogues to residual entropy\n(1996). Also, they obtained some properties and applications of that. In this\npaper, we study the extropy to measure the uncertainty in a past lifetime\ndistribution. This measure of uncertainty is called past extropy. Also it is\nshowed a characterization result about the past extropy of largest order\nstatistics.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 08:22:51 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Kamari", "Osman", ""], ["Buono", "Francesco", ""]]}, {"id": "2009.02262", "submitter": "Yicong Lin", "authors": "Yicong Lin and Hanno Reuvers", "title": "Cointegrating Polynomial Regressions with Power Law Trends: A New Angle\n  on the Environmental Kuznets Curve", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Environment Kuznets Curve (EKC) predicts an inverted U-shaped\nrelationship between economic growth and environmental pollution. Current\nanalyses frequently employ models which restrict the nonlinearities in the data\nto be explained by the economic growth variable only. We propose a Generalized\nCointegrating Polynomial Regression (GCPR) with flexible time trends to proxy\ntime effects such as technological progress and/or environmental awareness.\nMore specifically, a GCPR includes flexible powers of deterministic trends and\ninteger powers of stochastic trends. We estimate the GCPR by nonlinear least\nsquares and derive its asymptotic distribution. Endogeneity of the regressors\ncan introduce nuisance parameters into this limiting distribution but a\nsimulated approach nevertheless enables us to conduct valid inference.\nMoreover, a subsampling KPSS test can be used to check the stationarity of the\nerrors. A comprehensive simulation study shows good performance of the\nsimulated inference approach and the subsampling KPSS test. We illustrate the\nGCPR approach on a dataset of 18 industrialised countries containing GDP and\nCO2 emissions. We conclude that: (1) the evidence for an EKC is significantly\nreduced when a nonlinear time trend is included, and (2) a linear cointegrating\nrelation between GDP and CO2 around a power law trend also provides an accurate\ndescription of the data.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 15:47:00 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Lin", "Yicong", ""], ["Reuvers", "Hanno", ""]]}, {"id": "2009.02318", "submitter": "Igor Rodionov V.", "authors": "Natalia M. Markovich, Igor V. Rodionov", "title": "Threshold selection for extremal index estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new threshold selection method for the nonparametric estimation\nof the extremal index of stochastic processes. The so-called discrepancy method\nwas proposed as a data-driven smoothing tool for estimation of a probability\ndensity function. Now it is modified to select a threshold parameter of an\nextremal index estimator. To this end, a specific normalization of the\ndiscrepancy statistic based on the Cram\\'{e}r-von Mises-Smirnov statistic\n$\\omega^2$ is calculated by the $k$ largest order statistics instead of an\nentire sample. Its asymptotic distribution as $k\\to\\infty$ is proved to be the\nsame as the $\\omega^2$-distribution. The quantiles of the latter distribution\nare used as discrepancy values. The rate of convergence of an extremal index\nestimate coupled with the discrepancy method is derived. The discrepancy method\nis used as an automatic threshold selection for the intervals and $K-$gaps\nestimators and it may be applied to other estimators of the extremal index.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 17:51:55 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Markovich", "Natalia M.", ""], ["Rodionov", "Igor V.", ""]]}, {"id": "2009.02578", "submitter": "Bruce Levin", "authors": "Bruce Levin and Cheng-Shiun Leu (Columbia University)", "title": "Positivity of Cumulative Sums for Multi-Index Function Components\n  Explains the Lower Bound Formula in the Levin-Robbins-Leu Family of\n  Sequential Subset Selection Procedures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We exhibit some strong positivity properties of a certain function which\nimplies a key inequality that in turn implies the lower bound formula for the\nprobability of correct selection in the Levin-Robbins-Leu family of sequential\nsubset selection procedures for binary outcomes. These properties provide a\nmore direct and comprehensive demonstration of the key inequality than was\ndiscussed in previous work.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 18:04:37 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Levin", "Bruce", "", "Columbia University"], ["Leu", "Cheng-Shiun", "", "Columbia University"]]}, {"id": "2009.02609", "submitter": "Ashwin Pananjady", "authors": "Ashwin Pananjady, Richard J. Samworth", "title": "Isotonic regression with unknown permutations: Statistics, computation,\n  and adaptation", "comments": "Version v2 contains reorganized material, one figure, and expanded\n  discussions", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT cs.LG math.IT stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by models for multiway comparison data, we consider the problem of\nestimating a coordinate-wise isotonic function on the domain $[0, 1]^d$ from\nnoisy observations collected on a uniform lattice, but where the design points\nhave been permuted along each dimension. While the univariate and bivariate\nversions of this problem have received significant attention, our focus is on\nthe multivariate case $d \\geq 3$. We study both the minimax risk of estimation\n(in empirical $L_2$ loss) and the fundamental limits of adaptation (quantified\nby the adaptivity index) to a family of piecewise constant functions. We\nprovide a computationally efficient Mirsky partition estimator that is minimax\noptimal while also achieving the smallest adaptivity index possible for\npolynomial time procedures. Thus, from a worst-case perspective and in sharp\ncontrast to the bivariate case, the latent permutations in the model do not\nintroduce significant computational difficulties over and above vanilla\nisotonic regression. On the other hand, the fundamental limits of adaptation\nare significantly different with and without unknown permutations: Assuming a\nhardness conjecture from average-case complexity theory, a\nstatistical-computational gap manifests in the former case. In a complementary\ndirection, we show that natural modifications of existing estimators fail to\nsatisfy at least one of the desiderata of optimal worst-case statistical\nperformance, computational efficiency, and fast adaptation. Along the way to\nshowing our results, we improve adaptation results in the special case $d = 2$\nand establish some properties of estimators for vanilla isotonic regression,\nboth of which may be of independent interest.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 22:17:51 GMT"}, {"version": "v2", "created": "Thu, 24 Jun 2021 13:58:37 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Pananjady", "Ashwin", ""], ["Samworth", "Richard J.", ""]]}, {"id": "2009.02786", "submitter": "Johannes Heiny", "authors": "Johannes Heiny and Mark Podolskij", "title": "On estimation of quadratic variation for multivariate pure jump\n  semimartingales", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present the asymptotic analysis of the realised quadratic\nvariation for multivariate symmetric $\\beta$-stable L\\'evy processes, $\\beta\n\\in (0,2)$, and certain pure jump semimartingales. The main focus is on\nderivation of functional limit theorems for the realised quadratic variation\nand its spectrum. We will show that the limiting process is a matrix-valued\n$\\beta$-stable L\\'evy process when the original process is symmetric\n$\\beta$-stable, while the limit is conditionally $\\beta$-stable in case of\nintegrals with respect to symmetric $\\beta$-stable motions. These asymptotic\nresults are mostly related to the work [5], which investigates the univariate\nversion of the problem. Furthermore, we will show the implications for\nestimation of eigenvalues and eigenvectors of the quadratic variation matrix,\nwhich is a useful result for the principle component analysis. Finally, we\npropose a consistent subsampling procedure in the L\\'evy setting to obtain\nconfidence regions.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 17:40:06 GMT"}, {"version": "v2", "created": "Wed, 5 May 2021 23:20:58 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Heiny", "Johannes", ""], ["Podolskij", "Mark", ""]]}, {"id": "2009.02824", "submitter": "Ruodu Wang", "authors": "Ruodu Wang and Aaditya Ramdas", "title": "False discovery rate control with e-values", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  E-values have gained attention as potential alternatives to p-values as\nmeasures of uncertainty, significance and evidence. In brief, e-values are\nrealized by random variables with expectation at most one under the null;\nexamples include betting scores, (point null) Bayes factors, likelihood ratios\nand stopped supermartingales. We design a natural analog of the\nBenjamini-Hochberg (BH) procedure for false discovery rate (FDR) control that\nutilizes e-values, called the e-BH procedure, and compare it with the standard\nprocedure for p-values. One of our central results is that, unlike the usual BH\nprocedure, the e-BH procedure controls the FDR at the desired level---with no\ncorrection---for any dependence structure between the e-values. We illustrate\nthat the new procedure is convenient in various settings of complicated\ndependence, structured and post-selection hypotheses, and multi-armed bandit\nproblems. Moreover, the BH procedure is a special case of the e-BH procedure\nthrough calibration between p-values and e-values. Overall, the e-BH procedure\nis a novel, powerful and general tool for multiple testing under dependence,\nthat is complementary to the BH procedure, each being an appropriate choice in\ndifferent applications.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 21:50:17 GMT"}, {"version": "v2", "created": "Wed, 18 Nov 2020 09:28:43 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Wang", "Ruodu", ""], ["Ramdas", "Aaditya", ""]]}, {"id": "2009.02905", "submitter": "Christian K\\\"ummerle", "authors": "Christian K\\\"ummerle, Claudio M. Verdun", "title": "Escaping Saddle Points in Ill-Conditioned Matrix Completion with a\n  Scalable Second Order Method", "comments": "15 pages, presented at the Workshop on \"Beyond first-order methods in\n  ML systems\" at the $37^th$ International Conference on Machine Learning\n  (ICML), Vienna, Austria, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.IT cs.LG math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an iterative algorithm for low-rank matrix completion that can be\ninterpreted as both an iteratively reweighted least squares (IRLS) algorithm\nand a saddle-escaping smoothing Newton method applied to a non-convex rank\nsurrogate objective. It combines the favorable data efficiency of previous IRLS\napproaches with an improved scalability by several orders of magnitude. Our\nmethod attains a local quadratic convergence rate already for a number of\nsamples that is close to the information theoretical limit. We show in\nnumerical experiments that unlike many state-of-the-art approaches, our\napproach is able to complete very ill-conditioned matrices with a condition\nnumber of up to $10^{10}$ from few samples.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 06:51:20 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["K\u00fcmmerle", "Christian", ""], ["Verdun", "Claudio M.", ""]]}, {"id": "2009.03117", "submitter": "Ivo V. Stoepker", "authors": "Ivo V. Stoepker, Rui M. Castro, Ery Arias-Castro, Edwin van den Heuvel", "title": "Anomaly Detection for a Large Number of Streams: A Permutation-Based\n  Higher Criticism Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection when observing a large number of data streams is essential\nin a variety of applications, ranging from epidemiological studies to\nmonitoring of complex systems. High-dimensional scenarios are usually tackled\nwith scan-statistics and related methods, requiring stringent modeling\nassumptions for proper calibration. In this work we take a non-parametric\nstance, and propose a permutation-based variant of the higher criticism\nstatistic not requiring knowledge of the null distribution. This results in an\nexact test in finite samples which is asymptotically optimal in the wide class\nof exponential models. We demonstrate the power loss in finite samples is\nminimal with respect to the oracle test. Furthermore, since the proposed\nstatistic does not rely on asymptotic approximations it typically performs\nbetter than popular variants of higher criticism that rely on such\napproximations. We include recommendations such that the test can be readily\napplied in practice, and demonstrate its applicability in monitoring the daily\nnumber of COVID-19 cases in the Netherlands.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 14:07:31 GMT"}, {"version": "v2", "created": "Thu, 22 Jul 2021 15:15:21 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Stoepker", "Ivo V.", ""], ["Castro", "Rui M.", ""], ["Arias-Castro", "Ery", ""], ["Heuvel", "Edwin van den", ""]]}, {"id": "2009.03149", "submitter": "Marat Burnashev V.", "authors": "Marat V. Burnashev", "title": "New Upper Bounds in the Hypothesis Testing Problem with Information\n  Constraints", "comments": null, "journal-ref": "Problems of Information Transmission, vol. 56, no. 2, pp. 64-81,\n  2020", "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a hypothesis testing problem where a part of data cannot be\nobserved. Our helper observes the missed data and can send us a limited amount\nof information about them. What kind of this limited information will allow us\nto make the best statistical inference? In particular, what is the minimum\ninformation sufficient to obtain the same results as if we directly observed\nall the data? We derive estimates for this minimum information and some other\nsimilar results.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 15:07:40 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Burnashev", "Marat V.", ""]]}, {"id": "2009.03167", "submitter": "Aaditya Ramdas", "authors": "Aaditya Ramdas, Johannes Ruf, Martin Larsson, Wouter Koolen", "title": "Admissible anytime-valid sequential inference must rely on nonnegative\n  martingales", "comments": "35 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wald's anytime-valid $p$-values and Robbins' confidence sequences enable\nsequential inference for composite and nonparametric classes of distributions\nat arbitrary stopping times, as do more recent proposals involving Vovk's\n`$e$-values' or Shafer's `betting scores'. Examining the literature, one finds\nthat at the heart of all these (quite different) approaches has been the\nidentification of composite nonnegative (super)martingales. Thus, informally,\nnonnegative (super)martingales are known to be sufficient for \\emph{valid}\nsequential inference. Our central contribution is to show that martingales are\nalso universal---all \\emph{admissible} constructions of (composite) anytime\n$p$-values, confidence sequences, or $e$-values must necessarily utilize\nnonnegative martingales (or so-called max-martingales in the case of\n$p$-values). Sufficient conditions for composite admissibility are also\nprovided. Our proofs utilize a plethora of modern mathematical tools for\ncomposite testing and estimation problems: max-martingales, Snell envelopes,\nand new Doob-L\\'evy martingales make appearances in previously unencountered\nways. Informally, if one wishes to perform anytime-valid sequential inference,\nthen any existing approach can be recovered or dominated using martingales. We\nprovide several sophisticated examples, with special focus on the nonparametric\nproblem of testing if a distribution is symmetric, where our new constructions\nrender past methods inadmissible.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 15:32:13 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2020 06:30:14 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Ramdas", "Aaditya", ""], ["Ruf", "Johannes", ""], ["Larsson", "Martin", ""], ["Koolen", "Wouter", ""]]}, {"id": "2009.03170", "submitter": "Marius Tirlea", "authors": "Joseph P. Romano, Marius A. Tirlea", "title": "Permutation Testing for Dependence in Time Series", "comments": "38 pages, 5 figures, proofs in supplement", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given observations from a stationary time series, permutation tests allow one\nto construct exactly level $\\alpha$ tests under the null hypothesis of an\ni.i.d. (or, more generally, exchangeable) distribution. On the other hand, when\nthe null hypothesis of interest is that the underlying process is an\nuncorrelated sequence, permutation tests are not necessarily level $\\alpha$,\nnor are they approximately level $\\alpha$ in large samples. In addition,\npermutation tests may have large Type 3, or directional, errors, in which a\ntwo-sided test rejects the null hypothesis and concludes that the first-order\nautocorrelation is larger than 0, when in fact it is less than 0. In this\npaper, under weak assumptions on the mixing coefficients and moments of the\nsequence, we provide a test procedure for which the asymptotic validity of the\npermutation test holds, while retaining the exact rejection probability\n$\\alpha$ in finite samples when the observations are independent and\nidentically distributed. A Monte Carlo simulation study, comparing the\npermutation test to other tests of autocorrelation, is also performed, along\nwith an empirical example of application to financial data.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 15:37:18 GMT"}, {"version": "v2", "created": "Tue, 8 Sep 2020 01:27:45 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Romano", "Joseph P.", ""], ["Tirlea", "Marius A.", ""]]}, {"id": "2009.03449", "submitter": "Weijing Tang", "authors": "Weijing Tang, Kevin He, Gongjun Xu, Ji Zhu", "title": "Survival Analysis via Ordinary Differential Equations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a general framework for survival analysis based on\nordinary differential equations (ODE). Specifically, this framework unifies\nmany existing survival models, including proportional hazards models, linear\ntransformation models, accelerated failure time models, and time-varying\ncoefficient models as special cases. Such a unified framework provides a novel\nperspective on modeling censored data and offers opportunities for designing\nnew and more flexible survival model structures. Further, the aforementioned\nexisting survival models are traditionally estimated by procedures that suffer\nfrom lack of scalability, statistical inefficiency, or implementation\ndifficulty. Based on well-established numerical solvers and sensitivity\nanalysis tools for ODEs, we propose a novel, scalable, and easy-to-implement\ngeneral estimation procedure that is applicable to a wide range of models. In\nparticular, we develop a sieve maximum likelihood estimator for a general\nsemi-parametric class of ODE models as an illustrative example. We also\nestablish a general sieve M-theorem for bundled parameters and show that the\nproposed sieve estimator is consistent and asymptotically normal, and achieves\nthe semi-parametric efficiency bound. The finite sample performance of the\nproposed estimator is examined in simulation studies and a real-world data\nexample.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 22:53:17 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Tang", "Weijing", ""], ["He", "Kevin", ""], ["Xu", "Gongjun", ""], ["Zhu", "Ji", ""]]}, {"id": "2009.03472", "submitter": "Hailin Sang", "authors": "Timothy Fortune and Hailin Sang", "title": "Shannon entropy estimation for linear processes", "comments": "14 pages, accepted by Journal of Risk and Financial Management", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we estimate the Shannon entropy $S(f) = -\\E[ \\log (f(x))]$ of\na one-sided linear process with probability density function $f(x)$. We employ\nthe integral estimator $S_n(f)$, which utilizes the standard kernel density\nestimator $f_n(x)$ of $f(x)$. We show that $S_n (f)$ converges to $S(f)$ almost\nsurely and in $\\L^2$ under reasonable conditions.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 01:09:22 GMT"}, {"version": "v2", "created": "Wed, 9 Sep 2020 04:25:04 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Fortune", "Timothy", ""], ["Sang", "Hailin", ""]]}, {"id": "2009.03505", "submitter": "Lin Zhou", "authors": "Lin Zhou, Yun Wei and Alfred Hero", "title": "Second-Order Asymptotically Optimal Universal Outlying Sequence\n  Detection with Reject Option", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by practical machine learning applications, we revisit the outlying\nsequence detection problem (Li \\emph{et al.}, TIT 2014) and derive fundamental\nlimits of optimal detection when the reject option is allowed for outlying\nsequences. In outlying sequence detection (OSD) one is given multiple observed\nsequences, where most sequences are generated i.i.d. from a nominal\ndistribution. The task is to discern the set of outlying sequences that are\ngenerated according to anomalous distributions. In OSD, the nominal and\nanomalous distributions are \\emph{unknown}. In this paper, we consider the case\nwhere there is a reject option for the OSD, i.e., reject the samples as\ninsufficient for reliable outlying sequence detection (cf. Bartlett \\emph{et\nal.}, JMLR 2008). We study the tradeoff among the probabilities of\nmisclassification error, false alarm and false reject for tests that satisfy\nweak conditions on the rate of decrease of these error probabilities as a\nfunction of sequence length. We propose a second-order asymptotically optimal\ntest which provides a finite sample approximation. We first consider the case\nof at most one outlying sequence and then generalize our results to multiple\noutlying sequences where each outlying sequence can follow a different\nanomalous distribution.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 03:47:18 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Zhou", "Lin", ""], ["Wei", "Yun", ""], ["Hero", "Alfred", ""]]}, {"id": "2009.03546", "submitter": "Didier Henrion", "authors": "Yohann de Castro (ICJ), Fabrice Gamboa (IMT), Didier Henrion\n  (LAAS-MAC), Jean Lasserre (LAAS-MAC, IMT)", "title": "Dual optimal design and the Christoffel-Darboux polynomial", "comments": null, "journal-ref": null, "doi": null, "report-no": "Rapport LAAS n{\\textdegree} 20178", "categories": "math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of this short note is to show that the Christoffel-Darboux\npolynomial, useful in approximation theory and data science, arises naturally\nwhen deriving the dual to the problem of semi-algebraic D-optimal experimental\ndesign in statistics. It uses only elementary notions of convex analysis.\nGeometric interpretations and algorithmic consequences are mentioned.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 07:06:51 GMT"}, {"version": "v2", "created": "Tue, 8 Dec 2020 15:47:01 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["de Castro", "Yohann", "", "ICJ"], ["Gamboa", "Fabrice", "", "IMT"], ["Henrion", "Didier", "", "LAAS-MAC"], ["Lasserre", "Jean", "", "LAAS-MAC, IMT"]]}, {"id": "2009.03652", "submitter": "Steven Golovkine", "authors": "Steven Golovkine, Nicolas Klutchnikoff and Valentin Patilea", "title": "Learning the smoothness of noisy curves with application to online curve\n  estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combining information both within and across trajectories, we propose a\nsimple estimator for the local regularity of the trajectories of a stochastic\nprocess. Independent trajectories are measured with errors at randomly sampled\ntime points. Non-asymptotic bounds for the concentration of the estimator are\nderived. Given the estimate of the local regularity, we build a nearly optimal\nlocal polynomial smoother from the curves from a new, possibly very large\nsample of noisy trajectories. We derive non-asymptotic pointwise risk bounds\nuniformly over the new set of curves. Our estimates perform well in\nsimulations. Real data sets illustrate the effectiveness of the new approaches.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 11:45:46 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Golovkine", "Steven", ""], ["Klutchnikoff", "Nicolas", ""], ["Patilea", "Valentin", ""]]}, {"id": "2009.03757", "submitter": "Chunhao Cai", "authors": "Chunhao Cai and Min Zhang", "title": "A Note On Inference for the Mixed Fractional Ornstein-Uhlenbeck Process\n  with Drift", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is devoted to parameter estimation of the mixed fractional\nOrnstein-Uhlenbeck process with a drift. Large sample asymptotical properties\nof the Maximum Likelihood Estimator is deduced using the Laplace transform\ncomputations or the Cameron-Martin formula with extra part from \\cite{CK19}\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 13:51:14 GMT"}, {"version": "v2", "created": "Sat, 16 Jan 2021 11:25:54 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Cai", "Chunhao", ""], ["Zhang", "Min", ""]]}, {"id": "2009.03803", "submitter": "Aniket Biswas", "authors": "Aniket Biswas and Gaurangadeb Chattopadhyay", "title": "Modified estimator for the proportion of true null hypotheses under\n  discrete setup with proven FDR control by the adaptive Benjamini-Hochberg\n  procedure", "comments": "8 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Some crucial issues about a recently proposed estimator for the proportion of\ntrue null hypotheses ($\\pi_0$) under discrete setup are discussed. An estimator\nfor $\\pi_0$ is introduced under the same setup. The estimator may be seen as a\nmodification of a very popular estimator for $\\pi_0$, originally proposed under\nthe assumption of continuous test statistics. It is shown that adaptive\nBenjamini-Hochberg procedure remains conservative with the new estimator for\n$\\pi_0$ being plugged in.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 14:58:44 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Biswas", "Aniket", ""], ["Chattopadhyay", "Gaurangadeb", ""]]}, {"id": "2009.03879", "submitter": "Conor Mayo-Wilson", "authors": "Conor Mayo-Wilson and Aditya Saraf", "title": "Qualitative Robust Bayesianism and the Likelihood Principle", "comments": "53 pages, no figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We argue that the likelihood principle (LP) and weak law of likelihood (LL)\ngeneralize naturally to settings in which experimenters are justified only in\nmaking comparative, non-numerical judgments of the form \"$A$ given $B$ is more\nlikely than $C$ given $D$.\" To do so, we first \\emph{formulate} qualitative\nanalogs of those theses. Then, using a framework for qualitative conditional\nprobability, just as the characterizes when all Bayesians (regardless of prior)\nagree that two pieces of evidence are equivalent, so a\nqualitative/non-numerical version of LP provides sufficient conditions for\nagreement among experimenters' whose degrees of belief satisfy only very weak\n\"coherence\" constraints. We prove a similar result for LL. We conclude by\ndiscussing the relevance of results to stopping rules.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 17:43:10 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Mayo-Wilson", "Conor", ""], ["Saraf", "Aditya", ""]]}, {"id": "2009.03969", "submitter": "Chao Gao", "authors": "Fengshuo Zhang and Chao Gao", "title": "Convergence Rates of Empirical Bayes Posterior Distributions: A\n  Variational Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the convergence rates of empirical Bayes posterior distributions for\nnonparametric and high-dimensional inference. We show that as long as the\nhyperparameter set is discrete, the empirical Bayes posterior distribution\ninduced by the maximum marginal likelihood estimator can be regarded as a\nvariational approximation to a hierarchical Bayes posterior distribution. This\nconnection between empirical Bayes and variational Bayes allows us to leverage\nthe recent results in the variational Bayes literature, and directly obtains\nthe convergence rates of empirical Bayes posterior distributions from a\nvariational perspective. For a more general hyperparameter set that is not\nnecessarily discrete, we introduce a new technique called \"prior decomposition\"\nto deal with prior distributions that can be written as convex combinations of\nprobability measures whose supports are low-dimensional subspaces. This leads\nto generalized versions of the classical \"prior mass and testing\" conditions\nfor the convergence rates of empirical Bayes. Our theory is applied to a number\nof statistical estimation problems including nonparametric density estimation\nand sparse linear regression.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 19:35:27 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Zhang", "Fengshuo", ""], ["Gao", "Chao", ""]]}, {"id": "2009.04072", "submitter": "Ery Arias-Castro", "authors": "Ery Arias-Castro and Lin Zheng", "title": "Template Matching and Change Point Detection by M-estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST eess.SP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the fundamental problem of matching a template to a signal. We do\nso by M-estimation, which encompasses procedures that are robust to gross\nerrors (i.e., outliers). Using standard results from empirical process theory,\nwe derive the convergence rate and the asymptotic distribution of the\nM-estimator under relatively mild assumptions. We also discuss the optimality\nof the estimator, both in finite samples in the minimax sense and in the\nlarge-sample limit in terms of local minimaxity and relative efficiency.\nAlthough most of the paper is dedicated to the study of the basic shift model\nin the context of a random design, we consider many extensions towards the end\nof the paper, including more flexible templates, fixed designs, the agnostic\nsetting, and more.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 02:15:15 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Arias-Castro", "Ery", ""], ["Zheng", "Lin", ""]]}, {"id": "2009.04136", "submitter": "Wei Ma", "authors": "Li Yang, Wei Ma, Yichen Qin, Feifang Hu", "title": "Testing for Treatment Effect in Covariate-Adaptive Randomized Clinical\n  Trials with Generalized Linear Models and Omitted Covariates", "comments": "Updated to the published version", "journal-ref": "Statistical Methods in Medical Research (2021)", "doi": "10.1177/09622802211008206", "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Concerns have been expressed over the validity of statistical inference under\ncovariate-adaptive randomization despite the extensive use in clinical trials.\nIn the literature, the inferential properties under covariate-adaptive\nrandomization have been mainly studied for continuous responses; in particular,\nit is well known that the usual two sample t-test for treatment effect is\ntypically conservative, in the sense that the actual test size is smaller than\nthe nominal level. This phenomenon of invalid tests has also been found for\ngeneralized linear models without adjusting for the covariates and are\nsometimes more worrisome due to inflated Type I error. The purpose of this\nstudy is to examine the unadjusted test for treatment effect under generalized\nlinear models and covariate-adaptive randomization. For a large class of\ncovariate-adaptive randomization methods, we obtain the asymptotic distribution\nof the test statistic under the null hypothesis and derive the conditions under\nwhich the test is conservative, valid, or anti-conservative. Several commonly\nused generalized linear models, such as logistic regression and Poisson\nregression, are discussed in detail. An adjustment method is also proposed to\nachieve a valid size based on the asymptotic results. Numerical studies confirm\nthe theoretical findings and demonstrate the effectiveness of the proposed\nadjustment method.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 07:15:48 GMT"}, {"version": "v2", "created": "Sun, 2 May 2021 10:42:42 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Yang", "Li", ""], ["Ma", "Wei", ""], ["Qin", "Yichen", ""], ["Hu", "Feifang", ""]]}, {"id": "2009.04188", "submitter": "Fran\\c{c}ois Bachoc", "authors": "Fran\\c{c}ois Bachoc, Andr\\'es F. L\\'opez Lopera and Olivier Roustant", "title": "Sequential construction and dimension reduction of Gaussian processes\n  under inequality constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accounting for inequality constraints, such as boundedness, monotonicity or\nconvexity, is challenging when modeling costly-to-evaluate black box functions.\nIn this regard, finite-dimensional Gaussian process (GP) models bring a\nvaluable solution, as they guarantee that the inequality constraints are\nsatisfied everywhere. Nevertheless, these models are currently restricted to\nsmall dimensional situations (up to dimension 5). Addressing this issue, we\nintroduce the MaxMod algorithm that sequentially inserts one-dimensional knots\nor adds active variables, thereby performing at the same time dimension\nreduction and efficient knot allocation. We prove the convergence of this\nalgorithm. In intermediary steps of the proof, we propose the notion of\nmulti-affine extension and study its properties. We also prove the convergence\nof finite-dimensional GPs, when the knots are not dense in the input space,\nextending the recent literature. With simulated and real data, we demonstrate\nthat the MaxMod algorithm remains efficient in higher dimension (at least in\ndimension 20), and has a smaller computational complexity than other\nconstrained GP models from the state-of-the-art, to reach a given approximation\nerror.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 09:44:07 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Bachoc", "Fran\u00e7ois", ""], ["Lopera", "Andr\u00e9s F. L\u00f3pez", ""], ["Roustant", "Olivier", ""]]}, {"id": "2009.04252", "submitter": "Wolfgang Karl H\\\"ardle", "authors": "Wolfgang Karl H\\\"ardle, Li-Shan Huang", "title": "Analysis of Deviance for Hypothesis Testing in Generalized Partially\n  Linear Models", "comments": null, "journal-ref": "Journal of Business & Economic Statistics, Volume 37, 2019 - Issue\n  2", "doi": "10.1080/07350015.2017.1330693", "report-no": null, "categories": "math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this study, we develop nonparametric analysis of deviance tools for\ngeneralized partially linear models based on local polynomial fitting. Assuming\na canonical link, we propose expressions for both local and global analysis of\ndeviance, which admit an additivity property that reduces to analysis of\nvariance decompositions in the Gaussian case. Chi-square tests based on\nintegrated likelihood functions are proposed to formally test whether the\nnonparametric term is significant. Simulation results are shown to illustrate\nthe proposed chi-square tests and to compare them with an existing procedure\nbased on penalized splines. The methodology is applied to German Bundesbank\nFederal Reserve data.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 12:20:35 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["H\u00e4rdle", "Wolfgang Karl", ""], ["Huang", "Li-Shan", ""]]}, {"id": "2009.04313", "submitter": "Tam\\'as F M\\'ori", "authors": "Tam\\'as F. M\\'ori and G\\'abor J. Sz\\'ekely", "title": "The Earth Mover's Correlation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Since Pearson's correlation was introduced at the end of the 19th century\nmany dependence measures have appeared in the literature. Recently we have\nsuggested four simple axioms for dependence measures of random variables that\ntake values in Hilbert spaces. We showed that distance correlation satisfies\nall these axioms. We still need a new measure of dependence because existing\nmeasures either do not work in general metric spaces (that are not Hilbert\nspaces) or they do not satisfy our four simple axioms. The earth mover's\ncorrelation introduced in this paper applies in general metric spaces and\nsatisfies our four axioms (two of them in a weaker form).\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 14:09:47 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["M\u00f3ri", "Tam\u00e1s F.", ""], ["Sz\u00e9kely", "G\u00e1bor J.", ""]]}, {"id": "2009.04428", "submitter": "Carlos Velasco", "authors": "Carlos Velasco", "title": "Identification and estimation of Structural VARMA models using higher\n  order dynamics", "comments": "71 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use information from higher order moments to achieve identification of\nnon-Gaussian structural vector autoregressive moving average (SVARMA) models,\npossibly non-fundamental or non-causal, through a frequency domain criterion\nbased on a new representation of the higher order spectral density arrays of\nvector linear processes. This allows to identify the location of the roots of\nthe determinantal lag matrix polynomials based on higher order cumulants\ndynamics and to identify the rotation of the model errors leading to the\nstructural shocks up to sign and permutation. We describe sufficient conditions\nfor global and local parameter identification that rely on simple rank\nassumptions on the linear dynamics and on finite order serial and component\nindependence conditions for the structural innovations. We generalize previous\nunivariate analysis to develop asymptotically normal and efficient estimates\nexploiting second and non-Gaussian higher order dynamics given a particular\nstructural shocks ordering without assumptions on causality or invertibility.\nBootstrap approximations to finite sample distributions and the properties of\nnumerical methods are explored with real and simulated data.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 17:24:54 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Velasco", "Carlos", ""]]}, {"id": "2009.04651", "submitter": "Donlapark Ponnoprat", "authors": "Donlapark Ponnoprat", "title": "Universal consistency of Wasserstein $k$-NN classifier", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Wasserstein distance provides a notion of dissimilarities between\nprobability measures, which has recent applications in learning of structured\ndata with varying size such as images and text documents. In this work, we\nanalyze the $k$-nearest neighbor classifier ($k$-NN) under the Wasserstein\ndistance and establish the universal consistency on families of distributions.\nUsing previous known results on the consistency of the $k$-NN classifier on\ninfinite dimensional metric spaces, it suffices to show that the families is a\ncountable union of finite dimension sets. As a result, we show that the $k$-NN\nclassifier is universally consistent on spaces of finitely supported measures,\nthe space of Gaussian measures, and the space of measures with finite wavelet\ndensities. In addition, we give a counterexample to show that the universal\nconsistency does not hold on $\\mathcal{W}_p((0,1))$.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 03:05:05 GMT"}, {"version": "v2", "created": "Sun, 13 Sep 2020 07:51:21 GMT"}, {"version": "v3", "created": "Mon, 14 Jun 2021 18:39:18 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Ponnoprat", "Donlapark", ""]]}, {"id": "2009.04710", "submitter": "Abhik Ghosh PhD", "authors": "Soumya Chakraborty, Ayanendranath Basu, Abhik Ghosh", "title": "Robust Clustering with Normal Mixture Models: A Pseudo\n  $\\beta$-Likelihood Approach", "comments": "Pre-print", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As in other estimation scenarios, likelihood based estimation in the normal\nmixture set-up is highly non-robust against model misspecification and presence\nof outliers (apart from being an ill-posed optimization problem). We propose a\nrobust alternative to the ordinary likelihood approach for this estimation\nproblem which performs simultaneous estimation and data clustering and leads to\nsubsequent anomaly detection. To invoke robustness, we follow, in spirit, the\nmethodology based on the minimization of the density power divergence (or\nalternatively, the maximization of the $\\beta$-likelihood) under suitable\nconstraints. An iteratively reweighted least squares approach has been followed\nin order to compute our estimators for the component means (or equivalently\ncluster centers) and component dispersion matrices which leads to simultaneous\ndata clustering. Some exploratory techniques are also suggested for anomaly\ndetection, a problem of great importance in the domain of statistics and\nmachine learning. Existence and consistency of the estimators are established\nunder the aforesaid constraints. We validate our method with simulation studies\nunder different set-ups; it is seen to perform competitively or better compared\nto the popular existing methods like K-means and TCLUST, especially when the\nmixture components (i.e., the clusters) share regions with significant overlap\nor outlying clusters exist with small but non-negligible weights. Two real\ndatasets are also used to illustrate the performance of our method in\ncomparison with others along with an application in image processing. It is\nobserved that our method detects the clusters with lower misclassification\nrates and successfully points out the outlying (anomalous) observations from\nthese datasets.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 07:50:08 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Chakraborty", "Soumya", ""], ["Basu", "Ayanendranath", ""], ["Ghosh", "Abhik", ""]]}, {"id": "2009.04729", "submitter": "Xiaoyu Lei", "authors": "Xiaoyu Lei, Huiming Zhang", "title": "Non-asymptotic Optimal Prediction Error for RKHS-based Partially\n  Functional Linear Models", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.FA stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Under the framework of reproducing kernel Hilbert space (RKHS), we consider\nthe penalized least-squares of the partially functional linear models (PFLM),\nwhose predictor contains both functional and traditional multivariate part, and\nthe multivariate part allows a divergent number of parameters. From the\nnon-asymptotic point of view, we focus on the rate-optimal upper and lower\nbounds of the prediction error. An exact upper bound for the excess prediction\nrisk is shown in a non-asymptotic form under a more general assumption known as\nthe effective dimension to the model, by which we also show the prediction\nconsistency when the number of multivariate covariates $p$ slightly increases\nwith the sample size $n$. Our new finding implies a trade-off between the\nnumber of non-functional predictors and the effective dimension of the kernel\nprincipal components to ensure the prediction consistency in the\nincreasing-dimensional setting. The analysis in our proof hinges on the\nspectral condition of the sandwich operator of the covariance operator and the\nreproducing kernel, and on the concentration inequalities for the random\nelements in Hilbert space. Finally, we derive the non-asymptotic minimax lower\nbound under the regularity assumption of Kullback-Leibler divergence of the\nmodels.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 08:49:32 GMT"}, {"version": "v2", "created": "Sat, 21 Nov 2020 02:40:31 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Lei", "Xiaoyu", ""], ["Zhang", "Huiming", ""]]}, {"id": "2009.04747", "submitter": "Mohammad Ghorbani Dr.", "authors": "Mohammad Ghorbani, Nafiseh Vafaei, Ji\\v{r}\\'i Dvo\\v{r}\\'ak, Mari\n  Myllym\\\"aki", "title": "Testing the first-order separability hypothesis for spatio-temporal\n  point patterns", "comments": "21 pages, 8 Figures (21 plots)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.AP stat.OT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  First-order separability of a spatio-temporal point process plays a\nfundamental role in the analysis of spatio-temporal point pattern data. While\nit is often a convenient assumption that simplifies the analysis greatly,\nexisting non-separable structures should be accounted for in the model\nconstruction. We propose three different tests to investigate this hypothesis\nas a step of preliminary data analysis. The first two tests are exact or\nasymptotically exact for Poisson processes. The first test based on\npermutations and global envelopes allows us to detect at which spatial and\ntemporal locations or lags the data deviate from the null hypothesis. The\nsecond test is a simple and computationally cheap $\\chi^2$-test. The third test\nis based on statistical reconstruction method and can be generally applied for\nnon-Poisson processes. The performance of the first two tests is studied in a\nsimulation study for Poisson and non-Poisson models. The third test is applied\nto the real data of the UK 2001 epidemic foot and mouth disease.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 09:35:16 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Ghorbani", "Mohammad", ""], ["Vafaei", "Nafiseh", ""], ["Dvo\u0159\u00e1k", "Ji\u0159\u00ed", ""], ["Myllym\u00e4ki", "Mari", ""]]}, {"id": "2009.04823", "submitter": "Celeste Mayer", "authors": "Vicky Fasen-Hartmann, Celeste Mayer", "title": "A note on estimation of $\\alpha$-stable CARMA processes sampled at low\n  frequencies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate estimators for symmetric $\\alpha$-stable CARMA\nprocesses sampled equidistantly. Simulation studies suggest that the Whittle\nestimator and the estimator presented in Garc\\'{\\i}a et al. (2011) are\nconsistent estimators for the parameters of stable CARMA processes. For CARMA\nprocesses with finite second moments it is well-known that the Whittle\nestimator is consistent and asymptotically normally distributed. Therefore, in\nthe light-tailed setting the properties of the Whittle estimator for CARMA\nprocesses are similar to those of the Whittle estimator for ARMA processes.\nHowever, in the present paper we prove that, in general, the Whittle estimator\nfor symmetric $\\alpha$-stable CARMA processes sampled at low frequencies is not\nconsistent and highlight why simulation studies suggest something else. Thus,\nin contrast to the light-tailed setting the properties of the Whittle estimator\nfor heavy-tailed ARMA processes can not be transferred to heavy-tailed CARMA\nprocesses. We elaborate as well that the estimator presented in Garc\\'{\\i}a et\nal. (2011) faces the same problems. However, the Whittle estimator for stable\nCAR(1) processes is consistent.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 12:48:26 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Fasen-Hartmann", "Vicky", ""], ["Mayer", "Celeste", ""]]}, {"id": "2009.04850", "submitter": "Hemant Tyagi", "authors": "Micha\\\"el Fanuel and Hemant Tyagi", "title": "Denoising modulo samples: k-NN regression and tightness of SDP\n  relaxation", "comments": "(i) 38 pages, 6 figures (ii) Revised the manuscript after receiving\n  reviews (iii) Removed Theorem 3(2) and Corollary 3 due to inaccuracies in the\n  proof, main results are unchanged (iv) Added Appendix B (v) Added Section 2.5\n  for estimating f (Theorem 5)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.OC stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many modern applications involve the acquisition of noisy modulo samples of a\nfunction $f$, with the goal being to recover estimates of the original samples\nof $f$. For a Lipschitz function $f:[0,1]^d \\to \\mathbb{R}$, suppose we are\ngiven the samples $y_i = (f(x_i) + \\eta_i)\\bmod 1; \\quad i=1,\\dots,n$ where\n$\\eta_i$ denotes noise. Assuming $\\eta_i$ are zero-mean i.i.d Gaussian's, and\n$x_i$'s form a uniform grid, we derive a two-stage algorithm that recovers\nestimates of the samples $f(x_i)$ with a uniform error rate $O((\\frac{\\log\nn}{n})^{\\frac{1}{d+2}})$ holding with high probability. The first stage\ninvolves embedding the points on the unit complex circle, and obtaining\ndenoised estimates of $f(x_i)\\bmod 1$ via a $k$NN (nearest neighbor) estimator.\nThe second stage involves a sequential unwrapping procedure which unwraps the\ndenoised mod $1$ estimates from the first stage. The estimates of the samples\n$f(x_i)$ can be subsequently utilized to construct an estimate of the function\n$f$, with the aforementioned uniform error rate.\n  Recently, Cucuringu and Tyagi proposed an alternative way of denoising modulo\n$1$ data which works with their representation on the unit complex circle. They\nformulated a smoothness regularized least squares problem on the product\nmanifold of unit circles, where the smoothness is measured with respect to the\nLaplacian of a proximity graph $G$ involving the $x_i$'s. This is a nonconvex\nquadratically constrained quadratic program (QCQP) hence they proposed solving\nits semidefinite program (SDP) based relaxation. We derive sufficient\nconditions under which the SDP is a tight relaxation of the QCQP. Hence under\nthese conditions, the global solution of QCQP can be obtained in polynomial\ntime.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 13:32:46 GMT"}, {"version": "v2", "created": "Sun, 2 May 2021 11:49:28 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Fanuel", "Micha\u00ebl", ""], ["Tyagi", "Hemant", ""]]}, {"id": "2009.04856", "submitter": "Francesco Buono", "authors": "Francesco Buono, Maria Longobardi, Magdalena Szymkowiak", "title": "On Generalized Reversed Aging Intensity Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The reversed aging intensity function is defined as the ratio of the\ninstantaneous reversed hazard rate to the baseline value of the reversed hazard\nrate. It analyzes the aging property quantitatively, the higher the reversed\naging intensity, the weaker the tendency of aging. In this paper, a family of\ngeneralized reversed aging intensity functions is introduced and studied. Those\nfunctions depend on a real parameter. If the parameter is positive they\ncharacterize uniquely the distribution functions of univariate positive\nabsolutely continuous random variables, in the opposite case they characterize\nfamilies of distributions. Furthermore, the generalized reversed aging\nintensity orders are defined and studied. Finally, several numerical examples\nare given.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 13:42:34 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Buono", "Francesco", ""], ["Longobardi", "Maria", ""], ["Szymkowiak", "Magdalena", ""]]}, {"id": "2009.04859", "submitter": "Hemant Tyagi", "authors": "Hemant Tyagi", "title": "Error analysis for denoising smooth modulo signals on a graph", "comments": "34 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many applications, we are given access to noisy modulo samples of a smooth\nfunction with the goal being to robustly unwrap the samples, i.e., to estimate\nthe original samples of the function. In a recent work, Cucuringu and Tyagi\nproposed denoising the modulo samples by first representing them on the unit\ncomplex circle and then solving a smoothness regularized least squares problem\n-- the smoothness measured w.r.t the Laplacian of a suitable proximity graph\n$G$ -- on the product manifold of unit circles. This problem is a quadratically\nconstrained quadratic program (QCQP) which is nonconvex, hence they proposed\nsolving its sphere-relaxation leading to a trust region subproblem (TRS). In\nterms of theoretical guarantees, $\\ell_2$ error bounds were derived for (TRS).\nThese bounds are however weak in general and do not really demonstrate the\ndenoising performed by (TRS).\n  In this work, we analyse the (TRS) as well as an unconstrained relaxation of\n(QCQP). For both these estimators we provide a refined analysis in the setting\nof Gaussian noise and derive noise regimes where they provably denoise the\nmodulo observations w.r.t the $\\ell_2$ norm. The analysis is performed in a\ngeneral setting where $G$ is any connected graph.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 13:45:21 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Tyagi", "Hemant", ""]]}, {"id": "2009.05150", "submitter": "Harold Chiang", "authors": "Harold D. Chiang, Kengo Kato, Yuya Sasaki", "title": "Inference for high-dimensional exchangeable arrays", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider inference for high-dimensional separately and jointly\nexchangeable arrays where the dimensions may be much larger than the sample\nsizes. For both exchangeable arrays, we first derive high-dimensional central\nlimit theorems over the rectangles and subsequently develop novel multiplier\nbootstraps with theoretical guarantees. These theoretical results rely on new\ntechnical tools such as Hoeffding-type decomposition and maximal inequalities\nfor the degenerate components in the Hoeffiding-type decomposition for the\nexchangeable arrays. We exhibit applications of our methods to uniform\nconfidence bands for density estimation under joint exchangeability and penalty\nchoice for $\\ell_1$-penalized regression under separate exchangeability.\nExtensive simulations demonstrate precise uniform coverage rates. We illustrate\nby constructing uniform confidence bands for international trade network\ndensities.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 21:03:01 GMT"}, {"version": "v2", "created": "Mon, 14 Sep 2020 01:24:54 GMT"}, {"version": "v3", "created": "Tue, 29 Dec 2020 17:55:38 GMT"}, {"version": "v4", "created": "Fri, 9 Jul 2021 23:27:16 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Chiang", "Harold D.", ""], ["Kato", "Kengo", ""], ["Sasaki", "Yuya", ""]]}, {"id": "2009.05162", "submitter": "Yuejuan Xi", "authors": "Yaozhong Hu and Yuejuan Xi", "title": "Estimation of all parameters in the reflected Orntein-Uhlenbeck process\n  from discrete observations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Assuming that a reflected Ornstein-Uhlenbeck state process is observed at\ndiscrete time instants, we propose generalized moment estimators to estimate\nall drift and diffusion parameters via the celebrated ergodic theorem. With the\nsampling time step h > 0 arbitrarily fixed, we prove the strong consistency and\nasymptotic normality of our estimators as the sampling size n tends to\ninfinity. This provides a complete solution to an open problem left in Hu et\nal. [5].\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 22:29:04 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Hu", "Yaozhong", ""], ["Xi", "Yuejuan", ""]]}, {"id": "2009.05232", "submitter": "Yuma Uehara", "authors": "Yuma Uehara", "title": "Bootstrap method for misspecified ergodic L\\'{e}vy driven stochastic\n  differential equation models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider possibly misspecified stochastic differential\nequation models driven by L\\'{e}vy processes. Regardless of whether the driving\nnoise is Gaussian or not, Gaussian quasi-likelihood estimator can estimate\nunknown parameters in the drift and scale coefficients. However, in the\nmisspecified case, the asymptotic distribution of the estimator varies by the\ncorrection of the misspecification bias, and consistent estimators for the\nasymptotic variance proposed in the correctly specified case may lose\ntheoretical validity. As one of its solutions, we propose a bootstrap method\nfor approximating the asymptotic distribution. We show that our bootstrap\nmethod theoretically works in both correctly specified case and misspecified\ncase without assuming the precise distribution of the driving noise.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 04:55:19 GMT"}, {"version": "v2", "created": "Mon, 8 Mar 2021 01:00:46 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Uehara", "Yuma", ""]]}, {"id": "2009.05298", "submitter": "Sven Wang", "authors": "Richard Nickl and Sven Wang", "title": "On polynomial-time computation of high-dimensional posterior measures by\n  Langevin-type algorithms", "comments": "68 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.NA math.AP math.NA math.PR stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of generating random samples of high-dimensional posterior\ndistributions is considered. The main results consist of non-asymptotic\ncomputational guarantees for Langevin-type MCMC algorithms which scale\npolynomially in key quantities such as the dimension of the model, the desired\nprecision level, and the number of available statistical measurements. As a\ndirect consequence, it is shown that posterior mean vectors as well as\noptimisation based maximum a posteriori (MAP) estimates are computable in\npolynomial time, with high probability under the distribution of the data.\nThese results are complemented by statistical guarantees for recovery of the\nground truth parameter generating the data.\n  Our results are derived in a general high-dimensional non-linear regression\nsetting (with Gaussian process priors) where posterior measures are not\nnecessarily log-concave, employing a set of local `geometric' assumptions on\nthe parameter space, and assuming that a good initialiser of the algorithm is\navailable. The theory is applied to a representative non-linear example from\nPDEs involving a steady-state Schr\\\"odinger equation.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 09:00:54 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Nickl", "Richard", ""], ["Wang", "Sven", ""]]}, {"id": "2009.05437", "submitter": "Karthik Sriram", "authors": "Kanti V. Mardia and Karthik Sriram", "title": "Families of discrete circular distributions with some novel applications", "comments": "46 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by some cutting edge circular data such as from Smart Home\ntechnologies and roulette spins from online and casino, we construct some new\nrich classes of discrete distributions on the circle. We give four new general\nmethods of construction, namely (i) maximum entropy, (ii) centered wrapping,\n(iii) marginalized and (iv) conditionalized methods. We motivate these methods\non the line and then work on the circular case and provide some properties to\ngain insight into these constructions. We mainly focus on the last two methods\n(iii) and (iv) in the context of circular location families, as they are\namenable to general methodology. We show that the marginalized and\nconditionalized discrete circular location families inherit important\nproperties from their parent continuous families. In particular, for the von\nMises and wrapped Cauchy as the parent distribution, we examine their\nproperties including the maximum likelihood estimators, the hypothesis test for\nuniformity and give a test of serial independence. Using our discrete circular\ndistributions, we demonstrate how to determine changepoint when the data arise\nin a sequence and how to fit mixtures of this distribution. Illustrative\nexamples are given which triggered the work. For example, for roulette data, we\ntest for uniformity (unbiasedness) , test for serial correlation, detect\nchangepoint in streaming roulette-spins data, and fit mixtures. We analyse a\nsmart home data using our mixtures. We examine the effect of ignoring\ndiscreteness of the underlying population, and discuss marginalized versus\nconditionalized approaches. We give various extensions of the families with\nskewness and kurtosis, to those supported on an irregular lattice, and discuss\npotential extension to general manifolds by showing a construction on the torus\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 13:44:06 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Mardia", "Kanti V.", ""], ["Sriram", "Karthik", ""]]}, {"id": "2009.05711", "submitter": "Lixing Zhu", "authors": "Chuyun Ye, Keli Guo, Lixing Zhu", "title": "Doubly robust estimation for conditional treatment effect: a study on\n  asymptotics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we apply doubly robust approach to estimate, when some\ncovariates are given, the conditional average treatment effect under\nparametric, semiparametric and nonparametric structure of the nuisance\npropensity score and outcome regression models. We then conduct a systematic\nstudy on the asymptotic distributions of nine estimators with different\ncombinations of estimated propensity score and outcome regressions. The study\ncovers the asymptotic properties with all models correctly specified; with\neither propensity score or outcome regressions locally / globally misspecified;\nand with all models locally / globally misspecified. The asymptotic variances\nare compared and the asymptotic bias correction under model-misspecification is\ndiscussed. The phenomenon that the asymptotic variance, with\nmodel-misspecification, could sometimes be even smaller than that with all\nmodels correctly specified is explored. We also conduct a numerical study to\nexamine the theoretical results.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 03:14:06 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Ye", "Chuyun", ""], ["Guo", "Keli", ""], ["Zhu", "Lixing", ""]]}, {"id": "2009.05974", "submitter": "Aur\\'elien Bibaut", "authors": "Aur\\'elien F. Bibaut, Alex Luedtke and Mark J. van der Laan", "title": "Sufficient and insufficient conditions for the stochastic convergence of\n  Ces\\`{a}ro means", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the stochastic convergence of the Ces\\`{a}ro mean of a sequence of\nrandom variables. These arise naturally in statistical problems that have a\nsequential component, where the sequence of random variables is typically\nderived from a sequence of estimators computed on data. We show that\nestablishing a rate of convergence in probability for a sequence is not\nsufficient in general to establish a rate in probability for its Ces\\`{a}ro\nmean. We also present several sets of conditions on the sequence of random\nvariables that are sufficient to guarantee a rate of convergence for its\nCes\\`{a}ro mean. We identify common settings in which these sets of conditions\nhold.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 10:26:01 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Bibaut", "Aur\u00e9lien F.", ""], ["Luedtke", "Alex", ""], ["van der Laan", "Mark J.", ""]]}, {"id": "2009.06004", "submitter": "Miles Lopes", "authors": "Miles E. Lopes", "title": "Central Limit Theorem and Bootstrap Approximation in High Dimensions\n  with Near $1/\\sqrt{n}$ Rates", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-asymptotic bounds for Gaussian and bootstrap approximation have recently\nattracted significant interest in high-dimensional statistics. This paper\nstudies Berry-Esseen bounds for such approximations (with respect to the\nmultivariate Kolmogorov distance), in the context of a sum of $n$ random\nvectors that are $p$-dimensional and i.i.d. Up to now, a growing line of work\nhas established bounds with mild logarithmic dependence on $p$. However, the\nproblem of developing corresponding bounds with near $n^{-1/2}$ dependence on\n$n$ has remained largely unresolved. Within the setting of random vectors that\nhave sub-Gaussian entries, this paper establishes bounds with near $n^{-1/2}$\ndependence, for both Gaussian and bootstrap approximation. In addition, the\nproofs are considerably distinct from other recent approaches.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 14:17:48 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Lopes", "Miles E.", ""]]}, {"id": "2009.06007", "submitter": "Sayar Karmakar", "authors": "Sayar Karmakar, Arkaprava Roy", "title": "Bayesian modelling of time-varying conditional heteroscedasticity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST econ.EM stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conditional heteroscedastic (CH) models are routinely used to analyze\nfinancial datasets. The classical models such as ARCH-GARCH with time-invariant\ncoefficients are often inadequate to describe frequent changes over time due to\nmarket variability. However we can achieve significantly better insight by\nconsidering the time-varying analogues of these models. In this paper, we\npropose a Bayesian approach to the estimation of such models and develop\ncomputationally efficient MCMC algorithm based on Hamiltonian Monte Carlo (HMC)\nsampling. We also established posterior contraction rates with increasing\nsample size in terms of the average Hellinger metric. The performance of our\nmethod is compared with frequentist estimates and estimates from the time\nconstant analogues. To conclude the paper we obtain time-varying parameter\nestimates for some popular Forex (currency conversion rate) and stock market\ndatasets.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 14:39:51 GMT"}, {"version": "v2", "created": "Mon, 8 Mar 2021 05:34:45 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Karmakar", "Sayar", ""], ["Roy", "Arkaprava", ""]]}, {"id": "2009.06107", "submitter": "Samuel Hopkins", "authors": "Matthew Brennan and Guy Bresler and Samuel B. Hopkins and Jerry Li and\n  Tselil Schramm", "title": "Statistical Query Algorithms and Low-Degree Tests Are Almost Equivalent", "comments": "Version 3 fixes typos and adds note on presentation at COLT 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Researchers currently use a number of approaches to predict and substantiate\ninformation-computation gaps in high-dimensional statistical estimation\nproblems. A prominent approach is to characterize the limits of restricted\nmodels of computation, which on the one hand yields strong computational lower\nbounds for powerful classes of algorithms and on the other hand helps guide the\ndevelopment of efficient algorithms. In this paper, we study two of the most\npopular restricted computational models, the statistical query framework and\nlow-degree polynomials, in the context of high-dimensional hypothesis testing.\nOur main result is that under mild conditions on the testing problem, the two\nclasses of algorithms are essentially equivalent in power. As corollaries, we\nobtain new statistical query lower bounds for sparse PCA, tensor PCA and\nseveral variants of the planted clique problem.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 22:55:18 GMT"}, {"version": "v2", "created": "Wed, 11 Nov 2020 05:28:15 GMT"}, {"version": "v3", "created": "Sat, 26 Jun 2021 17:06:23 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Brennan", "Matthew", ""], ["Bresler", "Guy", ""], ["Hopkins", "Samuel B.", ""], ["Li", "Jerry", ""], ["Schramm", "Tselil", ""]]}, {"id": "2009.06170", "submitter": "Qiaohui Lin", "authors": "Qiaohui Lin, Robert Lunde, Purnamrita Sarkar", "title": "Trading off Accuracy for Speedup: Multiplier Bootstraps for Subgraph\n  Counts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new class of multiplier bootstraps for count functionals. We\nconsider bootstrap procedures with linear and quadratic weights. These\ncorrespond to the first and second-order terms of the Hoeffding decomposition\nof the bootstrapped statistic arising from the multiplier bootstrap,\nrespectively. We show that the quadratic bootstrap procedure achieves\nhigher-order correctness for appropriately sparse graphs. The linear bootstrap\nprocedure requires fewer estimated network statistics, leading to improved\naccuracy over its higher-order correct counterpart in sparser regimes. To\nimprove the computational properties of the linear bootstrap further, we\nconsider fast sketching methods to conduct approximate subgraph counting and\nestablish consistency of the resulting bootstrap procedure. We complement our\ntheoretical results with a simulation study and real data analysis and verify\nthat our procedure offers state-of-the-art performance for several functionals.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 03:17:10 GMT"}, {"version": "v2", "created": "Wed, 7 Apr 2021 01:19:56 GMT"}, {"version": "v3", "created": "Mon, 12 Apr 2021 21:51:37 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Lin", "Qiaohui", ""], ["Lunde", "Robert", ""], ["Sarkar", "Purnamrita", ""]]}, {"id": "2009.06202", "submitter": "Johannes Lederer", "authors": "Johannes Lederer", "title": "Risk Bounds for Robust Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been observed that certain loss functions can render deep-learning\npipelines robust against flaws in the data. In this paper, we support these\nempirical findings with statistical theory. We especially show that\nempirical-risk minimization with unbounded, Lipschitz-continuous loss\nfunctions, such as the least-absolute deviation loss, Huber loss, Cauchy loss,\nand Tukey's biweight loss, can provide efficient prediction under minimal\nassumptions on the data. More generally speaking, our paper provides\ntheoretical evidence for the benefits of robust loss functions in deep\nlearning.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 05:06:59 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Lederer", "Johannes", ""]]}, {"id": "2009.06203", "submitter": "Nima Hejazi", "authors": "Nima S. Hejazi, Kara E. Rudolph, Mark J. van der Laan, Iv\\'an D\\'iaz", "title": "Nonparametric causal mediation analysis for stochastic interventional\n  (in)direct effects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal mediation analysis has historically been limited in two important\nways: (i) a focus has traditionally been placed on binary treatments and static\ninterventions, and (ii) direct and indirect effect decompositions have been\npursued that are only identifiable in the absence of intermediate confounders\naffected by treatment. We present a theoretical study of an (in)direct effect\ndecomposition of the population intervention effect, defined by stochastic\ninterventions jointly applied to the treatment and mediators. In contrast to\nexisting proposals, our causal effects can be evaluated regardless of whether a\ntreatment is categorical or continuous and remain well-defined even in the\npresence of intermediate confounders affected by treatment. Our (in)direct\neffects are identifiable without a restrictive assumption on cross-world\ncounterfactual independencies, allowing for substantive conclusions drawn from\nthem to be validated in randomized controlled trials. Beyond the novel effects\nintroduced, we provide a careful study of nonparametric efficiency theory\nrelevant for the construction of flexible, multiply robust estimators of our\n(in)direct effects, while avoiding undue restrictions induced by assuming\nparametric models of nuisance parameter functionals. To complement our\nnonparametric estimation strategy, we introduce inferential techniques for\nconstructing confidence intervals and hypothesis tests, and discuss open source\nsoftware implementing the proposed methodology.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 05:13:19 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2020 22:11:59 GMT"}, {"version": "v3", "created": "Sat, 3 Jul 2021 07:52:13 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Hejazi", "Nima S.", ""], ["Rudolph", "Kara E.", ""], ["van der Laan", "Mark J.", ""], ["D\u00edaz", "Iv\u00e1n", ""]]}, {"id": "2009.06221", "submitter": "Toma\\v{z} Ko\\v{s}ir", "authors": "Damjana Kokol Bukov\\v{s}ek, Toma\\v{z} Ko\\v{s}ir, Bla\\v{z}\n  Moj\\v{s}kerc, Matja\\v{z} Omladi\\v{c}", "title": "Spearman's footrule and Gini's gamma: Local bounds for bivariate copulas\n  and the exact region with respect to Blomqvist's beta", "comments": "30 pages, 13 figures", "journal-ref": null, "doi": "10.1016/j.cam.2021.113385", "report-no": null, "categories": "math.ST math.PR q-fin.RM q-fin.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Copulas are becoming an essential tool in analyzing data thus encouraging\ninterest in related questions. In the early stage of exploratory data analysis,\nsay, it is helpful to know local copula bounds with a fixed value of a given\nmeasure of association. These bounds have been computed for Spearman's rho,\nKendall's tau, and Blomqvist's beta. The importance of another two measures of\nassociation, Spearman's footrule and Gini's gamma, has been reconfirmed\nrecently. It is the main purpose of this paper to fill in the gap and present\nthe mentioned local bounds for these two measures as well. It turns out that\nthis is a quite non-trivial endeavor as the bounds are quasi-copulas that are\nnot copulas for certain values of the two measures. We also give relations\nbetween these two measures of association and Blomqvist's beta.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 06:33:45 GMT"}, {"version": "v2", "created": "Tue, 5 Jan 2021 12:03:04 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Bukov\u0161ek", "Damjana Kokol", ""], ["Ko\u0161ir", "Toma\u017e", ""], ["Moj\u0161kerc", "Bla\u017e", ""], ["Omladi\u010d", "Matja\u017e", ""]]}, {"id": "2009.06540", "submitter": "Ilias Diakonikolas", "authors": "Ilias Diakonikolas and Themis Gouleakis and Daniel M. Kane and John\n  Peebles and Eric Price", "title": "Optimal Testing of Discrete Distributions with High Probability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of testing discrete distributions with a focus on the\nhigh probability regime. Specifically, given samples from one or more discrete\ndistributions, a property $\\mathcal{P}$, and parameters $0< \\epsilon, \\delta\n<1$, we want to distinguish {\\em with probability at least $1-\\delta$} whether\nthese distributions satisfy $\\mathcal{P}$ or are $\\epsilon$-far from\n$\\mathcal{P}$ in total variation distance. Most prior work in distribution\ntesting studied the constant confidence case (corresponding to $\\delta =\n\\Omega(1)$), and provided sample-optimal testers for a range of properties.\nWhile one can always boost the confidence probability of any such tester by\nblack-box amplification, this generic boosting method typically leads to\nsub-optimal sample bounds.\n  Here we study the following broad question: For a given property\n$\\mathcal{P}$, can we {\\em characterize} the sample complexity of testing\n$\\mathcal{P}$ as a function of all relevant problem parameters, including the\nerror probability $\\delta$? Prior to this work, uniformity testing was the only\nstatistical task whose sample complexity had been characterized in this\nsetting. As our main results, we provide the first algorithms for closeness and\nindependence testing that are sample-optimal, within constant factors, as a\nfunction of all relevant parameters. We also show matching\ninformation-theoretic lower bounds on the sample complexity of these problems.\nOur techniques naturally extend to give optimal testers for related problems.\nTo illustrate the generality of our methods, we give optimal algorithms for\ntesting collections of distributions and testing closeness with unequal sized\nsamples.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 16:09:17 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Diakonikolas", "Ilias", ""], ["Gouleakis", "Themis", ""], ["Kane", "Daniel M.", ""], ["Peebles", "John", ""], ["Price", "Eric", ""]]}, {"id": "2009.06558", "submitter": "Marc Henry", "authors": "Yanqin Fan and Marc Henry", "title": "Vector copulas", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces vector copulas associated with multivariate\ndistributions with given multivariate marginals, based on the theory of measure\ntransportation, and establishes a vector version of Sklar's theorem. The latter\nprovides a theoretical justification for the use of vector copulas to\ncharacterize nonlinear or rank dependence between a finite number of random\nvectors (robust to within vector dependence), and to construct multivariate\ndistributions with any given non overlapping multivariate marginals. We\nconstruct Elliptical and Kendall families of vector copulas, derive their\ndensities, and present algorithms to generate data from them. The use of vector\ncopulas is illustrated with a stylized analysis of international financial\ncontagion.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 16:40:17 GMT"}, {"version": "v2", "created": "Mon, 12 Apr 2021 18:13:40 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Fan", "Yanqin", ""], ["Henry", "Marc", ""]]}, {"id": "2009.06621", "submitter": "Peng Ding", "authors": "Peng Ding", "title": "The Frisch--Waugh--Lovell Theorem for Standard Errors", "comments": null, "journal-ref": "Statistics and Probability Letters, 2020", "doi": null, "report-no": null, "categories": "math.ST econ.EM stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Frisch--Waugh--Lovell Theorem states the equivalence of the coefficients\nfrom the full and partial regressions. I further show the equivalence between\nvarious standard errors. Applying the new result to stratified experiments\nreveals the discrepancy between model-based and design-based standard errors.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 17:59:17 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Ding", "Peng", ""]]}, {"id": "2009.06784", "submitter": "Cheng Mao", "authors": "Cheng Mao and Yihong Wu", "title": "Learning Mixtures of Permutations: Groups of Pairwise Comparisons and\n  Combinatorial Method of Moments", "comments": "49 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.DS cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In applications such as rank aggregation, mixture models for permutations are\nfrequently used when the population exhibits heterogeneity. In this work, we\nstudy the widely used Mallows mixture model. In the high-dimensional setting,\nwe propose a polynomial-time algorithm that learns a Mallows mixture of\npermutations on $n$ elements with the optimal sample complexity that is\nproportional to $\\log n$, improving upon previous results that scale\npolynomially with $n$. In the high-noise regime, we characterize the optimal\ndependency of the sample complexity on the noise parameter. Both objectives are\naccomplished by first studying demixing permutations under a noiseless query\nmodel using groups of pairwise comparisons, which can be viewed as moments of\nthe mixing distribution, and then extending these results to the noisy Mallows\nmodel by simulating the noiseless oracle.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 23:11:46 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Mao", "Cheng", ""], ["Wu", "Yihong", ""]]}, {"id": "2009.06832", "submitter": "EPTCS", "authors": "Dominique Pastor (IMT Atlantique, LabSTICC, Universit\\'e de\n  Bretagne-Loire), Erwan Beurier (IMT Atlantique, LabSTICC, Universit\\'e de\n  Bretagne-Loire), Andr\\'ee Ehresmann (Facult\\'e des Sciences, Math\\'ematiques,\n  LAMFA, Universit\\'e de Picardie Jules Verne), Roger Waldeck (IMT Atlantique,\n  LEGO, Universit\\'e de Bretagne-Loire)", "title": "Interfacing biology, category theory and mathematical statistics", "comments": "In Proceedings ACT 2019, arXiv:2009.06334", "journal-ref": "EPTCS 323, 2020, pp. 136-148", "doi": "10.4204/EPTCS.323.9", "report-no": null, "categories": "math.CT cs.CE math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the concept of degeneracy in biology (Edelman, Gally 2001), we\nestablish a first connection between the Multiplicity Principle (Ehresmann,\nVanbremeersch 2007) and mathematical statistics. Specifically, we exhibit two\nfamilies of statistical tests that satisfy this principle to achieve the\ndetection of a signal in noise.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 02:15:18 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Pastor", "Dominique", "", "IMT Atlantique, LabSTICC, Universit\u00e9 de\n  Bretagne-Loire"], ["Beurier", "Erwan", "", "IMT Atlantique, LabSTICC, Universit\u00e9 de\n  Bretagne-Loire"], ["Ehresmann", "Andr\u00e9e", "", "Facult\u00e9 des Sciences, Math\u00e9matiques,\n  LAMFA, Universit\u00e9 de Picardie Jules Verne"], ["Waldeck", "Roger", "", "IMT Atlantique,\n  LEGO, Universit\u00e9 de Bretagne-Loire"]]}, {"id": "2009.07002", "submitter": "Fran\\c{c}ois Bachoc", "authors": "Fran\\c{c}ois Bachoc", "title": "Asymptotic analysis of maximum likelihood estimation of covariance\n  parameters for Gaussian processes: an introduction with proofs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article provides an introduction to the asymptotic analysis of\ncovariance parameter estimation for Gaussian processes. Maximum likelihood\nestimation is considered. The aim of this introduction is to be accessible to a\nwide audience and to present some existing results and proof techniques from\nthe literature. The increasing-domain and fixed-domain asymptotic settings are\nconsidered. Under increasing-domain asymptotics, it is shown that in general\nall the components of the covariance parameter can be estimated consistently by\nmaximum likelihood and that asymptotic normality holds. In contrast, under\nfixed-domain asymptotics, only some components of the covariance parameter,\nconstituting the microergodic parameter, can be estimated consistently. Under\nfixed-domain asymptotics, the special case of the family of isotropic Mat\\'ern\ncovariance functions is considered. It is shown that only a combination of the\nvariance and spatial scale parameter is microergodic. A consistency and\nasymptotic normality proof is sketched for maximum likelihood estimators.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 11:58:17 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Bachoc", "Fran\u00e7ois", ""]]}, {"id": "2009.07131", "submitter": "Anuj Abhishek", "authors": "Anuj Abhishek", "title": "Minimax optimal estimator in the stochastic inverse problem for\n  exponential Radon transform", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.DG stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we consider the problem of inverting the exponential Radon\ntransform of a function in the presence of noise. We propose a kernel estimator\nto estimate the true function, analogous to the one proposed by Korostel\\\"{e}v\nand Tsybakov in their article `Optimal rates of convergence of estimators in a\nprobabilistic setup of tomography problem', Problems of Information\nTransmission, 27:73-81,1991. For the estimator proposed in this article, we\nthen show that it converges to the true function at a minimax optimal rate.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 14:33:07 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Abhishek", "Anuj", ""]]}, {"id": "2009.07312", "submitter": "Florian Heinrichs", "authors": "Axel B\\\"ucher, Holger Dette, Florian Heinrichs", "title": "A Portmanteau-type test for detecting serial correlation in locally\n  stationary functional time series", "comments": "Keywords: Autocovariance operator, Block multiplier bootstrap,\n  Functional white noise, Time domain test", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Portmanteau test provides the vanilla method for detecting serial\ncorrelations in classical univariate time series analysis. The method is\nextended to the case of observations from a locally stationary functional time\nseries. Asymptotic critical values are obtained by a suitable block multiplier\nbootstrap procedure. The test is shown to asymptotically hold its level and to\nbe consistent against general alternatives.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 18:25:02 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["B\u00fccher", "Axel", ""], ["Dette", "Holger", ""], ["Heinrichs", "Florian", ""]]}, {"id": "2009.07341", "submitter": "Timo Dimitriadis", "authors": "Timo Dimitriadis and Xiaochun Liu and Julie Schnaitmann", "title": "Encompassing Tests for Value at Risk and Expected Shortfall Multi-Step\n  Forecasts based on Inference on the Boundary", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM math.ST q-fin.RM stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose forecast encompassing tests for the Expected Shortfall (ES)\njointly with the Value at Risk (VaR) based on flexible link (or combination)\nfunctions. Our setup allows testing encompassing for convex forecast\ncombinations and for link functions which preclude crossings of the combined\nVaR and ES forecasts. As the tests based on these link functions involve\nparameters which are on the boundary of the parameter space under the null\nhypothesis, we derive and base our tests on nonstandard asymptotic theory on\nthe boundary. Our simulation study shows that the encompassing tests based on\nour new link functions outperform tests based on unrestricted linear link\nfunctions for one-step and multi-step forecasts. We further illustrate the\npotential of the proposed tests in a real data analysis for forecasting VaR and\nES of the S&P 500 index.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 20:18:53 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Dimitriadis", "Timo", ""], ["Liu", "Xiaochun", ""], ["Schnaitmann", "Julie", ""]]}, {"id": "2009.07427", "submitter": "Zhenhua Lin", "authors": "Zhenhua Lin, Lingxuan Shao and Fang Yao", "title": "Intrinsic Riemannian Functional Data Analysis for Sparse Longitudinal\n  Observations", "comments": "36 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel framework is developed to intrinsically analyze sparsely observed\nRiemannian functional data. It features four innovative components: a\nframe-independent covariance function, a smooth vector bundle termed covariance\nvector bundle, a parallel transport and a smooth bundle metric on the\ncovariance vector bundle. The introduced intrinsic covariance function links\nestimation of covariance structure to smoothing problems that involve raw\ncovariance observations derived from sparsely observed Riemannian functional\ndata, while the covariance vector bundle provides a rigorous mathematical\nfoundation for formulating the smoothing problems. The parallel transport and\nthe bundle metric together make it possible to measure fidelity of fit to the\ncovariance function. They also plays a critical role in quantifying the quality\nof estimators for the covariance function. As an illustration, based on the\nproposed framework, we develop a local linear smoothing estimator for the\ncovariance function, analyze its theoretical properties, and provide numerical\ndemonstration via simulated and real datasets. The intrinsic feature of the\nframework makes it applicable to not only Euclidean submanifolds but also\nmanifolds without a canonical ambient space.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 02:29:07 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Lin", "Zhenhua", ""], ["Shao", "Lingxuan", ""], ["Yao", "Fang", ""]]}, {"id": "2009.07516", "submitter": "Maud Delattre", "authors": "Maud Delattre", "title": "A review on asymptotic inference in stochastic differential equations\n  with mixed-effects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is a survey of recent contributions on estimation in stochastic\ndifferential equations with mixed-effects. These models involve N stochastic\ndifferential equations with common drift and diffusion functions but random\nparameters that allow for differences between processes. The main objective is\nto estimate the distribution of the random effects and possibly other fixed\nparameters that are common to the N processes. While many algorithms have been\nproposed, the theoretical aspects related to estimation have been little\nstudied. This review article focuses only on theoretical inference for\nstochastic differential equations with mixed-effects. It has so far only been\nconsidered in some very specific classes of mixed-effect diffusion models,\nobserved without measurement error, where explicit estimators can be defined.\nWithin this framework, the asymptotic properties of several estimators, either\nparametric or nonparametric, are discussed. Different schemes of observations\nare considered according to the approach, associating a large number of\nindividuals with, in most cases, high-frequency observations of the\ntrajectories.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 07:30:26 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Delattre", "Maud", ""]]}, {"id": "2009.07520", "submitter": "Johannes Hertrich", "authors": "Johannes Hertrich, Dang Phoung Lan Nguyen, Jean-Fancois Aujol,\n  Dominique Bernard, Yannick Berthoumieu, Abdellatif Saadaldin, Gabriele Steidl", "title": "PCA Reduced Gaussian Mixture Models with Applications in Superresolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.IV math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the rapid development of computational hardware, the treatment of\nlarge and high dimensional data sets is still a challenging problem. This paper\nprovides a twofold contribution to the topic. First, we propose a Gaussian\nMixture Model in conjunction with a reduction of the dimensionality of the data\nin each component of the model by principal component analysis, called PCA-GMM.\nTo learn the (low dimensional) parameters of the mixture model we propose an EM\nalgorithm whose M-step requires the solution of constrained optimization\nproblems. Fortunately, these constrained problems do not depend on the usually\nlarge number of samples and can be solved efficiently by an (inertial) proximal\nalternating linearized minimization algorithm. Second, we apply our PCA-GMM for\nthe superresolution of 2D and 3D material images based on the approach of\nSandeep and Jacob. Numerical results confirm the moderate influence of the\ndimensionality reduction on the overall superresolution result.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 07:33:56 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2021 10:33:52 GMT"}, {"version": "v3", "created": "Thu, 6 May 2021 11:40:57 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Hertrich", "Johannes", ""], ["Nguyen", "Dang Phoung Lan", ""], ["Aujol", "Jean-Fancois", ""], ["Bernard", "Dominique", ""], ["Berthoumieu", "Yannick", ""], ["Saadaldin", "Abdellatif", ""], ["Steidl", "Gabriele", ""]]}, {"id": "2009.07542", "submitter": "Trung Vu", "authors": "Trung Vu, Evgenia Chunikhina and Raviv Raich", "title": "Perturbation expansions and error bounds for the truncated singular\n  value decomposition", "comments": "Accepted to Linear Algebra and Its Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Truncated singular value decomposition is a reduced version of the singular\nvalue decomposition in which only a few largest singular values are retained.\nThis paper presents a novel perturbation analysis for the truncated singular\nvalue decomposition for real matrices. First, we describe perturbation\nexpansions for the singular value truncation of order $r$. We extend\nperturbation results for the singular subspace decomposition to derive the\nfirst-order perturbation expansion of the truncated operator about a matrix\nwith rank greater than or equal to $r$. Observing that the first-order\nexpansion can be greatly simplified when the matrix has exact rank $r$, we\nfurther show that the singular value truncation admits a simple second-order\nperturbation expansion about a rank-$r$ matrix. Second, we introduce the\nfirst-known error bound on the linear approximation of the truncated singular\nvalue decomposition of a perturbed rank-$r$ matrix. Our bound only depends on\nthe least singular value of the unperturbed matrix and the norm of the\nperturbation matrix. Intriguingly, while the singular subspaces are known to be\nextremely sensitive to additive noises, the newly established error bound holds\nuniversally for perturbations with arbitrary magnitude. Finally, we demonstrate\nan application of our results to the analysis of the mean squared error\nassociated with the TSVD-based matrix denoising solution.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 08:28:29 GMT"}, {"version": "v2", "created": "Sun, 30 May 2021 19:04:35 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Vu", "Trung", ""], ["Chunikhina", "Evgenia", ""], ["Raich", "Raviv", ""]]}, {"id": "2009.07634", "submitter": "Arkaprava Roy", "authors": "Arkaprava Roy, Sayar Karmakar", "title": "Time-varying auto-regressive models for count time-series", "comments": "arXiv admin note: substantial text overlap with arXiv:2004.02281,\n  text overlap with arXiv:2009.06007", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Count-valued time series data are routinely collected in many application\nareas. We are particularly motivated to study the count time series of daily\nnew cases, arising from COVID-19 spread. We propose two Bayesian models, a\ntime-varying semiparametric AR(p) model for count and then a time-varying\nINGARCH model considering the rapid changes in the spread. We calculate\nposterior contraction rates of the proposed Bayesian methods with respect to\naverage Hellinger metric. Our proposed structures of the models are amenable to\nHamiltonian Monte Carlo (HMC) sampling for efficient computation. We\nsubstantiate our methods by simulations that show superiority compared to some\nof the close existing methods. Finally we analyze the daily time series data of\nnewly confirmed cases to study its spread through different government\ninterventions.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 21:50:49 GMT"}, {"version": "v2", "created": "Tue, 9 Mar 2021 16:09:21 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Roy", "Arkaprava", ""], ["Karmakar", "Sayar", ""]]}, {"id": "2009.07805", "submitter": "Yu-Lin Chou", "authors": "Yu-Lin Chou", "title": "An Intrinsic Treatment of Stochastic Linear Regression", "comments": "23 pages; some few minor changes, supplying a missing\n  acknowledgement, completing a sufficient condition with natural changes in\n  the surrounding texts", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear regression is perhaps one of the most popular statistical concepts,\nwhich permeates almost every scientific field of study. Due to the technical\nsimplicity and wide applicability of linear regression, attention is almost\nalways quickly directed to the algorithmic or computational side of linear\nregression. In particular, the underlying mathematics of stochastic linear\nregression itself as an entity usually gets either a peripheral treatment or a\nrelatively in-depth but ad hoc treatment depending on the type of concerned\nproblems; in other words, compared to the extensiveness of the study of\nmathematical properties of the \"derivatives\" of stochastic linear regression\nsuch as the least squares estimator, the mathematics of stochastic linear\nregression itself seems to have not yet received a due intrinsic treatment.\nApart from the conceptual importance, a consequence of an insufficient or\npossibly inaccurate understanding of stochastic linear regression would be the\nrecurrence for the role of stochastic linear regression in the important (and\nmore sophisticated) context of structural equation modeling to be misperceived\nor taught in a misleading way. We believe this pity is rectifiable when the\nfundamental concepts are correctly classified. Accompanied by some\nillustrative, distinguishing examples and counterexamples, we intend to pave\nout the mathematical framework for stochastic linear regression, in a rigorous\nbut non-technical way, by giving new results and pasting together several\nfundamental known results that are, we believe, both enlightening and\nconceptually useful, and that had not yet been systematically documented in the\nrelated literature. As a minor contribution, the way we arrange the fundamental\nknown results would be the first attempt in the related literature.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 16:55:40 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2020 10:15:53 GMT"}, {"version": "v3", "created": "Thu, 8 Oct 2020 12:36:59 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Chou", "Yu-Lin", ""]]}, {"id": "2009.08071", "submitter": "Yunyi Zhang", "authors": "Yunyi Zhang and Dimitris N. Politis", "title": "Ridge Regression Revisited: Debiasing, Thresholding and Bootstrap", "comments": "2 figures, 37 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of the Lasso in the era of high-dimensional data can be\nattributed to its conducting an implicit model selection, i.e., zeroing out\nregression coefficients that are not significant. By contrast, classical ridge\nregression can not reveal a potential sparsity of parameters, and may also\nintroduce a large bias under the high-dimensional setting. Nevertheless, recent\nwork on the Lasso involves debiasing and thresholding, the latter in order to\nfurther enhance the model selection. As a consequence, ridge regression may be\nworth another look since -- after debiasing and thresholding -- it may offer\nsome advantages over the Lasso, e.g., it can be easily computed using a\nclosed-form expression. % and it has similar performance to threshold Lasso. In\nthis paper, we define a debiased and thresholded ridge regression method, and\nprove a consistency result and a Gaussian approximation theorem. We further\nintroduce a wild bootstrap algorithm to construct confidence regions and\nperform hypothesis testing for a linear combination of parameters. In addition\nto estimation, we consider the problem of prediction, and present a novel,\nhybrid bootstrap algorithm tailored for prediction intervals. Extensive\nnumerical simulations further show that the debiased and thresholded ridge\nregression has favorable finite sample performance and may be preferable in\nsome settings.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 05:04:10 GMT"}, {"version": "v2", "created": "Thu, 22 Apr 2021 17:38:30 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Zhang", "Yunyi", ""], ["Politis", "Dimitris N.", ""]]}, {"id": "2009.08092", "submitter": "Preetum Nakkiran", "authors": "Preetum Nakkiran, Yamini Bansal", "title": "Distributional Generalization: A New Kind of Generalization", "comments": "Co-first authors. V2: Intro shortened; no new results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new notion of generalization -- Distributional Generalization\n-- which roughly states that outputs of a classifier at train and test time are\nclose *as distributions*, as opposed to close in just their average error. For\nexample, if we mislabel 30% of dogs as cats in the train set of CIFAR-10, then\na ResNet trained to interpolation will in fact mislabel roughly 30% of dogs as\ncats on the *test set* as well, while leaving other classes unaffected. This\nbehavior is not captured by classical generalization, which would only consider\nthe average error and not the distribution of errors over the input domain. Our\nformal conjectures, which are much more general than this example, characterize\nthe form of distributional generalization that can be expected in terms of\nproblem parameters: model architecture, training procedure, number of samples,\nand data distribution. We give empirical evidence for these conjectures across\na variety of domains in machine learning, including neural networks, kernel\nmachines, and decision trees. Our results thus advance our empirical\nunderstanding of interpolating classifiers.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 06:26:17 GMT"}, {"version": "v2", "created": "Thu, 15 Oct 2020 02:41:52 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Nakkiran", "Preetum", ""], ["Bansal", "Yamini", ""]]}, {"id": "2009.08130", "submitter": "Alexander McNeil", "authors": "Alexander J. McNeil and Johanna G. Neslehova and Andrew D. Smith", "title": "On attainability of Kendall's tau matrices and concordance signatures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The concordance signature of a multivariate continuous distribution is the\nvector of concordance probabilities for margins of all orders; it underlies the\nbivariate and multivariate Kendall's tau measure of concordance. It is shown\nthat every attainable concordance signature is equal to the concordance\nsignature of a unique mixture of the extremal copulas, that is the copulas with\nextremal correlation matrices consisting exclusively of 1's and -1's. This\nresult establishes that the set of attainable Kendall rank correlation matrices\nof multivariate continuous distributions in arbitrary dimension is the set of\nconvex combinations of extremal correlation matrices, a set known as the cut\npolytope. A methodology for testing the attainability of concordance signatures\nusing linear optimization and convex analysis is provided. The elliptical\ncopulas are shown to yield a strict subset of the attainable concordance\nsignatures as well as a strict subset of the attainable Kendall rank\ncorrelation matrices; the Student t copula is seen to converge to a mixture of\nextremal copulas sharing its concordance signature with all elliptical\ndistributions that have the same correlation matrix. A method of estimating an\nattainable concordance signature from data is derived and shown to correspond\nto using standard estimates of Kendall's tau in the absence of ties. The\nmethodology has application to Monte Carlo simulations of dependent random\nvariables as well as expert elicitation of consistent systems of Kendall's tau\ndependence measures.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 08:06:08 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2020 17:34:15 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["McNeil", "Alexander J.", ""], ["Neslehova", "Johanna G.", ""], ["Smith", "Andrew D.", ""]]}, {"id": "2009.08172", "submitter": "Asaf Levin", "authors": "Dorit S. Hochbaum and Asaf Levin and Xu Rao", "title": "Algorithms and Complexity for Variants of Covariates Fine Balance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM math.CO math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study here several variants of the covariates fine balance problem where\nwe generalize some of these problems and introduce a number of others. We\npresent here a comprehensive complexity study of the covariates problems\nproviding polynomial time algorithms, or a proof of NP-hardness. The polynomial\ntime algorithms described are mostly combinatorial and rely on network flow\ntechniques. In addition we present several fixed-parameter tractable results\nfor problems where the number of covariates and the number of levels of each\ncovariate are seen as a parameter.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 09:31:41 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Hochbaum", "Dorit S.", ""], ["Levin", "Asaf", ""], ["Rao", "Xu", ""]]}, {"id": "2009.08789", "submitter": "Zhenhua Lin", "authors": "Zhenhua Lin, Hans-Georg M\\\"uller and Byeong U. Park", "title": "Additive Models for Symmetric Positive-Definite Matrices, Riemannian\n  Manifolds and Lie groups", "comments": "21 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper an additive regression model for a symmetric positive-definite\nmatrix valued response and multiple scalar predictors is proposed. The model\nexploits the abelian group structure inherited from either the Log-Cholesky\nmetric or the Log-Euclidean framework that turns the space of symmetric\npositive-definite matrices into a Riemannian manifold and further a\nbi-invariant Lie group. The additive model for responses in the space of\nsymmetric positive-definite matrices with either of these metrics is shown to\nconnect to an additive model on a tangent space. This connection not only\nentails an efficient algorithm to estimate the component functions but also\nallows to generalize the proposed additive model to general Riemannian\nmanifolds that might not have a Lie group structure. Optimal asymptotic\nconvergence rates and normality of the estimated component functions are also\nestablished. Numerical studies show that the proposed model enjoys superior\nnumerical performance, especially when there are multiple predictors. The\npractical merits of the proposed model are demonstrated by analyzing diffusion\ntensor brain imaging data.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 12:29:31 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Lin", "Zhenhua", ""], ["M\u00fcller", "Hans-Georg", ""], ["Park", "Byeong U.", ""]]}, {"id": "2009.08848", "submitter": "Stefan Richter", "authors": "Nathawut Phandoidaen, Stefan Richter", "title": "Forecasting time series with encoder-decoder neural networks", "comments": "69 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider high-dimensional stationary processes where a new\nobservation is generated from a compressed version of past observations. The\nspecific evolution is modeled by an encoder-decoder structure. We estimate the\nevolution with an encoder-decoder neural network and give upper bounds for the\nexpected forecast error under specific structural and sparsity assumptions. The\nresults are shown separately for conditions either on the absolutely regular\nmixing coefficients or the functional dependence measure of the observed\nprocess. In a quantitative simulation we discuss the behavior of the network\nestimator under different model assumptions. We corroborate our theory by a\nreal data example where we consider forecasting temperature data.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 14:07:38 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Phandoidaen", "Nathawut", ""], ["Richter", "Stefan", ""]]}, {"id": "2009.08853", "submitter": "Holger Dette", "authors": "Holger Dette, Viatcheslav B. Melas, Petr Shpilev", "title": "A note on optimal designs for estimating the slope of a polynomial\n  regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note we consider the optimal design problem for estimating the slope\nof a polynomial regression with no intercept at a given point, say z. In\ncontrast to previous work, which considers symmetric design spaces we\ninvestigate the model on the interval $[0, a]$ and characterize those values of\n$z$, where an explicit solution of the optimal design is possible.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 14:20:49 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Dette", "Holger", ""], ["Melas", "Viatcheslav B.", ""], ["Shpilev", "Petr", ""]]}, {"id": "2009.09101", "submitter": "Andrew McCormack", "authors": "Andrew McCormack and Peter Hoff", "title": "The Stein Effect for Frechet Means", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Frechet mean is a useful description of location for a probability\ndistribution on a metric space that is not necessarily a vector space. This\narticle considers simultaneous estimation of multiple Frechet means from a\ndecision-theoretic perspective, and in particular, the extent to which the\nunbiased estimator of a Frechet mean can be dominated by a generalization of\nthe James-Stein shrinkage estimator. It is shown that if the metric space\nsatisfies a non-positive curvature condition, then this generalized James-Stein\nestimator asymptotically dominates the unbiased estimator as the dimension of\nthe space grows. These results hold for a large class of distributions on a\nvariety of spaces - including Hilbert spaces - and therefore partially extend\nknown results on the applicability of the James-Stein estimator to non-normal\ndistributions on Euclidean spaces. Simulation studies on metric trees and\nsymmetric-positive-definite matrices are presented, numerically demonstrating\nthe efficacy of this generalized James-Stein estimator.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 21:55:32 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["McCormack", "Andrew", ""], ["Hoff", "Peter", ""]]}, {"id": "2009.09177", "submitter": "Shengming Luo", "authors": "Jiashun Jin and Zheng Tracy Ke and Shengming Luo and Minzhe Wang", "title": "Estimating the number of communities by Stepwise Goodness-of-fit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a symmetric network with $n$ nodes, how to estimate the number of\ncommunities $K$ is a fundamental problem. We propose Stepwise Goodness-of-Fit\n(StGoF) as a new approach to estimating $K$. For $m = 1, 2, \\ldots$, StGoF\nalternately uses a community detection step (pretending $m$ is the correct\nnumber of communities) and a goodness-of-fit step. We use SCORE \\cite{SCORE}\nfor community detection, and propose a new goodness-of-fit measure. Denote the\ngoodness-of-fit statistic in step $m$ by $\\psi_n^{(m)}$. We show that as $n\n\\rightarrow \\infty$, $\\psi_n^{(m)} \\rightarrow N(0,1)$ when $m = K$ and\n$\\psi_n^{(m)} \\rightarrow \\infty$ in probability when $m < K$. Therefore, with\na proper threshold, StGoF terminates at $m = K$ as desired.\n  We consider a broad setting where we allow severe degree heterogeneity, a\nwide range of sparsity, and especially weak signals. In particular, we propose\na measure for signal-to-noise ratio (SNR) and show that there is a phase\ntransition: when $\\mathrm{SNR} \\rightarrow 0$ as $n \\rightarrow \\infty$,\nconsistent estimates for $K$ do not exist, and when $\\mathrm{SNR} \\rightarrow\n\\infty$, StGoF is consistent, uniformly for a broad class of settings. In this\nsense, StGoF achieves the optimal phase transition. Stepwise testing algorithms\nof similar kind (e.g., \\cite{wang2017likelihood, ma2018determining}) are known\nto face analytical challenges. We overcome the challenges by using a different\ndesign in the stepwise algorithm and by deriving sharp results in the\nunder-fitting case $(m < K)$ and the null case ($m = K$). The key to our\nanalysis is to show that SCORE has the {\\it Non-Splitting Property (NSP)}. The\nNSP is non-obvious, so additional to rigorous proofs, we also provide an\nintuitive explanation.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 06:44:14 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Jin", "Jiashun", ""], ["Ke", "Zheng Tracy", ""], ["Luo", "Shengming", ""], ["Wang", "Minzhe", ""]]}, {"id": "2009.09185", "submitter": "Martin Genzel", "authors": "Martin Genzel and Alexander Stollenwerk", "title": "A Unified Approach to Uniform Signal Recovery From Non-Linear\n  Observations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in quantized compressed sensing and high-dimensional\nestimation have shown that signal recovery is even feasible under strong\nnon-linear distortions in the observation process. An important characteristic\nof associated guarantees is uniformity, i.e., recovery succeeds for an entire\nclass of structured signals with a fixed measurement ensemble. However, despite\nsignificant results in various special cases, a general understanding of\nuniform recovery from non-linear observations is still missing. This paper\ndevelops a unified approach to this problem under the assumption i.i.d.\nsub-Gaussian measurement vectors. Our main result shows that a simple\nleast-squares estimator with any convex constraint can serve as a universal\nrecovery strategy, which is outlier robust and does not require explicit\nknowledge of the underlying non-linearity. Based on empirical process theory, a\nkey technical novelty is an approximative increment condition that can be\nimplemented for all common types of non-linear models. This flexibility allows\nus to apply our approach to a variety of problems in quantized compressed\nsensing and high-dimensional statistics, leading to several new and improved\nguarantees. Each of these applications is accompanied by a conceptually simple\nand systematic proof, which does not rely on any deeper properties of the\nobservation model. On the other hand, known local stability properties can be\nincorporated into our framework in a plug-and-play manner, thereby implying\nnear-optimal error bounds.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 08:29:30 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Genzel", "Martin", ""], ["Stollenwerk", "Alexander", ""]]}, {"id": "2009.09216", "submitter": "Pierre Lafaye de Micheaux", "authors": "Norbert Henze and Pierre Lafaye de Micheaux and Simos G. Meintanis", "title": "Tests for circular symmetry of complex-valued random vectors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose tests for the null hypothesis that the law of a complex-valued\nrandom vector is circularly symmetric. The test criteria are formulated as\n$L^2$-type criteria based on empirical characteristic functions, and they are\nconvenient from the computational point of view. Asymptotic as well as\nMonte-Carlo results are presented. Applications on real data are also reported.\nAn R package called CircSymTest is available from the authors.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 12:16:34 GMT"}, {"version": "v2", "created": "Fri, 19 Mar 2021 13:59:35 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Henze", "Norbert", ""], ["de Micheaux", "Pierre Lafaye", ""], ["Meintanis", "Simos G.", ""]]}, {"id": "2009.09248", "submitter": "Shouhao Zhou", "authors": "Shouhao Zhou", "title": "Posterior Averaging Information Criterion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new model selection method, the posterior averaging information\ncriterion, for Bayesian model assessment from a predictive perspective. The\ntheoretical foundation is built on the Kullback-Leibler divergence to quantify\nthe similarity between the proposed candidate model and the underlying true\nmodel. From a Bayesian perspective, our method evaluates the candidate models\nover the entire posterior distribution in terms of predicting a future\nindependent observation. Without assuming that the true distribution is\ncontained in the candidate models, the new criterion is developed by correcting\nthe asymptotic bias of the posterior mean of the log-likelihood against its\nexpected log-likelihood. It can be generally applied even for Bayesian models\nwith degenerate non-informative prior. The simulation in both normal and\nbinomial settings demonstrates decent small sample performance.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 14:58:34 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Zhou", "Shouhao", ""]]}, {"id": "2009.09286", "submitter": "Zhiqiang Tan", "authors": "Baoluo Sun, Zhiqiang Tan", "title": "High-dimensional Model-assisted Inference for Local Average Treatment\n  Effects with Instrumental Variables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider the problem of estimating the local average treatment effect with an\ninstrument variable, where the instrument unconfoundedness holds after\nadjusting for a set of measured covariates. Several unknown functions of the\ncovariates need to be estimated through regression models, such as instrument\npropensity score and treatment and outcome regression models. We develop a\ncomputationally tractable method in high-dimensional settings where the numbers\nof regression terms are close to or larger than the sample size. Our method\nexploits regularized calibrated estimation, which involves Lasso penalties but\ncarefully chosen loss functions for estimating coefficient vectors in these\nregression models, and then employs a doubly robust estimator for the treatment\nparameter through augmented inverse probability weighting. We provide rigorous\ntheoretical analysis to show that the resulting Wald confidence intervals are\nvalid for the treatment parameter under suitable sparsity conditions if the\ninstrument propensity score model is correctly specified, but the treatment and\noutcome regression models may be misspecified. For existing high-dimensional\nmethods, valid confidence intervals are obtained for the treatment parameter if\nall three models are correctly specified. We evaluate the proposed methods via\nextensive simulation studies and an empirical application to estimate the\nreturns to education.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 19:41:00 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Sun", "Baoluo", ""], ["Tan", "Zhiqiang", ""]]}, {"id": "2009.09304", "submitter": "Nikita Zhivotovskiy", "authors": "Tomas Va\\v{s}kevi\\v{c}ius and Nikita Zhivotovskiy", "title": "Suboptimality of Constrained Least Squares and Improvements via\n  Non-Linear Predictors", "comments": "37 pages, extended discussion, added references", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the problem of predicting as well as the best linear predictor in a\nbounded Euclidean ball with respect to the squared loss. When only boundedness\nof the data generating distribution is assumed, we establish that the least\nsquares estimator constrained to a bounded Euclidean ball does not attain the\nclassical $O(d/n)$ excess risk rate, where $d$ is the dimension of the\ncovariates and $n$ is the number of samples. In particular, we construct a\nbounded distribution such that the constrained least squares estimator incurs\nan excess risk of order $\\Omega(d^{3/2}/n)$ hence refuting a recent conjecture\nof Ohad Shamir [JMLR 2015]. In contrast, we observe that non-linear predictors\ncan achieve the optimal rate $O(d/n)$ with no assumptions on the distribution\nof the covariates. We discuss additional distributional assumptions sufficient\nto guarantee an $O(d/n)$ excess risk rate for the least squares estimator.\nAmong them are certain moment equivalence assumptions often used in the robust\nstatistics literature. While such assumptions are central in the analysis of\nunbounded and heavy-tailed settings, our work indicates that in some cases,\nthey also rule out unfavorable bounded distributions.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 21:39:46 GMT"}, {"version": "v2", "created": "Sun, 7 Mar 2021 16:24:01 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Va\u0161kevi\u010dius", "Tomas", ""], ["Zhivotovskiy", "Nikita", ""]]}, {"id": "2009.09310", "submitter": "Shanshan Cao", "authors": "Kai Ni, Shanshan Cao, and Xiaoming Huo", "title": "Fast and Asymptotically Powerful Detection for Filamentary Objects in\n  Digital Images", "comments": "13 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given an inhomogeneous chain embedded in a noisy image, we consider the\nconditions under which such an embedded chain is detectable. Many applications,\nsuch as detecting moving objects, detecting ship wakes, can be abstracted as\nthe detection on the existence of chains. In this work, we provide the\ndetection algorithm with low order of computation complexity to detect the\nchain and the optimal theoretical detectability regarding SNR (signal to noise\nratio) under the normal distribution model. Specifically, we derive an\nanalytical threshold that specifies what is detectable. We design a longest\nsignificant chain detection algorithm, with computation complexity in the order\nof $O(n\\log n)$. We also prove that our proposed algorithm is asymptotically\npowerful, which means, as the dimension $n \\rightarrow \\infty$, the probability\nof false detection vanishes. We further provide some simulated examples and a\nreal data example, which validate our theory.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 22:28:58 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Ni", "Kai", ""], ["Cao", "Shanshan", ""], ["Huo", "Xiaoming", ""]]}, {"id": "2009.09332", "submitter": "Xingzhi Pei", "authors": "Xingzhi Pei", "title": "Parameter estimation for Vasicek model driven by a general Gaussian\n  noise", "comments": "arXiv admin note: text overlap with arXiv:2002.09641 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper developed an inference problem for Vasicek model driven by a\ngeneral Gaussian process. We construct a least squares estimator and a moment\nestimator for the drift parameters of the Vasicek model, and we prove the\nconsistency and the asymptotic normality. Our approach extended the result of\nXiao and Yu (2018) for the case when noise is a fractional Brownian motion with\nHurst parameter H \\in [1/2,1).\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 01:30:36 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2020 11:44:53 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Pei", "Xingzhi", ""]]}, {"id": "2009.09420", "submitter": "Emiko Dupont", "authors": "Emiko Dupont, Simon N. Wood, Nicole Augustin", "title": "Spatial+: a novel approach to spatial confounding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In spatial regression models, collinearity between covariates and spatial\neffects can lead to significant bias in effect estimates. This problem, known\nas spatial confounding, is encountered modelling forestry data to assess the\neffect of temperature on tree health. Reliable inference is difficult as\nresults depend on whether or not spatial effects are included in the model. The\nmechanism behind spatial confounding is poorly understood and methods for\ndealing with it are limited. We propose a novel approach, spatial+, in which\ncollinearity is reduced by replacing the covariates in the spatial model by\ntheir residuals after spatial dependence has been regressed away. Using a thin\nplate spline model formulation, we recognise spatial confounding as a\nsmoothing-induced bias identified by Rice (1986), and through asymptotic\nanalysis of the effect estimates, we show that spatial+ avoids the bias\nproblems of the spatial model. This is also demonstrated in a simulation study.\nSpatial+ is straight-forward to implement using existing software and, as the\nresponse variable is the same as that of the spatial model, standard model\nselection criteria can be used for comparisons. A major advantage of the method\nis also that it extends to models with non-Gaussian response distributions.\nFinally, while our results are derived in a thin plate spline setting, the\nspatial+ methodology transfers easily to other spatial model formulations.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 12:11:35 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Dupont", "Emiko", ""], ["Wood", "Simon N.", ""], ["Augustin", "Nicole", ""]]}, {"id": "2009.09431", "submitter": "Goffredo Chirco", "authors": "Goffredo Chirco, Luigi Malag\\`o, Giovanni Pistone", "title": "Lagrangian and Hamiltonian Mechanics for Probabilities on the\n  Statistical Manifold", "comments": "39 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT hep-th math.IT math.OC stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide an Information-Geometric formulation of Classical Mechanics on the\nRiemannian manifold of probability distributions, which is an affine manifold\nendowed with a dually-flat connection. In a non-parametric formalism, we\nconsider the full set of positive probability functions on a finite sample\nspace, and we provide a specific expression for the tangent and cotangent\nspaces over the statistical manifold, in terms of a Hilbert bundle structure\nthat we call the Statistical Bundle. In this setting, we compute velocities and\naccelerations of a one-dimensional statistical model using the canonical dual\npair of parallel transports and define a coherent formalism for Lagrangian and\nHamiltonian mechanics on the bundle. Finally, in a series of examples, we show\nhow our formalism provides a consistent framework for accelerated natural\ngradient dynamics on the probability simplex, paving the way for direct\napplications in optimization, game theory and neural networks.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 14:03:13 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Chirco", "Goffredo", ""], ["Malag\u00f2", "Luigi", ""], ["Pistone", "Giovanni", ""]]}, {"id": "2009.09469", "submitter": "Alexey V. Lebedev", "authors": "Alexey V. Lebedev", "title": "Extremal Indices in the Series Scheme and their Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We generalize the concept of extremal index of a stationary random sequence\nto the series scheme of identically distributed random variables with random\nseries sizes tending to infinity in probability. We introduce new extremal\nindices through two definitions generalizing the basic properties of the\nclassical extremal index. We prove some useful properties of the new extremal\nindices. We show how the behavior of aggregate activity maxima on random graphs\n(in information network models) and the behavior of maxima of random particle\nscores in branching processes (in biological population models) can be\ndescribed in terms of the new extremal indices. We also obtain new results on\nmodels with copulas and threshold models. We show that the new indices can take\ndifferent values for the same system, as well as values greater than one.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 16:28:43 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Lebedev", "Alexey V.", ""]]}, {"id": "2009.09599", "submitter": "Olga Korotkova", "authors": "Olga Korotkova", "title": "Multi-Gaussian random variables", "comments": "14 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A generalization of the classic Gaussian random variable to the family of\nMulti- Gaussian (MG) random variables characterized by shape parameter M > 0,\nin addition to the mean and the standard deviation, is introduced. The\nprobability density function of the MG family members is the alternating series\nof the Gaussian functions with the suitably chosen heights and widths. In\nparticular, for the integer values of M the series has finite number of terms\nand leads to flattened profiles, while reducing to classic Gaussian density for\nM = 1. For non-integer, positive values of M a convergent infinite series of\nGaussian functions is obtained that can be truncated in practical problems.\nWhile for all M > 1 the MG PDF has attened profiles, for 0 < M < 1 it leads to\ncusped profiles. Moreover, the multivariate extension of the MG random variable\nis obtained and the Log-Multi-Gaussian (LMG) random variable is introduced.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 03:30:44 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Korotkova", "Olga", ""]]}, {"id": "2009.09695", "submitter": "Sophie Hautphenne", "authors": "Peter Braunsteins, Sophie Hautphenne, Carmen Minuesa", "title": "Parameter estimation in branching processes with almost sure extinction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider population-size-dependent branching processes (PSDBPs) which\neventually become extinct with probability one. For these processes, we derive\nmaximum likelihood estimators for the mean number of offspring born to\nindividuals when the current population size is $z\\geq 1$. As is standard in\nbranching process theory, an asymptotic analysis of the estimators requires us\nto condition on non-extinction up to a finite generation $n$ and let\n$n\\to\\infty$; however, because the processes become extinct with probability\none, we are able to demonstrate that our estimators do not satisfy the\nclassical consistency property ($C$-consistency). This leads us to define the\nconcept of $Q$-consistency, and we prove that our estimators are $Q$-consistent\nand asymptotically normal. To investigate the circumstances in which a\n$C$-consistent estimator is preferable to a $Q$-consistent estimator, we then\nprovide two $C$-consistent estimators for subcritical Galton-Watson branching\nprocesses. Our results rely on a combination of linear operator theory,\ncoupling arguments, and martingale methods.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 09:10:03 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Braunsteins", "Peter", ""], ["Hautphenne", "Sophie", ""], ["Minuesa", "Carmen", ""]]}, {"id": "2009.10285", "submitter": "Lixing Zhu", "authors": "Junshan Xie, Yicheng Zeng, Lixing Zhu", "title": "Limiting laws for extreme eigenvalues of large-dimensional spiked Fisher\n  matrices with a divergent number of spikes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider the $p\\times p$ matrix that is the product of a population\ncovariance matrix and the inverse of another population covariance matrix.\nSuppose that their difference has a divergent rank with respect to $p$, when\ntwo samples of sizes $n$ and $T$ from the two populations are available, we\nconstruct its corresponding sample version. In the regime of high dimension\nwhere both $n$ and $T$ are proportional to $p$, we investigate the limiting\nlaws for extreme (spiked) eigenvalues of the sample (spiked) Fisher matrix when\nthe number of spikes is divergent and these spikes are unbounded.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 02:34:26 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Xie", "Junshan", ""], ["Zeng", "Yicheng", ""], ["Zhu", "Lixing", ""]]}, {"id": "2009.10291", "submitter": "Xuejun Ma X.J. Ma", "authors": "Xuejun Ma, Yue Du and Jingli Wang", "title": "Model detection and variable selection for mode varying coefficient\n  model", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Varying coefficient model is often used in statistical modeling since it is\nmore flexible than the parametric model. However, model detection and variable\nselection of varying coefficient model are poorly understood in mode\nregression. Existing methods in the literature for these problems often based\non mean regression and quantile regression. In this paper, we propose a novel\nmethod to solve these problems for mode varying coefficient model based on the\nB-spline approximation and SCAD penalty. Moreover, we present a new algorithm\nto estimate the parameters of interest, and discuss the parameters selection\nfor the tuning parameters and bandwidth. We also establish the asymptotic\nproperties of estimated coefficients under some regular conditions. Finally, we\nillustrate the proposed method by some simulation studies and an empirical\nexample.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 02:48:53 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Ma", "Xuejun", ""], ["Du", "Yue", ""], ["Wang", "Jingli", ""]]}, {"id": "2009.10305", "submitter": "Yevgeniy Kovchegov", "authors": "Yevgeniy Kovchegov", "title": "A new life of Pearson's skewness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we show how coupling and stochastic dominance methods can be\nsuccessfully applied to a classical problem of rigorizing Pearson's skewness.\nHere, we use Fr\\'{e}chet means to define generalized notions of positive and\nnegative skewness that we call truly positive and truly negative. Then, we\napply stochastic dominance approach in establishing criteria for determining\nwhether a continuous random variable is truly positively skewed. Intuitively,\nthis means that scaled right tail of the probability density function exhibits\nstrict stochastic dominance over equivalently scaled left tail. Finally, we use\nthe stochastic dominance criteria and establish some basic examples of true\npositive skewness, thus demonstrating how the approach works in general.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 03:46:04 GMT"}, {"version": "v2", "created": "Tue, 29 Sep 2020 23:23:48 GMT"}, {"version": "v3", "created": "Sat, 26 Jun 2021 01:40:04 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Kovchegov", "Yevgeniy", ""]]}, {"id": "2009.10332", "submitter": "Maxwell Cairns", "authors": "Maxwell Cairns and Luke Prendergast", "title": "On ratio measures of population heterogeneity for meta-analyses", "comments": "Corrections made to Table 5 (V2), Updates to boxplot and table 4 (V3)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Popular measures of meta-analysis heterogeneity, such as $I^2$, cannot be\nconsidered measures of population heterogeneity since they are dependant on\nsamples sizes within studies. The coefficient of variation (CV) recently\nintroduced and defined to be the heterogeneity variance divided by the absolute\nvalue of the overall mean effect does not suffer such shortcomings. However,\nvery large CV values can occur when the effect is small making interpretation\ndifficult. The purpose of this paper is two-fold. Firstly, we consider variants\nof the CV that exist in the interval (0, 1] making interpretation simpler.\nSecondly, we provide interval estimators for the CV and its variants with\nexcellent coverage properties. We perform simulation studies based on simulated\nand real data sets and draw comparisons between the methods.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 05:55:15 GMT"}, {"version": "v2", "created": "Fri, 25 Sep 2020 10:45:49 GMT"}, {"version": "v3", "created": "Mon, 5 Oct 2020 02:26:20 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Cairns", "Maxwell", ""], ["Prendergast", "Luke", ""]]}, {"id": "2009.10383", "submitter": "Maximilian Wechsung", "authors": "Maximilian Wechsung (1) and Michael H. Neumann (2) ((1) Charit\\'e -\n  Universit\\\"atsmedizin Berlin, (2) Friedrich-Schiller-Universit\\\"at Jena)", "title": "Nonparametric least squares estimation in integer-valued GARCH models", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a nonparametric version of the integer-valued GARCH(1,1) model\nfor time series of counts. The link function in the recursion for the variances\nis not specified by finite-dimensional parameters, but we impose nonparametric\nsmoothness conditions. We propose a least squares estimator for this function\nand show that it is consistent with a rate that we conjecture to be nearly\noptimal.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 08:20:39 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Wechsung", "Maximilian", ""], ["Neumann", "Michael H.", ""]]}, {"id": "2009.10450", "submitter": "Lixing Zhu", "authors": "Niwen Zhou, Xu Guo, and Lixing Zhu", "title": "The Role of Propensity Score Structure in Asymptotic Efficiency of\n  Estimated Conditional Quantile Treatment Effect", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When a strict subset of covariates are given, we propose conditional quantile\ntreatment effect to capture the heterogeneity of treatment effects via the\nquantile sheet that is the function of the given covariates and quantile. We\nfocus on deriving the asymptotic normality of probability score-based\nestimators under parametric, nonparametric and semiparametric structure. We\nmake a systematic study on the estimation efficiency to check the importance of\npropensity score structure and the essential differences from the unconditional\ncounterparts. The derived unique properties can answer: what is the general\nranking of these estimators? how does the affiliation of the given covariates\nto the set of covariates of the propensity score affect the efficiency? how\ndoes the convergence rate of the estimated propensity score affect the\nefficiency? and why would semiparametric estimation be worth of recommendation\nin practice? We also give a brief discussion on the extension of the methods to\nhandle large-dimensional scenarios and on the estimation for the asymptotic\nvariances. The simulation studies are conducted to examine the performances of\nthese estimators. A real data example is analyzed for illustration and some new\nfindings are acquired.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 11:14:56 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Zhou", "Niwen", ""], ["Guo", "Xu", ""], ["Zhu", "Lixing", ""]]}, {"id": "2009.10482", "submitter": "Lixing Zhu", "authors": "Lu Li, Niwen Zhou, and Lixing Zhu", "title": "Outcome regression-based estimation of conditional average treatment\n  effect", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The research is about a systematic investigation on the following issues.\nFirst, we construct different outcome regression-based estimators for\nconditional average treatment effect under, respectively, true (oracle),\nparametric, nonparametric and semiparametric dimension reduction structure.\nSecond, according to the corresponding asymptotic variance functions, we answer\nthe following questions when supposing the models are correctly specified: what\nis the asymptotic efficiency ranking about the four estimators in general? how\nis the efficiency related to the affiliation of the given covariates in the set\nof arguments of the regression functions? what do the roles of bandwidth and\nkernel function selections play for the estimation efficiency; and in which\nscenarios should the estimator under semiparametric dimension reduction\nregression structure be used in practice? As a by-product, the results show\nthat any outcome regression-based estimation should be asymptotically more\nefficient than any inverse probability weighting-based estimation. All these\nresults give a relatively complete picture of the outcome regression-based\nestimation such that the theoretical conclusions could provide guidance for\npractical use when more than one estimations can be applied to the same\nproblem. Several simulation studies are conducted to examine the performances\nof these estimators in finite sample cases and a real dataset is analyzed for\nillustration.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 12:01:02 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Li", "Lu", ""], ["Zhou", "Niwen", ""], ["Zhu", "Lixing", ""]]}, {"id": "2009.10547", "submitter": "Sergio Brenner Miguel", "authors": "Sergio Brenner Miguel, Fabienne Comte and Jan Johannes", "title": "Spectral cut-off regularisation for density estimation under\n  multiplicative measurement errors", "comments": "22 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the non-parametric estimation of an unknown density f with support\non R+ based on an i.i.d. sample with multiplicative measurement errors. The\nproposed fully data driven procedure is based on the estimation of the Mellin\ntransform of the density f , a regularisation of the inverse of the Mellin\ntransform by a spectral cut-off and a data-driven model selection in order to\ndeal with the upcoming bias-variance trade-off. We introduce and discuss\nfurther Mellin-Sobolev spaces which characterize the regularity of the unknown\ndensity f through the decay of its Mellin transform. Additionally, we show\nminimax-optimality over Mellin-Sobolev spaces of the data-driven density\nestimator and hence its adaptivity.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 13:35:28 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Miguel", "Sergio Brenner", ""], ["Comte", "Fabienne", ""], ["Johannes", "Jan", ""]]}, {"id": "2009.10622", "submitter": "TrungTin Nguyen", "authors": "TrungTin Nguyen, Hien D Nguyen, Faicel Chamroukhi and Geoffrey J\n  McLachlan", "title": "An $l_1$-oracle inequality for the Lasso in mixture-of-experts\n  regression models", "comments": "Corrected typos. Added new Section 4. Discussion and comparisons", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.AI cs.LG stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mixture-of-experts (MoE) models are a popular framework for modeling\nheterogeneity in data, for both regression and classification problems in\nstatistics and machine learning, due to their flexibility and the abundance of\nstatistical estimation and model choice tools. Such flexibility comes from\nallowing the mixture weights (or gating functions) in the MoE model to depend\non the explanatory variables, along with the experts (or component densities).\nThis permits the modeling of data arising from more complex data generating\nprocesses, compared to the classical finite mixtures and finite mixtures of\nregression models, whose mixing parameters are independent of the covariates.\nThe use of MoE models in a high-dimensional setting, when the number of\nexplanatory variables can be much larger than the sample size (i.e., $p\\gg n$),\nis challenging from a computational point of view, and in particular from a\ntheoretical point of view, where the literature is still lacking results in\ndealing with the curse of dimensionality, in both the statistical estimation\nand feature selection. We consider the finite mixture-of-experts model with\nsoft-max gating functions and Gaussian experts for high-dimensional regression\non heterogeneous data, and its $l_1$-regularized estimation via the Lasso. We\nfocus on the Lasso estimation properties rather than its feature selection\nproperties. We provide a lower bound on the regularization parameter of the\nLasso function that ensures an $l_1$-oracle inequality satisfied by the Lasso\nestimator according to the Kullback-Leibler loss.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 15:23:35 GMT"}, {"version": "v2", "created": "Sun, 24 Jan 2021 17:28:26 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Nguyen", "TrungTin", ""], ["Nguyen", "Hien D", ""], ["Chamroukhi", "Faicel", ""], ["McLachlan", "Geoffrey J", ""]]}, {"id": "2009.10670", "submitter": "Daniel Hsu", "authors": "Daniel Hsu, Vidya Muthukumar, Ji Xu", "title": "On the proliferation of support vectors in high dimensions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The support vector machine (SVM) is a well-established classification method\nwhose name refers to the particular training examples, called support vectors,\nthat determine the maximum margin separating hyperplane. The SVM classifier is\nknown to enjoy good generalization properties when the number of support\nvectors is small compared to the number of training examples. However, recent\nresearch has shown that in sufficiently high-dimensional linear classification\nproblems, the SVM can generalize well despite a proliferation of support\nvectors where all training examples are support vectors. In this paper, we\nidentify new deterministic equivalences for this phenomenon of support vector\nproliferation, and use them to (1) substantially broaden the conditions under\nwhich the phenomenon occurs in high-dimensional settings, and (2) prove a\nnearly matching converse result.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 16:45:06 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Hsu", "Daniel", ""], ["Muthukumar", "Vidya", ""], ["Xu", "Ji", ""]]}, {"id": "2009.10683", "submitter": "Lin Chen", "authors": "Lin Chen, Sheng Xu", "title": "Deep Neural Tangent Kernel and Laplace Kernel Have the Same RKHS", "comments": "Accepted to ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that the reproducing kernel Hilbert spaces (RKHS) of a deep neural\ntangent kernel and the Laplace kernel include the same set of functions, when\nboth kernels are restricted to the sphere $\\mathbb{S}^{d-1}$. Additionally, we\nprove that the exponential power kernel with a smaller power (making the kernel\nless smooth) leads to a larger RKHS, when it is restricted to the sphere\n$\\mathbb{S}^{d-1}$ and when it is defined on the entire $\\mathbb{R}^d$.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 16:58:26 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2020 01:32:06 GMT"}, {"version": "v3", "created": "Wed, 30 Sep 2020 17:49:40 GMT"}, {"version": "v4", "created": "Thu, 1 Oct 2020 06:45:23 GMT"}, {"version": "v5", "created": "Thu, 18 Mar 2021 14:56:31 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Chen", "Lin", ""], ["Xu", "Sheng", ""]]}, {"id": "2009.10780", "submitter": "Tin Nguyen", "authors": "Tin D. Nguyen, Jonathan Huggins, Lorenzo Masoero, Lester Mackey,\n  Tamara Broderick", "title": "Independent finite approximations for Bayesian nonparametric inference", "comments": "Updated funding acknowledgments", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian nonparametric priors based on completely random measures (CRMs)\noffer a flexible modeling approach when the number of latent components in a\ndataset is unknown. However, managing the infinite dimensionality of CRMs\ntypically requires practitioners to derive ad-hoc algorithms, preventing the\nuse of general-purpose inference methods and often leading to long compute\ntimes. We propose a general but explicit recipe to construct a simple\nfinite-dimensional approximation that can replace the infinite-dimensional\nCRMs. Our independent finite approximation (IFA) is a generalization of\nimportant cases that are used in practice. The independence of atom weights in\nour approximation (i) makes the construction well-suited for parallel and\ndistributed computation and (ii) facilitates more convenient inference schemes.\nWe quantify the approximation error between IFAs and the target nonparametric\nprior. We compare IFAs with an alternative approximation scheme -- truncated\nfinite approximations (TFAs), where the atom weights are constructed\nsequentially. We prove that, for worst-case choices of observation likelihoods,\nTFAs are a more efficient approximation than IFAs. However, in real-data\nexperiments with image denoising and topic modeling, we find that IFAs perform\nvery similarly to TFAs in terms of task-specific accuracy metrics.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 19:37:21 GMT"}, {"version": "v2", "created": "Sun, 28 Feb 2021 20:33:53 GMT"}, {"version": "v3", "created": "Mon, 19 Jul 2021 22:36:57 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Nguyen", "Tin D.", ""], ["Huggins", "Jonathan", ""], ["Masoero", "Lorenzo", ""], ["Mackey", "Lester", ""], ["Broderick", "Tamara", ""]]}, {"id": "2009.10810", "submitter": "Hanbaek Lyu", "authors": "Hanbaek Lyu and Igor Pak", "title": "On the number of contingency tables and the independence heuristic", "comments": "10 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We obtain sharp asymptotic estimates on the number of $n \\times n$\ncontingency tables with two linear margins $Cn$ and $BCn$. The results imply a\nsecond order phase transition on the number of such contingency tables, with a\ncritical value at \\ts $B_{c}:=1 + \\sqrt{1+1/C}$. As a consequence, for \\ts\n$B>B_{c}$, we prove that the classical \\emph{independence heuristic} leads to a\nlarge undercounting.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 20:55:47 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Lyu", "Hanbaek", ""], ["Pak", "Igor", ""]]}, {"id": "2009.10838", "submitter": "James Melbourne", "authors": "James Melbourne", "title": "Strongly Convex Divergences", "comments": "Submitted to Entropy, special issue, Divergence Measures:\n  Mathematical Foundations and Applications in Information-Theoretic and\n  Statistical Problems, edited by Igal Sason", "journal-ref": null, "doi": "10.3390/e22111327", "report-no": null, "categories": "cs.IT math.IT math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a sub-class of the $f$-divergences satisfying a stronger\nconvexity property, which we refer to as strongly convex, or $\\kappa$-convex\ndivergences. We derive new and old relationships, based on convexity arguments,\nbetween popular $f$-divergences.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 22:09:47 GMT"}], "update_date": "2020-12-30", "authors_parsed": [["Melbourne", "James", ""]]}, {"id": "2009.10898", "submitter": "Lixing Zhu", "authors": "Niwen Zhou and Lixing Zhu", "title": "On IPW-based estimation of conditional average treatment effect", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The research in this paper gives a systematic investigation on the asymptotic\nbehaviours of four inverse probability weighting (IPW)-based estimators for\nconditional average treatment effect, with nonparametrically,\nsemiparametrically, parametrically estimated and true propensity score,\nrespectively. To this end, we first pay a particular attention to\nsemiparametric dimension reduction structure such that we can well study the\nsemiparametric-based estimator that can well alleviate the curse of\ndimensionality and greatly avoid model misspecification. We also derive some\nfurther properties of existing estimator with nonparametrically estimated\npropensity score. According to their asymptotic variance functions, the studies\nreveal the general ranking of their asymptotic efficiencies; in which scenarios\nthe asymptotic equivalence can hold; the critical roles of the affiliation of\nthe given covariates in the set of arguments of propensity score, the bandwidth\nand kernel selections. The results show an essential difference from the\nIPW-based (unconditional) average treatment effect(ATE). The numerical studies\nindicate that for high-dimensional paradigms, the semiparametric-based\nestimator performs well in general {whereas nonparametric-based estimator, even\nsometimes, parametric-based estimator, is more affected by dimensionality. Some\nnumerical studies are carried out to examine their performances. A real data\nexample is analysed for illustration.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 02:02:42 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Zhou", "Niwen", ""], ["Zhu", "Lixing", ""]]}, {"id": "2009.10900", "submitter": "Lixing Zhu", "authors": "Niwen Zhou, Xu Guo, and Lixing Zhu", "title": "A projection-based model checking for heterogeneous treatment effect", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the hypothesis testing problem that checks\nwhether part of covariates / confounders significantly affect the heterogeneous\ntreatment effect given all covariates. This model checking is particularly\nuseful in the case where there are many collected covariates such that we can\npossibly alleviate the typical curse of dimensionality.\n  In the test construction procedure, we use a projection-based idea and a\nnonparametric estimation-based test procedure to construct an aggregated\nversion over all projection directions. The resulting test statistic is then\ninterestingly with no effect from slow convergence rate the nonparametric\nestimation usually suffers from. This feature makes the test behave like a\nglobal smoothing test to have ability to detect a broad class of local\nalternatives converging to the null at the fastest possible rate in hypothesis\ntesting. Also, the test can inherit the merit of lobal smoothing tests to be\nsensitive to oscillating alternative models. The performance of the test is\nexamined by numerical studies and the analysis for a real data example for\nillustration.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 02:09:11 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Zhou", "Niwen", ""], ["Guo", "Xu", ""], ["Zhu", "Lixing", ""]]}, {"id": "2009.10902", "submitter": "Daniel Xiang", "authors": "Daniel Xiang, Peter McCullagh", "title": "Permanental Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The two components for infinite exchangeability of a sequence of\ndistributions $(P_n)$ are (i) consistency, and (ii) finite exchangeability for\neach $n$. A consequence of the Aldous-Hoover theorem is that any\nnode-exchangeable, subselection-consistent sequence of distributions that\ndescribes a randomly evolving network yields a sequence of random graphs whose\nexpected number of edges grows quadratically in the number of nodes. In this\nnote, another notion of consistency is considered, namely, delete-and-repair\nconsistency; it is motivated by the sense in which infinitely exchangeable\npermutations defined by the Chinese restaurant process (CRP) are consistent. A\ngoal is to exploit delete-and-repair consistency to obtain a nontrivial\nsequence of distributions on graphs $(P_n)$ that is sparse, exchangeable, and\nconsistent with respect to delete-and-repair, a well known example being the\nEwens permutations \\cite{tavare}. A generalization of the CRP$(\\alpha)$ as a\ndistribution on a directed graph using the $\\alpha$-weighted permanent is\npresented along with the corresponding normalization constant and degree\ndistribution; it is dubbed the Permanental Graph Model (PGM). A negative result\nis obtained: no setting of parameters in the PGM allows for a consistent\nsequence $(P_n)$ in the sense of either subselection or delete-and-repair.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 02:13:42 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Xiang", "Daniel", ""], ["McCullagh", "Peter", ""]]}, {"id": "2009.11010", "submitter": "Guangming Pan", "authors": "Zhixiang Zhang, Shurong Zheng, Guangming Pan, Pingshou Zhong", "title": "Asymptotic independence of spiked eigenvalues and linear spectral\n  statistics for large sample covariance matrices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider general high-dimensional spiked sample covariance models and show\nthat their leading sample spiked eigenvalues and their linear spectral\nstatistics are asymptotically independent when the sample size and dimension\nare proportional to each other. As a byproduct, we also establish the central\nlimit theorem of the leading sample spiked eigenvalues by removing the block\ndiagonal assumption on the population covariance matrix, which is commonly\nneeded in the literature. Moreover, we propose consistent estimators of the\n$L_4$ norm of the spiked population eigenvectors. Based on these results, we\ndevelop a new statistic to test the equality of two spiked population\ncovariance matrices. Numerical studies show that the new test procedure is more\npowerful than some existing methods.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 09:14:57 GMT"}, {"version": "v2", "created": "Thu, 24 Sep 2020 03:08:32 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Zhang", "Zhixiang", ""], ["Zheng", "Shurong", ""], ["Pan", "Guangming", ""], ["Zhong", "Pingshou", ""]]}, {"id": "2009.11124", "submitter": "Hien Nguyen", "authors": "Hien Duy Nguyen", "title": "Finite sample inference for generic autoregressive models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autoregressive stationary processes are fundamental modeling tools in time\nseries analysis. To conduct inference for such models usually requires\nasymptotic limit theorems. We establish finite sample-valid tools for\nhypothesis testing and confidence set construction in such settings. Further\nresults are established in the always-valid and sequential inference framework.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 13:04:09 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Nguyen", "Hien Duy", ""]]}, {"id": "2009.11134", "submitter": "Chris McKennan", "authors": "Chris McKennan", "title": "Factor analysis in high dimensional biological data with dependent\n  observations", "comments": "21 pages of main text, 85 with supplement; 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Factor analysis is a critical component of high dimensional biological data\nanalysis. However, modern biological data contain two key features that\nirrevocably corrupt existing methods. First, these data, which include\nlongitudinal, multi-treatment and multi-tissue data, contain samples that break\ncritical independence requirements necessary for the utilization of prevailing\nmethods. Second, biological data contain factors with large, moderate and small\nsignal strengths, and therefore violate the ubiquitous \"pervasive factor\"\nassumption essential to the performance of many methods. In this work, I\ndevelop a novel statistical framework to perform factor analysis and interpret\nits results in data with dependent observations and factors whose signal\nstrengths span several orders of magnitude. I then prove that my methodology\ncan be used to solve many important and previously unsolved problems that\nroutinely arise when analyzing dependent biological data, including high\ndimensional covariance estimation, subspace recovery, latent factor\ninterpretation and data denoising. Additionally, I show that my estimator for\nthe number of factors overcomes both the notorious \"eigenvalue shadowing\"\nproblem, as well as the biases due to the pervasive factor assumption that\nplague existing estimators. Simulated and real data demonstrate the superior\nperformance of my methodology in practice.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 13:23:29 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["McKennan", "Chris", ""]]}, {"id": "2009.11257", "submitter": "Federico Camerlenghi", "authors": "Fadhel Ayed, Marco Battiston, Federico Camerlenghi", "title": "An Information Theoretic approach to Post Randomization Methods under\n  Differential Privacy", "comments": null, "journal-ref": null, "doi": "10.1007/s11222-020-09949-3", "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Post Randomization Methods (PRAM) are among the most popular disclosure\nlimitation techniques for both categorical and continuous data. In the\ncategorical case, given a stochastic matrix $M$ and a specified variable, an\nindividual belonging to category $i$ is changed to category $j$ with\nprobability $M_{i,j}$. Every approach to choose the randomization matrix $M$\nhas to balance between two desiderata: 1) preserving as much statistical\ninformation from the raw data as possible; 2) guaranteeing the privacy of\nindividuals in the dataset. This trade-off has generally been shown to be very\nchallenging to solve. In this work, we use recent tools from the computer\nscience literature and propose to choose $M$ as the solution of a constrained\nmaximization problems. Specifically, $M$ is chosen as the solution of a\nconstrained maximization problem, where we maximize the Mutual Information\nbetween raw and transformed data, given the constraint that the transformation\nsatisfies the notion of Differential Privacy. For the general Categorical\nmodel, it is shown how this maximization problem reduces to a convex linear\nprogramming and can be therefore solved with known optimization algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 17:08:09 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Ayed", "Fadhel", ""], ["Battiston", "Marco", ""], ["Camerlenghi", "Federico", ""]]}, {"id": "2009.11282", "submitter": "Yuxin Chen", "authors": "Yanxi Chen, Cong Ma, H. Vincent Poor, Yuxin Chen", "title": "Learning Mixtures of Low-Rank Models", "comments": null, "journal-ref": "IEEE Transactions on Information Theory, 2021", "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG eess.SP math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning mixtures of low-rank models, i.e.\nreconstructing multiple low-rank matrices from unlabelled linear measurements\nof each. This problem enriches two widely studied settings -- low-rank matrix\nsensing and mixed linear regression -- by bringing latent variables (i.e.\nunknown labels) and structural priors (i.e. low-rank structures) into\nconsideration. To cope with the non-convexity issues arising from unlabelled\nheterogeneous data and low-complexity structure, we develop a three-stage\nmeta-algorithm that is guaranteed to recover the unknown matrices with\nnear-optimal sample and computational complexities under Gaussian designs. In\naddition, the proposed algorithm is provably stable against random noise. We\ncomplement the theoretical studies with empirical evidence that confirms the\nefficacy of our algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 17:53:48 GMT"}, {"version": "v2", "created": "Fri, 5 Mar 2021 21:36:55 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Chen", "Yanxi", ""], ["Ma", "Cong", ""], ["Poor", "H. Vincent", ""], ["Chen", "Yuxin", ""]]}, {"id": "2009.11413", "submitter": "Heejune Sheen", "authors": "Heejune Sheen, Yajun Mei", "title": "An elementary approach for minimax estimation of Bernoulli proportion in\n  the restricted parameter space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an elementary mathematical method to find the minimax estimator of\nthe Bernoulli proportion $\\theta$ under the squared error loss when $\\theta$\nbelongs to the restricted parameter space of the form $\\Omega = [0, \\eta]$ for\nsome pre-specified constant $0 \\leq \\eta \\leq 1$. This problem is inspired from\nthe problem of estimating the rate of positive COVID-19 tests. The presented\nresults and applications would be useful materials for both instructors and\nstudents when teaching point estimation in statistical or machine learning\ncourses.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 22:56:46 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Sheen", "Heejune", ""], ["Mei", "Yajun", ""]]}, {"id": "2009.11631", "submitter": "Olivier Peltre", "authors": "Olivier Peltre", "title": "Message-Passing Algorithms and Homology", "comments": "106 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math-ph math.AT math.MP math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This PhD thesis lays out algebraic and topological structures relevant for\nthe study of probabilistic graphical models.\n  Marginal estimation algorithms are introduced as diffusion equations of the\nform $\\dot u = \\delta \\varphi$. They generalise the traditional belief\npropagation (BP) algorithm, and provide an alternative for contrastive\ndivergence (CD) or Markov chain Monte Carlo (MCMC) algorithms, typically\ninvolved in estimating a free energy functional and its gradient w.r.t. model\nparameters.\n  We propose a new homological picture where parameters are a collections of\nlocal interaction potentials $(u_\\alpha) \\in A_0$, for $\\alpha$ running over\nthe factor nodes of a given region graph. The boundary operator $\\delta$\nmapping heat fluxes $(\\varphi_{\\alpha\\beta}) \\in A_1$ to a subspace $\\delta A_1\n\\subseteq A_0$ is the discrete analog of a divergence. The total energy $H =\n\\sum_\\alpha u_\\alpha$ defining the global probability $p = e^{-H} / Z$ is in\none-to-one correspondence with a homology class $[u] = u + \\delta A_1$ of\ninteraction potentials, so that total energy remains constant when $u$ evolves\nup to a boundary term $\\delta \\varphi$.\n  Stationary states of diffusion are shown to lie at the intersection of a\nhomology class of potentials with a non-linear constraint surface enforcing\nconsistency of the local marginals estimates. This picture allows us to precise\nand complete a proof on the correspondence between stationary states of BP and\ncritical points of a local free energy functional (obtained by Bethe-Kikuchi\napproximations) and to extend the uniqueness result for acyclic graphs (i.e.\ntrees) to a wider class of hypergraphs. In general, bifurcations of equilibria\nare related to the spectral singularities of a local diffusion operator,\nyielding new explicit examples of the degeneracy phenomenon.\n  Work supervised by Pr. Daniel Bennequin\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 12:25:46 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Peltre", "Olivier", ""]]}, {"id": "2009.11646", "submitter": "Halaleh Kamari", "authors": "Halaleh Kamari, Sylvie Huet, Marie-Luce Taupin", "title": "Risk upper bounds for RKHS ridge group sparse estimator in the\n  regression model with non-Gaussian and non-bounded error", "comments": "Previously this appeared as arXiv:1905.13695v3 which was submitted as\n  a replacement by accident. arXiv admin note: text overlap with\n  arXiv:1701.04671", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.OT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimating a meta-model of an unknown regression\nmodel with non-Gaussian and non-bounded error. The meta-model belongs to a\nreproducing kernel Hilbert space constructed as a direct sum of Hilbert spaces\nleading to an additive decomposition including the variables and interactions\nbetween them. The estimator of this meta-model is calculated by minimizing an\nempirical least-squares criterion penalized by the sum of the Hilbert norm and\nthe empirical $L^2$-norm. In this context, the upper bounds of the empirical\n$L^2$ risk and the $L^2$ risk of the estimator are established.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 20:28:06 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Kamari", "Halaleh", ""], ["Huet", "Sylvie", ""], ["Taupin", "Marie-Luce", ""]]}, {"id": "2009.11849", "submitter": "Jane Ivy Coons", "authors": "Tobias Boege, Jane Ivy Coons, Christopher Eur, Aida Maraj, Frank\n  R\\\"ottger", "title": "Reciprocal Maximum Likelihood Degrees of Brownian Motion Tree Models", "comments": "14 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.AG stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give an explicit formula for the reciprocal maximum likelihood degree of\nBrownian motion tree models. To achieve this, we connect them to certain toric\n(or log-linear) models, and express the Brownian motion tree model of an\narbitrary tree as a toric fiber product of star tree models.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 17:53:11 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Boege", "Tobias", ""], ["Coons", "Jane Ivy", ""], ["Eur", "Christopher", ""], ["Maraj", "Aida", ""], ["R\u00f6ttger", "Frank", ""]]}, {"id": "2009.12031", "submitter": "Guangming Pan", "authors": "Zhixiang Zhang and Guangming Pan", "title": "Tracy-Widom law for the extreme eigenvalues of large signal-plus-noise\n  matrices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $\\bY =\\bR+\\bX$ be an $M\\times N$ matrix, where $\\bR$ is a rectangular\ndiagonal matrix and $\\bX$ consists of $i.i.d.$ entries. This is a\nsignal-plus-noise type model. Its signal matrix could be full rank, which is\nrarely studied in literature compared with the low rank cases. This paper is to\nstudy the extreme eigenvalues of $\\bY\\bY^*$. We show that under the high\ndimensional setting ($M/N\\rightarrow c\\in(0,1]$) and some regularity conditions\non $\\bR$ the rescaled extreme eigenvalue converges in distribution to\nTracy-Widom distribution ($TW_1$).\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 04:30:09 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Zhang", "Zhixiang", ""], ["Pan", "Guangming", ""]]}, {"id": "2009.12297", "submitter": "Elad Romanov", "authors": "David L. Donoho, Matan Gavish and Elad Romanov", "title": "ScreeNOT: Exact MSE-Optimal Singular Value Thresholding in Correlated\n  Noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive a formula for optimal hard thresholding of the singular value\ndecomposition in the presence of correlated additive noise; although it\nnominally involves unobservables, we show how to apply it even where the noise\ncovariance structure is not a-priori known or is not independently estimable.\n  The proposed method, which we call ScreeNOT, is a mathematically solid\nalternative to Cattell's ever-popular but vague Scree Plot heuristic from 1966.\n  ScreeNOT has a surprising oracle property: it typically achieves exactly, in\nlarge finite samples, the lowest possible MSE for matrix recovery, on each\ngiven problem instance - i.e. the specific threshold it selects gives exactly\nthe smallest achievable MSE loss among all possible threshold choices for that\nnoisy dataset and that unknown underlying true low rank model. The method is\ncomputationally efficient and robust against perturbations of the underlying\ncovariance structure.\n  Our results depend on the assumption that the singular values of the noise\nhave a limiting empirical distribution of compact support; this model, which is\nstandard in random matrix theory, is satisfied by many models exhibiting either\ncross-row correlation structure or cross-column correlation structure, and also\nby many situations where there is inter-element correlation structure.\nSimulations demonstrate the effectiveness of the method even at moderate matrix\nsizes. The paper is supplemented by ready-to-use software packages implementing\nthe proposed algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 15:40:05 GMT"}, {"version": "v2", "created": "Thu, 6 May 2021 01:00:28 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Donoho", "David L.", ""], ["Gavish", "Matan", ""], ["Romanov", "Elad", ""]]}, {"id": "2009.12337", "submitter": "Alex Dytso", "authors": "Alex Dytso, Martina Cardone, and Cynthia Rush", "title": "Measuring Dependencies of Order Statistics: An Information Theoretic\n  Perspective", "comments": "This is an extended version of a paper submitted to IEEE ITW 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a random sample $X_1 , X_2 , ..., X_n$ drawn independently and\nidentically distributed from some known sampling distribution $P_X$. Let\n$X_{(1)} \\le X_{(2)} \\le ... \\le X_{(n)}$ represent the order statistics of the\nsample. The first part of the paper focuses on distributions with an invertible\ncumulative distribution function. Under this assumption, a distribution-free\nproperty is established, which shows that the $f$-divergence between the joint\ndistribution of order statistics and the product distribution of order\nstatistics does not depend on the original sampling distribution $P_X$.\nMoreover, it is shown that the mutual information between two subsets of order\nstatistics also satisfies a distribution-free property; that is, it does not\ndepend on $P_X$. Furthermore, the decoupling rates between $X_{(r)}$ and\n$X_{(m)}$ (i.e., rates at which the mutual information approaches zero) are\ncharacterized for various choices of $(r,m)$. The second part of the paper\nconsiders a family of discrete distributions, which does not satisfy the\nassumptions in the first part of the paper. In comparison to the results of the\nfirst part, it is shown that in the discrete setting, the mutual information\nbetween order statistics does depend on the sampling distribution $P_X$.\nNonetheless, it is shown that the results of the first part can still be used\nas upper bounds on the decoupling rates.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 16:56:06 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Dytso", "Alex", ""], ["Cardone", "Martina", ""], ["Rush", "Cynthia", ""]]}, {"id": "2009.12528", "submitter": "Takahiro Hoshino", "authors": "Takahiro Hoshino", "title": "Identification of causal direct-indirect effects without untestable\n  assumptions", "comments": "The paper has been submitted and the discussion paper will appear in\n  SSRN", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In causal mediation analysis, identification of existing causal direct or\nindirect effects requires untestable assumptions in which potential outcomes\nand potential mediators are independent. This paper defines a new causal direct\nand indirect effect that does not require the untestable assumptions. We show\nthat the proposed measure is identifiable from the observed data, even if\npotential outcomes and potential mediators are dependent, while the existing\nnatural direct or indirect effects may find a pseudo-indirect effect when the\nuntestable assumptions are violated.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 07:48:37 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Hoshino", "Takahiro", ""]]}, {"id": "2009.12641", "submitter": "Andrew Sills", "authors": "Andrew V. Sills", "title": "A refinement of the binomial distribution using the quantum binomial\n  theorem", "comments": "16 pages. This version: Title changed. Abstract modified. Additional\n  related results included. An error in a previous version was corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.CO math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  $q$-analogs of special functions, including hypergeometric functions, play a\ncentral role in mathematics and have numerous applications in physics. In the\ntheory of probability, $q$-analogs of various probability distributions have\nbeen introduced over the years, including the binomial distribution. Here, I\npropose a new refinement of the binomial distribution by way of the quantum\nbinomial theorem (also known as the the noncommutative $q$-binomial theorem),\nwhere the $q$ is a formal variable in which information related to the sequence\nof successes and failures in the underlying binomial experiment is encoded in\nits exponent.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 17:00:45 GMT"}, {"version": "v2", "created": "Mon, 12 Oct 2020 04:41:17 GMT"}, {"version": "v3", "created": "Sat, 13 Feb 2021 01:41:23 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Sills", "Andrew V.", ""]]}, {"id": "2009.12755", "submitter": "Yunlong Feng", "authors": "Yunlong Feng and Qiang Wu", "title": "A Statistical Learning Assessment of Huber Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As one of the triumphs and milestones of robust statistics, Huber regression\nplays an important role in robust inference and estimation. It has also been\nfinding a great variety of applications in machine learning. In a parametric\nsetup, it has been extensively studied. However, in the statistical learning\ncontext where a function is typically learned in a nonparametric way, there is\nstill a lack of theoretical understanding of how Huber regression estimators\nlearn the conditional mean function and why it works in the absence of\nlight-tailed noise assumptions. To address these fundamental questions, we\nconduct an assessment of Huber regression from a statistical learning\nviewpoint. First, we show that the usual risk consistency property of Huber\nregression estimators, which is usually pursued in machine learning, cannot\nguarantee their learnability in mean regression. Second, we argue that Huber\nregression should be implemented in an adaptive way to perform mean regression,\nimplying that one needs to tune the scale parameter in accordance with the\nsample size and the moment condition of the noise. Third, with an adaptive\nchoice of the scale parameter, we demonstrate that Huber regression estimators\ncan be asymptotic mean regression calibrated under $(1+\\epsilon)$-moment\nconditions ($\\epsilon>0$). Last but not least, under the same moment\nconditions, we establish almost sure convergence rates for Huber regression\nestimators. Note that the $(1+\\epsilon)$-moment conditions accommodate the\nspecial case where the response variable possesses infinite variance and so the\nestablished convergence rates justify the robustness feature of Huber\nregression estimators. In the above senses, the present study provides a\nsystematic statistical learning assessment of Huber regression estimators and\njustifies their merits in terms of robustness from a theoretical viewpoint.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 06:08:21 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Feng", "Yunlong", ""], ["Wu", "Qiang", ""]]}, {"id": "2009.12907", "submitter": "Jie Ding", "authors": "Jun Gao and Jie Ding", "title": "Large Deviation Principle for the Whittaker 2d Growth Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.IT math-ph math.IT math.MP math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Whittaker 2d growth model is a triangular continuous Markov diffusion\nprocess that appears in many scientific contexts. It has been theoretically\nintriguing to establish a large deviation principle for this 2d process with a\nscaling factor. The main challenge is the spatiotemporal interactions and\ndynamics that may depend on potential sample-path intersections. We develop\nsuch a principle with a novel rate function. Our approach is mainly based on\nSchider's Theorem, contraction principle, and special treatment for\nintersecting sample paths.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 17:52:53 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Gao", "Jun", ""], ["Ding", "Jie", ""]]}, {"id": "2009.12976", "submitter": "Ankit Pensia", "authors": "Ankit Pensia, Varun Jog, Po-Ling Loh", "title": "Robust regression with covariate filtering: Heavy tails and adversarial\n  contamination", "comments": "V2: Adds new results for unknown covariance matrix (Theorem 3.13),\n  Gaussian design (Remark 3.12), and Simulations (Section 7)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of linear regression where both covariates and responses\nare potentially (i) heavy-tailed and (ii) adversarially contaminated. Several\ncomputationally efficient estimators have been proposed for the simpler setting\nwhere the covariates are sub-Gaussian and uncontaminated; however, these\nestimators may fail when the covariates are either heavy-tailed or contain\noutliers. In this work, we show how to modify the Huber regression, least\ntrimmed squares, and least absolute deviation estimators to obtain estimators\nwhich are simultaneously computationally and statistically efficient in the\nstronger contamination model. Our approach is quite simple, and consists of\napplying a filtering algorithm to the covariates, and then applying the\nclassical robust regression estimators to the remaining data. We show that the\nHuber regression estimator achieves near-optimal error rates in this setting,\nwhereas the least trimmed squares and least absolute deviation estimators can\nbe made to achieve near-optimal error after applying a postprocessing step.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 22:48:48 GMT"}, {"version": "v2", "created": "Mon, 17 May 2021 16:40:45 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Pensia", "Ankit", ""], ["Jog", "Varun", ""], ["Loh", "Po-Ling", ""]]}, {"id": "2009.13016", "submitter": "Krishnakumar Balasubramanian", "authors": "Abhishek Roy, Krishnakumar Balasubramanian, Saeed Ghadimi, Prasant\n  Mohapatra", "title": "Escaping Saddle-Points Faster under Interpolation-like Conditions", "comments": "To appear in NeurIPS, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we show that under over-parametrization several standard\nstochastic optimization algorithms escape saddle-points and converge to\nlocal-minimizers much faster. One of the fundamental aspects of\nover-parametrized models is that they are capable of interpolating the training\ndata. We show that, under interpolation-like assumptions satisfied by the\nstochastic gradients in an over-parametrization setting, the first-order oracle\ncomplexity of Perturbed Stochastic Gradient Descent (PSGD) algorithm to reach\nan $\\epsilon$-local-minimizer, matches the corresponding deterministic rate of\n$\\tilde{\\mathcal{O}}(1/\\epsilon^{2})$. We next analyze Stochastic\nCubic-Regularized Newton (SCRN) algorithm under interpolation-like conditions,\nand show that the oracle complexity to reach an $\\epsilon$-local-minimizer\nunder interpolation-like conditions, is\n$\\tilde{\\mathcal{O}}(1/\\epsilon^{2.5})$. While this obtained complexity is\nbetter than the corresponding complexity of either PSGD, or SCRN without\ninterpolation-like assumptions, it does not match the rate of\n$\\tilde{\\mathcal{O}}(1/\\epsilon^{1.5})$ corresponding to deterministic\nCubic-Regularized Newton method. It seems further Hessian-based\ninterpolation-like assumptions are necessary to bridge this gap. We also\ndiscuss the corresponding improved complexities in the zeroth-order settings.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 02:15:18 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Roy", "Abhishek", ""], ["Balasubramanian", "Krishnakumar", ""], ["Ghadimi", "Saeed", ""], ["Mohapatra", "Prasant", ""]]}, {"id": "2009.13020", "submitter": "Chun-Hao Yang", "authors": "Chun-Hao Yang and Baba C. Vemuri", "title": "Shrinkage Estimation of the Frechet Mean in Lie groups", "comments": "32 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data in non-Euclidean spaces are commonly encountered in many fields of\nScience and Engineering. For instance, in Robotics, attitude sensors capture\norientation which is an element of a Lie group. In the recent past, several\nresearchers have reported methods that take into account the geometry of Lie\nGroups in designing parameter estimation algorithms in nonlinear spaces.\nMaximum likelihood estimators (MLE) are quite commonly used for such tasks and\nit is well known in the field of statistics that Stein's shrinkage estimators\ndominate the MLE in a mean-squared sense assuming the observations are from a\nnormal population. In this paper, we present a novel shrinkage estimator for\ndata residing in Lie groups, specifically, abelian or compact Lie groups. The\nkey theoretical results presented in this paper are: (i) Stein's Lemma and its\nproof for Lie groups and, (ii) proof of dominance of the proposed shrinkage\nestimator over MLE for abelian and compact Lie groups. We present examples of\nsimulation studies of the dominance of the proposed shrinkage estimator and an\napplication of shrinkage estimation to multiple-robot localization.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 02:18:56 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Yang", "Chun-Hao", ""], ["Vemuri", "Baba C.", ""]]}, {"id": "2009.13040", "submitter": "Yudong Chen", "authors": "Yudong Chen and Xumei Xi", "title": "Likelihood Landscape and Local Minima Structures of Gaussian Mixture\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the landscape of the population negative\nlog-likelihood function of Gaussian Mixture Models with a general number of\ncomponents. Due to nonconvexity, there exist multiple local minima that are not\nglobally optimal, even when the mixture is well-separated. We show that all\nlocal minima share the same form of structure that partially identifies the\ncomponent centers of the true mixture, in the sense that each local minimum\ninvolves a non-overlapping combination of fitting multiple Gaussians to a\nsingle true component and fitting a single Gaussian to multiple true\ncomponents. Our results apply to the setting where the true mixture components\nsatisfy a certain separation condition, and are valid even when the number of\ncomponents is over-or under-specified. For Gaussian mixtures with three\ncomponents, we obtain sharper results in terms of the scaling with the\nseparation between the components.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 03:23:54 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Chen", "Yudong", ""], ["Xi", "Xumei", ""]]}, {"id": "2009.13143", "submitter": "Dong Wang", "authors": "Zhigang Bao and Dong Wang", "title": "Eigenvector distribution in the critical regime of BBP transition", "comments": "54 pages, 19 figures, some computational details elaborated", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math-ph math.MP math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the random matrix model of Gaussian Unitary Ensemble\n(GUE) with fixed-rank (aka spiked) external source. We will focus on the\ncritical regime of the Baik-Ben Arous-P\\'ech\\'e (BBP) phase transition and\nestablish the distribution of the eigenvectors associated with the leading\neigenvalues. The distribution is given in terms of a determinantal point\nprocess with extended Airy kernel. Our result can be regarded as an eigenvector\ncounterpart of the BBP eigenvalue phase transition (arXiv:math/0403022). The\nderivation of the distribution makes use of the recently re-discovered\neigenvector-eigenvalue identity, together with the determinantal point process\nrepresentation of the GUE minor process with external source.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 08:44:16 GMT"}, {"version": "v2", "created": "Tue, 27 Apr 2021 02:54:45 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Bao", "Zhigang", ""], ["Wang", "Dong", ""]]}, {"id": "2009.13174", "submitter": "Manon Costa", "authors": "Manon Costa and S\\'ebastien Gadat", "title": "Non asymptotic controls on a recursive superquantile approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we study a new recursive stochastic algorithm for the joint\nestimation of quantile and superquantile of an unknown distribution. The\nnovelty of this algorithm is to use the Cesaro averaging of the quantile\nestimation inside the recursive approximation of the superquantile. We provide\nsome sharp non-asymptotic bounds on the quadratic risk of the superquantile\nestimator for different step size sequences. We also prove new non-asymptotic\n$L^p$-controls on the Robbins Monro algorithm for quantile estimation and its\naveraged version. Finally, we derive a central limit theorem of our joint\nprocedure using the diffusion approximation point of view hidden behind our\nstochastic algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 09:43:45 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 08:29:44 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Costa", "Manon", ""], ["Gadat", "S\u00e9bastien", ""]]}, {"id": "2009.13189", "submitter": "Alessia Caponera", "authors": "Alessia Caponera", "title": "SPHARMA approximations for stationary functional time series on the\n  sphere", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we focus on isotropic and stationary sphere-cross-time random\nfields. We first introduce the class of spherical functional\nautoregressive-moving average processes (SPHARMA), which extend in a natural\nway the spherical functional autoregressions (SPHAR) recently studied in [8,\n7]; more importantly, we then show that SPHAR and SPHARMA processes of\nsufficiently large order can be exploited to approximate every isotropic and\nstationary sphere-cross-time random field, thus generalizing to this\ninfinite-dimensional framework some classical results on real-valued stationary\nprocesses. Further characterizations in terms of functional spectral\nrepresentation theorems and Wold-like decompositions are also established.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 10:03:30 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Caponera", "Alessia", ""]]}, {"id": "2009.13229", "submitter": "Alexander Mozeika", "authors": "Alexander Mozeika, Mansoor Sheikh, Fabian Aguirre-Lopez, Fabrizio\n  Antenucci, Anthony CC Coolen", "title": "Exact results on high-dimensional linear regression via statistical\n  physics", "comments": "Most recent version accepted for publication in Physical Review E", "journal-ref": "Phys. Rev. E 103, 042142 (2021)", "doi": "10.1103/PhysRevE.103.042142", "report-no": null, "categories": "math.ST cond-mat.dis-nn stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is clear that conventional statistical inference protocols need to be\nrevised to deal correctly with the high-dimensional data that are now common.\nMost recent studies aimed at achieving this revision rely on powerful\napproximation techniques, that call for rigorous results against which they can\nbe tested. In this context, the simplest case of high-dimensional linear\nregression has acquired significant new relevance and attention. In this paper\nwe use the statistical physics perspective on inference to derive a number of\nnew exact results for linear regression in the high-dimensional regime.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 11:47:59 GMT"}, {"version": "v2", "created": "Mon, 30 Nov 2020 14:57:37 GMT"}, {"version": "v3", "created": "Tue, 1 Dec 2020 12:13:00 GMT"}, {"version": "v4", "created": "Tue, 6 Apr 2021 21:51:48 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Mozeika", "Alexander", ""], ["Sheikh", "Mansoor", ""], ["Aguirre-Lopez", "Fabian", ""], ["Antenucci", "Fabrizio", ""], ["Coolen", "Anthony CC", ""]]}, {"id": "2009.13488", "submitter": "Larissa Matos", "authors": "Christian E. Galarza and Larissa A. Matos and Dipak K. Dey and Victor\n  H. Lachos", "title": "On moments of folded and doubly truncated multivariate extended\n  skew-normal distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops recurrence relations for integrals that relate the\ndensity of multivariate extended skew-normal (ESN) distribution, including the\nwell-known skew-normal (SN) distribution introduced by Azzalini and Dalla-Valle\n(1996) and the popular multivariate normal distribution. These recursions offer\na fast computation of arbitrary order product moments of the multivariate\ntruncated extended skew-normal and multivariate folded extended skew-normal\ndistributions with the product moments as a byproduct. In addition to the\nrecurrence approach, we realized that any arbitrary moment of the truncated\nmultivariate extended skew-normal distribution can be computed using a\ncorresponding moment of a truncated multivariate normal distribution, pointing\nthe way to a faster algorithm since a less number of integrals is required for\nits computation which result much simpler to evaluate. Since there are several\nmethods available to calculate the first two moments of a multivariate\ntruncated normal distribution, we propose an optimized method that offers a\nbetter performance in terms of time and accuracy, in addition to consider\nextreme cases in which other methods fail. The R MomTrunc package provides\nthese new efficient methods for practitioners.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 17:27:34 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Galarza", "Christian E.", ""], ["Matos", "Larissa A.", ""], ["Dey", "Dipak K.", ""], ["Lachos", "Victor H.", ""]]}, {"id": "2009.13591", "submitter": "Sanket Jantre", "authors": "Sanket R. Jantre, Shrijita Bhattacharya, Tapabrata Maiti", "title": "Quantile Regression Neural Networks: A Bayesian Approach", "comments": null, "journal-ref": "J Stat Theory Pract 15 (3), 1-34, 2021", "doi": "10.1007/s42519-021-00189-w", "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article introduces a Bayesian neural network estimation method for\nquantile regression assuming an asymmetric Laplace distribution (ALD) for the\nresponse variable. It is shown that the posterior distribution for feedforward\nneural network quantile regression is asymptotically consistent under a\nmisspecified ALD model. This consistency proof embeds the problem from density\nestimation domain and uses bounds on the bracketing entropy to derive the\nposterior consistency over Hellinger neighborhoods. This consistency result is\nshown in the setting where the number of hidden nodes grow with the sample\nsize. The Bayesian implementation utilizes the normal-exponential mixture\nrepresentation of the ALD density. The algorithm uses Markov chain Monte Carlo\n(MCMC) simulation technique - Gibbs sampling coupled with Metropolis-Hastings\nalgorithm. We have addressed the issue of complexity associated with the\nafore-mentioned MCMC implementation in the context of chain convergence, choice\nof starting values, and step sizes. We have illustrated the proposed method\nwith simulation studies and real data examples.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 19:21:00 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Jantre", "Sanket R.", ""], ["Bhattacharya", "Shrijita", ""], ["Maiti", "Tapabrata", ""]]}, {"id": "2009.13673", "submitter": "Arun Kuchibhotla", "authors": "Arun Kumar Kuchibhotla, Alessandro Rinaldo", "title": "High-dimensional CLT for Sums of Non-degenerate Random Vectors:\n  $n^{-1/2}$-rate", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note, we provide a Berry--Esseen bounds for rectangles in\nhigh-dimensions when the random vectors have non-singular covariance matrices.\nUnder this assumption of non-singularity, we prove an $n^{-1/2}$ scaling for\nthe Berry--Esseen bound for sums of mean independent random vectors with a\nfinite third moment. The proof is essentially the method of compositions proof\nof multivariate Berry--Esseen bound from Senatov (2011). Similar to other\nexisting works (Kuchibhotla et al. 2018, Fang and Koike 2020a), this note\nconsiders the applicability and effectiveness of classical CLT proof techniques\nfor the high-dimensional case.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 22:52:32 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Kuchibhotla", "Arun Kumar", ""], ["Rinaldo", "Alessandro", ""]]}, {"id": "2009.13968", "submitter": "Arij Amiri", "authors": "A. Amiri (LPP), S Dachian (LPP, SSP&QF)", "title": "On Smooth Change-Point Location Estimation for Poisson Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are interested in estimating the location of what we call \"smooth\nchange-point\" from $n$ independent observations of an inhomogeneous Poisson\nprocess. The smooth change-point is a transition of the intensity function of\nthe process from one level to another which happens smoothly, but over such a\nsmall interval, that its length $\\delta\\_n$ is considered to be decreasing to\n$0$ as $n\\to+\\infty$. We show that if $\\delta\\_n$ goes to zero slower than\n$1/n$, our model is locally asymptotically normal (with a rather unusual rate\n$\\sqrt{\\delta\\_n/n}$), and the maximum likelihood and Bayesian estimators are\nconsistent, asymptotically normal and asymptotically efficient. If, on the\ncontrary, $\\delta\\_n$ goes to zero faster than $1/n$, our model is non-regular\nand behaves like a change-point model. More precisely, in this case we show\nthat the Bayesian estimators are consistent, converge at rate $1/n$, have\nnon-Gaussian limit distributions and are asymptotically efficient. All these\nresults are obtained using the likelihood ratio analysis method of Ibragimov\nand Khasminskii, which equally yields the convergence of polynomial moments of\nthe considered estimators. However, in order to study the maximum likelihood\nestimator in the case where $\\delta\\_n$ goes to zero faster than $1/n$, this\nmethod cannot be applied using the usual topologies of convergence in\nfunctional spaces. So, this study should go through the use of an alternative\ntopology and will be considered in a future work.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 12:36:41 GMT"}, {"version": "v2", "created": "Tue, 16 Feb 2021 09:09:28 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Amiri", "A.", "", "LPP"], ["Dachian", "S", "", "LPP, SSP&QF"]]}, {"id": "2009.13995", "submitter": "Bruno Ebner", "authors": "Bruno Ebner and Shawn C. Liebenberg", "title": "On a new test of fit to the beta distribution", "comments": "10 pages, 1 figure, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new $L^2$-type goodness-of-fit test for the family of beta\ndistributions based on a conditional moment characterisation. The asymptotic\nnull distribution is identified, and since it depends on the underlying\nparameters, a parametric bootstrap procedure is proposed. Consistency against\nall alternatives that satisfy a convergence criterion is shown, and a Monte\nCarlo simulation study indicates that the new procedure outperforms most of the\nclassical tests. Finally, the procedure is applied to a real data set related\nto air humidity.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 13:29:16 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Ebner", "Bruno", ""], ["Liebenberg", "Shawn C.", ""]]}, {"id": "2009.14150", "submitter": "Fernando Castro-Prado", "authors": "Fernando Castro-Prado and Wenceslao Gonz\\'alez-Manteiga", "title": "Nonparametric independence tests in metric spaces: What is known and\n  what is not", "comments": "18 pages with no figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.ME stat.TH", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Distance correlation is a recent extension of Pearson's correlation, that\ncharacterises general statistical independence between Euclidean-space-valued\nrandom variables, not only linear relations. This review delves into how and\nwhen distance correlation can be extended to metric spaces, combining the\ninformation that is available in the literature with some original remarks and\nproofs, in a way that is comprehensible for any mathematical statistician.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 16:47:56 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Castro-Prado", "Fernando", ""], ["Gonz\u00e1lez-Manteiga", "Wenceslao", ""]]}, {"id": "2009.14193", "submitter": "Anastasios Angelopoulos", "authors": "Anastasios Angelopoulos, Stephen Bates, Jitendra Malik, Michael I.\n  Jordan", "title": "Uncertainty Sets for Image Classifiers using Conformal Prediction", "comments": "ICLR 2021 Spotlight, https://openreview.net/forum?id=eNdiU_DbM9 .\n  Project website available at\n  https://people.eecs.berkeley.edu/~angelopoulos/blog/posts/conformal-classification/\n  . Codebase available at\n  https://github.com/aangelopoulos/conformal_classification", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional image classifiers can achieve high predictive accuracy, but\nquantifying their uncertainty remains an unresolved challenge, hindering their\ndeployment in consequential settings. Existing uncertainty quantification\ntechniques, such as Platt scaling, attempt to calibrate the network's\nprobability estimates, but they do not have formal guarantees. We present an\nalgorithm that modifies any classifier to output a predictive set containing\nthe true label with a user-specified probability, such as 90%. The algorithm is\nsimple and fast like Platt scaling, but provides a formal finite-sample\ncoverage guarantee for every model and dataset. Our method modifies an existing\nconformal prediction algorithm to give more stable predictive sets by\nregularizing the small scores of unlikely classes after Platt scaling. In\nexperiments on both Imagenet and Imagenet-V2 with ResNet-152 and other\nclassifiers, our scheme outperforms existing approaches, achieving coverage\nwith sets that are often factors of 5 to 10 smaller than a stand-alone Platt\nscaling baseline.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 17:58:04 GMT"}, {"version": "v2", "created": "Wed, 23 Dec 2020 18:59:13 GMT"}, {"version": "v3", "created": "Tue, 16 Mar 2021 01:50:26 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Angelopoulos", "Anastasios", ""], ["Bates", "Stephen", ""], ["Malik", "Jitendra", ""], ["Jordan", "Michael I.", ""]]}, {"id": "2009.14286", "submitter": "Alexander Tsigler", "authors": "A. Tsigler (1) and P. L. Bartlett (1) ((1) UC Berkeley)", "title": "Benign overfitting in ridge regression", "comments": "28 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical learning theory suggests that strong regularization is needed to\nlearn a class with large complexity. This intuition is in contrast with the\nmodern practice of machine learning, in particular learning neural networks,\nwhere the number of parameters often exceeds the number of data points. It has\nbeen observed empirically that such overparametrized models can show good\ngeneralization performance even if trained with vanishing or negative\nregularization. The aim of this work is to understand theoretically how this\neffect can occur, by studying the setting of ridge regression. We provide\nnon-asymptotic generalization bounds for overparametrized ridge regression that\ndepend on the arbitrary covariance structure of the data, and show that those\nbounds are tight for a range of regularization parameter values. To our\nknowledge this is the first work that studies overparametrized ridge regression\nin such a general setting. We identify when small or negative regularization is\nsufficient for obtaining small generalization error. On the technical side, our\nbounds only require the data vectors to be i.i.d. sub-gaussian, while most\nprevious work assumes independence of the components of those vectors.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 20:00:31 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Tsigler", "A.", "", "UC Berkeley"], ["Bartlett", "P. L.", "", "UC Berkeley"]]}, {"id": "2009.14367", "submitter": "Matias Cattaneo", "authors": "Matias D. Cattaneo and Michael Jansson and Xinwei Ma", "title": "Local Regression Distribution Estimators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the large sample properties of local regression\ndistribution estimators, which include a class of boundary adaptive density\nestimators as a prime example. First, we establish a pointwise Gaussian large\nsample distributional approximation in a unified way, allowing for both\nboundary and interior evaluation points simultaneously. Using this result, we\nstudy the asymptotic efficiency of the estimators, and show that a carefully\ncrafted minimum distance implementation based on \"redundant\" regressors can\nlead to efficiency gains. Second, we establish uniform linearizations and\nstrong approximations for the estimators, and employ these results to construct\nvalid confidence bands. Third, we develop extensions to weighted distributions\nwith estimated weights and to local $L^{2}$ least squares estimation. Finally,\nwe illustrate our methods with two applications in program evaluation:\ncounterfactual density testing, and IV specification and heterogeneity density\nanalysis. Companion software packages in Stata and R are available.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 01:10:44 GMT"}, {"version": "v2", "created": "Thu, 28 Jan 2021 14:46:10 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Cattaneo", "Matias D.", ""], ["Jansson", "Michael", ""], ["Ma", "Xinwei", ""]]}, {"id": "2009.14761", "submitter": "J\\\"urgen Kampf", "authors": "J\\\"urgen Kampf, Alexander Meister", "title": "Testing for linearity in boundary regression models with application to\n  maximal life expectancies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a regression model with errors that are a.s. negative. Thus the\nregression function is not the expected value of the observations but the right\nendpoint of their support. We develop two goodness-of-fit tests for the\nhypotheses that the regression function is an affine function, study the\nasymptotic distributions of the test statistics in order to approximately fix\nthe sizes of the tests, derive their finite-sample properties based on\nsimulations and apply them to life expectancy data.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 16:00:59 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Kampf", "J\u00fcrgen", ""], ["Meister", "Alexander", ""]]}]