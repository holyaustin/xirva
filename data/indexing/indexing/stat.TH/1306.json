[{"id": "1306.0040", "submitter": "James Scott", "authors": "James G. Scott and Liang Sun", "title": "Expectation-maximization for logistic regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a family of expectation-maximization (EM) algorithms for binary\nand negative-binomial logistic regression, drawing a sharp connection with the\nvariational-Bayes algorithm of Jaakkola and Jordan (2000). Indeed, our results\nallow a version of this variational-Bayes approach to be re-interpreted as a\ntrue EM algorithm. We study several interesting features of the algorithm, and\nof this previously unrecognized connection with variational Bayes. We also\ngeneralize the approach to sparsity-promoting priors, and to an online method\nwhose convergence properties are easily established. This latter method\ncompares favorably with stochastic-gradient descent in situations with marked\ncollinearity.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2013 21:57:12 GMT"}], "update_date": "2013-06-04", "authors_parsed": [["Scott", "James G.", ""], ["Sun", "Liang", ""]]}, {"id": "1306.0084", "submitter": "Agust\\'in G. Nogales", "authors": "Agust\\'in G. Nogales", "title": "Conditional Expectation of a Markov Kernel Given Another with Some\n  Applications in Statistical Inference and Disease Diagnosis", "comments": "Research paper. 16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov kernels play a decisive role in probability and mathematical\nstatistics theories, and are an extension of the concepts of sigma-field and\nstatistic. Concepts such as independence, sufficiency, completeness,\nancillarity or conditional distribution have been extended previously to Markov\nkernels. In this paper, the concept of conditional expectation of a Markov\nkernel given another is introduced, setting its first properties. An\napplication to clinical diagnosis is provided, obtaining {an} optimality\nproperty of the predictive values of a diagnosis test. In a statistical\nframework, this new probabilistic tool is used to extend to Markov kernels the\ntheorems of {Rao-Blackwell} and Lehmann-Scheff\\'e. A result about the\ncompleteness of a sufficient statistic is obtained in passing by properly\nenlarging the family of probabilities. As a final statistical scholium, a\ngeneralization of a result about the completeness of the family of\nnonrandomized estimators is given.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2013 07:25:56 GMT"}, {"version": "v2", "created": "Tue, 2 Feb 2016 21:10:20 GMT"}, {"version": "v3", "created": "Tue, 12 Sep 2017 14:54:16 GMT"}, {"version": "v4", "created": "Fri, 9 Nov 2018 11:22:29 GMT"}], "update_date": "2018-11-12", "authors_parsed": [["Nogales", "Agust\u00edn G.", ""]]}, {"id": "1306.0113", "submitter": "Johannes Lederer", "authors": "Johannes Lederer", "title": "Trust, but verify: benefits and pitfalls of least-squares refitting in\n  high dimensions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Least-squares refitting is widely used in high dimensional regression to\nreduce the prediction bias of l1-penalized estimators (e.g., Lasso and\nSquare-Root Lasso). We present theoretical and numerical results that provide\nnew insights into the benefits and pitfalls of least-squares refitting. In\nparticular, we consider both prediction and estimation, and we pay close\nattention to the effects of correlations in the design matrices of linear\nregression models, since these correlations - although often neglected - are\ncrucial in the context of linear regression, especially in high dimensional\ncontexts. First, we demonstrate that the benefit of least-squares refitting\nstrongly depends on the setting and task under consideration: least-squares\nrefitting can be beneficial even for settings with highly correlated design\nmatrices but is not advisable for all settings, and least-squares refitting can\nbe beneficial for estimation but performs better for prediction. Finally, we\nintroduce a criterion that indicates whether least-squares refitting is\nadvisable for a specific setting and task under consideration, and we conduct a\nthorough simulation study involving the Lasso to show the usefulness of this\ncriterion.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2013 14:41:52 GMT"}], "update_date": "2013-06-04", "authors_parsed": [["Lederer", "Johannes", ""]]}, {"id": "1306.0254", "submitter": "Tiefeng Jiang", "authors": "Tiefeng Jiang and Fan Yang", "title": "Central Limit Theorems for Classical Likelihood Ratio Tests for\n  High-Dimensional Normal Distributions", "comments": "Published in Ann. Stat. 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For random samples of size n obtained from p-variate normal distributions, we\nconsider the classical likelihood ratio tests (LRT) for their means and\ncovariance matrices in the high-dimensional setting. These test statistics have\nbeen extensively studied in multivariate analysis and their limiting\ndistributions under the null hypothesis were proved to be chi-square\ndistributions as n goes to infinity and p remains fixed. In this paper, we\nconsider the high-dimensional case where both p and n go to infinity with p=n/y\nin (0, 1]. We prove that the likelihood ratio test statistics under this\nassumption will converge in distribution to normal distributions with explicit\nmeans and variances. We perform the simulation study to show that the\nlikelihood ratio tests using our central limit theorems outperform those using\nthe traditional chi-square approximations for analyzing high-dimensional data.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jun 2013 22:25:28 GMT"}], "update_date": "2013-06-04", "authors_parsed": [["Jiang", "Tiefeng", ""], ["Yang", "Fan", ""]]}, {"id": "1306.0256", "submitter": "Tiefeng Jiang", "authors": "Tony Cai, Jianqing Fan and Tiefeng Jiang", "title": "Distributions of Angles in Random Packing on Spheres", "comments": "Published in Journal of Machine Learning Research; 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the asymptotic behaviors of the pairwise angles among n\nrandomly and uniformly distributed unit vectors in R^p as the number of points\nn -> infinity, while the dimension p is either fixed or growing with n. For\nboth settings, we derive the limiting empirical distribution of the random\nangles and the limiting distributions of the extreme angles. The results reveal\ninteresting differences in the two settings and provide a precise\ncharacterization of the folklore that \"all high-dimensional random vectors are\nalmost always nearly orthogonal to each other\". Applications to statistics and\nmachine learning and connections with some open problems in physics and\nmathematics are also discussed.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jun 2013 22:32:28 GMT"}], "update_date": "2013-06-04", "authors_parsed": [["Cai", "Tony", ""], ["Fan", "Jianqing", ""], ["Jiang", "Tiefeng", ""]]}, {"id": "1306.0290", "submitter": "Argyn Kuketayev", "authors": "Argyn Kuketayev", "title": "Probability density function of the Cartesian x-coordinate of the random\n  point inside the hypersphere", "comments": "7 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Consider randomly picked points inside the n-dimensional unit hypersphere\ncentered at the origin of the Cartesian coordinate system. The Cartesian\ncoordinates of the points are random variables, which form an n-dimensional\nvector for each point. Observing only the x-coordinate I obtained its\nprobability density function (PDF). I show that it is related to the Gaussian\ndistribution: in limit its companion PDF?? converges to the PDF of the standard\nnormal distribution.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2013 04:01:30 GMT"}], "update_date": "2013-06-04", "authors_parsed": [["Kuketayev", "Argyn", ""]]}, {"id": "1306.0325", "submitter": "Paulo Serra", "authors": "Eduard Belitser, Paulo Serra", "title": "Online Tracking of a Predictable Drifting Parameter of a Time Series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an online algorithm for tracking a multidimensional time-varying\nparameter of a time series, which is also allowed to be a predictable process\nwith respect to the underlying time series. The algorithm is driven by a gain\nfunction. Under assumptions on the gain, we derive uniform non-asymptotic error\nbounds on the tracking algorithm in terms of chosen step size for the algorithm\nand the variation of the parameter of interest. We also outline how appropriate\ngain functions can be constructed. We give several examples of different\nvariational setups for the parameter process where our result can be applied.\nThe proposed approach covers many frameworks and models (including the\nclassical Robbins-Monro and Kiefer-Wolfowitz procedures) where stochastic\napproximation algorithms comprise the main inference tool for the data\nanalysis. We treat in some detail a couple of specific models.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2013 08:42:53 GMT"}, {"version": "v2", "created": "Thu, 14 Nov 2013 09:14:57 GMT"}], "update_date": "2013-11-15", "authors_parsed": [["Belitser", "Eduard", ""], ["Serra", "Paulo", ""]]}, {"id": "1306.0480", "submitter": "Giovanni Pistone", "authors": "Giovanni Pistone", "title": "Nonparametric Information Geometry", "comments": "Submitted for publication in the Proceedings od GSI2013 Aug 28-30\n  2013 Paris", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The differential-geometric structure of the set of positive densities on a\ngiven measure space has raised the interest of many mathematicians after the\ndiscovery by C.R. Rao of the geometric meaning of the Fisher information. Most\nof the research is focused on parametric statistical models. In series of\npapers by author and coworkers a particular version of the nonparametric case\nhas been discussed. It consists of a minimalistic structure modeled according\nthe theory of exponential families: given a reference density other densities\nare represented by the centered log likelihood which is an element of an Orlicz\nspace. This mappings give a system of charts of a Banach manifold. It has been\nobserved that, while the construction is natural, the practical applicability\nis limited by the technical difficulty to deal with such a class of Banach\nspaces. It has been suggested recently to replace the exponential function with\nother functions with similar behavior but polynomial growth at infinity in\norder to obtain more tractable Banach spaces, e.g. Hilbert spaces. We give\nfirst a review of our theory with special emphasis on the specific issues of\nthe infinite dimensional setting. In a second part we discuss two specific\ntopics, differential equations and the metric connection. The position of this\nline of research with respect to other approaches is briefly discussed.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2013 16:08:01 GMT"}, {"version": "v2", "created": "Mon, 15 Jul 2013 11:14:35 GMT"}], "update_date": "2013-07-16", "authors_parsed": [["Pistone", "Giovanni", ""]]}, {"id": "1306.0623", "submitter": "Kai Zhang", "authors": "Kai Zhang", "title": "Rank-Extreme Association of Gaussian Vectors and Low-Rank Detection", "comments": "It is merged with the article arXiv:1511.06198", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the spherical cap packing problem with a probabilistic approach.\nSuch probabilistic considerations result in an asymptotic sharp universal\nuniform bound on the maximal inner product between any set of unit vectors and\na stochastically independent uniformly distributed unit vector. When the set of\nunit vectors are themselves independently uniformly distributed, we further\ndevelop the extreme value distribution limit of the maximal inner product,\nwhich characterizes its uncertainty around the bound. As applications of the\nabove asymptotic results, we derive (1) an asymptotic sharp universal uniform\nbound on the maximal spurious correlation, as well as its uniform convergence\nin distribution when the explanatory variables are independently Gaussian\ndistributed; and (2) an asymptotic sharp universal bound on the maximum norm of\na low-rank elliptically distributed vector, as well as related limiting\ndistributions. With these results, we develop a fast detection method for a\nlow-rank structure in high-dimensional Gaussian data without using the spectrum\ninformation.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2013 23:50:16 GMT"}, {"version": "v2", "created": "Mon, 10 Jun 2013 15:08:23 GMT"}, {"version": "v3", "created": "Thu, 27 Jun 2013 21:36:08 GMT"}, {"version": "v4", "created": "Mon, 8 Jul 2013 17:29:24 GMT"}, {"version": "v5", "created": "Sun, 14 Jul 2013 19:10:14 GMT"}, {"version": "v6", "created": "Mon, 2 Sep 2013 16:59:17 GMT"}, {"version": "v7", "created": "Thu, 4 May 2017 23:58:56 GMT"}], "update_date": "2017-05-08", "authors_parsed": [["Zhang", "Kai", ""]]}, {"id": "1306.0818", "submitter": "Ulf Schepsmeier", "authors": "Ulf Schepsmeier", "title": "A goodness-of-fit test for regular vine copula models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new goodness-of-fit test for regular vine (R-vine) copula\nmodels. R-vine copulas are a very flexible class of multivariate copulas based\non a pair-copula construction (PCC). The test arises from the information\nmatrix equality and specification test proposed by White (1982) and extends the\ngoodness-of-fit test for copulas introduced by Huang and Prokhorov (2011). The\ncorresponding critical value can be approximated by asymptotic theory or\nsimulation. The simulation based test shows excellent performance with regard\nto observed size and power in an extensive simulation study, while the\nasymptotic theory based test is inaccurate for n<10000 for a 5-dimensional\nmodel (in d=8 even 20000 are not enough). The simulation based test is applied\nto select among different R-vine specifications to model the dependency among\nexchange rates.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2013 14:35:51 GMT"}], "update_date": "2013-06-05", "authors_parsed": [["Schepsmeier", "Ulf", ""]]}, {"id": "1306.0842", "submitter": "Krikamol Muandet", "authors": "Krikamol Muandet, Kenji Fukumizu, Bharath Sriperumbudur, Arthur\n  Gretton, Bernhard Sch\\\"olkopf", "title": "Kernel Mean Estimation and Stein's Effect", "comments": "first draft", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A mean function in reproducing kernel Hilbert space, or a kernel mean, is an\nimportant part of many applications ranging from kernel principal component\nanalysis to Hilbert-space embedding of distributions. Given finite samples, an\nempirical average is the standard estimate for the true kernel mean. We show\nthat this estimator can be improved via a well-known phenomenon in statistics\ncalled Stein's phenomenon. After consideration, our theoretical analysis\nreveals the existence of a wide class of estimators that are better than the\nstandard. Focusing on a subset of this class, we propose efficient shrinkage\nestimators for the kernel mean. Empirical evaluations on several benchmark\napplications clearly demonstrate that the proposed estimators outperform the\nstandard kernel mean estimator.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2013 16:09:20 GMT"}, {"version": "v2", "created": "Thu, 6 Jun 2013 17:18:25 GMT"}], "update_date": "2013-06-07", "authors_parsed": [["Muandet", "Krikamol", ""], ["Fukumizu", "Kenji", ""], ["Sriperumbudur", "Bharath", ""], ["Gretton", "Arthur", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "1306.1059", "submitter": "Richard Berk", "authors": "Richard Berk, Lawrence Brown, Andreas Buja, Kai Zhang, Linda Zhao", "title": "Valid post-selection inference", "comments": "Published in at http://dx.doi.org/10.1214/12-AOS1077 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2013, Vol. 41, No. 2, 802-837", "doi": "10.1214/12-AOS1077", "report-no": "IMS-AOS-AOS1077", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is common practice in statistical data analysis to perform data-driven\nvariable selection and derive statistical inference from the resulting model.\nSuch inference enjoys none of the guarantees that classical statistical theory\nprovides for tests and confidence intervals when the model has been chosen a\npriori. We propose to produce valid ``post-selection inference'' by reducing\nthe problem to one of simultaneous inference and hence suitably widening\nconventional confidence and retention intervals. Simultaneity is required for\nall linear functions that arise as coefficient estimates in all submodels. By\npurchasing ``simultaneity insurance'' for all possible submodels, the resulting\npost-selection inference is rendered universally valid under all possible model\nselection procedures. This inference is therefore generally conservative for\nparticular selection procedures, but it is always less conservative than full\nScheffe protection. Importantly it does not depend on the truth of the selected\nsubmodel, and hence it produces valid inference even in wrong models. We\ndescribe the structure of the simultaneous inference problem and give some\nasymptotic results.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2013 11:13:15 GMT"}], "update_date": "2013-06-06", "authors_parsed": [["Berk", "Richard", ""], ["Brown", "Lawrence", ""], ["Buja", "Andreas", ""], ["Zhang", "Kai", ""], ["Zhao", "Linda", ""]]}, {"id": "1306.1154", "submitter": "Anru Zhang", "authors": "T. Tony Cai and Anru Zhang", "title": "Sparse Representation of a Polytope and Recovery of Sparse Signals and\n  Low-rank Matrices", "comments": "to appear in IEEE Transactions on Information Theory", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  This paper considers compressed sensing and affine rank minimization in both\nnoiseless and noisy cases and establishes sharp restricted isometry conditions\nfor sparse signal and low-rank matrix recovery. The analysis relies on a key\ntechnical tool which represents points in a polytope by convex combinations of\nsparse vectors. The technique is elementary while leads to sharp results.\n  It is shown that for any given constant $t\\ge {4/3}$, in compressed sensing\n$\\delta_{tk}^A < \\sqrt{(t-1)/t}$ guarantees the exact recovery of all $k$\nsparse signals in the noiseless case through the constrained $\\ell_1$\nminimization, and similarly in affine rank minimization\n$\\delta_{tr}^\\mathcal{M}< \\sqrt{(t-1)/t}$ ensures the exact reconstruction of\nall matrices with rank at most $r$ in the noiseless case via the constrained\nnuclear norm minimization. Moreover, for any $\\epsilon>0$,\n$\\delta_{tk}^A<\\sqrt{\\frac{t-1}{t}}+\\epsilon$ is not sufficient to guarantee\nthe exact recovery of all $k$-sparse signals for large $k$. Similar result also\nholds for matrix recovery. In addition, the conditions $\\delta_{tk}^A <\n\\sqrt{(t-1)/t}$ and $\\delta_{tr}^\\mathcal{M}< \\sqrt{(t-1)/t}$ are also shown to\nbe sufficient respectively for stable recovery of approximately sparse signals\nand low-rank matrices in the noisy case.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2013 15:50:28 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2013 03:45:04 GMT"}], "update_date": "2013-10-23", "authors_parsed": [["Cai", "T. Tony", ""], ["Zhang", "Anru", ""]]}, {"id": "1306.1170", "submitter": "Paulo C. Marques F.", "authors": "Paulo C. Marques F", "title": "On the computation of the marginal likelihood", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe briefly in this note a procedure for consistently estimating the\nmarginal likelihood of a statistical model through a sample from the posterior\ndistribution of the model parameters.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2013 18:54:01 GMT"}, {"version": "v2", "created": "Tue, 10 Jun 2014 20:19:20 GMT"}], "update_date": "2014-06-12", "authors_parsed": [["F", "Paulo C. Marques", ""]]}, {"id": "1306.1294", "submitter": "Tianxiao Pang", "authors": "Pang Tianxiao, Zhang Danna and Chong Terence Tai-Leung", "title": "Asymptotic inferences for an AR(1) model with a change point: stationary\n  and nearly non-stationary cases", "comments": "35 pages, 24 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper examines the asymptotic inference for AR(1) models with a possible\nstructural break in the AR parameter $\\beta $ near the unity at an unknown time\n$k_{0}$. Consider the model $y_{t}=\\beta_{1}y_{t-1}I\\{t\\leq k_{0}\\}+\\beta\n_{2}y_{t-1}I\\{t>k_{0}\\}+\\varepsilon_{t},~t=1,2,\\cdots ,T,$ where $I\\{\\cdot \\}$\ndenotes the indicator function. We examine two cases: Case (I)\n$|\\beta_{1}|<1,\\beta_{2}=\\beta_{2T}=1-c/T$; and case\n(II)~$\\beta_{1}=\\beta_{1T}=1-c/T,|\\beta _{2}|<1$, where $c$\\ is a fixed\nconstant, and $\\{\\varepsilon_{t},t\\geq 1\\}$\\ is a sequence of i.i.d. random\nvariables which are in the domain of attraction of the normal law with zero\nmeans and possibly infinite variances. We derive the limiting distributions of\nthe least squares estimators of $\\beta_{1}$ and $\\beta_{2} $, and that of the\nbreak-point estimator for shrinking break for the aforementioned cases. Monte\nCarlo simulations are conducted to demonstrate the finite sample properties of\nthe estimators. Our theoretical results are supported by Monte Carlo\nsimulations.\\newline\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2013 04:58:21 GMT"}], "update_date": "2013-06-07", "authors_parsed": [["Tianxiao", "Pang", ""], ["Danna", "Zhang", ""], ["Tai-Leung", "Chong Terence", ""]]}, {"id": "1306.1298", "submitter": "Allon G. Percus", "authors": "Cristina Garcia-Cardona, Arjuna Flenner, Allon G. Percus", "title": "Multiclass Semi-Supervised Learning on Graphs using Ginzburg-Landau\n  Functional Minimization", "comments": "16 pages, to appear in Springer's Lecture Notes in Computer Science\n  volume \"Pattern Recognition Applications and Methods 2013\", part of series on\n  Advances in Intelligent and Soft Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST physics.data-an stat.TH", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  We present a graph-based variational algorithm for classification of\nhigh-dimensional data, generalizing the binary diffuse interface model to the\ncase of multiple classes. Motivated by total variation techniques, the method\ninvolves minimizing an energy functional made up of three terms. The first two\nterms promote a stepwise continuous classification function with sharp\ntransitions between classes, while preserving symmetry among the class labels.\nThe third term is a data fidelity term, allowing us to incorporate prior\ninformation into the model in a semi-supervised framework. The performance of\nthe algorithm on synthetic data, as well as on the COIL and MNIST benchmark\ndatasets, is competitive with state-of-the-art graph-based multiclass\nsegmentation methods.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2013 05:32:00 GMT"}], "update_date": "2013-06-07", "authors_parsed": [["Garcia-Cardona", "Cristina", ""], ["Flenner", "Arjuna", ""], ["Percus", "Allon G.", ""]]}, {"id": "1306.1318", "submitter": "Sergio Bacallado", "authors": "Sergio Bacallado, Stefano Favaro, Lorenzo Trippa", "title": "Bayesian nonparametric analysis of reversible Markov chains", "comments": "Published in at http://dx.doi.org/10.1214/13-AOS1102 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2013, Vol. 41, No. 2, 870-896", "doi": "10.1214/13-AOS1102", "report-no": "IMS-AOS-AOS1102", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a three-parameter random walk with reinforcement, called the\n$(\\theta,\\alpha,\\beta)$ scheme, which generalizes the linearly edge reinforced\nrandom walk to uncountable spaces. The parameter $\\beta$ smoothly tunes the\n$(\\theta,\\alpha,\\beta)$ scheme between this edge reinforced random walk and the\nclassical exchangeable two-parameter Hoppe urn scheme, while the parameters\n$\\alpha$ and $\\theta$ modulate how many states are typically visited. Resorting\nto de Finetti's theorem for Markov chains, we use the $(\\theta,\\alpha,\\beta)$\nscheme to define a nonparametric prior for Bayesian analysis of reversible\nMarkov chains. The prior is applied in Bayesian nonparametric inference for\nspecies sampling problems with data generated from a reversible Markov chain\nwith an unknown transition kernel. As a real example, we analyze data from\nmolecular dynamics simulations of protein folding.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2013 07:08:51 GMT"}], "update_date": "2013-06-07", "authors_parsed": [["Bacallado", "Sergio", ""], ["Favaro", "Stefano", ""], ["Trippa", "Lorenzo", ""]]}, {"id": "1306.1320", "submitter": "Dietrich Braess", "authors": "Dietrich Braess, Holger Dette", "title": "Optimal discriminating designs for several competing regression models", "comments": "Published in at http://dx.doi.org/10.1214/13-AOS1103 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2013, Vol. 41, No. 2, 897-922", "doi": "10.1214/13-AOS1103", "report-no": "IMS-AOS-AOS1103", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of constructing optimal discriminating designs for a class of\nregression models is considered. We investigate a version of the\n$T_p$-optimality criterion as introduced by Atkinson and Fedorov [Biometrika 62\n(1975a) 289-303]. The numerical construction of optimal designs is very hard\nand challenging, if the number of pairwise comparisons is larger than 2. It is\ndemonstrated that optimal designs with respect to this type of criteria can be\nobtained by solving (nonlinear) vector-valued approximation problems. We use a\ncharacterization of the best approximations to develop an efficient algorithm\nfor the determination of the optimal discriminating designs. The new procedure\nis compared with the currently available methods in several numerical examples,\nand we demonstrate that the new method can find optimal discriminating designs\nin situations where the currently available procedures fail.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2013 07:13:34 GMT"}], "update_date": "2013-06-07", "authors_parsed": [["Braess", "Dietrich", ""], ["Dette", "Holger", ""]]}, {"id": "1306.1322", "submitter": "Lam Si Tung Ho", "authors": "Lam Si Tung Ho, C\\'ecile An\\'e", "title": "Asymptotic theory with hierarchical autocorrelation: Ornstein-Uhlenbeck\n  tree models", "comments": "Published in at http://dx.doi.org/10.1214/13-AOS1105 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2013, Vol. 41, No. 2, 957-981", "doi": "10.1214/13-AOS1105", "report-no": "IMS-AOS-AOS1105", "categories": "math.ST q-bio.PE stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical autocorrelation in the error term of linear models arises when\nsampling units are related to each other according to a tree. The residual\ncovariance is parametrized using the tree-distance between sampling units. When\nobservations are modeled using an Ornstein-Uhlenbeck (OU) process along the\ntree, the autocorrelation between two tips decreases exponentially with their\ntree distance. These models are most often applied in evolutionary biology,\nwhen tips represent biological species and the OU process parameters represent\nthe strength and direction of natural selection. For these models, we show that\nthe mean is not microergodic: no estimator can ever be consistent for this\nparameter and provide a lower bound for the variance of its MLE. For covariance\nparameters, we give a general sufficient condition ensuring microergodicity.\nThis condition suggests that some parameters may not be estimated at the same\nrate as others. We show that, indeed, maximum likelihood estimators of the\nautocorrelation parameter converge at a slower rate than that of generally\nmicroergodic parameters. We showed this theoretically in a symmetric tree\nasymptotic framework and through simulations on a large real tree comprising\n4507 mammal species.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2013 07:24:33 GMT"}], "update_date": "2013-08-09", "authors_parsed": [["Ho", "Lam Si Tung", ""], ["An\u00e9", "C\u00e9cile", ""]]}, {"id": "1306.1324", "submitter": "Chris Field", "authors": "Chris Field, John Robinson", "title": "Relative errors for bootstrap approximations of the serial correlation\n  coefficient", "comments": "Published in at http://dx.doi.org/10.1214/13-AOS1111 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2013, Vol. 41, No. 2, 1035-1053", "doi": "10.1214/13-AOS1111", "report-no": "IMS-AOS-AOS1111", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the first serial correlation coefficient under an AR(1) model\nwhere errors are not assumed to be Gaussian. In this case it is necessary to\nconsider bootstrap approximations for tests based on the statistic since the\ndistribution of errors is unknown. We obtain saddle-point approximations for\ntail probabilities of the statistic and its bootstrap version and use these to\nshow that the bootstrap tail probabilities approximate the true values with\ngiven relative errors, thus extending the classical results of Daniels\n[Biometrika 43 (1956) 169-185] for the Gaussian case. The methods require\nconditioning on the set of odd numbered observations and suggest a conditional\nbootstrap which we show has similar relative error properties.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2013 07:39:36 GMT"}], "update_date": "2013-06-07", "authors_parsed": [["Field", "Chris", ""], ["Robinson", "John", ""]]}, {"id": "1306.1438", "submitter": "Charles R Doss", "authors": "Charles R. Doss and Jon A. Wellner", "title": "Global Rates of Convergence of the MLEs of Log-concave and s-concave\n  Densities", "comments": "38 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We establish global rates of convergence for the Maximum Likelihood\nEstimators (MLEs) of log-concave and $s$-concave densities on $\\mathbb{R}$. The\nmain finding is that the rate of convergence of the MLE in the Hellinger metric\nis no worse than $n^{-2/5}$ when $-1 < s < \\infty$ where $s=0$ corresponds to\nthe log-concave case. We also show that the MLE does not exist for the classes\nof $s$-concave densities with $s < - 1$.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2013 15:30:18 GMT"}, {"version": "v2", "created": "Sun, 12 Apr 2015 17:09:23 GMT"}, {"version": "v3", "created": "Tue, 15 Sep 2015 14:32:31 GMT"}], "update_date": "2015-09-16", "authors_parsed": [["Doss", "Charles R.", ""], ["Wellner", "Jon A.", ""]]}, {"id": "1306.1452", "submitter": "Claudia Neves", "authors": "Isabel Fraga Alves and Cl\\'audia Neves", "title": "Estimation of the finite right endpoint in the Gumbel domain", "comments": null, "journal-ref": "Statistica Sinica 24 (2014), 1811-1835", "doi": "10.5705/ss.2013.183", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A simple estimator for the finite right endpoint of a distribution function\nin the Gumbel max-domain of attraction is proposed. Large sample properties\nsuch as consistency and the asymptotic distribution are derived. A simulation\nstudy is also presented.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2013 16:08:41 GMT"}], "update_date": "2015-06-16", "authors_parsed": [["Alves", "Isabel Fraga", ""], ["Neves", "Cl\u00e1udia", ""]]}, {"id": "1306.1465", "submitter": "HongVan Le", "authors": "H\\^ong V\\^an L\\^e", "title": "The uniqueness of the Fisher metric as information metric", "comments": "v.4. 18 p. Minor changes in exposition. Reference N 14 and Remark\n  6.3.3 are added", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define a mixed topology on the fiber space $\\cup_\\mu \\oplus^n L^n(\\mu)$\nover the space $\\mathcal{M}(\\Omega)$ of all finite non-negative measures $\\mu$\non a separable metric space $\\Omega$ provided with Borel $\\sigma$-algebra. We\ndefine a notion of strong continuity of a covariant $n$-tensor field on\n$\\mathcal{M}(\\Omega)$. Under the assumption of strong continuity of an\ninformation metric we prove the uniqueness of the Fisher metric as information\nmetric on statistical models associated with $\\Omega$. Our proof realizes a\nsuggestion due to Amari and Nagaoka to derive the uniqueness of the Fisher\nmetric from the special case proved by Chentsov by using a special kind of\nlimiting procedure. The obtained result extends the monotonicity\ncharacterization of the Fisher metric on statistical models associated with\nfinite sample spaces and complement the uniqueness theorem by\nAy-Jost-L\\^e-Schwachh\\\"ofer that characterizes the Fisher metric by its\ninvariance under sufficient statistics.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2013 16:33:11 GMT"}, {"version": "v2", "created": "Fri, 15 Aug 2014 10:28:09 GMT"}, {"version": "v3", "created": "Tue, 15 Sep 2015 09:40:26 GMT"}, {"version": "v4", "created": "Sun, 24 Jan 2016 18:42:37 GMT"}], "update_date": "2016-01-26", "authors_parsed": [["L\u00ea", "H\u00f4ng V\u00e2n", ""]]}, {"id": "1306.1492", "submitter": "Alexander Sakhnovich", "authors": "Lev Sakhnovich", "title": "Levy processes: long time behavior and convolution-type form of the Ito\n  representation of the infinitesimal generator", "comments": "arXiv admin note: text overlap with arXiv:math/0702378,\n  arXiv:1212.3603", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.FA math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the present paper we show that the Levy-Ito representation of the\ninfinitesimal generator $L$ for Levy processes $X_t$ can be written in a\nconvolution-type form. Using the obtained convolution form we have constructed\nthe quasi-potential operator $B$. We denote by $p(t,\\Delta)$ the probability\nthat a sample of the process $X_t$ remains inside the domain $\\Delta$ for\n$0{\\leq}\\tau{\\leq}t$ (ruin problem). With the help of the operator $B$ we find\na new formula for $p(t,\\Delta)$. This formula allows us to obtain long time\nbehavior of $p(t,\\Delta)$.\n", "versions": [{"version": "v1", "created": "Sat, 18 May 2013 11:47:45 GMT"}], "update_date": "2013-06-07", "authors_parsed": [["Sakhnovich", "Lev", ""]]}, {"id": "1306.1493", "submitter": "Min Tsao Dr.", "authors": "Min Tsao and Fan Wu", "title": "Extended empirical likelihood for general estimating equations", "comments": "8 pages and 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive an extended empirical likelihood for parameters defined by\nestimating equations which generalizes the original empirical likelihood for\nsuch parameters to the full parameter space. Under mild conditions, the\nextended empirical likelihood has all asymptotic properties of the original\nempirical likelihood. Its contours retain the data-driven shape of the latter.\nIt can also attain the second order accuracy. The first order extended\nempirical likelihood is easy-to-use yet it is substantially more accurate than\nother empirical likelihoods, including second order ones. We recommend it for\npractical applications of the empirical likelihood method.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2013 18:03:23 GMT"}], "update_date": "2013-06-07", "authors_parsed": [["Tsao", "Min", ""], ["Wu", "Fan", ""]]}, {"id": "1306.1510", "submitter": "Mathias Rafler", "authors": "Mathias Rafler and Hans Zessin", "title": "The logical postulates of B\\\"oge, Carnap and Johnson in the context of\n  Papangelou processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We adapt Johnson's sufficiency postulate, Carnap's prediction invariance\npostulate and B\\\"oge's learn-merge invariance to the context of Papangelou\nprocesses and discuss equivalence of their generalizations, in particular their\nweak and strong generalizations. This discussion identifies a condition which\noccurs in the construction of Papangelou processes. In particular, we show that\nthese generalizations characterize classes of Poisson and P\\'olya point\nprocesses.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2013 19:07:03 GMT"}, {"version": "v2", "created": "Fri, 7 Jun 2013 06:14:01 GMT"}, {"version": "v3", "created": "Tue, 11 Feb 2014 16:06:32 GMT"}], "update_date": "2014-02-12", "authors_parsed": [["Rafler", "Mathias", ""], ["Zessin", "Hans", ""]]}, {"id": "1306.1587", "submitter": "Hau-tieng Wu", "authors": "Amit Singer and Hau-tieng Wu", "title": "Spectral Convergence of the connection Laplacian from random samples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA math.ST stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral methods that are based on eigenvectors and eigenvalues of discrete\ngraph Laplacians, such as Diffusion Maps and Laplacian Eigenmaps are often used\nfor manifold learning and non-linear dimensionality reduction. It was\npreviously shown by Belkin and Niyogi \\cite{belkin_niyogi:2007} that the\neigenvectors and eigenvalues of the graph Laplacian converge to the\neigenfunctions and eigenvalues of the Laplace-Beltrami operator of the manifold\nin the limit of infinitely many data points sampled independently from the\nuniform distribution over the manifold. Recently, we introduced Vector\nDiffusion Maps and showed that the connection Laplacian of the tangent bundle\nof the manifold can be approximated from random samples. In this paper, we\npresent a unified framework for approximating other connection Laplacians over\nthe manifold by considering its principle bundle structure. We prove that the\neigenvectors and eigenvalues of these Laplacians converge in the limit of\ninfinitely many independent random samples. We generalize the spectral\nconvergence results to the case where the data points are sampled from a\nnon-uniform distribution, and for manifolds with and without boundary.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2013 02:06:31 GMT"}, {"version": "v2", "created": "Mon, 15 Sep 2014 22:38:55 GMT"}, {"version": "v3", "created": "Sun, 31 May 2015 17:58:26 GMT"}], "update_date": "2015-06-02", "authors_parsed": [["Singer", "Amit", ""], ["Wu", "Hau-tieng", ""]]}, {"id": "1306.1678", "submitter": "Francesco Bartolucci", "authors": "Francesco Bartolucci and Alessio Farcomeni", "title": "A discrete time event-history approach to informative drop-out in\n  multivariate latent Markov models with covariates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latent Markov (LM) models represent an important tool of analysis of\nlongitudinal data when response variables are affected by time-varying\nunobserved heterogeneity, which is accounted for by a hidden Markov chain. In\norder to avoid bias when using a model of this type in the presence of\ninformative drop-out, we propose an event-history (EH) extension of the LM\napproach that may be used with multivariate longitudinal data, in which one or\nmore outcomes of a different nature are observed at each time occasion. The EH\ncomponent of the resulting model is referred to the interval-censored drop-out,\nand bias in LM modeling is avoided by correlated random effects, included in\nthe different model components, which follow a common Markov chain. In order to\nperform maximum likelihood estimation of the proposed model by the\nExpectation-Maximization algorithm, we extend the usual backward-forward\nrecursions of Baum and Welch. The algorithm has the same complexity of the one\nadopted in cases of non-informative drop-out. Standard errors for the parameter\nestimates are derived by using the Oakes' identity. We illustrate the proposed\napproach through an application based on data coming from a medical study about\nprimary biliary cirrhosis in which there are two outcomes of interest, the\nfirst of which is continuous and the second is binary.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2013 10:00:43 GMT"}], "update_date": "2013-06-10", "authors_parsed": [["Bartolucci", "Francesco", ""], ["Farcomeni", "Alessio", ""]]}, {"id": "1306.1728", "submitter": "Amparo Gil", "authors": "Amparo Gil, Javier Segura and Nico M. Temme", "title": "On the computation of moments of the partial non-central chi-squared\n  distribution function", "comments": "6 pages", "journal-ref": "Proceedings of the International Conference \"Applications of\n  Mathematics 2013\". ISBN 978-80-85823-61-5", "doi": null, "report-no": null, "categories": "math.CA math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Properties satisfied by the moments of the partial non-central chi-square\ndistribution function, also known as Nuttall Q-functions, and methods for\ncomputing these moments are discussed in this paper. The Nuttall Q-function is\ninvolved in the study of a variety of problems in different fields, as for\nexample digital communications.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2013 13:53:09 GMT"}], "update_date": "2013-06-10", "authors_parsed": [["Gil", "Amparo", ""], ["Segura", "Javier", ""], ["Temme", "Nico M.", ""]]}, {"id": "1306.1754", "submitter": "Amparo Gil", "authors": "Amparo Gil, Javier Segura and Nico M. Temme", "title": "Efficient and accurate algorithms for the computation and inversion of\n  the incomplete gamma function ratios", "comments": "17 pages, 5 figures", "journal-ref": "SIAM Journal on Scientific Computing 34(6) (2012), A2965-A2981", "doi": null, "report-no": null, "categories": "math.CA math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithms for the numerical evaluation of the incomplete gamma function\nratios $P(a,x)=\\gamma(a,x)/\\Gamma(a)$ and $Q(a,x)=\\Gamma(a,x)/\\Gamma(a)$ are\ndescribed for positive values of $a$ and $x$. Also, inversion methods are given\nfor solving the equations $P(a,x)=p$, $Q(a,x)=q$, with $0<p,q<1$. Both the\ndirect computation and the inversion of the incomplete gamma function ratios\nare used in many problems in statistics and applied probability. The analytical\napproach from earlier literature is summarized and new initial estimates are\nderived for starting the inversion algorithms. The performance of the\nassociated software to our algorithms (the Fortran 90 module {\\bf IncgamFI}) is\nanalyzed and compared with earlier published algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2013 15:50:12 GMT"}], "update_date": "2013-06-10", "authors_parsed": [["Gil", "Amparo", ""], ["Segura", "Javier", ""], ["Temme", "Nico M.", ""]]}, {"id": "1306.1866", "submitter": "Xiao Wang", "authors": "Teresa M. Lebair, Jinglai Shen, Xiao Wang", "title": "Minimax Optimal Estimation of Convex Functions in the Supreme Norm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimation of convex functions finds broad applications in engineering and\nscience, while convex shape constraint gives rise to numerous challenges in\nasymptotic performance analysis. This paper is devoted to minimax optimal\nestimation of univariate convex functions from the H\\\"older class in the\nframework of shape constrained nonparametric estimation. Particularly, the\npaper establishes the optimal rate of convergence in two steps for the minimax\nsup-norm risk of convex functions with the H\\\"older order between one and two.\nIn the first step, by applying information theoretical results on probability\nmeasure distance, we establish the minimax lower bound under the supreme norm\nby constructing a novel family of piecewise quadratic convex functions in the\nH\\\"older class. In the second step, we develop a penalized convex spline\nestimator and establish the minimax upper bound under the supreme norm. Due to\nthe convex shape constraint, the optimality conditions of penalized convex\nsplines are characterized by nonsmooth complementarity conditions. By\nexploiting complementarity methods, a critical uniform Lipschitz property of\noptimal spline coefficients in the infinity norm is established. This property,\nalong with asymptotic estimation techniques, leads to uniform bounds for bias\nand stochastic errors on the entire interval of interest. This further yields\nthe optimal rate of convergence by choosing the suitable number of knots and\npenalty value. The present paper provides the first rigorous justification of\nthe optimal minimax risk for convex estimation under the supreme norm.\n", "versions": [{"version": "v1", "created": "Sat, 8 Jun 2013 01:46:26 GMT"}], "update_date": "2013-06-11", "authors_parsed": [["Lebair", "Teresa M.", ""], ["Shen", "Jinglai", ""], ["Wang", "Xiao", ""]]}, {"id": "1306.1868", "submitter": "Xiao Wang", "authors": "Xiao Wang, Pang Du, Jinglai Shen", "title": "Smoothing splines with varying smoothing parameter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the development of spatially adaptive smoothing splines\nfor the estimation of a regression function with non-homogeneous smoothness\nacross the domain. Two challenging issues that arise in this context are the\nevaluation of the equivalent kernel and the determination of a local penalty.\nThe roughness penalty is a function of the design points in order to\naccommodate local behavior of the regression function. It is shown that the\nspatially adaptive smoothing spline estimator is approximately a kernel\nestimator. The resulting equivalent kernel is spatially dependent. The\nequivalent kernels for traditional smoothing splines are a special case of this\ngeneral solution. With the aid of the Green's function for a two-point boundary\nvalue problem, the explicit forms of the asymptotic mean and variance are\nobtained for any interior point. Thus, the optimal roughness penalty function\nis obtained by approximately minimizing the asymptotic integrated mean square\nerror. Simulation results and an application illustrate the performance of the\nproposed estimator.\n", "versions": [{"version": "v1", "created": "Sat, 8 Jun 2013 01:52:31 GMT"}], "update_date": "2013-06-11", "authors_parsed": [["Wang", "Xiao", ""], ["Du", "Pang", ""], ["Shen", "Jinglai", ""]]}, {"id": "1306.1998", "submitter": "Enkelejd Hashorva", "authors": "Enkelejd Hashorva and Zhongquan Tan", "title": "Large Deviations of Shepp Statistics for Fractional Brownian Motion", "comments": "8 pages", "journal-ref": null, "doi": "10.1016/j.spl.2013.06.013", "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Define the incremental fractional Brownian field $B_{H}(s+\\tau)-B_{H}(s),\nH\\in (0,1)$, where $B_{H}(s)$ is a standard fractional Brownian motion with\nHurst index $H\\in(0,1)$. In this paper we derive the exact asymptotic behaviour\nof the maximum $\\max_{(\\tau,s)\\in[0,1]\\times[0,T]} (B_{H}(s+\\tau)-B_{H}(s)) $\nfor any $H\\in (0,1/2)$ complimenting thus the result of Zholud (2008) for the\nBrownian motion.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2013 09:20:59 GMT"}], "update_date": "2013-09-03", "authors_parsed": [["Hashorva", "Enkelejd", ""], ["Tan", "Zhongquan", ""]]}, {"id": "1306.2003", "submitter": "Abraao D. C. Nacimento", "authors": "Abra\\~ao D. C. Nascimento, Michelle M. Horta, Alejandro C. Frery, and\n  Renato J. Cintra", "title": "Comparing Edge Detection Methods based on Stochastic Entropies and\n  Distances for PolSAR Imagery", "comments": "12 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.CV eess.IV stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Polarimetric synthetic aperture radar (PolSAR) has achieved a prominent\nposition as a remote imaging method. However, PolSAR images are contaminated by\nspeckle noise due to the coherent illumination employed during the data\nacquisition. This noise provides a granular aspect to the image, making its\nprocessing and analysis (such as in edge detection) hard tasks. This paper\ndiscusses seven methods for edge detection in multilook PolSAR images. In all\nmethods, the basic idea consists in detecting transition points in the finest\npossible strip of data which spans two regions. The edge is contoured using the\ntransitions points and a B-spline curve. Four stochastic distances, two\ndifferences of entropies, and the maximum likelihood criterion were used under\nthe scaled complex Wishart distribution; the first six stem from the h-phi\nclass of measures. The performance of the discussed detection methods was\nquantified and analyzed by the computational time and probability of correct\nedge detection, with respect to the number of looks, the backscatter matrix as\na whole, the SPAN, the covariance an the spatial resolution. The detection\nprocedures were applied to three real PolSAR images. Results provide evidence\nthat the methods based on the Bhattacharyya distance and the difference of\nShannon entropies outperform the other techniques.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2013 10:40:20 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Nascimento", "Abra\u00e3o D. C.", ""], ["Horta", "Michelle M.", ""], ["Frery", "Alejandro C.", ""], ["Cintra", "Renato J.", ""]]}, {"id": "1306.2035", "submitter": "Martin Azizyan", "authors": "Martin Azizyan, Aarti Singh, Larry Wasserman", "title": "Minimax Theory for High-dimensional Gaussian Mixtures with Sparse Mean\n  Separation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While several papers have investigated computationally and statistically\nefficient methods for learning Gaussian mixtures, precise minimax bounds for\ntheir statistical performance as well as fundamental limits in high-dimensional\nsettings are not well-understood. In this paper, we provide precise information\ntheoretic bounds on the clustering accuracy and sample complexity of learning a\nmixture of two isotropic Gaussians in high dimensions under small mean\nseparation. If there is a sparse subset of relevant dimensions that determine\nthe mean separation, then the sample complexity only depends on the number of\nrelevant dimensions and mean separation, and can be achieved by a simple\ncomputationally efficient procedure. Our results provide the first step of a\ntheoretical basis for recent methods that combine feature selection and\nclustering.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2013 16:28:56 GMT"}], "update_date": "2013-06-11", "authors_parsed": [["Azizyan", "Martin", ""], ["Singh", "Aarti", ""], ["Wasserman", "Larry", ""]]}, {"id": "1306.2056", "submitter": "Shuhei Mano", "authors": "Shuhei Mano", "title": "Extreme sizes in the Gibbs-type exchangeable random partitions", "comments": "34 pages, 1 figure", "journal-ref": "Ann Inst Stat Math (2017) 69: 1-37", "doi": "10.1007/s10463-015-0530-0", "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gibbs-type exchangeable random partitions, which is a class of multiplicative\nmeasures on the set of positive integer partitions, appear in various contexts,\nincluding Bayesian statistics, random combinatorial structures, and stochastic\nmodels of diversity in various phenomena. Some distributional results on\nordered sizes in the Gibbs partition are established by introducing associated\npartial Bell polynomials and analysis of the generating functions. The\ncombinatorial approach is applied to derive explicit results on asymptotic\nbehavior of the extreme sizes in the Gibbs partition. Especially, Ewens-Pitman\npartition, which is the sample from the Poisson-Dirichlet process and has been\ndiscussed from rather model-specific viewpoints, and a random partition which\nwas recently introduced by Gnedin, are discussed in the details. As\nby-products, some formulas for the associated partial Bell polynomials are\npresented.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2013 19:33:48 GMT"}, {"version": "v2", "created": "Mon, 1 Jul 2013 00:48:03 GMT"}, {"version": "v3", "created": "Tue, 17 Dec 2013 12:23:05 GMT"}, {"version": "v4", "created": "Wed, 6 Aug 2014 07:16:17 GMT"}, {"version": "v5", "created": "Mon, 29 Jun 2015 05:33:51 GMT"}], "update_date": "2017-06-14", "authors_parsed": [["Mano", "Shuhei", ""]]}, {"id": "1306.2193", "submitter": "Federico Polito", "authors": "Elisa Benedetto, Federico Polito, Laura Sacerdote", "title": "On Firing Rate Estimation for Dependent Interspike Intervals", "comments": null, "journal-ref": "Neural Computation, Vol. 27 (3), 699-724, 2015", "doi": "10.1162/NECO_a_00709", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  If interspike intervals are dependent the instantaneous firing rate does not\ncatch important features of spike trains. In this case the conditional\ninstantaneous rate plays the role of the instantaneous firing rate for the case\nof samples of independent interspike intervals. If the conditional distribution\nof the interspikes intervals is unknown, it becomes difficult to evaluate the\nconditional firing rate. We propose a non parametric estimator for the\nconditional instantaneous firing rate for Markov, stationary and ergodic ISIs.\nAn algorithm to check the reliability of the proposed estimator is introduced\nand its consistency properties are proved. The method is applied to data\nobtained from a stochastic two compartment model and to in vitro experimental\ndata.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2013 13:11:25 GMT"}, {"version": "v2", "created": "Mon, 14 Apr 2014 12:01:24 GMT"}, {"version": "v3", "created": "Mon, 21 Jul 2014 16:54:48 GMT"}], "update_date": "2015-09-21", "authors_parsed": [["Benedetto", "Elisa", ""], ["Polito", "Federico", ""], ["Sacerdote", "Laura", ""]]}, {"id": "1306.2194", "submitter": "Michael Chichignoud", "authors": "Michael Chichignoud and S\\'ebastien Loustau", "title": "Adaptive Noisy Clustering", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of adaptive noisy clustering is investigated. Given a set of\nnoisy observations $Z_i=X_i+\\epsilon_i$, $i=1,...,n$, the goal is to design\nclusters associated with the law of $X_i$'s, with unknown density $f$ with\nrespect to the Lebesgue measure. Since we observe a corrupted sample, a direct\napproach as the popular {\\it $k$-means} is not suitable in this case. In this\npaper, we propose a noisy $k$-means minimization, which is based on the\n$k$-means loss function and a deconvolution estimator of the density $f$. In\nparticular, this approach suffers from the dependence on a bandwidth involved\nin the deconvolution kernel. Fast rates of convergence for the excess risk are\nproposed for a particular choice of the bandwidth, which depends on the\nsmoothness of the density $f$.\n  Then, we turn out into the main issue of the paper: the data-driven choice of\nthe bandwidth. We state an adaptive upper bound for a new selection rule,\ncalled ERC (Empirical Risk Comparison). This selection rule is based on the\nLepski's principle, where empirical risks associated with different bandwidths\nare compared. Finally, we illustrate that this adaptive rule can be used in\nmany statistical problems of $M$-estimation where the empirical risk depends on\na nuisance parameter.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2013 13:15:25 GMT"}], "update_date": "2013-06-11", "authors_parsed": [["Chichignoud", "Michael", ""], ["Loustau", "S\u00e9bastien", ""]]}, {"id": "1306.2290", "submitter": "Xinjia Chen", "authors": "Xinjia Chen", "title": "Asymptotically Optimal Sequential Estimation of the Mean Based on\n  Inclusion Principle", "comments": "75 pages, no figures. The main results of this paper appeared in\n  Proceeding of SPIE Conferences", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A large class of problems in sciences and engineering can be formulated as\nthe general problem of constructing random intervals with pre-specified\ncoverage probabilities for the mean. Wee propose a general approach for\nstatistical inference of mean values based on accumulated observational data.\nWe show that the construction of such random intervals can be accomplished by\ncomparing the endpoints of random intervals with confidence sequences for the\nmean. Asymptotic results are obtained for such sequential methods.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2013 19:11:25 GMT"}], "update_date": "2013-06-11", "authors_parsed": [["Chen", "Xinjia", ""]]}, {"id": "1306.2419", "submitter": "Paul Kabaila", "authors": "Waruni Abeysekera and Paul Kabaila", "title": "A new recentered confidence sphere for the multivariate normal mean", "comments": "A small error has been corrected", "journal-ref": "Optimized recentered confidence spheres for the multivariate\n  normal mean. Electronic Journal of Statistics, 11, 1798-1826 (2017)", "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a new recentered confidence sphere for the mean, theta, of a\nmultivariate normal distribution. This sphere is centred on the positive-part\nJames-Stein estimator, with radius that is a piecewise cubic Hermite\ninterpolating polynomial function of the norm of the data vector. This radius\nfunction is determined by numerically minimizing the scaled expected volume, at\ntheta = 0, of this confidence sphere, subject to the coverage constraint. We\nuse the computationally-convenient formula, derived by Casella and Hwang [3],\nfor the coverage probability of a recentered confidence sphere. Casella and\nHwang, op. cit., describe a recentered confidence sphere that is also centred\non the positive-part James-Stein estimator, but with radius function determined\nby empirical Bayes considerations. Our new recentered confidence sphere\ncompares favourably with this confidence sphere, in terms of both the minimum\ncoverage probability and the scaled expected volume at theta = 0.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2013 05:01:05 GMT"}, {"version": "v2", "created": "Wed, 10 Dec 2014 01:51:20 GMT"}], "update_date": "2017-10-18", "authors_parsed": [["Abeysekera", "Waruni", ""], ["Kabaila", "Paul", ""]]}, {"id": "1306.2671", "submitter": "Antonio Canale", "authors": "Antonio Canale and Pierpaolo De Blasi", "title": "Posterior asymptotics of nonparametric location-scale mixtures for\n  multivariate density estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Density estimation represents one of the most successful applications of\nBayesian nonparametrics. In particular, Dirichlet process mixtures of normals\nare the gold standard for density estimation and their asymptotic properties\nhave been studied extensively, especially in the univariate case. However a gap\nbetween practitioners and the current theoretical literature is present. So\nfar, posterior asymptotic results in the multivariate case are available only\nfor location mixtures of Gaussian kernels with independent prior on the common\ncovariance matrix, while in practice as well as from a conceptual point of view\na location-scale mixture is often preferable. In this paper we address\nposterior consistency for such general mixture models by adapting a convergence\nrate result which combines the usual low-entropy, high-mass sieve approach with\na suitable summability condition. Specifically, we establish consistency for\nDirichlet process mixtures of Gaussian kernels with various prior\nspecifications on the covariance matrix. Posterior convergence rates are also\ndiscussed.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2013 22:26:17 GMT"}, {"version": "v2", "created": "Sat, 26 Oct 2013 12:56:34 GMT"}, {"version": "v3", "created": "Wed, 1 Jul 2015 13:59:35 GMT"}], "update_date": "2015-07-02", "authors_parsed": [["Canale", "Antonio", ""], ["De Blasi", "Pierpaolo", ""]]}, {"id": "1306.2814", "submitter": "Andrius \\v{C}iginas", "authors": "Andrius \\v{C}iginas and Tomas Rudys", "title": "A solution in small area estimation problems", "comments": "16 pages, 30 figures. The previous version is much improved in the\n  quality estimation of estimators. A simulation study was extended", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new method in problems where estimates are needed for finite\npopulation domains with small or even zero sample sizes. In contrast to known\nestimation methods, an auxiliary information is used to model sizes of\npopulation units instead of a direct prediction of their values of interest. In\nparticular, via an additional characterization of regression models, we\nincorporate a scatter and variabilities of the units sizes into an estimator,\nand then it uses an information of the whole sample by taking into an account a\nlocation of the estimation domain inside the population. To reduce an impact of\nthe introduced domain total estimator bias to the mean square error, we\nconstruct also a regression type version of the estimator. An efficiency of the\nmethod proposed is shown in a simulation study.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2013 13:05:31 GMT"}, {"version": "v2", "created": "Fri, 20 Jun 2014 16:57:14 GMT"}], "update_date": "2014-06-23", "authors_parsed": [["\u010ciginas", "Andrius", ""], ["Rudys", "Tomas", ""]]}, {"id": "1306.3092", "submitter": "Ryan Martin", "authors": "Ryan Martin and Chuanhai Liu", "title": "Marginal inferential models: prior-free probabilistic inference on\n  interest parameters", "comments": "23 pages, 2 figures", "journal-ref": "Journal of the American Statistical Association, volume 110, pages\n  1621--1631, 2015", "doi": "10.1080/01621459.2014.985827", "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The inferential models (IM) framework provides prior-free,\nfrequency-calibrated, posterior probabilistic inference. The key is the use of\nrandom sets to predict unobservable auxiliary variables connected to the\nobservable data and unknown parameters. When nuisance parameters are present, a\nmarginalization step can reduce the dimension of the auxiliary variable which,\nin turn, leads to more efficient inference. For regular problems, exact\nmarginalization can be achieved, and we give conditions for marginal IM\nvalidity. We show that our approach provides exact and efficient marginal\ninference in several challenging problems, including a many-normal-means\nproblem. In non-regular problems, we propose a generalized marginalization\ntechnique and prove its validity. Details are given for two benchmark examples,\nnamely, the Behrens--Fisher and gamma mean problems.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2013 12:08:17 GMT"}, {"version": "v2", "created": "Sun, 22 Dec 2013 16:05:34 GMT"}, {"version": "v3", "created": "Thu, 10 Jul 2014 18:20:59 GMT"}, {"version": "v4", "created": "Fri, 24 Oct 2014 21:32:53 GMT"}], "update_date": "2016-01-26", "authors_parsed": [["Martin", "Ryan", ""], ["Liu", "Chuanhai", ""]]}, {"id": "1306.3301", "submitter": "Anne Philippe", "authors": "Remigijus Leipus, Anne Philippe (LMJL), Donata Puplinskaite (LMJL),\n  Donatas Surgailis", "title": "Aggregation and long memory: recent developments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well-known that the aggregated time series might have very different\nproperties from those of the individual series, in particular, long memory. At\nthe present time, aggregation has become one of the main tools for modelling of\nlong memory processes. We review recent work on contemporaneous aggregation of\nrandom-coefficient AR(1) and related models, with particular focus on various\nlong memory properties of the aggregated process.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2013 06:19:28 GMT"}], "update_date": "2013-06-17", "authors_parsed": [["Leipus", "Remigijus", "", "LMJL"], ["Philippe", "Anne", "", "LMJL"], ["Puplinskaite", "Donata", "", "LMJL"], ["Surgailis", "Donatas", ""]]}, {"id": "1306.3373", "submitter": "Santiago Gallon", "authors": "Chlo\\'e Dimeglio (IMT), Santiago Gall\\'on (IMT), Jean-Michel Loubes\n  (IMT), Elie Maza (GBF)", "title": "A robust algorithm for template curve estimation based on manifold\n  embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the problem of finding a meaningful template function\nthat represents the common pattern of a sample of curves. To address this\nissue, a novel algorithm based on a robust version of the isometric featuring\nmapping (Isomap) algorithm is developed. Assuming that the functional data lie\non an intrinsically low-dimensional smooth manifold with unknown underlying\nstructure, we propose an approximation of the geodesic distance. This\napproximation is used to compute the corresponding empirical Fr\\'echet median\nfunction, which provides an intrinsic estimator of the template function.\nUnlike the Isomap method, the algorithm has the advantage of being parameter\nfree and easier to use. Comparisons with other methods, with both simulated and\nreal datasets, show that the algorithm works well and outperforms these\nmethods.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2013 12:04:30 GMT"}], "update_date": "2013-06-17", "authors_parsed": [["Dimeglio", "Chlo\u00e9", "", "IMT"], ["Gall\u00f3n", "Santiago", "", "IMT"], ["Loubes", "Jean-Michel", "", "IMT"], ["Maza", "Elie", "", "GBF"]]}, {"id": "1306.3494", "submitter": "Jelena Bradic", "authors": "Jelena Bradic", "title": "Randomized maximum-contrast selection: subagging for large-scale\n  regression", "comments": null, "journal-ref": "Electron. J. Statist. Volume 10, Number 1 (2016), 121-170", "doi": "10.1214/15-EJS1085", "report-no": null, "categories": "math.ST stat.CO stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a very general method for sparse and large-scale variable\nselection. The large-scale regression settings is such that both the number of\nparameters and the number of samples are extremely large. The proposed method\nis based on careful combination of penalized estimators, each applied to a\nrandom projection of the sample space into a low-dimensional space. In one\nspecial case that we study in detail, the random projections are divided into\nnon-overlapping blocks; each consisting of only a small portion of the original\ndata. Within each block we select the projection yielding the smallest\nout-of-sample error. Our random ensemble estimator then aggregates the results\naccording to new maximal-contrast voting scheme to determine the final selected\nset. Our theoretical results illuminate the effect on performance of increasing\nthe number of non-overlapping blocks. Moreover, we demonstrate that statistical\noptimality is retained along with the computational speedup. The proposed\nmethod achieves minimax rates for approximate recovery over all estimators\nusing the full set of samples. Furthermore, our theoretical results allow the\nnumber of subsamples to grow with the subsample size and do not require\nirrepresentable condition. The estimator is also compared empirically with\nseveral other popular high-dimensional estimators via an extensive simulation\nstudy, which reveals its excellent finite-sample performance.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2013 19:39:54 GMT"}, {"version": "v2", "created": "Wed, 14 Aug 2013 07:01:09 GMT"}, {"version": "v3", "created": "Fri, 19 Sep 2014 00:43:48 GMT"}, {"version": "v4", "created": "Wed, 1 Jul 2015 15:25:51 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Bradic", "Jelena", ""]]}, {"id": "1306.3609", "submitter": "Yihong Wu", "authors": "Zongming Ma and Yihong Wu", "title": "Volume Ratio, Sparsity, and Minimaxity under Unitarily Invariant Norms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current paper presents a novel machinery for studying non-asymptotic\nminimax estimation of high-dimensional matrices, which yields tight minimax\nrates for a large collection of loss functions in a variety of problems.\n  Based on the convex geometry of finite-dimensional Banach spaces, we first\ndevelop a volume ratio approach for determining minimax estimation rates of\nunconstrained normal mean matrices under all squared unitarily invariant norm\nlosses. In addition, we establish the minimax rates for estimating mean\nmatrices with submatrix sparsity, where the sparsity constraint introduces an\nadditional term in the rate whose dependence on the norm differs completely\nfrom the rate of the unconstrained problem. Moreover, the approach is\napplicable to the matrix completion problem under the low-rank constraint.\n  The new method also extends beyond the normal mean model. In particular, it\nyields tight rates in covariance matrix estimation and Poisson rate matrix\nestimation problems for all unitarily invariant norms.\n", "versions": [{"version": "v1", "created": "Sat, 15 Jun 2013 22:16:00 GMT"}], "update_date": "2013-06-18", "authors_parsed": [["Ma", "Zongming", ""], ["Wu", "Yihong", ""]]}, {"id": "1306.3690", "submitter": "Robert Krauthgamer", "authors": "Robert Krauthgamer, Boaz Nadler, Dan Vilenchik", "title": "Do semidefinite relaxations solve sparse PCA up to the information\n  limit?", "comments": "Published at http://dx.doi.org/10.1214/15-AOS1310 in the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2015, Vol. 43, No. 3, 1300-1322", "doi": "10.1214/15-AOS1310", "report-no": "IMS-AOS-AOS1310", "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating the leading principal components of data, assuming they are\nsparse, is a central task in modern high-dimensional statistics. Many\nalgorithms were developed for this sparse PCA problem, from simple diagonal\nthresholding to sophisticated semidefinite programming (SDP) methods. A key\ntheoretical question is under what conditions can such algorithms recover the\nsparse principal components? We study this question for a single-spike model\nwith an $\\ell_0$-sparse eigenvector, in the asymptotic regime as dimension $p$\nand sample size $n$ both tend to infinity. Amini and Wainwright [Ann. Statist.\n37 (2009) 2877-2921] proved that for sparsity levels $k\\geq\\Omega(n/\\log p)$,\nno algorithm, efficient or not, can reliably recover the sparse eigenvector. In\ncontrast, for $k\\leq O(\\sqrt{n/\\log p})$, diagonal thresholding is consistent.\nIt was further conjectured that an SDP approach may close this gap between\ncomputational and information limits. We prove that when\n$k\\geq\\Omega(\\sqrt{n})$, the proposed SDP approach, at least in its standard\nusage, cannot recover the sparse spike. In fact, we conjecture that in the\nsingle-spike model, no computationally-efficient algorithm can recover a spike\nof $\\ell_0$-sparsity $k\\geq\\Omega(\\sqrt{n})$. Finally, we present empirical\nresults suggesting that up to sparsity levels $k=O(\\sqrt{n})$, recovery is\npossible by a simple covariance thresholding algorithm.\n", "versions": [{"version": "v1", "created": "Sun, 16 Jun 2013 17:40:09 GMT"}, {"version": "v2", "created": "Sun, 21 Sep 2014 13:02:37 GMT"}, {"version": "v3", "created": "Mon, 12 Jan 2015 18:50:07 GMT"}, {"version": "v4", "created": "Wed, 3 Jun 2015 08:30:11 GMT"}], "update_date": "2015-06-04", "authors_parsed": [["Krauthgamer", "Robert", ""], ["Nadler", "Boaz", ""], ["Vilenchik", "Dan", ""]]}, {"id": "1306.3768", "submitter": "Michal Pe\\v{s}ta PhD", "authors": "\\v{S}\\'arka Hudecov\\'a and Michal Pe\\v{s}ta", "title": "Modeling Dependencies in Claims Reserving with GEE", "comments": "Submitted on April 9, 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP math.PR math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common approach to the claims reserving problem is based on generalized\nlinear models (GLM). Within this framework, the claims in different origin and\ndevelopment years are assumed to be independent variables. If this assumption\nis violated, the classical techniques may provide incorrect predictions of the\nclaims reserves or even misleading estimates of the prediction error.\n  In this article, the application of generalized estimating equations (GEE)\nfor estimation of the claims reserves is shown. Claim triangles are handled as\npanel data, where claim amounts within the same accident year are dependent.\nSince the GEE allow to incorporate dependencies, various correlation structures\nare introduced and some practical recommendations are given.\n  Model selection criteria within the GEE reserving method are proposed.\nMoreover, an estimate for the mean square error of prediction for the claims\nreserves is derived in a nonstandard way and its advantages are discussed. Real\ndata examples are provided as an illustration of the potential benefits of the\npresented approach.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2013 08:40:34 GMT"}], "update_date": "2013-06-18", "authors_parsed": [["Hudecov\u00e1", "\u0160\u00e1rka", ""], ["Pe\u0161ta", "Michal", ""]]}, {"id": "1306.3930", "submitter": "Axel B\\\"{u}cher", "authors": "Axel B\\\"ucher, Ivan Kojadinovic", "title": "A dependent multiplier bootstrap for the sequential empirical copula\n  process under strong mixing", "comments": "Published at http://dx.doi.org/10.3150/14-BEJ682 in the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2016, Vol. 22, No. 2, 927-968", "doi": "10.3150/14-BEJ682", "report-no": "IMS-BEJ-BEJ682", "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two key ingredients to carry out inference on the copula of multivariate\nobservations are the empirical copula process and an appropriate resampling\nscheme for the latter. Among the existing techniques used for i.i.d.\nobservations, the multiplier bootstrap of R\\'{e}millard and Scaillet (J.\nMultivariate Anal. 100 (2009) 377-386) frequently appears to lead to inference\nprocedures with the best finite-sample properties. B\\\"{u}cher and Ruppert (J.\nMultivariate Anal. 116 (2013) 208-229) recently proposed an extension of this\ntechnique to strictly stationary strongly mixing observations by adapting the\ndependent multiplier bootstrap of B\\\"{u}hlmann (The blockwise bootstrap in time\nseries and empirical processes (1993) ETH Z\\\"{u}rich, Section 3.3) to the\nempirical copula process. The main contribution of this work is a\ngeneralization of the multiplier resampling scheme proposed by B\\\"{u}cher and\nRuppert along two directions. First, the resampling scheme is now genuinely\nsequential, thereby allowing to transpose to the strongly mixing setting many\nof the existing multiplier tests on the unknown copula, including nonparametric\ntests for change-point detection. Second, the resampling scheme is now fully\nautomatic as a data-adaptive procedure is proposed which can be used to\nestimate the bandwidth parameter. A simulation study is used to investigate the\nfinite-sample performance of the resampling scheme and provides suggestions on\nhow to choose several additional parameters. As by-products of this work, the\nvalidity of a sequential version of the dependent multiplier bootstrap for\nempirical processes of B\\\"{u}hlmann is obtained under weaker conditions on the\nstrong mixing coefficients and the multipliers, and the weak convergence of the\nsequential empirical copula process is established under many serial dependence\nconditions.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2013 17:05:57 GMT"}, {"version": "v2", "created": "Fri, 14 Mar 2014 09:36:21 GMT"}, {"version": "v3", "created": "Wed, 8 Oct 2014 18:41:48 GMT"}, {"version": "v4", "created": "Tue, 9 Feb 2016 11:13:10 GMT"}], "update_date": "2016-02-10", "authors_parsed": [["B\u00fccher", "Axel", ""], ["Kojadinovic", "Ivan", ""]]}, {"id": "1306.4158", "submitter": "Louis H. Y. Chen", "authors": "Louis H. Y. Chen, Adrian R\\\"ollin", "title": "Approximating dependent rare events", "comments": "Published in at http://dx.doi.org/10.3150/12-BEJSP18 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2013, Vol. 19, No. 4, 1243-1267", "doi": "10.3150/12-BEJSP18", "report-no": "IMS-BEJ-BEJSP18", "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we give a historical account of the development of Poisson\napproximation using Stein's method and present some of the main results. We\ngive two recent applications, one on maximal arithmetic progressions and the\nother on bootstrap percolation. We also discuss generalisations to compound\nPoisson approximation, Poisson process approximation and multivariate Poisson\napproximation, and state a few open problems.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2013 11:51:34 GMT"}, {"version": "v2", "created": "Mon, 30 Sep 2013 13:00:54 GMT"}, {"version": "v3", "created": "Tue, 8 Oct 2013 08:32:43 GMT"}], "update_date": "2013-10-09", "authors_parsed": [["Chen", "Louis H. Y.", ""], ["R\u00f6llin", "Adrian", ""]]}, {"id": "1306.4391", "submitter": "Akshay Soni", "authors": "Akshay Soni and Jarvis Haupt", "title": "On the Fundamental Limits of Recovering Tree Sparse Vectors from Noisy\n  Linear Measurements", "comments": "33 pages, 5 figures, IEEE Transactions on Information Theory\n  (accepted for publication)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent breakthrough results in compressive sensing (CS) have established that\nmany high dimensional signals can be accurately recovered from a relatively\nsmall number of non-adaptive linear observations, provided that the signals\npossess a sparse representation in some basis. Subsequent efforts have shown\nthat the performance of CS can be improved by exploiting additional structure\nin the locations of the nonzero signal coefficients during inference, or by\nutilizing some form of data-dependent adaptive measurement focusing during the\nsensing process. To our knowledge, our own previous work was the first to\nestablish the potential benefits that can be achieved when fusing the notions\nof adaptive sensing and structured sparsity -- that work examined the task of\nsupport recovery from noisy linear measurements, and established that an\nadaptive sensing strategy specifically tailored to signals that are tree-sparse\ncan significantly outperform adaptive and non-adaptive sensing strategies that\nare agnostic to the underlying structure. In this work we establish fundamental\nperformance limits for the task of support recovery of tree-sparse signals from\nnoisy measurements, in settings where measurements may be obtained either\nnon-adaptively (using a randomized Gaussian measurement strategy motivated by\ninitial CS investigations) or by any adaptive sensing strategy. Our main\nresults here imply that the adaptive tree sensing procedure analyzed in our\nprevious work is nearly optimal, in the sense that no other sensing and\nestimation strategy can perform fundamentally better for identifying the\nsupport of tree-sparse signals.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2013 23:27:17 GMT"}, {"version": "v2", "created": "Wed, 16 Oct 2013 02:58:26 GMT"}], "update_date": "2013-10-17", "authors_parsed": [["Soni", "Akshay", ""], ["Haupt", "Jarvis", ""]]}, {"id": "1306.4408", "submitter": "Jinyuan Chang", "authors": "Jinyuan Chang, Cheng Yong Tang, Yichao Wu", "title": "Marginal empirical likelihood and sure independence feature screening", "comments": "Published in at http://dx.doi.org/10.1214/13-AOS1139 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2013, Vol. 41, No. 4, 2123-2148", "doi": "10.1214/13-AOS1139", "report-no": "IMS-AOS-AOS1139", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a marginal empirical likelihood approach in scenarios when the\nnumber of variables grows exponentially with the sample size. The marginal\nempirical likelihood ratios as functions of the parameters of interest are\nsystematically examined, and we find that the marginal empirical likelihood\nratio evaluated at zero can be used to differentiate whether an explanatory\nvariable is contributing to a response variable or not. Based on this finding,\nwe propose a unified feature screening procedure for linear models and the\ngeneralized linear models. Different from most existing feature screening\napproaches that rely on the magnitudes of some marginal estimators to identify\ntrue signals, the proposed screening approach is capable of further\nincorporating the level of uncertainties of such estimators. Such a merit\ninherits the self-studentization property of the empirical likelihood approach,\nand extends the insights of existing feature screening methods. Moreover, we\nshow that our screening approach is less restrictive to distributional\nassumptions, and can be conveniently adapted to be applied in a broad range of\nscenarios such as models specified using general moment conditions. Our\ntheoretical results and extensive numerical examples by simulations and data\nanalysis demonstrate the merits of the marginal empirical likelihood approach.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2013 01:36:19 GMT"}, {"version": "v2", "created": "Tue, 3 Sep 2013 13:37:48 GMT"}, {"version": "v3", "created": "Wed, 6 Nov 2013 06:17:19 GMT"}], "update_date": "2013-11-07", "authors_parsed": [["Chang", "Jinyuan", ""], ["Tang", "Cheng Yong", ""], ["Wu", "Yichao", ""]]}, {"id": "1306.4529", "submitter": "Michal Pe\\v{s}ta PhD", "authors": "Michal Pe\\v{s}ta and Ostap Okhrin", "title": "Conditional Least Squares and Copulae in Claims Reserving for a Single\n  Line of Business", "comments": "Submitted on June 19, 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP math.PR math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the main goals in non-life insurance is to estimate the claims reserve\ndistribution. A generalized time series model, that allows for modeling the\nconditional mean and variance of the claim amounts, is proposed for the claims\ndevelopment. On contrary to the classical stochastic reserving techniques, the\nnumber of model parameters does not depend on the number of development\nperiods, which leads to a more precise forecasting.\n  Moreover, the time series innovations for the consecutive claims are not\nconsidered to be independent anymore. Conditional least squares are used for\nmodel parameter estimation and consistency of such estimate is proved. Copula\napproach is used for modeling the dependence structure, which improves the\nprecision of the reserve distribution estimate as well.\n  Real data examples are provided as an illustration of the potential benefits\nof the presented approach.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2013 13:05:45 GMT"}], "update_date": "2013-06-20", "authors_parsed": [["Pe\u0161ta", "Michal", ""], ["Okhrin", "Ostap", ""]]}, {"id": "1306.4790", "submitter": "Tim Wirtz", "authors": "Tim Wirtz and Thomas Guhr", "title": "Distribution of the Smallest Eigenvalue in the Correlated Wishart Model", "comments": "5 pages, 1 figure", "journal-ref": "Phys. Rev. Lett. 111, 094101 (2013)", "doi": "10.1103/PhysRevLett.111.094101", "report-no": null, "categories": "math-ph math.MP math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wishart random matrix theory is of major importance for the analysis of\ncorrelated time series. The distribution of the smallest eigenvalue for Wishart\ncorrelation matrices is particularly interesting in many applications. In the\ncomplex and in the real case, we calculate it exactly for arbitrary empirical\neigenvalues, i.e., for fully correlated Gaussian Wishart ensembles. To this\nend, we derive certain dualities of matrix models in ordinary space. We thereby\ncompletely avoid the otherwise unsurmountable problem of computing a highly\nnon-trivial group integral. Our results are compact and much easier to handle\nthan previous ones. Furthermore, we obtain a new universality for the\ndistribution of the smallest eigenvalue on the proper local scale.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2013 08:56:49 GMT"}, {"version": "v2", "created": "Fri, 18 Oct 2013 08:35:29 GMT"}], "update_date": "2013-10-21", "authors_parsed": [["Wirtz", "Tim", ""], ["Guhr", "Thomas", ""]]}, {"id": "1306.4847", "submitter": "Jian Huang", "authors": "Jian Huang, Tingni Sun, Zhiliang Ying, Yi Yu, Cun-Hui Zhang", "title": "Oracle inequalities for the lasso in the Cox model", "comments": "Published in at http://dx.doi.org/10.1214/13-AOS1098 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2013, Vol. 41, No. 3, 1142-1165", "doi": "10.1214/13-AOS1098", "report-no": "IMS-AOS-AOS1098", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the absolute penalized maximum partial likelihood estimator in\nsparse, high-dimensional Cox proportional hazards regression models where the\nnumber of time-dependent covariates can be larger than the sample size. We\nestablish oracle inequalities based on natural extensions of the compatibility\nand cone invertibility factors of the Hessian matrix at the true regression\ncoefficients. Similar results based on an extension of the restricted\neigenvalue can be also proved by our method. However, the presented oracle\ninequalities are sharper since the compatibility and cone invertibility factors\nare always greater than the corresponding restricted eigenvalue. In the Cox\nregression model, the Hessian matrix is based on time-dependent covariates in\ncensored risk sets, so that the compatibility and cone invertibility factors,\nand the restricted eigenvalue as well, are random variables even when they are\nevaluated for the Hessian at the true regression coefficients. Under mild\nconditions, we prove that these quantities are bounded from below by positive\nconstants for time-dependent covariates, including cases where the number of\ncovariates is of greater order than the sample size. Consequently, the\ncompatibility and cone invertibility factors can be treated as positive\nconstants in our oracle inequalities.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2013 12:21:50 GMT"}], "update_date": "2013-06-21", "authors_parsed": [["Huang", "Jian", ""], ["Sun", "Tingni", ""], ["Ying", "Zhiliang", ""], ["Yu", "Yi", ""], ["Zhang", "Cun-Hui", ""]]}, {"id": "1306.4864", "submitter": "Yongmiao Hong", "authors": "Yongmiao Hong, Yoon-Jin Lee", "title": "A loss function approach to model specification testing and its relative\n  efficiency", "comments": "Published in at http://dx.doi.org/10.1214/13-AOS1099 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2013, Vol. 41, No. 3, 1166-1203", "doi": "10.1214/13-AOS1099", "report-no": "IMS-AOS-AOS1099", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The generalized likelihood ratio (GLR) test proposed by Fan, Zhang and Zhang\n[Ann. Statist. 29 (2001) 153-193] and Fan and Yao [Nonlinear Time Series:\nNonparametric and Parametric Methods (2003) Springer] is a generally applicable\nnonparametric inference procedure. In this paper, we show that although it\ninherits many advantages of the parametric maximum likelihood ratio (LR) test,\nthe GLR test does not have the optimal power property. We propose a generally\napplicable test based on loss functions, which measure discrepancies between\nthe null and nonparametric alternative models and are more relevant to\ndecision-making under uncertainty. The new test is asymptotically more powerful\nthan the GLR test in terms of Pitman's efficiency criterion. This efficiency\ngain holds no matter what smoothing parameter and kernel function are used and\neven when the true likelihood function is available for the GLR test.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2013 13:09:52 GMT"}], "update_date": "2013-06-21", "authors_parsed": [["Hong", "Yongmiao", ""], ["Lee", "Yoon-Jin", ""]]}, {"id": "1306.4867", "submitter": "Alexei Onatski", "authors": "Alexei Onatski, Marcelo J. Moreira, Marc Hallin", "title": "Asymptotic power of sphericity tests for high-dimensional data", "comments": "Published in at http://dx.doi.org/10.1214/13-AOS1100 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2013, Vol. 41, No. 3, 1204-1231", "doi": "10.1214/13-AOS1100", "report-no": "IMS-AOS-AOS1100", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the asymptotic power of tests of sphericity against\nperturbations in a single unknown direction as both the dimensionality of the\ndata and the number of observations go to infinity. We establish the\nconvergence, under the null hypothesis and contiguous alternatives, of the log\nratio of the joint densities of the sample covariance eigenvalues to a Gaussian\nprocess indexed by the norm of the perturbation. When the perturbation norm is\nlarger than the phase transition threshold studied in Baik, Ben Arous and Peche\n[Ann. Probab. 33 (2005) 1643-1697] the limiting process is degenerate, and\ndiscrimination between the null and the alternative is asymptotically certain.\nWhen the norm is below the threshold, the limiting process is nondegenerate,\nand the joint eigenvalue densities under the null and alternative hypotheses\nare mutually contiguous. Using the asymptotic theory of statistical\nexperiments, we obtain asymptotic power envelopes and derive the asymptotic\npower for various sphericity tests in the contiguity region. In particular, we\nshow that the asymptotic power of the Tracy-Widom-type tests is trivial (i.e.,\nequals the asymptotic size), whereas that of the eigenvalue-based likelihood\nratio test is strictly larger than the size, and close to the power envelope.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2013 13:27:39 GMT"}], "update_date": "2013-06-21", "authors_parsed": [["Onatski", "Alexei", ""], ["Moreira", "Marcelo J.", ""], ["Hallin", "Marc", ""]]}, {"id": "1306.4872", "submitter": "Holger Dette", "authors": "Holger Dette, Kirsten Schorning", "title": "Complete classes of designs for nonlinear regression models and\n  principal representations of moment spaces", "comments": "Published in at http://dx.doi.org/10.1214/13-AOS1108 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2013, Vol. 41, No. 3, 1260-1267", "doi": "10.1214/13-AOS1108", "report-no": "IMS-AOS-AOS1108", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a recent paper Yang and Stufken [Ann. Statist. 40 (2012a) 1665-1685] gave\nsufficient conditions for complete classes of designs for nonlinear regression\nmodels. In this note we demonstrate that there is an alternative way to\nvalidate this result. Our main argument utilizes the fact that boundary points\nof moment spaces generated by Chebyshev systems possess unique representations.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2013 13:33:37 GMT"}], "update_date": "2013-06-21", "authors_parsed": [["Dette", "Holger", ""], ["Schorning", "Kirsten", ""]]}, {"id": "1306.4943", "submitter": "Gordon Belot", "authors": "Gordon Belot", "title": "Failure of Calibration is Typical", "comments": "Forthcoming in Statistics and Probability Letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Schervish (1985b) showed that every forecasting system is noncalibrated for\nuncountably many data sequences that it might see. This result is strengthened\nhere: from a topological point of view, failure of calibration is typical and\ncalibration rare. Meanwhile, Bayesian forecasters are certain that they are\ncalibrated---this invites worries about the connection between Bayesianism and\nrationality.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2013 17:45:09 GMT"}], "update_date": "2013-06-21", "authors_parsed": [["Belot", "Gordon", ""]]}, {"id": "1306.5006", "submitter": "Antonio Punzo", "authors": "Luca Bagnato and Lucio De Capitani and Antonio Punzo", "title": "Improving the autodependogram using the Kulback-Leibler divergence", "comments": "We have decided to withdraw the paper due to a crucial error in\n  equation (9), that is in the definition of the p-value. This invalidates the\n  results reported into the manuscript", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.AP stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The autodependogram is a graphical device recently proposed in the literature\nto analyze autodependencies. It is defined computing the classical Pearson\nchi-square statistics of independence at various lags in order to point out the\npresence lag-depedencies. This paper proposes an improvement of this diagram\nobtained by substituting the chi-square statistics with an estimator of the\nKulback-Leibler divergence between the bivariate density of two delayed\nvariables and the product of their marginal distributions. A simulation study,\non well-established time series models, shows that this new autodependogram is\nmore powerful than the previous one. An application to financial data is also\nshown.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2013 21:43:18 GMT"}, {"version": "v2", "created": "Wed, 26 Jun 2013 13:48:13 GMT"}, {"version": "v3", "created": "Wed, 28 Jan 2015 10:33:14 GMT"}], "update_date": "2015-01-29", "authors_parsed": [["Bagnato", "Luca", ""], ["De Capitani", "Lucio", ""], ["Punzo", "Antonio", ""]]}, {"id": "1306.5311", "submitter": "Michal Pe\\v{s}ta PhD", "authors": "Michal Pe\\v{s}ta", "title": "Asymptotics for weakly dependent errors-in-variables", "comments": "Submitted on April 11, 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear relations, containing measurement errors in input and output data, are\ntaken into account in this paper. Parameters of these so-called\nerrors-in-variables (EIV) models can be estimated by minimizing the total least\nsquares (TLS) of the input-output disturbances. Such an estimate is highly\nnon-linear. Moreover in some realistic situations, the errors cannot be\nconsidered as independent by nature. Weakly dependent (\\alpha- and \\phi-mixing)\ndisturbances, which are not necessarily stationary nor identically distributed,\nare considered in the EIV model. Asymptotic normality of the TLS estimate is\nproved under some reasonable stochastic assumptions on the errors. Derived\nasymptotic properties provide necessary basis for the validity of\nblock-bootstrap procedures.\n", "versions": [{"version": "v1", "created": "Sat, 22 Jun 2013 11:12:51 GMT"}], "update_date": "2013-06-25", "authors_parsed": [["Pe\u0161ta", "Michal", ""]]}, {"id": "1306.5353", "submitter": "James Ledoux", "authors": "Lo\\\"ic Herv\\'e (IRMAR), James Ledoux (IRMAR)", "title": "A local limit theorem for densities of the additive component of a\n  finite Markov Additive Process", "comments": "Additional material at arXiv:1305.5644 with some overlap", "journal-ref": "Statistics and Probability Letters 83, 9 (2013) 2119-2128", "doi": "10.1016/j.spl.2013.05.032", "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we are concerned with centered Markov Additive Processes\n$\\{(X_t,Y_t)\\}_{t\\in\\T}$ where the driving Markov process $\\{X_t\\}_{t\\in\\T}$\nhas a finite state space. Under suitable conditions, we provide a local limit\ntheorem for the density of the absolutely continuous part of the probability\ndistribution of $t^{-1/2}Y_t$ given $X_0$. The rate of convergence and the\nmoment condition are the expected ones with respect to the i.i.d case. An\napplication to the joint distribution of local times of a finite jump process\nis sketched.\n", "versions": [{"version": "v1", "created": "Sat, 22 Jun 2013 21:12:27 GMT"}], "update_date": "2013-06-25", "authors_parsed": [["Herv\u00e9", "Lo\u00efc", "", "IRMAR"], ["Ledoux", "James", "", "IRMAR"]]}, {"id": "1306.5392", "submitter": "Nikolai Leonenko", "authors": "A.V. Ivanov, N.N. Leonenko, M.D. Ruiz-Medina, and B.M. Zhurakovsky", "title": "Estimation of harmonic component in regression with cyclically dependent\n  errors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with the estimation of hidden periodicities in a non-linear\nregression model with stationary noise displaying cyclical dependence.\nConsistency and asymptotic normality are established for the least-squares\nestimates.\n", "versions": [{"version": "v1", "created": "Sun, 23 Jun 2013 10:54:52 GMT"}], "update_date": "2013-06-25", "authors_parsed": [["Ivanov", "A. V.", ""], ["Leonenko", "N. N.", ""], ["Ruiz-Medina", "M. D.", ""], ["Zhurakovsky", "B. M.", ""]]}, {"id": "1306.5393", "submitter": "Nicola Lunardon", "authors": "Nicola Lunardon and Elvezio Ronchetti", "title": "Composite Likelihood Inference by Nonparametric Saddlepoint Tests", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The class of composite likelihood functions provides a flexible and powerful\ntoolkit to carry out approximate inference for complex statistical models when\nthe full likelihood is either impossible to specify or unfeasible to compute.\nHowever, the strenght of the composite likelihood approach is dimmed when\nconsidering hypothesis testing about a multidimensional parameter because the\nfinite sample behavior of likelihood ratio, Wald, and score-type test\nstatistics is tied to the Godambe information matrix. Consequently inaccurate\nestimates of the Godambe information translate in inaccurate p-values. In this\npaper it is shown how accurate inference can be obtained by using a fully\nnonparametric saddlepoint test statistic derived from the composite score\nfunctions. The proposed statistic is asymptotically chi-square distributed up\nto a relative error of second order and does not depend on the Godambe\ninformation. The validity of the method is demonstrated through simulation\nstudies.\n", "versions": [{"version": "v1", "created": "Sun, 23 Jun 2013 11:31:13 GMT"}], "update_date": "2013-06-25", "authors_parsed": [["Lunardon", "Nicola", ""], ["Ronchetti", "Elvezio", ""]]}, {"id": "1306.5461", "submitter": "Helmut Rieder F.", "authors": "Helmut Rieder", "title": "Connections between Semiparametrics and Robustness", "comments": "60 pages, including 10 figures; talk presented at Tsinghua\n  University, Beijing, May 23 and 28, 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust and semiparametric statistics are of the same historical origin and\nlargely employ the same locally asymptotically normal framework. In our talk,\nwe consider he following more intrinsic connections of both fields:\n  1) Robust influence curves for semiparametric models with infinite\ndimensional nuisance parameter; for example, for semiparametric regression\n(Cox), and mixture models (Neyman--Scott).\n  2) Adaptiveness in the sense of Stein's necessary condition of robust\nneighborhood models and estimators with respect to a finite dimensional\nnuisance parameter; for example, location, linear regression, and ARMA.\n  3) Semiparametric treatment of gross error deviations from an ideal model as\nan infinite dimensional nuisance parameter, by projection on balls; for\ntesting, an asymptotic version of the Huber--Strassen maximin result is thus\nobtained.\n  4) Uniform and nonuniform asymptotic normality of robust and adaptive\nestimators, respectively, in regression and time series models.\n  5) Fragility of optimal one-sided tests and confidence limits obtained for\nconvex tangent cones, by projection on cones, as opposed to stability of\ncorresponding procedures, even two-sided, for linear tangent spaces.\n  6) The unknown neighborhood radius as a nuisance parameter in robustness.\n  The investigation relies on asymptotic techniques and on numerical\nevaluations of robust estimates.\n  The construction under 1) of robust estimates which are adaptive, an\nappropriate LAM estimation bound for balls under 3), and the minimization of\nthe norm under 5) on a certain restricted set of differences of tangents from a\ncone are examples of challenging open problems.\n", "versions": [{"version": "v1", "created": "Sun, 23 Jun 2013 19:28:20 GMT"}], "update_date": "2013-06-25", "authors_parsed": [["Rieder", "Helmut", ""]]}, {"id": "1306.5505", "submitter": "Hanzhong Liu", "authors": "Hanzhong Liu and Bin Yu", "title": "Asymptotic Properties of Lasso+mLS and Lasso+Ridge in Sparse\n  High-dimensional Linear Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the asymptotic properties of Lasso+mLS and Lasso+Ridge under the\nsparse high-dimensional linear regression model: Lasso selecting predictors and\nthen modified Least Squares (mLS) or Ridge estimating their coefficients.\nFirst, we propose a valid inference procedure for parameter estimation based on\nparametric residual bootstrap after Lasso+mLS and Lasso+Ridge. Second, we\nderive the asymptotic unbiasedness of Lasso+mLS and Lasso+Ridge. More\nspecifically, we show that their biases decay at an exponential rate and they\ncan achieve the oracle convergence rate of $s/n$ (where $s$ is the number of\nnonzero regression coefficients and $n$ is the sample size) for mean squared\nerror (MSE). Third, we show that Lasso+mLS and Lasso+Ridge are asymptotically\nnormal. They have an oracle property in the sense that they can select the true\npredictors with probability converging to 1 and the estimates of nonzero\nparameters have the same asymptotic normal distribution that they would have if\nthe zero parameters were known in advance. In fact, our analysis is not limited\nto adopting Lasso in the selection stage, but is applicable to any other model\nselection criteria with exponentially decay rates of the probability of\nselecting wrong models.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2013 03:48:03 GMT"}, {"version": "v2", "created": "Tue, 25 Jun 2013 02:59:06 GMT"}, {"version": "v3", "created": "Sun, 12 Jan 2014 06:34:17 GMT"}], "update_date": "2014-01-14", "authors_parsed": [["Liu", "Hanzhong", ""], ["Yu", "Bin", ""]]}, {"id": "1306.5510", "submitter": "Nadia Saad", "authors": "Beno\\^it Collins, David McDonald and Nadia Saad", "title": "Compound Wishart Matrices and Noisy Covariance Matrices: Risk\n  Underestimation", "comments": "24 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM math.ST q-fin.PM stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we obtain a property of the expectation of the inverse of\ncompound Wishart matrices which results from their orthogonal invariance. Using\nthis property as well as results from random matrix theory (RMT), we derive the\nasymptotic effect of the noise induced by estimating the covariance matrix on\ncomputing the risk of the optimal portfolio. This in turn enables us to get an\nasymptotically unbiased estimator of the risk of the optimal portfolio not only\nfor the case of independent observations but also in the case of correlated\nobservations. This improvement provides a new approach to estimate the risk of\na portfolio based on covariance matrices estimated from exponentially weighted\nmoving averages of stock returns.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2013 04:50:04 GMT"}], "update_date": "2013-06-25", "authors_parsed": [["Collins", "Beno\u00eet", ""], ["McDonald", "David", ""], ["Saad", "Nadia", ""]]}, {"id": "1306.5603", "submitter": "Kevin McGoff", "authors": "Kevin McGoff, Sayan Mukherjee, Andrew Nobel, Natesh Pillai", "title": "Consistency of maximum likelihood estimation for some dynamical systems", "comments": "Published in at http://dx.doi.org/10.1214/14-AOS1259 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2015, Vol. 43, No. 1, 1-29", "doi": "10.1214/14-AOS1259", "report-no": "IMS-AOS-AOS1259", "categories": "math.ST math.DS stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the asymptotic consistency of maximum likelihood parameter\nestimation for dynamical systems observed with noise. Under suitable conditions\non the dynamical systems and the observations, we show that maximum likelihood\nparameter estimation is consistent. Our proof involves ideas from both\ninformation theory and dynamical systems. Furthermore, we show how some\nwell-studied properties of dynamical systems imply the general statistical\nproperties related to maximum likelihood estimation. Finally, we exhibit\nclassical families of dynamical systems for which maximum likelihood estimation\nis consistent. Examples include shifts of finite type with Gibbs measures and\nAxiom A attractors with SRB measures.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2013 12:57:37 GMT"}, {"version": "v2", "created": "Thu, 27 Nov 2014 11:32:29 GMT"}], "update_date": "2014-12-01", "authors_parsed": [["McGoff", "Kevin", ""], ["Mukherjee", "Sayan", ""], ["Nobel", "Andrew", ""], ["Pillai", "Natesh", ""]]}, {"id": "1306.5786", "submitter": "Alexander Volfovsky", "authors": "Alexander Volfovsky and Peter D. Hoff", "title": "Testing for nodal dependence in relational data matrices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relational data are often represented as a square matrix, the entries of\nwhich record the relationships between pairs of objects. Many statistical\nmethods for the analysis of such data assume some degree of similarity or\ndependence between objects in terms of the way they relate to each other.\nHowever, formal tests for such dependence have not been developed. We provide a\ntest for such dependence using the framework of the matrix normal model, a type\nof multivariate normal distribution parameterized in terms of row- and\ncolumn-specific covariance matrices. We develop a likelihood ratio test (LRT)\nfor row and column dependence based on the observation of a single relational\ndata matrix. We obtain a reference distribution for the LRT statistic, thereby\nproviding an exact test for the presence of row or column correlations in a\nsquare relational data matrix. Additionally, we provide extensions of the test\nto accommodate common features of such data, such as undefined diagonal\nentries, a non-zero mean, multiple observations, and deviations from normality.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2013 21:15:39 GMT"}], "update_date": "2013-06-26", "authors_parsed": [["Volfovsky", "Alexander", ""], ["Hoff", "Peter D.", ""]]}, {"id": "1306.5806", "submitter": "Lizhen Lin", "authors": "Rabi Bhattacharya and Lizhen Lin", "title": "Omnibus CLTs for Fr\\'echet means and nonparametric inference on\n  non-Euclidean spaces", "comments": "Proceedings of the American Mathematical Society (2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two central limit theorems for sample Fr\\'echet means are derived, both\nsignificant for nonparametric inference on non-Euclidean spaces. The first one,\nTheorem 2.2, encompasses and improves upon most earlier CLTs on Fr\\'echet means\nand broadens the scope of the methodology beyond manifolds to diverse new\nnon-Euclidean data including those on certain stratified spaces which are\nimportant in the study of phylogenetic trees. It does not require that the\nunderlying distribution $Q$ have a density, and applies to both intrinsic and\nextrinsic analysis. The second theorem, Theorem 3.3, focuses on intrinsic means\non Riemannian manifolds of dimensions $d>2$ and breaks new ground by providing\na broad CLT without any of the earlier restrictive support assumptions. It\nmakes the statistically reasonable assumption of a somewhat smooth density of\n$Q$. The excluded case of dimension $d=2$ proves to be an enigma, although the\nfirst theorem does provide a CLT in this case as well under a support\nrestriction. Theorem 3.3 immediately applies to spheres $S^d$, $d>2$, which are\nalso of considerable importance in applications to axial spaces and to\nlandmarks based image analysis, as these spaces are quotients of spheres under\na Lie group $\\mathcal G $ of isometries of $S^d$.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2013 23:25:01 GMT"}, {"version": "v2", "created": "Sat, 28 Feb 2015 22:12:17 GMT"}, {"version": "v3", "created": "Mon, 28 Mar 2016 01:39:53 GMT"}], "update_date": "2016-03-29", "authors_parsed": [["Bhattacharya", "Rabi", ""], ["Lin", "Lizhen", ""]]}, {"id": "1306.5824", "submitter": "Paul McNicholas", "authors": "Ryan P. Browne, Sanjeena Subedi and Paul McNicholas", "title": "Constrained Optimization for a Subset of the Gaussian Parsimonious\n  Clustering Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The expectation-maximization (EM) algorithm is an iterative method for\nfinding maximum likelihood estimates when data are incomplete or are treated as\nbeing incomplete. The EM algorithm and its variants are commonly used for\nparameter estimation in applications of mixture models for clustering and\nclassification. This despite the fact that even the Gaussian mixture model\nlikelihood surface contains many local maxima and is singularity riddled.\nPrevious work has focused on circumventing this problem by constraining the\nsmallest eigenvalue of the component covariance matrices. In this paper, we\nconsider constraining the smallest eigenvalue, the largest eigenvalue, and both\nthe smallest and largest within the family setting. Specifically, a subset of\nthe GPCM family is considered for model-based clustering, where we use a\nre-parameterized version of the famous eigenvalue decomposition of the\ncomponent covariance matrices. Our approach is illustrated using various\nexperiments with simulated and real data.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2013 01:27:09 GMT"}], "update_date": "2013-06-26", "authors_parsed": [["Browne", "Ryan P.", ""], ["Subedi", "Sanjeena", ""], ["McNicholas", "Paul", ""]]}, {"id": "1306.5883", "submitter": "Dave Zachariah", "authors": "Dave Zachariah, Petter Wirf\\\"alt, Magnus Jansson, Saikat Chatterjee", "title": "Line Spectrum Estimation with Probabilistic Priors", "comments": null, "journal-ref": "Signal Processing, Volume 93, Issue 11, November 2013, Pages\n  2969-2974", "doi": "10.1016/j.sigpro.2013.03.038", "report-no": null, "categories": "math.ST cs.IT math.IT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For line spectrum estimation, we derive the maximum a posteriori probability\nestimator where prior knowledge of frequencies is modeled probabilistically.\nSince the spectrum is periodic, an appropriate distribution is the circular von\nMises distribution that can parameterize the entire range of prior certainty of\nthe frequencies. An efficient alternating projections method is used to solve\nthe resulting optimization problem. The estimator is evaluated numerically and\ncompared with other estimators and the Cram\\'er-Rao bound.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2013 08:55:39 GMT"}], "update_date": "2013-06-26", "authors_parsed": [["Zachariah", "Dave", ""], ["Wirf\u00e4lt", "Petter", ""], ["Jansson", "Magnus", ""], ["Chatterjee", "Saikat", ""]]}, {"id": "1306.5899", "submitter": "Alexandra Carpentier", "authors": "Alexandra Carpentier", "title": "Honest and adaptive confidence sets in Lp", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of constructing honest and adaptive confidence sets\nin Lp-loss (with p>=1 and p < infinity) over sets of Sobolev-type classes, in\nthe setting of non-parametric Gaussian regression. The objective is to adapt\nthe diameter of the confidence sets with respect to the smoothness degree of\nthe underlying function, while ensuring that the true function lies in the\nconfidence interval with high probability.When p >=2, we identify two main\nregimes, (i) one where adaptation is possible without any restrictions on the\nmodel, and (ii) one where critical regions have to be removed. We also prove by\na matching lower bound that the size of the regions that we remove can not be\nchosen significantly smaller. These regimes are shown to depend in a\nqualitative way on the index p, and a continuous transition from p = 2 to p =\ninfinity is exhibited.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2013 09:40:58 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2013 11:05:31 GMT"}], "update_date": "2013-11-13", "authors_parsed": [["Carpentier", "Alexandra", ""]]}, {"id": "1306.6042", "submitter": "N. Raj Rao", "authors": "Raj Rao Nadakuditi", "title": "OptShrink: An algorithm for improved low-rank signal matrix denoising by\n  optimal, data-driven singular value shrinkage", "comments": "Published version. The algorithm can be downloaded from\n  http://www.eecs.umich.edu/~rajnrao/optshrink", "journal-ref": "IEEE Transactions on Information Theory, vol. 60, no. 6, pp. 1-17,\n  May 2014", "doi": "10.1109/TIT.2014.2311661", "report-no": null, "categories": "math.ST cs.IT math.IT stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The truncated singular value decomposition (SVD) of the measurement matrix is\nthe optimal solution to the_representation_ problem of how to best approximate\na noisy measurement matrix using a low-rank matrix. Here, we consider the\n(unobservable)_denoising_ problem of how to best approximate a low-rank signal\nmatrix buried in noise by optimal (re)weighting of the singular vectors of the\nmeasurement matrix. We exploit recent results from random matrix theory to\nexactly characterize the large matrix limit of the optimal weighting\ncoefficients and show that they can be computed directly from data for a large\nclass of noise models that includes the i.i.d. Gaussian noise case.\n  Our analysis brings into sharp focus the shrinkage-and-thresholding form of\nthe optimal weights, the non-convex nature of the associated shrinkage function\n(on the singular values) and explains why matrix regularization via singular\nvalue thresholding with convex penalty functions (such as the nuclear norm)\nwill always be suboptimal. We validate our theoretical predictions with\nnumerical simulations, develop an implementable algorithm (OptShrink) that\nrealizes the predicted performance gains and show how our methods can be used\nto improve estimation in the setting where the measured matrix has missing\nentries.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2013 17:39:48 GMT"}, {"version": "v2", "created": "Tue, 23 Jul 2013 00:34:14 GMT"}, {"version": "v3", "created": "Mon, 3 Feb 2014 17:04:45 GMT"}, {"version": "v4", "created": "Fri, 18 Apr 2014 14:58:17 GMT"}], "update_date": "2014-04-21", "authors_parsed": [["Nadakuditi", "Raj Rao", ""]]}, {"id": "1306.6179", "submitter": "Enno Mammen", "authors": "Enno Mammen, Ingrid Van Keilegom, Kyusang Yu", "title": "Expansion for moments of regression quantiles with application to\n  nonparametric testing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss nonparametric tests for parametric specifications of regression\nquantiles. The test is based on the comparison of parametric and nonparametric\nfits of these quantiles. The nonparametric fit is a Nadaraya-Watson quantile\nsmoothing estimator.\n  An asymptotic treatment of the test statistic requires the development of new\nmathematical arguments. An approach that makes only use of plugging in a\nBahadur expansion of the nonparametric estimator is not satisfactory. It\nrequires too strong conditions on the dimension and the choice of the\nbandwidth.\n  Our alternative mathematical approach requires the calculation of moments of\nNadaraya-Watson quantile regression estimators. This calculation is done by\napplication of higher order Edgeworth expansions.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2013 09:30:02 GMT"}, {"version": "v2", "created": "Wed, 2 Dec 2015 12:51:39 GMT"}, {"version": "v3", "created": "Fri, 14 Jul 2017 11:51:11 GMT"}], "update_date": "2017-07-17", "authors_parsed": [["Mammen", "Enno", ""], ["Van Keilegom", "Ingrid", ""], ["Yu", "Kyusang", ""]]}, {"id": "1306.6222", "submitter": "Vladim\\'ir Lacko", "authors": "V. Lacko", "title": "Ultimate efficiency of designs for processes of Ornstein-Uhlenbeck type", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  For a process governed by a linear Ito stochastic differential equation of\nthe form dX(t)=[a(t)+b(t)X(t)]dt + \\sigma(t)dW(t) we prove an existence of\noptimal sampling designs with strictly increasing sampling times. We derive an\nasymptotic Fisher information matrix, which we take as a reference in assessing\na quality of finite-point sampling designs. The results are extended to a\nbroader class of Ito stochastic differential equations satisfying a certain\ncondition. We give an example based on the Gompertz growth law refuting a\ngenerally accepted opinion that small-sample designs lead to a very high level\nof efficiency.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2013 12:28:58 GMT"}, {"version": "v2", "created": "Wed, 10 Jul 2013 10:56:18 GMT"}], "update_date": "2013-07-11", "authors_parsed": [["Lacko", "V.", ""]]}, {"id": "1306.6295", "submitter": "Yihong Wu", "authors": "Alexandr Andoni and Huy L. Nguyen and Yury Polyanskiy and Yihong Wu", "title": "Tight Lower Bound for Linear Sketches of Moments", "comments": "In Proceedings of the 40th International Colloquium on Automata,\n  Languages and Programming (ICALP), Riga, Latvia, July 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of estimating frequency moments of a data stream has attracted a\nlot of attention since the onset of streaming algorithms [AMS99]. While the\nspace complexity for approximately computing the $p^{\\rm th}$ moment, for\n$p\\in(0,2]$ has been settled [KNW10], for $p>2$ the exact complexity remains\nopen. For $p>2$ the current best algorithm uses $O(n^{1-2/p}\\log n)$ words of\nspace [AKO11,BO10], whereas the lower bound is of $\\Omega(n^{1-2/p})$ [BJKS04].\n  In this paper, we show a tight lower bound of $\\Omega(n^{1-2/p}\\log n)$ words\nfor the class of algorithms based on linear sketches, which store only a sketch\n$Ax$ of input vector $x$ and some (possibly randomized) matrix $A$. We note\nthat all known algorithms for this problem are linear sketches.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2013 17:19:54 GMT"}], "update_date": "2013-06-27", "authors_parsed": [["Andoni", "Alexandr", ""], ["Nguyen", "Huy L.", ""], ["Polyanskiy", "Yury", ""], ["Wu", "Yihong", ""]]}, {"id": "1306.6430", "submitter": "Pier Giovanni Bissiri Dott.", "authors": "Pier Giovanni Bissiri, Chris Holmes, Stephen Walker", "title": "A General Framework for Updating Belief Distributions", "comments": "This is the pre-peer reviewed version of the article \"A General\n  Framework for Updating Belief Distributions\", which has been accepted for\n  publication in the Journal of Statistical Society - Series B. This article\n  may be used for non-commercial purposes in accordance with Wiley Terms and\n  Conditions for Self-Archiving", "journal-ref": null, "doi": "10.1111/rssb.12158", "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a framework for general Bayesian inference. We argue that a valid\nupdate of a prior belief distribution to a posterior can be made for parameters\nwhich are connected to observations through a loss function rather than the\ntraditional likelihood function, which is recovered under the special case of\nusing self information loss. Modern application areas make it is increasingly\nchallenging for Bayesians to attempt to model the true data generating\nmechanism. Moreover, when the object of interest is low dimensional, such as a\nmean or median, it is cumbersome to have to achieve this via a complete model\nfor the whole data distribution. More importantly, there are settings where the\nparameter of interest does not directly index a family of density functions and\nthus the Bayesian approach to learning about such parameters is currently\nregarded as problematic. Our proposed framework uses loss-functions to connect\ninformation in the data to functionals of interest. The updating of beliefs\nthen follows from a decision theoretic approach involving cumulative loss\nfunctions. Importantly, the procedure coincides with Bayesian updating when a\ntrue likelihood is known, yet provides coherent subjective inference in much\nmore general settings. Connections to other inference frameworks are\nhighlighted.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2013 08:16:41 GMT"}, {"version": "v2", "created": "Thu, 28 Jan 2016 14:11:48 GMT"}], "update_date": "2016-02-29", "authors_parsed": [["Bissiri", "Pier Giovanni", ""], ["Holmes", "Chris", ""], ["Walker", "Stephen", ""]]}, {"id": "1306.6557", "submitter": "Mladen Kolar", "authors": "Mladen Kolar, Han Liu", "title": "Optimal Feature Selection in High-Dimensional Discriminant Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the high-dimensional discriminant analysis problem. For this\nproblem, different methods have been proposed and justified by establishing\nexact convergence rates for the classification risk, as well as the l2\nconvergence results to the discriminative rule. However, sharp theoretical\nanalysis for the variable selection performance of these procedures have not\nbeen established, even though model interpretation is of fundamental importance\nin scientific data analysis. This paper bridges the gap by providing sharp\nsufficient conditions for consistent variable selection using the sparse\ndiscriminant analysis (Mai et al., 2012). Through careful analysis, we\nestablish rates of convergence that are significantly faster than the best\nknown results and admit an optimal scaling of the sample size n, dimensionality\np, and sparsity level s in the high-dimensional setting. Sufficient conditions\nare complemented by the necessary information theoretic limits on the variable\nselection problem in the context of high-dimensional discriminant analysis.\nExploiting a numerical equivalence result, our method also establish the\noptimal results for the ROAD estimator (Fan et al., 2012) and the sparse\noptimal scaling estimator (Clemmensen et al., 2011). Furthermore, we analyze an\nexhaustive search procedure, whose performance serves as a benchmark, and show\nthat it is variable selection consistent under weaker conditions. Extensive\nsimulations demonstrating the sharpness of the bounds are also provided.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2013 16:05:30 GMT"}], "update_date": "2013-06-28", "authors_parsed": [["Kolar", "Mladen", ""], ["Liu", "Han", ""]]}, {"id": "1306.6566", "submitter": "Prathapasinghe Dharmawansa", "authors": "Prathapasinghe Dharmawansa", "title": "Three Problems Related to the Eigenvalues of Complex Non-central Wishart\n  Matrices with a Rank-1 Mean", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, D. Wang has devised a new contour integral based method to simplify\ncertain matrix integrals. Capitalizing on that approach, we derive a new\nexpression for the probability density function (p.d.f.) of the joint\neigenvalues of a complex non-central Wishart matrix with a rank-1 mean. The\nresulting functional form in turn enables us to use powerful classical\northogonal polynomial techniques in solving three problems related to the\nnon-central Wishart matrix. To be specific, for an $n\\times n$ complex\nnon-central Wishart matrix $\\mathbf{W}$ with $m$ degrees of freedom ($m\\geq n$)\nand a rank-1 mean, we derive a new expression for the cumulative distribution\nfunction (c.d.f.) of the minimum eigenvalue ($\\lambda_{\\min}$). The c.d.f. is\nexpressed as the determinant of a square matrix, the size of which depends only\non the difference $m-n$. This further facilitates the analysis of the\nmicroscopic limit for the minimum eigenvalue which takes the form of the\ndeterminant of a square matrix of size $m-n$ with the Bessel kernel. We also\ndevelop a moment generating function based approach to derive the p.d.f. of the\nrandom variable $\\frac{\\text{tr}(\\mathbf{W})}{\\lambda_{\\min}}$, where\n$\\text{tr}(\\cdot)$ denotes the trace of a square matrix. This random quantity\nis of great importance in the so-called smoothed analysis of Demmel condition\nnumber. Finally, we find the average of the reciprocal of the characteristic\npolynomial $\\det[z\\mathbf{I}_n+\\mathbf{W}],\\; |\\arg z|<\\pi$, where\n$\\mathbf{I}_n$ and $\\det[\\cdot]$ denote the identity matrix of size $n$ and the\ndeterminant, respectively.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2013 16:38:22 GMT"}], "update_date": "2013-06-28", "authors_parsed": [["Dharmawansa", "Prathapasinghe", ""]]}, {"id": "1306.6770", "submitter": "Wanyang Dai", "authors": "Wanyang Dai", "title": "Numerical Methods and Analysis via Random Field Based Malliavin Calculus\n  for Backward Stochastic PDEs", "comments": "39 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.DS math.NA math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the adapted solution, numerical methods, and related convergence\nanalysis for a unified backward stochastic partial differential equation\n(B-SPDE). The equation is vector-valued, whose drift and diffusion coefficients\nmay involve nonlinear and high-order partial differential operators. Under\ncertain generalized Lipschitz and linear growth conditions, the existence and\nuniqueness of adapted solution to the B-SPDE are justified. The methods are\nbased on completely discrete schemes in terms of both time and space. The\nanalysis concerning error estimation or rate of convergence of the methods is\nconducted. The key of the analysis is to develop new theory for random field\nbased Malliavin calculus to prove the existence and uniqueness of adapted\nsolutions to the first-order and second-order Malliavin derivative based\nB-SPDEs under random environments.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2013 09:47:38 GMT"}], "update_date": "2013-07-01", "authors_parsed": [["Dai", "Wanyang", ""]]}]