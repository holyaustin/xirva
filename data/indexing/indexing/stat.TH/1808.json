[{"id": "1808.00131", "submitter": "Xingwei Hu Dr", "authors": "Xingwei Hu", "title": "A Theory of Dichotomous Valuation with Applications to Variable\n  Selection", "comments": "74 pages, 3 figures, 3 tables, 4 algorithms, 12 theorems, and 14\n  proofs", "journal-ref": "Econometric Reviews, 2020", "doi": "10.1080/07474938.2020.1735750", "report-no": null, "categories": "stat.ML cs.LG econ.EM math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An econometric or statistical model may undergo a marginal gain if we admit a\nnew variable to the model, and a marginal loss if we remove an existing\nvariable from the model. Assuming equality of opportunity among all candidate\nvariables, we derive a valuation framework by the expected marginal gain and\nmarginal loss in all potential modeling scenarios. However, marginal gain and\nloss are not symmetric; thus, we introduce three unbiased solutions. When used\nin variable selection, our new approaches significantly outperform several\npopular methods used in practice. The results also explore some novel traits of\nthe Shapley value.\n", "versions": [{"version": "v1", "created": "Wed, 1 Aug 2018 01:30:22 GMT"}, {"version": "v2", "created": "Mon, 10 Dec 2018 20:42:09 GMT"}, {"version": "v3", "created": "Tue, 15 Jan 2019 19:07:46 GMT"}, {"version": "v4", "created": "Fri, 14 Feb 2020 14:35:59 GMT"}, {"version": "v5", "created": "Fri, 13 Mar 2020 13:25:34 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Hu", "Xingwei", ""]]}, {"id": "1808.00242", "submitter": "Dennis Dobler", "authors": "Dennis Dobler and Markus Pauly and Thomas H. Scheike", "title": "Wild Bootstrap based Confidence Bands for Multiplicative Hazards Models", "comments": "15 pages, 1 figure, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose new resampling-based approaches to construct asymptotically valid\ntime simultaneous confidence bands for cumulative hazard functions in\nmulti-state Cox models. In particular, we exemplify the methodology in detail\nfor the simple Cox model with time dependent covariates, where the data may be\nsubject to independent right-censoring or left-truncation. In extensive\nsimulations we investigate their finite sample behaviour. Finally, the methods\nare utilized to analyze an empirical example.\n", "versions": [{"version": "v1", "created": "Wed, 1 Aug 2018 09:34:29 GMT"}], "update_date": "2018-08-02", "authors_parsed": [["Dobler", "Dennis", ""], ["Pauly", "Markus", ""], ["Scheike", "Thomas H.", ""]]}, {"id": "1808.00387", "submitter": "Tengyuan Liang", "authors": "Tengyuan Liang, Alexander Rakhlin", "title": "Just Interpolate: Kernel \"Ridgeless\" Regression Can Generalize", "comments": "28 pages, 8 figures", "journal-ref": "The Annals of Statistics 48 (2020) 1329-1347", "doi": "10.1214/19-AOS1849", "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the absence of explicit regularization, Kernel \"Ridgeless\" Regression with\nnonlinear kernels has the potential to fit the training data perfectly. It has\nbeen observed empirically, however, that such interpolated solutions can still\ngeneralize well on test data. We isolate a phenomenon of implicit\nregularization for minimum-norm interpolated solutions which is due to a\ncombination of high dimensionality of the input data, curvature of the kernel\nfunction, and favorable geometric properties of the data such as an eigenvalue\ndecay of the empirical covariance and kernel matrices. In addition to deriving\na data-dependent upper bound on the out-of-sample error, we present\nexperimental evidence suggesting that the phenomenon occurs in the MNIST\ndataset.\n", "versions": [{"version": "v1", "created": "Wed, 1 Aug 2018 15:50:23 GMT"}, {"version": "v2", "created": "Fri, 8 Feb 2019 03:53:50 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Liang", "Tengyuan", ""], ["Rakhlin", "Alexander", ""]]}, {"id": "1808.00631", "submitter": "Andrew Ying", "authors": "Shiyun Chen, Andrew Ying, Ery Arias-Castro", "title": "A Scan Procedure for Multiple Testing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a multiple testing framework, we propose a method that identifies the\ninterval with the highest estimated false discovery rate of P-values and\nrejects the corresponding null hypotheses. Unlike the Benjamini-Hochberg\nmethod, which does the same but over intervals with an endpoint at the origin,\nthe new procedure `scans' all intervals. In parallel with\n\\citep*{storey2004strong}, we show that this scan procedure provides strong\ncontrol of asymptotic false discovery rate. In addition, we investigate its\nasymptotic false non-discovery rate, deriving conditions under which it\noutperforms the Benjamini-Hochberg procedure. For example, the scan procedure\nis superior in power-law location models.\n", "versions": [{"version": "v1", "created": "Thu, 2 Aug 2018 01:59:40 GMT"}], "update_date": "2018-08-03", "authors_parsed": [["Chen", "Shiyun", ""], ["Ying", "Andrew", ""], ["Arias-Castro", "Ery", ""]]}, {"id": "1808.00728", "submitter": "Ying Zhang", "authors": "Sotirios Sabanis, Ying Zhang", "title": "Higher Order Langevin Monte Carlo Algorithm", "comments": "47 pages", "journal-ref": null, "doi": "10.1214/19-EJS1615", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new (unadjusted) Langevin Monte Carlo (LMC) algorithm with improved rates\nin total variation and in Wasserstein distance is presented. All these are\nobtained in the context of sampling from a target distribution $\\pi$ that has a\ndensity $\\hat{\\pi}$ on $\\mathbb{R}^d$ known up to a normalizing constant.\nMoreover, $-\\log \\hat{\\pi}$ is assumed to have a locally Lipschitz gradient and\nits third derivative is locally H\\\"{o}lder continuous with exponent $\\beta \\in\n(0,1]$. Non-asymptotic bounds are obtained for the convergence to stationarity\nof the new sampling method with convergence rate $1+ \\beta/2$ in Wasserstein\ndistance, while it is shown that the rate is 1 in total variation even in the\nabsence of convexity. Finally, in the case where $-\\log \\hat{\\pi}$ is strongly\nconvex and its gradient is Lipschitz continuous, explicit constants are\nprovided.\n", "versions": [{"version": "v1", "created": "Thu, 2 Aug 2018 09:37:34 GMT"}, {"version": "v2", "created": "Mon, 5 Nov 2018 19:39:04 GMT"}, {"version": "v3", "created": "Wed, 25 Sep 2019 16:18:10 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Sabanis", "Sotirios", ""], ["Zhang", "Ying", ""]]}, {"id": "1808.00731", "submitter": "Samuel Rosa", "authors": "Radoslav Harman, Samuel Rosa", "title": "Removal of the points that do not support an E-optimal experimental\n  design", "comments": "11 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method of removal of design points that cannot support any\nE-optimal experimental design of a linear regression model with uncorrelated\nobservations. The proposed method can be used to reduce the size of some large\nE-optimal design problems such that they can be efficiently solved by\nsemidefinite programming. This paper complements the results of Pronzato\n[Pronzato, L., 2013. A delimitation of the support of optimal designs for\nKiefer's $\\phi_p$-class of criteria. Statistics & Probability Letters 83,\n2721--2728], who studied the same problem for analytically simpler criteria of\ndesign optimality.\n", "versions": [{"version": "v1", "created": "Thu, 2 Aug 2018 09:44:06 GMT"}], "update_date": "2018-08-03", "authors_parsed": [["Harman", "Radoslav", ""], ["Rosa", "Samuel", ""]]}, {"id": "1808.00789", "submitter": "Tobias Siems", "authors": "Tobias Siems, Lisa Koeppel", "title": "A note on the Metropolis-Hastings acceptance probabilities for mixture\n  spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work is driven by the ubiquitous dissent over the abilities and\ncontributions of the Metropolis-Hastings and reversible jump algorithm within\nthe context of trans dimensional sampling. We demystify this topic by taking a\ndeeper look into the implementation of Metropolis-Hastings acceptance\nprobabilities with regard to general mixture spaces. Whilst unspectacular from\na theoretical point of view, mixture spaces gave rise to challenging demands\nconcerning their effective exploration. An often applied but not extensively\nstudied tool for transitioning between distinct spaces are so-called\ntranslation functions. We give an enlightening treatment of this topic that\nyields a generalization of the reversible jump algorithm and unveils another\npromising translation technique. Furthermore, by reconsidering the well-known\nMetropolis within Gibbs paradigm, we come across a dual strategy to develop\nMetropolis-Hastings samplers. We underpin our findings and compare the\nperformance of our approaches by means of a change point example. Thereafter,\nin a more theoretical context, we revitalize the somewhat forgotten concept of\nmaximal acceptance probabilities. This allows for an interesting classification\nof Metropolis-Hastings algorithms and gives further advice on their usage. A\nreview of some errors in reasoning that have led to the aforementioned dissent\nconcludes this paper.\n", "versions": [{"version": "v1", "created": "Thu, 2 Aug 2018 12:57:53 GMT"}, {"version": "v2", "created": "Sun, 28 Jul 2019 17:25:00 GMT"}, {"version": "v3", "created": "Fri, 2 Aug 2019 16:26:12 GMT"}], "update_date": "2019-08-05", "authors_parsed": [["Siems", "Tobias", ""], ["Koeppel", "Lisa", ""]]}, {"id": "1808.00791", "submitter": "Joni Virta", "authors": "Joni Virta, Niko Lietz\\'en, Pauliina Ilmonen, and Klaus Nordhausen", "title": "Fast tensorial JADE", "comments": "44 pages, 11 figures. Note: the title of the manuscript was earlier\n  \"Asymptotically and computationally efficient tensorial JADE\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a novel method for tensorial independent component\nanalysis. Our approach is based on TJADE and $ k $-JADE, two recently proposed\ngeneralizations of the classical JADE algorithm. Our novel method achieves the\nconsistency and the limiting distribution of TJADE under mild assumptions, and\nat the same time offers notable improvement in computational speed. Detailed\nmathematical proofs of the statistical properties of our method are given and,\nas a special case, a conjecture on the properties of $ k $-JADE is resolved.\nSimulations and timing comparisons demonstrate remarkable gain in speed.\nMoreover, the desired efficiency is obtained approximately for finite samples.\nThe method is applied successfully to large-scale video data, for which neither\nTJADE nor $ k $-JADE is feasible. Finally, an experimental procedure is\nproposed to select the values of a set of tuning parameters.\n", "versions": [{"version": "v1", "created": "Thu, 2 Aug 2018 12:59:30 GMT"}, {"version": "v2", "created": "Fri, 17 Jan 2020 14:33:19 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Virta", "Joni", ""], ["Lietz\u00e9n", "Niko", ""], ["Ilmonen", "Pauliina", ""], ["Nordhausen", "Klaus", ""]]}, {"id": "1808.00921", "submitter": "Reza Gheissari", "authors": "Gerard Ben Arous, Reza Gheissari, Aukosh Jagannath", "title": "Algorithmic thresholds for tensor PCA", "comments": "34 pages. The manuscript has been updated to add a proof of what was\n  Conjecture 1 in the first version", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the algorithmic thresholds for principal component analysis of\nGaussian $k$-tensors with a planted rank-one spike, via Langevin dynamics and\ngradient descent. In order to efficiently recover the spike from natural\ninitializations, the signal to noise ratio must diverge in the dimension. Our\nproof shows that the mechanism for the success/failure of recovery is the\nstrength of the \"curvature\" of the spike on the maximum entropy region of the\ninitial data. To demonstrate this, we study the dynamics on a generalized\nfamily of high-dimensional landscapes with planted signals, containing the\nspiked tensor models as specific instances. We identify thresholds of\nsignal-to-noise ratios above which order 1 time recovery succeeds; in the case\nof the spiked tensor model these match the thresholds conjectured for\nalgorithms such as Approximate Message Passing. Below these thresholds, where\nthe curvature of the signal on the maximal entropy region is weak, we show that\nrecovery from certain natural initializations takes at least stretched\nexponential time. Our approach combines global regularity estimates for spin\nglasses with point-wise estimates, to study the recovery problem by a\nperturbative approach.\n", "versions": [{"version": "v1", "created": "Thu, 2 Aug 2018 17:12:21 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 23:08:19 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Arous", "Gerard Ben", ""], ["Gheissari", "Reza", ""], ["Jagannath", "Aukosh", ""]]}, {"id": "1808.01072", "submitter": "Christopher Ferrie", "authors": "Christopher Ferrie and Robin Blume-Kohout", "title": "Maximum likelihood quantum state tomography is inadmissible", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maximum likelihood estimation (MLE) is the most common approach to quantum\nstate tomography. In this letter, we investigate whether it is also optimal in\nany sense. We show that MLE is an inadmissible estimator for most of the\ncommonly used metrics of accuracy, i.e., some other estimator is more accurate\nfor every true state. MLE is inadmissible for fidelity, mean squared error\n(squared Hilbert-Schmidt distance), and relative entropy. We prove that almost\nany estimator that can report both pure states and mixed states is\ninadmissible. This includes MLE, compressed sensing (nuclear-norm regularized)\nestimators, and constrained least squares. We provide simple examples to\nillustrate why reporting pure states is suboptimal even when the true state is\nitself pure, and why \"hedging\" away from pure states generically improves\nperformance.\n", "versions": [{"version": "v1", "created": "Fri, 3 Aug 2018 02:45:40 GMT"}], "update_date": "2018-08-06", "authors_parsed": [["Ferrie", "Christopher", ""], ["Blume-Kohout", "Robin", ""]]}, {"id": "1808.01274", "submitter": "Yunyi Zhang", "authors": "Yunyi Zhang, Dimitris N. Politis, Jiazheng Liu, Zexin Pan", "title": "Monotone function estimator and its application", "comments": "21 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the model $Y_i=g(Z_i),\\ i=1,2,...,n$ with $Z_i$ being random\nvariables with known distribution and $g(x)$ being unknown strictly increasing\nfunction is proposed and almost sure convergence of estimator for $g(x)$ is\nproved for i.i.d and short range dependent data. Confidence intervals and bands\nare constructed for i.i.d data theoretically and confidence intervals are\nintroduced for short range dependent data through resampling. Besides, a test\nfor equivalence of $g(x)$ to the desired function is proposed. Finite sample\nanalysis and application of this model on an urban waste water treatment\nplant's data is demonstrated as well.\n", "versions": [{"version": "v1", "created": "Fri, 3 Aug 2018 17:52:30 GMT"}], "update_date": "2018-08-06", "authors_parsed": [["Zhang", "Yunyi", ""], ["Politis", "Dimitris N.", ""], ["Liu", "Jiazheng", ""], ["Pan", "Zexin", ""]]}, {"id": "1808.01393", "submitter": "Pranava Chaitanya Jayanti", "authors": "Pranava Chaitanya Jayanti, Konstantina Trivisa", "title": "Bounded Statistics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  If two probability density functions (PDFs) have values for their first $n$\nmoments which are quite close to each other (upper bounds of their differences\nare known), can it be expected that the PDFs themselves are very similar? Shown\nbelow is an algorithm to quantitatively estimate this \"similarity\" between the\ngiven PDFs, depending on how many moments one has information about. This\nmethod involves the concept of functions behaving \"similarly\" at certain\n\"length scales\", which is also precisely defined. This technique could find use\nin data analysis, to compare a data set with a PDF or another data set, without\nhaving to fit a functional form to the data.\n", "versions": [{"version": "v1", "created": "Sat, 4 Aug 2018 00:15:34 GMT"}, {"version": "v2", "created": "Wed, 15 Aug 2018 00:20:58 GMT"}], "update_date": "2018-08-16", "authors_parsed": [["Jayanti", "Pranava Chaitanya", ""], ["Trivisa", "Konstantina", ""]]}, {"id": "1808.01398", "submitter": "Max Farrell", "authors": "Sebastian Calonico, Matias D. Cattaneo, Max H. Farrell", "title": "Coverage Error Optimal Confidence Intervals for Local Polynomial\n  Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies higher-order inference properties of nonparametric local\npolynomial regression methods under random sampling. We prove Edgeworth\nexpansions for $t$ statistics and coverage error expansions for interval\nestimators that (i) hold uniformly in the data generating process, (ii) allow\nfor the uniform kernel, and (iii) cover estimation of derivatives of the\nregression function. The terms of the higher-order expansions, and their\nassociated rates as a function of the sample size and bandwidth sequence,\ndepend on the smoothness of the population regression function, the smoothness\nexploited by the inference procedure, and on whether the evaluation point is in\nthe interior or on the boundary of the support. We prove that robust bias\ncorrected confidence intervals have the fastest coverage error decay rates in\nall cases, and we use our results to deliver novel, inference-optimal bandwidth\nselectors. The main methodological results are implemented in companion\n\\textsf{R} and \\textsf{Stata} software packages.\n", "versions": [{"version": "v1", "created": "Sat, 4 Aug 2018 01:10:13 GMT"}, {"version": "v2", "created": "Thu, 21 Mar 2019 15:11:04 GMT"}, {"version": "v3", "created": "Thu, 28 May 2020 15:28:11 GMT"}, {"version": "v4", "created": "Fri, 23 Jul 2021 17:03:27 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Calonico", "Sebastian", ""], ["Cattaneo", "Matias D.", ""], ["Farrell", "Max H.", ""]]}, {"id": "1808.01544", "submitter": "Qiang Zhang", "authors": "Xueqin Wang, Qiang Zhang, Wenliang Pan, Xin Chen and Heping Zhang", "title": "Hierarchical Change-Point Detection for Multivariate Time Series via a\n  Ball Detection Function", "comments": "38 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequences of random objects arise from many real applications, including high\nthroughput omic data and functional imaging data. Those sequences are usually\ndependent, non-linear, or even Non-Euclidean, and an important problem is\nchange-point detection in such dependent sequences in Banach spaces or metric\nspaces. The problem usually requires the accurate inference for not only\nwhether changes might have occurred but also the locations of the changes when\nthey did occur. To this end, we first introduce a Ball detection function and\nshow that it reaches its maximum at the change-point if a sequence has only one\nchange point. Furthermore, we propose a consistent estimator of Ball detection\nfunction based on which we develop a hierarchical algorithm to detect all\npossible change points. We prove that the estimated change-point locations are\nconsistent. Our procedure can estimate the number of change-points and detect\ntheir locations without assuming any particular types of change-points as a\nchange can occur in a sequence in different ways. Extensive simulation studies\nand analyses of two interesting real datasets wind direction and Bitcoin price\ndemonstrate that our method has considerable advantages over existing\ncompetitors, especially when data are non-Euclidean or when there are\ndistributional changes in the variance.\n", "versions": [{"version": "v1", "created": "Sun, 5 Aug 2018 00:27:11 GMT"}, {"version": "v2", "created": "Wed, 26 Jun 2019 18:39:39 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Wang", "Xueqin", ""], ["Zhang", "Qiang", ""], ["Pan", "Wenliang", ""], ["Chen", "Xin", ""], ["Zhang", "Heping", ""]]}, {"id": "1808.01638", "submitter": "Henryk Gzyl", "authors": "Henryk Gzyl", "title": "Prediction in Riemannian metrics derived from divergence functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Divergence functions are interesting discrepancy measures. Even though they\nare not true distances, we can use them to measure how separated two points\nare. Curiously enough, when they are applied to random variables, they lead to\na notion of best predictor that coincides with usual best predictor in\nEuclidean distance. Given a divergence function, we can derive from it a\nRiemannian metric, which leads to a distance in which means and best predictors\ndo not coincide with their Euclidean counterparts. It is the purpose of this\nnote to study the Riemannian metric derived from the divergence function as\nwell as its use in prediction theory.\n", "versions": [{"version": "v1", "created": "Sun, 5 Aug 2018 15:55:14 GMT"}, {"version": "v2", "created": "Wed, 19 Sep 2018 19:21:12 GMT"}], "update_date": "2018-09-21", "authors_parsed": [["Gzyl", "Henryk", ""]]}, {"id": "1808.01655", "submitter": "Maria D. Ruiz-Medina MDRM", "authors": "M. D. Ruiz-Medina, D. Miranda and R.M. Espejo", "title": "Dynamical multiple regression in function spaces, under kernel\n  regressors, with ARH(1) errors", "comments": "This paper has been submitted to TEST Journal, and now the reviewing\n  process status is on the submitted first revised version on June, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A linear multiple regression model in function spaces is formulated, under\ntemporal correlated errors. This formulation involves kernel regressors. A\ngeneralized least-squared regression parameter estimator is derived. Its\nasymptotic normality and strong consistency is obtained, under suitable\nconditions. The correlation analysis is based on a componentwise estimator of\nthe residual autocorrelation operator. When the dependence structure of the\nfunctional error term is unknown, a plug-in generalized least-squared\nregression parameter estimator is formulated. Its strong-consistency is proved\nas well. A simulation study is undertaken to illustrate the performance of the\npresented approach, under different regularity conditions. An application to\nfinancial panel data is also considered.\n", "versions": [{"version": "v1", "created": "Sun, 5 Aug 2018 17:29:53 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Ruiz-Medina", "M. D.", ""], ["Miranda", "D.", ""], ["Espejo", "R. M.", ""]]}, {"id": "1808.01659", "submitter": "Maria D. Ruiz-Medina MDRM", "authors": "MD Ruiz-Medina, J. Alvarez-Liebana", "title": "Strongly consistent autoregressive predictors in abstract Banach spaces", "comments": "This paper has been accepted in Journal of Multivariate Analysis, it\n  will appear in 2019. arXiv admin note: substantial text overlap with\n  arXiv:1801.08817", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work derives new results on strong consistent estimation and prediction\nfor autoregressive processes of order 1 in a separable Banach space B. The\nconsistency results are obtained for the component-wise estimator of the\nautocorrelation operator in the norm of the space L(B) of bounded linear\noperators on B. The strong consistency of the associated plug-in predictor then\nfollows in the B-norm. A Gelfand triple is defined through the Hilbert space\nconstructed in Kuelbs (1970)' lemma. A Hilbert--Schmidt embedding introduces\nthe Reproducing Kernel Hilbert space (RKHS), generated by the autocovariance\noperator, into the Hilbert space conforming the Rigged Hilbert space structure.\nThis paper extends the work of Bosq (2000) and Labbas and Mourid 2002.\n", "versions": [{"version": "v1", "created": "Sun, 5 Aug 2018 17:37:58 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Ruiz-Medina", "MD", ""], ["Alvarez-Liebana", "J.", ""]]}, {"id": "1808.01691", "submitter": "Zach Branson", "authors": "Zach Branson and Tirthankar Dasgupta", "title": "Sampling-based randomized designs for causal inference under the\n  potential outcomes framework", "comments": "30 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We establish the inferential properties of the mean-difference estimator for\nthe average treatment effect in randomized experiments where each unit in a\npopulation is randomized to one of two treatments and then units within\ntreatment groups are randomly sampled. The properties of this estimator are\nwell-understood in the experimental design scenario where first units are\nrandomly sampled and then treatment is randomly assigned, but not for the\naforementioned scenario where the sampling and treatment assignment stages are\nreversed. We find that the inferential properties of the mean-difference\nestimator under this experimental design scenario are identical to those under\nthe more common sample-first-randomize-second design. This finding will bring\nsome clarifications about sampling-based randomized designs for causal\ninference, particularly for settings where there is a finite super-population.\nFinally, we explore to what extent pre-treatment measurements can be used to\nimprove upon the mean-difference estimator for this\nrandomize-first-sample-second design. Unfortunately, we find that pre-treatment\nmeasurements are often unhelpful in improving the precision of average\ntreatment effect estimators under this design, unless a large number of\npre-treatment measurements that are highly associative with the post-treatment\nmeasurements can be obtained. We confirm these results using a simulation study\nbased on a real experiment in nanomaterials.\n", "versions": [{"version": "v1", "created": "Sun, 5 Aug 2018 22:10:25 GMT"}, {"version": "v2", "created": "Sat, 16 Feb 2019 19:27:18 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Branson", "Zach", ""], ["Dasgupta", "Tirthankar", ""]]}, {"id": "1808.01750", "submitter": "Lei Yu", "authors": "Lei Yu", "title": "Beyond the Central Limit Theorem: Universal and Non-universal\n  Simulations of Random Variables by General Mappings", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the Central Limit Theorem, in this paper, we study both\nuniversal and non-universal simulations of random variables with an arbitrary\ntarget distribution $Q_{Y}$ by general mappings, not limited to linear ones (as\nin the Central Limit Theorem). We derive the fastest convergence rate of the\napproximation errors for such problems. Interestingly, we show that for\ndiscontinuous or absolutely continuous $P_{X}$, the approximation error for the\nuniversal simulation is almost as small as that for the non-universal one; and\nmoreover, for both universal and non-universal simulations, the approximation\nerrors by general mappings are strictly smaller than those by linear mappings.\nFurthermore, we also generalize these results to simulation from Markov\nprocesses, and simulation of random elements (or general random variables).\n", "versions": [{"version": "v1", "created": "Mon, 6 Aug 2018 07:09:28 GMT"}, {"version": "v2", "created": "Tue, 4 Dec 2018 13:39:35 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["Yu", "Lei", ""]]}, {"id": "1808.01781", "submitter": "Efoevi Angelo Koudou", "authors": "Essomanda Konzou (IECL), Angelo Koudou (IECL)", "title": "About the Stein equation for the generalized inverse Gaussian and Kummer\n  distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a Stein characterization of the Kummer distribution on (0,\n$\\infty$). This result follows from our observation that the density of the\nKummer distribution satisfies a certain differential equation, leading to a\nsolution of the related Stein equation. A bound is derived for the solution,\nunder a condition on the parameters. The derivation of this bound is carried\nout using the same framework as in Gaunt 2017 [A Stein characterisation of the\ngeneralized hyper-bolic distribution. ESAIM: Probability and Statistics, 21,\n303--316] in the case of the generalized inverse Gaussian distribution, which\nwe revisit by correcting a minor error in the latter paper.\n", "versions": [{"version": "v1", "created": "Mon, 6 Aug 2018 08:50:42 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Konzou", "Essomanda", "", "IECL"], ["Koudou", "Angelo", "", "IECL"]]}, {"id": "1808.01857", "submitter": "Quentin Berthet", "authors": "Quentin Berthet, Varun Kanade", "title": "Statistical Windows in Testing for the Initial Distribution of a\n  Reversible Markov Chain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of hypothesis testing between two discrete\ndistributions, where we only have access to samples after the action of a known\nreversible Markov chain, playing the role of noise. We derive\ninstance-dependent minimax rates for the sample complexity of this problem, and\nshow how its dependence in time is related to the spectral properties of the\nMarkov chain. We show that there exists a wide statistical window, in terms of\nsample complexity for hypothesis testing between different pairs of initial\ndistributions. We illustrate these results in several concrete examples.\n", "versions": [{"version": "v1", "created": "Mon, 6 Aug 2018 12:54:04 GMT"}], "update_date": "2018-08-15", "authors_parsed": [["Berthet", "Quentin", ""], ["Kanade", "Varun", ""]]}, {"id": "1808.01905", "submitter": "Michal Pe\\v{s}ta PhD", "authors": "Michal Pe\\v{s}ta and Martin Wendler", "title": "Nuisance Parameters Free Changepoint Detection in Non-stationary Series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting abrupt changes in the mean of a time series, so-called\nchangepoints, is important for many applications. However, many procedures rely\non the estimation of nuisance parameters (like long-run variance). Under the\nalternative (a change in mean), estimators might be biased and data-adaptive\nrules for the choice of tuning parameters might not work as expected. If the\ndata is not stationary, but heteroscedastic, this becomes more challenging. The\naim of this paper is to present and investigate two changepoint tests, which\ninvolve neither nuisance nor tuning parameters. This is achieved by combing\nself-normalization and wild bootstrap. We study the asymptotic behavior and\nshow the consistency of the bootstrap under the hypothesis as well as under the\nalternative, assuming mild conditions on the weak dependence of the time series\nand allowing the variance to change over time. As a by-product of the proposed\ntests, a changepoint estimator is introduced and its consistency is proved. The\nresults are illustrated through a simulation study, which demonstrates\ncomputational efficiency of the developed methods. The new tests will also be\napplied to real data examples from finance and hydrology.\n", "versions": [{"version": "v1", "created": "Mon, 6 Aug 2018 13:48:03 GMT"}, {"version": "v2", "created": "Mon, 13 Aug 2018 16:55:30 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Pe\u0161ta", "Michal", ""], ["Wendler", "Martin", ""]]}, {"id": "1808.02174", "submitter": "Cl\\'ement Canonne", "authors": "Jayadev Acharya, Cl\\'ement L. Canonne, Cody Freitag, Himanshu Tyagi", "title": "Test without Trust: Optimal Locally Private Distribution Testing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR cs.DM cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of distribution testing when the samples can only be\naccessed using a locally differentially private mechanism and focus on two\nrepresentative testing questions of identity (goodness-of-fit) and independence\ntesting for discrete distributions. We are concerned with two settings: First,\nwhen we insist on using an already deployed, general-purpose locally\ndifferentially private mechanism such as the popular RAPPOR or the recently\nintroduced Hadamard Response for collecting data, and must build our tests\nbased on the data collected via this mechanism; and second, when no such\nrestriction is imposed, and we can design a bespoke mechanism specifically for\ntesting. For the latter purpose, we introduce the Randomized Aggregated Private\nTesting Optimal Response (RAPTOR) mechanism which is remarkably simple and\nrequires only one bit of communication per sample.\n  We propose tests based on these mechanisms and analyze their sample\ncomplexities. Each proposed test can be implemented efficiently. In each case\n(barring one), we complement our performance bounds for algorithms with\ninformation-theoretic lower bounds and establish sample optimality of our\nproposed algorithm. A peculiar feature that emerges is that our sample-optimal\nalgorithm based on RAPTOR uses public-coins, and any test based on RAPPOR or\nHadamard Response, which are both private-coin mechanisms, requires\nsignificantly more samples.\n", "versions": [{"version": "v1", "created": "Tue, 7 Aug 2018 01:18:57 GMT"}], "update_date": "2018-08-08", "authors_parsed": [["Acharya", "Jayadev", ""], ["Canonne", "Cl\u00e9ment L.", ""], ["Freitag", "Cody", ""], ["Tyagi", "Himanshu", ""]]}, {"id": "1808.02336", "submitter": "Nina Holden", "authors": "Nina Holden and Russell Lyons", "title": "Lower bounds for trace reconstruction", "comments": "Minor changes. 23 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.CC cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the trace reconstruction problem, an unknown bit string ${\\bf x}\\in\\{0,1\n\\}^n$ is sent through a deletion channel where each bit is deleted\nindependently with some probability $q\\in(0,1)$, yielding a contracted string\n$\\widetilde{\\bf x}$. How many i.i.d.\\ samples of $\\widetilde{\\bf x}$ are needed\nto reconstruct $\\bf x$ with high probability? We prove that there exist ${\\bf\nx},{\\bf y} \\in\\{0,1 \\}^n$ such that at least $c\\, n^{5/4}/\\sqrt{\\log n}$ traces\nare required to distinguish between ${\\bf x}$ and ${\\bf y}$ for some absolute\nconstant $c$, improving the previous lower bound of $c\\,n$. Furthermore, our\nresult improves the previously known lower bound for reconstruction of random\nstrings from $c \\log^2 n$ to $c \\log^{9/4}n/\\sqrt{\\log \\log n} $.\n", "versions": [{"version": "v1", "created": "Sat, 4 Aug 2018 05:45:19 GMT"}, {"version": "v2", "created": "Fri, 7 Jun 2019 14:35:48 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Holden", "Nina", ""], ["Lyons", "Russell", ""]]}, {"id": "1808.02361", "submitter": "Thanh Mai Pham Ngoc", "authors": "Thanh Mai Pham Ngoc", "title": "Adaptive optimal kernel density estimation for directional data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on the nonparametric density estimation problem with directional\ndata. We propose a new rule for bandwidth selection for kernel density\nestimation. Our procedure is automatic, fully data-driven and adaptive to the\nsmoothness degree of the density. We obtain an oracle inequality and optimal\nrates of convergence for the L2 error. Our theoretical results are illustrated\nwith simulations.\n", "versions": [{"version": "v1", "created": "Tue, 7 Aug 2018 13:43:01 GMT"}], "update_date": "2018-08-08", "authors_parsed": [["Ngoc", "Thanh Mai Pham", ""]]}, {"id": "1808.02439", "submitter": "Shankar Bhamidi", "authors": "Sayan Banerjee and Shankar Bhamidi and Iain Carmichael", "title": "Fluctuation bounds for continuous time branching processes and\n  nonparametric change point detection in growing networks", "comments": "55 pages 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by applications, both for modeling real world systems as well as in\nthe study of probabilistic systems such as recursive trees, the last few years\nhave seen an explosion in models for dynamically evolving networks. The aim of\nthis paper is two fold: (a) develop mathematical techniques based on continuous\ntime branching processes (CTBP) to derive quantitative error bounds for\nfunctionals of a major class of these models about their large network limits;\n(b) develop general theory to understand the role of abrupt changes in the\nevolution dynamics of these models using which one can develop non-parametric\nchange point detection estimators. In the context of the second aim, for fixed\nfinal network size $n$ and a change point $\\tau(n) < n$, we consider models of\ngrowing networks which evolve via new vertices attaching to the pre-existing\nnetwork according to one attachment function $f$ till the system grows to size\n$\\tau(n)$ when new vertices switch their behavior to a different function $g$\ntill the system reaches size $n$. With general non-explosivity assumptions on\nthe attachment functions $f,g$, we consider both the standard model where\n$\\tau(n) = \\Theta(n)$ as well as the \\emph{quick big bang model} when $\\tau(n)\n= n^\\gamma$ for some $0<\\gamma <1$. Proofs rely on a careful analysis of an\nassociated \\emph{inhomogeneous} continuous time branching process. Techniques\ndeveloped in the paper are robust enough to understand the behavior of these\nmodels for any sequence of change points $\\tau(n)\\to\\infty$. This paper derives\nrates of convergence for functionals such as the degree distribution; the same\nproof techniques should enable one to analyze more complicated functionals such\nas the associated fringe distributions.\n", "versions": [{"version": "v1", "created": "Tue, 7 Aug 2018 16:10:37 GMT"}], "update_date": "2018-08-08", "authors_parsed": [["Banerjee", "Sayan", ""], ["Bhamidi", "Shankar", ""], ["Carmichael", "Iain", ""]]}, {"id": "1808.02560", "submitter": "Fabio Cuzzolin", "authors": "Fabio Cuzzolin", "title": "Belief likelihood function for generalised logistic regression", "comments": "10 pages, 3 figures; submitted to UAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.AI stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The notion of belief likelihood function of repeated trials is introduced,\nwhenever the uncertainty for individual trials is encoded by a belief measure\n(a finite random set). This generalises the traditional likelihood function,\nand provides a natural setting for belief inference from statistical data.\nFactorisation results are proven for the case in which conjunctive or\ndisjunctive combination are employed, leading to analytical expressions for the\nlower and upper likelihoods of `sharp' samples in the case of Bernoulli trials,\nand to the formulation of a generalised logistic regression framework.\n", "versions": [{"version": "v1", "created": "Tue, 7 Aug 2018 21:43:32 GMT"}, {"version": "v2", "created": "Mon, 20 Aug 2018 10:12:21 GMT"}], "update_date": "2018-08-21", "authors_parsed": [["Cuzzolin", "Fabio", ""]]}, {"id": "1808.02648", "submitter": "Cheng Zhou", "authors": "Cheng Zhou, Xinsheng Zhang, Wenxin Zhou, Han Liu", "title": "A Unified Framework for Testing High Dimensional Parameters: A\n  Data-Adaptive Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High dimensional hypothesis test deals with models in which the number of\nparameters is significantly larger than the sample size. Existing literature\ndevelops a variety of individual tests. Some of them are sensitive to the dense\nand small disturbance, and others are sensitive to the sparse and large\ndisturbance. Hence, the powers of these tests depend on the assumption of the\nalternative scenario. This paper provides a unified framework for developing\nnew tests which are adaptive to a large variety of alternative scenarios in\nhigh dimensions. In particular, our framework includes arbitrary hypotheses\nwhich can be tested using high dimensional $U$-statistic based vectors. Under\nthis framework, we first develop a broad family of tests based on a novel\nvariant of the $L_p$-norm with $p\\in \\{1,\\dots,\\infty\\}$. We then combine these\ntests to construct a data-adaptive test that is simultaneously powerful under\nvarious alternative scenarios. To obtain the asymptotic distributions of these\ntests, we utilize the multiplier bootstrap for $U$-statistics. In addition, we\nconsider the computational aspect of the bootstrap method and propose a novel\nlow-cost scheme. We prove the optimality of the proposed tests. Thorough\nnumerical results on simulated and real datasets are provided to support our\ntheory.\n", "versions": [{"version": "v1", "created": "Wed, 8 Aug 2018 07:29:41 GMT"}], "update_date": "2018-08-09", "authors_parsed": [["Zhou", "Cheng", ""], ["Zhang", "Xinsheng", ""], ["Zhou", "Wenxin", ""], ["Liu", "Han", ""]]}, {"id": "1808.02721", "submitter": "Wojciech Rejchel", "authors": "B{\\l}a\\.zej Miasojedow, Wojciech Niemiro, Wojciech Rejchel", "title": "Asymptotics of maximum likelihood estimators based on Markov chain Monte\n  Carlo methods", "comments": "arXiv admin note: text overlap with arXiv:1412.6371", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many complex statistical models maximum likelihood estimators cannot be\ncalculated. In the paper we solve this problem using Markov chain Monte Carlo\napproximation of the true likelihood. In the main result we prove asymptotic\nnormality of the estimator, when both sample sizes (the initial and Monte Carlo\none) tend to infinity. Our result can be applied to models with intractable\nnorming constants and missing data models.\n", "versions": [{"version": "v1", "created": "Wed, 8 Aug 2018 10:56:46 GMT"}], "update_date": "2018-08-09", "authors_parsed": [["Miasojedow", "B\u0142a\u017cej", ""], ["Niemiro", "Wojciech", ""], ["Rejchel", "Wojciech", ""]]}, {"id": "1808.03106", "submitter": "Guillaume Lecu\\'e", "authors": "Guillaume Lecu\\'e and Matthieu Lerasle and Timoth\\'ee Mathieu", "title": "Robust classification via MOM minimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an extension of Vapnik's classical empirical risk minimizer (ERM)\nwhere the empirical risk is replaced by a median-of-means (MOM) estimator, the\nnew estimators are called MOM minimizers. While ERM is sensitive to corruption\nof the dataset for many classical loss functions used in classification, we\nshow that MOM minimizers behave well in theory, in the sense that it achieves\nVapnik's (slow) rates of convergence under weak assumptions: data are only\nrequired to have a finite second moment and some outliers may also have\ncorrupted the dataset.\n  We propose an algorithm inspired by MOM minimizers. These algorithms can be\nanalyzed using arguments quite similar to those used for Stochastic Block\nGradient descent. As a proof of concept, we show how to modify a proof of\nconsistency for a descent algorithm to prove consistency of its MOM version. As\nMOM algorithms perform a smart subsampling, our procedure can also help to\nreduce substantially time computations and memory ressources when applied to\nnon linear algorithms.\n  These empirical performances are illustrated on both simulated and real\ndatasets.\n", "versions": [{"version": "v1", "created": "Thu, 9 Aug 2018 12:00:41 GMT"}], "update_date": "2018-08-10", "authors_parsed": [["Lecu\u00e9", "Guillaume", ""], ["Lerasle", "Matthieu", ""], ["Mathieu", "Timoth\u00e9e", ""]]}, {"id": "1808.03218", "submitter": "Nicolas Garcia Trillos", "authors": "Nicolas Garcia Trillos, Ryan Murray, Daniel Sanz-Alonso", "title": "Spatial extreme values: variational techniques and stochastic integrals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work employs variational techniques to revisit and expand the\nconstruction and analysis of extreme value processes. These techniques permit a\nnovel study of spatial statistics of the location of minimizing events. We\ndevelop integral formulas for computing statistics of spatially-biased extremal\nevents, and show that they are analogous to stochastic integrals in the setting\nof standard stochastic processes. We also establish an asymptotic result in the\nspirit of the Fisher-Tippett-Gnedenko theory for a broader class of extremal\nevents and discuss some applications of our results.\n", "versions": [{"version": "v1", "created": "Thu, 9 Aug 2018 16:15:01 GMT"}], "update_date": "2018-08-10", "authors_parsed": [["Trillos", "Nicolas Garcia", ""], ["Murray", "Ryan", ""], ["Sanz-Alonso", "Daniel", ""]]}, {"id": "1808.03444", "submitter": "S\\'andor Baran", "authors": "Kinga Sikolya and S\\'andor Baran", "title": "On the optimal designs for the prediction of complex Ornstein-Uhlenbeck\n  processes", "comments": "14 pages, 2 figures, 1 table", "journal-ref": "Communications in Statistics - Theory and Methods 49 (2020), no.\n  20, 4859-4870", "doi": "10.1080/03610926.2019.1645855", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Physics, chemistry, biology or finance are just some examples out of the many\nfields where complex Ornstein-Uhlenbeck (OU) processes have various\napplications in statistical modelling. They play role e.g. in the description\nof the motion of a charged test particle in a constant magnetic field or in the\nstudy of rotating waves in time-dependent reaction diffusion systems, whereas\nKolmogorov used such a process to model the so-called Chandler wobble, the\nsmall deviation in the Earth's axis of rotation. A common problem in these\napplications is deciding how to choose a set of a sample locations in order to\npredict a random process in an optimal way. We study the optimal design problem\nfor the prediction of a complex OU process on a compact interval with respect\nto integrated mean square prediction error (IMSPE) and entropy criteria. We\nderive the exact forms of both criteria, moreover, we show that optimal designs\nbased on entropy criterion are equidistant, whereas the IMSPE based ones may\ndiffer from it. Finally, we present some numerical experiments to illustrate\nselected cases of optimal designs for small number of sampling locations.\n", "versions": [{"version": "v1", "created": "Fri, 10 Aug 2018 07:59:49 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Sikolya", "Kinga", ""], ["Baran", "S\u00e1ndor", ""]]}, {"id": "1808.03545", "submitter": "Jianfeng Yao", "authors": "Zeng Li and Clifford Lam and Jianfeng Yao and Qiwei Yao", "title": "On testing for high-dimensional white noise", "comments": "An earlier version of the paper has been circulated since 2016 and\n  submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Testing for white noise is a classical yet important problem in statistics,\nespecially for diagnostic checks in time series modeling and linear regression.\nFor high-dimensional time series in the sense that the dimension $p$ is large\nin relation to the sample size $T$, the popular omnibus tests including the\nmultivariate Hosking and Li-McLeod tests are extremely conservative, leading to\nsubstantial power loss. To develop more relevant tests for high-dimensional\ncases, we propose a portmanteau-type test statistic which is the sum of squared\nsingular values of the first $q$ lagged sample autocovariance matrices. It,\ntherefore, encapsulates all the serial correlations (upto the time lag $q$)\nwithin and across all component series. Using the tools from random matrix\ntheory and assuming both $p$ and $T$ diverge to infinity, we derive the\nasymptotic normality of the test statistic under both the null and a specific\nVMA(1) alternative hypothesis. As the actual implementation of the test\nrequires the knowledge of three characteristic constants of the population\ncross-sectional covariance matrix and the value of the fourth moment of the\nstandardized innovations, non trivial estimations are proposed for these\nparameters and their integration leads to a practically usable test. Extensive\nsimulation confirms the excellent finite-sample performance of the new test\nwith accurate size and satisfactory power for a large range of finite $(p,T)$\ncombinations, therefore ensuring wide applicability in practice. In particular,\nthe new tests are consistently superior to the traditional Hosking and\nLi-McLeod tests.\n", "versions": [{"version": "v1", "created": "Fri, 10 Aug 2018 13:52:54 GMT"}, {"version": "v2", "created": "Fri, 23 Nov 2018 09:59:35 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Li", "Zeng", ""], ["Lam", "Clifford", ""], ["Yao", "Jianfeng", ""], ["Yao", "Qiwei", ""]]}, {"id": "1808.03889", "submitter": "Ziwei Zhu", "authors": "Jianqing Fan, Kaizheng Wang, Yiqiao Zhong, Ziwei Zhu", "title": "Robust high dimensional factor models with applications to statistical\n  machine learning", "comments": "41 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Factor models are a class of powerful statistical models that have been\nwidely used to deal with dependent measurements that arise frequently from\nvarious applications from genomics and neuroscience to economics and finance.\nAs data are collected at an ever-growing scale, statistical machine learning\nfaces some new challenges: high dimensionality, strong dependence among\nobserved variables, heavy-tailed variables and heterogeneity. High-dimensional\nrobust factor analysis serves as a powerful toolkit to conquer these\nchallenges.\n  This paper gives a selective overview on recent advance on high-dimensional\nfactor models and their applications to statistics including Factor-Adjusted\nRobust Model selection (FarmSelect) and Factor-Adjusted Robust Multiple testing\n(FarmTest). We show that classical methods, especially principal component\nanalysis (PCA), can be tailored to many new problems and provide powerful tools\nfor statistical estimation and inference. We highlight PCA and its connections\nto matrix perturbation theory, robust statistics, random projection, false\ndiscovery rate, etc., and illustrate through several applications how insights\nfrom these fields yield solutions to modern challenges. We also present\nfar-reaching connections between factor models and popular statistical learning\nproblems, including network analysis and low-rank matrix recovery.\n", "versions": [{"version": "v1", "created": "Sun, 12 Aug 2018 04:34:24 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Fan", "Jianqing", ""], ["Wang", "Kaizheng", ""], ["Zhong", "Yiqiao", ""], ["Zhu", "Ziwei", ""]]}, {"id": "1808.03946", "submitter": "Andrew McCormack", "authors": "Andrew McCormack, Nancy Reid, Nicola Sartori and Sri-Amirthan\n  Theivendran", "title": "A New Look at $F$-Tests", "comments": "9 pages, 14 pages of supporting information", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Directional inference for vector parameters based on higher order\napproximations in likelihood inference has recently been developed in the\nliterature. Here we explore examples of directional inference where the\ncalculations can be simplified. It is found that in several classical\nsituations the directional test is equivalent to the usual $F$-test. These\nsituations include testing the ratio of group variances and rates from normal\nand exponential distributions, linear regression with a linear constraint and\nHotelling's $T^2$-test.\n", "versions": [{"version": "v1", "created": "Sun, 12 Aug 2018 14:03:46 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["McCormack", "Andrew", ""], ["Reid", "Nancy", ""], ["Sartori", "Nicola", ""], ["Theivendran", "Sri-Amirthan", ""]]}, {"id": "1808.03993", "submitter": "Maryna Prus", "authors": "Maryna Prus", "title": "Various Optimality Criteria for the Prediction of Individual Response\n  Curves", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider optimal designs for the Kiefer cirteria, which include the\nE-criterion as a particular case, and the G-criterion in random coefficients\nregression (RCR) models. We obtain general the Kiefer criteria for approximate\ndesigns and prove the equivalence of the E-criteria in the fixed effects and\nRCR models. We discuss in detail the G-criterion for ordinary linear regression\non specific design regions.\n", "versions": [{"version": "v1", "created": "Sun, 12 Aug 2018 19:34:30 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Prus", "Maryna", ""]]}, {"id": "1808.04092", "submitter": "Florian Heinrichs", "authors": "Axel B\\\"ucher, Holger Dette, Florian Heinrichs", "title": "Detecting deviations from second-order stationarity in locally\n  stationary functional time series", "comments": "Key words: alpha-mixing, CUSUM-test, auto-covariance operator, block\n  multiplier bootstrap, change points", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A time-domain test for the assumption of second order stationarity of a\nfunctional time series is proposed. The test is based on combining individual\ncumulative sum tests which are designed to be sensitive to changes in the mean,\nvariance and autocovariance operators, respectively. The combination of their\ndependent $p$-values relies on a joint dependent block multiplier bootstrap of\nthe individual test statistics. Conditions under which the proposed combined\ntesting procedure is asymptotically valid under stationarity are provided. A\nprocedure is proposed to automatically choose the block length parameter needed\nfor the construction of the bootstrap. The finite-sample behavior of the\nproposed test is investigated in Monte Carlo experiments and an illustration on\na real data set is provided.\n", "versions": [{"version": "v1", "created": "Mon, 13 Aug 2018 07:57:27 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["B\u00fccher", "Axel", ""], ["Dette", "Holger", ""], ["Heinrichs", "Florian", ""]]}, {"id": "1808.04098", "submitter": "Farzan Haddadi", "authors": "Farzan Haddadi and Arash Amini", "title": "Eigenvectors of Deformed Wigner Random Matrices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate eigenvectors of rank-one deformations of random matrices\n$\\boldsymbol B = \\boldsymbol A + \\theta \\boldsymbol {uu}^*$ in which\n$\\boldsymbol A \\in \\mathbb R^{N \\times N}$ is a Wigner real symmetric random\nmatrix, $\\theta \\in \\mathbb R^+$, and $\\boldsymbol u$ is uniformly distributed\non the unit sphere. It is well known that for $\\theta > 1$ the eigenvector\nassociated with the largest eigenvalue of $\\boldsymbol B$ closely estimates\n$\\boldsymbol u$ asymptotically, while for $\\theta < 1$ the eigenvectors of\n$\\boldsymbol B$ are uninformative about $\\boldsymbol u$. We examine $\\mathcal\nO(\\frac{1}{N})$ correlation of eigenvectors with $\\boldsymbol u$ before phase\ntransition and show that eigenvectors with larger eigenvalue exhibit stronger\nalignment with deforming vector through an explicit inverse law. This\ndistribution function will be shown to be the ordinary generating function of\nChebyshev polynomials of second kind. These polynomials form an orthogonal set\nwith respect to the semicircle weighting function. This law is an increasing\nfunction in the support of semicircle law for eigenvalues $(-2\\: ,+2)$.\nTherefore, most of energy of the unknown deforming vector is concentrated in a\n$cN$-dimensional ($c<1$) known subspace of $\\boldsymbol B$. We use a\ncombinatorial approach to prove the result.\n", "versions": [{"version": "v1", "created": "Mon, 13 Aug 2018 08:18:09 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Haddadi", "Farzan", ""], ["Amini", "Arash", ""]]}, {"id": "1808.04246", "submitter": "Kolyan Ray", "authors": "Kolyan Ray and Aad van der Vaart", "title": "Semiparametric Bayesian causal inference", "comments": "54 pages", "journal-ref": "Ann. Statist. 48 (2020), 2999-3020", "doi": "10.1214/19-AOS1919", "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a semiparametric Bayesian approach for estimating the mean\nresponse in a missing data model with binary outcomes and a nonparametrically\nmodelled propensity score. Equivalently we estimate the causal effect of a\ntreatment, correcting nonparametrically for confounding. We show that standard\nGaussian process priors satisfy a semiparametric Bernstein-von Mises theorem\nunder smoothness conditions. We further propose a novel propensity\nscore-dependent prior that provides efficient inference under strictly weaker\nconditions. We also show that it is theoretically preferable to model the\ncovariate distribution with a Dirichlet process or Bayesian bootstrap, rather\nthan modelling the covariate density using a Gaussian process prior.\n", "versions": [{"version": "v1", "created": "Mon, 13 Aug 2018 14:13:02 GMT"}, {"version": "v2", "created": "Thu, 10 Oct 2019 13:55:19 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Ray", "Kolyan", ""], ["van der Vaart", "Aad", ""]]}, {"id": "1808.04295", "submitter": "Zhiqin Xu", "authors": "Zhiqin John Xu", "title": "Understanding training and generalization in deep learning by Fourier\n  analysis", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: It is still an open research area to theoretically understand why\nDeep Neural Networks (DNNs)---equipped with many more parameters than training\ndata and trained by (stochastic) gradient-based methods---often achieve\nremarkably low generalization error. Contribution: We study DNN training by\nFourier analysis. Our theoretical framework explains: i) DNN with (stochastic)\ngradient-based methods often endows low-frequency components of the target\nfunction with a higher priority during the training; ii) Small initialization\nleads to good generalization ability of DNN while preserving the DNN's ability\nto fit any function. These results are further confirmed by experiments of DNNs\nfitting the following datasets, that is, natural images, one-dimensional\nfunctions and MNIST dataset.\n", "versions": [{"version": "v1", "created": "Mon, 13 Aug 2018 15:40:41 GMT"}, {"version": "v2", "created": "Tue, 21 Aug 2018 21:01:43 GMT"}, {"version": "v3", "created": "Tue, 18 Sep 2018 01:14:01 GMT"}, {"version": "v4", "created": "Thu, 29 Nov 2018 03:20:18 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Xu", "Zhiqin John", ""]]}, {"id": "1808.04513", "submitter": "Zach Branson", "authors": "Zach Branson and Stephane Shao", "title": "Ridge Rerandomization: An Experimental Design Strategy in the Presence\n  of Collinearity", "comments": "33 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Randomization ensures that observed and unobserved covariates are balanced,\non average. However, randomizing units to treatment and control often leads to\ncovariate imbalances in realization, and such imbalances can inflate the\nvariance of estimators of the treatment effect. One solution to this problem is\nrerandomization---an experimental design strategy that randomizes units until\nsome balance criterion is fulfilled---which yields more precise estimators of\nthe treatment effect if covariates are correlated with the outcome. Most\nrerandomization schemes in the literature utilize the Mahalanobis distance,\nwhich may not be preferable when covariates are correlated or vary in\nimportance. As an alternative, we introduce an experimental design strategy\ncalled ridge rerandomization, which utilizes a modified Mahalanobis distance\nthat addresses collinearities among covariates and automatically places a\nhierarchy of importance on the covariates according to their eigenstructure.\nThis modified Mahalanobis distance has connections to principal components and\nthe Euclidean distance, and---to our knowledge---has remained unexplored. We\nestablish several theoretical properties of this modified Mahalanobis distance\nand our ridge rerandomization scheme. These results guarantee that ridge\nrerandomization is preferable over randomization and suggest when ridge\nrerandomization is preferable over standard rerandomization schemes. We also\nprovide simulation evidence that suggests that ridge rerandomization is\nparticularly preferable over typical rerandomization schemes in\nhigh-dimensional or high-collinearity settings.\n", "versions": [{"version": "v1", "created": "Tue, 14 Aug 2018 03:21:15 GMT"}, {"version": "v2", "created": "Sun, 9 Feb 2020 21:12:49 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Branson", "Zach", ""], ["Shao", "Stephane", ""]]}, {"id": "1808.04523", "submitter": "Max Simchowitz", "authors": "Max Simchowitz and Kevin Jamieson and Jordan W. Suchow and Thomas L.\n  Griffiths", "title": "Adaptive Sampling for Convex Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce the first principled adaptive-sampling procedure\nfor learning a convex function in the $L_\\infty$ norm, a problem that arises\noften in the behavioral and social sciences. We present a function-specific\nmeasure of complexity and use it to prove that, for each convex function\n$f_{\\star}$, our algorithm nearly attains the information-theoretically\noptimal, function-specific error rate. We also corroborate our theoretical\ncontributions with numerical experiments, finding that our method substantially\noutperforms passive, uniform sampling for favorable synthetic and data-derived\nfunctions in low-noise settings with large sampling budgets. Our results also\nsuggest an idealized \"oracle strategy\", which we use to gauge the potential\nadvance of any adaptive-sampling strategy over passive sampling, for any given\nconvex function.\n", "versions": [{"version": "v1", "created": "Tue, 14 Aug 2018 05:01:55 GMT"}, {"version": "v2", "created": "Wed, 15 Aug 2018 06:05:40 GMT"}, {"version": "v3", "created": "Sun, 26 Aug 2018 22:45:16 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Simchowitz", "Max", ""], ["Jamieson", "Kevin", ""], ["Suchow", "Jordan W.", ""], ["Griffiths", "Thomas L.", ""]]}, {"id": "1808.04611", "submitter": "Rodwell Kufakunesu", "authors": "Lesedi Mabitsela, Calisto Guambe and Rodwell Kufakunesu", "title": "A note on representation of BSDE-based dynamic risk measures and dynamic\n  capital allocations", "comments": "17", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PM math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we provide a representation theorem for dynamic capital\nallocation under It{\\^o}-L{\\'e}vy model. We consider the representation of\ndynamic risk measures defined under Backward Stochastic Differential Equations\n(BSDE) with generators that grow quadratic-exponentially in the control\nvariables. Dynamic capital allocation is derived from the differentiability of\nBSDEs with jumps. The results are illustrated by deriving a capital allocation\nrepresentation for dynamic entropic risk measure and static coherent risk\nmeasure.\n", "versions": [{"version": "v1", "created": "Tue, 14 Aug 2018 10:16:46 GMT"}], "update_date": "2018-08-15", "authors_parsed": [["Mabitsela", "Lesedi", ""], ["Guambe", "Calisto", ""], ["Kufakunesu", "Rodwell", ""]]}, {"id": "1808.04753", "submitter": "Si Cheng", "authors": "Si Cheng (1), Daniel J. Eck (2), Forrest W. Crawford (3,4,5 and 6)\n  ((1) Department of Biostatistics, University of Washington, (2) Department of\n  Statistics, University of Illinois Urbana-Champaign, (3) Department of\n  Biostatistics, Yale School of Public Health, (4) Department of Statistics &\n  Data Science, Yale University, (5) Department of Ecology & Evolutionary\n  Biology, Yale University, (6) Yale School of Management)", "title": "Estimating the size of a hidden finite set: large-sample behavior of\n  estimators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A finite set is \"hidden\" if its elements are not directly enumerable or if\nits size cannot be ascertained via a deterministic query. In public health,\nepidemiology, demography, ecology and intelligence analysis, researchers have\ndeveloped a wide variety of indirect statistical approaches, under different\nmodels for sampling and observation, for estimating the size of a hidden set.\nSome methods make use of random sampling with known or estimable sampling\nprobabilities, and others make structural assumptions about relationships (e.g.\nordering or network information) between the elements that comprise the hidden\nset. In this review, we describe models and methods for learning about the size\nof a hidden finite set, with special attention to asymptotic properties of\nestimators. We study the properties of these methods under two asymptotic\nregimes, \"infill\" in which the number of fixed-size samples increases, but the\npopulation size remains constant, and \"outfill\" in which the sample size and\npopulation size grow together. Statistical properties under these two regimes\ncan be dramatically different.\n", "versions": [{"version": "v1", "created": "Tue, 14 Aug 2018 15:31:56 GMT"}, {"version": "v2", "created": "Tue, 15 Oct 2019 23:20:16 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Cheng", "Si", "", "3,4,5 and 6"], ["Eck", "Daniel J.", "", "3,4,5 and 6"], ["Crawford", "Forrest W.", "", "3,4,5 and 6"]]}, {"id": "1808.04855", "submitter": "Joshua Cape", "authors": "Joshua Cape and Minh Tang and Carey E. Priebe", "title": "On spectral embedding performance and elucidating network structure in\n  stochastic block model graphs", "comments": "38 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical inference on graphs often proceeds via spectral methods involving\nlow-dimensional embeddings of matrix-valued graph representations, such as the\ngraph Laplacian or adjacency matrix. In this paper, we analyze the asymptotic\ninformation-theoretic relative performance of Laplacian spectral embedding and\nadjacency spectral embedding for block assignment recovery in stochastic block\nmodel graphs by way of Chernoff information. We investigate the relationship\nbetween spectral embedding performance and underlying network structure\n(e.g.~homogeneity, affinity, core-periphery, (un)balancedness) via a\ncomprehensive treatment of the two-block stochastic block model and the class\nof $K$-block models exhibiting homogeneous balanced affinity structure. Our\nfindings support the claim that, for a particular notion of sparsity, loosely\nspeaking, \"Laplacian spectral embedding favors relatively sparse graphs,\nwhereas adjacency spectral embedding favors not-too-sparse graphs.\" We also\nprovide evidence in support of the claim that \"adjacency spectral embedding\nfavors core-periphery network structure.\"\n", "versions": [{"version": "v1", "created": "Tue, 14 Aug 2018 18:51:52 GMT"}], "update_date": "2018-08-16", "authors_parsed": [["Cape", "Joshua", ""], ["Tang", "Minh", ""], ["Priebe", "Carey E.", ""]]}, {"id": "1808.04872", "submitter": "Maria D. Ruiz-Medina", "authors": "M. D. Ruiz-Medina and J. Alvarez-Liebana", "title": "A note on strong-consistency of componentwise ARH(1) predictors", "comments": "Submitted to Statistics & Probability Letters in December, 2016 (now,\n  still in process after revision in April, 2018). arXiv admin note:\n  substantial text overlap with arXiv:1709.04938", "journal-ref": "Statistics & Probability Letters, 2018", "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  New results on strong-consistency, in the Hilbert-Schmidt and trace operator\nnorms, are obtained, in the parameter estimation of an autoregressive\nHilbertian process of order one (ARH(1) process). In particular, a\nstrongly-consistent diagonal componentwise estimator of the autocorrelation\noperator is derived, based on its empirical singular value decomposition.\n", "versions": [{"version": "v1", "created": "Wed, 15 Aug 2018 11:35:09 GMT"}, {"version": "v2", "created": "Mon, 10 Sep 2018 18:00:40 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Ruiz-Medina", "M. D.", ""], ["Alvarez-Liebana", "J.", ""]]}, {"id": "1808.04878", "submitter": "Ozan Candogan", "authors": "Baris Ata, Alexandre Belloni, Ozan Candogan", "title": "Latent Agents in Networks: Estimation and Pricing", "comments": "91 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CV econ.TH math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on a setting where agents in a social network consume a product that\nexhibits positive local network externalities. A seller has access to data on\npast consumption decisions/prices for a subset of observable agents, and can\ntarget these agents with appropriate discounts to exploit network effects and\nincrease her revenues. A novel feature of the model is that the observable\nagents potentially interact with additional latent agents. These latent agents\ncan purchase the same product from a different channel, and are not observed by\nthe seller. Observable agents influence each other both directly and indirectly\nthrough the influence they exert on the latent agents. The seller knows the\nconnection structure of neither the observable nor the latent part of the\nnetwork.\n  Due to the presence of network externalities, an agent's consumption decision\ndepends not only on the price offered to her, but also on the consumption\ndecisions of (and in turn the prices offered to) her neighbors in the\nunderlying network. We investigate how the seller can use the available data to\nestimate the matrix that captures the dependence of observable agents'\nconsumption decisions on the prices offered to them. We provide an algorithm\nfor estimating this matrix under an approximate sparsity condition, and obtain\nconvergence rates for the proposed estimator despite the high dimensionality\nthat allows more agents than observations. Importantly, we then show that this\napproximate sparsity condition holds under standard conditions present in the\nliterature and hence our algorithms are applicable to a large class of\nnetworks. We establish that by using the estimated matrix the seller can\nconstruct prices that lead to a small revenue loss relative to\nrevenue-maximizing prices under complete information, and the optimality gap\nvanishes relative to the size of the network.\n", "versions": [{"version": "v1", "created": "Tue, 14 Aug 2018 19:57:55 GMT"}, {"version": "v2", "created": "Wed, 12 Dec 2018 16:51:27 GMT"}], "update_date": "2018-12-13", "authors_parsed": [["Ata", "Baris", ""], ["Belloni", "Alexandre", ""], ["Candogan", "Ozan", ""]]}, {"id": "1808.04935", "submitter": "Gustavo Didier", "authors": "B. Cooper Boniece, Gustavo Didier and Farzad Sabzikar", "title": "Tempered fractional Brownian motion: wavelet estimation, modeling and\n  testing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Davenport spectrum is a modification of the classical Kolmogorov spectrum\nfor the inertial range of turbulence that accounts for non-scaling low\nfrequency behavior. Like the classical fractional Brownian motion vis-\\`a-vis\nthe Kolmogorov spectrum, tempered fractional Brownian motion (tfBm) is a\ncanonical model that displays the Davenport spectrum. The autocorrelation of\nthe increments of tfBm displays semi-long range dependence (hyperbolic and\nquasi-exponential decays over moderate and large scales, respectively), a\nphenomenon that has been observed in wide a range of applications from wind\nspeeds to geophysics to finance. In this paper, we use wavelets to construct\nthe first estimation method for tfBm and a simple and computationally efficient\ntest for fBm vs tfBm alternatives. The properties of the wavelet estimator and\ntest are mathematically and computationally established. An application of the\nmethodology to the analysis of geophysical flow data shows that tfBm provides a\nmuch closer fit than fBm.\n", "versions": [{"version": "v1", "created": "Wed, 15 Aug 2018 01:18:34 GMT"}], "update_date": "2018-08-16", "authors_parsed": [["Boniece", "B. Cooper", ""], ["Didier", "Gustavo", ""], ["Sabzikar", "Farzad", ""]]}, {"id": "1808.05076", "submitter": "Timothy Ferguson", "authors": "Jared Bronski and Timothy Ferguson", "title": "Motifs, Coherent Configurations and Second Order Network Generation", "comments": "26 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we illuminate some algebraic-combinatorial structure underlying\nthe second order networks (SONETS) random graph model of Nykamp, Zhao and\ncollaborators. In particular we show that this algorithm is deeply connected\nwith a certain homogeneous coherent configuration, a non-commuting\ngeneralization of the classical Johnson scheme. This algebraic structure\nunderlies certain surprising identities (that do not appear to have been\npreviously observed) satisfied by the covariance matrices in the Nykamp-Zhao\nscheme. We show that an understanding of this algebraic structure leads to\nsimplified numerical methods for carrying out the linear algebra required to\nimplement the SONETS algorithm. We also show that this structure extends\nnaturally to the problem of generating random subgraphs of graphs other than\nthe complete directed graph.\n", "versions": [{"version": "v1", "created": "Mon, 13 Aug 2018 18:23:07 GMT"}], "update_date": "2018-08-16", "authors_parsed": [["Bronski", "Jared", ""], ["Ferguson", "Timothy", ""]]}, {"id": "1808.05214", "submitter": "Lev B Klebanov", "authors": "Lev B. Klebanov and Irina V. Volchenkova", "title": "Characterization of multivariate distributions by means of univariate\n  one", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this paper is to show a possibility to identify multivariate\ndistribution by means of specially constructed one-dimensional random variable.\nWe give some inequalities which may appear to helpful for a construction of\nmultivariate two-sample tests.\n  Key words: inequalities; multivariate distributions; two-sample tests\n", "versions": [{"version": "v1", "created": "Wed, 15 Aug 2018 08:23:17 GMT"}], "update_date": "2018-08-17", "authors_parsed": [["Klebanov", "Lev B.", ""], ["Volchenkova", "Irina V.", ""]]}, {"id": "1808.05293", "submitter": "Susan Athey", "authors": "Susan Athey and Guido Imbens", "title": "Design-based Analysis in Difference-In-Differences Settings with\n  Staggered Adoption", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study estimation of and inference for average treatment\neffects in a setting with panel data. We focus on the setting where units,\ne.g., individuals, firms, or states, adopt the policy or treatment of interest\nat a particular point in time, and then remain exposed to this treatment at all\ntimes afterwards. We take a design perspective where we investigate the\nproperties of estimators and procedures given assumptions on the assignment\nprocess. We show that under random assignment of the adoption date the standard\nDifference-In-Differences estimator is is an unbiased estimator of a particular\nweighted average causal effect. We characterize the proeperties of this\nestimand, and show that the standard variance estimator is conservative.\n", "versions": [{"version": "v1", "created": "Wed, 15 Aug 2018 22:10:57 GMT"}, {"version": "v2", "created": "Thu, 30 Aug 2018 15:50:27 GMT"}, {"version": "v3", "created": "Sat, 1 Sep 2018 15:48:05 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Athey", "Susan", ""], ["Imbens", "Guido", ""]]}, {"id": "1808.05296", "submitter": "Merlin Mpoudeu", "authors": "Merlin Mpoudeu and Bertrand Clarke", "title": "Model Selection via the VC-Dimension", "comments": "62 pages and 16 figures, 14 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive an objective function that can be optimized to give an estimator of\nthe Vapnik- Chervonenkis dimension for model selection in regression problems.\nWe verify our estimator is consistent. Then, we verify it performs well\ncompared to seven other model selection techniques. We do this for a variety of\ntypes of data sets.\n", "versions": [{"version": "v1", "created": "Wed, 15 Aug 2018 22:23:26 GMT"}], "update_date": "2018-08-17", "authors_parsed": [["Mpoudeu", "Merlin", ""], ["Clarke", "Bertrand", ""]]}, {"id": "1808.05352", "submitter": "Benjamin Poignard", "authors": "Benjamin Poignard", "title": "Sparse Multivariate ARCH Models: Finite Sample Properties", "comments": "The concentration inequality contains a mistake", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide finite sample properties of sparse multivariate ARCH processes,\nwhere the linear representation of ARCH models allows for an ordinary least\nsquares estimation. Under the restricted strong convexity of the unpenalized\nloss function, regularity conditions on the penalty function, strict stationary\nand beta-mixing process, we prove non-asymptotic error bounds on the\nregularized ARCH estimator. Based on the primal-dual witness method of Loh and\nWainwright (2017), we establish variable selection consistency, including the\ncase when the penalty function is non-convex. These theoretical results are\nsupported by empirical studies.\n", "versions": [{"version": "v1", "created": "Thu, 16 Aug 2018 05:57:38 GMT"}, {"version": "v2", "created": "Thu, 21 Feb 2019 12:17:37 GMT"}], "update_date": "2019-02-22", "authors_parsed": [["Poignard", "Benjamin", ""]]}, {"id": "1808.05362", "submitter": "Dandan Jiang", "authors": "Dandan Jiang and Zhidong Bai", "title": "Generalized Four Moment Theorem and an Application to CLT for Spiked\n  Eigenvalues of Large-dimensional Covariance Matrices", "comments": "48 pages, 4 figures,5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a more generalized spiked covariance matrix $\\Sigma$, which is a\ngeneral non-definite matrix with the spiked eigenvalues scattered into a few\nbulks and the largest ones allowed to tend to infinity. By relaxing the\nmatching of the 4th moment to a tail probability decay, a {\\it Generalized Four\nMoment Theorem} (G4MT) is proposed to show the universality of the asymptotic\nlaw for the local spectral statistics of generalized spiked covariance\nmatrices, which implies the limiting distribution of the spiked eigenvalues of\nthe generalized spiked covariance matrix is independent of the actual\ndistributions of the samples satisfying our relaxed assumptions. Moreover, by\napplying it to the Central Limit Theorem (CLT) for the spiked eigenvalues of\nthe generalized spiked covariance matrix, we also extend the result of Bai and\nYao (2012) to a general form of the population covariance matrix, where the 4th\nmoment is not necessarily required to exist and the spiked eigenvalues are\nallowed to be dependent on the non-spiked ones, thus meeting the actual cases\nbetter.\n", "versions": [{"version": "v1", "created": "Thu, 16 Aug 2018 07:15:28 GMT"}, {"version": "v2", "created": "Tue, 9 Oct 2018 10:55:34 GMT"}, {"version": "v3", "created": "Thu, 25 Apr 2019 03:22:18 GMT"}], "update_date": "2019-04-26", "authors_parsed": [["Jiang", "Dandan", ""], ["Bai", "Zhidong", ""]]}, {"id": "1808.05412", "submitter": "Marius Schmidt", "authors": "Marius Schmidt, Rainer Schwabe", "title": "Optimal Designs for Poisson Count Data with Gamma Block Effects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Poisson-Gamma model is a generalization of the Poisson model, which can\nbe used for modelling count data. We show that the $D$-optimality criterion for\nthe Poisson-Gamma model is equivalent to a combined weighted optimality\ncriterion of $D$-optimality and $D_s$-optimality for the Poisson model.\nMoreover, we determine the $D$-optimal designs for the Poisson-Gamma model for\nmultiple regression with an arbitrary number of covariates, obtaining the\n$D_s$-optimal designs for the Poisson and Poisson-Gamma model as a special\ncase. For linear optimality criteria like $L$- and $c$-optimality it is shown\nthat the optimal designs in the Poisson and Poisson-Gamma model coincide.\n", "versions": [{"version": "v1", "created": "Thu, 16 Aug 2018 11:03:01 GMT"}], "update_date": "2018-08-17", "authors_parsed": [["Schmidt", "Marius", ""], ["Schwabe", "Rainer", ""]]}, {"id": "1808.05541", "submitter": "Rune Christiansen", "authors": "Rune Christiansen (University of Copenhagen) and Jonas Peters\n  (University of Copenhagen)", "title": "Switching Regression Models and Causal Inference in the Presence of\n  Discrete Latent Variables", "comments": "46 pages, 14 figures; real-world application added in Section 5.2;\n  additional numerical experiments added in the Appendix E", "journal-ref": "Journal of Machine Learning Research 21(41): 1--46, 2020", "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a response $Y$ and a vector $X = (X^1, \\dots, X^d)$ of $d$ predictors,\nwe investigate the problem of inferring direct causes of $Y$ among the vector\n$X$. Models for $Y$ that use all of its causal covariates as predictors enjoy\nthe property of being invariant across different environments or interventional\nsettings. Given data from such environments, this property has been exploited\nfor causal discovery. Here, we extend this inference principle to situations in\nwhich some (discrete-valued) direct causes of $ Y $ are unobserved. Such cases\nnaturally give rise to switching regression models. We provide sufficient\nconditions for the existence, consistency and asymptotic normality of the MLE\nin linear switching regression models with Gaussian noise, and construct a test\nfor the equality of such models. These results allow us to prove that the\nproposed causal discovery method obtains asymptotic false discovery control\nunder mild conditions. We provide an algorithm, make available code, and test\nour method on simulated data. It is robust against model violations and\noutperforms state-of-the-art approaches. We further apply our method to a real\ndata set, where we show that it does not only output causal predictors, but\nalso a process-based clustering of data points, which could be of additional\ninterest to practitioners.\n", "versions": [{"version": "v1", "created": "Thu, 16 Aug 2018 15:35:04 GMT"}, {"version": "v2", "created": "Thu, 6 Dec 2018 10:14:09 GMT"}, {"version": "v3", "created": "Wed, 11 Mar 2020 12:41:54 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Christiansen", "Rune", "", "University of Copenhagen"], ["Peters", "Jonas", "", "University of Copenhagen"]]}, {"id": "1808.05550", "submitter": "De Huang", "authors": "De Huang", "title": "A generalized Lieb's theorem and its applications to spectrum estimates\n  for a sum of random matrices", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we prove the concavity of the $k$-trace functions, $A\\mapsto\n(\\text{Tr}_k[\\exp(H+\\ln A)])^{1/k}$, on the convex cone of all positive\ndefinite matrices. $\\text{Tr}_k[A]$ denotes the $k_{\\mathrm{th}}$ elementary\nsymmetric polynomial of the eigenvalues of $A$. As an application, we use the\nconcavity of these $k$-trace functions to derive tail bounds and expectation\nestimates on the sum of the $k$ largest (or smallest) eigenvalues of a sum of\nrandom matrices.\n", "versions": [{"version": "v1", "created": "Fri, 10 Aug 2018 02:57:49 GMT"}, {"version": "v2", "created": "Fri, 30 Nov 2018 01:13:43 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Huang", "De", ""]]}, {"id": "1808.05593", "submitter": "Forrest Crawford", "authors": "Daniel J. Eck, Olga Morozova, Forrest W. Crawford", "title": "Randomization for the susceptibility effect of an infectious disease\n  intervention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP math.ST q-bio.PE stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Randomized trials of infectious disease interventions, such as vaccines,\noften focus on groups of connected or potentially interacting individuals. When\nthe pathogen of interest is transmissible between study subjects, interference\nmay occur: individual infection outcomes may depend on treatments received by\nothers. Epidemiologists have defined the primary causal effect of interest --\ncalled the \"susceptibility effect\" -- as a contrast in infection risk under\ntreatment versus no treatment, while holding exposure to infectiousness\nconstant. A related quantity -- the \"direct effect\" -- is defined as an\nunconditional contrast between the infection risk under treatment versus no\ntreatment. The purpose of this paper is to show that under a widely recommended\nrandomization design, the direct effect may fail to recover the sign of the\ntrue susceptibility effect of the intervention in a randomized trial when\noutcomes are contagious. The analytical approach uses structural features of\ninfectious disease transmission to define the susceptibility effect. A new\nprobabilistic coupling argument reveals stochastic dominance relations between\npotential infection outcomes under different treatment allocations. The results\nsuggest that estimating the direct effect under randomization may provide\nmisleading inferences about the effect of an intervention -- such as a vaccine\n-- when outcomes are contagious.\n", "versions": [{"version": "v1", "created": "Thu, 16 Aug 2018 17:25:07 GMT"}, {"version": "v2", "created": "Sat, 8 Sep 2018 17:55:27 GMT"}, {"version": "v3", "created": "Mon, 9 Dec 2019 15:59:31 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Eck", "Daniel J.", ""], ["Morozova", "Olga", ""], ["Crawford", "Forrest W.", ""]]}, {"id": "1808.05627", "submitter": "Marc Ditzhaus", "authors": "Marc Ditzhaus and Markus Pauly", "title": "Wild bootstrap logrank tests with broader power functions for testing\n  superiority", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce novel wild bootstrap procedures for testing superiority in\nunpaired two-sample survival data. By combining different classical weighted\nlogrank test we obtain tests with broader power behavior. Right censoring\nwithin the data is allowed and may differ between the groups. The tests are\nshown to be asymptotically exact under the null, consistent for fixed\nalternatives and admissible for a larger set of local alternatives. Beside\nthese asymptotic properties we also illustrate the procedures' strength in\nsimulations for finite sample sizes. The tests are implemented in the novel\nR-package mdir.logrank and its application is demonstrated in an exemplary data\nanalysis.\n", "versions": [{"version": "v1", "created": "Thu, 16 Aug 2018 18:05:03 GMT"}], "update_date": "2018-08-20", "authors_parsed": [["Ditzhaus", "Marc", ""], ["Pauly", "Markus", ""]]}, {"id": "1808.05655", "submitter": "Robert Adler", "authors": "Robert J Adler and Sarit Agami", "title": "Modelling Persistence Diagrams with Planar Point Processes, and\n  Revealing Topology with Bagplots", "comments": "37 pages, 20 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new model for planar point point processes, with the aim of\ncapturing the structure of point interaction and spread in persistence\ndiagrams. Persistence diagrams themselves are a key tool of TDA (topological\ndata analysis), crucial for the delineation and estimation of global\ntopological structure in large data sets. To a large extent, the statistical\nanalysis of persistence diagrams has been hindered by difficulties in providing\nreplications, a problem that was addressed in an earlier paper, which\nintroduced a procedure called RST (replicating statistical topology). Here we\nsignificantly improve on the power of RST via the introduction of a more\nrealistic class of models for the persistence diagrams. In addition, we\nintroduce to TDA the idea of bagplotting, a powerful technique from\nnon-parametric statistics well adapted for differentiating between\ntopologically significant points, and noise, in persistence diagrams.\n  Outside the setting of TDA, our model provides a setting for fashioning point\nprocesses, in any dimension, in which both local interactions between the\npoints, along with global restraints on the general point cloud, are important\nand perhaps competing.\n", "versions": [{"version": "v1", "created": "Thu, 16 Aug 2018 19:33:24 GMT"}], "update_date": "2018-08-20", "authors_parsed": [["Adler", "Robert J", ""], ["Agami", "Sarit", ""]]}, {"id": "1808.05771", "submitter": "Sina Molavipour", "authors": "Sina Molavipour, Germ\\'an Bassi, Mikael Skoglund", "title": "Non-Asymptotic Behavior of the Maximum Likelihood Estimate of a Discrete\n  Distribution", "comments": "30 pages, 1 figure, submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the maximum likelihood estimate of the probability\nmass function (pmf) of $n$ independent and identically distributed (i.i.d.)\nrandom variables, in the non-asymptotic regime. We are interested in\ncharacterizing the Neyman--Pearson criterion, i.e., the log-likelihood ratio\nfor testing a true hypothesis within a larger hypothesis. Wilks' theorem states\nthat this ratio behaves like a $\\chi^2$ random variable in the asymptotic case;\nhowever, less is known about the precise behavior of the ratio when the number\nof samples is finite. In this work, we find an explicit bound for the\ndifference between the cumulative distribution function (cdf) of the\nlog-likelihood ratio and the cdf of a $\\chi^2$ random variable. Furthermore, we\nshow that this difference vanishes with a rate of order $1/\\sqrt{n}$ in\naccordance with Wilks' theorem.\n", "versions": [{"version": "v1", "created": "Fri, 17 Aug 2018 06:40:11 GMT"}, {"version": "v2", "created": "Mon, 29 Jul 2019 16:49:37 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Molavipour", "Sina", ""], ["Bassi", "Germ\u00e1n", ""], ["Skoglund", "Mikael", ""]]}, {"id": "1808.05781", "submitter": "Tomonari Sei", "authors": "Tomonari Sei", "title": "Inconsistency of diagonal scaling under high-dimensional limit: a\n  replica approach", "comments": "22 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note, we claim that diagonal scaling of a sample covariance matrix is\nasymptotically inconsistent if the ratio of the dimension to the sample size\nconverges to a positive constant, where population is assumed to be Gaussian\nwith a spike covariance model. Our non-rigorous proof relies on the replica\nmethod developed in statistical physics. In contrast to similar results known\nin literature on principal component analysis, the strong inconsistency is not\nobserved. Numerical experiments support the derived formulas.\n", "versions": [{"version": "v1", "created": "Fri, 17 Aug 2018 07:38:57 GMT"}], "update_date": "2018-08-20", "authors_parsed": [["Sei", "Tomonari", ""]]}, {"id": "1808.05923", "submitter": "Yongdao Zhou", "authors": "Feng Yang, Yong-Dao Zhou, Aijun Zhang", "title": "Mixed-Level Column Augmented Uniform Designs", "comments": "43 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Follow-up experimental designs are popularly used in industry. In many\nfollow-up designs, some additional factors with two or three levels may be\nadded in the follow-up stage since they are quite important but may be\nneglected in the first stage. Such follow-up designs are called mixed-level\ncolumn augmented designs. In this paper, based on the initial designs,\nmixed-level column augmented uniform designs are proposed by using the\nuniformity criterion, wrap-around $L_2$-discrepancy (WD). The multi-stage\naugmented procedure which adds the additional design points stage by stage is\nalso investigated. We present the analytical expressions and the corresponding\nlower bounds of the WD of the column augmented designs. It is shown that the\ncolumn augmented uniform designs are also the optimal designs under the\nnon-orthogonality criterion, $E(f_{NOD})$. Furthermore, a construction\nalgorithm for the column augmented uniform design is provided. Some examples\nshow that the lower bounds are tight and the construction algorithm is\neffective.\n", "versions": [{"version": "v1", "created": "Fri, 17 Aug 2018 16:38:45 GMT"}, {"version": "v2", "created": "Wed, 22 Aug 2018 17:25:22 GMT"}], "update_date": "2018-08-23", "authors_parsed": [["Yang", "Feng", ""], ["Zhou", "Yong-Dao", ""], ["Zhang", "Aijun", ""]]}, {"id": "1808.05925", "submitter": "Koji Tsukuda", "authors": "Koji Tsukuda, Yoichi Nishiyama", "title": "Weak convergences of marked empirical processes in a Hilbert space and\n  their applications", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, weak convergences of marked empirical processes in\n$L^2(\\mathbb{R},\\nu)$ and their applications to statistical goodness-of-fit\ntests are provided, where $L^2(\\mathbb{R},\\nu)$ is the set of equivalence\nclasses of the square integrable functions on $\\mathbb{R}$ with respect to a\nfinite Borel measure $\\nu$. The results obtained in our framework of weak\nconvergences are, in the topological sense, weaker than those in the Skorokhod\ntopology on a space of c\\'adl\\'ag functions or the uniform topology on a space\nof bounded functions, which have been well studied in previous works. However,\nour results have the following merits: (1) avoiding conditions which do not\nsuit for our purpose; (2) treating a weight function which makes us possible to\npropose an Anderson--Darling type test statistics for goodness-of-fit tests.\nIndeed, the applications presented in this paper are novel.\n", "versions": [{"version": "v1", "created": "Fri, 17 Aug 2018 16:44:48 GMT"}, {"version": "v2", "created": "Tue, 15 Jan 2019 03:17:36 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Tsukuda", "Koji", ""], ["Nishiyama", "Yoichi", ""]]}, {"id": "1808.06040", "submitter": "Benjamin D. Wandelt", "authors": "Justin Alsing, Benjamin D. Wandelt, Stephen M. Feeney", "title": "Optimal proposals for Approximate Bayesian Computation", "comments": "14 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive the optimal proposal density for Approximate Bayesian Computation\n(ABC) using Sequential Monte Carlo (SMC) (or Population Monte Carlo, PMC). The\ncriterion for optimality is that the SMC/PMC-ABC sampler maximise the effective\nnumber of samples per parameter proposal. The optimal proposal density\nrepresents the optimal trade-off between favoring high acceptance rate and\nreducing the variance of the importance weights of accepted samples. We discuss\ntwo convenient approximations of this proposal and show that the optimal\nproposal density gives a significant boost in the expected sampling efficiency\ncompared to standard kernels that are in common use in the ABC literature,\nespecially as the number of parameters increases.\n", "versions": [{"version": "v1", "created": "Sat, 18 Aug 2018 04:52:37 GMT"}], "update_date": "2018-08-21", "authors_parsed": [["Alsing", "Justin", ""], ["Wandelt", "Benjamin D.", ""], ["Feeney", "Stephen M.", ""]]}, {"id": "1808.06148", "submitter": "Tomohiro Nishiyama", "authors": "Tomohiro Nishiyama", "title": "Generalized Bregman and Jensen divergences which include some\n  f-divergences", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce new classes of divergences by extending the\ndefinitions of the Bregman divergence and the skew Jensen divergence. These new\ndivergence classes (g-Bregman divergence and skew g-Jensen divergence) satisfy\nsome properties similar to the Bregman or skew Jensen divergence. We show these\ng-divergences include divergences which belong to a class of f-divergence (the\nHellinger distance, the chi-square divergence and the alpha-divergence in\naddition to the Kullback-Leibler divergence). Moreover, we derive an inequality\nbetween the g-Bregman divergence and the skew g-Jensen divergence and show this\ninequality is a generalization of Lin's inequality.\n", "versions": [{"version": "v1", "created": "Sun, 19 Aug 2018 00:59:55 GMT"}, {"version": "v2", "created": "Wed, 22 Aug 2018 01:50:47 GMT"}, {"version": "v3", "created": "Fri, 7 Sep 2018 13:29:26 GMT"}, {"version": "v4", "created": "Mon, 17 Sep 2018 06:29:29 GMT"}, {"version": "v5", "created": "Thu, 20 Sep 2018 13:00:22 GMT"}], "update_date": "2018-09-21", "authors_parsed": [["Nishiyama", "Tomohiro", ""]]}, {"id": "1808.06310", "submitter": "Daniel Nevo", "authors": "Daniel Nevo, Judith J. Lok, Donna Spiegelman", "title": "Analysis of \"Learn-As-You-Go\" (LAGO) Studies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In learn-as-you-go (LAGO) adaptive studies, the intervention is a complex\npackage consisting of multiple components, and is adapted in stages during the\nstudy based on past outcome data. This design formalizes standard practice, and\ndesires for practice, in public health intervention studies. An effective\nintervention package is sought, while minimizing intervention package cost.\nWhen analyzing data from a learn-as-you-go study, the interventions in later\nstages depend upon the outcomes in the previous stages, violating standard\nstatistical theory. We develop methods for estimating the intervention effects\nin a LAGO study. We prove consistency and asymptotic normality using a novel\ncoupling argument, ensuring the validity of the test for the hypothesis of no\noverall intervention effect. We develop a confidence set for the optimal\nintervention package and confidence bands for the success probabilities under\nalternative package compositions. We illustrate our methods in the BetterBirth\nStudy, which aimed to improve maternal and neonatal outcomes among 157,689\nbirths in Uttar Pradesh, India through a complex, multi-component intervention\npackage.\n", "versions": [{"version": "v1", "created": "Mon, 20 Aug 2018 05:29:53 GMT"}, {"version": "v2", "created": "Wed, 23 Jan 2019 08:43:31 GMT"}], "update_date": "2019-01-24", "authors_parsed": [["Nevo", "Daniel", ""], ["Lok", "Judith J.", ""], ["Spiegelman", "Donna", ""]]}, {"id": "1808.06329", "submitter": "Martin Genzel", "authors": "Martin Genzel and Gitta Kutyniok", "title": "The Mismatch Principle: The Generalized Lasso Under Large Model\n  Uncertainties", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the estimation capacity of the generalized Lasso, i.e., least\nsquares minimization combined with a (convex) structural constraint. While\nLasso-type estimators were originally designed for noisy linear regression\nproblems, it has recently turned out that they are in fact robust against\nvarious types of model uncertainties and misspecifications, most notably,\nnon-linearly distorted observation models. This work provides more theoretical\nevidence for this somewhat astonishing phenomenon. At the heart of our analysis\nstands the mismatch principle, which is a simple recipe to establish\ntheoretical error bounds for the generalized Lasso. The associated estimation\nguarantees are of independent interest and are formulated in a fairly general\nsetup, permitting arbitrary sub-Gaussian data, possibly with strongly\ncorrelated feature designs; in particular, we do not assume a specific\nobservation model which connects the input and output variables. Although the\nmismatch principle is conceived based on ideas from statistical learning\ntheory, its actual application area are (high-dimensional) estimation tasks for\nsemi-parametric models. In this context, the benefits of the mismatch principle\nare demonstrated for a variety of popular problem classes, such as single-index\nmodels, generalized linear models, and variable selection. Apart from that, our\nfindings are also relevant to recent advances in quantized and distributed\ncompressed sensing.\n", "versions": [{"version": "v1", "created": "Mon, 20 Aug 2018 07:35:39 GMT"}, {"version": "v2", "created": "Wed, 11 Sep 2019 08:56:31 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Genzel", "Martin", ""], ["Kutyniok", "Gitta", ""]]}, {"id": "1808.06341", "submitter": "Helen Ogden", "authors": "Helen Ogden", "title": "On the error in Laplace approximations of high-dimensional integrals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Laplace approximations are commonly used to approximate high-dimensional\nintegrals in statistical applications, but the quality of such approximations\nas the dimension of the integral grows is not well understood. In this paper,\nwe prove a new result on the size of the error in first- and higher-order\nLaplace approximations, and apply this result to investigate the quality of\nLaplace approximations to the likelihood in some generalized linear mixed\nmodels.\n", "versions": [{"version": "v1", "created": "Mon, 20 Aug 2018 08:24:24 GMT"}], "update_date": "2018-08-21", "authors_parsed": [["Ogden", "Helen", ""]]}, {"id": "1808.06482", "submitter": "Tomohiro Nishiyama", "authors": "Tomohiro Nishiyama", "title": "Divergence functions in dually flat spaces and their properties", "comments": "13 pages, 1 Table", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.IT math.DG math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the field of statistics, many kind of divergence functions have been\nstudied as an amount which measures the discrepancy between two probability\ndistributions. In the differential geometrical approach in statistics\n(information geometry), dually flat spaces play a key role. In a dually flat\nspace, there exist dual affine coordinate systems and strictly convex functions\ncalled potential and a canonical divergence is naturally introduced as a\nfunction of the affine coordinates and potentials. The canonical divergence\nsatisfies a relational expression called triangular relation. This can be\nregarded as a generalization of the law of cosines in Euclidean space.\n  In this paper, we newly introduce two kinds of divergences. The first\ndivergence is a function of affine coordinates and it is consistent with the\nJeffreys divergence for exponential or mixture families. For this divergence,\nwe show that more relational equations and theorems similar to Euclidean space\nhold in addition to the law of cosines. The second divergences are functions of\npotentials and they are consistent with the Bhattacharyya distance for\nexponential families and are consistent with the Jensen-Shannon divergence for\nmixture families respectively. We derive an inequality between the the first\nand the second divergences and show that the inequality is a generalization of\nLin's inequality.\n", "versions": [{"version": "v1", "created": "Thu, 16 Aug 2018 08:00:34 GMT"}, {"version": "v2", "created": "Sat, 8 Sep 2018 13:18:47 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Nishiyama", "Tomohiro", ""]]}, {"id": "1808.06901", "submitter": "Fritjof Freise", "authors": "Fritjof Freise and Heinz Holling and Rainer Schwabe", "title": "Optimal designs for two-level main effects models on a restricted design\n  region", "comments": null, "journal-ref": "Journal of Statistical Planning and Inference 204 (2020) 45-54", "doi": "10.1016/j.jspi.2019.04.005", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop $D$-optimal designs for linear main effects models on a subset of\nthe $2^K$ full factorial design region, when the number of factors set to the\nhigher level is bounded. It turns out that in the case of narrow margins only\nthose settings of the design points are admitted, where the number of high\nlevels is equal to the upper or lower bounds, while in the case of wide margins\nthe settings are more spread and the resulting optimal designs are as efficient\nas a full factorial design. These findings also apply to other optimality\ncriteria.\n", "versions": [{"version": "v1", "created": "Tue, 21 Aug 2018 13:59:06 GMT"}, {"version": "v2", "created": "Wed, 31 Oct 2018 10:57:48 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Freise", "Fritjof", ""], ["Holling", "Heinz", ""], ["Schwabe", "Rainer", ""]]}, {"id": "1808.06924", "submitter": "Xing-gang Mao", "authors": "Xing-gang Mao, Xiao-yan Xue", "title": "General hypergeometric distribution: A basic statistical distribution\n  for the number of overlapped elements in multiple subsets drawn from a finite\n  population", "comments": "22 pages, 2 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  General hypergeometric distribution (GHGD) describes the following\ndistribution: from a finite space containing N elements, select T subsets with\neach subset contains M[i] (T-1 >= i >= 0) elements, what is the probability\nthat exactly x elements are overlapped exactly t times or at least t times\n(XLO=t or XLO>=t, T >= t >= 0, here LO is level of overlap)? The classical\nhypergeometric distribution (HGD) describes the situation of two subsets, while\nthe general situation has not been resolved, despite the overlapped elements\nhas been visualized with the Venn diagram method for about 140 years. GHGD\ndescribed not only the distribution of XLO=t or XLO>=t that are overlapped in\nall of the subsets (XLO=T), but also the XLO=t or XLO>=t that are overlapped in\na portion of the subsets (LO = t or LO >= t, T >= t >= 0). Here, we developed\nalgorithms to calculate the GHGD and discovered graceful formulas of the\nessential statistics for the GHGD, including mathematical expectation,\nvariance, and high order moments. In addition, statistical theory to infer a\nstatistically reliable gene set from multiple datasets based on these formulas\nwas established by applying Chebyshev's inequalities.\n", "versions": [{"version": "v1", "created": "Tue, 21 Aug 2018 14:31:22 GMT"}, {"version": "v2", "created": "Wed, 12 Dec 2018 01:51:30 GMT"}], "update_date": "2018-12-13", "authors_parsed": [["Mao", "Xing-gang", ""], ["Xue", "Xiao-yan", ""]]}, {"id": "1808.06996", "submitter": "Zhuoran Yang", "authors": "Jianqing Fan, Han Liu, Zhaoran Wang, Zhuoran Yang", "title": "Curse of Heterogeneity: Computational Barriers in Sparse Mixture Models\n  and Phase Retrieval", "comments": "75 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT cs.LG math.IT stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the fundamental tradeoffs between statistical accuracy and\ncomputational tractability in the analysis of high dimensional heterogeneous\ndata. As examples, we study sparse Gaussian mixture model, mixture of sparse\nlinear regressions, and sparse phase retrieval model. For these models, we\nexploit an oracle-based computational model to establish conjecture-free\ncomputationally feasible minimax lower bounds, which quantify the minimum\nsignal strength required for the existence of any algorithm that is both\ncomputationally tractable and statistically accurate. Our analysis shows that\nthere exist significant gaps between computationally feasible minimax risks and\nclassical ones. These gaps quantify the statistical price we must pay to\nachieve computational tractability in the presence of data heterogeneity. Our\nresults cover the problems of detection, estimation, support recovery, and\nclustering, and moreover, resolve several conjectures of Azizyan et al. (2013,\n2015); Verzelen and Arias-Castro (2017); Cai et al. (2016). Interestingly, our\nresults reveal a new but counter-intuitive phenomenon in heterogeneous data\nanalysis that more data might lead to less computation complexity.\n", "versions": [{"version": "v1", "created": "Tue, 21 Aug 2018 16:16:46 GMT"}], "update_date": "2018-08-22", "authors_parsed": [["Fan", "Jianqing", ""], ["Liu", "Han", ""], ["Wang", "Zhaoran", ""], ["Yang", "Zhuoran", ""]]}, {"id": "1808.07105", "submitter": "Mateusz B. Majka", "authors": "Mateusz B. Majka, Aleksandar Mijatovi\\'c, Lukasz Szpruch", "title": "Non-asymptotic bounds for sampling algorithms without log-concavity", "comments": "48 pages, revised version, accepted for publication in The Annals of\n  Applied Probability", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discrete time analogues of ergodic stochastic differential equations (SDEs)\nare one of the most popular and flexible tools for sampling high-dimensional\nprobability measures. Non-asymptotic analysis in the $L^2$ Wasserstein distance\nof sampling algorithms based on Euler discretisations of SDEs has been recently\ndeveloped by several authors for log-concave probability distributions. In this\nwork we replace the log-concavity assumption with a log-concavity at infinity\ncondition. We provide novel $L^2$ convergence rates for Euler schemes,\nexpressed explicitly in terms of problem parameters. From there we derive\nnon-asymptotic bounds on the distance between the laws induced by Euler schemes\nand the invariant laws of SDEs, both for schemes with standard and with\nrandomised (inaccurate) drifts. We also obtain bounds for the hierarchy of\ndiscretisation, which enables us to deploy a multi-level Monte Carlo estimator.\nOur proof relies on a novel construction of a coupling for the Markov chains\nthat can be used to control both the $L^1$ and $L^2$ Wasserstein distances\nsimultaneously. Finally, we provide a weak convergence analysis that covers\nboth the standard and the randomised (inaccurate) drift case. In particular, we\nreveal that the variance of the randomised drift does not influence the rate of\nweak convergence of the Euler scheme to the SDE.\n", "versions": [{"version": "v1", "created": "Tue, 21 Aug 2018 19:55:33 GMT"}, {"version": "v2", "created": "Thu, 20 Sep 2018 16:54:50 GMT"}, {"version": "v3", "created": "Thu, 10 Oct 2019 16:47:44 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Majka", "Mateusz B.", ""], ["Mijatovi\u0107", "Aleksandar", ""], ["Szpruch", "Lukasz", ""]]}, {"id": "1808.07127", "submitter": "Ying Zhu", "authors": "Ying Zhu", "title": "Statistical inference and feasibility determination: a nonasymptotic\n  approach", "comments": "33 pages, 2 tables; this version fixed one typo: \"=\" in program (11)\n  on p.6 in v3 is replaced with \">=\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop non-asymptotically justified methods for hypothesis testing about\nthe $p-$dimensional coefficients $\\theta^{*}$ in (possibly nonlinear)\nregression models. Given a function $h:\\,\\mathbb{R}^{p}\\mapsto\\mathbb{R}^{m}$,\nwe consider the null hypothesis $H_{0}:\\,h(\\theta^{*})\\in\\Omega$ against the\nalternative hypothesis $H_{1}:\\,h(\\theta^{*})\\notin\\Omega$, where $\\Omega$ is a\nnonempty closed subset of $\\mathbb{R}^{m}$ and $h$ can be nonlinear in\n$\\theta^{*}$. Our (nonasymptotic) control on the Type I and Type II errors\nholds for fixed $n$ and does not rely on well-behaved estimation error or\nprediction error; in particular, when the number of restrictions in $H_{0}$ is\nlarge relative to $p-n$, we show it is possible to bypass the sparsity\nassumption on $\\theta^{*}$ (for both Type I and Type II error control),\nregularization on the estimates of $\\theta^{*}$, and other inherent challenges\nin an inverse problem. We also demonstrate an interesting link between our\nframework and Farkas' lemma (in math programming) under uncertainty, which\npoints to some potential applications of our method outside traditional\nhypothesis testing.\n", "versions": [{"version": "v1", "created": "Fri, 17 Aug 2018 16:05:58 GMT"}, {"version": "v2", "created": "Sun, 30 Sep 2018 19:37:12 GMT"}, {"version": "v3", "created": "Fri, 21 Jun 2019 17:57:11 GMT"}, {"version": "v4", "created": "Fri, 28 Jun 2019 15:14:05 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Zhu", "Ying", ""]]}, {"id": "1808.07280", "submitter": "Bj\\\"orn B\\\"ottcher", "authors": "Georg Berschneider and Bj\\\"orn B\\\"ottcher", "title": "On complex Gaussian random fields, Gaussian quadratic forms and sample\n  distance multivariance", "comments": "improved presentation of the results of the previous version (v1)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper contains results in three areas: First we present a general\nestimate for tail probabilities of Gaussian quadratic forms with known\nexpectation and variance. Thereafter we analyze the distribution of norms of\ncomplex Gaussian random fields (with possibly dependent real and complex part)\nand derive representation results, which allow to find efficient estimators for\nthe moments of the associated Gaussian quadratic form. Finally, we apply these\nresults to sample distance multivariance, which is the test statistic\ncorresponding to distance multivariance -- a recently introduced multivariate\ndependence measure. The results yield new tests for independence of multiple\nrandom vectors. These are less conservative than the classical tests based on a\ngeneral quadratic form estimate and they are (much) faster than tests based on\na resampling approach. As a special case this also improves independence tests\nbased on distance covariance, i.e., tests for independence of two random\nvectors.\n", "versions": [{"version": "v1", "created": "Wed, 22 Aug 2018 08:55:28 GMT"}, {"version": "v2", "created": "Tue, 19 Mar 2019 09:22:08 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Berschneider", "Georg", ""], ["B\u00f6ttcher", "Bj\u00f6rn", ""]]}, {"id": "1808.07319", "submitter": "Micha Mandel PhD", "authors": "Micha Mandel", "title": "The Scaled Uniform Model Revisited", "comments": "An error in the proof of proposition 1 -- the claim is wrong", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sufficiency, Conditionality and Invariance are basic principles of\nstatistical inference. Current mathematical statistics courses do not devote\nmuch teaching time to these classical principles, and even ignore the latter\ntwo, in order to teach modern methods. However, being the philosophical\ncornerstones of statistical inference, a minimal understanding of these\nprinciples should be part of any curriculum in statistics. The scaled uniform\nmodel is used here to demonstrate the importance and usefulness of the\nprinciples. The main focus is on the conditionality principle that is probably\nthe most basic and less familiar among the three. The appendix discusses the\ninvariance principle and the conditionality principle in the case of sampling\nfrom a finite population.\n", "versions": [{"version": "v1", "created": "Wed, 22 Aug 2018 11:27:13 GMT"}, {"version": "v2", "created": "Sun, 14 Oct 2018 11:48:08 GMT"}, {"version": "v3", "created": "Mon, 19 Nov 2018 16:52:03 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Mandel", "Micha", ""]]}, {"id": "1808.07410", "submitter": "Rameesa Jan", "authors": "Rameesa Jan, T.R.Jan, Peer Bilal Ahmad", "title": "Exponentiated Inverse Power Lindley Distribution and its Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this article,a three parameter generalisation of inverse lindley\ndistribution is obtained, with the purpose of obtaining a more flexible model\nrelative to the behaviour of hazard rate functions. Various statistical\nproperties such as density, hazard rate functions, moments, moment generating\nfunctions, stochastic ordering, Renyi entropy, distribution of rth order\nstatistics has been derived. The method of maximum likelihood estimation has\nbeen used to estimate parameters. Further confidence intervals are also\nobtained. Finally applicability of the proposed model to the real data is\nanalysed. A comparison has also been made with some existing distributions.\n", "versions": [{"version": "v1", "created": "Wed, 22 Aug 2018 15:47:46 GMT"}], "update_date": "2018-08-23", "authors_parsed": [["Jan", "Rameesa", ""], ["Jan", "T. R.", ""], ["Ahmad", "Peer Bilal", ""]]}, {"id": "1808.07433", "submitter": "Fangzheng Xie", "authors": "Fangzheng Xie, Yanxun Xu, Carey E. Priebe, Joshua Cape", "title": "Bayesian Estimation of Sparse Spiked Covariance Matrices in High\n  Dimensions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a Bayesian methodology for estimating spiked covariance matrices\nwith jointly sparse structure in high dimensions. The spiked covariance matrix\nis reparametrized in terms of the latent factor model, where the loading matrix\nis equipped with a novel matrix spike-and-slab LASSO prior, which is a\ncontinuous shrinkage prior for modeling jointly sparse matrices. We establish\nthe rate-optimal posterior contraction for the covariance matrix with respect\nto the operator norm as well as that for the principal subspace with respect to\nthe projection operator norm loss. We also study the posterior contraction rate\nof the principal subspace with respect to the two-to-infinity norm loss, a\nnovel loss function measuring the distance between subspaces that is able to\ncapture element-wise eigenvector perturbations. We show that the posterior\ncontraction rate with respect to the two-to-infinity norm loss is tighter than\nthat with respect to the routinely used projection operator norm loss under\ncertain low-rank and bounded coherence conditions. In addition, a point\nestimator for the principal subspace is proposed with the rate-optimal risk\nbound with respect to the projection operator norm loss. These results are\nbased on a collection of concentration and large deviation inequalities for the\nmatrix spike-and-slab LASSO prior. The numerical performance of the proposed\nmethodology is assessed through synthetic examples and the analysis of a\nreal-world face data example.\n", "versions": [{"version": "v1", "created": "Wed, 22 Aug 2018 16:42:04 GMT"}, {"version": "v2", "created": "Wed, 30 Jan 2019 03:04:23 GMT"}], "update_date": "2019-01-31", "authors_parsed": [["Xie", "Fangzheng", ""], ["Xu", "Yanxun", ""], ["Priebe", "Carey E.", ""], ["Cape", "Joshua", ""]]}, {"id": "1808.07646", "submitter": "Toma\\v{z} Ko\\v{s}ir", "authors": "Toma\\v{z} Ko\\v{s}ir, Matja\\v{z} Omladi\\v{c}", "title": "Reflected maxmin copulas and modelling quadrant subindependence", "comments": "30 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR q-fin.RM stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Copula models have become popular in different applications, including\nmodeling shocks, in view of their ability to describe better the dependence\nconcepts in stochastic systems. The class of maxmin copulas was recently\nintroduced by Omladi\\v{c} and Ru\\v{z}i\\'{c}. It extends the well known classes\nof Marshall-Olkin and Marshall copulas by allowing the external shocks to have\ndifferent effects on the two components of the system. By a reflection (flip)\nin one of the variables we introduce a new class of bivariate copulas called\nreflected maxmin (RMM) copulas. We explore their properties and show that\nsymmetric RMM copulas relate to general RMM copulas similarly as do semilinear\ncopulas relate to Marshall copulas. We transfer that relation also to maxmin\ncopulas. We also characterize possible diagonal functions of symmetric RMM\ncopulas.\n", "versions": [{"version": "v1", "created": "Thu, 23 Aug 2018 06:43:25 GMT"}, {"version": "v2", "created": "Tue, 11 Dec 2018 11:49:47 GMT"}], "update_date": "2018-12-12", "authors_parsed": [["Ko\u0161ir", "Toma\u017e", ""], ["Omladi\u010d", "Matja\u017e", ""]]}, {"id": "1808.07721", "submitter": "Ismael Castillo", "authors": "Ismael Castillo and Botond Szabo", "title": "Spike and slab empirical Bayes sparse credible sets", "comments": "45 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the sparse normal means model, coverage of adaptive Bayesian posterior\ncredible sets associated to spike and slab prior distributions is considered.\nThe key sparsity hyperparameter is calibrated via marginal maximum likelihood\nempirical Bayes. First, adaptive posterior contraction rates are derived with\nrespect to $d_q$--type--distances for $q\\leq 2$. Next, under a type of\nso-called excessive-bias conditions, credible sets are constructed that have\ncoverage of the true parameter at prescribed $1-\\alpha$ confidence level and at\nthe same time are of optimal diameter. We also prove that the previous\nconditions cannot be significantly weakened from the minimax perspective.\n", "versions": [{"version": "v1", "created": "Thu, 23 Aug 2018 12:43:50 GMT"}, {"version": "v2", "created": "Sat, 2 Feb 2019 12:52:36 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Castillo", "Ismael", ""], ["Szabo", "Botond", ""]]}, {"id": "1808.07737", "submitter": "Toma\\v{z} Ko\\v{s}ir", "authors": "Damjana Kokol Bukov\\v{s}ek, Toma\\v{z} Ko\\v{s}ir, Bla\\v{z}\n  Moj\\v{s}kerc, and Matja\\v{z} Omladi\\v{c}", "title": "Asymmetric linkages: maxmin vs. reflected maxmin copulas", "comments": "31 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR q-fin.RM stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce some new copulas emerging from shock models. It\nwas shown earlier that reflected maxmin copulas (RMM for short) are not just\nsome specific singular copulas; they contain many important absolutely\ncontinuous copulas including the negative quadrant dependent part of the\nEyraud-Farlie-Gumbel-Morgenstern class. The main goal of this paper is to\ndevelop the RMM copulas with dependent endogenous shocks and give evidence that\nRMM copulas may exhibit some characteristics better than the original maxmin\ncopulas (MM for short): (1) An important evidence for that is the iteration\nprocedure of the RMM transformation which we prove to be always convergent and\nwe give many properties of it that are useful in applications. (2) Using this\nresult we find also the limit of the iteration procedure of the MM\ntransformation thus answering a question proposed earlier by Durante,\nOmladi\\v{c}, Ora\\v{z}em, and Ru\\v{z}i\\'{c}. (3) We give the multivariate\ndependent RMM copula that compares to the MM version given by Durante,\nOmladi\\v{c}, Ora\\v{z}em, and Ru\\v{z}i\\'{c}. In all our copulas the\nidiosyncratic and systemic shocks are combined via asymmetric linking functions\nas opposed to Marshall copulas where symmetric linking functions are used.\n", "versions": [{"version": "v1", "created": "Thu, 23 Aug 2018 13:22:39 GMT"}, {"version": "v2", "created": "Wed, 12 Dec 2018 08:49:34 GMT"}, {"version": "v3", "created": "Mon, 15 Jul 2019 11:15:49 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Bukov\u0161ek", "Damjana Kokol", ""], ["Ko\u0161ir", "Toma\u017e", ""], ["Moj\u0161kerc", "Bla\u017e", ""], ["Omladi\u010d", "Matja\u017e", ""]]}, {"id": "1808.07748", "submitter": "Mahmoud El-Morshedy", "authors": "M. S. Eliwa and M. El-Morshedy", "title": "Bivariate Discrete Inverse Weibull Distribution", "comments": "arXiv admin note: text overlap with arXiv:1805.05199,\n  arXiv:1701.03569 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new class of bivariate distributions, called the\nbivariate discrete inverse Weibull (BDsIW) distribution, whose marginals are\ndiscrete inverse Weibull (DsIW) distributions. Some statistical and\nmathematical properties are presented. The maximum likelihood method is used\nfor estimating the model parameters. Simulations are presented to verify the\nperformance of the direct maximum likelihood estimation. Finally, two real data\nsets are analyzed for illustrative purposes.\n", "versions": [{"version": "v1", "created": "Wed, 22 Aug 2018 11:35:40 GMT"}], "update_date": "2018-08-24", "authors_parsed": [["Eliwa", "M. S.", ""], ["El-Morshedy", "M.", ""]]}, {"id": "1808.07890", "submitter": "Zhou Fan", "authors": "Zhou Fan and Song Mei and Andrea Montanari", "title": "TAP free energy, spin glasses, and variational inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math-ph math.MP math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the Sherrington-Kirkpatrick model of spin glasses with\nferromagnetically biased couplings. For a specific choice of the couplings\nmean, the resulting Gibbs measure is equivalent to the Bayesian posterior for a\nhigh-dimensional estimation problem known as `$Z_2$ synchronization'.\nStatistical physics suggests to compute the expectation with respect to this\nGibbs measure (the posterior mean in the synchronization problem), by\nminimizing the so-called Thouless-Anderson-Palmer (TAP) free energy, instead of\nthe mean field (MF) free energy. We prove that this identification is correct,\nprovided the ferromagnetic bias is larger than a constant (i.e. the noise level\nis small enough in synchronization). Namely, we prove that the scaled $\\ell_2$\ndistance between any low energy local minimizers of the TAP free energy and the\nmean of the Gibbs measure vanishes in the large size limit. Our proof technique\nis based on upper bounding the expected number of critical points of the TAP\nfree energy using the Kac-Rice formula.\n", "versions": [{"version": "v1", "created": "Thu, 23 Aug 2018 18:09:43 GMT"}, {"version": "v2", "created": "Thu, 26 Mar 2020 14:00:33 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Fan", "Zhou", ""], ["Mei", "Song", ""], ["Montanari", "Andrea", ""]]}, {"id": "1808.07915", "submitter": "Bodhisattva Sen", "authors": "Rajarshi Mukherjee and Bodhisattva Sen", "title": "On Efficiency of the Plug-in Principle for Estimating Smooth Integrated\n  Functionals of a Nonincreasing Density", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimating smooth integrated functionals of a\nmonotone nonincreasing density $f$ on $[0,\\infty)$ using the nonparametric\nmaximum likelihood based plug-in estimator. We find the exact asymptotic\ndistribution of this natural (tuning parameter-free) plug-in estimator,\nproperly normalized. In particular, we show that the simple plug-in estimator\nis always $\\sqrt{n}$-consistent, and is additionally asymptotically normal with\nzero mean and the semiparametric efficient variance for estimating a subclass\nof integrated functionals. Compared to the previous results on this topic (see\ne.g., Nickl (2007), Gine and Nickl (2008), Jankowski (2014), and Sohl (2015))\nour results hold for a much larger class of functionals (which include linear\nand non-linear functionals) under less restrictive assumptions on the\nunderlying $f$ --- we do not require $f$ to be (i) smooth, (ii) bounded away\nfrom $0$, or (iii) compactly supported. Further, when $f$ is the uniform\ndistribution on a compact interval we explicitly characterize the asymptotic\ndistribution of the plug-in estimator --- which now converges at a non-standard\nrate --- thereby extending the results in Groeneboom and Pyke (1983) for the\ncase of the quadratic functional.\n", "versions": [{"version": "v1", "created": "Thu, 23 Aug 2018 19:21:40 GMT"}, {"version": "v2", "created": "Tue, 12 Feb 2019 04:12:18 GMT"}, {"version": "v3", "created": "Sun, 14 Apr 2019 14:33:15 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Mukherjee", "Rajarshi", ""], ["Sen", "Bodhisattva", ""]]}, {"id": "1808.07950", "submitter": "Alois Pichler", "authors": "Arun Kumar and Nikolai Leonenko and Alois Pichler", "title": "Fractional Risk Process in Insurance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Important models in insurance, for example the Carm{\\'e}r--Lundberg theory\nand the Sparre Andersen model, essentially rely on the Poisson process. The\nprocess is used to model arrival times of insurance claims.\n  This paper extends the classical framework for ruin probabilities by\nproposing and involving the fractional Poisson process as a counting process\nand addresses fields of applications in insurance.\n  The interdependence of the fractional Poisson process is an important feature\nof the process, which leads to initial stress of the surplus process. On the\nother hand we demonstrate that the average capital required to recover a\ncompany after ruin does not change when switching to the fractional Poisson\nregime. We finally address particular risk measures, which allow simple\nevaluations in an environment governed by the fractional Poisson process.\n", "versions": [{"version": "v1", "created": "Thu, 23 Aug 2018 21:14:26 GMT"}, {"version": "v2", "created": "Sat, 13 Apr 2019 16:54:26 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Kumar", "Arun", ""], ["Leonenko", "Nikolai", ""], ["Pichler", "Alois", ""]]}, {"id": "1808.07997", "submitter": "Dong Xia", "authors": "Dong Xia", "title": "Non-asymptotic bounds for percentiles of independent non-identical\n  random variables", "comments": "14 pages", "journal-ref": "Statistics & Probability Letters, 2019", "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This note displays an interesting phenomenon for percentiles of independent\nbut non-identical random variables. Let $X_1,\\cdots,X_n$ be independent random\nvariables obeying non-identical continuous distributions and $X^{(1)}\\geq\n\\cdots\\geq X^{(n)}$ be the corresponding order statistics. For any $p\\in(0,1)$,\nwe investigate the $100(1-p)$%-th percentile $X^{(pn)}$ and prove\nnon-asymptotic bounds for $X^{(pn)}$. In particular, for a wide class of\ndistributions, we discover an intriguing connection between their median and\nthe harmonic mean of the associated standard deviations. For example, if\n$X_k\\sim\\mathcal{N}(0,\\sigma_k^2)$ for $k=1,\\cdots,n$ and $p=\\frac{1}{2}$, we\nshow that its median $\\big|{\\rm Med}\\big(X_1,\\cdots,X_n\\big)\\big|=\nO_P\\Big(n^{1/2}\\cdot\\big(\\sum_{k=1}^n\\sigma_k^{-1}\\big)^{-1}\\Big)$ as long as\n$\\{\\sigma_k\\}_{k=1}^n$ satisfy certain mild non-dispersion property.\n", "versions": [{"version": "v1", "created": "Fri, 24 Aug 2018 03:42:44 GMT"}, {"version": "v2", "created": "Sat, 2 Feb 2019 08:13:12 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Xia", "Dong", ""]]}, {"id": "1808.08104", "submitter": "Sylvain Le Corff", "authors": "Sylvain Le Corff (LMO), Matthieu Lerasle (LM-Orsay), Elodie Vernet\n  (CMAP)", "title": "A Bayesian nonparametric approach for generalized Bradley-Terry models\n  in random environment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with the estimation of the unknown distribution of hidden\nrandom variables from the observation of pairwise comparisons between these\nvariables. This problem is inspired by recent developments on Bradley-Terry\nmodels in random environment since this framework happens to be relevant to\npredict for instance the issue of a championship from the observation of a few\ncontests per team. This paper provides three contributions on a Bayesian\nnonparametric approach to solve this problem. First, we establish contraction\nrates of the posterior distribution. We also propose a Markov Chain Monte Carlo\nalgorithm to approximately sample from this posterior distribution inspired\nfrom a recent Bayesian nonparametric method for hidden Markov models. Finally,\nthe performance of this algorithm are appreciated by comparing predictions on\nthe issue of a championship based on the actual values of the teams and those\nobtained by sampling from the estimated posterior distribution.\n", "versions": [{"version": "v1", "created": "Fri, 24 Aug 2018 12:26:18 GMT"}], "update_date": "2018-08-27", "authors_parsed": [["Corff", "Sylvain Le", "", "LMO"], ["Lerasle", "Matthieu", "", "LM-Orsay"], ["Vernet", "Elodie", "", "CMAP"]]}, {"id": "1808.08153", "submitter": "Matthias L\\\"offler", "authors": "Matthias L\\\"offler and Antoine Picard", "title": "Spectral thresholding for the estimation of Markov chain transition\n  operators", "comments": "28 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider nonparametric estimation of the transition operator $P$ of a\nMarkov chain and its transition density $p$ where the singular values of $P$\nare assumed to decay exponentially fast. This is for instance the case for\nperiodised, reversible multi-dimensional diffusion processes observed in low\nfrequency. We investigate the performance of a spectral hard thresholded\nGalerkin-type estimator for $P$ and ${p}$, discarding most of the estimated\nsingular triples. The construction is based on smooth basis functions such as\nwavelets or B-splines. We show its statistical optimality by establishing\nmatching minimax upper and lower bounds in $L^2$-loss. Particularly, the effect\nof the dimensionality $d$ of the state space on the nonparametric rate improves\nfrom $2d$ to $d$ compared to the case without singular value decay.\n", "versions": [{"version": "v1", "created": "Fri, 24 Aug 2018 14:22:18 GMT"}, {"version": "v2", "created": "Wed, 29 Aug 2018 09:04:41 GMT"}, {"version": "v3", "created": "Thu, 16 Jan 2020 12:58:28 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["L\u00f6ffler", "Matthias", ""], ["Picard", "Antoine", ""]]}, {"id": "1808.08161", "submitter": "Atte Aalto", "authors": "Atte Aalto, Lauri Viitasaari, Pauliina Ilmonen, Laurent Mombaerts and\n  Jorge Goncalves", "title": "Continuous time Gaussian process dynamical models in gene regulatory\n  network inference", "comments": "Preprint version of a published article. NOTE: The published version\n  title is different from the preprint", "journal-ref": "\"Gene regulatory network inference from sparsely sampled noisy\n  data\", Nature Communications 11: 3493 (2020)", "doi": "10.1038/s41467-020-17217-1", "report-no": null, "categories": "math.OC math.ST q-bio.MN stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the focus areas of modern scientific research is to reveal mysteries\nrelated to genes and their interactions. The dynamic interactions between genes\ncan be encoded into a gene regulatory network (GRN), which can be used to gain\nunderstanding on the genetic mechanisms behind observable phenotypes. GRN\ninference from time series data has recently been a focus area of systems\nbiology. Due to low sampling frequency of the data, this is a notoriously\ndifficult problem. We tackle the challenge by introducing the so-called\ncontinuous-time Gaussian process dynamical model, based on Gaussian process\nframework that has gained popularity in nonlinear regression problems arising\nin machine learning. The model dynamics are governed by a stochastic\ndifferential equation, where the dynamics function is modelled as a Gaussian\nprocess. We prove the existence and uniqueness of solutions of the stochastic\ndifferential equation. We derive the probability distribution for the Euler\ndiscretised trajectories and establish the convergence of the discretisation.\nWe develop a GRN inference method called BINGO, based on the developed\nframework. BINGO is based on MCMC sampling of trajectories of the GPDM and\nestimating the hyperparameters of the covariance function of the Gaussian\nprocess. Using benchmark data examples, we show that BINGO is superior in\ndealing with poor time resolution and it is computationally feasible.\n", "versions": [{"version": "v1", "created": "Fri, 24 Aug 2018 14:50:28 GMT"}, {"version": "v2", "created": "Fri, 19 Jul 2019 09:01:44 GMT"}, {"version": "v3", "created": "Wed, 15 Jul 2020 12:46:19 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Aalto", "Atte", ""], ["Viitasaari", "Lauri", ""], ["Ilmonen", "Pauliina", ""], ["Mombaerts", "Laurent", ""], ["Goncalves", "Jorge", ""]]}, {"id": "1808.08320", "submitter": "Yunyi Zhang", "authors": "Yunyi Zhang, Jiazheng Liu, Zexin Pan, Dimitris N. Politis", "title": "$L_p$ and almost sure convergence of estimation on heavy tail index\n  under random censoring", "comments": "There are totally 6 figures and 17 pages of this article", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we prove $L_p,\\ p\\geq 2$ and almost sure convergence of tail\nindex estimator mentioned in \\cite{grama2008} under random censoring and\nseveral assumptions. $p$th moment of the error of the estimator is proved to be\nof order $O\\left(\\frac{1}{\\log^{m\\kappa/2}n}\\right)$ with given assumptions. We\nalso perform several finite sample simulations to quantify performance of this\nestimator. Finite sample results show that the proposed estimator is effective\nin finding underlying tail index even when censor rate is high.\n", "versions": [{"version": "v1", "created": "Fri, 24 Aug 2018 21:41:43 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Zhang", "Yunyi", ""], ["Liu", "Jiazheng", ""], ["Pan", "Zexin", ""], ["Politis", "Dimitris N.", ""]]}, {"id": "1808.08491", "submitter": "Hedibert Lopes", "authors": "Hedibert F. Lopes and Nicholas G. Polson", "title": "Bayesian Hypothesis Testing: Redux", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian hypothesis testing is re-examined from the perspective of an a\npriori assessment of the test statistic distribution under the alternative. By\nassessing the distribution of an observable test statistic, rather than prior\nparameter values, we provide a practical default Bayes factor which is\nstraightforward to interpret. To illustrate our methodology, we provide\nexamples where evidence for a Bayesian strikingly supports the null, but leads\nto rejection under a classical test. Finally, we conclude with directions for\nfuture research.\n", "versions": [{"version": "v1", "created": "Sun, 26 Aug 2018 00:40:56 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Lopes", "Hedibert F.", ""], ["Polson", "Nicholas G.", ""]]}, {"id": "1808.08507", "submitter": "Wenpin Tang", "authors": "Wenpin Tang", "title": "Mallows Ranking Models: Maximum Likelihood Estimate and Regeneration", "comments": "10 pages, 2 figures, 5 tables. This paper is published by\n  http://proceedings.mlr.press/v97/tang19a.html", "journal-ref": "Proceedings of the 36th International Conference on Machine\n  Learning (ICML 2019), PMLR 97, 6125-6134", "doi": null, "report-no": null, "categories": "math.ST math.PR stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with various Mallows ranking models. We study the\nstatistical properties of the MLE of Mallows' $\\phi$ model. We also make\nconnections of various Mallows ranking models, encompassing recent progress in\nmathematics. Motivated by the infinite top-$t$ ranking model, we propose an\nalgorithm to select the model size $t$ automatically. The key idea relies on\nthe renewal property of such an infinite random permutation. Our algorithm\nshows good performance on several data sets.\n", "versions": [{"version": "v1", "created": "Sun, 26 Aug 2018 05:42:14 GMT"}, {"version": "v2", "created": "Sat, 15 Jun 2019 17:23:00 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Tang", "Wenpin", ""]]}, {"id": "1808.08991", "submitter": "Shlomi Reuveni", "authors": "Iddo Eliazar, Ralf Metzler, and Shlomi Reuveni", "title": "Poisson-process limit-laws yield Gumbel Max-Min and Min-Max", "comments": null, "journal-ref": "Phys. Rev. E 100, 022129 (2019)", "doi": "10.1103/PhysRevE.100.022129", "report-no": null, "categories": "cond-mat.stat-mech math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \"A chain is only as strong as its weakest link\" says the proverb. But what\nabout a collection of statistically identical chains: How long till all chains\nfail? The answer to this question is given by the Max-Min of a matrix whose\n$\\left(i,j\\right)$ entry is the failure time of link $j$ of chain $i$: take the\nminimum of each row, and then the maximum of the rows' minima. The\ncorresponding Min-Max is obtained by taking the maximum of each column, and\nthen the minimum of the columns' maxima. The Min-Max applies to the storage of\ncritical data. Indeed, consider multiple backup copies of a set of critical\ndata items, and consider the $\\left(i,j\\right)$ matrix entry to be the time at\nwhich item $j$ on copy $i$ is lost; then, the Min-Max is the time at which the\nfirst critical data item is lost. In this paper, we address random matrices\nwhose entries are independent and identically distributed random variables. We\nestablish Poisson-process limit-laws for the row's minima and for the columns'\nmaxima. Then, we further establish Gumbel limit-laws for the Max-Min and for\nthe Min-Max. The limit-laws hold whenever the entries' distribution has a\ndensity, and the Gumbel limit-laws yield highly applicable approximation tools\nand design tools for large random matrices.\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2018 18:51:59 GMT"}, {"version": "v2", "created": "Mon, 25 Feb 2019 21:22:20 GMT"}, {"version": "v3", "created": "Thu, 1 Aug 2019 09:16:31 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Eliazar", "Iddo", ""], ["Metzler", "Ralf", ""], ["Reuveni", "Shlomi", ""]]}, {"id": "1808.09011", "submitter": "Yaowu Liu", "authors": "Yaowu Liu and Jun Xie", "title": "Cauchy combination test: a powerful test with analytic p-value\n  calculation under arbitrary dependency structures", "comments": "To appear in Journal of the American Statistical Association, Theory\n  and Methods", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combining individual p-values to aggregate multiple small effects has a\nlong-standing interest in statistics, dating back to the classic Fisher's\ncombination test. In modern large-scale data analysis, correlation and sparsity\nare common features and efficient computation is a necessary requirement for\ndealing with massive data. To overcome these challenges, we propose a new test\nthat takes advantage of the Cauchy distribution. Our test statistic has a very\nsimple form and is defined as a weighted sum of Cauchy transformation of\nindividual p-values. We prove a non-asymptotic result that the tail of the null\ndistribution of our proposed test statistic can be well approximated by a\nCauchy distribution under arbitrary dependency structures. Based on this\ntheoretical result, the p-value calculation of our proposed test is not only\naccurate, but also as simple as the classic z-test or t-test, making our test\nwell suited for analyzing massive data. We further show that the power of the\nproposed test is asymptotically optimal in a strong sparsity setting. Extensive\nsimulations demonstrate that the proposed test has both strong power against\nsparse alternatives and a good accuracy with respect to p-value calculations,\nespecially for very small p-values. The proposed test has also been applied to\na genome-wide association study of Crohn's disease and compared with several\nexisting tests.\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2018 19:38:16 GMT"}, {"version": "v2", "created": "Wed, 28 Nov 2018 23:02:58 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Liu", "Yaowu", ""], ["Xie", "Jun", ""]]}, {"id": "1808.09047", "submitter": "Grant Backlund", "authors": "Grant Backlund, James P. Hobert, Yeun Ji Jung, and Kshitij Khare", "title": "A Hybrid Scan Gibbs Sampler for Bayesian Models with Latent Variables", "comments": "35 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gibbs sampling is a widely popular Markov chain Monte Carlo algorithm that\ncan be used to analyze intractable posterior distributions associated with\nBayesian hierarchical models. There are two standard versions of the Gibbs\nsampler: The systematic scan (SS) version, where all variables are updated at\neach iteration, and the random scan (RS) version, where a single, randomly\nselected variable is updated at each iteration. The literature comparing the\ntheoretical properties of SS and RS Gibbs samplers is reviewed, and an\nalternative hybrid scan Gibbs sampler is introduced, which is particularly well\nsuited to Bayesian models with latent variables. The word \"hybrid\" reflects the\nfact that the scan used within this algorithm has both systematic and random\nelements. Indeed, at each iteration, one updates the entire set of latent\nvariables, along with a randomly chosen block of the remaining variables. The\nhybrid scan (HS) Gibbs sampler has important advantages over the two standard\nscan Gibbs samplers. Firstly, the HS algorithm is often easier to analyze from\na theoretical standpoint. In particular, it can be much easier to establish the\ngeometric ergodicity of a HS Gibbs Markov chain than to do the same for the\ncorresponding SS and RS versions. Secondly, the sandwich methodology developed\nin Hobert and Marchev (2008), which is also reviewed, can be applied to the HS\nGibbs algorithm (but not to the standard scan Gibbs samplers). It is shown\nthat, under weak regularity conditions, adding sandwich steps to the HS Gibbs\nsampler always results in a theoretically superior algorithm. Three specific\nBayesian hierarchical models of varying complexity are used to illustrate the\nresults. One is a simple location-scale model for data from the Student's $t$\ndistribution, which is used as a pedagogical tool. The other two are\nsophisticated, yet practical Bayesian regression models.\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2018 22:13:13 GMT"}, {"version": "v2", "created": "Mon, 30 Dec 2019 23:51:47 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Backlund", "Grant", ""], ["Hobert", "James P.", ""], ["Jung", "Yeun Ji", ""], ["Khare", "Kshitij", ""]]}, {"id": "1808.09171", "submitter": "Eric Benhamou", "authors": "Eric Benhamou and Valentin Melot", "title": "Seven proofs of the Pearson Chi-squared independence test and its\n  graphical interpretation", "comments": "18 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper revisits the Pearson Chi-squared independence test. After\npresenting the underlying theory with modern notations and showing new way of\nderiving the proof, we describe an innovative and intuitive graphical\npresentation of this test. This enables not only interpreting visually the test\nbut also measuring how close or far we are from accepting or rejecting the null\nhypothesis of non independence\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 08:43:11 GMT"}, {"version": "v2", "created": "Wed, 29 Aug 2018 10:47:54 GMT"}, {"version": "v3", "created": "Mon, 3 Sep 2018 13:04:01 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Benhamou", "Eric", ""], ["Melot", "Valentin", ""]]}, {"id": "1808.09184", "submitter": "Patricia Reynaud-Bouret", "authors": "P Hodara (INRA Jouy en Josas), Patricia Reynaud-Bouret (JAD)", "title": "Exponential inequality for chaos based on sampling without replacement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are interested in the behavior of particular functionals, in a framework\nwhere the only source of randomness is a sampling without replacement. More\nprecisely the aim of this short note is to prove an exponential concentration\ninequality for special U-statistics of order 2, that can be seen as chaos.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 09:07:41 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Hodara", "P", "", "INRA Jouy en Josas"], ["Reynaud-Bouret", "Patricia", "", "JAD"]]}, {"id": "1808.09372", "submitter": "Konstantinos Spiliopoulos", "authors": "Justin Sirignano and Konstantinos Spiliopoulos", "title": "Mean Field Analysis of Neural Networks: A Central Limit Theorem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We rigorously prove a central limit theorem for neural network models with a\nsingle hidden layer. The central limit theorem is proven in the asymptotic\nregime of simultaneously (A) large numbers of hidden units and (B) large\nnumbers of stochastic gradient descent training iterations. Our result\ndescribes the neural network's fluctuations around its mean-field limit. The\nfluctuations have a Gaussian distribution and satisfy a stochastic partial\ndifferential equation. The proof relies upon weak convergence methods from\nstochastic analysis. In particular, we prove relative compactness for the\nsequence of processes and uniqueness of the limiting process in a suitable\nSobolev space.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 15:43:20 GMT"}, {"version": "v2", "created": "Mon, 3 Jun 2019 15:58:31 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Sirignano", "Justin", ""], ["Spiliopoulos", "Konstantinos", ""]]}, {"id": "1808.09489", "submitter": "Jiangning Chen", "authors": "Jiangning Chen", "title": "Convergence Rate of Krasulina Estimator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Principal component analysis (PCA) is one of the most commonly used\nstatistical procedures with a wide range of applications. Consider the points\n$X_1, X_2,..., X_n$ are vectors drawn i.i.d. from a distribution with mean zero\nand covariance $\\Sigma$, where $\\Sigma$ is unknown. Let $A_n = X_nX_n^T$, then\n$E[A_n] = \\Sigma$. This paper consider the problem of finding the least\neigenvalue and eigenvector of matrix $\\Sigma$. A classical such estimator are\ndue to Krasulina\\cite{krasulina_method_1969}. We are going to state the\nconvergence proof of Krasulina for the least eigenvalue and corresponding\neigenvector, and then find their convergence rate.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 18:47:20 GMT"}, {"version": "v2", "created": "Sat, 27 Apr 2019 22:12:53 GMT"}, {"version": "v3", "created": "Tue, 7 May 2019 18:09:15 GMT"}, {"version": "v4", "created": "Tue, 23 Jul 2019 04:05:08 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Chen", "Jiangning", ""]]}, {"id": "1808.09698", "submitter": "Toma\\v{z} Ko\\v{s}ir", "authors": "Damjana Kokol Bukov\\v{s}ek, Toma\\v{z} Ko\\v{s}ir, Bla\\v{z}\n  Moj\\v{s}kerc, and Matja\\v{z} Omladi\\v{c}", "title": "Non-exchangeability of copulas arising from shock models", "comments": "The latest version (V.4) contains a correction in Theorem 3.1 and\n  Remark 3.3 compared to the printed version in the journal and to the previous\n  version on arXiv. Functions $P_{\\lambda}$ in the earlier version of Theorem\n  3.1 are not copulas as claimed. We wish to thank Professor Piotr Jaworski for\n  pointing out the fact. (31 pages, 14 figures)", "journal-ref": "Journal of Computational and Applied Mathematics, Vol. 358 (2019),\n  61-83", "doi": "10.1016/j.cam.2019.02.031", "report-no": null, "categories": "math.ST math.PR q-fin.RM stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When choosing the right copula for our data a key point is to distinguish the\nfamily that describes it at the best. In this respect, a better choice of the\ncopulas could be obtained through the information about the (non)symmetry of\nthe data. Exchangeability as a probability concept (first next to independence)\nhas been studied since 1930's, copulas have been studied since 1950's, and even\nthe most important class of copulas from the point of view of applications,\ni.e. the ones arising from shock models s.a. Marshall's copulas, have been\nstudied since 1960's. However, the point of non-exchangeability of copulas was\nbrought up only in 2006 and has been intensively studied ever since. One of the\nmain contributions of this paper is the maximal asymmetry function for a family\nof copulas. We compute this function for the major families of shock-based\ncopulas, i.e. Marshall, maxmin and reflected maxmin (RMM for short) copulas and\nalso for some other important families. We compute the sharp bound of asymmetry\nmeasure $\\mu_\\infty$, the most important of the asymmetry measures, for the\nfamily of Marshall copulas and the family of maxmin copulas, which both equal\nto $\\frac{4}{27}\\ (\\approx 0.148)$. One should compare this bound to the one\nfor the class of PQD copulas to which they belong, which is $3-2\\sqrt{2}\\\n\\approx 0.172)$, and to the general bound for all copulas that is $\\frac13$.\nFurthermore, we give the sharp bound of the same asymmetry measure for RMM\ncopulas which is $3-2\\sqrt{2}$, compared to the same bound for NQD copulas,\nwhere they belong, which is $\\sqrt{5}-2\\ (\\approx 0.236)$. One of our main\nresults is also the statistical interpretation of shocks in a given model at\nwhich the maximal asymmetry measure bound is attained. These interpretations\nfor the three families studied are illustrated by examples that should be\nhelpful to practitioners when choosing the model for their data.\n", "versions": [{"version": "v1", "created": "Wed, 29 Aug 2018 09:18:56 GMT"}, {"version": "v2", "created": "Tue, 11 Dec 2018 12:19:35 GMT"}, {"version": "v3", "created": "Thu, 21 Feb 2019 13:22:11 GMT"}, {"version": "v4", "created": "Thu, 11 Jul 2019 13:03:24 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Bukov\u0161ek", "Damjana Kokol", ""], ["Ko\u0161ir", "Toma\u017e", ""], ["Moj\u0161kerc", "Bla\u017e", ""], ["Omladi\u010d", "Matja\u017e", ""]]}, {"id": "1808.09748", "submitter": "Ismael Castillo", "authors": "Ismael Castillo and Etienne Roquain", "title": "On spike and slab empirical Bayes multiple testing", "comments": "83 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores a connection between empirical Bayes posterior\ndistributions and false discovery rate (FDR) control. In the Gaussian sequence\nmodel, this work shows that empirical Bayes-calibrated spike and slab posterior\ndistributions allow a correct FDR control under sparsity. Doing so, it offers a\nfrequentist theoretical validation of empirical Bayes methods in the context of\nmultiple testing. Our theoretical results are illustrated with numerical\nexperiments.\n", "versions": [{"version": "v1", "created": "Wed, 29 Aug 2018 12:12:30 GMT"}, {"version": "v2", "created": "Sat, 15 Jun 2019 10:13:34 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Castillo", "Ismael", ""], ["Roquain", "Etienne", ""]]}, {"id": "1808.09933", "submitter": "Mikael Vejdemo-Johansson", "authors": "Mikael Vejdemo-Johansson and Alisa Leshchenko", "title": "Certified Mapper: Repeated testing for acyclicity and obstructions to\n  the nerve lemma", "comments": "16 pages, submitted to the proceedings of the Abel symposium", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AT cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Mapper algorithm does not include a check for whether the cover produced\nconforms to the requirements of the nerve lemma. To perform a check for\nobstructions to the nerve lemma, statistical considerations of multiple testing\nquickly arise.\n  In this paper, we propose several statistical approaches to finding\nobstructions: through a persistent nerve lemma, through simulation testing, and\nusing a parametric refinement of simulation tests.\n  We suggest Certified Mapper -- a method built from these approaches to\ngenerate certificates of non-obstruction, or identify specific obstructions to\nthe nerve lemma -- and we give recommendations for which statistical approaches\nare most appropriate for the task.\n", "versions": [{"version": "v1", "created": "Wed, 29 Aug 2018 17:21:17 GMT"}], "update_date": "2018-08-30", "authors_parsed": [["Vejdemo-Johansson", "Mikael", ""], ["Leshchenko", "Alisa", ""]]}, {"id": "1808.10056", "submitter": "Rachel Cummings", "authors": "Rachel Cummings, Sara Krehbiel, Yajun Mei, Rui Tuo, Wanrong Zhang", "title": "Differentially Private Change-Point Detection", "comments": null, "journal-ref": "Proceedings of the 32nd International Conference on Neural\n  Information Processing Systems (2018) Pages 10848-10857", "doi": null, "report-no": null, "categories": "math.ST cs.DS cs.LG stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The change-point detection problem seeks to identify distributional changes\nat an unknown change-point k* in a stream of data. This problem appears in many\nimportant practical settings involving personal data, including\nbiosurveillance, fault detection, finance, signal detection, and security\nsystems. The field of differential privacy offers data analysis tools that\nprovide powerful worst-case privacy guarantees. We study the statistical\nproblem of change-point detection through the lens of differential privacy. We\ngive private algorithms for both online and offline change-point detection,\nanalyze these algorithms theoretically, and provide empirical validation of our\nresults.\n", "versions": [{"version": "v1", "created": "Wed, 29 Aug 2018 22:17:24 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Cummings", "Rachel", ""], ["Krehbiel", "Sara", ""], ["Mei", "Yajun", ""], ["Tuo", "Rui", ""], ["Zhang", "Wanrong", ""]]}, {"id": "1808.10065", "submitter": "Guang Cheng", "authors": "Qing Yang and Guang Cheng", "title": "Quadratic Discriminant Analysis under Moderate Dimension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quadratic discriminant analysis (QDA) is a simple method to classify a\nsubject into two populations, and was proven to perform as well as the Bayes\nrule when the data dimension p is fixed. The main purpose of this paper is to\nexamine the empirical and theoretical behaviors of QDA where p grows\nproportionally to the sample sizes without imposing any structural assumption\non the parameters. The first finding in this moderate dimension regime is that\nQDA can perform as poorly as random guessing even when the two populations\ndeviate significantly. This motivates a generalized version of QDA that\nautomatically adapts to dimensionality. Under a finite fourth moment condition,\nwe derive misclassification rates for both the generalized QDA and the optimal\none. A direct comparison reveals one \"easy\" case where the difference between\ntwo rates converges to zero and one \"hard\" case where that converges to some\nstrictly positive constant. For the latter, a divide-and-conquer approach over\ndimension (rather than sample) followed by a screening procedure is proposed to\nnarrow the gap. Various numerical studies are conducted to back up the proposed\nmethodology.\n", "versions": [{"version": "v1", "created": "Wed, 29 Aug 2018 23:11:00 GMT"}], "update_date": "2018-08-31", "authors_parsed": [["Yang", "Qing", ""], ["Cheng", "Guang", ""]]}, {"id": "1808.10092", "submitter": "HuaMing Wang", "authors": "Hua-Ming Wang, Meijuan Zhang", "title": "Maximum likelihood estimator and its consistency for an $(L,1)$ random\n  walk in a parametric random environment", "comments": "with 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider an $(L,1)$ random walk in an i.i.d. random environment, whose\nenvironment involves certain parameter. We get the maximum likelihood\nestimator(MLE) of the environment parameter which can be written as functionals\nof a multitype branching process with immigration in a random\nenvironment(BPIRE). Because the offspring distributions of the involved\nmultitype BPIRE are of the linear fractional type, the limit invariant\ndistribution of the multitype BPIRE can be computed explicitly. As a result, we\nget the consistency of the MLE. Our result is a generalization of Comets et al.\n[Stochastic Process. Appl. 2014, 124, 268-288].\n", "versions": [{"version": "v1", "created": "Thu, 30 Aug 2018 02:48:45 GMT"}], "update_date": "2018-08-31", "authors_parsed": [["Wang", "Hua-Ming", ""], ["Zhang", "Meijuan", ""]]}, {"id": "1808.10121", "submitter": "Yufan Li Mr.", "authors": "Yufan Li, Jeffery Rosenthal", "title": "A Divergent Random Walk on Stairs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a state-dependent, time-dependent, discrete random walks\n$X_t^{\\{a_n\\}}$ defined on natural numbers $\\mathbb{N}$ (bent to a \"stair\" in\n$\\mathbb{N}^2$) where the random walk depends on input of a positive\ndeterministic sequence $\\{a_n\\}$. This walk has the peculiar property that if\nwe set $a_n$ to be $+\\infty$ for all $n$, it converges to a stationary\ndistribution $\\pi(\\cdot)$; but if $a_n$ is uniformly bounded (over all $n$) by\nany upper bound $a \\in (0,\\infty)$, this walk diverges to infinity with\nprobability 1. It is thus interesting to consider the intermediate case where\n$a_n<\\infty$ for all $n$ but $a_n$ eventually tends to $+\\infty$.\n  (Latuszynski et al., 2013) first defined this walk and conjectured that a\nparticular choice of sequence $\\{a_n\\}$ exists such that (i) $a_n \\to \\infty$\nand, (ii) $P(X_t^{\\{a_n\\}} \\to \\infty )=1$. They managed to construct a\nsequence $\\{a_n\\}$ that satisfies (i) and $P(X_t^{\\{a_n\\}}\\to \\infty)>0$, which\nis weaker than (ii).\n  In this paper, we obtain a stronger result: for any $\\sigma<1$, there exists\na choice of $\\{a_n\\}$ so that $P(X_t\\to \\infty)\\ge \\sigma$. Our result does not\napply when $\\sigma=1$, the original conjecture remains open. We record our\nmethod here for technical interests.\n", "versions": [{"version": "v1", "created": "Thu, 30 Aug 2018 05:12:47 GMT"}, {"version": "v2", "created": "Fri, 27 Sep 2019 22:45:08 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Li", "Yufan", ""], ["Rosenthal", "Jeffery", ""]]}, {"id": "1808.10185", "submitter": "Li-Chun Zhang", "authors": "Li-Chun Zhang and Raymond L. Chambers", "title": "Minimal inference from incomplete 2x2-tables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimates based on 2x2 tables of frequencies are widely used in statistical\napplications. However, in many cases these tables are incomplete in the sense\nthat the data required to compute the frequencies for a subset of the cells\ndefining the table are unavailable. Minimal inference addresses those\nsituations where this incompleteness leads to target parameters for these\ntables that are interval, rather than point, identifiable. In particular, we\ndevelop the concept of corroboration as a measure of the statistical evidence\nin the observed data that is not based on likelihoods. The corroboration\nfunction identifies the parameter values that are the hardest to refute, i.e.,\nthose values which, under repeated sampling, remain interval identified. This\nenables us to develop a general approach to inference from incomplete 2x2\ntables when the additional assumptions required to support a likelihood-based\napproach cannot be sustained based on the data available. This minimal\ninference approach then provides a foundation for further analysis that aims at\nmaking sharper inference supported by plausible external beliefs.\n", "versions": [{"version": "v1", "created": "Thu, 30 Aug 2018 08:47:15 GMT"}], "update_date": "2018-08-31", "authors_parsed": [["Zhang", "Li-Chun", ""], ["Chambers", "Raymond L.", ""]]}, {"id": "1808.10593", "submitter": "Yuling Yan", "authors": "Yuling Yan, Bret Hanlon, Sebastien Roch, Karl Rohe", "title": "Asymptotic Seed Bias in Respondent-driven Sampling", "comments": "37 pages, 7 figures; typos corrected, proof outlines added", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.SI math.PR stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Respondent-driven sampling (RDS) collects a sample of individuals in a\nnetworked population by incentivizing the sampled individuals to refer their\ncontacts into the sample. This iterative process is initialized from some seed\nnode(s). Sometimes, this selection creates a large amount of seed bias. Other\ntimes, the seed bias is small. This paper gains a deeper understanding of this\nbias by characterizing its effect on the limiting distribution of various RDS\nestimators. Using classical tools and results from multi-type branching\nprocesses (Kesten and Stigum, 1966), we show that the seed bias is negligible\nfor the Generalized Least Squares (GLS) estimator and non-negligible for both\nthe inverse probability weighted and Volz-Heckathorn (VH) estimators. In\nparticular, we show that (i) above a critical threshold, VH converge to a\nnon-trivial mixture distribution, where the mixture component depends on the\nseed node, and the mixture distribution is possibly multi-modal. Moreover, (ii)\nGLS converges to a Gaussian distribution independent of the seed node, under a\ncertain condition on the Markov process. Numerical experiments with both\nsimulated data and empirical social networks suggest that these results appear\nto hold beyond the Markov conditions of the theorems.\n", "versions": [{"version": "v1", "created": "Fri, 31 Aug 2018 04:16:58 GMT"}, {"version": "v2", "created": "Wed, 21 Aug 2019 04:53:31 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Yan", "Yuling", ""], ["Hanlon", "Bret", ""], ["Roch", "Sebastien", ""], ["Rohe", "Karl", ""]]}, {"id": "1808.10660", "submitter": "Claudia Strauch", "authors": "Cathrine Aeckerle-Willems, Claudia Strauch", "title": "Sup-norm adaptive simultaneous drift estimation for ergodic diffusions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the question of estimating the drift and the invariant density\nfor a large class of scalar ergodic diffusion processes, based on continuous\nobservations, in $\\sup$-norm loss. The unknown drift $b$ is supposed to belong\nto a nonparametric class of smooth functions of unknown order. We suggest an\nadaptive approach which allows to construct drift estimators attaining minimax\noptimal $\\sup$-norm rates of convergence. In addition, we prove a Donsker\ntheorem for the classical kernel estimator of the invariant density and\nestablish its semiparametric efficiency. Finally, we combine both results and\npropose a fully data-driven bandwidth selection procedure which simultaneously\nyields both a rate-optimal drift estimator and an asymptotically efficient\nestimator of the invariant density of the diffusion. Crucial tool for our\ninvestigation are uniform exponential inequalities for empirical processes of\ndiffusions.\n", "versions": [{"version": "v1", "created": "Fri, 31 Aug 2018 10:15:03 GMT"}], "update_date": "2018-09-03", "authors_parsed": [["Aeckerle-Willems", "Cathrine", ""], ["Strauch", "Claudia", ""]]}, {"id": "1808.10669", "submitter": "Joni Virta", "authors": "Joni Virta and Klaus Nordhausen", "title": "Determining the signal dimension in second order source separation", "comments": "60 pages, 5 figures", "journal-ref": null, "doi": "10.5705/ss.202018.0347", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While an important topic in practice, the estimation of the number of\nnon-noise components in blind source separation has received little attention\nin the literature. Recently, two bootstrap-based techniques for estimating the\ndimension were proposed, and although very efficient, they suffer from the long\ncomputation times caused by the resampling. We approach the problem from a\nlarge sample viewpoint and develop an asymptotic test for the true dimension.\nOur test statistic based on second-order temporal information has a very simple\nlimiting distribution under the null hypothesis and requires no parameters to\nestimate. Comparisons to the resampling-based estimates show that the\nasymptotic test provides comparable error rates with significantly faster\ncomputation time. An application to sound recording data is used to illustrate\nthe method in practice.\n", "versions": [{"version": "v1", "created": "Fri, 31 Aug 2018 10:35:54 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Virta", "Joni", ""], ["Nordhausen", "Klaus", ""]]}, {"id": "1808.10722", "submitter": "Luc Pronzato", "authors": "Luc Pronzato (GdR MASCOT-NUM), Anatoly Zhigljavsky", "title": "Bayesian quadrature and energy minimization for space-filling design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A standard objective in computer experiments is to approximate the behaviour\nof an unknown function on a compact domain from a few evaluations inside the\ndomain. When little is known about the function, space-filling design is\nadvisable: typically, points of evaluation spread out across the available\nspace are obtained by minimizing a geometrical (for instance, covering radius)\nor a discrepancy criterion measuring distance to uniformity. The paper\ninvestigates connections between design for integration (quadrature design),\nconstruction of the (continuous) BLUE for the location model, space-filling\ndesign, and minimization of energy (kernel discrepancy) for signed measures.\nIntegrally strictly positive definite kernels define strictly convex energy\nfunctionals, with an equivalence between the notions of potential and\ndirectional derivative, showing the strong relation between discrepancy\nminimization and more traditional design of optimal experiments. In particular,\nkernel herding algorithms, which are special instances of vertex-direction\nmethods used in optimal design, can be applied to the construction of point\nsequences with suitable space-filling properties.\n", "versions": [{"version": "v1", "created": "Fri, 31 Aug 2018 13:15:36 GMT"}], "update_date": "2018-09-03", "authors_parsed": [["Pronzato", "Luc", "", "GdR MASCOT-NUM"], ["Zhigljavsky", "Anatoly", ""]]}, {"id": "1808.10770", "submitter": "Tomohiro Nishiyama", "authors": "Tomohiro Nishiyama", "title": "Improved Chebyshev inequality: new probability bounds with known\n  supremum of PDF", "comments": "7 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we derive new probability bounds for Chebyshev's inequality if\nthe supremum of the probability density function is known. This result holds\nfor one-dimensional or multivariate continuous probability distributions with\nfinite mean and variance (covariance matrix). We also show that the similar\nresult holds for specific discrete probability distributions.\n", "versions": [{"version": "v1", "created": "Fri, 31 Aug 2018 14:26:28 GMT"}, {"version": "v2", "created": "Fri, 7 Sep 2018 12:47:54 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Nishiyama", "Tomohiro", ""]]}, {"id": "1808.10828", "submitter": "Axel B\\\"ucher", "authors": "Axel B\\\"ucher and Stanislav Volgushev and Nan Zou", "title": "On Second Order Conditions in the Multivariate Block Maxima and Peak\n  over Threshold Method", "comments": "23 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Second order conditions provide a natural framework for establishing\nasymptotic results about estimators for tail related quantities. Such\nconditions are typically tailored to the estimation principle at hand, and may\nbe vastly different for estimators based on the block maxima (BM) method or the\npeak-over-threshold (POT) approach. In this paper we provide details on the\nrelationship between typical second order conditions for BM and POT methods in\nthe multivariate case. We show that the two conditions typically imply each\nother, but with a possibly different second order parameter. The latter implies\nthat, depending on the data generating process, one of the two methods can\nattain faster convergence rates than the other. The class of multivariate\nArchimax copulas is examined in detail; we find that this class contains models\nfor which the second order parameter is smaller for the BM method and vice\nversa. The theory is illustrated by a small simulation study.\n", "versions": [{"version": "v1", "created": "Fri, 31 Aug 2018 16:15:56 GMT"}], "update_date": "2018-09-03", "authors_parsed": [["B\u00fccher", "Axel", ""], ["Volgushev", "Stanislav", ""], ["Zou", "Nan", ""]]}]