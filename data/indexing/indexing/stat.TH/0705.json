[{"id": "0705.0069", "submitter": "Alessandro Tarozzi", "authors": "Xiaohong Chen, Han Hong, Alessandro Tarozzi", "title": "Semiparametric efficiency in GMM models with auxiliary data", "comments": "Published in at http://dx.doi.org/10.1214/009053607000000947 the\n  Annals of Statistics (http://www.imstat.org/aos/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2008, Vol. 36, No. 2, 808-843", "doi": "10.1214/009053607000000947", "report-no": "IMS-AOS-AOS0348", "categories": "math.ST stat.TH", "license": null, "abstract": "  We study semiparametric efficiency bounds and efficient estimation of\nparameters defined through general moment restrictions with missing data.\nIdentification relies on auxiliary data containing information about the\ndistribution of the missing variables conditional on proxy variables that are\nobserved in both the primary and the auxiliary database, when such distribution\nis common to the two data sets. The auxiliary sample can be independent of the\nprimary sample, or can be a subset of it. For both cases, we derive bounds when\nthe probability of missing data given the proxy variables is unknown, or known,\nor belongs to a correctly specified parametric family. We find that the\nconditional probability is not ancillary when the two samples are independent.\nFor all cases, we discuss efficient semiparametric estimators. An estimator\nbased on a conditional expectation projection is shown to require milder\nregularity conditions than one based on inverse probability weighting.\n", "versions": [{"version": "v1", "created": "Tue, 1 May 2007 04:21:06 GMT"}, {"version": "v2", "created": "Fri, 4 Apr 2008 14:15:21 GMT"}], "update_date": "2008-04-04", "authors_parsed": [["Chen", "Xiaohong", ""], ["Hong", "Han", ""], ["Tarozzi", "Alessandro", ""]]}, {"id": "0705.0209", "submitter": "Nathalie Villa", "authors": "Fabrice Rossi (INRIA Rocquencourt / INRIA Sophia Antipolis), Nathalie\n  Villa (GRIMM)", "title": "Support vector machine for functional data classification", "comments": "13 pages", "journal-ref": "Neurocomputing / EEG Neurocomputing 69, 7-9 (2006) 730-742", "doi": "10.1016/j.neucom.2005.12.010", "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": null, "abstract": "  In many applications, input data are sampled functions taking their values in\ninfinite dimensional spaces rather than standard vectors. This fact has complex\nconsequences on data analysis algorithms that motivate modifications of them.\nIn fact most of the traditional data analysis tools for regression,\nclassification and clustering have been adapted to functional inputs under the\ngeneral name of functional Data Analysis (FDA). In this paper, we investigate\nthe use of Support Vector Machines (SVMs) for functional data analysis and we\nfocus on the problem of curves discrimination. SVMs are large margin classifier\ntools based on implicit non linear mappings of the considered data into high\ndimensional spaces thanks to kernels. We show how to define simple kernels that\ntake into account the unctional nature of the data and lead to consistent\nclassification. Experiments conducted on real world data emphasize the benefit\nof taking into account some functional aspects of the problems.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2007 06:48:41 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Rossi", "Fabrice", "", "INRIA Rocquencourt / INRIA Sophia Antipolis"], ["Villa", "Nathalie", "", "GRIMM"]]}, {"id": "0705.0210", "submitter": "Nathalie Villa", "authors": "Nathalie Villa (GRIMM), Fabrice Rossi (INRIA Rocquencourt / INRIA\n  Sophia Antipolis)", "title": "Un r\\'esultat de consistance pour des SVM fonctionnels par interpolation\n  spline", "comments": "6 pages", "journal-ref": "Comptes Rendus de l Acad\\'emie des Sciences - Series I -\n  Mathematics 343, 8 (15/10/2006) 555-560", "doi": "10.1016/j.crma.2006.09.025", "report-no": null, "categories": "math.ST stat.TH", "license": null, "abstract": "  This Note proposes a new methodology for function classification with Support\nVector Machine (SVM). Rather than relying on projection on a truncated Hilbert\nbasis as in our previous work, we use an implicit spline interpolation that\nallows us to compute SVM on the derivatives of the studied functions. To that\nend, we propose a kernel defined directly on the discretizations of the\nobserved functions. We show that this method is universally consistent.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2007 06:52:13 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Villa", "Nathalie", "", "GRIMM"], ["Rossi", "Fabrice", "", "INRIA Rocquencourt / INRIA\n  Sophia Antipolis"]]}, {"id": "0705.0211", "submitter": "Nathalie Villa", "authors": "Louis Ferr\\'e (GRIMM), Nathalie Villa (GRIMM)", "title": "Multilayer Perceptron with Functional Inputs: an Inverse Regression\n  Approach", "comments": "17 pages", "journal-ref": "Scandinavian Journal of Statistics 33, 4 (12/2006) 807-823", "doi": "10.1111/j.1467-9469.2006.00496.x", "report-no": null, "categories": "math.ST stat.TH", "license": null, "abstract": "  Functional data analysis is a growing research field as more and more\npractical applications involve functional data. In this paper, we focus on the\nproblem of regression and classification with functional predictors: the model\nsuggested combines an efficient dimension reduction procedure [functional\nsliced inverse regression, first introduced by Ferr\\'e & Yao (Statistics, 37,\n2003, 475)], for which we give a regularized version, with the accuracy of a\nneural network. Some consistency results are given and the method is\nsuccessfully confronted to real-life data.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2007 06:56:00 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Ferr\u00e9", "Louis", "", "GRIMM"], ["Villa", "Nathalie", "", "GRIMM"]]}, {"id": "0705.0269", "submitter": "Robert Tibshirani", "authors": "Trevor Hastie, Jonathan Taylor, Robert Tibshirani, Guenther Walther", "title": "Forward stagewise regression and the monotone lasso", "comments": "Published at http://dx.doi.org/10.1214/07-EJS004 in the Electronic\n  Journal of Statistics (http://www.i-journals.org/ejs/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Electronic Journal of Statistics 2007, Vol. 1, 1-29", "doi": "10.1214/07-EJS004", "report-no": "IMS-EJS-EJS_2007_4", "categories": "math.ST stat.TH", "license": null, "abstract": "  We consider the least angle regression and forward stagewise algorithms for\nsolving penalized least squares regression problems. In Efron, Hastie,\nJohnstone & Tibshirani (2004) it is proved that the least angle regression\nalgorithm, with a small modification, solves the lasso regression problem. Here\nwe give an analogous result for incremental forward stagewise regression,\nshowing that it solves a version of the lasso problem that enforces\nmonotonicity. One consequence of this is as follows: while lasso makes optimal\nprogress in terms of reducing the residual sum-of-squares per unit increase in\n$L_1$-norm of the coefficient $\\beta$, forward stage-wise is optimal per unit\n$L_1$ arc-length traveled along the coefficient path. We also study a condition\nunder which the coefficient paths of the lasso are monotone, and hence the\ndifferent algorithms coincide. Finally, we compare the lasso and forward\nstagewise procedures in a simulation study involving a large number of\ncorrelated predictors.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2007 12:21:59 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Hastie", "Trevor", ""], ["Taylor", "Jonathan", ""], ["Tibshirani", "Robert", ""], ["Walther", "Guenther", ""]]}, {"id": "0705.0274", "submitter": "Dominique Picard", "authors": "G\\'erard Kerkyacharian, Pencho Petrushev, Dominique Picard, Thomas\n  Willer", "title": "Needlet algorithms for estimation in inverse problems", "comments": "Published at http://dx.doi.org/10.1214/07-EJS014 in the Electronic\n  Journal of Statistics (http://www.i-journals.org/ejs/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Electronic Journal of Statistics 2007, Vol. 1, 30-76", "doi": "10.1214/07-EJS014", "report-no": "IMS-EJS-EJS_2007_14", "categories": "math.ST stat.TH", "license": null, "abstract": "  We provide a new algorithm for the treatment of inverse problems which\ncombines the traditional SVD inversion with an appropriate thresholding\ntechnique in a well chosen new basis. Our goal is to devise an inversion\nprocedure which has the advantages of localization and multiscale analysis of\nwavelet representations without losing the stability and computability of the\nSVD decompositions. To this end we utilize the construction of localized frames\n(termed \"needlets\") built upon the SVD bases. We consider two different\nsituations: the \"wavelet\" scenario, where the needlets are assumed to behave\nsimilarly to true wavelets, and the \"Jacobi-type\" scenario, where we assume\nthat the properties of the frame truly depend on the SVD basis at hand (hence\non the operator). To illustrate each situation, we apply the estimation\nalgorithm respectively to the deconvolution problem and to the Wicksell\nproblem. In the latter case, where the SVD basis is a Jacobi polynomial basis,\nwe show that our scheme is capable of achieving rates of convergence which are\noptimal in the $L_2$ case, we obtain interesting rates of convergence for other\n$L_p$ norms which are new (to the best of our knowledge) in the literature, and\nwe also give a simulation study showing that the NEED-D estimator outperforms\nother standard algorithms in almost all situations.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2007 12:46:00 GMT"}], "update_date": "2016-08-14", "authors_parsed": [["Kerkyacharian", "G\u00e9rard", ""], ["Petrushev", "Pencho", ""], ["Picard", "Dominique", ""], ["Willer", "Thomas", ""]]}, {"id": "0705.0456", "submitter": "Emilio Porcu", "authors": "Christian Berg, Jorge Mateu, Emilio Porcu", "title": "The Dagum family of isotropic correlation functions", "comments": "Published in at http://dx.doi.org/10.3150/08-BEJ139 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2008, Vol. 14, No. 4, 1134-1149", "doi": "10.3150/08-BEJ139", "report-no": "IMS-BEJ-BEJ139", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A function $\\rho:[0,\\infty)\\to(0,1]$ is a completely monotonic function if\nand only if $\\rho(\\Vert\\mathbf{x}\\Vert^2)$ is positive definite on\n$\\mathbb{R}^d$ for all $d$ and thus it represents the correlation function of a\nweakly stationary and isotropic Gaussian random field. Radial positive definite\nfunctions are also of importance as they represent characteristic functions of\nspherically symmetric probability distributions. In this paper, we analyze the\nfunction \\[\\rho(\\beta ,\\gamma)(x)=1-\\biggl(\\frac{x^{\\beta}}{1+x^{\\beta}}\\biggr\n)^{\\gamma},\\qquad x\\ge 0, \\beta,\\gamma>0,\\] called the Dagum function, and show\nthose ranges for which this function is completely monotonic, that is, positive\ndefinite, on any $d$-dimensional Euclidean space. Important relations arise\nwith other families of completely monotonic and logarithmically completely\nmonotonic functions.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2007 13:08:21 GMT"}, {"version": "v2", "created": "Mon, 17 Nov 2008 08:48:44 GMT"}], "update_date": "2008-11-17", "authors_parsed": [["Berg", "Christian", ""], ["Mateu", "Jorge", ""], ["Porcu", "Emilio", ""]]}, {"id": "0705.0503", "submitter": "Stefano M. Iacus", "authors": "Alessandro De Gregorio, Stefano M. Iacus", "title": "Change point estimation for the telegraph process observed at discrete\n  times", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR q-fin.ST stat.ME stat.TH", "license": null, "abstract": "  The telegraph process models a random motion with finite velocity and it is\nusually proposed as an alternative to diffusion models. The process describes\nthe position of a particle moving on the real line, alternatively with constant\nvelocity $+ v$ or $-v$. The changes of direction are governed by an homogeneous\nPoisson process with rate $\\lambda >0.$ In this paper, we consider a change\npoint estimation problem for the rate of the underlying Poisson process by\nmeans of least squares method. The consistency and the rate of convergence for\nthe change point estimator are obtained and its asymptotic distribution is\nderived. Applications to real data are also presented.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2007 16:59:59 GMT"}], "update_date": "2008-12-02", "authors_parsed": [["De Gregorio", "Alessandro", ""], ["Iacus", "Stefano M.", ""]]}, {"id": "0705.1235", "submitter": "Thanh Mai Pham Ngoc", "authors": "Thanh Mai Pham Ngoc (PMA)", "title": "Statistical minimax approach of the Hausdorff moment problem", "comments": "21 pages", "journal-ref": "Inverse Problems (2008) 24 045018", "doi": "10.1088/0266-5611/24/4/045018", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of this paper is to study the problem of estimating a compactly\nsupported density of probability from noisy observations of its moments. In\nfact, we provide a statistical approach to the famous Hausdorff classical\nmoment problem. We prove an upper bound and a lower bound on the rate of\nconvergence of the mean squared error showing that the considered estimator\nattains minimax rate over the corresponding smoothness classes.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2007 13:07:54 GMT"}, {"version": "v2", "created": "Thu, 10 May 2007 15:18:13 GMT"}, {"version": "v3", "created": "Thu, 23 Apr 2009 06:10:22 GMT"}], "update_date": "2013-10-09", "authors_parsed": [["Ngoc", "Thanh Mai Pham", "", "PMA"]]}, {"id": "0705.1268", "submitter": "Fabio Gobbi", "authors": "Fabio Gobbi, Cecilia Mancini", "title": "Diffusion covariation and co-jumps in bidimensional asset price\n  processes with stochastic volatility and infinite activity Levy jumps", "comments": null, "journal-ref": null, "doi": "10.1117/12.724566", "report-no": null, "categories": "math.PR math.ST stat.TH", "license": null, "abstract": "  In this paper we consider two processes driven by diffusions and jumps. The\njump components are Levy processes and they can both have finite activity and\ninfinite activity. Given discrete observations we estimate the covariation\nbetween the two diffusion parts and the co-jumps. The detection of the co-jumps\nallows to gain insight in the dependence structure of the jump components and\nhas important applications in finance. Our estimators are based on a threshold\nprinciple allowing to isolate the jumps. This work follows Gobbi and Mancini\n(2006) where the asymptotic normality for the estimator of the covariation,\nwith convergence speed given by the squared root of h, was obtained when the\njump components have finite activity. Here we show that the speed is the\nsquared root of h only when the activity of the jump components is moderate.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2007 12:13:25 GMT"}], "update_date": "2009-11-13", "authors_parsed": [["Gobbi", "Fabio", ""], ["Mancini", "Cecilia", ""]]}, {"id": "0705.1270", "submitter": "Romain Neugebauer", "authors": "Romain Neugebauer, Mark J. van der Laan, Marshall M. Joffe, Ira B.\n  Tager", "title": "Causal inference in longitudinal studies with history-restricted\n  marginal structural models", "comments": "Published at http://dx.doi.org/10.1214/07-EJS050 in the Electronic\n  Journal of Statistics (http://www.i-journals.org/ejs/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Electronic Journal of Statistics 2007, Vol. 1, 119-154", "doi": "10.1214/07-EJS050", "report-no": "IMS-EJS-EJS_2007_50", "categories": "math.ST stat.ME stat.TH", "license": null, "abstract": "  A new class of Marginal Structural Models (MSMs), History-Restricted MSMs\n(HRMSMs), was recently introduced for longitudinal data for the purpose of\ndefining causal parameters which may often be better suited for public health\nresearch or at least more practicable than MSMs \\citejoffe,feldman. HRMSMs\nallow investigators to analyze the causal effect of a treatment on an outcome\nbased on a fixed, shorter and user-specified history of exposure compared to\nMSMs. By default, the latter represent the treatment causal effect of interest\nbased on a treatment history defined by the treatments assigned between the\nstudy's start and outcome collection. We lay out in this article the formal\nstatistical framework behind HRMSMs. Beyond allowing a more flexible causal\nanalysis, HRMSMs improve computational tractability and mitigate statistical\npower concerns when designing longitudinal studies. We also develop three\nconsistent estimators of HRMSM parameters under sufficient model assumptions:\nthe Inverse Probability of Treatment Weighted (IPTW), G-computation and Double\nRobust (DR) estimators. In addition, we show that the assumptions commonly\nadopted for identification and consistent estimation of MSM parameters\n(existence of counterfactuals, consistency, time-ordering and sequential\nrandomization assumptions) also lead to identification and consistent\nestimation of HRMSM parameters.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2007 12:22:37 GMT"}], "update_date": "2009-09-29", "authors_parsed": [["Neugebauer", "Romain", ""], ["van der Laan", "Mark J.", ""], ["Joffe", "Marshall M.", ""], ["Tager", "Ira B.", ""]]}, {"id": "0705.1613", "submitter": "Dhafer Malouche DM", "authors": "Dhafer Malouche", "title": "Determining full conditional independence by low-order conditioning", "comments": "Published in at http://dx.doi.org/10.3150/09-BEJ193 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2009, Vol. 15, No. 4, 1179-1189", "doi": "10.3150/09-BEJ193", "report-no": "IMS-BEJ-BEJ193", "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A concentration graph associated with a random vector is an undirected graph\nwhere each vertex corresponds to one random variable in the vector. The absence\nof an edge between any pair of vertices (or variables) is equivalent to full\nconditional independence between these two variables given all the other\nvariables. In the multivariate Gaussian case, the absence of an edge\ncorresponds to a zero coefficient in the precision matrix, which is the inverse\nof the covariance matrix. It is well known that this concentration graph\nrepresents some of the conditional independencies in the distribution of the\nassociated random vector. These conditional independencies correspond to the\n\"separations\" or absence of edges in that graph. In this paper we assume that\nthere are no other independencies present in the probability distribution than\nthose represented by the graph. This property is called the perfect\nMarkovianity of the probability distribution with respect to the associated\nconcentration graph. We prove in this paper that this particular concentration\ngraph, the one associated with a perfect Markov distribution, can be determined\nby only conditioning on a limited number of variables. We demonstrate that this\nnumber is equal to the maximum size of the minimal separators in the\nconcentration graph.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2007 09:59:53 GMT"}, {"version": "v2", "created": "Fri, 13 Feb 2009 14:24:07 GMT"}, {"version": "v3", "created": "Sun, 20 Dec 2009 07:00:47 GMT"}, {"version": "v4", "created": "Thu, 14 Jan 2010 07:45:38 GMT"}], "update_date": "2010-01-14", "authors_parsed": [["Malouche", "Dhafer", ""]]}, {"id": "0705.1701", "submitter": "P\\'ech\\'e Sandrine", "authors": "Sandrine Peche", "title": "Universality results for largest eigenvalues of some sample covariance\n  matrix ensembles", "comments": "3 figures 47 pages Simulations have been included, a mistake in the\n  computation of the variance has been corrected (Section 2.5)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": null, "abstract": "  For sample covariance matrices with iid entries with sub-Gaussian tails, when\nboth the number of samples and the number of variables become large and the\nratio approaches to one, it is a well-known result of A. Soshnikov that the\nlimiting distribution of the largest eigenvalue is same as the of Gaussian\nsamples. In this paper, we extend this result to two cases. The first case is\nwhen the ratio approaches to an arbitrary finite value. The second case is when\nthe ratio becomes infinity or arbitrarily small.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2007 18:06:10 GMT"}, {"version": "v2", "created": "Thu, 21 Jun 2007 03:35:36 GMT"}], "update_date": "2007-06-21", "authors_parsed": [["Peche", "Sandrine", ""]]}, {"id": "0705.1766", "submitter": "Teo Sharia", "authors": "Teo Sharia", "title": "Recursive Parameter Estimation: Convergence", "comments": "25 pages with 1 postscript figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": null, "abstract": "  We consider estimation procedures which are recursive in the sense that each\nsuccessive estimator is obtained from the previous one by a simple adjustment.\nWe propose a wide class of recursive estimation procedures for the general\nstatistical model and study convergence.\n", "versions": [{"version": "v1", "created": "Sat, 12 May 2007 11:38:51 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Sharia", "Teo", ""]]}, {"id": "0705.1767", "submitter": "Teo Sharia", "authors": "Teo Sharia", "title": "Rate of Convergence in Recursive Parameter Estimation procedures", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": null, "abstract": "  We consider estimation procedures which are recursive in the sense that each\nsuccessive estimator is obtained from the previous one by a simple adjustment.\nWe study rate of convergence of recursive estimation procedures for the general\nstatistical model.\n", "versions": [{"version": "v1", "created": "Sat, 12 May 2007 11:51:57 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Sharia", "Teo", ""]]}, {"id": "0705.1783", "submitter": "Teo Sharia", "authors": "Teo Sharia", "title": "Recursive Parameter Estimation: Asymptotic expansion", "comments": "30 pages with 1 postscript figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": null, "abstract": "  We consider estimation procedures which are recursive in the sense that each\nsuccessive estimator is obtained from the previous one by a simple adjustment.\nThe model considered in the paper is very general as we do not impose any\npreliminary restrictions on the probabilistic nature of the observation process\nand cover a wide class of nonlinear recursive procedures. In this paper we\nstudy asymptotic behaviour of the recursive estimators. The results of the\npaper can be used to determine the form of a recursive procedure which is\nexpected to have the same asymptotic properties as the corresponding\nnon-recursive one defined as a solution of the corresponding estimating\nequation.\n", "versions": [{"version": "v1", "created": "Sat, 12 May 2007 17:02:42 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Sharia", "Teo", ""]]}, {"id": "0705.1794", "submitter": "Teo Sharia", "authors": "N. Lazrieva, T. Sharia and T. Toronjadze", "title": "Semimartingale Stochastic Approximation Procedures and Recursive\n  Estimation", "comments": "62 pages, no figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": null, "abstract": "  The semimartingale stochastic approximation procedure, namely, the\nRobbins-Monro type SDE is introduced which naturally includes both generalized\nstochastic approximation algorithms with martingale noises and recursive\nparameter estimation procedures for statistical models associated with\nsemimartingales. General results concerning the asymptotic behaviour of the\nsolution are presented. In particular, the conditions ensuring the convergence,\nrate of convergence and asymptotic expansion are established. The results\nconcerning the Polyak weighted averaging procedure are also presented.\n", "versions": [{"version": "v1", "created": "Sat, 12 May 2007 19:47:15 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Lazrieva", "N.", ""], ["Sharia", "T.", ""], ["Toronjadze", "T.", ""]]}, {"id": "0705.1927", "submitter": "Fanny Godet", "authors": "Fanny Godet (LMJL)", "title": "Linear Prediction of Long-Memory Processes: Asymptotic Results on\n  Mean-squared Errors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": null, "abstract": "  We present two approaches for linear prediction of long-memory time series.\nThe first approach consists in truncating the Wiener-Kolmogorov predictor by\nrestricting the observations to the last $k$ terms, which are the only\navailable values in practice. We derive the asymptotic behaviour of the\nmean-squared error as $k$ tends to $ + \\infty$. By contrast, the second\napproach is non-parametric. An AR($k$) model is fitted to the long-memory time\nseries and we study the error that arises in this misspecified model.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2007 12:28:03 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Godet", "Fanny", "", "LMJL"]]}, {"id": "0705.2262", "submitter": "Panagiotis Stinis", "authors": "Dror Givon, Panagiotis Stinis, and Jonathan Weare", "title": "Variance reduction for particle filters of systems with time-scale\n  separation", "comments": "Changed content, added examples and references", "journal-ref": null, "doi": null, "report-no": "LBNL-62141", "categories": "math.NA math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a particle filter construction for a system that exhibits\ntime-scale separation. The separation of time-scales allows two simplifications\nthat we exploit: i) The use of the averaging principle for the dimensional\nreduction of the system needed to solve for each particle and ii) the\nfactorization of the transition probability which allows the\nRao-Blackwellization of the filtering step. Both simplifications can be\nimplemented using the coarse projective integration framework. The resulting\nparticle filter is faster and has smaller variance than the particle filter\nbased on the original system. The method is tested on a multiscale stochastic\ndifferential equation and on a multiscale pure jump diffusion motivated by\nchemical reactions.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2007 00:46:09 GMT"}, {"version": "v2", "created": "Wed, 19 Dec 2007 01:41:34 GMT"}, {"version": "v3", "created": "Wed, 4 Jun 2008 21:41:48 GMT"}], "update_date": "2008-06-05", "authors_parsed": [["Givon", "Dror", ""], ["Stinis", "Panagiotis", ""], ["Weare", "Jonathan", ""]]}, {"id": "0705.2540", "submitter": "Leo Butler", "authors": "Leo T. Butler, Boris Levit", "title": "A Bayesian approach to the estimation of maps between riemannian\n  manifolds", "comments": "20 pages, no figures published version includes correction to eq.s\n  31, 41, 43", "journal-ref": "Mathematical Methods of Statistics. 16(4):1--17, 2007", "doi": "10.3103/S1066530707040011", "report-no": null, "categories": "math.ST stat.TH", "license": null, "abstract": "  Let \\Theta be a smooth compact oriented manifold without boundary, embedded\nin a euclidean space and let \\gamma be a smooth map \\Theta into a riemannian\nmanifold \\Lambda. An unknown state \\theta \\in \\Theta is observed via\nX=\\theta+\\epsilon \\xi where \\epsilon>0 is a small parameter and \\xi is a white\nGaussian noise. For a given smooth prior on \\Theta and smooth estimator g of\nthe map \\gamma we derive a second-order asymptotic expansion for the related\nBayesian risk. The calculation involves the geometry of the underlying spaces\n\\Theta and \\Lambda, in particular, the integration-by-parts formula. Using this\nresult, a second-order minimax estimator of \\gamma is found based on the modern\ntheory of harmonic maps and hypo-elliptic differential operators.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2007 15:01:50 GMT"}, {"version": "v2", "created": "Tue, 25 Mar 2008 17:33:12 GMT"}], "update_date": "2008-03-25", "authors_parsed": [["Butler", "Leo T.", ""], ["Levit", "Boris", ""]]}, {"id": "0705.2605", "submitter": "N. Raj Rao", "authors": "N. Raj Rao and Alan Edelman", "title": "Sample eigenvalue based detection of high dimensional signals in white\n  noise using relatively few samples", "comments": "Submitted to the IEEE Transactions on Signal Processing (In Review)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": null, "abstract": "  We present a mathematically justifiable, computationally simple, sample\neigenvalue based procedure for estimating the number of high-dimensional\nsignals in white noise using relatively few samples. The main motivation for\nconsidering a sample eigenvalue based scheme is the computational simplicity\nand the robustness to eigenvector modelling errors which are can adversely\nimpact the performance of estimators that exploit information in the sample\neigenvectors.\n  There is, however, a price we pay by discarding the information in the sample\neigenvectors; we highlight a fundamental asymptotic limit of sample eigenvalue\nbased detection of weak/closely spaced high-dimensional signals from a limited\nsample size. This motivates our heuristic definition of the effective number of\nidentifiable signals which is equal to the number of \"signal\" eigenvalues of\nthe population covariance matrix which exceed the noise variance by a factor\nstrictly greater than 1+sqrt(Dimensionality of the system/Sample size). The\nfundamental asymptotic limit brings into sharp focus why, when there are too\nfew samples available so that the effective number of signals is less than the\nactual number of signals, underestimation of the model order is unavoidable (in\nan asymptotic sense) when using any sample eigenvalue based detection scheme,\nincluding the one proposed herein. The analysis reveals why adding more sensors\ncan only exacerbate the situation. Numerical simulations are used to\ndemonstrate that the proposed estimator consistently estimates the true number\nof signals in the dimension fixed, large sample size limit and the effective\nnumber of identifiable signals in the large dimension, large sample size limit.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2007 21:43:41 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Rao", "N. Raj", ""], ["Edelman", "Alan", ""]]}, {"id": "0705.2701", "submitter": "Philippe Soulier", "authors": "Meng-Chen Hsieh, Clifford M. Hurvich (IOMS), Philippe Soulier\n  (MODAL'X)", "title": "Asymptotics for Duration-Driven Long Range Dependent Processes", "comments": null, "journal-ref": "Journal of Econometrics Volume 141, Issue 2, December 2007, Pages\n  913-949", "doi": "10.1016/j.jeconom.2006.12.001", "report-no": null, "categories": "math.ST stat.TH", "license": null, "abstract": "  We consider processes with second order long range dependence resulting from\nheavy tailed durations. We refer to this phenomenon as duration-driven long\nrange dependence (DDLRD), as opposed to the more widely studied linear long\nrange dependence based on fractional differencing of an $iid$ process. We\nconsider in detail two specific processes having DDLRD, originally presented in\nTaqqu and Levy (1986), and Parke (1999). For these processes, we obtain the\nlimiting distribution of suitably standardized discrete Fourier transforms\n(DFTs) and sample autocovariances. At low frequencies, the standardized DFTs\nconverge to a stable law, as do the standardized sample autocovariances at\nfixed lags. Finite collections of standardized sample autocovariances at a\nfixed set of lags converge to a degenerate distribution. The standardized DFTs\nat high frequencies converge to a Gaussian law. Our asymptotic results are\nstrikingly similar for the two DDLRD processes studied. We calibrate our\nasymptotic results with a simulation study which also investigates the\nproperties of the semiparametric log periodogram regression estimator of the\nmemory parameter.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2007 13:47:49 GMT"}], "update_date": "2012-09-19", "authors_parsed": [["Hsieh", "Meng-Chen", "", "IOMS"], ["Hurvich", "Clifford M.", "", "IOMS"], ["Soulier", "Philippe", "", "MODAL'X"]]}, {"id": "0705.3139", "submitter": "Valentin Konakov", "authors": "Valentin Konakov, Enno Mammen", "title": "Small time Edgeworth-type expansions for weakly convergent\n  nonhomogeneous Markov chains", "comments": "58 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": null, "abstract": "  We consider triangular arrays of Markov chains that converge weakly to a\ndiffusion process. Second order Edgeworth type expansions for transition\ndensities are proved. The paper differs from recent results in two respects. We\nallow nonhomogeneous diffusion limits and we treat transition densities with\ntime lag converging to zero. Small time asymptotics are motivated by\nstatistical applications and by resulting approximations for the joint density\nof diffusion values at an increasing grid of points.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2007 11:50:22 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Konakov", "Valentin", ""], ["Mammen", "Enno", ""]]}, {"id": "0705.3308", "submitter": "Marten Wegkamp", "authors": "Florentina Bunea, Alexandre Tsybakov, Marten Wegkamp", "title": "Sparsity oracle inequalities for the Lasso", "comments": "Published at http://dx.doi.org/10.1214/07-EJS008 in the Electronic\n  Journal of Statistics (http://www.i-journals.org/ejs/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Electronic Journal of Statistics 2007, Vol. 1, 169-194", "doi": "10.1214/07-EJS008", "report-no": "IMS-EJS-EJS_2007_8", "categories": "math.ST stat.TH", "license": null, "abstract": "  This paper studies oracle properties of $\\ell_1$-penalized least squares in\nnonparametric regression setting with random design. We show that the penalized\nleast squares estimator satisfies sparsity oracle inequalities, i.e., bounds in\nterms of the number of non-zero components of the oracle vector. The results\nare valid even when the dimension of the model is (much) larger than the sample\nsize and the regression matrix is not positive definite. They can be applied to\nhigh-dimensional linear regression, to nonparametric adaptive regression\nestimation and to the problem of aggregation of arbitrary estimators.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2007 08:53:38 GMT"}], "update_date": "2007-08-03", "authors_parsed": [["Bunea", "Florentina", ""], ["Tsybakov", "Alexandre", ""], ["Wegkamp", "Marten", ""]]}, {"id": "0705.3482", "submitter": "Jan Johannes", "authors": "Jan Johannes", "title": "Deconvolution with unknown error distribution", "comments": "Published in at http://dx.doi.org/10.1214/08-AOS652 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2009, Vol. 37, No. 5A, 2301-2323", "doi": "10.1214/08-AOS652", "report-no": "IMS-AOS-AOS652", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimating a density $f_X$ using a sample\n$Y_1,...,Y_n$ from $f_Y=f_X\\star f_{\\epsilon}$, where $f_{\\epsilon}$ is an\nunknown density. We assume that an additional sample\n$\\epsilon_1,...,\\epsilon_m$ from $f_{\\epsilon}$ is observed. Estimators of\n$f_X$ and its derivatives are constructed by using nonparametric estimators of\n$f_Y$ and $f_{\\epsilon}$ and by applying a spectral cut-off in the Fourier\ndomain. We derive the rate of convergence of the estimators in case of a known\nand unknown error density $f_{\\epsilon}$, where it is assumed that $f_X$\nsatisfies a polynomial, logarithmic or general source condition. It is shown\nthat the proposed estimators are asymptotically optimal in a minimax sense in\nthe models with known or unknown error density, if the density $f_X$ belongs to\na Sobolev space $H_{\\mathbh p}$ and $f_{\\epsilon}$ is ordinary smooth or\nsupersmooth.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2007 23:06:26 GMT"}, {"version": "v2", "created": "Fri, 21 Aug 2009 13:06:20 GMT"}], "update_date": "2009-08-21", "authors_parsed": [["Johannes", "Jan", ""]]}, {"id": "0705.3590", "submitter": "Luca Giuzzi", "authors": "A. Aguglia, L. Giuzzi", "title": "Orthogonal arrays from Hermitian varieties", "comments": "Corrected a typo on page 5. 14 Pages", "journal-ref": "Innovations in Incidence Geometry 5: 129-144 (2007)", "doi": null, "report-no": null, "categories": "math.CO math.ST stat.TH", "license": null, "abstract": "  An orthogonal array OA(q^{2n-1},q^{2n-2}, q,2) is constructed from the action\nof a subset of PGL(n+1,q^2) on some non--degenerate Hermitian varieties in\nPG(n,q^2). It is also shown that the rows of this orthogonal array correspond\nto some blocks of an affine design, which for q> 2 is a non--classical model of\nthe affine space AG(2n-1,q).\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2007 14:20:57 GMT"}, {"version": "v2", "created": "Mon, 4 Jun 2007 21:08:32 GMT"}, {"version": "v3", "created": "Tue, 3 Jul 2007 16:05:06 GMT"}], "update_date": "2009-07-18", "authors_parsed": [["Aguglia", "A.", ""], ["Giuzzi", "L.", ""]]}, {"id": "0705.3693", "submitter": "Jan Mandel", "authors": "Jonathan D. Beezley, Jan Mandel", "title": "Morphing Ensemble Kalman Filters", "comments": "17 pages, 7 figures. Added DDDAS references to the introduction", "journal-ref": null, "doi": "10.1111/j.1600-0870.2007.00275.x", "report-no": "UCDHSC CCM Report 240", "categories": "math.DS cs.CV math.ST physics.ao-ph stat.ME stat.TH", "license": null, "abstract": "  A new type of ensemble filter is proposed, which combines an ensemble Kalman\nfilter (EnKF) with the ideas of morphing and registration from image\nprocessing. This results in filters suitable for nonlinear problems whose\nsolutions exhibit moving coherent features, such as thin interfaces in wildfire\nmodeling. The ensemble members are represented as the composition of one common\nstate with a spatial transformation, called registration mapping, plus a\nresidual. A fully automatic registration method is used that requires only\ngridded data, so the features in the model state do not need to be identified\nby the user. The morphing EnKF operates on a transformed state consisting of\nthe registration mapping and the residual. Essentially, the morphing EnKF uses\nintermediate states obtained by morphing instead of linear combinations of the\nstates.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2007 05:46:33 GMT"}, {"version": "v2", "created": "Sun, 27 May 2007 19:38:42 GMT"}, {"version": "v3", "created": "Wed, 8 Aug 2007 17:17:36 GMT"}, {"version": "v4", "created": "Thu, 23 Aug 2007 07:45:33 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Beezley", "Jonathan D.", ""], ["Mandel", "Jan", ""]]}, {"id": "0705.3851", "submitter": "Jan Mandel", "authors": "Deborah H. Glueck, Anis Karimpour-Fard, Jan Mandel, Larry Hunter,\n  Keith E. Muller", "title": "Fast computation by block permanents of cumulative distribution\n  functions of order statistics from several populations", "comments": "21 pages, 3 figures", "journal-ref": "Communications in Statistics - Theory and Methods 37 (18):\n  2815-2824 2008", "doi": "10.1080/03610920802001896", "report-no": null, "categories": "math.ST math.PR stat.CO stat.TH", "license": null, "abstract": "  The joint cumulative distribution function for order statistics arising from\nseveral different populations is given in terms of the distribution function of\nthe populations. The computational cost of the formula in the case of two\npopulations is still exponential in the worst case, but it is a dramatic\nimprovement compared to the general formula by Bapat and Beg. In the case when\nonly the joint distribution function of a subset of the order statistics of\nfixed size is needed, the complexity is polynomial, for the case of two\npopulations.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2007 20:32:53 GMT"}], "update_date": "2008-11-27", "authors_parsed": [["Glueck", "Deborah H.", ""], ["Karimpour-Fard", "Anis", ""], ["Mandel", "Jan", ""], ["Hunter", "Larry", ""], ["Muller", "Keith E.", ""]]}, {"id": "0705.4230", "submitter": "Aiyou Chen", "authors": "Aiyou Chen, Peter J. Bickel", "title": "Efficient independent component analysis", "comments": "Published at http://dx.doi.org/10.1214/009053606000000939 in the\n  Annals of Statistics (http://www.imstat.org/aos/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2006, Vol. 34, No. 6, 2825-2855", "doi": "10.1214/009053606000000939", "report-no": "IMS-AOS-AOS0205", "categories": "stat.ME math.ST stat.ML stat.TH", "license": null, "abstract": "  Independent component analysis (ICA) has been widely used for blind source\nseparation in many fields such as brain imaging analysis, signal processing and\ntelecommunication. Many statistical techniques based on M-estimates have been\nproposed for estimating the mixing matrix. Recently, several nonparametric\nmethods have been developed, but in-depth analysis of asymptotic efficiency has\nnot been available. We analyze ICA using semiparametric theories and propose a\nstraightforward estimate based on the efficient score function by using\nB-spline approximations. The estimate is asymptotically efficient under\nmoderate conditions and exhibits better performance than standard ICA methods\nin a variety of simulations.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2007 15:15:33 GMT"}, {"version": "v2", "created": "Thu, 2 Aug 2007 06:04:57 GMT"}], "update_date": "2009-09-29", "authors_parsed": [["Chen", "Aiyou", ""], ["Bickel", "Peter J.", ""]]}, {"id": "0705.4312", "submitter": "Marcus Hutter", "authors": "Alberto Piatti and Marco Zaffalon and Fabio Trojani and Marcus Hutter", "title": "Learning about a Categorical Latent Variable under Prior Near-Ignorance", "comments": "15 LaTeX pages", "journal-ref": "Proc. 5th International Symposium on Imprecise Probability:\n  Theories and Applications (ISIPTA 2007) pages 357-364", "doi": null, "report-no": "IDSIA-05-07", "categories": "math.PR math.ST stat.TH", "license": null, "abstract": "  It is well known that complete prior ignorance is not compatible with\nlearning, at least in a coherent theory of (epistemic) uncertainty. What is\nless widely known, is that there is a state similar to full ignorance, that\nWalley calls near-ignorance, that permits learning to take place. In this paper\nwe provide new and substantial evidence that also near-ignorance cannot be\nreally regarded as a way out of the problem of starting statistical inference\nin conditions of very weak beliefs. The key to this result is focusing on a\nsetting characterized by a variable of interest that is latent. We argue that\nsuch a setting is by far the most common case in practice, and we show, for the\ncase of categorical latent variables (and general manifest variables) that\nthere is a sufficient condition that, if satisfied, prevents learning to take\nplace under prior near-ignorance. This condition is shown to be easily\nsatisfied in the most common statistical problems.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2007 22:38:10 GMT"}], "update_date": "2008-06-26", "authors_parsed": [["Piatti", "Alberto", ""], ["Zaffalon", "Marco", ""], ["Trojani", "Fabio", ""], ["Hutter", "Marcus", ""]]}, {"id": "0705.4476", "submitter": "Aiyou Chen", "authors": "Aiyou Chen, Jin Cao", "title": "Network tomography based on 1-D projections", "comments": "Published at http://dx.doi.org/10.1214/074921707000000238 in the IMS\n  Lecture Notes Monograph Series\n  (http://www.imstat.org/publications/lecnotes.htm) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "IMS Lecture Notes Monograph Series 2007, Vol. 54, 45-61", "doi": "10.1214/074921707000000238", "report-no": "IMS-LNMS54-LNMS5404", "categories": "stat.AP math.ST stat.ME stat.TH", "license": null, "abstract": "  Network tomography has been regarded as one of the most promising\nmethodologies for performance evaluation and diagnosis of the massive and\ndecentralized Internet. This paper proposes a new estimation approach for\nsolving a class of inverse problems in network tomography, based on marginal\ndistributions of a sequence of one-dimensional linear projections of the\nobserved data. We give a general identifiability result for the proposed method\nand study the design issue of these one dimensional projections in terms of\nstatistical efficiency. We show that for a simple Gaussian tomography model,\nthere is an optimal set of one-dimensional projections such that the estimator\nobtained from these projections is asymptotically as efficient as the maximum\nlikelihood estimator based on the joint distribution of the observed data. For\npractical applications, we carry out simulation studies of the proposed method\nfor two instances of network tomography. The first is for traffic demand\ntomography using a Gaussian Origin-Destination traffic model with a power\nrelation between its mean and variance, and the second is for network delay\ntomography where the link delays are to be estimated from the end-to-end path\ndelays. We compare estimators obtained from our method and that obtained from\nusing the joint distribution and other lower dimensional projections, and show\nthat in both cases, the proposed method yields satisfactory results.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2007 20:52:27 GMT"}, {"version": "v2", "created": "Wed, 8 Aug 2007 07:08:12 GMT"}], "update_date": "2007-08-22", "authors_parsed": [["Chen", "Aiyou", ""], ["Cao", "Jin", ""]]}, {"id": "0705.4485", "submitter": "Edoardo Airoldi", "authors": "Edoardo M Airoldi, David M Blei, Stephen E Fienberg, Eric P Xing", "title": "Mixed membership stochastic blockmodels", "comments": "46 pages, 14 figures, 3 tables", "journal-ref": "Journal of Machine Learning Research, 9, 1981-2014.", "doi": null, "report-no": null, "categories": "stat.ME cs.LG math.ST physics.soc-ph stat.ML stat.TH", "license": null, "abstract": "  Observations consisting of measurements on relationships for pairs of objects\narise in many settings, such as protein interaction and gene regulatory\nnetworks, collections of author-recipient email, and social networks. Analyzing\nsuch data with probabilisic models can be delicate because the simple\nexchangeability assumptions underlying many boilerplate models no longer hold.\nIn this paper, we describe a latent variable model of such data called the\nmixed membership stochastic blockmodel. This model extends blockmodels for\nrelational data to ones which capture mixed membership latent relational\nstructure, thus providing an object-specific low-dimensional representation. We\ndevelop a general variational inference algorithm for fast approximate\nposterior inference. We explore applications to social and protein interaction\nnetworks.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2007 23:22:59 GMT"}], "update_date": "2010-02-22", "authors_parsed": [["Airoldi", "Edoardo M", ""], ["Blei", "David M", ""], ["Fienberg", "Stephen E", ""], ["Xing", "Eric P", ""]]}, {"id": "0705.4516", "submitter": "Mathias Drton", "authors": "Mathias Drton", "title": "Multiple solutions to the likelihood equations in the Behrens-Fisher\n  problem", "comments": null, "journal-ref": "Statistics & Probability Letters 2008, Vol. 78, No. 18, 3288-3293", "doi": "10.1016/j.spl.2008.06.012", "report-no": null, "categories": "math.ST stat.TH", "license": null, "abstract": "  The Behrens-Fisher problem concerns testing the equality of the means of two\nnormal populations with possibly different variances. The null hypothesis in\nthis problem induces a statistical model for which the likelihood function may\nhave more than one local maximum. We show that such multimodality contradicts\nthe null hypothesis in the sense that if this hypothesis is true then the\nprobability of multimodality converges to zero when both sample sizes tend to\ninfinity. Additional results include a finite-sample bound on the probability\nof multimodality under the null and asymptotics for the probability of\nmultimodality under the alternative.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2007 04:55:14 GMT"}], "update_date": "2010-03-04", "authors_parsed": [["Drton", "Mathias", ""]]}]