[{"id": "1502.00043", "submitter": "Markus Bibinger", "authors": "Markus Bibinger, Moritz Jirak and Mathias Vetter", "title": "Nonparametric change-point analysis of volatility", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work develops change-point methods for statistics of high-frequency\ndata. The main interest is in the volatility of an It\\^{o} semi-martingale, the\nlatter being discretely observed over a fixed time horizon. We construct a\nminimax-optimal test to discriminate continuous paths from paths comprising\nvolatility jumps. This is embedded into a more general theory to infer the\nsmoothness of volatilities. In a high-frequency framework we prove weak\nconvergence of the test statistic under the hypothesis to an extreme value\ndistribution. Moreover, we develop methods to infer changes in the Hurst\nparameter of fractional volatility processes. A simulation study demonstrates\nthe practical value in finite-sample applications.\n", "versions": [{"version": "v1", "created": "Fri, 30 Jan 2015 23:29:40 GMT"}, {"version": "v2", "created": "Tue, 12 Jan 2016 07:41:21 GMT"}], "update_date": "2016-01-13", "authors_parsed": [["Bibinger", "Markus", ""], ["Jirak", "Moritz", ""], ["Vetter", "Mathias", ""]]}, {"id": "1502.00095", "submitter": "Ieva Grublyt\\.e", "authors": "Paul Doukhan, Ieva Grublyt\\.e, Donatas Surgailis", "title": "A nonlinear model for long memory conditional heteroscedasticity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss a class of conditionally heteroscedastic time series models\nsatisfying the equation $r_t= \\zeta_t \\sigma_t$, where $\\zeta_t$ are\nstandardized i.i.d. r.v.'s and the conditional standard deviation $\\sigma_t$ is\na nonlinear function $Q$ of inhomogeneous linear combination of past values\n$r_s, s<t$ with coefficients $b_j$. The existence of stationary solution $r_t$\nwith finite $p$th moment, $0< p < \\infty $ is obtained under some conditions on\n$Q, b_j$ and $p$th moment of $\\zeta_0$. Weak dependence properties of $r_t$ are\nstudied, including the invariance principle for partial sums of Lipschitz\nfunctions of $r_t$. In the case of quadratic $Q^2$, we prove that $r_t$ can\nexhibit a leverage effect and long memory, in the sense that the squared\nprocess $r^2_t$ has long memory autocorrelation and its normalized partial sums\nprocess converges to a fractional Brownian motion.\n", "versions": [{"version": "v1", "created": "Sat, 31 Jan 2015 12:20:19 GMT"}, {"version": "v2", "created": "Sun, 18 Oct 2015 15:03:27 GMT"}], "update_date": "2015-10-20", "authors_parsed": [["Doukhan", "Paul", ""], ["Grublyt\u0117", "Ieva", ""], ["Surgailis", "Donatas", ""]]}, {"id": "1502.00139", "submitter": "Sergiy Vorobyov A.", "authors": "Mahdi Shaghaghi and Sergiy A. Vorobyov", "title": "Subspace Leakage Analysis and Improved DOA Estimation with Small Sample\n  Size", "comments": "37 pages, 10 figures, Submitted to the IEEE Transactions on Signal\n  Processing in July 2014", "journal-ref": "IEEE Trans. Signal Processing, vol. 63, no. 12, pp. 3251-3265,\n  June 2015", "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical methods of DOA estimation such as the MUSIC algorithm are based on\nestimating the signal and noise subspaces from the sample covariance matrix.\nFor a small number of samples, such methods are exposed to performance\nbreakdown, as the sample covariance matrix can largely deviate from the true\ncovariance matrix. In this paper, the problem of DOA estimation performance\nbreakdown is investigated. We consider the structure of the sample covariance\nmatrix and the dynamics of the root-MUSIC algorithm. The performance breakdown\nin the threshold region is associated with the subspace leakage where some\nportion of the true signal subspace resides in the estimated noise subspace. In\nthis paper, the subspace leakage is theoretically derived. We also propose a\ntwo-step method which improves the performance by modifying the sample\ncovariance matrix such that the amount of the subspace leakage is reduced.\nFurthermore, we introduce a phenomenon named as root-swap which occurs in the\nroot-MUSIC algorithm in the low sample size region and degrades the performance\nof the DOA estimation. A new method is then proposed to alleviate this problem.\nNumerical examples and simulation results are given for uncorrelated and\ncorrelated sources to illustrate the improvement achieved by the proposed\nmethods. Moreover, the proposed algorithms are combined with the pseudo-noise\nresampling method to further improve the performance.\n", "versions": [{"version": "v1", "created": "Sat, 31 Jan 2015 16:57:49 GMT"}], "update_date": "2016-03-03", "authors_parsed": [["Shaghaghi", "Mahdi", ""], ["Vorobyov", "Sergiy A.", ""]]}, {"id": "1502.00140", "submitter": "Jacek Wesolowski", "authors": "Jacek Wesolowski", "title": "Regression version of the Matsumoto-Yor type characterization of the\n  gamma and Kummer distributions", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study a Matsumoto-Yor type property for the gamma and Kummer\ninde- pendent variables discovered in Koudou and Vallois (2012). We prove that\nconstancy of regressions of U = (1 + 1/(X + Y ))=(1 + 1/X) given V = X + Y and\nof 1/U given V , where X and Y are indepen- dent and positive random variables,\ncharacterizes the gamma and Kummer distributions. This result completes\ncharacterizations by independence of U and V obtained, under smoothness\nassumptions for densities, in Koudou and Vallois (2011, 2012). Since we work\nwith differential equations for the Laplace transforms, no density assumptions\nare needed.\n", "versions": [{"version": "v1", "created": "Sat, 31 Jan 2015 17:33:11 GMT"}], "update_date": "2015-02-03", "authors_parsed": [["Wesolowski", "Jacek", ""]]}, {"id": "1502.00146", "submitter": "Olga Klopp", "authors": "Olga Klopp (CREST, MODAL'X)", "title": "Matrix completion by singular value thresholding: sharp bounds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the matrix completion problem where the aim is to esti-mate a\nlarge data matrix for which only a relatively small random subset of its\nentries is observed. Quite popular approaches to matrix completion problem are\niterative thresholding methods. In spite of their empirical success, the\ntheoretical guarantees of such iterative thresholding methods are poorly\nunderstood. The goal of this paper is to provide strong theo-retical\nguarantees, similar to those obtained for nuclear-norm penalization methods and\none step thresholding methods, for an iterative thresholding algorithm which is\na modification of the softImpute algorithm. An im-portant consequence of our\nresult is the exact minimax optimal rates of convergence for matrix completion\nproblem which were known until know only up to a logarithmic factor.\n", "versions": [{"version": "v1", "created": "Sat, 31 Jan 2015 18:49:04 GMT"}], "update_date": "2015-02-03", "authors_parsed": [["Klopp", "Olga", "", "CREST, MODAL'X"]]}, {"id": "1502.00184", "submitter": "Jan Johannes", "authors": "Jan Johannes and Anna Simoni and Rudolf Schenk", "title": "Adaptive Bayesian estimation in indirect Gaussian sequence space models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In an indirect Gaussian sequence space model lower and upper bounds are\nderived for the concentration rate of the posterior distribution of the\nparameter of interest shrinking to the parameter value $\\theta^\\circ$ that\ngenerates the data. While this establishes posterior consistency, however, the\nconcentration rate depends on both $\\theta^\\circ$ and a tuning parameter which\nenters the prior distribution. We first provide an oracle optimal choice of the\ntuning parameter, i.e., optimized for each $\\theta^\\circ$ separately. The\noptimal choice of the prior distribution allows us to derive an oracle optimal\nconcentration rate of the associated posterior distribution. Moreover, for a\ngiven class of parameters and a suitable choice of the tuning parameter, we\nshow that the resulting uniform concentration rate over the given class is\noptimal in a minimax sense. Finally, we construct a hierarchical prior that is\nadaptive. This means that, given a parameter $\\theta^\\circ$ or a class of\nparameters, respectively, the posterior distribution contracts at the oracle\nrate or at the minimax rate over the class. Notably, the hierarchical prior\ndoes not depend neither on $\\theta^\\circ$ nor on the given class. Moreover,\nconvergence of the fully data-driven Bayes estimator at the oracle or at the\nminimax rate is established.\n", "versions": [{"version": "v1", "created": "Sun, 1 Feb 2015 01:02:57 GMT"}], "update_date": "2015-02-03", "authors_parsed": [["Johannes", "Jan", ""], ["Simoni", "Anna", ""], ["Schenk", "Rudolf", ""]]}, {"id": "1502.00235", "submitter": "Stephen DeSalvo", "authors": "Stephen DeSalvo", "title": "Exact sampling algorithms for Latin squares and Sudoku matrices via\n  probabilistic divide-and-conquer", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide several algorithms for the exact, uniform random sampling of Latin\nsquares and Sudoku matrices via probabilistic divide-and-conquer (PDC). Our\napproach divides the sample space into smaller pieces, samples each separately,\nand combines them in a manner which yields an exact sample from the target\ndistribution. We demonstrate, in particular, a version of PDC in which one of\nthe pieces is sampled using a brute force approach, which we dub\n$\\textit{almost deterministic second half}$, as it is a generalization to a\nprevious application of PDC for which one of the pieces is uniquely determined\ngiven the others.\n", "versions": [{"version": "v1", "created": "Sun, 1 Feb 2015 11:29:11 GMT"}, {"version": "v2", "created": "Thu, 8 Sep 2016 13:51:14 GMT"}], "update_date": "2016-09-09", "authors_parsed": [["DeSalvo", "Stephen", ""]]}, {"id": "1502.00301", "submitter": "Elias David Nino Ruiz", "authors": "Elias D. Nino-Ruiz and Adrian Sandu", "title": "Ensemble Kalman Filter Implementations Based on Covariance Matrix\n  Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": "CSL-TR-16-2015", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops efficient ensemble Kalman filter (EnKF) implementations\nbased on shrinkage covariance estimation. The forecast ensemble members at each\nstep are used to estimate the background error covariance matrix via the\nRao-Blackwell Ledoit and Wolf estimator, which has been developed specifically\ndeveloped to approximate high-dimensional covariance matrices using a small\nnumber of samples. Additional samples are taken from the normal distribution\ndescribed by the background ensemble mean and the estimated background\ncovariance matrix in order to increase the size of the ensemble and reduce the\nsampling error of the filter. This increase in the size of the ensemble is\nobtained without running the forward model. After the assimilation step, the\nadditional samples are discarded and only the initial members are propagated.\nTwo implementations are considered. In the EnKF Full-Space (EnKF-FS) approach\nthe assimilation process is performed in the model space, while the EnKF\nReduce-Space (EnKF-RS) formulation performs the analysis in the subspace\nspanned by the ensemble members. Numerical experiments carried out with a\nquasi-geostrophic model show that the proposed implementations outperform\ncurrent methods such as the traditional EnKF formulation, square root filters,\nand inflation-free EnKF implementations. The proposed implementations provide\ngood results with small ensemble sizes ($\\sim 10$) and small percentages of\nobserved components from the vector state. These results are similar (and in\nsome cases better) to traditional methods using large ensemble sizes ($\\sim\n80$) and large percentages of observed components. The computational times of\nthe new implementations remain reasonably low.\n", "versions": [{"version": "v1", "created": "Sun, 1 Feb 2015 19:37:38 GMT"}], "update_date": "2015-02-03", "authors_parsed": [["Nino-Ruiz", "Elias D.", ""], ["Sandu", "Adrian", ""]]}, {"id": "1502.00320", "submitter": "Jon A. Wellner", "authors": "Lutz Duembgen, Jon A. Wellner, and Malcolm Wolff", "title": "A law of the iterated logarithm for Grenander's estimator", "comments": "11 pages, 3 figures", "journal-ref": "Stochastic Processes and their Applications, Vol. 126 (12), 2016,\n  pp. 3854-3864", "doi": "10.1016/j.spa.2016.04.012", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note we prove the following law of the iterated logarithm for the\nGrenander estimator of a monotone decreasing density: If $f(t_0) > 0$, $f'(t_0)\n< 0$, and $f'$ is continuous in a neighborhood of $t_0$, then \\begin{eqnarray*}\n\\limsup_{n\\rightarrow \\infty} \\left ( \\frac{n}{2\\log \\log n} \\right )^{1/3} (\n\\widehat{f}_n (t_0 ) - f(t_0) ) = \\left| f(t_0) f'(t_0)/2 \\right|^{1/3} 2M\n\\end{eqnarray*} almost surely where $ M \\equiv \\sup_{g \\in {\\cal G}} T_g =\n(3/4)^{1/3}$ and $ T_g \\equiv \\mbox{argmax}_u \\{ g(u) - u^2 \\} $; here ${\\cal\nG}$ is the two-sided Strassen limit set on $R$. The proof relies on laws of the\niterated logarithm for local empirical processes, Groeneboom's switching\nrelation, and properties of Strassen's limit set analogous to distributional\nproperties of Brownian motion.\n", "versions": [{"version": "v1", "created": "Sun, 1 Feb 2015 22:02:59 GMT"}], "update_date": "2016-12-09", "authors_parsed": [["Duembgen", "Lutz", ""], ["Wellner", "Jon A.", ""], ["Wolff", "Malcolm", ""]]}, {"id": "1502.00342", "submitter": "Jon A. Wellner", "authors": "Evan Greene and Jon A. Wellner", "title": "Finite sampling inequalities: an application to two-sample\n  Kolmogorov-Smirnov statistics", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We review a finite-sampling exponential bound due to Serfling and discuss\nrelated exponential bounds for the hypergeometric distribution. We then discuss\nhow such bounds motivate some new results for two-sample empirical processes.\nOur development complements recent results by Wei and Dudley (2011) concerning\nexponential bounds for two-sided Kolmogorov - Smirnov statistics by giving\ncorresponding results for one-sided statistics with emphasis on \"adjusted\"\ninequalities of the type proved originally by Dvoretzky, Kiefer, and Wolfowitz\n(1956) and by Massart (1990) for one-sample versions of these statistics.\n", "versions": [{"version": "v1", "created": "Mon, 2 Feb 2015 02:18:43 GMT"}, {"version": "v2", "created": "Sat, 1 Aug 2015 20:16:38 GMT"}, {"version": "v3", "created": "Fri, 17 Feb 2017 00:59:40 GMT"}], "update_date": "2017-02-20", "authors_parsed": [["Greene", "Evan", ""], ["Wellner", "Jon A.", ""]]}, {"id": "1502.00352", "submitter": "Denis Chetverikov", "authors": "Victor Chernozhukov, Denis Chetverikov, and Kengo Kato", "title": "Empirical and multiplier bootstraps for suprema of empirical processes\n  of increasing complexity, and related Gaussian couplings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive strong approximations to the supremum of the non-centered empirical\nprocess indexed by a possibly unbounded VC-type class of functions by the\nsuprema of the Gaussian and bootstrap processes. The bounds of these\napproximations are non-asymptotic, which allows us to work with classes of\nfunctions whose complexity increases with the sample size. The construction of\ncouplings is not of the Hungarian type and is instead based on the\nSlepian-Stein methods and Gaussian comparison inequalities. The increasing\ncomplexity of classes of functions and non-centrality of the processes make the\nresults useful for applications in modern nonparametric statistics (Gin\\'{e}\nand Nickl, 2015), in particular allowing us to study the power properties of\nnonparametric tests using Gaussian and bootstrap approximations.\n", "versions": [{"version": "v1", "created": "Mon, 2 Feb 2015 04:12:19 GMT"}, {"version": "v2", "created": "Sun, 6 Sep 2015 23:40:45 GMT"}], "update_date": "2015-09-08", "authors_parsed": [["Chernozhukov", "Victor", ""], ["Chetverikov", "Denis", ""], ["Kato", "Kengo", ""]]}, {"id": "1502.00412", "submitter": "Giacomo Aletti", "authors": "Andrea Ghiglietti, Francesca Ieva, Anna Maria Paganoni and Giacomo\n  Aletti", "title": "On linear regression models in infinite dimensional spaces with scalar\n  response", "comments": null, "journal-ref": "Stat Papers (2017) 58: 527-548", "doi": "10.1007/s00362-015-0710-2", "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In functional linear regression, the parameters estimation involves solving a\nnon necessarily well-posed problem and it has points of contact with a range of\nmethodologies, including statistical smoothing, deconvolution and projection on\nfinite-dimensional subspaces. We discuss the standard approach based explicitly\non functional principal components analysis, nevertheless the choice of the\nnumber of basis components remains something subjective and not always properly\ndiscussed and justified. In this work we discuss inferential properties of\nleast square estimation in this context with different choices of projection\nsubspaces, as well as we study asymptotic behaviour increasing the dimension of\nsubspaces.\n", "versions": [{"version": "v1", "created": "Mon, 2 Feb 2015 09:14:18 GMT"}], "update_date": "2018-01-04", "authors_parsed": [["Ghiglietti", "Andrea", ""], ["Ieva", "Francesca", ""], ["Paganoni", "Anna Maria", ""], ["Aletti", "Giacomo", ""]]}, {"id": "1502.00560", "submitter": "Anindya Bhadra", "authors": "Anindya Bhadra, Jyotishka Datta, Nicholas G. Polson and Brandon\n  Willard", "title": "The Horseshoe+ Estimator of Ultra-Sparse Signals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new prior for ultra-sparse signal detection that we term the\n\"horseshoe+ prior.\" The horseshoe+ prior is a natural extension of the\nhorseshoe prior that has achieved success in the estimation and detection of\nsparse signals and has been shown to possess a number of desirable theoretical\nproperties while enjoying computational feasibility in high dimensions. The\nhorseshoe+ prior builds upon these advantages. Our work proves that the\nhorseshoe+ posterior concentrates at a rate faster than that of the horseshoe\nin the Kullback-Leibler (K-L) sense. We also establish theoretically that the\nproposed estimator has lower posterior mean squared error in estimating signals\ncompared to the horseshoe and achieves the optimal Bayes risk in testing up to\na constant. For global-local scale mixture priors, we develop a new technique\nfor analyzing the marginal sparse prior densities using the class of Meijer-G\nfunctions. In simulations, the horseshoe+ estimator demonstrates superior\nperformance in a standard design setting against competing methods, including\nthe horseshoe and Dirichlet-Laplace estimators. We conclude with an\nillustration on a prostate cancer data set and by pointing out some directions\nfor future research.\n", "versions": [{"version": "v1", "created": "Mon, 2 Feb 2015 17:25:45 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2015 18:39:18 GMT"}], "update_date": "2015-06-16", "authors_parsed": [["Bhadra", "Anindya", ""], ["Datta", "Jyotishka", ""], ["Polson", "Nicholas G.", ""], ["Willard", "Brandon", ""]]}, {"id": "1502.00600", "submitter": "Arnak Dalalyan S.", "authors": "Arnak S. Dalalyan", "title": "Discussion on the paper: Hypotheses testing by convex optimization by\n  Goldenshluger, Juditsky and Nemirovski", "comments": "To appear in the EJS", "journal-ref": "Electron. J. Statist. Volume 9, Number 2 (2015), 1733-1737", "doi": "10.1214/15-EJS994", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We briefly discuss some interesting questions related to the paper\n\"Hypotheses testing by convex optimization\" by Goldenshluger, Juditsky and\nNemirovski.\n", "versions": [{"version": "v1", "created": "Mon, 2 Feb 2015 20:02:41 GMT"}], "update_date": "2015-08-11", "authors_parsed": [["Dalalyan", "Arnak S.", ""]]}, {"id": "1502.00665", "submitter": "Olivier Collier", "authors": "Olivier Collier, La\\\"etitia Comminges and Alexandre B. Tsybakov", "title": "Minimax estimation of linear and quadratic functionals on sparsity\n  classes", "comments": "32 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the Gaussian sequence model, we obtain non-asymptotic minimax rates of\nestimation of the linear, quadratic and the L2-norm functionals on classes of\nsparse vectors and construct optimal estimators that attain these rates. The\nmain object of interest is the class s-sparse vectors for which we also provide\ncompletely adaptive estimators (independent of s and of the noise variance)\nhaving only logarithmically slower rates than the minimax ones. Furthermore, we\nobtain the minimax rates on the Lq-balls where 0 < q < 2. This analysis shows\nthat there are, in general, three zones in the rates of convergence that we\ncall the sparse zone, the dense zone and the degenerate zone, while a fourth\nzone appears for estimation of the quadratic functional. We show that, as\nopposed to estimation of the vector, the correct logarithmic terms in the\noptimal rates for the sparse zone scale as log(d/s^2) and not as log(d/s). For\nthe sparse class, the rates of estimation of the linear functional and of the\nL2-norm have a simple elbow at s = sqrt(d) (boundary between the sparse and the\ndense zones) and exhibit similar performances, whereas the estimation of the\nquadratic functional reveals more complex effects and is not possible only on\nthe basis of sparsity described by the sparsity condition on the vector.\nFinally, we apply our results on estimation of the L2-norm to the problem of\ntesting against sparse alternatives. In particular, we obtain a non-asymptotic\nanalog of the Ingster-Donoho-Jin theory revealing some effects that were not\ncaptured by the previous asymptotic analysis.\n", "versions": [{"version": "v1", "created": "Mon, 2 Feb 2015 22:02:18 GMT"}], "update_date": "2015-02-04", "authors_parsed": [["Collier", "Olivier", ""], ["Comminges", "La\u00ebtitia", ""], ["Tsybakov", "Alexandre B.", ""]]}, {"id": "1502.00738", "submitter": "Jose A. Diaz-Garcia", "authors": "Francisco J. Caro-Lopera and Jos\\'e A. D\\'iaz-Garc\\'ia", "title": "Polynomial Eulerian shape distributions", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper a new approach is derived in the context of shape theory. The\nimplemented methodology is motivated in an open problem proposed in\n\\citet{GM93} about the construction of certain shape density involving Euler\nhypergeometric functions of matrix arguments.\n  The associated distribution is obtained by establishing a connection between\nthe required shape invariants and a known result on canonical correlations\navailable since 1963; as usual in statistical shape theory and the addressed\nresult, the densities are expressed in terms of infinite series of zonal\npolynomials which involves considerable difficulties in inference. Then the\nwork proceeds to solve analytically the problem of computation by using the\nEulerian matrix relation of two matrix argument for deriving the corresponding\npolynomial distribution in certain parametric space which allows to perform\nexact inference based on exact distributions characterized for polynomials of\nvery low degree. A methodology for comparing correlation shape structure is\nproposed and applied in handwritten differentiation.\n", "versions": [{"version": "v1", "created": "Tue, 3 Feb 2015 04:49:07 GMT"}], "update_date": "2015-02-04", "authors_parsed": [["Caro-Lopera", "Francisco J.", ""], ["D\u00edaz-Garc\u00eda", "Jos\u00e9 A.", ""]]}, {"id": "1502.01106", "submitter": "Abhik Ghosh", "authors": "Abhik Ghosh, Ayanendranath Basu", "title": "Robust Bounded Influence Tests for Independent Non-Homogeneous\n  Observations", "comments": "To appear in Statistica Sinica (2017)", "journal-ref": null, "doi": "10.5705/ss.202015.0320", "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Experiments often yield non-identically distributed data for statistical\nanalysis. Tests of hypothesis under such set-ups are generally performed using\nthe likelihood ratio test, which is non-robust with respect to outliers and\nmodel misspecification. In this paper, we consider the set-up of\nnon-identically but independently distributed observations and develop a\ngeneral class of test statistics for testing parametric hypothesis based on the\ndensity power divergence. The proposed tests have bounded influence functions,\nare highly robust with respect to data contamination, have high power against\ncontiguous alternatives, and are consistent at any fixed alternative. The\nmethodology is illustrated by the simple and generalized linear regression\nmodels with fixed covariates.\n", "versions": [{"version": "v1", "created": "Wed, 4 Feb 2015 06:22:49 GMT"}, {"version": "v2", "created": "Tue, 15 Sep 2015 19:13:51 GMT"}, {"version": "v3", "created": "Fri, 9 Sep 2016 09:23:13 GMT"}, {"version": "v4", "created": "Fri, 7 Jul 2017 19:03:50 GMT"}], "update_date": "2017-07-25", "authors_parsed": [["Ghosh", "Abhik", ""], ["Basu", "Ayanendranath", ""]]}, {"id": "1502.01173", "submitter": "Sobom Matthieu Som\\'e", "authors": "C\\'elestin C. Kokonendji and Sobom M. Som\\'e", "title": "On multivariate associated kernels for smoothing general density\n  functions", "comments": "37 pages, 20 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multivariate associated kernel estimators, which depend on both target point\nand bandwidth matrix, are appropriate for partially or totally bounded\ndistributions and generalize the classical ones as Gaussian. Previous studies\non multivariate associated kernels have been restricted to product of\nunivariate associated kernels, also considered having diagonal bandwidth\nmatrices. However, it is shown in classical cases that for certain forms of\ntarget density such as multimodal, the use of full bandwidth matrices offers\nthe potential for significantly improved density estimation. In this paper,\ngeneral associated kernel estimators with correlation structure are introduced.\nProperties of these estimators are presented; in particular, the boundary bias\nis investigated. Then, the generalized bivariate beta kernels are handled with\nmore details. The associated kernel with a correlation structure is built with\na variant of the mode-dispersion method and two families of bandwidth matrices\nare discussed under the criterion of cross-validation. Several simulation\nstudies are done. In the particular situation of bivariate beta kernels, it is\ntherefore pointed out the very good performance of associated kernel estimators\nwith correlation structure compared to the diagonal case. Finally, an\nillustration on real dataset of paired rates in a framework of political\nelections is presented.\n", "versions": [{"version": "v1", "created": "Wed, 4 Feb 2015 12:23:49 GMT"}], "update_date": "2015-02-05", "authors_parsed": [["Kokonendji", "C\u00e9lestin C.", ""], ["Som\u00e9", "Sobom M.", ""]]}, {"id": "1502.01178", "submitter": "Evgeni Ovcharov Y", "authors": "Evgeni Y. Ovcharov", "title": "Proper Scoring Rules and Bregman Divergences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the mathematical foundations of proper scoring rules (PSRs) and\nBregman divergences and present their characteristic properties in a unified\ntheoretical framework. In many situations it is preferable not to generate a\nPSR directly from its convex entropy on the unit simplex but instead by the\nsublinear extension of the entropy to the positive orthant. This gives the\nscoring rule simply as a subgradient of the extended entropy, allowing for a\nmore elegant theory. The other convex extensions of the entropy generate affine\nextensions of the scoring rule and induce the class of functional Bregman\ndivergences. We discuss the geometric nature of the relationship between PSRs\nand Bregman divergences and extend and unify existing partial results. We also\napproach the topic of differentiability of entropy functions. Not all entropies\nof interest possess functional derivatives, but they do all have directional\nderivatives in almost every direction. Relying on the notion of quasi-interior\nof a convex set to quantify the latter property, we formalise under what\nconditions a PSR may be considered to be uniquely determined from its entropy.\n", "versions": [{"version": "v1", "created": "Wed, 4 Feb 2015 12:45:38 GMT"}, {"version": "v2", "created": "Thu, 10 Sep 2015 13:07:31 GMT"}], "update_date": "2015-09-11", "authors_parsed": [["Ovcharov", "Evgeni Y.", ""]]}, {"id": "1502.01269", "submitter": "Evgeni Ovcharov Y", "authors": "Evgeni Y. Ovcharov", "title": "Existence and Uniqueness of Proper Scoring Rules", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To discuss the existence and uniqueness of proper scoring rules one needs to\nextend the associated entropy functions as sublinear functions to the conic\nhull of the prediction set. In some natural function spaces, such as the\nLebesgue $L^p$-spaces over $\\mathbb R^d$, the positive cones have empty\ninterior. Entropy functions defined on such cones have only directional\nderivatives. Certain entropies may be further extended continuously to open\ncones in normed spaces containing signed densities. The extended densities are\nG\\^ateaux differentiable except on a negligible set and have everywhere\ncontinuous subgradients due to the supporting hyperplane theorem. We introduce\nthe necessary framework from analysis and algebra that allows us to give an\naffirmative answer to the titular question of the paper. As a result of this,\nwe give a formal sense in which entropy functions have uniquely associated\nproper scoring rules. We illustrate our framework by studying the derivatives\nand subgradients of the following three prototypical entropies: Shannon\nentropy, Hyv\\\"arinen entropy, and quadratic entropy.\n", "versions": [{"version": "v1", "created": "Wed, 4 Feb 2015 17:46:45 GMT"}, {"version": "v2", "created": "Thu, 10 Sep 2015 17:37:06 GMT"}], "update_date": "2015-09-11", "authors_parsed": [["Ovcharov", "Evgeni Y.", ""]]}, {"id": "1502.01328", "submitter": "Michele Pavon", "authors": "Michele Pavon", "title": "A layman's note on a class of frequentist hypothesis testing problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is observed that for testing between simple hypotheses where the cost of\nType I and Type II errors can be quantified, it is better to let the\noptimization choose the test size.\n", "versions": [{"version": "v1", "created": "Wed, 4 Feb 2015 20:45:43 GMT"}], "update_date": "2015-02-05", "authors_parsed": [["Pavon", "Michele", ""]]}, {"id": "1502.01413", "submitter": "Donald Richards", "authors": "Johannes Dueck, Dominic Edelmann, and Donald Richards", "title": "Distance Correlation Coefficients for Lancaster Distributions", "comments": "32 pages, 1 figure", "journal-ref": "Journal of Multivariate Analysis, 154 (2017), 19--39", "doi": "10.1016/j.jmva.2016.10.012", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of calculating distance correlation coefficients\nbetween random vectors whose joint distributions belong to the class of\nLancaster distributions. We derive under mild convergence conditions a general\nseries representation for the distance covariance for these distributions. To\nillustrate the general theory, we apply the series representation to derive\nexplicit expressions for the distance covariance and distance correlation\ncoefficients for the bivariate normal distribution and its generalizations of\nLancaster type, the multivariate normal distributions, and the bivariate gamma,\nPoisson, and negative binomial distributions which are of Lancaster type.\n", "versions": [{"version": "v1", "created": "Thu, 5 Feb 2015 02:39:42 GMT"}, {"version": "v2", "created": "Tue, 29 Nov 2016 00:35:40 GMT"}], "update_date": "2016-11-30", "authors_parsed": [["Dueck", "Johannes", ""], ["Edelmann", "Dominic", ""], ["Richards", "Donald", ""]]}, {"id": "1502.01488", "submitter": "Sobom Matthieu Som\\'e", "authors": "Sobom M. Som\\'e, C\\'elestin C. Kokonendji", "title": "Effects of associated kernels in nonparametric multiple regressions", "comments": "19 pages, 2 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Associated kernels have been introduced to improve the classical continuous\nkernels for smoothing any functional on several kinds of supports such as\nbounded continuous and discrete sets. This work deals with the effects of\ncombined associated kernels on nonparametric multiple regression functions.\nUsing the Nadaraya-Watson estimator with optimal bandwidth matrices selected by\ncross-validation procedure, different behaviours of multiple regression\nestimations are pointed out according the type of multivariate associated\nkernels with correlation or not. Through simulation studies, there are no\neffect of correlation structures for the continuous regression functions and\nalso for the associated continuous kernels; however, there exist really effects\nof the choice of multivariate associated kernels following the support of the\nmultiple regression functions bounded continuous or discrete. Applications are\nmade on two real datasets.\n", "versions": [{"version": "v1", "created": "Thu, 5 Feb 2015 10:18:31 GMT"}], "update_date": "2015-02-06", "authors_parsed": [["Som\u00e9", "Sobom M.", ""], ["Kokonendji", "C\u00e9lestin C.", ""]]}, {"id": "1502.01533", "submitter": "Maarten Jansen", "authors": "Maarten Jansen", "title": "Non-equispaced B-spline wavelets", "comments": "42 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper has three main contributions. The first is the construction of\nwavelet transforms from B-spline scaling functions defined on a grid of\nnon-equispaced knots. The new construction extends the equispaced,\nbiorthogonal, compactly supported Cohen-Daubechies-Feauveau wavelets. The new\nconstruction is based on the factorisation of wavelet transforms into lifting\nsteps. The second and third contributions are new insights on how to use these\nand other wavelets in statistical applications. The second contribution is\nrelated to the bias of a wavelet representation. It is investigated how the\nfine scaling coefficients should be derived from the observations. In the\ncontext of equispaced data, it is common practice to simply take the\nobservations as fine scale coefficients. It is argued in this paper that this\nis not acceptable for non-interpolating wavelets on non-equidistant data.\nFinally, the third contribution is the study of the variance in a\nnon-orthogonal wavelet transform in a new framework, replacing the numerical\ncondition as a measure for non-orthogonality. By controlling the variances of\nthe reconstruction from the wavelet coefficients, the new framework allows us\nto design wavelet transforms on irregular point sets with a focus on their use\nfor smoothing or other applications in statistics.\n", "versions": [{"version": "v1", "created": "Thu, 5 Feb 2015 13:23:28 GMT"}, {"version": "v2", "created": "Wed, 19 Oct 2016 11:38:02 GMT"}], "update_date": "2016-10-20", "authors_parsed": [["Jansen", "Maarten", ""]]}, {"id": "1502.01600", "submitter": "David Ruelle", "authors": "David Ruelle", "title": "Biology and nonequilibrium: remarks on a paper by J.L. England", "comments": "11 pages, 1figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math-ph math.MP math.ST quant-ph stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This note analyzes the physical basis of J.R. England's paper \"Statistical\nphysics of self-replication.\" [J. Chem. Phys. {\\bf 139}, 121923(2013)]. We\nfollow England's use of time-reversal symmetry but replace stochastic by\ndeterministic dynamics, and introduce a definition of metastable states based\non equilibrium statistical mechanics. We rederive England's detailed balance\nrelation and obtain another similar relation which appears more natural and\nremains valid for quantum systems. The detailed balance relations are based on\nserious physical ideas, and either of them can be used for England's biological\ndiscussion. This biological discussion does of course deserve further scrutiny.\n", "versions": [{"version": "v1", "created": "Thu, 5 Feb 2015 15:09:28 GMT"}], "update_date": "2015-02-06", "authors_parsed": [["Ruelle", "David", ""]]}, {"id": "1502.01750", "submitter": "Donald Richards", "authors": "Linda V. Hansen, Thordis L. Thorarinsdottir, Evgeni Ovcharov, Tilmann\n  Gneiting, and Donald Richards", "title": "Gaussian Random Particles with Flexible Hausdorff Dimension", "comments": "22 pages, 5 figures, 3 tables; to appear in Advances in Applied\n  Probability", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian particles provide a flexible framework for modelling and simulating\nthree-dimensional star-shaped random sets. In our framework, the radial\nfunction of the particle arises from a kernel smoothing, and is associated with\nan isotropic random field on the sphere. If the kernel is a von Mises--Fisher\ndensity, or uniform on a spherical cap, the correlation function of the\nassociated random field admits a closed form expression. The Hausdorff\ndimension of the surface of the Gaussian particle reflects the decay of the\ncorrelation function at the origin, as quantified by the fractal index. Under\npower kernels we obtain particles with boundaries of any Hausdorff dimension\nbetween 2 and 3.\n", "versions": [{"version": "v1", "created": "Thu, 5 Feb 2015 22:37:37 GMT"}, {"version": "v2", "created": "Wed, 11 Feb 2015 20:31:09 GMT"}, {"version": "v3", "created": "Thu, 12 Feb 2015 19:39:26 GMT"}], "update_date": "2015-02-13", "authors_parsed": [["Hansen", "Linda V.", ""], ["Thorarinsdottir", "Thordis L.", ""], ["Ovcharov", "Evgeni", ""], ["Gneiting", "Tilmann", ""], ["Richards", "Donald", ""]]}, {"id": "1502.01752", "submitter": "Jon A. Wellner", "authors": "Fuchang Gao and Jon A. Wellner", "title": "Entropy of convex functions on $R^d$", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $\\Omega$ be a bounded closed convex set in ${\\mathbb R}^d$ with non-empty\ninterior, and let ${\\cal C}_r(\\Omega)$ be the class of convex functions on\n$\\Omega$ with $L^r$-norm bounded by $1$. We obtain sharp estimates of the\n$\\epsilon$-entropy of ${\\cal C}_r(\\Omega)$ under $L^p(\\Omega)$ metrics, $1\\le\np<r\\le \\infty$. In particular, the results imply that the universal lower bound\n$\\epsilon^{-d/2}$ is also an upper bound for all $d$-polytopes, and the\nuniversal upper bound of $\\epsilon^{-\\frac{(d-1)}{2}\\cdot \\frac{pr}{r-p}}$ for\n$p>\\frac{dr}{d+(d-1)r}$ is attained by the closed unit ball. While a general\nconvex body can be approximated by inscribed polytopes, the entropy rate does\nnot carry over to the limiting body. Our results have applications to questions\nconcerning rates of convergence of nonparametric estimators of high-dimensional\nshape-constrained functions.\n", "versions": [{"version": "v1", "created": "Thu, 5 Feb 2015 22:46:08 GMT"}, {"version": "v2", "created": "Mon, 16 Nov 2015 18:41:21 GMT"}, {"version": "v3", "created": "Sun, 26 Feb 2017 20:16:05 GMT"}], "update_date": "2017-02-28", "authors_parsed": [["Gao", "Fuchang", ""], ["Wellner", "Jon A.", ""]]}, {"id": "1502.01798", "submitter": "Yuehan Yang", "authors": "Yuehan Yang, Hu Yang", "title": "Model Selection Consistency of Lasso for Empirical Data", "comments": "14 pages, 2 figures, Chinese Annals of Mathematics, Series B, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale empirical data, the sample size and the dimension are high, often\nexhibit various characteristics. For example, the noise term follows unknown\ndistributions or the model is very sparse that the number of critical variables\nis fixed while dimensionality grows with $n$. We consider the model selection\nproblem of lasso for this kind of data. We investigate both theoretical\nguarantees and simulations, and show that the lasso is robust for various kinds\nof data.\n", "versions": [{"version": "v1", "created": "Fri, 6 Feb 2015 05:23:49 GMT"}, {"version": "v2", "created": "Fri, 15 Jun 2018 00:59:09 GMT"}], "update_date": "2018-06-18", "authors_parsed": [["Yang", "Yuehan", ""], ["Yang", "Hu", ""]]}, {"id": "1502.01866", "submitter": "Renato J Cintra", "authors": "L. C. R\\^ego, R. J. Cintra", "title": "An Extension of the Dirichlet Density for Sets of Gaussian Integers", "comments": "13 pages, 1 figure", "journal-ref": "Can. Math. Bull. 56 (2013) 161-172", "doi": "10.4153/CMB-2011-149-9", "report-no": null, "categories": "math.NT cs.CG math.CA math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several measures for the density of sets of integers have been proposed, such\nas the asymptotic density, the Schnirelmann density, and the Dirichlet density.\nThere has been some work in the literature on extending some of these concepts\nof density to higher dimensional sets of integers. In this work, we propose an\nextension of the Dirichlet density for sets of Gaussian integers and\ninvestigate some of its properties.\n", "versions": [{"version": "v1", "created": "Fri, 6 Feb 2015 12:01:15 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["R\u00eago", "L. C.", ""], ["Cintra", "R. J.", ""]]}, {"id": "1502.01988", "submitter": "Tengyuan Liang", "authors": "T. Tony Cai, Tengyuan Liang and Alexander Rakhlin", "title": "Computational and Statistical Boundaries for Submatrix Localization in a\n  Large Noisy Matrix", "comments": "37 pages, 1 figure", "journal-ref": "The Annals of Statistics 45 (2017) 1403-1430", "doi": "10.1214/16-AOS1488", "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The interplay between computational efficiency and statistical accuracy in\nhigh-dimensional inference has drawn increasing attention in the literature. In\nthis paper, we study computational and statistical boundaries for submatrix\nlocalization. Given one observation of (one or multiple non-overlapping) signal\nsubmatrix (of magnitude $\\lambda$ and size $k_m \\times k_n$) contaminated with\na noise matrix (of size $m \\times n$), we establish two transition thresholds\nfor the signal to noise $\\lambda/\\sigma$ ratio in terms of $m$, $n$, $k_m$, and\n$k_n$. The first threshold, $\\sf SNR_c$, corresponds to the computational\nboundary. Below this threshold, it is shown that no polynomial time algorithm\ncan succeed in identifying the submatrix, under the \\textit{hidden clique\nhypothesis}. We introduce adaptive linear time spectral algorithms that\nidentify the submatrix with high probability when the signal strength is above\nthe threshold $\\sf SNR_c$. The second threshold, $\\sf SNR_s$, captures the\nstatistical boundary, below which no method can succeed with probability going\nto one in the minimax sense. The exhaustive search method successfully finds\nthe submatrix above this threshold. The results show an interesting phenomenon\nthat $\\sf SNR_c$ is always significantly larger than $\\sf SNR_s$, which implies\nan essential gap between statistical optimality and computational efficiency\nfor submatrix localization.\n", "versions": [{"version": "v1", "created": "Fri, 6 Feb 2015 18:58:28 GMT"}, {"version": "v2", "created": "Wed, 21 Oct 2015 17:51:11 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Cai", "T. Tony", ""], ["Liang", "Tengyuan", ""], ["Rakhlin", "Alexander", ""]]}, {"id": "1502.01997", "submitter": "Julien Stoehr", "authors": "Julien Stoehr (I3M), Nial Friel (UCD)", "title": "Calibration of conditional composite likelihood for Bayesian inference\n  on Gibbs random fields", "comments": "JMLR Workshop and Conference Proceedings, 18th International\n  Conference on Artificial Intelligence and Statistics (AISTATS), San Diego,\n  California, USA, 9-12 May 2015 (Vol. 38, pp. 921-929). arXiv admin note:\n  substantial text overlap with arXiv:1207.5758", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gibbs random fields play an important role in statistics, however, the\nresulting likelihood is typically unavailable due to an intractable normalizing\nconstant. Composite likelihoods offer a principled means to construct useful\napproximations. This paper provides a mean to calibrate the posterior\ndistribution resulting from using a composite likelihood and illustrate its\nperformance in several examples.\n", "versions": [{"version": "v1", "created": "Fri, 6 Feb 2015 19:22:27 GMT"}, {"version": "v2", "created": "Wed, 18 Nov 2015 11:38:42 GMT"}], "update_date": "2015-11-19", "authors_parsed": [["Stoehr", "Julien", "", "I3M"], ["Friel", "Nial", "", "UCD"]]}, {"id": "1502.01999", "submitter": "Laurent Rouviere", "authors": "St\\'ephane Auray (CREST), Nicolas Klutchnikoff (IRMA, CREST), Laurent\n  Rouvi\\`ere (IRMAR, CREST)", "title": "On clustering procedures and nonparametric mixture estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with nonparametric estimation of conditional den-sities in\nmixture models in the case when additional covariates are available. The\nproposed approach consists of performing a prelim-inary clustering algorithm on\nthe additional covariates to guess the mixture component of each observation.\nConditional densities of the mixture model are then estimated using kernel\ndensity estimates ap-plied separately to each cluster. We investigate the\nexpected L 1 -error of the resulting estimates and derive optimal rates of\nconvergence over classical nonparametric density classes provided the\nclustering method is accurate. Performances of clustering algorithms are\nmeasured by the maximal misclassification error. We obtain upper bounds of this\nquantity for a single linkage hierarchical clustering algorithm. Lastly,\napplications of the proposed method to mixture models involving elec-tricity\ndistribution data and simulated data are presented.\n", "versions": [{"version": "v1", "created": "Fri, 6 Feb 2015 19:26:47 GMT"}], "update_date": "2015-02-09", "authors_parsed": [["Auray", "St\u00e9phane", "", "CREST"], ["Klutchnikoff", "Nicolas", "", "IRMA, CREST"], ["Rouvi\u00e8re", "Laurent", "", "IRMAR, CREST"]]}, {"id": "1502.02049", "submitter": "Renato J Cintra", "authors": "L. R. Soares, H. M. de Oliveira, R. J. Cintra", "title": "The Fourier-Like and Hartley-Like Wavelet Analysis Based on Hilbert\n  Transforms", "comments": "7 pages, 10 figures, Anais do XXII Simp\\'osio Brasileiro de\n  Telecomunica\\c{c}\\~oes, Campinas, 2005", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CA math.ST physics.data-an stat.AP stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In continuous-time wavelet analysis, most wavelet present some kind of\nsymmetry. Based on the Fourier and Hartley transform kernels, a new wavelet\nmultiresolution analysis is proposed. This approach is based on a pair of\northogonal wavelet functions and is named as the Fourier-Like and Hartley-Like\nwavelet analysis. A Hilbert transform analysis on the wavelet theory is also\nincluded.\n", "versions": [{"version": "v1", "created": "Fri, 6 Feb 2015 21:16:31 GMT"}], "update_date": "2015-02-10", "authors_parsed": [["Soares", "L. R.", ""], ["de Oliveira", "H. M.", ""], ["Cintra", "R. J.", ""]]}, {"id": "1502.02069", "submitter": "Ying Wang", "authors": "Y.X. Rachel Wang, Peter J. Bickel", "title": "Likelihood-based model selection for stochastic block models", "comments": "35 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The stochastic block model (SBM) provides a popular framework for modeling\ncommunity structures in networks. However, more attention has been devoted to\nproblems concerning estimating the latent node labels and the model parameters\nthan the issue of choosing the number of blocks. We consider an approach based\non the log likelihood ratio statistic and analyze its asymptotic properties\nunder model misspecification. We show the limiting distribution of the\nstatistic in the case of underfitting is normal and obtain its convergence rate\nin the case of overfitting. These conclusions remain valid when the average\ndegree grows at a polylog rate. The results enable us to derive the correct\norder of the penalty term for model complexity and arrive at a likelihood-based\nmodel selection criterion that is asymptotically consistent. Our analysis can\nalso be extended to a degree-corrected block model (DCSBM). In practice, the\nlikelihood function can be estimated using more computationally efficient\nvariational methods or consistent label estimation algorithms, allowing the\ncriterion to be applied to large networks.\n", "versions": [{"version": "v1", "created": "Fri, 6 Feb 2015 22:53:10 GMT"}, {"version": "v2", "created": "Thu, 19 Feb 2015 00:52:51 GMT"}, {"version": "v3", "created": "Tue, 1 Mar 2016 00:26:04 GMT"}], "update_date": "2016-03-02", "authors_parsed": [["Wang", "Y. X. Rachel", ""], ["Bickel", "Peter J.", ""]]}, {"id": "1502.02120", "submitter": "Davy Paindaveine", "authors": "Christine Cutting, Davy Paindaveine, Thomas Verdebout", "title": "Testing uniformity on high-dimensional spheres against monotone\n  rotationally symmetric alternatives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of testing uniformity on high-dimensional unit\nspheres. We are primarily interested in non-null issues. We show that\nrotationally symmetric alternatives lead to two Local Asymptotic Normality\n(LAN) structures. The first one is for fixed modal location $\\theta$ and allows\nto derive locally asymptotically most powerful tests under specified $\\theta$.\nThe second one, that addresses the Fisher-von Mises-Langevin (FvML) case,\nrelates to the unspecified-$\\theta$ problem and shows that the high-dimensional\nRayleigh test is locally asymptotically most powerful invariant. Under mild\nassumptions, we derive the asymptotic non-null distribution of this test, which\nallows to extend away from the FvML case the asymptotic powers obtained there\nfrom Le Cam's third lemma. Throughout, we allow the dimension $p$ to go to\ninfinity in an arbitrary way as a function of the sample size $n$. Some of our\nresults also strengthen the local optimality properties of the Rayleigh test in\nlow dimensions. We perform a Monte Carlo study to illustrate our asymptotic\nresults. Finally, we treat an application related to testing for sphericity in\nhigh dimensions.\n", "versions": [{"version": "v1", "created": "Sat, 7 Feb 2015 10:04:11 GMT"}, {"version": "v2", "created": "Thu, 16 Jul 2015 16:44:25 GMT"}, {"version": "v3", "created": "Fri, 17 Jul 2015 14:02:41 GMT"}, {"version": "v4", "created": "Mon, 18 Jan 2016 14:44:12 GMT"}, {"version": "v5", "created": "Wed, 27 Apr 2016 16:27:10 GMT"}], "update_date": "2016-04-28", "authors_parsed": [["Cutting", "Christine", ""], ["Paindaveine", "Davy", ""], ["Verdebout", "Thomas", ""]]}, {"id": "1502.02291", "submitter": "David King", "authors": "David B. King", "title": "Regularized Functional Canonical Correlation Analysis for Stochastic\n  Processes", "comments": "44 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we derive the asymptotic distributions of two distinct\nregularized estimators for functional canonical correlation as well as their\nassociated eigenvalues, eigenvectors and projection operators. The methods we\ndeveloped utilize regularized estimators which approach the functional\noperators based in reproducing kernel Hilbert spaces (RKHS) as the\nregularization parameter approaches zero. In addition to providing some\njustification for the RKHS methods, we explore the asymptotics of regularized\noperators associated with both Tikhinov and truncated singular value\ndecomposition (TSVD) type regularization. Together, these regularization\nmethods represent two of the most commonly utilized forms of regularization.\n", "versions": [{"version": "v1", "created": "Sun, 8 Feb 2015 19:34:58 GMT"}], "update_date": "2015-02-10", "authors_parsed": [["King", "David B.", ""]]}, {"id": "1502.02323", "submitter": "Satoshi Aoki", "authors": "Satoshi Aoki, Takayuki Hibi and Hidefumi Ohsugi", "title": "Markov chain Monte Carlo methods for the Box-Behnken designs and\n  centrally symmetric configurations", "comments": "15 pages, 1 figure", "journal-ref": "Journal of Statistical Theory and Practice 10 (2016), no. 1, 59-72", "doi": "10.1080/15598608.2015.1067172", "report-no": null, "categories": "math.ST math.AC stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider Markov chain Monte Carlo methods for calculating conditional p\nvalues of statistical models for count data arising in Box-Behnken designs. The\nstatistical model we consider is a discrete version of the first-order model in\nthe response surface methodology. For our models, the Markov basis, a key\nnotion to construct a connected Markov chain on a given sample space, is\ncharacterized as generators of the toric ideals for the centrally symmetric\nconfigurations of root system D_n. We show the structure of the Groebner bases\nfor these cases. A numerical example for an imaginary data set is given.\n", "versions": [{"version": "v1", "created": "Mon, 9 Feb 2015 01:12:32 GMT"}], "update_date": "2018-08-22", "authors_parsed": [["Aoki", "Satoshi", ""], ["Hibi", "Takayuki", ""], ["Ohsugi", "Hidefumi", ""]]}, {"id": "1502.02336", "submitter": "Debdeep Pati", "authors": "Anirban Bhattacharya and Debdeep Pati", "title": "Posterior contraction in Gaussian process regression using Wasserstein\n  approximations", "comments": "previous version modified to focus on the rate of posterior\n  convergence", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study posterior rates of contraction in Gaussian process regression with\nunbounded covariate domain. Our argument relies on developing a Gaussian\napproximation to the posterior of the leading coefficients of a\nKarhunen--Lo\\'{e}ve expansion of the Gaussian process. The salient feature of\nour result is deriving such an approximation in the $L^2$ Wasserstein distance\nand relating the speed of the approximation to the posterior contraction rate\nusing a coupling argument. Specific illustrations are provided for the Gaussian\nor squared-exponential covariance kernel.\n", "versions": [{"version": "v1", "created": "Mon, 9 Feb 2015 02:43:55 GMT"}, {"version": "v2", "created": "Fri, 2 Oct 2015 23:25:35 GMT"}], "update_date": "2015-10-06", "authors_parsed": [["Bhattacharya", "Anirban", ""], ["Pati", "Debdeep", ""]]}, {"id": "1502.02343", "submitter": "Rajesh Singh", "authors": "Prayas Sharma, Hemant K. Verma, Nitesh K. Adichwal and Rajesh Singh", "title": "Generalized estimators using characteristics of Poisson distribution", "comments": "16 pages, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we have proposed a generalized class of estimators,\nexponential class of estimators based on adaption of Sharma and Singh (2015)\nand Solanki and Singh (2013) and simple difference estimator for estimating\nunknown population mean in case of Poisson distributed population in simple\nrandom sampling without replacement. The expressions for mean square errors of\nthe proposed classes of estimators are derived to the first order of\napproximation. It is shown that the adapted version of Solanki and Singh\n(2013), exponential class of estimator, is always more efficient than usual\nestimator, ratio, product, exponential ratio and exponential product type\nestimators and equal efficient to simple difference estimator. Moreover, the\nadapted version of Sharma and Singh (2015) estimator are always more efficient\nthan all the estimators available in literature. In addition, theoretical\nfindings are supported by an empirical study to show the superiority of the\nconstructed estimators over others with earthquake data of Turkey.\n", "versions": [{"version": "v1", "created": "Mon, 9 Feb 2015 03:20:01 GMT"}], "update_date": "2015-02-10", "authors_parsed": [["Sharma", "Prayas", ""], ["Verma", "Hemant K.", ""], ["Adichwal", "Nitesh K.", ""], ["Singh", "Rajesh", ""]]}, {"id": "1502.02355", "submitter": "Shuheng Zhou", "authors": "Mark Rudelson and Shuheng Zhou", "title": "High dimensional errors-in-variables models with dependent measurements", "comments": "61 pages", "journal-ref": null, "doi": null, "report-no": "Department of Statistics TR 538, University of Michigan", "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suppose that we observe $y \\in \\mathbb{R}^f$ and $X \\in \\mathbb{R}^{f \\times\nm}$ in the following errors-in-variables model: \\begin{eqnarray*} y & = & X_0\n\\beta^* + \\epsilon \\\\ X & = & X_0 + W \\end{eqnarray*} where $X_0$ is a $f\n\\times m$ design matrix with independent subgaussian row vectors, $\\epsilon \\in\n\\mathbb{R}^f$ is a noise vector and $W$ is a mean zero $f \\times m$ random\nnoise matrix with independent subgaussian column vectors, independent of $X_0$\nand $\\epsilon$. This model is significantly different from those analyzed in\nthe literature in the sense that we allow the measurement error for each\ncovariate to be a dependent vector across its $f$ observations. Such error\nstructures appear in the science literature when modeling the trial-to-trial\nfluctuations in response strength shared across a set of neurons.\n  Under sparsity and restrictive eigenvalue type of conditions, we show that\none is able to recover a sparse vector $\\beta^* \\in \\mathbb{R}^m$ from the\nmodel given a single observation matrix $X$ and the response vector $y$. We\nestablish consistency in estimating $\\beta^*$ and obtain the rates of\nconvergence in the $\\ell_q$ norm, where $q = 1, 2$ for the Lasso-type\nestimator, and for $q \\in [1, 2]$ for a Dantzig-type conic programming\nestimator. We show error bounds which approach that of the regular Lasso and\nthe Dantzig selector in case the errors in $W$ are tending to 0.\n", "versions": [{"version": "v1", "created": "Mon, 9 Feb 2015 04:43:58 GMT"}, {"version": "v2", "created": "Fri, 18 Dec 2015 16:26:56 GMT"}], "update_date": "2015-12-21", "authors_parsed": [["Rudelson", "Mark", ""], ["Zhou", "Shuheng", ""]]}, {"id": "1502.02373", "submitter": "Liubov Markovich", "authors": "L.A. Markovich", "title": "Gamma kernel estimation of the density derivative on the positive\n  semi-axis by dependent data", "comments": "21 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We estimate the derivative of a probability density function defined on\n$[0,\\infty)$. For this purpose, we choose the class of kernel estimators with\nasymmetric gamma kernel functions. The use of gamma kernels is fruitful due to\nthe fact that they are nonnegative, change their shape depending on the\nposition on the semi-axis and possess good boundary properties for a wide class\nof densities. We find an optimal bandwidth of the kernel as a minimum of the\nmean integrated squared error by dependent data with strong mixing. This\nbandwidth differs from that proposed for the gamma kernel density estimation.\nTo this end, we derive the covariance of derivatives of the density and deduce\nits upper bound. Finally, the obtained results are applied to the case of a\nfirst-order autoregressive process with strong mixing. The accuracy of the\nestimates is checked by a simulation study. The comparison of the proposed\nestimates based on independent and dependent data is provided.\n", "versions": [{"version": "v1", "created": "Mon, 9 Feb 2015 06:09:35 GMT"}], "update_date": "2015-02-10", "authors_parsed": [["Markovich", "L. A.", ""]]}, {"id": "1502.02398", "submitter": "David Lopez-Paz", "authors": "David Lopez-Paz, Krikamol Muandet, Bernhard Sch\\\"olkopf, Ilya\n  Tolstikhin", "title": "Towards a Learning Theory of Cause-Effect Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We pose causal inference as the problem of learning to classify probability\ndistributions. In particular, we assume access to a collection\n$\\{(S_i,l_i)\\}_{i=1}^n$, where each $S_i$ is a sample drawn from the\nprobability distribution of $X_i \\times Y_i$, and $l_i$ is a binary label\nindicating whether \"$X_i \\to Y_i$\" or \"$X_i \\leftarrow Y_i$\". Given these data,\nwe build a causal inference rule in two steps. First, we featurize each $S_i$\nusing the kernel mean embedding associated with some characteristic kernel.\nSecond, we train a binary classifier on such embeddings to distinguish between\ncausal directions. We present generalization bounds showing the statistical\nconsistency and learning rates of the proposed approach, and provide a simple\nimplementation that achieves state-of-the-art cause-effect inference.\nFurthermore, we extend our ideas to infer causal relationships between more\nthan two variables.\n", "versions": [{"version": "v1", "created": "Mon, 9 Feb 2015 08:49:26 GMT"}, {"version": "v2", "created": "Mon, 18 May 2015 21:45:37 GMT"}], "update_date": "2015-05-20", "authors_parsed": [["Lopez-Paz", "David", ""], ["Muandet", "Krikamol", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["Tolstikhin", "Ilya", ""]]}, {"id": "1502.02501", "submitter": "Pascal Vallet", "authors": "Pascal Vallet and Xavier Mestre and Philippe Loubaton", "title": "A CLT for an improved subspace estimator with observations of increasing\n  dimensions", "comments": "Adding remark 2", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with subspace estimation in the small sample size regime,\nwhere the number of samples is comparable in magnitude with the observation\ndimension. The traditional estimators, mostly based on the sample correlation\nmatrix, are known to perform well as long as the number of available samples is\nmuch larger than the observation dimension. However, in the small sample size\nregime, the performance degrades. Recently, based on random matrix theory\nresults, a new subspace estimator was introduced, which was shown to be\nconsistent in the asymptotic regime where the number of samples and the\nobservation dimension converge to infinity at the same rate. In practice, this\nestimator outperforms the traditional ones even for certain scenarios where the\nobservation dimension is small and of the same order of magnitude as the number\nof samples. In this paper, we address a performance analysis of this recent\nestimator, by proving a central limit theorem in the above asymptotic regime.\nWe propose an accurate approximation of the mean square error, which can be\nevaluated numerically.\n", "versions": [{"version": "v1", "created": "Mon, 9 Feb 2015 14:36:29 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2015 08:11:35 GMT"}], "update_date": "2015-06-19", "authors_parsed": [["Vallet", "Pascal", ""], ["Mestre", "Xavier", ""], ["Loubaton", "Philippe", ""]]}, {"id": "1502.03049", "submitter": "Can Le", "authors": "Can M. Le, Elizaveta Levina, Roman Vershynin", "title": "Sparse random graphs: regularization and concentration of the Laplacian", "comments": "Added references", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.SI math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study random graphs with possibly different edge probabilities in the\nchallenging sparse regime of bounded expected degrees. Unlike in the dense\ncase, neither the graph adjacency matrix nor its Laplacian concentrate around\ntheir expectations due to the highly irregular distribution of node degrees. It\nhas been empirically observed that simply adding a constant of order $1/n$ to\neach entry of the adjacency matrix substantially improves the behavior of\nLaplacian. Here we prove that this regularization indeed forces Laplacian to\nconcentrate even in sparse graphs. As an immediate consequence in network\nanalysis, we establish the validity of one of the simplest and fastest\napproaches to community detection -- regularized spectral clustering, under the\nstochastic block model. Our proof of concentration of regularized Laplacian is\nbased on Grothendieck's inequality and factorization, combined with paving\narguments.\n", "versions": [{"version": "v1", "created": "Tue, 10 Feb 2015 19:37:24 GMT"}, {"version": "v2", "created": "Thu, 23 Apr 2015 05:44:44 GMT"}], "update_date": "2015-04-24", "authors_parsed": [["Le", "Can M.", ""], ["Levina", "Elizaveta", ""], ["Vershynin", "Roman", ""]]}, {"id": "1502.03211", "submitter": "Fang Han", "authors": "Cheng Zhou, Fang Han, Xinsheng Zhang, Han Liu", "title": "An Extreme-Value Approach for Testing the Equality of Large U-Statistic\n  Based Correlation Matrices", "comments": "to appear in Bernoulli", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been an increasing interest in testing the equality of large\nPearson's correlation matrices. However, in many applications it is more\nimportant to test the equality of large rank-based correlation matrices since\nthey are more robust to outliers and nonlinearity. Unlike the Pearson's case,\ntesting the equality of large rank-based statistics has not been well explored\nand requires us to develop new methods and theory. In this paper, we provide a\nframework for testing the equality of two large U-statistic based correlation\nmatrices, which include the rank-based correlation matrices as special cases.\nOur approach exploits extreme value statistics and the Jackknife estimator for\nuncertainty assessment and is valid under a fully nonparametric model.\nTheoretically, we develop a theory for testing the equality of U-statistic\nbased correlation matrices. We then apply this theory to study the problem of\ntesting large Kendall's tau correlation matrices and demonstrate its\noptimality. For proving this optimality, a novel construction of least\nfavourable distributions is developed for the correlation matrix comparison.\n", "versions": [{"version": "v1", "created": "Wed, 11 Feb 2015 07:54:25 GMT"}, {"version": "v2", "created": "Fri, 30 Mar 2018 16:51:19 GMT"}], "update_date": "2018-04-02", "authors_parsed": [["Zhou", "Cheng", ""], ["Han", "Fang", ""], ["Zhang", "Xinsheng", ""], ["Liu", "Han", ""]]}, {"id": "1502.03300", "submitter": "Jacopo Mandozzi", "authors": "Jacopo Mandozzi and Peter B\\\"uhlmann", "title": "A sequential rejection testing method for high-dimensional regression\n  with correlated variables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a general, modular method for significance testing of groups (or\nclusters) of variables in a high-dimensional linear model. In presence of high\ncorrelations among the covariables, due to serious problems of identifiability,\nit is indispensable to focus on detecting groups of variables rather than\nsingletons. We propose an inference method which allows to build in\nhierarchical structures. It relies on repeated sample splitting and sequential\nrejection, and we prove that it asymptotically controls the familywise error\nrate. It can be implemented on any collection of clusters and leads to improved\npower in comparison to more standard non-sequential rejection methods. We\ncomplete the theoretical analysis with empirical results for simulated and real\ndata.\n", "versions": [{"version": "v1", "created": "Wed, 11 Feb 2015 13:25:06 GMT"}], "update_date": "2015-02-12", "authors_parsed": [["Mandozzi", "Jacopo", ""], ["B\u00fchlmann", "Peter", ""]]}, {"id": "1502.03722", "submitter": "Thijs Laarhoven", "authors": "Thijs Laarhoven", "title": "Optimal sequential fingerprinting: Wald vs. Tardos", "comments": "12 pages, 10 figures", "journal-ref": "ACM Workshop on Information Hiding and Multimedia Security\n  (IH&MMSec), pp. 97-107, 2015", "doi": "10.1145/2756601.2756603", "report-no": null, "categories": "cs.CR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study sequential collusion-resistant fingerprinting, where the\nfingerprinting code is generated in advance but accusations may be made between\nrounds, and show that in this setting both the dynamic Tardos scheme and\nschemes building upon Wald's sequential probability ratio test (SPRT) are\nasymptotically optimal. We further compare these two approaches to sequential\nfingerprinting, highlighting differences between the two schemes. Based on\nthese differences, we argue that Wald's scheme should in general be preferred\nover the dynamic Tardos scheme, even though both schemes have their merits. As\na side result, we derive an optimal sequential group testing method for the\nclassical model, which can easily be generalized to different group testing\nmodels.\n", "versions": [{"version": "v1", "created": "Thu, 12 Feb 2015 16:36:46 GMT"}], "update_date": "2015-10-01", "authors_parsed": [["Laarhoven", "Thijs", ""]]}, {"id": "1502.03813", "submitter": "James Barrett", "authors": "James E. Barrett", "title": "Information-adaptive clinical trials: a selective recruitment design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel adaptive design for clinical trials with time-to-event\noutcomes and covariates (which may consist of or include biomarkers). Our\nmethod is based on the expected entropy of the posterior distribution of a\nproportional hazards model. The expected entropy is evaluated as a function of\na patient's covariates, and the information gained due to a patient is defined\nas the decrease in the corresponding entropy. Candidate patients are only\nrecruited onto the trial if they are likely to provide sufficient information.\nPatients with covariates that are deemed uninformative are filtered out. A\nspecial case is where all patients are recruited, and we determine the optimal\ntreatment arm allocation. This adaptive design has the advantage of potentially\nelucidating the relationship between covariates, treatments, and survival\nprobabilities using fewer patients, albeit at the cost of rejecting some\ncandidates. We assess the performance of our adaptive design using data from\nthe German Breast Cancer Study group and numerical simulations of a biomarker\nvalidation trial.\n", "versions": [{"version": "v1", "created": "Thu, 12 Feb 2015 20:59:42 GMT"}, {"version": "v2", "created": "Tue, 26 Jan 2016 16:19:45 GMT"}, {"version": "v3", "created": "Mon, 28 Mar 2016 16:06:34 GMT"}], "update_date": "2016-03-29", "authors_parsed": [["Barrett", "James E.", ""]]}, {"id": "1502.03836", "submitter": "Erwan Scornet", "authors": "Erwan Scornet (LSTA)", "title": "Random forests and kernel methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random forests are ensemble methods which grow trees as base learners and\ncombine their predictions by averaging. Random forests are known for their good\npractical performance, particularly in high dimensional set-tings. On the\ntheoretical side, several studies highlight the potentially fruitful connection\nbetween random forests and kernel methods. In this paper, we work out in full\ndetails this connection. In particular, we show that by slightly modifying\ntheir definition, random forests can be rewrit-ten as kernel methods (called\nKeRF for Kernel based on Random Forests) which are more interpretable and\neasier to analyze. Explicit expressions of KeRF estimates for some specific\nrandom forest models are given, together with upper bounds on their rate of\nconsistency. We also show empirically that KeRF estimates compare favourably to\nrandom forest estimates.\n", "versions": [{"version": "v1", "created": "Thu, 12 Feb 2015 21:20:47 GMT"}, {"version": "v2", "created": "Thu, 17 Sep 2015 12:49:54 GMT"}], "update_date": "2015-09-18", "authors_parsed": [["Scornet", "Erwan", "", "LSTA"]]}, {"id": "1502.03955", "submitter": "Brahimi Brahim", "authors": "Brahim Brahimi, Djamel Meraghni and Abdelhakim Necir", "title": "Nelson-Aalen tail product-limit process and extreme value index\n  estimation under random censorship", "comments": "submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  On the basis of Nelson-Aalen nonparametric estimator of the cumulative\ndistribution function, we provide a weak approximation to tail product-limit\nprocess for randomly right-censored heavy-tailed data. In this context, a new\nconsistent reduced-bias estimator of the extreme value index is introduced and\nits asymptotic normality is established only by assuming the second-order\nregular variation of the underlying distribution function. A simulation study\nshows that the newly proposed estimator performs better than the existing ones.\n", "versions": [{"version": "v1", "created": "Fri, 13 Feb 2015 11:57:38 GMT"}, {"version": "v2", "created": "Fri, 22 Jul 2016 13:32:59 GMT"}], "update_date": "2016-07-25", "authors_parsed": [["Brahimi", "Brahim", ""], ["Meraghni", "Djamel", ""], ["Necir", "Abdelhakim", ""]]}, {"id": "1502.04071", "submitter": "Yaniv Plan", "authors": "Yaniv Plan and Roman Vershynin", "title": "The generalized Lasso with non-linear observations", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of signal estimation from non-linear observations when\nthe signal belongs to a low-dimensional set buried in a high-dimensional space.\nA rough heuristic often used in practice postulates that non-linear\nobservations may be treated as noisy linear observations, and thus the signal\nmay be estimated using the generalized Lasso. This is appealing because of the\nabundance of efficient, specialized solvers for this program. Just as noise may\nbe diminished by projecting onto the lower dimensional space, the error from\nmodeling non-linear observations with linear observations will be greatly\nreduced when using the signal structure in the reconstruction. We allow general\nsignal structure, only assuming that the signal belongs to some set K in R^n.\nWe consider the single-index model of non-linearity. Our theory allows the\nnon-linearity to be discontinuous, not one-to-one and even unknown. We assume a\nrandom Gaussian model for the measurement matrix, but allow the rows to have an\nunknown covariance matrix. As special cases of our results, we recover\nnear-optimal theory for noisy linear observations, and also give the first\ntheoretical accuracy guarantee for 1-bit compressed sensing with unknown\ncovariance matrix of the measurement vectors.\n", "versions": [{"version": "v1", "created": "Fri, 13 Feb 2015 17:56:06 GMT"}, {"version": "v2", "created": "Mon, 16 Nov 2015 19:32:13 GMT"}], "update_date": "2015-11-17", "authors_parsed": [["Plan", "Yaniv", ""], ["Vershynin", "Roman", ""]]}, {"id": "1502.04189", "submitter": "Marco Chiani Dr.", "authors": "Marco Chiani", "title": "On the probability that all eigenvalues of Gaussian, Wishart, and double\n  Wishart random matrices lie within an interval", "comments": "IEEE Transactions on Information Theory, 2017", "journal-ref": null, "doi": "10.1109/TIT.2017.2694846", "report-no": null, "categories": "math.ST cs.IT math-ph math.IT math.MP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive the probability that all eigenvalues of a random matrix $\\bf M$ lie\nwithin an arbitrary interval $[a,b]$,\n$\\psi(a,b)\\triangleq\\Pr\\{a\\leq\\lambda_{\\min}({\\bf M}), \\lambda_{\\max}({\\bf\nM})\\leq b\\}$, when $\\bf M$ is a real or complex finite dimensional Wishart,\ndouble Wishart, or Gaussian symmetric/Hermitian matrix. We give efficient\nrecursive formulas allowing the exact evaluation of $\\psi(a,b)$ for Wishart\nmatrices, even with large number of variates and degrees of freedom. We also\nprove that the probability that all eigenvalues are within the limiting\nspectral support (given by the Mar{\\v{c}}enko-Pastur or the semicircle laws)\ntends for large dimensions to the universal values $0.6921$ and $0.9397$ for\nthe real and complex cases, respectively. Applications include improved bounds\nfor the probability that a Gaussian measurement matrix has a given restricted\nisometry constant in compressed sensing.\n", "versions": [{"version": "v1", "created": "Sat, 14 Feb 2015 11:05:22 GMT"}, {"version": "v2", "created": "Sat, 22 Apr 2017 08:12:08 GMT"}], "update_date": "2017-04-25", "authors_parsed": [["Chiani", "Marco", ""]]}, {"id": "1502.04203", "submitter": "Subrata Chakraborty", "authors": "Subrata Chakraborty", "title": "Transmuted Geometric Distribution and its Prpoerties", "comments": "10 pages, 1 figure, prepreprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transmuted geometric distribution with two parameters and is proposed as a\nnew generalization of the geometric distribution by employing the quadratic\ntransmutation techniques of Shaw and Buckley (2007). Its important\ndistributional and reliability properties are investigated. Parameter\nestimation methods is discussed.\n", "versions": [{"version": "v1", "created": "Sat, 14 Feb 2015 12:29:11 GMT"}], "update_date": "2015-02-17", "authors_parsed": [["Chakraborty", "Subrata", ""]]}, {"id": "1502.04237", "submitter": "Wen-Xin Zhou", "authors": "Jianqing Fan, Qi-Man Shao, Wen-Xin Zhou", "title": "Are Discoveries Spurious? Distributions of Maximum Spurious Correlations\n  and Their Applications", "comments": null, "journal-ref": null, "doi": "10.1214/17-AOS1575", "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the last two decades, many exciting variable selection methods have been\ndeveloped for finding a small group of covariates that are associated with the\nresponse from a large pool. Can the discoveries from these data mining\napproaches be spurious due to high dimensionality and limited sample size? Can\nour fundamental assumptions about the exogeneity of the covariates needed for\nsuch variable selection be validated with the data? To answer these questions,\nwe need to derive the distributions of the maximum spurious correlations given\na certain number of predictors, namely, the distribution of the correlation of\na response variable $Y$ with the best $s$ linear combinations of $p$ covariates\n$\\mathbf{X}$, even when $\\mathbf{X}$ and $Y$ are independent. When the\ncovariance matrix of $\\mathbf{X}$ possesses the restricted eigenvalue property,\nwe derive such distributions for both a finite $s$ and a diverging $s$, using\nGaussian approximation and empirical process techniques. However, such a\ndistribution depends on the unknown covariance matrix of $\\mathbf{X}$. Hence,\nwe use the multiplier bootstrap procedure to approximate the unknown\ndistributions and establish the consistency of such a simple bootstrap\napproach. The results are further extended to the situation where the residuals\nare from regularized fits. Our approach is then used to construct the upper\nconfidence limit for the maximum spurious correlation and to test the\nexogeneity of the covariates. The former provides a baseline for guarding\nagainst false discoveries and the latter tests whether our fundamental\nassumptions for high-dimensional model selection are statistically valid. Our\ntechniques and results are illustrated with both numerical examples and real\ndata analysis.\n", "versions": [{"version": "v1", "created": "Sat, 14 Feb 2015 19:42:19 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2015 00:14:48 GMT"}, {"version": "v3", "created": "Tue, 11 Apr 2017 21:14:04 GMT"}, {"version": "v4", "created": "Fri, 21 Jul 2017 14:14:14 GMT"}], "update_date": "2017-07-24", "authors_parsed": [["Fan", "Jianqing", ""], ["Shao", "Qi-Man", ""], ["Zhou", "Wen-Xin", ""]]}, {"id": "1502.04620", "submitter": "Wolfgang Trutschnig", "authors": "Manuela Schreyer and Roland Paulin and Wolfgang Trutschnig", "title": "On the exact region determined by Kendall's tau and Spearman's rho", "comments": "24 pages, 4 figures", "journal-ref": "Journal of the Royal Statistical Society: Series B (Statistical\n  Methodology) 79 (2), 613-633 (2017)", "doi": "10.1111/rssb.12181", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using properties of shuffles of copulas and tools from combinatorics we solve\nthe open question about the exact region $\\Omega$ determined by all possible\nvalues of Kendall's $\\tau$ and Spearman's $\\rho$. In particular, we prove that\nthe well-known inequality established by Durbin and Stuart in 1951 is only\nsharp on a countable set with sole accumulation point $(-1,-1)$, give a simple\nanalytic characterization of $\\Omega$ in terms of a continuous, strictly\nincreasing piecewise concave function, and show that $\\Omega$ is compact and\nsimply connected but not convex. The results also show that for each $(x,y)\\in\n\\Omega$ there are mutually completely dependent random variables whose $\\tau$\nand $\\rho$ values coincide with $x$ and $y$ respectively.\n", "versions": [{"version": "v1", "created": "Mon, 16 Feb 2015 16:44:49 GMT"}, {"version": "v2", "created": "Thu, 20 Apr 2017 11:15:41 GMT"}], "update_date": "2017-04-21", "authors_parsed": [["Schreyer", "Manuela", ""], ["Paulin", "Roland", ""], ["Trutschnig", "Wolfgang", ""]]}, {"id": "1502.04643", "submitter": "Christoph  Mecklenbr\\\"auker", "authors": "Christoph F. Mecklenbr\\\"auker, Peter Gerstoft, Erich Z\\\"ochmann", "title": "Using the LASSO's Dual for Regularization in Sparse Signal\n  Reconstruction from Array Data", "comments": "submitted to IEEE Transactions on Signal Processing, 09-Aug-2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Waves from a sparse set of source hidden in additive noise are observed by a\nsensor array. We treat the estimation of the sparse set of sources as a\ngeneralized complex-valued LASSO problem. The corresponding dual problem is\nformulated and it is shown that the dual solution is useful for selecting the\nregularization parameter of the LASSO when the number of sources is given. The\nsolution path of the complex-valued LASSO is analyzed. For a given number of\nsources, the corresponding regularization parameter is determined by an\norder-recursive algorithm and two iterative algorithms that are based on a\nfurther approximation. Using this regularization parameter, the DOAs of all\nsources are estimated.\n", "versions": [{"version": "v1", "created": "Mon, 16 Feb 2015 17:30:57 GMT"}, {"version": "v2", "created": "Wed, 2 Sep 2015 09:38:02 GMT"}], "update_date": "2015-09-03", "authors_parsed": [["Mecklenbr\u00e4uker", "Christoph F.", ""], ["Gerstoft", "Peter", ""], ["Z\u00f6chmann", "Erich", ""]]}, {"id": "1502.04654", "submitter": "Alexandra Carpentier", "authors": "Alexandra Carpentier and Arlene K. H. Kim", "title": "An iterative hard thresholding estimator for low rank matrix recovery\n  with explicit limiting distribution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of low rank matrix recovery in a stochastically noisy\nhigh dimensional setting. We propose a new estimator for the low rank matrix,\nbased on the iterative hard thresholding method, and that is computationally\nefficient and simple. We prove that our estimator is efficient both in terms of\nthe Frobenius risk, and in terms of the entry-wise risk uniformly over any\nchange of orthonormal basis. This result allows us, in the case where the\ndesign is Gaussian, to provide the limiting distribution of the estimator,\nwhich is of great interest for constructing tests and confidence sets for low\ndimensional subsets of entries of the low rank matrix.\n", "versions": [{"version": "v1", "created": "Mon, 16 Feb 2015 18:17:43 GMT"}, {"version": "v2", "created": "Tue, 17 Feb 2015 15:56:02 GMT"}, {"version": "v3", "created": "Tue, 1 Mar 2016 11:11:13 GMT"}], "update_date": "2016-03-02", "authors_parsed": [["Carpentier", "Alexandra", ""], ["Kim", "Arlene K. H.", ""]]}, {"id": "1502.04733", "submitter": "Weichen Wang", "authors": "Jianqing Fan and Weichen Wang", "title": "Asymptotics of Empirical Eigen-structure for Ultra-high Dimensional\n  Spiked Covariance Model", "comments": "50 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive the asymptotic distributions of the spiked eigenvalues and\neigenvectors under a generalized and unified asymptotic regime, which takes\ninto account the spike magnitude of leading eigenvalues, sample size, and\ndimensionality. This new regime allows high dimensionality and diverging\neigenvalue spikes and provides new insights into the roles the leading\neigenvalues, sample size, and dimensionality play in principal component\nanalysis. The results are proven by a technical device, which swaps the role of\nrows and columns and converts the high-dimensional problems into\nlow-dimensional ones. Our results are a natural extension of those in Paul\n(2007) to more general setting with new insights and solve the rates of\nconvergence problems in Shen et al. (2013). They also reveal the biases of the\nestimation of leading eigenvalues and eigenvectors by using principal component\nanalysis, and lead to a new covariance estimator for the approximate factor\nmodel, called shrinkage principal orthogonal complement thresholding (S-POET),\nthat corrects the biases. Our results are successfully applied to outstanding\nproblems in estimation of risks of large portfolios and false discovery\nproportions for dependent test statistics and are illustrated by simulation\nstudies.\n", "versions": [{"version": "v1", "created": "Mon, 16 Feb 2015 21:44:14 GMT"}, {"version": "v2", "created": "Sat, 12 Sep 2015 05:04:14 GMT"}], "update_date": "2015-09-15", "authors_parsed": [["Fan", "Jianqing", ""], ["Wang", "Weichen", ""]]}, {"id": "1502.04874", "submitter": "Sebastien Gadat", "authors": "S\\'ebastien Gadat and Fabien Panloup and Sofiane Saadane", "title": "Regret bounds for Narendra-Shapiro bandit algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Narendra-Shapiro (NS) algorithms are bandit-type algorithms that have been\nintroduced in the sixties (with a view to applications in Psychology or\nlearning automata), whose convergence has been intensively studied in the\nstochastic algorithm literature. In this paper, we adress the following\nquestion: are the Narendra-Shapiro (NS) bandit algorithms competitive from a\n\\textit{regret} point of view? In our main result, we show that some\ncompetitive bounds can be obtained for such algorithms in their penalized\nversion (introduced in \\cite{Lamberton_Pages}). More precisely, up to an\nover-penalization modification, the pseudo-regret $\\bar{R}_n$ related to the\npenalized two-armed bandit algorithm is uniformly bounded by $C \\sqrt{n}$\n(where $C$ is made explicit in the paper). \\noindent We also generalize\nexisting convergence and rates of convergence results to the multi-armed case\nof the over-penalized bandit algorithm, including the convergence toward the\ninvariant measure of a Piecewise Deterministic Markov Process (PDMP) after a\nsuitable renormalization. Finally, ergodic properties of this PDMP are given in\nthe multi-armed case.\n", "versions": [{"version": "v1", "created": "Tue, 17 Feb 2015 12:49:01 GMT"}, {"version": "v2", "created": "Sat, 16 Jan 2016 13:13:35 GMT"}], "update_date": "2016-01-19", "authors_parsed": [["Gadat", "S\u00e9bastien", ""], ["Panloup", "Fabien", ""], ["Saadane", "Sofiane", ""]]}, {"id": "1502.04890", "submitter": "Leonid Torgovitski", "authors": "Leonid Torgovitski", "title": "Algorithm for overlapping estimation of common change-sets in spatial\n  data of fixed size", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a flexible class of estimates for \"common change in the mean\" sets\nin spatio-temporal data. We rely on a scan type approach by subdividing the\nspatial observations into suitable overlapping regions to which classical CUSUM\n(cumulative sums) estimates may then be applied separately. The aggregated\n\"local\" estimates are used to construct consistent \"global\" estimates of the\nchange set(s) by taking the overlapping structure into account. The domain and\nthe change regions may have irregular shapes and the suggested procedure is\nespecially suited for estimation of multiple change regions. The performance is\ndemonstrated in a simulation study.\n", "versions": [{"version": "v1", "created": "Tue, 17 Feb 2015 13:40:36 GMT"}], "update_date": "2015-02-18", "authors_parsed": [["Torgovitski", "Leonid", ""]]}, {"id": "1502.04900", "submitter": "Krist\\'of K\\\"ormendi", "authors": "Krist\\'of K\\\"ormendi, Gyula Pap", "title": "Statistical inference of 2-type critical Galton-Watson processes with\n  immigration", "comments": "61 pages. Restates Appendices, and some earlier results from\n  arXiv:1210.8315, arXiv:1406.3325, and arXiv:1202.1617 for sake of\n  completeness", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper the asymptotic behavior of the conditional least squares\nestimators of the offspring mean matrix for a 2-type critical positively\nregular Galton-Watson branching process with immigration is described.We also\nstudy this question for a natural estimator of the spectral radius of the\noffspring mean matrix, which we call criticality parameter. We discuss the\nsubcritical case as well.\n", "versions": [{"version": "v1", "created": "Tue, 17 Feb 2015 14:10:12 GMT"}, {"version": "v2", "created": "Mon, 9 May 2016 08:39:10 GMT"}], "update_date": "2016-05-10", "authors_parsed": [["K\u00f6rmendi", "Krist\u00f3f", ""], ["Pap", "Gyula", ""]]}, {"id": "1502.04977", "submitter": "Christos Thrampoulidis", "authors": "Christos Thrampoulidis, Ashkan Panahi, Daniel Guo, Babak Hassibi", "title": "Precise Error Analysis of the $\\ell_2$-LASSO", "comments": "in 40th IEEE International Conference on Acoustics, Speech and Signal\n  Processing (ICASSP) 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.OC stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A classical problem that arises in numerous signal processing applications\nasks for the reconstruction of an unknown, $k$-sparse signal $x_0\\in R^n$ from\nunderdetermined, noisy, linear measurements $y=Ax_0+z\\in R^m$. One standard\napproach is to solve the following convex program $\\hat x=\\arg\\min_x \\|y-Ax\\|_2\n+ \\lambda \\|x\\|_1$, which is known as the $\\ell_2$-LASSO. We assume that the\nentries of the sensing matrix $A$ and of the noise vector $z$ are i.i.d\nGaussian with variances $1/m$ and $\\sigma^2$. In the large system limit when\nthe problem dimensions grow to infinity, but in constant rates, we\n\\emph{precisely} characterize the limiting behavior of the normalized\nsquared-error $\\|\\hat x-x_0\\|^2_2/\\sigma^2$. Our numerical illustrations\nvalidate our theoretical predictions.\n", "versions": [{"version": "v1", "created": "Tue, 17 Feb 2015 17:49:46 GMT"}], "update_date": "2015-02-18", "authors_parsed": [["Thrampoulidis", "Christos", ""], ["Panahi", "Ashkan", ""], ["Guo", "Daniel", ""], ["Hassibi", "Babak", ""]]}, {"id": "1502.04985", "submitter": "Natalia Markovich M", "authors": "Natalia Markovich", "title": "Extremes Control of Complex Systems With Applications to Social Network", "comments": "6 pages, 6 figures, conference IFAC INCOM-2015, Ottawa, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The control and risk assessment in complex information systems require to\ntake into account extremes arising from nodes with large node degrees. Various\nsampling techniques like a Page Rank random walk, a Metropolis-Hastings Markov\nchain and others serve to collect information about the nodes. The paper\ncontributes to the comparison of sampling techniques in complex networks by\nmeans of the first hitting time, that is the minimal time required to reach a\nlarge node. Both the mean and the distribution of the first hitting time is\nshown to be determined by the so called extremal index. The latter indicates a\ndependence measure of extremes and also reflects the cluster structure of the\nnetwork. The clustering is caused by dependence between nodes and heavy-tailed\ndistributions of their degrees. Based on extreme value theory we estimate the\nmean and the distribution of the first hitting time and the distribution of\nnode degrees by real data from social networks. We demonstrate the heaviness of\nthe tails of these data using appropriate tools. The same methodology can be\napplied to other complex networks like peer-to-peer telecommunication systems.\n", "versions": [{"version": "v1", "created": "Tue, 17 Feb 2015 18:17:52 GMT"}], "update_date": "2015-02-18", "authors_parsed": [["Markovich", "Natalia", ""]]}, {"id": "1502.05017", "submitter": "Brahimi Brahim", "authors": "Brahim Brahimi and Zoubir Kenioua", "title": "Robust estimator of distortion risk premiums for heavy-tailed losses", "comments": "submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We use the so-called t-Hill tail index estimator proposed by Fabi\\'an(2001),\nrather than Hill's one, to derive a robust estimator for the distortion risk\npremium of loss. Under the second-order condition of regular variation, we\nestablish its asymptotic normality. By simulation study, we show that this new\nestimator is more robust than of Necir and Meraghni 2009 both for small and\nlarge samples.\n", "versions": [{"version": "v1", "created": "Tue, 17 Feb 2015 20:11:27 GMT"}, {"version": "v2", "created": "Fri, 4 Dec 2015 20:09:15 GMT"}, {"version": "v3", "created": "Sat, 13 Feb 2016 20:24:58 GMT"}], "update_date": "2016-02-16", "authors_parsed": [["Brahimi", "Brahim", ""], ["Kenioua", "Zoubir", ""]]}, {"id": "1502.05032", "submitter": "Konstantin Zuev M", "authors": "Konstantin Zuev, Or Eisenberg, Dmitri Krioukov", "title": "Exponential Random Simplicial Complexes", "comments": "22 pages, 6 figures", "journal-ref": "J. Phys. A: Math. Theor. 48 465002 (2015)", "doi": "10.1088/1751-8113/48/46/465002", "report-no": null, "categories": "math.ST cond-mat.stat-mech math.PR physics.soc-ph stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exponential random graph models have attracted significant research attention\nover the past decades. These models are maximum-entropy ensembles under the\nconstraints that the expected values of a set of graph observables are equal to\ngiven values. Here we extend these maximum-entropy ensembles to random\nsimplicial complexes, which are more adequate and versatile constructions to\nmodel complex systems in many applications. We show that many random simplicial\ncomplex models considered in the literature can be casted as maximum-entropy\nensembles under certain constraints. We introduce and analyze the most general\nrandom simplicial complex ensemble $\\mathbf{\\Delta}$ with statistically\nindependent simplices. Our analysis is simplified by the observation that any\ndistribution $\\mathbb{P}(O)$ on any collection of objects $\\mathcal{O}=\\{O\\}$,\nincluding graphs and simplicial complexes, is maximum-entropy under the\nconstraint that the expected value of $-\\ln \\mathbb{P}(O)$ is equal to the\nentropy of the distribution. With the help of this observation, we prove that\nensemble $\\mathbf{\\Delta}$ is maximum-entropy under two types of constraints\nthat fix the expected numbers of simplices and their boundaries.\n", "versions": [{"version": "v1", "created": "Tue, 17 Feb 2015 20:48:26 GMT"}, {"version": "v2", "created": "Thu, 29 Oct 2015 17:33:08 GMT"}], "update_date": "2015-10-30", "authors_parsed": [["Zuev", "Konstantin", ""], ["Eisenberg", "Or", ""], ["Krioukov", "Dmitri", ""]]}, {"id": "1502.05457", "submitter": "Pierpaolo Brutti", "authors": "Pierpaolo Brutti", "title": "A note on an Adaptive Goodness-of-Fit test with Finite Sample Validity\n  for Random Design Regression Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given an i.i.d. sample $\\{(X_i,Y_i)\\}_{i \\in \\{1 \\ldots n\\}}$ from the random\ndesign regression model $Y = f(X) + \\epsilon$ with $(X,Y) \\in [0,1] \\times\n[-M,M]$, in this paper we consider the problem of testing the (simple) null\nhypothesis $f = f_0$, against the alternative $f \\neq f_0$ for a fixed $f_0 \\in\nL^2([0,1],G_X)$, where $G_X(\\cdot)$ denotes the marginal distribution of the\ndesign variable $X$. The procedure proposed is an adaptation to the regression\nsetting of a multiple testing technique introduced by Fromont and Laurent\n(2005), and it amounts to consider a suitable collection of unbiased estimators\nof the $L^2$--distance $d_2(f,f_0) = \\int {[f(x) - f_0 (x)]^2 d\\,G_X (x)}$,\nrejecting the null hypothesis when at least one of them is greater than its\n$(1-u_\\alpha)$ quantile, with $u_\\alpha$ calibrated to obtain a level--$\\alpha$\ntest. To build these estimators, we will use the warped wavelet basis\nintroduced by Picard and Kerkyacharian (2004). We do not assume that the errors\nare normally distributed, and we do not assume that $X$ and $\\epsilon$ are\nindependent but, mainly for technical reasons, we will assume, as in most part\nof the current literature in learning theory, that $|f(x) - y|$ is uniformly\nbounded (almost everywhere). We show that our test is adaptive over a\nparticular collection of approximation spaces linked to the classical Besov\nspaces.\n", "versions": [{"version": "v1", "created": "Thu, 19 Feb 2015 03:17:18 GMT"}], "update_date": "2015-02-20", "authors_parsed": [["Brutti", "Pierpaolo", ""]]}, {"id": "1502.05460", "submitter": "Tavis Abrahamsen", "authors": "Tavis Abrahamsen, James P. Hobert", "title": "Convergence analysis of block Gibbs samplers for Bayesian linear mixed\n  models with $p>N$", "comments": "Published at http://dx.doi.org/10.3150/15-BEJ749 in the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2017, Vol. 23, No. 1, 459-478", "doi": "10.3150/15-BEJ749", "report-no": "IMS-BEJ-BEJ749", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploration of the intractable posterior distributions associated with\nBayesian versions of the general linear mixed model is often performed using\nMarkov chain Monte Carlo. In particular, if a conditionally conjugate prior is\nused, then there is a simple two-block Gibbs sampler available. Rom\\'{a}n and\nHobert [Linear Algebra Appl. 473 (2015) 54-77] showed that, when the priors are\nproper and the $X$ matrix has full column rank, the Markov chains underlying\nthese Gibbs samplers are nearly always geometrically ergodic. In this paper,\nRom\\'{a}n and Hobert's (2015) result is extended by allowing improper priors on\nthe variance components, and, more importantly, by removing all assumptions on\nthe $X$ matrix. So, not only is $X$ allowed to be (column) rank deficient,\nwhich provides additional flexibility in parameterizing the fixed effects, it\nis also allowed to have more columns than rows, which is necessary in the\nincreasingly important situation where $p>N$. The full rank assumption on $X$\nis at the heart of Rom\\'{a}n and Hobert's (2015) proof. Consequently, the\nextension to unrestricted $X$ requires a substantially different analysis.\n", "versions": [{"version": "v1", "created": "Thu, 19 Feb 2015 03:51:22 GMT"}, {"version": "v2", "created": "Wed, 1 Apr 2015 17:40:12 GMT"}, {"version": "v3", "created": "Fri, 30 Sep 2016 07:56:07 GMT"}], "update_date": "2016-10-03", "authors_parsed": [["Abrahamsen", "Tavis", ""], ["Hobert", "James P.", ""]]}, {"id": "1502.05510", "submitter": "Markus Rei{\\ss}", "authors": "Nikolay Baldin and Markus Rei{\\ss}", "title": "Unbiased estimation of the volume of a convex body", "comments": "slightly extended version", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Based on observations of points uniformly distributed over a convex set in\n$\\R^d$, a new estimator for the volume of the convex set is proposed. The\nestimator is minimax optimal and also efficient non-asymptotically: it is\nnearly unbiased with minimal variance among all unbiased oracle-type\nestimators. Our approach is based on a Poisson point process model and as an\ningredient, we prove that the convex hull is a sufficient and complete\nstatistic. No hypotheses on the boundary of the convex set are imposed. In a\nnumerical study, we show that the estimator outperforms earlier estimators for\nthe volume. In addition, an improved set estimator for the convex body itself\nis proposed.\n", "versions": [{"version": "v1", "created": "Thu, 19 Feb 2015 09:33:44 GMT"}, {"version": "v2", "created": "Thu, 16 Jul 2015 11:04:28 GMT"}, {"version": "v3", "created": "Thu, 21 Jan 2016 08:00:59 GMT"}], "update_date": "2016-01-22", "authors_parsed": [["Baldin", "Nikolay", ""], ["Rei\u00df", "Markus", ""]]}, {"id": "1502.05522", "submitter": "Diane  Donovan Dr", "authors": "Diane Donovan, Benjamin Haaland, David J. Nott", "title": "A Simple Approach to Constructing Quasi-Sudoku-based Sliced\n  Space-Filling Designs", "comments": "15 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sliced Sudoku-based space-filling designs and, more generally, quasi-sliced\northogonal array-based space-filling designs are useful experimental designs in\nseveral contexts, including computer experiments with categorical in addition\nto quantitative inputs and cross-validation. Here, we provide a straightforward\nconstruction of doubly orthogonal quasi-Sudoku Latin squares which can be used\nto generate sliced space-filling designs which achieve uniformity in one and\ntwo-dimensional projections for both the full design and each slice. A\nconstruction of quasi-sliced orthogonal arrays based on these constructed\ndoubly orthogonal quasi-Sudoku Latin squares is also provided and can, in turn,\nbe used to generate sliced space-filling designs which achieve uniformity in\none and two-dimensional projections for the full design and and uniformity in\ntwo-dimensional projections for each slice. These constructions are very\npractical to implement and yield a spectrum of design sizes and numbers of\nfactors not currently broadly available.\n", "versions": [{"version": "v1", "created": "Thu, 19 Feb 2015 10:33:27 GMT"}], "update_date": "2015-02-20", "authors_parsed": [["Donovan", "Diane", ""], ["Haaland", "Benjamin", ""], ["Nott", "David J.", ""]]}, {"id": "1502.05990", "submitter": "Jie Yang", "authors": "Jie Yang, Liping Tong and Abhyuday Mandal", "title": "D-optimal Designs with Ordered Categorical Data", "comments": "38 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cumulative link models have been widely used for ordered categorical\nresponses. Uniform allocation of experimental units is commonly used in\npractice, but often suffers from a lack of efficiency. We consider D-optimal\ndesigns with ordered categorical responses and cumulative link models. For a\npredetermined set of design points, we derive the necessary and sufficient\nconditions for an allocation to be locally D-optimal and develop efficient\nalgorithms for obtaining approximate and exact designs. We prove that the\nnumber of support points in a minimally supported design only depends on the\nnumber of predictors, which can be much less than the number of parameters in\nthe model. We show that a D-optimal minimally supported allocation in this case\nis usually not uniform on its support points. In addition, we provide EW\nD-optimal designs as a highly efficient surrogate to Bayesian D-optimal\ndesigns. Both of them can be much more robust than uniform designs.\n", "versions": [{"version": "v1", "created": "Fri, 20 Feb 2015 20:51:49 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2015 03:47:54 GMT"}, {"version": "v3", "created": "Tue, 26 Apr 2016 02:52:20 GMT"}, {"version": "v4", "created": "Sat, 10 Sep 2016 06:48:17 GMT"}, {"version": "v5", "created": "Wed, 8 Nov 2017 05:01:57 GMT"}], "update_date": "2017-11-09", "authors_parsed": [["Yang", "Jie", ""], ["Tong", "Liping", ""], ["Mandal", "Abhyuday", ""]]}, {"id": "1502.06046", "submitter": "Thomas Fung", "authors": "Thomas Fung and Eugene Seneta", "title": "Tail dependence convergence rate for the bivariate skew normal under the\n  equal-skewness condition", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive the rate of decay of the tail dependence of the bivariate skew\nnormal distribution under the equal-skewness condition {\\theta}1 = {\\theta}2,=\n{\\theta}, say. The rate of convergence depends on whether {\\theta} > 0 or\n{\\theta} < 0. The latter case gives rate asymp- totically identical with the\ncase {\\theta} = 0. The asymptotic behaviour of the quantile function for the\nunivariate skew normal is part of the theoretical development.\n", "versions": [{"version": "v1", "created": "Sat, 21 Feb 2015 00:30:56 GMT"}], "update_date": "2015-02-24", "authors_parsed": [["Fung", "Thomas", ""], ["Seneta", "Eugene", ""]]}, {"id": "1502.06134", "submitter": "Tengyuan Liang", "authors": "Tengyuan Liang, Alexander Rakhlin, Karthik Sridharan", "title": "Learning with Square Loss: Localization through Offset Rademacher\n  Complexity", "comments": "21 pages, 1 figure", "journal-ref": "Proceedings of the 28th Conference on Learning Theory 40 (2015)\n  1260-1285", "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider regression with square loss and general classes of functions\nwithout the boundedness assumption. We introduce a notion of offset Rademacher\ncomplexity that provides a transparent way to study localization both in\nexpectation and in high probability. For any (possibly non-convex) class, the\nexcess loss of a two-step estimator is shown to be upper bounded by this offset\ncomplexity through a novel geometric inequality. In the convex case, the\nestimator reduces to an empirical risk minimizer. The method recovers the\nresults of \\citep{RakSriTsy15} for the bounded case while also providing\nguarantees without the boundedness assumption.\n", "versions": [{"version": "v1", "created": "Sat, 21 Feb 2015 19:20:44 GMT"}, {"version": "v2", "created": "Thu, 26 Feb 2015 16:10:05 GMT"}, {"version": "v3", "created": "Mon, 15 Jun 2015 15:20:08 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Liang", "Tengyuan", ""], ["Rakhlin", "Alexander", ""], ["Sridharan", "Karthik", ""]]}, {"id": "1502.06144", "submitter": "Quentin Berthet", "authors": "Quentin Berthet and Jordan S. Ellenberg", "title": "Detection of Planted Solutions for Flat Satisfiability Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.CC cs.LG stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the detection problem of finding planted solutions in random\ninstances of flat satisfiability problems, a generalization of boolean\nsatisfiability formulas. We describe the properties of random instances of flat\nsatisfiability, as well of the optimal rates of detection of the associated\nhypothesis testing problem. We also study the performance of an algorithmically\nefficient testing procedure. We introduce a modification of our model, the\nlight planting of solutions, and show that it is as hard as the problem of\nlearning parity with noise. This hints strongly at the difficulty of detecting\nplanted flat satisfiability for a wide class of tests.\n", "versions": [{"version": "v1", "created": "Sat, 21 Feb 2015 22:14:04 GMT"}, {"version": "v2", "created": "Wed, 6 Mar 2019 15:07:54 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Berthet", "Quentin", ""], ["Ellenberg", "Jordan S.", ""]]}, {"id": "1502.06197", "submitter": "Adel Javanmard", "authors": "Adel Javanmard and Andrea Montanari", "title": "On Online Control of False Discovery Rate", "comments": "31 pages, 6 figures (minor edits)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple hypotheses testing is a core problem in statistical inference and\narises in almost every scientific field. Given a sequence of null hypotheses\n$\\mathcal{H}(n) = (H_1,..., H_n)$, Benjamini and Hochberg\n\\cite{benjamini1995controlling} introduced the false discovery rate (FDR)\ncriterion, which is the expected proportion of false positives among rejected\nnull hypotheses, and proposed a testing procedure that controls FDR below a\npre-assigned significance level. They also proposed a different criterion,\ncalled mFDR, which does not control a property of the realized set of tests;\nrather it controls the ratio of expected number of false discoveries to the\nexpected number of discoveries.\n  In this paper, we propose two procedures for multiple hypotheses testing that\nwe will call \"LOND\" and \"LORD\". These procedures control FDR and mFDR in an\n\\emph{online manner}. Concretely, we consider an ordered --possibly infinite--\nsequence of null hypotheses $\\mathcal{H} = (H_1,H_2,H_3,...)$ where, at each\nstep $i$, the statistician must decide whether to reject hypothesis $H_i$\nhaving access only to the previous decisions. To the best of our knowledge, our\nwork is the first that controls FDR in this setting. This model was introduced\nby Foster and Stine \\cite{alpha-investing} whose alpha-investing rule only\ncontrols mFDR in online manner.\n  In order to compare different procedures, we develop lower bounds on the\ntotal discovery rate under the mixture model and prove that both LOND and LORD\nhave nearly linear number of discoveries. We further propose adjustment to LOND\nto address arbitrary correlation among the $p$-values. Finally, we evaluate the\nperformance of our procedures on both synthetic and real data comparing them\nwith alpha-investing rule, Benjamin-Hochberg method and a Bonferroni procedure.\n", "versions": [{"version": "v1", "created": "Sun, 22 Feb 2015 09:07:07 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2015 00:39:16 GMT"}], "update_date": "2015-03-05", "authors_parsed": [["Javanmard", "Adel", ""], ["Montanari", "Andrea", ""]]}, {"id": "1502.06287", "submitter": "Christos Thrampoulidis", "authors": "Christos Thrampoulidis, Ashkan Panahi, Babak Hassibi", "title": "Asymptotically Exact Error Analysis for the Generalized $\\ell_2^2$-LASSO", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given an unknown signal $\\mathbf{x}_0\\in\\mathbb{R}^n$ and linear noisy\nmeasurements\n$\\mathbf{y}=\\mathbf{A}\\mathbf{x}_0+\\sigma\\mathbf{v}\\in\\mathbb{R}^m$, the\ngeneralized $\\ell_2^2$-LASSO solves\n$\\hat{\\mathbf{x}}:=\\arg\\min_{\\mathbf{x}}\\frac{1}{2}\\|\\mathbf{y}-\\mathbf{A}\\mathbf{x}\\|_2^2\n+ \\sigma\\lambda f(\\mathbf{x})$. Here, $f$ is a convex regularization function\n(e.g. $\\ell_1$-norm, nuclear-norm) aiming to promote the structure of\n$\\mathbf{x}_0$ (e.g. sparse, low-rank), and, $\\lambda\\geq 0$ is the regularizer\nparameter. A related optimization problem, though not as popular or well-known,\nis often referred to as the generalized $\\ell_2$-LASSO and takes the form\n$\\hat{\\mathbf{x}}:=\\arg\\min_{\\mathbf{x}}\\|\\mathbf{y}-\\mathbf{A}\\mathbf{x}\\|_2 +\n\\lambda f(\\mathbf{x})$, and has been analyzed in [1]. [1] further made\nconjectures about the performance of the generalized $\\ell_2^2$-LASSO. This\npaper establishes these conjectures rigorously. We measure performance with the\nnormalized squared error\n$\\mathrm{NSE}(\\sigma):=\\|\\hat{\\mathbf{x}}-\\mathbf{x}_0\\|_2^2/\\sigma^2$.\nAssuming the entries of $\\mathbf{A}$ and $\\mathbf{v}$ be i.i.d. standard\nnormal, we precisely characterize the \"asymptotic NSE\"\n$\\mathrm{aNSE}:=\\lim_{\\sigma\\rightarrow 0}\\mathrm{NSE}(\\sigma)$ when the\nproblem dimensions $m,n$ tend to infinity in a proportional manner. The role of\n$\\lambda,f$ and $\\mathbf{x}_0$ is explicitly captured in the derived expression\nvia means of a single geometric quantity, the Gaussian distance to the\nsubdifferential. We conjecture that $\\mathrm{aNSE} =\n\\sup_{\\sigma>0}\\mathrm{NSE}(\\sigma)$. We include detailed discussions on the\ninterpretation of our result, make connections to relevant literature and\nperform computational experiments that validate our theoretical findings.\n", "versions": [{"version": "v1", "created": "Sun, 22 Feb 2015 23:07:24 GMT"}], "update_date": "2015-02-24", "authors_parsed": [["Thrampoulidis", "Christos", ""], ["Panahi", "Ashkan", ""], ["Hassibi", "Babak", ""]]}, {"id": "1502.06291", "submitter": "Sourav Chatterjee", "authors": "Sourav Chatterjee and Jafar Jafarov", "title": "Prediction error of cross-validated Lasso", "comments": "18 pages. Minor revisions and additional references", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In spite of the wealth of literature on the theoretical properties of the\nLasso, there is very little known when the value of the tuning parameter is\nchosen using the data, even though this is what actually happens in practice.\nWe give a general upper bound on the prediction error of Lasso when the tuning\nparameter is chosen using a variant of 2-fold cross-validation. No special\nassumption is made about the structure of the design matrix, and the tuning\nparameter is allowed to be optimized over an arbitrary data-dependent set of\nvalues. The proof is based on a general principle that may extend to other\nkinds of cross-validation as well as to other penalized regression methods.\nBased on this result, we propose a new estimate for error variance in high\ndimensional regression and prove that it has good properties under minimal\nassumptions.\n", "versions": [{"version": "v1", "created": "Mon, 23 Feb 2015 00:18:47 GMT"}, {"version": "v2", "created": "Wed, 31 Aug 2016 22:22:18 GMT"}], "update_date": "2016-09-02", "authors_parsed": [["Chatterjee", "Sourav", ""], ["Jafarov", "Jafar", ""]]}, {"id": "1502.06338", "submitter": "Thibault Jaisson", "authors": "Thibault Jaisson and Mathieu Rosenbaum", "title": "The different asymptotic regimes of nearly unstable autoregressive\n  processes", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend classical results about the convergence of nearly unstable AR(p)\nprocesses to the infinite order case. To do so, we proceed as in recent works\nabout Hawkes processes by using limit theorems for some well chosen geometric\nsums. We prove that when the coefficients sequence has a light tail, infinite\norder nearly unstable autoregressive processes behave as Ornstein-Uhlenbeck\nmodels. However, in the heavy tail case, we show that fractional diffusions\narise as limiting laws for such processes.\n", "versions": [{"version": "v1", "created": "Mon, 23 Feb 2015 08:04:42 GMT"}], "update_date": "2015-02-24", "authors_parsed": [["Jaisson", "Thibault", ""], ["Rosenbaum", "Mathieu", ""]]}, {"id": "1502.06349", "submitter": "Gareth Peters Dr", "authors": "Antonio Dalessandro, Gareth W. Peters", "title": "Tensor Approximation of Generalized Correlated Diffusions and Functional\n  Copula Operators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST q-fin.MF stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate aspects of semimartingale decompositions, approximation and\nthe martingale representation for multidimensional correlated Markov processes.\nA new interpretation of the dependence among processes is given using the\nmartingale approach. We show that it is possible to represent, in both\ncontinuous and discrete space, that a multidimensional correlated generalized\ndiffusion is a linear combination of processes that originate from the\ndecomposition of the starting multidimensional semimartingale. This result not\nonly reconciles with the existing theory of diffusion approximations and\ndecompositions, but defines the general representation of infinitesimal\ngenerators for both multidimensional generalized diffusions and as we will\ndemonstrate also for the specification of copula density dependence structures.\nThis new result provides immediate representation of the approximate solution\nfor correlated stochastic differential equations. We demonstrate desirable\nconvergence results for the proposed multidimensional semimartingales\ndecomposition approximations.\n", "versions": [{"version": "v1", "created": "Mon, 23 Feb 2015 08:58:30 GMT"}], "update_date": "2015-02-24", "authors_parsed": [["Dalessandro", "Antonio", ""], ["Peters", "Gareth W.", ""]]}, {"id": "1502.06590", "submitter": "Yash Deshpande", "authors": "Yash Deshpande and Andrea Montanari", "title": "Improved Sum-of-Squares Lower Bounds for Hidden Clique and Hidden\n  Submatrix Problems", "comments": "40 pages, 1 table, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.IT math.IT math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a large data matrix $A\\in\\mathbb{R}^{n\\times n}$, we consider the\nproblem of determining whether its entries are i.i.d. with some known marginal\ndistribution $A_{ij}\\sim P_0$, or instead $A$ contains a principal submatrix\n$A_{{\\sf Q},{\\sf Q}}$ whose entries have marginal distribution $A_{ij}\\sim\nP_1\\neq P_0$. As a special case, the hidden (or planted) clique problem\nrequires to find a planted clique in an otherwise uniformly random graph.\n  Assuming unbounded computational resources, this hypothesis testing problem\nis statistically solvable provided $|{\\sf Q}|\\ge C \\log n$ for a suitable\nconstant $C$. However, despite substantial effort, no polynomial time algorithm\nis known that succeeds with high probability when $|{\\sf Q}| = o(\\sqrt{n})$.\nRecently Meka and Wigderson \\cite{meka2013association}, proposed a method to\nestablish lower bounds within the Sum of Squares (SOS) semidefinite hierarchy.\n  Here we consider the degree-$4$ SOS relaxation, and study the construction of\n\\cite{meka2013association} to prove that SOS fails unless $k\\ge C\\,\nn^{1/3}/\\log n$. An argument presented by Barak implies that this lower bound\ncannot be substantially improved unless the witness construction is changed in\nthe proof. Our proof uses the moments method to bound the spectrum of a certain\nrandom association scheme, i.e. a symmetric random matrix whose rows and\ncolumns are indexed by the edges of an Erd\\\"os-Renyi random graph.\n", "versions": [{"version": "v1", "created": "Mon, 23 Feb 2015 20:45:11 GMT"}], "update_date": "2015-02-24", "authors_parsed": [["Deshpande", "Yash", ""], ["Montanari", "Andrea", ""]]}, {"id": "1502.06644", "submitter": "Robert Vandermeulen", "authors": "Robert A. Vandermeulen and Clayton D. Scott", "title": "On The Identifiability of Mixture Models from Grouped Samples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finite mixture models are statistical models which appear in many problems in\nstatistics and machine learning. In such models it is assumed that data are\ndrawn from random probability measures, called mixture components, which are\nthemselves drawn from a probability measure P over probability measures. When\nestimating mixture models, it is common to make assumptions on the mixture\ncomponents, such as parametric assumptions. In this paper, we make no\nassumption on the mixture components, and instead assume that observations from\nthe mixture model are grouped, such that observations in the same group are\nknown to be drawn from the same component. We show that any mixture of m\nprobability measures can be uniquely identified provided there are 2m-1\nobservations per group. Moreover we show that, for any m, there exists a\nmixture of m probability measures that cannot be uniquely identified when\ngroups have 2m-2 observations. Our results hold for any sample space with more\nthan one element.\n", "versions": [{"version": "v1", "created": "Mon, 23 Feb 2015 22:24:26 GMT"}], "update_date": "2015-02-25", "authors_parsed": [["Vandermeulen", "Robert A.", ""], ["Scott", "Clayton D.", ""]]}, {"id": "1502.06718", "submitter": "Giovanni Pistone", "authors": "Giovanni Pistone and Maria Piera Rogantin", "title": "The gradient flow of the polarization measure. With an appendix", "comments": "22 pages with 6 figures and 1 table. Extended version of the poster\n  presented at the SIS conference Cagliari 2014. The main sections (not the\n  appendixes) have been submitted to the journal STATISTICA. Typos corrected in\n  v2", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The polarization measure is the probability that among 3 individuals chosen\nat random from a finite population exactly 2 come from the same class. This\nindex is maximum at the midpoints of the edges of the probability simplex. We\ncompute the gradient flow of this index that is the differential equation whose\nsolutions are the curves of steepest ascent. Tools from Information Geometry\nare extensively used. In a time series, a comparison of the estimated velocity\nof variation with the direction of the gradient field should be a better index\nthan the simple variation of the index.\n", "versions": [{"version": "v1", "created": "Tue, 24 Feb 2015 09:09:28 GMT"}, {"version": "v2", "created": "Tue, 21 Apr 2015 11:08:35 GMT"}], "update_date": "2015-04-22", "authors_parsed": [["Pistone", "Giovanni", ""], ["Rogantin", "Maria Piera", ""]]}, {"id": "1502.06745", "submitter": "Hammou Elotmany", "authors": "H Elotma (FSSM)", "title": "Parameter estimation for stochastic diffusion process", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the present paper we propose a new stochastic diffusion process with drift\nproportional to the Weibull density function defined as X $\\epsilon$ = x, dX t\n= $\\gamma$ t (1 - t $\\gamma$+1) - t $\\gamma$ X t dt + $\\sigma$X t dB t , t\n\\textgreater{} 0, with parameters $\\gamma$ \\textgreater{} 0 and $\\sigma$\n\\textgreater{} 0, where B is a standard Brownian motion and t = $\\epsilon$ is a\ntime proche to zero. First we interested to probabilistic solution of this\nprocess as the explicit expression of this process. By using the maximum\nlikelihood method and by considering a discrete sampling of the sample of the\nnew process we estimate the parameters $\\gamma$ and $\\sigma$.\n", "versions": [{"version": "v1", "created": "Tue, 24 Feb 2015 10:11:25 GMT"}, {"version": "v2", "created": "Wed, 25 Feb 2015 13:04:09 GMT"}], "update_date": "2015-02-26", "authors_parsed": [["Elotma", "H", "", "FSSM"]]}, {"id": "1502.06774", "submitter": "Giovanni Pistone", "authors": "Bertrand Lods and Giovanni Pistone", "title": "Information Geometry Formalism for the Spatially Homogeneous Boltzmann\n  Equation", "comments": "39 pages, 1 figure. Expanded version of a paper presente at the\n  conference SigmaPhi 2014 Rhodes GR. Under revision for Entropy", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information Geometry generalizes to infinite dimension by modeling the\ntangent space of the relevant manifold of probability densities with\nexponential Orlicz spaces. We review here several properties of the exponential\nmanifold on a suitable set $\\mathcal E$ of mutually absolutely continuous\ndensities. We study in particular the fine properties of the Kullback-Liebler\ndivergence in this context. We also show that this setting is well-suited for\nthe study of the spatially homogeneous Boltzmann equation if $\\mathcal E$ is a\nset of positive densities with finite relative entropy with respect to the\nMaxwell density. More precisely, we analyse the Boltzmann operator in the\ngeometric setting from the point of its Maxwell's weak form as a composition of\nelementary operations in the exponential manifold, namely tensor product,\nconditioning, marginalization and we prove in a geometric way the basic facts\ni.e., the H-theorem. We also illustrate the robustness of our method by\ndiscussing, besides the Kullback-Leibler divergence, also the property of\nHyv\\\"arinen divergence. This requires to generalise our approach to\nOrlicz-Sobolev spaces to include derivatives.%\n", "versions": [{"version": "v1", "created": "Tue, 24 Feb 2015 11:53:25 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2015 09:58:02 GMT"}], "update_date": "2015-06-15", "authors_parsed": [["Lods", "Bertrand", ""], ["Pistone", "Giovanni", ""]]}, {"id": "1502.06781", "submitter": "Dave Zachariah", "authors": "Dave Zachariah, Petre Stoica", "title": "Cramer-Rao bound analog of Bayes rule", "comments": null, "journal-ref": "IEEE Signal Processing Magazine, vol. 32, no. 2, pp. 164-168, 2015", "doi": "10.1109/MSP.2014.2365593", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this lecture note, we show a general property of the Cramer-Rao bound\n(CRB) that quantifies the interdependencies between the parameters in a vector.\nThe presented result is valid for more general models than the additive noise\nmodel and also generalizes previous results to vector parameters. The CRB\nanalog to Bayes' rule will be illustrated via two examples.\n", "versions": [{"version": "v1", "created": "Tue, 24 Feb 2015 12:23:30 GMT"}, {"version": "v2", "created": "Wed, 6 May 2015 18:50:46 GMT"}], "update_date": "2015-05-07", "authors_parsed": [["Zachariah", "Dave", ""], ["Stoica", "Petre", ""]]}, {"id": "1502.06895", "submitter": "Xiangyu Wang", "authors": "Xiangyu Wang, Chenlei Leng, David B. Dunson", "title": "On the consistency theory of high dimensional variable screening", "comments": "adding comments on REC", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variable screening is a fast dimension reduction technique for assisting high\ndimensional feature selection. As a preselection method, it selects a moderate\nsize subset of candidate variables for further refining via feature selection\nto produce the final model. The performance of variable screening depends on\nboth computational efficiency and the ability to dramatically reduce the number\nof variables without discarding the important ones. When the data dimension $p$\nis substantially larger than the sample size $n$, variable screening becomes\ncrucial as 1) Faster feature selection algorithms are needed; 2) Conditions\nguaranteeing selection consistency might fail to hold. This article studies a\nclass of linear screening methods and establishes consistency theory for this\nspecial class. In particular, we prove the restricted diagonally dominant (RDD)\ncondition is a necessary and sufficient condition for strong screening\nconsistency. As concrete examples, we show two screening methods $SIS$ and\n$HOLP$ are both strong screening consistent (subject to additional constraints)\nwith large probability if $n > O((\\rho s + \\sigma/\\tau)^2\\log p)$ under random\ndesigns. In addition, we relate the RDD condition to the irrepresentable\ncondition, and highlight limitations of $SIS$.\n", "versions": [{"version": "v1", "created": "Tue, 24 Feb 2015 17:52:20 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2015 18:38:42 GMT"}, {"version": "v3", "created": "Sat, 6 Jun 2015 07:33:02 GMT"}], "update_date": "2015-06-09", "authors_parsed": [["Wang", "Xiangyu", ""], ["Leng", "Chenlei", ""], ["Dunson", "David B.", ""]]}, {"id": "1502.06902", "submitter": "Koenraad M. R. Audenaert", "authors": "Koenraad M.R. Audenaert", "title": "A Determinantal Inequality for the Geometric Mean with an Application in\n  Diffusion Tensor Imaging", "comments": "9 pages; v2: reference added", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.RA math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that for positive semidefinite matrices $A$ and $B$ the following\ndeterminantal inequality holds: \\[ \\det(I+A\\#B)\\le \\det(I+A^{1/2}B^{1/2}), \\]\nwhere $A\\#B$ is the geometric mean of $A$ and $B$. We apply this inequality to\nthe study of interpolation methods in diffusion tensor imaging.\n", "versions": [{"version": "v1", "created": "Wed, 18 Feb 2015 20:04:36 GMT"}, {"version": "v2", "created": "Sat, 14 Mar 2015 08:10:32 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Audenaert", "Koenraad M. R.", ""]]}, {"id": "1502.06919", "submitter": "Jean Lafond", "authors": "Jean Lafond (LTCI)", "title": "Low Rank Matrix Completion with Exponential Family Noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The matrix completion problem consists in reconstructing a matrix from a\nsample of entries, possibly observed with noise. A popular class of estimator,\nknown as nuclear norm penalized estimators, are based on minimizing the sum of\na data fitting term and a nuclear norm penalization. Here, we investigate the\ncase where the noise distribution belongs to the exponential family and is\nsub-exponential. Our framework alllows for a general sampling scheme. We first\nconsider an estimator defined as the minimizer of the sum of a log-likelihood\nterm and a nuclear norm penalization and prove an upper bound on the Frobenius\nprediction risk. The rate obtained improves on previous works on matrix\ncompletion for exponential family. When the sampling distribution is known, we\npropose another estimator and prove an oracle inequality w.r.t. the\nKullback-Leibler prediction risk, which translates immediatly into an upper\nbound on the Frobenius prediction risk. Finally, we show that all the rates\nobtained are minimax optimal up to a logarithmic factor.\n", "versions": [{"version": "v1", "created": "Tue, 24 Feb 2015 19:27:06 GMT"}, {"version": "v2", "created": "Mon, 20 Apr 2015 09:02:08 GMT"}], "update_date": "2015-04-21", "authors_parsed": [["Lafond", "Jean", "", "LTCI"]]}, {"id": "1502.06952", "submitter": "Wanjie Wang", "authors": "Jiashun Jin, Zheng Tracy Ke, Wanjie Wang", "title": "Phase Transitions for High Dimensional Clustering and Related Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Consider a two-class clustering problem where we observe $X_i = \\ell_i \\mu +\nZ_i$, $Z_i \\stackrel{iid}{\\sim} N(0, I_p)$, $1 \\leq i \\leq n$. The feature\nvector $\\mu\\in R^p$ is unknown but is presumably sparse. The class labels\n$\\ell_i\\in\\{-1, 1\\}$ are also unknown and the main interest is to estimate\nthem.\n  We are interested in the statistical limits. In the two-dimensional phase\nspace calibrating the rarity and strengths of useful features, we find the\nprecise demarcation for the Region of Impossibility and Region of Possibility.\nIn the former, useful features are too rare/weak for successful clustering. In\nthe latter, useful features are strong enough to allow successful clustering.\nThe results are extended to the case of colored noise using Le Cam's idea on\ncomparison of experiments.\n  We also extend the study on statistical limits for clustering to that for\nsignal recovery and that for hypothesis testing. We compare the statistical\nlimits for three problems and expose some interesting insight.\n  We propose classical PCA and Important Features PCA (IF-PCA) for clustering.\nFor a threshold $t > 0$, IF-PCA clusters by applying classical PCA to all\ncolumns of $X$ with an $L^2$-norm larger than $t$. We also propose two\naggregation methods. For any parameter in the Region of Possibility, some of\nthese methods yield successful clustering. We find an interesting phase\ntransition for IF-PCA.\n  Our results require delicate analysis, especially on post-selection Random\nMatrix Theory and on lower bound arguments.\n", "versions": [{"version": "v1", "created": "Tue, 24 Feb 2015 20:58:44 GMT"}, {"version": "v2", "created": "Wed, 25 Mar 2015 16:52:44 GMT"}, {"version": "v3", "created": "Mon, 28 Dec 2015 21:20:45 GMT"}, {"version": "v4", "created": "Wed, 8 Jun 2016 19:29:50 GMT"}], "update_date": "2016-06-09", "authors_parsed": [["Jin", "Jiashun", ""], ["Ke", "Zheng Tracy", ""], ["Wang", "Wanjie", ""]]}, {"id": "1502.07042", "submitter": "Subhabrata Majumdar", "authors": "Subhabrata Majumdar", "title": "Robust estimation of principal components from depth-based multivariate\n  rank covariance matrix", "comments": "Presented in Joint Statistical Meetings 2015, Seattle, WA. Expanded\n  version under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Analyzing principal components for multivariate data from its spatial sign\ncovariance matrix (SCM) has been proposed as a computationally simple and\nrobust alternative to normal PCA, but it suffers from poor efficiency\nproperties and is actually inadmissible with respect to the maximum likelihood\nestimator. Here we use data depth-based spatial ranks in place of spatial signs\nto obtain the orthogonally equivariant Depth Covariance Matrix (DCM) and use\nits eigenvector estimates for PCA. We derive asymptotic properties of the\nsample DCM and influence functions of its eigenvectors. The shapes of these\ninfluence functions indicate robustness of estimated principal components, and\ngood efficiency properties compared to the SCM. Finite sample simulation\nstudies show that principal components of the sample DCM are robust with\nrespect to deviations from normality, as well as are more efficient than the\nSCM and its affine equivariant version, Tyler's shape matrix. Through two real\ndata examples, we also show the effectiveness of DCM-based PCA in analyzing\nhigh-dimensional data and outlier detection, and compare it with other methods\nof robust PCA.\n", "versions": [{"version": "v1", "created": "Wed, 25 Feb 2015 03:54:24 GMT"}, {"version": "v2", "created": "Sun, 10 May 2015 06:44:36 GMT"}, {"version": "v3", "created": "Wed, 9 Mar 2016 20:09:53 GMT"}], "update_date": "2016-03-10", "authors_parsed": [["Majumdar", "Subhabrata", ""]]}, {"id": "1502.07061", "submitter": "Jinyuan Chang", "authors": "Jinyuan Chang, Cheng Yong Tang, Yichao Wu", "title": "Local independence feature screening for nonparametric and\n  semiparametric models by marginal empirical likelihood", "comments": "Published at http://dx.doi.org/10.1214/15-AOS1374 in the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2016, Vol. 44, No. 2, 515-539", "doi": "10.1214/15-AOS1374", "report-no": "IMS-AOS-AOS1374", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider an independence feature screening technique for identifying\nexplanatory variables that locally contribute to the response variable in\nhigh-dimensional regression analysis. Without requiring a specific parametric\nform of the underlying data model, our approach accommodates a wide spectrum of\nnonparametric and semiparametric model families. To detect the local\ncontributions of explanatory variables, our approach constructs empirical\nlikelihood locally in conjunction with marginal nonparametric regressions.\nSince our approach actually requires no estimation, it is advantageous in\nscenarios such as the single-index models where even specification and\nidentification of a marginal model is an issue. By automatically incorporating\nthe level of variation of the nonparametric regression and directly assessing\nthe strength of data evidence supporting local contribution from each\nexplanatory variable, our approach provides a unique perspective for solving\nfeature screening problems. Theoretical analysis shows that our approach can\nhandle data dimensionality growing exponentially with the sample size. With\nextensive theoretical illustrations and numerical examples, we show that the\nlocal independence screening approach performs promisingly.\n", "versions": [{"version": "v1", "created": "Wed, 25 Feb 2015 06:10:04 GMT"}, {"version": "v2", "created": "Wed, 30 Mar 2016 11:59:27 GMT"}], "update_date": "2016-03-31", "authors_parsed": [["Chang", "Jinyuan", ""], ["Tang", "Cheng Yong", ""], ["Wu", "Yichao", ""]]}, {"id": "1502.07097", "submitter": "Shahar Mendelson", "authors": "Shahar Mendelson", "title": "On aggregation for heavy-tailed classes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an alternative to the notion of `fast rate' in Learning Theory,\nwhich coincides with the optimal error rate when the given class happens to be\nconvex and regular in some sense. While it is well known that such a rate\ncannot always be attained by a learning procedure (i.e., a procedure that\nselects a function in the given class), we introduce an aggregation procedure\nthat attains that rate under rather minimal assumptions -- for example, that\nthe $L_q$ and $L_2$ norms are equivalent on the linear span of the class for\nsome $q>2$, and the target random variable is square-integrable.\n", "versions": [{"version": "v1", "created": "Wed, 25 Feb 2015 09:33:49 GMT"}], "update_date": "2015-02-26", "authors_parsed": [["Mendelson", "Shahar", ""]]}, {"id": "1502.07102", "submitter": "Tam\\'as T. Szab\\'o", "authors": "Gyula Pap, Tam\\'as T. Szab\\'o", "title": "Change detection in the Cox-Ingersoll-Ross model", "comments": "30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a change detection method for the famous Cox--Ingersoll--Ross\nmodel. This model is widely used in financial mathematics and therefore\ndetecting a change in its parameters is of crucial importance. We develop one-\nand two-sided testing procedures for both drift parameters of the process. The\ntest process is based on estimators that are motivated by the discrete time\nleast-squares estimators, and its asymptotic distribution under the no-change\nhypothesis is that of a Brownian bridge. We prove the asymptotic weak\nconsistence of the test, and derive the asymptotic properties of the\nchange-point estimator under the alternative hypothesis of change at one point\nin time.\n", "versions": [{"version": "v1", "created": "Wed, 25 Feb 2015 10:03:15 GMT"}], "update_date": "2015-02-26", "authors_parsed": [["Pap", "Gyula", ""], ["Szab\u00f3", "Tam\u00e1s T.", ""]]}, {"id": "1502.07131", "submitter": "Benjamin Stucky", "authors": "Sara van de Geer, Benjamin Stucky", "title": "$\\chi^2$-confidence sets in high-dimensional regression", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a high-dimensional regression model. Aim is to construct a\nconfidence set for a given group of regression coefficients, treating all other\nregression coefficients as nuisance parameters. We apply a one-step procedure\nwith the square-root Lasso as initial estimator and a multivariate square-root\nLasso for constructing a surrogate Fisher information matrix. The multivariate\nsquare-root Lasso is based on nuclear norm loss with $\\ell_1$-penalty. We show\nthat this procedure leads to an asymptotically $\\chi^2$-distributed pivot, with\na remainder term depending only on the $\\ell_1$-error of the initial estimator.\nWe show that under $\\ell_1$-sparsity conditions on the regression coefficients\n$\\beta^0$ the square-root Lasso produces to a consistent estimator of the noise\nvariance and we establish sharp oracle inequalities which show that the\nremainder term is small under further sparsity conditions on $\\beta^0$ and\ncompatibility conditions on the design.\n", "versions": [{"version": "v1", "created": "Wed, 25 Feb 2015 11:31:59 GMT"}, {"version": "v2", "created": "Tue, 15 Sep 2015 09:29:22 GMT"}], "update_date": "2015-09-16", "authors_parsed": [["van de Geer", "Sara", ""], ["Stucky", "Benjamin", ""]]}, {"id": "1502.07181", "submitter": "Ben Berckmoes", "authors": "Ben Berckmoes and Geert Molenberghs", "title": "On the asymptotic behavior of the contaminated sample mean", "comments": "14 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An observation of a cumulative distribution function $F$ with finite variance\nis said to be contaminated according to the inflated variance model if it has a\nlarge probability of coming from the original target distribution $F$, but a\nsmall probability of coming from a contaminating distribution that has the same\nmean and shape as $F$, though a larger variance. It is well known that in the\npresence of data contamination, the ordinary sample mean looses many of its\ngood properties, making it preferable to use more robust estimators. From a\ndidactical point of view, it is insightful to see to what extent an intuitive\nestimator such as the sample mean becomes less favorable in a contaminated\nsetting. In this paper, we investigate under which conditions the sample mean,\nbased on a finite number of independent observations of $F$ which are\ncontaminated according to the inflated variance model, is a valid estimator for\nthe mean of $F$. In particular, we examine to what extent this estimator is\nweakly consistent for the mean of $F$ and asymptotically normal. As classical\ncentral limit theory is generally inaccurate to cope with the asymptotic\nnormality in this setting, we invoke more general approximate central limit\ntheory as developed by Berckmoes, Lowen, and Van Casteren (2013). Our\ntheoretical results are illustrated by a specific example and a simulation\nstudy.\n", "versions": [{"version": "v1", "created": "Wed, 25 Feb 2015 14:37:04 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2015 14:54:47 GMT"}, {"version": "v3", "created": "Thu, 22 Dec 2016 14:18:04 GMT"}, {"version": "v4", "created": "Fri, 23 Dec 2016 18:40:28 GMT"}, {"version": "v5", "created": "Sun, 10 Dec 2017 08:12:37 GMT"}], "update_date": "2017-12-12", "authors_parsed": [["Berckmoes", "Ben", ""], ["Molenberghs", "Geert", ""]]}, {"id": "1502.07300", "submitter": "Mohammad Arashi", "authors": "A. Bekker, M. Arashi and J. van Niekerk", "title": "Wishart Generator Distribution", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Wishart distribution and its generalizations are among the most prominent\nprobability distributions in multivariate statistical analysis, arising\nnaturally in applied research and as a basis for theoretical models. In this\npaper, we generalize the Wishart distribution utilizing a different approach\nthat leads to the Wishart generator distribution with the Wishart distribution\nas a special case. It is not restricted, however some special cases are\nexhibited. Important statistical characteristics of the Wishart generator\ndistribution are derived from the matrix theory viewpoint. Estimation is also\ntouched upon as a guide for further research from the classical approach as\nwell as from the Bayesian paradigm. The paper is concluded by giving\napplications of two special cases of this distribution in calculating the\nproduct of beta functions and astronomy.\n", "versions": [{"version": "v1", "created": "Wed, 25 Feb 2015 18:48:58 GMT"}], "update_date": "2015-02-26", "authors_parsed": [["Bekker", "A.", ""], ["Arashi", "M.", ""], ["van Niekerk", "J.", ""]]}, {"id": "1502.07321", "submitter": "Alexander Schnurr", "authors": "Alexander Schnurr", "title": "An Ordinal Pattern Approach to Detect and to Model Leverage Effects and\n  Dependence Structures Between Financial Time Series", "comments": "13 pages, 3 figures", "journal-ref": "Stat. Papers 55(4) (2014), 919-931", "doi": null, "report-no": null, "categories": "q-fin.ST math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce two types of ordinal pattern dependence between time series.\nPositive (resp. negative) ordinal pattern dependence can be seen as a\nnon-paramatric and in particular non-linear counterpart to positive (resp.\nnegative) correlation. We show in an explorative study that both types of this\ndependence show up in real world financial data.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jan 2015 14:15:50 GMT"}], "update_date": "2015-02-26", "authors_parsed": [["Schnurr", "Alexander", ""]]}, {"id": "1502.07409", "submitter": "Yasutaka Shimizu", "authors": "Yasutaka Shimizu", "title": "Threshold estimation for stochastic processes with small noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a process satisfying a stochastic differential equation with unknown\ndrift parameter, and suppose that discrete observations are given. It is known\nthat a simple least squares estimator (LSE) can be consistent, but numerically\nunstable in the sense of large standard deviations under finite samples when\nthe noise process has jumps. We propose a filter to cut large shocks from data,\nand construct the same LSE from data selected by the filter. The proposed\nestimator can be asymptotically equivalent to the usual LSE, whose asymptotic\ndistribution strongly depends on the noise process. However, in numerical\nstudy, it looked asymptotically normal in an example where filter was choosen\nsuitably, and the noise was a L\\'evy process. We will try to justify this\nphenomenon mathematically, under certain restricted assumptions.\n", "versions": [{"version": "v1", "created": "Thu, 26 Feb 2015 00:58:22 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2015 07:22:00 GMT"}, {"version": "v3", "created": "Thu, 16 Mar 2017 06:45:26 GMT"}], "update_date": "2017-03-17", "authors_parsed": [["Shimizu", "Yasutaka", ""]]}, {"id": "1502.07463", "submitter": "Gogi Pantsulaia", "authors": "Murman Kintsurashvili, Tengiz Kiria and Gogi Pantsulaia", "title": "On objective and strong objective consistent estimates of unknown\n  parameters for statistical structures in a Polish group admitting an\n  invariant metric", "comments": "40 pages, 3 figures. In Table 1 (p.4) last column is deleted; In Page\n  28, indications of Statistics $T_n^{(1)}$(and $T_n^{(3)}$ are corrected\n  ((5.14) is replaced with (5.13); (5.30) is replaced with (5.19); P. 29, line\n  5,1 from above $T^{(1)}_ n$ is replaced with $T^{(2)}_ n$; The corresponding\n  correction is entered in Table 2. AoS is deleted . Now pages are 34", "journal-ref": "Journal of Statistics: Advances in Theory and Applications, Volume\n  13, No. 2 (2015) 179-233", "doi": "10.18642/jsata_7100121469", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By using the notion of a Haar ambivalent set introduced by Balka, Buczolich\nand Elekes (2012), essentially new classes of statistical structures having\nobjective and strong objective estimates of unknown parameters are introduced\nin a Polish non-locally-compact group admitting an invariant metric and\nrelations between them are studied in this paper. An example of such a weakly\nseparated statistical structure is constructed for which a question asking\n\"{\\it whether there exists a consistent estimate of an unknown parameter}\" is\nnot solvable within the theory $(ZF)~\\&~(DC)$. A question asking \"{\\it whether\nthere exists an objective consistent estimate of an unknown parameter for any\nstatistical structure in a non-locally compact Polish group with an invariant\nmetric when subjective one exists}\" is answered positively when there exists at\nleast one such a parameter the pre-image of which under this subjective\nestimate is a prevalent. These results extend recent results of authors. Some\nexamples of objective and strong objective consistent estimates in a compact\nPolish group $\\{0; 1\\}^N$ are considered in this paper.\n", "versions": [{"version": "v1", "created": "Thu, 26 Feb 2015 08:14:22 GMT"}, {"version": "v2", "created": "Sat, 28 Feb 2015 10:17:20 GMT"}, {"version": "v3", "created": "Sat, 14 Mar 2015 15:30:01 GMT"}, {"version": "v4", "created": "Thu, 19 Mar 2015 03:14:50 GMT"}], "update_date": "2015-10-15", "authors_parsed": [["Kintsurashvili", "Murman", ""], ["Kiria", "Tengiz", ""], ["Pantsulaia", "Gogi", ""]]}, {"id": "1502.07523", "submitter": "Sergiy Vorobyov A.", "authors": "Mahdi Shaghaghi and Sergiy A. Vorobyov", "title": "Cramer-Rao Bound for Sparse Signals Fitting the Low-Rank Model with\n  Small Number of Parameters", "comments": "14 pages, 1 figure, Submitted to IEEE Signal Processing Letters on\n  December 2014", "journal-ref": "IEEE Signal Processing Letters, vol. 22, no. 9, pp. 1497-1501,\n  Sept. 2015", "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider signals with a low-rank covariance matrix which\nreside in a low-dimensional subspace and can be written in terms of a finite\n(small) number of parameters. Although such signals do not necessarily have a\nsparse representation in a finite basis, they possess a sparse structure which\nmakes it possible to recover the signal from compressed measurements. We study\nthe statistical performance bound for parameter estimation in the low-rank\nsignal model from compressed measurements. Specifically, we derive the\nCramer-Rao bound (CRB) for a generic low-rank model and we show that the number\nof compressed samples needs to be larger than the number of sources for the\nexistence of an unbiased estimator with finite estimation variance. We further\nconsider the applications to direction-of-arrival (DOA) and spectral estimation\nwhich fit into the low-rank signal model. We also investigate the effect of\ncompression on the CRB by considering numerical examples of the DOA estimation\nscenario, and show how the CRB increases by increasing the compression or\nequivalently reducing the number of compressed samples.\n", "versions": [{"version": "v1", "created": "Thu, 26 Feb 2015 12:26:02 GMT"}], "update_date": "2016-03-03", "authors_parsed": [["Shaghaghi", "Mahdi", ""], ["Vorobyov", "Sergiy A.", ""]]}, {"id": "1502.07641", "submitter": "Rina Foygel Barber", "authors": "Rina Foygel Barber and Mladen Kolar", "title": "ROCKET: Robust Confidence Intervals via Kendall's Tau for\n  Transelliptical Graphical Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Undirected graphical models are used extensively in the biological and social\nsciences to encode a pattern of conditional independences between variables,\nwhere the absence of an edge between two nodes $a$ and $b$ indicates that the\ncorresponding two variables $X_a$ and $X_b$ are believed to be conditionally\nindependent, after controlling for all other measured variables. In the\nGaussian case, conditional independence corresponds to a zero entry in the\nprecision matrix $\\Omega$ (the inverse of the covariance matrix $\\Sigma$). Real\ndata often exhibits heavy tail dependence between variables, which cannot be\ncaptured by the commonly-used Gaussian or nonparanormal (Gaussian copula)\ngraphical models. In this paper, we study the transelliptical model, an\nelliptical copula model that generalizes Gaussian and nonparanormal models to a\nbroader family of distributions. We propose the ROCKET method, which constructs\nan estimator of $\\Omega_{ab}$ that we prove to be asymptotically normal under\nmild assumptions. Empirically, ROCKET outperforms the nonparanormal and\nGaussian models in terms of achieving accurate inference on simulated data. We\nalso compare the three methods on real data (daily stock returns), and find\nthat the ROCKET estimator is the only method whose behavior across subsamples\nagrees with the distribution predicted by the theory.\n", "versions": [{"version": "v1", "created": "Thu, 26 Feb 2015 17:25:03 GMT"}, {"version": "v2", "created": "Mon, 23 Mar 2015 19:23:59 GMT"}, {"version": "v3", "created": "Fri, 1 Sep 2017 18:59:57 GMT"}], "update_date": "2017-09-05", "authors_parsed": [["Barber", "Rina Foygel", ""], ["Kolar", "Mladen", ""]]}, {"id": "1502.07989", "submitter": "Chun Wang", "authors": "Chun Wang, Ming-Hui Chen, Elizabeth Schifano, Jing Wu, and Jun Yan", "title": "Statistical Methods and Computing for Big Data", "comments": null, "journal-ref": "Statistics and Its Interface 9 (2016) 399-414", "doi": "10.4310/SII.2016.v9.n4.a1", "report-no": null, "categories": "stat.CO math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Big data are data on a massive scale in terms of volume, intensity, and\ncomplexity that exceed the capacity of standard software tools. They present\nopportunities as well as challenges to statisticians. The role of computational\nstatisticians in scientific discovery from big data analyses has been\nunder-recognized even by peer statisticians. This article reviews recent\nmethodological and software developments in statistics that address the big\ndata challenges. Methodologies are grouped into three classes:\nsubsampling-based, divide and conquer, and sequential updating for stream data.\nSoftware review focuses on the open source R and R packages, covering recent\ntools that help break the barriers of computer memory and computing power. Some\nof the tools are illustrated in a case study with a logistic regression for the\nchance of airline delay.\n", "versions": [{"version": "v1", "created": "Fri, 27 Feb 2015 17:59:22 GMT"}, {"version": "v2", "created": "Wed, 28 Oct 2015 03:09:07 GMT"}], "update_date": "2018-06-13", "authors_parsed": [["Wang", "Chun", ""], ["Chen", "Ming-Hui", ""], ["Schifano", "Elizabeth", ""], ["Wu", "Jing", ""], ["Yan", "Jun", ""]]}, {"id": "1502.08012", "submitter": "Abdelhakim Necir", "authors": "S. Benchaira, D. Meraghni and A. Necir", "title": "On the estimation of the extreme value index for randomly\n  right-truncated data and application", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  We introduce a consistent estimator of the extreme value index under random\ntruncation based on a single sample fraction of top observations from truncated\nand truncation data. We establish the asymptotic normality of the proposed\nestimator by making use of the weighted tail-copula process framework and we\ncheck its finite sample behavior through some simulations. As an application,\nwe provide asymptotic normality results for an estimator of the excess-of-loss\nreinsurance premium.\n", "versions": [{"version": "v1", "created": "Fri, 27 Feb 2015 19:01:31 GMT"}], "update_date": "2015-03-02", "authors_parsed": [["Benchaira", "S.", ""], ["Meraghni", "D.", ""], ["Necir", "A.", ""]]}]