[{"id": "1303.0148", "submitter": "Claudio Durastanti", "authors": "Claudio Durastanti and Xiaohong Lan", "title": "High-Frequency Tail Index Estimation by Nearly Tight Frames", "comments": "38 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work develops the asymptotic properties (weak consistency and\nGaussianity), in the high-frequency limit, of approximate maximum likelihood\nestimators for the spectral parameters of Gaussian and isotropic spherical\nrandom fields. The procedure we used exploits the so-called mexican needlet\nconstruction by Geller and Mayeli in [Geller, Mayeli (2009)]. Furthermore, we\npropose a plug-in procedure to optimize the precision of the estimators in\nterms of asymptotic variance.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2013 11:34:39 GMT"}], "update_date": "2013-03-04", "authors_parsed": [["Durastanti", "Claudio", ""], ["Lan", "Xiaohong", ""]]}, {"id": "1303.0159", "submitter": "Vydas \\v{C}ekanavi\\v{c}ius", "authors": "Vydas Cekanavicius and Aiste Elijio", "title": "Smoothing effect of Compound Poisson approximation to distribution of\n  weighted sums", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The accuracy of compound Poisson approximation to the sum\n$S=w_1S_1+w_2S_2+...+w_NS_N$ is estimated.\n  Here $S_i$ are sums of independent or weakly dependent random variables, and\n$w_i$ denote weights. The overall smoothing effect of $S$ on $w_iS_i$ is\nestimated by L\\' evy concentration function.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2013 12:53:01 GMT"}], "update_date": "2013-03-04", "authors_parsed": [["Cekanavicius", "Vydas", ""], ["Elijio", "Aiste", ""]]}, {"id": "1303.0238", "submitter": "James M. Flegal", "authors": "James M. Flegal and Lei Gong", "title": "Relative fixed-width stopping rules for Markov chain Monte Carlo\n  simulations", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov chain Monte Carlo (MCMC) simulations are commonly employed for\nestimating features of a target distribution, particularly for Bayesian\ninference. A fundamental challenge is determining when these simulations should\nstop. We consider a sequential stopping rule that terminates the simulation\nwhen the width of a confidence interval is sufficiently small relative to the\nsize of the target parameter. Specifically, we propose relative magnitude and\nrelative standard deviation stopping rules in the context of MCMC. In each\nsetting, we develop sufficient conditions for asymptotic validity, that is\nconditions to ensure the simulation will terminate with probability one and the\nresulting confidence intervals will have the proper coverage probability. Our\nresults are applicable in a wide variety of MCMC estimation settings, such as\nexpectation, quantile, or simultaneous multivariate estimation. Finally, we\ninvestigate the finite sample properties through a variety of examples and\nprovide some recommendations to practitioners.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2013 18:04:30 GMT"}], "update_date": "2013-03-04", "authors_parsed": [["Flegal", "James M.", ""], ["Gong", "Lei", ""]]}, {"id": "1303.0268", "submitter": "Guido F.  Montufar", "authors": "Guido Montufar, Johannes Rauh, Nihat Ay", "title": "Maximal Information Divergence from Statistical Models defined by Neural\n  Networks", "comments": "8 pages, 1 figure", "journal-ref": "Geometric science of information : first international conference,\n  GSI 2013, Paris, France, August 28-30, 2013. Proceedings / F. Nielsen...\n  (eds.). Springer, 2013. - P. 759-766", "doi": "10.1007/978-3-642-40020-9_85", "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We review recent results about the maximal values of the Kullback-Leibler\ninformation divergence from statistical models defined by neural networks,\nincluding naive Bayes models, restricted Boltzmann machines, deep belief\nnetworks, and various classes of exponential families. We illustrate approaches\nto compute the maximal divergence from a given model starting from simple sub-\nor super-models. We give a new result for deep and narrow belief networks with\nfinite-valued units.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2013 20:21:32 GMT"}], "update_date": "2014-06-18", "authors_parsed": [["Montufar", "Guido", ""], ["Rauh", "Johannes", ""], ["Ay", "Nihat", ""]]}, {"id": "1303.0458", "submitter": "Yunbei  MA", "authors": "Jianqing Fan, Yunbei Ma and Wei Dai", "title": "Nonparametric Independence Screening in Sparse Ultra-High Dimensional\n  Varying Coefficient Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The varying-coefficient model is an important nonparametric statistical model\nthat allows us to examine how the effects of covariates vary with exposure\nvariables. When the number of covariates is big, the issue of variable\nselection arrives. In this paper, we propose and investigate marginal\nnonparametric screening methods to screen variables in ultra-high dimensional\nsparse varying-coefficient models. The proposed nonparametric independence\nscreening (NIS) selects variables by ranking a measure of the nonparametric\nmarginal contributions of each covariate given the exposure variable. The sure\nindependent screening property is established under some mild technical\nconditions when the dimensionality is of nonpolynomial order, and the\ndimensionality reduction of NIS is quantified. To enhance practical utility and\nthe finite sample performance, two data-driven iterative NIS methods are\nproposed for selecting thresholding parameters and variables: conditional\npermutation and greedy methods, resulting in Conditional-INIS and Greedy-INIS.\nThe effectiveness and flexibility of the proposed methods are further\nillustrated by simulation studies and real data applications.\n", "versions": [{"version": "v1", "created": "Sun, 3 Mar 2013 05:15:16 GMT"}], "update_date": "2013-03-05", "authors_parsed": [["Fan", "Jianqing", ""], ["Ma", "Yunbei", ""], ["Dai", "Wei", ""]]}, {"id": "1303.0518", "submitter": "Sara van de Geer", "authors": "Sara van de Geer, Peter B\\\"uhlmann, Ya'acov Ritov, Ruben Dezeure", "title": "On asymptotically optimal confidence regions and tests for\n  high-dimensional models", "comments": "Published in at http://dx.doi.org/10.1214/14-AOS1221 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2014, Vol. 42, No. 3, 1166-1202", "doi": "10.1214/14-AOS1221", "report-no": "IMS-AOS-AOS1221", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a general method for constructing confidence intervals and\nstatistical tests for single or low-dimensional components of a large parameter\nvector in a high-dimensional model. It can be easily adjusted for multiplicity\ntaking dependence among tests into account. For linear models, our method is\nessentially the same as in Zhang and Zhang [J. R. Stat. Soc. Ser. B Stat.\nMethodol. 76 (2014) 217-242]: we analyze its asymptotic properties and\nestablish its asymptotic optimality in terms of semiparametric efficiency. Our\nmethod naturally extends to generalized linear models with convex loss\nfunctions. We develop the corresponding theory which includes a careful\nanalysis for Gaussian, sub-Gaussian and bounded correlated designs.\n", "versions": [{"version": "v1", "created": "Sun, 3 Mar 2013 15:36:31 GMT"}, {"version": "v2", "created": "Thu, 10 Oct 2013 14:12:14 GMT"}, {"version": "v3", "created": "Mon, 23 Jun 2014 11:31:41 GMT"}], "update_date": "2014-06-24", "authors_parsed": [["van de Geer", "Sara", ""], ["B\u00fchlmann", "Peter", ""], ["Ritov", "Ya'acov", ""], ["Dezeure", "Ruben", ""]]}, {"id": "1303.0727", "submitter": "Miles Lopes", "authors": "Miles E. Lopes", "title": "Estimating a sharp convergence bound for randomized ensembles", "comments": "This paper extends the earlier work, \"The Convergence Rate of\n  Majority Vote under Exchangeability\" from 2013, as well as \"A Sharp Bound on\n  the Computation-Accuracy Tradeoff for Majority Voting Ensembles\" from 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.SI math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When randomized ensembles such as bagging or random forests are used for\nbinary classification, the prediction error of the ensemble tends to decrease\nand stabilize as the number of classifiers increases. However, the precise\nrelationship between prediction error and ensemble size is unknown in practice.\nIn the standard case when classifiers are aggregated by majority vote, the\npresent work offers a way to quantify this convergence in terms of \"algorithmic\nvariance,\" i.e. the variance of prediction error due only to the randomized\ntraining algorithm. Specifically, we study a theoretical upper bound on this\nvariance, and show that it is sharp --- in the sense that it is attained by a\nspecific family of randomized classifiers. Next, we address the problem of\nestimating the unknown value of the bound, which leads to a unique twist on the\nclassical problem of non-parametric density estimation. In particular, we\ndevelop an estimator for the bound and show that its MSE matches optimal\nnon-parametric rates under certain conditions. (Concurrent with this work, some\nclosely related results have also been considered in Cannings and Samworth\n(2017) and Lopes (2019).)\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2013 15:16:00 GMT"}, {"version": "v2", "created": "Fri, 3 Jun 2016 10:34:41 GMT"}, {"version": "v3", "created": "Tue, 30 Apr 2019 08:23:09 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Lopes", "Miles E.", ""]]}, {"id": "1303.0974", "submitter": "Claudio Durastanti", "authors": "Claudio Durastanti", "title": "Block Thresholding on the Sphere", "comments": "25 pages", "journal-ref": "Sankhya A February 2015, Volume 77, Issue 1, pp 153-185", "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this paper is to study the nonparametric regression estimators on\nthe sphere built by the needlet block thresholding. The block thresholding\nprocedure proposed here follows the method introduced by Hall, Kerkyacharian\nand Picard in [Hall, Kerkyacharian, Picard, (1998), (1999)], modified to\nexploit the properties of the spherical standard needlets. Therefore, we will\ninvestigate on their convergence rates, attaining their adaptive properties\nover the Besov balls. This work is strongly motivated by issues arising in\nCosmology and Astrophysics, concerning in particular the analysis of cosmic\nrays.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2013 10:28:58 GMT"}, {"version": "v2", "created": "Fri, 23 Jan 2015 09:48:21 GMT"}], "update_date": "2015-04-03", "authors_parsed": [["Durastanti", "Claudio", ""]]}, {"id": "1303.1284", "submitter": "Michael Falk", "authors": "Michael Falk", "title": "On Idempotent D-Norms", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Replacing the spectral measure by a random vector $\\bfZ$ allows the\nrepresentation of a max-stable distribution on $\\R^d$ with standard negative\nmargins via a norm, called \\emph{$D$-norm}, whose generator is $\\bfZ$. The set\nof $D$-norms can be equipped with a commutative multiplication type operation,\nmaking it a semigroup with an identity element. This multiplication leads to\nidempotent $D$-norms. We characterize the set of idempotent $D$-norms.\nIterating the multiplication provides a track of $D$-norms, whose limit exists\nand is again a $D$-norm. If this iteration is repeatedly done on the same\n$D$-norm, then the limit of the track is idempotent.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2013 09:38:15 GMT"}, {"version": "v2", "created": "Thu, 31 Oct 2013 09:18:20 GMT"}, {"version": "v3", "created": "Wed, 26 Nov 2014 10:00:07 GMT"}], "update_date": "2014-11-27", "authors_parsed": [["Falk", "Michael", ""]]}, {"id": "1303.1285", "submitter": "Animesh Kumar", "authors": "Animesh Kumar", "title": "Bandlimited Signal Reconstruction From the Distribution of Unknown\n  Sampling Locations", "comments": "Submitted to SampTA 2013 workshop", "journal-ref": null, "doi": "10.1109/TSP.2015.2394248", "report-no": null, "categories": "cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the reconstruction of bandlimited fields from samples taken at\nunknown but statistically distributed sampling locations. The setup is\nmotivated by distributed sampling where precise knowledge of sensor locations\ncan be difficult.\n  Periodic one-dimensional bandlimited fields are considered for sampling.\nPerfect samples of the field at independent and identically distributed\nlocations are obtained. The statistical realization of sampling locations is\nnot known. First, it is shown that a bandlimited field cannot be uniquely\ndetermined with samples taken at statistically distributed but unknown\nlocations, even if the number of samples is infinite. Next, it is assumed that\nthe order of sample locations is known. In this case, using insights from\norder-statistics, an estimate for the field with useful asymptotic properties\nis designed. Distortion (mean-squared error) and central-limit are established\nfor this estimate.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2013 09:39:09 GMT"}], "update_date": "2017-07-12", "authors_parsed": [["Kumar", "Animesh", ""]]}, {"id": "1303.1288", "submitter": "M{\\aa}ns Thulin", "authors": "M{\\aa}ns Thulin", "title": "The cost of using exact confidence intervals for a binomial proportion", "comments": null, "journal-ref": "Electronic Journal of Statistics, 8, 817-840 (2014)", "doi": "10.1214/14-EJS909", "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When computing a confidence interval for a binomial proportion p one must\nchoose between using an exact interval, which has a coverage probability of at\nleast 1-{\\alpha} for all values of p, and a shorter approximate interval, which\nmay have lower coverage for some p but that on average has coverage equal to\n1-\\alpha. We investigate the cost of using the exact one and two-sided\nClopper--Pearson confidence intervals rather than shorter approximate\nintervals, first in terms of increased expected length and then in terms of the\nincrease in sample size required to obtain a desired expected length. Using\nasymptotic expansions, we also give a closed-form formula for determining the\nsample size for the exact Clopper--Pearson methods. For two-sided intervals,\nour investigation reveals an interesting connection between the frequentist\nClopper--Pearson interval and Bayesian intervals based on noninformative\npriors.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2013 10:00:25 GMT"}], "update_date": "2015-03-11", "authors_parsed": [["Thulin", "M\u00e5ns", ""]]}, {"id": "1303.1435", "submitter": "Victoria Zinde-Walsh", "authors": "Victoria Zinde-Walsh", "title": "Nonparametric functionals as generalized functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper considers probability distribution, density, conditional\ndistribution and density and conditional moments as well as their kernel\nestimators in spaces of generalized functions. This approach does not require\nrestrictions on classes of distributions common in nonparametric estimation.\nDensity in usual function spaces is not well-posed; this paper establishes\nexistence and well-posedness of the generalized density function. It also\ndemonstrates root-n convergence of the kernel density estimator in the space of\ngeneralized functions. It is shown that the usual kernel estimator of the\nconditional distribution converges at a parametric rate as a random process in\nthe space of generalized functions to a limit Gaussian process regardless of\npointwise existence of the conditional distribution. Conditional moments such\nas conditional mean are also be characterized via generalized functions.\nConvergence of the kernel estimators to the limit Gaussian process is shown to\nhold as long as the appropriate moments exist.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2013 19:45:28 GMT"}], "update_date": "2013-03-07", "authors_parsed": [["Zinde-Walsh", "Victoria", ""]]}, {"id": "1303.1690", "submitter": "Johanna F. Ziegel", "authors": "Johanna F. Ziegel", "title": "Coherence and elicitability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM math.ST q-fin.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The risk of a financial position is usually summarized by a risk measure. As\nthis risk measure has to be estimated from historical data, it is important to\nbe able to verify and compare competing estimation procedures. In statistical\ndecision theory, risk measures for which such verification and comparison is\npossible, are called elicitable. It is known that quantile based risk measures\nsuch as value at risk are elicitable. In this paper we show that law-invariant\nspectral risk measures such as expected shortfall are not elicitable unless\nthey reduce to minus the expected value. Hence, it is unclear how to perform\nforecast verification or comparison. However, the class of elicitable\nlaw-invariant coherent risk measures does not reduce to minus the expected\nvalue. We show that it consists of certain expectiles.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2013 14:03:32 GMT"}, {"version": "v2", "created": "Fri, 8 Mar 2013 10:39:49 GMT"}, {"version": "v3", "created": "Mon, 31 Mar 2014 13:12:28 GMT"}], "update_date": "2014-04-01", "authors_parsed": [["Ziegel", "Johanna F.", ""]]}, {"id": "1303.1698", "submitter": "Itai Dattner", "authors": "Itai Dattner, Markus Rei{\\ss}, Mathias Trabs", "title": "Adaptive quantile estimation in deconvolution with unknown error\n  distribution", "comments": "Published at http://dx.doi.org/10.3150/14-BEJ626 in the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2016, Vol. 22, No. 1, 143-192", "doi": "10.3150/14-BEJ626", "report-no": "IMS-BEJ-BEJ626", "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantile estimation in deconvolution problems is studied comprehensively. In\nparticular, the more realistic setup of unknown error distributions is covered.\nOur plug-in method is based on a deconvolution density estimator and is minimax\noptimal under minimal and natural conditions. This closes an important gap in\nthe literature. Optimal adaptive estimation is obtained by a data-driven\nbandwidth choice. As a side result, we obtain optimal rates for the plug-in\nestimation of distribution functions with unknown error distributions. The\nmethod is applied to a real data example.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2013 14:23:32 GMT"}, {"version": "v2", "created": "Wed, 15 May 2013 08:34:35 GMT"}, {"version": "v3", "created": "Tue, 26 Nov 2013 14:45:25 GMT"}, {"version": "v4", "created": "Mon, 14 Apr 2014 13:16:06 GMT"}, {"version": "v5", "created": "Fri, 15 Jan 2016 13:20:27 GMT"}], "update_date": "2016-01-18", "authors_parsed": [["Dattner", "Itai", ""], ["Rei\u00df", "Markus", ""], ["Trabs", "Mathias", ""]]}, {"id": "1303.1743", "submitter": "David K\\\"allberg Mr", "authors": "David K\\\"allberg, Nikolaj Leonenko, Oleg Seleznjev", "title": "Statistical estimation of quadratic R\\'enyi entropy for a stationary\n  m-dependent sequence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The R\\'enyi entropy is a generalization of the Shannon entropy and is widely\nused in mathematical statistics and applied sciences for quantifying the\nuncertainty in a probability distribution. We consider estimation of the\nquadratic R\\'enyi entropy and related functionals for the marginal distribution\nof a stationary m-dependent sequence. The U-statistic estimators under study\nare based on the number of epsilon-close vector observations in the\ncorresponding sample. A variety of asymptotic properties for these estimators\nare obtained (e.g., consistency, asymptotic normality, Poisson convergence).\nThe results can be used in diverse statistical and computer science problems\nwhenever the conventional independence assumption is too strong (e.g.,\nepsilon-keys in time series databases, distribution identification problems for\ndependent samples).\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2013 16:48:33 GMT"}], "update_date": "2013-03-08", "authors_parsed": [["K\u00e4llberg", "David", ""], ["Leonenko", "Nikolaj", ""], ["Seleznjev", "Oleg", ""]]}, {"id": "1303.1927", "submitter": "Ori Davidov", "authors": "Ori Davidov, Shyamal Peddada", "title": "The linear stochastic order and directed inference for multivariate\n  ordered distributions", "comments": "Published in at http://dx.doi.org/10.1214/12-AOS1062 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2013, Vol. 41, No. 1, 1-40", "doi": "10.1214/12-AOS1062", "report-no": "IMS-AOS-AOS1062", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Researchers are often interested in drawing inferences regarding the order\nbetween two experimental groups on the basis of multivariate response data.\nSince standard multivariate methods are designed for two-sided alternatives,\nthey may not be ideal for testing for order between two groups. In this article\nwe introduce the notion of the linear stochastic order and investigate its\nproperties. Statistical theory and methodology are developed to both estimate\nthe direction which best separates two arbitrary ordered distributions and to\ntest for order between the two groups. The new methodology generalizes Roy's\nclassical largest root test to the nonparametric setting and is applicable to\nrandom vectors with discrete and/or continuous components. The proposed\nmethodology is illustrated using data obtained from a 90-day pre-chronic rodent\ncancer bioassay study conducted by the National Toxicology Program (NTP).\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2013 10:10:54 GMT"}], "update_date": "2013-03-11", "authors_parsed": [["Davidov", "Ori", ""], ["Peddada", "Shyamal", ""]]}, {"id": "1303.2209", "submitter": "Donata Puplinskait\\normalfont\\.{E}", "authors": "Donata Puplinskait\\.e, Donatas Surgailis", "title": "Aggregation of autoregressive random fields and anisotropic long-range\n  dependence", "comments": "Published at http://dx.doi.org/10.3150/15-BEJ733 in the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2016, Vol. 22, No. 4, 2401-2441", "doi": "10.3150/15-BEJ733", "report-no": "IMS-BEJ-BEJ733", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the notions of scaling transition and distributional long-range\ndependence for stationary random fields $Y$ on $\\mathbb {Z}^2$ whose normalized\npartial sums on rectangles with sides growing at rates $O(n)$ and\n$O(n^{\\gamma})$ tend to an operator scaling random field $V_{\\gamma}$ on\n$\\mathbb {R}^2$, for any $\\gamma>0$. The scaling transition is characterized by\nthe fact that there exists a unique $\\gamma_0>0$ such that the scaling limits\n$V_{\\gamma}$ are different and do not depend on $\\gamma$ for $\\gamma>\\gamma_0$\nand $\\gamma<\\gamma_0$. The existence of scaling transition together with\nanisotropic and isotropic distributional long-range dependence properties is\ndemonstrated for a class of $\\alpha$-stable $(1<\\alpha\\le2)$ aggregated\nnearest-neighbor autoregressive random fields on $\\mathbb{Z}^2$ with a scalar\nrandom coefficient $A$ having a regularly varying probability density near the\n\"unit root\" $A=1$.\n", "versions": [{"version": "v1", "created": "Sat, 9 Mar 2013 13:40:53 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2013 22:00:37 GMT"}, {"version": "v3", "created": "Sun, 23 Nov 2014 18:27:26 GMT"}, {"version": "v4", "created": "Thu, 23 Jun 2016 09:03:41 GMT"}], "update_date": "2016-06-24", "authors_parsed": [["Puplinskait\u0117", "Donata", ""], ["Surgailis", "Donatas", ""]]}, {"id": "1303.2236", "submitter": "Benjamin Guedj", "authors": "G\\'erard Biau and Aur\\'elie Fischer and Benjamin Guedj and James\n  Malley", "title": "COBRA: A Combined Regression Strategy", "comments": "42 pages", "journal-ref": "Journal of Multivariate Analysis (2016), vol. 146, 18--28", "doi": "10.1016/j.jmva.2015.04.007", "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A new method for combining several initial estimators of the regression\nfunction is introduced. Instead of building a linear or convex optimized\ncombination over a collection of basic estimators $r_1,\\dots,r_M$, we use them\nas a collective indicator of the proximity between the training data and a test\nobservation. This local distance approach is model-free and very fast. More\nspecifically, the resulting nonparametric/nonlinear combined estimator is shown\nto perform asymptotically at least as well in the $L^2$ sense as the best\ncombination of the basic estimators in the collective. A companion R package\ncalled \\cobra (standing for COmBined Regression Alternative) is presented\n(downloadable on\n\\url{http://cran.r-project.org/web/packages/COBRA/index.html}). Substantial\nnumerical evidence is provided on both synthetic and real data sets to assess\nthe excellent performance and velocity of our method in a large variety of\nprediction problems.\n", "versions": [{"version": "v1", "created": "Sat, 9 Mar 2013 16:52:59 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2013 17:47:41 GMT"}, {"version": "v3", "created": "Wed, 20 Nov 2013 18:52:48 GMT"}, {"version": "v4", "created": "Thu, 23 May 2019 05:41:24 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Biau", "G\u00e9rard", ""], ["Fischer", "Aur\u00e9lie", ""], ["Guedj", "Benjamin", ""], ["Malley", "James", ""]]}, {"id": "1303.2423", "submitter": "Houying Zhu", "authors": "Josef Dick, Daniel Rudolf, Houying Zhu", "title": "Discrepancy bounds for uniformly ergodic Markov chain quasi-Monte Carlo", "comments": "Accepted for publication in the Annals of Applied Probability, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO math.NA math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov chains can be used to generate samples whose distribution approximates\na given target distribution. The quality of the samples of such Markov chains\ncan be measured by the discrepancy between the empirical distribution of the\nsamples and the target distribution. We prove upper bounds on this discrepancy\nunder the assumption that the Markov chain is uniformly ergodic and the driver\nsequence is deterministic rather than independent $U(0,1)$ random variables. In\nparticular, we show the existence of driver sequences for which the discrepancy\nof the Markov chain from the target distribution with respect to certain test\nsets converges with (almost) the usual Monte Carlo rate of $n^{-1/2}$.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2013 04:34:38 GMT"}, {"version": "v2", "created": "Tue, 19 Mar 2013 03:47:19 GMT"}, {"version": "v3", "created": "Fri, 15 Jan 2016 07:00:43 GMT"}], "update_date": "2016-01-18", "authors_parsed": [["Dick", "Josef", ""], ["Rudolf", "Daniel", ""], ["Zhu", "Houying", ""]]}, {"id": "1303.2452", "submitter": "Stefan Aulbach", "authors": "Stefan Aulbach, Michael Falk, Martin Hofmann and Maximilian Zott", "title": "Max-stable processes and the functional D-norm revisited", "comments": "22 pages", "journal-ref": null, "doi": "10.1007/s10687-014-0210-0", "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aulbach et al. (2013) introduced a max-domain of attraction approach for\nextreme value theory in C[0,1] based on functional distribution functions,\nwhich is more general than the approach based on weak convergence in de Haan\nand Lin (2001). We characterize this new approach by decomposing a process into\nits univariate margins and its copula process. In particular, those processes\nwith a polynomial rate of convergence towards a max-stable process are\nconsidered. Furthermore we investigate the concept of differentiability in\ndistribution of a max-stable processes.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2013 08:40:10 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2014 16:15:06 GMT"}, {"version": "v3", "created": "Fri, 28 Feb 2014 14:32:10 GMT"}, {"version": "v4", "created": "Thu, 11 Dec 2014 18:02:00 GMT"}], "update_date": "2014-12-12", "authors_parsed": [["Aulbach", "Stefan", ""], ["Falk", "Michael", ""], ["Hofmann", "Martin", ""], ["Zott", "Maximilian", ""]]}, {"id": "1303.2456", "submitter": "Domenico Marinucci", "authors": "Domenico Marinucci, Sreekar Vadlamani", "title": "High-frequency asymptotics for Lipschitz-Killing curvatures of excursion\n  sets on the sphere", "comments": "Published at http://dx.doi.org/10.1214/15-AAP1097 in the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Probability 2016, Vol. 26, No. 1, 462-506", "doi": "10.1214/15-AAP1097", "report-no": "IMS-AAP-AAP1097", "categories": "math.PR astro-ph.CO math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we shall be concerned with geometric functionals and excursion\nprobabilities for some nonlinear transforms evaluated on Fourier components of\nspherical random fields. In particular, we consider both random spherical\nharmonics and their smoothed averages, which can be viewed as random wavelet\ncoefficients in the continuous case. For such fields, we consider smoothed\npolynomial transforms; we focus on the geometry of their excursion sets, and we\nstudy their asymptotic behaviour, in the high-frequency sense. We focus on the\nanalysis of Euler-Poincar\\'{e} characteristics, which can be exploited to\nderive extremely accurate estimates for excursion probabilities. The present\nanalysis is motivated by the investigation of asymmetries and anisotropies in\ncosmological data. The statistics we focus on are also suitable to deal with\nspherical random fields which can only be partially observed, the canonical\nexample being provided by the masking effect of the Milky Way on Cosmic\nMicrowave Background (CMB) radiation data.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2013 09:00:08 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2014 05:26:58 GMT"}, {"version": "v3", "created": "Tue, 12 Jan 2016 08:07:12 GMT"}], "update_date": "2016-01-13", "authors_parsed": [["Marinucci", "Domenico", ""], ["Vadlamani", "Sreekar", ""]]}, {"id": "1303.2698", "submitter": "Xiaodong Luo", "authors": "Xiaodong Luo, and Ibrahim Hoteit", "title": "Efficient particle filtering through residual nudging", "comments": "Accepted to publish in Quarterly Journal of the Royal Meteorological\n  Society (QJRMS)", "journal-ref": null, "doi": "10.1002/qj.2152", "report-no": null, "categories": "physics.ao-ph math.ST physics.data-an stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an auxiliary technique, called residual nudging, to the particle\nfilter to enhance its performance in cases that it performs poorly. The main\nidea of residual nudging is to monitor, and if necessary, adjust the residual\nnorm of a state estimate in the observation space so that it does not exceed a\npre-specified threshold. We suggest a rule to choose the pre-specified\nthreshold, and construct a state estimate accordingly to achieve this\nobjective. Numerical experiments suggest that introducing residual nudging to a\nparticle filter may (substantially) improve its performance, in terms of filter\naccuracy and/or stability against divergence, especially when the particle\nfilter is implemented with a relatively small number of particles.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2013 21:26:03 GMT"}], "update_date": "2013-06-03", "authors_parsed": [["Luo", "Xiaodong", ""], ["Hoteit", "Ibrahim", ""]]}, {"id": "1303.2707", "submitter": "Andrew Francis", "authors": "Andrew R. Francis and Henry P. Wynn", "title": "Subgroup Majorization", "comments": "18 pages. To appear, Linear Algebra and its Applications", "journal-ref": "Linear Algebra and its Applications, Volume 444, 1 March 2014,\n  Pages 53--66", "doi": "10.1016/j.laa.2013.11.042", "report-no": null, "categories": "math.ST math.GR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The extension of majorization (also called the rearrangement ordering), to\nmore general groups than the symmetric (permutation) group, is referred to as\n$G$-majorization. There are strong results in the case that $G$ is a reflection\ngroup and this paper builds on this theory in the direction of subgroups,\nnormal subgroups, quotient groups and extensions. The implications for\nfundamental cones and order-preserving functions are studied. The main example\nconsidered is the hyperoctahedral group, which, acting on a vector in $\\mathbb\nR^n$, permutes and changes the signs of components.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2013 22:53:25 GMT"}, {"version": "v2", "created": "Thu, 27 Jun 2013 23:04:18 GMT"}, {"version": "v3", "created": "Sun, 24 Nov 2013 11:24:01 GMT"}, {"version": "v4", "created": "Wed, 27 Nov 2013 21:59:09 GMT"}], "update_date": "2014-09-30", "authors_parsed": [["Francis", "Andrew R.", ""], ["Wynn", "Henry P.", ""]]}, {"id": "1303.2800", "submitter": "Wei Zheng", "authors": "Wei Zheng", "title": "Universally optimal crossover designs under subject dropout", "comments": "Published in at http://dx.doi.org/10.1214/12-AOS1074 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2013, Vol. 41, No. 1, 63-90", "doi": "10.1214/12-AOS1074", "report-no": "IMS-AOS-AOS1074", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subject dropout is very common in practical applications of crossover\ndesigns. However, there is very limited design literature taking this into\naccount. Optimality results have not yet been well established due to the\ncomplexity of the problem. This paper establishes feasible, as well as\nnecessary and sufficient conditions for a crossover design to be universally\noptimal in approximate design theory in the presence of subject dropout. These\nconditions are essentially linear equations with respect to proportions of all\npossible treatment sequences being applied to subjects and hence they can be\neasily solved. A general algorithm is proposed to derive exact designs which\nare shown to be efficient and robust.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2013 08:13:22 GMT"}], "update_date": "2013-03-13", "authors_parsed": [["Zheng", "Wei", ""]]}, {"id": "1303.2814", "submitter": "Dawn B. Woodard", "authors": "Dawn B. Woodard, Jeffrey S. Rosenthal", "title": "Convergence rate of Markov chain methods for genomic motif discovery", "comments": "Published in at http://dx.doi.org/10.1214/12-AOS1075 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2013, Vol. 41, No. 1, 91-124", "doi": "10.1214/12-AOS1075", "report-no": "IMS-AOS-AOS1075", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the convergence rate of a simplified version of a popular Gibbs\nsampling method used for statistical discovery of gene regulatory binding\nmotifs in DNA sequences. This sampler satisfies a very strong form of\nergodicity (uniform). However, we show that, due to multimodality of the\nposterior distribution, the rate of convergence often decreases exponentially\nas a function of the length of the DNA sequence. Specifically, we show that\nthis occurs whenever there is more than one true repeating pattern in the data.\nIn practice there are typically multiple such patterns in biological data, the\ngoal being to detect the most well-conserved and frequently-occurring of these.\nOur findings match empirical results, in which the motif-discovery Gibbs\nsampler has exhibited such poor convergence that it is used only for finding\nmodes of the posterior distribution (candidate motifs) rather than for\nobtaining samples from that distribution. Ours are some of the first meaningful\nbounds on the convergence rate of a Markov chain method for sampling from a\nmultimodal posterior distribution, as a function of statistical quantities like\nthe number of observations.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2013 09:32:02 GMT"}], "update_date": "2013-03-13", "authors_parsed": [["Woodard", "Dawn B.", ""], ["Rosenthal", "Jeffrey S.", ""]]}, {"id": "1303.2863", "submitter": "Holger Dette", "authors": "Holger Dette, Andrey Pepelyshev, Anatoly Zhigljavsky", "title": "Optimal design for linear models with correlated observations", "comments": "Published in at http://dx.doi.org/10.1214/12-AOS1079 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2013, Vol. 41, No. 1, 143-176", "doi": "10.1214/12-AOS1079", "report-no": "IMS-AOS-AOS1079", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the common linear regression model the problem of determining optimal\ndesigns for least squares estimation is considered in the case where the\nobservations are correlated. A necessary condition for the optimality of a\ngiven design is provided, which extends the classical equivalence theory for\noptimal designs in models with uncorrelated errors to the case of dependent\ndata. If the regression functions are eigenfunctions of an integral operator\ndefined by the covariance kernel, it is shown that the corresponding measure\ndefines a universally optimal design. For several models universally optimal\ndesigns can be identified explicitly. In particular, it is proved that the\nuniform distribution is universally optimal for a class of trigonometric\nregression models with a broad class of covariance kernels and that the arcsine\ndistribution is universally optimal for the polynomial regression model with\ncorrelation structure defined by the logarithmic potential. To the best\nknowledge of the authors these findings provide the first explicit results on\noptimal designs for regression models with correlated observations, which are\nnot restricted to the location scale model.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2013 12:51:43 GMT"}], "update_date": "2013-03-13", "authors_parsed": [["Dette", "Holger", ""], ["Pepelyshev", "Andrey", ""], ["Zhigljavsky", "Anatoly", ""]]}, {"id": "1303.2874", "submitter": "Jiming Jiang", "authors": "Jiming Jiang", "title": "The subset argument and consistency of MLE in GLMM: Answer to an open\n  problem and beyond", "comments": "Published in at http://dx.doi.org/10.1214/13-AOS1084 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2013, Vol. 41, No. 1, 177-195", "doi": "10.1214/13-AOS1084", "report-no": "IMS-AOS-AOS1084", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give answer to an open problem regarding consistency of the maximum\nlikelihood estimators (MLEs) in generalized linear mixed models (GLMMs)\ninvolving crossed random effects. The solution to the open problem introduces\nan interesting, nonstandard approach to proving consistency of the MLEs in\ncases of dependent observations. Using the new technique, we extend the results\nto MLEs under a general GLMM. An example is used to further illustrate the\ntechnique.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2013 13:28:36 GMT"}], "update_date": "2013-03-13", "authors_parsed": [["Jiang", "Jiming", ""]]}, {"id": "1303.2910", "submitter": "Gareth Peters Dr", "authors": "Gareth W.Peters and Rodrigo S. Targino and Pavel V. Shevchenko", "title": "Understanding Operational Risk Capital Approximations: First and Second\n  Orders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We set the context for capital approximation within the framework of the\nBasel II / III regulatory capital accords. This is particularly topical as the\nBasel III accord is shortly due to take effect. In this regard, we provide a\nsummary of the role of capital adequacy in the new accord, highlighting along\nthe way the significant loss events that have been attributed to the\nOperational Risk class that was introduced in the Basel II and III accords.\nThen we provide a semi-tutorial discussion on the modelling aspects of capital\nestimation under a Loss Distributional Approach (LDA). Our emphasis is to focus\non the important loss processes with regard to those that contribute most to\ncapital, the so called high consequence, low frequency loss processes. This\nleads us to provide a tutorial overview of heavy tailed loss process modelling\nin OpRisk under Basel III, with discussion on the implications of such tail\nassumptions for the severity model in an LDA structure. This provides\npractitioners with a clear understanding of the features that they may wish to\nconsider when developing OpRisk severity models in practice. From this\ndiscussion on heavy tailed severity models, we then develop an understanding of\nthe impact such models have on the right tail asymptotics of the compound loss\nprocess and we provide detailed presentation of what are known as first and\nsecond order tail approximations for the resulting heavy tailed loss process.\nFrom this we develop a tutorial on three key families of risk measures and\ntheir equivalent second order asymptotic approximations: Value-at-Risk (Basel\nIII industry standard); Expected Shortfall (ES) and the Spectral Risk Measure.\nThese then form the capital approximations.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2013 15:17:00 GMT"}], "update_date": "2013-03-13", "authors_parsed": [["Peters", "Gareth W.", ""], ["Targino", "Rodrigo S.", ""], ["Shevchenko", "Pavel V.", ""]]}, {"id": "1303.3118", "submitter": "Johannes Schmidt-Hieber", "authors": "Johannes Schmidt-Hieber", "title": "On an estimator achieving the adaptive rate in nonparametric regression\n  under $L^p$-loss for all $1\\leq p \\leq \\infty$", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider nonparametric function estimation under $L^p$-loss. The minimax rate\nfor estimation of the regression function over a H\\\"older ball with smoothness\nindex $\\beta$ is $n^{-\\beta/(2\\beta+1)}$ if $1\\leq p<\\infty$ and $(n/\\log\nn)^{-\\beta/(2\\beta+1)}$ if $p=\\infty.$ There are many known procedures that\neither attain this rate for $p=\\infty$ but are suboptimal by a $\\log n$ factor\nin the case $p<\\infty$ or the other way around. In this article, we construct\nan estimator that simultaneously achieves the optimal rates under $L^p$-risk\nfor all $1\\leq p\\leq \\infty$ without prior knowledge of $\\beta.$ In contrast to\nclassical wavelet thresholding methods that kill small empirical wavelet\ncoefficients and keep large ones, it is essential for simultaneous adaptation\nthat on each resolution level, the largest empirical wavelet coefficients are\ntruncated. This leads to a completely different point of view on wavelet\nthresholding. The crucial part in the construction of the estimator is the size\nof the truncation level which is linked to the unknown smoothness index.\nAlthough estimation of the smoothness index is known to be a difficult task,\nthere is a data-driven choice of the truncation level that is sufficiently\nprecise for our purpose.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2013 09:52:42 GMT"}, {"version": "v2", "created": "Sat, 7 Feb 2015 11:16:19 GMT"}], "update_date": "2015-02-10", "authors_parsed": [["Schmidt-Hieber", "Johannes", ""]]}, {"id": "1303.3216", "submitter": "Alain Hauser", "authors": "Alain Hauser and Peter B\\\"uhlmann", "title": "Jointly interventional and observational data: estimation of\n  interventional Markov equivalence classes of directed acyclic graphs", "comments": null, "journal-ref": null, "doi": "10.1111/rssb.12071", "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many applications we have both observational and (randomized)\ninterventional data. We propose a Gaussian likelihood framework for joint\nmodeling of such different data-types, based on global parameters consisting of\na directed acyclic graph (DAG) and correponding edge weights and error\nvariances. Thanks to the global nature of the parameters, maximum likelihood\nestimation is reasonable with only one or few data points per intervention. We\nprove consistency of the BIC criterion for estimating the interventional Markov\nequivalence class of DAGs which is smaller than the observational analogue due\nto increased partial identifiability from interventional data. Such an\nimprovement in identifiability has immediate implications for tighter bounds\nfor inferring causal effects. Besides methodology and theoretical derivations,\nwe present empirical results from real and simulated data.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2013 17:19:47 GMT"}], "update_date": "2014-06-03", "authors_parsed": [["Hauser", "Alain", ""], ["B\u00fchlmann", "Peter", ""]]}, {"id": "1303.3365", "submitter": "Paulo Serra", "authors": "Eduard Belitser and Paulo Serra", "title": "Adaptive Priors based on Splines with Random Knots", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Splines are useful building blocks when constructing priors on nonparametric\nmodels indexed by functions. Recently it has been established in the literature\nthat hierarchical priors based on splines with a random number of equally\nspaced knots and random coefficients in the B-spline basis corresponding to\nthose knots lead, under certain conditions, to adaptive posterior contraction\nrates, over certain smoothness functional classes. In this paper we extend\nthese results for when the location of the knots is also endowed with a prior.\nThis has already been a common practice in MCMC applications, where the\nresulting posterior is expected to be more \"spatially adaptive\", but a\ntheoretical basis in terms of adaptive contraction rates was missing. Under\nsome mild assumptions, we establish a result that provides sufficient\nconditions for adaptive contraction rates in a range of models.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2013 07:20:00 GMT"}], "update_date": "2013-03-15", "authors_parsed": [["Belitser", "Eduard", ""], ["Serra", "Paulo", ""]]}, {"id": "1303.3482", "submitter": "Philip Preu{\\ss}", "authors": "Kemal Sen, Philip Preuss, Holger Dette", "title": "Measuring stationarity in long-memory processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider the problem of measuring stationarity in locally\nstationary long-memory processes. We introduce an $L_2$-distance between the\nspectral density of the locally stationary process and its best approximation\nunder the assumption of stationarity. The distance is estimated by a numerical\napproximation of the integrated spectral periodogram and asymptotic normality\nof the resulting estimate is established. The results can be used to construct\na simple test for the hypothesis of stationarity in locally stationary\nlong-range dependent processes. We also propose a bootstrap procedure to\nimprove the approximation of the nominal level and prove its consistency.\nThroughout the paper, we will work with Riemann sums of a squared periodogram\ninstead of integrals (as it is usually done in the literature) and as a\nby-product of independent interest it is demonstrated that the two approaches\nbehave differently in the limit.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2013 15:45:15 GMT"}], "update_date": "2013-03-15", "authors_parsed": [["Sen", "Kemal", ""], ["Preuss", "Philip", ""], ["Dette", "Holger", ""]]}, {"id": "1303.3518", "submitter": "Salima El Kolei", "authors": "Salima El Kolei", "title": "Propagation of initial errors on the parameters for linear and Gaussian\n  state space models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For linear and Gaussian state space models parametrized by $\\theta_0 \\in\n\\Theta \\subset \\mathbb{R}^r, r \\geq 1$ corresponding to the vector of\nparameters of the model, the Kalman filter gives exactly the solution for the\noptimal filtering under weak assumptions. This result supposes that $\\theta_0$\nis perfectly known. In most real applications, this assumption is not realistic\nsince $\\theta_0$ is unknown and has to be estimated. In this paper, we analysis\nthe Kalman filter for a biased estimator of $\\theta_0$. We show the propagation\nof this bias on the estimation of the hidden state. We give an expression of\nthis propagation for linear and Gaussian state space models and we extend this\nresult for almost linear models estimated by the Extended Kalman filter. An\nillustration is given for the autoregressive process with measurement noises\nwidely studied in econometrics to model economic and financial data.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2013 17:13:44 GMT"}], "update_date": "2017-04-04", "authors_parsed": [["Kolei", "Salima El", ""]]}, {"id": "1303.3594", "submitter": "Michael Messer", "authors": "Michael Messer, Marietta Kirchner, Julia Schiemann, Jochen Roeper,\n  Ralph Neininger, Gaby Schneider", "title": "A multiple filter test for the detection of rate changes in renewal\n  processes with varying variance", "comments": "Published in at http://dx.doi.org/10.1214/14-AOAS782 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2014, Vol. 8, No. 4, 2027-2067", "doi": "10.1214/14-AOAS782", "report-no": "IMS-AOAS-AOAS782", "categories": "stat.AP math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonstationarity of the event rate is a persistent problem in modeling time\nseries of events, such as neuronal spike trains. Motivated by a variety of\npatterns in neurophysiological spike train recordings, we define a general\nclass of renewal processes. This class is used to test the null hypothesis of\nstationary rate versus a wide alternative of renewal processes with finitely\nmany rate changes (change points). Our test extends ideas from the filtered\nderivative approach by using multiple moving windows simultaneously. To adjust\nthe rejection threshold of the test, we use a Gaussian process, which emerges\nas the limit of the filtered derivative process. We also develop a multiple\nfilter algorithm, which can be used when the null hypothesis is rejected in\norder to estimate the number and location of change points. We analyze the\nbenefits of multiple filtering and its increased detection probability as\ncompared to a single window approach. Application to spike trains recorded from\ndopamine midbrain neurons in anesthetized mice illustrates the relevance of the\nproposed techniques as preprocessing steps for methods that assume rate\nstationarity. In over 70% of all analyzed spike trains classified as rate\nnonstationary, different change points were detected by different window sizes.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2013 20:31:08 GMT"}, {"version": "v2", "created": "Tue, 2 Apr 2013 18:41:59 GMT"}, {"version": "v3", "created": "Thu, 28 Nov 2013 16:21:43 GMT"}, {"version": "v4", "created": "Mon, 2 Dec 2013 12:39:41 GMT"}, {"version": "v5", "created": "Wed, 6 Aug 2014 12:45:52 GMT"}, {"version": "v6", "created": "Fri, 16 Jan 2015 11:28:46 GMT"}], "update_date": "2015-01-19", "authors_parsed": [["Messer", "Michael", ""], ["Kirchner", "Marietta", ""], ["Schiemann", "Julia", ""], ["Roeper", "Jochen", ""], ["Neininger", "Ralph", ""], ["Schneider", "Gaby", ""]]}, {"id": "1303.3716", "submitter": "Reinhard Heckel", "authors": "Reinhard Heckel and Helmut B\\\"olcskei", "title": "Subspace Clustering via Thresholding and Spectral Clustering", "comments": "ICASSP 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of clustering a set of high-dimensional data points\ninto sets of low-dimensional linear subspaces. The number of subspaces, their\ndimensions, and their orientations are unknown. We propose a simple and\nlow-complexity clustering algorithm based on thresholding the correlations\nbetween the data points followed by spectral clustering. A probabilistic\nperformance analysis shows that this algorithm succeeds even when the subspaces\nintersect, and when the dimensions of the subspaces scale (up to a log-factor)\nlinearly in the ambient dimension. Moreover, we prove that the algorithm also\nsucceeds for data points that are subject to erasures with the number of\nerasures scaling (up to a log-factor) linearly in the ambient dimension.\nFinally, we propose a simple scheme that provably detects outliers.\n", "versions": [{"version": "v1", "created": "Fri, 15 Mar 2013 09:52:54 GMT"}], "update_date": "2013-03-18", "authors_parsed": [["Heckel", "Reinhard", ""], ["B\u00f6lcskei", "Helmut", ""]]}, {"id": "1303.3738", "submitter": "Christophe Ley", "authors": "Christophe Ley and Thomas Verdebout", "title": "Local powers of optimal one- and multi-sample tests for the\n  concentration of Fisher-von Mises-Langevin distributions", "comments": "21", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One-sample and multi-sample tests on the concentration parameter of\nFisher-von Mises-Langevin (FvML) distributions have been well studied in the\nliterature. However, only very little is known about their behavior under local\nalternatives, which is due to complications inherent to the curved nature of\nthe parameter space. The aim of the present paper therefore consists in filling\nthat gap by having recourse to the Le Cam methodology, which has been adapted\nfrom the linear to the spherical setup in Ley \\emph{et al.} (2013). We obtain\nexplicit expressions of the powers for the most efficient one- and multi-sample\ntests; these tests are those considered in Watamori and Jupp (2005). As a nice\nby-product, we are also able to write down the powers (against local FvML\nalternatives) of the celebrated Rayleigh (1919) test of uniformity. A Monte\nCarlo simulation study confirms our theoretical findings and shows the\nfinite-sample behavior of the above-mentioned procedures.\n", "versions": [{"version": "v1", "created": "Fri, 15 Mar 2013 11:23:42 GMT"}], "update_date": "2013-03-18", "authors_parsed": [["Ley", "Christophe", ""], ["Verdebout", "Thomas", ""]]}, {"id": "1303.3740", "submitter": "Federico G. Poloni", "authors": "Giacomo Sbrana and Federico Poloni", "title": "A closed-form estimator for the multivariate GARCH(1,1) model", "comments": null, "journal-ref": "J. Multivariate Anal., vol. 120, 2013, pp. 152-162", "doi": "10.1016/j.jmva.2013.05.005", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a closed-form estimator based on the VARMA representation for the\nunrestricted multivariate GARCH(1,1). We show that all parameters can be\nderived using basic linear algebra tools. We show that the estimator is\nconsistent and asymptotically normal distributed. Our results allow also to\nderive a closed form for the parameters in the context of temporal aggregation\nof multivariate GARCH(1,1) by solving the equations as in Hafner [2008].\n", "versions": [{"version": "v1", "created": "Fri, 15 Mar 2013 11:24:46 GMT"}], "update_date": "2014-08-26", "authors_parsed": [["Sbrana", "Giacomo", ""], ["Poloni", "Federico", ""]]}, {"id": "1303.4035", "submitter": "Qinwen Wang", "authors": "Qinwen Wang and Jianfeng Yao", "title": "On the sphericity test with large-dimensional observations", "comments": "37 pages, 3 figures", "journal-ref": "Electronic Journal of Statistics 7:2164-2192, July 2013", "doi": "10.1214/13-EJS842", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose corrections to the likelihood ratio test and John's\ntest for sphericity in large-dimensions. New formulas for the limiting\nparameters in the CLT for linear spectral statistics of sample covariance\nmatrices with general fourth moments are first established. Using these\nformulas, we derive the asymptotic distribution of the two proposed test\nstatistics under the null. These asymptotics are valid for general population,\ni.e. not necessarily Gaussian, provided a finite fourth-moment. Extensive\nMonte-Carlo experiments are conducted to assess the quality of these tests with\na comparison to several existing methods from the literature. Moreover, we also\nobtain their asymptotic power functions under the alternative of a spiked\npopulation model as a specific alternative.\n", "versions": [{"version": "v1", "created": "Sun, 17 Mar 2013 06:06:07 GMT"}, {"version": "v2", "created": "Fri, 30 Aug 2013 06:12:14 GMT"}], "update_date": "2018-01-23", "authors_parsed": [["Wang", "Qinwen", ""], ["Yao", "Jianfeng", ""]]}, {"id": "1303.4121", "submitter": "Gery Geenens", "authors": "Gery Geenens", "title": "Probit transformation for kernel density estimation on the unit interval", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernel estimation of a probability density function supported on the unit\ninterval has proved difficult, because of the well known boundary bias issues a\nconventional kernel density estimator would necessarily face in this situation.\nTransforming the variable of interest into a variable whose density has\nunconstrained support, estimating that density, and obtaining an estimate of\nthe density of the original variable through back-transformation, seems a\nnatural idea to easily get rid of the boundary problems. In practice, however,\na simple and efficient implementation of this methodology is far from\nimmediate, and the few attempts found in the literature have been reported not\nto perform well. In this paper, the main reasons for this failure are\nidentified and an easy way to correct them is suggested. It turns out that\ncombining the transformation idea with local likelihood density estimation\nproduces viable density estimators, mostly free from boundary issues. Their\nasymptotic properties are derived, and a practical cross-validation bandwidth\nselection rule is devised. Extensive simulations demonstrate the excellent\nperformance of these estimators compared to their main competitors for a wide\nrange of density shapes. In fact, they turn out to be the best choice overall.\nFinally, they are used to successfully estimate a density of non-standard shape\nsupported on $[0,1]$ from a small-size real data sample.\n", "versions": [{"version": "v1", "created": "Sun, 17 Mar 2013 23:42:28 GMT"}], "update_date": "2013-03-19", "authors_parsed": [["Geenens", "Gery", ""]]}, {"id": "1303.4179", "submitter": "Thimo Hildebrandt", "authors": "T. Hildebrandt, N. Bissantz and H. Dette", "title": "Additive inverse regression models with convolution-type operators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a recent paper Birke and Bissantz (2008) considered the problem of\nnonparametric estimation in inverse regression models with convolution-type\noperators. For multivariate predictors nonparametric methods suffer from the\ncurse of dimensionality and we consider inverse regression models with the\nadditional qualitative assumption of additivity. In these models several\nadditive estimators are studied. In particular, we investigate estimators under\nthe random design assumption which are applicable when observations are not\navailable on a grid. Finally, we compare this estimator with the marginal\nintegration and the non-additive estimator by means of a simulation study. It\nis demonstrated that the new method yields a substantial improvement of the\ncurrently available procedures.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2013 08:18:33 GMT"}], "update_date": "2013-03-19", "authors_parsed": [["Hildebrandt", "T.", ""], ["Bissantz", "N.", ""], ["Dette", "H.", ""]]}, {"id": "1303.4288", "submitter": "Nicolas Jegou", "authors": "Arnaud Guyader, Nick Hengartner, Nicolas J\\'egou, Eric\n  Matzner-L{\\o}ber", "title": "Iterative Isotonic Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article introduces a new nonparametric method for estimating a\nunivariate regression function of bounded variation. The method exploits the\nJordan decomposition which states that a function of bounded variation can be\ndecomposed as the sum of a non-decreasing function and a non-increasing\nfunction. This suggests combining the backfitting algorithm for estimating\nadditive functions with isotonic regression for estimating monotone functions.\nThe resulting iterative algorithm is called Iterative Isotonic Regression\n(I.I.R.). The main technical result in this paper is the consistency of the\nproposed estimator when the number of iterations $k_n$ grows appropriately with\nthe sample size $n$. The proof requires two auxiliary results that are of\ninterest in and by themselves: firstly, we generalize the well-known\nconsistency property of isotonic regression to the framework of a non-monotone\nregression function, and secondly, we relate the backfitting algorithm to Von\nNeumann's algorithm in convex analysis.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2013 15:31:32 GMT"}], "update_date": "2016-08-11", "authors_parsed": [["Guyader", "Arnaud", ""], ["Hengartner", "Nick", ""], ["J\u00e9gou", "Nicolas", ""], ["Matzner-L\u00f8ber", "Eric", ""]]}, {"id": "1303.4518", "submitter": "Takuma Takeuchi", "authors": "Takuma Takeuchi, Hiroto Sekido", "title": "An Approximate Approach to E-optimal Designs for Weighted Polynomial\n  Regression by Using Tchebycheff Systems and Orthogonal Polynomials", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In statistics, experimental designs are methods for making efficient\nexperiments. E-optimal designs are the multisets of experimental conditions\nwhich minimize the maximum axis of the confidence ellipsoid of estimators. The\naim of this thesis is to propose a new algorithm for constructing E-optimal\ndesigns approximately for weighted polynomial regression with a nonnegative\nweight function.\n  First, an algorithm to calculate E-optimal designs for weighted polynomial\nregression of particular weight functions is discussed. Next a new algorithm\nfor constructing E-optimal designs approximately is proposed. Notions of the\nTchebycheff systems and orthogonal polynomials are used in the proposed\nalgorithm. Finally in this thesis, the results of numerical examples are shown\nin order to verify the accuracy of the E-optimal designs computed by the\nproposed algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2013 09:14:46 GMT"}], "update_date": "2013-03-20", "authors_parsed": [["Takeuchi", "Takuma", ""], ["Sekido", "Hiroto", ""]]}, {"id": "1303.4600", "submitter": "Jian Ren", "authors": "Jian Ren and Jinqiao Duan", "title": "A parameter estimation method based on random slow manifolds", "comments": "16 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.DS math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A parameter estimation method is devised for a slow-fast stochastic dynamical\nsystem, where often only the slow component is observable. By using the\nobservations only on the slow component, the system parameters are estimated by\nworking on the slow system on the random slow manifold. This offers a benefit\nof dimension reduction in quantifying parameters in stochastic dynamical\nsystems. An example is presented to illustrate this method, and verify that the\nparameter estimator based on the lower dimensional, reduced slow system is a\ngood approximation of the parameter estimator for original slow-fast stochastic\ndynamical system.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2013 13:57:46 GMT"}], "update_date": "2013-03-20", "authors_parsed": [["Ren", "Jian", ""], ["Duan", "Jinqiao", ""]]}, {"id": "1303.4620", "submitter": "Michael L. Stein", "authors": "Michael L. Stein", "title": "On a class of space-time intrinsic random functions", "comments": "Published in at http://dx.doi.org/10.3150/11-BEJ405 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2013, Vol. 19, No. 2, 387-408", "doi": "10.3150/11-BEJ405", "report-no": "IMS-BEJ-BEJ405", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Power law generalized covariance functions provide a simple model for\ndescribing the local behavior of an isotropic random field. This work seeks to\nextend this class of covariance functions to spatial-temporal processes for\nwhich the degree of smoothness in space and in time may differ while\nmaintaining other desirable properties for the covariance functions, including\nthe availability of explicit convergent and asymptotic series expansions.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2013 14:34:43 GMT"}], "update_date": "2013-03-20", "authors_parsed": [["Stein", "Michael L.", ""]]}, {"id": "1303.4640", "submitter": "Andreas Andresen", "authors": "Andreas Andresen, Vladimir Spokoiny", "title": "Critical dimension in profile semiparametric estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper revisits the classical inference results for profile quasi maximum\nlikelihood estimators (profile MLE) in the semiparametric estimation problem.\nWe mainly focus on two prominent theorems: the Wilks phenomenon and Fisher\nexpansion for the profile MLE are stated in a new fashion allowing finite\nsamples and model misspecification. The method of study is also essentially\ndifferent from the usual analysis of the semiparametric problem based on the\nnotion of the hardest parametric submodel. Instead we derive finite sample\ndeviation bounds for the linear approximation error for the gradient of the\nloglikelihood. This novel approach particularly allows to address the important\nissue of the effective target and nuisance dimension. The obtained\nnonasymptotic results are surprisingly sharp and yield the classical asymptotic\nstatements including the asymptotic normality and efficiency of the profile\nMLE. The general results are specified to the important special cases of an\ni.i.d. sample and the analysis is exemplified with a single index model.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2013 15:41:53 GMT"}, {"version": "v2", "created": "Mon, 16 Jun 2014 15:13:00 GMT"}, {"version": "v3", "created": "Tue, 17 Jun 2014 13:56:29 GMT"}], "update_date": "2014-06-18", "authors_parsed": [["Andresen", "Andreas", ""], ["Spokoiny", "Vladimir", ""]]}, {"id": "1303.4767", "submitter": "Xiaosun Lu", "authors": "Xiaosun Lu, J. S. Marron and Perry Haaland", "title": "Object Oriented Data Analysis of Cell-Well Structured Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Object oriented data analysis (OODA) aims at statistically analyzing\npopulations of complicated objects. This paper is motivated by a study of cell\nimages in cell culture biology, which highlights a common critical issue:\nchoice of data objects. Instead of conventionally treating either the\nindividual cells or the wells (a container in which the cells are grown) as\ndata objects, a new type of data object is proposed, that is the union of a\nwell with its corresponding set of cells. This paper contains two parts. The\nfirst part is the image data analysis, which suggests empirically that the\ncell-well unions can be a better choice of data objects than the cells or the\nwells alone. The second part discusses the benefit of choosing cell-well unions\nas data objects using an illustrative example and simulations. This research\nsuggests that OODA is not simply a frame work for understanding the structure\nof the data analysis. It leads to useful interdisciplinary discussion that\ngives better results through more appropriate choice of data objects,\nespecially for complex data analyses.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2013 20:55:31 GMT"}], "update_date": "2013-03-21", "authors_parsed": [["Lu", "Xiaosun", ""], ["Marron", "J. S.", ""], ["Haaland", "Perry", ""]]}, {"id": "1303.4857", "submitter": "Chol-Rim Min Mr", "authors": "Kyong-Hui Kim, Hak-Myong Pak", "title": "Asymptotic Normality of Estimates in Flexible Seasonal Time Series Model\n  with Weak Dependent Error Terms", "comments": "10 pages, presented in International Symposium in Commemoration of\n  the 65th Anniversary of the Foundation of Kim Il Sung University\n  (Mathematics), 20-21. Sep. Juche100(2011) Pyongyang DPR Korea", "journal-ref": "International Symposium in Commemoration of the 65th Anniversary\n  of the Foundation of Kim Il Sung University (Mathematics), 20-21. Sep.\n  Juche100(2011) Pyongyang DPR Korea, 105-110pp", "doi": null, "report-no": "KISU-MATH-2011-E-C-007", "categories": "math-ph math.MP math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we consider flexible seasonal time series models which\nconsist of a common trend function over periods and additive individual trend\n(seasonal effect) functions. The consistency and asymptotic normality of the\nlocal linear estimators were obtained under the $\\alpha$-mixing conditions and\nwithout specifying the error distribution. We develop these results to\nconsistency and asymptotic normality of local linear estimates by using central\nlimit theorems for flexible seasonal time series model, which error terms are\n$k$-weak dependent and $\\lambda$-weak dependent random variables.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2013 07:49:55 GMT"}, {"version": "v2", "created": "Mon, 10 Mar 2014 03:06:36 GMT"}], "update_date": "2014-03-11", "authors_parsed": [["Kim", "Kyong-Hui", ""], ["Pak", "Hak-Myong", ""]]}, {"id": "1303.4867", "submitter": "Song-Yon Kim Dr", "authors": "Song-Yon Kim and Mun-Chol Kim", "title": "The Identification of Thresholds and Time Delay in Self-Exciting\n  Threshold AR Model by Wavelet", "comments": "4 pages, presented in International Symposium in Commemoration of the\n  65th Anniversary of the Foundation of Kim Il Sung University (Mathematics),\n  20-21. Sep. Juche100(2011) Pyongyang DPR Korea, ver 2 corrected title and\n  some typos", "journal-ref": "International Symposium in Commemoration of the 65th Anniversary\n  of the Foundation of Kim Il Sung University (Mathematics), 20-21. Sep.\n  Juche100(2011) Pyongyang DPR Korea, 92-95pp", "doi": null, "report-no": "KISU-MATH-2011-E-C-012", "categories": "math-ph math.MP math.PR math.ST q-fin.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we studied about the wavelet identification of the thresholds\nand time delay for more general case without the constraint that the time delay\nis smaller than the order of the model. Here we composed an empirical wavelet\nfrom the SETAR (Self-Exciting Threshold Autoregressive) model and identified\nthe thresholds and time delay in the model using it.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2013 08:15:59 GMT"}, {"version": "v2", "created": "Mon, 4 Nov 2013 10:11:31 GMT"}], "update_date": "2013-11-05", "authors_parsed": [["Kim", "Song-Yon", ""], ["Kim", "Mun-Chol", ""]]}, {"id": "1303.4871", "submitter": "M. Hoffmann", "authors": "M. Hoffmann, M. Rosenbaum, N. Yoshida", "title": "Estimation of the lead-lag parameter from non-synchronous data", "comments": "Published in at http://dx.doi.org/10.3150/11-BEJ407 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2013, Vol. 19, No. 2, 426-461", "doi": "10.3150/11-BEJ407", "report-no": "IMS-BEJ-BEJ407", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a simple continuous time model for modeling the lead-lag effect\nbetween two financial assets. A two-dimensional process $(X_t,Y_t)$ reproduces\na lead-lag effect if, for some time shift $\\vartheta\\in \\mathbb{R}$, the\nprocess $(X_t,Y_{t+\\vartheta})$ is a semi-martingale with respect to a certain\nfiltration. The value of the time shift $\\vartheta$ is the lead-lag parameter.\nDepending on the underlying filtration, the standard no-arbitrage case is\nobtained for $\\vartheta=0$. We study the problem of estimating the unknown\nparameter $\\vartheta\\in \\mathbb{R}$, given randomly sampled non-synchronous\ndata from $(X_t)$ and $(Y_t)$. By applying a certain contrast optimization\nbased on a modified version of the Hayashi-Yoshida covariation estimator, we\nobtain a consistent estimator of the lead-lag parameter, together with an\nexplicit rate of convergence governed by the sparsity of the sampling design.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2013 08:36:34 GMT"}], "update_date": "2013-03-21", "authors_parsed": [["Hoffmann", "M.", ""], ["Rosenbaum", "M.", ""], ["Yoshida", "N.", ""]]}, {"id": "1303.4875", "submitter": "Uwe K\\\"{u}chler", "authors": "Uwe K\\\"uchler, Michael S{\\o}rensen", "title": "Statistical inference for discrete-time samples from affine stochastic\n  delay differential equations", "comments": "Published in at http://dx.doi.org/10.3150/11-BEJ411 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2013, Vol. 19, No. 2, 409-425", "doi": "10.3150/11-BEJ411", "report-no": "IMS-BEJ-BEJ411", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical inference for discrete time observations of an affine stochastic\ndelay differential equation is considered. The main focus is on maximum\npseudo-likelihood estimators, which are easy to calculate in practice. A more\ngeneral class of prediction-based estimating functions is investigated as well.\nIn particular, the optimal prediction-based estimating function and the\nasymptotic properties of the estimators are derived. The maximum\npseudo-likelihood estimator is a particular case, and an expression is found\nfor the efficiency loss when using the maximum pseudo-likelihood estimator,\nrather than the computationally more involved optimal prediction-based\nestimator. The distribution of the pseudo-likelihood estimator is investigated\nin a simulation study. Two examples of affine stochastic delay equation are\nconsidered in detail.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2013 08:57:41 GMT"}], "update_date": "2013-03-21", "authors_parsed": [["K\u00fcchler", "Uwe", ""], ["S\u00f8rensen", "Michael", ""]]}, {"id": "1303.4890", "submitter": "Ingrid Hob{\\ae}k Haff", "authors": "Ingrid Hob{\\ae}k Haff", "title": "Parameter estimation for pair-copula constructions", "comments": "Published in at http://dx.doi.org/10.3150/12-BEJ413 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2013, Vol. 19, No. 2, 462-491", "doi": "10.3150/12-BEJ413", "report-no": "IMS-BEJ-BEJ413", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore various estimators for the parameters of a pair-copula\nconstruction (PCC), among those the stepwise semiparametric (SSP) estimator,\ndesigned for this dependence structure. We present its asymptotic properties,\nas well as the estimation algorithm for the two most common types of PCCs.\nCompared to the considered alternatives, that is, maximum likelihood, inference\nfunctions for margins and semiparametric estimation, SSP is in general\nasymptotically less efficient. As we show in a few examples, this loss of\nefficiency may however be rather low. Furthermore, SSP is semiparametrically\nefficient for the Gaussian copula. More importantly, it is computationally\ntractable even in high dimensions, as opposed to its competitors. In any case,\nSSP may provide start values, required by the other estimators. It is also well\nsuited for selecting the pair-copulae of a PCC for a given data set.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2013 09:53:56 GMT"}], "update_date": "2013-03-21", "authors_parsed": [["Haff", "Ingrid Hob\u00e6k", ""]]}, {"id": "1303.4911", "submitter": "Liang Peng", "authors": "Liang Peng, Linyi Qian, Jingping Yang", "title": "Weighted estimation of the dependence function for an extreme-value\n  distribution", "comments": "Published in at http://dx.doi.org/10.3150/11-BEJ409 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2013, Vol. 19, No. 2, 492-520", "doi": "10.3150/11-BEJ409", "report-no": "IMS-BEJ-BEJ409", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bivariate extreme-value distributions have been used in modeling extremes in\nenvironmental sciences and risk management. An important issue is estimating\nthe dependence function, such as the Pickands dependence function. Some\nestimators for the Pickands dependence function have been studied by assuming\nthat the marginals are known. Recently, Genest and Segers [Ann. Statist. 37\n(2009) 2990-3022] derived the asymptotic distributions of those proposed\nestimators with marginal distributions replaced by the empirical distributions.\nIn this article, we propose a class of weighted estimators including those of\nGenest and Segers (2009) as special cases. We propose a jackknife empirical\nlikelihood method for constructing confidence intervals for the Pickands\ndependence function, which avoids estimating the complicated asymptotic\nvariance. A simulation study demonstrates the effectiveness of our proposed\njackknife empirical likelihood method.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2013 11:37:51 GMT"}], "update_date": "2013-03-21", "authors_parsed": [["Peng", "Liang", ""], ["Qian", "Linyi", ""], ["Yang", "Jingping", ""]]}, {"id": "1303.4917", "submitter": "Herold Dehling", "authors": "Herold Dehling, Aeneas Rooch, Murad S. Taqqu", "title": "Power of Change-Point Tests for Long-Range Dependent Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the power of the CUSUM test and the Wilcoxon change-point test\nfor a shift in the mean of a process with long-range dependent noise. We derive\nanalytiv formulas for the power of these tests under local alternatives. These\nresults enable us to calculate the asymptotic relative efficiency (ARE) of the\nCUSUM test and the Wilcoxon change point test. We obtain the surprising result\nthat for Gaussian data, the ARE of these two tests equals 1, in contrast to the\ncase of i.i.d. noise when the ARE is known to be $3/\\pi$.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2013 12:20:51 GMT"}], "update_date": "2013-03-21", "authors_parsed": [["Dehling", "Herold", ""], ["Rooch", "Aeneas", ""], ["Taqqu", "Murad S.", ""]]}, {"id": "1303.4956", "submitter": "Tomasz Piotrowski", "authors": "Tomasz Piotrowski and Isao Yamada", "title": "Performance of the stochastic MV-PURE estimator in highly noisy settings", "comments": "submitted to Journal of the Franklin Institute", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The stochastic MV-PURE estimator has been developed to provide linear\nestimation robust to ill-conditioning, high noise levels, and imperfections in\nmodel knowledge. In this paper, we investigate the theoretical performance of\nthe stochastic MV-PURE estimator under varying level of additive noise. More\nprecisely, we prove that the mean-square-error (MSE) of this estimator in the\nlow signal-to-noise (SNR) region is much smaller than that obtained with its\nfull-rank version, the minimum-variance distortionless estimator, and that the\ngap in performance is the larger the higher the noise level. These results shed\nlight on the excellent performance of the stochastic MV-PURE estimator in\nhighly noisy settings obtained in simulations so far. We extend here previously\nconducted numerical simulations to demonstrate a new insight provided by\nresults of this paper in practical applications.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2013 14:51:54 GMT"}], "update_date": "2013-03-21", "authors_parsed": [["Piotrowski", "Tomasz", ""], ["Yamada", "Isao", ""]]}, {"id": "1303.5046", "submitter": "Luc Pronzato", "authors": "Luc Pronzato (- M\\'ethodes d'Analyse Stochastique des Codes et\n  Traitements Num\\'eriques)", "title": "A delimitation of the support of optimal designs for Kiefer's\n  $\\phi_p$-class of criteria", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper extends the result of Harman and Pronzato [Stat. & Prob. Lett.,\n77:90--94, 2007], which corresponds to $p=0$, to all strictly concave criteria\nin Kiefer's $\\phi_p$-class. Let $\\xi$ be any design on a compact set\n$X\\subset\\mathbb{R}^m$ with a nonsingular information matrix $\\Mb(\\xi)$, and\nlet $\\delta$ be the maximum of the directional derivative $F_{\\phi_p}(\\xi,x)$\nover all $x\\in X$. We show that any support point $x_*$ of a $\\phi_p$-optimal\ndesign satisfies the inequality $F_{\\phi_p}(\\xi,x_*) \\geq\nh_p[\\Mb(\\xi),\\delta]$, where the bound $h_p[\\Mb(\\xi),\\delta]$ is easily\ncomputed: it requires the determination of the unique root of a simple\nunivariate equation (polynomial when $p$ is integer) in a given interval. The\nconstruction can be used to accelerate algorithms for $\\phi_p$-optimal design\nand is illustrated on an example with $A$-optimal design.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2013 19:43:28 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2013 09:27:14 GMT"}], "update_date": "2013-09-11", "authors_parsed": [["Pronzato", "Luc", "", "- M\u00e9thodes d'Analyse Stochastique des Codes et\n  Traitements Num\u00e9riques"]]}, {"id": "1303.5142", "submitter": "Jos\\'e A. D\\'iaz-Garc\\'ia", "authors": "Jose A. Diaz-Garcia", "title": "Moments of the Riesz distribution", "comments": "P. 2-3, properties 1, 2, and 5 have been corrected. P. 5, Proposition\n  2.1 has been modified. P. 6, equation (18), $q_{\\kappa}(\\mathbf{\\Sigma})$ has\n  been replaced by $q_{\\kappa}^{-1}(\\mathbf{\\Sigma}^{-1})$; and\n  $\\mathbf{\\Sigma}^{1/2}$ by $\\left(\\mathbf{\\Sigma}^{1/2}\\right)^{*}$ in\n  several places", "journal-ref": "Journal of Statistical Planning and Inference, 143, 1880-1886", "doi": "10.1016/j.jspi.2013.07.012", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article derives the first two moments of the two versions of the Riesz\ndistribution in the terms of their characteristic functions.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2013 01:56:57 GMT"}, {"version": "v2", "created": "Sat, 30 May 2015 20:49:43 GMT"}], "update_date": "2015-06-02", "authors_parsed": [["Diaz-Garcia", "Jose A.", ""]]}, {"id": "1303.5153", "submitter": "David Callan", "authors": "Grace Wahba", "title": "Statistical Model Building, Machine Learning, and the Ah-Ha Moment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Committee of Presidents of Statistical Societies (COPSS) will celebrate\nits 50th Anniversary in 2013. As part of its celebration, COPSS intends to\npublish a book with contributions from the past recipients of its four awards,\nnamely the Fisher Lecture Award, the President's Award, the Elizabeth Scott\nAward, and the FN David Award. The theme of the book is Past, Present and\nFuture of Statistical Science. As a winner of the Elizabeth Scott Award, I have\nbeen invited to contribute. We were given several topics to choose from and I\nhave chosen to focus on \"Statistical Career: Your reflection on your own\ncareer, lessons and experience you have learned, and advice you would like to\nprovide to young statisticians if sought.\" This article is my contribution.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2013 03:33:10 GMT"}], "update_date": "2013-03-26", "authors_parsed": [["Wahba", "Grace", ""]]}, {"id": "1303.5172", "submitter": "Rahul Mukerjee", "authors": "Mausumi Bose", "title": "Respondent privacy and estimation efficiency in randomized response\n  surveys for discrete-valued sensitive variables", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In some socio-economic surveys, data are collected on sensitive or\nstigmatizing issues such as tax evasion, criminal conviction, drug use, etc. In\nsuch surveys, direct questioning of respondents is not of much use and the\nrandomized response technique is used instead. A few researchers have studied\nthe issue of privacy protection or respondent jeopardy for surveys on\ndichotomous populations, where the objective is to estimate the proportion of\npersons bearing the sensitive trait. However, not much is yet known about\nrespondent protection when the variable under study takes discrete numerical\nvalues and the objective of the survey is to estimate the population mean of\nthis variable. In this article we study this issue. We first propose a\nrandomization device for this situation and give the corresponding estimation\nprocedure. We next propose a measure of privacy and show that given a certain\nstipulated level of this privacy measure, we can determine the parameter of the\nrandomization device so as to maximize the efficiency of estimation, while\nguaranteeing the desired level of privacy protection. In particular, our study\nalso covers the case of polychotomous populations and we can estimate the\nproportions of individuals belonging to the different classes. Consequently,\nresults for dichotomous populations follow as corollaries.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2013 05:52:23 GMT"}], "update_date": "2013-03-22", "authors_parsed": [["Bose", "Mausumi", ""]]}, {"id": "1303.5180", "submitter": "Guillaume Lecu\\'{e}", "authors": "Guillaume Lecu\\'e, Shahar Mendelson", "title": "On the optimality of the aggregate with exponential weights for low\n  temperatures", "comments": "Published in at http://dx.doi.org/10.3150/11-BEJ408 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2013, Vol. 19, No. 2, 646-675", "doi": "10.3150/11-BEJ408", "report-no": "IMS-BEJ-BEJ408", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a finite class of functions F, the problem of aggregation is to\nconstruct a procedure with a risk as close as possible to the risk of the best\nelement in the class. A classical procedure (PAC-Bayesian statistical learning\ntheory (2004) Paris 6, Statistical Learning Theory and Stochastic Optimization\n(2001) Springer, Ann. Statist. 28 (2000) 75-87) is the aggregate with\nexponential weights (AEW), defined by \\[\\tilde{f}^{\\mathrm{AEW}}=\\sum_{f\\in\nF}\\hat{\\theta}(f)f,\\qquad where\n\\hat{\\theta}(f)=\\frac{\\exp(-({n}/{T})R_n(f))}{\\sum_{g\\in\nF}\\exp(-({n}/{T})R_n(g))},\\] where $T>0$ is called the temperature parameter\nand $R_n(\\cdot)$ is an empirical risk. In this article, we study the optimality\nof the AEW in the regression model with random design and in the\nlow-temperature regime. We prove three properties of AEW. First, we show that\nAEW is a suboptimal aggregation procedure in expectation with respect to the\nquadratic risk when $T\\leq c_1$, where $c_1$ is an absolute positive constant\n(the low-temperature regime), and that it is suboptimal in probability even for\nhigh temperatures. Second, we show that as the cardinality of the dictionary\ngrows, the behavior of AEW might deteriorate, namely, that in the\nlow-temperature regime it might concentrate with high probability around\nelements in the dictionary with risk greater than the risk of the best function\nin the dictionary by at least an order of $1/\\sqrt{n}$. Third, we prove that if\na geometric condition on the dictionary (the so-called \"Bernstein condition) is\nassumed, then AEW is indeed optimal both in high probability and in expectation\nin the low-temperature regime. Moreover, under that assumption, the complexity\nterm is essentially the logarithm of the cardinality of the set of \"almost\nminimizers\" rather than the logarithm of the cardinality of the entire\ndictionary. This result holds for small values of the temperature parameter,\nthus complementing an analogous result for high temperatures.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2013 07:20:20 GMT"}], "update_date": "2013-03-22", "authors_parsed": [["Lecu\u00e9", "Guillaume", ""], ["Mendelson", "Shahar", ""]]}, {"id": "1303.5441", "submitter": "Vincent Labatut", "authors": "Vincent Labatut (LIA)", "title": "Generalized Measures for the Evaluation of Community Detection Methods", "comments": "The R source code (based on the igraph library) for the measures\n  described in this article is freely available on\n  GitHub:https://github.com/CompNet/TopoMeasures", "journal-ref": "International Journal of Social Network Analysis and Mining\n  (SNAM), 2015, 2 (1), pp.44-63", "doi": "10.1504/IJSNM.2015.069776", "report-no": null, "categories": "cs.SI math.ST physics.soc-ph stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Community detection can be considered as a variant of cluster analysis\napplied to complex networks. For this reason, all existing studies have been\nusing tools derived from this field when evaluating community detection\nalgorithms. However, those are not completely relevant in the context of\nnetwork analysis, because they ignore an essential part of the available\ninformation: the network structure. Therefore, they can lead to incorrect\ninterpretations. In this article, we review these measures, and illustrate this\nlimitation. We propose a modification to solve this problem, and apply it to\nthe three most widespread measures: purity, Rand index and normalized mutual\ninformation (NMI). We then perform an experimental evaluation on artificially\ngenerated networks with realistic community structure. We assess the relevance\nof the modified measures by comparison with their traditional counterparts, and\nalso relatively to the topological properties of the community structures. On\nthese data, the modified NMI turns out to provide the most relevant results.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2013 07:06:37 GMT"}, {"version": "v2", "created": "Fri, 13 May 2016 15:12:33 GMT"}, {"version": "v3", "created": "Tue, 17 May 2016 09:43:33 GMT"}], "update_date": "2016-05-18", "authors_parsed": [["Labatut", "Vincent", "", "LIA"]]}, {"id": "1303.5613", "submitter": "Steven Smith", "authors": "Steven T. Smith, Kenneth D. Senne, Scott Philips, Edward K. Kao, and\n  Garrett Bernstein", "title": "Network Detection Theory and Performance", "comments": "Submitted to IEEE Trans. Signal Processing", "journal-ref": "IEEE Trans. Signal Process., vol. 62, no. 20, pp. 5324-5338,\n  October 2014", "doi": "10.1109/TSP.2014.2336613", "report-no": null, "categories": "cs.SI cs.LG math.ST physics.soc-ph stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network detection is an important capability in many areas of applied\nresearch in which data can be represented as a graph of entities and\nrelationships. Oftentimes the object of interest is a relatively small subgraph\nin an enormous, potentially uninteresting background. This aspect characterizes\nnetwork detection as a \"big data\" problem. Graph partitioning and network\ndiscovery have been major research areas over the last ten years, driven by\ninterest in internet search, cyber security, social networks, and criminal or\nterrorist activities. The specific problem of network discovery is addressed as\na special case of graph partitioning in which membership in a small subgraph of\ninterest must be determined. Algebraic graph theory is used as the basis to\nanalyze and compare different network detection methods. A new Bayesian network\ndetection framework is introduced that partitions the graph based on prior\ninformation and direct observations. The new approach, called space-time threat\npropagation, is proved to maximize the probability of detection and is\ntherefore optimum in the Neyman-Pearson sense. This optimality criterion is\ncompared to spectral community detection approaches which divide the global\ngraph into subsets or communities with optimal connectivity properties. We also\nexplore a new generative stochastic model for covert networks and analyze using\nreceiver operating characteristics the detection performance of both classes of\noptimal detection techniques.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2013 13:34:28 GMT"}], "update_date": "2018-04-12", "authors_parsed": [["Smith", "Steven T.", ""], ["Senne", "Kenneth D.", ""], ["Philips", "Scott", ""], ["Kao", "Edward K.", ""], ["Bernstein", "Garrett", ""]]}, {"id": "1303.5647", "submitter": "Cristina Butucea", "authors": "Cristina Butucea, Yuri I. Ingster and Irina Suslina", "title": "Sharp Variable Selection of a Sparse Submatrix in a High-Dimensional\n  Noisy Matrix", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We observe a $N\\times M$ matrix of independent, identically distributed\nGaussian random variables which are centered except for elements of some\nsubmatrix of size $n\\times m$ where the mean is larger than some $a>0$. The\nsubmatrix is sparse in the sense that $n/N$ and $m/M$ tend to 0, whereas $n,\\,\nm, \\, N$ and $M$ tend to infinity.\n  We consider the problem of selecting the random variables with significantly\nlarge mean values. We give sufficient conditions on $a$ as a function of $n,\\,\nm,\\,N$ and $M$ and construct a uniformly consistent procedure in order to do\nsharp variable selection. We also prove the minimax lower bounds under\nnecessary conditions which are complementary to the previous conditions. The\ncritical values $a^*$ separating the necessary and sufficient conditions are\nsharp (we show exact constants).\n  We note a gap between the critical values $a^*$ for selection of variables\nand that of detecting that such a submatrix exists given by Butucea and Ingster\n(2012). When $a^*$ is in this gap, consistent detection is possible but no\nconsistent selector of the corresponding variables can be found.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2013 15:36:21 GMT"}], "update_date": "2013-03-25", "authors_parsed": [["Butucea", "Cristina", ""], ["Ingster", "Yuri I.", ""], ["Suslina", "Irina", ""]]}, {"id": "1303.5809", "submitter": "Zhiyuan Zhang", "authors": "Yingying Li, Zhiyuan Zhang and Xinghua Zheng", "title": "Volatility Inference in the Presence of Both Endogenous Time and\n  Microstructure Noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we consider the volatility inference in the presence of both\nmarket microstructure noise and endogenous time. Estimators of the integrated\nvolatility in such a setting are proposed, and their asymptotic properties are\nstudied. Our proposed estimator is compared with the existing popular\nvolatility estimators via numerical studies. The results show that our\nestimator can have substantially better performance when time endogeneity\nexists.\n", "versions": [{"version": "v1", "created": "Sat, 23 Mar 2013 01:49:15 GMT"}], "update_date": "2013-03-26", "authors_parsed": [["Li", "Yingying", ""], ["Zhang", "Zhiyuan", ""], ["Zheng", "Xinghua", ""]]}, {"id": "1303.5817", "submitter": "Sourav Chatterjee", "authors": "Sourav Chatterjee", "title": "Assumptionless consistency of the Lasso", "comments": "10 pages. Typos corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Lasso is a popular statistical tool invented by Robert Tibshirani for\nlinear regression when the number of covariates is greater than or comparable\nto the number of observations. The purpose of this note is to highlight the\nsimple fact (noted in a number of earlier papers in various guises) that for\nthe loss function considered in Tibshirani's original paper, the Lasso is\nconsistent under almost no assumptions at all.\n", "versions": [{"version": "v1", "created": "Sat, 23 Mar 2013 04:28:38 GMT"}, {"version": "v2", "created": "Thu, 4 Apr 2013 02:21:43 GMT"}, {"version": "v3", "created": "Thu, 18 Apr 2013 23:41:07 GMT"}, {"version": "v4", "created": "Fri, 7 Feb 2014 00:03:35 GMT"}, {"version": "v5", "created": "Thu, 26 Jun 2014 02:05:08 GMT"}], "update_date": "2014-06-27", "authors_parsed": [["Chatterjee", "Sourav", ""]]}, {"id": "1303.6042", "submitter": "Alexandre Janon", "authors": "Alexandre Janon (INRIA Grenoble Rh\\^one-Alpes / LJK Laboratoire Jean\n  Kuntzmann, - M\\'ethodes d'Analyse Stochastique des Codes et Traitements\n  Num\\'eriques, SAF)", "title": "Multifidelity variance reduction for pick-freeze Sobol index estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many mathematical models involve input parameters, which are not precisely\nknown. Global sensitivity analysis aims to identify the parameters whose\nuncertainty has the largest impact on the variability of a quantity of interest\n(output of the model). One of the statistical tools used to quantify the\ninfluence of each input variable on the output is the Sobol sensitivity index,\nwhich can be estimated using a large sample of evaluations of the output. We\npropose a variance reduction technique, based on the availability of a fast\napproximation of the output, which can enable significant computational savings\nwhen the output is costly to evaluate.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2013 07:50:13 GMT"}], "update_date": "2013-03-26", "authors_parsed": [["Janon", "Alexandre", "", "INRIA Grenoble Rh\u00f4ne-Alpes / LJK Laboratoire Jean\n  Kuntzmann, - M\u00e9thodes d'Analyse Stochastique des Codes et Traitements\n  Num\u00e9riques, SAF"]]}, {"id": "1303.6146", "submitter": "Markus Bibinger", "authors": "Markus Bibinger, Nikolaus Hautsch, Peter Malec, Markus Rei{\\ss}", "title": "Estimating the quadratic covariation matrix from noisy observations:\n  Local method of moments and efficiency", "comments": "Published in at http://dx.doi.org/10.1214/14-AOS1224 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2014, Vol. 42, No. 4, 1312-1346", "doi": "10.1214/14-AOS1224", "report-no": "IMS-AOS-AOS1224", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An efficient estimator is constructed for the quadratic covariation or\nintegrated co-volatility matrix of a multivariate continuous martingale based\non noisy and nonsynchronous observations under high-frequency asymptotics. Our\napproach relies on an asymptotically equivalent continuous-time observation\nmodel where a local generalised method of moments in the spectral domain turns\nout to be optimal. Asymptotic semi-parametric efficiency is established in the\nCram\\'{e}r-Rao sense. Main findings are that nonsynchronicity of observation\ntimes has no impact on the asymptotics and that major efficiency gains are\npossible under correlation. Simulations illustrate the finite-sample behaviour.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2013 14:51:26 GMT"}, {"version": "v2", "created": "Mon, 27 Jan 2014 13:53:25 GMT"}, {"version": "v3", "created": "Tue, 1 Jul 2014 11:34:38 GMT"}], "update_date": "2014-07-02", "authors_parsed": [["Bibinger", "Markus", ""], ["Hautsch", "Nikolaus", ""], ["Malec", "Peter", ""], ["Rei\u00df", "Markus", ""]]}, {"id": "1303.6149", "submitter": "Francis Bach", "authors": "Francis Bach (INRIA Paris - Rocquencourt, LIENS)", "title": "Adaptivity of averaged stochastic gradient descent to local strong\n  convexity for logistic regression", "comments": null, "journal-ref": "Journal of Machine Learning Research 15 (2014) 595-627", "doi": null, "report-no": null, "categories": "math.ST cs.LG math.OC stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider supervised learning problems such as logistic\nregression and study the stochastic gradient method with averaging, in the\nusual stochastic approximation setting where observations are used only once.\nWe show that after $N$ iterations, with a constant step-size proportional to\n$1/R^2 \\sqrt{N}$ where $N$ is the number of observations and $R$ is the maximum\nnorm of the observations, the convergence rate is always of order\n$O(1/\\sqrt{N})$, and improves to $O(R^2 / \\mu N)$ where $\\mu$ is the lowest\neigenvalue of the Hessian at the global optimum (when this eigenvalue is\ngreater than $R^2/\\sqrt{N}$). Since $\\mu$ does not need to be known in advance,\nthis shows that averaged stochastic gradient is adaptive to \\emph{unknown\nlocal} strong convexity of the objective function. Our proof relies on the\ngeneralized self-concordance properties of the logistic loss and thus extends\nto all generalized linear models with uniformly bounded features.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2013 14:53:33 GMT"}, {"version": "v2", "created": "Sat, 26 Oct 2013 18:14:11 GMT"}, {"version": "v3", "created": "Sun, 16 Mar 2014 06:25:08 GMT"}], "update_date": "2014-03-18", "authors_parsed": [["Bach", "Francis", "", "INRIA Paris - Rocquencourt, LIENS"]]}, {"id": "1303.6171", "submitter": "Dan  Shen", "authors": "Dan Shen, Haipeng Shen, Hongtu Zhu and J. S. Marron", "title": "Surprising Asymptotic Conical Structure in Critical Sample\n  Eigen-Directions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this paper is to establish several deep theoretical properties of\nprincipal component analysis for multiple-component spike covariance models.\nOur new results reveal a surprising asymptotic conical structure in critical\nsample eigendirections under the spike models with distinguishable (or\nindistinguishable) eigenvalues, when the sample size and/or the number of\nvariables (or dimension) tend to infinity. The consistency of the sample\neigenvectors relative to their population counterparts is determined by the\nratio between the dimension and the product of the sample size with the spike\nsize. When this ratio converges to a nonzero constant, the sample eigenvector\nconverges to a cone, with a certain angle to its corresponding population\neigenvector.In the High Dimension, Low Sample Size case, the angle between the\nsample eigenvector and its population counterpart converges to a limiting\ndistribution.Several generalizations of the multi-spike covariance models are\nalso explored, and additional theoretical results are presented.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2013 15:37:20 GMT"}], "update_date": "2013-03-26", "authors_parsed": [["Shen", "Dan", ""], ["Shen", "Haipeng", ""], ["Zhu", "Hongtu", ""], ["Marron", "J. S.", ""]]}, {"id": "1303.6349", "submitter": "Yuwei Zhao", "authors": "Richard A. Davis and Thomas Mikosch and Yuwei Zhao", "title": "Measures of serial extremal dependence and their estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  The goal of this paper is two-fold: 1. We review classical and recent\nmeasures of serial extremal dependence in a strictly stationary time series as\nwell as their estimation. 2. We discuss recent concepts of heavy-tailed time\nseries, including regular variation and max-stable processes. Serial extremal\ndependence is typically characterized by clusters of exceedances of high\nthresholds in the series. We start by discussing the notion of extremal index\nof a univariate sequence, i.e. the reciprocal of the expected cluster size,\nwhich has attracted major attention in the extremal value literature. Then we\ncontinue by introducing the extremogram which is an asymptotic auto-correlation\nfunction for sequences of extremal events in a time series. In this context, we\ndiscuss regular variation of a time series. This notion has been useful for\ndescribing serial extremal dependence and heavy tails in a strictly stationary\nsequence. We briefly discuss the tail process coined by Basrak and Segers to\ndescribe the dependence structure of regularly varying sequences in a\nprobabilistic way. Max-stable processes with Frechet marginals are an important\nclass of reg- ularly varying sequences. Recently, this class has attracted\nattention for modeling and statistical purposes. We apply the extremogram to\nmax-stable processes. Finally, we discuss estimation of the extremogram both in\nthe time and frequency domains.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2013 23:31:45 GMT"}], "update_date": "2013-03-27", "authors_parsed": [["Davis", "Richard A.", ""], ["Mikosch", "Thomas", ""], ["Zhao", "Yuwei", ""]]}, {"id": "1303.6379", "submitter": "Jian Song", "authors": "Chihoon Lee, Jian Song", "title": "On drift parameter estimation for reflected fractional\n  Ornstein-Uhlenbeck processes", "comments": "27 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a reflected Ornstein-Uhlenbeck process $X$ driven by a fractional\nBrownian motion with Hurst parameter $H\\in (0, \\frac12) \\cup (\\frac12, 1)$. Our\ngoal is to estimate an unknown drift parameter $\\alpha\\in (-\\infty,\\infty)$ on\nthe basis of continuous observation of the state process. We establish Girsanov\ntheorem for the process $X$, derive the standard maximum likelihood estimator\nof the drift parameter $\\alpha$, and prove its strong consistency and\nasymptotic normality. As an improved estimator, we obtain the explicit formulas\nfor the sequential maximum likelihood estimator and its mean squared error by\nassuming the process is observed until a certain information reaches a\nspecified precision level. The estimator is shown to be unbiased, uniformly\nnormally distributed, and efficient in the mean square error sense.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2013 03:53:34 GMT"}, {"version": "v2", "created": "Thu, 28 Mar 2013 05:21:49 GMT"}, {"version": "v3", "created": "Mon, 23 Mar 2015 04:16:39 GMT"}], "update_date": "2015-03-24", "authors_parsed": [["Lee", "Chihoon", ""], ["Song", "Jian", ""]]}, {"id": "1303.6447", "submitter": "Alexandre Janon", "authors": "Fabrice Gamboa (UMR CNRS 5219), Alexandre Janon (INRIA Grenoble\n  Rh\\^one-Alpes / LJK Laboratoire Jean Kuntzmann, - M\\'ethodes d'Analyse\n  Stochastique des Codes et Traitements Num\\'eriques, SAF), Thierry Klein\n  (IMT), Agnes Lagnoux-Renaudie (IMT), Cl\\'ementine Prieur (INRIA Grenoble\n  Rh\\^one-Alpes / LJK Laboratoire Jean Kuntzmann, - M\\'ethodes d'Analyse\n  Stochastique des Codes et Traitements Num\\'eriques), Cl\\'ementine Prieur\n  (INRIA Grenoble Rh\\^one-Alpes / LJK Laboratoire Jean Kuntzmann, - M\\'ethodes\n  d'Analyse Stochastique des Codes et Traitements Num\\'eriques)", "title": "Statistical inference for Sobol pick freeze Monte Carlo method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many mathematical models involve input parameters, which are not precisely\nknown. Global sensitivity analysis aims to identify the parameters whose\nuncertainty has the largest impact on the variability of a quantity of interest\n(output of the model). One of the statistical tools used to quantify the\ninfluence of each input variable on the output is the Sobol sensitivity index.\nWe consider the statistical estimation of this index from a finite sample of\nmodel outputs. We study asymptotic and non-asymptotic properties of two\nestimators of Sobol indices. These properties are applied to significance tests\nand estimation by confidence intervals.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2013 12:03:48 GMT"}], "update_date": "2013-03-27", "authors_parsed": [["Gamboa", "Fabrice", "", "UMR CNRS 5219"], ["Janon", "Alexandre", "", "INRIA Grenoble\n  Rh\u00f4ne-Alpes / LJK Laboratoire Jean Kuntzmann, - M\u00e9thodes d'Analyse\n  Stochastique des Codes et Traitements Num\u00e9riques, SAF"], ["Klein", "Thierry", "", "IMT"], ["Lagnoux-Renaudie", "Agnes", "", "IMT"], ["Prieur", "Cl\u00e9mentine", "", "INRIA Grenoble\n  Rh\u00f4ne-Alpes / LJK Laboratoire Jean Kuntzmann, - M\u00e9thodes d'Analyse\n  Stochastique des Codes et Traitements Num\u00e9riques"], ["Prieur", "Cl\u00e9mentine", "", "INRIA Grenoble\n  Rh\u00f4ne-Alpes / LJK Laboratoire Jean Kuntzmann, - M\u00e9thodes d'Analyse\n  Stochastique des Codes et Traitements Num\u00e9riques"]]}, {"id": "1303.6451", "submitter": "Alexandre Janon", "authors": "Alexandre Janon (INRIA Grenoble Rh\\^one-Alpes / LJK Laboratoire Jean\n  Kuntzmann, - M\\'ethodes d'Analyse Stochastique des Codes et Traitements\n  Num\\'eriques), Thierry Klein (IMT), Agnes Lagnoux-Renaudie (IMT), Ma\\\"elle\n  Nodet (INRIA Grenoble Rh\\^one-Alpes / LJK Laboratoire Jean Kuntzmann),\n  Cl\\'ementine Prieur (INRIA Grenoble Rh\\^one-Alpes / LJK Laboratoire Jean\n  Kuntzmann, - M\\'ethodes d'Analyse Stochastique des Codes et Traitements\n  Num\\'eriques)", "title": "Asymptotic normality and efficiency of two Sobol index estimators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many mathematical models involve input parameters, which are not precisely\nknown. Global sensitivity analysis aims to identify the parameters whose\nuncertainty has the largest impact on the variability of a quantity of interest\n(output of the model). One of the statistical tools used to quantify the\ninfluence of each input variable on the output is the Sobol sensitivity index.\nWe consider the statistical estimation of this index from a finite sample of\nmodel outputs: we present two estimators and state a central limit theorem for\neach. We show that one of these estimators has an optimal asymptotic variance.\nWe also generalize our results to the case where the true output is not\nobservable, and is replaced by a noisy version.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2013 12:20:03 GMT"}], "update_date": "2013-03-27", "authors_parsed": [["Janon", "Alexandre", "", "INRIA Grenoble Rh\u00f4ne-Alpes / LJK Laboratoire Jean\n  Kuntzmann, - M\u00e9thodes d'Analyse Stochastique des Codes et Traitements\n  Num\u00e9riques"], ["Klein", "Thierry", "", "IMT"], ["Lagnoux-Renaudie", "Agnes", "", "IMT"], ["Nodet", "Ma\u00eblle", "", "INRIA Grenoble Rh\u00f4ne-Alpes / LJK Laboratoire Jean Kuntzmann"], ["Prieur", "Cl\u00e9mentine", "", "INRIA Grenoble Rh\u00f4ne-Alpes / LJK Laboratoire Jean\n  Kuntzmann, - M\u00e9thodes d'Analyse Stochastique des Codes et Traitements\n  Num\u00e9riques"]]}, {"id": "1303.6466", "submitter": "Jean-Bernard Salomond", "authors": "Jean-Bernard Salomond", "title": "Testing Un-Separated Hypotheses by Estimating a Distance", "comments": null, "journal-ref": null, "doi": "10.1214/17-BA1059", "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a Bayesian answer to testing problems when the\nhypotheses are not well separated. The idea of the method is to study the\nposterior distribution of a discrepancy measure between the parameter and the\nmodel we want to test for. This is shown to be equivalent to a modification of\nthe testing loss. An advantage of this approach is that it can easily be\nadapted to complex hypotheses testing which are in general difficult to test\nfor. Asymptotic properties of the test can be derived from the asymptotic\nbehaviour of the posterior distribution of the discrepancy measure, and gives\ninsight on possible calibrations. In addition one can derive separation rates\nfor testing, which ensure the asymptotic frequentist optimality of our\nprocedures.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2013 12:57:54 GMT"}, {"version": "v2", "created": "Tue, 13 May 2014 08:47:47 GMT"}, {"version": "v3", "created": "Thu, 19 Feb 2015 14:51:47 GMT"}, {"version": "v4", "created": "Tue, 27 Jun 2017 09:56:37 GMT"}], "update_date": "2017-06-28", "authors_parsed": [["Salomond", "Jean-Bernard", ""]]}, {"id": "1303.6690", "submitter": "Federico Polito", "authors": "Dexter O. Cahoy, Federico Polito", "title": "Parameter estimation for fractional birth and fractional death processes", "comments": null, "journal-ref": "Statistics and Computing, Vol. 24 (2), 211-222, 2014", "doi": "10.1007/s11222-012-9365-1", "report-no": null, "categories": "math.ST math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fractional birth and the fractional death processes are more desirable in\npractice than their classical counterparts as they naturally provide greater\nflexibility in modeling growing and decreasing systems. In this paper, we\npropose formal parameter estimation procedures for the fractional Yule, the\nfractional linear death, and the fractional sublinear death processes. The\nmethods use all available data possible, are computationally simple and\nasymptotically unbiased. The procedures exploited the natural structure of the\nrandom inter-birth and inter-death times that are known to be independent but\nare not identically distributed. We also showed how these methods can be\napplied to certain models with more general birth and death rates. The\ncomputational tests showed favorable results for our proposed methods even with\nrelatively small sample sizes. The proposed methods are also illustrated using\nthe branching times of the plethodontid salamanders data of \\cite{hal79}.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2013 22:45:47 GMT"}], "update_date": "2014-06-30", "authors_parsed": [["Cahoy", "Dexter O.", ""], ["Polito", "Federico", ""]]}, {"id": "1303.6744", "submitter": "Paul Kabaila", "authors": "Paul Kabaila and Dilshani Tissera", "title": "On confidence intervals in regression that utilize uncertain prior\n  information about a vector parameter", "comments": "Some typographical errors have been corrected", "journal-ref": "On confidence intervals that utilize uncertain prior information\n  about a vector parameter. Australian & New Zealand Journal of Statistics, 56,\n  371-383 (2014)", "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a linear regression model with n-dimensional response vector,\np-dimensional regression parameter beta and independent normally distributed\nerrors. Suppose that the parameter of interest is theta = a^T beta where a is a\nspecified vector. Define the s-dimensional parameter vector tau=C^T beta-t\nwhere C and t are specified. Also suppose that we have uncertain prior\ninformation that tau=0. Part of our evaluation of a frequentist confidence\ninterval for theta is the ratio (expected length of this confidence\ninterval)/(expected length of standard 1-alpha confidence interval), the scaled\nexpected length of this interval. We say that a 1-alpha confidence interval for\ntheta utilizes this uncertain prior information if (a) the scaled expected\nlength of this interval is significantly less than 1 when tau=0, (b) the\nmaximum value of the scaled expected length is not too large and (c) this\nconfidence interval reverts to the standard 1-alpha confidence interval when\nthe data happen to strongly contradict the prior information. Let\nhat{Theta}=a^T hat{beta} and hat{tau}=C^T hat{beta}-t, where hat{beta} is the\nleast squares estimator of beta. We consider the particular case that that\nE((hat{tau}-tau)(hat{Theta}-theta))=0, so that hat{Theta} and hat{tau} are\nindependent. We present a new 1-alpha confidence interval for theta that\nutilizes the uncertain prior informationthat tau=0. The following problem is\nused to illustrate the application of this new confidence interval. Consider a\n2^3 factorial experiment with 1 replicate. Suppose that the parameter of\ninterest theta is a specified linear combination of the main effects. Assume\nthat the three-factorinteraction is zero. Also suppose that we have uncertain\nprior information that all of the two-factor interactions are zero. Our aim is\nto find a frequentist 0.95 confidence interval for theta that utilizes this\nuncertain prior information.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 06:07:24 GMT"}, {"version": "v2", "created": "Thu, 25 Apr 2013 00:32:59 GMT"}], "update_date": "2017-10-18", "authors_parsed": [["Kabaila", "Paul", ""], ["Tissera", "Dilshani", ""]]}, {"id": "1303.6841", "submitter": "Richard Clegg", "authors": "R. G. Clegg, R. Landa, M. Rio", "title": "Criticisms of modelling packet traffic using long-range dependence\n  (extended version)", "comments": "This is an extended version of the conference paper\n  http://arxiv.org/abs/0910.0144", "journal-ref": "Journal of Computer and System Sciences, 77(5) pp 861--868 2010", "doi": "10.1016/j.jcss.2010.08.004", "report-no": null, "categories": "cs.NI math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper criticises the notion that long-range dependence is an important\ncontributor to the queuing behaviour of real Internet traffic. The idea is\nquestioned in two different ways. Firstly, a class of models used to simulate\nInternet traffic is shown to have important theoretical flaws. It is shown that\nthis behaviour is inconsistent with the behaviour of real traffic traces.\nSecondly, the notion that long-range correlations significantly affects the\nqueuing performance of traffic is investigated by destroying those correlations\nin real traffic traces (by reordering). It is shown that the longer ranges of\ncorrelations are not important except in one case with an extremely high load.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 14:37:43 GMT"}], "update_date": "2013-03-28", "authors_parsed": [["Clegg", "R. G.", ""], ["Landa", "R.", ""], ["Rio", "M.", ""]]}, {"id": "1303.6856", "submitter": "Jochen Fiedler", "authors": "Jochen Fiedler", "title": "From Fourier to Gegenbauer: Dimension walks on spheres", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the even- resp. odd-dimensional Schoenberg coefficients in\nGegenbauer expansions of isotropic positive definite functions on the d-sphere\ncan be expressed as linear combinations of Fourier resp. Legendre coefficients,\nand we give closed form expressions for the coefficients involved in these\nexpansions.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 15:17:54 GMT"}, {"version": "v2", "created": "Tue, 9 Sep 2014 09:45:09 GMT"}], "update_date": "2014-09-10", "authors_parsed": [["Fiedler", "Jochen", ""]]}, {"id": "1303.7090", "submitter": "Nicolas Durrande", "authors": "Nicolas Durrande (Mines Saint-\\'Etienne MSE, LIMOS), James Hensman,\n  Magnus Rattray, Neil D. Lawrence", "title": "Gaussian process models for periodicity detection", "comments": "in PeerJ Computer Science, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of detecting and quantifying the periodic component\nof a function given noise-corrupted observations of a limited number of\ninput/output tuples. Our approach is based on Gaussian process regression which\nprovides a flexible non-parametric framework for modelling periodic data. We\nintroduce a novel decomposition of the covariance function as the sum of\nperiodic and aperiodic kernels. This decomposition allows for the creation of\nsub-models which capture the periodic nature of the signal and its complement.\nTo quantify the periodicity of the signal, we derive a periodicity ratio which\nreflects the uncertainty in the fitted sub-models. Although the method can be\napplied to many kernels, we give a special emphasis to the Mat\\'ern family,\nfrom the expression of the reproducing kernel Hilbert space inner product to\nthe implementation of the associated periodic kernels in a Gaussian process\ntoolkit. The proposed method is illustrated by considering the detection of\nperiodically expressed genes in the arabidopsis genome.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2013 10:59:18 GMT"}, {"version": "v2", "created": "Wed, 17 Feb 2016 19:39:24 GMT"}, {"version": "v3", "created": "Fri, 19 Aug 2016 15:59:55 GMT"}], "update_date": "2016-08-22", "authors_parsed": [["Durrande", "Nicolas", "", "Mines Saint-\u00c9tienne MSE, LIMOS"], ["Hensman", "James", ""], ["Rattray", "Magnus", ""], ["Lawrence", "Neil D.", ""]]}, {"id": "1303.7092", "submitter": "Eric Gautier", "authors": "Eric Gautier (CREST, ENSAE), Alexandre Tsybakov (CREST, ENSAE)", "title": "Pivotal estimation in high-dimensional regression via linear programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST q-fin.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new method of estimation in high-dimensional linear regression\nmodel. It allows for very weak distributional assumptions including\nheteroscedasticity, and does not require the knowledge of the variance of\nrandom errors. The method is based on linear programming only, so that its\nnumerical implementation is faster than for previously known techniques using\nconic programs, and it allows one to deal with higher dimensional models. We\nprovide upper bounds for estimation and prediction errors of the proposed\nestimator showing that it achieves the same rate as in the more restrictive\nsituation of fixed design and i.i.d. Gaussian errors with known variance.\nFollowing Gautier and Tsybakov (2011), we obtain the results under weaker\nsensitivity assumptions than the restricted eigenvalue or assimilated\nconditions.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2013 11:01:46 GMT"}, {"version": "v2", "created": "Mon, 15 Apr 2013 09:45:31 GMT"}], "update_date": "2013-04-16", "authors_parsed": [["Gautier", "Eric", "", "CREST, ENSAE"], ["Tsybakov", "Alexandre", "", "CREST, ENSAE"]]}, {"id": "1303.7117", "submitter": "Brittany Terese Fasy", "authors": "Brittany Terese Fasy, Fabrizio Lecci, Alessandro Rinaldo, Larry\n  Wasserman, Sivaraman Balakrishnan, Aarti Singh", "title": "Confidence sets for persistence diagrams", "comments": "Published in at http://dx.doi.org/10.1214/14-AOS1252 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2014, Vol. 42, No. 6, 2301-2339", "doi": "10.1214/14-AOS1252", "report-no": "IMS-AOS-AOS1252", "categories": "math.ST cs.CG cs.LG stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Persistent homology is a method for probing topological properties of point\nclouds and functions. The method involves tracking the birth and death of\ntopological features (2000) as one varies a tuning parameter. Features with\nshort lifetimes are informally considered to be \"topological noise,\" and those\nwith a long lifetime are considered to be \"topological signal.\" In this paper,\nwe bring some statistical ideas to persistent homology. In particular, we\nderive confidence sets that allow us to separate topological signal from\ntopological noise.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2013 12:59:00 GMT"}, {"version": "v2", "created": "Fri, 7 Feb 2014 16:36:57 GMT"}, {"version": "v3", "created": "Thu, 20 Nov 2014 08:16:51 GMT"}], "update_date": "2014-11-21", "authors_parsed": [["Fasy", "Brittany Terese", ""], ["Lecci", "Fabrizio", ""], ["Rinaldo", "Alessandro", ""], ["Wasserman", "Larry", ""], ["Balakrishnan", "Sivaraman", ""], ["Singh", "Aarti", ""]]}, {"id": "1303.7152", "submitter": "Victor Chernozhukov", "authors": "Victor Chernozhukov, Denis Chetverikov, Kengo Kato", "title": "Anti-concentration and honest, adaptive confidence bands", "comments": "Published in at http://dx.doi.org/10.1214/14-AOS1235 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2014, Vol. 42, No. 5, 1787-1818", "doi": "10.1214/14-AOS1235", "report-no": "IMS-AOS-AOS1235", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern construction of uniform confidence bands for nonparametric densities\n(and other functions) often relies on the classical Smirnov-Bickel-Rosenblatt\n(SBR) condition; see, for example, Gin\\'{e} and Nickl [Probab. Theory Related\nFields 143 (2009) 569-596]. This condition requires the existence of a limit\ndistribution of an extreme value type for the supremum of a studentized\nempirical process (equivalently, for the supremum of a Gaussian process with\nthe same covariance function as that of the studentized empirical process). The\nprincipal contribution of this paper is to remove the need for this classical\ncondition. We show that a considerably weaker sufficient condition is derived\nfrom an anti-concentration property of the supremum of the approximating\nGaussian process, and we derive an inequality leading to such a property for\nseparable Gaussian processes. We refer to the new condition as a generalized\nSBR condition. Our new result shows that the supremum does not concentrate too\nfast around any value. We then apply this result to derive a Gaussian\nmultiplier bootstrap procedure for constructing honest confidence bands for\nnonparametric density estimators (this result can be applied in other\nnonparametric problems as well). An essential advantage of our approach is that\nit applies generically even in those cases where the limit distribution of the\nsupremum of the studentized empirical process does not exist (or is unknown).\nThis is of particular importance in problems where resolution levels or other\ntuning parameters have been chosen in a data-driven fashion, which is needed\nfor adaptive constructions of the confidence bands. Finally, of independent\ninterest is our introduction of a new, practical version of Lepski's method,\nwhich computes the optimal, nonconservative resolution levels via a Gaussian\nmultiplier bootstrap method.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2013 15:39:44 GMT"}, {"version": "v2", "created": "Fri, 29 Mar 2013 23:07:46 GMT"}, {"version": "v3", "created": "Wed, 4 Dec 2013 19:28:36 GMT"}, {"version": "v4", "created": "Tue, 23 Sep 2014 12:56:01 GMT"}], "update_date": "2014-09-24", "authors_parsed": [["Chernozhukov", "Victor", ""], ["Chetverikov", "Denis", ""], ["Kato", "Kengo", ""]]}, {"id": "1303.7291", "submitter": "Mihailo Stojnic", "authors": "Mihailo Stojnic", "title": "A framework to characterize performance of LASSO algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.OC math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider solving \\emph{noisy} under-determined systems of\nlinear equations with sparse solutions. A noiseless equivalent attracted\nenormous attention in recent years, above all, due to work of\n\\cite{CRT,CanRomTao06,DonohoPol} where it was shown in a statistical and large\ndimensional context that a sparse unknown vector (of sparsity proportional to\nthe length of the vector) can be recovered from an under-determined system via\na simple polynomial $\\ell_1$-optimization algorithm. \\cite{CanRomTao06} further\nestablished that even when the equations are \\emph{noisy}, one can, through an\nSOCP noisy equivalent of $\\ell_1$, obtain an approximate solution that is (in\nan $\\ell_2$-norm sense) no further than a constant times the noise from the\nsparse unknown vector. In our recent works\n\\cite{StojnicCSetam09,StojnicUpper10}, we created a powerful mechanism that\nhelped us characterize exactly the performance of $\\ell_1$ optimization in the\nnoiseless case (as shown in \\cite{StojnicEquiv10} and as it must be if the\naxioms of mathematics are well set, the results of\n\\cite{StojnicCSetam09,StojnicUpper10} are in an absolute agreement with the\ncorresponding exact ones from \\cite{DonohoPol}). In this paper we design a\nmechanism, as powerful as those from \\cite{StojnicCSetam09,StojnicUpper10},\nthat can handle the analysis of a LASSO type of algorithm (and many others)\nthat can be (or typically are) used for \"solving\" noisy under-determined\nsystems. Using the mechanism we then, in a statistical context, compute the\nexact worst-case $\\ell_2$ norm distance between the unknown sparse vector and\nthe approximate one obtained through such a LASSO. The obtained results match\nthe corresponding exact ones obtained in \\cite{BayMon10,DonMalMon10}. Moreover,\nas a by-product of our analysis framework we recognize existence of an SOCP\ntype of algorithm that achieves the same performance.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2013 03:55:09 GMT"}], "update_date": "2013-04-01", "authors_parsed": [["Stojnic", "Mihailo", ""]]}, {"id": "1303.7297", "submitter": "Tomonari Sei", "authors": "Tomonari Sei", "title": "Infinitely imbalanced binomial regression and deformed exponential\n  families", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The logistic regression model is known to converge to a Poisson point process\nmodel if the binary response tends to infinitely imbalanced. In this paper, it\nis shown that this phenomenon is universal in a wide class of link functions on\nbinomial regression. The proof relies on the extreme value theory. For the\nlogit, probit and complementary log-log link functions, the intensity measure\nof the point process becomes an exponential family. For some other link\nfunctions, deformed exponential families appear. A penalized maximum likelihood\nestimator for the Poisson point process model is suggested.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2013 05:37:51 GMT"}, {"version": "v2", "created": "Sun, 21 Apr 2013 17:32:52 GMT"}], "update_date": "2013-04-23", "authors_parsed": [["Sei", "Tomonari", ""]]}, {"id": "1303.7437", "submitter": "Thomas Vareschi", "authors": "Thomas Vareschi", "title": "Noisy Laplace deconvolution with error in the operator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We adress the problem of Laplace deconvolution with random noise in a\nregression framework. The time set is not considered to be fixed, but grows\nwith the number of observation points. Moreover, the convolution kernel is\nunknown, and accessible only through experimental noise. We make use of a\nrecent procedure of estimation which couples a Galerkin projection of the\noperator on Laguerre functions, with a threshold performed both on the operator\nand the observed signal. We establish the minimax optimality of our procedure\nunder the squared loss error, when the smoothness of the signal is measured in\na Laguerre-Sobolev sense and the kernel satisfies fair blurring assumptions. It\nis important to stress that the resulting process is adaptive with regard both\nto the target function's smoothness and to the kernel's blurring properties. We\nend this paper with a numerical study emphazising the good practical\nperformances of the procedure on concrete examples.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2013 16:54:51 GMT"}, {"version": "v2", "created": "Thu, 4 Apr 2013 08:27:59 GMT"}], "update_date": "2013-04-05", "authors_parsed": [["Vareschi", "Thomas", ""]]}]