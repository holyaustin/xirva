[{"id": "1601.00078", "submitter": "Wiktor  Ejsmont", "authors": "Wiktor Ejsmont", "title": "A Characterization of the Normal Distribution by the Independence of a\n  Pair of Random Vectors", "comments": "6 pages", "journal-ref": "Statist. Probab. Lett. 114 (2016), 1-5", "doi": "10.1016/j.spl.2016.02.011", "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kagan and Shalaevski 1967 have shown that if the random variables\n$X_1,\\dots,X_n$ are independent and identically distributed and the\ndistribution of $\\sum_{i=1}^n(X_i+a_i)^2$ $a_i\\in \\mathbb{R}$ depends only on\n$\\sum_{i=1}^na_i^2$ , then each $X_i$ follows the normal distribution $N(0,\n\\sigma)$. Cook 1971 generalized this result replacing independence of all $X_i$\nby the independence of $(X_1,\\dots, X_m) \\textrm{ and } (X_{m+1},\\dots,X_n )$\nand removing the requirement that $X_i$ have the same distribution. In this\npaper, we will give other characterizations of the normal distribution which\nare formulated in a similar spirit.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jan 2016 12:49:26 GMT"}], "update_date": "2016-09-06", "authors_parsed": [["Ejsmont", "Wiktor", ""]]}, {"id": "1601.00155", "submitter": "Jean-Marc Bardet", "authors": "Jean-Marc Bardet (SAMM), Yakoub Boularouk (USTHB), Khedidja Djaballah\n  (USTHB)", "title": "Asymptotic behavior of the Laplacian quasi-maximum likelihood estimator\n  of affine causal processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove the consistency and asymptotic normality of the Laplacian\nQuasi-Maximum Likelihood Estimator (QMLE) for a general class of causal time\nseries including ARMA, AR($\\infty$), GARCH, ARCH($\\infty$), ARMA-GARCH, APARCH,\nARMA-APARCH,..., processes. We notably exhibit the advantages (moment order and\nrobustness) of this estimator compared to the classical Gaussian QMLE.\nNumerical simulations confirms the accuracy of this estimator.\n", "versions": [{"version": "v1", "created": "Sat, 2 Jan 2016 09:36:16 GMT"}, {"version": "v2", "created": "Tue, 21 Feb 2017 15:25:08 GMT"}], "update_date": "2017-02-22", "authors_parsed": [["Bardet", "Jean-Marc", "", "SAMM"], ["Boularouk", "Yakoub", "", "USTHB"], ["Djaballah", "Khedidja", "", "USTHB"]]}, {"id": "1601.00202", "submitter": "Piet Groeneboom", "authors": "Piet Groeneboom and Kim Hendrickx", "title": "Current status linear regression", "comments": "64 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We construct $\\sqrt{n}$-consistent and asymptotically normal estimates for\nthe finite dimensional regression parameter in the current status linear\nregression model, which do not require any smoothing device and are based on\nmaximum likelihood estimates (MLEs) of the infinite dimensional parameter. We\nalso construct estimates, again only based on these MLEs, which are arbitrarily\nclose to efficient estimates, if the generalized Fisher information is finite.\nThis type of efficiency is also derived under minimal conditions for estimates\nbased on smooth non-monotone plug-in estimates of the distribution function.\nAlgorithms for computing the estimates and for selecting the bandwidth of the\nsmooth estimates with a bootstrap method are provided. The connection with\nresults in the econometric literature is also pointed out.\n", "versions": [{"version": "v1", "created": "Sat, 2 Jan 2016 18:07:34 GMT"}, {"version": "v2", "created": "Thu, 2 Jun 2016 13:08:20 GMT"}, {"version": "v3", "created": "Fri, 3 Jun 2016 09:12:00 GMT"}, {"version": "v4", "created": "Mon, 29 Aug 2016 15:57:19 GMT"}, {"version": "v5", "created": "Thu, 5 Jan 2017 15:07:06 GMT"}, {"version": "v6", "created": "Sat, 1 Apr 2017 21:02:07 GMT"}], "update_date": "2017-04-04", "authors_parsed": [["Groeneboom", "Piet", ""], ["Hendrickx", "Kim", ""]]}, {"id": "1601.00389", "submitter": "Armeen Taeb", "authors": "Armeen Taeb, Venkat Chandrasekaran", "title": "Interpreting Latent Variables in Factor Models via Convex Optimization", "comments": null, "journal-ref": "Mathematical Programming 2018, Vol. 167, 129--154", "doi": "10.1007/s10107-017-1187-7", "report-no": null, "categories": "stat.ME math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latent or unobserved phenomena pose a significant difficulty in data analysis\nas they induce complicated and confounding dependencies among a collection of\nobserved variables. Factor analysis is a prominent multivariate statistical\nmodeling approach that addresses this challenge by identifying the effects of\n(a small number of) latent variables on a set of observed variables. However,\nthe latent variables in a factor model are purely mathematical objects that are\nderived from the observed phenomena, and they do not have any interpretation\nassociated to them. A natural approach for attributing semantic information to\nthe latent variables in a factor model is to obtain measurements of some\nadditional plausibly useful covariates that may be related to the original set\nof observed variables, and to associate these auxiliary covariates to the\nlatent variables. In this paper, we describe a systematic approach for\nidentifying such associations. Our method is based on solving computationally\ntractable convex optimization problems, and it can be viewed as a\ngeneralization of the minimum-trace factor analysis procedure for fitting\nfactor models via convex optimization. We analyze the theoretical consistency\nof our approach in a high-dimensional setting as well as its utility in\npractice via experimental demonstrations with real data.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2016 06:29:16 GMT"}, {"version": "v2", "created": "Thu, 3 Nov 2016 01:18:57 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Taeb", "Armeen", ""], ["Chandrasekaran", "Venkat", ""]]}, {"id": "1601.00399", "submitter": "Eric Sibony", "authors": "Eric Sibony (LTCI), St\\'ephan Cl\\'emen\\c{c}on (LTCI), J\\'er\\'emie\n  Jakubowicz (SAMOVAR)", "title": "A Multiresolution Analysis Framework for the Statistical Analysis of\n  Incomplete Rankings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Though the statistical analysis of ranking data has been a subject of\ninterest over the past centuries, especially in economics, psychology or social\nchoice theory, it has been revitalized in the past 15 years by recent\napplications such as recommender or search engines and is receiving now\nincreasing interest in the machine learning literature. Numerous modern systems\nindeed generate ranking data, representing for instance ordered results to a\nquery or user preferences. Each such ranking usually involves a small but\nvarying subset of the whole catalog of items only. The study of the variability\nof these data, i.e. the statistical analysis of incomplete rank-ings, is\nhowever a great statistical and computational challenge, because of their\nheterogeneity and the related combinatorial complexity of the problem. Whereas\nmany statistical methods for analyzing full rankings (orderings of all the\nitems in the catalog) are documented in the dedicated literature, partial\nrankings (full rankings with ties) or pairwise comparisons, only a few\napproaches are available today to deal with incomplete ranking, relying each on\na strong specific assumption. It is the purpose of this article to introduce a\nnovel general framework for the statistical analysis of incomplete rankings. It\nis based on a representation tailored to these specific data, whose\nconstruction is also explained here, which fits with the natural multi-scale\nstructure of incomplete rankings and provides a new decomposition of rank\ninformation with a multiresolu-tion analysis interpretation (MRA). We show that\nthe MRA representation naturally allows to overcome both the statistical and\ncomputational challenges without any structural assumption on the data. It\ntherefore provides a general and flexible framework to solve a wide variety of\nstatistical problems, where data are of the form of incomplete rankings.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2016 07:40:15 GMT"}], "update_date": "2016-01-05", "authors_parsed": [["Sibony", "Eric", "", "LTCI"], ["Cl\u00e9men\u00e7on", "St\u00e9phan", "", "LTCI"], ["Jakubowicz", "J\u00e9r\u00e9mie", "", "SAMOVAR"]]}, {"id": "1601.00549", "submitter": "Dariush Kari", "authors": "Dariush Kari and Farhan Khan and Selami Ciftci and Suleyman Serdar\n  Kozat", "title": "A Novel Family of Boosted Online Regression Algorithms with Strong\n  Theoretical Bounds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate boosted online regression and propose a novel family of\nregression algorithms with strong theoretical bounds. In addition, we implement\nseveral variants of the proposed generic algorithm. We specifically provide\ntheoretical bounds for the performance of our proposed algorithms that hold in\na strong mathematical sense. We achieve guaranteed performance improvement over\nthe conventional online regression methods without any statistical assumptions\non the desired data or feature vectors. We demonstrate an intrinsic\nrelationship, in terms of boosting, between the adaptive mixture-of-experts and\ndata reuse algorithms. Furthermore, we introduce a boosting algorithm based on\nrandom updates that is significantly faster than the conventional boosting\nmethods and other variants of our proposed algorithms while achieving an\nenhanced performance gain. Hence, the random updates method is specifically\napplicable to the fast and high dimensional streaming data. Specifically, we\ninvestigate Newton Method-based and Stochastic Gradient Descent-based linear\nregression algorithms in a mixture-of-experts setting and provide several\nvariants of these well-known adaptation methods. However, the proposed\nalgorithms can be extended to other base learners, e.g., nonlinear, tree-based\npiecewise linear. Furthermore, we provide theoretical bounds for the\ncomputational complexity of our proposed algorithms. We demonstrate substantial\nperformance gains in terms of mean square error over the base learners through\nan extensive set of benchmark real data sets and simulated examples.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2016 15:55:10 GMT"}, {"version": "v2", "created": "Tue, 6 Dec 2016 19:27:02 GMT"}], "update_date": "2016-12-07", "authors_parsed": [["Kari", "Dariush", ""], ["Khan", "Farhan", ""], ["Ciftci", "Selami", ""], ["Kozat", "Suleyman Serdar", ""]]}, {"id": "1601.00773", "submitter": "Geoffrey McLachlan", "authors": "Geoffrey J. McLachlan, Sharon X. Lee", "title": "Comment on \"On Nomenclature, and the Relative Merits of Two Formulations\n  of Skew Distributions\" by A. Azzalini, R. Browne, M. Genton, and P.\n  McNicholas", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We comment on the recent paper by Azzalini et al. (2015) on two different\ndistributions proposed in the literature for the modelling of data that have\nasymmetric and possibly long-tailed clusters. They are referred to as the\nrestricted and unrestricted skew normal and skew t-distributions by Lee and\nMcLachlan (2013a). We clarify an apparent misunderstanding in Azzalini et\nal.(2015) of this nomenclature to distinguish between these two models. Also,\nwe note that McLachlan and Lee (2014) have obtained improved results for the\nunrestricted model over those reported in Azzalini et al. (2015) for the two\ndatasets that were analysed by them to form the basis of their claimson the\nrelative superiority of the restricted and unrestricted models. On this matter\nof the relative superiority of these two models, Lee and McLachlan (2014b,\n2016) have shown how a distribution belonging to the broader class, the\ncanonical fundamental skew t (CFUST) class, can be fitted with little\nadditional computational effort than for the unrestricted distribution. The\nCFUST class includes the restricted and unrestricted distributions as special\ncases. Thus the user now has the option of letting the data decide as to which\nmodel is appropriate for their particular dataset.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2016 09:10:58 GMT"}], "update_date": "2016-01-06", "authors_parsed": [["McLachlan", "Geoffrey J.", ""], ["Lee", "Sharon X.", ""]]}, {"id": "1601.00815", "submitter": "Jana Jankova", "authors": "Jana Jankova and Sara van de Geer", "title": "Semi-parametric efficiency bounds for high-dimensional models", "comments": "68 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Asymptotic lower bounds for estimation play a fundamental role in assessing\nthe quality of statistical procedures. In this paper we propose a framework for\nobtaining semi-parametric efficiency bounds for sparse high-dimensional models,\nwhere the dimension of the parameter is larger than the sample size. We adopt a\nsemi-parametric point of view: we concentrate on one dimensional functions of a\nhigh-dimensional parameter. We follow two different approaches to reach the\nlower bounds: asymptotic Cram\\'er-Rao bounds and Le Cam's type of analysis.\nBoth these approaches allow us to define a class of asymptotically unbiased or\n\"regular\" estimators for which a lower bound is derived. Consequently, we show\nthat certain estimators obtained by de-sparsifying (or de-biasing) an\n$\\ell_1$-penalized M-estimator are asymptotically unbiased and achieve the\nlower bound on the variance: thus in this sense they are asymptotically\nefficient. The paper discusses in detail the linear regression model and the\nGaussian graphical model.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2016 12:50:05 GMT"}, {"version": "v2", "created": "Wed, 8 Jun 2016 16:47:30 GMT"}, {"version": "v3", "created": "Fri, 4 Aug 2017 13:10:07 GMT"}, {"version": "v4", "created": "Thu, 12 Oct 2017 20:43:50 GMT"}], "update_date": "2017-10-16", "authors_parsed": [["Jankova", "Jana", ""], ["van de Geer", "Sara", ""]]}, {"id": "1601.00934", "submitter": "J\\\"org Stoye", "authors": "Hiroaki Kaido and Francesca Molinari and J\\\"org Stoye", "title": "Confidence Intervals for Projections of Partially Identified Parameters", "comments": "This version is identical to the paper forthcoming at Econometrica\n  and includes the online appendix", "journal-ref": null, "doi": "10.3982/ECTA14075", "report-no": null, "categories": "math.ST econ.EM stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a bootstrap-based calibrated projection procedure to build\nconfidence intervals for single components and for smooth functions of a\npartially identified parameter vector in moment (in)equality models. The method\ncontrols asymptotic coverage uniformly over a large class of data generating\nprocesses. The extreme points of the calibrated projection confidence interval\nare obtained by extremizing the value of the function of interest subject to a\nproper relaxation of studentized sample analogs of the moment (in)equality\nconditions. The degree of relaxation, or critical level, is calibrated so that\nthe function of theta, not theta itself, is uniformly asymptotically covered\nwith prespecified probability. This calibration is based on repeatedly checking\nfeasibility of linear programming problems, rendering it computationally\nattractive.\n  Nonetheless, the program defining an extreme point of the confidence interval\nis generally nonlinear and potentially intricate. We provide an algorithm,\nbased on the response surface method for global optimization, that approximates\nthe solution rapidly and accurately, and we establish its rate of convergence.\nThe algorithm is of independent interest for optimization problems with simple\nobjectives and complicated constraints. An empirical application estimating an\nentry game illustrates the usefulness of the method. Monte Carlo simulations\nconfirm the accuracy of the solution algorithm, the good statistical as well as\ncomputational performance of calibrated projection (including in comparison to\nother methods), and the algorithm's potential to greatly accelerate computation\nof other confidence intervals.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2016 18:45:22 GMT"}, {"version": "v2", "created": "Wed, 1 Nov 2017 18:06:01 GMT"}, {"version": "v3", "created": "Mon, 21 Jan 2019 16:09:17 GMT"}, {"version": "v4", "created": "Wed, 5 Jun 2019 19:22:01 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Kaido", "Hiroaki", ""], ["Molinari", "Francesca", ""], ["Stoye", "J\u00f6rg", ""]]}, {"id": "1601.01045", "submitter": "Deepesh Bhati Mr.", "authors": "Deepesh Bhati, Mohd. Aamir Malik and K.K. Jose", "title": "A new 3-parameter extension of generalized lindley distribution", "comments": "15 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Here, we introduce a new class of Lindley generated distributions which\nresults in more flexible model with increasing failure rate (IFR), decreasing\nfailure rate(DFR) and up-side down hazard functions for different choices of\nparametric values. We explore, various distributional properties including\nlimiting distribution of extreme order statistics explored. Maximum likelihood\nestimators and the confidence intervals of the parameters are obtained. The\napplicability of the proposed distribution is shown through modelling two sets\nof real data on bladder cancer patients and waiting time in a queue. Further,\nwe carry out stress-strength analysis for applying the model in system\nreliability studies.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jan 2016 01:44:47 GMT"}], "update_date": "2016-01-07", "authors_parsed": [["Bhati", "Deepesh", ""], ["Malik", "Mohd. Aamir", ""], ["Jose", "K. K.", ""]]}, {"id": "1601.01082", "submitter": "Shoichi Eguchi", "authors": "Shoichi Eguchi", "title": "Model comparison for generalized linear models with dependent\n  observations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The stochastic expansion of the marginal quasi-likelihood function associated\nwith a class of generalized linear models is shown. Based on the expansion, a\nquasi-Bayesian information criterion is proposed that is able to deal with\nmisspecified models and dependent data, resulting in a theoretical extension of\nthe classical Schwarz's Bayesian information criterion. It is also proved that\nthe proposed criterion has model selection consistency with respect to the\noptimal model. Some illustrative numerical examples and a real data example are\npresented.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jan 2016 05:33:12 GMT"}, {"version": "v2", "created": "Thu, 17 Nov 2016 09:40:42 GMT"}, {"version": "v3", "created": "Tue, 18 Apr 2017 08:56:28 GMT"}], "update_date": "2017-04-19", "authors_parsed": [["Eguchi", "Shoichi", ""]]}, {"id": "1601.01122", "submitter": "Johannes Tewes", "authors": "Johannes Tewes", "title": "Block bootstrap for the empirical process of long-range dependent data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider long-range dependent data. It is shown that the bootstrapped\nempirical process of these data converges to a semi-degenerate limit. The\nrandom part of this limit is always Gaussian. Thus the bootstrap might fail\nwhen the original empirical process accomplishes a noncentral limit theorem.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jan 2016 10:06:10 GMT"}], "update_date": "2016-01-07", "authors_parsed": [["Tewes", "Johannes", ""]]}, {"id": "1601.01131", "submitter": "S.N. Lahiri", "authors": "S.N. Lahiri, Peter M. Robinson", "title": "Central limit theorems for long range dependent spatial linear processes", "comments": "Published at http://dx.doi.org/10.3150/14-BEJ661 in the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2016, Vol. 22, No. 1, 345-375", "doi": "10.3150/14-BEJ661", "report-no": "IMS-BEJ-BEJ661", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Central limit theorems are established for the sum, over a spatial region, of\nobservations from a linear process on a $d$-dimensional lattice. This region\nneed not be rectangular, but can be irregularly-shaped. Separate results are\nestablished for the cases of positive strong dependence, short range\ndependence, and negative dependence. We provide approximations to asymptotic\nvariances that reveal differential rates of convergence under the three types\nof dependence. Further, in contrast to the one dimensional (i.e., the time\nseries) case, it is shown that the form of the asymptotic variance in\ndimensions $d>1$ critically depends on the geometry of the sampling region\nunder positive strong dependence and under negative dependence and that there\ncan be non-trivial edge-effects under negative dependence for $d>1$. Precise\nconditions for the presence of edge effects are also given.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jan 2016 10:34:07 GMT"}], "update_date": "2016-01-07", "authors_parsed": [["Lahiri", "S. N.", ""], ["Robinson", "Peter M.", ""]]}, {"id": "1601.01170", "submitter": "Manabu Kuroki", "authors": "Manabu Kuroki", "title": "Equivalence between direct and indirect effects with different sets of\n  intermediate variables and covariates", "comments": "Published at http://dx.doi.org/10.3150/14-BEJ664 in the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2016, Vol. 22, No. 1, 421-443", "doi": "10.3150/14-BEJ664", "report-no": "IMS-BEJ-BEJ664", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with the concept of equivalence between direct and indirect\neffects of a treatment on a response using two sets of intermediate variables\nand covariates. First, we provide criteria for testing whether two sets of\nvariables can estimate the same direct and indirect effects. Next, based on the\nproposed criteria, we discuss the variable selection problem from the viewpoint\nof estimation accuracy of direct and indirect effects, and show that selecting\na set of variables that has a direct effect on a response cannot always improve\nestimation accuracy, which is contrary to the situation found in linear\nregression models. These results enable us to judge whether different sets of\nvariables can yield the same direct and indirect effects and thus help us\nselect appropriate variables to estimate direct and indirect effects with cost\nreduction or estimation accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jan 2016 13:15:33 GMT"}], "update_date": "2016-01-07", "authors_parsed": [["Kuroki", "Manabu", ""]]}, {"id": "1601.01186", "submitter": "Emmanuel Gobet", "authors": "Emmanuel Gobet, Plamen Turkedjiev", "title": "Approximation of backward stochastic differential equations using\n  Malliavin weights and least-squares regression", "comments": "Published at http://dx.doi.org/10.3150/14-BEJ667 in the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2016, Vol. 22, No. 1, 530-562", "doi": "10.3150/14-BEJ667", "report-no": "IMS-BEJ-BEJ667", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We design a numerical scheme for solving a Dynamic Programming equation with\nMalliavin weights arising from the time-discretization of backward stochastic\ndifferential equations with the integration by parts-representation of the\n$Z$-component by (Ann. Appl. Probab. 12 (2002) 1390-1418). When the sequence of\nconditional expectations is computed using empirical least-squares regressions,\nwe establish, under general conditions, tight error bounds as the time-average\nof local regression errors only (up to logarithmic factors). We compute the\nalgorithm complexity by a suitable optimization of the parameters, depending on\nthe dimension and the smoothness of value functions, in the limit as the number\nof grid times goes to infinity. The estimates take into account the regularity\nof the terminal function.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jan 2016 14:13:10 GMT"}], "update_date": "2016-01-07", "authors_parsed": [["Gobet", "Emmanuel", ""], ["Turkedjiev", "Plamen", ""]]}, {"id": "1601.01345", "submitter": "Benjamin Guedj", "authors": "Pierre Alquier and Benjamin Guedj", "title": "An Oracle Inequality for Quasi-Bayesian Non-Negative Matrix\n  Factorization", "comments": "This is the corrected version of the published paper P. Alquier, B.\n  Guedj, An Oracle Inequality for Quasi-Bayesian Non-negative Matrix\n  Factorization, Mathematical Methods of Statistics, 2017, vol. 26, no. 1, pp.\n  55-67. Since then Arnak Dalalyan (ENSAE) found a mistake in the proofs. We\n  fixed the mistake at the price of a slightly different logarithmic term in\n  the bound", "journal-ref": "Mathematical Methods of Statistics (MMS), 26(1): 55-67, 2017", "doi": "10.3103/S1066530717010045", "report-no": null, "categories": "stat.ML math.ST stat.TH", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The aim of this paper is to provide some theoretical understanding of\nquasi-Bayesian aggregation methods non-negative matrix factorization. We derive\nan oracle inequality for an aggregated estimator. This result holds for a very\ngeneral class of prior distributions and shows how the prior affects the rate\nof convergence.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jan 2016 22:28:50 GMT"}, {"version": "v2", "created": "Tue, 7 Jun 2016 17:15:36 GMT"}, {"version": "v3", "created": "Wed, 24 Aug 2016 16:00:22 GMT"}, {"version": "v4", "created": "Tue, 26 Jun 2018 07:51:34 GMT"}], "update_date": "2018-06-27", "authors_parsed": [["Alquier", "Pierre", ""], ["Guedj", "Benjamin", ""]]}, {"id": "1601.01413", "submitter": "Peter Aronow", "authors": "Peter M. Aronow", "title": "Local average causal effects and superefficiency", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent approaches in causal inference have proposed estimating average causal\neffects that are local to some subpopulation, often for reasons of efficiency.\nThese inferential targets are sometimes data-adaptive, in that they are\ndependent on the empirical distribution of the data. In this short note, we\nshow that if researchers are willing to adapt the inferential target on the\nbasis of efficiency, then extraordinary gains in precision can be obtained.\nSpecifically, when causal effects are heterogeneous, any asymptotically normal\nand root-$n$ consistent estimator of the population average causal effect is\nsuperefficient for a data-adaptive local average causal effect. Our result\nillustrates the fundamental gain in statistical certainty afforded by\nindifference about the inferential target.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2016 06:56:23 GMT"}, {"version": "v2", "created": "Fri, 5 Feb 2016 00:21:06 GMT"}], "update_date": "2016-02-08", "authors_parsed": [["Aronow", "Peter M.", ""]]}, {"id": "1601.01426", "submitter": "Estate Khmaladze", "authors": "Estate Khmaladze", "title": "Unitary transformations, empirical processes and distribution free\n  testing", "comments": "Published at http://dx.doi.org/10.3150/14-BEJ668 in the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2016, Vol. 22, No. 1, 563-588", "doi": "10.3150/14-BEJ668", "report-no": "IMS-BEJ-BEJ668", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main message in this paper is that there are surprisingly many different\nBrownian bridges, some of them - familiar, some of them - less familiar. Many\nof these Brownian bridges are very close to Brownian motions. Somewhat loosely\nspeaking, we show that all the bridges can be conveniently mapped onto each\nother, and hence, to one \"standard\" bridge. The paper shows that, a consequence\nof this, we obtain a unified theory of distribution free testing in $\\mathbb\n{R}^d$, both for discrete and continuous cases, and for simple and parametric\nhypothesis.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2016 07:41:28 GMT"}], "update_date": "2016-01-08", "authors_parsed": [["Khmaladze", "Estate", ""]]}, {"id": "1601.01434", "submitter": "Yuichi Hirose", "authors": "Yuichi Hirose", "title": "On differentiability of implicitly defined function in semi-parametric\n  profile likelihood estimation", "comments": "Published at http://dx.doi.org/10.3150/14-BEJ669 in the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2016, Vol. 22, No. 1, 589-614", "doi": "10.3150/14-BEJ669", "report-no": "IMS-BEJ-BEJ669", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the differentiability of implicitly defined functions\nwhich we encounter in the profile likelihood estimation of parameters in\nsemi-parametric models. Scott and Wild (Biometrika 84 (1997) 57-71; J. Statist.\nPlann. Inference 96 (2001) 3-27) and Murphy and van der Vaart (J. Amer.\nStatist. Assoc. 95 (2000) 449-485) developed methodologies that can avoid\ndealing with such implicitly defined functions by parametrizing parameters in\nthe profile likelihood and using an approximate least favorable submodel in\nsemi-parametric models. Our result shows applicability of an alternative\napproach presented in Hirose (Ann. Inst. Statist. Math. 63 (2011) 1247-1275)\nwhich uses the direct expansion of the profile likelihood.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2016 08:03:03 GMT"}], "update_date": "2016-01-08", "authors_parsed": [["Hirose", "Yuichi", ""]]}, {"id": "1601.01452", "submitter": "Sucharita Roy", "authors": "Sucharita Roy and Sourabh Bhattacharya", "title": "Bayes meet Riemann- Bayesian Characterization of Infinite Series with\n  Application to Riemann Hypothesis", "comments": "An updated version", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the classical literature on infinite series there are various tests to\ndetermine if a given infinite series converges, diverges, or oscillates. But\nunfortunately, for very many infinite series all the existing tests can fail to\nprovide definitive answers. In this article we propose a novel Bayesian theory\nfor assessment of convergence properties of any given infinite series.\nRemarkably, this theory attempts to provide conclusive answers to the question\nof convergence even where all the existing tests of convergence fail. We apply\nour ideas to seven different examples, obtaining very encouraging results.\nImportantly, we also apply our ideas to investigate the Riemann Hypothesis, and\nobtain results that do not completely support the conjecture.\n  We also extend our ideas to develop a Bayesian theory on oscillating series,\nwhere we allow even infinite number of limit points. Analysis of Riemann\nHypothesis using Bayesian multiple limit points theory yielded almost identical\nresults as the Bayesian theory of convergence assessment.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2016 09:12:58 GMT"}, {"version": "v2", "created": "Wed, 11 May 2016 04:33:11 GMT"}, {"version": "v3", "created": "Fri, 10 Feb 2017 11:30:37 GMT"}, {"version": "v4", "created": "Wed, 15 Mar 2017 18:38:36 GMT"}, {"version": "v5", "created": "Tue, 25 Jul 2017 16:08:10 GMT"}, {"version": "v6", "created": "Thu, 12 Apr 2018 10:13:31 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["Roy", "Sucharita", ""], ["Bhattacharya", "Sourabh", ""]]}, {"id": "1601.01457", "submitter": "Karim Lounici", "authors": "Vladimir Koltchinskii and Karim Lounici", "title": "New asymptotic results in principal component analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $X$ be a mean zero Gaussian random vector in a separable Hilbert space\n${\\mathbb H}$ with covariance operator $\\Sigma:={\\mathbb E}(X\\otimes X).$ Let\n$\\Sigma=\\sum_{r\\geq 1}\\mu_r P_r$ be the spectral decomposition of $\\Sigma$ with\ndistinct eigenvalues $\\mu_1>\\mu_2> \\dots$ and the corresponding spectral\nprojectors $P_1, P_2, \\dots.$ Given a sample $X_1,\\dots, X_n$ of size $n$ of\ni.i.d. copies of $X,$ the sample covariance operator is defined as $\\hat\n\\Sigma_n := n^{-1}\\sum_{j=1}^n X_j\\otimes X_j.$ The main goal of principal\ncomponent analysis is to estimate spectral projectors $P_1, P_2, \\dots$ by\ntheir empirical counterparts $\\hat P_1, \\hat P_2, \\dots$ properly defined in\nterms of spectral decomposition of the sample covariance operator $\\hat\n\\Sigma_n.$ The aim of this paper is to study asymptotic distributions of\nimportant statistics related to this problem, in particular, of statistic\n$\\|\\hat P_r-P_r\\|_2^2,$ where $\\|\\cdot\\|_2^2$ is the squared Hilbert--Schmidt\nnorm. This is done in a \"high-complexity\" asymptotic framework in which the so\ncalled effective rank ${\\bf r}(\\Sigma):=\\frac{{\\rm\ntr}(\\Sigma)}{\\|\\Sigma\\|_{\\infty}}$ (${\\rm tr}(\\cdot)$ being the trace and\n$\\|\\cdot\\|_{\\infty}$ being the operator norm) of the true covariance $\\Sigma$\nis becoming large simultaneously with the sample size $n,$ but ${\\bf\nr}(\\Sigma)=o(n)$ as $n\\to\\infty.$ In this setting, we prove that, in the case\nof one-dimensional spectral projector $P_r,$ the properly centered and\nnormalized statistic $\\|\\hat P_r-P_r\\|_2^2$ with {\\it data-dependent} centering\nand normalization converges in distribution to a Cauchy type limit. The proofs\nof this and other related results rely on perturbation analysis and Gaussian\nconcentration.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2016 09:30:15 GMT"}], "update_date": "2016-01-08", "authors_parsed": [["Koltchinskii", "Vladimir", ""], ["Lounici", "Karim", ""]]}, {"id": "1601.01470", "submitter": "Gabriela Cio{\\l}ek", "authors": "Gabriela Cio{\\l}ek", "title": "Bootstrap uniform central limit theorems for Harris recurrent Markov\n  chains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main objective of this paper is to establish bootstrap uniform functional\ncentral limit theorem for Harris recurrent Markov chains over uniformly bounded\nclasses of functions. We show that the result can be generalized also to the\nunbounded case. To avoid some complicated mixing conditions, we make use of the\nwell-known regeneration properties of Markov chains. We show that in the atomic\ncase the proof of the bootstrap uniform central limit theorem for Markov chains\nfor functions dominated by a function in $L^{2}$ space proposed by\nRadulovi\\'{c} (2004) can be significantly simplified. Finally, we prove\nbootstrap uniform central limit theorems for Fr\\'{e}chet differentiable\nfunctionals in a Markovian setting.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2016 10:34:40 GMT"}], "update_date": "2016-01-08", "authors_parsed": [["Cio\u0142ek", "Gabriela", ""]]}, {"id": "1601.01972", "submitter": "David Schnoerr", "authors": "David Schnoerr, Ramon Grima and Guido Sanguinetti", "title": "Cox process representation and inference for stochastic\n  reaction-diffusion processes", "comments": "18 pages, 5 figures", "journal-ref": "Nature Communications, 7 (11729) (2016)", "doi": "10.1038/ncomms11729", "report-no": null, "categories": "cond-mat.stat-mech math.ST physics.data-an q-bio.QM stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex behaviour in many systems arises from the stochastic interactions of\nspatially distributed particles or agents. Stochastic reaction-diffusion\nprocesses are widely used to model such behaviour in disciplines ranging from\nbiology to the social sciences, yet they are notoriously difficult to simulate\nand calibrate to observational data. Here we use ideas from statistical physics\nand machine learning to provide a solution to the inverse problem of learning a\nstochastic reaction-diffusion process from data. Our solution relies on a\nnon-trivial connection between stochastic reaction-diffusion processes and\nspatio-temporal Cox processes, a well-studied class of models from\ncomputational statistics. This connection leads to an efficient and flexible\nalgorithm for parameter inference and model selection. Our approach shows\nexcellent accuracy on numeric and real data examples from systems biology and\nepidemiology. Our work provides both insights into spatio-temporal stochastic\nsystems, and a practical solution to a long-standing problem in computational\nmodelling.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jan 2016 18:44:03 GMT"}, {"version": "v2", "created": "Mon, 22 Aug 2016 15:41:23 GMT"}], "update_date": "2016-08-23", "authors_parsed": [["Schnoerr", "David", ""], ["Grima", "Ramon", ""], ["Sanguinetti", "Guido", ""]]}, {"id": "1601.02049", "submitter": "Rados{\\l}aw Adamczak", "authors": "Rados{\\l}aw Adamczak", "title": "A note on the sample complexity of the Er-SpUD algorithm by Spielman,\n  Wang and Wright for exact recovery of sparsely used dictionaries", "comments": "Minor typos corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of recovering an invertible $n \\times n$ matrix $A$\nand a sparse $n \\times p$ random matrix $X$ based on the observation of $Y =\nAX$ (up to a scaling and permutation of columns of $A$ and rows of $X$). Using\nonly elementary tools from the theory of empirical processes we show that a\nversion of the Er-SpUD algorithm by Spielman, Wang and Wright with high\nprobability recovers $A$ and $X$ exactly, provided that $p \\ge Cn\\log n$, which\nis optimal up to the constant $C$.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jan 2016 23:00:40 GMT"}, {"version": "v2", "created": "Tue, 12 Jan 2016 23:29:07 GMT"}], "update_date": "2016-01-14", "authors_parsed": [["Adamczak", "Rados\u0142aw", ""]]}, {"id": "1601.02068", "submitter": "Yining Wang", "authors": "Yining Wang and Adams Wei Yu and Aarti Singh", "title": "On Computationally Tractable Selection of Experiments in\n  Measurement-Constrained Regression Models", "comments": "41 pages. Accepted for publication in Journal of Machine Learning\n  Research", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive computationally tractable methods to select a small subset of\nexperiment settings from a large pool of given design points. The primary focus\nis on linear regression models, while the technique extends to generalized\nlinear models and Delta's method (estimating functions of linear regression\nmodels) as well. The algorithms are based on a continuous relaxation of an\notherwise intractable combinatorial optimization problem, with sampling or\ngreedy procedures as post-processing steps. Formal approximation guarantees are\nestablished for both algorithms, and numerical results on both synthetic and\nreal-world data confirm the effectiveness of the proposed methods.\n", "versions": [{"version": "v1", "created": "Sat, 9 Jan 2016 03:05:31 GMT"}, {"version": "v2", "created": "Wed, 27 Jan 2016 21:05:35 GMT"}, {"version": "v3", "created": "Tue, 5 Jul 2016 21:29:33 GMT"}, {"version": "v4", "created": "Fri, 2 Dec 2016 20:07:28 GMT"}, {"version": "v5", "created": "Fri, 24 Mar 2017 00:57:10 GMT"}, {"version": "v6", "created": "Wed, 20 Dec 2017 06:52:49 GMT"}], "update_date": "2017-12-21", "authors_parsed": [["Wang", "Yining", ""], ["Yu", "Adams Wei", ""], ["Singh", "Aarti", ""]]}, {"id": "1601.02121", "submitter": "Renato Pelessoni", "authors": "Ignacio Montes, Enrique Miranda, Renato Pelessoni, Paolo Vicig", "title": "Sklar's Theorem in an Imprecise Setting", "comments": "A definitive version has been published in a special issue on\n  uncertainty and imprecision modelling in decision making (EUROFUSE 2013) of\n  Fuzzy Sets and Systems", "journal-ref": "Fuzzy Sets and Systems, vol. 278, 1 November 2015, pages 48-66", "doi": "10.1016/j.fss.2014.10.007", "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sklar's theorem is an important tool that connects bidimensional distribution\nfunctions with their marginals by means of a copula. When there is imprecision\nabout the marginals, we can model the available information by means of\np-boxes, that are pairs of ordered distribution functions. Similarly, we can\nconsider a set of copulas instead of a single one. We study the extension of\nSklar's theorem under these conditions, and link the obtained results to\nstochastic ordering with imprecision.\n", "versions": [{"version": "v1", "created": "Sat, 9 Jan 2016 15:24:03 GMT"}], "update_date": "2016-01-12", "authors_parsed": [["Montes", "Ignacio", ""], ["Miranda", "Enrique", ""], ["Pelessoni", "Renato", ""], ["Vicig", "Paolo", ""]]}, {"id": "1601.02127", "submitter": "Michel Grabisch", "authors": "Michel Grabisch and Christophe Labreuche", "title": "A note on the Sobol' indices and interactive criteria", "comments": null, "journal-ref": null, "doi": null, "report-no": "hal-01253075", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Choquet integral and the Owen extension (or multilinear extension) are\nthe most popular tools in multicriteria decision making to take into account\nthe interaction between criteria. It is known that the interaction transform\nand the Banzhaf interaction transform arise as the average total variation of\nthe Choquet integral and multilinear extension respectively. We consider in\nthis note another approach to define interaction, by using the Sobol' indices\nwhich are related to the analysis of variance of a multivariate model. We prove\nthat the Sobol' indices of the multilinear extension gives the square of the\nFourier transform, a well-known concept in computer sciences. We also relate\nthe latter to the Banzhaf interaction transform and compute the Sobol' indices\nfor the 2-additive Choquet integral.\n", "versions": [{"version": "v1", "created": "Sat, 9 Jan 2016 16:26:57 GMT"}], "update_date": "2016-01-12", "authors_parsed": [["Grabisch", "Michel", ""], ["Labreuche", "Christophe", ""]]}, {"id": "1601.02177", "submitter": "Iosif Pinelis", "authors": "Iosif Pinelis", "title": "Optimal-order bounds on the rate of convergence to normality for maximum\n  likelihood estimators", "comments": "Version 2: It is shown in the added appendix that (under some\n  regularity conditions) certain structural assumptions used in certain\n  previous papers can only hold when the family of densities is a one-parameter\n  exponential one. Version 3: Condition (ix) in Proposition A.1 in Version 2 of\n  this paper is removed", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that under general regularity conditions the distribution of\nthe maximum likelihood estimator (MLE) is asymptotically normal. Very recently,\nbounds of the optimal order $O(1/\\sqrt n)$ on the closeness of the distribution\nof the MLE to normality in the so-called bounded Wasserstein distance were\nobtained, where $n$ is the sample size. However, the corresponding bounds on\nthe Kolmogorov distance were only of the order $O(1/n^{1/4})$. In this note,\nbounds of the optimal order $O(1/\\sqrt n)$ on the closeness of the distribution\nof the MLE to normality in the Kolmogorov distance are given, as well as their\nnonuniform counterparts, which work better for large deviations of the MLE.\nThese results are based on previously obtained general optimal-order bounds on\nthe rate of convergence to normality in the multivariate delta method. The\ncrucial observation is that, under natural conditions, the MLE can be tightly\nenough bracketed between two smooth enough functions of the sum of independent\nrandom vectors, which makes the delta method applicable.\n", "versions": [{"version": "v1", "created": "Sun, 10 Jan 2016 05:01:50 GMT"}, {"version": "v2", "created": "Mon, 12 Dec 2016 21:29:24 GMT"}, {"version": "v3", "created": "Wed, 14 Dec 2016 03:40:37 GMT"}], "update_date": "2016-12-15", "authors_parsed": [["Pinelis", "Iosif", ""]]}, {"id": "1601.02387", "submitter": "Guillaume Dehaene", "authors": "Guillaume P Dehaene and Simon Barthelm\\'e", "title": "Bounding errors of Expectation-Propagation", "comments": "Accepted and published at NIPS 2015", "journal-ref": "Advances in Neural Information Processing Systems 28, 244--252,\n  2015", "doi": null, "report-no": null, "categories": "stat.CO math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Expectation Propagation is a very popular algorithm for variational\ninference, but comes with few theoretical guarantees. In this article, we prove\nthat the approximation errors made by EP can be bounded. Our bounds have an\nasymptotic interpretation in the number $n$ of datapoints, which allows us to\nstudy EP's convergence with respect to the true posterior. In particular, we\nshow that EP converges at a rate of $\\mathcal{0}(n^{-2})$ for the mean, up to\nan order of magnitude faster than the traditional Gaussian approximation at the\nmode. We also give similar asymptotic expansions for moments of order 2 to 4,\nas well as excess Kullback-Leibler cost (defined as the additional KL cost\nincurred by using EP rather than the ideal Gaussian approximation). All these\nexpansions highlight the superior convergence properties of EP. Our approach\nfor deriving those results is likely applicable to many similar approximate\ninference methods. In addition, we introduce bounds on the moments of\nlog-concave distributions that may be of independent interest.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jan 2016 10:34:21 GMT"}], "update_date": "2016-01-12", "authors_parsed": [["Dehaene", "Guillaume P", ""], ["Barthelm\u00e9", "Simon", ""]]}, {"id": "1601.02640", "submitter": "Sharif Rahman", "authors": "Sharif Rahman, Xuchun Ren, and Vaibhav Yadav", "title": "High-Dimensional Stochastic Design Optimization by Adaptive-Sparse\n  Polynomial Dimensional Decomposition", "comments": "18 pages, 2 figures, to appear in Sparse Grids and\n  Applications--Stuttgart 2014, Lecture Notes in Computational Science and\n  Engineering 109, edited by J. Garcke and D. Pfl\\\"{u}ger, Springer\n  International Publishing, 2016", "journal-ref": null, "doi": "10.1007/978-3-319-28262-6", "report-no": null, "categories": "math.NA math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel adaptive-sparse polynomial dimensional\ndecomposition (PDD) method for stochastic design optimization of complex\nsystems. The method entails an adaptive-sparse PDD approximation of a\nhigh-dimensional stochastic response for statistical moment and reliability\nanalyses; a novel integration of the adaptive-sparse PDD approximation and\nscore functions for estimating the first-order design sensitivities of the\nstatistical moments and failure probability; and standard gradient-based\noptimization algorithms. New analytical formulae are presented for the design\nsensitivities that are simultaneously determined along with the moments or the\nfailure probability. Numerical results stemming from mathematical functions\nindicate that the new method provides more computationally efficient design\nsolutions than the existing methods. Finally, stochastic shape optimization of\na jet engine bracket with 79 variables was performed, demonstrating the power\nof the new method to tackle practical engineering problems.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jan 2016 21:05:05 GMT"}], "update_date": "2016-01-13", "authors_parsed": [["Rahman", "Sharif", ""], ["Ren", "Xuchun", ""], ["Yadav", "Vaibhav", ""]]}, {"id": "1601.02739", "submitter": "Wen-Xin Zhou", "authors": "Aurore Delaigle, Peter Hall, Wen-Xin Zhou", "title": "Nonparametric covariate-adjusted regression", "comments": "32 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider nonparametric estimation of a regression curve when the data are\nobserved with multiplicative distortion which depends on an observed\nconfounding variable. We suggest several estimators, ranging from a relatively\nsimple one that relies on restrictive assumptions usually made in the\nliterature, to a sophisticated piecewise approach that involves reconstructing\na smooth curve from an estimator of a constant multiple of its absolute value,\nand which can be applied in much more general scenarios. We show that, although\nour nonparametric estimators are constructed from predictors of the unobserved\nundistorted data, they have the same first order asymptotic properties as the\nstandard estimators that could be computed if the undistorted data were\navailable. We illustrate the good numerical performance of our methods on both\nsimulated and real datasets.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2016 06:06:42 GMT"}], "update_date": "2016-01-13", "authors_parsed": [["Delaigle", "Aurore", ""], ["Hall", "Peter", ""], ["Zhou", "Wen-Xin", ""]]}, {"id": "1601.02762", "submitter": "Thanh Mai Pham Ngoc", "authors": "Micha\\\"el Chichignoud, Van Ha Hoang (LPP), Thanh Mai Pham Ngoc\n  (LM-Orsay), Vincent Rivoirard (CEREMADE)", "title": "Adaptive wavelet multivariate regression with errors in variables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the multidimensional setting, we consider the errors-in-variables model.\nWe aim at estimating the unknown nonparametric multivariate regression function\nwith errors in the covariates. We devise an adaptive estimator based on\nprojection kernels on wavelets and a deconvolution operator. We propose an\nautomatic and fully data driven procedure to select the wavelet level\nresolution. We obtain an oracle inequality and optimal rates of convergence\nover anisotropic H{\\\"o}lder classes. Our theoretical results are illustrated by\nsome simulations.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2016 08:19:53 GMT"}], "update_date": "2016-01-13", "authors_parsed": [["Chichignoud", "Micha\u00ebl", "", "LPP"], ["Hoang", "Van Ha", "", "LPP"], ["Ngoc", "Thanh Mai Pham", "", "LM-Orsay"], ["Rivoirard", "Vincent", "", "CEREMADE"]]}, {"id": "1601.02798", "submitter": "Alois Kneip", "authors": "Alois Kneip, Dominik Po{\\ss}, Pascal Sarda", "title": "Functional linear regression with points of impact", "comments": "Published at http://dx.doi.org/10.1214/15-AOS1323 in the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2016, Vol. 44, No. 1, 1-30", "doi": "10.1214/15-AOS1323", "report-no": "IMS-AOS-AOS1323", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper considers functional linear regression, where scalar responses\n$Y_1,\\ldots,Y_n$ are modeled in dependence of i.i.d. random functions\n$X_1,\\ldots,X_n$. We study a generalization of the classical functional linear\nregression model. It is assumed that there exists an unknown number of \"points\nof impact,\" that is, discrete observation times where the corresponding\nfunctional values possess significant influences on the response variable. In\naddition to estimating a functional slope parameter, the problem then is to\ndetermine the number and locations of points of impact as well as corresponding\nregression coefficients. Identifiability of the generalized model is considered\nin detail. It is shown that points of impact are identifiable if the underlying\nprocess generating $X_1,\\ldots,X_n$ possesses \"specific local variation.\"\nExamples are well-known processes like the Brownian motion, fractional Brownian\nmotion or the Ornstein-Uhlenbeck process. The paper then proposes an easily\nimplementable method for estimating the number and locations of points of\nimpact. It is shown that this number can be estimated consistently.\nFurthermore, rates of convergence for location estimates, regression\ncoefficients and the slope parameter are derived. Finally, some simulation\nresults as well as a real data application are presented.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2016 10:48:48 GMT"}], "update_date": "2016-01-13", "authors_parsed": [["Kneip", "Alois", ""], ["Po\u00df", "Dominik", ""], ["Sarda", "Pascal", ""]]}, {"id": "1601.02804", "submitter": "Alexis Decurninge", "authors": "Alexis Decurninge, Fr\\'ed\\'eric Barbaresco", "title": "Robust Burg Estimation of Radar Scatter Matrix for Autoregressive\n  structured SIRV based on Fr\\'echet medians", "comments": "24 pages, submitted to IET Radar Sonar & Navigation", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the estimation of the scatter matrix of a scale mixture of\nGaussian stationary autoregressive vectors. This is equivalent to consider the\nestimation of a structured scatter matrix of a Spherically Invariant Random\nVector (SIRV) whose structure comes from an autoregressive modelization. The\nToeplitz structure representative of stationary models is a particular case for\nthe class of structures we consider. For Gaussian autoregressive processes,\nBurg method is often used in case of stationarity for its efficiency when few\nsamples are available. Unfortunately, if we directly apply these methods to\nestimate the common scatter matrix of N vectors coming from a non-Gaussian\ndistribution, their efficiency will strongly decrease. We propose then to adapt\nthese methods to scale mixtures of autoregressive vectors by changing the\nenergy functional minimized in the Burg algorithm. Moreover, we study several\napproaches of robust modification of the introduced Burg algorithms, based on\nFr\\'echet medians defined for the Euclidean or the Poincar\\'e metric, in\npresence of outliers or contaminating distributions. The considered structured\nmodelization is motivated by radar applications, the performances of our\nmethods will then be compared to the very popular Fixed Point estimator and\nOS-CFAR detector through radar simulated scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2016 11:26:00 GMT"}, {"version": "v2", "created": "Mon, 25 Jan 2016 14:27:10 GMT"}, {"version": "v3", "created": "Thu, 28 Jan 2016 14:16:24 GMT"}, {"version": "v4", "created": "Fri, 6 May 2016 15:39:43 GMT"}], "update_date": "2016-05-09", "authors_parsed": [["Decurninge", "Alexis", ""], ["Barbaresco", "Fr\u00e9d\u00e9ric", ""]]}, {"id": "1601.02844", "submitter": "Claudio Durastanti Dr.", "authors": "Claudio Durastanti", "title": "Adaptive global thresholding on the sphere", "comments": "36 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work is concerned with the study of the adaptivity properties of\nnonparametric regression estimators over the $d$-dimensional sphere within the\nglobal thresholding framework. The estimators are constructed by means of a\nform of spherical wavelets, the so-called needlets, which enjoy strong\nconcentration properties in both harmonic and real domains. The author\nestablishes the convergence rates of the $L^p$-risks of these estimators,\nfocussing on their minimax properties and proving their optimality over a scale\nof nonparametric regularity function spaces, namely, the Besov spaces.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2016 13:12:25 GMT"}, {"version": "v2", "created": "Tue, 26 Jul 2016 11:25:45 GMT"}], "update_date": "2016-07-27", "authors_parsed": [["Durastanti", "Claudio", ""]]}, {"id": "1601.02869", "submitter": "Alexander Petersen", "authors": "Alexander Petersen, Hans-Georg M\\\"uller", "title": "Functional data analysis for density functions by transformation to a\n  Hilbert space", "comments": "Published at http://dx.doi.org/10.1214/15-AOS1363 in the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2016, Vol. 44, No. 1, 183-218", "doi": "10.1214/15-AOS1363", "report-no": "IMS-AOS-AOS1363", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Functional data that are nonnegative and have a constrained integral can be\nconsidered as samples of one-dimensional density functions. Such data are\nubiquitous. Due to the inherent constraints, densities do not live in a vector\nspace and, therefore, commonly used Hilbert space based methods of functional\ndata analysis are not applicable. To address this problem, we introduce a\ntransformation approach, mapping probability densities to a Hilbert space of\nfunctions through a continuous and invertible map. Basic methods of functional\ndata analysis, such as the construction of functional modes of variation,\nfunctional regression or classification, are then implemented by using\nrepresentations of the densities in this linear space. Representations of the\ndensities themselves are obtained by applying the inverse map from the linear\nfunctional space to the density space. Transformations of interest include log\nquantile density and log hazard transformations, among others. Rates of\nconvergence are derived for the representations that are obtained for a general\nclass of transformations under certain structural properties. If the\nsubject-specific densities need to be estimated from data, these rates\ncorrespond to the optimal rates of convergence for density estimation. The\nproposed methods are illustrated through simulations and applications in brain\nimaging.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2016 14:13:52 GMT"}], "update_date": "2016-01-13", "authors_parsed": [["Petersen", "Alexander", ""], ["M\u00fcller", "Hans-Georg", ""]]}, {"id": "1601.03379", "submitter": "Georgios Fellouris Dr.", "authors": "Georgios Fellouris and Alexander G. Tartakovsky", "title": "Multichannel Sequential Detection- Part I: Non-i.i.d. Data", "comments": "35 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of sequential signal detection in a multichannel\nsystem where the number and location of signals is a priori unknown. We assume\nthat the data in each channel are sequentially observed and follow a general\nnon-i.i.d. stochastic model. Under the assumption that the local log-likelihood\nratio processes in the channels converge r-completely to positive and finite\nnumbers, we establish the asymptotic optimality of a generalized sequential\nlikelihood ratio test and a mixture-based sequential likelihood ratio test.\nSpecifically, we show that both tests minimize the first r moments of the\nstopping time distribution asymptotically as the probabilities of false alarm\nand missed detection approach zero. Moreover, we show that both tests\nasymptotically minimize all moments of the stopping time distribution when the\nlocal log-likelihood ratio processes have independent increments and simply\nobey the Strong Law of Large Numbers. This extends a result previously known in\nthe case of i.i.d. observations when only one channel is affected. We\nillustrate the general detection theory using several practical examples,\nincluding the detection of signals in Gaussian hidden Markov models, white\nGaussian noises with unknown intensity, and testing of the first-order\nautoregression's correlation coefficient. Finally, we illustrate the\nfeasibility of both sequential tests when assuming an upper and a lower bound\non the number of signals and compare their non-asymptotic performance using a\nsimulation study.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2016 20:46:29 GMT"}], "update_date": "2016-01-14", "authors_parsed": [["Fellouris", "Georgios", ""], ["Tartakovsky", "Alexander G.", ""]]}, {"id": "1601.03524", "submitter": "Frederik Riis Mikkelsen", "authors": "Frederik Riis Mikkelsen and Niels Richard Hansen", "title": "Degrees of Freedom for Piecewise Lipschitz Estimators", "comments": "113 pages, 89 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A representation of the degrees of freedom akin to Stein's lemma is given for\na class of estimators of a mean value parameter in $\\mathbb{R}^n$. Contrary to\nprevious results our representation holds for a range of discontinues\nestimators. It shows that even though the discontinuities form a Lebesgue null\nset, they cannot be ignored when computing degrees of freedom. Estimators with\ndiscontinuities arise naturally in regression if data driven variable selection\nis used. Two such examples, namely best subset selection and lasso-OLS, are\nconsidered in detail in this paper. For lasso-OLS the general representation\nleads to an estimate of the degrees of freedom based on the lasso solution\npath, which in turn can be used for estimating the risk of lasso-OLS. A similar\nestimate is proposed for best subset selection. The usefulness of the risk\nestimates for selecting the number of variables is demonstrated via simulations\nwith a particular focus on lasso-OLS.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jan 2016 09:28:25 GMT"}, {"version": "v2", "created": "Fri, 10 Jun 2016 14:24:20 GMT"}, {"version": "v3", "created": "Fri, 10 Feb 2017 08:16:07 GMT"}], "update_date": "2017-02-13", "authors_parsed": [["Mikkelsen", "Frederik Riis", ""], ["Hansen", "Niels Richard", ""]]}, {"id": "1601.03614", "submitter": "Yuta Koike", "authors": "Yuta Koike", "title": "On the asymptotic structure of Brownian motions with a small lead-lag\n  effect", "comments": "24 pages", "journal-ref": "Journal of the Japan Statistical Society 47 (2017), no.2, 1-31", "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers two Brownian motions in a situation where one is\ncorrelated to the other with a slight delay. We study the problem of estimating\nthe time lag parameter between these Brownian motions from their high-frequency\nobservations, which are possibly subject to measurement errors. The measurement\nerrors are assumed to be i.i.d., centered Gaussian and independent of the\nlatent processes. We investigate the asymptotic structure of the likelihood\nratio process for this model when the lag parameter is asymptotically\ninfinitesimal. We show that the structure of the limit experiment depends on\nthe level of the measurement errors: If the measurement errors locally dominate\nthe latent Brownian motions, the model enjoys the LAN property. Otherwise, the\nlimit experiment does not result in typical ones appearing in the literature.\nThe proof is based on the fact that the model is asymptotically equivalent to\ndiscrete observations of two Brownian motions under endogenous measurement\nerrors. We also discuss the efficient estimation of the lag parameter to\nhighlight the statistical implications.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jan 2016 15:10:41 GMT"}, {"version": "v2", "created": "Sun, 8 Apr 2018 10:18:15 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Koike", "Yuta", ""]]}, {"id": "1601.03704", "submitter": "Florencia Leonardi", "authors": "Florencia Leonardi and Peter B\\\"uhlmann", "title": "Computationally efficient change point detection for high-dimensional\n  regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale sequential data is often exposed to some degree of inhomogeneity\nin the form of sudden changes in the parameters of the data-generating process.\nWe consider the problem of detecting such structural changes in a\nhigh-dimensional regression setting. We propose a joint estimator of the number\nand the locations of the change points and of the parameters in the\ncorresponding segments. The estimator can be computed using dynamic programming\nor, as we emphasize here, it can be approximated using a binary search\nalgorithm with $O(n \\log(n) \\mathrm{Lasso}(n))$ computational operations while\nstill enjoying essentially the same theoretical properties; here\n$\\mathrm{Lasso}(n)$ denotes the computational cost of computing the Lasso for\nsample size $n$. We establish oracle inequalities for the estimator as well as\nfor its binary search approximation, covering also the case with a large\n(asymptotically growing) number of change points. We evaluate the performance\nof the proposed estimation algorithms on simulated data and apply the\nmethodology to real data.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jan 2016 19:30:44 GMT"}], "update_date": "2016-01-15", "authors_parsed": [["Leonardi", "Florencia", ""], ["B\u00fchlmann", "Peter", ""]]}, {"id": "1601.03822", "submitter": "Hossein Keshavarz", "authors": "Hossein Keshavarz, Clayton Scott, XuanLong Nguyen", "title": "On the consistency of inversion-free parameter estimation for Gaussian\n  random fields", "comments": "41 pages, 2 Figures", "journal-ref": "Journal of Multivariate Analysis (2016), pp. 245-266", "doi": "10.1016/j.jmva.2016.06.003", "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian random fields are a powerful tool for modeling environmental\nprocesses. For high dimensional samples, classical approaches for estimating\nthe covariance parameters require highly challenging and massive computations,\nsuch as the evaluation of the Cholesky factorization or solving linear systems.\nRecently, Anitescu, Chen and Stein \\cite{M.Anitescu} proposed a fast and\nscalable algorithm which does not need such burdensome computations. The main\nfocus of this article is to study the asymptotic behavior of the algorithm of\nAnitescu et al. (ACS) for regular and irregular grids in the increasing domain\nsetting. Consistency, minimax optimality and asymptotic normality of this\nalgorithm are proved under mild differentiability conditions on the covariance\nfunction. Despite the fact that ACS's method entails a non-concave\nmaximization, our results hold for any stationary point of the objective\nfunction. A numerical study is presented to evaluate the efficiency of this\nalgorithm for large data sets.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jan 2016 05:47:29 GMT"}, {"version": "v2", "created": "Tue, 21 Jun 2016 04:26:08 GMT"}], "update_date": "2016-10-05", "authors_parsed": [["Keshavarz", "Hossein", ""], ["Scott", "Clayton", ""], ["Nguyen", "XuanLong", ""]]}, {"id": "1601.03868", "submitter": "Aleksey Polunchenko", "authors": "Aleksey S. Polunchenko and Grigory Sokolov", "title": "An Analytic Expression for the Distribution of the Generalized\n  Shiryaev-Roberts Diffusion", "comments": "45 pages; 8 figures; to appear in Methodology and Computing in\n  Applied Probability", "journal-ref": null, "doi": "10.1007/s11009-016-9478-7", "report-no": null, "categories": "stat.ME math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the quickest change-point detection problem where the aim is to\ndetect the onset of a pre-specified drift in \"live\"-monitored standard Brownian\nmotion; the change-point is assumed unknown (nonrandom). The topic of interest\nis the distribution of the Generalized Shryaev-Roberts (GSR) detection\nstatistic set up to \"sense\" the presence of the drift. Specifically, we derive\na closed-form formula for the transition probability density function (pdf) of\nthe time-homogeneous Markov diffusion process generated by the GSR statistic\nwhen the Brownian motion under surveillance is \"drift-free\", i.e., in the\npre-change regime; the GSR statistic's (deterministic) nonnegative headstart is\nassumed arbitrarily given. The transition pdf formula is found analytically,\nthrough direct solution of the respective Kolmogorov forward equation via the\nFourier spectral method to achieve separation of the spacial and temporal\nvariables. The obtained result generalizes the well-known formula for the\n(pre-change) stationary distribution of the GSR statistic: the latter's\nstationary distribution is the temporal limit of the distribution sought in\nthis work. To conclude, we exploit the obtained formula numerically and briefly\nstudy the pre-change behavior of the GSR statistic versus three factors: (a)\ndrift-shift magnitude, (b) time, and (c) the GSR statistic's headstart.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jan 2016 10:46:31 GMT"}], "update_date": "2016-01-18", "authors_parsed": [["Polunchenko", "Aleksey S.", ""], ["Sokolov", "Grigory", ""]]}, {"id": "1601.03900", "submitter": "Lee H. Dicker", "authors": "Lee H. Dicker", "title": "Ridge regression and asymptotic minimax estimation over spheres of\n  growing dimension", "comments": "Published at http://dx.doi.org/10.3150/14-BEJ609 in the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2016, Vol. 22, No. 1, 1-37", "doi": "10.3150/14-BEJ609", "report-no": "IMS-BEJ-BEJ609", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study asymptotic minimax problems for estimating a $d$-dimensional\nregression parameter over spheres of growing dimension ($d\\to \\infty$).\nAssuming that the data follows a linear model with Gaussian predictors and\nerrors, we show that ridge regression is asymptotically minimax and derive new\nclosed form expressions for its asymptotic risk under squared-error loss. The\nasymptotic risk of ridge regression is closely related to the Stieltjes\ntransform of the Mar\\v{c}enko-Pastur distribution and the spectral distribution\nof the predictors from the linear model. Adaptive ridge estimators are also\nproposed (which adapt to the unknown radius of the sphere) and connections with\nequivariant estimation are highlighted. Our results are mostly relevant for\nasymptotic settings where the number of observations, $n$, is proportional to\nthe number of predictors, that is, $d/n\\to\\rho\\in(0,\\infty)$.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jan 2016 13:07:53 GMT"}], "update_date": "2016-01-18", "authors_parsed": [["Dicker", "Lee H.", ""]]}, {"id": "1601.03906", "submitter": "Simon Guillotte", "authors": "Simon Guillotte, Fran\\c{c}ois Perron", "title": "Polynomial Pickands functions", "comments": "Published at http://dx.doi.org/10.3150/14-BEJ656 in the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2016, Vol. 22, No. 1, 213-241", "doi": "10.3150/14-BEJ656", "report-no": "IMS-BEJ-BEJ656", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pickands dependence functions characterize bivariate extreme value copulas.\nIn this paper, we study the class of polynomial Pickands functions. We provide\na solution for the characterization of such polynomials of degree at most\n$m+2$, $m\\geq0$, and show that these can be parameterized by a vector in\n$\\mathbb{R}^{m+1}$ belonging to the intersection of two ellipsoids. We also\nstudy the class of Bernstein approximations of order $m+2$ of Pickands\nfunctions which are shown to be (polynomial) Pickands functions and\nparameterized by a vector in $\\mathbb{R}^{m+1}$ belonging to a polytope. We\ngive necessary and sufficient conditions for which a polynomial Pickands\nfunction is in fact a Bernstein approximation of some Pickands function.\nApproximation results of Pickands dependence functions by polynomials are\ngiven. Finally, inferential methodology is discussed and comparisons based on\nsimulated data are provided.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jan 2016 13:23:58 GMT"}], "update_date": "2016-01-18", "authors_parsed": [["Guillotte", "Simon", ""], ["Perron", "Fran\u00e7ois", ""]]}, {"id": "1601.04189", "submitter": "Damiano  Brigo", "authors": "Damiano Brigo, Giovanni Pistone", "title": "Projection based dimensionality reduction for measure valued evolution\n  equations in statistical manifolds", "comments": "Added maximum likelihood theorem and projection approximation\n  analysis. Updated version to appear in: Nielsen, F., Critchley, F., & Dodson,\n  K. (Eds), Computational Information Geometry for Image and Signal Processing,\n  Springer Verlag, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a dimensionality reduction method for infinite-dimensional\nmeasure-valued evolution equations such as the Fokker-Planck partial\ndifferential equation or the Kushner-Stratonovich resp. Duncan-Mortensen-Zakai\nstochastic partial differential equations of nonlinear filtering, with\npotential applications to signal processing, quantitative finance, heat flows\nand quantum theory among many other areas. Our method is based on the\nprojection coming from a duality argument built in the exponential statistical\nmanifold structure developed by G. Pistone and co-authors. The choice of the\nfinite dimensional manifold on which one should project the infinite\ndimensional equation is crucial, and we propose finite dimensional exponential\nand mixture families. This same problem had been studied, especially in the\ncontext of nonlinear filtering, by D. Brigo and co-authors but the $L^2$\nstructure on the space of square roots of densities or of densities themselves\nwas used, without taking an infinite dimensional manifold environment space for\nthe equation to be projected. Here we re-examine such works from the\nexponential statistical manifold point of view, which allows for a deeper\ngeometric understanding of the manifold structures at play. We also show that\nthe projection in the exponential manifold structure is consistent with the\nFisher Rao metric and, in case of finite dimensional exponential families, with\nthe assumed density approximation. Further, we show that if the sufficient\nstatistics of the finite dimensional exponential family are chosen among the\neigenfunctions of the backward diffusion operator then the statistical-manifold\nor Fisher-Rao projection provides the maximum likelihood estimator for the\nFokker Planck equation solution. We finally try to clarify how the finite\ndimensional and infinite dimensional terminology for exponential and mixture\nspaces are related.\n", "versions": [{"version": "v1", "created": "Sat, 16 Jan 2016 17:57:13 GMT"}, {"version": "v2", "created": "Wed, 2 Mar 2016 14:55:02 GMT"}, {"version": "v3", "created": "Wed, 26 Oct 2016 15:55:18 GMT"}], "update_date": "2016-10-27", "authors_parsed": [["Brigo", "Damiano", ""], ["Pistone", "Giovanni", ""]]}, {"id": "1601.04262", "submitter": "Aleksey Polunchenko", "authors": "Aleksey S. Polunchenko", "title": "Exact Distribution of the Generalized Shiryaev-Roberts Stopping Time\n  Under the Minimax Brownian Motion Setup", "comments": "39 pages; 13 figures", "journal-ref": "Sequential Analysis, vol. 35, no. 1, pp. 108-143, 2016", "doi": "10.1080/07474946.2016.1132066", "report-no": null, "categories": "math.ST stat.CO stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the quickest change-point detection problem where the aim is to\ndetect the onset of a pre-specified drift in \"live\"-monitored standard Brownian\nmotion; the change-point is assumed unknown (nonrandom). The object of interest\nis the distribution of the stopping time associated with the Generalized\nShryaev-Roberts (GSR) detection procedure set up to \"sense\" the presence of the\ndrift in the Brownian motion under surveillance. Specifically, we seek the GSR\nstopping time's survival function (the tail probability that no alarm is\ntriggered by the GSR procedure prior to a given point in time), and distinguish\ntwo scenarios: (a) when the drift never sets in (pre-change regime) and (b)\nwhen the drift is in effect ab initio (post-change regime). Under each\nscenario, we obtain a closed-form formula for the respective survival function,\nwith the GSR statistic's (deterministic) nonnegative headstart assumed\narbitrarily given. The two formulae are found analytically, through direct\nsolution of the respective Kolmogorov forward equation via the Fourier spectral\nmethod to achieve separation of the spacial and temporal variables. We then\nexploit the obtained formulae numerically and characterize the pre- and\npost-change distributions of the GSR stopping time depending on three factors:\n(a) magnitude of the drift, (b) detection threshold, and (c) the GSR\nstatistic's headstart.\n", "versions": [{"version": "v1", "created": "Sun, 17 Jan 2016 08:37:06 GMT"}, {"version": "v2", "created": "Mon, 18 Apr 2016 18:27:49 GMT"}], "update_date": "2016-04-19", "authors_parsed": [["Polunchenko", "Aleksey S.", ""]]}, {"id": "1601.04355", "submitter": "Madalin Guta", "authors": "Madalin Guta and Jukka Kiukas", "title": "Information geometry and local asymptotic normality for multi-parameter\n  estimation of quantum Markov dynamics", "comments": "28 pages, 4 figures", "journal-ref": "Journal of Mathematical Physics 58, 052201 (2017)", "doi": "10.1063/1.4982958", "report-no": null, "categories": "quant-ph math-ph math.MP math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with the problem of identifying and estimating dynamical\nparameters of continuous-time quantum open systems, in the input-output\nformalism. First, we characterise the space of identifiable parameters for\nergodic dynamics, assuming full access to the output state for arbitrarily long\ntimes, and show that the equivalence classes of undistinguishable parameters\nare orbits of a Lie group acting on the space of dynamical parameters. Second,\nwe define an information geometric structure on this space, including a\nprincipal bundle given by the action of the group, as well as a compatible\nconnection, and a Riemannian metric based on the quantum Fisher information of\nthe output. We compute the metric explicitly in terms of the Markov covariance\nof certain \"fluctuation operators\", and relate it to the horizontal bundle of\nthe connection. Third, we show that the system-output and reduced output state\nsatisfy local asymptotic normality, i.e. they can be approximated by a Gaussian\nmodel consisting of coherent states of a multimode continuos variables system\nconstructed from the Markov covariance \"data\". We illustrate the result by\nworking out the details of the information geometry of a physically relevant\ntwo-level system.\n", "versions": [{"version": "v1", "created": "Sun, 17 Jan 2016 21:41:29 GMT"}, {"version": "v2", "created": "Mon, 7 Mar 2016 16:45:06 GMT"}], "update_date": "2019-01-04", "authors_parsed": [["Guta", "Madalin", ""], ["Kiukas", "Jukka", ""]]}, {"id": "1601.04650", "submitter": "Madhu Advani", "authors": "Madhu Advani and Surya Ganguli", "title": "Statistical Mechanics of High-Dimensional Inference", "comments": "See http://ganguli-gang.stanford.edu/pdf/HighDimInf.Supp.pdf for\n  supplementary material", "journal-ref": "Phys. Rev. X 6, 031034 (2016)", "doi": "10.1103/PhysRevX.6.031034", "report-no": null, "categories": "stat.ML cond-mat.dis-nn cond-mat.stat-mech math.ST q-bio.QM stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To model modern large-scale datasets, we need efficient algorithms to infer a\nset of $P$ unknown model parameters from $N$ noisy measurements. What are\nfundamental limits on the accuracy of parameter inference, given finite\nsignal-to-noise ratios, limited measurements, prior information, and\ncomputational tractability requirements? How can we combine prior information\nwith measurements to achieve these limits? Classical statistics gives incisive\nanswers to these questions as the measurement density $\\alpha =\n\\frac{N}{P}\\rightarrow \\infty$. However, these classical results are not\nrelevant to modern high-dimensional inference problems, which instead occur at\nfinite $\\alpha$. We formulate and analyze high-dimensional inference as a\nproblem in the statistical physics of quenched disorder. Our analysis uncovers\nfundamental limits on the accuracy of inference in high dimensions, and reveals\nthat widely cherished inference algorithms like maximum likelihood (ML) and\nmaximum-a posteriori (MAP) inference cannot achieve these limits. We further\nfind optimal, computationally tractable algorithms that can achieve these\nlimits. Intriguingly, in high dimensions, these optimal algorithms become\ncomputationally simpler than MAP and ML, while still outperforming them. For\nexample, such optimal algorithms can lead to as much as a 20% reduction in the\namount of data to achieve the same performance relative to MAP. Moreover, our\nanalysis reveals simple relations between optimal high dimensional inference\nand low dimensional scalar Bayesian inference, insights into the nature of\ngeneralization and predictive power in high dimensions, information theoretic\nlimits on compressed sensing, phase transitions in quadratic inference, and\nconnections to central mathematical objects in convex optimization theory and\nrandom matrix theory.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2016 18:38:35 GMT"}, {"version": "v2", "created": "Mon, 22 Feb 2016 03:10:56 GMT"}], "update_date": "2016-09-07", "authors_parsed": [["Advani", "Madhu", ""], ["Ganguli", "Surya", ""]]}, {"id": "1601.04731", "submitter": "Farbod Roosta-Khorasani", "authors": "Farbod Roosta-Khorasani and Gabor J. Szekely", "title": "Schur properties of convolutions of gamma random variables", "comments": null, "journal-ref": "Metrika 78(8):997-1014, 2015", "doi": "10.1007/s00184-015-0537-9", "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sufficient conditions for comparing the convolutions of heterogeneous gamma\nrandom variables in terms of the usual stochastic order are established. Such\ncomparisons are characterized by the Schur convexity properties of the\ncumulative distribution function of the convolutions. Some examples of the\npractical applications of our results are given.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2016 21:40:23 GMT"}], "update_date": "2016-01-20", "authors_parsed": [["Roosta-Khorasani", "Farbod", ""], ["Szekely", "Gabor J.", ""]]}, {"id": "1601.05033", "submitter": "Kevin McGoff", "authors": "Kevin McGoff and Andrew B. Nobel", "title": "Variational analysis of inference from dynamical systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.DS math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce and study a variational framework for the analysis of empirical\nrisk based inference for dynamical systems and ergodic processes. The analysis\napplies to a two-stage estimation procedure in which (i) the trajectory of an\nobserved (but unknown) system is fit to a trajectory from a known reference\nsystem by minimizing cumulative per-state loss, and (ii) a parameter estimate\nis obtained from the initial state of the best fit reference trajectory. We\nshow that the empirical risk of the best fit trajectory converges almost surely\nto a constant that can be expressed in a variational form as the minimal\nexpected loss over dynamically invariant couplings (joinings) of the observed\nand reference systems. Moreover, we establish that the family of joinings\nminimizing the expected loss is convex and compact, and that it fully\ncharacterizes the asymptotic behavior of the estimated parameters, addressing\nboth identifiability and misspecification. The two-stage estimation framework\nand associated variational analysis apply to a broad family of empirical risk\nmiminization procedures for dependent observations. To illustrate this, we\napply variational analysis to the well studied problems of maximum likelihood\nand non-linear regression, and then undertake an extended analysis of system\nidentification from quantized trajectories subject to noise, a problem of\ninterest in dynamics, where the models themselves exhibit dynamical behavior\nacross time.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jan 2016 18:49:08 GMT"}, {"version": "v2", "created": "Tue, 20 Sep 2016 14:27:06 GMT"}, {"version": "v3", "created": "Wed, 7 Jun 2017 00:54:39 GMT"}, {"version": "v4", "created": "Tue, 23 Jan 2018 15:52:54 GMT"}], "update_date": "2018-01-24", "authors_parsed": [["McGoff", "Kevin", ""], ["Nobel", "Andrew B.", ""]]}, {"id": "1601.05053", "submitter": "Yogendra Chaubey", "authors": "Yogendra P. Chaubey", "title": "Smooth Kernel Estimation of a Circular Density Function: A Connection to\n  Orthogonal Polynomials on the Unit Circle", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note we provide a simple approximation theory motivation for the\ncircular kernel density estimation and further explore the usefulness of the\nwrapped Cauchy kernel in this context. It is seen that the wrapped Cauchy\nkernel appears as a natural candidate in connection to orthogonal series\ndensity estimation on a unit circle. This adds further weight to the\nconsiderable role of the wrapped Cauchy in circular statistics.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jan 2016 19:53:50 GMT"}], "update_date": "2016-01-20", "authors_parsed": [["Chaubey", "Yogendra P.", ""]]}, {"id": "1601.05155", "submitter": "Peng Ding", "authors": "Peng Ding, Tyler J. VanderWeele", "title": "Sharp sensitivity bounds for mediation under unmeasured mediator-outcome\n  confounding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is often of interest to decompose a total effect of an exposure into the\ncomponent that acts on the outcome through some mediator and the component that\nacts independently through other pathways. Said another way, we are interested\nin the direct and indirect effects of the exposure on the outcome. Even if the\nexposure is randomly assigned, it is often infeasible to randomize the\nmediator, leaving the mediator-outcome confounding not fully controlled. We\ndevelop a sensitivity analysis technique that can bound the direct and indirect\neffects without parametric assumptions about the unmeasured mediator-outcome\nconfounding.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jan 2016 03:03:37 GMT"}], "update_date": "2016-01-21", "authors_parsed": [["Ding", "Peng", ""], ["VanderWeele", "Tyler J.", ""]]}, {"id": "1601.05261", "submitter": "Henryk Z\\\"ahle", "authors": "Volker Kr\\\"atschmer and Henryk Z\\\"ahle", "title": "Statistical inference for expectile-based risk measures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Expectiles were introduced by Newey and Powell (1987) in the context of\nlinear regression models. Recently, Bellini et al. (2014) revealed that\nexpectiles can also be seen as reasonable law-invariant risk measures. In this\narticle, we show that the corresponding statistical functionals are continuous\nw.r.t. the $1$-weak topology and suitably functionally differentiable. By means\nof these regularity results we can derive several properties as consistency,\nasymptotic normality, bootstrap consistency, and qualitative robustness of the\ncorresponding estimators in nonparametric and parametric statistical models.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jan 2016 13:03:28 GMT"}, {"version": "v2", "created": "Tue, 13 Sep 2016 13:13:43 GMT"}, {"version": "v3", "created": "Tue, 20 Sep 2016 13:01:54 GMT"}], "update_date": "2016-09-21", "authors_parsed": [["Kr\u00e4tschmer", "Volker", ""], ["Z\u00e4hle", "Henryk", ""]]}, {"id": "1601.05388", "submitter": "Steven N. Evans", "authors": "Joshua G. Schraiber and Steven N. Evans and Montgomery Slatkin", "title": "Bayesian inference of natural selection from allele frequency time\n  series", "comments": "27 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advent of accessible ancient DNA technology now allows the direct\nascertainment of allele frequencies in ancestral populations, thereby enabling\nthe use of allele frequency time series to detect and estimate natural\nselection. Such direct observations of allele frequency dynamics are expected\nto be more powerful than inferences made using patterns of linked neutral\nvariation obtained from modern individuals. We develop a Bayesian method to\nmake use of allele frequency time series data and infer the parameters of\ngeneral diploid selection, along with allele age, in non-equilibrium\npopulations. We introduce a novel path augmentation approach, in which we use\nMarkov chain Monte Carlo to integrate over the space of allele frequency\ntrajectories consistent with the observed data. Using simulations, we show that\nthis approach has good power to estimate selection coefficients and allele age.\nMoreover, when applying our approach to data on horse coat color, we find that\nignoring a relevant demographic history can significantly bias the results of\ninference. Our approach is made available in a C++ software package.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jan 2016 19:48:24 GMT"}], "update_date": "2016-01-21", "authors_parsed": [["Schraiber", "Joshua G.", ""], ["Evans", "Steven N.", ""], ["Slatkin", "Montgomery", ""]]}, {"id": "1601.05557", "submitter": "Ilias Diakonikolas", "authors": "Ilias Diakonikolas, Daniel M. Kane", "title": "A New Approach for Testing Properties of Discrete Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we give a novel general approach for distribution testing. We\ndescribe two techniques: our first technique gives sample-optimal testers,\nwhile our second technique gives matching sample lower bounds. As a\nconsequence, we resolve the sample complexity of a wide variety of testing\nproblems.\n  Our upper bounds are obtained via a modular reduction-based approach. Our\napproach yields optimal testers for numerous problems by using a standard\n$\\ell_2$-identity tester as a black-box. Using this recipe, we obtain simple\nestimators for a wide range of problems, encompassing most problems previously\nstudied in the TCS literature, namely: (1) identity testing to a fixed\ndistribution, (2) closeness testing between two unknown distributions (with\nequal/unequal sample sizes), (3) independence testing (in any number of\ndimensions), (4) closeness testing for collections of distributions, and (5)\ntesting histograms. For all of these problems, our testers are sample-optimal,\nup to constant factors. With the exception of (1), ours are the {\\em first\nsample-optimal testers for the corresponding problems.} Moreover, our\nestimators are significantly simpler to state and analyze compared to previous\nresults.\n  As an application of our reduction-based technique, we obtain the first {\\em\nnearly instance-optimal} algorithm for testing equivalence between two {\\em\nunknown} distributions. Moreover, our technique naturally generalizes to other\nmetrics beyond the $\\ell_1$-distance.\n  Our lower bounds are obtained via a direct information-theoretic approach:\nGiven a candidate hard instance, our proof proceeds by bounding the mutual\ninformation between appropriate random variables. While this is a classical\nmethod in information theory, prior to our work, it had not been used in\ndistribution property testing.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2016 09:06:17 GMT"}, {"version": "v2", "created": "Mon, 9 May 2016 06:55:09 GMT"}], "update_date": "2016-05-10", "authors_parsed": [["Diakonikolas", "Ilias", ""], ["Kane", "Daniel M.", ""]]}, {"id": "1601.05560", "submitter": "Olivier Wintenberger", "authors": "Christian Francq (LFA), Olivier Wintenberger (LSTA), Jean-Michel\n  Zako\\\"ian (LFA)", "title": "Goodness-of-fit tests for extended Log-GARCH models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies goodness of fit tests and specification tests for an\nextension of the log-GARCH model which is stable by scaling. A\nLagrange-Multiplier test is derived for testing the null assumption of extended\nlog-GARCH against more general formulations including the Exponential GARCH\n(EGARCH). The null assumption of an EGARCH is also tested. Portmanteau\ngoodness-of-fit tests are developed for the extended log-GARCH. Simulations\nillustrating the theoretical results and an application to real financial data\nare proposed.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2016 09:16:23 GMT"}, {"version": "v2", "created": "Mon, 6 Jun 2016 12:47:12 GMT"}], "update_date": "2016-06-07", "authors_parsed": [["Francq", "Christian", "", "LFA"], ["Wintenberger", "Olivier", "", "LSTA"], ["Zako\u00efan", "Jean-Michel", "", "LFA"]]}, {"id": "1601.05584", "submitter": "Guillaume Lecu\\'e", "authors": "Guillaume Lecu\\'e and Shahar Mendelson", "title": "Regularization and the small-ball method I: sparse recovery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We obtain bounds on estimation error rates for regularization procedures of\nthe form \\begin{equation*}\n  \\hat f \\in {\\rm argmin}_{f\\in\n  F}\\left(\\frac{1}{N}\\sum_{i=1}^N\\left(Y_i-f(X_i)\\right)^2+\\lambda\n\\Psi(f)\\right) \\end{equation*} when $\\Psi$ is a norm and $F$ is convex.\n  Our approach gives a common framework that may be used in the analysis of\nlearning problems and regularization problems alike. In particular, it sheds\nsome light on the role various notions of sparsity have in regularization and\non their connection with the size of subdifferentials of $\\Psi$ in a\nneighbourhood of the true minimizer.\n  As `proof of concept' we extend the known estimates for the LASSO, SLOPE and\ntrace norm regularization.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2016 10:44:37 GMT"}, {"version": "v2", "created": "Tue, 3 Jan 2017 15:23:21 GMT"}], "update_date": "2017-01-04", "authors_parsed": [["Lecu\u00e9", "Guillaume", ""], ["Mendelson", "Shahar", ""]]}, {"id": "1601.05682", "submitter": "Jean-Marc Bardet", "authors": "Jean-Marc Bardet (SAMM), B\\'echir Dola (SAMM)", "title": "Semiparametric stationarity and fractional unit roots tests based on\n  data-driven multidimensional increment ratio statistics", "comments": "arXiv admin note: substantial text overlap with arXiv:1207.2453", "journal-ref": "Journal of Time Series Econometrics, De Gruyter, 2016, 8 (1), pp.1\n  -- 25", "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we show that the central limit theorem (CLT) satisfied by the\ndata-driven Multidimensional Increment Ratio (MIR) estimator of the memory\nparameter d established in Bardet and Dola (2012) for d $\\in$ (--0.5, 0.5) can\nbe extended to a semiparametric class of Gaussian fractionally integrated\nprocesses with memory parameter d $\\in$ (--0.5, 1.25). Since the asymptotic\nvariance of this CLT can be estimated, by data-driven MIR tests for the two\ncases of stationarity and non-stationarity, so two tests are constructed\ndistinguishing the hypothesis d \\textless{} 0.5 and d $\\ge$ 0.5, as well as a\nfractional unit roots test distinguishing the case d = 1 from the case d\n\\textless{} 1. Simulations done on numerous kinds of short-memory, long-memory\nand non-stationary processes, show both the high accuracy and robustness of\nthis MIR estimator compared to those of usual semiparametric estimators. They\nalso attest of the reasonable efficiency of MIR tests compared to other usual\nstationarity tests or fractional unit roots tests. Keywords: Gaussian\nfractionally integrated processes; semiparametric estimators of the memory\nparameter; test of long-memory; stationarity test; fractional unit roots test.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2016 15:42:15 GMT"}], "update_date": "2016-01-22", "authors_parsed": [["Bardet", "Jean-Marc", "", "SAMM"], ["Dola", "B\u00e9chir", "", "SAMM"]]}, {"id": "1601.05686", "submitter": "Richard Fischer", "authors": "Cristina Butucea, Jean-Fran\\c{c}ois Delmas, Anne Dutfoy, Richard\n  Fischer", "title": "Optimal exponential bounds for aggregation of estimators for the\n  Kullback-Leibler loss", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of model selection type aggregation with respect to the\nKullback-Leibler divergence for various probabilistic models. Rather than\nconsidering a convex combination of the initial estimators $f_1, \\ldots, f_N$,\nour aggregation procedures rely on the convex combination of the logarithms of\nthese functions. The first method is designed for probability density\nestimation as it gives an aggregate estimator that is also a proper density\nfunction, whereas the second method concerns spectral density estimation and\nhas no such mass-conserving feature. We select the aggregation weights based on\na penalized maximum likelihood criterion. We give sharp oracle inequalities\nthat hold with high probability, with a remainder term that is decomposed into\na bias and a variance part. We also show the optimality of the remainder terms\nby providing the corresponding lower bound results.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2016 15:51:30 GMT"}], "update_date": "2016-01-22", "authors_parsed": [["Butucea", "Cristina", ""], ["Delmas", "Jean-Fran\u00e7ois", ""], ["Dutfoy", "Anne", ""], ["Fischer", "Richard", ""]]}, {"id": "1601.05702", "submitter": "Axel B\\\"ucher", "authors": "Axel B\\\"ucher and Johan Segers", "title": "On the maximum likelihood estimator for the Generalized Extreme-Value\n  distribution", "comments": "31 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The vanilla method in univariate extreme-value theory consists of fitting the\nthree-parameter Generalized Extreme-Value (GEV) distribution to a sample of\nblock maxima. Despite claims to the contrary, the asymptotic normality of the\nmaximum likelihood estimator has never been established. In this paper, a\nformal proof is given using a general result on the maximum likelihood\nestimator for parametric families that are differentiable in quadratic mean but\nwhose supports depend on the parameter. An interesting side result concerns the\n(lack of) differentiability in quadratic mean of the GEV family.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2016 16:38:50 GMT"}, {"version": "v2", "created": "Thu, 13 Oct 2016 13:21:26 GMT"}, {"version": "v3", "created": "Wed, 15 Mar 2017 08:00:33 GMT"}], "update_date": "2017-03-16", "authors_parsed": [["B\u00fccher", "Axel", ""], ["Segers", "Johan", ""]]}, {"id": "1601.05766", "submitter": "Pierre C. Bellec", "authors": "Pierre C. Bellec", "title": "Adaptive confidence sets in shape restricted regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A simple construction of adaptive confidence sets is proposed in isotonic,\nconvex and unimodal regression. In univariate isotonic regression, the proposed\nconfidence set enjoys uniform coverage over all non-decreasing regression\nfunctions. Furthermore, the diameter of the proposed confidence set\nautomatically adapts to the unknown number of pieces of the true parameter, in\nthe sense that the diameter is bounded from above by the minimax risk over the\nclass of $k$-piecewise constant functions. The diameter of the confidence set\nis a simple increasing function of the number of jumps of the isotonic\nleast-squares estimate.\n  A similar construction is proposed in convex regression where the true\nregression function is convex and piecewise affine. Here, the confidence set\nenjoys uniform coverage and its diameter automatically adapt to the number of\naffine pieces of the true regression function. The diameter of the confidence\nset is an increasing function of the number of affine pieces of the convex\nleast-squares estimate.\n  We explain how to extend this technique to a non-convex set by proposing a\nsimilar adaptive confidence set in unimodal regression. The confidence set\nautomatically adapts to the number of jumps of the true unimodal regression\nfunction and its diameter is an increasing function of the number of jumps of\nthe unimodal least-squares estimate.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2016 20:17:23 GMT"}, {"version": "v2", "created": "Tue, 9 Apr 2019 14:35:48 GMT"}], "update_date": "2019-04-10", "authors_parsed": [["Bellec", "Pierre C.", ""]]}, {"id": "1601.05835", "submitter": "Jiannan Lu", "authors": "Jiannan Lu and Alex Deng", "title": "Demystifying the Bias from Selective Inference: a Revisit to Dawid's\n  Treatment Selection Problem", "comments": "To appear in Statistics and Probability Letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the heuristic discussion in Senn (2008) on the bias from selective\ninference for the treatment selection problem (Dawid 1994), by deriving the\nclosed-form expression for the selection bias. We illustrate the advantages of\nour theoretical results through numerical and simulated examples.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2016 22:43:59 GMT"}, {"version": "v2", "created": "Thu, 9 Jun 2016 15:26:40 GMT"}], "update_date": "2016-06-10", "authors_parsed": [["Lu", "Jiannan", ""], ["Deng", "Alex", ""]]}, {"id": "1601.05842", "submitter": "Kinjal Basu", "authors": "Kinjal Basu, Rajarshi Mukherjee", "title": "Asymptotic Normality of Scrambled Geometric Net Quadrature", "comments": "41 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.NA stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a very recent work, Basu and Owen (2015) propose the use of scrambled\ngeometric nets in numerical integration when the domain is a product of $s$\narbitrary spaces of dimension $d$ having a certain partitioning constraint. It\nwas shown that for a class of smooth functions, the integral estimate has\nvariance $O( n^{-1 -2/d} (\\log n)^{s-1})$ for scrambled geometric nets,\ncompared to $O(n^{-1})$ for ordinary Monte Carlo.\n  The main idea of this paper is to develop on the work by Loh (2003), to show\nthat the scrambled geometric net estimate has an asymptotic normal distribution\nfor certain smooth functions defined on products of suitable subsets of\n$\\mathbb{R}^d$.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2016 23:19:47 GMT"}, {"version": "v2", "created": "Tue, 16 Feb 2016 01:23:10 GMT"}, {"version": "v3", "created": "Wed, 27 Apr 2016 02:59:46 GMT"}], "update_date": "2016-04-28", "authors_parsed": [["Basu", "Kinjal", ""], ["Mukherjee", "Rajarshi", ""]]}, {"id": "1601.05870", "submitter": "Olivier Ledoit", "authors": "Olivier Ledoit and Michael Wolf", "title": "Numerical Implementation of the QuEST Function", "comments": "35 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": "University of Zurich Department of Economics Working Paper No. 215", "categories": "stat.CO math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with certain estimation problems involving the covariance\nmatrix in large dimensions. Due to the breakdown of finite-dimensional\nasymptotic theory when the dimension is not negligible with respect to the\nsample size, it is necessary to resort to an alternative framework known as\nlarge-dimensional asymptotics. Recently, Ledoit and Wolf (2015) have proposed\nan estimator of the eigenvalues of the population covariance matrix that is\nconsistent according to a mean-square criterion under large-dimensional\nasymptotics. It requires numerical inversion of a multivariate nonrandom\nfunction which they call the QuEST function. The present paper explains how to\nnumerically implement the QuEST function in practice through a series of six\nsuccessive steps. It also provides an algorithm to compute the Jacobian\nanalytically, which is necessary for numerical inversion by a nonlinear\noptimizer. Monte Carlo simulations document the effectiveness of the code.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jan 2016 03:17:30 GMT"}], "update_date": "2016-01-25", "authors_parsed": [["Ledoit", "Olivier", ""], ["Wolf", "Michael", ""]]}, {"id": "1601.06000", "submitter": "Ben Sherwood", "authors": "Ben Sherwood, Lan Wang", "title": "Partially linear additive quantile regression in ultra-high dimension", "comments": "Published at http://dx.doi.org/10.1214/15-AOS1367 in the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2016, Vol. 44, No. 1, 288-317", "doi": "10.1214/15-AOS1367", "report-no": "IMS-AOS-AOS1367", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a flexible semiparametric quantile regression model for analyzing\nhigh dimensional heterogeneous data. This model has several appealing features:\n(1) By considering different conditional quantiles, we may obtain a more\ncomplete picture of the conditional distribution of a response variable given\nhigh dimensional covariates. (2) The sparsity level is allowed to be different\nat different quantile levels. (3) The partially linear additive structure\naccommodates nonlinearity and circumvents the curse of dimensionality. (4) It\nis naturally robust to heavy-tailed distributions. In this paper, we\napproximate the nonlinear components using B-spline basis functions. We first\nstudy estimation under this model when the nonzero components are known in\nadvance and the number of covariates in the linear part diverges. We then\ninvestigate a nonconvex penalized estimator for simultaneous variable selection\nand estimation. We derive its oracle property for a general class of nonconvex\npenalty functions in the presence of ultra-high dimensional covariates under\nrelaxed conditions. To tackle the challenges of nonsmooth loss function,\nnonconvex penalty function and the presence of nonlinear components, we combine\na recently developed convex-differencing method with modern empirical process\ntechniques. Monte Carlo simulations and an application to a microarray study\ndemonstrate the effectiveness of the proposed method. We also discuss how the\nmethod for a single quantile of interest can be extended to simultaneous\nvariable selection and estimation at multiple quantiles.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jan 2016 13:46:56 GMT"}], "update_date": "2016-01-25", "authors_parsed": [["Sherwood", "Ben", ""], ["Wang", "Lan", ""]]}, {"id": "1601.06003", "submitter": "Chaohua Dong", "authors": "Chaohua Dong, Jiti Gao, Dag Tj{\\o}stheim", "title": "Estimation for single-index and partially linear single-index integrated\n  models", "comments": "Published at http://dx.doi.org/10.1214/15-AOS1372 in the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2016, Vol. 44, No. 1, 425-453", "doi": "10.1214/15-AOS1372", "report-no": "IMS-AOS-AOS1372", "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimation mainly for two classes of popular models, single-index and\npartially linear single-index models, is studied in this paper. Such models\nfeature nonstationarity. Orthogonal series expansion is used to approximate the\nunknown integrable link functions in the models and a profile approach is used\nto derive the estimators. The findings include the dual rate of convergence of\nthe estimators for the single-index models and a trio of convergence rates for\nthe partially linear single-index models. A new central limit theorem is\nestablished for a plug-in estimator of the unknown link function. Meanwhile, a\nconsiderable extension to a class of partially nonlinear single-index models is\ndiscussed in Section 4. Monte Carlo simulation verifies these theoretical\nresults. An empirical study furnishes an application of the proposed estimation\nprocedures in practice.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jan 2016 13:51:38 GMT"}], "update_date": "2016-01-25", "authors_parsed": [["Dong", "Chaohua", ""], ["Gao", "Jiti", ""], ["Tj\u00f8stheim", "Dag", ""]]}, {"id": "1601.06064", "submitter": "Matteo Ruggiero", "authors": "Cristina Costantini, Pierpaolo De Blasi, Stewart N. Ethier, Matteo\n  Ruggiero and Dario Spano", "title": "Wright-Fisher construction of the two-parameter Poisson-Dirichlet\n  diffusion", "comments": "To appear in The Annals of Applied Probability", "journal-ref": "Ann. Appl. Probab.27 (2017) pp. 1923-1950", "doi": "10.1214/16-AAP1252", "report-no": null, "categories": "math.PR math.ST q-bio.PE stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The two-parameter Poisson--Dirichlet diffusion, introduced in 2009 by Petrov,\nextends the infinitely-many-neutral-alleles diffusion model, related to\nKingman's one-parameter Poisson--Dirichlet distribution and to certain\nFleming--Viot processes. The additional parameter has been shown to regulate\nthe clustering structure of the population, but is yet to be fully understood\nin the way it governs the reproductive process. Here we shed some light on\nthese dynamics by formulating a $K$-allele Wright--Fisher model for a\npopulation of size $N$, involving a uniform mutation pattern and a specific\nstate-dependent migration mechanism. Suitably scaled, this process converges in\ndistribution to a $K$-dimensional diffusion process as $N\\to\\infty$. Moreover,\nthe descending order statistics of the $K$-dimensional diffusion converge in\ndistribution to the two-parameter Poisson--Dirichlet diffusion as $K\\to\\infty$.\nThe choice of the migration mechanism depends on a delicate balance between\nreinforcement and redistributive effects. The proof of convergence to the\ninfinite-dimensional diffusion is nontrivial because the generators do not\nconverge on a core. Our strategy for overcoming this complication is to prove\n\\textit{a priori} that in the limit there is no \"loss of mass\", i.e., that, for\neach limit point of the sequence of finite-dimensional diffusions (after a\nreordering of components by size), allele frequencies sum to one.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jan 2016 16:35:09 GMT"}, {"version": "v2", "created": "Mon, 29 Aug 2016 14:25:53 GMT"}, {"version": "v3", "created": "Mon, 12 Dec 2016 17:31:19 GMT"}], "update_date": "2019-02-14", "authors_parsed": [["Costantini", "Cristina", ""], ["De Blasi", "Pierpaolo", ""], ["Ethier", "Stewart N.", ""], ["Ruggiero", "Matteo", ""], ["Spano", "Dario", ""]]}, {"id": "1601.06079", "submitter": "Dario Span\\`o DR", "authors": "Dario Span\\`o, Antonio Lijoi", "title": "Canonical correlations for dependent gamma processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.CA math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present paper provides a characterisation of exchangeable pairs of random\nmeasures $(\\widetilde\\mu_1,\\widetilde\\mu_2)$ whose identical margins are fixed\nto coincide with the distribution of a gamma completely random measure, and\nwhose dependence structure is given in terms of canonical correlations. It is\nfirst shown that canonical correlation sequences for the finite-dimensional\ndistributions of $(\\widetilde\\mu_1,\\widetilde\\mu_2)$ are moments of means of a\nDirichlet process having random base measure. Necessary and sufficient\nconditions are further given for canonically correlated gamma completely random\nmeasures to have independent joint increments. Finally, time-homogeneous Feller\nprocesses with gamma reversible measure and canonical autocorrelations are\ncharacterised as Dawson--Watanabe diffusions with independent homogeneous\nimmigration, time-changed via an independent subordinator. It is thus shown\nthat Dawson--Watanabe diffusions subordinated by pure drift are the only\nprocesses in this class whose time-finite-dimensional distributions have,\njointly, independent increments.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jan 2016 17:21:57 GMT"}], "update_date": "2016-01-25", "authors_parsed": [["Span\u00f2", "Dario", ""], ["Lijoi", "Antonio", ""]]}, {"id": "1601.06103", "submitter": "Mohammad Amin Rahimian", "authors": "M. Amin Rahimian and Ali Jadbabaie", "title": "Bayesian Learning without Recall", "comments": null, "journal-ref": null, "doi": "10.1109/TSIPN.2016.2631943", "report-no": null, "categories": "math.ST cs.SI cs.SY math.OC math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze a model of learning and belief formation in networks in which\nagents follow Bayes rule yet they do not recall their history of past\nobservations and cannot reason about how other agents' beliefs are formed. They\ndo so by making rational inferences about their observations which include a\nsequence of independent and identically distributed private signals as well as\nthe actions of their neighboring agents at each time. Successive applications\nof Bayes rule to the entire history of past observations lead to forebodingly\ncomplex inferences: due to lack of knowledge about the global network\nstructure, and unavailability of private observations, as well as third party\ninteractions preceding every decision. Such difficulties make Bayesian updating\nof beliefs an implausible mechanism for social learning. To address these\ncomplexities, we consider a Bayesian without Recall model of inference. On the\none hand, this model provides a tractable framework for analyzing the behavior\nof rational agents in social networks. On the other hand, this model also\nprovides a behavioral foundation for the variety of non-Bayesian update rules\nin the literature. We present the implications of various choices for the\nstructure of the action space and utility functions for such agents and\ninvestigate the properties of learning, convergence, and consensus in special\ncases.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2016 04:31:40 GMT"}, {"version": "v2", "created": "Mon, 7 Nov 2016 12:15:47 GMT"}], "update_date": "2016-11-29", "authors_parsed": [["Rahimian", "M. Amin", ""], ["Jadbabaie", "Ali", ""]]}, {"id": "1601.06212", "submitter": "Guang Cheng", "authors": "Junwei Lu, Guang Cheng, Han Liu", "title": "Nonparametric Heterogeneity Testing For Massive Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A massive dataset often consists of a growing number of (potentially)\nheterogeneous sub-populations. This paper is concerned about testing various\nforms of heterogeneity arising from massive data. In a general nonparametric\nframework, a set of testing procedures are designed to accommodate a growing\nnumber of sub-populations, denoted as $s$, with computational feasibility. In\ntheory, their null limit distributions are derived as being nearly Chi-square\nwith diverging degrees of freedom as long as $s$ does not grow too fast.\nInterestingly, we find that a lower bound on $s$ needs to be set for obtaining\na sufficiently powerful testing result, so-called \"blessing of aggregation.\" As\na by-produc, a type of homogeneity testing is also proposed with a test\nstatistic being aggregated over all sub-populations. Numerical results are\npresented to support our theory.\n", "versions": [{"version": "v1", "created": "Sat, 23 Jan 2016 00:34:19 GMT"}], "update_date": "2016-01-26", "authors_parsed": [["Lu", "Junwei", ""], ["Cheng", "Guang", ""], ["Liu", "Han", ""]]}, {"id": "1601.06233", "submitter": "Christos Thrampoulidis", "authors": "Christos Thrampoulidis, Ehsan Abbasi, Babak Hassibi", "title": "Precise Error Analysis of Regularized M-estimators in High-dimensions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A popular approach for estimating an unknown signal from noisy, linear\nmeasurements is via solving a so called \\emph{regularized M-estimator}, which\nminimizes a weighted combination of a convex loss function and of a convex\n(typically, non-smooth) regularizer. We accurately predict the squared error\nperformance of such estimators in the high-dimensional proportional regime. The\nrandom measurement matrix is assumed to have entries iid Gaussian, only minimal\nand rather mild regularity conditions are imposed on the loss function, the\nregularizer, and on the noise and signal distributions. We show that the error\nconverges in probability to a nontrivial limit that is given as the solution to\na minimax convex-concave optimization problem on four scalar optimization\nvariables. We identify a new summary parameter, termed the Expected Moreau\nenvelope to play a central role in the error characterization. The\n\\emph{precise} nature of the results permits an accurate performance comparison\nbetween different instances of regularized M-estimators and allows to optimally\ntune the involved parameters (e.g. regularizer parameter, number of\nmeasurements). The key ingredient of our proof is the \\emph{Convex Gaussian\nMin-max Theorem} (CGMT) which is a tight and strengthened version of a\nclassical Gaussian comparison inequality that was proved by Gordon in 1988.\n", "versions": [{"version": "v1", "created": "Sat, 23 Jan 2016 05:17:58 GMT"}], "update_date": "2016-01-26", "authors_parsed": [["Thrampoulidis", "Christos", ""], ["Abbasi", "Ehsan", ""], ["Hassibi", "Babak", ""]]}, {"id": "1601.06239", "submitter": "Yao Wang", "authors": "Xiangyu Chang, Shaobo Lin and Yao Wang", "title": "Divide and Conquer Local Average Regression", "comments": "36 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The divide and conquer strategy, which breaks a massive data set into a se-\nries of manageable data blocks, and then combines the independent results of\ndata blocks to obtain a final decision, has been recognized as a\nstate-of-the-art method to overcome challenges of massive data analysis. In\nthis paper, we merge the divide and conquer strategy with local average\nregression methods to infer the regressive relationship of input-output pairs\nfrom a massive data set. After theoretically analyzing the pros and cons, we\nfind that although the divide and conquer local average regression can reach\nthe optimal learning rate, the restric- tion to the number of data blocks is a\nbit strong, which makes it only feasible for small number of data blocks. We\nthen propose two variants to lessen (or remove) this restriction. Our results\nshow that these variants can achieve the optimal learning rate with much milder\nrestriction (or without such restriction). Extensive experimental studies are\ncarried out to verify our theoretical assertions.\n", "versions": [{"version": "v1", "created": "Sat, 23 Jan 2016 06:17:03 GMT"}, {"version": "v2", "created": "Sun, 13 Mar 2016 18:00:50 GMT"}], "update_date": "2016-03-15", "authors_parsed": [["Chang", "Xiangyu", ""], ["Lin", "Shaobo", ""], ["Wang", "Yao", ""]]}, {"id": "1601.06259", "submitter": "Aaditya Ramdas", "authors": "Aaditya Ramdas, David Isenberg, Aarti Singh, Larry Wasserman", "title": "Minimax Lower Bounds for Linear Independence Testing", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear independence testing is a fundamental information-theoretic and\nstatistical problem that can be posed as follows: given $n$ points\n$\\{(X_i,Y_i)\\}^n_{i=1}$ from a $p+q$ dimensional multivariate distribution\nwhere $X_i \\in \\mathbb{R}^p$ and $Y_i \\in\\mathbb{R}^q$, determine whether $a^T\nX$ and $b^T Y$ are uncorrelated for every $a \\in \\mathbb{R}^p, b\\in\n\\mathbb{R}^q$ or not. We give minimax lower bound for this problem (when $p+q,n\n\\to \\infty$, $(p+q)/n \\leq \\kappa < \\infty$, without sparsity assumptions). In\nsummary, our results imply that $n$ must be at least as large as $\\sqrt\n{pq}/\\|\\Sigma_{XY}\\|_F^2$ for any procedure (test) to have non-trivial power,\nwhere $\\Sigma_{XY}$ is the cross-covariance matrix of $X,Y$. We also provide\nsome evidence that the lower bound is tight, by connections to two-sample\ntesting and regression in specific settings.\n", "versions": [{"version": "v1", "created": "Sat, 23 Jan 2016 10:20:58 GMT"}], "update_date": "2016-01-26", "authors_parsed": [["Ramdas", "Aaditya", ""], ["Isenberg", "David", ""], ["Singh", "Aarti", ""], ["Wasserman", "Larry", ""]]}, {"id": "1601.06412", "submitter": "Helio M. de Oliveira", "authors": "H. M. de Oliveira and R. J. Cintra", "title": "A New Information Theoretical Concept: Information-Weighted Heavy-tailed\n  Distributions", "comments": "21 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given an arbitrary continuous probability density function, it is introduced\na conjugated probability density, which is defined through the Shannon\ninformation associated with its cumulative distribution function. These new\ndensities are computed from a number of standard distributions, including\nuniform, normal, exponential, Pareto, logistic, Kumaraswamy, Rayleigh, Cauchy,\nWeibull, and Maxwell-Boltzmann. The case of joint information-weighted\nprobability distribution is assessed. An additive property is derived in the\ncase of independent variables. One-sided and two-sided information-weighting\nare considered. The asymptotic behavior of the tail of the new distributions is\nexamined. It is proved that all probability densities proposed here define\nheavy-tailed distributions. It is shown that the weighting of distributions\nregularly varying with extreme-value index $\\alpha > 0$ still results in a\nregular variation distribution with the same index. This approach can be\nparticularly valuable in applications where the tails of the distribution play\na major role.\n", "versions": [{"version": "v1", "created": "Sun, 24 Jan 2016 18:04:27 GMT"}], "update_date": "2018-01-26", "authors_parsed": [["de Oliveira", "H. M.", ""], ["Cintra", "R. J.", ""]]}, {"id": "1601.06448", "submitter": "Varun  Jog", "authors": "Varun Jog and Po-Ling Loh", "title": "Analysis of centrality in sublinear preferential attachment trees via\n  the CMJ branching process", "comments": "23 pages, 4 figures. An error in Lemma 15 in the earlier version has\n  been fixed by modifying our theorems to establish terminal centrality. This\n  paper has been accepted to IEEE Transactions on Network Science and\n  Engineering", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.DM cs.IT cs.SI math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate centrality and root-inference properties in a class of growing\nrandom graphs known as sublinear preferential attachment trees. We show that a\ncontinuous time branching processes called the Crump-Mode-Jagers (CMJ)\nbranching process is well-suited to analyze such random trees, and prove that\nalmost surely, a unique terminal tree centroid emerges, having the property\nthat it becomes more central than any other fixed vertex in the limit of the\nrandom growth process. Our result generalizes and extends previous work\nestablishing persistent centrality in uniform and linear preferential\nattachment trees. We also show that centrality may be utilized to generate a\nfinite-sized $1-\\epsilon$ confidence set for the root node, for any $\\epsilon >\n0$ in a certain subclass of sublinear preferential attachment trees.\n", "versions": [{"version": "v1", "created": "Sun, 24 Jan 2016 23:33:07 GMT"}, {"version": "v2", "created": "Thu, 27 Oct 2016 15:57:10 GMT"}], "update_date": "2016-10-28", "authors_parsed": [["Jog", "Varun", ""], ["Loh", "Po-Ling", ""]]}, {"id": "1601.06523", "submitter": "Shahar Mendelson", "authors": "Shahar Mendelson", "title": "On multiplier processes under weak moment assumptions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that if $V \\subset \\R^n$ satisfies a certain symmetry condition\n(closely related to unconditionaity) and if $X$ is an isotropic random vector\nfor which $\\|\\inr{X,t}\\|_{L_p} \\leq L \\sqrt{p}$ for every $t \\in S^{n-1}$ and\n$p \\lesssim \\log n$, then the corresponding empirical and multiplier processes\nindexed by $V$ behave as if $X$ were $L$-subgaussian.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2016 09:21:54 GMT"}], "update_date": "2016-01-26", "authors_parsed": [["Mendelson", "Shahar", ""]]}, {"id": "1601.06537", "submitter": "Quentin Paris", "authors": "Geoffrey Decrouez, Michael Grabchak and Quentin Paris", "title": "Finite sample properties of the mean occupancy counts and probabilities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a probability distribution $P$ on an at most countable alphabet $\\mathcal\nA$, this article gives finite sample bounds for the expected occupancy counts\n$\\mathbb E K_{n,r}$ and probabilities $\\mathbb E M_{n,r}$. Both upper and lower\nbounds are given in terms of the counting function $\\nu$ of $P$. Special\nattention is given to the case where $\\nu$ is bounded by a regularly varying\nfunction. In this case, it is shown that our general results lead to an\noptimal-rate control of the expected occupancy counts and probabilities with\nexplicit constants. Our results are also put in perspective with Turing's\nformula and recent concentration bounds to deduce bounds in probability. At the\nend of the paper, we discuss an extension of the occupancy problem to arbitrary\ndistributions in a metric space.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2016 10:00:30 GMT"}, {"version": "v2", "created": "Wed, 16 Nov 2016 17:51:13 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Decrouez", "Geoffrey", ""], ["Grabchak", "Michael", ""], ["Paris", "Quentin", ""]]}, {"id": "1601.06810", "submitter": "Nir Elkayam", "authors": "Nir Elkayam and Meir Feder", "title": "Variational formulas for the power of the binary hypothesis testing\n  problem with applications", "comments": "Submitted to ISIT 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two variational formulas for the power of the binary hypothesis testing\nproblem are derived. The first is given as the Legendre transform of a certain\nfunction and the second, induced from the first, is given in terms of the\nCumulative Distribution Function (CDF) of the log-likelihood ratio. One\napplication of the first formula is an upper bound on the power of the binary\nhypothesis testing problem in terms of the Re'nyi divergence. The second\nformula provide a general framework for proving asymptotic and non-asymptotic\nexpressions for the power of the test utilizing corresponding expressions for\nthe CDF of the log-likelihood. The framework is demonstrated in the central\nlimit regime (i.e., for non-vanishing type I error) and in the large deviations\nregime.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2016 21:21:20 GMT"}], "update_date": "2016-01-27", "authors_parsed": [["Elkayam", "Nir", ""], ["Feder", "Meir", ""]]}, {"id": "1601.06844", "submitter": "Jon A. Wellner", "authors": "Qiyang Han and Jon A. Wellner", "title": "Multivariate convex regression: global risk bounds and adaptation", "comments": "75 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of estimating a multivariate convex function defined on\na convex body in a regression setting with random design. We are interested in\noptimal rates of convergence under a squared global continuous $l_2$ loss in\nthe multivariate setting $(d\\geq 2)$. One crucial fact is that the minimax\nrisks depend heavily on the shape of the support of the regression function. It\nis shown that the global minimax risk is on the order of $n^{-2/(d+1)}$ when\nthe support is sufficiently smooth, but that the rate $n^{-4/(d+4)}$ is when\nthe support is a polytope. Such differences in rates are due to difficulties in\nestimating the regression function near the boundary of smooth regions.\n  We then study the natural bounded least squares estimators (BLSE): we show\nthat the BLSE nearly attains the optimal rates of convergence in low\ndimensions, while suffering rate-inefficiency in high dimensions. We show that\nthe BLSE adapts nearly parametrically to polyhedral functions when the support\nis polyhedral in low dimensions by a local entropy method. We also show that\nthe boundedness constraint cannot be dropped when risk is assessed via\ncontinuous $l_2$ loss.\n  Given rate sub-optimality of the BLSE in higher dimensions, we further study\nrate-efficient adaptive estimation procedures. Two general model selection\nmethods are developed to provide sieved adaptive estimators (SAE) that achieve\nnearly optimal rates of convergence for particular \"regular\" classes of convex\nfunctions, while maintaining nearly parametric rate-adaptivity to polyhedral\nfunctions in arbitrary dimensions. Interestingly, the uniform boundedness\nconstraint is unnecessary when risks are measured in discrete $l_2$ norms.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2016 23:01:06 GMT"}], "update_date": "2016-01-27", "authors_parsed": [["Han", "Qiyang", ""], ["Wellner", "Jon A.", ""]]}, {"id": "1601.06858", "submitter": "Karthyek Rajhaa Annaswamy Murthy", "authors": "Jose Blanchet, Fei He, and Karthyek R. A. Murthy", "title": "On distributionally robust extreme value analysis", "comments": null, "journal-ref": null, "doi": "10.1007/s10687-019-00371-1", "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study distributional robustness in the context of Extreme Value Theory\n(EVT). We provide a data-driven method for estimating extreme quantiles in a\nmanner that is robust against incorrect model assumptions underlying the\napplication of the standard Extremal Types Theorem. Typical studies in\ndistributional robustness involve computing worst case estimates over a model\nuncertainty region expressed in terms of the Kullback-Leibler discrepancy. We\ngo beyond standard distributional robustness in that we investigate different\nforms of discrepancies, and prove rigorous results which are helpful for\nunderstanding the role of a putative model uncertainty region in the context of\nextreme quantile estimation. Finally, we illustrate our data-driven method in\nvarious settings, including examples showing how standard EVT can significantly\nunderestimate quantiles of interest.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2016 01:04:03 GMT"}, {"version": "v2", "created": "Sun, 7 Jun 2020 03:46:10 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Blanchet", "Jose", ""], ["He", "Fei", ""], ["Murthy", "Karthyek R. A.", ""]]}, {"id": "1601.07141", "submitter": "Mamikon Ginovyan", "authors": "M. S. Ginovyan and A. A. Sahakyan", "title": "On the robustness to small trends of parameter estimation for\n  continuous-time stationary models with memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper deals with a question of robustness of inferences, carried out on a\ncontinuous-time stationary process contaminated by a small trend, to this\ndeparture from stationarity. We show that a smoothed periodogram approach to\nparameter estimation is highly robust to the presence of a small trend in the\nmodel. The obtained result is a continuous version of that of Hede and Dai\n(Journal of Time Series Analysis, 17, 141-150, 1996) for discrete time\nprocesses.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2016 19:35:22 GMT"}], "update_date": "2016-01-27", "authors_parsed": [["Ginovyan", "M. S.", ""], ["Sahakyan", "A. A.", ""]]}, {"id": "1601.07375", "submitter": "Sophia Sulis", "authors": "Sophia Sulis, David Mary and Lionel Bigot", "title": "Using hydrodynamical simulations of stellar atmospheres for periodogram\n  standardization : application to exoplanet detection", "comments": "5 pages, 3 figures. This manuscript was submitted and accepted to the\n  41st IEEE International Conference on Acoustics Speech and Signal Processing\n  (ICASSP), 2016", "journal-ref": null, "doi": "10.1109/ICASSP.2016.7472514", "report-no": null, "categories": "stat.AP astro-ph.IM math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our aim is to devise a detection method for exoplanet signatures (multiple\nsinusoids) that is both powerful and robust to partially unknown statistics\nunder the null hypothesis. In the considered application, the noise is mostly\ncreated by the stellar atmosphere, with statistics depending on the complicated\ninterplay of several parameters. Recent progresses in hydrodynamic (HD)\nsimulations show however that realistic stellar noise realizations can be\nnumerically produced off-line by astrophysicists. We propose a detection method\nthat is calibrated by HD simulations and analyze its performances. A comparison\nof the theoretical results with simulations on synthetic and real data shows\nthat the proposed method is powerful and robust.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2016 14:12:27 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Sulis", "Sophia", ""], ["Mary", "David", ""], ["Bigot", "Lionel", ""]]}, {"id": "1601.07410", "submitter": "Pedro Ramos", "authors": "P. L. Ramos and F. Louzada", "title": "The Generalized Weighted Lindley Distribution: Properties, Estimation\n  and Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we proposed a new lifetime distribution namely generalized\nweighted Lindley (GLW) distribution. The GLW distribution is a useful\ngeneralization of the weighted Lindley distribution, which accommodates\nincreasing, decreasing, decreasing-increasing-decreasing, bathtub, or unimodal\nhazard functions, making the GWL distribution a flexible model for reliability\ndata. A significant account of mathematical properties of the new distribution\nare presented. Different estimation procedures are also given such as, maximum\nlikelihood estimators, method of moments, ordinary and weighted least-squares,\npercentile, maximum product of spacings and minimum distance estimators. The\ndifferent estimators are compared by an extensive numerical simulations.\nFinally, we analyze two data sets for illustrative purposes, proving that the\nGWL outperform several usual three parameters lifetime distributions.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2016 15:37:07 GMT"}, {"version": "v2", "created": "Mon, 18 Jul 2016 21:42:52 GMT"}], "update_date": "2016-07-20", "authors_parsed": [["Ramos", "P. L.", ""], ["Louzada", "F.", ""]]}, {"id": "1601.07417", "submitter": "Shahab Asoodeh", "authors": "Shahab Asoodeh, Fady Alajaji, and Tam\\'as Linder", "title": "Privacy-Aware MMSE Estimation", "comments": "9 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem of the predictability of random variable $Y$ under\na privacy constraint dictated by random variable $X$, correlated with $Y$,\nwhere both predictability and privacy are assessed in terms of the minimum\nmean-squared error (MMSE). Given that $X$ and $Y$ are connected via a\nbinary-input symmetric-output (BISO) channel, we derive the \\emph{optimal}\nrandom mapping $P_{Z|Y}$ such that the MMSE of $Y$ given $Z$ is minimized while\nthe MMSE of $X$ given $Z$ is greater than $(1-\\epsilon)\\mathsf{var}(X)$ for a\ngiven $\\epsilon\\geq 0$. We also consider the case where $(X,Y)$ are continuous\nand $P_{Z|Y}$ is restricted to be an additive noise channel.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2016 15:44:04 GMT"}], "update_date": "2016-01-28", "authors_parsed": [["Asoodeh", "Shahab", ""], ["Alajaji", "Fady", ""], ["Linder", "Tam\u00e1s", ""]]}, {"id": "1601.07496", "submitter": "Simeng Qu", "authors": "Simeng Qu, Jane-Ling Wang and Xiao Wang", "title": "Optimal Estimation for the Functional Cox Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Functional covariates are common in many medical, biodemographic, and\nneuroimaging studies. The aim of this paper is to study functional Cox models\nwith right-censored data in the presence of both functional and scalar\ncovariates. We study the asymptotic properties of the maximum partial\nlikelihood estimator and establish the asymptotic normality and efficiency of\nthe estimator of the finite-dimensional estimator. Under the framework of\nreproducing kernel Hilbert space, the estimator of the coefficient function for\na functional covariate achieves the minimax optimal rate of convergence under a\nweighted $L_2$-risk. This optimal rate is determined jointly by the censoring\nscheme, the reproducing kernel and the covariance kernel of the functional\ncovariates. Implementation of the estimation approach and the selection of the\nsmoothing parameter are discussed in detail. The finite sample performance is\nillustrated by simulated examples and a real application.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2016 18:54:38 GMT"}], "update_date": "2016-01-28", "authors_parsed": [["Qu", "Simeng", ""], ["Wang", "Jane-Ling", ""], ["Wang", "Xiao", ""]]}, {"id": "1601.07521", "submitter": "Mark Chamness", "authors": "Mark Chamness, Rachel Traylor", "title": "Multiple Outliers in Small Samples", "comments": "This paper has been withdrawn due to additional research which has\n  led to new conclusions", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Z-scores are often employed in outlier detection in a dataset. For small\nsamples, the presence of multiple outliers forces a finite supremum on the\nabsolute value of possible z-scores that decreases with an increasing number of\noutliers, creating a \"masking effect\" that hinders identification of true\noutliers. We give an illustrative case study in which the accurate detection of\nthe number of outliers is critical, and provide a closed form expression of the\nmaximum possible z-score in terms of the sample size and number of outliers. In\naddition, a corresponding analysis on the $t-$statistic is performed.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2016 20:02:37 GMT"}, {"version": "v2", "created": "Mon, 14 Mar 2016 18:20:49 GMT"}], "update_date": "2016-03-15", "authors_parsed": [["Chamness", "Mark", ""], ["Traylor", "Rachel", ""]]}, {"id": "1601.07872", "submitter": "Daren Wang", "authors": "Mattia Ciollaro, Christopher R. Genovese, Daren Wang", "title": "Nonparametric Clustering of Functional Data Using Pseudo-Densities", "comments": null, "journal-ref": "Electron. J. Statist., Volume 10, Number 2 (2016), 2922-2972", "doi": "10.1214/16-EJS1198", "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study nonparametric clustering of smooth random curves on the basis of the\nL2 gradient flow associated to a pseudo-density functional and we show that the\nclustering is well-defined both at the population and at the sample level. We\nprovide an algorithm to mark significant local modes, which are associated to\ninformative sample clusters, and we derive its consistency properties. Our\ntheory is developed under weak assumptions, which essentially reduce to the\nintegrability of the random curves, and does not require to project the random\ncurves on a finite-dimensional subspace. However, if the underlying probability\ndistribution is supported on a finite-dimensional subspace, we show that the\npseudo-density and the expectation of a kernel density estimator induce the\nsame gradient flow, and therefore the same clustering. Although our theory is\ndeveloped for smooth curves that belong to an infinite-dimensional functional\nspace, we also provide consistent procedures that can be used with real data\n(discretized and noisy observations).\n", "versions": [{"version": "v1", "created": "Thu, 28 Jan 2016 19:27:27 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Ciollaro", "Mattia", ""], ["Genovese", "Christopher R.", ""], ["Wang", "Daren", ""]]}, {"id": "1601.07911", "submitter": "Helen Ogden", "authors": "Helen Ogden", "title": "On asymptotic validity of naive inference with an approximate likelihood", "comments": "Updated to add an additional example (inference for an Ising model on\n  a lattice using reduced dependence approximations to the likelihood)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many statistical models have likelihoods which are intractable: it is\nimpossible or too expensive to compute the likelihood exactly. In such\nsettings, a common approach is to replace the likelihood with an approximation,\nand proceed with inference as if the approximate likelihood were the exact\nlikelihood. In this paper, we describe conditions on the approximate likelihood\nwhich guarantee that this naive inference with an approximate likelihood has\nthe same first-order asymptotic properties as inference with the exact\nlikelihood. We investigate the implications of these results for inference\nusing a Laplace approximation to the likelihood in a simple two-level latent\nvariable model, and using reduced dependence approximations to the likelihood\nin an Ising model on a lattice.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jan 2016 21:00:48 GMT"}, {"version": "v2", "created": "Tue, 22 Nov 2016 10:07:13 GMT"}], "update_date": "2016-11-23", "authors_parsed": [["Ogden", "Helen", ""]]}, {"id": "1601.07975", "submitter": "Sergio Yuhjtman", "authors": "Nicol\\'as \\'Alvarez, Ver\\'onica Becher, Pablo A. Ferrari, Sergio A.\n  Yuhjtman", "title": "Perfect Necklaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.DM math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a variant of de Bruijn words that we call perfect necklaces. Fix\na finite alphabet. Recall that a word is a finite sequence of symbols in the\nalphabet and a circular word, or necklace, is the equivalence class of a word\nunder rotations. For positive integers k and n, we call a necklace\n(k,n)-perfect if each word of length k occurs exactly n times at positions\nwhich are different modulo n for any convention on the starting point. We call\na necklace perfect if it is (k,k)-perfect for some k. We prove that every\narithmetic sequence with difference coprime with the alphabet size induces a\nperfect necklace. In particular, the concatenation of all words of the same\nlength in lexicographic order yields a perfect necklace. For each k and n, we\ngive a closed formula for the number of (k,n)-perfect necklaces. Finally, we\nprove that every infinite periodic sequence whose period coincides with some\n(k,n)-perfect necklace for any n, passes all statistical tests of size up to k,\nbut not all larger tests. This last theorem motivated this work.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jan 2016 04:14:43 GMT"}], "update_date": "2016-02-01", "authors_parsed": [["\u00c1lvarez", "Nicol\u00e1s", ""], ["Becher", "Ver\u00f3nica", ""], ["Ferrari", "Pablo A.", ""], ["Yuhjtman", "Sergio A.", ""]]}, {"id": "1601.08065", "submitter": "Gabriela Ciuperca", "authors": "Gabriela Ciuperca", "title": "Adaptive group LASSO selection in quantile models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper considers a linear model with grouped explanatory variables. If the\nmodel errors are not with zero mean and bounded variance or if model contains\noutliers, then the least squares framework is not appropriate. Thus, the\nquantile regression is an interesting alternative. In order to automatically\nselect the relevant variable groups, we propose and study here the adaptive\ngroup LASSO quantile estimator. We establish the sparsity and asymptotic\nnormality of the proposed estimator in two cases: fixed number and divergent\nnumber of variable groups. Numerical study by Monte Carlo simulations confirms\nthe theoretical results and illustrates the performance of the proposed\nestimator.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jan 2016 11:51:13 GMT"}, {"version": "v2", "created": "Wed, 13 Jul 2016 07:56:45 GMT"}], "update_date": "2016-07-14", "authors_parsed": [["Ciuperca", "Gabriela", ""]]}, {"id": "1601.08136", "submitter": "Giacomo Aletti", "authors": "Giacomo Aletti, Nikolai Leonenko and Ely Merzbach", "title": "Fractional Poisson Fields and Martingales", "comments": null, "journal-ref": null, "doi": "10.1007/s10955-018-1951-y", "report-no": null, "categories": "math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present new properties for the Fractional Poisson process and the\nFractional Poisson field on the plane. A martingale characterization for\nFractional Poisson processes is given. We extend this result to Fractional\nPoisson fields, obtaining some other characterizations. The fractional\ndifferential equations are studied. We consider a more general Mixed-Fractional\nPoisson process and show that this process is the stochastic solution of a\nsystem of fractional differential-difference equations. Finally, we give some\nsimulations of the Fractional Poisson field on the plane.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jan 2016 14:45:33 GMT"}, {"version": "v2", "created": "Mon, 1 Aug 2016 20:40:48 GMT"}, {"version": "v3", "created": "Wed, 15 Mar 2017 07:59:35 GMT"}, {"version": "v4", "created": "Thu, 14 Dec 2017 22:53:41 GMT"}], "update_date": "2018-01-30", "authors_parsed": [["Aletti", "Giacomo", ""], ["Leonenko", "Nikolai", ""], ["Merzbach", "Ely", ""]]}, {"id": "1601.08169", "submitter": "Franz J. Kir\\'aly", "authors": "Franz J Kir\\'aly, Harald Oberhauser", "title": "Kernels for sequentially ordered data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DM cs.LG math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel framework for kernel learning with sequential data of any\nkind, such as time series, sequences of graphs, or strings. Our approach is\nbased on signature features which can be seen as an ordered variant of sample\n(cross-)moments; it allows to obtain a \"sequentialized\" version of any static\nkernel. The sequential kernels are efficiently computable for discrete\nsequences and are shown to approximate a continuous moment form in a sampling\nsense.\n  A number of known kernels for sequences arise as \"sequentializations\" of\nsuitable static kernels: string kernels may be obtained as a special case, and\nalignment kernels are closely related up to a modification that resolves their\nopen non-definiteness issue. Our experiments indicate that our signature-based\nsequential kernel framework may be a promising approach to learning with\nsequential data, such as time series, that allows to avoid extensive manual\npre-processing.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jan 2016 16:06:36 GMT"}], "update_date": "2016-02-01", "authors_parsed": [["Kir\u00e1ly", "Franz J", ""], ["Oberhauser", "Harald", ""]]}, {"id": "1601.08174", "submitter": "Yury Kutoyants", "authors": "Yury A. Kutoyants, Anastasia Motrunich", "title": "On Multi-step MLE-process for Markov Sequences", "comments": "24 pages, 6 fugures", "journal-ref": null, "doi": "10.1007/s00184-015-0574-4", "report-no": null, "categories": "math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of the construction of the estimator-process of the\nunknown finite-dimensional parameter in the case of the observations of\nnonlinear autoregressive process. The estimation is done in two or three steps.\nFirst we estimate the unknown parameter by a learning relatively short part of\nobservations and then we use the one-step MLE idea to construct an-estimator\nprocess which is asymptotically equivalent to the MLE. To have the learning\ninterval shorter we introduce the two-step procedure which leads to the\nasymptotically efficient estimator-process too. The presented results are\nillustrated with the help of two numerical examples.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jan 2016 16:10:51 GMT"}], "update_date": "2016-02-01", "authors_parsed": [["Kutoyants", "Yury A.", ""], ["Motrunich", "Anastasia", ""]]}]