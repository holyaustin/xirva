[{"id": "2009.00972", "submitter": "Michael Monoyios Prof", "authors": "Michael Monoyios", "title": "Infinite horizon utility maximisation from inter-temporal wealth", "comments": "arXiv admin note: substantial text overlap with arXiv:2006.04687", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PM math.OC math.PR q-fin.MF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a duality theory for the problem of maximising expected lifetime\nutility from inter-temporal wealth over an infinite horizon, under the minimal\nno-arbitrage assumption of No Unbounded Profit with Bounded Risk (NUPBR). We\nuse only deflators, with no arguments involving equivalent martingale measures,\nso do not require the stronger condition of No Free Lunch with Vanishing Risk\n(NFLVR). Our formalism also works without alteration for the finite horizon\nversion of the problem. As well as extending work of Bouchard and Pham to any\nhorizon and to a weaker no-arbitrage setting, we obtain a stronger duality\nstatement, because we do not assume by definition that the dual domain is the\npolar set of the primal space. Instead, we adopt a method akin to that used for\ninter-temporal consumption problems, developing a supermartingale property of\nthe deflated wealth and its path that yields an infinite horizon budget\nconstraint and serves to define the correct dual variables. The structure of\nour dual space allows us to show that it is convex, without forcing this\nproperty by assumption. We proceed to enlarge the primal and dual domains to\nconfer solidity to them, and use supermartingale convergence results which\nexploit Fatou convergence, to establish that the enlarged dual domain is the\nbipolar of the original dual space. The resulting duality theorem shows that\nall the classical tenets of convex duality hold. Moreover, at the optimum, the\ndeflated wealth process is a potential converging to zero. We work out\nexamples, including a case with a stock whose market price of risk is a\nthree-dimensional Bessel process, so satisfying NUPBR but not NFLVR.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 18:08:39 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2020 21:43:39 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Monoyios", "Michael", ""]]}, {"id": "2009.03362", "submitter": "Rodrigo Rivera-Castro", "authors": "Rodrigo Rivera-Castro, Polina Pilyugina, Evgeny Burnaev", "title": "Topological Data Analysis for Portfolio Management of Cryptocurrencies", "comments": null, "journal-ref": "2019 International Conference on Data Mining Workshops (ICDMW)", "doi": "10.1109/ICDMW.2019.00044", "report-no": null, "categories": "q-fin.PM cs.LG q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Portfolio management is essential for any investment decision. Yet,\ntraditional methods in the literature are ill-suited for the characteristics\nand dynamics of cryptocurrencies. This work presents a method to build an\ninvestment portfolio consisting of more than 1500 cryptocurrencies covering 6\nyears of market data. It is centred around Topological Data Analysis (TDA), a\nrecent approach to analyze data sets from the perspective of their topological\nstructure. This publication proposes a system combining persistence landscapes\nto identify suitable investment opportunities in cryptocurrencies. Using a\nnovel and comprehensive data set of cryptocurrency prices, this research shows\nthat the proposed system enables analysts to outperform a classic method from\nthe literature without requiring any feature engineering or domain knowledge in\nTDA. This work thus introduces TDA-based portfolio management of\ncryptocurrencies as a viable tool for the practitioner.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 18:30:36 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Rivera-Castro", "Rodrigo", ""], ["Pilyugina", "Polina", ""], ["Burnaev", "Evgeny", ""]]}, {"id": "2009.03394", "submitter": "Jozef Barunik", "authors": "Mykola Babiak and Jozef Barunik", "title": "Deep Learning, Predictability, and Optimal Portfolio Returns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.GN q-fin.PM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study dynamic portfolio choice of a long-horizon investor who uses deep\nlearning methods to predict equity returns when forming optimal portfolios. Our\nresults show statistically and economically significant benefits from using\ndeep learning to form optimal portfolios through certainty equivalent returns\nand Sharpe ratios. We demonstrate that a long-short-term-memory recurrent\nneural network, which excels in learning complex time-series dependencies,\ngenerates a superior performance among a variety of networks considered. Return\npredictability via deep learning generates substantially improved portfolio\nperformance across different subsamples, particularly during recessionary\nperiods. These gains are robust to including transaction costs, short-selling\nand borrowing constraints.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 19:50:40 GMT"}, {"version": "v2", "created": "Mon, 23 Nov 2020 15:42:24 GMT"}, {"version": "v3", "created": "Wed, 21 Jul 2021 12:46:05 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Babiak", "Mykola", ""], ["Barunik", "Jozef", ""]]}, {"id": "2009.04461", "submitter": "Wolfgang Karl H\\\"ardle", "authors": "Alla Petukhina, Simon Trimborn, Wolfgang Karl H\\\"ardle, Hermann\n  Elendner", "title": "Investing with Cryptocurrencies -- evaluating their potential for\n  portfolio allocation strategies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cryptocurrencies (CCs) have risen rapidly in market capitalization over the\nlast years. Despite striking price volatility, their high average returns have\ndrawn attention to CCs as alternative investment assets for portfolio and risk\nmanagement. We investigate the utility gains for different types of investors\nwhen they consider cryptocurrencies as an addition to their portfolio of\ntraditional assets. We consider risk-averse, return-seeking as well as\ndiversificationpreferring investors who trade along different allocation\nfrequencies, namely daily, weekly or monthly. Out-of-sample performance and\ndiversification benefits are studied for the most popular\nportfolio-construction rules, including mean-variance optimization,\nrisk-parity, and maximum-diversification strategies, as well as combined\nstrategies. To account for low liquidity in CC markets, we incorporate\nliquidity constraints via the LIBRO method. Our results show that CCs can\nimprove the risk-return profile of portfolios. In particular, a\nmaximum-diversification strategy (maximizing the Portfolio Diversification\nIndex, PDI) draws appreciably on CCs, and spanning tests clearly indicate that\nCC returns are non-redundant additions to the investment universe. Though our\nanalysis also shows that illiquidity of CCs potentially reverses the results.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 11:05:15 GMT"}, {"version": "v2", "created": "Wed, 16 Sep 2020 18:09:27 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Petukhina", "Alla", ""], ["Trimborn", "Simon", ""], ["H\u00e4rdle", "Wolfgang Karl", ""], ["Elendner", "Hermann", ""]]}, {"id": "2009.07086", "submitter": "Michael Darlin", "authors": "Michael Darlin, Nikolaos Papadis, Leandros Tassiulas", "title": "Optimal Bidding Strategy for Maker Auctions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.TR q-fin.PM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Maker Protocol is a decentralized finance application that enables\ncollateralized lending. The application uses open-bid, second-price auctions to\ncomplete its loan liquidation process. In this paper, we develop a bidding\nfunction for these auctions, focusing on the costs incurred to participate in\nthe auctions. We then optimize these costs using parameters from historical\nauction data, and compare our optimal bidding prices to the historical auction\nprices. We find that the majority of auctions end at higher prices than our\nrecommended optimal prices, and we propose several theories for these results.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 13:30:19 GMT"}, {"version": "v2", "created": "Wed, 26 May 2021 16:00:52 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Darlin", "Michael", ""], ["Papadis", "Nikolaos", ""], ["Tassiulas", "Leandros", ""]]}, {"id": "2009.07200", "submitter": "Eric Benhamou", "authors": "Eric Benhamou, David Saltiel, Jean-Jacques Ohana, and Jamal Atif", "title": "Detecting and adapting to crisis pattern with context based Deep\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (DRL) has reached super human levels in complex\ntasks like game solving (Go and autonomous driving). However, it remains an\nopen question whether DRL can reach human level in applications to financial\nproblems and in particular in detecting pattern crisis and consequently\ndis-investing. In this paper, we present an innovative DRL framework consisting\nin two sub-networks fed respectively with portfolio strategies past\nperformances and standard deviations as well as additional contextual features.\nThe second sub network plays an important role as it captures dependencies with\ncommon financial indicators features like risk aversion, economic surprise\nindex and correlations between assets that allows taking into account context\nbased information. We compare different network architectures either using\nlayers of convolutions to reduce network's complexity or LSTM block to capture\ntime dependency and whether previous allocations is important in the modeling.\nWe also use adversarial training to make the final model more robust. Results\non test set show this approach substantially over-performs traditional\nportfolio optimization methods like Markowitz and is able to detect and\nanticipate crisis like the current Covid one.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 12:11:08 GMT"}, {"version": "v2", "created": "Mon, 9 Nov 2020 07:49:45 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Benhamou", "Eric", ""], ["Saltiel", "David", ""], ["Ohana", "Jean-Jacques", ""], ["Atif", "Jamal", ""]]}, {"id": "2009.07892", "submitter": "Christopher Kath", "authors": "Christopher Kath and Florian Ziel", "title": "Optimal Order Execution in Intraday Markets: Minimizing Costs in Trade\n  Trajectories", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.TR q-fin.PM", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Optimal execution, i.e., the determination of the most cost-effective way to\ntrade volumes in continuous trading sessions, has been a topic of interest in\nthe equity trading world for years. Electricity intraday trading slowly follows\nthis trend but is far from being well-researched. The underlying problem is a\nvery complex one. Energy traders, producers, and electricity wholesale\ncompanies receive various position updates from customer businesses, renewable\nenergy production, or plant outages and need to trade these positions in\nintraday markets. They have a variety of options when it comes to position\nsizing or timing. Is it better to trade all amounts at once? Should they split\norders into smaller pieces? Taking the German continuous hourly intraday market\nas an example, this paper derives an appropriate model for electricity trading.\nWe present our results from an out-of-sample study and differentiate between\nsimple benchmark models and our more refined optimization approach that takes\ninto account order book depth, time to delivery, and different trading regimes\nlike XBID (Cross-Border Intraday Project) trading. Our paper is highly relevant\nas it contributes further insight into the academic discussion of algorithmic\nexecution in continuous intraday markets and serves as an orientation for\npractitioners. Our initial results suggest that optimal execution strategies\nhave a considerable monetary impact.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 18:54:51 GMT"}, {"version": "v2", "created": "Sat, 3 Oct 2020 19:35:34 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Kath", "Christopher", ""], ["Ziel", "Florian", ""]]}, {"id": "2009.08412", "submitter": "Kyle Steinhauer", "authors": "Kyle Steinhauer, Takahisa Fukadai, Sho Yoshida", "title": "Solving the Optimal Trading Trajectory Problem Using Simulated\n  Bifurcation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP q-fin.PM q-fin.RM quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use an optimization procedure based on simulated bifurcation (SB) to solve\nthe integer portfolio and trading trajectory problem with an unprecedented\ncomputational speed. The underlying algorithm is based on a classical\ndescription of quantum adiabatic evolutions of a network of non-linearly\ninteracting oscillators. This formulation has already proven to beat state of\nthe art computation times for other NP-hard problems and is expected to show\nsimilar performance for certain portfolio optimization problems. Inspired by\nsuch we apply the SB approach to the portfolio integer optimization problem\nwith quantity constraints and trading activities. We show first numerical\nresults for portfolios of up to 1000 assets, which already confirm the power of\nthe SB algorithm for its novel use-case as a portfolio and trading trajectory\noptimizer.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 16:42:04 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Steinhauer", "Kyle", ""], ["Fukadai", "Takahisa", ""], ["Yoshida", "Sho", ""]]}, {"id": "2009.08533", "submitter": "David Itkin", "authors": "David Itkin and Martin Larsson", "title": "Robust Asymptotic Growth in Stochastic Portfolio Theory under Long-Only\n  Constraints", "comments": "39 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.MF math.PR q-fin.PM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of maximizing the asymptotic growth rate of an\ninvestor under drift uncertainty in the setting of stochastic portfolio theory\n(SPT). As in the work of Kardaras and Robertson we take as inputs (i) a\nMarkovian volatility matrix $c(x)$ and (ii) an invariant density $p(x)$ for the\nmarket weights, but we additionally impose long-only constraints on the\ninvestor. Our principal contribution is proving a uniqueness and existence\nresult for the class of concave functionally generated portfolios and\ndeveloping a finite dimensional approximation, which can be used to numerically\nfind the optimum. In addition to the general results outlined above, we propose\nthe use of a broad class of models for the volatility matrix $c(x)$, which can\nbe calibrated to data and, under which, we obtain explicit formulas of the\noptimal unconstrained portfolio for any invariant density.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 21:02:14 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Itkin", "David", ""], ["Larsson", "Martin", ""]]}, {"id": "2009.08794", "submitter": "Jeremy Turiel", "authors": "Jeremy D. Turiel, Paolo Barucca and Tomaso Aste", "title": "Simplicial persistence of financial markets: filtering, generative\n  processes and portfolio risk", "comments": "8 pages, 5 figures, 3 tables. arXiv admin note: substantial text\n  overlap with arXiv:1910.08628", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST physics.soc-ph q-fin.PM q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce simplicial persistence, a measure of time evolution of network\nmotifs in subsequent temporal layers. We observe long memory in the evolution\nof structures from correlation filtering, with a two regime power law decay in\nthe number of persistent simplicial complexes. Null models of the underlying\ntime series are tested to investigate properties of the generative process and\nits evolutional constraints. Networks are generated with both TMFG filtering\ntechnique and thresholding showing that embedding-based filtering methods\n(TMFG) are able to identify higher order structures throughout the market\nsample, where thresholding methods fail. The decay exponents of these long\nmemory processes are used to characterise financial markets based on their\nstage of development and liquidity. We find that more liquid markets tend to\nhave a slower persistence decay. This is in contrast with the common\nunderstanding that developed markets are more random. We find that they are\nindeed less predictable for what concerns the dynamics of each single variable\nbut they are more predictable for what concerns the collective evolution of the\nvariables. This could imply higher fragility to systemic shocks.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 18:00:21 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Turiel", "Jeremy D.", ""], ["Barucca", "Paolo", ""], ["Aste", "Tomaso", ""]]}, {"id": "2009.08826", "submitter": "Frederic Butin", "authors": "Fr\\'ed\\'eric Butin", "title": "Generalized distance to a simplex and a new geometrical method for\n  portfolio optimization", "comments": "18 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Risk aversion plays a significant and central role in investors' decisions in\nthe process of developing a portfolio. In this framework of portfolio\noptimization we determine the portfolio that possesses the minimal risk by\nusing a new geometrical method. For this purpose, we elaborate an algorithm\nthat enables us to compute any generalized Euclidean distance to a standard\nsimplex. With this new approach, we are able to treat the case of portfolio\noptimization without short-selling in its entirety, and we also recover in\ngeometrical terms the well-known results on portfolio optimization with allowed\nshort-selling. Then, we apply our results in order to determine which convex\ncombination of the CAC 40 stocks possesses the lowest risk: not only we get a\nvery low risk compared to the index, but we also get a return rate that is\nalmost three times better than the one of the index.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 13:13:58 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Butin", "Fr\u00e9d\u00e9ric", ""]]}, {"id": "2009.10852", "submitter": "Keith Lewis", "authors": "Keith A. Lewis", "title": "Efficient Portfolios", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given two random realized returns on an investment, which is to be preferred?\nThis is a fundamental problem in finance that has no definitive solution except\nin the case one investment always returns more than the other. In 1952\nMarkowitz and Roy introduced the following criterion for risk vs. return in\nportfolio selection: if two portfolios have the same expected realized return\nthen prefer the one with smaller variance. An efficient portfolio has the least\nvariance among all portfolios having the same expected realized return.\n  The primary contribution of this short note is observation that the CAPM\nformula holds for realized returns as random variables, not just their\nexpectations. This follows directly from writing down a mathematical model for\none period investments.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 23:06:05 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Lewis", "Keith A.", ""]]}, {"id": "2009.11189", "submitter": "Weiqing Liu", "authors": "Xiao Yang, Weiqing Liu, Dong Zhou, Jiang Bian and Tie-Yan Liu", "title": "Qlib: An AI-oriented Quantitative Investment Platform", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.GN cs.LG q-fin.PM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantitative investment aims to maximize the return and minimize the risk in\na sequential trading period over a set of financial instruments. Recently,\ninspired by rapid development and great potential of AI technologies in\ngenerating remarkable innovation in quantitative investment, there has been\nincreasing adoption of AI-driven workflow for quantitative research and\npractical investment. In the meantime of enriching the quantitative investment\nmethodology, AI technologies have raised new challenges to the quantitative\ninvestment system. Particularly, the new learning paradigms for quantitative\ninvestment call for an infrastructure upgrade to accommodate the renovated\nworkflow; moreover, the data-driven nature of AI technologies indeed indicates\na requirement of the infrastructure with more powerful performance;\nadditionally, there exist some unique challenges for applying AI technologies\nto solve different tasks in the financial scenarios. To address these\nchallenges and bridge the gap between AI technologies and quantitative\ninvestment, we design and develop Qlib that aims to realize the potential,\nempower the research, and create the value of AI technologies in quantitative\ninvestment.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 12:57:10 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Yang", "Xiao", ""], ["Liu", "Weiqing", ""], ["Zhou", "Dong", ""], ["Bian", "Jiang", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "2009.11367", "submitter": "Cheng Peng", "authors": "Cheng Peng and Young Shin Kim", "title": "Portfolio Optimization on Multivariate Regime Switching GARCH Model with\n  Normal Tempered Stable Innovation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM q-fin.MF q-fin.PM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a Markov regime switching GARCH model with multivariate normal\ntempered stable innovation to accommodate fat tails and other stylized facts in\nreturns of financial assets. The model is used to simulate sample paths as\ninput for portfolio optimization with risk measures, namely, conditional value\nat risk and conditional drawdown. The motivation is to have a portfolio that\navoids left tail events by combining models that incorporates fat tail with\noptimization that focuses on tail risk. In-sample test is conducted to\ndemonstrate goodness of fit. Out-of-sample test shows that our approach yields\nhigher performance measured by Sharpe-like ratios than the market and equally\nweighted portfolio in recent years which includes some of the most volatile\nperiods in history. We also find that suboptimal portfolios with higher return\nconstraints tend to outperform optimal portfolios.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 20:25:14 GMT"}, {"version": "v2", "created": "Mon, 30 Nov 2020 02:39:48 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Peng", "Cheng", ""], ["Kim", "Young Shin", ""]]}, {"id": "2009.14136", "submitter": "Eric Benhamou", "authors": "Eric Benhamou, David Saltiel, Sandrine Ungari, Abhishek Mukhopadhyay", "title": "Time your hedge with Deep Reinforcement Learning", "comments": "9 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can an asset manager plan the optimal timing for her/his hedging strategies\ngiven market conditions? The standard approach based on Markowitz or other more\nor less sophisticated financial rules aims to find the best portfolio\nallocation thanks to forecasted expected returns and risk but fails to fully\nrelate market conditions to hedging strategies decision. In contrast, Deep\nReinforcement Learning (DRL) can tackle this challenge by creating a dynamic\ndependency between market information and hedging strategies allocation\ndecisions. In this paper, we present a realistic and augmented DRL framework\nthat: (i) uses additional contextual information to decide an action, (ii) has\na one period lag between observations and actions to account for one day lag\nturnover of common asset managers to rebalance their hedge, (iii) is fully\ntested in terms of stability and robustness thanks to a repetitive train test\nmethod called anchored walk forward training, similar in spirit to k fold cross\nvalidation for time series and (iv) allows managing leverage of our hedging\nstrategy. Our experiment for an augmented asset manager interested in sizing\nand timing his hedges shows that our approach achieves superior returns and\nlower risk.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 06:43:41 GMT"}, {"version": "v2", "created": "Mon, 9 Nov 2020 07:56:27 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Benhamou", "Eric", ""], ["Saltiel", "David", ""], ["Ungari", "Sandrine", ""], ["Mukhopadhyay", "Abhishek", ""]]}, {"id": "2009.14559", "submitter": "Dorothee Westphal", "authors": "J\\\"orn Sass, Dorothee Westphal", "title": "Robust Utility Maximization in a Multivariate Financial Market with\n  Stochastic Drift", "comments": "26 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a utility maximization problem in a financial market with a\nstochastic drift process, combining a worst-case approach with filtering\ntechniques. Drift processes are difficult to estimate from asset prices, and at\nthe same time optimal strategies in portfolio optimization problems depend\ncrucially on the drift. We approach this problem by setting up a worst-case\noptimization problem with a time-dependent uncertainty set for the drift.\nInvestors assume that the worst possible drift process with values in the\nuncertainty set will occur. This leads to local optimization problems, and the\nresulting optimal strategy needs to be updated continuously in time. We prove a\nminimax theorem for the local optimization problems and derive the optimal\nstrategy. Further, we show how an ellipsoidal uncertainty set can be defined\nbased on filtering techniques and demonstrate that investors need to choose a\nrobust strategy to be able to profit from additional information.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 11:00:41 GMT"}, {"version": "v2", "created": "Wed, 24 Mar 2021 13:22:20 GMT"}, {"version": "v3", "created": "Sun, 30 May 2021 12:03:59 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Sass", "J\u00f6rn", ""], ["Westphal", "Dorothee", ""]]}, {"id": "2009.14561", "submitter": "Aurelio F. Bariviera", "authors": "Nektarios Aslanidis, Aurelio F. Bariviera, Alejandro Perez-Laborda", "title": "Are cryptocurrencies becoming more interconnected?", "comments": "15 pages, 5 figures, 5 tables, supplementary material included", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST q-fin.PM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the dynamic market linkages among cryptocurrencies during\nAugust 2015 - July 2020 and finds a substantial increase in market linkages for\nboth returns and volatilities. We use different methodologies to check the\ndifferent aspects of market linkages. Financial and regulatory implications are\ndiscussed.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 11:04:56 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Aslanidis", "Nektarios", ""], ["Bariviera", "Aurelio F.", ""], ["Perez-Laborda", "Alejandro", ""]]}]