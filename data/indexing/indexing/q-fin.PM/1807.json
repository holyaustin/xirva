[{"id": "1807.00568", "submitter": "Dorothee Westphal", "authors": "J\\\"orn Sass, Dorothee Westphal, Ralf Wunderlich", "title": "Diffusion Approximations for Expert Opinions in a Financial Market with\n  Gaussian Drift", "comments": "Update with changes in notation, 38 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates a financial market where returns depend on an\nunobservable Gaussian drift process. While the observation of returns yields\ninformation about the underlying drift, we also incorporate discrete-time\nexpert opinions as an external source of information.\n  For estimating the hidden drift it is crucial to consider the conditional\ndistribution of the drift given the available observations, the so-called\nfilter. For an investor observing both the return process and the discrete-time\nexpert opinions, we investigate in detail the asymptotic behavior of the filter\nas the frequency of the arrival of expert opinions tends to infinity. In our\nsetting, a higher frequency of expert opinions comes at the cost of accuracy,\nmeaning that as the frequency of expert opinions increases, the variance of\nexpert opinions becomes larger. We consider a model where information dates are\ndeterministic and equidistant and another model where the information dates\narrive randomly as the jump times of a Poisson process. In both cases we derive\nlimit theorems stating that the information obtained from observing the\ndiscrete-time expert opinions is asymptotically the same as that from observing\na certain diffusion process which can be interpreted as a continuous-time\nexpert.\n  We use our limit theorems to derive so-called diffusion approximations of the\nfilter for high-frequency discrete-time expert opinions. These diffusion\napproximations are extremely helpful for deriving simplified approximate\nsolutions of utility maximization problems.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 09:45:21 GMT"}, {"version": "v2", "created": "Fri, 18 Jan 2019 16:49:13 GMT"}, {"version": "v3", "created": "Mon, 18 Nov 2019 13:19:39 GMT"}, {"version": "v4", "created": "Thu, 5 Mar 2020 09:22:44 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Sass", "J\u00f6rn", ""], ["Westphal", "Dorothee", ""], ["Wunderlich", "Ralf", ""]]}, {"id": "1807.01979", "submitter": "Marco Piccirilli", "authors": "Marco Piccirilli and Tiziano Vargiolu", "title": "Optimal Portfolio in Intraday Electricity Markets Modelled by\n  L\\'evy-Ornstein-Uhlenbeck Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PM math.OC math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study an optimal portfolio problem designed for an agent operating in\nintraday electricity markets. The investor is allowed to trade in a single\nrisky asset modelling the continuously traded power and aims to maximize the\nexpected terminal utility of his wealth. We assume a mean-reverting additive\nprocess to drive the power prices. In the case of logarithmic utility, we\nreduce the fully non-linear Hamilton-Jacobi-Bellman equation to a linear\nparabolic integro-differential equation, for which we explicitly exhibit a\nclassical solution in two cases of modelling interest. The optimal strategy is\ngiven implicitly as the solution of an integral equation, which is possible to\nsolve numerically as well as to describe analytically. An analysis of two\ndifferent approximations for the optimal policy is provided. Finally, we\nperform a numerical test by adapting the parameters of a popular electricity\nspot price model.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2018 13:00:50 GMT"}], "update_date": "2018-07-06", "authors_parsed": [["Piccirilli", "Marco", ""], ["Vargiolu", "Tiziano", ""]]}, {"id": "1807.05265", "submitter": "Chung-Han Hsieh", "authors": "Chung-Han Hsieh, John A. Gubner, B. Ross Barmish", "title": "Rebalancing Frequency Considerations for Kelly-Optimal Stock Portfolios\n  in a Control-Theoretic Framework", "comments": "To appear in the Proceedings of the IEEE Conference on Decision and\n  Control, Miami Beach, FL, 2018", "journal-ref": null, "doi": "10.1109/CDC.2018.8619189", "report-no": null, "categories": "q-fin.PM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, motivated by the celebrated work of Kelly, we consider the\nproblem of portfolio weight selection to maximize expected logarithmic growth.\nGoing beyond existing literature, our focal point here is the rebalancing\nfrequency which we include as an additional parameter in our analysis. The\nproblem is first set in a control-theoretic framework, and then, the main\nquestion we address is as follows: In the absence of transaction costs, does\nhigh-frequency trading always lead to the best performance? Related to this is\nour prior work on betting, also in the Kelly context, which examines the impact\nof making a wager and letting it ride. Our results on betting frequency can be\ninterpreted in the context of weight selection for a two-asset portfolio\nconsisting of one risky asset and one riskless asset. With regard to the\nquestion above, our prior results indicate that it is often the case that there\nare no performance benefits associated with high-frequency trading. In the\npresent paper, we generalize the analysis to portfolios with multiple risky\nassets. We show that if there is an asset satisfying a new condition which we\ncall dominance, then an optimal portfolio consists of this asset alone; i.e.,\nthe trader has \"all eggs in one basket\" and performance becomes a constant\nfunction of rebalancing frequency. Said another way, the problem of rebalancing\nis rendered moot. The paper also includes simulations which address practical\nconsiderations associated with real stock prices and the dominant asset\ncondition.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jul 2018 19:51:52 GMT"}, {"version": "v2", "created": "Tue, 21 Aug 2018 21:17:43 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Hsieh", "Chung-Han", ""], ["Gubner", "John A.", ""], ["Barmish", "B. Ross", ""]]}, {"id": "1807.05773", "submitter": "Kerem Ugurlu", "authors": "Kerem Ugurlu", "title": "Portfolio Optimization with Nondominated Priors and Unbounded Parameters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC q-fin.PM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider classical Merton problem of terminal wealth maximization in\nfinite horizon. We assume that the drift of the stock is following\nOrnstein-Uhlenbeck process and the volatility of it is following GARCH(1)\nprocess. In particular, both mean and volatility are unbounded. We assume that\nthere is Knightian uncertainty on the parameters of both mean and volatility.\nWe take that the investor has logarithmic utility function, and solve the\ncorresponding utility maximization problem explicitly. To the best of our\nknowledge, this is the first work on utility maximization with unbounded mean\nand volatility in Knightian uncertainty under nondominated priors.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 10:26:00 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Ugurlu", "Kerem", ""]]}, {"id": "1807.06449", "submitter": "Sina Yansori", "authors": "Tahir Choulli and Sina Yansori", "title": "Log-optimal portfolio without NFLVR: existence, complete\n  characterization, and duality", "comments": "arXiv admin note: text overlap with arXiv:1803.10128", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.MF q-fin.PM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the log-optimal portfolio for a general semimartingale\nmodel. The most advanced literature on the topic elaborates existence and\ncharacterization of this portfolio under no-free-lunch-with-vanishing-risk\nassumption (NFLVR). There are many financial models violating NFLVR, while\nadmitting the log-optimal portfolio on the one hand. On the other hand, for\nfinancial markets under progressively enlargement of filtration, NFLVR remains\ncompletely an open issue, and hence the literature can be applied to these\nmodels. Herein, we provide a complete characterization of log-optimal portfolio\nand its associated optimal deflator, necessary and sufficient conditions for\ntheir existence, and we elaborate their duality as well without NFLVR.\n", "versions": [{"version": "v1", "created": "Sat, 14 Jul 2018 02:03:47 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Choulli", "Tahir", ""], ["Yansori", "Sina", ""]]}, {"id": "1807.08278", "submitter": "Johannes Muhle-Karbe", "authors": "Peter Bank, Ibrahim Ekren, Johannes Muhle-Karbe", "title": "Liquidity in Competitive Dealer Markets", "comments": "29 pages, 3 figures, forthcoming in 'Mathematical Finance'", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.TR q-fin.GN q-fin.PM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a continuous-time version of the intermediation model of Grossman\nand Miller (1988). To wit, we solve for the competitive equilibrium prices at\nwhich liquidity takers' demands are absorbed by dealers with quadratic\ninventory costs, who can in turn gradually transfer these positions to an\nexogenous open market with finite liquidity. This endogenously leads to\ntransient price impact in the dealer market. Smooth, diffusive, and discrete\ntrades all incur finite but nontrivial liquidity costs, and can arise naturally\nfrom the liquidity takers' optimization.\n", "versions": [{"version": "v1", "created": "Sun, 22 Jul 2018 12:31:09 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2020 17:13:51 GMT"}, {"version": "v3", "created": "Tue, 2 Mar 2021 09:08:32 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Bank", "Peter", ""], ["Ekren", "Ibrahim", ""], ["Muhle-Karbe", "Johannes", ""]]}, {"id": "1807.09864", "submitter": "Eric Benhamou", "authors": "Eric Benhamou and Beatrice Guez", "title": "Incremental Sharpe and other performance ratios", "comments": "18 pages", "journal-ref": "Journal of Statistical and Econometric Methods, vol.7, no.4, 2018,\n  19-37", "doi": null, "report-no": null, "categories": "q-fin.PM q-fin.RM q-fin.ST stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new methodology of computing incremental contribution for\nperformance ratios for portfolio like Sharpe, Treynor, Calmar or Sterling\nratios. Using Euler's homogeneous function theorem, we are able to decompose\nthese performance ratios as a linear combination of individual modified\nperformance ratios. This allows understanding the drivers of these performance\nratios as well as deriving a condition for a new asset to provide incremental\nperformance for the portfolio. We provide various numerical examples of this\nperformance ratio decomposition.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jul 2018 16:30:47 GMT"}, {"version": "v2", "created": "Fri, 27 Jul 2018 01:12:25 GMT"}, {"version": "v3", "created": "Tue, 4 Sep 2018 05:47:16 GMT"}, {"version": "v4", "created": "Sun, 16 Sep 2018 10:52:25 GMT"}, {"version": "v5", "created": "Mon, 17 Dec 2018 07:19:59 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Benhamou", "Eric", ""], ["Guez", "Beatrice", ""]]}, {"id": "1807.09919", "submitter": "Zurab Kakushadze", "authors": "Zura Kakushadze and Willie Yu", "title": "Betas, Benchmarks and Beating the Market", "comments": "36 pages; to appear in The Journal of Trading", "journal-ref": "The Journal of Trading 13(3) (2018) 44-66", "doi": null, "report-no": null, "categories": "q-fin.PM q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give an explicit formulaic algorithm and source code for building\nlong-only benchmark portfolios and then using these benchmarks in long-only\nmarket outperformance strategies. The benchmarks (or the corresponding betas)\ndo not involve any principal components, nor do they require iterations.\nInstead, we use a multifactor risk model (which utilizes multilevel industry\nclassification or clustering) specifically tailored to long-only benchmark\nportfolios to compute their weights, which are explicitly positive in our\nconstruction.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2018 01:58:39 GMT"}], "update_date": "2018-08-02", "authors_parsed": [["Kakushadze", "Zura", ""], ["Yu", "Willie", ""]]}, {"id": "1807.09967", "submitter": "Artit Wangperawong", "authors": "Xinyi Liu and Artit Wangperawong", "title": "A Collaborative Approach to Angel and Venture Capital Investment\n  Recommendations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PM cs.IR cs.LG q-fin.GN stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix factorization was used to generate investment recommendations for\ninvestors. An iterative conjugate gradient method was used to optimize the\nregularized squared-error loss function. The number of latent factors, number\nof iterations, and regularization values were explored. Overfitting can be\naddressed by either early stopping or regularization parameter tuning. The\nmodel achieved the highest average prediction accuracy of 13.3%. With a similar\nmodel, the same dataset was used to generate investor recommendations for\ncompanies undergoing fundraising, which achieved highest prediction accuracy of\n11.1%.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2018 06:14:08 GMT"}], "update_date": "2018-07-27", "authors_parsed": [["Liu", "Xinyi", ""], ["Wangperawong", "Artit", ""]]}, {"id": "1807.11381", "submitter": "Natalie Packham", "authors": "Natalie Packham and Fabian Woebbeking", "title": "A factor-model approach for correlation scenarios and correlation\n  stress-testing", "comments": null, "journal-ref": "Journal of Banking and Finance, 101 (2019), 92-103", "doi": "10.1016/j.jbankfin.2019.01.020", "report-no": null, "categories": "q-fin.RM q-fin.PM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 2012, JPMorgan accumulated a USD~6.2 billion loss on a credit derivatives\nportfolio, the so-called `London Whale', partly as a consequence of\nde-correlations of non-perfectly correlated positions that were supposed to\nhedge each other. Motivated by this case, we devise a factor model for\ncorrelations that allows for scenario-based stress testing of correlations. We\nderive a number of analytical results related to a portfolio of homogeneous\nassets. Using the concept of Mahalanobis distance, we show how to identify\nadverse scenarios of correlation risk. In addition, we demonstrate how\ncorrelation and volatility stress tests can be combined. As an example, we\napply the factor-model approach to the \"London Whale\" portfolio and determine\nthe value-at-risk impact from correlation changes. Since our findings are\nparticularly relevant for large portfolios, where even small correlation\nchanges can have a large impact, a further application would be to stress test\nportfolios of central counterparties, which are of systemically relevant size.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2018 14:55:36 GMT"}, {"version": "v2", "created": "Tue, 27 Nov 2018 08:53:05 GMT"}, {"version": "v3", "created": "Mon, 28 Jan 2019 19:03:19 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Packham", "Natalie", ""], ["Woebbeking", "Fabian", ""]]}]