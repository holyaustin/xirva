[{"id": "0903.1525", "submitter": "Gilles Zumbach", "authors": "Gilles Zumbach", "title": "The empirical properties of large covariance matrices", "comments": "21 pages,9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST q-fin.PM q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The salient properties of large empirical covariance and correlation matrices\nare studied for three datasets of size 54, 55 and 330. The covariance is\ndefined as a simple cross product of the returns, with weights that decay\nlogarithmically slowly. The key general properties of the covariance matrices\nare the following. The spectrum of the covariance is very static, except for\nthe top three to ten eigenvalues, and decay exponentially fast toward zero. The\nmean spectrum and spectral density show no particular feature that would\nseparate \"meaningful\" from \"noisy\" eigenvalues. The spectrum of the correlation\nis more static, with three to five eigenvalues that have distinct dynamics. The\nmean projector of rank k on the leading subspace shows instead that most of the\ndynamics occur in the eigenvectors, including deep in the spectrum. Together,\nthis implies that the reduction of the covariance to a few leading eigenmodes\nmisses most of the dynamics, and that a covariance estimator correctly\nevaluates both volatilities and correlations.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2009 11:00:31 GMT"}], "update_date": "2009-03-10", "authors_parsed": [["Zumbach", "Gilles", ""]]}, {"id": "0903.1531", "submitter": "Gilles Zumbach", "authors": "Gilles Zumbach", "title": "Inference on multivariate ARCH processes with large sizes", "comments": "22 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST q-fin.PM q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The covariance matrix is formulated in the framework of a linear multivariate\nARCH process with long memory, where the natural cross product structure of the\ncovariance is generalized by adding two linear terms with their respective\nparameter. The residuals of the linear ARCH process are computed using\nhistorical data and the (inverse square root of the) covariance matrix. Simple\nmeasure of qualities assessing the independence and unit magnitude of the\nresidual distributions are proposed. The salient properties of the computed\nresiduals are studied for three data sets of size 54, 55 and 330. Both new\nterms introduced in the covariance help in producing uncorrelated residuals,\nbut the residual magnitudes are very different from unity. The large sizes of\nthe inferred residuals are due to the limited information that can be extracted\nfrom the empirical data when the number of time series is large, and denotes a\nfundamental limitation to the inference that can be achieved.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2009 11:14:50 GMT"}], "update_date": "2009-03-10", "authors_parsed": [["Zumbach", "Gilles", ""]]}, {"id": "0903.2243", "submitter": "Edward D. Weinberger", "authors": "Edward D. Weinberger", "title": "Pragmatic Information Rates, Generalizations of the Kelly Criterion, and\n  Financial Market Efficiency", "comments": "Revised to clarify the text", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT q-fin.PM q-fin.TR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is part of an ongoing investigation of \"pragmatic information\",\ndefined in Weinberger (2002) as \"the amount of information actually used in\nmaking a decision\". Because a study of information rates led to the Noiseless\nand Noisy Coding Theorems, two of the most important results of Shannon's\ntheory, we begin the paper by defining a pragmatic information rate, showing\nthat all of the relevant limits make sense, and interpreting them as the\nimprovement in compression obtained from using the correct distribution of\ntransmitted symbols.\n  The first of two applications of the theory extends the information theoretic\nanalysis of the Kelly Criterion, and its generalization, the horse race, to a\nseries of races where the stochastic process of winning horses, payoffs, and\nstrategies depend on some stationary process, including, but not limited to the\nhistory of previous races. If the bettor is receiving messages (side\ninformation) about the probability distribution of winners, the doubling rate\nof the bettor's winnings is bounded by the pragmatic information of the\nmessages.\n  A second application is to the question of market efficiency. An efficient\nmarket is, by definition, a market in which the pragmatic information of the\n\"tradable past\" with respect to current prices is zero. Under this definition,\nmarkets whose returns are characterized by a GARCH(1,1) process cannot be\nefficient.\n  Finally, a pragmatic informational analogue to Shannon's Noisy Coding Theorem\nsuggests that a cause of market inefficiency is that the underlying\nfundamentals are changing so fast that the price discovery mechanism simply\ncannot keep up. This may happen most readily in the run-up to a financial\nbubble, where investors' willful ignorance degrade the information processing\ncapabilities of the market.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2009 18:27:02 GMT"}, {"version": "v2", "created": "Sat, 11 Dec 2010 06:00:35 GMT"}, {"version": "v3", "created": "Mon, 28 Feb 2011 14:55:08 GMT"}, {"version": "v4", "created": "Mon, 22 Sep 2014 23:48:22 GMT"}], "update_date": "2014-09-24", "authors_parsed": [["Weinberger", "Edward D.", ""]]}, {"id": "0903.2910", "submitter": "Bernhard Meister", "authors": "Yingdong Lv, Bernhard K. Meister", "title": "Application of the Kelly Criterion to Ornstein-Uhlenbeck Processes", "comments": "presented at Complex'2009 (Shanghai, Feb. 23-25)", "journal-ref": null, "doi": "10.1007/978-3-642-02466-5_105", "report-no": null, "categories": "q-fin.PM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the Kelly criterion in the continuous time framework\nbuilding on the work of E.O. Thorp and others. The existence of an optimal\nstrategy is proven in a general setting and the corresponding optimal wealth\nprocess is found. A simple formula is provided for calculating the optimal\nportfolio for a set of price processes satisfying some simple conditions.\nProperties of the optimal investment strategy for assets governed by multiple\nOrnstein-Uhlenbeck processes are studied. The paper ends with a short\ndiscussion of the implications of these ideas for financial markets.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2009 07:24:32 GMT"}], "update_date": "2015-05-13", "authors_parsed": [["Lv", "Yingdong", ""], ["Meister", "Bernhard K.", ""]]}]