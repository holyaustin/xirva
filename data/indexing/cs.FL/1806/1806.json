[{"id": "1806.00528", "submitter": "Giovanni Bacci", "authors": "Giovanni Bacci and Giorgio Bacci and Kim G. Larsen and Radu Mardare", "title": "On the Metric-based Approximate Minimization of Markov Chains", "comments": "This article in an extended and revised version of a paper accepted\n  for publication at ICALP 2017", "journal-ref": null, "doi": "10.1016/j.jlamp.2018.05.006", "report-no": null, "categories": "cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we address the approximate minimization problem of Markov\nChains (MCs) from a behavioral metric-based perspective. Specifically, given a\nfinite MC and a positive integer k, we are looking for an MC with at most k\nstates having minimal distance to the original. The metric considered in this\nwork is the bisimilarity distance of Desharnais et al.. For this metric we show\nthat (1) optimal approximations always exist; (2) the problem has a bilinear\nprogram characterization; and (3) prove that its threshold problem is in PSPACE\nand NP-hard. In addition to the bilinear program solution, we present an\napproach inspired by expectation maximization techniques for computing\nsuboptimal solutions to the problem. Experiments suggest that our method gives\na practical approach that outperforms the bilinear program implementation run\non state-of-the-art bilinear solvers.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 13:09:33 GMT"}], "update_date": "2018-06-07", "authors_parsed": [["Bacci", "Giovanni", ""], ["Bacci", "Giorgio", ""], ["Larsen", "Kim G.", ""], ["Mardare", "Radu", ""]]}, {"id": "1806.00842", "submitter": "Michael Bar-Sinai", "authors": "Michael Bar-Sinai, Gera Weiss, Reut Shmuel", "title": "BPjs --- a framework for modeling reactive systems using a scripting\n  language and BP", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.FL cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe some progress towards a new common framework for model driven\nengineering, based on behavioral programming. The tool we have developed\nunifies almost all of the work done in behavioral programming so far, under a\ncommon set of interfaces. Its architecture supports pluggable event selection\nstrategies, which can make models more intuitive and compact. Program state\nspace can be traversed using various algorithms, such as DFS and A*.\nFurthermore, program state is represented in a way that enables scanning a\nstate space using parallel and distributed algorithms. Executable models\ncreated with this tool can be directly embedded in Java applications, enabling\na model-first approach to system engineering, where initially a model is\ncreated and verified, and then a working application is gradually built around\nthe model. The model itself consists of a collection of small scripts written\nin JavaScript (hence \"BPjs\"). Using a variety of case-studies, this paper shows\nhow the combination of a lenient programming language with formal model\nanalysis tools creates an efficient way of developing robust complex systems.\nAdditionally, as we learned from an experimental course we ran, the usage of\nJavaScript make practitioners more amenable to using this system and, thus,\nmodel checking and model driven engineering. In addition to providing\ninfrastructure for development and case-studies in behavioral programming, the\ntool is designed to serve as a common platform for research and innovation in\nbehavioral programming and in model driven engineering in general.\n", "versions": [{"version": "v1", "created": "Sun, 3 Jun 2018 17:48:22 GMT"}], "update_date": "2018-06-05", "authors_parsed": [["Bar-Sinai", "Michael", ""], ["Weiss", "Gera", ""], ["Shmuel", "Reut", ""]]}, {"id": "1806.01630", "submitter": "Alexis Linard", "authors": "Alexis Linard", "title": "Learning Several Languages from Labeled Strings: State Merging and\n  Evolutionary Approaches", "comments": "This paper has been accepted at the Learning and Automata (LearnAut\n  2018) Workshop, FLOC 2018 (Oxford, UK)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of learning pairwise disjoint deterministic finite automata (DFA)\nfrom positive examples has been recently addressed. In this paper, we address\nthe problem of identifying a set of DFAs from labeled strings and come up with\ntwo methods. The first is based on state merging and a heuristic related to the\nsize of each state merging iteration. State merging operations involving a\nlarge number of states are extracted, to provide sub-DFAs. The second method is\nbased on a multi-objective evolutionary algorithm whose fitness function takes\ninto account the accuracy of the DFA w.r.t. the learning sample, as well as the\ndesired number of DFAs. We evaluate our methods on a dataset originated from\nindustry.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jun 2018 12:24:55 GMT"}, {"version": "v2", "created": "Tue, 12 Jun 2018 08:41:22 GMT"}], "update_date": "2018-06-13", "authors_parsed": [["Linard", "Alexis", ""]]}, {"id": "1806.02041", "submitter": "Micha{\\l} Skrzypczak", "authors": "Miko{\\l}aj Boja\\'nczyk, Filippo Cavallari, Thomas Place, Micha{\\l}\n  Skrzypczak", "title": "Regular tree languages in low levels of the Wadge Hierarchy", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 15, Issue 3 (September\n  4, 2019) lmcs:5743", "doi": "10.23638/LMCS-15(3:27)2019", "report-no": null, "categories": "cs.FL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this article we provide effective characterisations of regular languages\nof infinite trees that belong to the low levels of the Wadge hierarchy. More\nprecisely we prove decidability for each of the finite levels of the hierarchy;\nfor the class of the Boolean combinations of open sets $BC(\\Sigma_1^0)$ (i.e.\nthe union of the first $\\omega$ levels); and for the Borel class $\\Delta_2^0$\n(i.e. for the union of the first $\\omega_1$ levels).\n", "versions": [{"version": "v1", "created": "Wed, 6 Jun 2018 07:46:31 GMT"}, {"version": "v2", "created": "Sat, 16 Jun 2018 16:35:40 GMT"}, {"version": "v3", "created": "Mon, 17 Jun 2019 10:56:58 GMT"}, {"version": "v4", "created": "Mon, 2 Sep 2019 10:16:50 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Boja\u0144czyk", "Miko\u0142aj", ""], ["Cavallari", "Filippo", ""], ["Place", "Thomas", ""], ["Skrzypczak", "Micha\u0142", ""]]}, {"id": "1806.02718", "submitter": "Gabriele Fici", "authors": "Panagiotis Charalampopoulos, Maxime Crochemore, Gabriele Fici, Robert\n  Mercas, Solon P. Pissis", "title": "Alignment-free sequence comparison using absent words", "comments": "Extended version of \"Linear-Time Sequence Comparison Using Minimal\n  Absent Words & Applications\" Proc. LATIN 2016, arxiv:1506.04917", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence comparison is a prerequisite to virtually all comparative genomic\nanalyses. It is often realised by sequence alignment techniques, which are\ncomputationally expensive. This has led to increased research into\nalignment-free techniques, which are based on measures referring to the\ncomposition of sequences in terms of their constituent patterns. These\nmeasures, such as $q$-gram distance, are usually computed in time linear with\nrespect to the length of the sequences. In this paper, we focus on the\ncomplementary idea: how two sequences can be efficiently compared based on\ninformation that does not occur in the sequences. A word is an {\\em absent\nword} of some sequence if it does not occur in the sequence. An absent word is\n{\\em minimal} if all its proper factors occur in the sequence. Here we present\nthe first linear-time and linear-space algorithm to compare two sequences by\nconsidering {\\em all} their minimal absent words. In the process, we present\nresults of combinatorial interest, and also extend the proposed techniques to\ncompare circular sequences. We also present an algorithm that, given a word $x$\nof length $n$, computes the largest integer for which all factors of $x$ of\nthat length occur in some minimal absent word of $x$ in time and space\n$\\cO(n)$. Finally, we show that the known asymptotic upper bound on the number\nof minimal absent words of a word is tight.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jun 2018 15:03:00 GMT"}], "update_date": "2018-06-08", "authors_parsed": [["Charalampopoulos", "Panagiotis", ""], ["Crochemore", "Maxime", ""], ["Fici", "Gabriele", ""], ["Mercas", "Robert", ""], ["Pissis", "Solon P.", ""]]}, {"id": "1806.03315", "submitter": "Justin DeBenedetto", "authors": "Justin DeBenedetto and David Chiang", "title": "Algorithms and Training for Weighted Multiset Automata and Regular\n  Expressions", "comments": "Accepted to CIAA 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiset automata are a class of automata for which the symbols can be read\nin any order and obtain the same result. We investigate weighted multiset\nautomata and show how to construct them from weighted regular expressions. We\npresent training methods to learn the weights for weighted regular expressions\nand for general multiset automata from data. Finally, we examine situations in\nwhich inside weights can be computed more efficiently.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jun 2018 18:28:19 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["DeBenedetto", "Justin", ""], ["Chiang", "David", ""]]}, {"id": "1806.04361", "submitter": "Janusz Schmude", "authors": "Adrien Boiret, Rados{\\l}aw Pi\\'orkowski, Janusz Schmude", "title": "Reducing Transducer Equivalence to Register Automata Problems Solved by\n  \"Hilbert Method\"", "comments": null, "journal-ref": null, "doi": "10.4230/LIPIcs.FSTTCS.2018.48", "report-no": null, "categories": "cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past decades, classical results from algebra, including Hilbert's\nBasis Theorem, had various applications in formal languages, including a proof\nof the Ehrenfeucht Conjecture, decidability of HDT0L sequence equivalence, and\ndecidability of the equivalence problem for functional tree-to-string\ntransducers. In this paper, we study the scope of the algebraic methods\nmentioned above, particularily as applied to the equivalence problem for\nregister automata. We provide two results, one positive, one negative. The\npositive result is that equivalence is decidable for MSO transformations on\nunordered forests. The negative result comes from a try to extend this method\nto decide equivalence on macro tree transducers. We reduce macro tree\ntransducers equivalence to an equivalence problem for some class of register\nautomata naturally relevant to our method. We then prove this latter problem to\nbe undecidable.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jun 2018 07:11:53 GMT"}, {"version": "v2", "created": "Fri, 4 Jan 2019 10:36:42 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Boiret", "Adrien", ""], ["Pi\u00f3rkowski", "Rados\u0142aw", ""], ["Schmude", "Janusz", ""]]}, {"id": "1806.04478", "submitter": "Erez Nesharim", "authors": "Faustin Adiceam, Erez Nesharim and Fred Lunnon", "title": "On the $t$-adic Littlewood Conjecture", "comments": "36 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NT cs.DM cs.FL math.CO math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The $p$-adic Littlewood Conjecture due to De Mathan and Teuli\\'e asserts that\nfor any prime number $p$ and any real number $\\alpha$, the equation\n$$\\inf_{|m|\\ge 1} |m|\\cdot |m|_p\\cdot |\\langle m\\alpha \\rangle|\\, =\\, 0 $$\nholds. Here, $|m|$ is the usual absolute value of the integer $m$, $|m|_p$ its\n$p$-adic absolute value and $ |\\langle x\\rangle|$ denotes the distance from a\nreal number $x$ to the set of integers. This still open conjecture stands as a\nvariant of the well-known Littlewood Conjecture. In the same way as the latter,\nit admits a natural counterpart over the field of formal Laurent series\n$\\mathbb{K}\\left(\\left(t^{-1}\\right)\\right)$ of a ground field $\\mathbb{K}$.\nThis is the so-called \\emph{$t$-adic Littlewood Conjecture} ($t$-LC).\n  It is known that $t$--LC fails when the ground field $\\mathbb{K}$ is\ninfinite. This article is concerned with the much more difficult case when the\nlatter field is finite. More precisely, a \\emph{fully explicit} counterexample\nis provided to show that $t$-LC does not hold in the case that $\\mathbb{K}$ is\na finite field with characteristic 3. Generalizations to fields with\ncharacteristics different from 3 are also discussed.\n  The proof is computer assisted. It reduces to showing that an infinite matrix\nencoding Hankel determinants of the Paper-Folding sequence over $\\mathbb{F}_3$,\nthe so-called Number Wall of this sequence, can be obtained as a\ntwo-dimensional automatic tiling satisfying a finite number of suitable local\nconstraints.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jun 2018 13:01:26 GMT"}, {"version": "v2", "created": "Sun, 11 Oct 2020 08:11:07 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Adiceam", "Faustin", ""], ["Nesharim", "Erez", ""], ["Lunnon", "Fred", ""]]}, {"id": "1806.04645", "submitter": "Sylvie Davies", "authors": "Janusz A. Brzozowski, Sylvie Davies, Abhishek Madan", "title": "State Complexity of Pattern Matching in Regular Languages", "comments": "30 pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a simple pattern matching problem one has a pattern $w$ and a text $t$,\nwhich are words over a finite alphabet $\\Sigma$. One may ask whether $w$ occurs\nin $t$, and if so, where? More generally, we may have a set $P$ of patterns and\na set $T$ of texts, where $P$ and $T$ are regular languages. We are interested\nwhether any word of $T$ begins with a word of $P$, ends with a word of $P$, has\na word of $P$ as a factor, or has a word of $P$ as a subsequence. Thus we are\ninterested in the languages $(P\\Sigma^*)\\cap T$, $(\\Sigma^*P)\\cap T$,\n$(\\Sigma^* P\\Sigma^*)\\cap T$, and $(\\Sigma^* \\mathbin{\\operatorname{shu}}\nP)\\cap T$, where $\\operatorname{shu}$ is the shuffle operation. The state\ncomplexity $\\kappa(L)$ of a regular language $L$ is the number of states in the\nminimal deterministic finite automaton recognizing $L$. We derive the following\nupper bounds on the state complexities of our pattern-matching languages, where\n$\\kappa(P)\\le m$, and $\\kappa(T)\\le n$: $\\kappa((P\\Sigma^*)\\cap T) \\le mn$;\n$\\kappa((\\Sigma^*P)\\cap T) \\le 2^{m-1}n$; $\\kappa((\\Sigma^*P\\Sigma^*)\\cap T)\n\\le (2^{m-2}+1)n$; and $\\kappa((\\Sigma^*\\mathbin{\\operatorname{shu}} P)\\cap T)\n\\le (2^{m-2}+1)n$. We prove that these bounds are tight, and that to meet them,\nthe alphabet must have at least two letters in the first three cases, and at\nleast $m-1$ letters in the last case. We also consider the special case where\n$P$ is a single word $w$, and obtain the following tight upper bounds:\n$\\kappa((w\\Sigma^*)\\cap T_n) \\le m+n-1$; $\\kappa((\\Sigma^*w)\\cap T_n) \\le\n(m-1)n-(m-2)$; $\\kappa((\\Sigma^*w\\Sigma^*)\\cap T_n) \\le (m-1)n$; and\n$\\kappa((\\Sigma^*\\mathbin{\\operatorname{shu}} w)\\cap T_n) \\le (m-1)n$. For\nunary languages, we have a tight upper bound of $m+n-2$ in all eight of the\naforementioned cases.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jun 2018 16:59:13 GMT"}, {"version": "v2", "created": "Sun, 4 Nov 2018 19:06:21 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Brzozowski", "Janusz A.", ""], ["Davies", "Sylvie", ""], ["Madan", "Abhishek", ""]]}, {"id": "1806.04996", "submitter": "Lukas Fleischer", "authors": "Lukas Fleischer", "title": "The Intersection Problem for Finite Semigroups", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the intersection problem for finite semigroups, which asks for\na given set of regular languages, represented by recognizing morphisms to\nfinite semigroups, whether there exists a word contained in their intersection.\nWe introduce compressibility measures as a useful tool to classify the\nintersection problem for certain classes of finite semigroups into circuit\ncomplexity classes and Turing machine complexity classes. Using this framework,\nwe obtain a new and simple proof that for groups and commutative semigroups,\nthe problem is contained in NP. We uncover certain structural and\nnon-structural properties determining the complexity of the intersection\nproblem for varieties of semigroups containing only trivial submonoids. More\nspecifically, we prove NP-hardness for classes of semigroups having a property\ncalled unbounded order and for the class of all nilpotent semigroups of bounded\norder. On the contrary, we show that bounded order and commutativity imply\ncontainment in the circuit complexity class qAC^k (for some k) and decidability\nin quasi-polynomial time. We also establish connections to the monoid variant\nof the problem.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2018 12:54:10 GMT"}], "update_date": "2018-06-14", "authors_parsed": [["Fleischer", "Lukas", ""]]}, {"id": "1806.06143", "submitter": "Radu Grigore", "authors": "Radu Grigore and Stefan Kiefer", "title": "Selective Monitoring", "comments": "CONCUR 2018", "journal-ref": null, "doi": "10.4230/LIPIcs.CONCUR.2018.20", "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study selective monitors for labelled Markov chains. Monitors observe the\noutputs that are generated by a Markov chain during its run, with the goal of\nidentifying runs as correct or faulty. A monitor is selective if it skips\nobservations in order to reduce monitoring overhead. We are interested in\nmonitors that minimize the expected number of observations. We establish an\nundecidability result for selectively monitoring general Markov chains. On the\nother hand, we show for non-hidden Markov chains (where any output identifies\nthe state the Markov chain is in) that simple optimal monitors exist and can be\ncomputed efficiently, based on DFA language equivalence. These monitors do not\ndepend on the precise transition probabilities in the Markov chain. We report\non experiments where we compute these monitors for several open-source Java\nprojects.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jun 2018 22:08:38 GMT"}, {"version": "v2", "created": "Mon, 2 Jul 2018 10:48:57 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Grigore", "Radu", ""], ["Kiefer", "Stefan", ""]]}, {"id": "1806.06299", "submitter": "Andrew Ryzhikov", "authors": "Andrew Ryzhikov, Marek Szyku{\\l}a", "title": "Finding Short Synchronizing Words for Prefix Codes", "comments": "Accepted to MFCS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problems of finding a shortest synchronizing word and its length\nfor a given prefix code. This is done in two different settings: when the code\nis defined by an arbitrary decoder recognizing its star and when the code is\ndefined by its literal decoder (whose size is polynomially equivalent to the\ntotal length of all words in the code). For the first case for every\n$\\varepsilon > 0$ we prove $n^{1 - \\varepsilon}$-inapproximability for\nrecognizable binary maximal prefix codes, $\\Theta(\\log n)$-inapproximability\nfor finite binary maximal prefix codes and $n^{\\frac{1}{2} -\n\\varepsilon}$-inapproximability for finite binary prefix codes. By\n$c$-inapproximability here we mean the non-existence of a $c$-approximation\npolynomial time algorithm under the assumption P $\\ne$ NP, and by $n$ the\nnumber of states of the decoder in the input. For the second case, we propose\napproximation and exact algorithms and conjecture that for finite maximal\nprefix codes the problem can be solved in polynomial time. We also study the\nrelated problems of finding a shortest mortal and a shortest avoiding word.\n", "versions": [{"version": "v1", "created": "Sat, 16 Jun 2018 21:18:06 GMT"}], "update_date": "2018-06-19", "authors_parsed": [["Ryzhikov", "Andrew", ""], ["Szyku\u0142a", "Marek", ""]]}, {"id": "1806.06562", "submitter": "Stefano Crespi Reghizzi", "authors": "Stefano Crespi Reghizzi and Pierluigi San Pietro", "title": "Deque languages, automata and planar graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The memory of a deque (double ended queue) automaton is more general than a\nqueue or two stacks; to avoid overgeneralization, we consider quasi-real-time\noperation. Normal forms of such automata are given. Deque languages form an AFL\nbut not a full one. We define the characteristic deque language, CDL, which\ncombines Dyck and AntiDyck (or FIFO) languages, and homomorphically\ncharacterizes the deque languages. The notion of deque graph, from graph\ntheory, well represents deque computation by means of a planar hamiltonian\ngraph on a cylinder, with edges visualizing producer-consumer relations for\ndeque symbols. We give equivalent definitions of CDL by labelled deque graphs,\nby cancellation rules, and by means of shuffle and intersection of simpler\nlanguages. The labeled deque graph of a sentence generalizes traditional syntax\ntrees. The layout of deque computations on a cylinder is remindful of 3D models\nused in theoretical (bio)chemistry.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2018 09:14:47 GMT"}], "update_date": "2018-06-19", "authors_parsed": [["Reghizzi", "Stefano Crespi", ""], ["Pietro", "Pierluigi San", ""]]}, {"id": "1806.06759", "submitter": "Ivan Scagnetto", "authors": "Alberto Ciaffaglione, Furio Honsell, Marina Lenisa, Ivan Scagnetto", "title": "Lambda-calculus and Reversible Automatic Combinators", "comments": "43 pages (22+21 of Appendix)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 2005, Abramsky introduced various linear/affine combinatory algebras of\npartial involutions over a suitable formal language, to discuss reversible\ncomputation in a game-theoretic setting. These algebras arise as instances of\nthe general paradigm explored by Haghverdi (Abramsky's Programme), which\namounts to defining a lambda-algebra starting from a GoI Situation in a traced\nsymmetric monoidal category. We investigate this construction from the point of\nview of the model theory of lambda-calculus. We focus on the strictly linear\nand affine parts of Abramsky's Affine Combinatory Algebras, sketching how to\nencompass the full algebra. The gist of our approach is that the GoI\ninterpretation of a term based on involutions is dual to the principal type of\nthe term, w.r.t. the type discipline for a linear/affine lambda-calculus. In\nthe general case the type discipline and the calculus need to be extended,\nresp., with intersection, !-types, and !-abstractions. Our analysis unveils\nthree conceptually independent, but ultimately equivalent, accounts of\napplication in the lambda-calculus: beta-reduction, the GoI application of\ninvolutions based on symmetric feedback (Girard's Execution Formula), and\nunification of principal types. Thus we provide an answer, in the strictly\naffine case, to the question raised in [1] of characterising the partial\ninvolutions arising from bi-orthogonal pattern matching automata, which are\ndenotations of affine combinators, and we point to the answer to the full\nquestion. Furthermore, we prove that the strictly linear combinatory algebra of\npartial involutions is a strictly linear lambda-algebra, albeit not a\ncombinatory model, while both the strictly affine combinatory algebra and the\nfull affine combinatory algebra are not. To check all the equations involved in\nthe definition of affine lambda-algebra, we implement in Erlang application of\ninvolutions.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2018 15:14:03 GMT"}, {"version": "v2", "created": "Thu, 30 Aug 2018 13:33:06 GMT"}], "update_date": "2018-08-31", "authors_parsed": [["Ciaffaglione", "Alberto", ""], ["Honsell", "Furio", ""], ["Lenisa", "Marina", ""], ["Scagnetto", "Ivan", ""]]}, {"id": "1806.08297", "submitter": "Philip Amortila", "authors": "Philip Amortila and Guillaume Rabusseau", "title": "Learning Graph Weighted Models on Pictures", "comments": "International Conference on Grammatical Inference 2018 (v2:\n  camera-ready)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Weighted Models (GWMs) have recently been proposed as a natural\ngeneralization of weighted automata over strings and trees to arbitrary\nfamilies of labeled graphs (and hypergraphs). A GWM generically associates a\nlabeled graph with a tensor network and computes a value by successive\ncontractions directed by its edges. In this paper, we consider the problem of\nlearning GWMs defined over the graph family of pictures (or 2-dimensional\nwords). As a proof of concept, we consider regression and classification tasks\nover the simple Bars & Stripes and Shifting Bits picture languages and provide\nan experimental study investigating whether these languages can be learned in\nthe form of a GWM from positive and negative examples using gradient-based\nmethods. Our results suggest that this is indeed possible and that\ninvestigating the use of gradient-based methods to learn picture series and\nfunctions computed by GWMs over other families of graphs could be a fruitful\ndirection.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jun 2018 15:44:51 GMT"}, {"version": "v2", "created": "Sun, 2 Dec 2018 17:38:44 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Amortila", "Philip", ""], ["Rabusseau", "Guillaume", ""]]}, {"id": "1806.08476", "submitter": "Sylvie Davies", "authors": "Sylvie Davies", "title": "A General Approach to State Complexity of Operations: Formalization and\n  Limitations", "comments": "27 pages, 1 figure. Short version (covering just the case of unary\n  operations) accepted to DLT 2018. Introduction has been expanded to give a\n  more complete historical overview of the ideas in the paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The state complexity of the result of a regular operation is often positively\ncorrelated with the number of distinct transformations induced by letters in\nthe minimal deterministic finite automaton of the input languages. That is,\nmore transformations in the inputs means higher state complexity in the output.\nWhen this correlation holds, the state complexity of a unary operation can be\nmaximized using languages in which there is one letter corresponding to each\npossible transformation; for operations of higher arity, we can use $m$-tuples\nof languages in which there is one letter corresponding to each possible\n$m$-tuple of transformations. In this way, a small set of languages can be used\nas witnesses for many common regular operations, eliminating the need to search\nfor witnesses -- though at the expense of using very large alphabets. We\nformalize this approach and examine its limitations. We define a class of\n\"uniform\" operations for which this approach works; the class is closed under\ncomposition and includes common operations such as star, concatenation,\nreversal, union, and complement. Our main result is that the worst-case state\ncomplexity of a uniform operation can be determined by considering a finite set\nof witnesses, and this set depends only on the arity of the operation and the\nstate complexities of the inputs.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jun 2018 03:04:18 GMT"}, {"version": "v2", "created": "Wed, 5 Sep 2018 22:38:32 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Davies", "Sylvie", ""]]}, {"id": "1806.08684", "submitter": "Claudio Menghi", "authors": "Claudio Menghi, Marcello Bersani, Matteo Rossi and Pierluigi San\n  Pietro", "title": "Verifying MITL formulae on Timed Automata considering a Continuous Time\n  Semantics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Timed Automata (TA) is de facto a standard modelling formalism to represent\nsystems when the interest is the analysis of their behaviour as time\nprogresses. This modelling formalism is mostly used for checking whether the\nbehaviours of a system satisfy a set of properties of interest. Even if\nefficient model-checkers for Timed Automata exist, these tools are not easily\nconfigurable. First, they are not designed to easily allow adding new Timed\nAutomata constructs, such as new synchronization mechanisms or communication\nprocedures, but they assume a fixed set of Timed Automata constructs. Second,\nthey usually do not support the full Metric Interval Temporal Logic (MITL) and\nrely on a precise semantics for the logic in which the property of interest is\nspecified which cannot be easily modified and customized. Finally, they do not\neasily allow using different solvers that may speed up verification in\ndifferent contexts. This paper presents a novel technique to perform model\nchecking of full Metric Interval Temporal Logic (MITL) properties on TA. The\ntechnique relies on the translation of both the TA and the MITL formula into an\nintermediate Constraint LTL over clocks (CLTLoc) formula which is verified\nthrough an available decision procedure. The technique is flexible since the\nintermediate logic allows the encoding of new semantics as well as new TA\nconstructs, by just adding new CLTLoc formulae. Furthermore, our technique is\nnot bound to a specific solver as the intermediate CLTLoc formula can be\nverified using different procedures.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jun 2018 14:14:09 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 10:23:24 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Menghi", "Claudio", ""], ["Bersani", "Marcello", ""], ["Rossi", "Matteo", ""], ["Pietro", "Pierluigi San", ""]]}, {"id": "1806.08729", "submitter": "Yingjun Guo", "authors": "Ying-Jun Guo", "title": "On the regularity of the Hankel determinant sequence of the\n  characteristic sequence of powers", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NT cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For any sequences $\\mathbf{u}=\\{u(n)\\}_{n\\geq0},\n\\mathbf{v}=\\{v(n)\\}_{n\\geq0},$ we define\n$\\mathbf{u}\\mathbf{v}:=\\{u(n)v(n)\\}_{n\\geq0}$ and\n$\\mathbf{u}+\\mathbf{v}:=\\{u(n)+v(n)\\}_{n\\geq0}$. Let $f_i(x)~(0\\leq i< k)$ be\nsequence polynomials whose coefficients are integer sequences. We say an\ninteger sequence $\\mathbf{u}=\\{u(n)\\}_{n\\geq0}$ is a polynomial generated\nsequence if $$\\{u(kn+i)\\}_{n\\geq0}=f_i(\\mathbf{u}),~(0\\leq i< k).$$ %Here we\ndefine $\\mathbf{u}\\mathbf{v}:=\\{u(n)v(n)\\}_{n\\geq0}$ and\n$\\mathbf{u}+\\mathbf{v}:=\\{u(n)+v(n)\\}_{n\\geq0}$ for any two sequences\n$\\mathbf{u}=\\{u(n)\\}_{n\\geq0}, \\mathbf{v}=\\{v(n)\\}_{n\\geq0}.$\n  In this paper, we study the polynomial generated sequences. Assume $k\\geq2$\nand $f_i(x)=\\mathbf{a}_ix+\\mathbf{b}_i~(0\\leq i< k)$. If $\\mathbf{a}_i$ are\n$k$-automatic and $\\mathbf{b}_i$ are $k$-regular for $0\\leq i< k$, then we\nprove that the corresponding polynomial generated sequences are $k$-regular. As\na application, we prove that the Hankel determinant sequence\n$\\{\\det(p_{i+j})_{i,j=0}^{n-1}\\}_{n\\geq0}$ is $2$-regular, where\n$\\{p(n)\\}_{n\\geq0}=0110100010000\\cdots$ is the characteristic sequence of\npowers 2. Moreover, we give a answer of Cigler's conjecture about the Hankel\ndeterminants.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2018 12:59:55 GMT"}], "update_date": "2018-06-25", "authors_parsed": [["Guo", "Ying-Jun", ""]]}, {"id": "1806.08771", "submitter": "David Feller", "authors": "David Feller, Joe B. Wells, Fairouz Kamareddine (ULTRA), Sebastien\n  Carlier", "title": "What Does This Notation Mean Anyway?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Following the introduction of BNF notation by Backus for the Algol 60 report\nand subsequent notational variants, a metalanguage involving formal \"grammars\"\nhas developed for discussing structured objects in Computer Science and\nMathematical Logic. We refer to this offspring of BNF as Math-BNF or MBNF, to\nthe original BNF and its notational variants just as BNF, and to aspects common\nto both as BNF-style. What all BNF-style notations share is the use of\nproduction rules roughly of this form: $$\\bullet \\mathrel{::=} \\circ_1 \\mid\n\\cdots \\mid \\circ_n $$ Normally, such a rule says \"every instance of $\\circ_i$\nfor $i \\in \\{1, \\ldots, n\\}$ is also an in stance of $\\bullet$\". MBNF is\ndistinct from BNF in the entities and operations it allows. Instead of strings,\nMBNF builds arrangements of symbols that we call math-text. Sometimes \"syntax\"\nis defined by interleaving MBNF production rules and other mathematical\ndefinitions that can contain chunks of math-text. There is no clear definition\nof MBNF. Readers do not have a document which tells them how MBNF is to be read\nand must learn MBNF through a process of cultural initiation. To the extent\nthat MBNF is defined, it is largely through examples scattered throughout the\nliterature and which require readers to guess the mathematical structures\nunderpinning them. This paper gives MBNF examples illustrating some of the\ndifferences between MBNF and BNF. We propose a definition of syntactic math\ntext (SMT) which handles many (but far from all) uses of math-text and MBNF in\nthe wild. We aim to balance the goal of being accessible and not requiring too\nmuch prerequisite knowledge with the conflicting goal of providing a rich\nmathematical structure that already supports many uses and has possibilities to\nbe extended to support more challenging cases.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jun 2018 13:07:15 GMT"}], "update_date": "2018-06-25", "authors_parsed": [["Feller", "David", "", "ULTRA"], ["Wells", "Joe B.", "", "ULTRA"], ["Kamareddine", "Fairouz", "", "ULTRA"], ["Carlier", "Sebastien", ""]]}, {"id": "1806.09534", "submitter": "Anna Frid", "authors": "Pierre Bonardo, Anna E. Frid, Jeffrey Shallit", "title": "The number of valid factorizations of Fibonacci prefixes", "comments": "Version accepted to Theoretical Computer Science", "journal-ref": null, "doi": "10.1016/j.tcs.2018.12.016", "report-no": null, "categories": "math.CO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We establish several recurrence relations and an explicit formula for V(n),\nthe number of factorizations of the length-n prefix of the Fibonacci word into\na (not necessarily strictly) decreasing sequence of standard Fibonacci words.\nIn particular, we show that the sequence V(n) is the shuffle of the ceilings of\ntwo linear functions of n.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jun 2018 15:43:50 GMT"}, {"version": "v2", "created": "Thu, 12 Jul 2018 03:19:26 GMT"}, {"version": "v3", "created": "Fri, 4 Jan 2019 09:08:03 GMT"}, {"version": "v4", "created": "Mon, 7 Jan 2019 09:17:01 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Bonardo", "Pierre", ""], ["Frid", "Anna E.", ""], ["Shallit", "Jeffrey", ""]]}, {"id": "1806.11150", "submitter": "S\\'ergio Medeiros", "authors": "S\\'ergio Medeiros and Fabio Mascarenhas", "title": "Syntax Error Recovery in Parsing Expression Grammars", "comments": "Published on ACM Symposium On Applied Computing 2018", "journal-ref": null, "doi": "10.1145/3167132.3167261", "report-no": null, "categories": "cs.PL cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parsing Expression Grammars (PEGs) are a formalism used to describe top-down\nparsers with backtracking. As PEGs do not provide a good error recovery\nmechanism, PEG-based parsers usually do not recover from syntax errors in the\ninput, or recover from syntax errors using ad-hoc, implementation-specific\nfeatures. The lack of proper error recovery makes PEG parsers unsuitable for\nusing with Integrated Development Environments (IDEs), which need to build\nsyntactic trees even for incomplete, syntactically invalid programs.\n  We propose a conservative extension, based on PEGs with labeled failures,\nthat adds a syntax error recovery mechanism for PEGs. This extension associates\nrecovery expressions to labels, where a label now not only reports a syntax\nerror but also uses this recovery expression to reach a synchronization point\nin the input and resume parsing. We give an operational semantics of PEGs with\nthis recovery mechanism, and use an implementation based on such semantics to\nbuild a robust parser for the Lua language. We evaluate the effectiveness of\nthis parser, alone and in comparison with a Lua parser with automatic error\nrecovery generated by ANTLR, a popular parser generator.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jun 2018 19:20:06 GMT"}], "update_date": "2018-07-02", "authors_parsed": [["Medeiros", "S\u00e9rgio", ""], ["Mascarenhas", "Fabio", ""]]}]