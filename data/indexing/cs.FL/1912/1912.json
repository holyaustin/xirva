[{"id": "1912.00692", "submitter": "Ville Salo", "authors": "Ville Salo, Ilkka T\\\"orm\\\"a", "title": "Gardens of Eden in the Game of Life", "comments": "16 pages + 5 pages of code; some figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.DS cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that in the Game of Life, if the thickness-four zero-padding of a\nrectangular pattern is not an orphan, then the corresponding finite-support\nconfiguration is not a Garden of Eden, and that the preimage of every\nfinite-support configuration has dense semilinear configurations. In particular\nfinite-support Gardens of Eden are in co-NP.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 11:41:02 GMT"}, {"version": "v2", "created": "Tue, 3 Dec 2019 13:52:57 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Salo", "Ville", ""], ["T\u00f6rm\u00e4", "Ilkka", ""]]}, {"id": "1912.01289", "submitter": "Francesco Tiezzi", "authors": "Rocco De Nicola, Gianluigi Ferrari, Rosario Pugliese, Francesco Tiezzi", "title": "A Formal Approach to the Engineering of Domain-Specific Distributed\n  Systems", "comments": "In Press", "journal-ref": "Journal of Logical and Algebraic Methods in Programming, Elsevier,\n  2019", "doi": "10.1016/j.jlamp.2019.100511", "report-no": null, "categories": "cs.PL cs.FL cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We review some results regarding specification, programming and verification\nof different classes of distributed systems which stemmed from the research of\nthe Concurrency and Mobility Group at University of Firenze. More specifically,\nwe examine the distinguishing features of network-aware programming,\nservice-oriented computing, autonomic computing, and collective adaptive\nsystems programming. We then present an overview of four different languages,\nnamely Klaim, Cows, Scel and AbC. For each language, we discuss design choices,\npresent syntax and semantics, show how the different formalisms can be used to\nmodel and program a travel booking scenario, and describe programming\nenvironments and verification techniques.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 10:45:53 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["De Nicola", "Rocco", ""], ["Ferrari", "Gianluigi", ""], ["Pugliese", "Rosario", ""], ["Tiezzi", "Francesco", ""]]}, {"id": "1912.01532", "submitter": "Nicolas Beldiceanu", "authors": "Nicolas Beldiceanu, Mats Carlsson, Claude-Guy Quimper, Maria-Isabel\n  Restrepo-Ruiz", "title": "Classifying Pattern and Feature Properties to Get a $\\Theta(n)$ Checker\n  and Reformulation for Sliding Time-Series Constraints", "comments": "47 pages, 5 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given, a sequence $\\mathcal{X}$ of $n$ variables, a time-series constraint\nctr using the Sum aggregator, and a sliding time-series constraint enforcing\nthe constraint ctr on each sliding window of $\\mathcal{X}$ of $m$ consecutive\nvariables, we describe a $\\Theta(n)$ time complexity checker, as well as a\n$\\Theta(n)$ space complexity reformulation for such sliding constraint.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 17:19:40 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Beldiceanu", "Nicolas", ""], ["Carlsson", "Mats", ""], ["Quimper", "Claude-Guy", ""], ["Restrepo-Ruiz", "Maria-Isabel", ""]]}, {"id": "1912.02660", "submitter": "D\\'avid K\\'osz\\'o", "authors": "Zolt\\'an F\\\"ul\\\"op, D\\'avid K\\'osz\\'o, Heiko Vogler", "title": "Crisp-determinization of weighted tree automata over strong bimonoids", "comments": null, "journal-ref": "Discrete Mathematics & Theoretical Computer Science, vol. 23 no.\n  1, Automata, Logic and Semantics (June 15, 2021) dmtcs:7580", "doi": null, "report-no": null, "categories": "cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider weighted tree automata (wta) over strong bimonoids and their\ninitial algebra semantics and their run semantics. There are wta for which\nthese semantics are different; however, for bottom-up deterministic wta and for\nwta over semirings, the difference vanishes. A wta is crisp-deterministic if it\nis bottom-up deterministic and each transition is weighted by one of the unit\nelements of the strong bimonoid. We prove that the class of weighted tree\nlanguages recognized by crisp-deterministic wta is the same as the class of\nrecognizable step mappings. Moreover, we investigate the following two\ncrisp-determinization problems: for a given wta ${\\cal A}$, (a) does there\nexist a crisp-deterministic wta which computes the initial algebra semantics of\n${\\cal A}$ and (b) does there exist a crisp-deterministic wta which computes\nthe run semantics of ${\\cal A}$? We show that the finiteness of the Nerode\nalgebra ${\\cal N}({\\cal A})$ of ${\\cal A}$ implies a positive answer for (a),\nand that the finite order property of ${\\cal A}$ implies a positive answer for\n(b). We show a sufficient condition which guarantees the finiteness of ${\\cal\nN}({\\cal A})$ and a sufficient condition which guarantees the finite order\nproperty of ${\\cal A}$. Also, we provide an algorithm for the construction of\nthe crisp-deterministic wta according to (a) if ${\\cal N}({\\cal A})$ is finite,\nand similarly for (b) if ${\\cal A}$ has finite order property. We prove that it\nis undecidable whether an arbitrary wta ${\\cal A}$ is crisp-determinizable. We\nalso prove that both, the finiteness of ${\\cal N}({\\cal A})$ and the finite\norder property of ${\\cal A}$ are undecidable.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 15:46:17 GMT"}, {"version": "v2", "created": "Tue, 2 Feb 2021 14:47:22 GMT"}, {"version": "v3", "created": "Mon, 14 Jun 2021 12:49:59 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["F\u00fcl\u00f6p", "Zolt\u00e1n", ""], ["K\u00f3sz\u00f3", "D\u00e1vid", ""], ["Vogler", "Heiko", ""]]}, {"id": "1912.03028", "submitter": "M. Saqib Nawaz", "authors": "M. Saqib Nawaz, Moin Malik, Yi Li, Meng Sun and M. Ikram Ullah Lali", "title": "A Survey on Theorem Provers in Formal Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mechanical reasoning is a key area of research that lies at the crossroads of\nmathematical logic and artificial intelligence. The main aim to develop\nmechanical reasoning systems (also known as theorem provers) was to enable\nmathematicians to prove theorems by computer programs. However, these tools\nevolved with time and now play vital role in the modeling and reasoning about\ncomplex and large-scale systems, especially safety-critical systems.\nTechnically, mathematical formalisms and automated reasoning based-approaches\nare employed to perform inferences and to generate proofs in theorem provers.\nIn literature, there is a shortage of comprehensive documents that can provide\nproper guidance about the preferences of theorem provers with respect to their\ndesigns, performances, logical frameworks, strengths, differences and their\napplication areas. In this work, more than 40 theorem provers are studied in\ndetail and compared to present a comprehensive analysis and evaluation of these\ntools. Theorem provers are investigated based on various parameters, which\nincludes: implementation architecture, logic and calculus used, library\nsupport, level of automation, programming paradigm, programming language,\ndifferences and application areas.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 09:05:38 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Nawaz", "M. Saqib", ""], ["Malik", "Moin", ""], ["Li", "Yi", ""], ["Sun", "Meng", ""], ["Lali", "M. Ikram Ullah", ""]]}, {"id": "1912.05793", "submitter": "Guillermo P\\'erez", "authors": "Guillermo A. Perez", "title": "The Extended HOA Format for Synthesis", "comments": "Updated the link to a cited tool and made it explicit that parity\n  automata can be assumed to be complete", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a small extension to the Hanoi Omega-Automata format to define\nreactive-synthesis problems. Namely, we add a \"controllable-AP\" header item\nspecifying the subset of atomic propositions which is controllable. We describe\nthe semantics of the new format and propose an output format for synthesized\nstrategies. Finally, we also comment on tool support meant to encourage fast\nadoption of the extended Hanoi Omega-Automata format for synthesis.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 06:46:47 GMT"}, {"version": "v2", "created": "Wed, 13 May 2020 13:35:40 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Perez", "Guillermo A.", ""]]}, {"id": "1912.05907", "submitter": "Thomas Chatain", "authors": "Thomas Chatain (MEXICO, LSV, ENS Paris Saclay), Mathilde Boltenhagen\n  (LSV, CNRS, MEXICO), Josep Carmona (UPC)", "title": "Anti-Alignments -- Measuring The Precision of Process Models and Event\n  Logs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Processes are a crucial artefact in organizations, since they coordinate the\nexecution of activities so that products and services are provided. The use of\nmodels to analyse the underlying processes is a well-known practice. However,\ndue to the complexity and continuous evolution of their processes,\norganizations need an effective way of analysing the relation between processes\nand models. Conformance checking techniques asses the suitability of a process\nmodel in representing an underlying process, observed through a collection of\nreal executions. One important metric in conformance checking is to asses the\nprecision of the model with respect to the observed executions, i.e.,\ncharacterize the ability of the model to produce behavior unrelated to the one\nobserved. In this paper we present the notion of anti-alignment as a concept to\nhelp unveiling runs in the model that may deviate significantly from the\nobserved behavior. Using anti-alignments, a new metric for precision is\nproposed. In contrast to existing metrics, anti-alignment based precision\nmetrics satisfy most of the required axioms highlighted in a recent\npublication. Moreover, a complexity analysis of the problem of computing\nanti-alignments is provided, which sheds light into the practicability of using\nanti-alignment to estimate precision. Experiments are provided that witness the\nvalidity of the concepts introduced in this paper.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 07:39:23 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Chatain", "Thomas", "", "MEXICO, LSV, ENS Paris Saclay"], ["Boltenhagen", "Mathilde", "", "LSV, CNRS, MEXICO"], ["Carmona", "Josep", "", "UPC"]]}, {"id": "1912.06110", "submitter": "Dominik D. Freydenberger", "authors": "Dominik D. Freydenberger and Liat Peterfreund", "title": "The theory of concatenation over finite models", "comments": "Update to make this version consistent with conference version (ICALP\n  2021), which renamed Datasplog to FC-Datalog", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DB cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose FC, a new logic on words that combines finite model theory with\nthe theory of concatenation - a first-order logic that is based on word\nequations. Like the theory of concatenation, FC is built around word equations;\nin contrast to it, its semantics are defined to only allow finite models, by\nlimiting the universe to a word and all its factors. As a consequence of this,\nFC has many of the desirable properties of FO on finite models, while being far\nmore expressive than FO[<]. Most noteworthy among these desirable properties\nare sufficient criteria for efficient model checking, and capturing various\ncomplexity classes by adding operators for transitive closures or fixed points.\n  Not only does FC allow us to obtain new insights and techniques for\nexpressive power and efficient evaluation of document spanners, but it also\nprovides a general framework for logic on words that also has potential\napplications in other areas.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 18:18:55 GMT"}, {"version": "v2", "created": "Fri, 13 Dec 2019 14:18:54 GMT"}, {"version": "v3", "created": "Mon, 13 Jan 2020 18:23:35 GMT"}, {"version": "v4", "created": "Tue, 18 Feb 2020 13:52:43 GMT"}, {"version": "v5", "created": "Thu, 11 Mar 2021 12:42:24 GMT"}, {"version": "v6", "created": "Thu, 13 May 2021 16:38:17 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Freydenberger", "Dominik D.", ""], ["Peterfreund", "Liat", ""]]}, {"id": "1912.06897", "submitter": "Jan Philipp W\\\"achter", "authors": "Ievgen Bondarenko and Jan Philipp W\\\"achter", "title": "On Orbits and the Finiteness of Bounded Automaton Groups", "comments": "Slightly revised version", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.GR cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We devise an algorithm which, given a bounded automaton A, decides whether\nthe group generated by A is finite. The solution comes from a description of\nthe infinite sequences having an infinite A-orbit using a deterministic\nfinite-state acceptor. This acceptor can also be used to decide whether the\nbounded automaton acts level-transitively.\n", "versions": [{"version": "v1", "created": "Sat, 14 Dec 2019 18:14:33 GMT"}, {"version": "v2", "created": "Sun, 30 Aug 2020 15:51:59 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Bondarenko", "Ievgen", ""], ["W\u00e4chter", "Jan Philipp", ""]]}, {"id": "1912.07312", "submitter": "Tom\\'a\\v{s} Masopust", "authors": "Ji\\v{r}\\'i Balun and Tom\\'a\\v{s} Masopust", "title": "On Verification of D-Detectability for Discrete Event Systems", "comments": "Extended version of a paper accepted for WODES 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detectability has been introduced as a generalization of state-estimation\nproperties of discrete event systems studied in the literature. It asks whether\nthe current and subsequent states of a system can be determined based on\nobservations. Since, in some applications, to exactly determine the current and\nsubsequent states may be too strict, a relaxed notion of D-detectability has\nbeen introduced, distinguishing only certain pairs of states rather than all\nstates. Four variants of D-detectability have been defined: strong (periodic)\nD-detectability and weak (periodic) D-detectability. Deciding weak (periodic)\nD-detectability is PSpace-complete, while deciding strong (periodic)\ndetectability or strong D-detectability is polynomial (and we show that it is\nactually NL-complete). However, to the best of our knowledge, it is an open\nproblem whether there exists a polynomial-time algorithm deciding strong\nperiodic D-detectability. We solve this problem by showing that deciding strong\nperiodic D-detectability is a PSpace-complete problem, and hence there is no\npolynomial-time algorithm unless PSpace = P. We further show that there is no\npolynomial-time algorithm deciding strong periodic D-detectability even for\nsystems with a single observable event, unless P = NP. Finally, we propose a\nclass of systems for which the problem is tractable.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 12:10:30 GMT"}, {"version": "v2", "created": "Sat, 16 May 2020 22:25:30 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Balun", "Ji\u0159\u00ed", ""], ["Masopust", "Tom\u00e1\u0161", ""]]}, {"id": "1912.07314", "submitter": "Tom\\'a\\v{s} Masopust", "authors": "Ji\\v{r}\\'i Balun and Tom\\'a\\v{s} Masopust", "title": "On Opacity Verification for Discrete-Event Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Opacity is an information flow property characterizing whether a system\nreveals its secret to an intruder. Verification of opacity for discrete-event\nsystems modeled by automata is in general a hard problem. We discuss the\nquestion whether there are structural restrictions on the system models for\nwhich the opacity verification is tractable. We consider two kinds of automata\nmodels: (i) acyclic automata, and (ii) automata where all cycles are only in\nthe form of self-loops. In some sense, these models are the simplest models of\n(deadlock-free) systems. Although the expressivity of such systems is weaker\nthan the expressivity of linear temporal logic, we show that the opacity\nverification for these systems is still hard.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 12:15:56 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Balun", "Ji\u0159\u00ed", ""], ["Masopust", "Tom\u00e1\u0161", ""]]}, {"id": "1912.07804", "submitter": "Shufang Zhu", "authors": "Shufang Zhu, Giuseppe De Giacomo, Geguang Pu, Moshe Vardi", "title": "LTLf Synthesis with Fairness and Stability Assumptions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.FL cs.GT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In synthesis, assumptions are constraints on the environment that rule out\ncertain environment behaviors. A key observation here is that even if we\nconsider systems with LTLf goals on finite traces, environment assumptions need\nto be expressed over infinite traces, since accomplishing the agent goals may\nrequire an unbounded number of environment action. To solve synthesis with\nrespect to finite-trace LTLf goals under infinite-trace assumptions, we could\nreduce the problem to LTL synthesis. Unfortunately, while synthesis in LTLf and\nin LTL have the same worst-case complexity (both 2EXPTIME-complete), the\nalgorithms available for LTL synthesis are much more difficult in practice than\nthose for LTLf synthesis. In this work we show that in interesting cases we can\navoid such a detour to LTL synthesis and keep the simplicity of LTLf synthesis.\nSpecifically, we develop a BDD-based fixpoint-based technique for handling\nbasic forms of fairness and of stability assumptions. We show, empirically,\nthat this technique performs much better than standard LTL synthesis.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 03:44:39 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Zhu", "Shufang", ""], ["De Giacomo", "Giuseppe", ""], ["Pu", "Geguang", ""], ["Vardi", "Moshe", ""]]}, {"id": "1912.07817", "submitter": "Yihao Huang", "authors": "Yihao Huang, Jincao Feng, Hanyue Zheng, Jiayi Zhu, Shang Wang, Siyuan\n  Jiang, Weikai Miao, Geguang Pu", "title": "Prema: A Tool for Precise Requirements Editing, Modeling and Analysis", "comments": "accepted by ASE2019 demonstration track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Prema, a tool for Precise Requirement Editing, Modeling and\nAnalysis. It can be used in various fields for describing precise requirements\nusing formal notations and performing rigorous analysis. By parsing the\nrequirements written in formal modeling language, Prema is able to get a model\nwhich aptly depicts the requirements. It also provides different rigorous\nverification and validation techniques to check whether the requirements meet\nusers' expectation and find potential errors. We show that our tool can provide\na unified environment for writing and verifying requirements without using\ntools that are not well inter-related. For experimental demonstration, we use\nthe requirements of the automatic train protection (ATP) system of CASCO signal\nco. LTD., the largest railway signal control system manufacturer of China. The\ncode of the tool cannot be released here because the project is commercially\nconfidential. However, a demonstration video of the tool is available at\nhttps://youtu.be/BX0yv8pRMWs.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 04:54:05 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Huang", "Yihao", ""], ["Feng", "Jincao", ""], ["Zheng", "Hanyue", ""], ["Zhu", "Jiayi", ""], ["Wang", "Shang", ""], ["Jiang", "Siyuan", ""], ["Miao", "Weikai", ""], ["Pu", "Geguang", ""]]}, {"id": "1912.07992", "submitter": "Nathan Grosshans", "authors": "Nathan Grosshans", "title": "The Power of Programs over Monoids in J and Threshold Dot-depth One\n  Languages", "comments": "Journal version of this submission, still under preparation. The\n  conference version has been substantially extended in that the algebraic\n  characterisation of threshold dot-depth one languages that was only\n  conjectured now has a complete proof (hence the new title). The proofs\n  previously left in the appendix were also included in the body of the paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The model of programs over (finite) monoids, introduced by Barrington and\nTh\\'erien, gives an interesting way to characterise the circuit complexity\nclass $\\mathsf{NC^1}$ and its subclasses and showcases deep connections with\nalgebraic automata theory. In this article, we investigate the computational\npower of programs over monoids in $\\mathbf{J}$, a small variety of finite\naperiodic monoids. First, we give a fine hierarchy within the class of\nlanguages recognised by programs over monoids from $\\mathbf{J}$, based on the\nlength of programs but also some parametrisation of $\\mathbf{J}$. Second, and\nmost importantly, we make progress in understanding what regular languages can\nbe recognised by programs over monoids in $\\mathbf{J}$. To this end, we\nintroduce a new class of restricted dot-depth one languages, threshold\ndot-depth one languages. We show that programs over monoids in $\\mathbf{J}$\nactually can recognise all languages from this class, using a non-trivial\ntrick, and conjecture that threshold dot-depth one languages with additional\npositional modular counting suffice to characterise the regular languages\nrecognised by programs over monoids in $\\mathbf{J}$. Finally, using a result by\nJ. C. Costa, we give an algebraic characterisation of threshold dot-depth one\nlanguages that supports that conjecture and is of independent interest.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 13:15:30 GMT"}, {"version": "v2", "created": "Tue, 16 Mar 2021 15:50:41 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Grosshans", "Nathan", ""]]}, {"id": "1912.08147", "submitter": "Lukas Fleischer", "authors": "Lukas Fleischer, Samin Riasat, Jeffrey Shallit", "title": "New Bounds on Antipowers in Words", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fici et al. defined a word to be a k-power if it is the concatenation of k\nconsecutive identical blocks, and an r-antipower if it is the concatenation of\nr pairwise distinct blocks of the same size. They defined N (k, r) as the\nsmallest l such that every binary word of length l contains either a k-power or\nan r-antipower. In this note we obtain some new upper and lower bounds on N (k,\nr). We also consider avoiding 3-antipowers and 4-antipowers over larger\nalphabets, and obtain a lower bound for N (k, 5) in the binary case.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 17:29:45 GMT"}, {"version": "v2", "created": "Sat, 4 Jul 2020 21:03:09 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Fleischer", "Lukas", ""], ["Riasat", "Samin", ""], ["Shallit", "Jeffrey", ""]]}, {"id": "1912.08277", "submitter": "Michel de Rougemont", "authors": "Richard Lassaigne and Michel de Rougemont", "title": "Testing Membership for Timed Automata", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a timed automata which admits thick components and a timed word $x$, we\npresent a tester which decides if $x$ is in the language of the automaton or if\n$x$ is $\\epsilon$-far from the language, using finitely many samples taken from\nthe weighted time distribution $\\mu$ associated with an input $x$. We introduce\na distance between timed words, the {\\em timed edit distance}, which\ngeneralizes the classical edit distance. A timed word $x$ is $\\epsilon$-far\nfrom a timed language if its relative distance to the language is greater than\n$\\epsilon$.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 21:24:41 GMT"}, {"version": "v2", "created": "Thu, 28 May 2020 15:55:15 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Lassaigne", "Richard", ""], ["de Rougemont", "Michel", ""]]}, {"id": "1912.08966", "submitter": "EPTCS", "authors": "Rachid Echahed, Detlef Plump", "title": "Proceedings Tenth International Workshop on Graph Computation Models", "comments": null, "journal-ref": "EPTCS 309, 2019", "doi": "10.4204/EPTCS.309", "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the post-proceedings of the Tenth International Workshop\non Graph Computation Models (GCM 2019: http://gcm2019.imag.fr). The workshop\nwas held in Eindhoven, The Netherlands, on July 17th, 2019, as part of STAF\n2019 (Software Technologies: Applications and Foundations).\n  Graphs are common mathematical structures that are visual and intuitive. They\nconstitute a natural and seamless way for system modelling in science,\nengineering and beyond, including computer science, biology, business process\nmodelling, etc. Graph computation models constitute a class of very high-level\nmodels where graphs are first-class citizens. The aim of the International GCM\nWorkshop series is to bring together researchers interested in all aspects of\ncomputation models based on graphs and graph transformation. It promotes the\ncross-fertilizing exchange of ideas and experiences among senior and young\nresearchers from the different communities interested in the foundations,\napplications, and implementations of graph computation models and related\nareas.\n  These post-proceedings contain four selected papers from GCM2019 proceedings\nand an invited presentation that gives an account of the very successful panel\ndiscussion dedicated to the Analysis of Graph Transformation Systems, which\ntook place during the workshop and was animated by Reiko Heckel, Leen Lambers\nand Maryam Ghaffari Saadat.\n  All submissions were subject to careful refereeing. The topics of accepted\npapers include theoretical aspects of graph transformation and parsing\ntechniques as well as an application to model-driven engineering.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 00:44:10 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Echahed", "Rachid", ""], ["Plump", "Detlef", ""]]}, {"id": "1912.09326", "submitter": "Markus Schmid", "authors": "Markus L. Schmid", "title": "Conjunctive Regular Path Queries with String Variables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the class CXRPQ of conjunctive xregex path queries, which are\nobtained from conjunctive regular path queries (CRPQs) by adding string\nvariables (also called backreferences) as found in practical implementations of\nregular expressions. CXRPQs can be considered user-friendly, since they combine\ntwo concepts that are well-established in practice: pattern-based graph queries\nand regular expressions with backreferences. Due to the string variables,\nCXRPQs can express inter-path dependencies, which are not expressible by CRPQs.\nThe evaluation complexity of CXRPQs, if not further restricted, is PSPACE-hard\nin data-complexity. We identify three natural fragments with more acceptable\nevaluation complexity: their data-complexity is in NL, while their combined\ncomplexity varies between EXPSPACE, PSPACE and NP. In terms of expressive\npower, we compare the CXRPQ-fragments with CRPQs and unions of CRPQs, and with\nextended conjunctive regular path queries (ECRPQs) and unions of ECRPQs.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 16:04:58 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Schmid", "Markus L.", ""]]}, {"id": "1912.09608", "submitter": "EPTCS", "authors": "Aaron Lye", "title": "Transformation of Turing Machines into Context-Dependent Fusion Grammars", "comments": "In Proceedings GCM 2019, arXiv:1912.08966", "journal-ref": "EPTCS 309, 2019, pp. 53-70", "doi": "10.4204/EPTCS.309.3", "report-no": null, "categories": "cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Context-dependent fusion grammars were recently introduced as devices for the\ngeneration of hypergraph languages. In this paper, we show that this new type\nof hypergraph grammars, where the application of fusion rules is restricted by\npositive and negative context conditions, is a universal computation model. Our\nmain result is that Turing machines can be transformed into these grammars such\nthat the recognized language of the Turing machine and the generated language\nof the corresponding context-dependent fusion grammar coincide up to\nrepresentation of strings as graphs. As a corollary we get that\ncontext-dependent fusion grammars can generate all recursively enumerable\nstring languages.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 01:40:21 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Lye", "Aaron", ""]]}, {"id": "1912.09609", "submitter": "EPTCS", "authors": "Mark Minas", "title": "Speeding up Generalized PSR Parsers by Memoization Techniques", "comments": "In Proceedings GCM 2019, arXiv:1912.08966", "journal-ref": "EPTCS 309, 2019, pp. 71-86", "doi": "10.4204/EPTCS.309.4", "report-no": null, "categories": "cs.FL cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictive shift-reduce (PSR) parsing for hyperedge replacement (HR) grammars\nis very efficient, but restricted to a subclass of unambiguous HR grammars. To\novercome this restriction, we have recently extended PSR parsing to generalized\nPSR (GPSR) parsing along the lines of Tomita-style generalized LR parsing.\nUnfortunately, GPSR parsers turned out to be too inefficient without manual\ntuning. This paper proposes to use memoization techniques to speed up GPSR\nparsers without any need of manual tuning, and which has been realized within\nthe graph parser distiller Grappa. We present running time measurements for\nsome example languages; they show a significant speed up by some orders of\nmagnitude when parsing valid graphs. But memoization techniques do not help\nwhen parsing invalid graphs or if all parses of an ambiguous input graph shall\nbe determined.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 01:40:51 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Minas", "Mark", ""]]}, {"id": "1912.09770", "submitter": "Pepe Vila", "authors": "Pepe Vila, Pierre Ganty, Marco Guarnieri, and Boris K\\\"opf", "title": "CacheQuery: Learning Replacement Policies from Hardware Caches", "comments": "17 pages, 5 tables, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how to infer deterministic cache replacement policies using\noff-the-shelf automata learning and program synthesis techniques. For this, we\nconstruct and chain two abstractions that expose the cache replacement policy\nof any set in the cache hierarchy as a membership oracle to the learning\nalgorithm, based on timing measurements on a silicon CPU. Our experiments\ndemonstrate an advantage in scope and scalability over prior art and uncover 2\npreviously undocumented cache replacement policies.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 11:31:28 GMT"}, {"version": "v2", "created": "Tue, 26 May 2020 10:11:02 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Vila", "Pepe", ""], ["Ganty", "Pierre", ""], ["Guarnieri", "Marco", ""], ["K\u00f6pf", "Boris", ""]]}, {"id": "1912.10240", "submitter": "Amazigh Amrane", "authors": "Amazigh Amrane and Nicolas Bedon", "title": "Logic and Rational Languages of Scattered and Countable Series-Parallel\n  Posets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Let $A$ be an alphabet and $SP^\\diamond(A)$ denote the class of all countable\nN-free partially ordered sets labeled by $A$, in which chains are scattered\nlinear orderings and antichains are finite. We characterize the rational\nlanguages of $SP^\\diamond(A)$ by means of logic. We define an extension of\nmonadic second-order logic by Presburger arithmetic, named P-MSO, such that a\nlanguage $L$ of $SP^\\diamond(A)$ is rational if and only if $L$ is the language\nof a sentence of P-MSO, with effective constructions from one formalism to the\nother. As a corollary, the P-MSO theory of $SP^\\diamond(A)$ is decidable.\n", "versions": [{"version": "v1", "created": "Sat, 21 Dec 2019 10:27:40 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Amrane", "Amazigh", ""], ["Bedon", "Nicolas", ""]]}, {"id": "1912.10628", "submitter": "EPTCS", "authors": "Jan Bessai (Technical University of Dortmund), Moritz Roidl (Technical\n  University of Dortmund), Anna Vasileva (Technical University of Dortmund)", "title": "Experience Report: Towards Moving Things with Types -- Helping Logistics\n  Domain Experts to Control Cyber-Physical Systems with Type-Based Synthesis", "comments": "In Proceedings F-IDE 2019, arXiv:1912.09611", "journal-ref": "EPTCS 310, 2019, pp. 1-6", "doi": "10.4204/EPTCS.310.1", "report-no": null, "categories": "cs.HC cs.FL cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the ultimate goals of software engineering is to leave virtual spaces\nand move real things. We take one step toward supporting users with this goal\nby connecting a type-based synthesis algorithm, (CL)S, and its IDE to a\nlogistics lab environment. The environment is built and used by domain experts,\nwho have little or no training in formal methods, and need to cope with large\nspaces of software, hardware and problem specific solution variability. It\nconsists of a number of Cyber-Physical Systems (CPS), including wheel-driven\nrobots as well as flying drones, and it has laser-based support to visualize\ntheir possible movements. Our work describes results on an experiment\nintegrating the latter with (CL)S. Possibilities and challenges of working in\nthe domain of logistics and in cooperation with its experts are outlined.\nFuture research plans are presented and an invitation is made to join the\neffort of building better, formally understood, development tools for\nCPS-enabled industrial environments.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 05:39:44 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Bessai", "Jan", "", "Technical University of Dortmund"], ["Roidl", "Moritz", "", "Technical\n  University of Dortmund"], ["Vasileva", "Anna", "", "Technical University of Dortmund"]]}, {"id": "1912.11203", "submitter": "Sasha Rubin", "authors": "Benjamin Aminof and Giuseppe De Giacomo and Sasha Rubin", "title": "Stochastic Fairness and Language-Theoretic Fairness in Planning on\n  Nondeterministic Domains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address two central notions of fairness in the literature of planning on\nnondeterministic fully observable domains. The first, which we call stochastic\nfairness, is classical, and assumes an environment which operates\nprobabilistically using possibly unknown probabilities. The second, which is\nlanguage-theoretic, assumes that if an action is taken from a given state\ninfinitely often then all its possible outcomes should appear infinitely often\n(we call this state-action fairness). While the two notions coincide for\nstandard reachability goals, they diverge for temporally extended goals. This\nimportant difference has been overlooked in the planning literature, and we\nargue has led to confusion in a number of published algorithms which use\nreductions that were stated for state-action fairness, for which they are\nincorrect, while being correct for stochastic fairness. We remedy this and\nprovide an optimal sound and complete algorithm for solving state-action fair\nplanning for LTL/LTLf goals, as well as a correct proof of the lower bound of\nthe goal-complexity (our proof is general enough that it provides new proofs\nalso for the no-fairness and stochastic-fairness cases). Overall, we show that\nstochastic fairness is better behaved than state-action fairness.\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2019 04:35:33 GMT"}], "update_date": "2019-12-25", "authors_parsed": [["Aminof", "Benjamin", ""], ["De Giacomo", "Giuseppe", ""], ["Rubin", "Sasha", ""]]}, {"id": "1912.11388", "submitter": "Lucas Mol", "authors": "Lucas Mol and Narad Rampersad", "title": "The Weak Circular Repetition Threshold Over Large Alphabets", "comments": "arXiv admin note: text overlap with arXiv:1911.05779", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.DM cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The repetition threshold for words on $n$ letters, denoted $\\mbox{RT}(n)$, is\nthe infimum of the set of all $r$ such that there are arbitrarily long $r$-free\nwords over $n$ letters. A repetition threshold for circular words on $n$\nletters can be defined in three natural ways, which gives rise to the weak,\nintermediate, and strong circular repetition thresholds for $n$ letters,\ndenoted $\\mbox{CRT}_{\\mbox{W}}(n)$, $\\mbox{CRT}_{\\mbox{I}}(n)$, and\n$\\mbox{CRT}_{\\mbox{S}}(n)$, respectively. Currie and the present authors\nconjectured that\n$\\mbox{CRT}_{\\mbox{I}}(n)=\\mbox{CRT}_{\\mbox{W}}(n)=\\mbox{RT}(n)$ for all $n\\geq\n4$. We prove that $\\mbox{CRT}_{\\mbox{W}}(n)=\\mbox{RT}(n)$ for all $n\\geq 45$,\nwhich confirms a weak version of this conjecture for all but finitely many\nvalues of $n$.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 03:07:12 GMT"}], "update_date": "2019-12-25", "authors_parsed": [["Mol", "Lucas", ""], ["Rampersad", "Narad", ""]]}, {"id": "1912.11396", "submitter": "Nathana\\\"el Fijalkow", "authors": "Nathana\\\"el Fijalkow", "title": "Lower bounds for the state complexity of probabilistic languages and the\n  language of prime numbers", "comments": "Submitted to the Journal of Logic and Computation, Special Issue on\n  LFCS'2016) (Logical Foundations of Computer Science). Guest Editors: S.\n  Artemov and A. Nerode. This journal version extends two conference papers:\n  the first published in the proceedings of LFCS'2016 and the second in the\n  proceedings of LICS'2018. arXiv admin note: substantial text overlap with\n  arXiv:1607.00259", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the complexity of languages of finite words using automata\ntheory. To go beyond the class of regular languages, we consider infinite\nautomata and the notion of state complexity defined by Karp. Motivated by the\nseminal paper of Rabin from 1963 introducing probabilistic automata, we study\nthe (deterministic) state complexity of probabilistic languages and prove that\nprobabilistic languages can have arbitrarily high deterministic state\ncomplexity. We then look at alternating automata as introduced by Chandra,\nKozen and Stockmeyer: such machines run independent computations on the word\nand gather their answers through boolean combinations. We devise a lower bound\ntechnique relying on boundedly generated lattices of languages, and give two\napplications of this technique. The first is a hierarchy theorem, stating that\nthere are languages of arbitrarily high polynomial alternating state\ncomplexity, and the second is a linear lower bound on the alternating state\ncomplexity of the prime numbers written in binary. This second result\nstrengthens a result of Hartmanis and Shank from 1968, which implies an\nexponentially worse lower bound for the same model.\n", "versions": [{"version": "v1", "created": "Sat, 21 Dec 2019 15:28:38 GMT"}], "update_date": "2019-12-25", "authors_parsed": [["Fijalkow", "Nathana\u00ebl", ""]]}, {"id": "1912.11699", "submitter": "\\\"Ozlem Salehi", "authors": "\\\"Ozlem Salehi", "title": "Extended Models of Finite Automata", "comments": "Ph.D. Thesis, Bo\\u{g}azi\\c{c}i University Computer Engineering\n  Department, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many of the numerous automaton models proposed in the literature can be\nregarded as a finite automaton equipped with an additional storage mechanism.\nIn this thesis, we focus on two such models, namely the finite automata over\ngroups and the homing vector automata.\n  A finite automaton over a group $ G $ is a nondeterministic finite automaton\nequipped with a register that holds an element of the group $ G $. The register\nis initialized to the identity element of the group and a computation is\nsuccessful if the register is equal to the identity element at the end of the\ncomputation after being multiplied with a group element at every step. We\ninvestigate the language recognition power of finite automata over integer and\nrational matrix groups and reveal new relationships between the language\nclasses corresponding to these models. We examine the effect of various\nparameters on the language recognition power. We establish a link between the\ndecision problems of matrix semigroups and the corresponding automata. We\npresent some new results about valence pushdown automata and context-free\nvalence grammars.\n  We also propose the new homing vector automaton model, which is a finite\nautomaton equipped with a vector that can be multiplied with a matrix at each\nstep. The vector can be checked for equivalence to the initial vector and the\nacceptance criterion is ending up in an accept state with the value of the\nvector being equal to the initial vector. We examine the effect of various\nrestrictions on the model by confining the matrices to a particular set and\nallowing the equivalence test only at the end of the computation. We define the\ndifferent variants of the model and compare their language recognition power\nwith that of the classical models.\n", "versions": [{"version": "v1", "created": "Wed, 25 Dec 2019 17:33:41 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Salehi", "\u00d6zlem", ""]]}, {"id": "1912.13401", "submitter": "Vladislav Makarov", "authors": "Vladislav Makarov", "title": "Bounded languages described by GF(2)-grammars", "comments": "34 pages, 0 figures A big simplification and some discussion around\n  it, compared to v. 1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  GF(2)-grammars are a recently introduced grammar family with some unusual\nalgebraic properties. They are closely connected to unambiguous grammars. By\nusing the method of formal power series, we establish strong conditions that\nare necessary for subsets of a^* b^* and a^* b^* c^* to be described by some\nGF(2)-grammar. By further applying the established results, we settle the\nlong-standing open question of proving inherent ambiguity of the language {a^n\nb^m c^k | n != m or m != k}$, as well as give a new purely algebraic proof of\nthe inherent ambiguity of the language {a^n b^m c^k}{n = m or m = k}.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 16:41:01 GMT"}, {"version": "v2", "created": "Thu, 17 Dec 2020 18:51:04 GMT"}, {"version": "v3", "created": "Tue, 16 Feb 2021 17:26:05 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Makarov", "Vladislav", ""]]}, {"id": "1912.13430", "submitter": "Alberto Camacho", "authors": "Alberto Camacho, Sheila A. McIlraith", "title": "Towards Neural-Guided Program Synthesis for Linear Temporal Logic\n  Specifications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.FL cs.GT cs.LO cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Synthesizing a program that realizes a logical specification is a classical\nproblem in computer science. We examine a particular type of program synthesis,\nwhere the objective is to synthesize a strategy that reacts to a potentially\nadversarial environment while ensuring that all executions satisfy a Linear\nTemporal Logic (LTL) specification. Unfortunately, exact methods to solve\nso-called LTL synthesis via logical inference do not scale. In this work, we\ncast LTL synthesis as an optimization problem. We employ a neural network to\nlearn a Q-function that is then used to guide search, and to construct programs\nthat are subsequently verified for correctness. Our method is unique in\ncombining search with deep learning to realize LTL synthesis. In our\nexperiments the learned Q-function provides effective guidance for synthesis\nproblems with relatively small specifications.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 17:09:49 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Camacho", "Alberto", ""], ["McIlraith", "Sheila A.", ""]]}]