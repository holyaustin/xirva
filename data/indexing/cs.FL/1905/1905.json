[{"id": "1905.00559", "submitter": "Heiko Vogler", "authors": "Joost Engelfriet and Heiko Vogler", "title": "A B\\\"uchi-Elgot-Trakhtenbrot theorem for automata with MSO graph storage", "comments": null, "journal-ref": "Discrete Mathematics & Theoretical Computer Science, vol. 22 no.\n  4, Automata, Logic and Semantics (August 27, 2020) dmtcs:6734", "doi": "10.23638/DMTCS-22-4-3", "report-no": null, "categories": "cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce MSO graph storage types, and call a storage type MSO-expressible\nif it is isomorphic to some MSO graph storage type. An MSO graph storage type\nhas MSO-definable sets of graphs as storage configurations and as storage\ntransformations. We consider sequential automata with MSO graph storage and\nassociate with each such automaton a string language (in the usual way) and a\ngraph language; a graph is accepted by the automaton if it represents a correct\nsequence of storage configurations for a given input string. For each MSO graph\nstorage type, we define an MSO logic which is a subset of the usual MSO logic\non graphs. We prove a B\\\"uchi-Elgot-Trakhtenbrot theorem, both for the string\ncase and the graph case. Moreover, we prove that (i) each MSO graph\ntransduction can be used as storage transformation in an MSO graph storage\ntype, (ii) every automatic storage type is MSO-expressible, and (iii) the\npushdown operator on storage types preserves the property of\nMSO-expressibility. Thus, the iterated pushdown storage types are\nMSO-expressible.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 03:03:44 GMT"}, {"version": "v2", "created": "Thu, 7 Nov 2019 14:51:48 GMT"}, {"version": "v3", "created": "Wed, 1 Jul 2020 12:11:53 GMT"}, {"version": "v4", "created": "Thu, 20 Aug 2020 16:04:42 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Engelfriet", "Joost", ""], ["Vogler", "Heiko", ""]]}, {"id": "1905.01340", "submitter": "Manon Stipulanti", "authors": "Marieh Jahannia, Morteza Mohammad-noori, Narad Rampersad, Manon\n  Stipulanti", "title": "Palindromic Ziv-Lempel and Crochemore Factorizations of $m$-Bonacci\n  Infinite Words", "comments": "34 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.FL math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a variation of the Ziv-Lempel and Crochemore factorizations of\nwords by requiring each factor to be a palindrome. We compute these\nfactorizations for the Fibonacci word, and more generally, for all $m$-bonacci\nwords.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 18:40:09 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Jahannia", "Marieh", ""], ["Mohammad-noori", "Morteza", ""], ["Rampersad", "Narad", ""], ["Stipulanti", "Manon", ""]]}, {"id": "1905.01607", "submitter": "Siham Khoussi", "authors": "Siham Khoussi, Ayoub Nouri, Junxiao Shi, James Filliben, Lotfi\n  Benmohamed, Abdella Battou, Saddek Bensalem", "title": "Performance Evaluation of the NDN Data Plane Using Statistical Model\n  Checking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.FL", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Named Data Networking (NDN) is an emerging technology for a future internet\narchitecture that addresses weaknesses of the Internet Protocol (IP). Since\nInternet users and applications have demonstrated an ever-increasing need for\nhigh speed packet forwarding, research groups have investigated different\ndesigns and implementation for fast NDN data plane forwarders and claimed they\nwere capable of achieving high throughput rates. However, the correctness of\nthese statements is not supported by any verification technique or formal\nproof. In this paper, we propose using a formal model-based approach to\novercome this issue. We consider the NDN-DPDK prototype implementation of a\nforwarder realized at NIST, which leverages concurrency to enhance overall\nquality of service. We use our approach to improve its design and to formally\nshow that it can achieve high throughput rates.\n", "versions": [{"version": "v1", "created": "Sun, 5 May 2019 05:02:06 GMT"}, {"version": "v2", "created": "Fri, 26 Jul 2019 20:29:45 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Khoussi", "Siham", ""], ["Nouri", "Ayoub", ""], ["Shi", "Junxiao", ""], ["Filliben", "James", ""], ["Benmohamed", "Lotfi", ""], ["Battou", "Abdella", ""], ["Bensalem", "Saddek", ""]]}, {"id": "1905.02145", "submitter": "S\\'ergio Medeiros", "authors": "S\\'ergio Queiroz de Medeiros, Gilney de Azevedo Alvez Junior, Fabio\n  Mascarenhas", "title": "Automatic Syntax Error Reporting and Recovery in Parsing Expression\n  Grammars", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Error recovery is an essential feature for a parser that should be plugged in\nIntegrated Development Environments (IDEs), which must build Abstract Syntax\nTrees (ASTs) even for syntactically invalid programs in order to offer features\nsuch as automated refactoring and code completion.\n  Parsing Expressions Grammars (PEGs) are a formalism that naturally describes\nrecursive top-down parsers using a restricted form of backtracking. Labeled\nfailures are a conservative extension of PEGs that adds an error reporting\nmechanism for PEG parsers, and these labels can also be associated with\nrecovery expressions to provide an error recovery mechanism. These expressions\ncan use the full expressivity of PEGs to recover from syntactic errors.\n  Manually annotating a large grammar with labels and recovery expressions can\nbe difficult. In this work, we present two approaches, Standard and Unique, to\nautomatically annotate a PEG with labels, and to build their corresponding\nrecovery expressions. The Standard approach annotates a grammar in a way\nsimilar to manual annotation, but it may insert labels incorrectly, while the\nUnique approach is more conservative to annotate a grammar and does not insert\nlabels incorrectly.\n  We evaluate both approaches by using them to generate error recovering\nparsers for four programming languages: Titan, C, Pascal and Java. In our\nevaluation, the parsers produced using the Standard approach, after a manual\nintervention to remove the labels incorrectly added, gave an acceptable\nrecovery for at least 70% of the files in each language. By it turn, the\nacceptable recovery rate of the parsers produced via the Unique approach,\nwithout the need of manual intervention, ranged from 41% to 76%.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 16:56:35 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2019 16:39:16 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["de Medeiros", "S\u00e9rgio Queiroz", ""], ["Junior", "Gilney de Azevedo Alvez", ""], ["Mascarenhas", "Fabio", ""]]}, {"id": "1905.03538", "submitter": "L\\'eo Exibard", "authors": "L\\'eo Exibard, Emmanuel Filiot, Pierre-Alain Reynier", "title": "Synthesis of Data Word Transducers", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 17, Issue 1 (March 18,\n  2021) lmcs:7279", "doi": null, "report-no": null, "categories": "cs.FL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In reactive synthesis, the goal is to automatically generate an\nimplementation from a specification of the reactive and non-terminating\ninput/output behaviours of a system. Specifications are usually modelled as\nlogical formulae or automata over infinite sequences of signals\n($\\omega$-words), while implementations are represented as transducers. In the\nclassical setting, the set of signals is assumed to be finite. In this paper,\nwe consider data $\\omega$-words instead, i.e., words over an infinite alphabet.\nIn this context, we study specifications and implementations respectively given\nas automata and transducers extended with a finite set of registers. We\nconsider different instances, depending on whether the specification is\nnondeterministic, universal or deterministic, and depending on whether the\nnumber of registers of the implementation is given or not.\n  In the unbounded setting, we show undecidability for both universal and\nnondeterministic specifications, while decidability is recovered in the\ndeterministic case. In the bounded setting, undecidability still holds for\nnondeterministic specifications, but can be recovered by disallowing tests over\ninput data. The generic technique we use to show the latter result allows us to\nreprove some known result, namely decidability of bounded synthesis for\nuniversal specifications.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 11:27:25 GMT"}, {"version": "v2", "created": "Tue, 17 Dec 2019 10:35:12 GMT"}, {"version": "v3", "created": "Tue, 9 Jun 2020 12:27:15 GMT"}, {"version": "v4", "created": "Tue, 9 Feb 2021 14:26:27 GMT"}, {"version": "v5", "created": "Wed, 17 Mar 2021 13:56:55 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Exibard", "L\u00e9o", ""], ["Filiot", "Emmanuel", ""], ["Reynier", "Pierre-Alain", ""]]}, {"id": "1905.03560", "submitter": "L\\'eo Exibard", "authors": "L\\'eo Exibard, Emmanuel Filiot, Isma\\\"el Jecker", "title": "The Complexity of Transducer Synthesis from Multi-Sequential\n  Specifications", "comments": "MFCS 2018", "journal-ref": null, "doi": "10.4230/LIPIcs.MFCS.2018.46", "report-no": null, "categories": "cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The transducer synthesis problem on finite words asks, given a specification\n$S \\subseteq I \\times O$, where $I$ and $O$ are sets of finite words, whether\nthere exists an implementation $f: I \\rightarrow O$ which (1) fulfils the\nspecification, i.e., $(i,f(i))\\in S$ for all $i\\in I$, and (2) can be defined\nby some input-deterministic (aka sequential) transducer $\\mathcal{T}_f$. If\nsuch an implementation $f$ exists, the procedure should also output\n$\\mathcal{T}_f$. The realisability problem is the corresponding decision\nproblem.\n  For specifications given by synchronous transducers (which read and write\nalternately one symbol), this is the finite variant of the classical synthesis\nproblem on $\\omega$-words, solved by B\\\"uchi and Landweber in 1969, and the\nrealisability problem is known to be ExpTime-c in both finite and $\\omega$-word\nsettings. For specifications given by asynchronous transducers (which can write\na batch of symbols, or none, in a single step), the realisability problem is\nknown to be undecidable.\n  We consider here the class of multi-sequential specifications, defined as\nfinite unions of sequential transducers over possibly incomparable domains. We\nprovide optimal decision procedures for the realisability problem in both the\nsynchronous and asynchronous setting, showing that it is PSpace-c. Moreover,\nwhenever the specification is realisable, we expose the construction of a\nsequential transducer that realises it and has a size that is doubly\nexponential, which we prove to be optimal.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 12:09:52 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Exibard", "L\u00e9o", ""], ["Filiot", "Emmanuel", ""], ["Jecker", "Isma\u00ebl", ""]]}, {"id": "1905.04486", "submitter": "Masaki Waga", "authors": "Masaki Waga and \\'Etienne Andr\\'e and Ichiro Hasuo", "title": "Symbolic Monitoring against Specifications Parametric in Time and Data", "comments": "Accepted to CAV 2019", "journal-ref": null, "doi": "10.1007/978-3-030-25540-4_30", "report-no": null, "categories": "cs.FL cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monitoring consists in deciding whether a log meets a given specification. In\nthis work, we propose an automata-based formalism to monitor logs in the form\nof actions associated with time stamps and arbitrarily data values over\ninfinite domains. Our formalism uses both timing parameters and data\nparameters, and is able to output answers symbolic in these parameters and in\nthe log segments where the property is satisfied or violated. We implemented\nour approach in an ad-hoc prototype SyMon, and experiments show that its high\nexpressive power still allows for efficient online monitoring.\n", "versions": [{"version": "v1", "created": "Sat, 11 May 2019 09:48:57 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Waga", "Masaki", ""], ["Andr\u00e9", "\u00c9tienne", ""], ["Hasuo", "Ichiro", ""]]}, {"id": "1905.05114", "submitter": "Stefan Jaax", "authors": "Stefan Jaax, Stefan Kiefer", "title": "On Affine Reachability Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze affine reachability problems in dimensions 1 and 2. We show that\nthe reachability problem for 1-register machines over the integers with affine\nupdates is PSPACE-hard, hence PSPACE-complete, strengthening a result by Finkel\net al. that required polynomial updates. Building on recent results on\ntwo-dimensional integer matrices, we prove NP-completeness of the mortality\nproblem for 2-dimensional integer matrices with determinants +1 and 0.\nMotivated by tight connections with 1-dimensional affine reachability problems\nwithout control states, we also study the complexity of a number of\nreachability problems in finitely generated semigroups of 2-dimensional\nupper-triangular integer matrices.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 16:05:10 GMT"}, {"version": "v2", "created": "Tue, 21 Jan 2020 11:15:04 GMT"}, {"version": "v3", "created": "Thu, 2 Jul 2020 16:10:32 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Jaax", "Stefan", ""], ["Kiefer", "Stefan", ""]]}, {"id": "1905.05500", "submitter": "Simon Foster", "authors": "Simon Foster, James Baxter, Ana Cavalcanti, Jim Woodcock, and Frank\n  Zeyda", "title": "Unifying Semantic Foundations for Automated Verification Tools in\n  Isabelle/UTP", "comments": "40 pages, Accepted for Science of Computer Programming, June 2020", "journal-ref": null, "doi": "10.1016/j.scico.2020.102510", "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing complexity and diversity of models used in the engineering of\ndependable systems implies that a variety of formal methods, across differing\nabstractions, paradigms, and presentations, must be integrated. Such an\nintegration relies on unified semantic foundations for the various notations,\nand co-ordination of a variety of automated verification tools. The\ncontribution of this paper is Isabelle/UTP, an implementation of Hoare and He's\nUnifying Theories of Programming, a framework for unification of formal\nsemantics. Isabelle/UTP permits the mechanisation of computational theories for\ndiverse paradigms, and their use in constructing formalised semantic models.\nThese can be further applied in the development of verification tools,\nharnessing Isabelle's proof automation facilities. Several layers of\nmathematical foundations are developed, including lenses to model variables and\nstate spaces as algebraic objects, alphabetised predicates and relations to\nmodel programs, including algebraic and axiomatic semantics, proof tools for\nHoare logic and refinement calculus, and UTP theories to encode computational\nparadigms.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 10:16:36 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 14:22:15 GMT"}, {"version": "v3", "created": "Mon, 22 Jun 2020 11:26:22 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Foster", "Simon", ""], ["Baxter", "James", ""], ["Cavalcanti", "Ana", ""], ["Woodcock", "Jim", ""], ["Zeyda", "Frank", ""]]}, {"id": "1905.05519", "submitter": "Gerco van Heerdt", "authors": "Gerco van Heerdt, Joshua Moerman, Matteo Sammartino, Alexandra Silva", "title": "A (co)algebraic theory of succinct automata", "comments": null, "journal-ref": null, "doi": "10.1016/j.jlamp.2019.02.008", "report-no": null, "categories": "cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The classical subset construction for non-deterministic automata can be\ngeneralized to other side-effects captured by a monad. The key insight is that\nboth the state space of the determinized automaton and its\nsemantics---languages over an alphabet---have a common algebraic structure:\nthey are Eilenberg-Moore algebras for the powerset monad. In this paper we\nstudy the reverse question to determinization. We will present a construction\nto associate succinct automata to languages based on different algebraic\nstructures. For instance, for classical regular languages the construction will\ntransform a deterministic automaton into a non-deterministic one, where the\nstates represent the join-irreducibles of the language accepted by a\n(potentially) larger deterministic automaton. Other examples will yield\nalternating automata, automata with symmetries, CABA-structured automata, and\nweighted automata.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 11:03:40 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["van Heerdt", "Gerco", ""], ["Moerman", "Joshua", ""], ["Sammartino", "Matteo", ""], ["Silva", "Alexandra", ""]]}, {"id": "1905.05537", "submitter": "Jan Otop", "authors": "Krishnendu Chatterjee, Thomas A. Henzinger and Jan Otop", "title": "Long-Run Average Behavior of Vector Addition Systems with States", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A vector addition system with states (VASS) consists of a finite set of\nstates and counters. A configuration is a state and a value for each counter; a\ntransition changes the state and each counter is incremented, decremented, or\nleft unchanged. While qualitative properties such as state and configuration\nreachability have been studied for VASS, we consider the long-run average cost\nof infinite computations of VASS. The cost of a configuration is for each\nstate, a linear combination of the counter values. In the special case of\nuniform cost functions, the linear combination is the same for all states. The\n(regular) long-run emptiness problem is, given a VASS, a cost function, and a\nthreshold value, if there is a (lasso-shaped) computation such that the\nlong-run average value of the cost function does not exceed the threshold. For\nuniform cost functions, we show that the regular long-run emptiness problem is\n(a)~decidable in polynomial time for integer-valued VASS, and (b)~decidable but\nnonelementarily hard for natural-valued VASS (i.e., nonnegative counters). For\ngeneral cost functions, we show that the problem is (c)~NP-complete for\ninteger-valued VASS, and (d)~undecidable for natural-valued VASS. Our most\ninteresting result is for (c) integer-valued VASS with general cost functions,\nwhere we establish a connection between the regular long-run emptiness problem\nand quadratic Diophantine inequalities. The general (nonregular) long-run\nemptiness problem is equally hard as the regular problem in all cases except\n(c), where it remains open.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 12:05:54 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Chatterjee", "Krishnendu", ""], ["Henzinger", "Thomas A.", ""], ["Otop", "Jan", ""]]}, {"id": "1905.05801", "submitter": "Joseph Vandehey", "authors": "Olivier Carton and Joseph Vandehey", "title": "Preservation of normality by non-oblivious group selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give two different proofs of the fact that non-oblivious selection via\nregular group sets preserves normality. Non-oblivious here means that whether\nor not a symbol is selected can depend on the symbol itself. One proof relies\non the incompressibility of normal sequences, the other on the use of augmented\ndynamical systems.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 01:19:52 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Carton", "Olivier", ""], ["Vandehey", "Joseph", ""]]}, {"id": "1905.06138", "submitter": "Jarkko Peltom\\\"aki", "authors": "Jarkko Peltom\\\"aki", "title": "Abelian periods of factors of Sturmian words", "comments": "27 pages, 3 figures", "journal-ref": "Journal of Number Theory, Vol. 214, 251-285 (2020)", "doi": "10.1016/j.jnt.2020.04.007", "report-no": null, "categories": "cs.FL math.NT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the abelian period sets of Sturmian words, which are codings of\nirrational rotations on a one-dimensional torus. The main result states that\nthe minimum abelian period of a factor of a Sturmian word of angle $\\alpha$\nwith continued fraction expansion $[0; a_1, a_2, \\ldots]$ is either $tq_k$ with\n$1 \\leq t \\leq a_{k+1}$ (a multiple of a denominator $q_k$ of a convergent of\n$\\alpha$) or $q_{k,\\ell}$ (a denominator $q_{k,\\ell}$ of a semiconvergent of\n$\\alpha$). This result generalizes a result of Fici et. al stating that the\nabelian period set of the Fibonacci word is the set of Fibonacci numbers. A\ncharacterization of the Fibonacci word in terms of its abelian period set is\nobtained as a corollary.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 12:33:32 GMT"}, {"version": "v2", "created": "Thu, 2 Jan 2020 12:16:32 GMT"}, {"version": "v3", "created": "Wed, 22 Apr 2020 10:53:55 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Peltom\u00e4ki", "Jarkko", ""]]}, {"id": "1905.06604", "submitter": "Burkhart Wolff", "authors": "Sergio Bezzecchi, Paolo Crisafulli, Charlotte Pichot, and Burkhart\n  Wolff", "title": "Making Agile Development Processes fit for V-style Certification\n  Procedures", "comments": "11 pages, 6 figures. Appeared in the online conference publication of\n  ERTS 2018, 31.1. - 2.2.2018, Toulouse, France", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a process for the development of safety and security critical\ncomponents in transportation systems targeting a high-level certification\n(CENELEC 50126/50128, DO 178, CC ISO/IEC 15408). The process adheres to the\nobjectives of an \"agile development\" in terms of evolutionary flexibility and\ncontinuous improvement. Yet, it enforces the overall coherence of the\ndevelopment artifacts (ranging from proofs over tests to code) by a particular\nenvironment (CVCE). In particular, the validation process is built around a\nformal development based on the interactive theorem proving system\nIsabelle/HOL, by linking the business logic of the application to the operating\nsystem model, down to code and concrete hardware models thanks to a series of\nrefinement proofs. We apply both the process and its support in CVCE to a\ncase-study that comprises a model of an odometric service in a railway-system\nwith its corresponding implementation integrated in seL4 (a secure kernel for\nwhich a comprehensive Isabelle development exists). Novel techniques\nimplemented in Isabelle enforce the coherence of semi-formal and formal\ndefinitions within specific certification processes in order to improve their\ncost-effectiveness . This paper has been published at ERTS2018.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 08:58:16 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Bezzecchi", "Sergio", ""], ["Crisafulli", "Paolo", ""], ["Pichot", "Charlotte", ""], ["Wolff", "Burkhart", ""]]}, {"id": "1905.06732", "submitter": "Maryam Bagheri", "authors": "Maryam Bagheri, Marjan Sirjani, Ehsan Khamespanah, Christel Baier, and\n  Ali Movaghar", "title": "Magnifier: A Compositional Analysis Approach for Autonomous Traffic\n  Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous traffic control systems are large-scale systems with critical\ngoals. Due to the dynamic nature of the surrounding world of these systems,\nassuring the satisfaction of their properties at runtime and in the presence of\na change is important. A prominent approach to assure the correct behavior of\nthese systems is verification at runtime, which has strict time and memory\nlimitations. To tackle these limitations, we propose Magnifier, an iterative,\nincremental, and compositional verification approach that operates on a\ncomponent-based model. The Magnifier idea is zooming on the component affected\nby a change, verifying the correctness of properties of interest of the system\nafter adapting the component to the change, and then zooming out and tracing\nthe change if it propagates. If the change propagates, all components affected\nby the change are adapted and are composed to form a new component. Magnifier\nrepeats the same process for the new component. This iterative process\nterminates whenever the propagation of the change stops. In Magnifier, we use\nthe Coordinated Adaptive Actor model (CoodAA) of traffic control systems. We\npresent a formal semantics for CoodAA as a network of Timed Input-Output\nAutomata (TIOAs). The change does not propagate if TIOAs of the adapted\ncomponent and its environment are compatible. We implement our approach in\nPtolemy II. The results of our experiments indicate that the proposed approach\nimproves the verification time and the memory consumption compared to a\nnon-compositional approach.\n", "versions": [{"version": "v1", "created": "Sat, 20 Apr 2019 06:48:33 GMT"}, {"version": "v2", "created": "Mon, 12 Oct 2020 17:45:41 GMT"}, {"version": "v3", "created": "Thu, 11 Mar 2021 11:24:28 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Bagheri", "Maryam", ""], ["Sirjani", "Marjan", ""], ["Khamespanah", "Ehsan", ""], ["Baier", "Christel", ""], ["Movaghar", "Ali", ""]]}, {"id": "1905.07139", "submitter": "Ond\\v{r}ej Leng\\'al", "authors": "Yu-Fang Chen, Vojt\\v{e}ch Havlena, Ond\\v{r}ej Leng\\'al", "title": "Simulations in Rank-Based B\\\"uchi Automata Complementation (Technical\n  Report)", "comments": "An extended version of a paper to appear in Proc. of APLAS'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complementation of B\\\"uchi automata is an essential technique used in some\napproaches for termination analysis of programs. The long search for an optimal\ncomplementation construction climaxed with the work of Schewe, who proposed a\nworst-case optimal rank-based procedure that generates complements of a size\nmatching the theoretical lower bound of $(0.76n)^n$, modulo a polynomial factor\nof $O(n^2)$. Although worst-case optimal, the procedure in many cases produces\nautomata that are unnecessarily large. In this paper, we propose several ways\nof how to use the direct and delayed simulation relations to reduce the size of\nthe automaton obtained in the rank-based complementation procedure. Our\ntechniques are based on either (i) ignoring macrostates that cannot be used for\naccepting a word in the complement or (ii) saturating macrostates with\nsimulation-smaller states, in order to decrease their total number. We\nexperimentally showed that our techniques can indeed considerably decrease the\nsize of the output of the complementation.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 07:26:49 GMT"}, {"version": "v2", "created": "Fri, 4 Oct 2019 15:10:27 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Chen", "Yu-Fang", ""], ["Havlena", "Vojt\u011bch", ""], ["Leng\u00e1l", "Ond\u0159ej", ""]]}, {"id": "1905.07223", "submitter": "Aleksi Saarela", "authors": "Aleksi Saarela", "title": "Separating many words by counting occurrences of factors", "comments": "16 pages. Full version of an article to appear in the proceedings of\n  the 23rd International Conference on Developments in Language Theory (DLT\n  2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a given language $L$, we study the languages $X$ such that for all\ndistinct words $u, v \\in L$, there exists a word $x \\in X$ that appears a\ndifferent number of times as a factor in $u$ and in $v$. In particular, we are\ninterested in the following question: For which languages $L$ does there exist\na finite language $X$ satisfying the above condition? We answer this question\nfor all regular languages and for all sets of factors of infinite words.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 12:24:01 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Saarela", "Aleksi", ""]]}, {"id": "1905.07365", "submitter": "Victor Roussanaly", "authors": "Victor Roussanaly, Ocan Sankur, Nicolas Markey", "title": "Abstraction Refinement Algorithms for Timed Automata", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present abstraction-refinement algorithms for model checking safety\nproperties of timed automata. The abstraction domain we consider abstracts away\nzones by restricting the set of clock constraints that can be used to define\nthem, while the refinement procedure computes the set of constraints that must\nbe taken into consideration in the abstraction so as to exclude a given\nspurious counterexample. We implement this idea in two ways: an enumerative\nalgorithm where a lazy abstraction approach is adopted, meaning that possibly\ndifferent abstract domains are assigned to each exploration node; and a\nsymbolic algorithm where the abstract transition system is encoded with Boolean\nformulas.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 16:33:39 GMT"}, {"version": "v2", "created": "Mon, 20 May 2019 10:00:37 GMT"}, {"version": "v3", "created": "Fri, 24 May 2019 12:27:23 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Roussanaly", "Victor", ""], ["Sankur", "Ocan", ""], ["Markey", "Nicolas", ""]]}, {"id": "1905.07737", "submitter": "Ziyuan Gao", "authors": "Ziyuan Gao", "title": "The teaching complexity of erasing pattern languages with bounded\n  variable frequency", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Patterns provide a concise, syntactic way of describing a set of strings, but\ntheir expressive power comes at a price: a number of fundamental decision\nproblems concerning (erasing) pattern languages, such as the membership problem\nand inclusion problem, are known to be NP-complete or even undecidable, while\nthe decidability of the equivalence problem is still open; in learning theory,\nthe class of pattern languages is unlearnable in models such as the\ndistribution-free (PAC) framework (if $\\mathcal{P}/poly \\neq\n\\mathcal{NP}/poly$). Much work on the algorithmic learning of pattern languages\nhas thus focussed on interesting subclasses of patterns for which positive\nlearnability results may be achieved. A natural restriction on a pattern is a\nbound on its variable frequency -- the maximum number $m$ such that some\nvariable occurs exactly $m$ times in the pattern. This paper examines the\neffect of limiting the variable frequency of all patterns belonging to a class\n$\\Pi$ on the worst-case minimum number of labelled examples needed to uniquely\nidentify any pattern of $\\Pi$ in cooperative teaching-learning models. Two such\nmodels, the teaching dimension model as well as the preference-based teaching\nmodel, will be considered.\n", "versions": [{"version": "v1", "created": "Sun, 19 May 2019 13:22:41 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Gao", "Ziyuan", ""]]}, {"id": "1905.08120", "submitter": "Pascal Caron", "authors": "Pascal Caron, Jean-Gabriel Luque, Bruno Patrou", "title": "A combinatorial approach for the state complexity of the Shuffle product", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the state complexity of the shuffle operation on regular\nlanguages initiated by Campeanu et al. and studied subsequently by Brzozowski\net al. We shift the problem into the combinatorics domain by turning the\nproblem of state accessibility into a problem of intersection of partitions.\nThis allows us to develop new tools and to reformulate the conjecture of\nBrzozowski et al. about the above-mentionned state complexity.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 14:00:38 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Caron", "Pascal", ""], ["Luque", "Jean-Gabriel", ""], ["Patrou", "Bruno", ""]]}, {"id": "1905.08169", "submitter": "Beyazit Yalcinkaya", "authors": "Beyazit Yalcinkaya and Ebru Aydin Gol", "title": "ATAC: A Tool for Automating Timed Automata Construction", "comments": "10 pages, 1 figure, tool paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we focus on the design and verification of timed automata\n(TA). We introduce a new method for assisting construction and verification of\nTA models along with a tool implementing the proposed method, i.e., ATAC:\nAutomated Timed Automata Construction. Our method provides two main\nfunctionalities, i.e., construction of TA models from descriptions and\ngeneration of temporal logic queries from specifications. Both description and\nspecification sentences shall follow our well-defined structured natural\nlanguage definition. TA models constructed from descriptions and temporal logic\nqueries generated from specifications can be imported to UPPAAL, a verification\ntool for TA models. The goal is to accelerate the design phase for real-time\nsystems by assisting the construction and verification of a formal model. We\nbelieve ATAC can be useful especially during the initial phases of the design\nprocess and help designers to avoid erroneous models.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 15:29:36 GMT"}, {"version": "v2", "created": "Wed, 1 Jul 2020 18:54:25 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Yalcinkaya", "Beyazit", ""], ["Gol", "Ebru Aydin", ""]]}, {"id": "1905.08531", "submitter": "Mathias Ruggaard Pedersen", "authors": "Mathias Ruggaard Pedersen", "title": "Behavioural Preorders on Stochastic Systems - Logical, Topological, and\n  Computational Aspects", "comments": "PhD dissertation from Aalborg University", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Computer systems can be found everywhere: in space, in our homes, in our\ncars, in our pockets, and sometimes even in our own bodies. For concerns of\nsafety, economy, and convenience, it is important that such systems work\ncorrectly. However, it is a notoriously difficult task to ensure that the\nsoftware running on computers behaves correctly.\n  One approach to ease this task is that of model checking, where a model of\nthe system is made using some mathematical formalism. Requirements expressed in\na formal language can then be verified against the model in order to give\nguarantees that the model satisfies the requirements.\n  For many computer systems, time is an important factor. As such, we need our\nformalisms and requirement languages to be able to incorporate real time.\n  We therefore develop formalisms and algorithms that allow us to compare and\nexpress properties about real-time systems. We first introduce a logical\nformalism for reasoning about upper and lower bounds on time, and study the\nproperties of this formalism, including axiomatisation and algorithms for\nchecking when a formula is satisfied.\n  We then consider the question of when a system is faster than another system.\nWe show that this is a difficult question which can not be answered in general,\nbut we identify special cases where this question can be answered. We also show\nthat under this notion of faster-than, a local increase in speed may lead to a\nglobal decrease in speed, and we take step towards avoiding this.\n  Finally, we consider how to compare the real-time behaviour of systems not\njust qualitatively, but also quantitatively. Thus, we are interested in knowing\nhow much one system is faster or slower than another system. This is done by\nintroducing a distance between systems. We show how to compute this distance\nand that it behaves well with respect to certain properties.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 10:30:30 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Pedersen", "Mathias Ruggaard", ""]]}, {"id": "1905.08697", "submitter": "Ond\\v{r}ej Leng\\'al", "authors": "Vojt\\v{e}ch Havlena, Luk\\'a\\v{s} Hol\\'ik, Ond\\v{r}ej Leng\\'al,\n  Tom\\'a\\v{s} Vojnar", "title": "Automata Terms in a Lazy WSkS Decision Procedure (Technical Report)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a lazy decision procedure for the logic WSkS. It builds a\nterm-based symbolic representation of the state space of the tree automaton\n(TA) constructed by the classical WSkS decision procedure. The classical\ndecision procedure transforms the symbolic representation into a TA via a\nbottom-up traversal and then tests its language non-emptiness, which\ncorresponds to satisfiability of the formula. On the other hand, we start\nevaluating the representation from the top, construct the state space on the\nfly, and utilize opportunities to prune away parts of the state space\nirrelevant to the language emptiness test. In order to do so, we needed to\nextend the notion of language terms (denoting language derivatives) used in our\nprevious procedure for the linear fragment of the logic (the so-called WS1S)\ninto automata terms. We implemented our decision procedure and identified\nclasses of formulae on which our prototype implementation is significantly\nfaster than the classical procedure implemented in the Mona tool.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 15:28:35 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Havlena", "Vojt\u011bch", ""], ["Hol\u00edk", "Luk\u00e1\u0161", ""], ["Leng\u00e1l", "Ond\u0159ej", ""], ["Vojnar", "Tom\u00e1\u0161", ""]]}, {"id": "1905.08701", "submitter": "Ananda Theertha Suresh", "authors": "Ananda Theertha Suresh, Brian Roark, Michael Riley, Vlad Schogol", "title": "Approximating probabilistic models as weighted finite automata", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.FL cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weighted finite automata (WFA) are often used to represent probabilistic\nmodels, such as $n$-gram language models, since they are efficient for\nrecognition tasks in time and space. The probabilistic source to be represented\nas a WFA, however, may come in many forms. Given a generic probabilistic model\nover sequences, we propose an algorithm to approximate it as a weighted finite\nautomaton such that the Kullback-Leiber divergence between the source model and\nthe WFA target model is minimized. The proposed algorithm involves a counting\nstep and a difference of convex optimization step, both of which can be\nperformed efficiently. We demonstrate the usefulness of our approach on various\ntasks, including distilling $n$-gram models from neural models, building\ncompact language models, and building open-vocabulary character models. The\nalgorithms used for these experiments are available in an open-source software\nlibrary.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 15:36:54 GMT"}, {"version": "v2", "created": "Mon, 13 Jan 2020 20:33:53 GMT"}, {"version": "v3", "created": "Fri, 29 Jan 2021 16:56:07 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Suresh", "Ananda Theertha", ""], ["Roark", "Brian", ""], ["Riley", "Michael", ""], ["Schogol", "Vlad", ""]]}, {"id": "1905.08760", "submitter": "Martin Jansche", "authors": "Martin Jansche, Alexander Gutkin", "title": "Sampling from Stochastic Finite Automata with Applications to CTC\n  Decoding", "comments": null, "journal-ref": null, "doi": "10.21437/Interspeech.2019-2740", "report-no": null, "categories": "cs.CL cs.FL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Stochastic finite automata arise naturally in many language and speech\nprocessing tasks. They include stochastic acceptors, which represent certain\nprobability distributions over random strings. We consider the problem of\nefficient sampling: drawing random string variates from the probability\ndistribution represented by stochastic automata and transformations of those.\nWe show that path-sampling is effective and can be efficient if the\nepsilon-graph of a finite automaton is acyclic. We provide an algorithm that\nensures this by conflating epsilon-cycles within strongly connected components.\nSampling is also effective in the presence of non-injective transformations of\nstrings. We illustrate this in the context of decoding for Connectionist\nTemporal Classification (CTC), where the predictive probabilities yield\nauxiliary sequences which are transformed into shorter labeling strings. We can\nsample efficiently from the transformed labeling distribution and use this in\ntwo different strategies for finding the most probable CTC labeling.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 17:26:39 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Jansche", "Martin", ""], ["Gutkin", "Alexander", ""]]}, {"id": "1905.09458", "submitter": "\\'Etienne Andr\\'e", "authors": "\\'Etienne Andr\\'e", "title": "Formalizing Time4sys using parametric timed automata", "comments": "This is the author (and slightly extended) version of the manuscript\n  of the same name published in the proceedings of the 13th International\n  Symposium on Theoretical Aspects of Software Engineering (TASE 2019)", "journal-ref": null, "doi": "10.1109/TASE.2019.00031", "report-no": null, "categories": "cs.SE cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Critical real-time systems must be verified to avoid the risk of dramatic\nconsequences in case of failure. Thales developed an open formalism Time4sys to\nmodel real-time systems, with expressive features such as periodic or sporadic\ntasks, task dependencies, distributed systems, etc. However, Time4sys does not\nnatively allow for a formal reasoning. In this work, we present a translation\nfrom Time4sys to (parametric) timed automata, so as to allow for a formal\nverification.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 04:32:09 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Andr\u00e9", "\u00c9tienne", ""]]}, {"id": "1905.09996", "submitter": "Peizun Liu", "authors": "Peizun Liu and Thomas Wahl and Akash LaL", "title": "Verifying Asynchronous Event-Driven Programs Using Partial Abstract\n  Transformers (Extended Manuscript)", "comments": "This is an extended technical report of a paper published in CAV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of analyzing asynchronous event-driven programs, in\nwhich concurrent agents communicate via unbounded message queues. The safety\nverification problem for such programs is undecidable. We present in this paper\na technique that combines queue-bounded exploration with a convergence test: if\nthe sequence of certain abstractions of the reachable states, for increasing\nqueue bounds k, converges, we can prove any property of the program that is\npreserved by the abstraction. If the abstract state space is finite,\nconvergence is guaranteed; the challenge is to catch the point k_max where it\nhappens. We further demonstrate how simple invariants formulated over the\nconcrete domain can be used to eliminate spurious abstract states, which\notherwise prevent the sequence from converging. We have implemented our\ntechnique for the P programming language for event-driven programs. We show\nexperimentally that the sequence of abstractions often converges fully\nautomatically, in hard cases with minimal designer support in the form of\nsequentially provable invariants, and that this happens for a value of k_max\nsmall enough to allow the method to succeed in practice.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 01:48:26 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Liu", "Peizun", ""], ["Wahl", "Thomas", ""], ["LaL", "Akash", ""]]}, {"id": "1905.10460", "submitter": "Jorge Almeida", "authors": "Jorge Almeida, Jos\\'e Carlos Costa, Marc Zeitoun", "title": "Recognizing pro-R closures of regular languages", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.GR cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a regular language L, we effectively construct a unary semigroup that\nrecognizes the topological closure of L in the free unary semigroup relative to\nthe variety of unary semigroups generated by the pseudovariety R of all finite\nR-trivial semigroups. In particular, we obtain a new effective solution of the\nseparation problem of regular languages by R-languages.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 22:00:51 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Almeida", "Jorge", ""], ["Costa", "Jos\u00e9 Carlos", ""], ["Zeitoun", "Marc", ""]]}, {"id": "1905.11125", "submitter": "Ramchandra Phawade", "authors": "Devendra. Bhave, S. N. Krishna, Ramchandra Phawade, and Ashutosh\n  Trivedi", "title": "On Timed Scope-bounded Context-sensitive Languages", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In (DLT 2016) we studied timed context sensitive languages characterized by\nmultiple stack push down automata (MPA), with an explicit bound on number of\nstages where in each stage at most one stack is used (k-round MPA).\n  In this paper, we continue our work on timed MPA and study a subclass in\nwhich a symbol corresponding to a stack being pushed in it must be popped\nwithin fixed number of contexts of that stack---scope-bounded push-down\nautomata with multiple stacks (k-scope MPA). We use Visibly Push-down Alphabet\nand Event Clocks to show that timed k-scope MPA have decidable reachability\nproblem; are closed under Boolean operations; and have an equivalent logical\ncharacterization.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 11:21:21 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Bhave", "Devendra.", ""], ["Krishna", "S. N.", ""], ["Phawade", "Ramchandra", ""], ["Trivedi", "Ashutosh", ""]]}, {"id": "1905.11847", "submitter": "Pamela Fleischmann", "authors": "Pamela Fleischmann, Mitja Kulczynski, Dirk Nowotka", "title": "On Collapsing Prefix Normal Words", "comments": "deleted some typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL math.CO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Prefix normal words are binary words in which each prefix has at least the\nsame number of $\\so$s as any factor of the same length. Firstly introduced by\nFici and Lipt\\'ak in 2011, the problem of determining the index of the prefix\nequivalence relation is still open. In this paper, we investigate two aspects\nof the problem, namely prefix normal palindromes and so-called collapsing words\n(extending the notion of critical words). We prove characterizations for both\nthe palindromes and the collapsing words and show their connection. Based on\nthis, we show that still open problems regarding prefix normal words can be\nsplit into certain subproblems.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 14:28:12 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 09:23:36 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Fleischmann", "Pamela", ""], ["Kulczynski", "Mitja", ""], ["Nowotka", "Dirk", ""]]}, {"id": "1905.11857", "submitter": "\\\"Ozlem Salehi", "authors": "\\\"Ozlem Salehi, Abuzer Yakary{\\i}lmaz, A. C. Cem Say", "title": "New Results on Vector and Homing Vector Automata", "comments": "Accepted to IJFCS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present several new results and connections between various extensions of\nfinite automata through the study of vector automata and homing vector\nautomata. We show that homing vector automata outperform extended finite\nautomata when both are defined over $ 2 \\times 2 $ integer matrices. We study\nthe string separation problem for vector automata and demonstrate that\ngeneralized finite automata with rational entries can separate any pair of\nstrings using only two states. Investigating stateless homing vector automata,\nwe prove that a language is recognized by stateless blind deterministic\nreal-time version of finite automata with multiplication iff it is commutative\nand its Parikh image is the set of nonnegative integer solutions to a system of\nlinear homogeneous Diophantine equations.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 14:42:25 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Salehi", "\u00d6zlem", ""], ["Yakary\u0131lmaz", "Abuzer", ""], ["Say", "A. C. Cem", ""]]}, {"id": "1905.11981", "submitter": "Jakub Konieczny", "authors": "Jakub Konieczny", "title": "On multiplicative automatic sequences", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NT cs.FL math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that any automatic multiplicative sequence either coincides with a\nDirichlet character or is identically zero when restricted to integers not\ndivisible by small primes. This answers a question of Bell, Bruin and Coons. A\nsimilar result was obtained independently by Klurman and Kurlberg.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 17:59:11 GMT"}, {"version": "v2", "created": "Sun, 11 Aug 2019 21:19:35 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Konieczny", "Jakub", ""]]}, {"id": "1905.12445", "submitter": "Antoine Mottet", "authors": "Antoine Mottet and Karin Quaas", "title": "On the Containment Problem for Unambiguous Single-Register Automata with\n  Guessing", "comments": "arXiv admin note: text overlap with arXiv:1809.08985", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Register automata extend classical finite automata with a finite set of\nregisters that can store data from an infinite data domain for later equality\ncomparisons with data from an input data word. While the registers in the\noriginal model of register automata, introduced in 1994 by Kaminski and\nFrancez, can only store data occurring in the data word processed so far, we\nstudy here the more expressive class of register automata with guessing, where\nregisters can nondeterministically take any value from the infinite data\ndomain, even if this data does not occur in the input data word. It is well\nknown that the containment problem, i.e., the problem of deciding for two given\nregister automata with guessing A and B, whether the language L(A) accepted by\nA is contained in the language L(B) accepted by B, is undecidable, even if B\nonly uses a single register. We prove that the problem is decidable if B is\nunambiguous and uses a single register.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 10:34:04 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Mottet", "Antoine", ""], ["Quaas", "Karin", ""]]}, {"id": "1905.12944", "submitter": "Kirill Krinkin", "authors": "Ren\\'e Haberland, Kirill Krinkin", "title": "A Non-repetitive Logic for Verification of Dynamic Memory with Explicit\n  Heap Conjunction and Disjunction", "comments": "9 pages, 7 figures", "journal-ref": "IARIA ADVCOMP, Oct.2016, p.1-9, ISBN 978-1-61208-506-7, ISSN\n  2308-4499", "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we review existing points-to Separation Logics for dynamic\nmemory reasoning and we find that different usages of heap separation tend to\nbe an obstacle. Hence, two total and strict spatial heap operations are\nproposed upon heap graphs, for conjunction and disjunction -- similar to\nlogical conjuncts. Heap conjunction implies that there exists a free heap\nvertex to connect to or an explicit destination vertex is provided.\nEssentially, Burstall's properties do not change. By heap we refer to an\narbitrary simple directed graph, which is finite and may contain composite\nvertices representing class objects. Arbitrary heap memory access is\nrestricted, as well as type punning, late class binding and further\nrestrictions. Properties of the new logic are investigated, and as a result\ngroup properties are shown. Both expecting and superficial heaps are\nspecifiable. Equivalence transformations may make denotated heaps inconsistent,\nalthough those may be detected and patched by the two generic linear\ncanonization steps presented. The properties help to motivate a later full\nintroduction of a set of equivalences over heap for future work. Partial heaps\nare considered as a useful specification technique that help to reduce\nincompleteness issues with specifications. Finally, the logic proposed may be\nconsidered for extension for the Object Constraint Language.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 10:18:58 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Haberland", "Ren\u00e9", ""], ["Krinkin", "Kirill", ""]]}, {"id": "1905.12963", "submitter": "EPTCS", "authors": "Omar al Duhaiby (Eindhoven University of Technology), Jan Friso Groote\n  (Eindhoven University of Technology)", "title": "Distribution of Behaviour into Parallel Communicating Subsystems", "comments": "In Proceedings EXPRESS/SOS 2019, arXiv:1908.08213", "journal-ref": "EPTCS 300, 2019, pp. 54-68", "doi": "10.4204/EPTCS.300.4", "report-no": null, "categories": "cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The process of decomposing a complex system into simpler subsystems has been\nof interest to computer scientists over many decades, for instance, for the\nfield of distributed computing. In this paper, motivated by the desire to\ndistribute the process of active automata learning onto multiple subsystems, we\nstudy the equivalence between a system and the total behaviour of its\ndecomposition which comprises subsystems with communication between them. We\nshow synchronously- and asynchronously-communicating decompositions that\nmaintain branching bisimilarity, and we prove that there is no decomposition\noperator that maintains divergence-preserving branching bisimilarity over all\nLTSs.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 11:09:48 GMT"}, {"version": "v2", "created": "Mon, 12 Aug 2019 07:42:04 GMT"}, {"version": "v3", "created": "Fri, 23 Aug 2019 01:55:55 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Duhaiby", "Omar al", "", "Eindhoven University of Technology"], ["Groote", "Jan Friso", "", "Eindhoven University of Technology"]]}, {"id": "1905.13190", "submitter": "Sandra Kiefer", "authors": "Miko{\\l}aj Boja\\'nczyk, Sandra Kiefer, Nathan Lhote", "title": "String-to-String Interpretations with Polynomial-Size Output", "comments": "35 pages, full version of a paper accepted for the 46th International\n  Colloquium on Automata, Languages and Programming (ICALP 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  String-to-string MSO interpretations are like Courcelle's MSO transductions,\nexcept that a single output position can be represented using a tuple of input\npositions instead of just a single input position. In particular, the output\nlength is polynomial in the input length, as opposed to MSO transductions,\nwhich have output of linear length. We show that string-to-string MSO\ninterpretations are exactly the polyregular functions. The latter class has\nvarious characterizations, one of which is that it consists of the\nstring-to-string functions recognized by pebble transducers.\n  Our main result implies the surprising fact that string-to-string MSO\ninterpretations are closed under composition.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 17:21:26 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Boja\u0144czyk", "Miko\u0142aj", ""], ["Kiefer", "Sandra", ""], ["Lhote", "Nathan", ""]]}, {"id": "1905.13411", "submitter": "Markus N Rabe", "authors": "Markus N. Rabe, Leander Tentrup, Cameron Rasmussen, and Sanjit A.\n  Seshia", "title": "Understanding and Extending Incremental Determinization for 2QBF", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Incremental determinization is a recently proposed algorithm for solving\nquantified Boolean formulas with one quantifier alternation. In this paper, we\nformalize incremental determinization as a set of inference rules to help\nunderstand the design space of similar algorithms. We then present additional\ninference rules that extend incremental determinization in two ways. The first\nextension integrates the popular CEGAR principle and the second extension\nallows us to analyze different cases in isolation. The experimental evaluation\ndemonstrates that the extensions significantly improve the performance.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 04:35:07 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Rabe", "Markus N.", ""], ["Tentrup", "Leander", ""], ["Rasmussen", "Cameron", ""], ["Seshia", "Sanjit A.", ""]]}, {"id": "1905.13467", "submitter": "Lo\\\"ic Paulev\\'e", "authors": "Thomas Chatain, Stefan Haar, Juraj Kol\\v{c}\\'ak, Lo\\\"ic Paulev\\'e,\n  Aalok Thakkar", "title": "Concurrency in Boolean networks", "comments": "Accepted in Natural Computing, 2019", "journal-ref": null, "doi": "10.1007/s11047-019-09748-4", "report-no": null, "categories": "cs.LO cs.DM cs.FL q-bio.MN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Boolean networks (BNs) are widely used to model the qualitative dynamics of\nbiological systems. Besides the logical rules determining the evolution of each\ncomponent with respect to the state of its regulators, the scheduling of\ncomponent updates can have a dramatic impact on the predicted behaviours. In\nthis paper, we explore the use of Read (contextual) Petri Nets (RPNs) to study\ndynamics of BNs from a concurrency theory perspective. After showing\nbi-directional translations between RPNs and BNs and analogies between results\non synchronism sensitivity, we illustrate that usual updating modes for BNs can\nmiss plausible behaviours, i.e., incorrectly conclude on the\nabsence/impossibility of reaching specific configurations. We propose an\nencoding of BNs capitalizing on the RPN semantics enabling more behaviour than\nthe generalized asynchronous updating mode. The proposed encoding ensures a\ncorrect abstraction of any multivalued refinement, as one may expect to achieve\nwhen modelling biological systems with no assumption on its time features.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 09:01:08 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Chatain", "Thomas", ""], ["Haar", "Stefan", ""], ["Kol\u010d\u00e1k", "Juraj", ""], ["Paulev\u00e9", "Lo\u00efc", ""], ["Thakkar", "Aalok", ""]]}]