[{"id": "2101.00012", "submitter": "Nikolaos Kekatos", "authors": "Nikolaos Kekatos", "title": "Encoding sinusoidal functions in hybrid automata formalism", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Hybrid systems can express a plethora of physical phenomena and systems as\nthey can combine continuous and discrete dynamics. There exist several tools\nthat enable the reachability analysis of hybrid systems modeled as hybrid\nautomata. However, these tools exhibit certain limitations in the type of\nmathematical operations that they natively support. For example, SpaceEx, a\nwell-established tool in the hybrid verification community, supports the use of\nlinear ODEs in the flow of each discrete location. Mathematical functions like\nalgebraic equations or trigonometric functions have to be encoded as the\nsolutions of a set of ODEs. In this article, we provide a mechanism to define\nsinusoidal functions that are supported by SpaceEx. We also show how certain\nSimulink blocks can be translated into hybrid automata.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 18:55:44 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Kekatos", "Nikolaos", ""]]}, {"id": "2101.00942", "submitter": "Henning Urbat", "authors": "Jiri Adamek and Liang-Ting Chen and Stefan Milius and Henning Urbat", "title": "Reiterman's Theorem on Finite Algebras for a Monad", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CT cs.FL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Profinite equations are an indispensable tool for the algebraic\nclassification of formal languages. Reiterman's theorem states that they\nprecisely specify pseudovarieties, i.e.~classes of finite algebras closed under\nfinite products, subalgebras and quotients. In this paper, Reiterman's theorem\nis generalized to finite Eilenberg-Moore algebras for a monad T on a category\nD: we prove that a class of finite T-algebras is a pseudovariety iff it is\npresentable by profinite equations. As a key technical tool, we introduce the\nconcept of a profinite monad associated to the monad T, which gives a\ncategorical view of the construction of the space of profinite terms.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2021 13:17:59 GMT"}, {"version": "v2", "created": "Mon, 31 May 2021 13:15:32 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Adamek", "Jiri", ""], ["Chen", "Liang-Ting", ""], ["Milius", "Stefan", ""], ["Urbat", "Henning", ""]]}, {"id": "2101.01033", "submitter": "Lorenzo Clemente", "authors": "Corentin Barloy, Lorenzo Clemente", "title": "Bidimensional linear recursive sequences and universality of unambiguous\n  register automata", "comments": "full version of the homonymous paper to appear in the proceedings of\n  STACS'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the universality and inclusion problems for register automata over\nequality data. We show that the universality and the inclusion problems can be\nsolved with 2-EXPTIME complexity when the input automata are without guessing\nand unambiguous, improving on the currently best-known 2-EXPSPACE upper bound\nby Mottet and Quaas. When the number of registers of both automata is fixed, we\nobtain a lower EXPTIME complexity, also improving the EXPSPACE upper bound from\nMottet and Quaas for fixed number of registers. We reduce inclusion to\nuniversality, and then we reduce universality to the problem of counting the\nnumber of orbits of runs of the automaton. We show that the orbit-counting\nfunction satisfies a system of bidimensional linear recursive equations with\npolynomial coefficients (linrec), which generalises analogous recurrences for\nthe Stirling numbers of the second kind, and then we show that universality\nreduces to the zeroness problem for linrec sequences. While such a counting\napproach is classical and has successfully been applied to unambiguous finite\nautomata and grammars over finite alphabets, its application to register\nautomata over infinite alphabets is novel. We provide two algorithms to decide\nthe zeroness problem for bidimensional linear recursive sequences arising from\norbit-counting functions. Both algorithms rely on techniques from linear\nnon-commutative algebra. The first algorithm performs variable elimination and\nhas elementary complexity. The second algorithm is a refined version of the\nfirst one and it relies on the computation of the Hermite normal form of\nmatrices over a skew polynomial field. The second algorithm yields an EXPTIME\ndecision procedure for the zeroness problem of linrec sequences, which in turn\nyields the claimed bounds for the universality and inclusion problems of\nregister automata.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2021 15:33:35 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Barloy", "Corentin", ""], ["Clemente", "Lorenzo", ""]]}, {"id": "2101.01255", "submitter": "Nikolaos Kekatos", "authors": "Antonio Anastasio Bruto da Costa, Pallab Dasgupta, Nikolaos Kekatos", "title": "Quantitative Corner Case Feature Analysis of Hybrid Automata with\n  ForFET$^{SMT}$", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The analysis and verification of hybrid automata (HA) models against rich\nformal properties can be a challenging task. Existing methods and tools can\nmainly reason whether a given property is satisfied or violated. However, such\nqualitative answers might not provide sufficient information about the model\nbehaviors. This paper presents the ForFET$^{SMT}$ tool which can be used to\nreason quantitatively about such properties. It employs feature automata and\ncan evaluate quantitative property corners of HA. ForFET$^{SMT}$ uses two\nthird-party formal verification tools as its backbone: the SpaceEx reachability\ntool and the SMT solver dReach/dReal. Herein, we describe the design and\nimplementation of ForFET$^{SMT}$ and present its functionalities and modules.\nTo improve the usability of the tool for non-expert users, we also provide a\nlist of quantitative property templates.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2020 22:06:11 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["da Costa", "Antonio Anastasio Bruto", ""], ["Dasgupta", "Pallab", ""], ["Kekatos", "Nikolaos", ""]]}, {"id": "2101.01409", "submitter": "Arnaud Casteigts", "authors": "Arnaud Casteigts, Yves M\\'etivier, John Michael Robson", "title": "Revisiting the Role of Coverings in Anonymous Networks: Spanning Tree\n  Construction and Topology Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DM cs.FL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper revisits two classical distributed problems in anonymous networks,\nnamely spanning tree construction and topology recognition, from the point of\nview of graph covering theory. For both problems, we characterize necessary and\nsufficient conditions on the communication graph in terms of directed symmetric\ncoverings. These characterizations answer along-standing open question posed by\nYamashita and Kameda [YK96], and shed new light on the connection between\ncoverings and the concepts of views and quotient graphs developed by the same\nauthors. Characterizing conditions in terms of coverings is significant because\nit connects the field with a vast body of classical literature in graph theory\nand algebraic topology. In particular, it gives access to powerful tools such\nas Reidemeister's theorem and Mazurkiewicz's algorithm. Combined together,\nthese tools allow us to present elegant proofs of otherwise intricate results,\nand their constructive nature makes them effectively usable in the algorithms.\nThis paper also gives us the opportunity to present the field of covering\ntheory in a pedagogical way, with a focus on the two aforementioned tools,\nwhose potential impact goes beyond the specific problems considered in this\nwork.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2021 08:39:46 GMT"}, {"version": "v2", "created": "Sat, 23 Jan 2021 20:50:10 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Casteigts", "Arnaud", ""], ["M\u00e9tivier", "Yves", ""], ["Robson", "John Michael", ""]]}, {"id": "2101.01945", "submitter": "Markus Schmid", "authors": "Katrin Casel and Markus L. Schmid", "title": "Fine-Grained Complexity of Regular Path Queries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DB cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A regular path query (RPQ) is a regular expression q that returns all node\npairs (u, v) from a graph database that are connected by an arbitrary path\nlabelled with a word from L(q). The obvious algorithmic approach to\nRPQ-evaluation (called PG-approach), i.e., constructing the product graph\nbetween an NFA for q and the graph database, is appealing due to its simplicity\nand also leads to efficient algorithms. However, it is unclear whether the\nPG-approach is optimal. We address this question by thoroughly investigating\nwhich upper complexity bounds can be achieved by the PG-approach, and we\ncomplement these with conditional lower bounds (in the sense of the\nfine-grained complexity framework). A special focus is put on enumeration and\ndelay bounds, as well as the data complexity perspective. A main insight is\nthat we can achieve optimal (or near optimal) algorithms with the PG-approach,\nbut the delay for enumeration is rather high (linear in the database). We\nexplore three successful approaches towards enumeration with sub-linear delay:\nsuper-linear preprocessing, approximations of the solution sets, and restricted\nclasses of RPQs.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jan 2021 10:07:16 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Casel", "Katrin", ""], ["Schmid", "Markus L.", ""]]}, {"id": "2101.01968", "submitter": "Denis Kuperberg", "authors": "Denis Kuperberg", "title": "Positive first-order logic on words", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO math.LO", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We study FO+, a fragment of first-order logic on finite words, where monadic\npredicates can only appear positively. We show that there is a FO-definable\nlanguage that is monotone in monadic predicates but not definable in FO+. This\nprovides a simple proof that Lyndon's preservation theorem fails on finite\nstructures. We additionally show that given a regular language, it is\nundecidable whether it is definable in FO+.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jan 2021 11:08:06 GMT"}, {"version": "v2", "created": "Mon, 11 Jan 2021 16:49:29 GMT"}, {"version": "v3", "created": "Thu, 21 Jan 2021 14:14:57 GMT"}, {"version": "v4", "created": "Wed, 28 Apr 2021 15:44:33 GMT"}, {"version": "v5", "created": "Thu, 29 Apr 2021 10:27:55 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Kuperberg", "Denis", ""]]}, {"id": "2101.02310", "submitter": "Graham Campbell", "authors": "Graham Campbell", "title": "Parallel Hyperedge Replacement Grammars", "comments": "40 pages, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In 2018, it was shown that all finitely generated virtually Abelian groups\nhave multiple context-free word problems, and it is still an open problem as to\nwhere to precisely place the word problems of hyperbolic groups in the formal\nlanguage hierarchy. Motivated by this, we introduce a new language class, the\nparallel hyperedge replacement string languages, containing all multiple\ncontext-free and ET0L languages. We show that parallel hyperedge replacement\ngrammars can be \"synchronised\", which allows us to establish many useful formal\nlanguage closure results relating to both the hypergraph and string languages\ngenerated by various families of parallel hyperedge replacement grammars,\nlaying the foundations for future work in this area.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2021 00:24:35 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Campbell", "Graham", ""]]}, {"id": "2101.02577", "submitter": "Yuntao Liu", "authors": "Yuntao Liu, Michael Zuzak, Yang Xie, Abhishek Chakraborty, Ankur\n  Srivastava", "title": "Robust and Attack Resilient Logic Locking with a High Application-Level\n  Impact", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR cs.FL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Logic locking is a hardware security technique to intellectual property (IP)\nagainst security threats in the IC supply chain, especially untrusted fabs.\nSuch techniques incorporate additional locking circuitry within an IC that\ninduces incorrect functionality when an incorrect key is provided. The amount\nof error induced is known as the effectiveness of the locking technique. \"SAT\nattacks\" provide a strong mathematical formulation to find the correct key of\nlocked circuits. In order to achieve high SAT resilience(i.e. complexity of SAT\nattacks), many conventional logic locking schemes fail to inject sufficient\nerror into the circuit. For example, in the case of SARLock and Anti-SAT, there\nare usually very few (or only one) input minterms that cause any error at the\ncircuit output. The state-of-the-art stripped functionality logic locking\n(SFLL) technique introduced a trade-off between SAT resilience and\neffectiveness. In this work, we prove that such a trade-off is universal in\nlogic locking. In order to attain high effectiveness of locking without\ncompromising SAT resilience, we propose a novel logic locking scheme, called\nStrong Anti-SAT (SAS). In addition to SAT attacks, removal-based attacks are\nalso popular against logic locking. Based on SAS, we propose Robust SAS (RSAS)\nwhich is resilient to removal attacks and maintains the same SAT resilience and\nas effectiveness as SAS. SAS and RSAS have the following significant\nimprovements over existing techniques. (1) SAT resilience of SAS and RSAS\nagainst SAT attack is not compromised by increase in effectiveness. (2) In\ncontrast to prior work focusing solely on the circuit-level locking impact, we\nintegrate SAS-locked modules into a processor and show that SAS has a high\napplication-level impact. (3) Our experiments show that SAS and RSAS exhibit\nbetter SAT resilience than SFLL and have similar effectiveness.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2021 15:01:31 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Liu", "Yuntao", ""], ["Zuzak", "Michael", ""], ["Xie", "Yang", ""], ["Chakraborty", "Abhishek", ""], ["Srivastava", "Ankur", ""]]}, {"id": "2101.02594", "submitter": "Suguman Bansal", "authors": "Suguman Bansal, Krishnendu Chatterjee, Moshe Y. Vardi", "title": "On Satisficing in Quantitative Games", "comments": "arXiv admin note: text overlap with arXiv:2010.02055", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Several problems in planning and reactive synthesis can be reduced to the\nanalysis of two-player quantitative graph games. {\\em Optimization} is one form\nof analysis. We argue that in many cases it may be better to replace the\noptimization problem with the {\\em satisficing problem}, where instead of\nsearching for optimal solutions, the goal is to search for solutions that\nadhere to a given threshold bound.\n  This work defines and investigates the satisficing problem on a two-player\ngraph game with the discounted-sum cost model. We show that while the\nsatisficing problem can be solved using numerical methods just like the\noptimization problem, this approach does not render compelling benefits over\noptimization. When the discount factor is, however, an integer, we present\nanother approach to satisficing, which is purely based on automata methods. We\nshow that this approach is algorithmically more performant -- both\ntheoretically and empirically -- and demonstrates the broader applicability of\nsatisficing overoptimization.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jan 2021 07:47:13 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Bansal", "Suguman", ""], ["Chatterjee", "Krishnendu", ""], ["Vardi", "Moshe Y.", ""]]}, {"id": "2101.03039", "submitter": "Henning Urbat", "authors": "Robert Myers and Stefan Milius and Henning Urbat", "title": "Nondeterministic Syntactic Complexity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce a new measure on regular languages: their nondeterministic\nsyntactic complexity. It is the least degree of any extension of the `canonical\nboolean representation' of the syntactic monoid. Equivalently, it is the least\nnumber of states of any subatomic nondeterministic acceptor. It turns out that\nessentially all previous structural work on nondeterministic state-minimality\ncomputes this measure. Our approach rests on an algebraic interpretation of\nnondeterministic finite automata as deterministic finite automata endowed with\nsemilattice structure. Crucially, the latter form a self-dual category.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jan 2021 14:42:00 GMT"}, {"version": "v2", "created": "Mon, 11 Jan 2021 12:59:47 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Myers", "Robert", ""], ["Milius", "Stefan", ""], ["Urbat", "Henning", ""]]}, {"id": "2101.03866", "submitter": "Thomas Zeume", "authors": "Szymon Toru\\'nczyk, Thomas Zeume", "title": "Register Automata with Extrema Constraints, and an Application to\n  Two-Variable Logic", "comments": "The short version of this article appeared in the conference\n  proceedings of LICS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce a model of register automata over infinite trees with extrema\nconstraints. Such an automaton can store elements of a linearly ordered domain\nin its registers, and can compare those values to the suprema and infima of\nregister values in subtrees. We show that the emptiness problem for these\nautomata is decidable.\n  As an application, we prove decidability of the countable satisfiability\nproblem for two-variable logic in the presence of a tree order, a linear order,\nand arbitrary atoms that are MSO definable from the tree order. As a\nconsequence, the satisfiability problem for two-variable logic with arbitrary\npredicates, two of them interpreted by linear orders, is decidable.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jan 2021 13:26:48 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Toru\u0144czyk", "Szymon", ""], ["Zeume", "Thomas", ""]]}, {"id": "2101.04238", "submitter": "John Baez", "authors": "John C. Baez and Fabrizio Genovese and Jade Master and Michael Shulman", "title": "Categories of Nets", "comments": "29 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CT cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a unified framework for Petri nets and various variants, such as\npre-nets and Kock's whole-grain Petri nets. Our framework is based on a less\nwell-studied notion that we call $\\Sigma$-nets, which allow finer control over\nwhether tokens are treated using the collective or individual token philosophy.\nWe describe three forms of execution semantics in which pre-nets generate\nstrict monoidal categories, $\\Sigma$-nets (including whole-grain Petri nets)\ngenerate symmetric strict monoidal categories, and Petri nets generate\ncommutative monoidal categories, all by left adjoint functors. We also\nconstruct adjunctions relating these categories of nets to each other, in\nparticular showing that all kinds of net can be embedded in the unifying\ncategory of $\\Sigma$-nets, in a way that commutes coherently with their\nexecution semantics.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jan 2021 23:42:14 GMT"}, {"version": "v2", "created": "Mon, 26 Apr 2021 19:04:46 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Baez", "John C.", ""], ["Genovese", "Fabrizio", ""], ["Master", "Jade", ""], ["Shulman", "Michael", ""]]}, {"id": "2101.05057", "submitter": "Marek Szyku{\\l}a", "authors": "Mikhail V. Berlinkov, Robert Ferens, Andrew Ryzhikov, Marek Szyku{\\l}a", "title": "Synchronizing Strongly Connected Partial DFAs", "comments": "Full version of the paper at STACS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL math.CO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study synchronizing partial DFAs, which extend the classical concept of\nsynchronizing complete DFAs and are a special case of synchronizing unambiguous\nNFAs. A partial DFA is called synchronizing if it has a word (called a reset\nword) whose action brings a non-empty subset of states to a unique state and is\nundefined for all other states. While in the general case the problem of\nchecking whether a partial DFA is synchronizing is PSPACE-complete, we show\nthat in the strongly connected case this problem can be efficiently reduced to\nthe same problem for a complete DFA. Using combinatorial, algebraic, and formal\nlanguages methods, we develop techniques that relate main synchronization\nproblems for strongly connected partial DFAs with the same problems for\ncomplete DFAs. In particular, this includes the \\v{C}ern\\'{y} and the rank\nconjectures, the problem of finding a reset word, and upper bounds on the\nlength of the shortest reset words of literal automata of finite prefix codes.\nWe conclude that solving fundamental synchronization problems is equally hard\nin both models, as an essential improvement of the results for one model\nimplies an improvement for the other.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2021 13:43:54 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Berlinkov", "Mikhail V.", ""], ["Ferens", "Robert", ""], ["Ryzhikov", "Andrew", ""], ["Szyku\u0142a", "Marek", ""]]}, {"id": "2101.05415", "submitter": "EPTCS", "authors": "Tommaso Dreossi (Amazon Search), Giorgio Ballardin (Amazon Search),\n  Parth Gupta (Amazon Search), Jan Bakus (Amazon Search), Yu-Hsiang Lin (Amazon\n  Search), Vamsi Salaka (Amazon Search)", "title": "Analysis of E-commerce Ranking Signals via Signal Temporal Logic", "comments": "In Proceedings SNR 2020, arXiv:2101.05256", "journal-ref": "EPTCS 331, 2021, pp. 33-42", "doi": "10.4204/EPTCS.331.3", "report-no": null, "categories": "cs.LO cs.FL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The timed position of documents retrieved by learning to rank models can be\nseen as signals. Signals carry useful information such as drop or rise of\ndocuments over time or user behaviors. In this work, we propose to use the\nlogic formalism called Signal Temporal Logic (STL) to characterize document\nbehaviors in ranking accordingly to the specified formulas. Our analysis shows\nthat interesting document behaviors can be easily formalized and detected\nthanks to STL formulas. We validate our idea on a dataset of 100K product\nsignals. Through the presented framework, we uncover interesting patterns, such\nas cold start, warm start, spikes, and inspect how they affect our learning to\nranks models.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jan 2021 01:54:31 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Dreossi", "Tommaso", "", "Amazon Search"], ["Ballardin", "Giorgio", "", "Amazon Search"], ["Gupta", "Parth", "", "Amazon Search"], ["Bakus", "Jan", "", "Amazon Search"], ["Lin", "Yu-Hsiang", "", "Amazon\n  Search"], ["Salaka", "Vamsi", "", "Amazon Search"]]}, {"id": "2101.05895", "submitter": "Isma\\\"el Jecker", "authors": "Isma\\\"el Jecker", "title": "A Ramsey Theorem for Finite Monoids", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Repeated idempotent elements are commonly used to characterise iterable\nbehaviours in abstract models of computation. Therefore, given a monoid $M$, it\nis natural to ask how long a sequence of elements of $M$ needs to be to ensure\nthe presence of consecutive idempotent factors. This question is formalised\nthrough the notion of the Ramsey function $R_M$ associated to M, obtained by\nmapping every positive integer $k$ to the minimal integer $R_M(k)$ such that\nevery word $u$ in $M^*$ of length $R_M(k)$ contains $k$ consecutive non-empty\nfactors that correspond to the same idempotent element of $M$.\n  In this work, we study the behaviour of the Ramsey function $R_M$ by\ninvestigating the regular $D$-length of $M$, defined as the largest size $L(M)$\nof a submonoid of $M$ isomorphic to the set of natural numbers $\\{1,2, ...,\nL(M)\\}$ equipped with the Max operation. We show that the regular $D$-length of\n$M$ determines the degree of $R_M$, by proving that $k^{L(M)} \\leq R_M(k) \\leq\n(k|M|^4)^{L(M)}$.\n  To allow applications of this result, we provide the value of the regular\n$D$-length of diverse monoids. In particular, we prove that the full monoid of\n$n \\times n$ Boolean matrices, which is used to express transition monoids of\nnon-deterministic automata, has a regular $D$-length of $\\frac{n^2+n+2}{2}$.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jan 2021 22:34:24 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Jecker", "Isma\u00ebl", ""]]}, {"id": "2101.06104", "submitter": "Ru Yang", "authors": "Ru Yang, Zhijun Ding, Changjun Jiang and MengChu Zhou", "title": "Modeling and Analysis of Three Properties of Mobile Interactive Systems\n  Based on Variable Petri Nets", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.FL cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the mobility and frequent disconnections, the correctness of mobile\ninteraction systems, such as mobile robot systems and mobile payment systems,\nare often difficult to analyze. This paper introduces three critical properties\nof systems, called system connectivity, interaction soundness and data\nvalidity, and presents a related modeling and analysis method, based on a kind\nof Petri nets called VPN. For a given system, a model including component nets\nand interaction structure nets is constructed by using VPNs. The component net\ndescribes the internal process of each component, while the interaction\nstructure net reflects the dynamic interaction between components. Based on\nthis model, three properties are defined and analyzed. The case study of a\npractical mobile payment system shows the effectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jan 2021 13:39:57 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Yang", "Ru", ""], ["Ding", "Zhijun", ""], ["Jiang", "Changjun", ""], ["Zhou", "MengChu", ""]]}, {"id": "2101.06201", "submitter": "Artur Je\\.z", "authors": "Robert Ferens, Artur Je\\.z", "title": "Solving one variable word equations in the free group in cubic time", "comments": "52 pages, accepted to STACS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.GR cs.DM cs.DS cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A word equation with one variable in a free group is given as $U = V$, where\nboth $U$ and $V$ are words over the alphabet of generators of the free group\nand $X, X^{-1}$, for a fixed variable $X$. An element of the free group is a\nsolution when substituting it for $X$ yields a true equality (interpreted in\nthe free group) of left- and right-hand sides. It is known that the set of all\nsolutions of a given word equation with one variable is a finite union of sets\nof the form $\\{\\alpha w^i \\beta \\: : \\: i \\in \\mathbb Z \\}$, where $\\alpha, w,\n\\beta$ are reduced words over the alphabet of generators, and a polynomial-time\nalgorithm (of a high degree) computing this set is known. We provide a cubic\ntime algorithm for this problem, which also shows that the set of solutions\nconsists of at most a quadratic number of the above-mentioned sets. The\nalgorithm uses only simple tools of word combinatorics and group theory and is\nsimple to state. Its analysis is involved and focuses on the combinatorics of\noccurrences of powers of a word within a larger word.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jan 2021 16:33:03 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Ferens", "Robert", ""], ["Je\u017c", "Artur", ""]]}, {"id": "2101.06234", "submitter": "Fosco Loregian G.", "authors": "Fabrizio Romano Genovese, Fosco Loregian, Daniele Palombi", "title": "Nets with Mana: A Framework for Chemical Reaction Modelling", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CT cs.FL q-bio.MN", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We use categorical methods to define a new flavor of Petri nets where\ntransitions can only fire a limited number of times, specified by a quantity\nthat we call mana. We do so with chemistry in mind, looking at ways of\nmodelling the behavior of chemical reactions that depend on enzymes to work. We\nprove that such nets can be either obtained as a result of a comonadic\nconstruction, or by enriching them with extra information encoded into a\nfunctor. We then use a well-established categorical result to prove that the\ntwo constructions are equivalent, and generalize them to the case where the\nfiring of some transitions can \"regenerate\" the mana of others. This allows us\nto represent the action of catalysts and also of biochemical processes where\nthe byproducts of some chemical reaction are exactly the enzymes that another\nreaction needs to work.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jan 2021 17:42:21 GMT"}, {"version": "v2", "created": "Thu, 22 Apr 2021 09:25:30 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Genovese", "Fabrizio Romano", ""], ["Loregian", "Fosco", ""], ["Palombi", "Daniele", ""]]}, {"id": "2101.06490", "submitter": "Hunter Johnson", "authors": "Hunter R Johnson", "title": "Binary strings of finite VC dimension", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.AI cs.FL math.CO", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Any binary string can be associated with a unary predicate $P$ on\n$\\mathbb{N}$. In this paper we investigate subsets named by a predicate $P$\nsuch that the relation $P(x+y)$ has finite VC dimension. This provides a\nmeasure of complexity for binary strings with different properties than the\nstandard string complexity function (based on diversity of substrings). We\nprove that strings of bounded VC dimension are meagre in the topology of the\nreals, provide simple rules for bounding the VC dimension of a string, and show\nthat the bi-infinite strings of VC dimension $d$ are a non-sofic shift space.\nAdditionally we characterize the irreducible strings of low VC dimension (0,1\nand 2), and provide connections to mathematical logic.\n", "versions": [{"version": "v1", "created": "Sat, 16 Jan 2021 17:51:52 GMT"}, {"version": "v2", "created": "Sun, 24 Jan 2021 14:00:22 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Johnson", "Hunter R", ""]]}, {"id": "2101.07038", "submitter": "L\\'eo Exibard", "authors": "L\\'eo Exibard, Emmanuel Filiot, Nathan Lhote and Pierre-Alain Reynier", "title": "Computability of Data-Word Transductions over Different Data Domains", "comments": "Extended version of arxiv:2002.08203", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we investigate the problem of synthesizing computable\nfunctions of infinite words over an infinite alphabet (data $\\omega$-words).\nThe notion of computability is defined through Turing machines with infinite\ninputs which can produce the corresponding infinite outputs in the limit. We\nuse non-deterministic transducers equipped with registers, an extension of\nregister automata with outputs, to describe specifications. Being\nnon-deterministic, such transducers may not define functions but more generally\nrelations of data $\\omega$-words. In order to increase the expressive power of\nthese machines, we even allow guessing of arbitrary data values when updating\ntheir registers.\n  For functions over data $\\omega$-words, we identify a sufficient condition\n(the possibility of determining the next letter to be outputted, which we call\nnext letter problem) under which computability (resp. uniform computability)\nand continuity (resp. uniform continuity) coincide.\n  We focus on two kinds of data domains: first, the general setting of\noligomorphic data, which encompasses any data domain with equality, as well as\nthe setting of rational numbers with linear order; and second, the set of\nnatural numbers equipped with linear order. For both settings, we prove that\nfunctionality, i.e. determining whether the relation recognized by the\ntransducer is actually a function, is decidable. We also show that the\nso-called next letter problem is decidable, yielding equivalence between\n(uniform) continuity and (uniform) computability. Last, we provide\ncharacterizations of (uniform) continuity, which allow us to prove that these\nnotions, and thus also (uniform) computability, are decidable. We even show\nthat all these decision problems are PSpace-complete for (N,<) and for a large\nclass of oligomorphic data domains, including for instance (Q,<).\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2021 12:23:29 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Exibard", "L\u00e9o", ""], ["Filiot", "Emmanuel", ""], ["Lhote", "Nathan", ""], ["Reynier", "Pierre-Alain", ""]]}, {"id": "2101.07053", "submitter": "Iman Saberi", "authors": "Iman Saberi, Fathiyeh Faghih, Farzad Sobhi Bavil", "title": "A Passive Online Technique for Learning Hybrid Automata from\n  Input/Output Traces", "comments": "10 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Specification synthesis is the process of deriving a model from the\ninput-output traces of a system. It is used extensively in test design, reverse\nengineering, and system identification. One type of the resulting artifact of\nthis process for cyber-physical systems is hybrid automata. They are intuitive,\nprecise, tool independent, and at a high level of abstraction, and can model\nsystems with both discrete and continuous variables. In this paper, we propose\na new technique for synthesizing hybrid automaton from the input-output traces\nof a non-linear cyber-physical system. Similarity detection in non-linear\nbehaviors is the main challenge for extracting such models. We address this\nproblem by utilizing the Dynamic Time Warping technique. Our approach is\npassive, meaning that it does not need interaction with the system during\nautomata synthesis from the logged traces; and online, which means that each\ninput/output trace is used only once in the procedure. In other words, each new\ntrace can be used to improve the already synthesized automaton. We evaluated\nour algorithm in two industrial and simulated case studies. The accuracy of the\nderived automata show promising results.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2021 13:08:14 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Saberi", "Iman", ""], ["Faghih", "Fathiyeh", ""], ["Bavil", "Farzad Sobhi", ""]]}, {"id": "2101.07130", "submitter": "Luc Dartois", "authors": "Luc Dartois, Paul Gastin, Shankara Narayanan Krishna", "title": "SD-Regular Transducer Expressions for Aperiodic Transformations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  FO transductions, aperiodic deterministic two-way transducers, as well as\naperiodic streaming string transducers are all equivalent models for first\norder definable functions. In this paper, we solve the long standing open\nproblem of expressions capturing first order definable functions, thereby\ngeneralizing the seminal SF=AP (star free expressions = aperiodic languages)\nresult of Sch\\\"utzenberger. Our result also generalizes a lesser known\ncharacterization by Sch\\\"utzenberger of aperiodic languages by SD-regular\nexpressions (SD=AP). We show that every first order definable function over\nfinite words captured by an aperiodic deterministic two-way transducer can be\ndescribed with an SD-regular transducer expression (SDRTE). An SDRTE is a\nregular expression where Kleene stars are used in a restricted way: they can\nappear only on aperiodic languages which are prefix codes of bounded\nsynchronization delay. SDRTEs are constructed from simple functions using the\ncombinators unambiguous sum (deterministic choice), Hadamard product, and\nunambiguous versions of the Cauchy product and the k-chained Kleene-star, where\nthe star is restricted as mentioned. In order to construct an SDRTE associated\nwith an aperiodic deterministic two-way transducer, (i) we concretize\nSch\\\"utzenberger's SD=AP result, by proving that aperiodic languages are\ncaptured by SD-regular expressions which are unambiguous and stabilising; (ii)\nby structural induction on the unambiguous, stabilising SD-regular expressions\ndescribing the domain of the transducer, we construct SDRTEs. Finally, we also\nlook at various formalisms equivalent to SDRTEs which use the function\ncomposition, allowing to trade the k-chained star for a 1-star.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2021 15:45:55 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Dartois", "Luc", ""], ["Gastin", "Paul", ""], ["Krishna", "Shankara Narayanan", ""]]}, {"id": "2101.07174", "submitter": "Mohamed Wagdy Eldesouki Abdelghany", "authors": "Mohamed Abdelghany and Sofiene Tahar", "title": "Formal FT-based Cause-Consequence Reliability Analysis using Theorem\n  Proving", "comments": "41 pages, 17 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cause-consequence Diagram (CCD) is widely used as a deductive safety analysis\ntechnique for decision-making at the critical-system design stage. This\napproach models the causes of subsystem failures in a highly-critical system\nand their potential consequences using Fault Tree (FT) and Event Tree (ET)\nmethods, which are well-known dependability modeling techniques.\nPaper-and-pencil-based approaches and simulation tools, such as the Monte-Carlo\napproach, are commonly used to carry out CCD analysis, but lack the ability to\nrigorously verify essential system reliability properties. In this work, we\npropose to use formal techniques based on theorem proving for the formal\nmodeling and step-analysis of CCDs to overcome the inaccuracies of the\nsimulation-based analysis and the error-proneness of informal reasoning by\nmathematical proofs. In particular, we use the HOL4 theorem prover, which is a\ncomputer-based mathematical reasoning tool. To this end, we developed a\nformalization of CCDs in Higher-Order Logic (HOL), based on the algebraic\napproach, using HOL4. We demonstrate the practical effectiveness of the\nproposed CCD formalization by performing the formal reliability analysis of the\nIEEE 39-bus electrical power network. Also, we formally determine the Forced\nOutage Rate (FOR) of the power generation units and the network reliability\nindex, i.e., System Average Interruption Duration Index (SAIDI). To assess the\naccuracy of our proposed approach, we compare our results with those obtained\nwith MATLAB Monte-Carlo Simulation (MCS) as well as other state-of-the-art\napproaches for subsystem-level reliability analysis.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2021 17:23:34 GMT"}], "update_date": "2021-01-21", "authors_parsed": [["Abdelghany", "Mohamed", ""], ["Tahar", "Sofiene", ""]]}, {"id": "2101.07202", "submitter": "Christoph Weinhuber", "authors": "Pranav Ashok, Mathias Jackermeier, Jan K\\v{r}et\\'insk\\'y, Christoph\n  Weinhuber, Maximilian Weininger, Mayank Yadav", "title": "dtControl 2.0: Explainable Strategy Representation via Decision Tree\n  Learning Steered by Experts", "comments": null, "journal-ref": "TACAS (2) (pp. 326-345). Springer. 2021", "doi": "10.1007/978-3-030-72013-1_17", "report-no": null, "categories": "cs.AI cs.FL cs.LG cs.LO cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent advances have shown how decision trees are apt data structures for\nconcisely representing strategies (or controllers) satisfying various\nobjectives. Moreover, they also make the strategy more explainable. The recent\ntool dtControl had provided pipelines with tools supporting strategy synthesis\nfor hybrid systems, such as SCOTS and Uppaal Stratego. We present dtControl\n2.0, a new version with several fundamentally novel features. Most importantly,\nthe user can now provide domain knowledge to be exploited in the decision tree\nlearning process and can also interactively steer the process based on the\ndynamically provided information. To this end, we also provide a graphical user\ninterface. It allows for inspection and re-computation of parts of the result,\nsuggesting as well as receiving advice on predicates, and visual simulation of\nthe decision-making process. Besides, we interface model checkers of\nprobabilistic systems, namely Storm and PRISM and provide dedicated support for\ncategorical enumeration-type state variables. Consequently, the controllers are\nmore explainable and smaller.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jan 2021 11:22:49 GMT"}, {"version": "v2", "created": "Tue, 4 May 2021 10:10:43 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Ashok", "Pranav", ""], ["Jackermeier", "Mathias", ""], ["K\u0159et\u00ednsk\u00fd", "Jan", ""], ["Weinhuber", "Christoph", ""], ["Weininger", "Maximilian", ""], ["Yadav", "Mayank", ""]]}, {"id": "2101.07495", "submitter": "Nathan Grosshans", "authors": "Nathan Grosshans, Pierre Mckenzie (DIRO), Luc Segoufin (VALDA, DI-ENS)", "title": "Tameness and the power of programs over monoids in DA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DM cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The program-over-monoid model of computation originates with Barrington's\nproof that it captures the complexity class NC$^1$. Here we make progress in\nunderstanding the subtleties of the model. First, we identify a new tameness\ncondition on a class of monoids that entails a natural characterization of the\nregular languages recognizable by programs over monoids from the class. Second,\nwe prove that the class known as DA satisfies tameness and hence that the\nregular languages recognized by programs over monoids in DA are precisely those\nrecognizable in the classical sense by morphisms from QDA. Third, we show by\ncontrast that the well studied class of monoids called J is not tame. Finally,\nwe exhibit a program-length-based hierarchy within the class of languages\nrecognized by programs over monoids from DA.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jan 2021 07:41:31 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Grosshans", "Nathan", "", "DIRO"], ["Mckenzie", "Pierre", "", "DIRO"], ["Segoufin", "Luc", "", "VALDA, DI-ENS"]]}, {"id": "2101.08011", "submitter": "Anca Muscholl", "authors": "Sougata Bose, S.N. Krishna, Anca Muscholl, Gabriele Puppis", "title": "One-way resynchronizability of word transducers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The origin semantics for transducers was proposed in 2014, and led to various\ncharacterizations and decidability results that are in contrast with the\nclassical semantics. In this paper we add a further decidability result for\ncharacterizing transducers that are close to one-way transducers in the origin\nsemantics. We show that it is decidable whether a non-deterministic two-way\nword transducer can be resynchronized by a bounded, regular resynchronizer into\nan origin-equivalent one-way transducer. The result is in contrast with the\nusual semantics, where it is undecidable to know if a non-deterministic two-way\ntransducer is equivalent to some one-way transducer.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jan 2021 07:59:46 GMT"}], "update_date": "2021-01-21", "authors_parsed": [["Bose", "Sougata", ""], ["Krishna", "S. N.", ""], ["Muscholl", "Anca", ""], ["Puppis", "Gabriele", ""]]}, {"id": "2101.08200", "submitter": "Gail Weiss", "authors": "Daniel M. Yellin, Gail Weiss", "title": "Synthesizing Context-free Grammars from Recurrent Neural Networks\n  (Extended Version)", "comments": "Extended version of paper to appear in TACAS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an algorithm for extracting a subclass of the context free\ngrammars (CFGs) from a trained recurrent neural network (RNN). We develop a new\nframework, pattern rule sets (PRSs), which describe sequences of deterministic\nfinite automata (DFAs) that approximate a non-regular language. We present an\nalgorithm for recovering the PRS behind a sequence of such automata, and apply\nit to the sequences of automata extracted from trained RNNs using the L*\nalgorithm. We then show how the PRS may converted into a CFG, enabling a\nfamiliar and useful presentation of the learned language.\n  Extracting the learned language of an RNN is important to facilitate\nunderstanding of the RNN and to verify its correctness. Furthermore, the\nextracted CFG can augment the RNN in classifying correct sentences, as the\nRNN's predictive accuracy decreases when the recursion depth and distance\nbetween matching delimiters of its input sequences increases.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jan 2021 16:22:25 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2021 21:28:28 GMT"}, {"version": "v3", "created": "Sun, 28 Mar 2021 21:11:32 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Yellin", "Daniel M.", ""], ["Weiss", "Gail", ""]]}, {"id": "2101.08611", "submitter": "Ramanathan Srinivasan Thinniyam", "authors": "Rupak Majumdar, Ramanathan S. Thinniyam, Georg Zetzsche", "title": "General Decidability Results for Asynchronous Shared-Memory Programs:\n  Higher-Order and Beyond", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The model of asynchronous programming arises in many contexts, from low-level\nsystems software to high-level web programming. We take a language-theoretic\nperspective and show general decidability and undecidability results for\nasynchronous programs that capture all known results as well as show\ndecidability of new and important classes. As a main consequence, we show\ndecidability of safety, termination and boundedness verification for\nhigher-order asynchronous programs -- such as OCaml programs using Lwt -- and\nundecidability of liveness verification already for order-2 asynchronous\nprograms. We show that under mild assumptions, surprisingly, safety and\ntermination verification of asynchronous programs with handlers from a language\nclass are decidable iff emptiness is decidable for the underlying language\nclass. Moreover, we show that configuration reachability and liveness (fair\ntermination) verification are equivalent, and decidability of these problems\nimplies decidability of the well-known \"equal-letters\" problem on languages.\nOur results close the decidability frontier for asynchronous programs.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2021 13:57:22 GMT"}], "update_date": "2021-01-22", "authors_parsed": [["Majumdar", "Rupak", ""], ["Thinniyam", "Ramanathan S.", ""], ["Zetzsche", "Georg", ""]]}, {"id": "2101.08720", "submitter": "Alex Dixon", "authors": "Alex Dixon, Ranko Lazi\\'c, Andrzej S. Murawski and Igor Walukiewicz", "title": "Leafy Automata for Higher-Order Concurrency", "comments": "18 pages plus appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Finitary Idealized Concurrent Algol (FICA) is a prototypical programming\nlanguage combining functional, imperative, and concurrent computation. There\nexists a fully abstract game model of FICA, which in principle can be used to\nprove equivalence and safety of FICA programs. Unfortunately, the problems are\nundecidable for the whole language, and only very rudimentary decidable\nsub-languages are known. We propose leafy automata as a dedicated\nautomata-theoretic formalism for representing the game semantics of FICA. The\nautomata use an infinite alphabet with a tree structure. We show that the game\nsemantics of any FICA term can be represented by traces of a leafy automaton.\nConversely, the traces of any leafy automaton can be represented by a FICA\nterm. Because of the close match with FICA, we view leafy automata as a\npromising starting point for finding decidable subclasses of the language and,\nmore generally, to provide a new perspective on models of higher-order\nconcurrent computation. Moreover, we identify a fragment of FICA that is\namenable to verification by translation into a particular class of leafy\nautomata. Using a locality property of the latter class, where communication\nbetween levels is restricted and every other level is bounded, we show that\ntheir emptiness problem is decidable by reduction to Petri net reachability.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2021 17:00:50 GMT"}], "update_date": "2021-01-22", "authors_parsed": [["Dixon", "Alex", ""], ["Lazi\u0107", "Ranko", ""], ["Murawski", "Andrzej S.", ""], ["Walukiewicz", "Igor", ""]]}, {"id": "2101.08756", "submitter": "Salomon Sickert", "authors": "Orna Kupferman and Salomon Sickert", "title": "Certifying Inexpressibility", "comments": "This is the full version of an article with the same title that\n  appears in the FoSSaCS 2021 conference proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Different classes of automata on infinite words have different expressive\npower. Deciding whether a given language $L \\subseteq \\Sigma^\\omega$ can be\nexpressed by an automaton of a desired class can be reduced to deciding a game\nbetween Prover and Refuter: in each turn of the game, Refuter provides a letter\nin $\\Sigma$, and Prover responds with an annotation of the current state of the\nrun (for example, in the case of B\\\"uchi automata, whether the state is\naccepting or rejecting, and in the case of parity automata, what the color of\nthe state is). Prover wins if the sequence of annotations she generates is\ncorrect: it is an accepting run iff the word generated by Refuter is in $L$. We\nshow how a winning strategy for Refuter can serve as a simple and\neasy-to-understand certificate to inexpressibility, and how it induces\nadditional forms of certificates. Our framework handles all classes of\ndeterministic automata, including ones with structural restrictions like weak\nautomata. In addition, it can be used for refuting separation of two languages\nby an automaton of the desired class, and for finding automata that approximate\n$L$ and belong to the desired class.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2021 18:14:16 GMT"}, {"version": "v2", "created": "Fri, 19 Feb 2021 10:24:19 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Kupferman", "Orna", ""], ["Sickert", "Salomon", ""]]}, {"id": "2101.09100", "submitter": "Fosco Loregian G.", "authors": "Fabrizio Genovese, Fosco Loregian, Daniele Palombi", "title": "A Categorical Semantics for Bounded Petri Nets", "comments": "15 pages, gluten free. arXiv admin note: text overlap with\n  arXiv:2101.06234", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CT cs.FL cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We provide a categorical semantics for bounded Petri nets, both in the\ncollective- and individual-token philosophy. In both cases, we describe the\nprocess of bounding a net internally, by just constructing new categories of\nexecutions of a net using comonads, and externally, using lax-monoidal-lax\nfunctors. Our external semantics is non-local, meaning that tokens are endowed\nwith properties that say something about the global state of the net. We then\nprove, in both cases, that the internal and external constructions are\nequivalent, by using machinery built on top of the Grothendieck construction.\nThe individual-token case is harder, as it requires a more explicit reliance on\nabstract methods.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jan 2021 13:35:05 GMT"}, {"version": "v2", "created": "Mon, 25 Jan 2021 10:30:55 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Genovese", "Fabrizio", ""], ["Loregian", "Fosco", ""], ["Palombi", "Daniele", ""]]}, {"id": "2101.10284", "submitter": "Mingyu Cai", "authors": "Mingyu Cai, Shaoping Xiao, and Zhen Kan", "title": "Reinforcement Learning Based Temporal Logic Control with Soft\n  Constraints Using Limit-deterministic Generalized Buchi Automata", "comments": "arXiv admin note: text overlap with arXiv:2010.06797,\n  arXiv:2007.14325", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the control synthesis of motion planning subject to\nuncertainties. The uncertainties are considered in robot motion and environment\nproperties, giving rise to the probabilistic labeled Markov decision process\n(MDP). A model-free reinforcement learning (RL) is developed to generate a\nfinite-memory control policy to satisfy high-level tasks expressed in linear\ntemporal logic (LTL) formulas. One of the novelties is to translate LTL into a\nlimit deterministic generalized B\\\"uchi automaton (LDGBA) and develop a\ncorresponding embedded LDGBA (E-LDGBA) by incorporating a tracking-frontier\nfunction to overcome the issue of sparse accepting rewards, resulting in\nimproved learning performance without increasing computational complexity. Due\nto potentially conflicting tasks, a relaxed product MDP is developed to allow\nthe agent to revise its motion plan without strictly following the desired LTL\nconstraints if the desired tasks can only be partially fulfilled. An expected\nreturn composed of violation rewards and accepting rewards is developed. The\ndesigned violation function quantifies the differences between the revised and\nthe desired motion planning, while the accepting rewards are designed to\nenforce the satisfaction of the acceptance condition of the relaxed product\nMDP. Rigorous analysis shows that any RL algorithm that optimizes the expected\nreturn is guaranteed to find policies that, in decreasing order, can 1) satisfy\nacceptance condition of relaxed product MDP and 2) reduce the violation cost\nover long-term behaviors. Also, we validate the control synthesis approach via\nsimulation and experimental results.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2021 18:09:11 GMT"}, {"version": "v2", "created": "Sun, 31 Jan 2021 18:16:45 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Cai", "Mingyu", ""], ["Xiao", "Shaoping", ""], ["Kan", "Zhen", ""]]}, {"id": "2101.10890", "submitter": "Markus Schmid", "authors": "Markus L. Schmid and Nicole Schweikardt", "title": "Spanner Evaluation over SLP-Compressed Documents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of evaluating regular spanners over compressed\ndocuments, i.e., we wish to solve evaluation tasks directly on the compressed\ndata, without decompression. As compressed forms of the documents we use\nstraight-line programs (SLPs) -- a lossless compression scheme for textual data\nwidely used in different areas of theoretical computer science and particularly\nwell-suited for algorithmics on compressed data. In terms of data complexity,\nour results are as follows. For a regular spanner M and an SLP S that\nrepresents a document D, we can solve the tasks of model checking and of\nchecking non-emptiness in time O(size(S)). Computing the set M(D) of all\nspan-tuples extracted from D can be done in time O(size(S) size(M(D))), and\nenumeration of M(D) can be done with linear preprocessing O(size(S)) and a\ndelay of O(depth(S)), where depth(S) is the depth of S's derivation tree. Note\nthat size(S) can be exponentially smaller than the document's size |D|; and,\ndue to known balancing results for SLPs, we can always assume that depth(S) =\nO(log(|D|)) independent of D's compressibility. Hence, our enumeration\nalgorithm has a delay logarithmic in the size of the non-compressed data and a\npreprocessing time that is at best (i.e., in the case of highly compressible\ndocuments) also logarithmic, but at worst still linear. Therefore, in a\nbig-data perspective, our enumeration algorithm for SLP-compressed documents\nmay nevertheless beat the known linear preprocessing and constant delay\nalgorithms for non-compressed documents.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2021 18:37:35 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Schmid", "Markus L.", ""], ["Schweikardt", "Nicole", ""]]}, {"id": "2101.11196", "submitter": "Ingy ElSayed-Aly", "authors": "Ingy Elsayed-Aly, Suda Bharadwaj, Christopher Amato, R\\\"udiger Ehlers,\n  Ufuk Topcu, Lu Feng", "title": "Safe Multi-Agent Reinforcement Learning via Shielding", "comments": "8 pages, 11 figures and 2 tables, to be published in AAMAS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-agent reinforcement learning (MARL) has been increasingly used in a\nwide range of safety-critical applications, which require guaranteed safety\n(e.g., no unsafe states are ever visited) during the learning\nprocess.Unfortunately, current MARL methods do not have safety guarantees.\nTherefore, we present two shielding approaches for safe MARL. In centralized\nshielding, we synthesize a single shield to monitor all agents' joint actions\nand correct any unsafe action if necessary. In factored shielding, we\nsynthesize multiple shields based on a factorization of the joint state space\nobserved by all agents; the set of shields monitors agents concurrently and\neach shield is only responsible for a subset of agents at each\nstep.Experimental results show that both approaches can guarantee the safety of\nagents during learning without compromising the quality of learned policies;\nmoreover, factored shielding is more scalable in the number of agents than\ncentralized shielding.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2021 04:27:06 GMT"}, {"version": "v2", "created": "Tue, 2 Feb 2021 18:30:53 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Elsayed-Aly", "Ingy", ""], ["Bharadwaj", "Suda", ""], ["Amato", "Christopher", ""], ["Ehlers", "R\u00fcdiger", ""], ["Topcu", "Ufuk", ""], ["Feng", "Lu", ""]]}, {"id": "2101.11303", "submitter": "Alessio Ferrari", "authors": "Alessio Ferrari, Franco Mazzanti, Davide Basile, Maurice H. ter Beek", "title": "Systematic Evaluation and Usability Analysis of Formal Tools for Railway\n  System Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Formal methods and supporting tools have a long record of success in the\ndevelopment of safety-critical systems. However, no single tool has emerged as\nthe dominant solution for system design. Each tool differs from the others in\nterms of the modeling language used, its verification capabilities and other\ncomplementary features, and each development context has peculiar needs that\nrequire different tools. This is particularly problematic for the railway\nindustry, in which formal methods are highly recommended by the norms, but no\nactual guidance is provided for the selection of tools. To guide companies in\nthe selection of the most appropriate formal tools to adopt in their contexts,\na clear assessment of the features of the currently available tools is\nrequired.\n  To address this goal, this paper considers a set of 13 formal tools that have\nbeen used for railway system design, and it presents a systematic evaluation of\nsuch tools and a preliminary usability analysis of a subset of 7 tools,\ninvolving railway practitioners. The results are discussed considering the most\ndesired aspects by industry and earlier related studies. While the focus is on\nthe railway domain, the overall methodology can be applied to similar contexts.\nOur study thus contributes with a systematic evaluation of formal tools and it\nshows that despite the poor graphical interfaces, usability and maturity of the\ntools are not major problems, as claimed by contributions from the literature.\nInstead, support for process integration is the most relevant obstacle for the\nadoption of most of the tools.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2021 10:23:48 GMT"}, {"version": "v2", "created": "Thu, 13 May 2021 08:38:47 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Ferrari", "Alessio", ""], ["Mazzanti", "Franco", ""], ["Basile", "Davide", ""], ["ter Beek", "Maurice H.", ""]]}, {"id": "2101.11379", "submitter": "Ru Yang", "authors": "Zhijun Ding, Ru Yang, Puwen Cui, MengChu Zhou and Changjun Jiang", "title": "Variable Petri Nets for Mobility", "comments": "13 pages, submitted to IEEE Transactions on Systems, Man, and\n  Cybernetics: Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.FL cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile computing systems, service-based systems and some other systems with\nmobile interacting components have recently received much attention. However,\nbecause of their characteristics such as mobility and disconnection, it is\ndifficult to model and analyze them by using a structure-fixed model. This work\nproposes a new Petri net model called Variable Petri Net (VPN) for modeling and\nanalyzing these systems. The definition, firing rule, and related analysis\ntechnology of VPN are introduced in detail. In a VPN, the possible interaction\ninterfaces are abstracted as a new kind of places called virtual places, and\nthe occurrences of (dis)connections are described by new functions, which makes\nit appropriate to describe the component collaboration in systems and realize\nthe scalability and pluggability of systems. Moreover, to overcome the\nshortcoming that markings cannot reflect link capability of a system, VPNs add\na constraint function along with a marking to represent a complete system\nconfiguration. Several examples are used to demonstrate the newly proposed\nmodel and method.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jan 2021 13:21:22 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Ding", "Zhijun", ""], ["Yang", "Ru", ""], ["Cui", "Puwen", ""], ["Zhou", "MengChu", ""], ["Jiang", "Changjun", ""]]}, {"id": "2101.11727", "submitter": "Cristina Feier", "authors": "Cristina Feier", "title": "Characterising Fixed Parameter Tractability of Query Evaluation over\n  Guarded TGDs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.CC cs.DB cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the parameterized complexity of evaluating Ontology Mediated Queries\n(OMQs) based on Guarded TGDs (GTGDs) and Unions of Conjunctive Queries (UCQs),\nin the case where relational symbols have unrestricted arity and where the\nparameter is the size of the OMQ. We establish exact criteria for\nfixed-parameter tractability (fpt) evaluation of recursively enumerable classes\nof such OMQs (under the widely held Exponential Time Hypothesis). One of the\nmain technical tools introduced in the paper is an fpt-reduction from deciding\nparameterized uniform CSPs to parameterized OMQ evaluation. The reduction\npreserves measures which are known to be essential for classifying recursively\nenumerable classes of parameterized uniform CSPs: submodular width (according\nto the well known result of Marx for unrestricted-arity schemas) and treewidth\n(according to the well known result of Grohe for bounded-arity schemas). As\nsuch, it can be employed to obtain hardness results for evaluation of\nrecursively enumerable classes of parameterized OMQs both in the unrestricted\nand in the bounded arity case. Previously, in the case of bounded arity\nschemas, this has been tackled using a technique requiring full introspection\ninto the construction employed by Grohe.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2021 22:32:16 GMT"}, {"version": "v2", "created": "Wed, 23 Jun 2021 14:08:08 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Feier", "Cristina", ""]]}, {"id": "2101.11996", "submitter": "Guillermo P\\'erez", "authors": "Michael Blondin, Tim Leys, Filip Mazowiecki, Philip Offtermatt, and\n  Guillermo A. P\\'erez", "title": "Continuous One-Counter Automata", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the reachability problem for continuous one-counter automata, COCA\nfor short. In such automata, transitions are guarded by upper and lower bound\ntests against the counter value. Additionally, the counter updates associated\nwith taking transitions can be (non-deterministically) scaled down by a nonzero\nfactor between zero and one. Our three main results are as follows: (1) We\nprove that the reachability problem for COCA with global upper and lower bound\ntests is in NC2; (2) that, in general, the problem is decidable in polynomial\ntime; and (3) that it is decidable in the polynomial hierarchy for COCA with\nparametric counter updates and bound tests.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jan 2021 13:45:56 GMT"}, {"version": "v2", "created": "Wed, 3 Feb 2021 07:36:55 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Blondin", "Michael", ""], ["Leys", "Tim", ""], ["Mazowiecki", "Filip", ""], ["Offtermatt", "Philip", ""], ["P\u00e9rez", "Guillermo A.", ""]]}]