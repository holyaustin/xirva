[{"id": "1803.02651", "submitter": "Fredrik Dahlqvist", "authors": "Fredrik Dahlqvist, Vincent Danos, Ilias Garnier and Alexandra Silva", "title": "Borel Kernels and their Approximation, Categorically", "comments": "17 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a categorical framework to study the exact and\napproximate semantics of probabilistic programs. We construct a dagger\nsymmetric monoidal category of Borel kernels where the dagger-structure is\ngiven by Bayesian inversion. We show functorial bridges between this category\nand categories of Banach lattices which formalize the move from kernel-based\nsemantics to predicate transformer (backward) or state transformer (forward)\nsemantics. These bridges are related by natural transformations, and we show in\nparticular that the Radon-Nikodym and Riesz representation theorems - two\npillars of probability theory - define natural transformations.\n  With the mathematical infrastructure in place, we present a generic and\nendogenous approach to approximating kernels on standard Borel spaces which\nexploits the involutive structure of our category of kernels. The approximation\ncan be formulated in several equivalent ways by using the functorial bridges\nand natural transformations described above. Finally, we show that for sensible\ndiscretization schemes, every Borel kernel can be approximated by kernels on\nfinite spaces, and that these approximations converge for a natural choice of\ntopology.\n  We illustrate the theory by showing two examples of how approximation can\neffectively be used in practice: Bayesian inference and the Kleene star\noperation of ProbNetKAT.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2018 13:51:01 GMT"}, {"version": "v2", "created": "Thu, 8 Mar 2018 12:07:16 GMT"}], "update_date": "2018-03-09", "authors_parsed": [["Dahlqvist", "Fredrik", ""], ["Danos", "Vincent", ""], ["Garnier", "Ilias", ""], ["Silva", "Alexandra", ""]]}, {"id": "1803.02975", "submitter": "Chuchu Fan", "authors": "Chuchu Fan, Yu Meng, J\\\"urgen Maier, Ezio Bartocci, Sayan Mitra,\n  Ulrich Schmid", "title": "Verifying nonlinear analog and mixed-signal circuits with inputs", "comments": "8 pages, 8 figures, a shorter version will appear on the IFAC\n  Conference on Analysis and Design of Hybrid Systems (ADHS 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new technique for verifying nonlinear and hybrid models with\ninputs. We observe that once an input signal is fixed, the sensitivity analysis\nof the model can be computed much more precisely. Based on this result, we\npropose a new simulation-driven verification algorithm and apply it to a suite\nof nonlinear and hybrid models of CMOS digital circuits under different input\nsignals. The models are low-dimensional but with highly nonlinear ODEs, with\nnearly hundreds of logarithmic and exponential terms. Some of our experiments\nanalyze the metastability of bistable circuits with very sensitive ODEs and\nrigorously establish the connection between metastability recovery time and\nsensitivity.\n", "versions": [{"version": "v1", "created": "Thu, 8 Mar 2018 05:50:09 GMT"}], "update_date": "2018-03-09", "authors_parsed": [["Fan", "Chuchu", ""], ["Meng", "Yu", ""], ["Maier", "J\u00fcrgen", ""], ["Bartocci", "Ezio", ""], ["Mitra", "Sayan", ""], ["Schmid", "Ulrich", ""]]}, {"id": "1803.03158", "submitter": "Joerg Endrullis", "authors": "J\\\"org Endrullis, Juhani Karhum\\\"aki Jan Willem Klop, Aleksi Saarela", "title": "Degrees of Infinite Words, Polynomials, and Atoms (Extended Version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study finite-state transducers and their power for transforming infinite\nwords. Infinite sequences of symbols are of paramount importance in a wide\nrange of fields, from formal languages to pure mathematics and physics. While\nfinite automata for recognising and transforming languages are well-understood,\nvery little is known about the power of automata to transform infinite words.\n  The word transformation realised by finite-state transducers gives rise to a\ncomplexity comparison of words and thereby induces equivalence classes, called\n(transducer) degrees, and a partial order on these degrees. The ensuing\nhierarchy of degrees is analogous to the recursion-theoretic degrees of\nunsolvability, also known as Turing degrees, where the transformational devices\nare Turing machines. However, as a complexity measure, Turing machines are too\nstrong: they trivialise the classification problem by identifying all\ncomputable words. Finite-state transducers give rise to a much more\nfine-grained, discriminating hierarchy. In contrast to Turing degrees, hardly\nanything is known about transducer degrees, in spite of their naturality.\n  We use methods from linear algebra and analysis to show that there are\ninfinitely many atoms in the transducer degrees, that is, minimal non-trivial\ndegrees.\n", "versions": [{"version": "v1", "created": "Thu, 8 Mar 2018 15:33:40 GMT"}], "update_date": "2018-03-09", "authors_parsed": [["Endrullis", "J\u00f6rg", ""], ["Klop", "Juhani Karhum\u00e4ki Jan Willem", ""], ["Saarela", "Aleksi", ""]]}, {"id": "1803.04312", "submitter": "Stefan Gerdjikov", "authors": "Stefan Gerdjikov, Stoyan Mihov, Klaus U. Schulz", "title": "Space-Efficient Bimachine Construction Based on the Equalizer\n  Accumulation Principle", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithms for building bimachines from functional transducers found in the\nliterature in a run of the bimachine imitate one successful path of the input\ntransducer. Each single bimachine output exactly corresponds to the output of a\nsingle transducer transition. Here we introduce an alternative construction\nprinciple where bimachine steps take alternative parallel transducer paths into\naccount, maximizing the possible output at each step using a joint view. The\nsize of both the deterministic left and right automaton of the bimachine is\nrestricted by $2^{\\vert Q\\vert}$ where $\\vert Q\\vert$ is the number of\ntransducer states. Other bimachine constructions lead to larger subautomata. As\na concrete example we present a class of real-time functional transducers with\n$n+2$ states for which the standard bimachine construction generates a\nbimachine with at least $\\Theta(n!)$ states whereas the construction based on\nthe equalizer accumulation principle leads to $2^n + n +3$ states. Our\nconstruction can be applied to rational functions from free monoids to \"mge\nmonoids\", a large class of monoids including free monoids, groups, and others\nthat is closed under Cartesian products.\n", "versions": [{"version": "v1", "created": "Tue, 27 Feb 2018 16:57:31 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Gerdjikov", "Stefan", ""], ["Mihov", "Stoyan", ""], ["Schulz", "Klaus U.", ""]]}, {"id": "1803.05277", "submitter": "Domagoj Vrgo\\v{c}", "authors": "Fernando Florenzano, Cristian Riveros, Martin Ugarte, Stijn\n  Vansummeren, Domagoj Vrgoc", "title": "Constant delay algorithms for regular document spanners", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regular expressions and automata models with capture variables are core tools\nin rule-based information extraction. These formalisms, also called regular\ndocument spanners, use regular languages in order to locate the data that a\nuser wants to extract from a text document, and then store this data into\nvariables. Since document spanners can easily generate large outputs, it is\nimportant to have good evaluation algorithms that can generate the extracted\ndata in a quick succession, and with relatively little precomputation time.\nTowards this goal, we present a practical evaluation algorithm that allows\nconstant delay enumeration of a spanner's output after a precomputation phase\nthat is linear in the document. While the algorithm assumes that the spanner is\nspecified in a syntactic variant of variable set automata, we also study how it\ncan be applied when the spanner is specified by general variable set automata,\nregex formulas, or spanner algebras. Finally, we study the related problem of\ncounting the number of outputs of a document spanner, providing a fine grained\nanalysis of the classes of document spanners that support efficient enumeration\nof their results.\n", "versions": [{"version": "v1", "created": "Wed, 14 Mar 2018 13:44:53 GMT"}], "update_date": "2018-03-15", "authors_parsed": [["Florenzano", "Fernando", ""], ["Riveros", "Cristian", ""], ["Ugarte", "Martin", ""], ["Vansummeren", "Stijn", ""], ["Vrgoc", "Domagoj", ""]]}, {"id": "1803.06140", "submitter": "Christopher Spinrath", "authors": "Christof L\\\"oding (1) and Christopher Spinrath (2) ((1) RWTH Aachen\n  University, (2) TU Dortmund University)", "title": "Decision Problems for Subclasses of Rational Relations over Finite and\n  Infinite Words", "comments": "v1: 31 pages, submitted to DMTCS, extended version of the paper with\n  the same title published in the conference proceedings of FCT 2017; v2: 32\n  pages, minor revision of v1 (DMTCS review process), results unchanged; v3: 32\n  pages, enabled hyperref for Figure 1; v4: 32 pages, add reference for known\n  complexity results for the slenderness problem; v5: 32 pages, added DMTCS\n  metadata", "journal-ref": "Discrete Mathematics & Theoretical Computer Science, Vol. 21 no. 3\n  , Automata, Logic and Semantics (January 31, 2019) dmtcs:5141", "doi": "10.23638/DMTCS-21-3-4", "report-no": null, "categories": "cs.FL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider decision problems for relations over finite and infinite words\ndefined by finite automata. We prove that the equivalence problem for binary\ndeterministic rational relations over infinite words is undecidable in contrast\nto the case of finite words, where the problem is decidable. Furthermore, we\nshow that it is decidable in doubly exponential time for an automatic relation\nover infinite words whether it is a recognizable relation. We also revisit this\nproblem in the context of finite words and improve the complexity of the\ndecision procedure to single exponential time. The procedure is based on a\npolynomial time regularity test for deterministic visibly pushdown automata,\nwhich is a result of independent interest.\n", "versions": [{"version": "v1", "created": "Fri, 16 Mar 2018 10:05:29 GMT"}, {"version": "v2", "created": "Thu, 13 Dec 2018 16:54:01 GMT"}, {"version": "v3", "created": "Fri, 14 Dec 2018 18:52:20 GMT"}, {"version": "v4", "created": "Thu, 10 Jan 2019 16:30:13 GMT"}, {"version": "v5", "created": "Tue, 29 Jan 2019 10:18:41 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["L\u00f6ding", "Christof", ""], ["Spinrath", "Christopher", ""]]}, {"id": "1803.06163", "submitter": "Micha{\\l} Skrzypczak", "authors": "Micha{\\l} Skrzypczak", "title": "Unambiguous languages exhaust the index hierarchy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work is a study of the expressive power of unambiguity in the case of\nautomata over infinite trees. An automaton is called unambiguous if it has at\nmost one accepting run on every input, the language of such an automaton is\ncalled an unambiguous language. It is known that not every regular language of\ninfinite trees is unambiguous. Except that, very little is known about which\nregular tree languages are unambiguous.\n  This paper answers the question whether unambiguous languages are of bounded\ncomplexity among all regular tree languages. The notion of complexity is the\ncanonical one, called the (parity or Rabin-Mostowski) index hierarchy. The\nanswer is negative, as exhibited by a family of examples of unambiguous\nlanguages that cannot be recognised by any alternating parity tree automata of\nbounded range of priorities.\n  Hardness of the given examples is based on the theory of signatures in parity\ngames, previously studied by Walukiewicz. This theory is further developed here\nto construct canonical signatures. The technical core of the article is a\nparity game that compares signatures of a given pair of parity games (without\nan increase in the index).\n", "versions": [{"version": "v1", "created": "Fri, 16 Mar 2018 11:08:07 GMT"}, {"version": "v2", "created": "Tue, 17 Apr 2018 11:43:00 GMT"}, {"version": "v3", "created": "Wed, 18 Apr 2018 22:05:29 GMT"}, {"version": "v4", "created": "Fri, 20 Apr 2018 07:24:22 GMT"}], "update_date": "2018-04-23", "authors_parsed": [["Skrzypczak", "Micha\u0142", ""]]}, {"id": "1803.06168", "submitter": "Laure Daviaud", "authors": "Mikolaj Bojanczyk, Laure Daviaud and Krishna Shankara Narayanan", "title": "Regular and First Order List Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define two classes of functions, called regular (respectively,\nfirst-order) list functions, which manipulate objects such as lists, lists of\nlists, pairs of lists, lists of pairs of lists, etc. The definition is in the\nstyle of regular expressions: the functions are constructed by starting with\nsome basic functions (e.g. projections from pairs, or head and tail operations\non lists) and putting them together using four combinators (most importantly,\ncomposition of functions). Our main results are that first-order list functions\nare exactly the same as first-order transductions, under a suitable encoding of\nthe inputs; and the regular list functions are exactly the same as\nMSO-transductions.\n", "versions": [{"version": "v1", "created": "Fri, 16 Mar 2018 11:25:25 GMT"}], "update_date": "2018-03-19", "authors_parsed": [["Bojanczyk", "Mikolaj", ""], ["Daviaud", "Laure", ""], ["Narayanan", "Krishna Shankara", ""]]}, {"id": "1803.08034", "submitter": "Tara Brough", "authors": "Tara Brough", "title": "Word Problem Languages for Free Inverse Monoids", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.GR cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the word problem for free inverse monoids of finite rank\nfrom a language theory perspective. It is shown that no free inverse monoid has\ncontext-free word problem; that the word problem of the free inverse monoid of\nrank $1$ is both $2$-context-free (an intersection of two context-free\nlanguages) and ET0L; that the co-word problem of the free inverse monoid of\nrank $1$ is context-free; and that the word problem of a free inverse monoid of\nrank greater than $1$ is not poly-context-free.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 17:51:26 GMT"}], "update_date": "2018-03-22", "authors_parsed": [["Brough", "Tara", ""]]}, {"id": "1803.08145", "submitter": "Lucas Mol", "authors": "James D. Currie, Lucas Mol, Narad Rampersad", "title": "Circular repetition thresholds on some small alphabets: Last cases of\n  Gorbunova's conjecture", "comments": "27 pages (including a 6 page appendix). As promised in an earlier\n  version, we have added a proof that the strong circular repetition threshold\n  for five letters is 4/3, completing the last case of Gorbunova's conjecture", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A word is called $\\beta$-free if it has no factors of exponent greater than\nor equal to $\\beta$. The repetition threshold $\\mathrm{RT}(k)$ is the infimum\nof the set of all $\\beta$ such that there are arbitrarily long $k$-ary\n$\\beta$-free words (or equivalently, there are $k$-ary $\\beta$-free words of\nevery sufficiently large length, or even every length). These three equivalent\ndefinitions of the repetition threshold give rise to three natural definitions\nof a repetition threshold for circular words. The infimum of the set of all\n$\\beta$ such that\n  - there are arbitrarily long $k$-ary $\\beta$-free circular words is called\nthe weak circular repetition threshold, denoted $\\mathrm{CRT}_{\\mathrm{W}}(k)$;\n  - there are $k$-ary $\\beta$-free circular words of every sufficiently large\nlength is called the intermediate circular repetition threshold, denoted\n$\\mathrm{CRT}_{\\mathrm{I}}(k)$;\n  - there are $k$-ary $\\beta$-free circular words of every length is called the\nstrong circular repetition threshold, denoted $\\mathrm{CRT}_{\\mathrm{S}}(k)$.\n  We prove that $\\mathrm{CRT}_{\\mathrm{S}}(4)=\\tfrac{3}{2}$ and\n$\\mathrm{CRT}_{\\mathrm{S}}(5)=\\tfrac{4}{3}$, confirming a conjecture of\nGorbunova and providing the last unknown values of the strong circular\nrepetition threshold. We also prove that\n$\\mathrm{CRT}_{\\mathrm{I}}(3)=\\mathrm{CRT}_{\\mathrm{W}}(3)=\\mathrm{RT}(3)=\\tfrac{7}{4}$.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 21:43:53 GMT"}, {"version": "v2", "created": "Tue, 29 May 2018 14:36:29 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Currie", "James D.", ""], ["Mol", "Lucas", ""], ["Rampersad", "Narad", ""]]}, {"id": "1803.08668", "submitter": "EPTCS", "authors": "John P. Gallagher, Rob van Glabbeek, Wendelin Serwe", "title": "Proceedings Third Workshop on Models for Formal Analysis of Real Systems\n  and Sixth International Workshop on Verification and Program Transformation", "comments": null, "journal-ref": "EPTCS 268, 2018", "doi": "10.4204/EPTCS.268", "report-no": null, "categories": "cs.LO cs.FL cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the joint proceedings of MARS 2018, the third workshop\non Models for Formal Analysis of Real Systems, and VPT 2018, the sixth\ninternational workshop on Verification and Program Transformation, held\ntogether on April 20, 2018 in Thessaloniki, Greece, as part of ETAPS 2018, the\nEuropean Joint Conferences on Theory and Practice of Software.\n  MARS emphasises modelling over verification. It aims at discussing the\nlessons learned from making formal methods for the verification and analysis of\nrealistic systems. Examples are:\n  (1) Which formalism is chosen, and why?\n  (2) Which abstractions have to be made and why?\n  (3) How are important characteristics of the system modelled?\n  (4) Were there any complications while modelling the system?\n  (5) Which measures were taken to guarantee the accuracy of the model?\n  We invited papers that present full models of real systems, which may lay the\nbasis for future comparison and analysis. An aim of the workshop is to present\ndifferent modelling approaches and discuss pros and cons for each of them.\nAlternative formal descriptions of the systems presented at this workshop are\nencouraged, which should foster the development of improved specification\nformalisms.\n  VPT aims to provide a forum where people from the areas of program\ntransformation and program verification can fruitfully exchange ideas and gain\na deeper understanding of the interactions between those two fields. These\ninteractions have been beneficial in both directions. On the one hand, methods\nand tools developed in the field of program transformation, such as partial\ndeduction, partial evaluation, fold/unfold transformations, and\nsupercompilation, are applied with success to verification, in particular to\nthe verification of infinite state and parameterized systems. On the other\nhand, methods developed in program verification, such as model checking,\nabstract interpretation, SAT and SMT solving, and automated theorem proving,\nare used to enhance program transformation techniques, thereby making these\ntechniques more powerful and useful in practice.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 06:30:11 GMT"}], "update_date": "2018-03-26", "authors_parsed": [["Gallagher", "John P.", ""], ["van Glabbeek", "Rob", ""], ["Serwe", "Wendelin", ""]]}, {"id": "1803.08890", "submitter": "Hazem Torfah", "authors": "Bernd Finkbeiner and Hazem Torfah", "title": "The Density of Linear-time Properties", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding models for linear-time properties is a central problem in\nverification and planning. We study the distribution of linear-time models by\ninvestigating the density of linear-time properties over the space of\nultimately periodic words. The density of a property over a bound n is the\nratio of the number of lasso-shaped words of length n that satisfy the property\nto the total number of lasso-shaped words of length n. We investigate the\nproblem of computing the density for both linear-time properties in general and\nfor the important special case of omega-regular properties. For general\nlinear-time properties, the density is not necessarily convergent and can\noscillate indefinitely for certain properties. However, we show the oscillation\ncan be bounded by the growth of the sets of bad- and good-prefix of the\nproperty. For omega-regular properties, we show that the density is always\nconvergent and provide a general algorithm for computing the density of\nomega-regular properties as well as more specialized algorithms for certain\nsub-classes and their combinations.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 17:09:23 GMT"}], "update_date": "2018-03-26", "authors_parsed": [["Finkbeiner", "Bernd", ""], ["Torfah", "Hazem", ""]]}, {"id": "1803.08966", "submitter": "Mahsa Ghasemi", "authors": "Lu Feng, Mahsa Ghasemi, Kai-Wei Chang, Ufuk Topcu", "title": "Counterexamples for Robotic Planning Explained in Structured Language", "comments": "Accepted for publication in International Conference on Robotics and\n  Automation (ICRA) Proceedings, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CL cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated techniques such as model checking have been used to verify models\nof robotic mission plans based on Markov decision processes (MDPs) and generate\ncounterexamples that may help diagnose requirement violations. However, such\nartifacts may be too complex for humans to understand, because existing\nrepresentations of counterexamples typically include a large number of paths or\na complex automaton. To help improve the interpretability of counterexamples,\nwe define a notion of explainable counterexample, which includes a set of\nstructured natural language sentences to describe the robotic behavior that\nlead to a requirement violation in an MDP model of robotic mission plan. We\npropose an approach based on mixed-integer linear programming for generating\nexplainable counterexamples that are minimal, sound and complete. We\ndemonstrate the usefulness of the proposed approach via a case study of\nwarehouse robots planning.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 20:14:51 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Feng", "Lu", ""], ["Ghasemi", "Mahsa", ""], ["Chang", "Kai-Wei", ""], ["Topcu", "Ufuk", ""]]}, {"id": "1803.09285", "submitter": "Hazem Torfah", "authors": "Bernd Finkbeiner and Hazem Torfah", "title": "Synthesizing Skeletons for Reactive Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an analysis technique for temporal specifications of reactive\nsystems that identifies, on the level of individual system outputs over time,\nwhich parts of the implementation are determined by the specification, and\nwhich parts are still open. This information is represented in the form of a\nlabeled transition system, which we call skeleton. Each state of the skeleton\nis labeled with a three-valued assignment to the output variables: each output\ncan be true, false, or open, where true or false means that the value must be\ntrue or false, respectively, and open means that either value is still\npossible. We present algorithms for the verification of skeletons and for the\nlearning-based synthesis of skeletons from specifications in linear-time\ntemporal logic (LTL). The algorithm returns a skeleton that satisfies the given\nLTL specification in time polynomial in the size of the minimal skeleton. Our\nnew analysis technique can be used to recognize and repair specifications that\nunderspecify critical situations. The technique thus complements existing\nmethods for the recognition and repair of overspecifications via the\nidentification of unrealizable cores.\n", "versions": [{"version": "v1", "created": "Sun, 25 Mar 2018 16:02:28 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Finkbeiner", "Bernd", ""], ["Torfah", "Hazem", ""]]}, {"id": "1803.09703", "submitter": "Sebastian Muskalla", "authors": "Roland Meyer, Sebastian Muskalla, Georg Zetzsche", "title": "Bounded Context Switching for Valence Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study valence systems, finite-control programs over infinite-state\nmemories modeled in terms of graph monoids. Our contribution is a notion of\nbounded context switching (BCS). Valence systems generalize pushdowns,\nconcurrent pushdowns, and Petri nets. In these settings, our definition\nconservatively generalizes existing notions. The main finding is that\nreachability within a bounded number of context switches is in NP, independent\nof the memory (the graph monoid). Our proof is genuinely algebraic, and\ntherefore contributes a new way to think about BCS. In addition, we exhibit a\nclass of storage mechanisms for which BCS reachability belongs to P.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 16:33:16 GMT"}, {"version": "v2", "created": "Wed, 25 Apr 2018 16:28:49 GMT"}, {"version": "v3", "created": "Fri, 27 Apr 2018 00:22:52 GMT"}, {"version": "v4", "created": "Thu, 5 Jul 2018 11:51:14 GMT"}], "update_date": "2018-07-06", "authors_parsed": [["Meyer", "Roland", ""], ["Muskalla", "Sebastian", ""], ["Zetzsche", "Georg", ""]]}, {"id": "1803.09991", "submitter": "Matthieu Picantin", "authors": "Laurent Bartholdi and Thibault Godin and Ines Klimann and Matthieu\n  Picantin", "title": "A new hierarchy for automaton semigroups", "comments": "12 pages, accepted and presented at CIAA 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL math.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define a new strict and computable hierarchy for the family of automaton\nsemigroups, which reflects the various asymptotic behaviors of the\nstate-activity growth. This hierarchy extends that given by Sidki for automaton\ngroups, and also gives new insights into the latter. Its exponential part\ncoincides with a notion of entropy for some associated automata.\n  We prove that the Order Problem is decidable when the state-activity is\nbounded. The Order Problem remains open for the next level of this hierarchy,\nthat is, when the state-activity is linear. Gillibert showed that it is\nundecidable in the whole family.\n  The former results are implemented and will be available in the GAP package\nFR developed by the first author.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 09:52:19 GMT"}, {"version": "v2", "created": "Sun, 13 May 2018 21:11:09 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Bartholdi", "Laurent", ""], ["Godin", "Thibault", ""], ["Klimann", "Ines", ""], ["Picantin", "Matthieu", ""]]}, {"id": "1803.10324", "submitter": "EPTCS", "authors": "Franco Mazzanti (ISTI-CNR), Alessio Ferrari (ISTI-CNR)", "title": "Ten Diverse Formal Models for a CBTC Automatic Train Supervision System", "comments": "In Proceedings MARS/VPT 2018, arXiv:1803.08668", "journal-ref": "EPTCS 268, 2018, pp. 104-149", "doi": "10.4204/EPTCS.268.4", "report-no": null, "categories": "cs.SE cs.FL cs.LO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Communications-based Train Control (CBTC) systems are metro signalling\nplatforms, which coordinate and protect the movements of trains within the\ntracks of a station, and between different stations. In CBTC platforms, a\nprominent role is played by the Automatic Train Supervision (ATS) system, which\nautomatically dispatches and routes trains within the metro network. Among the\nvarious functions, an ATS needs to avoid deadlock situations, i.e., cases in\nwhich a group of trains block each other. In the context of a technology\ntransfer study, we designed an algorithm for deadlock avoidance in train\nscheduling. In this paper, we present a case study in which the algorithm has\nbeen applied. The case study has been encoded using ten different formal\nverification environments, namely UMC, SPIN, NuSMV/nuXmv, mCRL2, CPN Tools,\nFDR4, CADP, TLA+, UPPAAL and ProB. Based on our experience, we observe\ncommonalities and differences among the modelling languages considered, and we\nhighlight the impact of the specific characteristics of each language on the\npresented models.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 20:59:25 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Mazzanti", "Franco", "", "ISTI-CNR"], ["Ferrari", "Alessio", "", "ISTI-CNR"]]}, {"id": "1803.10327", "submitter": "EPTCS", "authors": "Robert Gl\\\"uck (DIKU, Dept. of Computer Science, University of\n  Copenhagen)", "title": "An Experiment in Ping-Pong Protocol Verification by Nondeterministic\n  Pushdown Automata", "comments": "In Proceedings MARS/VPT 2018, arXiv:1803.08668", "journal-ref": "EPTCS 268, 2018, pp. 169-184", "doi": "10.4204/EPTCS.268.6", "report-no": null, "categories": "cs.PL cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An experiment is described that confirms the security of a well-studied class\nof cryptographic protocols (Dolev-Yao intruder model) can be verified by\ntwo-way nondeterministic pushdown automata (2NPDA). A nondeterministic pushdown\nprogram checks whether the intersection of a regular language (the protocol to\nverify) and a given Dyck language containing all canceling words is empty. If\nit is not, an intruder can reveal secret messages sent between trusted users.\nThe verification is guaranteed to terminate in cubic time at most on a\n2NPDA-simulator. The interpretive approach used in this experiment simplifies\nthe verification, by separating the nondeterministic pushdown logic and program\ncontrol, and makes it more predictable. We describe the interpretive approach\nand the known transformational solutions, and show they share interesting\nfeatures. Also noteworthy is how abstract results from automata theory can\nsolve practical problems by programming language means.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 21:00:27 GMT"}], "update_date": "2018-04-02", "authors_parsed": [["Gl\u00fcck", "Robert", "", "DIKU, Dept. of Computer Science, University of\n  Copenhagen"]]}, {"id": "1803.11034", "submitter": "Tom\\'a\\v{s} Masopust", "authors": "Liyong Lin, Tom\\'a\\v{s} Masopust, W. Murray Wonham, Rong Su", "title": "Automatic Generation of Optimal Reductions of Distributions", "comments": "Accepted for publication in IEEE Transactions on Automatic Control", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.FL math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A reduction of a source distribution is a collection of smaller sized\ndistributions that are collectively equivalent to the source distribution with\nrespect to the property of decomposability. That is, an arbitrary language is\ndecomposable with respect to the source distribution if and only if it is\ndecomposable with respect to each smaller sized distribution (in the\nreduction). The notion of reduction of distributions has previously been\nproposed to improve the complexity of decomposability verification. In this\nwork, we address the problem of generating (optimal) reductions of\ndistributions automatically. A (partial) solution to this problem is provided,\nwhich consists of 1) an incremental algorithm for the production of candidate\nreductions and 2) a reduction validation procedure. In the incremental\nproduction stage, backtracking is applied whenever a candidate reduction that\ncannot be validated is produced. A strengthened substitution-based proof\ntechnique is used for reduction validation, while a fixed template of candidate\ncounter examples is used for reduction refutation; put together, they\nconstitute our (partial) solution to the reduction verification problem. In\naddition, we show that a recursive approach for the generation of (small)\nreductions is easily supported.\n", "versions": [{"version": "v1", "created": "Thu, 29 Mar 2018 12:49:58 GMT"}], "update_date": "2018-03-30", "authors_parsed": [["Lin", "Liyong", ""], ["Masopust", "Tom\u00e1\u0161", ""], ["Wonham", "W. Murray", ""], ["Su", "Rong", ""]]}]