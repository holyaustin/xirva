[{"id": "1210.0408", "submitter": "Arpit Sharma", "authors": "Arpit Sharma", "title": "A Two Step Perspective for Kripke Structure Reduction", "comments": "Accepted for Student Research Forum, 39th International Conference on\n  Current Trends in Theory and Practice of Computer Science (SOFSEM 2013)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel theoretical framework for the state space\nreduction of Kripke structures. We define two equivalence relations, Kripke\nminimization equivalence (KME) and weak Kripke minimization equivalence (WKME).\nWe define the quotient system under these relations and show that these\nrelations are strictly coarser than strong (bi)simulation and\ndivergence-sensitive stutter (bi)simulation, respectively. We prove that the\nquotient system obtained under KME and WKME preserves linear-time and\nstutter-insensitive linear-time properties. Finally, we show that KME is\ncompositional w.r.t. synchronous parallel composition.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2012 14:06:21 GMT"}], "update_date": "2012-10-02", "authors_parsed": [["Sharma", "Arpit", ""]]}, {"id": "1210.1097", "submitter": "EPTCS", "authors": "Yun Shang, Xian Lu, Ruqian Lu", "title": "Turing machines based on unsharp quantum logic", "comments": "In Proceedings QPL 2011, arXiv:1210.0298", "journal-ref": "EPTCS 95, 2012, pp. 251-261", "doi": "10.4204/EPTCS.95.17", "report-no": null, "categories": "cs.LO cs.FL quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider Turing machines based on unsharp quantum logic.\nFor a lattice-ordered quantum multiple-valued (MV) algebra E, we introduce\nE-valued non-deterministic Turing machines (ENTMs) and E-valued deterministic\nTuring machines (EDTMs). We discuss different E-valued recursively enumerable\nlanguages from width-first and depth-first recognition. We find that\nwidth-first recognition is equal to or less than depth-first recognition in\ngeneral. The equivalence requires an underlying E value lattice to degenerate\ninto an MV algebra. We also study variants of ENTMs. ENTMs with a classical\ninitial state and ENTMs with a classical final state have the same power as\nENTMs with quantum initial and final states. In particular, the latter can be\nsimulated by ENTMs with classical transitions under a certain condition. Using\nthese findings, we prove that ENTMs are not equivalent to EDTMs and that ENTMs\nare more powerful than EDTMs. This is a notable difference from the classical\nTuring machines.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2012 00:35:50 GMT"}], "update_date": "2012-10-04", "authors_parsed": [["Shang", "Yun", ""], ["Lu", "Xian", ""], ["Lu", "Ruqian", ""]]}, {"id": "1210.2273", "submitter": "Stefan Kiefer", "authors": "Vojtech Forejt and Petr Jancar and Stefan Kiefer and James Worrell", "title": "Bisimilarity of Probabilistic Pushdown Automata", "comments": "technical report accompanying an FSTTCS'12 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the bisimilarity problem for probabilistic pushdown automata (pPDA)\nand subclasses thereof. Our definition of pPDA allows both probabilistic and\nnon-deterministic branching, generalising the classical notion of pushdown\nautomata (without epsilon-transitions). Our first contribution is a general\nconstruction that reduces checking bisimilarity of probabilistic transition\nsystems to checking bisimilarity of non-deterministic transition systems. This\nconstruction directly yields decidability of bisimilarity for pPDA, as well as\nan elementary upper bound for the bisimilarity problem on the subclass of\nprobabilistic basic process algebras, i.e., single-state pPDA. We further show\nthat, with careful analysis, the general reduction can be used to prove an\nEXPTIME upper bound for bisimilarity of probabilistic visibly pushdown\nautomata. Here we also provide a matching lower bound, establishing\nEXPTIME-completeness. Finally we prove that deciding bisimilarity of\nprobabilistic one-counter automata, another subclass of pPDA, is\nPSPACE-complete. Here we use a more specialised argument to obtain optimal\ncomplexity bounds.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2012 13:37:12 GMT"}], "update_date": "2012-10-09", "authors_parsed": [["Forejt", "Vojtech", ""], ["Jancar", "Petr", ""], ["Kiefer", "Stefan", ""], ["Worrell", "James", ""]]}, {"id": "1210.2343", "submitter": "Luke Schaeffer", "authors": "Luke Schaeffer", "title": "Ostrowski Numeration and the Local Period of Sturmian Words", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the local period at position n in a characteristic Sturmian word\ncan be given in terms of the Ostrowski representation for n + 1.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2012 17:11:42 GMT"}], "update_date": "2012-10-09", "authors_parsed": [["Schaeffer", "Luke", ""]]}, {"id": "1210.2448", "submitter": "EPTCS", "authors": "Marta Capiluppi (Universit\\`a di Verona), Roberto Segala (Universit\\`a\n  di Verona)", "title": "Modelling Implicit Communication in Multi-Agent Systems with Hybrid\n  Input/Output Automata", "comments": "In Proceedings GandALF 2012, arXiv:1210.2028", "journal-ref": "EPTCS 96, 2012, pp. 1-14", "doi": "10.4204/EPTCS.96.1", "report-no": null, "categories": "cs.FL cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an extension of Hybrid I/O Automata (HIOAs) to model agent systems\nand their implicit communication through perturbation of the environment, like\nlocalization of objects or radio signals diffusion and detection. To this end\nwe decided to specialize some variables of the HIOAs whose values are functions\nboth of time and space. We call them world variables. Basically they are\ntreated similarly to the other variables of HIOAs, but they have the function\nof representing the interaction of each automaton with the surrounding\nenvironment, hence they can be output, input or internal variables. Since these\nspecial variables have the role of simulating implicit communication, their\ndynamics are specified both in time and space, because they model the\nperturbations induced by the agent to the environment, and the perturbations of\nthe environment as perceived by the agent. Parallel composition of world\nvariables is slightly different from parallel composition of the other\nvariables, since their signals are summed. The theory is illustrated through a\nsimple example of agents systems.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2012 00:52:54 GMT"}], "update_date": "2012-10-10", "authors_parsed": [["Capiluppi", "Marta", "", "Universit\u00e0 di Verona"], ["Segala", "Roberto", "", "Universit\u00e0\n  di Verona"]]}, {"id": "1210.2452", "submitter": "EPTCS", "authors": "Stephan Barth, Martin Hofmann", "title": "Learn with SAT to Minimize B\\\"uchi Automata", "comments": "In Proceedings GandALF 2012, arXiv:1210.2028", "journal-ref": "EPTCS 96, 2012, pp. 71-84", "doi": "10.4204/EPTCS.96.6", "report-no": null, "categories": "cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a minimization procedure for nondeterministic B\\\"uchi automata\n(NBA). For an automaton A another automaton A_min with the minimal number of\nstates is learned with the help of a SAT-solver.\n  This is done by successively computing automata A' that approximate A in the\nsense that they accept a given finite set of positive examples and reject a\ngiven finite set of negative examples. In the course of the procedure these\nexample sets are successively increased. Thus, our method can be seen as an\ninstance of a generic learning algorithm based on a \"minimally adequate\nteacher\" in the sense of Angluin.\n  We use a SAT solver to find an NBA for given sets of positive and negative\nexamples. We use complementation via construction of deterministic parity\nautomata to check candidates computed in this manner for equivalence with A.\nFailure of equivalence yields new positive or negative examples. Our method\nproved successful on complete samplings of small automata and of quite some\nexamples of bigger automata.\n  We successfully ran the minimization on over ten thousand automata with\nmostly up to ten states, including the complements of all possible automata\nwith two states and alphabet size three and discuss results and runtimes;\nsingle examples had over 100 states.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2012 00:53:36 GMT"}], "update_date": "2012-10-10", "authors_parsed": [["Barth", "Stephan", ""], ["Hofmann", "Martin", ""]]}, {"id": "1210.2453", "submitter": "EPTCS", "authors": "Alessandro Solimando (University of Genova, Italy), Giorgio Delzanno\n  (University of Genova, Italy), Giovanna Guerrini (University of Genova,\n  Italy)", "title": "Automata-based Static Analysis of XML Document Adaptation", "comments": "In Proceedings GandALF 2012, arXiv:1210.2028", "journal-ref": "EPTCS 96, 2012, pp. 85-98", "doi": "10.4204/EPTCS.96.7", "report-no": null, "categories": "cs.DB cs.DS cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The structure of an XML document can be optionally specified by means of XML\nSchema, thus enabling the exploitation of structural information for efficient\ndocument handling. Upon schema evolution, or when exchanging documents among\ndifferent collections exploiting related but not identical schemas, the need\nmay arise of adapting a document, known to be valid for a given schema S, to a\ntarget schema S'. The adaptation may require knowledge of the element semantics\nand cannot always be automatically derived. In this paper, we present an\nautomata-based method for the static analysis of user-defined XML document\nadaptations, expressed as sequences of XQuery Update update primitives. The key\nfeature of the method is the use of an automatic inference method for\nextracting the type, expressed as a Hedge Automaton, of a sequence of document\nupdates. The type is computed starting from the original schema S and from\nrewriting rules that formally define the operational semantics of a sequence of\ndocument updates. Type inclusion can then be used as conformance test w.r.t.\nthe type extracted from the target schema S'.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2012 00:53:46 GMT"}], "update_date": "2012-10-10", "authors_parsed": [["Solimando", "Alessandro", "", "University of Genova, Italy"], ["Delzanno", "Giorgio", "", "University of Genova, Italy"], ["Guerrini", "Giovanna", "", "University of Genova,\n  Italy"]]}, {"id": "1210.2454", "submitter": "EPTCS", "authors": "Aleksandar S. Dimovski", "title": "Symbolic Representation of Algorithmic Game Semantics", "comments": "In Proceedings GandALF 2012, arXiv:1210.2028", "journal-ref": "EPTCS 96, 2012, pp. 99-112", "doi": "10.4204/EPTCS.96.8", "report-no": null, "categories": "cs.FL cs.GT cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we revisit the regular-language representation of game\nsemantics of second-order recursion free Idealized Algol with infinite data\ntypes. By using symbolic values instead of concrete ones we generalize the\nstandard notion of regular-language and automata representations to that of\ncorresponding symbolic representations. In this way terms with infinite data\ntypes, such as integers, can be expressed as finite symbolic-automata although\nthe standard automata interpretation is infinite. Moreover, significant\nreductions of the state space of game semantics models are obtained. This\nenables efficient verification of terms, which is illustrated with several\nexamples.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2012 00:53:55 GMT"}], "update_date": "2012-10-10", "authors_parsed": [["Dimovski", "Aleksandar S.", ""]]}, {"id": "1210.2455", "submitter": "EPTCS", "authors": "Julian Gutierrez (University of Cambridge, United Kingdom), Felix\n  Klaedtke (ETH Zurich, Switzerland), Martin Lange (University of Kassel,\n  Germany)", "title": "The \\mu-Calculus Alternation Hierarchy Collapses over Structures with\n  Restricted Connectivity", "comments": "In Proceedings GandALF 2012, arXiv:1210.2028", "journal-ref": "EPTCS 96, 2012, pp. 113-126", "doi": "10.4204/EPTCS.96.9", "report-no": null, "categories": "cs.LO cs.CC cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is known that the alternation hierarchy of least and greatest fixpoint\noperators in the mu-calculus is strict. However, the strictness of the\nalternation hierarchy does not necessarily carry over when considering\nrestricted classes of structures. A prominent instance is the class of infinite\nwords over which the alternation-free fragment is already as expressive as the\nfull mu-calculus. Our current understanding of when and why the mu-calculus\nalternation hierarchy is not strict is limited. This paper makes progress in\nanswering these questions by showing that the alternation hierarchy of the\nmu-calculus collapses to the alternation-free fragment over some classes of\nstructures, including infinite nested words and finite graphs with feedback\nvertex sets of a bounded size. Common to these classes is that the connectivity\nbetween the components in a structure from such a class is restricted in the\nsense that the removal of certain vertices from the structure's graph\ndecomposes it into graphs in which all paths are of finite length. Our collapse\nresults are obtained in an automata-theoretic setting. They subsume,\ngeneralize, and strengthen several prior results on the expressivity of the\nmu-calculus over restricted classes of structures.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2012 00:54:03 GMT"}], "update_date": "2012-10-10", "authors_parsed": [["Gutierrez", "Julian", "", "University of Cambridge, United Kingdom"], ["Klaedtke", "Felix", "", "ETH Zurich, Switzerland"], ["Lange", "Martin", "", "University of Kassel,\n  Germany"]]}, {"id": "1210.2456", "submitter": "EPTCS", "authors": "Ricardo Almeida, Sabine Broda, Nelma Moreira", "title": "Deciding KAT and Hoare Logic with Derivatives", "comments": "In Proceedings GandALF 2012, arXiv:1210.2028", "journal-ref": "EPTCS 96, 2012, pp. 127-140", "doi": "10.4204/EPTCS.96.10", "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kleene algebra with tests (KAT) is an equational system for program\nverification, which is the combination of Boolean algebra (BA) and Kleene\nalgebra (KA), the algebra of regular expressions. In particular, KAT subsumes\nthe propositional fragment of Hoare logic (PHL) which is a formal system for\nthe specification and verification of programs, and that is currently the base\nof most tools for checking program correctness. Both the equational theory of\nKAT and the encoding of PHL in KAT are known to be decidable. In this paper we\npresent a new decision procedure for the equivalence of two KAT expressions\nbased on the notion of partial derivatives. We also introduce the notion of\nderivative modulo particular sets of equations. With this we extend the\nprevious procedure for deciding PHL. Some experimental results are also\npresented.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2012 00:54:12 GMT"}], "update_date": "2012-10-10", "authors_parsed": [["Almeida", "Ricardo", ""], ["Broda", "Sabine", ""], ["Moreira", "Nelma", ""]]}, {"id": "1210.2460", "submitter": "EPTCS", "authors": "Pawe{\\l} Parys (University of Warsaw)", "title": "Higher-Order Pushdown Systems with Data", "comments": "In Proceedings GandALF 2012, arXiv:1210.2028", "journal-ref": "EPTCS 96, 2012, pp. 210-223", "doi": "10.4204/EPTCS.96.16", "report-no": null, "categories": "cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new extension of higher-order pushdown automata, which allows to\nuse an infinite alphabet. The new automata recognize languages of data words\n(instead of normal words), which beside each its letter from a finite alphabet\nhave a data value from an infinite alphabet. Those data values can be loaded to\nthe stack of the automaton, and later compared with some farther data values on\nthe input. Our main purpose for introducing these automata is that they may\nhelp in analyzing normal automata (without data). As an example, we give a\nproof that deterministic automata with collapse can recognize more languages\nthan deterministic automata without collapse. This proof is simpler than in the\nno-data case. We also state a hypothesis how the new automaton model can be\nrelated to the original model of higher-order pushdown automata.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2012 00:55:10 GMT"}], "update_date": "2012-10-10", "authors_parsed": [["Parys", "Pawe\u0142", "", "University of Warsaw"]]}, {"id": "1210.2462", "submitter": "EPTCS", "authors": "Alex Kruckman (Berkeley University), Sasha Rubin (TU Vienna and IST\n  Austria), John Sheridan, Ben Zax", "title": "A Myhill-Nerode theorem for automata with advice", "comments": "In Proceedings GandALF 2012, arXiv:1210.2028", "journal-ref": "EPTCS 96, 2012, pp. 238-246", "doi": "10.4204/EPTCS.96.18", "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An automaton with advice is a finite state automaton which has access to an\nadditional fixed infinite string called an advice tape. We refine the\nMyhill-Nerode theorem to characterize the languages of finite strings that are\naccepted by automata with advice. We do the same for tree automata with advice.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2012 00:55:28 GMT"}], "update_date": "2012-10-10", "authors_parsed": [["Kruckman", "Alex", "", "Berkeley University"], ["Rubin", "Sasha", "", "TU Vienna and IST\n  Austria"], ["Sheridan", "John", ""], ["Zax", "Ben", ""]]}, {"id": "1210.2463", "submitter": "EPTCS", "authors": "Szczepan Hummel (University of Warsaw)", "title": "Unambiguous Tree Languages Are Topologically Harder Than Deterministic\n  Ones", "comments": "In Proceedings GandALF 2012, arXiv:1210.2028", "journal-ref": "EPTCS 96, 2012, pp. 247-260", "doi": "10.4204/EPTCS.96.19", "report-no": null, "categories": "cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper gives an example of a tree language G that is recognised by an\nunambiguous parity automaton and is analytic-complete as a set in Cantor space.\nThis already shows that the unambiguous languages are topologically more\ncomplex than the deterministic ones, that are all coanalytic.\n  Using set G as a building block we construct an unambiguous language that is\ntopologically harder than any countable boolean combination of analytic and\ncoanalytic sets. In particular the language is harder than any set in\ndifference hierarchy of analytic sets considered by O.Finkel and P.Simonnet in\nthe context of nondeterministic automata.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2012 00:55:43 GMT"}], "update_date": "2012-10-10", "authors_parsed": [["Hummel", "Szczepan", "", "University of Warsaw"]]}, {"id": "1210.2605", "submitter": "Olivier Bouissou", "authors": "Assal\\'e Adj\\'e and Jean Goubault-Larrecq", "title": "Concrete Semantics of Programs with Non-Deterministic and Random Inputs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This document gives semantics to programs written in a C-like programming\nlanguage, featuring interactions with an external environment with noisy and\nimprecise data.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2012 09:09:48 GMT"}], "update_date": "2012-10-10", "authors_parsed": [["Adj\u00e9", "Assal\u00e9", ""], ["Goubault-Larrecq", "Jean", ""]]}, {"id": "1210.3307", "submitter": "Saeid Pashazadeh", "authors": "Saeid Pashazadeh and Maryam Pashazadeh", "title": "Modelling an Automatic Proof Generator for Functional Dependency Rules\n  Using Colored Petri Net", "comments": "17 pages, 4 figures", "journal-ref": "International Journal in Foundations of Computer Science &\n  Technology (IJFCST) 2 (2012) 31-47", "doi": "10.5121/ijfcst.2012.2504", "report-no": null, "categories": "cs.DB cs.FL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Database administrators need to compute closure of functional dependencies\n(FDs) for normalization of database systems and enforcing integrity rules.\nColored Petri net (CPN) is a powerful formal method for modelling and\nverification of various systems. In this paper, we modelled Armstrong's axioms\nfor automatic proof generation of a new FD rule from initial FD rules using\nCPN. For this purpose, a CPN model of Armstrong's axioms presents and initial\nFDs considered in the model as initial color set. Then we search required FD in\nthe state space of the model via model checking. If it exists in the state\nspace, then a recursive ML code extracts the proof of this FD rule using\nfurther searches in the state space of the model.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2012 17:55:51 GMT"}], "update_date": "2012-10-12", "authors_parsed": [["Pashazadeh", "Saeid", ""], ["Pashazadeh", "Maryam", ""]]}, {"id": "1210.3593", "submitter": "Ond\\v{r}ej B\\'ilka", "authors": "Ond\\v{r}ej B\\'ilka", "title": "Pattern matching in compilers", "comments": "master thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this thesis we develop tools for effective and flexible pattern matching.\nWe introduce a new pattern matching system called amethyst. Amethyst is not\nonly a generator of parsers of programming languages, but can also serve as an\nalternative to tools for matching regular expressions.\n  Our framework also produces dynamic parsers. Its intended use is in the\ncontext of IDE (accurate syntax highlighting and error detection on the fly).\nAmethyst offers pattern matching of general data structures. This makes it a\nuseful tool for implementing compiler optimizations such as constant folding,\ninstruction scheduling, and dataflow analysis in general.\n  The parsers produced are essentially top-down parsers. Linear time complexity\nis obtained by introducing the novel notion of structured grammars and\nregularized regular expressions. Amethyst uses techniques known from compiler\noptimizations to produce effective parsers.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2012 18:23:56 GMT"}], "update_date": "2012-10-15", "authors_parsed": [["B\u00edlka", "Ond\u0159ej", ""]]}, {"id": "1210.3839", "submitter": "Josef Widder", "authors": "Annu John and Igor Konnov and Ulrich Schmid and Helmut Veith and Josef\n  Widder", "title": "Starting a Dialog between Model Checking and Fault-tolerant Distributed\n  Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fault-tolerant distributed algorithms are central for building reliable\nspatially distributed systems. Unfortunately, the lack of a canonical precise\nframework for fault-tolerant algorithms is an obstacle for both verification\nand deployment. In this paper, we introduce a new domain-specific framework to\ncapture the behavior of fault-tolerant distributed algorithms in an adequate\nand precise way. At the center of our framework is a parameterized system model\nwhere control flow automata are used for process specification. To account for\nthe specific features and properties of fault-tolerant distributed algorithms\nfor message-passing systems, our control flow automata are extended to model\nthreshold guards as well as the inherent non-determinism stemming from\nasynchronous communication, interleavings of steps, and faulty processes.\n  We demonstrate the adequacy of our framework in a representative case study\nwhere we formalize a family of well-known fault-tolerant broadcasting\nalgorithms under a variety of failure assumptions. Our case study is supported\nby model checking experiments with safety and liveness specifications for a\nfixed number of processes. In the experiments, we systematically varied the\nassumptions on both the resilience condition and the failure model. In all\ncases, our experiments coincided with the theoretical results predicted in the\ndistributed algorithms literature. This is giving clear evidence for the\nadequacy of our model.\n  In a companion paper, we are addressing the new model checking techniques\nnecessary for parametric verification of the distributed algorithms captured in\nour framework.\n", "versions": [{"version": "v1", "created": "Sun, 14 Oct 2012 20:51:31 GMT"}], "update_date": "2012-10-16", "authors_parsed": [["John", "Annu", ""], ["Konnov", "Igor", ""], ["Schmid", "Ulrich", ""], ["Veith", "Helmut", ""], ["Widder", "Josef", ""]]}, {"id": "1210.4289", "submitter": "Pierre Ganty", "authors": "Pierre Ganty, Radu Iosif, Filip Konecny", "title": "Underapproximation of Procedure Summaries for Integer Programs", "comments": "35 pages, 3 figures (this report supersedes the STTT version which in\n  turn supersedes the TACAS'13 version)", "journal-ref": null, "doi": "10.1007/s10009-016-0420-7", "report-no": null, "categories": "cs.PL cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how to underapproximate the procedure summaries of recursive programs\nover the integers using off-the-shelf analyzers for non-recursive programs. The\nnovelty of our approach is that the non-recursive program we compute may\ncapture unboundedly many behaviors of the original recursive program for which\nstack usage cannot be bounded. Moreover, we identify a class of recursive\nprograms on which our method terminates and returns the precise summary\nrelations without underapproximation. Doing so, we generalize a similar result\nfor non-recursive programs to the recursive case. Finally, we present\nexperimental results of an implementation of our method applied on a number of\nexamples.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2012 08:16:23 GMT"}, {"version": "v2", "created": "Tue, 13 May 2014 08:40:50 GMT"}, {"version": "v3", "created": "Mon, 24 Oct 2016 15:14:53 GMT"}], "update_date": "2016-10-25", "authors_parsed": [["Ganty", "Pierre", ""], ["Iosif", "Radu", ""], ["Konecny", "Filip", ""]]}, {"id": "1210.4787", "submitter": "Hongfei Fu", "authors": "Hongfei Fu", "title": "Approximating Acceptance Probabilities of CTMC-Paths on Multi-Clock\n  Deterministic Timed Automata", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of approximating the probability mass of the set of\ntimed paths under a continuous-time Markov chain (CTMC) that are accepted by a\ndeterministic timed automaton (DTA). As opposed to several existing works on\nthis topic, we consider DTA with multiple clocks. Our key contribution is an\nalgorithm to approximate these probabilities using finite difference methods.\nAn error bound is provided which indicates the approximation error. The\nstepping stones towards this result include rigorous proofs for the\nmeasurability of the set of accepted paths and the integral-equation system\ncharacterizing the acceptance probability, and a differential characterization\nfor the acceptance probability.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2012 16:28:57 GMT"}, {"version": "v2", "created": "Sat, 20 Oct 2012 19:10:27 GMT"}, {"version": "v3", "created": "Fri, 1 Feb 2013 15:14:16 GMT"}], "update_date": "2013-02-04", "authors_parsed": [["Fu", "Hongfei", ""]]}, {"id": "1210.4980", "submitter": "S{\\l}awomir Lasota", "authors": "Miko{\\l}aj Boja\\'nczyk and S{\\l}awomir Lasota", "title": "Minimization of semilinear automata", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate finite deterministic automata in sets with non-homogeneous\natoms: integers with successor. As there are uncount- ably many deterministic\nfinite automata in this setting, we restrict our attention to automata with\nsemilinear transition function. The main re- sults is a minimization procedure\nfor semilinear automata. The proof is subtle and refers to decidability of\nexistential Presburger arithmetic with divisibility predicates. Interestingly,\nthe minimization is not obtained by the standard partition refinement\nprocedure, and we demonstrate that this procedure does not necessarily\nterminate for semilinear automata.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2012 22:40:53 GMT"}], "update_date": "2012-10-19", "authors_parsed": [["Boja\u0144czyk", "Miko\u0142aj", ""], ["Lasota", "S\u0142awomir", ""]]}, {"id": "1210.4992", "submitter": "S\\'ergio Medeiros", "authors": "S\\'ergio Medeiros, Fabio Mascarenhas and Roberto Ierusalimschy", "title": "From Regexes to Parsing Expression Grammars", "comments": null, "journal-ref": null, "doi": "10.1016/j.scico.2012.11.006", "report-no": null, "categories": "cs.FL cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most scripting languages nowadays use regex pattern-matching libraries. These\nregex libraries borrow the syntax of regular expressions, but have an informal\nsemantics that is different from the semantics of regular expressions, removing\nthe commutativity of alternation and adding ad-hoc extensions that cannot be\nexpressed by formalisms for efficient recognition of regular languages, such as\ndeterministic finite automata.\n  Parsing Expression Grammars are a formalism that can describe all\ndeterministic context-free languages and has a simple computational model. In\nthis paper, we present a formalization of regexes via transformation to Parsing\nExpression Grammars. The proposed transformation easily accommodates several of\nthe common regex extensions, giving a formal meaning to them. It also provides\na clear computational model that helps to estimate the efficiency of\nregex-based matchers, and a basis for specifying provably correct optimizations\nfor them.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2012 23:53:30 GMT"}], "update_date": "2014-02-17", "authors_parsed": [["Medeiros", "S\u00e9rgio", ""], ["Mascarenhas", "Fabio", ""], ["Ierusalimschy", "Roberto", ""]]}, {"id": "1210.5093", "submitter": "Yousun Ko", "authors": "Yousun Ko, Minyoung Jung, Yo-Sub Han and Bernd Burgstaller", "title": "A Speculative Parallel DFA Membership Test for Multicore, SIMD and Cloud\n  Computing Environments", "comments": null, "journal-ref": null, "doi": "10.1007/s10766-013-0258-5", "report-no": null, "categories": "cs.DC cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present techniques to parallelize membership tests for Deterministic\nFinite Automata (DFAs). Our method searches arbitrary regular expressions by\nmatching multiple bytes in parallel using speculation. We partition the input\nstring into chunks, match chunks in parallel, and combine the matching results.\nOur parallel matching algorithm exploits structural DFA properties to minimize\nthe speculative overhead. Unlike previous approaches, our speculation is\nfailure-free, i.e., (1) sequential semantics are maintained, and (2)\nspeed-downs are avoided altogether. On architectures with a SIMD\ngather-operation for indexed memory loads, our matching operation is fully\nvectorized. The proposed load-balancing scheme uses an off-line profiling step\nto determine the matching capacity of each par- ticipating processor. Based on\nmatching capacities, DFA matches are load-balanced on inhomogeneous parallel\narchitectures such as cloud computing environments. We evaluated our\nspeculative DFA membership test for a representative set of benchmarks from the\nPerl-compatible Regular Expression (PCRE) library and the PROSITE protein\ndatabase. Evaluation was conducted on a 4 CPU (40 cores) shared-memory node of\nthe Intel Manycore Testing Lab (Intel MTL), on the Intel AVX2 SDE simulator for\n8-way fully vectorized SIMD execution, and on a 20-node (288 cores) cluster on\nthe Amazon EC2 computing cloud.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2012 11:17:23 GMT"}, {"version": "v2", "created": "Mon, 22 Jul 2013 15:32:29 GMT"}], "update_date": "2013-07-23", "authors_parsed": [["Ko", "Yousun", ""], ["Jung", "Minyoung", ""], ["Han", "Yo-Sub", ""], ["Burgstaller", "Bernd", ""]]}, {"id": "1210.5783", "submitter": "EPTCS", "authors": "Josep Silva (Universitat Polit\\`ecnica de Val\\`encia, Spain),\n  Francesco Tiezzi (IMT Institute for Advanced Studies Lucca, Italy)", "title": "Proceedings 8th International Workshop on Automated Specification and\n  Verification of Web Systems", "comments": "EPTCS 98, 2012", "journal-ref": null, "doi": "10.4204/EPTCS.98", "report-no": null, "categories": "cs.SE cs.FL cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the final and revised versions of the papers presented\nat the 8th International Workshop on Automated Specification and Verification\nof Web Systems (WWV 2012). The workshop was held in Stockholm, Sweden, on June\n16, 2012, as part of DisCoTec 2012.\n  WWV is a yearly workshop that aims at providing an interdisciplinary forum to\nfacilitate the cross-fertilization and the advancement of hybrid methods that\nexploit concepts and tools drawn from Rule-based programming, Software\nengineering, Formal methods and Web-oriented research. WWV has a reputation for\nbeing a lively, friendly forum for presenting and discussing work in progress.\nThe proceedings have been produced after the symposium to allow the authors to\nincorporate the feedback gathered during the event in the published papers.\n  All papers submitted to the workshop were reviewed by at least three Program\nCommittee members or external referees. The Program Committee held an\nelectronic discussion leading to the acceptance of all papers for presentation\nat the workshop. In addition to the presentation of the contributed papers, the\nscientific programme included the invited talks by two outstanding speakers:\nRocco De Nicola (IMT, Institute for Advanced Studies Lucca, Italy) and Jos\\`e\nLuiz Fiadeiro (Royal Holloway, United Kingdom).\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2012 00:17:53 GMT"}], "update_date": "2012-10-23", "authors_parsed": [["Silva", "Josep", "", "Universitat Polit\u00e8cnica de Val\u00e8ncia, Spain"], ["Tiezzi", "Francesco", "", "IMT Institute for Advanced Studies Lucca, Italy"]]}, {"id": "1210.6624", "submitter": "Richard Mayr", "authors": "Lorenzo Clemente and Richard Mayr", "title": "Advanced Automata Minimization", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": "EDI-INF-RR-1414", "categories": "cs.FL cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an efficient algorithm to reduce the size of nondeterministic\nBuchi word automata, while retaining their language. Additionally, we describe\nmethods to solve PSPACE-complete automata problems like universality,\nequivalence and inclusion for much larger instances (1-3 orders of magnitude)\nthan before. This can be used to scale up applications of automata in formal\nverification tools and decision procedures for logical theories. The algorithm\nis based on new transition pruning techniques. These use criteria based on\ncombinations of backward and forward trace inclusions. Since these relations\nare themselves PSPACE-complete, we describe methods to compute good\napproximations of them in polynomial time. Extensive experiments show that the\naverage-case complexity of our algorithm scales quadratically. The size\nreduction of the automata depends very much on the class of instances, but our\nalgorithm consistently outperforms all previous techniques by a wide margin. We\ntested our algorithm on Buchi automata derived from LTL-formulae, many classes\nof random automata and automata derived from mutual exclusion protocols, and\ncompared its performance to the well-known automata tool GOAL.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2012 18:43:12 GMT"}], "update_date": "2012-10-25", "authors_parsed": [["Clemente", "Lorenzo", ""], ["Mayr", "Richard", ""]]}, {"id": "1210.7686", "submitter": "Stefan Kiefer", "authors": "Michael Benedikt and Stefan G\\\"oller and Stefan Kiefer and Andrzej S.\n  Murawski", "title": "Bisimilarity of Pushdown Systems is Nonelementary", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given two pushdown systems, the bisimilarity problem asks whether they are\nbisimilar. While this problem is known to be decidable our main result states\nthat it is nonelementary, improving EXPTIME-hardness, which was the previously\nbest known lower bound for this problem. Our lower bound result holds for\nnormed pushdown systems as well.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2012 15:11:34 GMT"}], "update_date": "2012-10-31", "authors_parsed": [["Benedikt", "Michael", ""], ["G\u00f6ller", "Stefan", ""], ["Kiefer", "Stefan", ""], ["Murawski", "Andrzej S.", ""]]}]