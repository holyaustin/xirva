[{"id": "1901.00248", "submitter": "Donna Xu", "authors": "Donna Xu, Yaxin Shi, Ivor W. Tsang, Yew-Soon Ong, Chen Gong and Xiaobo\n  Shen", "title": "A Survey on Multi-output Learning", "comments": "Paper accepted by IEEE Transactions on Neural Networks and Learning\n  Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.GL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-output learning aims to simultaneously predict multiple outputs given\nan input. It is an important learning problem due to the pressing need for\nsophisticated decision making in real-world applications. Inspired by big data,\nthe 4Vs characteristics of multi-output imposes a set of challenges to\nmulti-output learning, in terms of the volume, velocity, variety and veracity\nof the outputs. Increasing number of works in the literature have been devoted\nto the study of multi-output learning and the development of novel approaches\nfor addressing the challenges encountered. However, it lacks a comprehensive\noverview on different types of challenges of multi-output learning brought by\nthe characteristics of the multiple outputs and the techniques proposed to\novercome the challenges. This paper thus attempts to fill in this gap to\nprovide a comprehensive review on this area. We first introduce different\nstages of the life cycle of the output labels. Then we present the paradigm on\nmulti-output learning, including its myriads of output structures, definitions\nof its different sub-problems, model evaluation metrics and popular data\nrepositories used in the study. Subsequently, we review a number of\nstate-of-the-art multi-output learning methods, which are categorized based on\nthe challenges.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jan 2019 03:10:24 GMT"}, {"version": "v2", "created": "Sun, 13 Oct 2019 10:59:28 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Xu", "Donna", ""], ["Shi", "Yaxin", ""], ["Tsang", "Ivor W.", ""], ["Ong", "Yew-Soon", ""], ["Gong", "Chen", ""], ["Shen", "Xiaobo", ""]]}, {"id": "1901.04020", "submitter": "Basel  Magableh  Dr", "authors": "Basel Magableh", "title": "A Framework for Evaluating Model-Driven Self-adaptive Software Systems", "comments": "model-driven architecture, COP, AOP, component composition,\n  self-adaptive application, context oriented software development", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.GL", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In the last few years, Model Driven Development (MDD), Component-based\nSoftware Development (CBSD), and context-oriented software have become\ninteresting alternatives for the design and construction of self-adaptive\nsoftware systems. In general, the ultimate goal of these technologies is to be\nable to reduce development costs and effort, while improving the modularity,\nflexibility, adaptability, and reliability of software systems. An analysis of\nthese technologies shows them all to include the principle of the separation of\nconcerns, and their further integration is a key factor to obtaining\nhigh-quality and self-adaptable software systems. Each technology identifies\ndifferent concerns and deals with them separately in order to specify the\ndesign of the self-adaptive applications, and, at the same time, support\nsoftware with adaptability and context-awareness. This research studies the\ndevelopment methodologies that employ the principles of model-driven\ndevelopment in building self-adaptive software systems. To this aim, this\narticle proposes an evaluation framework for analysing and evaluating the\nfeatures of model-driven approaches and their ability to support software with\nself-adaptability and dependability in highly dynamic contextual environment.\nSuch evaluation framework can facilitate the software developers on selecting a\ndevelopment methodology that suits their software requirements and reduces the\ndevelopment effort of building self-adaptive software systems. This study\nhighlights the major drawbacks of the propped model-driven approaches in the\nrelated works, and emphasise on considering the volatile aspects of\nself-adaptive software in the analysis, design and implementation phases of the\ndevelopment methodologies. In addition, we argue that the development\nmethodologies should leave the selection of modelling languages and modelling\ntools to the software developers.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jan 2019 17:11:08 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Magableh", "Basel", ""]]}, {"id": "1901.04819", "submitter": "Kai-Kristian Kemell", "authors": "Kai-Kristian Kemell, Xiaofeng Wang, Anh Nguyen-Duc, Jason Grendus,\n  Tuure Tuunanen and Pekka Abrahamsson", "title": "100+ Metrics for Software Startups - A Multi-Vocal Literature Review", "comments": "Published in the proceedings of The 1st Software-intensive Business\n  Workshop on Start-ups, Platforms and Ecosystems (SiBW 2018), Espoo, December\n  3rd, 2018. http://ceur-ws.org/Vol-2305/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GL econ.GN q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Metrics can be used by businesses to make more objective decisions based on\ndata. Software startups in particular are characterized by the uncertain or\neven chaotic nature of the contexts in which they operate. Using data in the\nform of metrics can help software startups to make the right decisions amidst\nuncertainty and limited resources. However, whereas conventional business\nmetrics and software metrics have been studied in the past, metrics in the\nspe-cific context of software startup are not widely covered within academic\nliterature. To promote research in this area and to create a starting point for\nit, we have conducted a multi-vocal literature review focusing on practitioner\nliterature in order to compile a list of metrics used by software startups.\nSaid list is intended to serve as a basis for further research in the area, as\nthe metrics in it are based on suggestions made by practitioners and not\nempirically verified.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2019 13:47:06 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Kemell", "Kai-Kristian", ""], ["Wang", "Xiaofeng", ""], ["Nguyen-Duc", "Anh", ""], ["Grendus", "Jason", ""], ["Tuunanen", "Tuure", ""], ["Abrahamsson", "Pekka", ""]]}]