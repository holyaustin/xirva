[{"id": "1911.05755", "submitter": "Nicholas Schmidt", "authors": "Nicholas Schmidt and Bryce Stephens", "title": "An Introduction to Artificial Intelligence and Solutions to the Problems\n  of Algorithmic Discrimination", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.GL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There is substantial evidence that Artificial Intelligence (AI) and Machine\nLearning (ML) algorithms can generate bias against minorities, women, and other\nprotected classes. Federal and state laws have been enacted to protect\nconsumers from discrimination in credit, housing, and employment, where\nregulators and agencies are tasked with enforcing these laws. Additionally,\nthere are laws in place to ensure that consumers understand why they are denied\naccess to services and products, such as consumer loans. In this article, we\nprovide an overview of the potential benefits and risks associated with the use\nof algorithms and data, and focus specifically on fairness. While our\nobservations generalize to many contexts, we focus on the fairness concerns\nraised in consumer credit and the legal requirements of the Equal Credit and\nOpportunity Act. We propose a methodology for evaluating algorithmic fairness\nand minimizing algorithmic bias that aligns with the provisions of federal and\nstate anti-discrimination statutes that outlaw overt, disparate treatment, and,\nspecifically, disparate impact discrimination. We argue that while the use of\nAI and ML algorithms heighten potential discrimination risks, these risks can\nbe evaluated and mitigated, but doing so requires a deep understanding of these\nalgorithms and the contexts and domains in which they are being used.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 22:29:56 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Schmidt", "Nicholas", ""], ["Stephens", "Bryce", ""]]}, {"id": "1911.08031", "submitter": "Abdul Dakkak", "authors": "Cheng Li, Abdul Dakkak, Jinjun Xiong, Wen-mei Hwu", "title": "The Design and Implementation of a Scalable DL Benchmarking Platform", "comments": null, "journal-ref": "2020 IEEE 13th International Conference on Cloud Computing\n  (CLOUD), 414-425", "doi": "10.1109/CLOUD49709.2020.00063", "report-no": null, "categories": "cs.DC cs.GL cs.LG cs.PF stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The current Deep Learning (DL) landscape is fast-paced and is rife with\nnon-uniform models, hardware/software (HW/SW) stacks, but lacks a DL\nbenchmarking platform to facilitate evaluation and comparison of DL\ninnovations, be it models, frameworks, libraries, or hardware. Due to the lack\nof a benchmarking platform, the current practice of evaluating the benefits of\nproposed DL innovations is both arduous and error-prone - stifling the adoption\nof the innovations.\n  In this work, we first identify $10$ design features which are desirable\nwithin a DL benchmarking platform. These features include: performing the\nevaluation in a consistent, reproducible, and scalable manner, being framework\nand hardware agnostic, supporting real-world benchmarking workloads, providing\nin-depth model execution inspection across the HW/SW stack levels, etc. We then\npropose MLModelScope, a DL benchmarking platform design that realizes the $10$\nobjectives. MLModelScope proposes a specification to define DL model\nevaluations and techniques to provision the evaluation workflow using the\nuser-specified HW/SW stack. MLModelScope defines abstractions for frameworks\nand supports board range of DL models and evaluation scenarios. We implement\nMLModelScope as an open-source project with support for all major frameworks\nand hardware architectures. Through MLModelScope's evaluation and automated\nanalysis workflows, we performed case-study analyses of $37$ models across $4$\nsystems and show how model, hardware, and framework selection affects model\naccuracy and performance under different benchmarking scenarios. We further\ndemonstrated how MLModelScope's tracing capability gives a holistic view of\nmodel execution and helps pinpoint bottlenecks.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 01:16:08 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Li", "Cheng", ""], ["Dakkak", "Abdul", ""], ["Xiong", "Jinjun", ""], ["Hwu", "Wen-mei", ""]]}]