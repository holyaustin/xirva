[{"id": "1603.00060", "submitter": "Adrian Dumitrescu", "authors": "Kevin Balas, Adrian Dumitrescu, and Csaba D. T\\'oth", "title": "Anchored Rectangle and Square Packings", "comments": "33 pages, 20 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For points $p_1,\\ldots , p_n$ in the unit square $[0,1]^2$, an \\emph{anchored\nrectangle packing} consists of interior-disjoint axis-aligned empty rectangles\n$r_1,\\ldots , r_n\\subseteq [0,1]^2$ such that point $p_i$ is a corner of the\nrectangle $r_i$ (that is, $r_i$ is \\emph{anchored} at $p_i$) for $i=1,\\ldots,\nn$. We show that for every set of $n$ points in $[0,1]^2$, there is an anchored\nrectangle packing of area at least $7/12-O(1/n)$, and for every $n\\in\n\\mathbf{N}$, there are point sets for which the area of every anchored\nrectangle packing is at most $2/3$. The maximum area of an anchored\n\\emph{square} packing is always at least $5/32$ and sometimes at most $7/27$.\n  The above constructive lower bounds immediately yield constant-factor\napproximations, of $7/12 -\\varepsilon$ for rectangles and $5/32$ for squares,\nfor computing anchored packings of maximum area in $O(n\\log n)$ time. We prove\nthat a simple greedy strategy achieves a $9/47$-approximation for anchored\nsquare packings, and $1/3$ for lower-left anchored square packings. Reductions\nto maximum weight independent set (MWIS) yield a QPTAS and a PTAS for anchored\nrectangle and square packings in $n^{O(1/\\varepsilon)}$ and $\\exp({\\rm\npoly}(\\log (n/\\varepsilon)))$ time, respectively.\n", "versions": [{"version": "v1", "created": "Mon, 29 Feb 2016 21:44:01 GMT"}], "update_date": "2016-03-02", "authors_parsed": [["Balas", "Kevin", ""], ["Dumitrescu", "Adrian", ""], ["T\u00f3th", "Csaba D.", ""]]}, {"id": "1603.00546", "submitter": "Jan Egger", "authors": "Jan Egger, Philip Voglreiter, Mark Dokter, Michael Hofmann, Xiaojun\n  Chen, Wolfram G. Zoller, Dieter Schmalstieg, Alexander Hann", "title": "US-Cut: Interactive Algorithm for rapid Detection and Segmentation of\n  Liver Tumors in Ultrasound Acquisitions", "comments": "6 pages, 6 figures, 1 table, 32 references", "journal-ref": "SPIE Medical Imaging Conference 2016, Paper 9790-47", "doi": "10.1117/12.2216509", "report-no": null, "categories": "cs.CV cs.CE cs.CG cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ultrasound (US) is the most commonly used liver imaging modality worldwide.\nIt plays an important role in follow-up of cancer patients with liver\nmetastases. We present an interactive segmentation approach for liver tumors in\nUS acquisitions. Due to the low image quality and the low contrast between the\ntumors and the surrounding tissue in US images, the segmentation is very\nchallenging. Thus, the clinical practice still relies on manual measurement and\noutlining of the tumors in the US images. We target this problem by applying an\ninteractive segmentation algorithm to the US data, allowing the user to get\nreal-time feedback of the segmentation results. The algorithm has been\ndeveloped and tested hand-in-hand by physicians and computer scientists to make\nsure a future practical usage in a clinical setting is feasible. To cover\ntypical acquisitions from the clinical routine, the approach has been evaluated\nwith dozens of datasets where the tumors are hyperechoic (brighter), hypoechoic\n(darker) or isoechoic (similar) in comparison to the surrounding liver tissue.\nDue to the interactive real-time behavior of the approach, it was possible even\nin difficult cases to find satisfying segmentations of the tumors within\nseconds and without parameter settings, and the average tumor deviation was\nonly 1.4mm compared with manual measurements. However, the long term goal is to\nease the volumetric acquisition of liver tumors in order to evaluate for\ntreatment response. Additional aim is the registration of intraoperative US\nimages via the interactive segmentations to the patient's pre-interventional CT\nacquisitions.\n", "versions": [{"version": "v1", "created": "Wed, 2 Mar 2016 01:42:48 GMT"}], "update_date": "2016-06-29", "authors_parsed": [["Egger", "Jan", ""], ["Voglreiter", "Philip", ""], ["Dokter", "Mark", ""], ["Hofmann", "Michael", ""], ["Chen", "Xiaojun", ""], ["Zoller", "Wolfram G.", ""], ["Schmalstieg", "Dieter", ""], ["Hann", "Alexander", ""]]}, {"id": "1603.00580", "submitter": "Matias Korman", "authors": "Ferran Hurtado, Matias Korman, Marc van Kreveld, Maarten L\\\"offler,\n  Vera Sacrist\\'an, Akiyoshi Shioura, Rodrigo I. Silveira, Bettina Speckmann,\n  Takeshi Tokuyama", "title": "Colored Spanning Graphs for Set Visualization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study an algorithmic problem that is motivated by ink minimization for\nsparse set visualizations. Our input is a set of points in the plane which are\neither blue, red, or purple. Blue points belong exclusively to the blue set,\nred points belong exclusively to the red set, and purple points belong to both\nsets. A \\emph{red-blue-purple spanning graph} (RBP spanning graph) is a set of\nedges connecting the points such that the subgraph induced by the red and\npurple points is connected, and the subgraph induced by the blue and purple\npoints is connected.\n  We study the geometric properties of minimum RBP spanning graphs and the\nalgorithmic problems associated with computing them. Specifically, we show that\nthe general problem can be solved in polynomial time using matroid techniques.\nIn addition, we discuss more efficient algorithms for the case in which points\nare located on a line or a circle, and also describe a fast $(\\frac\n12\\rho+1)$-approximation algorithm, where $\\rho$ is the Steiner ratio.\n", "versions": [{"version": "v1", "created": "Wed, 2 Mar 2016 05:13:13 GMT"}, {"version": "v2", "created": "Wed, 25 May 2016 13:01:06 GMT"}], "update_date": "2016-05-26", "authors_parsed": [["Hurtado", "Ferran", ""], ["Korman", "Matias", ""], ["van Kreveld", "Marc", ""], ["L\u00f6ffler", "Maarten", ""], ["Sacrist\u00e1n", "Vera", ""], ["Shioura", "Akiyoshi", ""], ["Silveira", "Rodrigo I.", ""], ["Speckmann", "Bettina", ""], ["Tokuyama", "Takeshi", ""]]}, {"id": "1603.00740", "submitter": "Orit E. Raz", "authors": "Orit E. Raz", "title": "A note on distinct distances", "comments": "16 pages", "journal-ref": "Combinator. Probab. Comp. 29 (2020) 650-663", "doi": "10.1017/S096354832000022X", "report-no": null, "categories": "math.MG cs.CG math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that, for a constant-degree algebraic curve $\\gamma$ in\n$\\mathbb{R}^D$, every set of $n$ points on $\\gamma$ spans at least\n$\\Omega(n^{4/3})$ distinct distances, unless $\\gamma$ is an {\\it algebraic\nhelix} (see Definition 1.1). This improves the earlier bound $\\Omega(n^{5/4})$\nof Charalambides [Discrete Comput. Geom. (2014)].\n  We also show that, for every set $P$ of $n$ points that lie on a\n$d$-dimensional constant-degree algebraic variety $V$ in $\\mathbb{R}^D$, there\nexists a subset $S\\subset P$ of size at least\n$\\Omega(n^{\\frac{4}{9+12(d-1)}})$, such that $S$ spans $\\binom{|S|}{2}$\ndistinct distances. This improves the earlier bound of\n$\\Omega(n^{\\frac{1}{3d}})$ of Conlon et al. [SIAM J. Discrete Math. (2015)].\n  Both results are consequences of a common technical tool, given in Lemma 2.7\nbelow.\n", "versions": [{"version": "v1", "created": "Mon, 29 Feb 2016 11:59:12 GMT"}, {"version": "v2", "created": "Tue, 14 Apr 2020 08:51:27 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Raz", "Orit E.", ""]]}, {"id": "1603.00847", "submitter": "Megan Owen", "authors": "Anna Lubiw, Daniela Maftuleac and Megan Owen", "title": "Shortest Paths and Convex Hulls in 2D Complexes with Non-Positive\n  Curvature", "comments": "minor clarifications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG math.CO math.MG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Globally non-positively curved, or CAT(0), polyhedral complexes arise in a\nnumber of applications, including evolutionary biology and robotics. These\nspaces have unique shortest paths and are composed of Euclidean polyhedra, yet\nmany algorithms and properties of shortest paths and convex hulls in Euclidean\nspace fail to transfer over. We give an algorithm, using linear programming, to\ncompute the convex hull of a set of points in a 2-dimensional CAT(0) polyhedral\ncomplex with a single vertex. We explore the use of shortest path maps to\nanswer single-source shortest path queries in 2-dimensional CAT(0) polyhedral\ncomplexes, and we unify efficient solutions for 2-manifold and rectangular\ncases.\n", "versions": [{"version": "v1", "created": "Wed, 2 Mar 2016 19:58:13 GMT"}, {"version": "v2", "created": "Mon, 28 Mar 2016 17:22:39 GMT"}, {"version": "v3", "created": "Sat, 23 Jul 2016 16:04:00 GMT"}, {"version": "v4", "created": "Sat, 4 Feb 2017 20:16:23 GMT"}, {"version": "v5", "created": "Thu, 15 Mar 2018 02:22:09 GMT"}, {"version": "v6", "created": "Wed, 17 Jul 2019 16:17:46 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Lubiw", "Anna", ""], ["Maftuleac", "Daniela", ""], ["Owen", "Megan", ""]]}, {"id": "1603.00960", "submitter": "Jan Egger", "authors": "Jan Egger, Christopher Nimsky", "title": "Cellular Automata Segmentation of the Boundary between the Compacta of\n  Vertebral Bodies and Surrounding Structures", "comments": "6 pages, 5 figures, 1 table, 42 references", "journal-ref": "SPIE Medical Imaging Conference 2016, Paper 9787-52", "doi": "10.1117/12.2209039", "report-no": null, "categories": "cs.CV cs.CG cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the aging population, spinal diseases get more and more common\nnowadays; e.g., lifetime risk of osteoporotic fracture is 40% for white women\nand 13% for white men in the United States. Thus the numbers of surgical spinal\nprocedures are also increasing with the aging population and precise diagnosis\nplays a vital role in reducing complication and recurrence of symptoms. Spinal\nimaging of vertebral column is a tedious process subjected to interpretation\nerrors. In this contribution, we aim to reduce time and error for vertebral\ninterpretation by applying and studying the GrowCut-algorithm for boundary\nsegmentation between vertebral body compacta and surrounding structures.\nGrowCut is a competitive region growing algorithm using cellular automata. For\nour study, vertebral T2-weighted Magnetic Resonance Imaging (MRI) scans were\nfirst manually outlined by neurosurgeons. Then, the vertebral bodies were\nsegmented in the medical images by a GrowCut-trained physician using the\nsemi-automated GrowCut-algorithm. Afterwards, results of both segmentation\nprocesses were compared using the Dice Similarity Coefficient (DSC) and the\nHausdorff Distance (HD) which yielded to a DSC of 82.99+/-5.03% and a HD of\n18.91+/-7.2 voxel, respectively. In addition, the times have been measured\nduring the manual and the GrowCut segmentations, showing that a\nGrowCut-segmentation - with an average time of less than six minutes\n(5.77+/-0.73) - is significantly shorter than a pure manual outlining.\n", "versions": [{"version": "v1", "created": "Thu, 3 Mar 2016 03:35:07 GMT"}], "update_date": "2016-06-29", "authors_parsed": [["Egger", "Jan", ""], ["Nimsky", "Christopher", ""]]}, {"id": "1603.02008", "submitter": "Patrizio Frosini", "authors": "Patrizio Frosini", "title": "Position paper: Towards an observer-oriented theory of shape comparison", "comments": "Preprint of the position paper submitted to the Eurographics Workshop\n  on 3D Object Retrieval (2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CV math.AT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this position paper we suggest a possible metric approach to shape\ncomparison that is based on a mathematical formalization of the concept of\nobserver, seen as a collection of suitable operators acting on a metric space\nof functions. These functions represent the set of data that are accessible to\nthe observer, while the operators describe the way the observer elaborates the\ndata and enclose the invariance that he/she associates with them. We expose\nthis model and illustrate some theoretical reasons that justify its possible\nuse for shape comparison.\n", "versions": [{"version": "v1", "created": "Mon, 7 Mar 2016 11:16:28 GMT"}], "update_date": "2016-03-08", "authors_parsed": [["Frosini", "Patrizio", ""]]}, {"id": "1603.02080", "submitter": "Mikkel Abrahamsen", "authors": "Mikkel Abrahamsen and Mikkel Thorup", "title": "Finding the Maximum Subset with Bounded Convex Curvature", "comments": "A preliminary version was presented at SoCG 2016. This version is\n  almost completely rewritten", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe an algorithm for solving an important geometric problem arising\nin computer-aided manufacturing. When cutting away a region from a solid piece\nof material -- such as steel, wood, ceramics, or plastic -- using a rough tool\nin a milling machine, sharp convex corners of the region cannot be done\nproperly, but have to be left for finer tools that are more expensive to use.\nWe want to determine a toolpath that maximizes the use of the rough tool. In\norder to formulate the problem in mathematical terms, we introduce the notion\nof bounded convex curvature. A region of points in the plane $Q$ has bounded\nconvex curvature if for any point $x\\in\\partial Q$, there is a unit disk $U$\nand $\\varepsilon>0$ such that $x\\in \\partial U$ and all points in $U$ within\ndistance $\\varepsilon$ from $x$ are in $Q$. This translates to saying that as\nwe traverse the boundary $\\partial Q$ with the interior of $Q$ on the left\nside, then $\\partial Q$ turns to the left with curvature at most $1$. There is\nno bound on the curvature where $\\partial Q$ turns to the right. Given a region\nof points $P$ in the plane, we are now interested in computing the maximum\nsubset $Q\\subseteq P$ of bounded convex curvature. The difference in the\nrequirement to left- and right-curvature is a natural consequence of different\nconditions when machining convex and concave areas of $Q$. We devise an\nalgorithm to compute the unique maximum such set $Q$, when the boundary of $P$\nconsists of $n$ line segments and circular arcs of arbitrary radii. In the\ngeneral case where $P$ may have holes, the algorithm runs in time $O(n^2)$ and\nuses $O(n)$ space. If $P$ is simply-connected, we describe a faster $O(n\\log\nn)$ time algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 7 Mar 2016 14:18:53 GMT"}, {"version": "v2", "created": "Mon, 8 Mar 2021 16:11:04 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Abrahamsen", "Mikkel", ""], ["Thorup", "Mikkel", ""]]}, {"id": "1603.02763", "submitter": "Marina Meila", "authors": "James McQueen and Marina Meila and Jacob VanderPlas and Zhongyue Zhang", "title": "megaman: Manifold Learning with Millions of points", "comments": "12 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Manifold Learning is a class of algorithms seeking a low-dimensional\nnon-linear representation of high-dimensional data. Thus manifold learning\nalgorithms are, at least in theory, most applicable to high-dimensional data\nand sample sizes to enable accurate estimation of the manifold. Despite this,\nmost existing manifold learning implementations are not particularly scalable.\nHere we present a Python package that implements a variety of manifold learning\nalgorithms in a modular and scalable fashion, using fast approximate neighbors\nsearches and fast sparse eigendecompositions. The package incorporates\ntheoretical advances in manifold learning, such as the unbiased Laplacian\nestimator and the estimation of the embedding distortion by the Riemannian\nmetric method. In benchmarks, even on a single-core desktop computer, our code\nembeds millions of data points in minutes, and takes just 200 minutes to embed\nthe main sample of galaxy spectra from the Sloan Digital Sky Survey ---\nconsisting of 0.6 million samples in 3750-dimensions --- a task which has not\npreviously been possible.\n", "versions": [{"version": "v1", "created": "Wed, 9 Mar 2016 02:05:11 GMT"}], "update_date": "2016-03-10", "authors_parsed": [["McQueen", "James", ""], ["Meila", "Marina", ""], ["VanderPlas", "Jacob", ""], ["Zhang", "Zhongyue", ""]]}, {"id": "1603.02853", "submitter": "Wolfgang Mulzer", "authors": "Yeganeh Bahoo, Bahareh Banyassady, Prosenjit Bose, Stephane Durocher\n  and Wolfgang Mulzer", "title": "A Time-Space Trade-off for Computing the k-Visibility Region of a Point\n  in a Polygon", "comments": "17 pages, 5 figures; a preliminary version appeared in WALCOM 2017;\n  this revision fixes a mistake in the proof of Theorem 4.4 in the published\n  version, the statement of the theorem remains unchanged", "journal-ref": null, "doi": "10.1016/j.tcs.2018.06.017", "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $P$ be a simple polygon with $n$ vertices, and let $q \\in P$ be a point\nin $P$. Let $k \\in \\{0, \\dots, n - 1\\}$. A point $p \\in P$ is $k$-visible from\n$q$ if and only if the line segment $pq$ crosses the boundary of $P$ at most\n$k$ times. The $k$-visibility region of $q$ in $P$ is the set of all points\nthat are $k$-visible from $q$. We study the problem of computing the\n$k$-visibility region in the limited workspace model, where the input resides\nin a random-access read-only memory of $O(n)$ words, each with\n$\\Omega(\\log{n})$ bits. The algorithm can read and write $O(s)$ additional\nwords of workspace, where $s \\in \\mathbb{N}$ is a parameter of the model. The\noutput is written to a write-only stream.\n  Given a simple polygon $P$ with $n$ vertices and a point $q \\in P$, we\npresent an algorithm that reports the $k$-visibility region of $q$ in $P$ in\n$O(cn/s+c\\log{s} + \\min\\{\\lceil k/s \\rceil n,n \\log{\\log_s{n}}\\})$ expected\ntime using $O(s)$ words of workspace. Here, $c \\in \\{1, \\dots, n\\}$ is the\nnumber of critical vertices of $P$ for $q$ where the $k$-visibility region of\n$q$ may change. We generalize this result for polygons with holes and for sets\nof non-crossing line segments.\n", "versions": [{"version": "v1", "created": "Wed, 9 Mar 2016 11:33:45 GMT"}, {"version": "v2", "created": "Sat, 9 Jun 2018 09:53:17 GMT"}, {"version": "v3", "created": "Tue, 13 Aug 2019 10:06:42 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Bahoo", "Yeganeh", ""], ["Banyassady", "Bahareh", ""], ["Bose", "Prosenjit", ""], ["Durocher", "Stephane", ""], ["Mulzer", "Wolfgang", ""]]}, {"id": "1603.03098", "submitter": "Sariel Har-Peled", "authors": "Sariel Har-Peled and Kent Quanrud", "title": "Notes on Approximation Algorithms for Polynomial-Expansion and\n  Low-Density Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This write-up contains some minor results and notes related to our work\n[HQ15] (some of them already known in the literature). In particular, it shows\nthe following:\n  - We show that a graph with polynomial expansion have sublinear separators.\n  - We show that hereditary sublinear separators imply that a graph have small\ndivisions.\n  - We show a natural condition on a set of segments, such that they have low\ndensity. This might be of independent interest in trying to define a realistic\ninput model for a set of segments. Unlike the previous two results, this is\nnew.\n  For context and more details, see the main paper.\n", "versions": [{"version": "v1", "created": "Wed, 9 Mar 2016 23:40:28 GMT"}], "update_date": "2016-03-11", "authors_parsed": [["Har-Peled", "Sariel", ""], ["Quanrud", "Kent", ""]]}, {"id": "1603.03463", "submitter": "Eric Braude", "authors": "Eric J. Braude", "title": "Generalizing The Morley Trisector and Various Theorems with\n  Realizability Computations", "comments": "23 pages, 21 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An approach is shown that proves various theorems of plane geometry in an\nalgorithmic manner. The approach affords transparent proofs of a generalization\nof the Theorem of Morley and other well known results by casting them in terms\nof constraint satisfaction.\n", "versions": [{"version": "v1", "created": "Thu, 10 Mar 2016 21:56:56 GMT"}], "update_date": "2016-03-14", "authors_parsed": [["Braude", "Eric J.", ""]]}, {"id": "1603.03818", "submitter": "Iyad Kanj", "authors": "Iyad Kanj, Ljubomir Perkovi\\'c, and Duru T\\\"urko\\v{g}lu", "title": "Degree Four Plane Spanners: Simpler and Better", "comments": "To appear in Proceedings of SoCG 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let ${\\cal P}$ be a set of $n$ points embedded in the plane, and let ${\\cal\nC}$ be the complete Euclidean graph whose point-set is ${\\cal P}$. Each edge in\n${\\cal C}$ between two points $p, q$ is realized as the line segment $[pq]$,\nand is assigned a weight equal to the Euclidean distance $|pq|$. In this paper,\nwe show how to construct in $O(n\\lg{n})$ time a plane spanner of ${\\cal C}$ of\nmaximum degree at most 4 and stretch factor at most 20. This improves a long\nsequence of results on the construction of plane spanners of ${\\cal C}$. Our\nresult matches the smallest known upper bound of 4 by Bonichon et al. on the\nmaximum degree of plane spanners of ${\\cal C}$, while significantly improving\ntheir stretch factor upper bound from 156.82 to 20. The construction of our\nspanner is based on Delaunay triangulations defined with respect to the\nequilateral-triangle distance, and uses a different approach than that used by\nBonichon et al. Our approach leads to a simple and intuitive construction of a\nwell-structured spanner, and reveals useful structural properties of the\nDelaunay triangulations defined with respect to the equilateral-triangle\ndistance.\n  The structure of the constructed spanner implies that when ${\\cal P}$ is in\nconvex position, the maximum degree of this spanner is at most 3. Combining the\nabove degree upper bound with the fact that 3 is a lower bound on the maximum\ndegree of any plane spanner of ${\\cal C}$ when the point-set ${\\cal P}$ is in\nconvex position, the results in this paper give a tight bound of 3 on the\nmaximum degree of plane spanners of ${\\cal C}$ for point-sets in convex\nposition.\n", "versions": [{"version": "v1", "created": "Fri, 11 Mar 2016 23:08:15 GMT"}], "update_date": "2016-03-15", "authors_parsed": [["Kanj", "Iyad", ""], ["Perkovi\u0107", "Ljubomir", ""], ["T\u00fcrko\u01e7lu", "Duru", ""]]}, {"id": "1603.03886", "submitter": "Andrea Cerri", "authors": "Andrea Cerri, Marc Ethier and Patrizio Frosini", "title": "The coherent matching distance in 2D persistent homology", "comments": "11 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG math.AT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Comparison between multidimensional persistent Betti numbers is often based\non the multidimensional matching distance. While this metric is rather simple\nto define and compute by considering a suitable family of filtering functions\nassociated with lines having a positive slope, it has two main drawbacks.\nFirst, it forgets the natural link between the homological properties of\nfiltrations associated with lines that are close to each other. As a\nconsequence, part of the interesting homological information is lost. Second,\nits intrinsically discontinuous definition makes it difficult to study its\nproperties. In this paper we introduce a new matching distance for 2D\npersistent Betti numbers, called coherent matching distance and based on\nmatchings that change coherently with the filtrations we take into account. Its\ndefinition is not trivial, as it must face the presence of monodromy in\nmultidimensional persistence, i.e. the fact that different paths in the space\nparameterizing the above filtrations can induce different matchings between the\nassociated persistent diagrams. In our paper we prove that the coherent 2D\nmatching distance is well-defined and stable.\n", "versions": [{"version": "v1", "created": "Sat, 12 Mar 2016 10:40:23 GMT"}], "update_date": "2016-03-15", "authors_parsed": [["Cerri", "Andrea", ""], ["Ethier", "Marc", ""], ["Frosini", "Patrizio", ""]]}, {"id": "1603.04109", "submitter": "Menghan Wang", "authors": "Meera Sitharam, Mohamad Tarifi, Menghan Wang", "title": "Combinatorial rigidity of Incidence systems and Application to\n  Dictionary learning", "comments": "arXiv admin note: text overlap with arXiv:1503.01837, arXiv:1402.7344", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a hypergraph $H$ with $m$ hyperedges and a set $Q$ of $m$ \\emph{pinning\nsubspaces}, i.e.\\ globally fixed subspaces in Euclidean space $\\mathbb{R}^d$, a\n\\emph{pinned subspace-incidence system} is the pair $(H, Q)$, with the\nconstraint that each pinning subspace in $Q$ is contained in the subspace\nspanned by the point realizations in $\\mathbb{R}^d$ of vertices of the\ncorresponding hyperedge of $H$. This paper provides a combinatorial\ncharacterization of pinned subspace-incidence systems that are \\emph{minimally\nrigid}, i.e.\\ those systems that are guaranteed to generically yield a locally\nunique realization.\n  Pinned subspace-incidence systems have applications in the \\emph{Dictionary\nLearning (aka sparse coding)} problem, i.e.\\ the problem of obtaining a sparse\nrepresentation of a given set of data vectors by learning \\emph{dictionary\nvectors} upon which the data vectors can be written as sparse linear\ncombinations. Viewing the dictionary vectors from a geometry perspective as the\nspanning set of a subspace arrangement, the result gives a tight bound on the\nnumber of dictionary vectors for sufficiently randomly chosen data vectors, and\ngives a way of constructing a dictionary that meets the bound. For less\nstringent restrictions on data, but a natural modification of the dictionary\nlearning problem, a further dictionary learning algorithm is provided. Although\nthere are recent rigidity based approaches for low rank matrix completion, we\nare unaware of prior application of combinatorial rigidity techniques in the\nsetting of Dictionary Learning. We also provide a systematic classification of\nproblems related to dictionary learning together with various algorithms, their\nassumptions and performance.\n", "versions": [{"version": "v1", "created": "Mon, 14 Mar 2016 01:40:40 GMT"}], "update_date": "2016-03-15", "authors_parsed": [["Sitharam", "Meera", ""], ["Tarifi", "Mohamad", ""], ["Wang", "Menghan", ""]]}, {"id": "1603.04210", "submitter": "Aniket Basu Roy", "authors": "Aniket Basu Roy, Anil Maheshwari, Sathish Govindarajan, Neeldhara\n  Misra, Subhas C Nandy, Shreyas Shetty", "title": "The Runaway Rectangle Escape Problem", "comments": "26 pages, 7 figures, A preliminary version appeared in the\n  Proceedings of the 26th Canadian Conference on Computational Geometry, 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the applications of routing in PCB buses, the Rectangle Escape\nProblem was recently introduced and studied. In this problem, we are given a\nset of rectangles $\\mathcal{S}$ in a rectangular region $R$, and we would like\nto extend these rectangles to one of the four sides of $R$. Define the density\nof a point $p$ in $R$ as the number of extended rectangles that contain $p$.\nThe question is then to find an extension with the smallest maximum density.\n  We consider the problem of maximizing the number of rectangles that can be\nextended when the maximum density allowed is at most $d$. It is known that this\nproblem is polynomially solvable for $d = 1$, and NP-hard for any $d \\geq 2$.\nWe consider approximation and exact algorithms for fixed values of $d$. We also\nshow that a very special case of this problem, when all the rectangles are unit\nsquares from a grid, continues to be NP-hard for $d = 2$.\n", "versions": [{"version": "v1", "created": "Mon, 14 Mar 2016 11:21:56 GMT"}, {"version": "v2", "created": "Tue, 15 Mar 2016 10:29:43 GMT"}], "update_date": "2016-03-16", "authors_parsed": [["Roy", "Aniket Basu", ""], ["Maheshwari", "Anil", ""], ["Govindarajan", "Sathish", ""], ["Misra", "Neeldhara", ""], ["Nandy", "Subhas C", ""], ["Shetty", "Shreyas", ""]]}, {"id": "1603.04422", "submitter": "Hossein Sartipizadeh", "authors": "Hossein Sartipizadeh and Tyrone L. Vincent", "title": "Computing the Approximate Convex Hull in High Dimensions", "comments": "5 pages, 1 figure, The more detailed version will be submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG math.MG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, an effective method with time complexity of\n$\\mathcal{O}(K^{3/2}N^2\\log \\frac{K}{\\epsilon_0})$ is introduced to find an\napproximation of the convex hull for $N$ points in dimension $n$, where $K$ is\nclose to the number of vertices of the approximation. Since the time complexity\nis independent of dimension, this method is highly suitable for the data in\nhigh dimensions. Utilizing a greedy approach, the proposed method attempts to\nfind the best approximate convex hull for a given number of vertices. The\napproximate convex hull can be a helpful substitute for the exact convex hull\nfor on-line processes and applications that have a favorable trade off between\naccuracy and parsimony.\n", "versions": [{"version": "v1", "created": "Tue, 8 Mar 2016 22:20:02 GMT"}], "update_date": "2016-03-15", "authors_parsed": [["Sartipizadeh", "Hossein", ""], ["Vincent", "Tyrone L.", ""]]}, {"id": "1603.04582", "submitter": "Laurent Buse", "authors": "Laurent Bus\\'e (GALAAD2), Andr\\'e Galligo (JAD, GALAAD2), Jiajun Zhang\n  (GALAAD2)", "title": "Extraction of cylinders and cones from minimal point sets", "comments": null, "journal-ref": "Graphical Models, Elsevier, 2016, 86, pp.1-12", "doi": null, "report-no": null, "categories": "cs.CG cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose new algebraic methods for extracting cylinders and cones from\nminimal point sets, including oriented points. More precisely, we are\ninterested in computing efficiently cylinders through a set of three points,\none of them being oriented, or through a set of five simple points. We are also\ninterested in computing efficiently cones through a set of two oriented points,\nthrough a set of four points, one of them being oriented, or through a set of\nsix points. For these different interpolation problems, we give optimal bounds\non the number of solutions. Moreover, we describe algebraic methods targeted to\nsolve these problems efficiently.\n", "versions": [{"version": "v1", "created": "Tue, 15 Mar 2016 07:37:29 GMT"}, {"version": "v2", "created": "Tue, 21 Jun 2016 08:36:41 GMT"}], "update_date": "2016-06-22", "authors_parsed": [["Bus\u00e9", "Laurent", "", "GALAAD2"], ["Galligo", "Andr\u00e9", "", "JAD, GALAAD2"], ["Zhang", "Jiajun", "", "GALAAD2"]]}, {"id": "1603.05310", "submitter": "Vinay Venkataraman", "authors": "Vinay Venkataraman, Karthikeyan Natesan Ramamurthy, and Pavan Turaga", "title": "Persistent Homology of Attractors For Action Recognition", "comments": "5 pages, Under review in International Conference on Image Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel framework for dynamical analysis of human\nactions from 3D motion capture data using topological data analysis. We model\nhuman actions using the topological features of the attractor of the dynamical\nsystem. We reconstruct the phase-space of time series corresponding to actions\nusing time-delay embedding, and compute the persistent homology of the\nphase-space reconstruction. In order to better represent the topological\nproperties of the phase-space, we incorporate the temporal adjacency\ninformation when computing the homology groups. The persistence of these\nhomology groups encoded using persistence diagrams are used as features for the\nactions. Our experiments with action recognition using these features\ndemonstrate that the proposed approach outperforms other baseline methods.\n", "versions": [{"version": "v1", "created": "Wed, 16 Mar 2016 23:15:50 GMT"}], "update_date": "2016-03-18", "authors_parsed": [["Venkataraman", "Vinay", ""], ["Ramamurthy", "Karthikeyan Natesan", ""], ["Turaga", "Pavan", ""]]}, {"id": "1603.05579", "submitter": "Quentin M\\'erigot", "authors": "Jun Kitagawa, Quentin M\\'erigot, Boris Thibert", "title": "Convergence of a Newton algorithm for semi-discrete optimal transport", "comments": "45 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.CG math.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many problems in geometric optics or convex geometry can be recast as optimal\ntransport problems: this includes the far-field reflector problem, Alexandrov's\ncurvature prescription problem, etc. A popular way to solve these problems\nnumerically is to assume that the source probability measure is absolutely\ncontinuous while the target measure is finitely supported. We refer to this\nsetting as semi-discrete optimal transport. Among the several algorithms\nproposed to solve semi-discrete optimal transport problems, one currently needs\nto choose between algorithms that are slow but come with a convergence speed\nanalysis (e.g. Oliker-Prussner) or algorithms that are much faster in practice\nbut which come with no convergence guarantees Algorithms of the first kind rely\non coordinate-wise increments and the number of iterations required to reach\nthe solution up to an error of $\\epsilon$ is of order $N^3/\\epsilon$, where $N$\nis the number of Dirac masses in the target measure. On the other hand,\nalgorithms of the second kind typically rely on the formulation of the\nsemi-discrete optimal transport problem as an unconstrained convex optimization\nproblem which is solved using a Newton or quasi-Newton method.\n  The purpose of this article is to bridge this gap between theory and practice\nby introducing a damped Newton's algorithm which is experimentally efficient\nand by proving the global convergence of this algorithm with optimal rates. The\nmain assumptions is that the cost function satisfies a condition that appears\nin the regularity theory for optimal transport (the Ma-Trudinger-Wang\ncondition) and that the support of the source density is connected in a\nquantitative way (it must satisfy a weighted Poincar\\'e-Wirtinger inequality).\n", "versions": [{"version": "v1", "created": "Thu, 17 Mar 2016 17:22:42 GMT"}, {"version": "v2", "created": "Tue, 7 Mar 2017 11:01:12 GMT"}], "update_date": "2017-03-08", "authors_parsed": [["Kitagawa", "Jun", ""], ["M\u00e9rigot", "Quentin", ""], ["Thibert", "Boris", ""]]}, {"id": "1603.05609", "submitter": "Milica Bogicevic", "authors": "Milica Bogicevic, Milan Merkle", "title": "ABCDepth: efficient algorithm for Tukey depth", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new algorithm for Tukey (halfspace) depth level sets and its\nimplementation. Given $d$-dimensional data set for any $d\\geq 2$, the algorithm\nis based on representation of level sets as intersections of balls in $R^d$,\nand can be easily adapted to related depths (Type D, Zuo and Serfling (Ann.\nStat. {\\bf 28} (2000), 461--482)). The algorithm complexity is $O(dn^2 +\nn^2\\log{n})$ where $n$ is the data set size. Examples with real and synthetic\ndata show that the algorithm is much faster than other implemented algorithms\nand that it can accept thousands of multidimensional observations, while other\nalgorithms are tested with two-dimensional data or with a couple of hundreds\nmultidimensional observations.\n", "versions": [{"version": "v1", "created": "Thu, 17 Mar 2016 18:47:30 GMT"}, {"version": "v2", "created": "Tue, 15 Nov 2016 15:43:27 GMT"}], "update_date": "2016-11-16", "authors_parsed": [["Bogicevic", "Milica", ""], ["Merkle", "Milan", ""]]}, {"id": "1603.05717", "submitter": "Boris Bukh", "authors": "Boris Bukh, Gabriel Nivasch", "title": "One-sided epsilon-approximants", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Given a finite point set $P\\subset\\mathbb{R}^d$, we call a multiset $A$ a\none-sided weak $\\varepsilon$-approximant for $P$ (with respect to convex sets),\nif $|P\\cap C|/|P|-|A\\cap C|/|A|\\leq\\varepsilon$ for every convex set $C$.\n  We show that, in contrast with the usual (two-sided) weak\n$\\varepsilon$-approximants, for every set $P\\subset \\mathbb{R}^d$ there exists\na one-sided weak $\\varepsilon$-approximant of size bounded by a function of\n$\\varepsilon$ and $d$.\n", "versions": [{"version": "v1", "created": "Thu, 17 Mar 2016 22:44:50 GMT"}, {"version": "v2", "created": "Fri, 27 May 2016 23:50:16 GMT"}], "update_date": "2016-05-31", "authors_parsed": [["Bukh", "Boris", ""], ["Nivasch", "Gabriel", ""]]}, {"id": "1603.05944", "submitter": "Daniela Maftuleac", "authors": "Aditya Kumar Akash, Sandor P. Fekete, Seoung Kyou Lee, Alejandro\n  Lopez-Ortiz, Daniela Maftuleac, James McLurkin", "title": "Lower Bounds for Graph Exploration Using Local Policies", "comments": "arXiv admin note: text overlap with arXiv:1410.2295", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give lower bounds for various natural node- and edge-based local\nstrategies for exploring a graph. We consider this problem both in the setting\nof an arbitrary graph as well as the abstraction of a geometric exploration of\na space by a robot, both of which have been extensively studied. We consider\nlocal exploration policies that use time-of-last- visit or alternatively\nleast-frequently-visited local greedy strategies to select the next step in the\nexploration path. Both of these strategies were previously considered by Cooper\net al. (2011) for a scenario in which counters for the last visit or visit\nfrequency are attached to the edges. In this work we consider the case in which\nthe counters are associated with the nodes, which for the case of dual graphs\nof geometric spaces could be argued to be intuitively more natural and likely\nmore efficient. Surprisingly, these alternate strategies give worst-case\nsuperpolynomial/ exponential time for exploration, whereas the least-frequently\nvisited strategy for edges has a polynomially bounded exploration time, as\nshown by Cooper et al. (2011).\n", "versions": [{"version": "v1", "created": "Fri, 18 Mar 2016 18:01:16 GMT"}], "update_date": "2016-03-21", "authors_parsed": [["Akash", "Aditya Kumar", ""], ["Fekete", "Sandor P.", ""], ["Lee", "Seoung Kyou", ""], ["Lopez-Ortiz", "Alejandro", ""], ["Maftuleac", "Daniela", ""], ["McLurkin", "James", ""]]}, {"id": "1603.06077", "submitter": "Sandor P. Fekete", "authors": "S\\'andor P. Fekete, Kan Huang, Joseph S. B. Mitchell, Ojas Parekh,\n  Cynthia A. Phillips", "title": "Geometric Hitting Set for Segments of Few Orientations", "comments": "35 pages, 10 figures; full journal version (to appear in Theory of\n  Computing Systems) of conference paper that appears in WAOA 2015, pp. 145-157", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study several natural instances of the geometric hitting set problem for\ninput consisting of sets of line segments (and rays, lines) having a small\nnumber of distinct slopes. These problems model path monitoring (e.g., on road\nnetworks) using the fewest sensors (the \"hitting points\"). We give\napproximation algorithms for cases including (i) lines of 3 slopes in the\nplane, (ii) vertical lines and horizontal segments, (iii) pairs of\nhorizontal/vertical segments. We give hardness and hardness of approximation\nresults for these problems. We prove that the hitting set problem for vertical\nlines and horizontal rays is polynomially solvable.\n", "versions": [{"version": "v1", "created": "Sat, 19 Mar 2016 10:21:30 GMT"}, {"version": "v2", "created": "Sat, 17 Dec 2016 20:58:22 GMT"}], "update_date": "2016-12-20", "authors_parsed": [["Fekete", "S\u00e1ndor P.", ""], ["Huang", "Kan", ""], ["Mitchell", "Joseph S. B.", ""], ["Parekh", "Ojas", ""], ["Phillips", "Cynthia A.", ""]]}, {"id": "1603.06252", "submitter": "Frank Staals", "authors": "Arthur van Goethem, Marc van Kreveld, Maarten L\\\"offler, Bettina\n  Speckmann, Frank Staals", "title": "Grouping Time-varying Data for Interactive Exploration", "comments": "Full version of our SoCG 2016 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present algorithms and data structures that support the interactive\nanalysis of the grouping structure of one-, two-, or higher-dimensional\ntime-varying data while varying all defining parameters. Grouping structures\ncharacterise important patterns in the temporal evaluation of sets of\ntime-varying data. We follow Buchin et al. [JoCG 2015] who define groups using\nthree parameters: group-size, group-duration, and inter-entity distance. We\ngive upper and lower bounds on the number of maximal groups over all parameter\nvalues, and show how to compute them efficiently. Furthermore, we describe data\nstructures that can report changes in the set of maximal groups in an\noutput-sensitive manner. Our results hold in $\\mathbb{R}^d$ for fixed $d$.\n", "versions": [{"version": "v1", "created": "Sun, 20 Mar 2016 18:42:12 GMT"}], "update_date": "2016-03-22", "authors_parsed": [["van Goethem", "Arthur", ""], ["van Kreveld", "Marc", ""], ["L\u00f6ffler", "Maarten", ""], ["Speckmann", "Bettina", ""], ["Staals", "Frank", ""]]}, {"id": "1603.06764", "submitter": "Javier Tejel", "authors": "Merc\\`e Claverol, Alfredo Garc\\'ia, Delia Garijo, Carlos Seara and\n  Javier Tejel", "title": "On Hamiltonian alternating cycles and paths", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We undertake a study on computing Hamiltonian alternating cycles and paths on\nbicolored point sets. This has been an intensively studied problem, not always\nwith a solution, when the paths and cycles are also required to be plane. In\nthis paper, we relax the constraint on the cycles and paths from being plane to\nbeing 1-plane, and deal with the same type of questions as those for the plane\ncase, obtaining a remarkable variety of results. Among them, we prove that a\n1-plane Hamiltonian alternating cycle on a bicolored point set in general\nposition can always be obtained, and that when the point set is in convex\nposition, every Hamiltonian alternating cycle with minimum number of crossings\nis 1-plane. Further, for point sets in convex position, we provide $O(n)$ and\n$O(n^2)$ time algorithms for computing, respectively, Hamiltonian alternating\ncycles and paths with minimum number of crossings.\n", "versions": [{"version": "v1", "created": "Tue, 22 Mar 2016 12:42:29 GMT"}, {"version": "v2", "created": "Fri, 31 Mar 2017 07:26:03 GMT"}], "update_date": "2017-04-03", "authors_parsed": [["Claverol", "Merc\u00e8", ""], ["Garc\u00eda", "Alfredo", ""], ["Garijo", "Delia", ""], ["Seara", "Carlos", ""], ["Tejel", "Javier", ""]]}, {"id": "1603.06972", "submitter": "Irina Kostitsyna", "authors": "Irina Kostitsyna and Maarten L\\\"offler and Valentin Polishchuk and\n  Frank Staals", "title": "On the complexity of minimum-link path problems", "comments": "An abridged version of this paper appeared in the proceedings of the\n  32nd International Symposium on Computational Geometry in 2016", "journal-ref": null, "doi": "10.20382/jocg.v8i2a5", "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the minimum-link path problem: Given a polyhedral domain and two\npoints in it, connect the points by a polygonal path with minimum number of\nedges. We consider settings where the vertices and/or the edges of the path are\nrestricted to lie on the boundary of the domain, or can be in its interior. Our\nresults include bit complexity bounds, a novel general hardness construction,\nand a polynomial-time approximation scheme. We fully characterize the situation\nin 2D, and provide first results in dimensions 3 and higher for several\nvariants of the problem.\n  Concretely, our results resolve several open problems. We prove that\ncomputing the minimum-link diffuse reflection path, motivated by ray tracing in\ncomputer graphics, is NP-hard, even for two-dimensional polygonal domains with\nholes. This has remained an open problem [1] despite a large body of work on\nthe topic. We also resolve the open problem from [2] mentioned in the handbook\n[3] (see Chapter 27.5, Open problem 3) and The Open Problems Project [4] (see\nProblem 22): \"What is the complexity of the minimum-link path problem in\n3-space?\" Our results imply that the problem is NP-hard even on terrains (and\nhence, due to discreteness of the answer, there is no FPTAS unless P=NP), but\nadmits a PTAS.\n", "versions": [{"version": "v1", "created": "Tue, 22 Mar 2016 20:41:16 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Kostitsyna", "Irina", ""], ["L\u00f6ffler", "Maarten", ""], ["Polishchuk", "Valentin", ""], ["Staals", "Frank", ""]]}, {"id": "1603.07021", "submitter": "Jie Xue", "authors": "Jie Xue, Yuan Li, Ravi Janardan", "title": "On the Separability of Stochastic Geometric Objects, with Applications", "comments": "Full version of our SoCG 2016 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the linear separability problem for stochastic\ngeometric objects under the well-known unipoint/multipoint uncertainty models.\nLet $S=S_R \\cup S_B$ be a given set of stochastic bichromatic points, and\ndefine $n = \\min\\{|S_R|, |S_B|\\}$ and $N = \\max\\{|S_R|, |S_B|\\}$. We show that\nthe separable-probability (SP) of $S$ can be computed in $O(nN^{d-1})$ time for\n$d \\geq 3$ and $O(\\min\\{nN \\log N, N^2\\})$ time for $d=2$, while the expected\nseparation-margin (ESM) of $S$ can be computed in $O(nN^{d})$ time for $d \\geq\n2$. In addition, we give an $\\Omega(nN^{d-1})$ witness-based lower bound for\ncomputing SP, which implies the optimality of our algorithm among all those in\nthis category. Also, a hardness result for computing ESM is given to show the\ndifficulty of further improving our algorithm. As an extension, we generalize\nthe same problems from points to general geometric objects, i.e., polytopes\nand/or balls, and extend our algorithms to solve the generalized SP and ESM\nproblems in $O(nN^{d})$ and $O(nN^{d+1})$ time, respectively. Finally, we\npresent some applications of our algorithms to stochastic convex-hull related\nproblems.\n", "versions": [{"version": "v1", "created": "Tue, 22 Mar 2016 22:51:55 GMT"}, {"version": "v2", "created": "Tue, 5 Apr 2016 02:54:37 GMT"}], "update_date": "2016-04-06", "authors_parsed": [["Xue", "Jie", ""], ["Li", "Yuan", ""], ["Janardan", "Ravi", ""]]}, {"id": "1603.07077", "submitter": "Sandor P. Fekete", "authors": "S\\'andor P. Fekete, Andreas Haas, Michael Hemmer, Michael Hoffmann,\n  Irina Kostitsyna, Dominik Krupke, Florian Maurer, Joseph S. B. Mitchell, Arne\n  Schmidt, Christiane Schmidt, and Julian Troegel", "title": "Computing Nonsimple Polygons of Minimum Perimeter", "comments": "24 pages, 21 figures, 1 table; full version of extended abstract that\n  is to appear in SEA 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide exact and approximation methods for solving a geometric relaxation\nof the Traveling Salesman Problem (TSP) that occurs in curve reconstruction:\nfor a given set of vertices in the plane, the problem Minimum Perimeter Polygon\n(MPP) asks for a (not necessarily simply connected) polygon with shortest\npossible boundary length. Even though the closely related problem of finding a\nminimum cycle cover is polynomially solvable by matching techniques, we prove\nhow the topological structure of a polygon leads to NP-hardness of the MPP. On\nthe positive side, we show how to achieve a constant-factor approximation.\n  When trying to solve MPP instances to provable optimality by means of integer\nprogramming, an additional difficulty compared to the TSP is the fact that only\na subset of subtour constraints is valid, depending not on combinatorics, but\non geometry. We overcome this difficulty by establishing and exploiting\nadditional geometric properties. This allows us to reliably solve a wide range\nof benchmark instances with up to 600 vertices within reasonable time on a\nstandard machine. We also show that using a natural geometry-based\nsparsification yields results that are on average within 0.5% of the optimum.\n", "versions": [{"version": "v1", "created": "Wed, 23 Mar 2016 06:25:07 GMT"}], "update_date": "2016-03-24", "authors_parsed": [["Fekete", "S\u00e1ndor P.", ""], ["Haas", "Andreas", ""], ["Hemmer", "Michael", ""], ["Hoffmann", "Michael", ""], ["Kostitsyna", "Irina", ""], ["Krupke", "Dominik", ""], ["Maurer", "Florian", ""], ["Mitchell", "Joseph S. B.", ""], ["Schmidt", "Arne", ""], ["Schmidt", "Christiane", ""], ["Troegel", "Julian", ""]]}, {"id": "1603.07269", "submitter": "G\\\"unter Rote", "authors": "Heuna Kim and G\\\"unter Rote", "title": "Congruence Testing of Point Sets in 4 Dimensions", "comments": "41 pages, 6 figures. This is the full version accompanying our paper\n  \"Congruence testing of point sets in 4-space\" that is to apper at the 32st\n  International Symposium on Computational Geometry (SoCG 2016), (LIPIcs\n  proceedings series)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Congruence between two n-point sets in 4 dimension can be checked in O(n log\nn) time. On the way to establishing this result, we revisit several parts of\n4-dimensional geometry, such as angles and distances between planes, Hopf\nfibrations, and Coxeter groups.\n", "versions": [{"version": "v1", "created": "Wed, 23 Mar 2016 16:59:21 GMT"}], "update_date": "2016-03-24", "authors_parsed": [["Kim", "Heuna", ""], ["Rote", "G\u00fcnter", ""]]}, {"id": "1603.07282", "submitter": "Edvin Berglin", "authors": "Peyman Afshani, Edvin Berglin, Ingo van Duijn, Jesper Sindahl Nielsen", "title": "Applications of incidence bounds in point covering problems", "comments": "SoCG 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the Line Cover problem a set of n points is given and the task is to cover\nthe points using either the minimum number of lines or at most k lines. In\nCurve Cover, a generalization of Line Cover, the task is to cover the points\nusing curves with d degrees of freedom. Another generalization is the\nHyperplane Cover problem where points in d-dimensional space are to be covered\nby hyperplanes. All these problems have kernels of polynomial size, where the\nparameter is the minimum number of lines, curves, or hyperplanes needed. First\nwe give a non-parameterized algorithm for both problems in O*(2^n) (where the\nO*(.) notation hides polynomial factors of n) time and polynomial space,\nbeating a previous exponential-space result. Combining this with incidence\nbounds similar to the famous Szemeredi-Trotter bound, we present a Curve Cover\nalgorithm with running time O*((Ck/log k)^((d-1)k)), where C is some constant.\nOur result improves the previous best times O*((k/1.35)^k) for Line Cover\n(where d=2), O*(k^(dk)) for general Curve Cover, as well as a few other bounds\nfor covering points by parabolas or conics. We also present an algorithm for\nHyperplane Cover in R^3 with running time O*((Ck^2/log^(1/5) k)^k), improving\non the previous time of O*((k^2/1.3)^k).\n", "versions": [{"version": "v1", "created": "Wed, 23 Mar 2016 17:35:54 GMT"}], "update_date": "2016-03-24", "authors_parsed": [["Afshani", "Peyman", ""], ["Berglin", "Edvin", ""], ["van Duijn", "Ingo", ""], ["Nielsen", "Jesper Sindahl", ""]]}, {"id": "1603.07340", "submitter": "Tillmann Miltzow", "authors": "D\\'aniel Marx and Tillmann Miltzow", "title": "Peeling and Nibbling the Cactus: Subexponential-Time Algorithms for\n  Counting Triangulations and Related Problems", "comments": "47 pages, 23 Figures, to appear in SoCG 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DM cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a set of $n$ points $S$ in the plane, a triangulation $T$ of $S$ is a\nmaximal set of non-crossing segments with endpoints in $S$. We present an\nalgorithm that computes the number of triangulations on a given set of $n$\npoints in time $n^{(11+ o(1))\\sqrt{n} }$, significantly improving the previous\nbest running time of $O(2^n n^2)$ by Alvarez and Seidel [SoCG 2013]. Our main\ntool is identifying separators of size $O(\\sqrt{n})$ of a triangulation in a\ncanonical way. The definition of the separators are based on the decomposition\nof the triangulation into nested layers (\"cactus graphs\"). Based on the above\nalgorithm, we develop a simple and formal framework to count other non-crossing\nstraight-line graphs in $n^{O(\\sqrt{n})}$ time. We demonstrate the usefulness\nof the framework by applying it to counting non-crossing Hamilton cycles,\nspanning trees, perfect matchings, $3$-colorable triangulations, connected\ngraphs, cycle decompositions, quadrangulations, $3$-regular graphs, and more.\n", "versions": [{"version": "v1", "created": "Wed, 23 Mar 2016 20:12:41 GMT"}], "update_date": "2016-08-06", "authors_parsed": [["Marx", "D\u00e1niel", ""], ["Miltzow", "Tillmann", ""]]}, {"id": "1603.07401", "submitter": "Csaba D. Toth", "authors": "Hugo Akitaya, Greg Aloupis, Jeff Erickson, Csaba D. T\\'oth", "title": "Recognizing Weakly Simple Polygons", "comments": "35 pages, 28 figures. A 15-page extended abstract has appeared in the\n  Proceeding of the 32nd International Symposium on Computational Geometry\n  (Boston, MA, 2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an $O(n\\log n)$-time algorithm that determines whether a given\nplanar $n$-gon is weakly simple. This improves upon an $O(n^2\\log n)$-time\nalgorithm by Chang, Erickson, and Xu (2015). Weakly simple polygons are\nrequired as input for several geometric algorithms. As such, how to recognize\nsimple or weakly simple polygons is a fundamental question.\n", "versions": [{"version": "v1", "created": "Thu, 24 Mar 2016 00:53:05 GMT"}, {"version": "v2", "created": "Sun, 30 Jul 2017 12:11:28 GMT"}], "update_date": "2017-08-01", "authors_parsed": [["Akitaya", "Hugo", ""], ["Aloupis", "Greg", ""], ["Erickson", "Jeff", ""], ["T\u00f3th", "Csaba D.", ""]]}, {"id": "1603.07737", "submitter": "Michael Hoffmann", "authors": "Markus Geyer, Michael Hoffmann, Michael Kaufmann, Vincent Kusters,\n  Csaba D. T\\'oth", "title": "The Planar Tree Packing Theorem", "comments": "Full version of our SoCG 2016 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Packing graphs is a combinatorial problem where several given graphs are\nbeing mapped into a common host graph such that every edge is used at most\nonce. In the planar tree packing problem we are given two trees T1 and T2 on n\nvertices and have to find a planar graph on n vertices that is the\nedge-disjoint union of T1 and T2. A clear exception that must be made is the\nstar which cannot be packed together with any other tree. But according to a\nconjecture of Garc\\'ia et al. from 1997 this is the only exception, and all\nother pairs of trees admit a planar packing. Previous results addressed various\nspecial cases, such as a tree and a spider tree, a tree and a caterpillar, two\ntrees of diameter four, two isomorphic trees, and trees of maximum degree\nthree. Here we settle the conjecture in the affirmative and prove its general\nform, thus making it the planar tree packing theorem. The proof is constructive\nand provides a polynomial time algorithm to obtain a packing for two given\nnonstar trees.\n", "versions": [{"version": "v1", "created": "Thu, 24 Mar 2016 20:08:38 GMT"}], "update_date": "2016-03-28", "authors_parsed": [["Geyer", "Markus", ""], ["Hoffmann", "Michael", ""], ["Kaufmann", "Michael", ""], ["Kusters", "Vincent", ""], ["T\u00f3th", "Csaba D.", ""]]}, {"id": "1603.08116", "submitter": "\\'Edouard Bonnet", "authors": "\\'Edouard Bonnet and Tillmann Miltzow", "title": "The Parameterized Hardness of Art Gallery Problems", "comments": "23 pages, 12 figures. Journal version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a simple polygon $\\mathcal{P}$ on $n$ vertices, two points $x,y$ in\n$\\mathcal{P}$ are said to be visible to each other if the line segment between\n$x$ and $y$ is contained in $\\mathcal{P}$. The Point Guard Art Gallery problem\nasks for a minimum set $S$ such that every point in $\\mathcal{P}$ is visible\nfrom a point in $S$. The Vertex Guard Art Gallery problem asks for such a set\n$S$ subset of the vertices of $\\mathcal{P}$. A point in the set $S$ is referred\nto as a guard. For both variants, we rule out any $f(k)n^{o(k / \\log k)}$\nalgorithm, where $k := |S|$ is the number of guards, for any computable\nfunction $f$, unless the Exponential Time Hypothesis fails. These lower bounds\nalmost match the $n^{O(k)}$ algorithms that exist for both problems.\n", "versions": [{"version": "v1", "created": "Sat, 26 Mar 2016 15:13:17 GMT"}, {"version": "v2", "created": "Sun, 24 Dec 2017 12:29:55 GMT"}, {"version": "v3", "created": "Mon, 22 Jun 2020 14:17:26 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Bonnet", "\u00c9douard", ""], ["Miltzow", "Tillmann", ""]]}, {"id": "1603.08151", "submitter": "L\\'aszl\\'o Kozma", "authors": "L\\'aszl\\'o Kozma, Thatchaphol Saranurak", "title": "Binary search trees and rectangulations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the classical problem of searching in a binary search tree (BST)\nusing rotations, and present novel connections of this problem to a number of\ngeometric and combinatorial structures. In particular, we show that the\nexecution trace of a BST that serves a sequence of queries is in close\ncorrespondence with the flip-sequence between two rectangulations.\n(Rectangulations are well-studied combinatorial objects also known as mosaic\nfloorplans.) We also reinterpret Small Manhattan Network, a problem with known\nconnections to the BST problem, in terms of flips in rectangulations. We apply\nfurther transformations to the obtained geometric model, to arrive at a\nparticularly simple view of the BST problem that resembles sequences of\nedge-relaxations in a shortest path algorithm.\n  Our connections yield new results and observations for all structures\nconcerned. In this draft we present some preliminary findings. BSTs with\nrotations are among the most fundamental and most thoroughly studied objects in\ncomputer science, nonetheless they pose long-standing open questions, such as\nthe dynamic optimality conjecture of Sleator and Tarjan (STOC 1983). Our hope\nis that the correspondences presented in this paper provide a new perspective\non this old problem and bring new tools to the study of dynamic optimality.\n", "versions": [{"version": "v1", "created": "Sat, 26 Mar 2016 22:49:46 GMT"}], "update_date": "2016-03-29", "authors_parsed": [["Kozma", "L\u00e1szl\u00f3", ""], ["Saranurak", "Thatchaphol", ""]]}, {"id": "1603.08367", "submitter": "Markus Thom", "authors": "Markus Thom and G\\\"unther Palm", "title": "Sparse Activity and Sparse Connectivity in Supervised Learning", "comments": "See http://jmlr.org/papers/v14/thom13a.html for the authoritative\n  version", "journal-ref": "Journal of Machine Learning Research, vol. 14, pp. 1091-1143, 2013", "doi": null, "report-no": null, "categories": "cs.LG cs.CG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparseness is a useful regularizer for learning in a wide range of\napplications, in particular in neural networks. This paper proposes a model\ntargeted at classification tasks, where sparse activity and sparse connectivity\nare used to enhance classification capabilities. The tool for achieving this is\na sparseness-enforcing projection operator which finds the closest vector with\na pre-defined sparseness for any given vector. In the theoretical part of this\npaper, a comprehensive theory for such a projection is developed. In\nconclusion, it is shown that the projection is differentiable almost everywhere\nand can thus be implemented as a smooth neuronal transfer function. The entire\nmodel can hence be tuned end-to-end using gradient-based methods. Experiments\non the MNIST database of handwritten digits show that classification\nperformance can be boosted by sparse activity or sparse connectivity. With a\ncombination of both, performance can be significantly better compared to\nclassical non-sparse approaches.\n", "versions": [{"version": "v1", "created": "Mon, 28 Mar 2016 12:06:49 GMT"}], "update_date": "2016-04-19", "authors_parsed": [["Thom", "Markus", ""], ["Palm", "G\u00fcnther", ""]]}, {"id": "1603.08485", "submitter": "Sarah Allen", "authors": "Sarah R. Allen, Luis Barba, John Iacono, Stefan Langerman", "title": "Incremental Voronoi Diagrams", "comments": "19 pages, SoCG 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the amortized number of combinatorial changes (edge insertions and\nremovals) needed to update the graph structure of the Voronoi diagram\n$\\mathcal{V}(S)$ (and several variants thereof) of a set $S$ of $n$ sites in\nthe plane as sites are added.\n  We define a general update operation for planar graphs modeling the\nincremental construction of several variants of Voronoi diagrams as well as the\nincremental construction of an intersection of halfspaces in $\\mathbb{R}^3$. We\nshow that the amortized number of edge insertions and removals needed to add a\nnew site is $O(\\sqrt{n})$. A matching $\\Omega(\\sqrt{n})$ combinatorial lower\nbound is shown, even in the case where the graph of the diagram is a tree. This\ncontrasts with the $O(\\log{n})$ upper bound of Aronov et al. (2006) for\nfarthest-point Voronoi diagrams when the points are inserted in order along\ntheir convex hull.\n  We present a semi-dynamic data structure that maintains the Voronoi diagram\nof a set $S$ of $n$ sites in convex position. This structure supports the\ninsertion of a new site $p$ and finds the asymptotically minimal number $K$ of\nedge insertions and removals needed to obtain the diagram of $S \\cup \\{p\\}$\nfrom the diagram of $S$, in time $O(K\\,\\mathrm{polylog}\\ n)$ worst case, which\nis $O(\\sqrt{n}\\;\\mathrm{polylog}\\ n)$ amortized by the aforementioned result.\n  The most distinctive feature of this data structure is that the graph of the\nVoronoi diagram is maintained at all times and can be traversed in the natural\nway; this contrasts with other known data structures supporting nearest\nneighbor queries. Our data structure supports general search operations on the\ncurrent Voronoi diagram, which can, for example, be used to perform point\nlocation queries in the cells of the current Voronoi diagram in $O(\\log n)$\ntime, or to determine whether two given sites are neighbors in the Delaunay\ntriangulation.\n", "versions": [{"version": "v1", "created": "Mon, 28 Mar 2016 18:59:36 GMT"}], "update_date": "2016-03-29", "authors_parsed": [["Allen", "Sarah R.", ""], ["Barba", "Luis", ""], ["Iacono", "John", ""], ["Langerman", "Stefan", ""]]}, {"id": "1603.08976", "submitter": "Zachary Friggstad", "authors": "Zachary Friggstad, Mohsen Rezapour, and Mohammad R. Salavatipour", "title": "Local Search Yields a PTAS for k-Means in Doubling Metrics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The most well known and ubiquitous clustering problem encountered in nearly\nevery branch of science is undoubtedly $k$-means: given a set of data points\nand a parameter $k$, select $k$ centres and partition the data points into $k$\nclusters around these centres so that the sum of squares of distances of the\npoints to their cluster centre is minimized. Typically these data points lie\n$\\mathbb{R}^d$ for some $d\\geq 2$.\n  $k$-means and the first algorithms for it were introduced in the 1950's.\nSince then, hundreds of papers have studied this problem and many algorithms\nhave been proposed for it. The most commonly used algorithm is known as\nLloyd-Forgy, which is also referred to as \"the\" $k$-means algorithm, and\nvarious extensions of it often work very well in practice. However, they may\nproduce solutions whose cost is arbitrarily large compared to the optimum\nsolution. Kanungo et al. [2004] analyzed a simple local search heuristic to get\na polynomial-time algorithm with approximation ratio $9+\\epsilon$ for any fixed\n$\\epsilon>0$ for $k$-means in Euclidean space.\n  Finding an algorithm with a better approximation guarantee has remained one\nof the biggest open questions in this area, in particular whether one can get a\ntrue PTAS for fixed dimension Euclidean space. We settle this problem by\nshowing that a simple local search algorithm provides a PTAS for $k$-means in\n$\\mathbb{R}^d$ for any fixed $d$. More precisely, for any error parameter\n$\\epsilon>0$, the local search algorithm that considers swaps of up to\n$\\rho=d^{O(d)}\\cdot{\\epsilon}^{-O(d/\\epsilon)}$ centres at a time finds a\nsolution using exactly $k$ centres whose cost is at most a\n$(1+\\epsilon)$-factor greater than the optimum.\n  Finally, we provide the first demonstration that local search yields a PTAS\nfor the uncapacitated facility location problem and $k$-median with non-uniform\nopening costs in doubling metrics.\n", "versions": [{"version": "v1", "created": "Tue, 29 Mar 2016 21:41:55 GMT"}, {"version": "v2", "created": "Mon, 9 Jan 2017 20:00:19 GMT"}], "update_date": "2017-01-11", "authors_parsed": [["Friggstad", "Zachary", ""], ["Rezapour", "Mohsen", ""], ["Salavatipour", "Mohammad R.", ""]]}, {"id": "1603.09535", "submitter": "Vincent Cohen-Addad", "authors": "Vincent Cohen-Addad and Philip N. Klein and Claire Mathieu", "title": "Local search yields approximation schemes for k-means and k-median in\n  Euclidean and minor-free metrics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give the first polynomial-time approximation schemes (PTASs) for the\nfollowing problems: (1) uniform facility location in edge-weighted planar\ngraphs; (2) $k$-median and $k$-means in edge-weighted planar graphs; (3)\n$k$-means in Euclidean spaces of bounded dimension. Our first and second\nresults extend to minor-closed families of graphs. All our results extend to\ncost functions that are the $p$-th power of the shortest-path distance. The\nalgorithm is local search where the local neighborhood of a solution $S$\nconsists of all solutions obtained from $S$ by removing and adding\n$1/\\epsilon^{O(1)}$ centers.\n", "versions": [{"version": "v1", "created": "Thu, 31 Mar 2016 11:40:07 GMT"}, {"version": "v2", "created": "Thu, 7 Apr 2016 07:53:51 GMT"}], "update_date": "2016-04-08", "authors_parsed": [["Cohen-Addad", "Vincent", ""], ["Klein", "Philip N.", ""], ["Mathieu", "Claire", ""]]}, {"id": "1603.09596", "submitter": "Georgios Samaras", "authors": "Yannis Avrithis, Ioannis Z. Emiris, and Georgios Samaras", "title": "High-dimensional approximate nearest neighbor: k-d Generalized\n  Randomized Forests", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new data-structure, the generalized randomized kd forest, or\nkgeraf, for approximate nearest neighbor searching in high dimensions. In\nparticular, we introduce new randomization techniques to specify a set of\nindependently constructed trees where search is performed simultaneously, hence\nincreasing accuracy. We omit backtracking, and we optimize distance\ncomputations, thus accelerating queries. We release public domain software\ngeraf and we compare it to existing implementations of state-of-the-art methods\nincluding BBD-trees, Locality Sensitive Hashing, randomized kd forests, and\nproduct quantization. Experimental results indicate that our method would be\nthe method of choice in dimensions around 1,000, and probably up to 10,000, and\npointsets of cardinality up to a few hundred thousands or even one million;\nthis range of inputs is encountered in many critical applications today. For\ninstance, we handle a real dataset of $10^6$ images represented in 960\ndimensions with a query time of less than $1$sec on average and 90\\% responses\nbeing true nearest neighbors.\n", "versions": [{"version": "v1", "created": "Thu, 31 Mar 2016 14:04:30 GMT"}], "update_date": "2016-04-01", "authors_parsed": [["Avrithis", "Yannis", ""], ["Emiris", "Ioannis Z.", ""], ["Samaras", "Georgios", ""]]}]