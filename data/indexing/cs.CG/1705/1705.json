[{"id": "1705.00274", "submitter": "Sibel Tari", "authors": "Asli Genctav, Yusuf Sahillioglu, and Sibel Tari", "title": "Topologically Robust 3D Shape Matching via Gradual Deflation and\n  Inflation", "comments": "Section 2 replaced", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.CG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite being vastly ignored in the literature, coping with topological noise\nis an issue of increasing importance, especially as a consequence of the\nincreasing number and diversity of 3D polygonal models that are captured by\ndevices of different qualities or synthesized by algorithms of different\nstabilities. One approach for matching 3D shapes under topological noise is to\nreplace the topology-sensitive geodesic distance with distances that are less\nsensitive to topological changes. We propose an alternative approach utilising\ngradual deflation (or inflation) of the shape volume, of which purpose is to\nbring the pair of shapes to be matched to a \\emph{comparable} topology before\nthe search for correspondences. Illustrative experiments using different\ndatasets demonstrate that as the level of topological noise increases, our\napproach outperforms the other methods in the literature.\n", "versions": [{"version": "v1", "created": "Sun, 30 Apr 2017 06:40:18 GMT"}, {"version": "v2", "created": "Fri, 12 May 2017 21:48:29 GMT"}], "update_date": "2017-05-16", "authors_parsed": [["Genctav", "Asli", ""], ["Sahillioglu", "Yusuf", ""], ["Tari", "Sibel", ""]]}, {"id": "1705.00324", "submitter": "Giovanni Viglietta", "authors": "Giuseppe A. Di Luna, Paola Flocchini, Nicola Santoro, Giovanni\n  Viglietta, and Masafumi Yamashita", "title": "Meeting in a Polygon by Anonymous Oblivious Robots", "comments": "37 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Meeting problem for $k\\geq 2$ searchers in a polygon $P$ (possibly with\nholes) consists in making the searchers move within $P$, according to a\ndistributed algorithm, in such a way that at least two of them eventually come\nto see each other, regardless of their initial positions. The polygon is\ninitially unknown to the searchers, and its edges obstruct both movement and\nvision. Depending on the shape of $P$, we minimize the number of searchers $k$\nfor which the Meeting problem is solvable. Specifically, if $P$ has a\nrotational symmetry of order $\\sigma$ (where $\\sigma=1$ corresponds to no\nrotational symmetry), we prove that $k=\\sigma+1$ searchers are sufficient, and\nthe bound is tight. Furthermore, we give an improved algorithm that optimally\nsolves the Meeting problem with $k=2$ searchers in all polygons whose\nbarycenter is not in a hole (which includes the polygons with no holes). Our\nalgorithms can be implemented in a variety of standard models of mobile robots\noperating in Look-Compute-Move cycles. For instance, if the searchers have\nmemory but are anonymous, asynchronous, and have no agreement on a coordinate\nsystem or a notion of clockwise direction, then our algorithms work even if the\ninitial memory contents of the searchers are arbitrary and possibly misleading.\nMoreover, oblivious searchers can execute our algorithms as well, encoding\ninformation by carefully positioning themselves within the polygon. This code\nis computable with basic arithmetic operations, and each searcher can\ngeometrically construct its own destination point at each cycle using only a\ncompass. We stress that such memoryless searchers may be located anywhere in\nthe polygon when the execution begins, and hence the information they initially\nencode is arbitrary. Our algorithms use a self-stabilizing map construction\nsubroutine which is of independent interest.\n", "versions": [{"version": "v1", "created": "Sun, 30 Apr 2017 15:25:31 GMT"}, {"version": "v2", "created": "Sun, 30 Jul 2017 14:37:18 GMT"}, {"version": "v3", "created": "Mon, 15 Jan 2018 18:03:35 GMT"}, {"version": "v4", "created": "Sat, 6 Jul 2019 08:43:04 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Di Luna", "Giuseppe A.", ""], ["Flocchini", "Paola", ""], ["Santoro", "Nicola", ""], ["Viglietta", "Giovanni", ""], ["Yamashita", "Masafumi", ""]]}, {"id": "1705.00325", "submitter": "Klaus Glashoff", "authors": "Klaus Glashoff and Claus Peter Ortlieb", "title": "Composition Operators, Matrix Representation, and the Finite Section\n  Method: A Theoretical Framework for Maps between Shapes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper intends to lay the theoretical foundation for the method of\nfunctional maps, first presented in 2012 by Ovsjanikov, Ben-Chen, Solomon,\nButscher and Guibas in the field of the theory and numerics of maps between\nshapes. We show how to analyze this method by looking at it as an application\nof the theories of composition operators, of matrix representa- tion of\noperators on separable Hilbert spaces, and of the theory of the Finite Section\nMethod. These are three well known fruitful topics in functional analysis. When\napplied to the task of modelling of correspondences of shapes in\nthree-dimensional space, these concepts lead directly to functional maps and\nits associated functional matrices. Mathematically spoken, functional maps are\ncomposition operators between two-dimensional manifolds, and functional\nmatrices are infinite matrix representations of such maps. We present an\nintroduction into the notion and theoretical foundation of the functional\nanalytic framework of the theory of matrix repre- sentation, especially of\ncomposition operators. We will also discuss two numerical methods for solving\nequations with such operators, namely, two variants of the Rectangular Finite\nSection Method. While one of these, which is well known, leads to an\noverdetermined system of linear equations, in the second one the minimum-norm\nsolution of an underdetermined system has to be computed. We will present the\nmain convergence results related to these methods.\n", "versions": [{"version": "v1", "created": "Sun, 30 Apr 2017 15:28:49 GMT"}], "update_date": "2017-05-02", "authors_parsed": [["Glashoff", "Klaus", ""], ["Ortlieb", "Claus Peter", ""]]}, {"id": "1705.00328", "submitter": "Klaus Glashoff", "authors": "Klaus Glashoff and Claus Peter Ortlieb", "title": "A Note on Properties of Discrete Composition Operators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive properties and a characterization of discrete composition matrices\nwhich are useful in the field of numerical computation of shape\ncorrespondences.\n", "versions": [{"version": "v1", "created": "Sun, 30 Apr 2017 15:40:32 GMT"}], "update_date": "2017-05-02", "authors_parsed": [["Glashoff", "Klaus", ""], ["Ortlieb", "Claus Peter", ""]]}, {"id": "1705.00720", "submitter": "Jan Verschelde", "authors": "Anders Jensen, Jeff Sommars, and Jan Verschelde", "title": "Computing Tropical Prevarieties in Parallel", "comments": "Accepted for publication in the proceedings of PASCO 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.CG cs.DC math.AG math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The computation of the tropical prevariety is the first step in the\napplication of polyhedral methods to compute positive dimensional solution sets\nof polynomial systems. In particular, pretropisms are candidate leading\nexponents for the power series developments of the solutions. The computation\nof the power series may start as soon as one pretropism is available, so our\nparallel computation of the tropical prevariety has an application in a\npipelined solver.\n  We present a parallel implementation of dynamic enumeration. Our first\ndistributed memory implementation with forked processes achieved good speedups,\nbut quite often resulted in large variations in the execution times of the\nprocesses. The shared memory multithreaded version applies work stealing to\nreduce the variability of the run time. Our implementation applies the thread\nsafe Parma Polyhedral Library (PPL), in exact arithmetic with the GNU\nMultiprecision Arithmetic Library (GMP), aided by the fast memory allocations\nof TCMalloc.\n  Our parallel implementation is capable of computing the tropical prevariety\nof the cyclic 16-roots problem. We also report on computational experiments on\nthe $n$-body and $n$-vortex problems; our computational results compare\nfavorably with Gfan.\n", "versions": [{"version": "v1", "created": "Mon, 1 May 2017 21:34:00 GMT"}, {"version": "v2", "created": "Sat, 1 Jul 2017 23:04:37 GMT"}], "update_date": "2017-07-04", "authors_parsed": [["Jensen", "Anders", ""], ["Sommars", "Jeff", ""], ["Verschelde", "Jan", ""]]}, {"id": "1705.00924", "submitter": "Sebastian Morr", "authors": "S\\'andor P. Fekete, Sebastian Morr, Christian Scheffer", "title": "Split Packing: Algorithms for Packing Circles with Optimal Worst-Case\n  Density", "comments": "36 pages, 34 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the classic circle packing problem, one asks whether a given set of\ncircles can be packed into a given container. Packing problems like this have\nbeen shown to be $\\mathsf{NP}$-hard. In this paper, we present new sufficient\nconditions for packing circles into square and triangular containers, using\nonly the sum of the circles' areas: For square containers, it is possible to\npack any set of circles with a combined area of up to approximately 53.90% of\nthe square's area. And when the container is a right or obtuse triangle, any\nset of circles whose combined area does not exceed the triangle's incircle can\nbe packed.\n  These area conditions are tight, in the sense that for any larger areas,\nthere are sets of circles which cannot be packed. Similar results have long\nbeen known for squares, but to the best of our knowledge, we give the first\nresults of this type for circular objects.\n  Our proofs are constructive: We describe a versatile,\ndivide-and-conquer-based algorithm for packing circles into various container\nshapes with optimal worst-case density. It employs an elegant subdivision\nscheme that recursively splits the circles into two groups and then packs these\ninto subcontainers. We call this algorithm \"Split Packing\". It can be used as a\nconstant-factor approximation algorithm when looking for the smallest container\nin which a given set of circles can be packed, due to its polynomial runtime.\n  A browser-based, interactive visualization of the Split Packing approach and\nother related material can be found at https://morr.cc/split-packing/\n", "versions": [{"version": "v1", "created": "Tue, 2 May 2017 11:48:45 GMT"}, {"version": "v2", "created": "Wed, 27 Jun 2018 10:27:36 GMT"}], "update_date": "2018-06-28", "authors_parsed": [["Fekete", "S\u00e1ndor P.", ""], ["Morr", "Sebastian", ""], ["Scheffer", "Christian", ""]]}, {"id": "1705.01465", "submitter": "S\\'andor Kisfaludi-Bak", "authors": "Mark de Berg, Hans L. Bodlaender, S\\'andor Kisfaludi-Bak", "title": "The Homogeneous Broadcast Problem in Narrow and Wide Strips", "comments": "50 pages, WADS 2017 submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $P$ be a set of nodes in a wireless network, where each node is modeled\nas a point in the plane, and let $s\\in P$ be a given source node. Each node $p$\ncan transmit information to all other nodes within unit distance, provided $p$\nis activated. The (homogeneous) broadcast problem is to activate a minimum\nnumber of nodes such that in the resulting directed communication graph, the\nsource $s$ can reach any other node. We study the complexity of the regular and\nthe hop-bounded version of the problem (in the latter, $s$ must be able to\nreach every node within a specified number of hops), with the restriction that\nall points lie inside a strip of width $w$. We almost completely characterize\nthe complexity of both the regular and the hop-bounded versions as a function\nof the strip width $w$.\n", "versions": [{"version": "v1", "created": "Wed, 3 May 2017 14:48:56 GMT"}], "update_date": "2017-05-04", "authors_parsed": [["de Berg", "Mark", ""], ["Bodlaender", "Hans L.", ""], ["Kisfaludi-Bak", "S\u00e1ndor", ""]]}, {"id": "1705.01532", "submitter": "Alexander Evako V", "authors": "Alexander V. Evako", "title": "Graph Theoretical Models of Closed n-Dimensional Manifolds: Digital\n  Models of a Moebius Strip, a Torus, a Projective Plane a Klein Bottle and\n  n-Dimensional Spheres", "comments": "12 pages, 12 figures", "journal-ref": "Applied Mathematics and Physics, 2017, Vol. 5, No. 1, 19-27;\n  http://pubs.sciepub.com/amp/5/1/3", "doi": "10.12691/amp-5-1-3", "report-no": null, "categories": "math.GT cs.CG math.AT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we show how to construct graph theoretical models of\nn-dimensional continuous objects and manifolds. These models retain topological\nproperties of their continuous counterparts. An LCL collection of n-cells in\nEuclidean space is introduced and investigated. If an LCL collection of n-cells\nis a cover of a continuous n-dimensional manifold then the intersection graph\nof this cover is a digital closed n-dimensional manifold with the same topology\nas its continuous counterpart. As an example, we prove that the digital model\nof a continuous n-dimensional sphere is a digital n-sphere with at least 2n+2\npoints, the digital model of a continuous projective plane is a digital\nprojective plane with at least eleven points, the digital model of a continuous\nKlein bottle is the digital Klein bottle with at least sixteen points, the\ndigital model of a continuous torus is the digital torus with at least sixteen\npoints and the digital model of a continuous Moebius band is the digital\nMoebius band with at least twelve points.\n", "versions": [{"version": "v1", "created": "Tue, 2 May 2017 12:32:00 GMT"}], "update_date": "2017-05-04", "authors_parsed": [["Evako", "Alexander V.", ""]]}, {"id": "1705.01690", "submitter": "Michael Lesnick", "authors": "Andrew J. Blumberg, Michael Lesnick", "title": "Universality of the Homotopy Interleaving Distance", "comments": "29 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AT cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a step towards establishing homotopy-theoretic foundations for topological\ndata analysis (TDA), we introduce and study homotopy interleavings between\nfiltered topological spaces. These are homotopy-invariant analogues of\ninterleavings, objects commonly used in TDA to articulate stability and\ninference theorems. Intuitively, whereas a strict interleaving between filtered\nspaces $X$ and $Y$ certifies that $X$ and $Y$ are approximately isomorphic, a\nhomotopy interleaving between $X$ and $Y$ certifies that $X$ and $Y$ are\napproximately weakly equivalent. The main results of this paper are that\nhomotopy interleavings induce an extended pseudometric $d_{HI}$ on filtered\nspaces, and that this is the universal pseudometric satisfying natural\nstability and homotopy invariance axioms. To motivate these axioms, we also\nobserve that $d_{HI}$ (or more generally, any pseudometric satisfying these two\naxioms and an additional \"homology bounding\" axiom) can be used to formulate\nlifts of several fundamental TDA theorems from the algebraic (homological)\nlevel to the level of filtered spaces. Finally, we consider the problem of\nestablishing a persistent Whitehead theorem in terms of homotopy interleavings.\nWe provide a counterexample to a naive formulation of the result.\n", "versions": [{"version": "v1", "created": "Thu, 4 May 2017 03:33:42 GMT"}], "update_date": "2017-05-05", "authors_parsed": [["Blumberg", "Andrew J.", ""], ["Lesnick", "Michael", ""]]}, {"id": "1705.01720", "submitter": "Shay Moran", "authors": "Daniel M. Kane and Shachar Lovett and Shay Moran", "title": "Near-optimal linear decision trees for k-SUM and related problems", "comments": "18 paged, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CC cs.DM cs.LG math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We construct near optimal linear decision trees for a variety of decision\nproblems in combinatorics and discrete geometry. For example, for any constant\n$k$, we construct linear decision trees that solve the $k$-SUM problem on $n$\nelements using $O(n \\log^2 n)$ linear queries. Moreover, the queries we use are\ncomparison queries, which compare the sums of two $k$-subsets; when viewed as\nlinear queries, comparison queries are $2k$-sparse and have only $\\{-1,0,1\\}$\ncoefficients. We give similar constructions for sorting sumsets $A+B$ and for\nsolving the SUBSET-SUM problem, both with optimal number of queries, up to\npoly-logarithmic terms.\n  Our constructions are based on the notion of \"inference dimension\", recently\nintroduced by the authors in the context of active classification with\ncomparison queries. This can be viewed as another contribution to the fruitful\nlink between machine learning and discrete geometry, which goes back to the\ndiscovery of the VC dimension.\n", "versions": [{"version": "v1", "created": "Thu, 4 May 2017 07:11:47 GMT"}], "update_date": "2017-05-05", "authors_parsed": [["Kane", "Daniel M.", ""], ["Lovett", "Shachar", ""], ["Moran", "Shay", ""]]}, {"id": "1705.01723", "submitter": "Elmar Langetepe", "authors": "Elmar Langetepe and Simone Lehmann", "title": "Exact VC-dimension for $L_1$-visibility of points in simple polygons", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The VC-dimension plays an important role for the algorithmic problem of\nguarding art galleries efficiently. We prove that inside a simple polygon at\nmost $5$ points can be shattered by $L_1$-visibility polygons and give an\nexample where 5 points are shattered. The VC-dimension is exactly $5$. The\nproof idea for the upper bound is different from previous approaches.\n  Keywords: Art gallery, VC-dimension, $L_1$-visibility, polygons\n", "versions": [{"version": "v1", "created": "Thu, 4 May 2017 07:18:28 GMT"}], "update_date": "2017-05-05", "authors_parsed": [["Langetepe", "Elmar", ""], ["Lehmann", "Simone", ""]]}, {"id": "1705.02451", "submitter": "Jeanne Pellerin", "authors": "Jeanne Pellerin, Amaury Johnen, Kilian Verhetsel, Jean-Francois\n  Remacle", "title": "Identifying combinations of tetrahedra into hexahedra: a vertex based\n  strategy", "comments": "Preprint submitted to CAD (26th IMR special issue)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Indirect hex-dominant meshing methods rely on the detection of adjacent\ntetrahedra an algorithm that performs this identification and builds the set of\nall possible combinations of tetrahedral elements of an input mesh T into\nhexahedra, prisms, or pyramids. All identified cells are valid for engineering\nanalysis. First, all combinations of eight/six/five vertices whose connectivity\nin T matches the connectivity of a hexahedron/prism/pyramid are computed. The\nsubset of tetrahedra of T triangulating each potential cell is then determined.\nQuality checks allow to early discard poor quality cells and to dramatically\nimprove the efficiency of the method. Each potential hexahedron/prism/pyramid\nis computed only once. Around 3 millions potential hexahedra are computed in 10\nseconds on a laptop. We finally demonstrate that the set of potential hexes\nbuilt by our algorithm is significantly larger than those built using\npredefined patterns of subdivision of a hexahedron in tetrahedral elements.\n", "versions": [{"version": "v1", "created": "Sat, 6 May 2017 06:12:59 GMT"}, {"version": "v2", "created": "Tue, 1 Aug 2017 14:59:53 GMT"}, {"version": "v3", "created": "Thu, 4 Jan 2018 15:12:06 GMT"}], "update_date": "2018-01-08", "authors_parsed": [["Pellerin", "Jeanne", ""], ["Johnen", "Amaury", ""], ["Verhetsel", "Kilian", ""], ["Remacle", "Jean-Francois", ""]]}, {"id": "1705.02752", "submitter": "Haitao Wang", "authors": "Haitao Wang and Jingru Zhang", "title": "An $O(n\\log n)$-Time Algorithm for the k-Center Problem in Trees", "comments": "9 figures; 32 pages; a preliminary version to appear in SoCG 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a classical k-center problem in trees. Let T be a tree of n\nvertices and every vertex has a nonnegative weight. The problem is to find k\ncenters on the edges of T such that the maximum weighted distance from all\nvertices to their closest centers is minimized. Megiddo and Tamir (SIAM J.\nComput., 1983) gave an algorithm that can solve the problem in $O(n\\log^2 n)$\ntime by using Cole's parametric search. Since then it has been open for over\nthree decades whether the problem can be solved in $O(n\\log n)$ time. In this\npaper, we present an $O(n\\log n)$ time algorithm for the problem and thus\nsettle the open problem affirmatively.\n", "versions": [{"version": "v1", "created": "Mon, 8 May 2017 05:58:07 GMT"}, {"version": "v2", "created": "Tue, 6 Mar 2018 16:47:26 GMT"}], "update_date": "2018-03-07", "authors_parsed": [["Wang", "Haitao", ""], ["Zhang", "Jingru", ""]]}, {"id": "1705.03911", "submitter": "Supanut Chaidee", "authors": "Supanut Chaidee, Kokichi Sugihara", "title": "Recognition of the Spherical Laguerre Voronoi Diagram", "comments": "Preprint submitted to Computational Geometry: Theory and Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we construct an algorithm for determining whether a given\ntessellation on a sphere is a spherical Laguerre Voronoi diagram or not. For\nspherical Laguerre tessellations, not only the locations of the Voronoi\ngenerators, but also their weights are required to recover. However, unlike the\nordinary spherical Voronoi diagram, the generator set is not unique, which\nmakes the problem difficult. To solve the problem, we use the property that a\ntessellation is a spherical Laguerre Voronoi diagram if and only if there is a\npolyhedron whose central projection coincides with the tessellation. We\ndetermine the degrees of freedom for the polyhedron, and then construct an\nalgorithm for recognizing Laguerre tessellations.\n", "versions": [{"version": "v1", "created": "Wed, 10 May 2017 18:22:24 GMT"}], "update_date": "2017-05-12", "authors_parsed": [["Chaidee", "Supanut", ""], ["Sugihara", "Kokichi", ""]]}, {"id": "1705.03950", "submitter": "Wouter Kuijper", "authors": "Wouter Kuijper", "title": "Zig-zagging in a Triangulation", "comments": "11 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an oblivious walk for point location in 2-dimensional\ntriangulations and a corresponding, strictly monotonically decreasing distance\nmeasure.\n", "versions": [{"version": "v1", "created": "Wed, 10 May 2017 21:01:31 GMT"}, {"version": "v2", "created": "Wed, 24 May 2017 14:15:24 GMT"}], "update_date": "2017-05-25", "authors_parsed": [["Kuijper", "Wouter", ""]]}, {"id": "1705.05176", "submitter": "Alexander Wolff", "authors": "Markus Chimani, Stefan Felsner, Stephen Kobourov, Torsten Ueckerdt,\n  Pavel Valtr, Alexander Wolff", "title": "On the Maximum Crossing Number", "comments": "16 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research about crossings is typically about minimization. In this paper, we\nconsider \\emph{maximizing} the number of crossings over all possible ways to\ndraw a given graph in the plane. Alpert et al. [Electron. J. Combin., 2009]\nconjectured that any graph has a \\emph{convex} straight-line drawing, e.g., a\ndrawing with vertices in convex position, that maximizes the number of edge\ncrossings. We disprove this conjecture by constructing a planar graph on twelve\nvertices that allows a non-convex drawing with more crossings than any convex\none. Bald et al. [Proc. COCOON, 2016] showed that it is NP-hard to compute the\nmaximum number of crossings of a geometric graph and that the weighted\ngeometric case is NP-hard to approximate. We strengthen these results by\nshowing hardness of approximation even for the unweighted geometric case and\nprove that the unweighted topological case is NP-hard.\n", "versions": [{"version": "v1", "created": "Mon, 15 May 2017 11:57:54 GMT"}], "update_date": "2017-05-16", "authors_parsed": [["Chimani", "Markus", ""], ["Felsner", "Stefan", ""], ["Kobourov", "Stephen", ""], ["Ueckerdt", "Torsten", ""], ["Valtr", "Pavel", ""], ["Wolff", "Alexander", ""]]}, {"id": "1705.05243", "submitter": "Radoslav Fulek", "authors": "Radoslav Fulek and Jan Kyn\\v{c}l", "title": "Hanani-Tutte for approximating maps of graphs", "comments": "minor corrections", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We resolve in the affirmative conjectures of Repovs and A. Skopenkov (1998),\nand M. Skopenkov (2003) generalizing the classical Hanani-Tutte theorem to the\nsetting of approximating maps of graphs on 2-dimensional surfaces by\nembeddings. Our proof of this result is constructive and almost immediately\nimplies an efficient algorithm for testing if a given piecewise linear map of a\ngraph in a surface is approximable by an embedding. More precisely, an instance\nof this problem consists of (i) a graph G whose vertices are partitioned into\nclusters and whose inter-cluster edges are partitioned into bundles, and (ii) a\nregion R of a 2-dimensional compact surface M given as the union of a set of\npairwise disjoint discs corresponding to the clusters and a set of pairwise\nnon-intersecting \"pipes\" corresponding to the bundles, connecting certain pairs\nof these discs. We are to decide whether G can be embedded inside M so that the\nvertices in every cluster are drawn in the corresponding disc, the edges in\nevery bundle pass only through its corresponding pipe, and every edge crosses\nthe boundary of each disc at most once.\n", "versions": [{"version": "v1", "created": "Mon, 15 May 2017 13:55:56 GMT"}, {"version": "v2", "created": "Wed, 14 Mar 2018 12:28:04 GMT"}, {"version": "v3", "created": "Thu, 22 Mar 2018 14:00:34 GMT"}, {"version": "v4", "created": "Sat, 10 Nov 2018 21:50:35 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Fulek", "Radoslav", ""], ["Kyn\u010dl", "Jan", ""]]}, {"id": "1705.05479", "submitter": "Debajyoti Mondal", "authors": "Debajyoti Mondal and Lev Nachmanson", "title": "A New Approach to GraphMaps, a System Browsing Large Graphs as\n  Interactive Maps", "comments": "Appears in the Proceedings of the 8th International Conference on\n  Information Visualization Theory and Applications (IVAPP 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A GraphMaps is a system that visualizes a graph using zoom levels, which is\nsimilar to a geographic map visualization. GraphMaps reveals the structural\nproperties of the graph and enables users to explore the graph in a natural way\nby using the standard zoom and pan operations. The available implementation of\nGraphMaps faces many challenges such as the number of zoom levels may be large,\nnodes may be unevenly distributed to different levels, shared edges may create\nambiguity due to the selection of multiple nodes. In this paper, we develop an\nalgorithmic framework to construct GraphMaps from any given mesh (generated\nfrom a 2D point set), and for any given number of zoom levels. We demonstrate\nour approach introducing competition mesh, which is simple to construct, has a\nlow dilation and high angular resolution. We present an algorithm for assigning\nnodes to zoom levels that minimizes the change in the number of nodes on\nvisible on the screen while the user zooms in and out between the levels. We\nthink that keeping this change small facilitates smooth browsing of the graph.\nWe also propose new node selection techniques to cope with some of the\nchallenges of the GraphMaps approach.\n", "versions": [{"version": "v1", "created": "Mon, 15 May 2017 23:25:07 GMT"}, {"version": "v2", "created": "Sun, 12 Aug 2018 04:19:52 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Mondal", "Debajyoti", ""], ["Nachmanson", "Lev", ""]]}, {"id": "1705.05569", "submitter": "Michael Hoffmann", "authors": "Michael Hoffmann and Csaba D. T\\'oth", "title": "Two-Planar Graphs Are Quasiplanar", "comments": "Superseded by arXiv:1909.00223 as a result of merging with\n  arXiv:1702.08716", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is shown that every 2-planar graph is quasiplanar, that is, if a simple\ngraph admits a drawing in the plane such that every edge is crossed at most\ntwice, then it also admits a drawing in which no three edges pairwise cross. We\nfurther show that quasiplanarity is witnessed by a simple topological drawing,\nthat is, any two edges cross at most once and adjacent edges do not cross.\n", "versions": [{"version": "v1", "created": "Tue, 16 May 2017 07:54:56 GMT"}, {"version": "v2", "created": "Wed, 4 Sep 2019 13:30:15 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Hoffmann", "Michael", ""], ["T\u00f3th", "Csaba D.", ""]]}, {"id": "1705.06180", "submitter": "Joseph S. B. Mitchell", "authors": "Gui Citovsky and Tyler Mayer and Joseph S. B. Mitchell", "title": "TSP With Locational Uncertainty: The Adversarial Model", "comments": "To appear, International Symposium on Computational Geometry (SoCG\n  2017)", "journal-ref": null, "doi": "10.4230/LIPIcs.SoCG.2017.32", "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study a natural special case of the Traveling Salesman\nProblem (TSP) with point-locational-uncertainty which we will call the {\\em\nadversarial TSP} problem (ATSP). Given a metric space $(X, d)$ and a set of\nsubsets $R = \\{R_1, R_2, ... , R_n\\} : R_i \\subseteq X$, the goal is to devise\nan ordering of the regions, $\\sigma_R$, that the tour will visit such that when\na single point is chosen from each region, the induced tour over those points\nin the ordering prescribed by $\\sigma_R$ is as short as possible. Unlike the\nclassical locational-uncertainty-TSP problem, which focuses on minimizing the\nexpected length of such a tour when the point within each region is chosen\naccording to some probability distribution, here, we focus on the {\\em\nadversarial model} in which once the choice of $\\sigma_R$ is announced, an\nadversary selects a point from each region in order to make the resulting tour\nas long as possible. In other words, we consider an offline problem in which\nthe goal is to determine an ordering of the regions $R$ that is optimal with\nrespect to the \"worst\" point possible within each region being chosen by an\nadversary, who knows the chosen ordering. We give a $3$-approximation when $R$\nis a set of arbitrary regions/sets of points in a metric space. We show how\ngeometry leads to improved constant factor approximations when regions are\nparallel line segments of the same lengths, and a polynomial-time approximation\nscheme (PTAS) for the important special case in which $R$ is a set of disjoint\nunit disks in the plane.\n", "versions": [{"version": "v1", "created": "Wed, 17 May 2017 14:36:34 GMT"}], "update_date": "2017-05-18", "authors_parsed": [["Citovsky", "Gui", ""], ["Mayer", "Tyler", ""], ["Mitchell", "Joseph S. B.", ""]]}, {"id": "1705.06242", "submitter": "Ali D. Mehrabi", "authors": "Mikkel Abrahamsen, Mark de Berg, Kevin Buchin, Mehran Mehr, and Ali D.\n  Mehrabi", "title": "Range-Clustering Queries", "comments": "23 pages and 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a geometric $k$-clustering problem the goal is to partition a set of\npoints in $\\mathbb{R}^d$ into $k$ subsets such that a certain cost function of\nthe clustering is minimized. We present data structures for orthogonal\nrange-clustering queries on a point set $S$: given a query box $Q$ and an\ninteger $k>2$, compute an optimal $k$-clustering for $S\\setminus Q$. We obtain\nthe following results. We present a general method to compute a\n$(1+\\epsilon)$-approximation to a range-clustering query, where $\\epsilon>0$ is\na parameter that can be specified as part of the query. Our method applies to a\nlarge class of clustering problems, including $k$-center clustering in any\n$L_p$-metric and a variant of $k$-center clustering where the goal is to\nminimize the sum (instead of maximum) of the cluster sizes. We extend our\nmethod to deal with capacitated $k$-clustering problems, where each of the\nclusters should not contain more than a given number of points. For the special\ncases of rectilinear $k$-center clustering in $\\mathbb{R}^1$, and in\n$\\mathbb{R}^2$ for $k=2$ or 3, we present data structures that answer\nrange-clustering queries exactly.\n", "versions": [{"version": "v1", "created": "Wed, 17 May 2017 16:20:46 GMT"}], "update_date": "2017-05-18", "authors_parsed": [["Abrahamsen", "Mikkel", ""], ["de Berg", "Mark", ""], ["Buchin", "Kevin", ""], ["Mehr", "Mehran", ""], ["Mehrabi", "Ali D.", ""]]}, {"id": "1705.07746", "submitter": "Zhaoming Yin", "authors": "Zhaoming Yin, Xuan Shi", "title": "Taming Near Repeat Calculation for Crime Analysis via Cohesive Subgraph\n  Computing", "comments": "The Twelfth International Conference on Advanced Geographic\n  Information Systems, Applications, and Services GEOProcessing 2020, ISBN\n  978-1-61208-762-7", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Near repeat (NR) is a well known phenomenon in crime analysis assuming that\ncrime events exhibit correlations within a given time and space frame.\nTraditional NR calculation generates 2 event pairs if 2 events happened within\na given space and time limit. When the number of events is large, however, NR\ncalculation is time consuming and how these pairs are organized are not yet\nexplored. In this paper, we designed a new approach to calculate clusters of NR\nevents efficiently. To begin with, R-tree is utilized to index crime events, a\nsingle event is represented by a vertex whereas edges are constructed by range\nquerying the vertex in R-tree, and a graph is formed. Cohesive subgraph\napproaches are applied to identify the event chains. k-clique, k-truss, k-core\nplus DBSCAN algorithms are implemented in sequence with respect to their varied\nrange of ability to find cohesive subgraphs. Real world crime data in Chicago,\nNew York and Washington DC are utilized to conduct experiments. The experiment\nconfirmed that near repeat is a solid effect in real big crime data by\nconducting Mapreduce empowered knox tests. The performance of 4 different\nalgorithms are validated, while the quality of the algorithms are gauged by the\ndistribution of number of cohesive subgraphs and their clustering coefficients.\nThe proposed framework is the first to process the real crime data of million\nrecord scale, and is the first to detect NR events with size of more than 2.\n", "versions": [{"version": "v1", "created": "Thu, 18 May 2017 12:39:09 GMT"}, {"version": "v2", "created": "Wed, 25 Mar 2020 22:18:53 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Yin", "Zhaoming", ""], ["Shi", "Xuan", ""]]}, {"id": "1705.09346", "submitter": "Minati De", "authors": "Ankush Acharyya, Minati De, Subhas C. Nandy and Bodhayan Roy", "title": "Range Assignment of Base-Stations Maximizing Coverage Area without\n  Interference", "comments": "27 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of assigning non-overlapping geometric objects centered\nat a given set of points such that the sum of area covered by them is\nmaximized. If the points are placed on a straight-line and the objects are\ndisks, then the problem is solvable in polynomial time. However, we show that\nthe problem is NP-hard even for simplest objects like disks or squares in\n${\\mathbb{R}}^2$. Eppstein [CCCG, pages 260--265, 2016] proposed a polynomial\ntime algorithm for maximizing the sum of radii (or perimeter) of\nnon-overlapping balls or disks when the points are arbitrarily placed on a\nplane. We show that Eppstein's algorithm for maximizing sum of perimeter of the\ndisks in ${\\mathbb{R}}^2$ gives a $2$-approximation solution for the sum of\narea maximization problem. We propose a PTAS for our problem. These\napproximation results are extendible to higher dimensions. All these\napproximation results hold for the area maximization problem by regular convex\npolygons with even number of edges centered at the given points.\n", "versions": [{"version": "v1", "created": "Thu, 25 May 2017 20:10:55 GMT"}, {"version": "v2", "created": "Wed, 26 Jul 2017 16:33:13 GMT"}, {"version": "v3", "created": "Thu, 14 Sep 2017 09:57:52 GMT"}], "update_date": "2017-09-15", "authors_parsed": [["Acharyya", "Ankush", ""], ["De", "Minati", ""], ["Nandy", "Subhas C.", ""], ["Roy", "Bodhayan", ""]]}, {"id": "1705.09691", "submitter": "Vitoriano Ruas", "authors": "Vitoriano Ruas", "title": "One-parameter tetrahedral mesh generation for spheroids", "comments": "The description of the method studied in this work was first\n  published in Portuguese in Revista Brasileira de Computa\\c{c}\\~ao, 4-3\n  (1985), 165-178. It was also published in Proc. Int. Conf. Numerical Grid\n  Generation in CFD, Landshut, Germany, 1986, C. Taylor ed., Pineridge Press,\n  Swansea, UK, p. 71-82, 1986. However method's implementation and assessment\n  by the author took place only in 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with a simple and straightforward procedure for automatic\ngeneration of finite-element or finite-volume meshes of spheroidal domains,\nconsisting of tetrahedra. Besides the equation of the boundary, the generated\nmeshes depend only on an integer parameter, whose value is associated with the\ndegree of refinement. More specifically the procedure applies to the case where\nthe boundary of a curved three-dimensional domain not so irregular can be\nexpressed in spherical coordinates, with origin placed at a suitable location\nin its interior. An optimal numbering of mesh elements and nodes can be\naccomplished very easily. Several examples indicate that the generated meshes\nform a quasi-uniform family of partitions, as the corresponding value of the\ninteger parameter increases, as long as the domain is not too distorted.\n", "versions": [{"version": "v1", "created": "Fri, 26 May 2017 19:32:32 GMT"}], "update_date": "2017-05-30", "authors_parsed": [["Ruas", "Vitoriano", ""]]}, {"id": "1705.10022", "submitter": "Javiel Rojas-Ledesma", "authors": "J\\'er\\'emy Barbay, Pablo P\\'erez-Lantero, Javiel Rojas-Ledesma", "title": "Depth Distribution in High Dimensions", "comments": "Extended Version of Article presented at COCOON'17", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the analysis of range queries in databases, we introduce the\ncomputation of the Depth Distribution of a set $\\mathcal{B}$ of axis aligned\nboxes, whose computation generalizes that of the Klee's Measure and of the\nMaximum Depth. In the worst case over instances of fixed input size $n$, we\ndescribe an algorithm of complexity within $O({n^\\frac{d+1}{2}\\log n})$, using\nspace within $O({n\\log n})$, mixing two techniques previously used to compute\nthe Klee's Measure. We refine this result and previous results on the Klee's\nMeasure and the Maximum Depth for various measures of difficulty of the input,\nsuch as the profile of the input and the degeneracy of the intersection graph\nformed by the boxes.\n", "versions": [{"version": "v1", "created": "Mon, 29 May 2017 02:31:33 GMT"}, {"version": "v2", "created": "Tue, 30 May 2017 15:28:57 GMT"}, {"version": "v3", "created": "Wed, 31 May 2017 18:37:14 GMT"}], "update_date": "2017-06-02", "authors_parsed": [["Barbay", "J\u00e9r\u00e9my", ""], ["P\u00e9rez-Lantero", "Pablo", ""], ["Rojas-Ledesma", "Javiel", ""]]}, {"id": "1705.10439", "submitter": "Oliver Knill", "authors": "Oliver Knill", "title": "On a Dehn-Sommerville functional for simplicial complexes", "comments": "24 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Assume G is a finite abstract simplicial complex with f-vector (v0,v1, ...),\nand generating function f(x) = sum(k=1 v(k-1) x^k = v0 x + v1 x^2+ v2 x^3 +\n..., the Euler characteristic of G can be written as chi(G)=f(0)-f(-1). We\nstudy here the functional f1'(0)-f1'(-1), where f1' is the derivative of the\ngenerating function f1 of G1. The Barycentric refinement G1 of G is the Whitney\ncomplex of the finite simple graph for which the faces of G are the vertices\nand where two faces are connected if one is a subset of the other. Let L is the\nconnection Laplacian of G, which is L=1+A, where A is the adjacency matrix of\nthe connection graph G', which has the same vertex set than G1 but where two\nfaces are connected they intersect. We have f1'(0)=tr(L) and for the Green\nfunction g L^(-1) also f1'(-1)=tr(g) so that eta1(G) = f1'(0)-f1'(-1) is equal\nto eta(G)=tr(L-L^(-1). The established formula tr(g)=f1'(-1) for the generating\nfunction of G1 complements the determinant expression det(L)=det(g)=zeta(-1)\nfor the Bowen-Lanford zeta function zeta(z)=1/det(1-z A) of the connection\ngraph G' of G. We also establish a Gauss-Bonnet formula eta1(G) = sum(x in\nV(G1) chi(S(x)), where S(x) is the unit sphere of x the graph generated by all\nvertices in G1 directly connected to x. Finally, we point out that the\nfunctional eta0(G) = sum(x in V(G) chi(S(x)) on graphs takes arbitrary small\nand arbitrary large values on every homotopy type of graphs.\n", "versions": [{"version": "v1", "created": "Tue, 30 May 2017 02:49:45 GMT"}], "update_date": "2017-05-31", "authors_parsed": [["Knill", "Oliver", ""]]}, {"id": "1705.11035", "submitter": "Vahideh Keikha", "authors": "Vahideh Keikha and Maarten L\\\"offler and Ali Mohades and J\\'er\\^ome\n  Urhausen and Ivor van der Hoog", "title": "Maximum-Area Triangle in a Convex Polygon, Revisited", "comments": null, "journal-ref": null, "doi": "10.1016/j.ipl.2020.105943", "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the following problem: Given a convex polygon $P$, find the\nlargest-area inscribed triangle. We show by example that the linear-time\nalgorithm presented in 1979 by Dobkin and Snyder for solving this problem\nfails. We then proceed to show that with a small adaptation, their approach\ndoes lead to a quadratic-time algorithm. We also present a more involved\n$O(n\\log n)$ time divide-and-conquer algorithm. Also we show by example that\nthe algorithm presented in 1979 by Dobkin and Snyder for finding the\nlargest-area $k$-gon that is inscribed in a convex polygon fails to find the\noptimal solution for $k=4$. Finally, we discuss the implications of our\ndiscoveries on the literature.\n", "versions": [{"version": "v1", "created": "Wed, 31 May 2017 11:27:28 GMT"}, {"version": "v2", "created": "Mon, 18 Dec 2017 14:24:06 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Keikha", "Vahideh", ""], ["L\u00f6ffler", "Maarten", ""], ["Mohades", "Ali", ""], ["Urhausen", "J\u00e9r\u00f4me", ""], ["van der Hoog", "Ivor", ""]]}]