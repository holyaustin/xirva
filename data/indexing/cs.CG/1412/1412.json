[{"id": "1412.0036", "submitter": "Aleksandar Nikolov", "authors": "Aleksandar Nikolov", "title": "Randomized Rounding for the Largest Simplex Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS math.FA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The maximum volume $j$-simplex problem asks to compute the $j$-dimensional\nsimplex of maximum volume inside the convex hull of a given set of $n$ points\nin $\\mathbb{Q}^d$. We give a deterministic approximation algorithm for this\nproblem which achieves an approximation ratio of $e^{j/2 + o(j)}$. The problem\nis known to be $\\mathrm{NP}$-hard to approximate within a factor of $c^{j}$ for\nsome constant $c > 1$. Our algorithm also gives a factor $e^{j + o(j)}$\napproximation for the problem of finding the principal $j\\times j$ submatrix of\na rank $d$ positive semidefinite matrix with the largest determinant. We\nachieve our approximation by rounding solutions to a generalization of the\n$D$-optimal design problem, or, equivalently, the dual of an appropriate\nsmallest enclosing ellipsoid problem. Our arguments give a short and simple\nproof of a restricted invertibility principle for determinants.\n", "versions": [{"version": "v1", "created": "Fri, 28 Nov 2014 21:51:40 GMT"}, {"version": "v2", "created": "Tue, 14 Apr 2015 04:03:22 GMT"}], "update_date": "2015-04-15", "authors_parsed": [["Nikolov", "Aleksandar", ""]]}, {"id": "1412.0143", "submitter": "Alexander Evako V", "authors": "Alexander V. Evako", "title": "Topology preserving representations of compact 2D manifolds by digital\n  2-surfaces. Compressed digital models and digital weights of compact 2D\n  manifolds. Classification of closed surfaces by digital tools", "comments": "12 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DM math.AG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using digital topology approach, we construct digital models of closed\nsurfaces as the intersection graphs of LCL covers of the surfaces. It is proved\nthat digital models of closed surfaces are digital 2-dimensional surfaces\npreserving the geometry and topology of their continuous counterparts. In the\nframework of the proposed models, we show that for any closed surface there\nexists a compressed model of this surface with the minimal number of points.\n  Key words: Closed Surface; Digital space; Cover; Graph; Digital model;\nMedical imaging;\n", "versions": [{"version": "v1", "created": "Sat, 29 Nov 2014 19:36:40 GMT"}], "update_date": "2014-12-02", "authors_parsed": [["Evako", "Alexander V.", ""]]}, {"id": "1412.0760", "submitter": "Andr\\'e van Renssen", "authors": "Prosenjit Bose, Rolf Fagerberg, Andr\\'e van Renssen, Sander\n  Verdonschot", "title": "Competitive Local Routing with Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $P$ be a set of $n$ vertices in the plane and $S$ a set of non-crossing\nline segments between vertices in $P$, called constraints. Two vertices are\nvisible if the straight line segment connecting them does not properly\nintersect any constraints. The constrained $\\Theta_m$-graph is constructed by\npartitioning the plane around each vertex into $m$ disjoint cones, each with\naperture $\\theta = 2 \\pi/m$, and adding an edge to the `closest' visible vertex\nin each cone. We consider how to route on the constrained $\\Theta_6$-graph. We\nfirst show that no deterministic 1-local routing algorithm is\n$o(\\sqrt{n})$-competitive on all pairs of vertices of the constrained\n$\\Theta_6$-graph. After that, we show how to route between any two visible\nvertices of the constrained $\\Theta_6$-graph using only 1-local information.\nOur routing algorithm guarantees that the returned path is 2-competitive.\nAdditionally, we provide a 1-local 18-competitive routing algorithm for visible\nvertices in the constrained half-$\\Theta_6$-graph, a subgraph of the\nconstrained $\\Theta_6$-graph that is equivalent to the Delaunay graph where the\nempty region is an equilateral triangle. To the best of our knowledge, these\nare the first local routing algorithms in the constrained setting with\nguarantees on the length of the returned path.\n", "versions": [{"version": "v1", "created": "Tue, 2 Dec 2014 02:40:17 GMT"}, {"version": "v2", "created": "Thu, 29 Oct 2015 01:50:43 GMT"}, {"version": "v3", "created": "Sat, 13 May 2017 04:51:32 GMT"}], "update_date": "2017-05-16", "authors_parsed": [["Bose", "Prosenjit", ""], ["Fagerberg", "Rolf", ""], ["van Renssen", "Andr\u00e9", ""], ["Verdonschot", "Sander", ""]]}, {"id": "1412.0779", "submitter": "Sariel Har-Peled", "authors": "Sariel Har-Peled", "title": "Shortest Path in a Polygon using Sublinear Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  $\\renewcommand{\\Re}{{\\rm I\\!\\hspace{-0.025em} R}}\n\\newcommand{\\SetX}{\\mathsf{X}} \\newcommand{\\VorX}[1]{\\mathcal{V} \\pth{#1}}\n\\newcommand{\\Polygon}{\\mathsf{P}} \\newcommand{\\Space}{\\overline{\\mathsf{m}}}\n\\newcommand{\\pth}[2][\\!]{#1\\left({#2}\\right)}$ We resolve an open problem due\nto Tetsuo Asano, showing how to compute the shortest path in a polygon, given\nin a read only memory, using sublinear space and subquadratic time.\nSpecifically, given a simple polygon $\\Polygon$ with $n$ vertices in a read\nonly memory, and additional working memory of size $\\Space$, the new algorithm\ncomputes the shortest path (in $\\Polygon$) in $O( n^2 /\\, \\Space )$ expected\ntime. This requires several new tools, which we believe to be of independent\ninterest.\n", "versions": [{"version": "v1", "created": "Tue, 2 Dec 2014 04:12:05 GMT"}, {"version": "v2", "created": "Sat, 28 Nov 2015 22:14:23 GMT"}], "update_date": "2015-12-01", "authors_parsed": [["Har-Peled", "Sariel", ""]]}, {"id": "1412.0962", "submitter": "Boris Aronov", "authors": "Boris Aronov and Matthew J. Katz", "title": "Batched Point Location in SINR Diagrams via Algebraic Tools", "comments": "full version, significantly extended, submitted for journal\n  publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The SINR model for wireless networks has been extensively studied recently.\nIt tries to model whether a particular transmitter is heard at a specific\nlocation, with $n$ transmitting simultaneously. The SINR diagram consists of\n$n$ regions where each transmitter can be heard and the remaining space where\nno one can be heard.\n  Efficient point location in the SINR diagram, i.e., building a data structure\nto determine, for a query point, whether any transmitter is heard there, and if\nso, which one, has been recently investigated. Previous such planar data\nstructures are constructed in time at least quadratic in $n$ and support\nlogarithmic-time approximate queries. Moreover, the performance of these\ndepends not only on the number $n$ of transmitters and on the approximation\nparameter $\\varepsilon$, but also on some geometric parameters that cannot be\nbounded a priori as a function of $n$ or $\\varepsilon$.\n  We address the question of batched point location queries, i.e., answering\nmany queries simultaneously. Specifically, in one dimension, we can answer $n$\nqueries exactly in amortized polylogarithmic time per query, while in the plane\nwe can do it approximately.\n  All these results can handle arbitrary power assignments to the transmitters.\nMoreover, the amortized query time in these results depends only on $n$ and\n$\\varepsilon$.\n  We also show how to speed up the preprocessing in a previously proposed\npoint-location structure in SINR diagram for uniform-power sites, by almost a\nfull order of magnitude. For this we obtain results on the sensitivity of the\nreception regions to slight changes in the reception threshold, which are of\nindependent interest.\n  Finally, these results demonstrate the (so far underutilized) power of\ncombining algebraic tools with those of computational geometry and other\nfields.\n", "versions": [{"version": "v1", "created": "Tue, 2 Dec 2014 16:20:18 GMT"}, {"version": "v2", "created": "Wed, 3 Dec 2014 02:14:47 GMT"}, {"version": "v3", "created": "Thu, 7 Dec 2017 20:22:17 GMT"}], "update_date": "2017-12-11", "authors_parsed": [["Aronov", "Boris", ""], ["Katz", "Matthew J.", ""]]}, {"id": "1412.1001", "submitter": "Zeyuan Allen-Zhu", "authors": "Zeyuan Allen-Zhu, Zhenyu Liao, Yang Yuan", "title": "Optimization Algorithms for Faster Computational Geometry", "comments": "An abstract of this paper is going to appear in the conference\n  proceedings of ICALP 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study two fundamental problems in computational geometry: finding the\nmaximum inscribed ball (MaxIB) inside a bounded polyhedron defined by $m$\nhyperplanes, and the minimum enclosing ball (MinEB) of a set of $n$ points,\nboth in $d$-dimensional space. We improve the running time of iterative\nalgorithms on\n  MaxIB from $\\tilde{O}(m d \\alpha^3 / \\varepsilon^3)$ to $\\tilde{O}(md + m\n\\sqrt{d} \\alpha / \\varepsilon)$, a speed-up up to $\\tilde{O}(\\sqrt{d} \\alpha^2\n/ \\varepsilon^2)$, and\n  MinEB from $\\tilde{O}(n d / \\sqrt{\\varepsilon})$ to $\\tilde{O}(nd + n\n\\sqrt{d} / \\sqrt{\\varepsilon})$, a speed-up up to $\\tilde{O}(\\sqrt{d})$.\n  Our improvements are based on a novel saddle-point optimization framework. We\npropose a new algorithm $\\mathtt{L1L2SPSolver}$ for solving a class of\nregularized saddle-point problems, and apply a randomized Hadamard space\nrotation which is a technique borrowed from compressive sensing. Interestingly,\nthe motivation of using Hadamard rotation solely comes from our optimization\nview but not the original geometry problem: indeed, it is not immediately clear\nwhy MaxIB or MinEB, as a geometric problem, should be easier to solve if we\nrotate the space by a unitary matrix. We hope that our optimization perspective\nsheds lights on solving other geometric problems as well.\n", "versions": [{"version": "v1", "created": "Tue, 2 Dec 2014 18:15:46 GMT"}, {"version": "v2", "created": "Sat, 5 Dec 2015 04:28:03 GMT"}, {"version": "v3", "created": "Thu, 5 May 2016 20:43:49 GMT"}], "update_date": "2016-05-09", "authors_parsed": [["Allen-Zhu", "Zeyuan", ""], ["Liao", "Zhenyu", ""], ["Yuan", "Yang", ""]]}, {"id": "1412.1039", "submitter": "Sorelle Friedler", "authors": "F. Betul Atalay, Sorelle A. Friedler, and Dianna Xu", "title": "Convex Hull for Probabilistic Points", "comments": "Accepted at SIBGRAPI 2016 - Conference on Graphics, Patterns and\n  Images", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the correctness of an O(n log n) time divide-and-conquer algorithm\nfor the convex hull problem when each input point is a location determined by a\nnormal distribution. We show that the algorithm finds the convex hull of such\nprobabilistic points to precision within some expected correctness determined\nby a user-given confidence value. In order to precisely explain how correct the\nresulting structure is, we introduce a new certificate error model for\ncalculating and understanding approximate geometric error based on the\nfundamental properties of a geometric structure. We show that this new error\nmodel implies correctness under a robust statistical error model, in which each\npoint lies within the hull with probability at least that of the user-given\nconfidence value, for the convex hull problem.\n", "versions": [{"version": "v1", "created": "Tue, 2 Dec 2014 19:52:37 GMT"}, {"version": "v2", "created": "Fri, 5 Aug 2016 15:06:34 GMT"}], "update_date": "2016-08-08", "authors_parsed": [["Atalay", "F. Betul", ""], ["Friedler", "Sorelle A.", ""], ["Xu", "Dianna", ""]]}, {"id": "1412.1060", "submitter": "Sivakanth Gopi", "authors": "Zeev Dvir, Sivakanth Gopi", "title": "On the number of rich lines in truly high dimensional sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove a new upper bound on the number of $r$-rich lines (lines with at\nleast $r$ points) in a `truly' $d$-dimensional configuration of points\n$v_1,\\ldots,v_n \\in \\mathbb{C}^d$. More formally, we show that, if the number\nof $r$-rich lines is significantly larger than $n^2/r^d$ then there must exist\na large subset of the points contained in a hyperplane. We conjecture that the\nfactor $r^d$ can be replaced with a tight $r^{d+1}$. If true, this would\ngeneralize the classic Szemer\\'edi-Trotter theorem which gives a bound of\n$n^2/r^3$ on the number of $r$-rich lines in a planar configuration. This\nconjecture was shown to hold in $\\mathbb{R}^3$ in the seminal work of Guth and\nKatz \\cite{GK10} and was also recently proved over $\\mathbb{R}^4$ (under some\nadditional restrictions) \\cite{SS14}. For the special case of arithmetic\nprogressions ($r$ collinear points that are evenly distanced) we give a bound\nthat is tight up to low order terms, showing that a $d$-dimensional grid\nachieves the largest number of $r$-term progressions.\n  The main ingredient in the proof is a new method to find a low degree\npolynomial that vanishes on many of the rich lines. Unlike previous\napplications of the polynomial method, we do not find this polynomial by\ninterpolation. The starting observation is that the degree $r-2$ Veronese\nembedding takes $r$-collinear points to $r$ linearly dependent images. Hence,\neach collinear $r$-tuple of points, gives us a dependent $r$-tuple of images.\nWe then use the design-matrix method of \\cite{BDWY12} to convert these 'local'\nlinear dependencies into a global one, showing that all the images lie in a\nhyperplane. This then translates into a low degree polynomial vanishing on the\noriginal set.\n", "versions": [{"version": "v1", "created": "Tue, 2 Dec 2014 20:45:22 GMT"}], "update_date": "2014-12-03", "authors_parsed": [["Dvir", "Zeev", ""], ["Gopi", "Sivakanth", ""]]}, {"id": "1412.1241", "submitter": "May Szedl\\'ak", "authors": "Komei Fukuda, Bernd G\\\"artner, May Szedl\\'ak", "title": "Combinatorial Redundancy Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of detecting and removing redundant constraints is fundamental in\noptimization. We focus on the case of linear programs (LPs) in dictionary form,\ngiven by $n$ equality constraints in $n+d$ variables, where the variables are\nconstrained to be nonnegative. A variable $x_r$ is called redundant, if after\nremoving $x_r \\geq 0$ the LP still has the same feasible region. The time\nneeded to solve such an LP is denoted by $LP(n,d)$.\n  It is easy to see that solving $n+d$ LPs of the above size is sufficient to\ndetect all redundancies. The currently fastest practical method is the one by\nClarkson: it solves $n+d$ linear programs, but each of them has at most $s$\nvariables, where $s$ is the number of nonredundant constraints.\n  In the first part we show that knowing all of the finitely many dictionaries\nof the LP is sufficient for the purpose of redundancy detection. A dictionary\nis a matrix that can be thought of as an enriched encoding of a vertex in the\nLP. Moreover - and this is the combinatorial aspect - it is enough to know only\nthe signs of the entries, the actual values do not matter. Concretely we show\nthat for any variable $x_r$ one can find a dictionary, such that its sign\npattern is either a redundancy or nonredundancy certificate for $x_r$.\n  In the second part we show that considering only the sign patterns of the\ndictionary, there is an output sensitive algorithm of running time\n$\\mathcal{O}(d \\cdot (n+d) \\cdot s^{d-1} \\cdot LP(s,d) + d \\cdot s^{d} \\cdot\nLP(n,d))$ to detect all redundancies. In the case where all constraints are in\ngeneral position, the running time is $\\mathcal{O}(s \\cdot LP(n,d) + (n+d)\n\\cdot LP(s,d))$, which is essentially the running time of the Clarkson method.\nOur algorithm extends naturally to a more general setting of arrangements of\noriented topological hyperplane arrangements.\n", "versions": [{"version": "v1", "created": "Wed, 3 Dec 2014 09:09:32 GMT"}], "update_date": "2014-12-04", "authors_parsed": [["Fukuda", "Komei", ""], ["G\u00e4rtner", "Bernd", ""], ["Szedl\u00e1k", "May", ""]]}, {"id": "1412.1398", "submitter": "Sariel Har-Peled", "authors": "Sariel Har-Peled and Nirman Kumar and David M. Mount and Benjamin\n  Raichel", "title": "Space Exploration via Proximity Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate what computational tasks can be performed on a point set in\n$\\Re^d$, if we are only given black-box access to it via nearest-neighbor\nsearch. This is a reasonable assumption if the underlying point set is either\nprovided implicitly, or it is stored in a data structure that can answer such\nqueries. In particular, we show the following: (A) One can compute an\napproximate bi-criteria $k$-center clustering of the point set, and more\ngenerally compute a greedy permutation of the point set. (B) One can decide if\na query point is (approximately) inside the convex-hull of the point set.\n  We also investigate the problem of clustering the given point set, such that\nmeaningful proximity queries can be carried out on the centers of the clusters,\ninstead of the whole point set.\n", "versions": [{"version": "v1", "created": "Wed, 3 Dec 2014 16:51:03 GMT"}], "update_date": "2014-12-04", "authors_parsed": [["Har-Peled", "Sariel", ""], ["Kumar", "Nirman", ""], ["Mount", "David M.", ""], ["Raichel", "Benjamin", ""]]}, {"id": "1412.1401", "submitter": "Kyung-Taek Jun", "authors": "Kyung-Taek Jun", "title": "Throat Finding Algorithms based on Throat Types", "comments": "23 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The three-dimensional geometry and connectivity of pore space determines the\nflow of single-phase incompressible flow. Herein I report on new throat finding\nalgorithms that contribute to finding the exact flow-relevant geometrical\nproperties of the void space, including high porosity samples of X2B images,\nthree-dimensional synchrotron X-ray computed microtomographic images, and\namounting to over 20% porosity. These new algorithms use the modified medial\naxis that comes from the 3DMA-Rock software package. To find accurate throats,\nwe classify three major throat types: mostly planar and simply connected type,\nnon-planar and simply connected type, and non-planar and non-simply connected\ntype. For each type, we make at least one algorithm to find the throats. Here I\nintroduce an example that has a non-planar and simply connected throat, and my\nsolution indicated by one of my algorithms. My five algorithms each calculate\nthe throat for each path. It selects one of them, which has the smallest inner\narea. New algorithms find accurate throats at least 98% among 12 high porosity\nsamples (over 20%). Also, I introduce a new length calculation in the digitized\nimage. The new calculation uses three mathematical concepts: i)\ndifferentiability, ii) implicit function theorem, iii) line integral. The\nresult can convert the discrete boundary of the XMCT image to the real\nboundary. When the real boundary has an arc shape, the new calculation has less\nthan 1% relative error.\n", "versions": [{"version": "v1", "created": "Tue, 28 Oct 2014 06:19:50 GMT"}], "update_date": "2014-12-04", "authors_parsed": [["Jun", "Kyung-Taek", ""]]}, {"id": "1412.1547", "submitter": "Jonathan Spreer", "authors": "Bhaskar Bagchi and Benjamin A. Burton and Basudeb Datta and Nitin\n  Singh and Jonathan Spreer", "title": "Efficient algorithms to decide tightness", "comments": "18 pages, 3 figures", "journal-ref": "32nd International Symposium on Computational Geometry (SoCG\n  2016), Leibniz International Proceedings in Informatics (LIPICS), vol. 51,\n  12:1-12:15, 2016", "doi": "10.4230/LIPIcs.SoCG.2016.12", "report-no": null, "categories": "cs.CG math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tightness is a generalisation of the notion of convexity: a space is tight if\nand only if it is \"as convex as possible\", given its topological constraints.\nFor a simplicial complex, deciding tightness has a straightforward exponential\ntime algorithm, but efficient methods to decide tightness are only known in the\ntrivial setting of triangulated surfaces.\n  In this article, we present a new polynomial time procedure to decide\ntightness for triangulations of $3$-manifolds -- a problem which previously was\nthought to be hard. Furthermore, we describe an algorithm to decide general\ntightness in the case of $4$-dimensional combinatorial manifolds which is fixed\nparameter tractable in the treewidth of the $1$-skeletons of their vertex\nlinks, and we present an algorithm to decide $\\mathbb{F}_2$-tightness for weak\npseudomanifolds $M$ of arbitrary but fixed dimension which is fixed parameter\ntractable in the treewidth of the dual graph of $M$.\n", "versions": [{"version": "v1", "created": "Thu, 4 Dec 2014 03:54:03 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Bagchi", "Bhaskar", ""], ["Burton", "Benjamin A.", ""], ["Datta", "Basudeb", ""], ["Singh", "Nitin", ""], ["Spreer", "Jonathan", ""]]}, {"id": "1412.1680", "submitter": "Micka\\\"el Buchet", "authors": "Micka\\\"el Buchet, Fr\\'ed\\'eric Chazal, Tamal K. Dey, Fengtao Fan,\n  Steve Y. Oudot, Yusu Wang", "title": "Topological analysis of scalar fields with outliers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Given a real-valued function $f$ defined over a manifold $M$ embedded in\n$\\mathbb{R}^d$, we are interested in recovering structural information about\n$f$ from the sole information of its values on a finite sample $P$. Existing\nmethods provide approximation to the persistence diagram of $f$ when geometric\nnoise and functional noise are bounded. However, they fail in the presence of\naberrant values, also called outliers, both in theory and practice.\n  We propose a new algorithm that deals with outliers. We handle aberrant\nfunctional values with a method inspired from the k-nearest neighbors\nregression and the local median filtering, while the geometric outliers are\nhandled using the distance to a measure. Combined with topological results on\nnested filtrations, our algorithm performs robust topological analysis of\nscalar fields in a wider range of noise models than handled by current methods.\nWe provide theoretical guarantees and experimental results on the quality of\nour approximation of the sampled scalar field.\n", "versions": [{"version": "v1", "created": "Thu, 4 Dec 2014 14:41:56 GMT"}, {"version": "v2", "created": "Mon, 6 Apr 2015 15:47:34 GMT"}, {"version": "v3", "created": "Tue, 7 Apr 2015 19:45:43 GMT"}], "update_date": "2015-04-08", "authors_parsed": [["Buchet", "Micka\u00ebl", ""], ["Chazal", "Fr\u00e9d\u00e9ric", ""], ["Dey", "Tamal K.", ""], ["Fan", "Fengtao", ""], ["Oudot", "Steve Y.", ""], ["Wang", "Yusu", ""]]}, {"id": "1412.1683", "submitter": "Ioannis Psarros", "authors": "Evangelos Anagnostopoulos, Ioannis Z. Emiris, and Ioannis Psarros", "title": "Randomized embeddings with slack, and high-dimensional Approximate\n  Nearest Neighbor", "comments": "15 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The approximate nearest neighbor problem ($\\epsilon$-ANN) in high dimensional\nEuclidean space has been mainly addressed by Locality Sensitive Hashing (LSH),\nwhich has polynomial dependence in the dimension, sublinear query time, but\nsubquadratic space requirement. In this paper, we introduce a new definition of\n\"low-quality\" embeddings for metric spaces. It requires that, for some query\npoint $q$, there exists an approximate nearest neighbor among the pre-images of\nthe $k>1$ approximate nearest neighbors in the target space. Focusing on\nEuclidean spaces, we employ random projections in order to reduce the original\nproblem to one in a space of dimension inversely proportional to $k$.\n  The $k$ approximate nearest neighbors can be efficiently retrieved by a data\nstructure such as BBD-trees. The same approach is applied to the problem of\ncomputing an approximate near neighbor, where we obtain a data structure\nrequiring linear space, and query time in $O(d n^{\\rho})$, for $\\rho\\approx\n1-\\epsilon^2/\\log(1/\\epsilon)$. This directly implies a solution for\n$\\epsilon$-ANN, while achieving a better exponent in the query time than the\nmethod based on BBD-trees. Better bounds are obtained in the case of doubling\nsubsets of $\\ell_2$, by combining our method with $r$-nets.\n  We implement our method in C++, and present experimental results in dimension\nup to $500$ and $10^6$ points, which show that performance is better than\npredicted by the analysis. In addition, we compare our ANN approach to E2LSH,\nwhich implements LSH, and we show that the theoretical advantages of each\nmethod are reflected on their actual performance.\n", "versions": [{"version": "v1", "created": "Thu, 4 Dec 2014 14:46:29 GMT"}, {"version": "v2", "created": "Sat, 3 Dec 2016 11:54:42 GMT"}], "update_date": "2016-12-06", "authors_parsed": [["Anagnostopoulos", "Evangelos", ""], ["Emiris", "Ioannis Z.", ""], ["Psarros", "Ioannis", ""]]}, {"id": "1412.1769", "submitter": "Bartosz Walczak", "authors": "Martin Balko, V\\'it Jel\\'inek, Pavel Valtr, Bartosz Walczak", "title": "On the Beer index of convexity and its variants", "comments": "Final version, minor revision", "journal-ref": "Discrete Comput. Geom. 57 (2017) 179-214", "doi": "10.1007/s00454-016-9821-3", "report-no": null, "categories": "math.MG cs.CG math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $S$ be a subset of $\\mathbb{R}^d$ with finite positive Lebesgue measure.\nThe Beer index of convexity $\\operatorname{b}(S)$ of $S$ is the probability\nthat two points of $S$ chosen uniformly independently at random see each other\nin $S$. The convexity ratio $\\operatorname{c}(S)$ of $S$ is the Lebesgue\nmeasure of the largest convex subset of $S$ divided by the Lebesgue measure of\n$S$. We investigate the relationship between these two natural measures of\nconvexity.\n  We show that every set $S\\subseteq\\mathbb{R}^2$ with simply connected\ncomponents satisfies $\\operatorname{b}(S)\\leq\\alpha\\operatorname{c}(S)$ for an\nabsolute constant $\\alpha$, provided $\\operatorname{b}(S)$ is defined. This\nimplies an affirmative answer to the conjecture of Cabello et al. that this\nestimate holds for simple polygons.\n  We also consider higher-order generalizations of $\\operatorname{b}(S)$. For\n$1\\leq k\\leq d$, the $k$-index of convexity $\\operatorname{b}_k(S)$ of a set\n$S\\subseteq\\mathbb{R}^d$ is the probability that the convex hull of a\n$(k+1)$-tuple of points chosen uniformly independently at random from $S$ is\ncontained in $S$. We show that for every $d\\geq 2$ there is a constant\n$\\beta(d)>0$ such that every set $S\\subseteq\\mathbb{R}^d$ satisfies\n$\\operatorname{b}_d(S)\\leq\\beta\\operatorname{c}(S)$, provided\n$\\operatorname{b}_d(S)$ exists. We provide an almost matching lower bound by\nshowing that there is a constant $\\gamma(d)>0$ such that for every\n$\\varepsilon\\in(0,1)$ there is a set $S\\subseteq\\mathbb{R}^d$ of Lebesgue\nmeasure $1$ satisfying $\\operatorname{c}(S)\\leq\\varepsilon$ and\n$\\operatorname{b}_d(S)\\geq\\gamma\\frac{\\varepsilon}{\\log_2{1/\\varepsilon}}\\geq\\gamma\\frac{\\operatorname{c}(S)}{\\log_2{1/\\operatorname{c}(S)}}$.\n", "versions": [{"version": "v1", "created": "Thu, 4 Dec 2014 18:59:05 GMT"}, {"version": "v2", "created": "Thu, 29 Dec 2016 16:12:35 GMT"}], "update_date": "2016-12-30", "authors_parsed": [["Balko", "Martin", ""], ["Jel\u00ednek", "V\u00edt", ""], ["Valtr", "Pavel", ""], ["Walczak", "Bartosz", ""]]}, {"id": "1412.1871", "submitter": "Estanislao Herscovich", "authors": "Estanislao Herscovich", "title": "A higher homotopic extension of persistent (co)homology", "comments": "Any comment(s) would be highly appreciated", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AT cs.CG cs.CV math.KT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our objective in this article is to show a possibly interesting structure of\nhomotopic nature appearing in persistent (co)homology. Assuming that the\nfiltration of the (say) simplicial set embedded in a finite dimensional vector\nspace induces a multiplicative filtration (which would not be a so harsh\nhypothesis in our setting) on the dg algebra given by the complex of simplicial\ncochains, we may use a result by T. Kadeishvili to get a unique (up to\nnoncanonical equivalence) A_infinity-algebra structure on the complete\npersistent cohomology of the filtered simplicial (or topological) set. We then\nprovide a construction of a (pseudo)metric on the set of all (generalized)\nbarcodes (that is, of all cohomological degrees) enriched with the\nA_infinity-algebra structure stated before, refining the usual bottleneck\nmetric, and which is also independent of the particular A_infinity-algebra\nstructure chosen (among those equivalent to each other). We think that this\ndistance might deserve some attention for topological data analysis, for it in\nparticular can recognize different linking or foldings patterns, as in the\nBorromean rings. As an aside, we give a simple proof of a result relating the\nbarcode structure between persistent homology and cohomology. This result was\nobserved in a recent article by V. de Silva, D. Morozov and M.\nVejdemo-Johansson under some restricted assumptions, which we do not suppose.\n", "versions": [{"version": "v1", "created": "Fri, 5 Dec 2014 01:09:19 GMT"}], "update_date": "2014-12-08", "authors_parsed": [["Herscovich", "Estanislao", ""]]}, {"id": "1412.2291", "submitter": "Konstantin Usevich", "authors": "Konstantin Usevich and Ivan Markovsky", "title": "Adjusted least squares fitting of algebraic hypersurfaces", "comments": "30 pages, 10 figures", "journal-ref": null, "doi": "10.1016/j.laa.2015.07.023", "report-no": null, "categories": "stat.CO cs.CG cs.CV math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of fitting a set of points in Euclidean space by an\nalgebraic hypersurface. We assume that points on a true hypersurface, described\nby a polynomial equation, are corrupted by zero mean independent Gaussian\nnoise, and we estimate the coefficients of the true polynomial equation. The\nadjusted least squares estimator accounts for the bias present in the ordinary\nleast squares estimator. The adjusted least squares estimator is based on\nconstructing a quasi-Hankel matrix, which is a bias-corrected matrix of\nmoments. For the case of unknown noise variance, the estimator is defined as a\nsolution of a polynomial eigenvalue problem. In this paper, we present new\nresults on invariance properties of the adjusted least squares estimator and an\nimproved algorithm for computing the estimator for an arbitrary set of\nmonomials in the polynomial equation.\n", "versions": [{"version": "v1", "created": "Sat, 6 Dec 2014 22:22:33 GMT"}, {"version": "v2", "created": "Thu, 20 Aug 2015 17:00:19 GMT"}], "update_date": "2015-08-21", "authors_parsed": [["Usevich", "Konstantin", ""], ["Markovsky", "Ivan", ""]]}, {"id": "1412.2300", "submitter": "Haitao Wang", "authors": "Aaron M. Andrews and Haitao Wang", "title": "Minimizing the Aggregate Movements for Interval Coverage", "comments": "33 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider an interval coverage problem. Given $n$ intervals of the same\nlength on a line $L$ and a line segment $B$ on $L$, we want to move the\nintervals along $L$ such that every point of $B$ is covered by at least one\ninterval and the sum of the moving distances of all intervals is minimized. As\na basic geometry problem, it has applications in mobile sensor barrier coverage\nin wireless sensor networks. The previous work solved the problem in $O(n^2)$\ntime. In this paper, by discovering many interesting observations and\ndeveloping new algorithmic techniques, we present an $O(n\\log n)$ time\nalgorithm. We also show an $\\Omega(n\\log n)$ time lower bound for this problem,\nwhich implies the optimality of our algorithm.\n", "versions": [{"version": "v1", "created": "Sun, 7 Dec 2014 00:43:36 GMT"}], "update_date": "2014-12-09", "authors_parsed": [["Andrews", "Aaron M.", ""], ["Wang", "Haitao", ""]]}, {"id": "1412.2562", "submitter": "Vincent Delos", "authors": "Vincent Delos (I2M), Denis Teissandier (I2M)", "title": "Minkowski sum of HV-polytopes in Rn", "comments": "4th Annual International Conference on Computational Mathematics,\n  Computational Geometry and Statistics, Jan 2015, Singapore, Singapore", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.MS physics.class-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Minkowski sums cover a wide range of applications in many different fields\nlike algebra, morphing, robotics, mechanical CAD/CAM systems ... This paper\ndeals with sums of polytopes in a n dimensional space provided that both\nH-representation and V-representation are available i.e. the polytopes are\ndescribed by both their half-spaces and vertices. The first method uses the\npolytope normal fans and relies on the ability to intersect dual polyhedral\ncones. Then we introduce another way of considering Minkowski sums of polytopes\nbased on the primal polyhedral cones attached to each vertex.\n", "versions": [{"version": "v1", "created": "Mon, 8 Dec 2014 13:56:17 GMT"}], "update_date": "2014-12-09", "authors_parsed": [["Delos", "Vincent", "", "I2M"], ["Teissandier", "Denis", "", "I2M"]]}, {"id": "1412.2564", "submitter": "Vincent Delos", "authors": "Vincent Delos (I2M), Denis Teissandier (I2M)", "title": "Minkowski Sum of Polytopes Defined by Their Vertices", "comments": null, "journal-ref": "Journal of Applied Mathematics and Physics (JAMP), Scientific\n  Research Publishing, 2015, 3 (1), pp.62-67", "doi": "10.4236/jamp.2015.31008", "report-no": null, "categories": "cs.CG cs.MS physics.class-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Minkowski sums are of theoretical interest and have applications in fields\nrelated to industrial backgrounds. In this paper we focus on the specific case\nof summing polytopes as we want to solve the tolerance analysis problem\ndescribed in [1]. Our approach is based on the use of linear programming and is\nsolvable in polynomial time. The algorithm we developed can be implemented and\nparallelized in a very easy way.\n", "versions": [{"version": "v1", "created": "Mon, 8 Dec 2014 13:57:21 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2015 09:39:04 GMT"}], "update_date": "2015-06-17", "authors_parsed": [["Delos", "Vincent", "", "I2M"], ["Teissandier", "Denis", "", "I2M"]]}, {"id": "1412.3290", "submitter": "Marc Pouget", "authors": "R\\'emi Imbach (INRIA Nancy - Grand Est / LORIA), Guillaume Moroz\n  (INRIA Nancy - Grand Est / LORIA), Marc Pouget (INRIA Nancy - Grand Est /\n  LORIA)", "title": "Numeric certified algorithm for the topology of resultant and\n  discriminant curves", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS cs.SC math.AG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $\\mathcal C$ be a real plane algebraic curve defined by the resultant of\ntwo polynomials (resp. by the discriminant of a polynomial). Geometrically such\na curve is the projection of the intersection of the surfaces\n$P(x,y,z)=Q(x,y,z)=0$ (resp. $P(x,y,z)=\\frac{\\partial P}{\\partial\nz}(x,y,z)=0$), and generically its singularities are nodes (resp. nodes and\nordinary cusps). State-of-the-art numerical algorithms compute the topology of\nsmooth curves but usually fail to certify the topology of singular ones. The\nmain challenge is to find practical numerical criteria that guarantee the\nexistence and the uniqueness of a singularity inside a given box $B$, while\nensuring that $B$ does not contain any closed loop of $\\mathcal{C}$. We solve\nthis problem by first providing a square deflation system, based on\nsubresultants, that can be used to certify numerically whether $B$ contains a\nunique singularity $p$ or not. Then we introduce a numeric adaptive separation\ncriterion based on interval arithmetic to ensure that the topology of $\\mathcal\nC$ in $B$ is homeomorphic to the local topology at $p$. Our algorithms are\nimplemented and experiments show their efficiency compared to state-of-the-art\nsymbolic or homotopic methods.\n", "versions": [{"version": "v1", "created": "Wed, 10 Dec 2014 12:57:08 GMT"}, {"version": "v2", "created": "Sat, 23 May 2015 10:22:21 GMT"}], "update_date": "2015-05-26", "authors_parsed": [["Imbach", "R\u00e9mi", "", "INRIA Nancy - Grand Est / LORIA"], ["Moroz", "Guillaume", "", "INRIA Nancy - Grand Est / LORIA"], ["Pouget", "Marc", "", "INRIA Nancy - Grand Est /\n  LORIA"]]}, {"id": "1412.3347", "submitter": "Wolfgang Mulzer", "authors": "Wolfgang Mulzer, Yannik Stein", "title": "Computational Aspects of the Colorful Carath\\'eodory Theorem", "comments": "28 pages, 7 figures. A preliminary version appeared at SoCG 2015", "journal-ref": "Discrete and Computational Geometry (DCG), 60(3), October 2018,\n  pp. 720-755", "doi": "10.1007/s00454-018-9979-y", "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $C_1,\\dots,C_{d+1}\\subset \\mathbb{R}^d$ be $d+1$ point sets, each\ncontaining the origin in its convex hull. We call these sets color classes, and\nwe call a sequence $p_1, \\dots, p_{d+1}$ with $p_i \\in C_i$, for $i = 1, \\dots,\nd+1$, a colorful choice. The colorful Carath\\'eodory theorem guarantees the\nexistence of a colorful choice that also contains the origin in its convex\nhull. The computational complexity of finding such a colorful choice (CCP) is\nunknown. This is particularly interesting in the light of polynomial-time\nreductions from several related problems, such as computing centerpoints, to\nCCP.\n  We define a novel notion of approximation that is compatible with the\npolynomial-time reductions to CCP: a sequence that contains at most $k$ points\nfrom each color class is called a $k$-colorful choice. We present an algorithm\nthat for any fixed $\\varepsilon > 0$, outputs an $\\lceil \\epsilon\nd\\rceil$-colorful choice containing the origin in its convex hull in polynomial\ntime.\n  Furthermore, we consider a related problem of CCP: in the nearest colorful\npolytope problem (NCP), we are given sets $C_1,\\dots,C_n\\subset\\mathbb{R}^d$\nthat do not necessarily contain the origin in their convex hulls. The goal is\nto find a colorful choice whose convex hull minimizes the distance to the\norigin. We show that computing a local optimum for NCP is PLS-complete, while\ncomputing a global optimum is NP-hard.\n", "versions": [{"version": "v1", "created": "Wed, 10 Dec 2014 15:57:52 GMT"}, {"version": "v2", "created": "Mon, 5 Feb 2018 14:26:13 GMT"}], "update_date": "2018-08-31", "authors_parsed": [["Mulzer", "Wolfgang", ""], ["Stein", "Yannik", ""]]}, {"id": "1412.3374", "submitter": "Claudia Landi", "authors": "Claudia Landi", "title": "The rank invariant stability via interleavings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A lower bound for the interleaving distance on persistence vector spaces is\ngiven in terms of rank invariants. This offers an alternative proof of the\nstability of rank invariants.\n", "versions": [{"version": "v1", "created": "Wed, 10 Dec 2014 17:19:30 GMT"}], "update_date": "2014-12-11", "authors_parsed": [["Landi", "Claudia", ""]]}, {"id": "1412.3922", "submitter": "Kunal Dutta", "authors": "Kunal Dutta, Arijit Ghosh", "title": "Size sensitive packing number for Hamming cube and its consequences", "comments": "At the time of submission, we have become aware of a similar packing\n  result proven simultaneously by Ezra. However, we note that our proof of the\n  main packing lemma is quite different from hers. Also, the focus of our paper\n  is on discrepancy bounds and sampling complexity", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CG cs.LG math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove a size-sensitive version of Haussler's Packing\nlemma~\\cite{Haussler92spherepacking} for set-systems with bounded primal\nshatter dimension, which have an additional {\\em size-sensitive property}. This\nanswers a question asked by Ezra~\\cite{Ezra-sizesendisc-soda-14}. We also\npartially address another point raised by Ezra regarding overcounting of sets\nin her chaining procedure. As a consequence of these improvements, we get an\nimprovement on the size-sensitive discrepancy bounds for set systems with the\nabove property. Improved bounds on the discrepancy for these special set\nsystems also imply an improvement in the sizes of {\\em relative $(\\varepsilon,\n\\delta)$-approximations} and $(\\nu, \\alpha)$-samples.\n", "versions": [{"version": "v1", "created": "Fri, 12 Dec 2014 08:46:28 GMT"}], "update_date": "2014-12-18", "authors_parsed": [["Dutta", "Kunal", ""], ["Ghosh", "Arijit", ""]]}, {"id": "1412.3984", "submitter": "Frank Hoffmann", "authors": "Frank Hoffmann, Klaus Kriegel, and Max Willert", "title": "Almost Tight Bounds for Conflict-Free Chromatic Guarding of Orthogonal\n  Galleries", "comments": "18 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address recently proposed chromatic versions of the classic Art Gallery\nProblem. Assume a simple polygon $P$ is guarded by a finite set of point guards\nand each guard is assigned one of $t$ colors. Such a chromatic guarding is said\nto be conflict-free if each point $p\\in P$ sees at least one guard with a\nunique color among all guards visible from $p$. The goal is to establish bounds\non the function $\\chi_{cf}(n)$ of the number of colors sufficient to guarantee\nthe existence of a conflict-free chromatic guarding for any $n$-vertex polygon.\nB\\\"artschi and Suri showed $\\chi_{cf}(n)\\in O(\\log n)$ (Algorithmica, 2014) for\nsimple orthogonal polygons and the same bound applies to general simple\npolygons (B\\\"artschi et al., SoCG 2014). In this paper, we assume the\nr-visibility model instead of standard line visibility. Points $p$ and $q$ in\nan orthogonal polygon are r-visible to each other if the rectangle spanned by\nthe points is contained in $P$. For this model we show $\\chi_{cf}(n)\\in\nO(\\log\\log n)$ and $\\chi_{cf}(n)\\in \\Omega(\\log\\log n /\\log\\log\\log n)$. Most\ninterestingly, we can show that the lower bound proof extends to guards with\nline visibility. To this end we introduce and utilize a novel discrete\ncombinatorial structure called multicolor tableau. This is the first\nnon-trivial lower bound for this problem setting.Furthermore, for the strong\nchromatic version of the problem, where all guards r-visible from a point must\nhave distinct colors, we prove a $\\Theta(\\log n)$-bound. Our results can be\ninterpreted as coloring results for special geometric hypergraphs.\n", "versions": [{"version": "v1", "created": "Fri, 12 Dec 2014 13:18:47 GMT"}], "update_date": "2014-12-15", "authors_parsed": [["Hoffmann", "Frank", ""], ["Kriegel", "Klaus", ""], ["Willert", "Max", ""]]}, {"id": "1412.3987", "submitter": "Vissarion Fisikopoulos", "authors": "Ioannis Z. Emiris, Vissarion Fisikopoulos, Bernd G\\\"artner", "title": "Efficient edge-skeleton computation for polytopes defined by oracles", "comments": "22 pages, 2 figures", "journal-ref": "Journal of Symbolic Computation 2016", "doi": "10.1016/j.jsc.2015.06.001", "report-no": null, "categories": "cs.CG cs.SC math.OC", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  In general dimension, there is no known total polynomial algorithm for either\nconvex hull or vertex enumeration, i.e. an algorithm whose complexity depends\npolynomially on the input and output sizes. It is thus important to identify\nproblems (and polytope representations) for which total polynomial-time\nalgorithms can be obtained. We offer the first total polynomial-time algorithm\nfor computing the edge-skeleton (including vertex enumeration) of a polytope\ngiven by an optimization or separation oracle, where we are also given a\nsuperset of its edge directions. We also offer a space-efficient variant of our\nalgorithm by employing reverse search. All complexity bounds refer to the\n(oracle) Turing machine model. There is a number of polytope classes naturally\ndefined by oracles; for some of them neither vertex nor facet representation is\nobvious. We consider two main applications, where we obtain (weakly) total\npolynomial-time algorithms: Signed Minkowski sums of convex polytopes, where\npolytopes can be subtracted provided the signed sum is a convex polytope, and\ncomputation of secondary, resultant, and discriminant polytopes. Further\napplications include convex combinatorial optimization and convex integer\nprogramming, where we offer a new approach, thus removing the complexity's\nexponential dependence in the dimension.\n", "versions": [{"version": "v1", "created": "Fri, 12 Dec 2014 13:34:22 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Emiris", "Ioannis Z.", ""], ["Fisikopoulos", "Vissarion", ""], ["G\u00e4rtner", "Bernd", ""]]}, {"id": "1412.4988", "submitter": "Arnaud de Mesmay", "authors": "Benjamin A. Burton, \\'Eric Colin de Verdi\\`ere, Arnaud de Mesmay", "title": "On the Complexity of Immersed Normal Surfaces", "comments": "17 pages, under journal submission", "journal-ref": "Geom. Topol. 20 (2016) 1061-1083", "doi": "10.2140/gt.2016.20.1061", "report-no": null, "categories": "math.GT cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Normal surface theory, a tool to represent surfaces in a triangulated\n3-manifold combinatorially, is ubiquitous in computational 3-manifold theory.\nIn this paper, we investigate a relaxed notion of normal surfaces where we\nremove the quadrilateral conditions. This yields normal surfaces that are no\nlonger embedded. We prove that it is NP-hard to decide whether such a surface\nis immersed. Our proof uses a reduction from Boolean constraint satisfaction\nproblems where every variable appears in at most two clauses, using a\nclassification theorem of Feder. We also investigate variants, and provide a\npolynomial-time algorithm to test for a local version of this problem.\n", "versions": [{"version": "v1", "created": "Tue, 16 Dec 2014 13:03:16 GMT"}], "update_date": "2016-05-04", "authors_parsed": [["Burton", "Benjamin A.", ""], ["de Verdi\u00e8re", "\u00c9ric Colin", ""], ["de Mesmay", "Arnaud", ""]]}, {"id": "1412.5010", "submitter": "Jens Ma{\\ss}berg", "authors": "Jens Ma{\\ss}berg", "title": "The rectilinear Steiner tree problem with given topology and length\n  restrictions", "comments": "14 pages", "journal-ref": "Computing and Combinatorics, Lecture Notes in Computer Science,\n  Volume 9198, 2015, pp 445-456", "doi": "10.1007/978-3-319-21398-9_35", "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of embedding the Steiner points of a Steiner tree\nwith given topology into the rectilinear plane. Thereby, the length of the path\nbetween a distinguished terminal and each other terminal must not exceed given\nlength restrictions. We want to minimize the total length of the tree.\n  The problem can be formulated as a linear program and therefore it is\nsolvable in polynomial time. In this paper we analyze the structure of feasible\nembeddings and give a combinatorial polynomial time algorithm for the problem.\nOur algorithm combines a dynamic programming approach and binary search and\nrelies on the total unimodularity of a matrix appearing in a sub-problem.\n", "versions": [{"version": "v1", "created": "Tue, 16 Dec 2014 14:21:39 GMT"}], "update_date": "2015-08-19", "authors_parsed": [["Ma\u00dfberg", "Jens", ""]]}, {"id": "1412.5034", "submitter": "Mikkel Abrahamsen", "authors": "Mikkel Abrahamsen", "title": "Spiral Toolpaths for High-Speed Machining of 2D Pockets with or without\n  Islands", "comments": "22 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe new methods for the construction of spiral toolpaths for\nhigh-speed machining. In the simplest case, our method takes a polygon as input\nand a number $\\delta>0$ and returns a spiral starting at a central point in the\npolygon, going around towards the boundary while morphing to the shape of the\npolygon. The spiral consists of linear segments and circular arcs, it is $G^1$\ncontinuous, it has no self-intersections, and the distance from each point on\nthe spiral to each of the neighboring revolutions is at most $\\delta$. Our\nmethod has the advantage over previously described methods that it is easily\nadjustable to the case where there is an island in the polygon to be avoided by\nthe spiral. In that case, the spiral starts at the island and morphs the island\nto the outer boundary of the polygon. It is shown how to apply that method to\nmake significantly shorter spirals in polygons with no islands. Finally, we\nshow how to make a spiral in a polygon with multiple islands by connecting the\nislands into one island.\n", "versions": [{"version": "v1", "created": "Tue, 16 Dec 2014 15:17:15 GMT"}, {"version": "v2", "created": "Wed, 17 Dec 2014 06:44:42 GMT"}, {"version": "v3", "created": "Sat, 20 Dec 2014 09:10:07 GMT"}, {"version": "v4", "created": "Tue, 20 Jan 2015 12:40:54 GMT"}], "update_date": "2015-01-21", "authors_parsed": [["Abrahamsen", "Mikkel", ""]]}, {"id": "1412.5153", "submitter": "Pablo P\\'erez-Lantero", "authors": "Pablo P\\'erez-Lantero", "title": "Area and Perimeter of the Convex Hull of Stochastic Points", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a set $P$ of $n$ points in the plane, we study the computation of the\nprobability distribution function of both the area and perimeter of the convex\nhull of a random subset $S$ of $P$. The random subset $S$ is formed by drawing\neach point $p$ of $P$ independently with a given rational probability $\\pi_p$.\nFor both measures of the convex hull, we show that it is \\#P-hard to compute\nthe probability that the measure is at least a given bound $w$. For\n$\\varepsilon\\in(0,1)$, we provide an algorithm that runs in\n$O(n^{6}/\\varepsilon)$ time and returns a value that is between the probability\nthat the area is at least $w$, and the probability that the area is at least\n$(1-\\varepsilon)w$. For the perimeter, we show a similar algorithm running in\n$O(n^{6}/\\varepsilon)$ time. Finally, given $\\varepsilon,\\delta\\in(0,1)$ and\nfor any measure, we show an $O(n\\log n+ (n/\\varepsilon^2)\\log(1/\\delta))$-time\nMonte Carlo algorithm that returns a value that, with probability of success at\nleast $1-\\delta$, differs at most $\\varepsilon$ from the probability that the\nmeasure is at least $w$.\n", "versions": [{"version": "v1", "created": "Tue, 16 Dec 2014 20:25:55 GMT"}, {"version": "v2", "created": "Fri, 8 May 2015 19:31:43 GMT"}, {"version": "v3", "created": "Wed, 9 Sep 2015 18:43:21 GMT"}], "update_date": "2015-09-10", "authors_parsed": [["P\u00e9rez-Lantero", "Pablo", ""]]}, {"id": "1412.5215", "submitter": "Esther Ezra", "authors": "Esther Ezra", "title": "Shallow Packings in Geometry", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We refine the bound on the packing number, originally shown by Haussler, for\nshallow geometric set systems. Specifically, let $\\V$ be a finite set system\ndefined over an $n$-point set $X$; we view $\\V$ as a set of indicator vectors\nover the $n$-dimensional unit cube. A $\\delta$-separated set of $\\V$ is a\nsubcollection $\\W$, s.t. the Hamming distance between each pair $\\uu, \\vv \\in\n\\W$ is greater than $\\delta$, where $\\delta > 0$ is an integer parameter. The\n$\\delta$-packing number is then defined as the cardinality of the largest\n$\\delta$-separated subcollection of $\\V$. Haussler showed an asymptotically\ntight bound of $\\Theta((n/\\delta)^d)$ on the $\\delta$-packing number if $\\V$\nhas VC-dimension (or \\emph{primal shatter dimension}) $d$. We refine this bound\nfor the scenario where, for any subset, $X' \\subseteq X$ of size $m \\le n$ and\nfor any parameter $1 \\le k \\le m$, the number of vectors of length at most $k$\nin the restriction of $\\V$ to $X'$ is only $O(m^{d_1} k^{d-d_1})$, for a fixed\ninteger $d > 0$ and a real parameter $1 \\le d_1 \\le d$ (this generalizes the\nstandard notion of \\emph{bounded primal shatter dimension} when $d_1 = d$). In\nthis case when $\\V$ is \"$k$-shallow\" (all vector lengths are at most $k$), we\nshow that its $\\delta$-packing number is $O(n^{d_1} k^{d-d_1}/\\delta^d)$,\nmatching Haussler's bound for the special cases where $d_1=d$ or $k=n$. As an\nimmediate consequence we conclude that set systems of halfspaces, balls, and\nparallel slabs defined over $n$ points in $d$-space admit better packing\nnumbers when $k$ is smaller than $n$. Last but not least, we describe\napplications to (i) spanning trees of low total crossing number, and (ii)\ngeometric discrepancy, based on previous work by the author.\n", "versions": [{"version": "v1", "created": "Tue, 16 Dec 2014 22:19:40 GMT"}], "update_date": "2014-12-18", "authors_parsed": [["Ezra", "Esther", ""]]}, {"id": "1412.5697", "submitter": "Zahed Rahmati", "authors": "Zahed Rahmati, Mohammad Ali Abam, Valerie King, Sue Whitesides", "title": "Kinetic $k$-Semi-Yao Graph and its Applications", "comments": "arXiv admin note: text overlap with arXiv:1307.2700, arXiv:1406.5554", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new proximity graph, called the $k$-Semi-Yao graph\n($k$-SYG), on a set $P$ of points in $\\mathbb{R}^d$, which is a supergraph of\nthe $k$-nearest neighbor graph ($k$-NNG) of $P$. We provide a kinetic data\nstructure (KDS) to maintain the $k$-SYG on moving points, where the trajectory\nof each point is a polynomial function whose degree is bounded by some\nconstant. Our technique gives the first KDS for the theta graph (\\ie, $1$-SYG)\nin $\\mathbb{R}^d$. It generalizes and improves on previous work on maintaining\nthe theta graph in $\\mathbb{R}^2$.\n  As an application, we use the kinetic $k$-SYG to provide the first KDS for\nmaintenance of all the $k$-nearest neighbors in $\\mathbb{R}^d$, for any $k\\geq\n1$. Previous works considered the $k=1$ case only. Our KDS for all the\n$1$-nearest neighbors is deterministic. The best previous KDS for all the\n$1$-nearest neighbors in $ \\mathbb{R}^d$ is randomized. Our structure and\nanalysis are simpler and improve on this work for the $k=1$ case. We also\nprovide a KDS for all the $(1+\\epsilon)$-nearest neighbors, which in fact gives\nbetter performance than previous KDS's for maintenance of all the exact\n$1$-nearest neighbors.\n  As another application, we present the first KDS for answering reverse\n$k$-nearest neighbor queries on moving points in $ \\mathbb{R}^d$, for any\n$k\\geq 1$.\n", "versions": [{"version": "v1", "created": "Thu, 18 Dec 2014 01:34:32 GMT"}], "update_date": "2014-12-19", "authors_parsed": [["Rahmati", "Zahed", ""], ["Abam", "Mohammad Ali", ""], ["King", "Valerie", ""], ["Whitesides", "Sue", ""]]}, {"id": "1412.6065", "submitter": "Elmar Langetepe", "authors": "Rolf Klein (1), Elmar Langetepe (1), Christos Levcopoulos (2) ((1)\n  University of Bonn, Germany, Institute of Computer Science I, (2) University\n  of Lund, Sweden, Department of Computer Science)", "title": "A Fire Fighter's Problem", "comments": "A preliminary version of the paper was presented at SoCG 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suppose that a circular fire spreads in the plane at unit speed. A single\nfire fighter can build a barrier at speed $v>1$. How large must $v$ be to\nensure that the fire can be contained, and how should the fire fighter proceed?\nWe contribute two results.\n  First, we analyze the natural curve $\\mbox{FF}_v$ that develops when the\nfighter keeps building, at speed $v$, a barrier along the boundary of the\nexpanding fire. We prove that the behavior of this spiralling curve is governed\nby a complex function $(e^{w Z} - s \\, Z)^{-1}$, where $w$ and $s$ are real\nfunctions of $v$. For $v>v_c=2.6144 \\ldots$ all zeroes are complex conjugate\npairs. If $\\phi$ denotes the complex argument of the conjugate pair nearest to\nthe origin then, by residue calculus, the fire fighter needs $\\Theta( 1/\\phi)$\nrounds before the fire is contained. As $v$ decreases towards $v_c$ these two\nzeroes merge into a real one, so that argument $\\phi$ goes to~0. Thus, curve\n$\\mbox{FF}_v$ does not contain the fire if the fighter moves at speed $v=v_c$.\n(That speed $v>v_c$ is sufficient for containing the fire has been proposed\nbefore by Bressan et al. [7], who constructed a sequence of logarithmic spiral\nsegments that stay strictly away from the fire.)\n  Second, we show that any curve that visits the four coordinate half-axes in\ncyclic order, and in inreasing distances from the origin, needs speed\n$v>1.618\\ldots$, the golden ratio, in order to contain the fire.\n  Keywords: Motion Planning, Dynamic Environments, Spiralling strategies, Lower\nand upper bounds\n", "versions": [{"version": "v1", "created": "Tue, 2 Dec 2014 10:46:13 GMT"}, {"version": "v2", "created": "Fri, 15 Apr 2016 13:14:03 GMT"}], "update_date": "2016-04-18", "authors_parsed": [["Klein", "Rolf", ""], ["Langetepe", "Elmar", ""], ["Levcopoulos", "Christos", ""]]}, {"id": "1412.6619", "submitter": "Daniel Lu", "authors": "Daniel Lu", "title": "Planar lower envelope of monotone polygonal chains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A simple linear search algorithm running in $O(n+mk)$ time is proposed for\nconstructing the lower envelope of $k$ vertices from $m$ monotone polygonal\nchains in 2D with $n$ vertices in total. This can be applied to\noutput-sensitive construction of lower envelopes for arbitrary line segments in\noptimal $O(n\\log k)$ time, where $k$ is the output size. Compared to existing\noutput-sensitive algorithms for lower envelopes, this is simpler to implement,\ndoes not require complex data structures, and is a constant factor faster.\n", "versions": [{"version": "v1", "created": "Sat, 20 Dec 2014 07:10:38 GMT"}, {"version": "v2", "created": "Sat, 14 Mar 2015 02:15:28 GMT"}, {"version": "v3", "created": "Sat, 4 Jul 2015 07:41:42 GMT"}], "update_date": "2015-07-07", "authors_parsed": [["Lu", "Daniel", ""]]}, {"id": "1412.6646", "submitter": "Ulrich Bauer", "authors": "Ulrich Bauer, Elizabeth Munch, Yusu Wang", "title": "Strong Equivalence of the Interleaving and Functional Distortion Metrics\n  for Reeb Graphs", "comments": null, "journal-ref": "31st International Symposium on Computational Geometry (SoCG\n  2015), LIPIcs 34 (2015), 461-475", "doi": "10.4230/LIPIcs.SOCG.2015.461", "report-no": null, "categories": "math.AT cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Reeb graph is a construction that studies a topological space through the\nlens of a real valued function. It has widely been used in applications,\nhowever its use on real data means that it is desirable and increasingly\nnecessary to have methods for comparison of Reeb graphs. Recently, several\nmethods to define metrics on the space of Reeb graphs have been presented. In\nthis paper, we focus on two: the functional distortion distance and the\ninterleaving distance. The former is based on the Gromov--Hausdorff distance,\nwhile the latter utilizes the equivalence between Reeb graphs and a particular\nclass of cosheaves. However, both are defined by constructing a\nnear-isomorphism between the two graphs of study. In this paper, we show that\nthe two metrics are strongly equivalent on the space of Reeb graphs. In\nparticular, this gives an immediate proof of bottleneck stability for\npersistence diagrams in terms of the Reeb graph interleaving distance.\n", "versions": [{"version": "v1", "created": "Sat, 20 Dec 2014 12:08:24 GMT"}], "update_date": "2015-08-11", "authors_parsed": [["Bauer", "Ulrich", ""], ["Munch", "Elizabeth", ""], ["Wang", "Yusu", ""]]}, {"id": "1412.6676", "submitter": "Natan Rubin", "authors": "J\\'anos Pach, Natan Rubin and G\\'abor Tardos", "title": "On the Richter-Thomassen Conjecture about Pairwise Intersecting Closed\n  Curves", "comments": "To appear in SODA 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A long standing conjecture of Richter and Thomassen states that the total\nnumber of intersection points between any $n$ simple closed Jordan curves in\nthe plane, so that any pair of them intersect and no three curves pass through\nthe same point, is at least $(1-o(1))n^2$.\n  We confirm the above conjecture in several important cases, including the\ncase (1) when all curves are convex, and (2) when the family of curves can be\npartitioned into two equal classes such that each curve from the first class is\ntouching every curve from the second class. (Two curves are said to be touching\nif they have precisely one point in common, at which they do not properly\ncross.)\n  An important ingredient of our proofs is the following statement: Let $S$ be\na family of the graphs of $n$ continuous real functions defined on\n$\\mathbb{R}$, no three of which pass through the same point. If there are $nt$\npairs of touching curves in $S$, then the number of crossing points is\n$\\Omega(nt\\sqrt{\\log t/\\log\\log t})$.\n", "versions": [{"version": "v1", "created": "Sat, 20 Dec 2014 18:28:02 GMT"}], "update_date": "2014-12-23", "authors_parsed": [["Pach", "J\u00e1nos", ""], ["Rubin", "Natan", ""], ["Tardos", "G\u00e1bor", ""]]}, {"id": "1412.6892", "submitter": "Jian Sun", "authors": "Jian Sun and Tianqi Wu and Xianfeng Gu and Feng Luo", "title": "Discrete Conformal Deformation: Algorithm and Experiments", "comments": "34 pages, 22 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a definition of discrete conformality for\ntriangulated surfaces with flat cone metrics and describe an algorithm for\nsolving the problem of prescribing curvature, that is to deform the metric\ndiscrete conformally so that the curvature of the resulting metric coincides\nwith the prescribed curvature. We explicitly construct a discrete conformal map\nbetween the input triangulated surface and the deformed triangulated surface.\nOur algorithm can handle the surface with any topology with or without\nboundary, and can find a deformed metric for any prescribed curvature\nsatisfying the Gauss-Bonnet formula. In addition, we present the numerical\nexamples to show the convergence of our discrete conformality and to\ndemonstrate the efficiency and the robustness of our algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 22 Dec 2014 07:38:26 GMT"}], "update_date": "2014-12-23", "authors_parsed": [["Sun", "Jian", ""], ["Wu", "Tianqi", ""], ["Gu", "Xianfeng", ""], ["Luo", "Feng", ""]]}, {"id": "1412.6985", "submitter": "Oliver Knill", "authors": "Oliver Knill", "title": "Coloring graphs using topology", "comments": "81 pages, 48 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CG cs.DM math.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Higher dimensional graphs can be used to colour two-dimensional geometric\ngraphs. If G the boundary of a three dimensional graph H for example, we can\nrefine the interior until it is colourable with 4 colours. The later goal is\nachieved if all interior edge degrees are even. Using a refinement process\nwhich cuts the interior along surfaces we can adapt the degrees along the\nboundary of that surface. More efficient is a self-cobordism of G with itself\nwith a host graph discretizing the product of G with an interval. It follows\nfrom the fact that Euler curvature is zero everywhere for three dimensional\ngeometric graphs, that the odd degree edge set O is a cycle and so a boundary\nif H is simply connected. A reduction to minimal colouring would imply the four\ncolour theorem. The method is expected to give a reason \"why 4 colours suffice\"\nand suggests that every two dimensional geometric graph of arbitrary degree and\norientation can be coloured by 5 colours: since the projective plane can not be\na boundary of a 3-dimensional graph and because for higher genus surfaces, the\ninterior H is not simply connected, we need in general to embed a surface into\na 4-dimensional simply connected graph in order to colour it. This explains the\nappearance of the chromatic number 5 for higher degree or non-orientable\nsituations, a number we believe to be the upper limit. For every surface type,\nwe construct examples with chromatic number 3,4 or 5, where the construction of\nsurfaces with chromatic number 5 is based on a method of Fisk. We have\nimplemented and illustrated all the topological aspects described in this paper\non a computer. So far we still need human guidance or simulated annealing to do\nthe refinements in the higher dimensional host graph.\n", "versions": [{"version": "v1", "created": "Mon, 22 Dec 2014 14:06:37 GMT"}], "update_date": "2014-12-23", "authors_parsed": [["Knill", "Oliver", ""]]}, {"id": "1412.7197", "submitter": "Fabrizio Lecci", "authors": "Fr\\'ed\\'eric Chazal, Brittany T. Fasy, Fabrizio Lecci, Bertrand\n  Michel, Alessandro Rinaldo, Larry Wasserman", "title": "Robust Topological Inference: Distance To a Measure and Kernel Distance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.CG math.AT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let P be a distribution with support S. The salient features of S can be\nquantified with persistent homology, which summarizes topological features of\nthe sublevel sets of the distance function (the distance of any point x to S).\nGiven a sample from P we can infer the persistent homology using an empirical\nversion of the distance function. However, the empirical distance function is\nhighly non-robust to noise and outliers. Even one outlier is deadly. The\ndistance-to-a-measure (DTM), introduced by Chazal et al. (2011), and the kernel\ndistance, introduced by Phillips et al. (2014), are smooth functions that\nprovide useful topological information but are robust to noise and outliers.\nChazal et al. (2014) derived concentration bounds for DTM. Building on these\nresults, we derive limiting distributions and confidence sets, and we propose a\nmethod for choosing tuning parameters.\n", "versions": [{"version": "v1", "created": "Mon, 22 Dec 2014 22:50:15 GMT"}], "update_date": "2014-12-24", "authors_parsed": [["Chazal", "Fr\u00e9d\u00e9ric", ""], ["Fasy", "Brittany T.", ""], ["Lecci", "Fabrizio", ""], ["Michel", "Bertrand", ""], ["Rinaldo", "Alessandro", ""], ["Wasserman", "Larry", ""]]}]