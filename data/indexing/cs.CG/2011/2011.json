[{"id": "2011.00319", "submitter": "Amirahmad Chapnevis", "authors": "Amirahmad Chapnevis, Babak Sadeghiyan", "title": "A Secure Two-Party Computation Protocol for Intersection Detection\n  between Two Convex Hulls", "comments": "11 Pages, 2 Tables, 40 formulas, and 6 figures This paper is\n  presented in CSICC2019, Computer Society of Iran Computer Conference, Sharif\n  University of Technology, Tehran 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intersection detection between three-dimensional bodies has various\napplications in computer graphics, video game development, robotics as well as\nmilitary industries. In some respects, entities do not want to disclose\nsensitive information about themselves, including their location. In this\npaper, we present a secure two-party protocol to determine the existence of an\nintersection between entities. The protocol presented in this paper allows for\nintersection detection in three-dimensional spaces in geometry. Our approach is\nto use an intersecting plane between two spaces to determine their separation\nor intersection. For this purpose, we introduce a computational geometry\nprotocol to determine the existence of an intersecting plane. In this paper, we\nfirst use the Minkowski difference to reduce the two-space problem into\none-space. Then, the separating set is obtained and the separation of two\nshapes is determined based on the inclusion of the center point. We then secure\nthe protocol by modifying the separating set computation method as a\nprivacy-preserver and changing the Minkowski difference method to achieve this\ngoal. The proposed protocol applies to any form of convex three-dimensional\nshape. The experiments successfully found a secure protocol for intersection\ndetection between two convex hulls in geometrical shapes such as the pyramid\nand cuboid.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 17:21:13 GMT"}, {"version": "v2", "created": "Wed, 4 Nov 2020 18:22:02 GMT"}, {"version": "v3", "created": "Fri, 21 May 2021 17:08:37 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Chapnevis", "Amirahmad", ""], ["Sadeghiyan", "Babak", ""]]}, {"id": "2011.00503", "submitter": "Peyman Afshani", "authors": "Peyman Afshani", "title": "A Lower Bound for Dynamic Fractional Cascading", "comments": "Minor edits, and fixes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the limits of one of the fundamental ideas in data structures:\nfractional cascading. This is an important data structure technique to speed up\nrepeated searches for the same key in multiple lists and it has numerous\napplications. Specifically, the input is a \"catalog\" graph, $G$, of constant\ndegree together with a list of values assigned to every vertex of $G$. The goal\nis to preprocess the input such that given a connected subgraph $H$ of $G$ and\na single query value $q$, one can find the predecessor of $q$ in every list\nthat belongs to $\\scat$. The classical result by Chazelle and Guibas shows that\nin a pointer machine, this can be done in the optimal time of $\\O(\\log n +\n|\\scat|)$ where $n$ is the total number of values. However, if insertion and\ndeletion of values are allowed, then the query time slows down to $\\O(\\log n +\n|\\scat| \\log\\log n)$. If only insertions (or deletions) are allowed, then once\nagain, an optimal query time can be obtained but by using amortization at\nupdate time.\n  We prove a lower bound of $\\Omega( \\log n \\sqrt{\\log\\log n})$ on the\nworst-case query time of dynamic fractional cascading, when queries are paths\nof length $O(\\log n)$. The lower bound applies both to fully dynamic data\nstructures with amortized polylogarithmic update time and incremental data\nstructures with polylogarithmic worst-case update time. As a side, this also\nroves that amortization is crucial for obtaining an optimal incremental data\nstructure.\n  This is the first non-trivial pointer machine lower bound for a dynamic data\nstructure that breaks the $\\Omega(\\log n)$ barrier. In order to obtain this\nresult, we develop a number of new ideas and techniques that hopefully can be\nuseful to obtain additional dynamic lower bounds in the pointer machine model.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 13:55:53 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2020 19:46:51 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Afshani", "Peyman", ""]]}, {"id": "2011.00731", "submitter": "Gary Pui-Tung Choi", "authors": "Ho Law, Gary P. T. Choi, Ka Chun Lam, Lok Ming Lui", "title": "Quasiconformal model with CNN features for large deformation image\n  registration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CG cs.LG math.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image registration has been widely studied over the past several decades,\nwith numerous applications in science, engineering and medicine. Most of the\nconventional mathematical models for large deformation image registration rely\non prescribed landmarks, which usually require tedious manual labeling and are\nprone to error. In recent years, there has been a surge of interest in the use\nof machine learning for image registration. In this paper, we develop a novel\nmethod for large deformation image registration by a fusion of quasiconformal\ntheory and convolutional neural network (CNN). More specifically, we propose a\nquasiconformal energy model with a novel fidelity term that incorporates the\nfeatures extracted using a pre-trained CNN, thereby allowing us to obtain\nmeaningful registration results without any guidance of prescribed landmarks.\nMoreover, unlike many prior image registration methods, the bijectivity of our\nmethod is guaranteed by quasiconformal theory. Experimental results are\npresented to demonstrate the effectiveness of the proposed method. More\nbroadly, our work sheds light on how rigorous mathematical theories and\npractical machine learning approaches can be integrated for developing\ncomputational methods with improved performance.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 14:15:31 GMT"}, {"version": "v2", "created": "Mon, 4 Jan 2021 18:14:53 GMT"}, {"version": "v3", "created": "Mon, 28 Jun 2021 10:59:26 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Law", "Ho", ""], ["Choi", "Gary P. T.", ""], ["Lam", "Ka Chun", ""], ["Lui", "Lok Ming", ""]]}, {"id": "2011.00968", "submitter": "Yushi Uno", "authors": "Joep Hamersma, Marc van Kreveld, Yushi Uno, Tom C. van der Zanden", "title": "Gourds: a sliding-block puzzle with turning", "comments": "15 pages + 3 pages appendix, including 18 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.CG cs.DM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a new kind of sliding-block puzzle, called Gourds, where the\nobjective is to rearrange 1 x 2 pieces on a hexagonal grid board of 2n + 1\ncells with n pieces, using sliding, turning and pivoting moves. This puzzle has\na single empty cell on a board and forms a natural extension of the 15-puzzle\nto include rotational moves. We analyze the puzzle and completely characterize\nthe cases when the puzzle can always be solved. We also study the complexity of\ndetermining whether a given set of colored pieces can be placed on a colored\nhexagonal grid board with matching colors. We show this problem is NP-complete\nfor arbitrarily many colors, but solvable in randomized polynomial time if the\nnumber of colors is a fixed constant.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 13:41:22 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Hamersma", "Joep", ""], ["van Kreveld", "Marc", ""], ["Uno", "Yushi", ""], ["van der Zanden", "Tom C.", ""]]}, {"id": "2011.00981", "submitter": "Huang Lingxiao", "authors": "Lingxiao Huang, K. Sudhir, Nisheeth K. Vishnoi", "title": "Coresets for Regressions with Panel Data", "comments": "This is a Full version of a paper to appear in NeurIPS 2020. The code\n  can be found in\n  https://github.com/huanglx12/Coresets-for-regressions-with-panel-data", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CG cs.DS econ.EM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the problem of coresets for regression problems to\npanel data settings. We first define coresets for several variants of\nregression problems with panel data and then present efficient algorithms to\nconstruct coresets of size that depend polynomially on 1/$\\varepsilon$ (where\n$\\varepsilon$ is the error parameter) and the number of regression parameters -\nindependent of the number of individuals in the panel data or the time units\neach individual is observed for. Our approach is based on the Feldman-Langberg\nframework in which a key step is to upper bound the \"total sensitivity\" that is\nroughly the sum of maximum influences of all individual-time pairs taken over\nall possible choices of regression parameters. Empirically, we assess our\napproach with synthetic and real-world datasets; the coreset sizes constructed\nusing our approach are much smaller than the full dataset and coresets indeed\naccelerate the running time of computing the regression objective.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 13:58:31 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2020 02:52:41 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Huang", "Lingxiao", ""], ["Sudhir", "K.", ""], ["Vishnoi", "Nisheeth K.", ""]]}, {"id": "2011.02197", "submitter": "Pilar Cano", "authors": "Prosenjit Bose, Pilar Cano, Rodrigo I. Silveira", "title": "Affine invariant triangulations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study affine invariant 2D triangulation methods. That is, methods that\nproduce the same triangulation for a point set $S$ for any (unknown) affine\ntransformation of $S$. Our work is based on a method by Nielson [A\ncharacterization of an affine invariant triangulation. Geom. Mod, 191-210.\nSpringer, 1993] that uses the inverse of the covariance matrix of $S$ to define\nan affine invariant norm, denoted $A_{S}$, and an affine invariant\ntriangulation, denoted ${DT}_{A_{S}}[S]$. We revisit the $A_{S}$-norm from a\ngeometric perspective, and show that ${DT}_{A_{S}}[S]$ can be seen as a\nstandard Delaunay triangulation of a transformed point set based on $S$. We\nprove that it retains all of its well-known properties such as being 1-tough,\ncontaining a perfect matching, and being a constant spanner of the complete\ngeometric graph of $S$. We show that the $A_{S}$-norm extends to a hierarchy of\nrelated geometric structures such as the minimum spanning tree, nearest\nneighbor graph, Gabriel graph, relative neighborhood graph, and higher order\nversions of these graphs. In addition, we provide different affine invariant\nsorting methods of a point set $S$ and of the vertices of a polygon $P$ that\ncan be combined with known algorithms to obtain other affine invariant\ntriangulation methods of $S$ and of $P$.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 09:41:16 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Bose", "Prosenjit", ""], ["Cano", "Pilar", ""], ["Silveira", "Rodrigo I.", ""]]}, {"id": "2011.02431", "submitter": "Fabrizio Frati", "authors": "Patrizio Angelini, Giordano Da Lozzo, Giuseppe Di Battista, Fabrizio\n  Frati, and Maurizio Patrignani", "title": "2-Level Quasi-Planarity or How Caterpillars Climb (SPQR-)Trees", "comments": "Extended version of a paper to appear at SODA '21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a bipartite graph $G=(V_b,V_r,E)$, the $2$-Level Quasi-Planarity\nproblem asks for the existence of a drawing of $G$ in the plane such that the\nvertices in $V_b$ and in $V_r$ lie along two parallel lines $\\ell_b$ and\n$\\ell_r$, respectively, each edge in $E$ is drawn in the unbounded strip of the\nplane delimited by $\\ell_b$ and $\\ell_r$, and no three edges in $E$ pairwise\ncross.\n  We prove that the $2$-Level Quasi-Planarity problem is NP-complete. This\nanswers an open question of Dujmovi\\'c, P\\'{o}r, and Wood. Furthermore, we show\nthat the problem becomes linear-time solvable if the ordering of the vertices\nin $V_b$ along $\\ell_b$ is prescribed. Our contributions provide the first\nresults on the computational complexity of recognizing quasi-planar graphs,\nwhich is a long-standing open question.\n  Our linear-time algorithm exploits several ingredients, including a\ncombinatorial characterization of the positive instances of the problem in\nterms of the existence of a planar embedding with a caterpillar-like structure,\nand an SPQR-tree-based algorithm for testing the existence of such a planar\nembedding. Our algorithm builds upon a classification of the types of\nembeddings with respect to the structure of the portion of the caterpillar they\ncontain and performs a computation of the realizable embedding types based on a\nsuccinct description of their features by means of constant-size gadgets.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 17:29:32 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Angelini", "Patrizio", ""], ["Da Lozzo", "Giordano", ""], ["Di Battista", "Giuseppe", ""], ["Frati", "Fabrizio", ""], ["Patrignani", "Maurizio", ""]]}, {"id": "2011.03107", "submitter": "Arash Vaezi", "authors": "Arash Vaezi, Bodhayan Roy, Mohammad Ghodsi", "title": "Visibility Extension via Reflection", "comments": "32 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies a variant of the Art-gallery problem in which \"walls\" can\nbe replaced by \\emph{reflecting-edges}, which allows the guard to see further\nand thereby see a larger portion of the gallery. The art-gallery is a simple\nclosed polygon $P$, a guard is a point $p$ in $P$, and a guard sees another\npoint $q$ in $P$ if the segment $\\overline{pq}$ is contained in the interior of\n$P$. The visibility region of $p$ is the set of points $q$ in $P$ that are\nvisible from $p$. If we let an edge of the polygon allow reflections, then the\nvisibility region should be changed accordingly. We study visibility with\nspecular and diffuse reflections. Moreover, the number of times a ray can be\nreflected can be taken as a parameter. For \\emph{vertex} guarding polygons with\n$k$ diffuse reflections, we establish an upper bound on the optimum solution.\nFor this problem, we generalize the $O(logn)$-approximation ratio algorithm of\nthe Art Gallery Problem. For a bounded $k$, the generalization gives a\npolynomial-time algorithm with $O(log n)$-approximation ratio for both cases\ndiffuse and specular reflections. Furthermore, We show that several cases of\nthe generalized problem are NP-hard. We also illustrate that if $P$ is a funnel\nor a weak visibility polygon, then the problem becomes more straightforward and\ncan be solved in polynomial time.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 21:42:03 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Vaezi", "Arash", ""], ["Roy", "Bodhayan", ""], ["Ghodsi", "Mohammad", ""]]}, {"id": "2011.03209", "submitter": "Youjia Zhou", "authors": "Youjia Zhou, Nithin Chalapathi, Archit Rathore, Yaodong Zhao, Bei Wang", "title": "Mapper Interactive: A Scalable, Extendable, and Interactive Toolbox for\n  the Visual Exploration of High-Dimensional Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.GR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The mapper algorithm is a popular tool from topological data analysis for\nextracting topological summaries of high-dimensional datasets. In this paper,\nwe present Mapper Interactive, a web-based framework for the interactive\nanalysis and visualization of high-dimensional point cloud data. It implements\nthe mapper algorithm in an interactive, scalable, and easily extendable way,\nthus supporting practical data analysis. In particular, its command-line API\ncan compute mapper graphs for 1 million points of 256 dimensions in about 3\nminutes (4 times faster than the vanilla implementation). Its visual interface\nallows on-the-fly computation and manipulation of the mapper graph based on\nuser-specified parameters and supports the addition of new analysis modules\nwith a few lines of code. Mapper Interactive makes the mapper algorithm\naccessible to nonspecialists and accelerates topological analytics workflows.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 06:55:59 GMT"}, {"version": "v2", "created": "Tue, 27 Apr 2021 06:03:35 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Zhou", "Youjia", ""], ["Chalapathi", "Nithin", ""], ["Rathore", "Archit", ""], ["Zhao", "Yaodong", ""], ["Wang", "Bei", ""]]}, {"id": "2011.03354", "submitter": "R Inkulu", "authors": "Sukanya Bhattacharjee, R. Inkulu", "title": "Vertex Fault-Tolerant Geometric Spanners for Weighted Points", "comments": "preliminary version accepted to COCOON 2019. arXiv admin note:\n  substantial text overlap with arXiv:1709.01061", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a set S of n points, a weight function w to associate a non-negative\nweight to each point in S, a positive integer k \\ge 1, and a real number\n\\epsilon > 0, we present algorithms for computing a spanner network G(S, E) for\nthe metric space (S, d_w) induced by the weighted points in S. The weighted\ndistance function d_w on the set S of points is defined as follows: for any p,\nq \\in S, d_w(p, q) is equal to w(p) + d_\\pi(p, q) + w(q) if p \\ne q, otherwise,\nd_w(p, q) is 0. Here, d_\\pi(p, q) is the Euclidean distance between p and q if\npoints in S are in \\mathbb{R}^d, otherwise, it is the geodesic (Euclidean)\ndistance between p and q. The following are our results: (1) When the weighted\npoints in S are located in \\mathbb{R}^d, we compute a k-vertex fault-tolerant\n(4+\\epsilon)-spanner network of size O(k n). (2) When the weighted points in S\nare located in the relative interior of the free space of a polygonal domain\n\\cal P, we detail an algorithm to compute a k-vertex fault-tolerant\n(4+\\epsilon)-spanner network with O(\\frac{kn\\sqrt{h+1}}{\\epsilon^2} \\lg{n})\nedges. Here, h is the number of simple polygonal holes in \\cal P. (3) When the\nweighted points in S are located on a polyhedral terrain \\cal T, we propose an\nalgorithm to compute a k-vertex fault-tolerant (4+\\epsilon)-spanner network,\nand the number of edges in this network is O(\\frac{kn}{\\epsilon^2} \\lg{n}).\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 14:18:58 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Bhattacharjee", "Sukanya", ""], ["Inkulu", "R.", ""]]}, {"id": "2011.03617", "submitter": "Georg Osang", "authors": "Herbert Edelsbrunner and Georg Osang", "title": "A Simple Algorithm for Higher-order Delaunay Mosaics and Alpha Shapes", "comments": "15 pages, 10 figures, submitted to Algorithmica, see\n  https://github.com/geoo89/rhomboidtiling for an implementation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a simple algorithm for computing higher-order Delaunay mosaics\nthat works in Euclidean spaces of any finite dimensions. The algorithm selects\nthe vertices of the order-$k$ mosaic from incrementally constructed lower-order\nmosaics and uses an algorithm for weighted first-order Delaunay mosaics as a\nblack-box to construct the order-$k$ mosaic from its vertices. Beyond this\nblack-box, the algorithm uses only combinatorial operations, thus facilitating\neasy implementation. We extend this algorithm to compute higher-order\n$\\alpha$-shapes and provide open-source implementations. We present\nexperimental results for properties of higher-order Delaunay mosaics of random\npoint sets.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 22:22:06 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Edelsbrunner", "Herbert", ""], ["Osang", "Georg", ""]]}, {"id": "2011.03778", "submitter": "Karol W\\k{e}grzycki", "authors": "S\\'andor Kisfaludi-Bak, Jesper Nederlof, Karol W\\k{e}grzycki", "title": "A Gap-ETH-Tight Approximation Scheme for Euclidean TSP", "comments": "43 pages, faster algorithms for Euclidean and Rectilinear Steiner\n  Tree", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the classic task of finding the shortest tour of $n$ points in\n$d$-dimensional Euclidean space, for any fixed constant $d \\geq 2$. We\ndetermine the optimal dependence on $\\varepsilon$ in the running time of an\nalgorithm that computes a $(1+\\varepsilon)$-approximate tour, under a plausible\nassumption. Specifically, we give an algorithm that runs in\n$2^{O(1/\\varepsilon^{d-1})} n\\log n$ time. This improves the previously\nsmallest dependence on $\\varepsilon$ in the running time\n$(1/\\varepsilon)^{O(1/\\varepsilon^{d-1})}n \\log n$ of the algorithm by Rao and\nSmith (STOC 1998). We also show that a\n$2^{o(1/\\varepsilon^{d-1})}\\mathrm{poly}(n)$ algorithm would violate the\nGap-Exponential Time Hypothesis (Gap-ETH).\n  Our new algorithm builds upon the celebrated quadtree-based methods initially\nproposed by Arora (J. ACM 1998), but it adds a new idea that we call\nsparsity-sensitive patching. On a high level this lets the granularity with\nwhich we simplify the tour depend on how sparse it is locally. We demonstrate\nthat our technique extends to other problems, by showing that for Steiner Tree\nand Rectilinear Steiner Tree it yields the same running time. We complement our\nresults with a matching Gap-ETH lower bound for Rectilinear Steiner Tree.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2020 13:50:43 GMT"}, {"version": "v2", "created": "Thu, 3 Jun 2021 14:59:33 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Kisfaludi-Bak", "S\u00e1ndor", ""], ["Nederlof", "Jesper", ""], ["W\u0119grzycki", "Karol", ""]]}, {"id": "2011.04221", "submitter": "Dishant Goyal", "authors": "Anup Bhattacharya, Dishant Goyal, Ragesh Jaiswal", "title": "Hardness of Approximation of Euclidean $k$-Median", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CG cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Euclidean $k$-median problem is defined in the following manner: given a\nset $\\mathcal{X}$ of $n$ points in $\\mathbb{R}^{d}$, and an integer $k$, find a\nset $C \\subset \\mathbb{R}^{d}$ of $k$ points (called centers) such that the\ncost function $\\Phi(C,\\mathcal{X}) \\equiv \\sum_{x \\in \\mathcal{X}} \\min_{c \\in\nC} \\|x-c\\|_{2}$ is minimized. The Euclidean $k$-means problem is defined\nsimilarly by replacing the distance with squared distance in the cost function.\nVarious hardness of approximation results are known for the Euclidean $k$-means\nproblem. However, no hardness of approximation results were known for the\nEuclidean $k$-median problem. In this work, assuming the unique games\nconjecture (UGC), we provide the first hardness of approximation result for the\nEuclidean $k$-median problem.\n  Furthermore, we study the hardness of approximation for the Euclidean\n$k$-means/$k$-median problems in the bi-criteria setting where an algorithm is\nallowed to choose more than $k$ centers. That is, bi-criteria approximation\nalgorithms are allowed to output $\\beta k$ centers (for constant $\\beta>1$) and\nthe approximation ratio is computed with respect to the optimal\n$k$-means/$k$-median cost. In this setting, we show the first hardness of\napproximation result for the Euclidean $k$-median problem for any $\\beta <\n1.015$, assuming UGC. We also show a similar bi-criteria hardness of\napproximation result for the Euclidean $k$-means problem with a stronger bound\nof $\\beta < 1.28$, again assuming UGC.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 06:50:34 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Bhattacharya", "Anup", ""], ["Goyal", "Dishant", ""], ["Jaiswal", "Ragesh", ""]]}, {"id": "2011.04255", "submitter": "Javier Tejel", "authors": "M. Claverol, A. Garc\\'ia, G. Hern\\'andez, C. Hernando, M. Maureso, M.\n  Mora and J. Tejel", "title": "Total domination in plane triangulations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A total dominating set of a graph $G=(V,E)$ is a subset $D$ of $V$ such that\nevery vertex in $V$ is adjacent to at least one vertex in $D$. The total\ndomination number of $G$, denoted by $\\gamma _t (G)$, is the minimum\ncardinality of a total dominating set of $G$. A near-triangulation is a\nbiconnected planar graph that admits a plane embedding such that all of its\nfaces are triangles except possibly the outer face. We show in this paper that\n$\\gamma _t (G) \\le \\lfloor \\frac{2n}{5}\\rfloor$ for any near-triangulation $G$\nof order $n\\ge 5$, with two exceptions.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 09:03:40 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Claverol", "M.", ""], ["Garc\u00eda", "A.", ""], ["Hern\u00e1ndez", "G.", ""], ["Hernando", "C.", ""], ["Maureso", "M.", ""], ["Mora", "M.", ""], ["Tejel", "J.", ""]]}, {"id": "2011.04611", "submitter": "Couvreur Alain", "authors": "Alain Couvreur and Thomas Debris-Alazard and Philippe Gaborit", "title": "On the hardness of code equivalence problems in rank metric", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CG math.IT math.RA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the recent years, the notion of rank metric in the context of coding\ntheory has known many interesting developments in terms of applications such as\nspace time coding, network coding or public key cryptography. These\napplications raised the interest of the community for theoretical properties of\nthis type of codes, such as the hardness of decoding in rank metric. Among\nclassical problems associated to codes for a given metric, the notion of code\nequivalence (to decide if two codes are isometric) has always been of the\ngreatest interest, for its cryptographic applications or its deep connexions to\nthe graph isomorphism problem.\n  In this article, we discuss the hardness of the code equivalence problem in\nrank metric for $\\mathbb{F}_{q^m}$-linear and general rank metric codes. In the\n$\\mathbb{F}_{q^m}$-linear case, we reduce the underlying problem to another one\ncalled {\\em Matrix Codes Right Equivalence Problem}. We prove the latter\nproblem to be either in $\\mathcal{P}$ or in $\\mathcal{ZPP}$ depending of the\nground field size. This is obtained by designing an algorithm whose principal\nroutines are linear algebra and factoring polynomials over finite fields. It\nturns out that the most difficult instances involve codes with non trivial {\\em\nstabilizer algebras}. The resolution of the latter case will involve tools\nrelated to finite dimensional algebras and Wedderburn--Artin theory. It is\ninteresting to note that 30 years ago, an important trend in theoretical\ncomputer science consisted to design algorithms making effective major results\nof this theory. These algorithmic results turn out to be particularly useful in\nthe present article.\n  Finally, for general matrix codes, we prove that the equivalence problem\n(both left and right) is at least as hard as the well--studied {\\em Monomial\nEquivalence Problem} for codes endowed with the Hamming metric.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 18:14:03 GMT"}, {"version": "v2", "created": "Thu, 10 Jun 2021 13:38:53 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Couvreur", "Alain", ""], ["Debris-Alazard", "Thomas", ""], ["Gaborit", "Philippe", ""]]}, {"id": "2011.04898", "submitter": "Jeff Calder", "authors": "Katrina Yezzi-Woodley, Jeff Calder, Peter J. Olver, Annie Melton,\n  Paige Cody, Thomas Huffstutler, Alexander Terwilliger, Martha Tappen, Reed\n  Coil, Gilbert Tostevin", "title": "The Virtual Goniometer: A new method for measuring angles on 3D models\n  of fragmentary bone and lithics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.CG cs.CV cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The contact goniometer is a commonly used tool in lithic and\nzooarchaeological analysis, despite suffering from a number of shortcomings due\nto the physical interaction between the measuring implement, the object being\nmeasured, and the individual taking the measurements. However, lacking a simple\nand efficient alternative, researchers in a variety of fields continue to use\nthe contact goniometer to this day. In this paper, we present a new goniometric\nmethod that we call the virtual goniometer, which takes angle measurements\nvirtually on a 3D model of an object. The virtual goniometer allows for rapid\ndata collection, and for the measurement of many angles that cannot be\nphysically accessed by a manual goniometer. We compare the intra-observer\nvariability of the manual and virtual goniometers, and find that the virtual\ngoniometer is far more consistent and reliable. Furthermore, the virtual\ngoniometer allows for precise replication of angle measurements, even among\nmultiple users, which is important for reproducibility of goniometric-based\nresearch. The virtual goniometer is available as a plug-in in the open source\nmesh processing packages Meshlab and Blender, making it easily accessible to\nresearchers exploring the potential for goniometry to improve archaeological\nmethods and address anthropological questions.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 05:13:29 GMT"}, {"version": "v2", "created": "Wed, 25 Nov 2020 14:01:18 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Yezzi-Woodley", "Katrina", ""], ["Calder", "Jeff", ""], ["Olver", "Peter J.", ""], ["Melton", "Annie", ""], ["Cody", "Paige", ""], ["Huffstutler", "Thomas", ""], ["Terwilliger", "Alexander", ""], ["Tappen", "Martha", ""], ["Coil", "Reed", ""], ["Tostevin", "Gilbert", ""]]}, {"id": "2011.05276", "submitter": "Piotr Beben", "authors": "Piotr Beben", "title": "Topology of Frame Field Design for Hex Meshing", "comments": "More citations added; last section updated; new material added", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AT cs.CG cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past decade frame fields have emerged as a promising approach for\ngenerating hexahedral meshes for CFD and CAE applications. One important\nproblem asks for construction of a boundary-aligned frame field with prescribed\nsingularity constraints over a volume that corresponds to a valid hexahedral\nmesh. We give a necessary and sufficient condition in terms of solutions to a\nsystem of monomial equations with variables in the binary octahedral group when\na boundary frame field and singularity graph have been fixed. This is phrased\nwith respect to general $CW$-decompositions of the volume, which allows some\nflexibility in simplifying these systems. Along the way we look at frame field\ndesign from an algebraic topological perspective, proving various results, some\nknown, some new.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 17:51:40 GMT"}, {"version": "v2", "created": "Thu, 12 Nov 2020 18:57:25 GMT"}, {"version": "v3", "created": "Fri, 13 Nov 2020 14:55:14 GMT"}, {"version": "v4", "created": "Wed, 18 Nov 2020 17:58:36 GMT"}, {"version": "v5", "created": "Wed, 25 Nov 2020 18:51:57 GMT"}, {"version": "v6", "created": "Thu, 3 Dec 2020 17:56:24 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Beben", "Piotr", ""]]}, {"id": "2011.06545", "submitter": "Zihan Tan", "authors": "Julia Chuzhoy, Sepideh Mahabadi, Zihan Tan", "title": "Towards Better Approximation of Graph Crossing Number", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Graph Crossing Number is a fundamental problem with various applications. In\nthis problem, the goal is to draw an input graph $G$ in the plane so as to\nminimize the number of crossings between the images of its edges. Despite\nextensive work, non-trivial approximation algorithms are only known for\nbounded-degree graphs. Even for this special case, the best current algorithm\nachieves a $\\tilde O(\\sqrt n)$-approximation, while the best current negative\nresult is APX-hardness. All current approximation algorithms for the problem\nbuild on the same paradigm: compute a set $E'$ of edges (called a\n\\emph{planarizing set}) such that $G\\setminus E'$ is planar; compute a planar\ndrawing of $G\\setminus E'$; then add the drawings of the edges of $E'$ to the\nresulting drawing. Unfortunately, there are examples of graphs, in which any\nimplementation of this method must incur $\\Omega (\\text{OPT}^2)$ crossings,\nwhere $\\text{OPT}$ is the value of the optimal solution. This barrier seems to\ndoom the only known approach to designing approximation algorithms for the\nproblem, and to prevent it from yielding a better than $O(\\sqrt\nn)$-approximation.\n  In this paper we propose a new paradigm that allows us to overcome this\nbarrier. We show an algorithm that, given a bounded-degree graph $G$ and a\nplanarizing set $E'$ of its edges, computes another set $E''$ with $E'\\subseteq\nE''$, such that $|E''|$ is relatively small, and there exists a near-optimal\ndrawing of $G$ in which only edges of $E''$ participate in crossings. This\nallows us to reduce the Crossing Number problem to \\emph{Crossing Number with\nRotation System} -- a variant in which the ordering of the edges incident to\nevery vertex is fixed as part of input. We show a randomized algorithm for this\nnew problem, that allows us to obtain an $O(n^{1/2-\\epsilon})$-approximation\nfor Crossing Number on bounded-degree graphs, for some constant $\\epsilon>0$.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 18:04:55 GMT"}, {"version": "v2", "created": "Mon, 11 Jan 2021 01:50:37 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Chuzhoy", "Julia", ""], ["Mahabadi", "Sepideh", ""], ["Tan", "Zihan", ""]]}, {"id": "2011.06640", "submitter": "Dan Reznik", "authors": "Ronaldo Garcia and Dan Reznik", "title": "Invariants of Self-Intersected N-Periodics in the Elliptic Billiard", "comments": "24 pages, 14 figures, 3 tables, and 21 videos", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.MG cs.CG cs.RO cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study self-intersected N-periodics in the elliptic billiard, describing\nnew facts about their geometry (e.g., self-intersected 4-periodics have\nvertices concyclic with the foci). We also check if some invariants listed in\n\"Eighty New Invariants of N-Periodics in the Elliptic Billiard\" (2020),\narXiv:2004.12497, remain invariant in the self-intersected case. Toward that\nend, we derive explicit expressions for many low-N simple and self-intersected\ncases. We identify two special cases (one simple, one self-intersected) where a\nquantity prescribed to be invariant is actually variable.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 20:28:53 GMT"}, {"version": "v2", "created": "Sat, 12 Dec 2020 10:54:27 GMT"}, {"version": "v3", "created": "Tue, 19 Jan 2021 13:00:24 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Garcia", "Ronaldo", ""], ["Reznik", "Dan", ""]]}, {"id": "2011.07107", "submitter": "Baris Irhan", "authors": "Baris Irhan", "title": "A universal predictor-corrector type incremental algorithm for the\n  construction of weighted straight skeletons based on the notion of deforming\n  polygon", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CE", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  A new predictor-corrector type incremental algorithm is proposed for the\nexact construction of weighted straight skeletons of 2D general planar polygons\nof arbitrary complexity based on the notion of deforming polygon. In the\nproposed algorithm, the raw input provided by the polygon itself is enough to\nresolve edge collapse and edge split events. Neither the construction of a\nkinetic triangulation nor the computation of a motorcycle graph is required.\nDue to its incremental nature, there is always a room in the algorithm for the\ninteractive construction of the straight skeleton. The proposed algorithm is of\npredictor-corrector type. In the algorithm, the edge collapse and edge split\nevents are tackled by a completely different novel original approach which is\nfirst of its kind. In the predictor step, the position of the vertices is\nadvanced in time by direct integration assuming no event. Then predicted\npositions are corrected by using linear interpolation if there are edge\ncollapse or edge split events within the same increment. In the algorithm edge\ncollapse and edge split events are detected by, respectively, edge swap and\nedge penetration. The proposed algorithm has been used to construct roof\ntopology starting from a floor plan of various complexity ranging from simple\nconvex to highly nonconvex with holes. In order to construct, improve and test\nthe building blocks of the underlying algorithm, a graphical user interface,\nStraight Skeleton Development Kit, has also been developed in parallel by the\nauthor using C++ programming language.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 19:54:09 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Irhan", "Baris", ""]]}, {"id": "2011.08232", "submitter": "Soroosh Tayebi Arasteh", "authors": "Soroosh Tayebi Arasteh, Adam Kalisz", "title": "Conversion Between Cubic Bezier Curves and Catmull-Rom Splines", "comments": "9 pages, 4 figures, submitted to SN Computer Science", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.CG math.AG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Splines are one of the main methods of mathematically representing\ncomplicated shapes, which have become the primary technique in the fields of\nComputer Graphics (CG) and Computer-Aided Geometric Design (CAGD) for modeling\ncomplex surfaces. Among all, B\\'ezier and Catmull-Rom splines are the most\ncommon in the sub-fields of engineering. In this paper, we focus on conversion\nbetween cubic B\\'ezier and Catmull-Rom curve segments, rather than going\nthrough their properties. By deriving the conversion equations, we aim at\nconverting the original set of the control points of either of the Catmull-Rom\nor B\\'ezier cubic curves to a new set of control points, which corresponds to\napproximately the same shape as the original curve, when considered as the set\nof the control points of the other curve. Due to providing simple linear\ntransformations of control points, the method is very simple, efficient, and\neasy to implement, which is further validated in this paper using some\nnumerical and visual examples.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 19:22:16 GMT"}, {"version": "v2", "created": "Mon, 28 Jun 2021 20:01:30 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Arasteh", "Soroosh Tayebi", ""], ["Kalisz", "Adam", ""]]}, {"id": "2011.08404", "submitter": "Ryan Grady", "authors": "Ryan E. Grady and Anna Schenfisch", "title": "Natural Stratifications of Reeb Spaces and Higher Morse Functions", "comments": "v2: Additional examples/figures, Appendix on notions of criticality\n  for PL map", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AT cs.CG math.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Both Reeb spaces and higher Morse functions induce natural stratifications.\nIn the former, we show that the data of the Jacobi set of a function $f:X \\to\n\\mathbb{R}^k$ induces stratifications on $X,\\mathbb{R}^k$, and the associated\nReeb space, and give conditions under which maps between these three spaces are\nstratified maps. We then extend this type of construction to the codomain of\nhigher Morse functions, using the singular locus to induce a stratification of\nwhich sub-posets are equivalent to multi-parameter filtrations.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 03:35:11 GMT"}, {"version": "v2", "created": "Sun, 27 Dec 2020 17:20:13 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Grady", "Ryan E.", ""], ["Schenfisch", "Anna", ""]]}, {"id": "2011.08676", "submitter": "Talha Bin Masood", "authors": "Wito Engelke, Talha Bin Masood, Jakob Beran, Rodrigo Caballero and\n  Ingrid Hotz", "title": "Topology-Based Feature Design and Tracking for Multi-Center Cyclones", "comments": "13 pages, 9 figures, 8th workshop on Topological Methods in Data\n  Analysis and Visualization (TopoInVis 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CG cs.CV cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a concept to design, track, and compare\napplication-specific feature definitions expressed as sets of critical points.\nOur work has been inspired by the observation that in many applications a large\nvariety of different feature definitions for the same concept are used. Often,\nthese definitions compete with each other and it is unclear which definition\nshould be used in which context. A prominent example is the definition of\ncyclones in climate research. Despite the differences, frequently these feature\ndefinitions can be related to topological concepts.\n  In our approach, we provide a cyclone tracking framework that supports\ninteractive feature definition and comparison based on a precomputed tracking\ngraph that stores all extremal points as well as their temporal correspondents.\nThe framework combines a set of independent building blocks: critical point\nextraction, critical point tracking, feature definition, and track exploration.\nOne of the major advantages of such an approach is the flexibility it provides,\nthat is, each block is exchangeable. Moreover, it also enables us to perform\nthe most expensive analysis, the construction of a full tracking graph, as a\nprepossessing step, while keeping the feature definition interactive. Different\nfeature definitions can be explored and compared interactively based on this\ntracking graph. Features are specified by rules for grouping critical points,\nwhile feature tracking corresponds to filtering and querying the full tracking\ngraph by specific requests. We demonstrate this method for cyclone\nidentification and tracking in the context of climate research.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 17:39:27 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Engelke", "Wito", ""], ["Masood", "Talha Bin", ""], ["Beran", "Jakob", ""], ["Caballero", "Rodrigo", ""], ["Hotz", "Ingrid", ""]]}, {"id": "2011.08952", "submitter": "Sarah Tymochko", "authors": "Sarah Tymochko, Zachary New, Lucius Bynum, Emilie Purvine, Timothy\n  Doster, Julien Chaput, Tegan Emerson", "title": "Argumentative Topology: Finding Loop(holes) in Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in natural language processing have resulted in increased\ncapabilities with respect to multiple tasks. One of the possible causes of the\nobserved performance gains is the introduction of increasingly sophisticated\ntext representations. While many of the new word embedding techniques can be\nshown to capture particular notions of sentiment or associative structures, we\nexplore the ability of two different word embeddings to uncover or capture the\nnotion of logical shape in text. To this end we present a novel framework that\nwe call Topological Word Embeddings which leverages mathematical techniques in\ndynamical system analysis and data driven shape extraction (i.e. topological\ndata analysis). In this preliminary work we show that using a topological delay\nembedding we are able to capture and extract a different, shape-based notion of\nlogic aimed at answering the question \"Can we find a circle in a circular\nargument?\"\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 21:23:58 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Tymochko", "Sarah", ""], ["New", "Zachary", ""], ["Bynum", "Lucius", ""], ["Purvine", "Emilie", ""], ["Doster", "Timothy", ""], ["Chaput", "Julien", ""], ["Emerson", "Tegan", ""]]}, {"id": "2011.09117", "submitter": "Yu Zhang", "authors": "Yu Zhang, Yangming Wu, Xigui Wang and Xiaocheng Zhou", "title": "Barycode-based GJK Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a more efficient GJK algorithm to solve the\ncollision detection and distance query problems in 2D. We contribute in two\naspects: First, we propose a new barycode-based sub-distance algorithm that\ndoes not only provide a simple and unified condition to determine the minimum\nsimplex but also improve the efficiency in distant, touching, and overlap cases\nin distance query. Second, we provide a highly efficient implementation\nsubroutine for collision detection by optimizing the exit conditions of our GJK\ndistance algorithm, which shows dramatic improvements in run-time for\napplications that only need binary results. We benchmark our methods along with\nthat of the well-known open-source collision detection libraries, such as\nBullet, FCL, OpenGJK, Box2D, and Apollo over a range of random datasets. The\nresults indicate that our methods and implementations outperform the\nstate-of-the-art in both collision detection and distance query.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 06:47:58 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Zhang", "Yu", ""], ["Wu", "Yangming", ""], ["Wang", "Xigui", ""], ["Zhou", "Xiaocheng", ""]]}, {"id": "2011.09138", "submitter": "Stefan Langer", "authors": "Markus Friedrich, Stefan Langer, Fabian Frey", "title": "Combining Gesture and Voice Control for Mid-Air Manipulation of CAD\n  Models in VR Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Modeling 3D objects in domains like Computer Aided Design (CAD) is\ntime-consuming and comes with a steep learning curve needed to master the\ndesign process as well as tool complexities. In order to simplify the modeling\nprocess, we designed and implemented a prototypical system that leverages the\nstrengths of Virtual Reality (VR) hand gesture recognition in combination with\nthe expressiveness of a voice-based interface for the task of 3D modeling.\nFurthermore, we use the Constructive Solid Geometry (CSG) tree representation\nfor 3D models within the VR environment to let the user manipulate objects from\nthe ground up, giving an intuitive understanding of how the underlying basic\nshapes connect. The system uses standard mid-air 3D object manipulation\ntechniques and adds a set of voice commands to help mitigate the deficiencies\nof current hand gesture recognition techniques. A user study was conducted to\nevaluate the proposed prototype. The combination of our hybrid input paradigm\nshows to be a promising step towards easier to use CAD modeling.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 07:26:29 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Friedrich", "Markus", ""], ["Langer", "Stefan", ""], ["Frey", "Fabian", ""]]}, {"id": "2011.09384", "submitter": "Dan Feldman PhD", "authors": "Dan Feldman", "title": "Introduction to Core-sets: an Updated Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CG cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In optimization or machine learning problems we are given a set of items,\nusually points in some metric space, and the goal is to minimize or maximize an\nobjective function over some space of candidate solutions. For example, in\nclustering problems, the input is a set of points in some metric space, and a\ncommon goal is to compute a set of centers in some other space (points, lines)\nthat will minimize the sum of distances to these points. In database queries,\nwe may need to compute such a some for a specific query set of $k$ centers.\n  However, traditional algorithms cannot handle modern systems that require\nparallel real-time computations of infinite distributed streams from sensors\nsuch as GPS, audio or video that arrive to a cloud, or networks of weaker\ndevices such as smartphones or robots.\n  Core-set is a \"small data\" summarization of the input \"big data\", where every\npossible query has approximately the same answer on both data sets. Generic\ntechniques enable efficient coreset \\changed{maintenance} of streaming,\ndistributed and dynamic data. Traditional algorithms can then be applied on\nthese coresets to maintain the approximated optimal solutions.\n  The challenge is to design coresets with provable tradeoff between their size\nand approximation error. This survey summarizes such constructions in a\nretrospective way, that aims to unified and simplify the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 16:31:34 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Feldman", "Dan", ""]]}, {"id": "2011.09591", "submitter": "Yiming Zhao", "authors": "Haitao Wang and Yiming Zhao", "title": "Algorithms for Diameters of Unicycle Graphs and Diameter-Optimally\n  Augmenting Trees", "comments": "A preliminary version will appear in WALCOM 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the problem of computing the diameter of a unicycle graph (i.e.,\na graph with a unique cycle). We present an O(n) time algorithm for the\nproblem, where n is the number of vertices of the graph. This improves the\nprevious best O(n \\log n) time solution [Oh and Ahn, ISAAC 2016]. Using this\nalgorithm as a subroutine, we solve the problem of adding a shortcut to a tree\nso that the diameter of the new graph (which is a unicycle graph) is minimized;\nour algorithm takes O(n^2 \\log n) time and O(n) space. The previous best\nalgorithms solve the problem in O(n^2 \\log^3 n) time and O(n) space [Oh and\nAhn, ISAAC 2016], or in O(n^2) time and O(n^2) space [Bil\\`o, ISAAC 2018].\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 00:07:43 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Wang", "Haitao", ""], ["Zhao", "Yiming", ""]]}, {"id": "2011.09714", "submitter": "Michael Gastner", "authors": "Ian K. Duncan, Shi Tingsheng, Simon T. Perrault and Michael T. Gastner", "title": "Task-Based Effectiveness of Interactive Contiguous Area Cartograms", "comments": "18 pages, 5 figures. Supplemental material available by clicking on\n  \"Other formats\". To be published in IEEE Transactions on Visualization and\n  Computer Graphics", "journal-ref": null, "doi": "10.1109/TVCG.2020.3041745", "report-no": null, "categories": "cs.HC cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cartograms are map-based data visualizations in which the area of each map\nregion is proportional to an associated numeric data value (e.g., population or\ngross domestic product). A cartogram is called contiguous if it conforms to\nthis area principle while also keeping neighboring regions connected. Because\nof their distorted appearance, contiguous cartograms have been criticized as\ndifficult to read. Some authors have suggested that cartograms may be more\nlegible if they are accompanied by interactive features (e.g., animations,\nlinked brushing, or infotips). We conducted an experiment to evaluate this\nclaim. Participants had to perform visual analysis tasks with interactive and\nnoninteractive contiguous cartograms. The task types covered various aspects of\ncartogram readability, ranging from elementary lookup tasks to synoptic tasks\n(i.e., tasks in which participants had to summarize high-level differences\nbetween two cartograms). Elementary tasks were carried out equally well with\nand without interactivity. Synoptic tasks, by contrast, were more difficult\nwithout interactive features. With access to interactivity, however, most\nparticipants answered even synoptic questions correctly. In a subsequent\nsurvey, participants rated the interactive features as \"easy to use\" and\n\"helpful.\" Our study suggests that interactivity has the potential to make\ncontiguous cartograms accessible even for those readers who are unfamiliar with\ninteractive computer graphics or do not have a prior affinity to working with\nmaps. Among the interactive features, animations had the strongest positive\neffect, so we recommend them as a minimum of interactivity when contiguous\ncartograms are displayed on a computer screen.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 08:32:16 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Duncan", "Ian K.", ""], ["Tingsheng", "Shi", ""], ["Perrault", "Simon T.", ""], ["Gastner", "Michael T.", ""]]}, {"id": "2011.09847", "submitter": "Matthijs Ebbens", "authors": "Matthijs Ebbens, Hugo Parlier and Gert Vegter", "title": "Minimal Delaunay triangulations of hyperbolic surfaces", "comments": "28 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG math.CO math.GT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Motivated by recent work on Delaunay triangulations of hyperbolic surfaces,\nwe consider the minimal number of vertices of such triangulations. First, we\nwill show that every hyperbolic surface of genus $g$ has a simplicial Delaunay\ntriangulation with $O(g)$ vertices, where edges are given by distance paths.\nThen, we will construct a class of hyperbolic surfaces for which the order of\nthis bound is optimal. Finally, to give a general lower bound, we will show\nthat the $\\Omega(\\sqrt{g})$ lower bound for the number of vertices of a\nsimplicial triangulation of a topological surface of genus $g$ is tight for\nhyperbolic surfaces as well.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 14:31:43 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Ebbens", "Matthijs", ""], ["Parlier", "Hugo", ""], ["Vegter", "Gert", ""]]}, {"id": "2011.09875", "submitter": "Tom Gilat", "authors": "Tom Gilat and Ben Gilat", "title": "Fast Dirichlet Optimal Parameterization of Disks and Sphere Sectors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We utilize symmetries of tori constructed from copies of given disk-type\nmeshes in 3d, together with symmetries of corresponding tilings of fundamental\ndomains of plane tori. We use these correspondences to prove optimality of the\nembedding of the mesh onto special types of triangles in the plane, and\nrectangles. The proof provides a certain framework for using symmetries of the\nimage domain. The complexity is linear in the mesh size. We then use the method\nto prove a novel embedding of a 3-fold rotationally symmetric sphere-type mesh\nonto a set in the plane with 3-fold rotational symmetry. The only additional\nconstraint on the set is that its translations tile the plane. The embedding is\noptimal under the symmetry and tiling constraint. This is done by a novel\nconstruction of a torus from 63 copies of the original sphere.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 14:56:37 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Gilat", "Tom", ""], ["Gilat", "Ben", ""]]}, {"id": "2011.09925", "submitter": "R Inkulu", "authors": "Sanjana Agrwal, R. Inkulu", "title": "Visibility Polygons and Visibility Graphs among Dynamic Polygonal\n  Obstacles in the Plane", "comments": "preliminary version appeared in COCOON 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We devise an algorithm for maintaining the visibility polygon of any query\npoint in a dynamic polygonal domain, i.e., as the polygonal domain is modified\nwith vertex insertions and deletions to its obstacles, we update the data\nstructures that store the visibility polygon of the query point. After\npreprocessing the initial input polygonal domain to build a few data\nstructures, our algorithm takes O(k(\\lg{|VP_{\\cal P'}(q)|})+(\\lg{n'})^{2}+h)\n(resp. O(k(\\lg n')^2+(\\lg|VP_{\\cal P'}(q)|)+h)) worst-case time to update data\nstructures that store visibility polygon VP_{\\cal P'}(q) of a query point q\nwhen any vertex v is inserted to (resp. deleted from) any obstacle of the\ncurrent polygonal domain \\cal P'. Here, n' is the number of vertices in \\cal\nP', h is the number of obstacles in \\cal P', VP_{\\cal P'}(q) is the visibility\npolygon of q in \\cal P' (|VP_{\\cal P'}(q)| is the number of vertices of\nVP_{\\cal P'}(q)), and k is the number of combinatorial changes in VP_{\\cal\nP'}(q) due to the insertion (resp. deletion) of v.\n  As an application of the above algorithm, we also devise an algorithm for\nmaintaining the visibility graph of a dynamic polygonal domain, i.e., as the\npolygonal domain is modified with vertex insertions and deletions to its\nobstacles, we update data structures that store the visibility graph of the\npolygonal domain. After preprocessing the initial input polygonal domain, our\ndynamic algorithm takes O(k(\\lg{n'})^{2}+h) (resp. O(k(\\lg{n'})^{2}+h))\nworst-case time to update data structures that store the visibility graph when\nany vertex v is inserted to (resp. deleted from) any obstacle of the current\npolygonal domain \\cal P'. Here, n' is the number of vertices in \\cal P', h is\nthe number of obstacles in \\cal P', and k is the number of combinatorial\nchanges in the visibility graph of \\cal P' due to the insertion (resp.\ndeletion) of v.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 16:07:41 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Agrwal", "Sanjana", ""], ["Inkulu", "R.", ""]]}, {"id": "2011.10175", "submitter": "Yuichi Nagata", "authors": "Yuichi Nagata and Shinji Imahori", "title": "Escherization with Generalized Distance Functions Focusing on Local\n  Structural Similarity", "comments": "This is a manuscript currently submitted to a journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Escherization problem involves finding a closed figure that tiles the\nplane that is most similar to a given goal figure. In Koizumi and Sugihara's\nformulation of the Escherization problem, the tile and goal figures are\nrepresented as $n$-point polygons where the similarity between them is measured\nbased on the difference in the positions between the corresponding points. This\npaper presents alternative similarity measures (distance functions) suitable\nfor this problem. The proposed distance functions focus on the similarity of\nlocal structures in several different manners. The designed distance functions\nare incorporated into a recently developed framework of the exhaustive search\nof the templates for the Escherization problem. Efficient exhaustive and\nincomplete search algorithms for the formulated problems are also developed to\nobtain results within a reasonable computation time. Experimental results\nshowed that the proposed algorithms found satisfactory tile shapes for fairly\ncomplicated goal figures in a reasonable computation time.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 02:24:54 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Nagata", "Yuichi", ""], ["Imahori", "Shinji", ""]]}, {"id": "2011.10508", "submitter": "Yue Hao", "authors": "Yue Hao, Weilin Guan, Edwin A Peraza Hernandez, and Jyh-Ming Lien", "title": "Planning Folding Motion with Simulation in the Loop Using Laser Forming\n  Origami and Thermal Behaviors as an Example", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing a robot or structure that can fold itself into a target shape is a\nprocess that involves challenges originated from multiple sources. For example,\nthe designer of rigid self-folding robots must consider foldability from\ngeometric and kinematic aspects to avoid self-intersection and undesired\ndeformations. Recent works have shown success in estimating foldability of a\ndesign using robot motion planners. However, many foldable structures are\nactuated using physically coupled reactions (i.e., folding originated from\nthermal, chemical, or electromagnetic loads). Therefore, a reliable foldability\nanalysis must consider additional constraints that resulted from these critical\nphenomena. This work investigates the idea of efficiently incorporating\ncomputationally expensive physics simulation within the folding motion planner\nto provide a better estimation of the foldability. In this paper, we will use\nlaser forming origami as an example to demonstrate the benefits of considering\nthe properties beyond geometry. We show that the design produced by the\nproposed method can be folded more efficiently.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 17:07:49 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Hao", "Yue", ""], ["Guan", "Weilin", ""], ["Hernandez", "Edwin A Peraza", ""], ["Lien", "Jyh-Ming", ""]]}, {"id": "2011.10963", "submitter": "Eklavya Sharma", "authors": "Eklavya Sharma", "title": "Harmonic Algorithms for Packing d-dimensional Cuboids Into Bins", "comments": "Update 2: major refactoring; Update 1: fix typos, slightly improve\n  readability, use title-case for title", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore approximation algorithms for the $d$-dimensional geometric bin\npacking problem ($d$BP). Caprara (MOR 2008) gave a harmonic-based algorithm for\n$d$BP having an asymptotic approximation ratio (AAR) of $T_{\\infty}^{d-1}$\n(where $T_{\\infty} \\approx 1.691$). However, their algorithm doesn't allow\nitems to be rotated. This is in contrast to some common applications of $d$BP,\nlike packing boxes into shipping containers. We give approximation algorithms\nfor $d$BP when items can be orthogonally rotated about all or a subset of axes.\nWe first give a fast and simple harmonic-based algorithm having AAR\n$T_{\\infty}^{d}$. We next give a more sophisticated harmonic-based algorithm,\nwhich we call $\\mathtt{HGaP}_k$, having AAR $T_{\\infty}^{d-1}(1+\\epsilon)$.\nThis gives an AAR of roughly $2.860 + \\epsilon$ for 3BP with rotations, which\nimproves upon the best-known AAR of $4.5$.\n  In addition, we study the multiple-choice bin packing problem that\ngeneralizes the rotational case. Here we are given $n$ sets of $d$-dimensional\ncuboidal items and we have to choose exactly one item from each set and then\npack the chosen items. Our algorithms also work for the multiple-choice bin\npacking problem. We also give fast and simple approximation algorithms for the\nmultiple-choice versions of $d$D strip packing and $d$D geometric knapsack.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2020 07:44:51 GMT"}, {"version": "v2", "created": "Thu, 17 Dec 2020 16:47:57 GMT"}, {"version": "v3", "created": "Wed, 21 Apr 2021 19:01:52 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Sharma", "Eklavya", ""]]}, {"id": "2011.10983", "submitter": "Thomas Dybdahl Ahle", "authors": "Anders Aamand, Mikkel Abrahamsen, Thomas D. Ahle, Peter M. R.\n  Rasmussen", "title": "Tiling with Squares and Packing Dominos in Polynomial Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider planar tiling and packing problems with polyomino pieces and a\npolyomino container $P$. A polyomino is a polygonal region with axis parallel\nedges and corners of integral coordinates, which may have holes. We give two\npolynomial time algorithms, one for deciding if $P$ can be tiled with $2\\times\n2$ squares (that is, deciding if $P$ is the union of a set of non-overlapping\ncopies of the $2\\times 2$ square) and one for packing $P$ with a maximum number\nof non-overlapping and axis-parallel $2\\times 1$ dominos, allowing rotations of\n$90^\\circ$. As packing is more general than tiling, the latter algorithm can\nalso be used to decide if $P$ can be tiled by $2\\times 1$ dominos.\n  These are classical problems with important applications in VLSI design, and\nthe related problem of finding a maximum packing of $2\\times 2$ squares is\nknown to be NP-Hard [J.~Algorithms 1990]. For our three problems there are\nknown pseudo-polynomial time algorithms, that is, algorithms with running times\npolynomial in the \\emph{area} of $P$. However, the standard, compact way to\nrepresent a polygon is by listing the coordinates of the corners in binary. We\nuse this representation, and thus present the first polynomial time algorithms\nfor the problems. Concretely, we give a simple $O(n\\log n)$ algorithm for\ntiling with squares, and a more involved $O(n^4)$ algorithm for packing and\ntiling with dominos.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2020 10:57:30 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Aamand", "Anders", ""], ["Abrahamsen", "Mikkel", ""], ["Ahle", "Thomas D.", ""], ["Rasmussen", "Peter M. R.", ""]]}, {"id": "2011.11134", "submitter": "Yuanxin Zhong", "authors": "Yuanxin Zhong", "title": "Differentiable Computational Geometry for 2D and 3D machine learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.GR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the growth of machine learning algorithms with geometry primitives, a\nhigh-efficiency library with differentiable geometric operators are desired. We\npresent an optimized Differentiable Geometry Algorithm Library (DGAL) loaded\nwith implementations of differentiable operators for geometric primitives like\nlines and polygons. The library is a header-only templated C++ library with GPU\nsupport. We discuss the internal design of the library and benchmark its\nperformance on some tasks with other implementations.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2020 23:22:49 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Zhong", "Yuanxin", ""]]}, {"id": "2011.11503", "submitter": "Timothy Chu", "authors": "Timothy Chu, Gary Miller, Shyam Narayanan, Mark Sellke", "title": "Functions that Preserve Manhattan Distances", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.LG math.MG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  What functions, when applied to the pairwise Manhattan distances between any\n$n$ points, result in the Manhattan distances between another set of $n$\npoints? In this paper, we show that a function has this property if and only if\nit is Bernstein. This class of functions admits several classical analytic\ncharacterizations and includes $f(x) = x^s$ for $0 \\leq s \\leq 1$ as well as\n$f(x) = 1-e^{-xt}$ for any $t \\geq 0$. While it was previously known that\nBernstein functions had this property, it was not known that these were the\nonly such functions.\n  Our results are a natural extension of the work of Schoenberg from 1938, who\naddressed this question for Euclidean distances. Schoenberg's work has been\napplied in probability theory, harmonic analysis, machine learning, theoretical\ncomputer science, and more.\n  We additionally show that if and only if $f$ is completely monotone, there\nexists \\mbox{$F:\\ell_1 \\rightarrow \\mathbb{R}^n$} for any $x_1, \\ldots x_n \\in\n\\ell_1$ such that $f(\\|x_i - x_j\\|_1) = \\langle F(x_i), F(x_j) \\rangle$.\nPreviously, it was known that completely monotone functions had this property,\nbut it was not known they were the only such functions. The same result but\nwith negative type distances instead of $\\ell_1$ is the foundation of all\nkernel methods in machine learning, and was proven by Schoenberg in 1942.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 16:03:12 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Chu", "Timothy", ""], ["Miller", "Gary", ""], ["Narayanan", "Shyam", ""], ["Sellke", "Mark", ""]]}, {"id": "2011.11579", "submitter": "Megan Johnson", "authors": "Megan Johnson, Jae-Hun Jung", "title": "The Interconnectivity Vector: A Finite-Dimensional Vector Representation\n  of Persistent Homology", "comments": "28 pages, 20 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Persistent Homology (PH) is a useful tool to study the underlying structure\nof a data set. Persistence Diagrams (PDs), which are 2D multisets of points,\nare a concise summary of the information found by studying the PH of a data\nset. However, PDs are difficult to incorporate into a typical machine learning\nworkflow. To that end, two main methods for representing PDs have been\ndeveloped: kernel methods and vectorization methods. In this paper we propose a\nnew finite-dimensional vector, called the interconnectivity vector,\nrepresentation of a PD adapted from Bag-of-Words (BoW). This new representation\nis constructed to demonstrate the connections between the homological features\nof a data set. This initial definition of the interconnectivity vector proves\nto be unstable, but we introduce a stabilized version of the vector and prove\nits stability with respect to small perturbations in the inputs. We evaluate\nboth versions of the presented vectorization on several data sets and show\ntheir high discriminative power.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 17:43:06 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Johnson", "Megan", ""], ["Jung", "Jae-Hun", ""]]}, {"id": "2011.11672", "submitter": "Ka Yaw Teo", "authors": "Ovidiu Daescu and Ka Yaw Teo", "title": "Characterization and Computation of Feasible Trajectories for an\n  Articulated Probe with a Variable-Length End Segment", "comments": "42 pages, 19 figures. A preliminary version of this work was\n  presented at the 32nd Annual Canadian Conference on Computational Geometry", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  An articulated probe is modeled in the plane as two line segments, $ab$ and\n$bc$, joined at $b$, with $ab$ being very long, and $bc$ of some small length\n$r$. We investigate a trajectory planning problem involving the articulated\ntwo-segment probe where the length $r$ of $bc$ can be customized. Consider a\nset $P$ of simple polygonal obstacles with a total of $n$ vertices, a target\npoint $t$ located in the free space such that $t$ cannot see to infinity, and a\ncircle $S$ centered at $t$ enclosing $P$. The probe initially resides outside\n$S$, with $ab$ and $bc$ being collinear, and is restricted to the following\nsequence of moves: a straight line insertion of $abc$ into $S$ followed by a\nrotation of $bc$ around $b$. The goal is to compute a feasible\nobstacle-avoiding trajectory for the probe so that, after the sequence of\nmoves, $c$ coincides with $t$.\n  We prove that, for $n$ line segment obstacles, the smallest length $r$ for\nwhich there exists a feasible probe trajectory can be found in\n$O(n^{2+\\epsilon})$ time using $O(n^{2+\\epsilon})$ space, for any constant\n$\\epsilon > 0$. Furthermore, we prove that all values $r$ for which a feasible\nprobe trajectory exists form $O(n^2)$ intervals, and can be computed in\n$O(n^{5/2})$ time using $O(n^{2+\\epsilon})$ space. We also show that, for a\ngiven $r$, the feasible trajectory space of the articulated probe can be\ncharacterized by a simple arrangement of complexity $O(n^2)$, which can be\nconstructed in $O(n^2)$ time. To obtain our solutions, we design efficient data\nstructures for a number of interesting variants of geometric intersection and\nemptiness query problems.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 19:11:59 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Daescu", "Ovidiu", ""], ["Teo", "Ka Yaw", ""]]}, {"id": "2011.11685", "submitter": "Ka Yaw Teo", "authors": "Ovidiu Daescu and Ka Yaw Teo", "title": "Computing Feasible Trajectories for an Articulated Probe in Three\n  Dimensions", "comments": "38 pages, 14 figures. A preliminary version of this work was\n  presented at the 31st Annual Canadian Conference on Computational Geometry", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Consider an input consisting of a set of $n$ disjoint triangular obstacles in\n$\\mathbb{R}^3$ and a target point $t$ in the free space, all enclosed by a\nlarge sphere $S$ of radius $R$ centered at $t$. An articulated probe is modeled\nas two line segments $ab$ and $bc$ connected at point $b$. The length of $ab$\ncan be equal to or greater than $R$, while $bc$ is of a given length $r \\leq\nR$. The probe is initially located outside $S$, assuming an unarticulated\nconfiguration, in which $ab$ and $bc$ are collinear and $b \\in ac$. The goal is\nto find a feasible (obstacle-avoiding) probe trajectory to reach $t$, with the\ncondition that the probe is constrained by the following sequence of moves -- a\nstraight-line insertion of the unarticulated probe into $S$, possibly followed\nby a rotation of $bc$ at $b$ for at most $\\pi/2$ radians, so that $c$ coincides\nwith $t$.\n  We prove that if there exists a feasible probe trajectory, then a set of\nextremal feasible trajectories must be present. Through careful case analysis,\nwe show that these extremal trajectories can be represented by $O(n^4)$\ncombinatorial events. We present a solution approach that enumerates and\nverifies these combinatorial events for feasibility in overall\n$O(n^{4+\\epsilon})$ time using $O(n^{4+\\epsilon})$ space, for any constant\n$\\epsilon > 0$. The enumeration algorithm is highly parallel, considering that\neach combinatorial event can be generated and verified for feasibility\nindependently of the others. In the process of deriving our solution, we design\nthe first data structure for addressing a special instance of circular sector\nemptiness queries among polyhedral obstacles in three dimensional space, and\nprovide a simplified data structure for the corresponding emptiness query\nproblem in two dimensions.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 19:24:43 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Daescu", "Ovidiu", ""], ["Teo", "Ka Yaw", ""]]}, {"id": "2011.12187", "submitter": "G\\'abor Dam\\'asdi", "authors": "G\\'abor Dam\\'asdi, P\\'alv\\\"olgyi D\\\"om\\\"ot\\\"or", "title": "Realizing an m-uniform four-chromatic hypergraph with disks", "comments": "17 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CG cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that for every $m$ there is a finite point set $\\mathcal{P}$ in the\nplane such that no matter how $\\mathcal{P}$ is three-colored, there is always a\ndisk containing exactly $m$ points, all of the same color. This improves a\nresult of Pach, Tardos and T\\'oth who proved the same for two colors. The main\ningredient of the construction is a subconstruction whose points are in convex\nposition. Namely, we show that for every $m$ there is a finite point set\n$\\mathcal{P}$ in the plane in convex position such that no matter how\n$\\mathcal{P}$ is two-colored, there is always a disk containing exactly $m$\npoints, all of the same color. We also prove that for unit disks no similar\nconstruction can work, and several other results.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 16:15:30 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Dam\u00e1sdi", "G\u00e1bor", ""], ["D\u00f6m\u00f6t\u00f6r", "P\u00e1lv\u00f6lgyi", ""]]}, {"id": "2011.12465", "submitter": "Sunipa Dev", "authors": "Sunipa Dev", "title": "The Geometry of Distributed Representations for Better Alignment,\n  Attenuated Bias, and Improved Interpretability", "comments": "PhD thesis, University of Utah (2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CG cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  High-dimensional representations for words, text, images, knowledge graphs\nand other structured data are commonly used in different paradigms of machine\nlearning and data mining. These representations have different degrees of\ninterpretability, with efficient distributed representations coming at the cost\nof the loss of feature to dimension mapping. This implies that there is\nobfuscation in the way concepts are captured in these embedding spaces. Its\neffects are seen in many representations and tasks, one particularly\nproblematic one being in language representations where the societal biases,\nlearned from underlying data, are captured and occluded in unknown dimensions\nand subspaces. As a result, invalid associations (such as different races and\ntheir association with a polar notion of good versus bad) are made and\npropagated by the representations, leading to unfair outcomes in different\ntasks where they are used. This work addresses some of these problems\npertaining to the transparency and interpretability of such representations. A\nprimary focus is the detection, quantification, and mitigation of socially\nbiased associations in language representation.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 01:04:11 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Dev", "Sunipa", ""]]}, {"id": "2011.12589", "submitter": "Jaskirat Singh", "authors": "Jaskirat Singh and Liang Zheng", "title": "Combining Semantic Guidance and Deep Reinforcement Learning For\n  Generating Human Level Paintings", "comments": null, "journal-ref": "Proceedings of the IEEE/CVF Conference on Computer Vision and\n  Pattern Recognition (CVPR), 2021, pp. 16387-16396", "doi": null, "report-no": null, "categories": "cs.CV cs.CG cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Generation of stroke-based non-photorealistic imagery, is an important\nproblem in the computer vision community. As an endeavor in this direction,\nsubstantial recent research efforts have been focused on teaching machines \"how\nto paint\", in a manner similar to a human painter. However, the applicability\nof previous methods has been limited to datasets with little variation in\nposition, scale and saliency of the foreground object. As a consequence, we\nfind that these methods struggle to cover the granularity and diversity\npossessed by real world images. To this end, we propose a Semantic Guidance\npipeline with 1) a bi-level painting procedure for learning the distinction\nbetween foreground and background brush strokes at training time. 2) We also\nintroduce invariance to the position and scale of the foreground object through\na neural alignment model, which combines object localization and spatial\ntransformer networks in an end to end manner, to zoom into a particular\nsemantic instance. 3) The distinguishing features of the in-focus object are\nthen amplified by maximizing a novel guided backpropagation based focus reward.\nThe proposed agent does not require any supervision on human stroke-data and\nsuccessfully handles variations in foreground object attributes, thus,\nproducing much higher quality canvases for the CUB-200 Birds and Stanford\nCars-196 datasets. Finally, we demonstrate the further efficacy of our method\non complex datasets with multiple foreground object instances by evaluating an\nextension of our method on the challenging Virtual-KITTI dataset. Source code\nand models are available at https://github.com/1jsingh/semantic-guidance.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 09:00:04 GMT"}, {"version": "v2", "created": "Tue, 15 Jun 2021 00:39:15 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Singh", "Jaskirat", ""], ["Zheng", "Liang", ""]]}, {"id": "2011.12636", "submitter": "Prateek Katiyar Dr.", "authors": "Prateek Katiyar, Anna Khoreva", "title": "Improving Augmentation and Evaluation Schemes for Semantic Image\n  Synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CG cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite data augmentation being a de facto technique for boosting the\nperformance of deep neural networks, little attention has been paid to\ndeveloping augmentation strategies for generative adversarial networks (GANs).\nTo this end, we introduce a novel augmentation scheme designed specifically for\nGAN-based semantic image synthesis models. We propose to randomly warp object\nshapes in the semantic label maps used as an input to the generator. The local\nshape discrepancies between the warped and non-warped label maps and images\nenable the GAN to learn better the structural and geometric details of the\nscene and thus to improve the quality of generated images. While benchmarking\nthe augmented GAN models against their vanilla counterparts, we discover that\nthe quantification metrics reported in the previous semantic image synthesis\nstudies are strongly biased towards specific semantic classes as they are\nderived via an external pre-trained segmentation network. We therefore propose\nto improve the established semantic image synthesis evaluation scheme by\nanalyzing separately the performance of generated images on the biased and\nunbiased classes for the given segmentation network. Finally, we show strong\nquantitative and qualitative improvements obtained with our augmentation\nscheme, on both class splits, using state-of-the-art semantic image synthesis\nmodels across three different datasets. On average across COCO-Stuff, ADE20K\nand Cityscapes datasets, the augmented models outperform their vanilla\ncounterparts by ~3 mIoU and ~10 FID points.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 10:55:26 GMT"}, {"version": "v2", "created": "Tue, 8 Dec 2020 16:22:06 GMT"}, {"version": "v3", "created": "Sat, 30 Jan 2021 09:43:15 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Katiyar", "Prateek", ""], ["Khoreva", "Anna", ""]]}, {"id": "2011.13275", "submitter": "Linda Kleist", "authors": "Thomas Byrne, S\\'andor P. Fekete, J\\\"org Kalcsics, and Linda Kleist", "title": "Competitive Location Problems: Balanced Facility Location and the\n  One-Round Manhattan Voronoi Game", "comments": "19 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DM cs.GT econ.TH math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study competitive location problems in a continuous setting, in which\nfacilities have to be placed in a rectangular domain $R$ of normalized\ndimensions of $1$ and $\\rho\\geq 1$, and distances are measured according to the\nManhattan metric. We show that the family of 'balanced' facility configurations\n(in which the Voronoi cells of individual facilities are equalized with respect\nto a number of geometric properties) is considerably richer in this metric than\nfor Euclidean distances. Our main result considers the 'One-Round Voronoi Game'\nwith Manhattan distances, in which first player White and then player Black\neach place $n$ points in $R$; each player scores the area for which one of its\nfacilities is closer than the facilities of the opponent. We give a tight\ncharacterization: White has a winning strategy if and only if $\\rho\\geq n$; for\nall other cases, we present a winning strategy for Black.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 13:20:21 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Byrne", "Thomas", ""], ["Fekete", "S\u00e1ndor P.", ""], ["Kalcsics", "J\u00f6rg", ""], ["Kleist", "Linda", ""]]}, {"id": "2011.13849", "submitter": "Reza Maalek", "authors": "Reza Maalek and Derek Lichti", "title": "Robust Detection of Non-overlapping Ellipses from Points with\n  Applications to Circular Target Extraction in Images and Cylinder Detection\n  in Point Clouds", "comments": null, "journal-ref": null, "doi": "10.1016/j.isprsjprs.2021.04.010", "report-no": null, "categories": "cs.CV cs.CG cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This manuscript provides a collection of new methods for the automated\ndetection of non-overlapping ellipses from edge points. The methods introduce\nnew developments in: (i) robust Monte Carlo-based ellipse fitting to\n2-dimensional (2D) points in the presence of outliers; (ii) detection of\nnon-overlapping ellipse from 2D edge points; and (iii) extraction of cylinder\nfrom 3D point clouds. The proposed methods were thoroughly compared with\nestablished state-of-the-art methods, using simulated and real-world datasets,\nthrough the design of four sets of original experiments. It was found that the\nproposed robust ellipse detection was superior to four reliable robust methods,\nincluding the popular least median of squares, in both simulated and real-world\ndatasets. The proposed process for detecting non-overlapping ellipses achieved\nF-measure of 99.3% on real images, compared to F-measures of 42.4%, 65.6%, and\n59.2%, obtained using the methods of Fornaciari, Patraucean, and Panagiotakis,\nrespectively. The proposed cylinder extraction method identified all detectable\nmechanical pipes in two real-world point clouds, obtained under laboratory, and\nindustrial construction site conditions. The results of this investigation show\npromise for the application of the proposed methods for automatic extraction of\ncircular targets from images and pipes from point clouds.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 21:56:02 GMT"}, {"version": "v2", "created": "Sun, 20 Dec 2020 15:07:21 GMT"}, {"version": "v3", "created": "Tue, 30 Mar 2021 17:56:30 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Maalek", "Reza", ""], ["Lichti", "Derek", ""]]}, {"id": "2011.14136", "submitter": "Huu Phuoc Le", "authors": "Huu Phuoc Le, Mohab Safey El Din", "title": "Solving parametric systems of polynomial equations over the reals\n  through Hermite matrices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SC cs.CG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We design a new algorithm for solving parametric systems having finitely many\ncomplex solutions for generic values of the parameters. More precisely, let $f\n= (f_1, \\ldots, f_m)\\subset \\mathbb{Q}[y][x]$ with $y = (y_1, \\ldots, y_t)$ and\n$x = (x_1, \\ldots, x_n)$, $V\\subset \\mathbb{C}^{t+n}$ be the algebraic set\ndefined by $f$ and $\\pi$ be the projection $(y, x) \\to y$. Under the\nassumptions that $f$ admits finitely many complex roots for generic values of\n$y$ and that the ideal generated by $f$ is radical, we solve the following\nproblem. On input $f$, we compute semi-algebraic formulas defining\nsemi-algebraic subsets $S_1, \\ldots, S_l$ of the $y$-space such that\n$\\cup_{i=1}^l S_i$ is dense in $\\mathbb{R}^t$ and the number of real points in\n$V\\cap \\pi^{-1}(\\eta)$ is invariant when $\\eta$ varies over each $S_i$.\n  This algorithm exploits properties of some well chosen monomial bases in the\nalgebra $\\mathbb{Q}(y)[x]/I$ where $I$ is the ideal generated by $f$ in\n$\\mathbb{Q}(y)[x]$ and the specialization property of the so-called Hermite\nmatrices. This allows us to obtain compact representations of the sets $S_i$ by\nmeans of semi-algebraic formulas encoding the signature of a symmetric matrix.\nWhen $f$ satisfies extra genericity assumptions, we derive complexity bounds on\nthe number of arithmetic operations in $\\mathbb{Q}$ and the degree of the\noutput polynomials. Let $d$ be the maximal degree of the $f_i$'s and $D =\nn(d-1)d^n$, we prove that, on a generic $f=(f_1,\\ldots,f_n)$, one can compute\nthose semi-algebraic formulas with $O^~( \\binom{t+D}{t}2^{3t}n^{2t+1}\nd^{3nt+2(n+t)+1})$ operations in $\\mathbb{Q}$ and that the polynomials involved\nhave degree bounded by $D$.\n  We report on practical experiments which illustrate the efficiency of our\nalgorithm on generic systems and systems from applications. It allows us to\nsolve problems which are out of reach of the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 14:09:06 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Le", "Huu Phuoc", ""], ["Din", "Mohab Safey El", ""]]}, {"id": "2011.14213", "submitter": "Yuxuan Yu", "authors": "Yuxuan Yu, Xiaodong Wei, Angran Li, Jialei Ginny Liu, Jeffrey He and\n  Yongjie Jessica Zhang", "title": "HexGen and Hex2Spline: Polycube-based Hexahedral Mesh Generation and\n  Spline Modeling for Isogeometric Analysis Applications in LS-DYNA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we present two software packages, HexGen and Hex2Spline, that\nseamlessly integrate geometry design with isogeometric analysis (IGA) in\nLS-DYNA. Given a boundary representation of a solid model, HexGen creates a\nhexahedral mesh by utilizing a semi-automatic polycube-based mesh generation\nmethod. Hex2Spline takes the output hexahedral mesh from HexGen as the input\ncontrol mesh and constructs volumetric truncated hierarchical splines. Through\nB\\'{e}zier extraction, Hex2Spline transfers spline information to LS-DYNA and\nperforms IGA therein. We explain the underlying algorithms in each software\npackage and use a rod model to explain how to run the software. We also apply\nour software to several other complex models to test its robustness. Our goal\nis to provide a robust volumetric modeling tool and thus expand the boundary of\nIGA to volume-based industrial applications.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 20:55:18 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Yu", "Yuxuan", ""], ["Wei", "Xiaodong", ""], ["Li", "Angran", ""], ["Liu", "Jialei Ginny", ""], ["He", "Jeffrey", ""], ["Zhang", "Yongjie Jessica", ""]]}, {"id": "2011.14282", "submitter": "Sergey Bereg", "authors": "Sergey Bereg and Mohammadreza Haghpanah", "title": "Constructing Order Type Graphs using an Axiomatic Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A given order type in the plane can be represented by a point set. However,\nit might be difficult to recognize the orientations of some point triples.\nRecently, Aichholzer \\etal \\cite{abh19} introduced exit graphs for visualizing\norder types in the plane. We present a new class of geometric graphs, called\n{\\em OT-graphs}, using abstract order types and their axioms described in the\nwell-known book by Knuth \\cite{k92}. Each OT-graph corresponds to a unique\norder type. We develop efficient algorithms for recognizing OT-graphs and\ncomputing a minimal OT-graph for a given order type in the plane. We provide\nexperimental results on all order types of up to nine points in the plane\nincluding a comparative analysis of exit graphs and OT-graphs.\n", "versions": [{"version": "v1", "created": "Sun, 29 Nov 2020 04:52:20 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Bereg", "Sergey", ""], ["Haghpanah", "Mohammadreza", ""]]}, {"id": "2011.14463", "submitter": "Neeraj Kumar", "authors": "Neeraj Kumar, Daniel Lokshtanov, Saket Saurabh, Subhash Suri", "title": "A Constant Factor Approximation for Navigating Through Connected\n  Obstacles in the Plane", "comments": "To appear in SODA 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DM", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Given two points s and t in the plane and a set of obstacles defined by\nclosed curves, what is the minimum number of obstacles touched by a path\nconnecting s and t? This is a fundamental and well-studied problem arising\nnaturally in computational geometry, graph theory (under the names Min-Color\nPath and Minimum Label Path), wireless sensor networks (Barrier Resilience) and\nmotion planning (Minimum Constraint Removal). It remains NP-hard even for very\nsimple-shaped obstacles such as unit-length line segments. In this paper we\ngive the first constant factor approximation algorithm for this problem,\nresolving an open problem of [Chan and Kirkpatrick, TCS, 2014] and\n[Bandyapadhyay et al., CGTA, 2020]. We also obtain a constant factor\napproximation for the Minimum Color Prize Collecting Steiner Forest where the\ngoal is to connect multiple request pairs (s1, t1), . . . ,(sk, tk) while\nminimizing the number of obstacles touched by any (si, ti) path plus a fixed\ncost of wi for each pair (si, ti) left disconnected. This generalizes the\nclassic Steiner Forest and Prize-Collecting Steiner Forest problems on planar\ngraphs, for which intricate PTASes are known. In contrast, no PTAS is possible\nfor Min-Color Path even on planar graphs since the problem is known to be\nAPXhard [Eiben and Kanj, TALG, 2020]. Additionally, we show that\ngeneralizations of the problem to disconnected obstacles\n", "versions": [{"version": "v1", "created": "Sun, 29 Nov 2020 23:04:03 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Kumar", "Neeraj", ""], ["Lokshtanov", "Daniel", ""], ["Saurabh", "Saket", ""], ["Suri", "Subhash", ""]]}, {"id": "2011.14490", "submitter": "Erlend Raa V{\\aa}gset", "authors": "Nello Blaser, Erlend Raa V{\\aa}gset", "title": "Homology Localization Through the Looking-Glass of Parameterized\n  Complexity Theory", "comments": "30 pages, 19 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CC math.AT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding a cycle of lowest weight that represents a homology class in a\nsimplicial complex is known as homology localization (HL). Here we address this\nNP-complete problem using parameterized complexity theory. We show that it is\nW[1]-hard to approximate the HL problem when it is parameterized by solution\nsize. We have also designed and implemented two algorithms based on treewidth\nsolving the HL problem in FPT-time. Both algorithms are ETH-tight but our\nresults shows that one outperforms the other in practice.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 01:25:37 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Blaser", "Nello", ""], ["V\u00e5gset", "Erlend Raa", ""]]}, {"id": "2011.14967", "submitter": "Celia Hacker", "authors": "Asilata Bapat, Robyn Brooks, Celia Hacker, Claudia Landi, Barbara I.\n  Mahler", "title": "Morse-based Fibering of the Persistence Rank Invariant", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AT cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although there is no doubt that multi-parameter persistent homology is a\nuseful tool to analyse multi-variate data, efficient ways to compute these\nmodules are still lacking in the available topological data analysis toolboxes.\nOther issues such as interpretation and visualization of the output remain\ndifficult to solve. Software visualizing multi-parameter persistence diagrams\nis currently only available for 2-dimensional persistence modules. One of the\nsimplest invariants for a multi-parameter persistence module is its rank\ninvariant, defined as the function that counts the number of linearly\nindependent homology classes that live in the filtration through a given pair\nof values of the multi-parameter. We propose a step towards interpretation and\nvisualization of the rank invariant for persistence modules for any given\nnumber of parameters. We show how discrete Morse theory may be used to compute\nthe rank invariant, proving that it is completely determined by its values at\npoints whose coordinates are critical with respect to a discrete Morse gradient\nvector field. These critical points partition the set of all lines of positive\nslope in the parameter space into equivalence classes, such that the rank\ninvariant along lines in the same class are also equivalent. We show that we\ncan deduce all persistence diagrams of the restrictions to the lines in a given\nclass from the persistence diagram of the restriction to a representative in\nthat class.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 16:38:30 GMT"}, {"version": "v2", "created": "Tue, 13 Apr 2021 18:46:38 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Bapat", "Asilata", ""], ["Brooks", "Robyn", ""], ["Hacker", "Celia", ""], ["Landi", "Claudia", ""], ["Mahler", "Barbara I.", ""]]}, {"id": "2011.15081", "submitter": "Albert Matveev", "authors": "Albert Matveev, Alexey Artemov, Ruslan Rakhimov, Gleb Bobrovskikh,\n  Daniele Panozzo, Denis Zorin, Evgeny Burnaev", "title": "DEF: Deep Estimation of Sharp Geometric Features in 3D Shapes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sharp feature lines carry essential information about human-made objects,\nenabling compact 3D shape representations, high-quality surface reconstruction,\nand are a signal source for mesh processing. While extracting high-quality\nlines from noisy and undersampled data is challenging for traditional methods,\ndeep learning-powered algorithms can leverage global and semantic information\nfrom the training data to aid in the process. We propose Deep Estimators of\nFeatures (DEFs), a learning-based framework for predicting sharp geometric\nfeatures in sampled 3D shapes. Differently from existing data-driven methods,\nwhich reduce this problem to feature classification, we propose to regress a\nscalar field representing the distance from point samples to the closest\nfeature line on local patches. By fusing the result of individual patches, we\ncan process large 3D models, which are impossible to process for existing\ndata-driven methods due to their size and complexity. Extensive experimental\nevaluation of DEFs is implemented on synthetic and real-world 3D shape datasets\nand suggests advantages of our image- and point-based estimators over\ncompetitor methods, as well as improved noise robustness and scalability of our\napproach.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 18:21:00 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Matveev", "Albert", ""], ["Artemov", "Alexey", ""], ["Rakhimov", "Ruslan", ""], ["Bobrovskikh", "Gleb", ""], ["Panozzo", "Daniele", ""], ["Zorin", "Denis", ""], ["Burnaev", "Evgeny", ""]]}]