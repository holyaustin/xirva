[{"id": "1511.00628", "submitter": "Mohamad Dolatshah", "authors": "Mohamad Dolatshah, Ali Hadian and Behrouz Minaei-Bidgoli", "title": "Ball*-tree: Efficient spatial indexing for constrained nearest-neighbor\n  search in metric spaces", "comments": "15 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emerging location-based systems and data analysis frameworks requires\nefficient management of spatial data for approximate and exact search. Exact\nsimilarity search can be done using space partitioning data structures, such as\nKd-tree, R*-tree, and Ball-tree. In this paper, we focus on Ball-tree, an\nefficient search tree that is specific for spatial queries which use euclidean\ndistance. Each node of a Ball-tree defines a ball, i.e. a hypersphere that\ncontains a subset of the points to be searched.\n  In this paper, we propose Ball*-tree, an improved Ball-tree that is more\nefficient for spatial queries. Ball*-tree enjoys a modified space partitioning\nalgorithm that considers the distribution of the data points in order to find\nan efficient splitting hyperplane. Also, we propose a new algorithm for KNN\nqueries with restricted range using Ball*-tree, which performs better than both\nKNN and range search for such queries. Results show that Ball*-tree performs\n39%-57% faster than the original Ball-tree algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2015 18:54:49 GMT"}], "update_date": "2015-11-03", "authors_parsed": [["Dolatshah", "Mohamad", ""], ["Hadian", "Ali", ""], ["Minaei-Bidgoli", "Behrouz", ""]]}, {"id": "1511.00797", "submitter": "Hyun-Seo Park", "authors": "Hyun-Seo Park, Yong-Seouk Choi, Tae-Joong Kim, Byung-Chul Kim, and\n  Jae-Yong Lee", "title": "Is It Possible to Simultaneously Achieve Zero Handover Failure Rate and\n  Ping-Pong Rate?", "comments": "15 pages, 9 figures. This work has been submitted to IEEE\n  Transactions on Vehicular Technology", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network densification through the deployment of large number of small cells\nhas been considered as the dominant driver for wireless evolution into 5G.\nHowever, it has increased the complexity of mobility management, and operators\nhave been facing the technical challenges in handover (HO) parameter\noptimization. The trade-off between the HO failure (HOF) rate and the ping-pong\n(PP) rate has further complicated the challenges. In this article, we proposed\nZEro handover failure with Unforced and automatic time-to-execute Scaling\n(ZEUS) HO. ZEUS HO assures HO signaling when a user equipment (UE) is in a good\nradio link condition and executes the HO at an optimal time. We analyzed the HO\nperformance of Long-Term Evolution (LTE) and ZEUS theoretically using a\ngeometry-based model, considering the most important HO parameter, i.e., HO\nmargin (HOM). We derived the probabilities of HOF and PP from the analysis. The\nnumerical results demonstrated that ZEUS HO can achieve zero HOF rate without\nincreasing the PP rate, solving the trade-off. Furthermore, we showed that the\nZEUS HO can accomplish zero HOF rate and zero PP rate simultaneously with an\nextension of keeping fast moving users out of small cells.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2015 07:24:44 GMT"}, {"version": "v2", "created": "Tue, 5 Apr 2016 10:26:32 GMT"}, {"version": "v3", "created": "Tue, 25 Oct 2016 06:56:18 GMT"}], "update_date": "2016-10-26", "authors_parsed": [["Park", "Hyun-Seo", ""], ["Choi", "Yong-Seouk", ""], ["Kim", "Tae-Joong", ""], ["Kim", "Byung-Chul", ""], ["Lee", "Jae-Yong", ""]]}, {"id": "1511.00820", "submitter": "Anne Marie Svane", "authors": "Julia H\\\"orrmann, Anne Marie Svane", "title": "Local digital algorithms applied to Boolean models", "comments": "28 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.CG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the estimation of specific intrinsic volumes of stationary\nBoolean models by local digital algorithms; that is, by weighted sums of $n\n\\times\\ldots \\times n$ configuration counts. We show that asymptotically\nunbiased estimators for the specific surface area or integrated mean curvature\ndo not exist if the dimension is at least two or three, respectively. For\n3-dimensional stationary, isotropic Boolean models, we derive asymptotically\nunbiased estimators for the specific surface area and integrated mean\ncurvature. For a Boolean model with balls as grains we even obtain an\nasymptotically unbiased estimator for the specific Euler characteristic.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2015 09:08:16 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["H\u00f6rrmann", "Julia", ""], ["Svane", "Anne Marie", ""]]}, {"id": "1511.00873", "submitter": "Martin Derka", "authors": "Therese Biedl, Martin Derka", "title": "The (3,1)-ordering for 4-connected planar triangulations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Canonical orderings of planar graphs have frequently been used in graph\ndrawing and other graph algorithms. In this paper we introduce the notion of an\n$(r,s)$-canonical order, which unifies many of the existing variants of\ncanonical orderings. We then show that $(3,1)$-canonical ordering for\n4-connected triangulations always exist; to our knowledge this variant of\ncanonical ordering was not previously known. We use it to give much simpler\nproofs of two previously known graph drawing results for 4-connected planar\ntriangulations, namely, rectangular duals and rectangle-of-influence drawings.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2015 12:17:51 GMT"}], "update_date": "2015-11-04", "authors_parsed": [["Biedl", "Therese", ""], ["Derka", "Martin", ""]]}, {"id": "1511.01612", "submitter": "Mohammad Ali Abam", "authors": "Mohammad Ali Abam, Mark de Berg, Mohammad Javad Rezaei Seraji", "title": "Geodesic Spanners for Points on a Polyhedral Terrain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that there exists a geodesic spanner with almost linear number of\nedges.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2015 05:25:15 GMT"}], "update_date": "2015-11-06", "authors_parsed": [["Abam", "Mohammad Ali", ""], ["de Berg", "Mark", ""], ["Seraji", "Mohammad Javad Rezaei", ""]]}, {"id": "1511.03501", "submitter": "Arkadiy Skopenkov", "authors": "S. Avvakumov, I. Mabillard, A. Skopenkov, U. Wagner", "title": "Eliminating Higher-Multiplicity Intersections, III. Codimension 2", "comments": "24 pages, 4 figures, exposition improved", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.GT cs.CG math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study conditions under which a finite simplicial complex $K$ can be mapped\nto $\\mathbb R^d$ without higher-multiplicity intersections. An almost\n$r$-embedding is a map $f: K\\to \\mathbb R^d$ such that the images of any $r$\npairwise disjoint simplices of $K$ do not have a common point. We show that if\n$r$ is not a prime power and $d\\geq 2r+1$, then there is a counterexample to\nthe topological Tverberg conjecture, i.e., there is an almost $r$-embedding of\nthe $(d+1)(r-1)$-simplex in $\\mathbb R^d$. This improves on previous\nconstructions of counterexamples (for $d\\geq 3r$) based on a series of papers\nby M. \\\"Ozaydin, M. Gromov, P. Blagojevi\\'c, F. Frick, G. Ziegler, and the\nsecond and fourth present authors.\n  The counterexamples are obtained by proving the following algebraic criterion\nin codimension 2: If $r\\ge3$ and if $K$ is a finite $2(r-1)$-complex then there\nexists an almost $r$-embedding $K\\to \\mathbb R^{2r}$ if and only if there\nexists a general position PL map $f:K\\to \\mathbb R^{2r}$ such that the\nalgebraic intersection number of the $f$-images of any $r$ pairwise disjoint\nsimplices of $K$ is zero. This result can be restated in terms of cohomological\nobstructions or equivariant maps, and extends an analogous codimension 3\ncriterion by the second and fourth authors. As another application we classify\nornaments $f:S^3 \\sqcup S^3\\sqcup S^3\\to \\mathbb R^5$ up to ornament\nconcordance.\n  It follows from work of M. Freedman, V. Krushkal and P. Teichner that the\nanalogous criterion for $r=2$ is false. We prove a lemma on singular\nhigher-dimensional Borromean rings, yielding an elementary proof of the\ncounterexample.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2015 13:47:38 GMT"}, {"version": "v2", "created": "Thu, 30 Jun 2016 11:08:52 GMT"}, {"version": "v3", "created": "Fri, 17 Feb 2017 06:28:33 GMT"}, {"version": "v4", "created": "Wed, 26 Jul 2017 16:11:04 GMT"}, {"version": "v5", "created": "Tue, 16 Oct 2018 16:59:10 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Avvakumov", "S.", ""], ["Mabillard", "I.", ""], ["Skopenkov", "A.", ""], ["Wagner", "U.", ""]]}, {"id": "1511.03576", "submitter": "Mohammad Khabbaz", "authors": "Mohammad Khabbaz", "title": "DataGrinder: Fast, Accurate, Fully non-Parametric Classification\n  Approach Using 2D Convex Hulls", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CG cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been a long time, since data mining technologies have made their ways\nto the field of data management. Classification is one of the most important\ndata mining tasks for label prediction, categorization of objects into groups,\nadvertisement and data management. In this paper, we focus on the standard\nclassification problem which is predicting unknown labels in Euclidean space.\nMost efforts in Machine Learning communities are devoted to methods that use\nprobabilistic algorithms which are heavy on Calculus and Linear Algebra. Most\nof these techniques have scalability issues for big data, and are hardly\nparallelizable if they are to maintain their high accuracies in their standard\nform. Sampling is a new direction for improving scalability, using many small\nparallel classifiers. In this paper, rather than conventional sampling methods,\nwe focus on a discrete classification algorithm with O(n) expected running\ntime. Our approach performs a similar task as sampling methods. However, we use\ncolumn-wise sampling of data, rather than the row-wise sampling used in the\nliterature. In either case, our algorithm is completely deterministic. Our\nalgorithm, proposes a way of combining 2D convex hulls in order to achieve high\nclassification accuracy as well as scalability in the same time. First, we\nthoroughly describe and prove our O(n) algorithm for finding the convex hull of\na point set in 2D. Then, we show with experiments our classifier model built\nbased on this idea is very competitive compared with existing sophisticated\nclassification algorithms included in commercial statistical applications such\nas MATLAB.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2015 17:06:35 GMT"}], "update_date": "2015-11-12", "authors_parsed": [["Khabbaz", "Mohammad", ""]]}, {"id": "1511.03827", "submitter": "Louis Esperet", "authors": "Louis Esperet, Daniel Gon\\c{c}alves, and Arnaud Labourel", "title": "Coloring non-crossing strings", "comments": "19 pages. A preliminary version of this work appeared in the\n  proceedings of EuroComb'09 under the title \"Coloring a set of touching\n  strings\"", "journal-ref": "Electronic Journal of Combinatorics 23(4) (2016), #P4.4", "doi": null, "report-no": null, "categories": "math.CO cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a family of geometric objects in the plane\n$\\mathcal{F}=\\{S_1,\\ldots,S_n\\}$, define $\\chi(\\mathcal{F})$ as the least\ninteger $\\ell$ such that the elements of $\\mathcal{F}$ can be colored with\n$\\ell$ colors, in such a way that any two intersecting objects have distinct\ncolors. When $\\mathcal{F}$ is a set of pseudo-disks that may only intersect on\ntheir boundaries, and such that any point of the plane is contained in at most\n$k$ pseudo-disks, it can be proven that $\\chi(\\mathcal{F})\\le 3k/2 + o(k)$\nsince the problem is equivalent to cyclic coloring of plane graphs. In this\npaper, we study the same problem when pseudo-disks are replaced by a family\n$\\mathcal{F}$ of pseudo-segments (a.k.a. strings) that do not cross. In other\nwords, any two strings of $\\mathcal{F}$ are only allowed to \"touch\" each other.\nSuch a family is said to be $k$-touching if no point of the plane is contained\nin more than $k$ elements of $\\mathcal{F}$. We give bounds on\n$\\chi(\\mathcal{F})$ as a function of $k$, and in particular we show that\n$k$-touching segments can be colored with $k+5$ colors. This partially answers\na question of Hlin\\v{e}n\\'y (1998) on the chromatic number of contact systems\nof strings.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2015 09:25:00 GMT"}, {"version": "v2", "created": "Fri, 18 Nov 2016 10:19:25 GMT"}], "update_date": "2016-11-21", "authors_parsed": [["Esperet", "Louis", ""], ["Gon\u00e7alves", "Daniel", ""], ["Labourel", "Arnaud", ""]]}, {"id": "1511.04036", "submitter": "Mikkel Abrahamsen", "authors": "Mikkel Abrahamsen", "title": "An Optimal Algorithm for the Separating Common Tangents of two Polygons", "comments": "12 pages, 6 figures. A preliminary version of this paper appeared at\n  SoCG 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe an algorithm for computing the separating common tangents of two\nsimple polygons using linear time and only constant workspace. A tangent of a\npolygon is a line touching the polygon such that all of the polygon lies to the\nsame side of the line. A separating common tangent of two polygons is a tangent\nof both polygons where the polygons are lying on different sides of the\ntangent. Each polygon is given as a read-only array of its corners. If a\nseparating common tangent does not exist, the algorithm reports that.\nOtherwise, two corners defining a separating common tangent are returned. The\nalgorithm is simple and implies an optimal algorithm for deciding if the convex\nhulls of two polygons are disjoint or not. This was not known to be possible in\nlinear time and constant workspace prior to this paper.\n  An outer common tangent is a tangent of both polygons where the polygons are\non the same side of the tangent. In the case where the convex hulls of the\npolygons are disjoint, we give an algorithm for computing the outer common\ntangents in linear time using constant workspace.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2015 19:59:53 GMT"}], "update_date": "2015-11-13", "authors_parsed": [["Abrahamsen", "Mikkel", ""]]}, {"id": "1511.04123", "submitter": "Matias Korman", "authors": "Luis Barba, Otfried Cheong, Jean Lou De Carufel, Michael Gene Dobbins,\n  Rudolf Fleischer, Akitoshi Kawamura, Matias Korman, Yoshio Okamoto, Janos\n  Pach, Yuan Tang, Takeshi Tokuyama, Sander Verdonschot, Tianhao Wang", "title": "Weight Balancing on Boundaries and Skeletons", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a polygonal region containing a target point (which we assume is the\norigin), it is not hard to see that there are two points on the perimeter that\nare antipodal, i.e., whose midpoint is the origin. We prove three\ngeneralizations of this fact. (1) For any polygon (or any bounded closed region\nwith connected boundary) containing the origin, it is possible to place a given\nset of weights on the boundary so that their barycenter (center of mass)\ncoincides with the origin, provided that the largest weight does not exceed the\nsum of the other weights. (2) On the boundary of any $3$-dimensional bounded\npolyhedron containing the origin, there exist three points that form an\nequilateral triangle centered at the origin. (3) On the $1$-skeleton of any\n$3$-dimensional bounded convex polyhedron containing the origin, there exist\nthree points whose center of mass coincides with the origin.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2015 23:25:04 GMT"}, {"version": "v2", "created": "Sat, 19 Dec 2015 04:20:54 GMT"}], "update_date": "2015-12-22", "authors_parsed": [["Barba", "Luis", ""], ["Cheong", "Otfried", ""], ["De Carufel", "Jean Lou", ""], ["Dobbins", "Michael Gene", ""], ["Fleischer", "Rudolf", ""], ["Kawamura", "Akitoshi", ""], ["Korman", "Matias", ""], ["Okamoto", "Yoshio", ""], ["Pach", "Janos", ""], ["Tang", "Yuan", ""], ["Tokuyama", "Takeshi", ""], ["Verdonschot", "Sander", ""], ["Wang", "Tianhao", ""]]}, {"id": "1511.05427", "submitter": "Claudia Landi", "authors": "Madjid Allili, Tomasz Kaczynski, Claudia Landi, Filippo Masoni", "title": "A New Matching Algorithm for Multidimensional Persistence", "comments": "Changes to version 2: proof of Lemma 3.6 expanded", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An algorithm is presented that constructs an acyclic partial matching on the\ncells of a given simplicial complex from a vector-valued function defined on\nthe vertices and extended to each simplex by taking the least common upper\nbound of the values on its vertices. The resulting acyclic partial matching may\nbe used to construct a reduced filtered complex with the same multidimensional\npersistent homology as the original simplicial complex filtered by the sublevel\nsets of the function. Numerical tests show that in practical cases the rate of\nreduction in the number of cells achieved by the algorithm is substantial. This\npromises to be useful for the computation of multidimensional persistent\nhomology of simplicial complexes filtered by sublevel sets of vector-valued\nfunctions.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2015 14:57:00 GMT"}, {"version": "v2", "created": "Wed, 3 Feb 2016 14:00:03 GMT"}, {"version": "v3", "created": "Thu, 23 Mar 2017 09:00:19 GMT"}], "update_date": "2017-03-24", "authors_parsed": [["Allili", "Madjid", ""], ["Kaczynski", "Tomasz", ""], ["Landi", "Claudia", ""], ["Masoni", "Filippo", ""]]}, {"id": "1511.05479", "submitter": "Jiayuan Wang", "authors": "Micka\\\"el Buchet, Tamal K. Dey, Jiayuan Wang, Yusu Wang", "title": "Declutter and Resample: Towards parameter free denoising", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many data analysis applications the following scenario is commonplace: we\nare given a point set that is supposed to sample a hidden ground truth $K$ in a\nmetric space, but it got corrupted with noise so that some of the data points\nlie far away from $K$ creating outliers also termed as {\\em ambient noise}. One\nof the main goals of denoising algorithms is to eliminate such noise so that\nthe curated data lie within a bounded Hausdorff distance of $K$. Popular\ndenoising approaches such as deconvolution and thresholding often require the\nuser to set several parameters and/or to choose an appropriate noise model\nwhile guaranteeing only asymptotic convergence. Our goal is to lighten this\nburden as much as possible while ensuring theoretical guarantees in all cases.\n  Specifically, first, we propose a simple denoising algorithm that requires\nonly a single parameter but provides a theoretical guarantee on the quality of\nthe output on general input points. We argue that this single parameter cannot\nbe avoided. We next present a simple algorithm that avoids even this parameter\nby paying for it with a slight strengthening of the sampling condition on the\ninput points which is not unrealistic. We also provide some preliminary\nempirical evidence that our algorithms are effective in practice.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2015 17:29:56 GMT"}, {"version": "v2", "created": "Mon, 27 Mar 2017 03:21:09 GMT"}], "update_date": "2017-03-28", "authors_parsed": [["Buchet", "Micka\u00ebl", ""], ["Dey", "Tamal K.", ""], ["Wang", "Jiayuan", ""], ["Wang", "Yusu", ""]]}, {"id": "1511.05823", "submitter": "Mathieu Carri\\`ere", "authors": "Mathieu Carri\\`ere and Steve Oudot", "title": "Structure and Stability of the 1-Dimensional Mapper", "comments": "Minor corrections", "journal-ref": "Published in Journal of Computational Mathematics in Oct. 2017", "doi": "10.1007/s10208-017-9370-z", "report-no": null, "categories": "math.AT cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a continuous function $f:X\\to\\mathbb{R}$ and a cover $\\mathcal{I}$ of\nits image by intervals, the Mapper is the nerve of a refinement of the pullback\ncover $f^{-1}(\\mathcal{I})$. Despite its success in applications, little is\nknown about the structure and stability of this construction from a theoretical\npoint of view. As a pixelized version of the Reeb graph of $f$, it is expected\nto capture a subset of its features (branches, holes), depending on how the\ninterval cover is positioned with respect to the critical values of the\nfunction. Its stability should also depend on this positioning. We propose a\ntheoretical framework that relates the structure of the Mapper to the one of\nthe Reeb graph, making it possible to predict which features will be present\nand which will be absent in the Mapper given the function and the cover, and\nfor each feature, to quantify its degree of (in-)stability. Using this\nframework, we can derive guarantees on the structure of the Mapper, on its\nstability, and on its convergence to the Reeb graph as the granularity of the\ncover $\\mathcal{I}$ goes to zero.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2015 15:12:05 GMT"}, {"version": "v2", "created": "Mon, 7 Dec 2015 16:43:27 GMT"}, {"version": "v3", "created": "Tue, 29 Mar 2016 12:19:01 GMT"}, {"version": "v4", "created": "Thu, 9 Nov 2017 13:19:16 GMT"}], "update_date": "2017-11-10", "authors_parsed": [["Carri\u00e8re", "Mathieu", ""], ["Oudot", "Steve", ""]]}, {"id": "1511.06487", "submitter": "Charles Jordan", "authors": "David Avis and Charles Jordan", "title": "mplrs: A scalable parallel vertex/facet enumeration code", "comments": "Revision incorporating additional suggested changes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.CG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a new parallel implementation, mplrs, of the vertex enumeration\ncode lrs that uses the MPI parallel environment and can be run on a network of\ncomputers. The implementation makes use of a C wrapper that essentially uses\nthe existing lrs code with only minor modifications. mplrs was derived from the\nearlier parallel implementation plrs, written by G. Roumanis in C++. plrs uses\nthe Boost library and runs on a shared memory machine. In developing mplrs we\ndiscovered a method of balancing the parallel tree search, called budgeting,\nthat greatly improves parallelization beyond the bottleneck encountered\npreviously at around 32 cores.\n  This method can be readily adapted for use in other reverse search\nenumeration codes. We also report some preliminary computational results\ncomparing parallel and sequential codes for vertex/facet enumeration problems\nfor convex polyhedra. The problems chosen span the range from simple to highly\ndegenerate polytopes. For most problems tested, the results clearly show the\nadvantage of using the parallel implementation mplrs of the reverse search\nbased code lrs, even when as few as 8 cores are available. For some problems\nalmost linear speedup was observed up to 1200 cores, the largest number of\ncores tested.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2015 04:54:22 GMT"}, {"version": "v2", "created": "Wed, 2 Dec 2015 07:08:43 GMT"}, {"version": "v3", "created": "Tue, 29 Nov 2016 04:33:01 GMT"}, {"version": "v4", "created": "Thu, 12 Oct 2017 01:44:42 GMT"}], "update_date": "2017-10-13", "authors_parsed": [["Avis", "David", ""], ["Jordan", "Charles", ""]]}, {"id": "1511.06624", "submitter": "Pui Tung Choi", "authors": "Ting Wei Meng, Gary Pui-Tung Choi, Lok Ming Lui", "title": "TEMPO: Feature-Endowed Teichm\\\"uller Extremal Mappings of Point Clouds", "comments": null, "journal-ref": "SIAM Journal on Imaging Sciences 9, 1922-1962 (2016)", "doi": "10.1137/15M1049117", "report-no": null, "categories": "cs.CG cs.CV cs.GR math.DG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent decades, the use of 3D point clouds has been widespread in computer\nindustry. The development of techniques in analyzing point clouds is\nincreasingly important. In particular, mapping of point clouds has been a\nchallenging problem. In this paper, we develop a discrete analogue of the\nTeichm\\\"{u}ller extremal mappings, which guarantee uniform conformality\ndistortions, on point cloud surfaces. Based on the discrete analogue, we\npropose a novel method called TEMPO for computing Teichm\\\"{u}ller extremal\nmappings between feature-endowed point clouds. Using our proposed method, the\nTeichm\\\"{u}ller metric is introduced for evaluating the dissimilarity of point\nclouds. Consequently, our algorithm enables accurate recognition and\nclassification of point clouds. Experimental results demonstrate the\neffectiveness of our proposed method.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2015 14:57:05 GMT"}, {"version": "v2", "created": "Tue, 26 Apr 2016 12:37:02 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Meng", "Ting Wei", ""], ["Choi", "Gary Pui-Tung", ""], ["Lui", "Lok Ming", ""]]}, {"id": "1511.07077", "submitter": "Friedrich Eisenbrand", "authors": "Alfonso Cevallos and Friedrich Eisenbrand and Rico Zenklusen", "title": "Max-sum diversity via convex programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diversity maximization is an important concept in information retrieval,\ncomputational geometry and operations research. Usually, it is a variant of the\nfollowing problem: Given a ground set, constraints, and a function $f(\\cdot)$\nthat measures diversity of a subset, the task is to select a feasible subset\n$S$ such that $f(S)$ is maximized. The \\emph{sum-dispersion} function $f(S) =\n\\sum_{x,y \\in S} d(x,y)$, which is the sum of the pairwise distances in $S$, is\nin this context a prominent diversification measure. The corresponding\ndiversity maximization is the \\emph{max-sum} or \\emph{sum-sum diversification}.\nMany recent results deal with the design of constant-factor approximation\nalgorithms of diversification problems involving sum-dispersion function under\na matroid constraint. In this paper, we present a PTAS for the max-sum\ndiversification problem under a matroid constraint for distances\n$d(\\cdot,\\cdot)$ of \\emph{negative type}. Distances of negative type are, for\nexample, metric distances stemming from the $\\ell_2$ and $\\ell_1$ norm, as well\nas the cosine or spherical, or Jaccard distance which are popular similarity\nmetrics in web and image search.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2015 22:25:47 GMT"}], "update_date": "2015-11-24", "authors_parsed": [["Cevallos", "Alfonso", ""], ["Eisenbrand", "Friedrich", ""], ["Zenklusen", "Rico", ""]]}, {"id": "1511.07303", "submitter": "Fabrizio Montecchiani", "authors": "William J. Lenhart, Giuseppe Liotta, Fabrizio Montecchiani", "title": "On Partitioning the Edges of 1-Plane Graphs", "comments": null, "journal-ref": null, "doi": "10.1016/j.tcs.2016.12.004", "report-no": null, "categories": "cs.CG math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A 1-plane graph is a graph embedded in the plane such that each edge is\ncrossed at most once. A 1-plane graph is optimal if it has maximum edge\ndensity. A red-blue edge coloring of an optimal 1-plane graph $G$ partitions\nthe edge set of $G$ into blue edges and red edges such that no two blue edges\ncross each other and no two red edges cross each other. We prove the following:\n$(i)$ Every optimal 1-plane graph has a red-blue edge coloring such that the\nblue subgraph is maximal planar while the red subgraph has vertex degree at\nmost four; this bound on the vertex degree is worst-case optimal. $(ii)$ A\nred-blue edge coloring may not always induce a red forest of bounded vertex\ndegree. Applications of these results to graph augmentation and graph drawing\nare also discussed.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2015 16:31:25 GMT"}, {"version": "v2", "created": "Fri, 15 Jan 2016 08:34:27 GMT"}, {"version": "v3", "created": "Wed, 7 Dec 2016 09:43:58 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Lenhart", "William J.", ""], ["Liotta", "Giuseppe", ""], ["Montecchiani", "Fabrizio", ""]]}, {"id": "1511.07357", "submitter": "Sariel Har-Peled", "authors": "Sariel Har-Peled and Sepideh Mahabadi", "title": "Proximity in the Age of Distraction: Robust Approximate Nearest Neighbor\n  Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new variant of the nearest neighbor search problem, which\nallows for some coordinates of the dataset to be arbitrarily corrupted or\nunknown. Formally, given a dataset of $n$ points $P=\\{ x_1,\\ldots, x_n\\}$ in\nhigh-dimensions, and a parameter $k$, the goal is to preprocess the dataset,\nsuch that given a query point $q$, one can compute quickly a point $x \\in P$,\nsuch that the distance of the query to the point $x$ is minimized, when\nignoring the \"optimal\" $k$ coordinates. Note, that the coordinates being\nignored are a function of both the query point and the point returned.\n  We present a general reduction from this problem to answering ANN queries,\nwhich is similar in spirit to LSH (locality sensitive hashing) [IM98].\nSpecifically, we give a sampling technique which achieves a bi-criterion\napproximation for this problem. If the distance to the nearest neighbor after\nignoring $k$ coordinates is $r$, the data-structure returns a point that is\nwithin a distance of $O(r)$ after ignoring $O(k)$ coordinates. We also present\nother applications and further extensions and refinements of the above result.\n  The new data-structures are simple and (arguably) elegant, and should be\npractical -- specifically, all bounds are polynomial in all relevant parameters\n(including the dimension of the space, and the robustness parameter $k$).\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2015 18:45:12 GMT"}], "update_date": "2015-11-24", "authors_parsed": [["Har-Peled", "Sariel", ""], ["Mahabadi", "Sepideh", ""]]}, {"id": "1511.07527", "submitter": "Thijs Laarhoven", "authors": "Thijs Laarhoven", "title": "Tradeoffs for nearest neighbors on the sphere", "comments": "16 pages, 1 table, 2 figures. Mostly subsumed by arXiv:1608.03580\n  [cs.DS] (along with arXiv:1605.02701 [cs.DS])", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider tradeoffs between the query and update complexities for the\n(approximate) nearest neighbor problem on the sphere, extending the recent\nspherical filters to sparse regimes and generalizing the scheme and analysis to\naccount for different tradeoffs. In a nutshell, for the sparse regime the\ntradeoff between the query complexity $n^{\\rho_q}$ and update complexity\n$n^{\\rho_u}$ for data sets of size $n$ is given by the following equation in\nterms of the approximation factor $c$ and the exponents $\\rho_q$ and $\\rho_u$:\n$$c^2\\sqrt{\\rho_q}+(c^2-1)\\sqrt{\\rho_u}=\\sqrt{2c^2-1}.$$\n  For small $c=1+\\epsilon$, minimizing the time for updates leads to a linear\nspace complexity at the cost of a query time complexity $n^{1-4\\epsilon^2}$.\nBalancing the query and update costs leads to optimal complexities\n$n^{1/(2c^2-1)}$, matching bounds from [Andoni-Razenshteyn, 2015] and [Dubiner,\nIEEE-TIT'10] and matching the asymptotic complexities of [Andoni-Razenshteyn,\nSTOC'15] and [Andoni-Indyk-Laarhoven-Razenshteyn-Schmidt, NIPS'15]. A\nsubpolynomial query time complexity $n^{o(1)}$ can be achieved at the cost of a\nspace complexity of the order $n^{1/(4\\epsilon^2)}$, matching the bound\n$n^{\\Omega(1/\\epsilon^2)}$ of [Andoni-Indyk-Patrascu, FOCS'06] and\n[Panigrahy-Talwar-Wieder, FOCS'10] and improving upon results of\n[Indyk-Motwani, STOC'98] and [Kushilevitz-Ostrovsky-Rabani, STOC'98].\n  For large $c$, minimizing the update complexity results in a query complexity\nof $n^{2/c^2+O(1/c^4)}$, improving upon the related exponent for large $c$ of\n[Kapralov, PODS'15] by a factor $2$, and matching the bound $n^{\\Omega(1/c^2)}$\nof [Panigrahy-Talwar-Wieder, FOCS'08]. Balancing the costs leads to optimal\ncomplexities $n^{1/(2c^2-1)}$, while a minimum query time complexity can be\nachieved with update complexity $n^{2/c^2+O(1/c^4)}$, improving upon the\nprevious best exponents of Kapralov by a factor $2$.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2015 01:07:08 GMT"}, {"version": "v2", "created": "Sat, 10 Sep 2016 00:21:29 GMT"}], "update_date": "2016-09-13", "authors_parsed": [["Laarhoven", "Thijs", ""]]}, {"id": "1511.08592", "submitter": "Fabrizio Montecchiani", "authors": "Therese Biedl, Giuseppe Liotta, Fabrizio Montecchiani", "title": "On Visibility Representations of Non-planar Graphs", "comments": null, "journal-ref": null, "doi": "10.1007/s00454-017-9939-y", "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A rectangle visibility representation (RVR) of a graph consists of an\nassignment of axis-aligned rectangles to vertices such that for every edge\nthere exists a horizontal or vertical line of sight between the rectangles\nassigned to its endpoints. Testing whether a graph has an RVR is known to be\nNP-hard. In this paper, we study the problem of finding an RVR under the\nassumption that an embedding in the plane of the input graph is fixed and we\nare looking for an RVR that reflects this embedding. We show that in this case\nthe problem can be solved in polynomial time for general embedded graphs and in\nlinear time for 1-plane graphs (i.e., embedded graphs having at most one\ncrossing per edge). The linear time algorithm uses a precise list of forbidden\nconfigurations, which extends the set known for straight-line drawings of\n1-plane graphs. These forbidden configurations can be tested for in linear\ntime, and so in linear time we can test whether a 1-plane graph has an RVR and\neither compute such a representation or report a negative witness. Finally, we\ndiscuss some extensions of our study to the case when the embedding is not\nfixed but the RVR can have at most one crossing per edge.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2015 09:44:17 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Biedl", "Therese", ""], ["Liotta", "Giuseppe", ""], ["Montecchiani", "Fabrizio", ""]]}, {"id": "1511.08941", "submitter": "Kumar Eswaran Dr.", "authors": "K.Eswaran", "title": "On the storage and retrieval of primes and other random numbers using\n  n-dimensional geometry", "comments": "15 pages, 2 figures. arXiv admin note: substantial text overlap with\n  arXiv:1509.08742", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that if you represent all primes with less than n-digits as points in\nn-dimensional space, then they can be stored and retrieved conveniently using\nn-dimensional geometry. Also once you have calculated all the prime numbers\nless than n digits, it is very easy to find out if a given number having less\nthan n-digits is or is not a prime. We do this by separating all the primes\nwhich are represented by points in n-dimension space by planes. It so turns out\nthat the number of planes q, required to separate all the points represented by\nprimes less than n-digit, are very few in number. Thus we obtain a very\nefficient storage and retrieval system in n-dimensional space. In addition the\nstorage and retieval repository has the property that when new primes are added\nthere is no need to start all over, we can begin where we last left off and add\nthe new primes in the repository and add new planes that separate them as and\nwhen necessary. Also we can arrange matters such that the repository can begin\nto accept larger primes which has more digits say n' where n' > n. The\nalgorithm does not make use of any property of prime numbers or of integers in\ngeneral,except for the fact that any n-digit integer can be represented as a\npoint in n-dimension space. Therefore the method can serve to be a storage and\nretrieval repository of any set of given integers, in practical cases they can\nrepresent information. Thus the algorithm can be used to devise a very\nefficient storage and retrieval system for large amounts of digital data.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2015 07:35:00 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2015 14:00:20 GMT"}], "update_date": "2015-12-02", "authors_parsed": [["Eswaran", "K.", ""]]}, {"id": "1511.09327", "submitter": "Francis Lazarus", "authors": "Vincent Despr\\'e and Francis Lazarus", "title": "Computing the Geometric Intersection Number of Curves", "comments": "59 pages, 33 figures, revised version accepted to Journal of the ACM.\n  The time complexity for testing if a curve is homotopic to a simple one has\n  been reduced to $O(n + \\ell\\log \\ell)$", "journal-ref": "Journal of the ACM 66(6), Article 45, Nov. 2019", "doi": "10.1145/3363367", "report-no": null, "categories": "cs.CG math.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The geometric intersection number of a curve on a surface is the minimal\nnumber of self-intersections of any homotopic curve, i.e. of any curve obtained\nby continuous deformation. Given a curve $c$ represented by a closed walk of\nlength at most $\\ell$ on a combinatorial surface of complexity $n$ we describe\nsimple algorithms to (1) compute the geometric intersection number of $c$ in\n$O(n+ \\ell^2)$ time, (2) construct a curve homotopic to $c$ that realizes this\ngeometric intersection number in $O(n+\\ell^4)$ time, (3) decide if the\ngeometric intersection number of $c$ is zero, i.e. if $c$ is homotopic to a\nsimple curve, in $O(n+\\ell\\log\\ell)$ time. The algorithms for (2) and (3) are\nrestricted to orientable surfaces, but the algorithm for (1) is also valid on\nnon-orientable surfaces.\n  To our knowledge, no exact complexity analysis had yet appeared on those\nproblems. An optimistic analysis of the complexity of the published algorithms\nfor problems (1) and (3) gives at best a $O(n+g^2\\ell^2)$ time complexity on a\ngenus $g$ surface without boundary. No polynomial time algorithm was known for\nproblem (2) for surfaces without boundary. Interestingly, our solution to\nproblem (3) provides a quasi-linear algorithm to a problem raised by Poincar\\'e\nmore than a century ago. Finally, we note that our algorithm for problem (1)\nextends to computing the geometric intersection number of two curves of length\nat most $\\ell$ in $O(n+ \\ell^2)$ time.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2015 14:34:15 GMT"}, {"version": "v2", "created": "Mon, 4 Jan 2016 16:25:52 GMT"}, {"version": "v3", "created": "Thu, 23 Jun 2016 09:30:09 GMT"}, {"version": "v4", "created": "Wed, 27 Nov 2019 17:30:14 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Despr\u00e9", "Vincent", ""], ["Lazarus", "Francis", ""]]}]