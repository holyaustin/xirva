[{"id": "1905.00157", "submitter": "Jie Xue", "authors": "Haitao Wang and Jie Xue", "title": "Improved Algorithms for the Bichromatic Two-Center Problem for Pairs of\n  Points", "comments": "A preliminary version of this paper will appear in the Proceedings of\n  the 16th Algorithms and Data Structures Symposium (WADS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a bichromatic two-center problem for pairs of points. Given a set\n$S$ of $n$ pairs of points in the plane, for every pair, we want to assign a\nred color to one point and a blue color to the other, in such a way that the\nvalue $\\max\\{r_1,r_2\\}$ is minimized, where $r_1$ (resp., $r_2$) is the radius\nof the smallest enclosing disk of all red (resp., blue) points. Previously, an\nexact algorithm of $O(n^3\\log^2 n)$ time and a $(1+\\varepsilon)$-approximate\nalgorithm of $O(n + (1/\\varepsilon)^6 \\log^2 (1/\\varepsilon))$ time were known.\nIn this paper, we propose a new exact algorithm of $O(n^2\\log^2 n)$ time and a\nnew $(1+\\varepsilon)$-approximate algorithm of $O(n + (1/\\varepsilon)^3 \\log^2\n(1/\\varepsilon))$ time.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 01:29:21 GMT"}], "update_date": "2019-05-02", "authors_parsed": [["Wang", "Haitao", ""], ["Xue", "Jie", ""]]}, {"id": "1905.00333", "submitter": "Sittichoke Som-Am", "authors": "Bogdan Grechuk and Sittichoke Som-Am", "title": "A convex cover for closed unit curves has area at least 0.0975", "comments": "41 pages, 15 figures, paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.MG cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We combine geometric methods with numerical box search algorithm to show that\nthe minimal area of a convex set on the plane which can cover every closed\nplane curve of unit length is at least 0.0975. This improves the best previous\nlower bound of 0.096694. In fact, we show that the minimal area of convex hull\nof circle, equilateral triangle, and rectangle of perimeter $1$ is between\n0.0975 and 0.09763.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 14:47:04 GMT"}], "update_date": "2019-05-02", "authors_parsed": [["Grechuk", "Bogdan", ""], ["Som-Am", "Sittichoke", ""]]}, {"id": "1905.00350", "submitter": "Luis Polanco", "authors": "Luis Polanco and Jose A. Perea", "title": "Coordinatizing Data With Lens Spaces and Persistent Cohomology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AT cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce here a framework to construct coordinates in \\emph{finite} Lens\nspaces for data with nontrivial 1-dimensional $\\mathbb{Z}_q$ persistent\ncohomology, $q\\geq 3$. Said coordinates are defined on an open neighborhood of\nthe data, yet constructed with only a small subset of landmarks. We also\nintroduce a dimensionality reduction scheme in $S^{2n-1}/\\mathbb{Z}_q$\n(Lens-PCA: $\\mathsf{LPCA}$), and demonstrate the efficacy of the pipeline\n$PH^1(\\;\\cdot\\; ; \\mathbb{Z}_q)$ class $\\Rightarrow$ $S^{2n-1}/\\mathbb{Z}_q$\ncoordinates $\\Rightarrow$ $\\mathsf{LPCA}$, for nonlinear (topological)\ndimensionality reduction.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 15:47:18 GMT"}, {"version": "v2", "created": "Wed, 26 Jun 2019 11:44:09 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Polanco", "Luis", ""], ["Perea", "Jose A.", ""]]}, {"id": "1905.00612", "submitter": "Sandor P. Fekete", "authors": "S\\'andor P. Fekete and Sven von H\\\"oveling and Christian Scheffer", "title": "Online Circle Packing", "comments": "13 pages, 11 figures, to appear in WADS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the online problem of packing circles into a square container. A\nsequence of circles has to be packed one at a time, without knowledge of the\nfollowing incoming circles and without moving previously packed circles. We\npresent an algorithm that packs any online sequence of circles with a combined\narea not larger than 0.350389 0.350389 of the square's area, improving the\nprevious best value of {\\pi}/10 \\approx 0.31416; even in an offline setting,\nthere is an upper bound of {\\pi}/(3 + 2 \\sqrt{2}) \\approx 0.5390. If only\ncircles with radii of at least 0.026622 are considered, our algorithm achieves\nthe higher value 0.375898. As a byproduct, we give an online algorithm for\npacking circles into a 1\\times b rectangle with b \\geq 1. This algorithm is\nworst case-optimal for b \\geq 2.36.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 08:20:39 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Fekete", "S\u00e1ndor P.", ""], ["von H\u00f6veling", "Sven", ""], ["Scheffer", "Christian", ""]]}, {"id": "1905.00727", "submitter": "Alireza Zarei", "authors": "Sahar Mehrpour, Alireza Zarei", "title": "Pseudo-Triangle Visibility Graph: Characterization and Reconstruction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The visibility graph of a simple polygon represents visibility relations\nbetween its vertices. Knowing the correct order of the vertices around the\nboundary of a polygon and its visibility graph, it is an open problem to locate\nthe vertices in a plane in such a way that it will be consistent with this\nvisibility graph. This problem has been solved for special cases when we know\nthat the target polygon is a {\\it tower} or a {\\it spiral}. Knowing that a\ngiven visibility graph belongs to a simple polygon with at most three concave\nchains on its boundary, a {\\it pseuodo-triangle}, we propose a linear time\nalgorithm for reconstructing one of its corresponding polygons. Moreover, we\nintroduce a set of necessary and sufficient properties for characterizing\nvisibility graphs of pseudo-triangles and propose polynomial algorithms for\nchecking these properties.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 13:31:01 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Mehrpour", "Sahar", ""], ["Zarei", "Alireza", ""]]}, {"id": "1905.00790", "submitter": "Ahmad Biniaz", "authors": "Therese Biedl, Ahmad Biniaz, and Anna Lubiw", "title": "Minimum Ply Covering of Points with Disks and Squares", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Following the seminal work of Erlebach and van Leeuwen in SODA 2008, we\nintroduce the minimum ply covering problem. Given a set $P$ of points and a set\n$S$ of geometric objects, both in the plane, our goal is to find a subset $S'$\nof $S$ that covers all points of $P$ while minimizing the maximum number of\nobjects covering any point in the plane (not only points of $P$). For objects\nthat are unit squares and unit disks, this problem is NP-hard and cannot be\napproximated by a ratio smaller than 2. We present 2-approximation algorithms\nfor this problem with respect to unit squares and unit disks. Our algorithms\nrun in polynomial time when the optimum objective value is bounded by a\nconstant.\n  Motivated by channel-assignment in wireless networks, we consider a variant\nof the problem where the selected unit disks must be 3-colorable, i.e., colored\nby three colors such that all disks of the same color are pairwise disjoint. We\npresent a polynomial-time algorithm that achieves a 2-approximate solution,\ni.e., a solution that is 6-colorable.\n  We also study the weighted version of the problem in dimension one, where $P$\nand $S$ are points and weighted intervals on a line, respectively. We present\nan algorithm that solves this problem in $O(n + m + M )$-time where $n$ is the\nnumber of points, $m$ is the number of intervals, and $M$ is the number of\npairs of overlapping intervals. This repairs a solution claimed by Nandy,\nPandit, and Roy in CCCG 2017.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 14:55:28 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Biedl", "Therese", ""], ["Biniaz", "Ahmad", ""], ["Lubiw", "Anna", ""]]}, {"id": "1905.00791", "submitter": "Ahmad Biniaz", "authors": "Ahmad Biniaz, Anil Maheshwari, and Michiel Smid", "title": "Flip Distance to some Plane Configurations", "comments": "15 pages, a preliminary version appeared in SWAT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study an old geometric optimization problem in the plane. Given a perfect\nmatching $M$ on a set of $n$ points in the plane, we can transform it to a\nnon-crossing perfect matching by a finite sequence of flip operations. The flip\noperation removes two crossing edges from $M$ and adds two non-crossing edges.\nLet $f(M)$ and $F(M)$ denote the minimum and maximum lengths of a flip sequence\non $M$, respectively. It has been proved by Bonnet and Miltzow (2016) that\n$f(M)=O(n^2)$ and by van Leeuwen and Schoone (1980) that $F(M)=O(n^3)$. We\nprove that $f(M)=O(n\\Delta)$ where $\\Delta$ is the spread of the point set,\nwhich is defined as the ratio between the longest and the shortest pairwise\ndistances. This improves the previous bound if the point set has sublinear\nspread. For a matching $M$ on $n$ points in convex position we prove that\n$f(M)=n/2-1$ and $F(M)={{n/2} \\choose 2}$; these bounds are tight.\n  Any bound on $F(\\cdot)$ carries over to the bichromatic setting, while this\nis not necessarily true for $f(\\cdot)$. Let $M'$ be a bichromatic matching. The\nbest known upper bound for $f(M')$ is the same as for $F(M')$, which is\nessentially $O(n^3)$. We prove that $f(M')\\le n-2$ for points in convex\nposition, and $f(M')= O(n^2)$ for semi-collinear points.\n  The flip operation can also be defined on spanning trees. For a spanning tree\n$T$ on a convex point set we show that $f(T)=O(n\\log n)$.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 14:56:09 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Biniaz", "Ahmad", ""], ["Maheshwari", "Anil", ""], ["Smid", "Michiel", ""]]}, {"id": "1905.01019", "submitter": "Marc Khoury", "authors": "Marc Khoury and Dylan Hadfield-Menell", "title": "Adversarial Training with Voronoi Constraints", "comments": "arXiv admin note: substantial text overlap with arXiv:1811.00525", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples are a pervasive phenomenon of machine learning models\nwhere seemingly imperceptible perturbations to the input lead to\nmisclassifications for otherwise statistically accurate models. We propose a\ngeometric framework, drawing on tools from the manifold reconstruction\nliterature, to analyze the high-dimensional geometry of adversarial examples.\nIn particular, we highlight the importance of codimension: for low-dimensional\ndata manifolds embedded in high-dimensional space there are many directions off\nthe manifold in which an adversary could construct adversarial examples.\nAdversarial examples are a natural consequence of learning a decision boundary\nthat classifies the low-dimensional data manifold well, but classifies points\nnear the manifold incorrectly. Using our geometric framework we prove that\nadversarial training is sample inefficient, and show sufficient sampling\nconditions under which nearest neighbor classifiers and ball-based adversarial\ntraining are robust. Finally we introduce adversarial training with Voronoi\nconstraints, which replaces the norm ball constraint with the Voronoi cell for\neach point in the training set. We show that adversarial training with Voronoi\nconstraints produces robust models which significantly improve over the\nstate-of-the-art on MNIST and are competitive on CIFAR-10.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 17:34:44 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["Khoury", "Marc", ""], ["Hadfield-Menell", "Dylan", ""]]}, {"id": "1905.01029", "submitter": "Jie Xue", "authors": "Timothy M. Chan, Saladi Rahul, Jie Xue", "title": "Range closest-pair search in higher dimensions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Range closest-pair (RCP) search is a range-search variant of the classical\nclosest-pair problem, which aims to store a given set $S$ of points into some\nspace-efficient data structure such that when a query range $Q$ is specified,\nthe closest pair in $S \\cap Q$ can be reported quickly. RCP search has received\nattention over years, but the primary focus was only on $\\mathbb{R}^2$. In this\npaper, we study RCP search in higher dimensions. We give the first nontrivial\nRCP data structures for orthogonal, simplex, halfspace, and ball queries in\n$\\mathbb{R}^d$ for any constant $d$. Furthermore, we prove a conditional lower\nbound for orthogonal RCP search for $d \\geq 3$.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 03:54:43 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["Chan", "Timothy M.", ""], ["Rahul", "Saladi", ""], ["Xue", "Jie", ""]]}, {"id": "1905.01185", "submitter": "Irina Kostitsyna", "authors": "Irina Kostitsyna and Maarten L\\\"offler and Valentin Polishchuk and\n  Frank Staals", "title": "Most vital segment barriers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study continuous analogues of \"vitality\" for discrete network flows/paths,\nand consider problems related to placing segment barriers that have highest\nimpact on a flow/path in a polygonal domain. This extends the graph-theoretic\nnotion of \"most vital arcs\" for flows/paths to geometric environments. We give\nhardness results and efficient algorithms for various versions of the problem,\n(almost) completely separating hard and polynomially-solvable cases.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 13:51:12 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["Kostitsyna", "Irina", ""], ["L\u00f6ffler", "Maarten", ""], ["Polishchuk", "Valentin", ""], ["Staals", "Frank", ""]]}, {"id": "1905.01772", "submitter": "Amol Kapoor", "authors": "Amol Kapoor, Hunter Larco, Raimondas Kiveris", "title": "Nostalgin: Extracting 3D City Models from Historical Image Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CG cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  What did it feel like to walk through a city from the past? In this work, we\ndescribe Nostalgin (Nostalgia Engine), a method that can faithfully reconstruct\ncities from historical images. Unlike existing work in city reconstruction, we\nfocus on the task of reconstructing 3D cities from historical images. Working\nwith historical image data is substantially more difficult, as there are\nsignificantly fewer buildings available and the details of the camera\nparameters which captured the images are unknown. Nostalgin can generate a city\nmodel even if there is only a single image per facade, regardless of viewpoint\nor occlusions. To achieve this, our novel architecture combines image\nsegmentation, rectification, and inpainting. We motivate our design decisions\nwith experimental analysis of individual components of our pipeline, and show\nthat we can improve on baselines in both speed and visual realism. We\ndemonstrate the efficacy of our pipeline by recreating two 1940s Manhattan city\nblocks. We aim to deploy Nostalgin as an open source platform where users can\ngenerate immersive historical experiences from their own photos.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 00:18:15 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Kapoor", "Amol", ""], ["Larco", "Hunter", ""], ["Kiveris", "Raimondas", ""]]}, {"id": "1905.01822", "submitter": "Pradeesha Ashok", "authors": "Akanksha Agrawal, Pradeesha Ashok, Meghana M Reddy, Saket Saurabh,\n  Dolly Yadav", "title": "FPT Algorithms for Conflict-free Coloring of Graphs and Chromatic\n  Terrain Guarding", "comments": "Submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present fixed parameter tractable algorithms for the conflict-free\ncoloring problem on graphs. Given a graph $G=(V,E)$, \\emph{conflict-free\ncoloring} of $G$ refers to coloring a subset of $V$ such that for every vertex\n$v$, there is a color that is assigned to exactly one vertex in the closed\nneighborhood of $v$. The \\emph{k-Conflict-free Coloring} problem is to decide\nwhether $G$ can be conflict-free colored using at most $k$ colors. This problem\nis NP-hard even for $k=1$ and therefore under standard complexity theoretic\nassumptions, FPT algorithms do not exist when parameterised by the solution\nsize. We consider the \\emph{k-Conflict-free Coloring} problem parameterised by\nthe treewidth of the graph and show that this problem is fixed parameter\ntractable. We also initiate the study of \\emph{Strong Conflict-free Coloring}\nof graphs. Given a graph $G=(V,E)$, \\emph{strong conflict-free coloring} of $G$\nrefers to coloring a subset of $V$ such that every vertex $v$ has at least one\ncolored vertex in its closed neighborhood and moreover all the colored vertices\nin $v$'s neighborhood have distinct colors. We show that this problem is in FPT\nwhen parameterised by both the treewidth and the solution size. We further\napply these algorithms to get efficient algorithms for a geometric problem\nnamely the Terrain Guarding problem, when parameterised by a structural\nparameter.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 04:29:28 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Agrawal", "Akanksha", ""], ["Ashok", "Pradeesha", ""], ["Reddy", "Meghana M", ""], ["Saurabh", "Saket", ""], ["Yadav", "Dolly", ""]]}, {"id": "1905.02067", "submitter": "David K\\\"ubel", "authors": "Sang-Sub Kim, Rolf Klein, David K\\\"ubel, Elmar Langetepe, and Barbara\n  Schwarzwald", "title": "Geometric Firefighting in the Half-plane", "comments": "15 pages, 10 figures, pre-print of an article published in WADS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 2006, Alberto Bressan suggested the following problem. Suppose a circular\nfire spreads in the Euclidean plane at unit speed. The task is to build, in\nreal time, barrier curves to contain the fire. At each time $t$ the total\nlength of all barriers built so far must not exceed $t \\cdot v$, where $v$ is a\nspeed constant. How large a speed $v$ is needed? He proved that speed $v>2$ is\nsufficient, and that $v>1$ is necessary. This gap of $(1,2]$ is still open. The\ncrucial question seems to be the following. {\\em When trying to contain a fire,\nshould one build, at maximum speed, the enclosing barrier, or does it make\nsense to spend some time on placing extra delaying barriers in the fire's way?}\nWe study the situation where the fire must be contained in the upper $L_1$\nhalf-plane by an infinite horizontal barrier to which vertical line segments\nmay be attached as delaying barriers. Surprisingly, such delaying barriers are\nhelpful when properly placed. We prove that speed $v=1.8772$ is sufficient,\nwhile $v >1.66$ is necessary.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 14:41:00 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Kim", "Sang-Sub", ""], ["Klein", "Rolf", ""], ["K\u00fcbel", "David", ""], ["Langetepe", "Elmar", ""], ["Schwarzwald", "Barbara", ""]]}, {"id": "1905.02176", "submitter": "Jeff Calder", "authors": "Riley O'Neill, Pedro Angulo-Umana, Jeff Calder, Bo Hessburg, Peter J.\n  Olver, Chehrzad Shakiban, Katrina Yezzi-Woodley", "title": "Computation of Circular Area and Spherical Volume Invariants via\n  Boundary Integrals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.CG cs.CV math.DG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how to compute the circular area invariant of planar curves, and the\nspherical volume invariant of surfaces, in terms of line and surface integrals,\nrespectively. We use the Divergence Theorem to express the area and volume\nintegrals as line and surface integrals, respectively, against particular\nkernels; our results also extend to higher dimensional hypersurfaces. The\nresulting surface integrals are computable analytically on a triangulated mesh.\nThis gives a simple computational algorithm for computing the spherical volume\ninvariant for triangulated surfaces that does not involve discretizing the\nambient space. We discuss potential applications to feature detection on broken\nbone fragments of interest in anthropology.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 17:51:00 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["O'Neill", "Riley", ""], ["Angulo-Umana", "Pedro", ""], ["Calder", "Jeff", ""], ["Hessburg", "Bo", ""], ["Olver", "Peter J.", ""], ["Shakiban", "Chehrzad", ""], ["Yezzi-Woodley", "Katrina", ""]]}, {"id": "1905.03718", "submitter": "Yanhao Wang", "authors": "Yanhao Wang, Yuchen Li, Kian-Lee Tan", "title": "Coresets for Minimum Enclosing Balls over Sliding Windows", "comments": "28 pages, 10 figures, to appear in The 25th ACM SIGKDD Conference on\n  Knowledge Discovery and Data Mining (KDD '19)", "journal-ref": null, "doi": "10.1145/3292500.3330826", "report-no": null, "categories": "cs.DS cs.CG cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  \\emph{Coresets} are important tools to generate concise summaries of massive\ndatasets for approximate analysis. A coreset is a small subset of points\nextracted from the original point set such that certain geometric properties\nare preserved with provable guarantees. This paper investigates the problem of\nmaintaining a coreset to preserve the minimum enclosing ball (MEB) for a\nsliding window of points that are continuously updated in a data stream.\nAlthough the problem has been extensively studied in batch and append-only\nstreaming settings, no efficient sliding-window solution is available yet. In\nthis work, we first introduce an algorithm, called AOMEB, to build a coreset\nfor MEB in an append-only stream. AOMEB improves the practical performance of\nthe state-of-the-art algorithm while having the same approximation ratio.\nFurthermore, using AOMEB as a building block, we propose two novel algorithms,\nnamely SWMEB and SWMEB+, to maintain coresets for MEB over the sliding window\nwith constant approximation ratios. The proposed algorithms also support\ncoresets for MEB in a reproducing kernel Hilbert space (RKHS). Finally,\nextensive experiments on real-world and synthetic datasets demonstrate that\nSWMEB and SWMEB+ achieve speedups of up to four orders of magnitude over the\nstate-of-the-art batch algorithm while providing coresets for MEB with rather\nsmall errors compared to the optimal ones.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 15:55:03 GMT"}, {"version": "v2", "created": "Fri, 10 May 2019 05:11:48 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Wang", "Yanhao", ""], ["Li", "Yuchen", ""], ["Tan", "Kian-Lee", ""]]}, {"id": "1905.04153", "submitter": "Shiyu Song", "authors": "Weixin Lu, Guowei Wan, Yao Zhou, Xiangyu Fu, Pengfei Yuan, Shiyu Song", "title": "DeepICP: An End-to-End Deep Neural Network for 3D Point Cloud\n  Registration", "comments": "10 pages, 6 figures, 3 tables, typos corrected, experimental results\n  updated, accepted by ICCV 2019", "journal-ref": "The IEEE International Conference on Computer Vision (ICCV), 2019,\n  pp. 12-21", "doi": "10.1109/ICCV.2019.00010", "report-no": null, "categories": "cs.CV cs.CG cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present DeepICP - a novel end-to-end learning-based 3D point cloud\nregistration framework that achieves comparable registration accuracy to prior\nstate-of-the-art geometric methods. Different from other keypoint based methods\nwhere a RANSAC procedure is usually needed, we implement the use of various\ndeep neural network structures to establish an end-to-end trainable network.\nOur keypoint detector is trained through this end-to-end structure and enables\nthe system to avoid the inference of dynamic objects, leverages the help of\nsufficiently salient features on stationary objects, and as a result, achieves\nhigh robustness. Rather than searching the corresponding points among existing\npoints, the key contribution is that we innovatively generate them based on\nlearned matching probabilities among a group of candidates, which can boost the\nregistration accuracy. Our loss function incorporates both the local similarity\nand the global geometric constraints to ensure all above network designs can\nconverge towards the right direction. We comprehensively validate the\neffectiveness of our approach using both the KITTI dataset and the\nApollo-SouthBay dataset. Results demonstrate that our method achieves\ncomparable or better performance than the state-of-the-art geometry-based\nmethods. Detailed ablation and visualization analysis are included to further\nillustrate the behavior and insights of our network. The low registration error\nand high robustness of our method makes it attractive for substantial\napplications relying on the point cloud registration task.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 13:08:28 GMT"}, {"version": "v2", "created": "Mon, 16 Sep 2019 08:49:52 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Lu", "Weixin", ""], ["Wan", "Guowei", ""], ["Zhou", "Yao", ""], ["Fu", "Xiangyu", ""], ["Yuan", "Pengfei", ""], ["Song", "Shiyu", ""]]}, {"id": "1905.04329", "submitter": "Audun Myers", "authors": "Audun D. Myers, Firas A. Khasawneh", "title": "Delay Parameter Selection in Permutation Entropy Using Topological Data\n  Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.data-an cs.CG cs.IT math.IT nlin.CD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Permutation Entropy (PE) is a powerful tool for quantifying the\npredictability of a sequence which includes measuring the regularity of a time\nseries. Despite its successful application in a variety of scientific domains,\nPE requires a judicious choice of the delay parameter $\\tau$. While another\nparameter of interest in PE is the motif dimension $n$, Typically $n$ is\nselected between $4$ and $8$ with $5$ or $6$ giving optimal results for the\nmajority of systems. Therefore, in this work we focus solely on choosing the\ndelay parameter. Selecting $\\tau$ is often accomplished using trial and error\nguided by the expertise of domain scientists. However, in this paper, we show\nthat persistent homology, the flag ship tool from Topological Data Analysis\n(TDA) toolset, provides an approach for the automatic selection of $\\tau$. We\nevaluate the successful identification of a suitable $\\tau$ from our TDA-based\napproach by comparing our results to a variety of examples in published\nliterature.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 18:20:23 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Myers", "Audun D.", ""], ["Khasawneh", "Firas A.", ""]]}, {"id": "1905.04383", "submitter": "Benjamin Filippenko", "authors": "Gunnar Carlsson, Benjamin Filippenko", "title": "Persistent homology of the sum metric", "comments": "To appear in Journal of Pure and Applied Algebra", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AT cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given finite metric spaces $(X, d_X)$ and $(Y, d_Y)$, we investigate the\npersistent homology $PH_*(X \\times Y)$ of the Cartesian product $X \\times Y$\nequipped with the sum metric $d_X + d_Y$. Interpreting persistent homology as a\nmodule over a polynomial ring, one might expect the usual K\\\"unneth short exact\nsequence to hold. We prove that it holds for $PH_0$ and $PH_1$, and we\nillustrate with the Hamming cube $\\{0,1\\}^k$ that it fails for $PH_n,\\,\\, n\n\\geq 2$. For $n = 2$, the prediction for $PH_2(X \\times Y)$ from the expected\nK\\\"unneth short exact sequence has a natural surjection onto $PH_2(X \\times\nY)$. We compute the nontrivial kernel of this surjection for the splitting of\nHamming cubes $\\{0,1\\}^k = \\{0,1\\}^{k-1} \\times \\{0,1\\}$. For all $n \\geq 0$,\nthe interleaving distance between the prediction for $PH_n(X \\times Y)$ and the\ntrue persistent homology is bounded above by the minimum of the diameters of\n$X$ and $Y$. As preliminary results of independent interest, we establish an\nalgebraic K\\\"unneth formula for simplicial modules over the ring\n$\\kappa[\\mathbb{R}_+]$ of polynomials with coefficients in a field $\\kappa$ and\nexponents in $\\mathbb{R}_+ = [0,\\infty)$, as well as a K\\\"unneth formula for\nthe persistent homology of $\\mathbb{R}_+$-filtered simplicial sets -- both of\nthese K\\\"unneth formulas hold in all homological dimensions $n \\geq 0$.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 21:12:07 GMT"}, {"version": "v2", "created": "Sun, 23 Jun 2019 19:43:40 GMT"}, {"version": "v3", "created": "Mon, 21 Oct 2019 03:36:14 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Carlsson", "Gunnar", ""], ["Filippenko", "Benjamin", ""]]}, {"id": "1905.04434", "submitter": "Jingjin Yu", "authors": "Si Wei Feng and Shuai D. Han and Kai Gao and Jingjin Yu", "title": "Efficient Algorithms for Optimal Perimeter Guarding", "comments": null, "journal-ref": "2019 Robotics: Science and Systems", "doi": null, "report-no": null, "categories": "cs.RO cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem of optimally assigning a large number of robots\n(or other types of autonomous agents) to guard the perimeters of closed 2D\nregions, where the perimeter of each region to be guarded may contain multiple\ndisjoint polygonal chains. Each robot is responsible for guarding a subset of a\nperimeter and any point on a perimeter must be guarded by some robot. In\nallocating the robots, the main objective is to minimize the maximum 1D\ndistance to be covered by any robot along the boundary of the regions. For this\noptimization problem which we call optimal perimeter guarding (OPG), thorough\nstructural analysis is performed, which is then exploited to develop fast exact\nalgorithms that run in guaranteed low polynomial time. In addition to formal\nanalysis and proofs, experimental evaluations and simulations are performed\nthat further validate the correctness and effectiveness of our algorithmic\nresults.\n", "versions": [{"version": "v1", "created": "Sat, 11 May 2019 03:06:40 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Feng", "Si Wei", ""], ["Han", "Shuai D.", ""], ["Gao", "Kai", ""], ["Yu", "Jingjin", ""]]}, {"id": "1905.04678", "submitter": "Wei Pan", "authors": "Wei Pan, Xuequan Lu, Yuanhao Gong, Wenming Tang, Jun Liu, Ying He,\n  Guoping Qiu", "title": "HLO: Half-kernel Laplacian Operator for Surface Smoothing", "comments": "Accepted to Computer Aided Design; Binary (exe) program avaliable:\n  https://github.com/WillPanSUTD/hlo", "journal-ref": null, "doi": "10.1016/j.cad.2019.102807", "report-no": null, "categories": "cs.CG cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a simple yet effective method for feature-preserving\nsurface smoothing. Through analyzing the differential property of surfaces, we\nshow that the conventional discrete Laplacian operator with uniform weights is\nnot applicable to feature points at which the surface is non-differentiable and\nthe second order derivatives do not exist. To overcome this difficulty, we\npropose a Half-kernel Laplacian Operator (HLO) as an alternative to the\nconventional Laplacian. Given a vertex v, HLO first finds all pairs of its\nneighboring vertices and divides each pair into two subsets (called half\nwindows); then computes the uniform Laplacians of all such subsets and\nsubsequently projects the computed Laplacians to the full-window uniform\nLaplacian to alleviate flipping and degeneration. The half window with least\nregularization energy is then chosen for v. We develop an iterative approach to\napply HLO for surface denoising. Our method is conceptually simple and easy to\nuse because it has a single parameter, i.e., the number of iterations for\nupdating vertices. We show that our method can preserve features better than\nthe popular uniform Laplacian-based denoising and it significantly alleviates\nthe shrinkage artifact. Extensive experimental results demonstrate that HLO is\nbetter than or comparable to state-of-the-art techniques both qualitatively and\nquantitatively and that it is particularly good at handling meshes with high\nnoise. We will make our source code publicly available.\n", "versions": [{"version": "v1", "created": "Sun, 12 May 2019 09:32:39 GMT"}, {"version": "v2", "created": "Wed, 15 Jan 2020 00:42:49 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Pan", "Wei", ""], ["Lu", "Xuequan", ""], ["Gong", "Yuanhao", ""], ["Tang", "Wenming", ""], ["Liu", "Jun", ""], ["He", "Ying", ""], ["Qiu", "Guoping", ""]]}, {"id": "1905.04773", "submitter": "Zeyuan He", "authors": "Zeyuan He, Simon D. Guest", "title": "Approximating a Target Surface with 1-DOF Rigid Origami", "comments": "16 pages, 7 figures", "journal-ref": "Origami 7: The Proceedings from the 7th International Meeting on\n  Origami in Science, Mathematics, and Education, Volume 2, Tarquin\n  Publications (2018), 505-520", "doi": null, "report-no": null, "categories": "math.MG cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop some design examples for approximating a target surface at the\nfinal rigidly folded state of a developable quadrilateral creased paper, which\nis folded with a 1-DOF rigid folding motion from the planar state. The final\nrigidly folded state is reached due to the clashing of panels. Now we can\napproximate some specific types of non-developable surfaces, but we do not yet\nfully understand how to approximate an arbitrary surface with a developable\ncreased paper that has limited DOFs. Our designs might have applications in\nareas related to the formation of a shell structure from a planar region.\n", "versions": [{"version": "v1", "created": "Sun, 12 May 2019 19:09:26 GMT"}, {"version": "v2", "created": "Fri, 26 Jul 2019 14:42:29 GMT"}, {"version": "v3", "created": "Thu, 11 Jun 2020 21:12:48 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["He", "Zeyuan", ""], ["Guest", "Simon D.", ""]]}, {"id": "1905.05066", "submitter": "Ankush Acharyya", "authors": "Ankush Acharyya and Anil Maheshwari and Subhas C. Nandy", "title": "Color spanning Localized query", "comments": "A preliminary version of the paper appeared in the proceedings of 5th\n  International Conference on Algorithms and Discrete Applied Mathematics,\n  CALDAM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let P be a set of n points and each of the points is colored with one of the\nk possible colors. We present efficient algorithms to pre-process P such that\nfor a given query point q, we can quickly identify the smallest color spanning\nobject of the desired type containing q. In this paper, we focus on (i)\nintervals, (ii) axis-parallel square, (iii) axis-parallel rectangle, (iv)\nequilateral triangle of fixed orientation and (v) circle, as our desired type\nof objects.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 14:47:45 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Acharyya", "Ankush", ""], ["Maheshwari", "Anil", ""], ["Nandy", "Subhas C.", ""]]}, {"id": "1905.05494", "submitter": "Apostolos Chalkis", "authors": "Apostolos Chalkis, Ioannis Z. Emiris, Vissarion Fisikopoulos", "title": "A practical algorithm for volume estimation based on billiard\n  trajectories and simulated annealing", "comments": "33 pages, 8 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We tackle the problem of efficiently approximating the volume of convex\npolytopes, when these are given in three different representations:\nH-polytopes, which have been studied extensively, V-polytopes, and zonotopes\n(Z-polytopes). We design a novel practical Multiphase Monte Carlo algorithm\nthat leverages random walks based on billiard trajectories, as well as new\nempirical convergence tests and a simulated annealing schedule of adaptive\nconvex bodies. We present a detailed experimental evaluation of our algorithm\nusing a rich dataset containing Birkhoff polytopes and polytopes from\nstructural biology. Our open-source implementation tackles problems that have\nbeen intractable so far, offering the first software to scale up in thousands\nof dimensions for H-polytopes and in the hundreds for V- and Z-polytopes on\nmoderate hardware. Last, we illustrate our software in evaluating Z-polytope\napproximations.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 10:10:10 GMT"}, {"version": "v2", "created": "Wed, 12 May 2021 19:10:15 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Chalkis", "Apostolos", ""], ["Emiris", "Ioannis Z.", ""], ["Fisikopoulos", "Vissarion", ""]]}, {"id": "1905.07124", "submitter": "Ankush Acharyya", "authors": "Ankush Acharyya and Minati De and Subhas C. Nandy and Supantha Pandit", "title": "Variations of largest rectangle recognition amidst a bichromatic point\n  set", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical separability problem involving multi-color point sets is an\nimportant area of study in computational geometry. In this paper, we study\ndifferent separability problems for bichromatic point set P=P_r\\cup P_b on a\nplane, where $P_r$ and $P_b$ represent the set of n red points and m blue\npoints respectively, and the objective is to compute a monochromatic object of\nthe desired type and of maximum size. We propose in-place algorithms for\ncomputing (i) an arbitrarily oriented monochromatic rectangle of maximum size\nin R^2, (ii) an axis-parallel monochromatic cuboid of maximum size in R^3. The\ntime complexities of the algorithms for problems (i) and (ii) are\nO(m(m+n)(m\\sqrt{n}+m\\log m+n \\log n)) and O(m^3\\sqrt{n}+m^2n\\log n),\nrespectively. As a prerequisite, we propose an in-place construction of the\nclassic data structure the k-d tree, which was originally invented by J. L.\nBentley in 1975. Our in-place variant of the $k$-d tree for a set of n points\nin R^k supports both orthogonal range reporting and counting query using O(1)\nextra workspace, and these query time complexities are the same as the\nclassical complexities, i.e., O(n^{1-1/k}+\\mu) and O(n^{1-1/k}), respectively,\nwhere \\mu is the output size of the reporting query. The construction time of\nthis data structure is O(n\\log n). Both the construction and query algorithms\nare non-recursive in nature that do not need O(\\log n) size recursion stack\ncompared to the previously known construction algorithm for in-place k-d tree\nand query in it. We believe that this result is of independent interest. We\nalso propose an algorithm for the problem of computing an arbitrarily oriented\nrectangle of maximum weight among a point set P=P_r \\cup P_b, where each point\nin P_b (resp. P_r) is associated with a negative (resp. positive) real-valued\nweight that runs in O(m^2(n+m)\\log(n+m)) time using O(n) extra space.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 06:11:49 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Acharyya", "Ankush", ""], ["De", "Minati", ""], ["Nandy", "Subhas C.", ""], ["Pandit", "Supantha", ""]]}, {"id": "1905.08691", "submitter": "Christina Katsamaki", "authors": "Ioannis Z. Emiris, Christina Katsamaki", "title": "Voronoi diagram of orthogonal polyhedra in two and three dimensions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Voronoi diagrams are a fundamental geometric data structure for obtaining\nproximity relations. We consider collections of axis-aligned orthogonal\npolyhedra in two and three-dimensional space under the max-norm, which is a\nparticularly useful scenario in certain application domains. We construct the\nexact Voronoi diagram inside an orthogonal polyhedron with holes defined by\nsuch polyhedra. Our approach avoids creating full-dimensional elements on the\nVoronoi diagram and yields a skeletal representation of the input object. We\nintroduce a complete algorithm in 2D and 3D that follows the subdivision\nparadigm relying on a bounding-volume hierarchy; this is an original approach\nto the problem. The complexity is adaptive and comparable to that of previous\nmethods. Under a mild assumption it is $O(n / \\Delta + 1 / \\Delta^2)$ in 2D or\n$O(n\\alpha^2 / \\Delta^2 +1 / \\Delta^3)$ in 3D, where $n$ is the number of\nsites, namely edges or facets resp., $\\Delta$ is the maximum cell size for the\nsubdivision to stop, and $\\alpha$ bounds vertex cardinality per facet. We also\nprovide a numerically stable, open-source implementation in Julia, illustrating\nthe practical nature of our algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 15:19:23 GMT"}, {"version": "v2", "created": "Tue, 20 Aug 2019 10:59:09 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Emiris", "Ioannis Z.", ""], ["Katsamaki", "Christina", ""]]}, {"id": "1905.09097", "submitter": "Ryan Viertel", "authors": "Ryan Viertel, Braxton Osting, Matthew Staten", "title": "Coarse Quad Layouts Through Robust Simplification of Cross Field\n  Separatrix Partitions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Streamline-based quad meshing algorithms use smooth cross fields to partition\nsurfaces into quadrilateral regions by tracing cross field separatrices. In\npractice, re-entrant corners and misalignment of singularities lead to small\nregions and limit cycles, negating some of the benefits a quad layout can\nprovide in quad meshing. We introduce three novel methods to improve on a\npipeline for coarse quad partitioning. First, we formulate an efficient method\nto compute high-quality cross fields on curved surfaces by extending the\ndiffusion generated method from Viertel and Osting (SISC, 2019). Next, we\nintroduce a method for accurately computing the trajectory of streamlines\nthrough singular triangles that prevents tangential crossings. Finally, we\nintroduce a robust method to produce coarse quad layouts by simplifying the\npartitions obtained via naive separatrix tracing. Our methods are tested on a\ndatabase of 100 objects and the results are analyzed. The algorithm performs\nwell both in terms of efficiency and visual results on the database when\ncompared to state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 12:18:30 GMT"}, {"version": "v2", "created": "Fri, 2 Aug 2019 21:58:13 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Viertel", "Ryan", ""], ["Osting", "Braxton", ""], ["Staten", "Matthew", ""]]}, {"id": "1905.09151", "submitter": "Mattia G. Bergomi", "authors": "Mattia G. Bergomi, Pietro Vertechi", "title": "Rank-based persistence", "comments": "24 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AT cs.CG math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Persistence has proved to be a valuable tool to analyze real world data\nrobustly. Several approaches to persistence have been attempted over time, some\ntopological in flavor, based on the vector space-valued homology functor, other\ncombinatorial, based on arbitrary set-valued functors. To unify the study of\ntopological and combinatorial persistence in a common categorical framework, we\ngive axioms for a generalized rank function on objects in a target category, so\nthat functors to that category induce persistence functions. We port the\ninterleaving and bottleneck distances to this novel framework and generalize\nclassical equalities and inequalities. Unlike sets and vector spaces, in many\ncategories the rank of an object does not identify it up to isomorphism: to\npreserve information about the structure of persistence modules, we define\ncolorable ranks, persistence diagrams and prove the equality between\nmulticolored bottleneck distance and interleaving distance in semisimple\nAbelian categories. To illustrate our framework in practice, we give examples\nof multicolored persistent homology on filtered topological spaces with a group\naction and labeled point cloud data.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 14:03:48 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Bergomi", "Mattia G.", ""], ["Vertechi", "Pietro", ""]]}, {"id": "1905.09434", "submitter": "Morad Behandish", "authors": "Morad Behandish, Saigopal Nelaturi, Chaman Singh Verma, Mats Allard", "title": "Automated Process Planning for Turning: A Feature-Free Approach", "comments": "A shorter version of the paper was presented at the International\n  Conference on Manufacturing Research (ICMR'2018), Sk\\\"ovde, Sweden", "journal-ref": "Journal of Production and Manufacturing Research, 2019", "doi": "10.1080/21693277.2019.1634650", "report-no": null, "categories": "cs.CG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Turning is the most commonly available and least expensive machining\noperation, in terms of both machine-hour rates and tool insert prices. A\npractical CNC process planner has to maximize the utilization of turning, not\nonly to attain precision requirements for turnable surfaces, but also to\nminimize the machining cost, while non-turnable features can be left for other\nprocesses such as milling. Most existing methods rely on separation of surface\nfeatures and lack guarantees when analyzing complex parts with interacting\nfeatures. In a previous study, we demonstrated successful implementation of a\nfeature-free milling process planner based on configuration space methods used\nfor spatial reasoning and AI search for planning. This paper extends the\nfeature-free method to include turning process planning. It opens up the\nopportunity for seamless integration of turning actions into a mill-turn\nprocess planner that can handle arbitrarily complex shapes with or without a\npriori knowledge of feature semantics.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 02:11:46 GMT"}, {"version": "v2", "created": "Sat, 29 Jun 2019 23:15:40 GMT"}, {"version": "v3", "created": "Tue, 2 Jul 2019 17:21:25 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Behandish", "Morad", ""], ["Nelaturi", "Saigopal", ""], ["Verma", "Chaman Singh", ""], ["Allard", "Mats", ""]]}, {"id": "1905.10469", "submitter": "Paul Atzberger", "authors": "B. J. Gross, N. Trask, P. Kuberry, and P. J. Atzberger", "title": "Meshfree Methods on Manifolds for Hydrodynamic Flows on Curved Surfaces:\n  A Generalized Moving Least-Squares (GMLS) Approach", "comments": null, "journal-ref": null, "doi": "10.1016/j.jcp.2020.109340", "report-no": null, "categories": "math.NA cond-mat.soft cs.CE cs.CG cs.NA q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We utilize generalized moving least squares (GMLS) to develop meshfree\ntechniques for discretizing hydrodynamic flow problems on manifolds. We use\nexterior calculus to formulate incompressible hydrodynamic equations in the\nStokesian regime and handle the divergence-free constraints via a generalized\nvector potential. This provides less coordinate-centric descriptions and\nenables the development of efficient numerical methods and splitting schemes\nfor the fourth-order governing equations in terms of a system of second-order\nelliptic operators. Using a Hodge decomposition, we develop methods for\nmanifolds having spherical topology. We show the methods exhibit high-order\nconvergence rates for solving hydrodynamic flows on curved surfaces. The\nmethods also provide general high-order approximations for the metric,\ncurvature, and other geometric quantities of the manifold and associated\nexterior calculus operators. The approaches also can be utilized to develop\nhigh-order solvers for other scalar-valued and vector-valued problems on\nmanifolds.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 22:46:05 GMT"}, {"version": "v2", "created": "Sat, 18 Jan 2020 06:29:12 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Gross", "B. J.", ""], ["Trask", "N.", ""], ["Kuberry", "P.", ""], ["Atzberger", "P. J.", ""]]}, {"id": "1905.10716", "submitter": "Rasoul Shahsavarifar", "authors": "Rasoul Shahsavarifar", "title": "Algorithmic and geometric aspects of data depth with focus on\n  $\\beta$-skeleton depth", "comments": "PhD thesis By Rasoul Shahsavarifar at the Faculty of Computer\n  Science, UNB", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The statistical rank tests play important roles in univariate non-parametric\ndata analysis. If one attempts to generalize the rank tests to a multivariate\ncase, the problem of defining a multivariate order will occur. It is not clear\nhow to define a multivariate order or statistical rank in a meaningful way. One\napproach to overcome this problem is to use the notion of data depth which\nmeasures the centrality of a point with respect to a given data set. In other\nwords, a data depth can be applied to indicate how deep a point is located with\nrespect to a given data set. Using data depth, a multivariate order can be\ndefined by ordering the data points according to their depth values. Various\nnotions of data depth have been introduced over the last decades. In this\nthesis, we discuss three depth functions: two well-known depth functions\nhalfspace depth and simplicial depth, and one recently defined depth function\nnamed as $\\beta$-skeleton depth, $\\beta\\geq 1$. The $\\beta$-skeleton depth is\nequivalent to the previously defined spherical depth and lens depth when\n$\\beta=1$ and $\\beta=2$, respectively. Our main focus in this thesis is to\nexplore the geometric and algorithmic aspects of $\\beta$-skeleton depth.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 02:51:02 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Shahsavarifar", "Rasoul", ""]]}, {"id": "1905.10820", "submitter": "Samir Chowdhury", "authors": "Samir Chowdhury", "title": "Geodesics in persistence diagram space", "comments": "20 pages, 4 figures. Comments welcome!", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.MG cs.CG math.AT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is known that for a variety of choices of metrics, including the standard\nbottleneck distance, the space of persistence diagrams admits geodesics.\nTypically these existence results produce geodesics that have the form of a\nconvex combination. More specifically, given two persistence diagrams and a\nchoice of metric, one obtains a bijection realizing the distance between the\ndiagrams, and uses this bijection to linearly interpolate from one diagram to\nanother. We prove that for several families of metrics, every geodesic in\npersistence diagram space arises as such a convex combination. For certain\nother choices of metrics, we explicitly construct infinite families of\ngeodesics that cannot have this form.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 15:46:11 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Chowdhury", "Samir", ""]]}, {"id": "1905.11203", "submitter": "G\\\"unter Rote", "authors": "G\\\"unter Rote", "title": "The Largest Contained Quadrilateral and the Smallest Enclosing\n  Parallelogram of a Convex Polygon", "comments": "7 pages + 4 pages of appendices, 4 figures, plus a prototype\n  implementation in Python. This version is substantially extended, and the\n  algorithms are given in pseudocode in the appendices. (Version 1 was only\n  about the largest contained quadrilateral.)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a linear-time algorithm for finding the quadrilateral of largest\narea contained in a convex polygon, and we show that it is closely related to\nan old algorithm for the smallest enclosing parallelogram of a convex polygon.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 13:44:15 GMT"}, {"version": "v2", "created": "Tue, 18 Jun 2019 09:49:16 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Rote", "G\u00fcnter", ""]]}, {"id": "1905.12118", "submitter": "Pawel Dlotko PhD", "authors": "Pawe{\\l} D{\\l}otko, Wanling Qiu, Simon Rudkin", "title": "Cyclicality, Periodicity and the Topology of Time Series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AT cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Periodic and semi periodic patterns are very common in nature. In this paper\nwe introduce a topological toolbox aiming in detecting and quantifying\nperiodicity. The presented technique is of a general nature and may be employed\nwherever there is suspected cyclic behaviour in a time series with no trend.\nThe approach is tested on a number of real-world examples enabling us to\nconsistently demonstrate an ability to recognise periodic behaviour where\nconventional techniques fail to do so. Quicker to react to changes in time\nseries behaviour, and with a high robustness to noise, the toolbox offers a\npowerful way to deeper understanding of time series dynamics.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 22:25:28 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["D\u0142otko", "Pawe\u0142", ""], ["Qiu", "Wanling", ""], ["Rudkin", "Simon", ""]]}, {"id": "1905.13196", "submitter": "Peter Bubenik", "authors": "Peter Bubenik, Michael Hull, Dhruv Patel, and Benjamin Whittle", "title": "Persistent homology detects curvature", "comments": "22 pages, corrections thanks to anonymous referees", "journal-ref": "Inverse Problems, 36, 025008 (2020)", "doi": "10.1088/1361-6420/ab4ac0", "report-no": null, "categories": "cs.CG cs.LG math.AT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In topological data analysis, persistent homology is used to study the \"shape\nof data\". Persistent homology computations are completely characterized by a\nset of intervals called a bar code. It is often said that the long intervals\nrepresent the \"topological signal\" and the short intervals represent \"noise\".\nWe give evidence to dispute this thesis, showing that the short intervals\nencode geometric information. Specifically, we prove that persistent homology\ndetects the curvature of disks from which points have been sampled. We describe\na general computational framework for solving inverse problems using the\naverage persistence landscape, a continuous mapping from metric spaces with a\nprobability measure to a Hilbert space. In the present application, the average\npersistence landscapes of points sampled from disks of constant curvature\nresults in a path in this Hilbert space which may be learned using standard\ntools from statistical and machine learning.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 17:36:58 GMT"}, {"version": "v2", "created": "Wed, 12 Jun 2019 13:49:29 GMT"}, {"version": "v3", "created": "Thu, 19 Sep 2019 16:04:05 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Bubenik", "Peter", ""], ["Hull", "Michael", ""], ["Patel", "Dhruv", ""], ["Whittle", "Benjamin", ""]]}, {"id": "1905.13246", "submitter": "Mehdi Behroozi", "authors": "Mehdi Behroozi", "title": "Largest Inscribed Rectangles in Geometric Convex Sets", "comments": "33 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG math.MG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the problem of finding maximum volume (axis-aligned)\ninscribed parallelotopes and boxes in a compact convex set, defined by a finite\nnumber of convex inequalities, and presents an optimization approach for\nsolving them. Several optimization models are developed that can be easily\ngeneralized to find other inscribed geometric shapes such as triangles, rhombi,\nand tetrahedrons. To find the largest axis-aligned inscribed rectangles in the\nhigher dimensions, an interior-point method algorithm is presented and\nanalyzed. Finally, a parametrized optimization approach is developed to find\nthe largest (axis-aligned) inscribed rectangles in two-dimensional space.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 18:06:00 GMT"}, {"version": "v2", "created": "Tue, 16 Feb 2021 21:13:09 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Behroozi", "Mehdi", ""]]}, {"id": "1905.13400", "submitter": "Kritika Singhal", "authors": "Facundo Memoli and Kritika Singhal", "title": "A Primer on Persistent Homology of Finite Metric Spaces", "comments": null, "journal-ref": "Bulletin of Mathematical Biology, (2019), 1-43", "doi": "10.1007/s11538-019-00614-z", "report-no": null, "categories": "math.AT cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  TDA (topological data analysis) is a relatively new area of research related\nto importing classical ideas from topology into the realm of data analysis.\nUnder the umbrella term TDA, there falls, in particular, the notion of\npersistent homology, which can be described in a nutshell, as the study of\nscale dependent homological invariants of datasets.\n  In these notes, we provide a terse self contained description of the main\nideas behind the construction of persistent homology as an invariant feature of\ndatasets, and its stability to perturbations.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 03:39:45 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Memoli", "Facundo", ""], ["Singhal", "Kritika", ""]]}]