[{"id": "0907.0884", "submitter": "Wolfgang Mulzer", "authors": "Nir Ailon, Bernard Chazelle, Kenneth L. Clarkson, Ding Liu, Wolfgang\n  Mulzer, C. Seshadhri", "title": "Self-Improving Algorithms", "comments": "26 pages, 8 figures, preliminary versions appeared at SODA 2006 and\n  SoCG 2008. Thorough revision to improve the presentation of the paper", "journal-ref": "SIAM Journal on Computing (SICOMP), 40(2), 2011, pp. 350-375", "doi": "10.1137/090766437", "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate ways in which an algorithm can improve its expected\nperformance by fine-tuning itself automatically with respect to an unknown\ninput distribution D. We assume here that D is of product type. More precisely,\nsuppose that we need to process a sequence I_1, I_2, ... of inputs I = (x_1,\nx_2, ..., x_n) of some fixed length n, where each x_i is drawn independently\nfrom some arbitrary, unknown distribution D_i. The goal is to design an\nalgorithm for these inputs so that eventually the expected running time will be\noptimal for the input distribution D = D_1 * D_2 * ... * D_n.\n  We give such self-improving algorithms for two problems: (i) sorting a\nsequence of numbers and (ii) computing the Delaunay triangulation of a planar\npoint set. Both algorithms achieve optimal expected limiting complexity. The\nalgorithms begin with a training phase during which they collect information\nabout the input distribution, followed by a stationary regime in which the\nalgorithms settle to their optimized incarnations.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jul 2009 19:48:43 GMT"}, {"version": "v2", "created": "Mon, 18 Oct 2010 09:43:17 GMT"}], "update_date": "2011-05-30", "authors_parsed": [["Ailon", "Nir", ""], ["Chazelle", "Bernard", ""], ["Clarkson", "Kenneth L.", ""], ["Liu", "Ding", ""], ["Mulzer", "Wolfgang", ""], ["Seshadhri", "C.", ""]]}, {"id": "0907.0907", "submitter": "Sariel Har-Peled", "authors": "Sariel Har-Peled", "title": "Randomized Incremental Construction of Compressed Quadtrees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a simple randomized incremental algorithm for building compressed\nquadtrees. The resulting algorithm seems to be simpler than previously known\nalgorithms for this task.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2009 03:03:42 GMT"}, {"version": "v2", "created": "Thu, 9 Jul 2009 15:08:25 GMT"}], "update_date": "2009-07-09", "authors_parsed": [["Har-Peled", "Sariel", ""]]}, {"id": "0907.1080", "submitter": "Matt Gibson", "authors": "Matt Gibson, Gaurav Kanade, Erik Krohn, Kasturi Varadarajan", "title": "Quasi-Polynomial Time Approximation Schemes for Target Tracking", "comments": "16 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of tracking $n$ targets in the plane using $2n$\ncameras. We can use two cameras to estimate the location of a target. We are\nthen interested in forming $n$ camera pairs where each camera belongs to\nexactly one pair, followed by forming a matching between the targets and camera\npairs so as to best estimate the locations of each of the targets. We consider\na special case of this problem where each of the cameras are placed along a\nhorizontal line $l$, and we consider two objective functions which have been\nshown to give good estimates of the locations of the targets when the distances\nbetween the targets and the cameras are sufficiently large. In the first\nobjective, the value of an assignment of a camera pair to a target is the\ntracking angle formed by the assignment. Here, we are interested in maximizing\nthe sum of these tracking angles. A polynomial time 2-approximation is known\nfor this problem. We give a quasi-polynomial time algorithm that returns a\nsolution whose value is at least a $(1-\\epsilon)$ factor of the value of an\noptimal solution for any $\\epsilon > 0$. In the second objective, the cost of\nan assignment of a camera pair to a target is the ratio of the vertical\ndistance between the target and $l$ to the horizontal distance between the\ncameras in the camera pair. In this setting, we are interested in minimizing\nthe sum of these ratios. A polynomial time 2-approximation is known for this\nproblem. We give a quasi-polynomial time algorithm that returns a solution\nwhose value is at most a $(1+\\epsilon)$ factor of the value of an optimal\nsolution for any $\\epsilon > 0$.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2009 19:55:38 GMT"}], "update_date": "2009-07-07", "authors_parsed": [["Gibson", "Matt", ""], ["Kanade", "Gaurav", ""], ["Krohn", "Erik", ""], ["Varadarajan", "Kasturi", ""]]}, {"id": "0907.1131", "submitter": "Sariel Har-Peled", "authors": "Sariel Har-Peled", "title": "Approximating Spanning Trees with Low Crossing Number", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a linear programming based algorithm for computing a spanning tree\n$T$ of a set $P$ of $n$ points in $\\Re^d$, such that its crossing number is\n$O(\\min(t \\log n, n^{1-1/d}))$, where $t$ the minimum crossing number of any\nspanning tree of $P$. This is the first guaranteed approximation algorithm for\nthis problem. We provide a similar approximation algorithm for the more general\nsettings of building a spanning tree for a set system with bounded \\VC\ndimension. Our approach is an alternative to the reweighting technique\npreviously used in computing such spanning trees.\n  Our approach is an alternative to the reweighting technique previously used\nin computing such spanning trees.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2009 02:27:52 GMT"}], "update_date": "2009-07-08", "authors_parsed": [["Har-Peled", "Sariel", ""]]}, {"id": "0907.1280", "submitter": "Erik Krohn", "authors": "James King and Erik Krohn", "title": "The Complexity of Guarding Terrains", "comments": "26 pages, 24 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A set $G$ of points on a 1.5-dimensional terrain, also known as an\n$x$-monotone polygonal chain, is said to guard the terrain if any point on the\nterrain is 'seen' by a point in $G$. Two points on the terrain see each other\nif and only if the line segment between them is never strictly below the\nterrain. The minimum terrain guarding problem asks for a minimum guarding set\nfor the given input terrain. We prove that the decision version of this problem\nis NP-hard. This solves a significant open problem and complements recent\npositive approximability results for the optimization problem.\n  Our proof uses a reduction from PLANAR 3-SAT. We build gadgets capable of\n'mirroring' a consistent variable assignment back and forth across a main\nvalley. The structural simplicity of 1.5-dimensional terrains makes it\ndifficult to build general clause gadgets that do not destroy this assignment\nwhen they are evaluated. However, we exploit the structure in instances of\nPLANAR 3-SAT to find very specific operations involving only 'adjacent'\nvariables. For these restricted operations we can construct gadgets that allow\na full reduction to work.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2009 19:07:51 GMT"}], "update_date": "2009-07-08", "authors_parsed": [["King", "James", ""], ["Krohn", "Erik", ""]]}, {"id": "0907.1817", "submitter": "Sheng-Gwo Chen", "authors": "Sheng-Gwo Chen, Mei-Hsiu Chi and Jyh-Yang Wu", "title": "A new intrinsic numerical method for PDE on surfaces", "comments": "14 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note we shall introduce a simple, effective numerical method for\nsolving partial differential equations for scalar and vector-valued data\ndefined on surfaces. Even though we shall follow the traditional way to\napproximate the regular surfaces under consideration by triangular meshes, the\nkey idea of our algorithm is to develop an intrinsic and unified way to compute\ndirectly the partial derivatives of functions defined on triangular meshes. We\nshall present examples in computer graphics and image processing applications.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2009 13:28:13 GMT"}], "update_date": "2009-07-13", "authors_parsed": [["Chen", "Sheng-Gwo", ""], ["Chi", "Mei-Hsiu", ""], ["Wu", "Jyh-Yang", ""]]}, {"id": "0907.2423", "submitter": "Afra Zomorodian", "authors": "Gunnar Carlsson, Gurjeet Singh, and Afra Zomorodian", "title": "Computing Multidimensional Persistence", "comments": "This paper has been withdrawn by the authors. Journal of\n  Computational Geometry, 1(1) 2010, pages 72-100.\n  http://jocg.org/index.php/jocg/article/view/19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The theory of multidimensional persistence captures the topology of a\nmultifiltration -- a multiparameter family of increasing spaces.\nMultifiltrations arise naturally in the topological analysis of scientific\ndata. In this paper, we give a polynomial time algorithm for computing\nmultidimensional persistence. We recast this computation as a problem within\ncomputational algebraic geometry and utilize algorithms from this area to solve\nit. While the resulting problem is Expspace-complete and the standard\nalgorithms take doubly-exponential time, we exploit the structure inherent\nwithing multifiltrations to yield practical algorithms. We implement all\nalgorithms in the paper and provide statistical experiments to demonstrate\ntheir feasibility.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2009 18:29:49 GMT"}, {"version": "v2", "created": "Fri, 2 Oct 2009 22:31:15 GMT"}, {"version": "v3", "created": "Fri, 19 Nov 2010 18:17:03 GMT"}], "update_date": "2010-11-22", "authors_parsed": [["Carlsson", "Gunnar", ""], ["Singh", "Gurjeet", ""], ["Zomorodian", "Afra", ""]]}, {"id": "0907.2585", "submitter": "Yifan Hu", "authors": "Emden R. Gansner, Yifan Hu, Stephen G. Kobourov", "title": "GMap: Drawing Graphs as Maps", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information visualization is essential in making sense out of large data\nsets. Often, high-dimensional data are visualized as a collection of points in\n2-dimensional space through dimensionality reduction techniques. However, these\ntraditional methods often do not capture well the underlying structural\ninformation, clustering, and neighborhoods. In this paper, we describe GMap: a\npractical tool for visualizing relational data with geographic-like maps. We\nillustrate the effectiveness of this approach with examples from several\ndomains All the maps referenced in this paper can be found in\nhttp://www.research.att.com/~yifanhu/GMap\n", "versions": [{"version": "v1", "created": "Wed, 15 Jul 2009 13:41:32 GMT"}], "update_date": "2009-07-16", "authors_parsed": [["Gansner", "Emden R.", ""], ["Hu", "Yifan", ""], ["Kobourov", "Stephen G.", ""]]}, {"id": "0907.3942", "submitter": "Megan Owen", "authors": "Megan Owen and J. Scott Provan", "title": "A Fast Algorithm for Computing Geodesic Distances in Tree Space", "comments": "20 pages, 5 figures. Added new section on including common edges and\n  leaf edge-lengths in the algorithm, clarified starting point for algorithm,\n  added references, other minor improvements. To appear in IEEE/ACM\n  Transactions on Computational Biology and Bioinformatics", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE cs.CG cs.DM math.MG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Comparing and computing distances between phylogenetic trees are important\nbiological problems, especially for models where edge lengths play an important\nrole. The geodesic distance measure between two phylogenetic trees with edge\nlengths is the length of the shortest path between them in the continuous tree\nspace introduced by Billera, Holmes, and Vogtmann. This tree space provides a\npowerful tool for studying and comparing phylogenetic trees, both in exhibiting\na natural distance measure and in providing a Euclidean-like structure for\nsolving optimization problems on trees. An important open problem is to find a\npolynomial time algorithm for finding geodesics in tree space. This paper gives\nsuch an algorithm, which starts with a simple initial path and moves through a\nseries of successively shorter paths until the geodesic is attained.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2009 15:39:16 GMT"}, {"version": "v2", "created": "Thu, 5 Nov 2009 01:14:54 GMT"}], "update_date": "2009-11-05", "authors_parsed": [["Owen", "Megan", ""], ["Provan", "J. Scott", ""]]}, {"id": "0907.4068", "submitter": "Masud Hasan", "authors": "Syed Ishtiaque Ahmed, Masud Hasan, and Md. Ariful Islam", "title": "Cutting a Convex Polyhedron Out of a Sphere", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a convex polyhedron $P$ of $n$ vertices inside a sphere $Q$, we give an\n$O(n^3)$-time algorithm that cuts $P$ out of $Q$ by using guillotine cuts and\nhas cutting cost $O((\\log n)^2)$ times the optimal.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2009 14:11:59 GMT"}, {"version": "v2", "created": "Tue, 9 Mar 2010 17:26:51 GMT"}], "update_date": "2010-03-10", "authors_parsed": [["Ahmed", "Syed Ishtiaque", ""], ["Hasan", "Masud", ""], ["Islam", "Md. Ariful", ""]]}, {"id": "0907.4957", "submitter": "Maurice Margenstern", "authors": "Maurice Margenstern", "title": "Iterative pushdown automata and hyperbolic contour words", "comments": "15 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we give an application of iterated pushdown automata to\ncontour words of balls and two other domains in infinitely many tilings of the\nhyperbolic plane. We also give a similar application for the tiling {5,3,4} of\nthe hyperbolic 3D space and for the tiling {5,3,3,4} of the hyperbolic 4D space\nas well.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2009 17:16:45 GMT"}], "update_date": "2009-07-29", "authors_parsed": [["Margenstern", "Maurice", ""]]}, {"id": "0907.5477", "submitter": "Lee-Ad Gottlieb", "authors": "Lee-Ad Gottlieb, and Robert Krauthgamer", "title": "A Nonlinear Approach to Dimension Reduction", "comments": null, "journal-ref": null, "doi": "10.1007/s00454-015-9707-9", "report-no": null, "categories": "cs.CG cs.DS math.FA math.MG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The $l_2$ flattening lemma of Johnson and Lindenstrauss [JL84] is a powerful\ntool for dimension reduction. It has been conjectured that the target dimension\nbounds can be refined and bounded in terms of the intrinsic dimensionality of\nthe data set (for example, the doubling dimension). One such problem was\nproposed by Lang and Plaut [LP01] (see also\n[GKL03,MatousekProblems07,ABN08,CGT10]), and is still open. We prove another\nresult in this line of work:\n  The snowflake metric $d^{1/2}$ of a doubling set $S \\subset l_2$ embeds with\nconstant distortion into $l_2^D$, for dimension $D$ that depends solely on the\ndoubling constant of the metric. In fact, the distortion can be made\narbitrarily close to 1, and the target dimension is polylogarithmic in the\ndoubling constant. Our techniques are robust and extend to the more difficult\nspaces $l_1$ and $l_\\infty$, although the dimension bounds here are\nquantitatively inferior than those for $l_2$.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2009 07:10:04 GMT"}, {"version": "v2", "created": "Sun, 11 Apr 2010 01:29:04 GMT"}, {"version": "v3", "created": "Sun, 3 Apr 2011 10:51:24 GMT"}, {"version": "v4", "created": "Thu, 14 May 2015 11:25:45 GMT"}], "update_date": "2015-06-09", "authors_parsed": [["Gottlieb", "Lee-Ad", ""], ["Krauthgamer", "Robert", ""]]}]