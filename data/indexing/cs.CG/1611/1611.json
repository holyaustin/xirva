[{"id": "1611.00106", "submitter": "Mirela Damian", "authors": "Mirela Damian, Erik Demaine, Robin Flatland and Joseph O'Rourke", "title": "Unfolding Genus-2 Orthogonal Polyhedra with Linear Refinement", "comments": "22 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that every orthogonal polyhedron of genus at most 2 can be unfolded\nwithout overlap while using only a linear number of orthogonal cuts (parallel\nto the polyhedron edges). This is the first result on unfolding general\northogonal polyhedra beyond genus-0. Our unfolding algorithm relies on the\nexistence of at most 2 special leaves in what we call the \"unfolding tree\"\n(which ties back to the genus), so unfolding polyhedra of genus 3 and beyond\nrequires new techniques.\n", "versions": [{"version": "v1", "created": "Tue, 1 Nov 2016 02:09:38 GMT"}], "update_date": "2016-11-02", "authors_parsed": [["Damian", "Mirela", ""], ["Demaine", "Erik", ""], ["Flatland", "Robin", ""], ["O'Rourke", "Joseph", ""]]}, {"id": "1611.01078", "submitter": "Gabriel Nivasch", "authors": "Boris Bukh and Po-Shen Loh and Gabriel Nivasch", "title": "Classifying unavoidable Tverberg partitions", "comments": "Revision following referee comments. 32 pages, 8 figures", "journal-ref": "Journal of Computational Geometry 8(1):174-205, 2017", "doi": "10.20382/jocg.v8i1a9", "report-no": null, "categories": "cs.CG math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $T(d,r) = (r-1)(d+1)+1$ be the parameter in Tverberg's theorem, and call\na partition $\\mathcal I$ of $\\{1,2,\\ldots,T(d,r)\\}$ into $r$ parts a \"Tverberg\ntype\". We say that $\\mathcal I$ \"occurs\" in an ordered point sequence $P$ if\n$P$ contains a subsequence $P'$ of $T(d,r)$ points such that the partition of\n$P'$ that is order-isomorphic to $\\mathcal I$ is a Tverberg partition. We say\nthat $\\mathcal I$ is \"unavoidable\" if it occurs in every sufficiently long\npoint sequence.\n  In this paper we study the problem of determining which Tverberg types are\nunavoidable. We conjecture a complete characterization of the unavoidable\nTverberg types, and we prove some cases of our conjecture for $d\\le 4$. Along\nthe way, we study the avoidability of many other geometric predicates.\n  Our techniques also yield a large family of $T(d,r)$-point sets for which the\nnumber of Tverberg partitions is exactly $(r-1)!^d$. This lends further support\nfor Sierksma's conjecture on the number of Tverberg partitions.\n", "versions": [{"version": "v1", "created": "Thu, 3 Nov 2016 16:15:59 GMT"}, {"version": "v2", "created": "Thu, 1 Dec 2016 19:26:37 GMT"}, {"version": "v3", "created": "Wed, 22 Mar 2017 21:02:21 GMT"}], "update_date": "2017-07-06", "authors_parsed": [["Bukh", "Boris", ""], ["Loh", "Po-Shen", ""], ["Nivasch", "Gabriel", ""]]}, {"id": "1611.01419", "submitter": "Lori Ziegelmeier", "authors": "Lori Ziegelmeier, Michael Kirby, Chris Peterson", "title": "Stratifying High Dimensional Data Based on Proximity to the Convex Hull\n  Boundary", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The convex hull of a set of points, $C$, serves to expose extremal properties\nof $C$ and can help identify elements in $C$ of high interest. For many\nproblems, particularly in the presence of noise, the true vertex set (and\nfacets) may be difficult to determine. One solution is to expand the list of\nhigh interest candidates to points lying near the boundary of the convex hull.\nWe propose a quadratic program for the purpose of stratifying points in a data\ncloud based on proximity to the boundary of the convex hull. For each data\npoint, a quadratic program is solved to determine an associated weight vector.\nWe show that the weight vector encodes geometric information concerning the\npoint's relationship to the boundary of the convex hull. The computation of the\nweight vectors can be carried out in parallel, and for a fixed number of points\nand fixed neighborhood size, the overall computational complexity of the\nalgorithm grows linearly with dimension. As a consequence, meaningful\ncomputations can be completed on reasonably large, high dimensional data sets.\n", "versions": [{"version": "v1", "created": "Fri, 4 Nov 2016 15:23:32 GMT"}], "update_date": "2016-11-07", "authors_parsed": [["Ziegelmeier", "Lori", ""], ["Kirby", "Michael", ""], ["Peterson", "Chris", ""]]}, {"id": "1611.01661", "submitter": "Ahmad Biniaz", "authors": "Ahmad Biniaz, Prosenjit Bose, David Eppstein, Anil Maheshwari, Pat\n  Morin, and Michiel Smid", "title": "Spanning Trees in Multipartite Geometric Graphs", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $R$ and $B$ be two disjoint sets of points in the plane where the points\nof $R$ are colored red and the points of $B$ are colored blue, and let\n$n=|R\\cup B|$. A bichromatic spanning tree is a spanning tree in the complete\nbipartite geometric graph with bipartition $(R,B)$. The minimum (respectively\nmaximum) bichromatic spanning tree problem is the problem of computing a\nbichromatic spanning tree of minimum (respectively maximum) total edge length.\n  1. We present a simple algorithm that solves the minimum bichromatic spanning\ntree problem in $O(n\\log^3 n)$ time. This algorithm can easily be extended to\nsolve the maximum bichromatic spanning tree problem within the same time bound.\nIt also can easily be generalized to multicolored point sets.\n  2. We present $\\Theta(n\\log n)$-time algorithms that solve the minimum and\nthe maximum bichromatic spanning tree problems.\n  3. We extend the bichromatic spanning tree algorithms and solve the\nmulticolored version of these problems in $O(n\\log n\\log k)$ time, where $k$ is\nthe number of different colors (or the size of the multipartition in a complete\nmultipartite geometric graph).\n", "versions": [{"version": "v1", "created": "Sat, 5 Nov 2016 15:54:46 GMT"}], "update_date": "2016-11-08", "authors_parsed": [["Biniaz", "Ahmad", ""], ["Bose", "Prosenjit", ""], ["Eppstein", "David", ""], ["Maheshwari", "Anil", ""], ["Morin", "Pat", ""], ["Smid", "Michiel", ""]]}, {"id": "1611.01856", "submitter": "Mayank Gupta", "authors": "Mayank Gupta and Bahman Kalantari", "title": "A Comparison of the Triangle Algorithm and SMO for Solving the Hard\n  Margin Problem", "comments": "arXiv admin note: text overlap with arXiv:1412.0356", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we consider the problem of testing, for two finite sets of\npoints in the Euclidean space, if their convex hulls are disjoint and computing\nan optimal supporting hyperplane if so. This is a fundamental problem of\nclassification in machine learning known as the hard-margin SVM. The problem\ncan be formulated as a quadratic programming problem. The SMO algorithm is the\ncurrent state of art algorithm for solving it, but it does not answer the\nquestion of separability. An alternative to solving both problems is the\nTriangle Algorithm, a geometrically inspired algorithm, initially described for\nthe convex hull membership problem, a fundamental problem in linear\nprogramming. First, we describe the experimental performance of the Triangle\nAlgorithm for testing the intersection of two convex hulls. Next, we compare\nthe performance of Triangle Algorithm with SMO for finding the optimal\nsupporting hyperplane. Based on experimental results ranging up to 5000 points\nin each set in dimensions up to 10000, the Triangle Algorithm outperforms SMO.\n", "versions": [{"version": "v1", "created": "Sun, 6 Nov 2016 22:24:10 GMT"}, {"version": "v2", "created": "Tue, 8 Nov 2016 12:19:07 GMT"}, {"version": "v3", "created": "Mon, 14 Nov 2016 03:05:03 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Gupta", "Mayank", ""], ["Kalantari", "Bahman", ""]]}, {"id": "1611.02147", "submitter": "Kaimo Hu", "authors": "Kaimo Hu, Dong-Ming Yan, David Bommes, Pierre Alliez and Bedrich Benes", "title": "Error-Bounded and Feature Preserving Surface Remeshing with Minimal\n  Angle Improvement", "comments": "14 pages, 20 figures. Submitted to IEEE Transactions on Visualization\n  and Computer Graphics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The typical goal of surface remeshing consists in finding a mesh that is (1)\ngeometrically faithful to the original geometry, (2) as coarse as possible to\nobtain a low-complexity representation and (3) free of bad elements that would\nhamper the desired application. In this paper, we design an algorithm to\naddress all three optimization goals simultaneously. The user specifies desired\nbounds on approximation error {\\delta}, minimal interior angle {\\theta} and\nmaximum mesh complexity N (number of vertices). Since such a desired mesh might\nnot even exist, our optimization framework treats only the approximation error\nbound {\\delta} as a hard constraint and the other two criteria as optimization\ngoals. More specifically, we iteratively perform carefully prioritized local\noperators, whenever they do not violate the approximation error bound and\nimprove the mesh otherwise. In this way our optimization framework greedily\nsearches for the coarsest mesh with minimal interior angle above {\\theta} and\napproximation error bounded by {\\delta}. Fast runtime is enabled by a local\napproximation error estimation, while implicit feature preservation is obtained\nby specifically designed vertex relocation operators. Experiments show that our\napproach delivers high-quality meshes with implicitly preserved features and\nbetter balances between geometric fidelity, mesh complexity and element quality\nthan the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2016 16:12:08 GMT"}], "update_date": "2016-11-08", "authors_parsed": [["Hu", "Kaimo", ""], ["Yan", "Dong-Ming", ""], ["Bommes", "David", ""], ["Alliez", "Pierre", ""], ["Benes", "Bedrich", ""]]}, {"id": "1611.02323", "submitter": "Zhengli Wang", "authors": "Kun He, Hui Ye, Zhengli Wang, Jingfa Liu", "title": "An Efficient Quasi-physical Quasi-human Algorithm for Packing Equal\n  Circles in a Circular Container", "comments": "19 pages, 16 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper addresses the equal circle packing problem, and proposes an\nefficient Quasi-physical Quasi-human (QPQH) algorithm. QPQH is based on a\nmodified Broyden-Fletcher-Goldfarb-Shanno (BFGS) algorithm which we call the\nlocal BFGS and a new basin hopping strategy based on a Chinese idiom: alternate\ntension with relaxation. Starting from a random initial layout, we apply the\nlocal BFGS algorithm to reach a local minimum layout. The local BFGS algorithm\nfully utilizes the neighborhood information of each circle to considerably\nspeed up the running time of the gradient descent process, and the efficiency\nis very apparent for large scale instances. When yielding a local minimum\nlayout, the new basin-hopping strategy is to shrink the container size to\ndifferent extent to generate several new layouts. Experimental results indicate\nthat the new basin-hopping strategy is very efficient, especially for a type of\nlayout with comparatively dense packing in the center and comparatively sparse\npacking around the boundary of the container. We test QPQH on the instances of\nn = 1,2,...,320, and obtain 66 new layouts which have smaller container sizes\nthan the current best-known results reported in literature.\n", "versions": [{"version": "v1", "created": "Tue, 2 Aug 2016 04:18:40 GMT"}, {"version": "v2", "created": "Thu, 13 Apr 2017 02:42:03 GMT"}], "update_date": "2017-04-14", "authors_parsed": [["He", "Kun", ""], ["Ye", "Hui", ""], ["Wang", "Zhengli", ""], ["Liu", "Jingfa", ""]]}, {"id": "1611.02541", "submitter": "Michael Hoffmann", "authors": "Jean Cardinal and Michael Hoffmann and Vincent Kusters and Csaba D.\n  T\\'oth and Manuel Wettstein", "title": "Arc diagrams, flip distances, and Hamiltonian triangulations", "comments": "29 pages, full version of our STACS 2015 paper corrected wrong author\n  affiliation marks from v1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that every triangulation (maximal planar graph) on $n\\ge 6$ vertices\ncan be flipped into a Hamiltonian triangulation using a sequence of less than\n$n/2$ combinatorial edge flips. The previously best upper bound uses\n$4$-connectivity as a means to establish Hamiltonicity. But in general about\n$3n/5$ flips are necessary to reach a $4$-connected triangulation. Our result\nimproves the upper bound on the diameter of the flip graph of combinatorial\ntriangulations on $n$ vertices from $5.2n-33.6$ to $5n-23$. We also show that\nfor every triangulation on $n$ vertices there is a simultaneous flip of less\nthan $2n/3$ edges to a $4$-connected triangulation. The bound on the number of\nedges is tight, up to an additive constant. As another application we show that\nevery planar graph on $n$ vertices admits an arc diagram with less than $n/2$\nbiarcs, that is, after subdividing less than $n/2$ (of potentially $3n-6$)\nedges the resulting graph admits a $2$-page book embedding.\n", "versions": [{"version": "v1", "created": "Tue, 8 Nov 2016 14:53:44 GMT"}, {"version": "v2", "created": "Fri, 11 Nov 2016 16:48:00 GMT"}], "update_date": "2016-11-14", "authors_parsed": [["Cardinal", "Jean", ""], ["Hoffmann", "Michael", ""], ["Kusters", "Vincent", ""], ["T\u00f3th", "Csaba D.", ""], ["Wettstein", "Manuel", ""]]}, {"id": "1611.02966", "submitter": "Arnaud de Mesmay", "authors": "Vincent Cohen-Addad, \\'Eric Colin de Verdi\\`ere, Arnaud de Mesmay", "title": "A Near-Linear Approximation Scheme for Multicuts of Embedded Graphs with\n  a Fixed Number of Terminals", "comments": "Final version, to appear in SICOMP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For an undirected edge-weighted graph $G$ and a set $R$ of pairs of vertices\ncalled pairs of terminals, a multicut is a set of edges such that removing\nthese edges from $G$ disconnects each pair in $R$. We provide an algorithm\ncomputing a $(1+\\varepsilon)$-approximation of the minimum multicut of a graph\n$G$ in time $(g+t)^{(O(g+t)^3)}\\cdot(1/\\varepsilon)^{O(g+t)} \\cdot n \\log n$,\nwhere $g$ is the genus of $G$ and $t$ is the number of terminals.\n  This result is tight in several aspects, as the minimum multicut problem is\nboth APX-hard and W[1]-hard (parameterized by the number of terminals), even on\nplanar graphs (equivalently, when $g=0$).\n  In order to achieve this, our article leverages on a novel characterization\nof a minimum multicut as a family of Steiner trees in the universal cover of a\nsurface on which $G$ is embedded. The algorithm heavily relies on topological\ntechniques, and in particular on the use of homotopical tools and computations\nin covering spaces, which we blend with classic ideas stemming from\napproximation schemes for planar graphs and low-dimensional geometric inputs.\n", "versions": [{"version": "v1", "created": "Wed, 9 Nov 2016 15:05:21 GMT"}, {"version": "v2", "created": "Fri, 7 Apr 2017 13:21:36 GMT"}, {"version": "v3", "created": "Fri, 3 Nov 2017 12:18:01 GMT"}, {"version": "v4", "created": "Mon, 5 Oct 2020 09:45:12 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Cohen-Addad", "Vincent", ""], ["de Verdi\u00e8re", "\u00c9ric Colin", ""], ["de Mesmay", "Arnaud", ""]]}, {"id": "1611.03187", "submitter": "Erik Demaine", "authors": "Nadia M. Benbernou, Erik D. Demaine, Martin L. Demaine, Anna Lubiw", "title": "Universal Hinge Patterns for Folding Strips Efficiently into Any Grid\n  Polyhedron", "comments": "22 pages, 18 figures. Added figures and clarified text", "journal-ref": "Computational Geometry: Theory and Applications 89 (2020)", "doi": "10.1016/j.comgeo.2020.101633", "report-no": null, "categories": "cs.CG cs.RO math.MG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present two universal hinge patterns that enable a strip of material to\nfold into any connected surface made up of unit squares on the 3D cube\ngrid--for example, the surface of any polycube. The folding is efficient: for\ntarget surfaces topologically equivalent to a sphere, the strip needs to have\nonly twice the target surface area, and the folding stacks at most two layers\nof material anywhere. These geometric results offer a new way to build\nprogrammable matter that is substantially more efficient than what is possible\nwith a square $N \\times N$ sheet of material, which can fold into all polycubes\nonly of surface area $O(N)$ and may stack $\\Theta(N^2)$ layers at one point. We\nalso show how our strip foldings can be executed by a rigid motion without\ncollisions (albeit assuming zero thickness), which is not possible in general\nwith 2D sheet folding.\n  To achieve these results, we develop new approximation algorithms for milling\nthe surface of a grid polyhedron, which simultaneously give a 2-approximation\nin tour length and an 8/3-approximation in the number of turns. Both length and\nturns consume area when folding a strip, so we build on past approximation\nalgorithms for these two objectives from 2D milling.\n", "versions": [{"version": "v1", "created": "Thu, 10 Nov 2016 05:19:56 GMT"}, {"version": "v2", "created": "Fri, 17 Jul 2020 13:31:01 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Benbernou", "Nadia M.", ""], ["Demaine", "Erik D.", ""], ["Demaine", "Martin L.", ""], ["Lubiw", "Anna", ""]]}, {"id": "1611.03260", "submitter": "Supantha Pandit", "authors": "Subhas C. Nandy, Supantha Pandit, and Sasanka Roy", "title": "Faster Approximation for Maximum Independent Set on Unit Disk Graph", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maximum independent set from a given set $D$ of unit disks intersecting a\nhorizontal line can be solved in $O(n^2)$ time and $O(n^2)$ space. As a\ncorollary, we design a factor 2 approximation algorithm for the maximum\nindependent set problem on unit disk graph which takes both time and space of\n$O(n^2)$. The best known factor 2 approximation algorithm for this problem runs\nin $O(n^2 \\log n)$ time and takes $O(n^2)$ space [Jallu and Das 2016, Das et\nal. 2016].\n", "versions": [{"version": "v1", "created": "Thu, 10 Nov 2016 11:22:51 GMT"}], "update_date": "2016-11-11", "authors_parsed": [["Nandy", "Subhas C.", ""], ["Pandit", "Supantha", ""], ["Roy", "Sasanka", ""]]}, {"id": "1611.03356", "submitter": "Stephan Brummer", "authors": "Stephan Brummer, Georg Maier, Tomas Sauer", "title": "Numerically robust computation of circular visibility", "comments": "Preprint submitted to CAGD on Nov. 08 2016, accepted Nov. 26 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the question of whether a point inside a domain bounded by a\nsimple closed arc spline is circularly visible from a specified arc from the\nboundary. We provide a simple and numerically stable linear time algorithm that\nsolves this problem. In particular, we present an easy-to-check criterion that\nimplies that a point is not visible from a specified boundary arc.\n", "versions": [{"version": "v1", "created": "Wed, 9 Nov 2016 13:41:38 GMT"}, {"version": "v2", "created": "Tue, 5 Dec 2017 16:37:00 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Brummer", "Stephan", ""], ["Maier", "Georg", ""], ["Sauer", "Tomas", ""]]}, {"id": "1611.03358", "submitter": "Manuel Mazzara", "authors": "Ilya Dmitrenok, Viktor Drobnyy, Leonard Johard and Manuel Mazzara", "title": "Evaluation of spatial trees for simulation of biological tissue", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatial organization is a core challenge for all large agent-based models\nwith local interactions. In biological tissue models, spatial search and\nreinsertion are frequently reported as the most expensive steps of the\nsimulation. One of the main methods utilized in order to maintain both\nfavorable algorithmic complexity and accuracy is spatial hierarchies. In this\npaper, we seek to clarify to which extent the choice of spatial tree affects\nperformance, and also to identify which spatial tree families are optimal for\nsuch scenarios. We make use of a prototype of the new BioDynaMo tissue\nsimulator for evaluating performances as well as for the implementation of the\ncharacteristics of several different trees.\n", "versions": [{"version": "v1", "created": "Wed, 9 Nov 2016 18:15:28 GMT"}], "update_date": "2016-11-11", "authors_parsed": [["Dmitrenok", "Ilya", ""], ["Drobnyy", "Viktor", ""], ["Johard", "Leonard", ""], ["Mazzara", "Manuel", ""]]}, {"id": "1611.03946", "submitter": "Xi Chen", "authors": "Xi Chen, Guojun Liao", "title": "New method of averaging diffeomorphisms based on Jacobian determinant\n  and curl vector", "comments": "12 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Averaging diffeomorphisms is a challenging problem, and it has great\napplications in areas like medical image atlases. The simple Euclidean average\ncan neither guarantee the averaged transformation is a diffeomorphism, nor get\nreasonable result when there is a local rotation. The goal of this paper is to\npropose a new approach to averaging diffeomorphisms based on the Jacobian\ndeterminant and the curl vector of the diffeomorphisms. Instead of averaging\nthe diffeomorphisms directly, we average the Jacobian determinants and the curl\nvectors, and then construct a diffeomorphism based on the averaged Jacobian\ndeterminant and averaged curl vector as the average of diffeomorphisms.\nNumerical examples with convincible results are presented to demonstrate the\nmethod.\n", "versions": [{"version": "v1", "created": "Sat, 12 Nov 2016 03:40:22 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Chen", "Xi", ""], ["Liao", "Guojun", ""]]}, {"id": "1611.04178", "submitter": "Luca Grilli", "authors": "Luca Grilli", "title": "On the $\\mathcal{NP}$-hardness of GRacSim Drawing and k-SEFE Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the complexity of two problems in simultaneous graph drawing. The\nfirst problem, GRacSim Drawing, asks for finding a simultaneous geometric\nembedding of two graphs such that only crossings at right angles are allowed.\nThe second problem, k-SEFE, is a restricted version of the topological\nsimultaneous embedding with fixed edges (SEFE) problem, for two planar graphs,\nin which every private edge may receive at most $k$ crossings, where $k$ is a\nprescribed positive integer. We show that GRacSim Drawing is\n$\\mathcal{NP}$-hard and that k-SEFE is $\\mathcal{NP}$-complete. The\n$\\mathcal{NP}$-hardness of both problems is proved using two similar reductions\nfrom 3-Partition.\n", "versions": [{"version": "v1", "created": "Sun, 13 Nov 2016 20:06:33 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Grilli", "Luca", ""]]}, {"id": "1611.04648", "submitter": "Guillermo Laguna", "authors": "Guillermo J. Laguna, Rui Zou and Sourabh Bhattacharya", "title": "Towards a Framework for Tracking Multiple Targets: Hybrid Systems meets\n  Computational Geometry", "comments": "The paper contains 8 pages, 9 figures, and it is a conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate a variation of the art gallery problem in which a team of\nmobile guards tries to track an unpredictable intruder in a simply-connected\npolygonal environment. In this work, we use the deployment strategy for\ndiagonal guards originally proposed in [1]. The guards are confined to move\nalong the diagonals of a polygon and the intruder can move freely within the\nenvironment. We define critical regions to generate event-triggered strategies\nfor the guards. We design a hybrid automaton based on the critical regions to\nmodel the tracking problem. Based on reachability analysis, we provide\nnecessary and sufficient conditions for tracking in terms of the maximal\ncontrolled invariant set of the hybrid system. We express these conditions in\nterms of the critical curves to find sufficient conditions for n/4 guards to\ntrack the mobile intruder using the reachability analysis.\n", "versions": [{"version": "v1", "created": "Tue, 15 Nov 2016 00:02:51 GMT"}], "update_date": "2016-11-16", "authors_parsed": [["Laguna", "Guillermo J.", ""], ["Zou", "Rui", ""], ["Bhattacharya", "Sourabh", ""]]}, {"id": "1611.05513", "submitter": "Takumi Murayama", "authors": "Jeffrey C. Lagarias, Takumi Murayama, D. Harry Richman", "title": "Dilated Floor Functions That Commute", "comments": "6 pages, to appear in Amer. Math. Monthly", "journal-ref": "Amer. Math. Monthly 123, no. 10 (2016) 1033-1038", "doi": "10.4169/amer.math.monthly.123.10.1033", "report-no": null, "categories": "math.NT cs.CG math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We determine all pairs of real numbers $(\\alpha, \\beta)$ such that the\ndilated floor functions $\\lfloor \\alpha x\\rfloor$ and $\\lfloor \\beta x\\rfloor$\ncommute under composition, i.e., such that $\\lfloor \\alpha \\lfloor \\beta\nx\\rfloor\\rfloor = \\lfloor \\beta \\lfloor \\alpha x\\rfloor\\rfloor$ holds for all\nreal $x$.\n", "versions": [{"version": "v1", "created": "Thu, 17 Nov 2016 00:16:08 GMT"}], "update_date": "2017-01-11", "authors_parsed": [["Lagarias", "Jeffrey C.", ""], ["Murayama", "Takumi", ""], ["Richman", "D. Harry", ""]]}, {"id": "1611.06222", "submitter": "Erik Waingarten", "authors": "Alexandr Andoni, Huy L. Nguyen, Aleksandar Nikolov, Ilya Razenshteyn,\n  Erik Waingarten", "title": "Approximate Near Neighbors for General Symmetric Norms", "comments": "27 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG cs.LG math.MG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that every symmetric normed space admits an efficient nearest\nneighbor search data structure with doubly-logarithmic approximation.\nSpecifically, for every $n$, $d = n^{o(1)}$, and every $d$-dimensional\nsymmetric norm $\\|\\cdot\\|$, there exists a data structure for\n$\\mathrm{poly}(\\log \\log n)$-approximate nearest neighbor search over\n$\\|\\cdot\\|$ for $n$-point datasets achieving $n^{o(1)}$ query time and\n$n^{1+o(1)}$ space. The main technical ingredient of the algorithm is a\nlow-distortion embedding of a symmetric norm into a low-dimensional iterated\nproduct of top-$k$ norms.\n  We also show that our techniques cannot be extended to general norms.\n", "versions": [{"version": "v1", "created": "Fri, 18 Nov 2016 20:56:26 GMT"}, {"version": "v2", "created": "Mon, 24 Jul 2017 13:21:13 GMT"}], "update_date": "2017-07-25", "authors_parsed": [["Andoni", "Alexandr", ""], ["Nguyen", "Huy L.", ""], ["Nikolov", "Aleksandar", ""], ["Razenshteyn", "Ilya", ""], ["Waingarten", "Erik", ""]]}, {"id": "1611.06501", "submitter": "Micha{\\l} Pilipczuk", "authors": "Micha{\\l} Pilipczuk and Erik Jan van Leeuwen and Andreas Wiese", "title": "Approximation and parameterized algorithms for geometric independent set\n  with shrinking", "comments": "25 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider the Maximum Weight Independent Set problem for rectangles: given a\nfamily of weighted axis-parallel rectangles in the plane, find a maximum-weight\nsubset of non-overlapping rectangles. The problem is notoriously hard both in\nthe approximation and in the parameterized setting. The best known\npolynomial-time approximation algorithms achieve super-constant approximation\nratios [Chalermsook and Chuzhoy, SODA 2009; Chan and Har-Peled, Discrete &\nComp. Geometry 2012], even though there is a $(1+\\epsilon)$-approximation\nrunning in quasi-polynomial time [Adamaszek and Wiese, FOCS 2013; Chuzhoy and\nEne, FOCS 2016]. When parameterized by the target size of the solution, the\nproblem is $\\mathsf{W}[1]$-hard even in the unweighted setting [Marx, FOCS\n2007].\n  To achieve tractability, we study the following shrinking model: one is\nallowed to shrink each input rectangle by a multiplicative factor $1-\\delta$\nfor some fixed $\\delta>0$, but the performance is still compared against the\noptimal solution for the original, non-shrunk instance. We prove that in this\nregime, the problem admits an EPTAS with running time $f(\\epsilon,\\delta)\\cdot\nn^{\\mathcal{O}(1)}$, and an FPT algorithm with running time $f(k,\\delta)\\cdot\nn^{\\mathcal{O}(1)}$, in the setting where a maximum-weight solution of size at\nmost $k$ is to be computed. This improves and significantly simplifies a PTAS\ngiven earlier for this problem [Adamaszek et al., APPROX 2015], and provides\nthe first parameterized results for the shrinking model. Furthermore, we\nexplore kernelization in the shrinking model, by giving efficient kernelization\nprocedures for several variants of the problem when the input rectangles are\nsquares.\n", "versions": [{"version": "v1", "created": "Sun, 20 Nov 2016 11:15:41 GMT"}], "update_date": "2016-11-22", "authors_parsed": [["Pilipczuk", "Micha\u0142", ""], ["van Leeuwen", "Erik Jan", ""], ["Wiese", "Andreas", ""]]}, {"id": "1611.06768", "submitter": "Georg Muntingh PhD", "authors": "Juan Gerardo Alc\\'azar, Heidi E. I. Dahl, Georg Muntingh", "title": "Symmetries of Canal Surfaces and Dupin Cyclides", "comments": "27 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AG cs.CG cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a characterization for the existence of symmetries of canal\nsurfaces defined by a rational spine curve and rational radius function. In\nturn, this characterization inspires an algorithm for computing the symmetries\nof such canal surfaces. For Dupin cyclides in canonical form, we apply the\ncharacterization to derive an intrinsic description of their symmetries and\nsymmetry groups, which gives rise to a method for computing the symmetries of a\nDupin cyclide not necessarily in canonical form. As a final application, we\ndiscuss the construction of patches and blends of rational canal surfaces with\na prescribed symmetry.\n", "versions": [{"version": "v1", "created": "Mon, 21 Nov 2016 12:57:43 GMT"}, {"version": "v2", "created": "Mon, 14 Aug 2017 09:15:54 GMT"}], "update_date": "2017-08-15", "authors_parsed": [["Alc\u00e1zar", "Juan Gerardo", ""], ["Dahl", "Heidi E. I.", ""], ["Muntingh", "Georg", ""]]}, {"id": "1611.06915", "submitter": "Frank Kammer", "authors": "Frank Kammer, Maarten L\\\"offler, Rodrigo I. Silveira", "title": "Space-Efficient Hidden Surface Removal", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a space-efficient algorithm for hidden surface removal that\ncombines one of the fastest previous algorithms for that problem with\ntechniques based on bit manipulation. Such techniques had been successfully\nused in other settings, for example to reduce working space for several graph\nalgorithms. However, bit manipulation is not usually employed in geometric\nalgorithms because the standard model of computation (the real RAM) does not\nsupport it. For this reason, we first revisit our model of computation to have\na reasonable theoretical framework. Under this framework we show how the use of\na bit representation for the union of triangles, in combination with\nrank-select data structures, allows us to implicitly compute the union of $n$\ntriangles with roughly $O(1)$ bits per union boundary vertex. This results in\nan algorithm that uses at most as much space as the previous one, and depending\non the input, can give a reduction of up to a factor $\\Theta(\\log n)$, while\nmaintaining the running time.\n", "versions": [{"version": "v1", "created": "Mon, 21 Nov 2016 17:44:15 GMT"}, {"version": "v2", "created": "Mon, 9 Jan 2017 18:43:44 GMT"}], "update_date": "2017-01-10", "authors_parsed": [["Kammer", "Frank", ""], ["L\u00f6ffler", "Maarten", ""], ["Silveira", "Rodrigo I.", ""]]}, {"id": "1611.07073", "submitter": "Martin T\\\"opfer", "authors": "Mat\\v{e}j Kone\\v{c}n\\'y, Stanislav Ku\\v{c}era, Michal Opler, Jakub\n  Sosnovec, \\v{S}t\\v{e}p\\'an \\v{S}imsa, Martin T\\\"opfer", "title": "Squarability of rectangle arrangements", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study when an arrangement of axis-aligned rectangles can be transformed\ninto an arrangement of axis-aligned squares in $\\mathbb{R}^2$ while preserving\nits structure. We found a counterexample to the conjecture of J. Klawitter, M.\nN\\\"ollenburg and T. Ueckerdt whether all arrangements without crossing and\nside-piercing can be squared. Our counterexample also works in a more general\ncase when we only need to preserve the intersection graph and we forbid\nside-piercing between squares. We also show counterexamples for transforming\nbox arrangements into combinatorially equivalent hypercube arrangements.\nFinally, we introduce a linear program deciding whether an arrangement of\nrectangles can be squared in a more restrictive version where the order of all\nsides is preserved.\n", "versions": [{"version": "v1", "created": "Mon, 21 Nov 2016 21:45:14 GMT"}, {"version": "v2", "created": "Wed, 23 Nov 2016 01:38:44 GMT"}], "update_date": "2016-11-24", "authors_parsed": [["Kone\u010dn\u00fd", "Mat\u011bj", ""], ["Ku\u010dera", "Stanislav", ""], ["Opler", "Michal", ""], ["Sosnovec", "Jakub", ""], ["\u0160imsa", "\u0160t\u011bp\u00e1n", ""], ["T\u00f6pfer", "Martin", ""]]}, {"id": "1611.07356", "submitter": "Gil Shamai", "authors": "Gil Shamai and Michael Zibulevsky and Ron Kimmel", "title": "Efficient Inter-Geodesic Distance Computation and Fast Classical Scaling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multidimensional scaling (MDS) is a dimensionality reduction tool used for\ninformation analysis, data visualization and manifold learning. Most MDS\nprocedures embed data points in low-dimensional Euclidean (flat) domains, such\nthat distances between the points are as close as possible to given inter-point\ndissimilarities. We present an efficient solver for classical scaling, a\nspecific MDS model, by extrapolating the information provided by distances\nmeasured from a subset of the points to the remainder. The computational and\nspace complexities of the new MDS methods are thereby reduced from quadratic to\nquasi-linear in the number of data points. Incorporating both local and global\ninformation about the data allows us to construct a low-rank approximation of\nthe inter-geodesic distances between the data points. As a by-product, the\nproposed method allows for efficient computation of geodesic distances.\n", "versions": [{"version": "v1", "created": "Mon, 21 Nov 2016 00:44:37 GMT"}, {"version": "v2", "created": "Mon, 22 Oct 2018 14:08:49 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Shamai", "Gil", ""], ["Zibulevsky", "Michael", ""], ["Kimmel", "Ron", ""]]}, {"id": "1611.07360", "submitter": "Gil Shamai", "authors": "Gil Shamai and Ron Kimmel", "title": "Geodesic Distance Descriptors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Gromov-Hausdorff (GH) distance is traditionally used for measuring\ndistances between metric spaces. It is defined as the minimal distortion of\nembedding one surface into the other, while the optimal correspondence can be\ndescribed as the map that minimizes this distortion. Solving such a\nminimization is a hard combinatorial problem that requires pre-computation and\nstoring of all pairwise geodesic distances for the matched surfaces. A popular\nway for compact representation of functions on surfaces is by projecting them\ninto the leading eigenfunctions of the Laplace-Beltrami Operator (LBO). When\ntruncated, The basis of the LBO is known to be the optimal for representing\nfunctions with bounded gradient in a min-max sense. Methods such as\nSpectral-GMDS exploit this idea to simplify and efficiently approximate a\nminimization related to the GH distance by operating in the truncated spectral\ndomain, and obtain state of the art results for matching of nearly isometric\nshapes. However, when considering only a specific set of functions on the\nsurface, such as geodesic distances, an optimized basis could be considered as\nan even better alternative. Here, we define the geodesic distance basis, which\nis optimal for compact approximation of geodesic distances, in terms of\nFrobenius norm. We use the suggested basis to extract the Geodesic Distance\nDescriptor (GDD), which encodes the geodesic distances information as a linear\ncombination of the basis functions. We then show how these ideas can be used to\nefficiently and accurately approximate the metric spaces matching problem with\nalmost no loss of information. These observations are used to construct a very\nsimple and efficient procedure for shape correspondence. Experimental results\nshow that the GDD improves both accuracy and efficiency of state of the art\nshape matching procedures.\n", "versions": [{"version": "v1", "created": "Mon, 21 Nov 2016 01:19:28 GMT"}], "update_date": "2016-11-23", "authors_parsed": [["Shamai", "Gil", ""], ["Kimmel", "Ron", ""]]}, {"id": "1611.07362", "submitter": "Saugata Basu", "authors": "Saugata Basu and Orit E. Raz", "title": "An o-minimal Szemer\\'edi-Trotter theorem", "comments": "15 pages. Final version to appear in The Quarterly Journal of\n  Mathematics", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.CG math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove an analog of the Szemer\\'edi-Trotter theorem in the plane for\ndefinable curves and points in any o-minimal structure over an arbitrary real\nclosed field $\\mathrm{R}$. One new ingredient in the proof is an extension of\nthe well known crossing number inequality for graphs to the case of embeddings\nin any o-minimal structure over an arbitrary real closed field.\n", "versions": [{"version": "v1", "created": "Tue, 22 Nov 2016 15:33:22 GMT"}, {"version": "v2", "created": "Thu, 22 Dec 2016 15:16:29 GMT"}, {"version": "v3", "created": "Wed, 12 Jul 2017 22:31:57 GMT"}], "update_date": "2017-07-14", "authors_parsed": [["Basu", "Saugata", ""], ["Raz", "Orit E.", ""]]}, {"id": "1611.07369", "submitter": "Georgina Hall", "authors": "Amir Ali Ahmadi, Georgina Hall, Ameesh Makadia, Vikas Sindhwani", "title": "Geometry of 3D Environments and Sum of Squares Polynomials", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CG cs.CV cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by applications in robotics and computer vision, we study problems\nrelated to spatial reasoning of a 3D environment using sublevel sets of\npolynomials. These include: tightly containing a cloud of points (e.g.,\nrepresenting an obstacle) with convex or nearly-convex basic semialgebraic\nsets, computation of Euclidean distances between two such sets, separation of\ntwo convex basic semalgebraic sets that overlap, and tight containment of the\nunion of several basic semialgebraic sets with a single convex one. We use\nalgebraic techniques from sum of squares optimization that reduce all these\ntasks to semidefinite programs of small size and present numerical experiments\nin realistic scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 22 Nov 2016 15:40:14 GMT"}, {"version": "v2", "created": "Wed, 1 Feb 2017 05:13:55 GMT"}, {"version": "v3", "created": "Tue, 7 Mar 2017 22:46:15 GMT"}], "update_date": "2017-03-09", "authors_parsed": [["Ahmadi", "Amir Ali", ""], ["Hall", "Georgina", ""], ["Makadia", "Ameesh", ""], ["Sindhwani", "Vikas", ""]]}, {"id": "1611.07808", "submitter": "Gautam K. Das", "authors": "Ramesh K Jallu and Gautam K Das", "title": "Hardness of Liar's Domination on Unit Disk Graphs", "comments": "6 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A unit disk graph is the intersection graph of a set of unit diameter disks\nin the plane. In this paper we consider liar's domination problem on unit disk\ngraphs, a variant of dominating set problem. We call this problem as {\\it\nEuclidean liar's domination problem}. In the Euclidean liar's domination\nproblem, a set ${\\cal P}=\\{p_1,p_2,\\ldots,p_n\\}$ of $n$ points (disk centers)\nare given in the Euclidean plane. For $p \\in {\\cal P}$, $N[p]$ is a subset of\n${\\cal P}$ such that for any $q \\in N[p]$, the Euclidean distance between $p$\nand $q$ is less than or equal to 1, i.e., the corresponding unit diameter disks\nintersect. The objective of the Euclidean liar's domination problem is to find\na subset $D\\; (\\subseteq {\\cal P})$ of minimum size having the following\nproperties : (i) $|N[p_i] \\cap D| \\geq 2$ for $1 \\leq i \\leq n$, and (ii)\n$|(N[p_i] \\cup N[p_j]) \\cap D| \\geq 3$ for $i\\neq j, 1\\leq i,j \\leq n$. This\narticle aims to prove the Euclidean liar's domination problem is NP-complete.\n", "versions": [{"version": "v1", "created": "Wed, 23 Nov 2016 14:21:02 GMT"}], "update_date": "2016-11-24", "authors_parsed": [["Jallu", "Ramesh K", ""], ["Das", "Gautam K", ""]]}, {"id": "1611.08315", "submitter": "Sandor P. Fekete", "authors": "S\\'andor P. Fekete and Qian Li and Joseph S. B. Mitchell and Christian\n  Scheffer", "title": "Universal Guard Problems", "comments": "28 pages, 19 figures, full version of extended abstract that appeared\n  in the 27th International Symposium on Algorithms and Computation (ISAAC\n  2016), 32:1-32:13", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a spectrum of results for the Universal Guard Problem, in which\none is to obtain a small set of points (\"guards\") that are \"universal\" in their\nability to guard any of a set of possible polygonal domains in the plane. We\ngive upper and lower bounds on the number of universal guards that are always\nsufficient to guard all polygons having a given set of n vertices, or to guard\nall polygons in a given set of k polygons on an n-point vertex set. Our upper\nbound proofs include algorithms to construct universal guard sets of the\nrespective cardinalities.\n", "versions": [{"version": "v1", "created": "Thu, 24 Nov 2016 21:38:59 GMT"}, {"version": "v2", "created": "Mon, 27 Mar 2017 07:19:12 GMT"}], "update_date": "2017-03-28", "authors_parsed": [["Fekete", "S\u00e1ndor P.", ""], ["Li", "Qian", ""], ["Mitchell", "Joseph S. B.", ""], ["Scheffer", "Christian", ""]]}, {"id": "1611.08752", "submitter": "Harishchandra Ramadas", "authors": "Avi Levy, Harishchandra Ramadas and Thomas Rothvoss", "title": "Deterministic Discrepancy Minimization via the Multiplicative Weight\n  Update Method", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CG cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A well-known theorem of Spencer shows that any set system with $n$ sets over\n$n$ elements admits a coloring of discrepancy $O(\\sqrt{n})$. While the original\nproof was non-constructive, recent progress brought polynomial time algorithms\nby Bansal, Lovett and Meka, and Rothvoss. All those algorithms are randomized,\neven though Bansal's algorithm admitted a complicated derandomization.\n  We propose an elegant deterministic polynomial time algorithm that is\ninspired by Lovett-Meka as well as the Multiplicative Weight Update method. The\nalgorithm iteratively updates a fractional coloring while controlling the\nexponential weights that are assigned to the set constraints.\n  A conjecture by Meka suggests that Spencer's bound can be generalized to\nsymmetric matrices. We prove that $n \\times n$ matrices that are block diagonal\nwith block size $q$ admit a coloring of discrepancy $O(\\sqrt{n} \\cdot\n\\sqrt{\\log(q)})$.\n  Bansal, Dadush and Garg recently gave a randomized algorithm to find a vector\n$x$ with entries in $\\lbrace{-1,1\\rbrace}$ with $\\|Ax\\|_{\\infty} \\leq\nO(\\sqrt{\\log n})$ in polynomial time, where $A$ is any matrix whose columns\nhave length at most 1. We show that our method can be used to deterministically\nobtain such a vector.\n", "versions": [{"version": "v1", "created": "Sat, 26 Nov 2016 22:27:17 GMT"}, {"version": "v2", "created": "Wed, 8 Mar 2017 19:01:41 GMT"}, {"version": "v3", "created": "Sat, 11 Mar 2017 00:55:41 GMT"}], "update_date": "2017-03-14", "authors_parsed": [["Levy", "Avi", ""], ["Ramadas", "Harishchandra", ""], ["Rothvoss", "Thomas", ""]]}, {"id": "1611.08757", "submitter": "Rebecca Hoberg", "authors": "Rebecca Hoberg, Harishchandra Ramadas, Thomas Rothvoss and Xin Yang", "title": "Number Balancing is as hard as Minkowski's Theorem and Shortest Vector", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The number balancing (NBP) problem is the following: given real numbers\n$a_1,\\ldots,a_n \\in [0,1]$, find two disjoint subsets $I_1,I_2 \\subseteq [n]$\nso that the difference $|\\sum_{i \\in I_1}a_i - \\sum_{i \\in I_2}a_i|$ of their\nsums is minimized. An application of the pigeonhole principle shows that there\nis always a solution where the difference is at most $O(\\frac{\\sqrt{n}}{2^n})$.\nFinding the minimum, however, is NP-hard. In polynomial time,the differencing\nalgorithm by Karmarkar and Karp from 1982 can produce a solution with\ndifference at most $n^{-\\Theta(\\log n)}$, but no further improvement has been\nmade since then.\n  In this paper, we show a relationship between NBP and Minkowski's Theorem.\nFirst we show that an approximate oracle for Minkowski's Theorem gives an\napproximate NBP oracle. Perhaps more surprisingly, we show that an approximate\nNBP oracle gives an approximate Minkowski oracle. In particular, we prove that\nany polynomial time algorithm that guarantees a solution of difference at most\n$2^{\\sqrt{n}} / 2^{n}$ would give a polynomial approximation for Minkowski as\nwell as a polynomial factor approximation algorithm for the Shortest Vector\nProblem.\n", "versions": [{"version": "v1", "created": "Sat, 26 Nov 2016 22:59:07 GMT"}, {"version": "v2", "created": "Tue, 29 Nov 2016 19:13:15 GMT"}], "update_date": "2016-11-30", "authors_parsed": [["Hoberg", "Rebecca", ""], ["Ramadas", "Harishchandra", ""], ["Rothvoss", "Thomas", ""], ["Yang", "Xin", ""]]}, {"id": "1611.08996", "submitter": "Darren Engwirda", "authors": "Darren Engwirda", "title": "JIGSAW-GEO (1.0): locally orthogonal staggered unstructured grid\n  generation for general circulation modelling on the sphere", "comments": "Final revisions, as per: Engwirda, D.: JIGSAW-GEO (1.0): locally\n  orthogonal staggered unstructured grid generation for general circulation\n  modelling on the sphere, Geosci. Model Dev., 10, 2117-2140,\n  https://doi.org/10.5194/gmd-10-2117-2017, 2017", "journal-ref": null, "doi": "10.5194/gmd-10-2117-2017", "report-no": null, "categories": "physics.ao-ph cs.CG physics.comp-ph physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An algorithm for the generation of non-uniform, locally-orthogonal staggered\nunstructured spheroidal grids is described. This technique is designed to\ngenerate very high-quality staggered Voronoi/Delaunay meshes appropriate for\ngeneral circulation modelling on the sphere, including applications to\natmospheric simulation, ocean-modelling and numerical weather prediction. Using\na recently developed Frontal-Delaunay refinement technique, a method for the\nconstruction of high-quality unstructured spheroidal Delaunay triangulations is\nintroduced. A locally-orthogonal polygonal grid, derived from the associated\nVoronoi diagram, is computed as the staggered dual. It is shown that use of the\nFrontal-Delaunay refinement technique allows for the generation of very\nhigh-quality unstructured triangulations, satisfying a-priori bounds on element\nsize and shape. Grid-quality is further improved through the application of\nhill-climbing type optimisation techniques. Overall, the algorithm is shown to\nproduce grids with very high element quality and smooth grading\ncharacteristics, while imposing relatively low computational expense. A\nselection of uniform and non-uniform spheroidal grids appropriate for\nhigh-resolution, multi-scale general circulation modelling are presented. These\ngrids are shown to satisfy the geometric constraints associated with\ncontemporary unstructured C-grid type finite-volume models, including the Model\nfor Prediction Across Scales (MPAS-O). The use of user-defined mesh-spacing\nfunctions to generate smoothly graded, non-uniform grids for multi-resolution\ntype studies is discussed in detail.\n", "versions": [{"version": "v1", "created": "Mon, 28 Nov 2016 06:28:55 GMT"}, {"version": "v2", "created": "Fri, 2 Dec 2016 23:24:30 GMT"}, {"version": "v3", "created": "Thu, 23 Mar 2017 15:42:01 GMT"}, {"version": "v4", "created": "Tue, 6 Jun 2017 19:49:37 GMT"}], "update_date": "2017-06-08", "authors_parsed": [["Engwirda", "Darren", ""]]}, {"id": "1611.09392", "submitter": "Ang Li", "authors": "Ang Li, Jin Sun, Joe Yue-Hei Ng, Ruichi Yu, Vlad I. Morariu, Larry S.\n  Davis", "title": "Generating Holistic 3D Scene Abstractions for Text-based Image Retrieval", "comments": "CVPR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CG cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatial relationships between objects provide important information for\ntext-based image retrieval. As users are more likely to describe a scene from a\nreal world perspective, using 3D spatial relationships rather than 2D\nrelationships that assume a particular viewing direction, one of the main\nchallenges is to infer the 3D structure that bridges images with users' text\ndescriptions. However, direct inference of 3D structure from images requires\nlearning from large scale annotated data. Since interactions between objects\ncan be reduced to a limited set of atomic spatial relations in 3D, we study the\npossibility of inferring 3D structure from a text description rather than an\nimage, applying physical relation models to synthesize holistic 3D abstract\nobject layouts satisfying the spatial constraints present in a textual\ndescription. We present a generic framework for retrieving images from a\ntextual description of a scene by matching images with these generated abstract\nobject layouts. Images are ranked by matching object detection outputs\n(bounding boxes) to 2D layout candidates (also represented by bounding boxes)\nwhich are obtained by projecting the 3D scenes with sampled camera directions.\nWe validate our approach using public indoor scene datasets and show that our\nmethod outperforms baselines built upon object occurrence histograms and\nlearned 2D pairwise relations.\n", "versions": [{"version": "v1", "created": "Mon, 28 Nov 2016 21:29:07 GMT"}, {"version": "v2", "created": "Tue, 11 Apr 2017 20:37:18 GMT"}], "update_date": "2017-04-13", "authors_parsed": [["Li", "Ang", ""], ["Sun", "Jin", ""], ["Ng", "Joe Yue-Hei", ""], ["Yu", "Ruichi", ""], ["Morariu", "Vlad I.", ""], ["Davis", "Larry S.", ""]]}, {"id": "1611.09485", "submitter": "Shimin Li", "authors": "Shimin Li and Haitao Wang", "title": "Dispersing Points on Intervals", "comments": "A preliminary version to appear in ISAAC 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a problem of dispersing points on disjoint intervals on a line.\nGiven n pairwise disjoint intervals sorted on a line, we want to find a point\nin each interval such that the minimum pairwise distance of these points is\nmaximized. Based on a greedy strategy, we present a linear time algorithm for\nthe problem. Further, we also solve in linear time the cycle version of the\nproblem where the intervals are given on a cycle.\n", "versions": [{"version": "v1", "created": "Tue, 29 Nov 2016 05:03:39 GMT"}], "update_date": "2016-11-30", "authors_parsed": [["Li", "Shimin", ""], ["Wang", "Haitao", ""]]}, {"id": "1611.10059", "submitter": "Amit Gurung", "authors": "Amit Gurung and Rajarshi Ray", "title": "An Efficient Algorithm for Vertex Enumeration of Two-Dimensional\n  Projection of Polytopes", "comments": "9 pages content, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An efficient algorithm to enumerate the vertices of a two-dimensional (2D)\nprojection of a polytope, is presented in this paper. The proposed algorithm\nuses the support function of the polytope to be projected and enumerated for\nvertices. The complexity of our algorithm is linear in the number of vertices\nof the projected polytope and we show empirically that the performance is\nsignificantly better in comparison to some known efficient algorithms of\nprojection and enumeration.\n", "versions": [{"version": "v1", "created": "Wed, 30 Nov 2016 09:30:41 GMT"}], "update_date": "2016-12-01", "authors_parsed": [["Gurung", "Amit", ""], ["Ray", "Rajarshi", ""]]}]