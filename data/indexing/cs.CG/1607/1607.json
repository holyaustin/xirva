[{"id": "1607.00208", "submitter": "Thiagarajan Hema", "authors": "T. Hema and K.S. Easwarakumar", "title": "An Optimal Algorithm for Range Search on Multidimensional Points", "comments": null, "journal-ref": "Asian Journal of Information Technology, 15:11,1723-1730, 2016", "doi": "10.3923/ajit.2016.1723.1730", "report-no": null, "categories": "cs.CG cs.DS", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  This paper proposes an efficient and novel method to address range search on\nmultidimensional points in $\\theta(t)$ time, where $t$ is the number of points\nreported in $\\Re^k$ space. This is accomplished by introducing a new data\nstructure, called BITS $k$d-tree. This structure also supports fast updation\nthat takes $\\theta(1)$ time for insertion and $O(\\log n)$ time for deletion.\nThe earlier best known algorithm for this problem is $O(\\log^k n+t)$ time in\nthe pointer machine model.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jul 2016 11:36:17 GMT"}], "update_date": "2016-07-04", "authors_parsed": [["Hema", "T.", ""], ["Easwarakumar", "K. S.", ""]]}, {"id": "1607.00278", "submitter": "Alexander Wolff", "authors": "Steven Chaplick, Fabian Lipp, Ji-won Park, Alexander Wolff", "title": "Obstructing Visibilities with One Obstacle", "comments": "Appears in the Proceedings of the 24th International Symposium on\n  Graph Drawing and Network Visualization (GD 2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Obstacle representations of graphs have been investigated quite intensely\nover the last few years. We focus on graphs that can be represented by a single\nobstacle. Given a (topologically open) polygon $C$ and a finite set $P$ of\npoints in general position in the complement of $C$, the visibility graph\n$G_C(P)$ has a vertex for each point in $P$ and an edge $pq$ for any two points\n$p$ and $q$ in $P$ that can see each other, that is, $\\overline{pq} \\cap\nC=\\emptyset$. We draw $G_C(P)$ straight-line. Given a graph $G$, we want to\ncompute an obstacle representation of $G$, that is, an obstacle $C$ and a set\nof points $P$ such that $G=G_C(P)$. The complexity of this problem is open,\neven for the case that the points are exactly the vertices of a simple polygon\nand the obstacle is the complement of the polygon-the simple-polygon visibility\ngraph problem. There are two types of obstacles; an inside obstacle lies in a\nbounded component of the complement of the visibility drawing, whereas an\noutside obstacle lies in the unbounded component.\n  We show that the class of graphs with an inside-obstacle representation is\nincomparable with the class of graphs that have an outside-obstacle\nrepresentation. We further show that any graph with at most seven vertices or\ncircumference at most 6 has an outside-obstacle representation, which does not\nhold for a specific graph with 8 vertices and circumference 8. Finally, we\nconsider the outside-obstacle graph sandwich problem: given graphs $G$ and $H$\non the same vertex set, is there a graph $K$ such that $G \\subseteq K \\subseteq\nH$ and $K$ has an outside-obstacle representation? We show that this problem is\nNP-hard even for co-bipartite graphs. With slight modifications, our proof also\nshows that the inside-obstacle graph sandwich problem, the single-obstacle\ngraph sandwich problem, and the simple-polygon visibility graph sandwich\nproblem are all NP-hard.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jul 2016 15:07:32 GMT"}, {"version": "v2", "created": "Thu, 1 Sep 2016 19:58:07 GMT"}], "update_date": "2016-09-02", "authors_parsed": [["Chaplick", "Steven", ""], ["Lipp", "Fabian", ""], ["Park", "Ji-won", ""], ["Wolff", "Alexander", ""]]}, {"id": "1607.00538", "submitter": "Stefan Langerman", "authors": "Jin Akiyama, Stefan Langerman and Kiyoko Matsunaga", "title": "Reversible Nets of Polyhedra", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An example of reversible (or hinge inside-out transformable) figures is the\nDudeney's Haberdasher's puzzle in which an equilateral triangle is dissected\ninto four pieces, then hinged like a chain, and then is transformed into a\nsquare by rotating the hinged pieces. Furthermore, the entire boundary of each\nfigure goes into the inside of the other figure and becomes the dissection\nlines of the other figure. Many intriguing results on reversibilities of\nfigures have been found in prior research, but most of them are results on\npolygons. This paper generalizes those results to a wider range of general\nconnected figures. It is shown that two nets obtained by cutting the surface of\nan arbitrary convex polyhedron along non-intersecting dissection trees are\nreversible. Moreover, a condition for two nets of an isotetrahedron to be both\nreversible and tessellative is given.\n", "versions": [{"version": "v1", "created": "Sat, 2 Jul 2016 17:40:37 GMT"}], "update_date": "2016-07-05", "authors_parsed": [["Akiyama", "Jin", ""], ["Langerman", "Stefan", ""], ["Matsunaga", "Kiyoko", ""]]}, {"id": "1607.00854", "submitter": "Thomas Rothvoss", "authors": "Thomas Rothvoss", "title": "Lecture Notes on the ARV Algorithm for Sparsest Cut", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the landmarks in approximation algorithms is the $O(\\sqrt{\\log\nn})$-approximation algorithm for the Uniform Sparsest Cut problem by Arora, Rao\nand Vazirani from 2004. The algorithm is based on a semidefinite program that\nfinds an embedding of the nodes respecting the triangle inequality. Their core\nargument shows that a random hyperplane approach will find two large sets of\n$\\Theta(n)$ many nodes each that have a distance of $\\Theta(1/\\sqrt{\\log n})$\nto each other if measured in terms of $\\|\\cdot \\|_2^2$.\n  Here we give a detailed set of lecture notes describing the algorithm. For\nthe proof of the Structure Theorem we use a cleaner argument based on expected\nmaxima over $k$-neighborhoods that significantly simplifies the analysis.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jul 2016 12:30:15 GMT"}], "update_date": "2016-07-05", "authors_parsed": [["Rothvoss", "Thomas", ""]]}, {"id": "1607.00868", "submitter": "Leo Liberti", "authors": "Claudia D'Ambrosio, Ky Vu, Carlile Lavor, Leo Liberti, Nelson Maculan", "title": "New error measures and methods for realizing protein graphs from\n  distance data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG math.MG math.OC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The interval Distance Geometry Problem (iDGP) consists in finding a\nrealization in $\\mathbb{R}^K$ of a simple undirected graph $G=(V,E)$ with\nnonnegative intervals assigned to the edges in such a way that, for each edge,\nthe Euclidean distance between the realization of the adjacent vertices is\nwithin the edge interval bounds. In this paper, we focus on the application to\nthe conformation of proteins in space, which is a basic step in determining\nprotein function: given interval estimations of some of the inter-atomic\ndistances, find their shape. Among different families of methods for\naccomplishing this task, we look at mathematical programming based methods,\nwhich are well suited for dealing with intervals. The basic question we want to\nanswer is: what is the best such method for the problem? The most meaningful\nerror measure for evaluating solution quality is the coordinate root mean\nsquare deviation. We first introduce a new error measure which addresses a\nparticular feature of protein backbones, i.e. many partial reflections also\nyield acceptable backbones. We then present a set of new and existing quadratic\nand semidefinite programming formulations of this problem, and a set of new and\nexisting methods for solving these formulations. Finally, we perform a\ncomputational evaluation of all the feasible solver$+$formulation combinations\naccording to new and existing error measures, finding that the best methodology\nis a new heuristic method based on multiplicative weights updates.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jul 2016 13:03:34 GMT"}], "update_date": "2016-07-05", "authors_parsed": [["D'Ambrosio", "Claudia", ""], ["Vu", "Ky", ""], ["Lavor", "Carlile", ""], ["Liberti", "Leo", ""], ["Maculan", "Nelson", ""]]}, {"id": "1607.01196", "submitter": "Fabian Lipp", "authors": "Steven Chaplick, Krzysztof Fleszar, Fabian Lipp, Alexander Ravsky,\n  Oleg Verbitsky, Alexander Wolff", "title": "Drawing Graphs on Few Lines and Few Planes", "comments": "Appears in the Proceedings of the 24th International Symposium on\n  Graph Drawing and Network Visualization (GD 2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem of drawing graphs in 2D and 3D such that their\nedges (or only their vertices) can be covered by few lines or planes. We insist\non straight-line edges and crossing-free drawings. This problem has many\nconnections to other challenging graph-drawing problems such as small-area or\nsmall-volume drawings, layered or track drawings, and drawing graphs with low\nvisual complexity. While some facts about our problem are implicit in previous\nwork, this is the first treatment of the problem in its full generality. Our\ncontribution is as follows.\n  We show lower and upper bounds for the numbers of lines and planes needed for\ncovering drawings of graphs in certain graph classes. In some cases our bounds\nare asymptotically tight; in some cases we are able to determine exact values.\n  We relate our parameters to standard combinatorial characteristics of graphs\n(such as the chromatic number, treewidth, maximum degree, or arboricity) and to\nparameters that have been studied in graph drawing (such as the track number or\nthe number of segments appearing in a drawing).\n  We pay special attention to planar graphs. For example, we show that there\nare planar graphs that can be drawn in 3-space on a lot fewer lines than in the\nplane.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jul 2016 11:23:46 GMT"}, {"version": "v2", "created": "Thu, 1 Sep 2016 17:32:39 GMT"}], "update_date": "2016-09-02", "authors_parsed": [["Chaplick", "Steven", ""], ["Fleszar", "Krzysztof", ""], ["Lipp", "Fabian", ""], ["Ravsky", "Alexander", ""], ["Verbitsky", "Oleg", ""], ["Wolff", "Alexander", ""]]}, {"id": "1607.01257", "submitter": "Boris Goldfarb", "authors": "Boris Goldfarb", "title": "Singular persistent homology with geometrically parallelizable\n  computation", "comments": "19 pages, 5 figures", "journal-ref": "Topology Proceedings 55 (2020), 273-294", "doi": null, "report-no": null, "categories": "cs.CG math.AT math.MG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Persistent homology is a popular tool in Topological Data Analysis. It\nprovides numerical characteristics of data sets which reflect global geometric\nproperties. In order to be useful in practice, for example for feature\ngeneration in machine learning, it needs to be effectively computable.\nClassical homology is a computable topological invariant because of the\nMayer-Vietoris exact and spectral sequences associated to coverings of a space.\nWe state and prove versions of the Mayer-Vietoris theorem for persistent\nhomology under mild and commonplace assumptions. This is done through the use\nof a new theory, the singular persistent homology, better suited for handling\ncoverings of data sets. As an application, we create a distributed\ncomputational workflow where the advantage is not only or even primarily in\nspeed improvement but in sheer feasibility for large data sets.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jul 2016 14:14:17 GMT"}, {"version": "v2", "created": "Fri, 7 Jul 2017 19:31:25 GMT"}, {"version": "v3", "created": "Fri, 13 Jul 2018 11:56:10 GMT"}, {"version": "v4", "created": "Sat, 22 Jun 2019 20:46:21 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Goldfarb", "Boris", ""]]}, {"id": "1607.01294", "submitter": "Alina Shaikhet", "authors": "Prosenjit Bose and Jean-Lou De Carufel and Alina Shaikhet and Michiel\n  Smid", "title": "Essential Constraints of Edge-Constrained Proximity Graphs", "comments": "24 pages, 22 figures. A preliminary version of this paper appeared in\n  the Proceedings of 27th International Workshop, IWOCA 2016, Helsinki,\n  Finland. It was published by Springer in the Lecture Notes in Computer\n  Science (LNCS) series", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a plane forest $F = (V, E)$ of $|V| = n$ points, we find the minimum\nset $S \\subseteq E$ of edges such that the edge-constrained minimum spanning\ntree over the set $V$ of vertices and the set $S$ of constraints contains $F$.\nWe present an $O(n \\log n )$-time algorithm that solves this problem. We\ngeneralize this to other proximity graphs in the constraint setting, such as\nthe relative neighbourhood graph, Gabriel graph, $\\beta$-skeleton and Delaunay\ntriangulation. We present an algorithm that identifies the minimum set\n$S\\subseteq E$ of edges of a given plane graph $I=(V,E)$ such that $I \\subseteq\nCG_\\beta(V, S)$ for $1 \\leq \\beta \\leq 2$, where $CG_\\beta(V, S)$ is the\nconstraint $\\beta$-skeleton over the set $V$ of vertices and the set $S$ of\nconstraints. The running time of our algorithm is $O(n)$, provided that the\nconstrained Delaunay triangulation of $I$ is given.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jul 2016 15:22:34 GMT"}, {"version": "v2", "created": "Sat, 1 Oct 2016 04:08:55 GMT"}], "update_date": "2016-10-04", "authors_parsed": [["Bose", "Prosenjit", ""], ["De Carufel", "Jean-Lou", ""], ["Shaikhet", "Alina", ""], ["Smid", "Michiel", ""]]}, {"id": "1607.02052", "submitter": "Jonathan Lambrechts", "authors": "Jean-Fran\\c{c}ois Remacle and Jonathan Lambrechts", "title": "Fast and robust mesh generation on the sphere Application to coastal\n  domains", "comments": "Submitted to the 25th international meshing round table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a fast an robust mesh generation procedure that is able\nto generate meshes of the earth system (ocean and continent) in matters of\nseconds. Our algorithm takes as input a standard shape-file i.e. geospatial\nvector data format for geographic information system (GIS) software. The input\nis initially coarsened in order to automatically remove unwanted channels that\nare under a desired resolution. A valid non-overlapping 1D mesh is then created\non the sphere using the Euclidian coordinates system $x,y,z$. A modified\nDelaunay kernel is then proposed that enables to generate meshes on the sphere\nin a straightforward manner without parametrization. One of the main difficulty\nin dealing with geographical data is the over-sampled nature of coastline\nrepresentations. We propose here an algorithm that automatically unrefines\ncoastline data. Small features are automatically removed while always keeping a\nvalid (non-overlapping) geometrical representation of the domain. A Delaunay\nrefinement procedure is subsequently applied to the domain. The refinement\nscheme is also multi-threaded at a fine grain level, allowing to generate about\na million points per second on 8 threads. Examples of meshes of the Baltic sea\nas well as of the global ocean are presented.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jul 2016 15:40:29 GMT"}], "update_date": "2016-07-08", "authors_parsed": [["Remacle", "Jean-Fran\u00e7ois", ""], ["Lambrechts", "Jonathan", ""]]}, {"id": "1607.02184", "submitter": "David Eppstein", "authors": "David Eppstein", "title": "Maximizing the Sum of Radii of Disjoint Balls or Disks", "comments": "20 pages, 11 figures. A preliminary version of this paper appeared at\n  the 28th Canadian Conference on Computational Geometry, Vancouver, 2016", "journal-ref": "J. Computational Geometry 8 (1): 316-339, 2017", "doi": "10.20382/jocg.v8i1a12", "report-no": null, "categories": "cs.CG cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Finding nonoverlapping balls with given centers in any metric space,\nmaximizing the sum of radii of the balls, can be expressed as a linear program.\nIts dual linear program expresses the problem of finding a minimum-weight set\nof cycles (allowing 2-cycles) covering all vertices in a complete geometric\ngraph. For points in a Euclidean space of any finite dimension~$d$, with any\nconvex distance function on this space, this graph can be replaced by a sparse\nsubgraph obeying a separator theorem. This graph structure leads to an\nalgorithm for finding the optimum set of balls in time $O(n^{2-1/d})$,\nimproving the $O(n^3)$ time of a naive cycle cover algorithm. As a subroutine,\nwe provide an algorithm for weighted bipartite matching in graphs with\nseparators, which speeds up the best previous algorithm for this problem on\nplanar bipartite graphs from $O(n^{3/2}\\log n)$ to $O(n^{3/2})$ time. We also\nshow how to constrain the balls to all have radius at least a given threshold\nvalue, and how to apply our radius-sum optimization algorithms to the problem\nof embedding a finite metric space into a star metric minimizing the average\ndistance to the hub.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jul 2016 22:28:34 GMT"}, {"version": "v2", "created": "Thu, 22 Jun 2017 00:47:37 GMT"}], "update_date": "2017-10-09", "authors_parsed": [["Eppstein", "David", ""]]}, {"id": "1607.02196", "submitter": "Sofya Chepushtanova", "authors": "Sofya Chepushtanova, Michael Kirby, Chris Peterson, Lori Ziegelmeier", "title": "Persistent Homology on Grassmann Manifolds for Analysis of Hyperspectral\n  Movies", "comments": "version 2: typos correction", "journal-ref": "Computational Topology in Image Context, Volume 9667 of the series\n  Lecture Notes in Computer Science, pp. 228-239, June 2016", "doi": "10.1007/978-3-319-39441-1_21", "report-no": null, "categories": "cs.CV cs.CG math.AT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The existence of characteristic structure, or shape, in complex data sets has\nbeen recognized as increasingly important for mathematical data analysis. This\nrealization has motivated the development of new tools such as persistent\nhomology for exploring topological invariants, or features, in large data sets.\nIn this paper we apply persistent homology to the characterization of gas\nplumes in time dependent sequences of hyperspectral cubes, i.e. the analysis of\n4-way arrays. We investigate hyperspectral movies of Long-Wavelength Infrared\ndata monitoring an experimental release of chemical simulant into the air. Our\napproach models regions of interest within the hyperspectral data cubes as\npoints on the real Grassmann manifold $G(k, n)$ (whose points parameterize the\n$k$-dimensional subspaces of $\\mathbb{R}^n$), contrasting our approach with the\nmore standard framework in Euclidean space. An advantage of this approach is\nthat it allows a sequence of time slices in a hyperspectral movie to be\ncollapsed to a sequence of points in such a way that some of the key structure\nwithin and between the slices is encoded by the points on the Grassmann\nmanifold. This motivates the search for topological features, associated with\nthe evolution of the frames of a hyperspectral movie, within the corresponding\npoints on the Grassmann manifold. The proposed mathematical model affords the\nprocessing of large data sets while retaining valuable discriminatory\ninformation. In this paper, we discuss how embedding our data in the Grassmann\nmanifold, together with topological data analysis, captures dynamical events\nthat occur as the chemical plume is released and evolves.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jul 2016 23:39:29 GMT"}, {"version": "v2", "created": "Mon, 11 Jul 2016 13:53:15 GMT"}], "update_date": "2016-07-12", "authors_parsed": [["Chepushtanova", "Sofya", ""], ["Kirby", "Michael", ""], ["Peterson", "Chris", ""], ["Ziegelmeier", "Lori", ""]]}, {"id": "1607.02218", "submitter": "Jonathan Spreer", "authors": "Cl\\'ement Maria and Jonathan Spreer", "title": "A polynomial time algorithm to compute quantum invariants of 3-manifolds\n  with bounded first Betti number", "comments": "14 pages, 3 figures", "journal-ref": "Proceedings of the ACM-SIAM Symposium on Discrete Algorithms (SODA\n  2017), Society for Industrial and Applied Mathematics, 2721-2732, 2017, and\n  Foundations of Computational Mathematics, 2019", "doi": "10.1007/s10208-019-09438-8", "report-no": null, "categories": "math.GT cs.CG math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we introduce a fixed parameter tractable algorithm for\ncomputing the Turaev-Viro invariants TV(4,q), using the dimension of the first\nhomology group of the manifold as parameter.\n  This is, to our knowledge, the first parameterised algorithm in computational\n3-manifold topology using a topological parameter. The computation of TV(4,q)\nis known to be #P-hard in general; using a topological parameter provides an\nalgorithm polynomial in the size of the input triangulation for the extremely\nlarge family of 3-manifolds with first homology group of bounded rank.\n  Our algorithm is easy to implement and running times are comparable with\nrunning times to compute integral homology groups for standard libraries of\ntriangulated 3-manifolds. The invariants we can compute this way are powerful:\nin combination with integral homology and using standard data sets we are able\nto roughly double the pairs of 3-manifolds we can distinguish.\n  We hope this qualifies TV(4,q) to be added to the short list of standard\nproperties (such as orientability, connectedness, Betti numbers, etc.) that can\nbe computed ad-hoc when first investigating an unknown triangulation.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jul 2016 02:49:59 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Maria", "Cl\u00e9ment", ""], ["Spreer", "Jonathan", ""]]}, {"id": "1607.02346", "submitter": "Giordano Da Lozzo", "authors": "Giordano Da Lozzo and Ignaz Rutter", "title": "Strengthening Hardness Results to 3-Connected Planar Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CG math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we extend some classical NP-hardness results from the class of\n2-connected planar graphs to subclasses of 3-connected planar graphs. The\nreduction are partly based on a new graph augmentation, which may be of\nindependent interest.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jul 2016 12:52:45 GMT"}], "update_date": "2016-07-11", "authors_parsed": [["Da Lozzo", "Giordano", ""], ["Rutter", "Ignaz", ""]]}, {"id": "1607.02347", "submitter": "Giordano Da Lozzo", "authors": "Giordano Da Lozzo and Ignaz Rutter", "title": "On the Complexity of Realizing Facial Cycles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the following combinatorial problem. Given a planar graph $G=(V,E)$\nand a set of simple cycles $\\mathcal C$ in $G$, find a planar embedding\n$\\mathcal E$ of $G$ such that the number of cycles in $\\mathcal C$ that bound a\nface in $\\mathcal E$ is maximized. We establish a tight border of tractability\nfor this problem in biconnected planar graphs by giving conditions under which\nthe problem is NP-hard and showing that relaxing any of these conditions makes\nthe problem polynomial-time solvable. Moreover, we give a $2$-approximation\nalgorithm for series-parallel graphs and a $(4+\\varepsilon)$-approximation for\nbiconnected planar graphs.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jul 2016 12:55:03 GMT"}], "update_date": "2016-07-11", "authors_parsed": [["Da Lozzo", "Giordano", ""], ["Rutter", "Ignaz", ""]]}, {"id": "1607.02725", "submitter": "Bart M. P. Jansen", "authors": "Mark de Berg, Kevin Buchin, Bart M. P. Jansen and Gerhard Woeginger", "title": "Fine-Grained Complexity Analysis of Two Classic TSP Variants", "comments": "Extended abstract appears in the Proceedings of the 43rd\n  International Colloquium on Automata, Languages, and Programming (ICALP 2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze two classic variants of the Traveling Salesman Problem using the\ntoolkit of fine-grained complexity. Our first set of results is motivated by\nthe Bitonic TSP problem: given a set of $n$ points in the plane, compute a\nshortest tour consisting of two monotone chains. It is a classic\ndynamic-programming exercise to solve this problem in $O(n^2)$ time. While the\nnear-quadratic dependency of similar dynamic programs for Longest Common\nSubsequence and Discrete Frechet Distance has recently been proven to be\nessentially optimal under the Strong Exponential Time Hypothesis, we show that\nbitonic tours can be found in subquadratic time. More precisely, we present an\nalgorithm that solves bitonic TSP in $O(n \\log^2 n)$ time and its bottleneck\nversion in $O(n \\log^3 n)$ time. Our second set of results concerns the popular\n$k$-OPT heuristic for TSP in the graph setting. More precisely, we study the\n$k$-OPT decision problem, which asks whether a given tour can be improved by a\n$k$-OPT move that replaces $k$ edges in the tour by $k$ new edges. A simple\nalgorithm solves $k$-OPT in $O(n^k)$ time for fixed $k$. For 2-OPT, this is\neasily seen to be optimal. For $k=3$ we prove that an algorithm with a runtime\nof the form $\\tilde{O}(n^{3-\\epsilon})$ exists if and only if All-Pairs\nShortest Paths in weighted digraphs has such an algorithm. The results for\n$k=2,3$ may suggest that the actual time complexity of $k$-OPT is\n$\\Theta(n^k)$. We show that this is not the case, by presenting an algorithm\nthat finds the best $k$-move in $O(n^{\\lfloor 2k/3 \\rfloor + 1})$ time for\nfixed $k \\geq 3$. This implies that 4-OPT can be solved in $O(n^3)$ time,\nmatching the best-known algorithm for 3-OPT. Finally, we show how to beat the\nquadratic barrier for $k=2$ in two important settings, namely for points in the\nplane and when we want to solve 2-OPT repeatedly.\n", "versions": [{"version": "v1", "created": "Sun, 10 Jul 2016 09:55:53 GMT"}], "update_date": "2016-07-12", "authors_parsed": [["de Berg", "Mark", ""], ["Buchin", "Kevin", ""], ["Jansen", "Bart M. P.", ""], ["Woeginger", "Gerhard", ""]]}, {"id": "1607.02770", "submitter": "Kiril Solovey", "authors": "Kiril Solovey and Dan Halperin", "title": "Sampling-based bottleneck pathfinding with applications to Frechet\n  matching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a general probabilistic framework to address a variety of\nFrechet-distance optimization problems. Specifically, we are interested in\nfinding minimal bottleneck-paths in $d$-dimensional Euclidean space between\ngiven start and goal points, namely paths that minimize the maximal value over\na continuous cost map. We present an efficient and simple sampling-based\nframework for this problem, which is inspired by, and draws ideas from,\ntechniques for robot motion planning. We extend the framework to handle not\nonly standard bottleneck pathfinding, but also the more demanding case, where\nthe path needs to be monotone in all dimensions. Finally, we provide\nexperimental results of the framework on several types of problems.\n", "versions": [{"version": "v1", "created": "Sun, 10 Jul 2016 18:23:31 GMT"}], "update_date": "2016-07-12", "authors_parsed": [["Solovey", "Kiril", ""], ["Halperin", "Dan", ""]]}, {"id": "1607.03039", "submitter": "Salma Sadat Mahdavi", "authors": "Mohammad Ghodsi, Salma Sadat Mahdavi, and Ali Narenji Sheshkalani", "title": "Clearing an Orthogonal Polygon Using Sliding Robots", "comments": "11 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a multi-robot system, a number of autonomous robots would sense,\ncommunicate, and decide to move within a given domain to achieve a common goal.\nIn this paper, we consider a new variant of the pursuit-evasion problem in\nwhich the robots (pursuers) each move back and forth along an orthogonal line\nsegment inside a simple orthogonal polygon $P$. A point $p$ can be covered by a\nsliding robot that moves along a line segment s, if there exists a point $q\\in\ns$ such that $\\overline{pq}$ is a line segment perpendicular to $s$. In the\npursuit-evasion problem, a polygonal region is given and a robot called a\npursuer tries to find some mobile targets called evaders. The goal of this\nproblem is to design a motion strategy for the pursuer such that it can detect\nall the evaders. We assume that $P$ includes unpredictable, moving evaders that\nhave unbounded speed. We propose a motion-planning algorithm for a group of\nsliding robots, assuming that they move along the pre-located line segments\nwith a constant speed to detect all the evaders with unbounded speed.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jul 2016 17:09:53 GMT"}, {"version": "v2", "created": "Mon, 15 Aug 2016 19:53:52 GMT"}], "update_date": "2016-08-16", "authors_parsed": [["Ghodsi", "Mohammad", ""], ["Mahdavi", "Salma Sadat", ""], ["Sheshkalani", "Ali Narenji", ""]]}, {"id": "1607.03338", "submitter": "Konstantinos Mastakas", "authors": "Konstantinos Mastakas and Antonios Symvonis", "title": "Rooted Uniform Monotone Minimum Spanning Trees", "comments": "Full version of an article accepted at the 10th International\n  Conference on Algorithms and Complexity (CIAC 2017). We mention some of the\n  changes we made w.r.t. the previous version. Using two data structures that\n  were given by Bentley (Information Processing Letters, 1979), the time\n  complexity of two of our algorithms was improved. Furthermore, text was added\n  and some typos were corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the construction of the minimum cost spanning geometric graph of a\ngiven rooted point set $P$ where each point of $P$ is connected to the root by\na path that satisfies a given property. We focus on two properties, namely the\nmonotonicity w.r.t. a single direction ($y$-monotonicity) and the monotonicity\nw.r.t. a single pair of orthogonal directions ($xy$-monotonicity). We propose\nalgorithms that compute the rooted $y$-monotone ($xy$-monotone) minimum\nspanning tree of $P$ in $O(|P|\\log^2 |P|)$ (resp. $O(|P|\\log^3 |P|)$) time when\nthe direction (resp. pair of orthogonal directions) of monotonicity is given,\nand in $O(|P|^2\\log|P|)$ time when the optimum direction (resp. pair of\northogonal directions) has to be determined. We also give simple algorithms\nwhich, given a rooted connected geometric graph, decide if the root is\nconnected to every other vertex by paths that are all monotone w.r.t. the same\ndirection (pair of orthogonal directions).\n", "versions": [{"version": "v1", "created": "Tue, 12 Jul 2016 12:49:28 GMT"}, {"version": "v2", "created": "Wed, 25 Jan 2017 21:08:04 GMT"}], "update_date": "2017-01-27", "authors_parsed": [["Mastakas", "Konstantinos", ""], ["Symvonis", "Antonios", ""]]}, {"id": "1607.03849", "submitter": "Piotr Beben", "authors": "Piotr Beben", "title": "Fitting a Simplicial Complex using a Variation of k-means", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a simple and effective two stage algorithm for approximating a point\ncloud $\\mathcal{S}\\subset\\mathbb{R}^m$ by a simplicial complex $K$. The first\nstage is an iterative fitting procedure that generalizes k-means clustering,\nwhile the second stage involves deleting redundant simplices. A form of\ndimension reduction of $\\mathcal{S}$ is obtained as a consequence.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jul 2016 18:15:52 GMT"}, {"version": "v2", "created": "Tue, 2 Aug 2016 15:34:40 GMT"}], "update_date": "2016-08-03", "authors_parsed": [["Beben", "Piotr", ""]]}, {"id": "1607.04005", "submitter": "Paul Liu", "authors": "David Kirkpatrick, Paul Liu", "title": "Characterizing minimum-length coordinated motions for two discs", "comments": "long-form of conference submission, 26 pages, 18 figures", "journal-ref": "Proceedings of the 28th Canadian Conference on Computational\n  Geometry (2016). p. 252-259", "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of determining optimal coordinated motions for two disc\nrobots in an otherwise obstacle-free plane. Using the total path length traced\nby the two disc centres as a measure of distance, we give an exact\ncharacterization of a shortest collision-avoiding motion for all initial and\nfinal configurations of the robots. The individual paths are composed of at\nmost six (straight or circular-arc) segments, and their total length can be\nexpressed as a simple integral with a closed form solution depending only on\nthe initial and final configuration of the robots. Furthermore, the paths can\nbe parametrized in such a way that (i) only one robot is moving at any given\ntime (decoupled motion), or (ii) the angle between the two robots' centres\nchanges monotonically.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jul 2016 06:16:49 GMT"}, {"version": "v2", "created": "Tue, 19 Jul 2016 07:10:43 GMT"}, {"version": "v3", "created": "Thu, 27 Oct 2016 05:28:40 GMT"}, {"version": "v4", "created": "Fri, 20 Jan 2017 11:21:47 GMT"}], "update_date": "2017-01-23", "authors_parsed": [["Kirkpatrick", "David", ""], ["Liu", "Paul", ""]]}, {"id": "1607.04083", "submitter": "Orit E. Raz", "authors": "Orit E. Raz", "title": "Configurations of lines in space and combinatorial rigidity", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CG cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $L$ be a sequence $(\\ell_1,\\ell_2,\\ldots,\\ell_n)$ of $n$ lines in\n$\\mathbb{C}^3$. We define the {\\it intersection graph} $G_L=([n],E)$ of $L$,\nwhere $[n]:=\\{1,\\ldots, n\\}$, and with $\\{i,j\\}\\in E$ if and only if $i\\neq j$\nand the corresponding lines $\\ell_i$ and $\\ell_j$ intersect, or are parallel\n(or coincide). For a graph $G=([n],E)$, we say that a sequence $L$ is a {\\it\nrealization} of $G$ if $G\\subset G_L$. One of the main results of this paper is\nto provide a combinatorial characterization of graphs $G=([n],E)$ that have the\nfollowing property: For every {\\it generic} realization $L$ of $G$ that\nconsists of $n$ pairwise distinct lines, we have $G_L=K_n$, in which case the\nlines of $L$ are either all concurrent or all coplanar.\n  The general statements that we obtain about lines, apart from their\nindependent interest, turns out to be closely related to the notion of graph\nrigidity. The connection is established due to the so-called Elekes--Sharir\nframework, which allows us to transform the problem into an incidence problem\ninvolving lines in three dimensions. By exploiting the geometry of contacts\nbetween lines in 3D, we can obtain alternative, simpler, and more precise\ncharacterizations of the rigidity of graphs.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jul 2016 11:03:04 GMT"}], "update_date": "2016-07-15", "authors_parsed": [["Raz", "Orit E.", ""]]}, {"id": "1607.04336", "submitter": "Esther Ezra", "authors": "Esther Ezra and Micha Sharir", "title": "The Decision Tree Complexity for $k$-SUM is at most Nearly Quadratic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Following a recent improvement of Cardinal et al. on the complexity of a\nlinear decision tree for $k$-SUM, resulting in $O(n^3 \\log^3{n})$ linear\nqueries, we present a further improvement to $O(n^2 \\log^2{n})$ such queries.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jul 2016 22:17:11 GMT"}], "update_date": "2016-07-18", "authors_parsed": [["Ezra", "Esther", ""], ["Sharir", "Micha", ""]]}, {"id": "1607.04557", "submitter": "Alfonso Cevallos", "authors": "Alfonso Cevallos, Friedrich Eisenbrand, Rico Zenklusen", "title": "Local Search for Max-Sum Diversification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide simple and fast polynomial time approximation schemes (PTASs) for\nseveral variants of the max-sum diversification problem which, in its most\nbasic form, is as follows: Given n points p_1,...,p_n in R^d and an integer k,\nselect k points such that the average Euclidean distance between these points\nis maximized. This problem commonly appears in information retrieval and\nweb-search in order to select a diverse set of points from the input. In this\ncontext, it has recently received a lot of attention.\n  We present new techniques to analyze natural local search algorithms. This\nleads to a (1-O(1/k))-approximation for distances of negative type, even\nsubject to any matroid constraint of rank k, in time O(n k^2 log k), when\nassuming that distance evaluations and calls to the independence oracle are\nconstant time. Negative type distances include as special cases Euclidean\ndistances and many further natural distances. Our result easily transforms into\na PTAS and improves on the only previously known PTAS for this setting, which\nrelies on convex optimization techniques in an n-dimensional space and is\nimpractical for large data sets. In contrast, our procedure has an (optimal)\nlinear dependence on n.\n  Using generalized exchange properties of matroid intersection, we show that a\nPTAS can be obtained for matroid intersection constraints as well. Moreover,\nour techniques, being based on local search, are conceptually simple and allow\nfor various extensions. In particular, we get asymptotically optimal\nO(1)-approximations when combining the classic dispersion function with a\nmonotone submodular objective, which is a very common class of functions to\nmeasure diversity and relevance. This result leverages recent advances on local\nsearch techniques based on proxy functions to obtain optimal approximations for\nmonotone submodular function maximization subject to a matroid constraint.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jul 2016 15:38:02 GMT"}], "update_date": "2016-07-18", "authors_parsed": [["Cevallos", "Alfonso", ""], ["Eisenbrand", "Friedrich", ""], ["Zenklusen", "Rico", ""]]}, {"id": "1607.04755", "submitter": "Ioannis Psarros", "authors": "Georgia Avarikioti, Ioannis Z. Emiris, Loukas Kavouras, Ioannis\n  Psarros", "title": "High-dimensional approximate $r$-nets", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The construction of $r$-nets offers a powerful tool in computational and\nmetric geometry. We focus on high-dimensional spaces and present a new\nrandomized algorithm which efficiently computes approximate $r$-nets with\nrespect to Euclidean distance. For any fixed $\\epsilon>0$, the approximation\nfactor is $1+\\epsilon$ and the complexity is polynomial in the dimension and\nsubquadratic in the number of points. The algorithm succeeds with high\nprobability. More specifically, the best previously known LSH-based\nconstruction of Eppstein et al.\\ \\cite{EHS15} is improved in terms of\ncomplexity by reducing the dependence on $\\epsilon$, provided that $\\epsilon$\nis sufficiently small. Our method does not require LSH but, instead, follows\nValiant's \\cite{Val15} approach in designing a sequence of reductions of our\nproblem to other problems in different spaces, under Euclidean distance or\ninner product, for which $r$-nets are computed efficiently and the error can be\ncontrolled. Our result immediately implies efficient solutions to a number of\ngeometric problems in high dimension, such as finding the\n$(1+\\epsilon)$-approximate $k$th nearest neighbor distance in time subquadratic\nin the size of the input.\n", "versions": [{"version": "v1", "created": "Sat, 16 Jul 2016 15:53:07 GMT"}, {"version": "v2", "created": "Sat, 6 May 2017 12:47:36 GMT"}], "update_date": "2017-05-09", "authors_parsed": [["Avarikioti", "Georgia", ""], ["Emiris", "Ioannis Z.", ""], ["Kavouras", "Loukas", ""], ["Psarros", "Ioannis", ""]]}, {"id": "1607.04789", "submitter": "Thijs Laarhoven", "authors": "Thijs Laarhoven", "title": "Sieving for closest lattice vectors (with preprocessing)", "comments": "23rd Conference on Selected Areas in Cryptography (SAC), 2016", "journal-ref": "23rd International Conference on Selected Areas in Cryptography\n  (SAC), pp. 523-542, 2016", "doi": "10.1007/978-3-319-69453-5_28", "report-no": null, "categories": "cs.CR cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lattice-based cryptography has recently emerged as a prime candidate for\nefficient and secure post-quantum cryptography. The two main hard problems\nunderlying its security are the shortest vector problem (SVP) and the closest\nvector problem (CVP). Various algorithms have been studied for solving these\nproblems, and for SVP, lattice sieving currently dominates in terms of the\nasymptotic time complexity: one can heuristically solve SVP in time\n$2^{0.292d}$ in high dimensions $d$ [BDGL'16]. Although several SVP algorithms\ncan also be used to solve CVP, it is not clear whether this also holds for\nheuristic lattice sieving methods. The best time complexity for CVP is\ncurrently $2^{0.377d}$ [BGJ'14].\n  In this paper we revisit sieving algorithms for solving SVP, and study how\nthese algorithms can be modified to solve CVP and its variants as well. Our\nfirst method is aimed at solving one problem instance and minimizes the overall\ntime complexity for a single CVP instance with a time complexity of\n$2^{0.292d}$. Our second method minimizes the amortized time complexity for\nseveral instances on the same lattice, at the cost of a larger preprocessing\ncost. We can solve the closest vector problem with preprocessing (CVPP) with\n$2^{0.636d}$ space and preprocessing, in $2^{0.136d}$ time, while the query\ncomplexity can even be reduced to $2^{\\epsilon d}$ at the cost of preprocessing\ntime and memory complexities of $(1/\\epsilon)^{O(d)}$.\n  For easier variants of CVP, such as approximate CVP and bounded distance\ndecoding (BDD), we further show how the preprocessing method achieves even\nbetter complexities. For instance, we can solve approximate CVPP with large\napproximation factors $k$ with polynomial-sized advice in polynomial time if $k\n= \\Omega(\\sqrt{d/\\log d})$, heuristically closing the gap between the\ndecision-CVPP result of [AR'04] and the search-CVPP result of [DRS'14].\n", "versions": [{"version": "v1", "created": "Sat, 16 Jul 2016 18:59:19 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Laarhoven", "Thijs", ""]]}, {"id": "1607.04800", "submitter": "Michal Kleinbort", "authors": "Michal Kleinbort and Oren Salzman and Dan Halperin", "title": "Collision detection or nearest-neighbor search? On the computational\n  bottleneck in sampling-based motion planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The complexity of nearest-neighbor search dominates the asymptotic running\ntime of many sampling-based motion-planning algorithms. However, collision\ndetection is often considered to be the computational bottleneck in practice.\nExamining various asymptotically optimal planning algorithms, we characterize\nsettings, which we call NN-sensitive, in which the practical computational role\nof nearest-neighbor search is far from being negligible, i.e., the portion of\nrunning time taken up by nearest-neighbor search is comparable, or sometimes\neven greater than the portion of time taken up by collision detection. This\nreinforces and substantiates the claim that motion-planning algorithms could\nsignificantly benefit from efficient and possibly specifically-tailored\nnearest-neighbor data structures. The asymptotic (near) optimality of these\nalgorithms relies on a prescribed connection radius, defining a ball around a\nconfiguration $q$, such that $q$ needs to be connected to all other\nconfigurations in that ball. To facilitate our study, we show how to adapt this\nradius to non-Euclidean spaces, which are prevalent in motion planning. This\ntechnical result is of independent interest, as it enables to compare the\nradial-connection approach with the common alternative, namely, connecting each\nconfiguration to its $k$ nearest neighbors ($k$-NN). Indeed, as we demonstrate,\nthere are scenarios where using the radial connection scheme, a solution path\nof a specific cost is produced ten-fold (and more) faster than with $k$-NN.\n", "versions": [{"version": "v1", "created": "Sat, 16 Jul 2016 20:19:29 GMT"}, {"version": "v2", "created": "Wed, 20 Jul 2016 07:59:00 GMT"}, {"version": "v3", "created": "Sun, 30 Oct 2016 19:11:46 GMT"}], "update_date": "2016-11-01", "authors_parsed": [["Kleinbort", "Michal", ""], ["Salzman", "Oren", ""], ["Halperin", "Dan", ""]]}, {"id": "1607.04989", "submitter": "Jian Li", "authors": "Lingxiao Huang, Jian Li", "title": "Stochastic $k$-Center and $j$-Flat-Center Problems", "comments": "full version. fixed a few typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solving geometric optimization problems over uncertain data have become\nincreasingly important in many applications and have attracted a lot of\nattentions in recent years. In this paper, we study two important geometric\noptimization problems, the $k$-center problem and the $j$-flat-center problem,\nover stochastic/uncertain data points in Euclidean spaces. For the stochastic\n$k$-center problem, we would like to find $k$ points in a fixed dimensional\nEuclidean space, such that the expected value of the $k$-center objective is\nminimized. For the stochastic $j$-flat-center problem, we seek a $j$-flat\n(i.e., a $j$-dimensional affine subspace) such that the expected value of the\nmaximum distance from any point to the $j$-flat is minimized. We consider both\nproblems under two popular stochastic geometric models, the existential\nuncertainty model, where the existence of each point may be uncertain, and the\nlocational uncertainty model, where the location of each point may be\nuncertain. We provide the first PTAS (Polynomial Time Approximation Scheme) for\nboth problems under the two models. Our results generalize the previous results\nfor stochastic minimum enclosing ball and stochastic enclosing cylinder.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jul 2016 09:43:41 GMT"}, {"version": "v2", "created": "Sat, 10 Sep 2016 18:10:47 GMT"}], "update_date": "2016-09-13", "authors_parsed": [["Huang", "Lingxiao", ""], ["Li", "Jian", ""]]}, {"id": "1607.05112", "submitter": "Kyle Fox", "authors": "Glencora Borradaile and Erin Wolf Chambers and Kyle Fox and Amir\n  Nayyeri", "title": "Minimum cycle and homology bases of surface embedded graphs", "comments": "A preliminary version of this work was presented at the 32nd Annual\n  International Symposium on Computational Geometry", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problems of finding a minimum cycle basis (a minimum weight set\nof cycles that form a basis for the cycle space) and a minimum homology basis\n(a minimum weight set of cycles that generates the $1$-dimensional\n($\\mathbb{Z}_2$)-homology classes) of an undirected graph embedded on a\nsurface. The problems are closely related, because the minimum cycle basis of a\ngraph contains its minimum homology basis, and the minimum homology basis of\nthe $1$-skeleton of any graph is exactly its minimum cycle basis.\n  For the minimum cycle basis problem, we give a deterministic\n$O(n^\\omega+2^{2g}n^2+m)$-time algorithm for graphs embedded on an orientable\nsurface of genus $g$. The best known existing algorithms for surface embedded\ngraphs are those for general graphs: an $O(m^\\omega)$ time Monte Carlo\nalgorithm and a deterministic $O(nm^2/\\log n + n^2 m)$ time algorithm. For the\nminimum homology basis problem, we give a deterministic $O((g+b)^3 n \\log n +\nm)$-time algorithm for graphs embedded on an orientable or non-orientable\nsurface of genus $g$ with $b$ boundary components, assuming shortest paths are\nunique, improving on existing algorithms for many values of $g$ and $n$. The\nassumption of unique shortest paths can be avoided with high probability using\nrandomization or deterministically by increasing the running time of the\nhomology basis algorithm by a factor of $O(\\log n)$.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jul 2016 14:58:06 GMT"}], "update_date": "2016-07-19", "authors_parsed": [["Borradaile", "Glencora", ""], ["Chambers", "Erin Wolf", ""], ["Fox", "Kyle", ""], ["Nayyeri", "Amir", ""]]}, {"id": "1607.05347", "submitter": "Ingo Van Duijn", "authors": "Ingo van Duijn, Irina Kostitsyna, Marc van Kreveld, Maarten L\\\"offler", "title": "Critical Placements of a Square or Circle amidst Trajectories for\n  Junction Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by automated junction recognition in tracking data, we study a\nproblem of placing a square or disc of fixed size in an arrangement of lines or\nline segments in the plane. We let distances among the intersection points of\nthe lines and line segments with the square or circle define a clustering, and\nstudy the complexity of \\emph{critical} placements for this clustering. Here\ncritical means that arbitrarily small movements of the placement change the\nclustering.\n  A parameter $\\varepsilon$ defines the granularity of the clustering. Without\nany assumptions on $\\varepsilon$, the critical placements have a trivial\n$O(n^4)$ upper bound. When the square or circle has unit size and $0 <\n\\varepsilon < 1$ is given, we show a refined $O(n^2/\\varepsilon^2)$ bound,\nwhich is tight in the worst case.\n  We use our combinatorial bounds to design efficient algorithms to compute\njunctions. As a proof of concept for our algorithms we have a prototype\nimplementation that showcases their application in a basic visualization of a\nset of $n$ trajectories and their $k$ most important junctions.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jul 2016 22:52:01 GMT"}], "update_date": "2016-07-20", "authors_parsed": [["van Duijn", "Ingo", ""], ["Kostitsyna", "Irina", ""], ["van Kreveld", "Marc", ""], ["L\u00f6ffler", "Maarten", ""]]}, {"id": "1607.05527", "submitter": "Tillmann Miltzow", "authors": "\\'Edouard Bonnet, Tillmann Miltzow", "title": "An Approximation Algorithm for the Art Gallery Problem", "comments": "25 pages, 4 pages proof ideas, many figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a simple polygon $\\mathcal{P}$ on $n$ vertices, two points $x,y$ in\n$\\mathcal{P}$ are said to be visible to each other if the line segment between\n$x$ and $y$ is contained in $\\mathcal{P}$. The Point Guard Art Gallery problem\nasks for a minimum set $S$ such that every point in $\\mathcal{P}$ is visible\nfrom a point in $S$. The set $S$ is referred to as guards. Assuming integer\ncoordinates and a specific general position assumption, we present the first\n$O(\\log \\text{OPT})$-approximation algorithm for the point guard problem for\nsimple polygons. This algorithm combines ideas of a paper of Efrat and\nHar-Peled [Inf. Process. Lett. 2006] and Deshpande et. al. [WADS 2007]. We also\npoint out a mistake in the latter.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jul 2016 11:32:54 GMT"}], "update_date": "2016-07-20", "authors_parsed": [["Bonnet", "\u00c9douard", ""], ["Miltzow", "Tillmann", ""]]}, {"id": "1607.05547", "submitter": "Fabian Stehn", "authors": "Ulrike Gro{\\ss}e, Joachim Gudmundsson, Christian Knauer, Michiel Smid\n  and Fabian Stehn", "title": "Fast Algorithms for Diameter-Optimally Augmenting Paths and Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of augmenting an n-vertex graph embedded in a metric\nspace, by inserting one additional edge in order to minimize the diameter of\nthe resulting graph. We present exact algorithms for the cases when (i) the\ninput graph is a path, running in O(n \\log^3 n) time, and (ii) the input graph\nis a tree, running in O(n^2 \\log n) time. We also present an algorithm that\ncomputes a (1+\\eps)-approximation in O(n + 1/\\eps^3) time, for paths in R^d,\nwhere d is a constant.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jul 2016 12:36:49 GMT"}], "update_date": "2016-07-20", "authors_parsed": [["Gro\u00dfe", "Ulrike", ""], ["Gudmundsson", "Joachim", ""], ["Knauer", "Christian", ""], ["Smid", "Michiel", ""], ["Stehn", "Fabian", ""]]}, {"id": "1607.05739", "submitter": "Martin Derka", "authors": "Martin Derka, Alejandro L\\'opez-Ortiz, Daniela Maftuleac", "title": "Recognition of Triangulation Duals of Simple Polygons With and Without\n  Holes", "comments": "A full version of the submission to CCCG 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem of determining if a given graph corresponds to the\ndual of a triangulation of a simple polygon. This is a graph recognition\nproblem, where in our particular case we wish to recognize a graph which\ncorresponds to the dual of a triangulation of a simple polygon with or without\nholes and interior points. We show that the difficulty of this problem depends\ncritically on the amount of information given and we give a sharp boundary\nbetween the various tractable and intractable versions of the problem.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jul 2016 20:05:43 GMT"}], "update_date": "2016-07-21", "authors_parsed": [["Derka", "Martin", ""], ["L\u00f3pez-Ortiz", "Alejandro", ""], ["Maftuleac", "Daniela", ""]]}, {"id": "1607.05791", "submitter": "Ioana O. Bercea", "authors": "Ioana O. Bercea, Volkan Isler, Samir Khuller", "title": "Minimizing Uncertainty through Sensor Placement with Angle Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of sensor placement in environments in which\nlocalization is a necessity, such as ad-hoc wireless sensor networks that allow\nthe placement of a few anchors that know their location or sensor arrays that\nare tracking a target. In most of these situations, the quality of localization\ndepends on the relative angle between the target and the pair of sensors\nobserving it. In this paper, we consider placing a small number of sensors\nwhich ensure good angular $\\alpha$-coverage: given $\\alpha$ in $[0,\\pi/2]$, for\neach target location $t$, there must be at least two sensors $s_1$ and $s_2$\nsuch that the $\\angle(s_1 t s_2)$ is in the interval $[\\alpha, \\pi-\\alpha]$.\nOne of the main difficulties encountered in such problems is that since the\nconstraints depend on at least two sensors, building a solution must account\nfor the inherent dependency between selected sensors, a feature that generic\nSet Cover techniques do not account for. We introduce a general framework that\nguarantees an angular coverage that is arbitrarily close to $\\alpha$ for any\n$\\alpha <= \\pi/3$ and apply it to a variety of problems to get bi-criteria\napproximations. When the angular coverage is required to be at least a constant\nfraction of $\\alpha$, we obtain results that are strictly better than what\nstandard geometric Set Cover methods give. When the angular coverage is\nrequired to be at least $(1-1/\\delta)\\cdot\\alpha$, we obtain a\n$\\mathcal{O}(\\log \\delta)$- approximation for sensor placement with\n$\\alpha$-coverage on the plane. In the presence of additional distance or\nvisibility constraints, the framework gives a $\\mathcal{O}(\\log\\delta\\cdot\\log\nk_{OPT})$-approximation, where $k_{OPT}$ is the size of the optimal solution.\nWe also use our framework to give a $\\mathcal{O}(\\log \\delta)$-approximation\nthat ensures $(1-1/\\delta)\\cdot \\alpha$-coverage and covers every target within\ndistance $3R$.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jul 2016 00:52:59 GMT"}], "update_date": "2016-07-21", "authors_parsed": [["Bercea", "Ioana O.", ""], ["Isler", "Volkan", ""], ["Khuller", "Samir", ""]]}, {"id": "1607.05824", "submitter": "Haitao Wang", "authors": "Haitao Wang", "title": "On the Geodesic Centers of Polygonal Domains", "comments": "44 pages, 14 figures, a preliminary version to appear in ESA 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of computing Euclidean geodesic centers\nof a polygonal domain $\\mathcal{P}$ with a total of $n$ vertices. We discover\nmany interesting observations. We give a necessary condition for a point being\na geodesic center. We show that there is at most one geodesic center among all\npoints of $\\mathcal{P}$ that have topologically-equivalent shortest path maps.\nThis implies that the total number of geodesic centers is bounded by the\ncombinatorial size of the shortest path map equivalence decomposition of\n$\\mathcal{P}$, which is known to be $O(n^{10})$. One key observation is a\n$\\pi$-range property on shortest path lengths when points are moving. With\nthese observations, we propose an algorithm that computes all geodesic centers\nin $O(n^{11}\\log n)$ time. Previously, an algorithm of $O(n^{12+\\epsilon})$\ntime was known for this problem, for any $\\epsilon>0$.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jul 2016 04:54:07 GMT"}], "update_date": "2016-07-21", "authors_parsed": [["Wang", "Haitao", ""]]}, {"id": "1607.05994", "submitter": "Omer Gold", "authors": "Omer Gold and Micha Sharir", "title": "Dynamic Time Warping and Geometric Edit Distance: Breaking the Quadratic\n  Barrier", "comments": "Removing the $\\log\\log\\log n$ factor from the runtime bound that\n  appeared in previous versions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic Time Warping (DTW) and Geometric Edit Distance (GED) are basic\nsimilarity measures between curves or general temporal sequences (e.g., time\nseries) that are represented as sequences of points in some metric space $(X,\n\\mathrm{dist})$. The DTW and GED measures are massively used in various fields\nof computer science, computational biology, and engineering. Consequently, the\ntasks of computing these measures are among the core problems in P. Despite\nextensive efforts to find more efficient algorithms, the best-known algorithms\nfor computing the DTW or GED between two sequences of points in $X =\n\\mathbb{R}^d$ are long-standing dynamic programming algorithms that require\nquadratic runtime, even for the one-dimensional case $d = 1$, which is perhaps\none of the most used in practice.\n  In this paper, we break the nearly 50 years old quadratic time bound for\ncomputing DTW or GED between two sequences of $n$ points in $\\mathbb{R}$, by\npresenting deterministic algorithms that run in $O\\left( n^2 / \\log\\log n\n\\right)$ time. Our algorithms can be extended to work also for higher\ndimensional spaces $\\mathbb{R}^d$, for any constant $d$, when the underlying\ndistance-metric $\\mathrm{dist}$ is polyhedral (e.g., $L_1, L_\\infty$).\n", "versions": [{"version": "v1", "created": "Wed, 20 Jul 2016 15:15:44 GMT"}, {"version": "v2", "created": "Mon, 15 Aug 2016 13:53:52 GMT"}, {"version": "v3", "created": "Sat, 5 Nov 2016 11:07:42 GMT"}, {"version": "v4", "created": "Tue, 28 Jan 2020 10:45:55 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Gold", "Omer", ""], ["Sharir", "Micha", ""]]}, {"id": "1607.06136", "submitter": "Boris Aronov", "authors": "Boris Aronov and Edward Y. Miller and Micha Sharir", "title": "Eliminating Depth Cycles among Triangles in Three Dimensions", "comments": "28 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given $n$ pairwise openly disjoint triangles in 3-space, their vertical depth\nrelation may contain cycles. We show that, for any $\\varepsilon>0$, the\ntriangles can be cut into $O(n^{3/2+\\varepsilon})$ connected semi-algebraic\npieces, whose description complexity depends only on the choice of\n$\\varepsilon$, such that the depth relation among these pieces is now a proper\npartial order. This bound is nearly tight in the worst case. We are not aware\nof any previous study of this problem, in this full generality, with a\nsubquadratic bound on the number of pieces.\n  This work extends the recent study by two of the authors (Aronov,\nSharir~2018) on eliminating depth cycles among lines in 3-space. Our approach\nis again algebraic, and makes use of a recent variant of the polynomial\npartitioning technique, due to Guth, which leads to a recursive procedure for\ncutting the triangles. In contrast to the case of lines, our analysis here is\nconsiderably more involved, due to the two-dimensional nature of the objects\nbeing cut, so additional tools, from topology and algebra, need to be brought\nto bear.\n  Our result essentially settles a 35-year-old open problem in computational\ngeometry, motivated by hidden-surface removal in computer graphics.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jul 2016 22:11:48 GMT"}, {"version": "v2", "created": "Thu, 7 Mar 2019 04:39:12 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Aronov", "Boris", ""], ["Miller", "Edward Y.", ""], ["Sharir", "Micha", ""]]}, {"id": "1607.06274", "submitter": "Hubert Wagner Hubert Wagner", "authors": "Herbert Edelsbrunner, Hubert Wagner", "title": "Topological Data Analysis with Bregman Divergences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG math.AT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a finite set in a metric space, the topological analysis generalizes\nhierarchical clustering using a 1-parameter family of homology groups to\nquantify connectivity in all dimensions. The connectivity is compactly\ndescribed by the persistence diagram. One limitation of the current framework\nis the reliance on metric distances, whereas in many practical applications\nobjects are compared by non-metric dissimilarity measures. Examples are the\nKullback-Leibler divergence, which is commonly used for comparing text and\nimages, and the Itakura-Saito divergence, popular for speech and sound. These\nare two members of the broad family of dissimilarities called Bregman\ndivergences.\n  We show that the framework of topological data analysis can be extended to\ngeneral Bregman divergences, widening the scope of possible applications. In\nparticular, we prove that appropriately generalized Cech and Delaunay (alpha)\ncomplexes capture the correct homotopy type, namely that of the corresponding\nunion of Bregman balls. Consequently, their filtrations give the correct\npersistence diagram, namely the one generated by the uniformly growing Bregman\nballs. Moreover, we show that unlike the metric setting, the filtration of\nVietoris-Rips complexes may fail to approximate the persistence diagram. We\npropose algorithms to compute the thus generalized Cech, Vietoris-Rips and\nDelaunay complexes and experimentally test their efficiency. Lastly, we explain\ntheir surprisingly good performance by making a connection with discrete Morse\ntheory.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jul 2016 11:36:58 GMT"}], "update_date": "2016-07-22", "authors_parsed": [["Edelsbrunner", "Herbert", ""], ["Wagner", "Hubert", ""]]}, {"id": "1607.06344", "submitter": "Peter Franek", "authors": "Peter Franek, Marek Kr\\v{c}\\'al, Hubert Wagner", "title": "Solving equations and optimization problems with uncertainty", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of detecting zeros of continuous functions that are\nknown only up to an error bound, extending the earlier theoretical work with\nexplicit algorithms and experiments with an implementation. More formally, the\nrobustness of zero of a continuous map $f: X\\to \\mathbb{R}^n$ is the maximal\n$r>0$ such that each $g:X\\to\\mathbb{R}^n$ with $\\|f-g\\|_\\infty\\le r$ has a\nzero. We develop and implement an efficient algorithm approximating the\nrobustness of zero. Further, we show how to use the algorithm for approximating\nworst-case optima in optimization problems in which the feasible domain is\ndefined by equations that are only known approximately.\n  An important ingredient is an algorithm for deciding the topological\nextension problem based on computing cohomological obstructions to\nextendability and their persistence. We describe an explicit algorithm for the\nprimary and secondary obstruction, two stages of a sequence of algorithms with\nincreasing complexity. We provide experimental evidence that for random\nGaussian fields, the primary obstruction---a much less computationally\ndemanding test than the secondary obstruction---is typically sufficient for\napproximating robustness of zero.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jul 2016 14:38:38 GMT"}, {"version": "v2", "created": "Mon, 17 Apr 2017 17:07:33 GMT"}, {"version": "v3", "created": "Wed, 27 Sep 2017 13:30:27 GMT"}], "update_date": "2017-09-28", "authors_parsed": [["Franek", "Peter", ""], ["Kr\u010d\u00e1l", "Marek", ""], ["Wagner", "Hubert", ""]]}, {"id": "1607.06444", "submitter": "Krzysztof Fleszar", "authors": "Steven Chaplick, Krzysztof Fleszar, Fabian Lipp, Alexander Ravsky,\n  Oleg Verbitsky, Alexander Wolff", "title": "The Complexity of Drawing Graphs on Few Lines and Few Planes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that any graph admits a crossing-free straight-line drawing\nin $\\mathbb{R}^3$ and that any planar graph admits the same even in\n$\\mathbb{R}^2$. For a graph $G$ and $d \\in \\{2,3\\}$, let $\\rho^1_d(G)$ denote\nthe minimum number of lines in $\\mathbb{R}^d$ that together can cover all edges\nof a drawing of $G$. For $d=2$, $G$ must be planar. We investigate the\ncomplexity of computing these parameters and obtain the following hardness and\nalgorithmic results.\n  - For $d\\in\\{2,3\\}$, we prove that deciding whether $\\rho^1_d(G)\\le k$ for a\ngiven graph $G$ and integer $k$ is ${\\exists\\mathbb{R}}$-complete.\n  - Since $\\mathrm{NP}\\subseteq{\\exists\\mathbb{R}}$, deciding $\\rho^1_d(G)\\le\nk$ is NP-hard for $d\\in\\{2,3\\}$. On the positive side, we show that the problem\nis fixed-parameter tractable with respect to $k$.\n  - Since ${\\exists\\mathbb{R}}\\subseteq\\mathrm{PSPACE}$, both $\\rho^1_2(G)$ and\n$\\rho^1_3(G)$ are computable in polynomial space. On the negative side, we show\nthat drawings that are optimal with respect to $\\rho^1_2$ or $\\rho^1_3$\nsometimes require irrational coordinates.\n  - Let $\\rho^2_3(G)$ be the minimum number of planes in $\\mathbb{R}^3$ needed\nto cover a straight-line drawing of a graph $G$. We prove that deciding whether\n$\\rho^2_3(G)\\le k$ is NP-hard for any fixed $k \\ge 2$. Hence, the problem is\nnot fixed-parameter tractable with respect to $k$ unless\n$\\mathrm{P}=\\mathrm{NP}$.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jul 2016 19:50:36 GMT"}, {"version": "v2", "created": "Wed, 14 Jun 2017 08:56:26 GMT"}], "update_date": "2017-06-15", "authors_parsed": [["Chaplick", "Steven", ""], ["Fleszar", "Krzysztof", ""], ["Lipp", "Fabian", ""], ["Ravsky", "Alexander", ""], ["Verbitsky", "Oleg", ""], ["Wolff", "Alexander", ""]]}, {"id": "1607.06539", "submitter": "Tim Wylie", "authors": "Tim Wylie", "title": "An Interesting Gadget for Chain Pair Simplification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present an interesting gadget based on the chain pair\nsimplification problem under the discrete Fr\\'echet distance (CPS-3F), which\nallows the construction of arbitrarily long paths that must be chosen in the\nsimplification of the two curves. A pseudopolynomial time reduction from set\npartition is given as an example. For clarification, CPS-3F was recently shown\nto be in \\textbf{P}, and the reduction is merely to show how the gadget works.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jul 2016 02:07:17 GMT"}], "update_date": "2016-07-25", "authors_parsed": [["Wylie", "Tim", ""]]}, {"id": "1607.06665", "submitter": "Steven Chaplick", "authors": "Steven Chaplick, Minati De, Alexander Ravsky, Joachim Spoerhase", "title": "Approximation Schemes for Geometric Coverage Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In their seminal work, Mustafa and Ray (2009) showed that a wide class of\ngeometric set cover (SC) problems admit a PTAS via local search -- this is one\nof the most general approaches known for such problems. Their result applies if\na naturally defined \"exchange graph\" for two feasible solutions is planar and\nis based on subdividing this graph via a planar separator theorem due to\nFrederickson (1987). Obtaining similar results for the related maximum\nk-coverage problem (MC) seems non-trivial due to the hard cardinality\nconstraint. In fact, while Badanidiyuru, Kleinberg, and Lee (2012) have shown\n(via a different analysis) that local search yields a PTAS for two-dimensional\nreal halfspaces, they only conjectured that the same holds true for dimension\nthree. Interestingly, at this point it was already known that local search\nprovides a PTAS for the corresponding set cover case and this followed directly\nfrom the approach of Mustafa and Ray.\n  In this work we provide a way to address the above-mentioned issue. First, we\npropose a color-balanced version of the planar separator theorem. The resulting\nsubdivision approximates locally in each part the global distribution of the\ncolors. Second, we show how this roughly balanced subdivision can be employed\nin a more careful analysis to strictly obey the hard cardinality constraint.\nMore specifically, we obtain a PTAS for any \"planarizable\" instance of MC and\nthus essentially for all cases where the corresponding SC instance can be\ntackled via the approach of Mustafa and Ray. As a corollary, we confirm the\nconjecture of Badanidiyuru, Kleinberg, and Lee regarding real half spaces in\ndimension three. We feel that our ideas could also be helpful in other\ngeometric settings involving a cardinality constraint.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jul 2016 13:02:16 GMT"}, {"version": "v2", "created": "Wed, 31 Aug 2016 10:00:49 GMT"}, {"version": "v3", "created": "Thu, 23 Feb 2017 14:34:06 GMT"}], "update_date": "2017-02-24", "authors_parsed": [["Chaplick", "Steven", ""], ["De", "Minati", ""], ["Ravsky", "Alexander", ""], ["Spoerhase", "Joachim", ""]]}, {"id": "1607.07009", "submitter": "Subhrajit Bhattacharya", "authors": "Subhrajit Bhattacharya", "title": "A Search Algorithm for Simplicial Complexes", "comments": "25 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the `Basic S*' algorithm for computing shortest path through a\nmetric simplicial complex. In particular, given a metric graph, $G$, which is\nconstructed as a discrete representation of an underlying configuration space\n(a larger \"continuous\" space/manifold typically of dimension greater than one),\nwe consider the Rips complex, $\\mathcal{R}(G)$, associated with it. Such a\ncomplex, and hence shortest paths in it, represent the underlying metric space\nmore closely than what the graph does. While discrete graph representations of\ncontinuous spaces is convenient for motion planning in configuration spaces of\nrobotic systems, the metric induced in them by the ambient configuration space\nis significantly different from the metric of the configuration space itself.\nWe remedy this problem using the simplicial complex representation. Our\nalgorithm requires only an abstract graph, $G=(V,E)$, and a cost/length\nfunction, $d:E\\rightarrow \\mathbb{R}_+$, as inputs, and no global information\nsuch as an embedding or a global coordinate chart is required. The complexity\nof the Basic S* algorithm is comparable to that of Dijkstra's search, but, as\nthe results presented in this paper demonstrate, the shortest paths obtained\nusing the proposed algorithm represent/approximate the geodesic paths in the\noriginal metric space significantly more closely.\n", "versions": [{"version": "v1", "created": "Sun, 24 Jul 2016 08:00:40 GMT"}, {"version": "v2", "created": "Sat, 6 Aug 2016 20:47:32 GMT"}], "update_date": "2016-08-09", "authors_parsed": [["Bhattacharya", "Subhrajit", ""]]}, {"id": "1607.07129", "submitter": "Yuan Gao", "authors": "Yuan Gao and Alan L. Yuille", "title": "Exploiting Symmetry and/or Manhattan Properties for 3D Object Structure\n  Estimation from Single and Multiple Images", "comments": "Accepted to CVPR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many man-made objects have intrinsic symmetries and Manhattan structure. By\nassuming an orthographic projection model, this paper addresses the estimation\nof 3D structures and camera projection using symmetry and/or Manhattan\nstructure cues, which occur when the input is single- or multiple-image from\nthe same category, e.g., multiple different cars. Specifically, analysis on the\nsingle image case implies that Manhattan alone is sufficient to recover the\ncamera projection, and then the 3D structure can be reconstructed uniquely\nexploiting symmetry. However, Manhattan structure can be difficult to observe\nfrom a single image due to occlusion. To this end, we extend to the\nmultiple-image case which can also exploit symmetry but does not require\nManhattan axes. We propose a novel rigid structure from motion method,\nexploiting symmetry and using multiple images from the same category as input.\nExperimental results on the Pascal3D+ dataset show that our method\nsignificantly outperforms baseline methods.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jul 2016 02:36:51 GMT"}, {"version": "v2", "created": "Sat, 19 Nov 2016 19:28:56 GMT"}, {"version": "v3", "created": "Wed, 29 Mar 2017 08:15:16 GMT"}], "update_date": "2017-03-30", "authors_parsed": [["Gao", "Yuan", ""], ["Yuille", "Alan L.", ""]]}, {"id": "1607.07256", "submitter": "Subhas Nandy C.", "authors": "Ankush Acharyya, Subhas C. Nandy, Supantha Pandit, and Sasanka Roy", "title": "Covering segments with unit squares", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study several variations of line segment covering problem with\naxis-parallel unit squares in $I\\!\\!R^2$. A set $S$ of $n$ line segments is\ngiven. The objective is to find the minimum number of axis-parallel unit\nsquares which cover at least one end-point of each segment. The variations\ndepend on the orientation and length of the input segments. We prove some of\nthese problems to be NP-complete, and give constant factor approximation\nalgorithms for those problems. For some variations, we have polynomial time\nexact algorithms. For the general version of the problem, where the segments\nare of arbitrary length and orientation, and the squares are given as input, we\npropose a factor 16 approximation result based on multilevel linear programming\nrelaxation technique, which may be useful for solving some other problems.\nFurther, we show that our problems have connections with the problems studied\nby Arkin et al. 2015 on conflict-free covering problem. Our NP-completeness\nresults hold for more simplified types of objects than those of Arkin et al.\n2015.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jul 2016 13:13:18 GMT"}, {"version": "v2", "created": "Tue, 27 Sep 2016 06:06:09 GMT"}], "update_date": "2016-09-28", "authors_parsed": [["Acharyya", "Ankush", ""], ["Nandy", "Subhas C.", ""], ["Pandit", "Supantha", ""], ["Roy", "Sasanka", ""]]}, {"id": "1607.07364", "submitter": "Saeed Mehrabi", "authors": "Therese Biedl, Saeed Mehrabi, and Ziting Yu", "title": "Sliding k-Transmitters: Hardness and Approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A sliding k-transmitter in an orthogonal polygon P is a mobile guard that\ntravels back and forth along an orthogonal line segment s inside P. It can see\na point p in P if the perpendicular from p onto s intersects the boundary of P\nat most k times. We show that guarding an orthogonal polygon P with the minimum\nnumber of k-transmitters is NP-hard, for any fixed k>0, even if P is simple and\nmonotone. Moreover, we give an O(1)-approximation algorithm for this problem.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jul 2016 17:08:39 GMT"}], "update_date": "2016-07-26", "authors_parsed": [["Biedl", "Therese", ""], ["Mehrabi", "Saeed", ""], ["Yu", "Ziting", ""]]}, {"id": "1607.07378", "submitter": "Saeed Mehrabi", "authors": "Saeed Mehrabi", "title": "Unique Set Cover on Unit Disks and Unit Squares", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the Unique Set Cover problem on unit disks and unit squares. For a\ngiven set $P$ of $n$ points and a set $D$ of $m$ geometric objects both in the\nplane, the objective of the Unique Set Cover problem is to select a subset\n$D'\\subseteq D$ of objects such that every point in $P$ is covered by at least\none object in $D'$ and the number of points covered uniquely is maximized,\nwhere a point is covered uniquely if the point is covered by exactly one object\nin $D'$. In this paper, (i) we show that the Unique Set Cover is NP-hard on\nboth unit disks and unit squares, and (ii) we give a PTAS for this problem on\nunit squares by applying the mod-one approach of Chan and Hu (Comput. Geom.\n48(5), 2015).\n", "versions": [{"version": "v1", "created": "Mon, 25 Jul 2016 17:38:39 GMT"}], "update_date": "2016-07-26", "authors_parsed": [["Mehrabi", "Saeed", ""]]}, {"id": "1607.07421", "submitter": "Joseph O'Rourke", "authors": "Joseph O'Rourke", "title": "Unfolding Convex Polyhedra via Radially Monotone Cut Trees", "comments": "41 pages, 39 figures. V2 updated to cite in an addendum work on\n  \"self-approaching curves.\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A notion of \"radially monotone\" cut paths is introduced as an effective\nchoice for finding a non-overlapping edge-unfolding of a convex polyhedron.\nThese paths have the property that the two sides of the cut avoid overlap\nlocally as the cut is infinitesimally opened by the curvature at the vertices\nalong the path. It is shown that a class of planar, triangulated convex domains\nalways have a radially monotone spanning forest, a forest that can be found by\nan essentially greedy algorithm. This algorithm can be mimicked in 3D and\napplied to polyhedra inscribed in a sphere. Although the algorithm does not\nprovably find a radially monotone cut tree, it in fact does find such a tree\nwith high frequency, and after cutting unfolds without overlap. This\nperformance of a greedy algorithm leads to the conjecture that spherical\npolyhedra always have a radially monotone cut tree and unfold without overlap.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jul 2016 19:36:40 GMT"}, {"version": "v2", "created": "Fri, 29 Jul 2016 16:12:51 GMT"}], "update_date": "2016-08-01", "authors_parsed": [["O'Rourke", "Joseph", ""]]}, {"id": "1607.08449", "submitter": "Karthik C. S.", "authors": "Jean-Daniel Boissonnat and Karthik C. S.", "title": "An Efficient Representation for Filtrations of Simplicial Complexes", "comments": "A preliminary version appeared in SODA 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A filtration over a simplicial complex $K$ is an ordering of the simplices of\n$K$ such that all prefixes in the ordering are subcomplexes of $K$. Filtrations\nare at the core of Persistent Homology, a major tool in Topological Data\nAnalysis. In order to represent the filtration of a simplicial complex, the\nentire filtration can be appended to any data structure that explicitly stores\nall the simplices of the complex such as the Hasse diagram or the recently\nintroduced Simplex Tree [Algorithmica '14]. However, with the popularity of\nvarious computational methods that need to handle simplicial complexes, and\nwith the rapidly increasing size of the complexes, the task of finding a\ncompact data structure that can still support efficient queries is of great\ninterest.\n  In this paper, we propose a new data structure called the Critical Simplex\nDiagram (CSD) which is a variant of the Simplex Array List (SAL) [Algorithmica\n'17]. Our data structure allows one to store in a compact way the filtration of\na simplicial complex, and allows for the efficient implementation of a large\nrange of basic operations. Moreover, we prove that our data structure is\nessentially optimal with respect to the requisite storage space. Finally, we\nshow that the CSD representation admits fast construction algorithms for Flag\ncomplexes and relaxed Delaunay complexes.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jul 2016 13:30:20 GMT"}, {"version": "v2", "created": "Sat, 5 Nov 2016 13:26:00 GMT"}, {"version": "v3", "created": "Sun, 4 Feb 2018 15:55:30 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["Boissonnat", "Jean-Daniel", ""], ["S.", "Karthik C.", ""]]}, {"id": "1607.08809", "submitter": "Santiago Arroyave-Tobon", "authors": "Santiago Arroyave-Tob\\'on (I2M), Denis Teissandier (I2M), Vincent\n  Delos (I2M)", "title": "Adapting polytopes dimension for managing degrees of freedom in\n  tolerancing analysis", "comments": "in 14th CIRP Conference on Computer Aided Tolerancing (CAT), May\n  2016, Gothenburg, Sweden", "journal-ref": null, "doi": "10.1016/j.procir.2016.01.020", "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In tolerancing analysis, geometrical or contact specifications can be\nrepresented by polytopes. Due to the degrees of invariance of surfaces and that\nof freedom of joints, these operand polytopes are originally unbounded in most\nof the cases (i.e. polyhedra). Homri et al. proposed the introduction of\nvirtual boundaries (called cap half-spaces) over the unbounded displacements of\neach polyhedron to turn them into 6-polytopes. This decision was motivated by\nthe complexity that operating on polyhedra in R6 supposes. However, that\nstrategy has to face the multiplication of the number of cap half-spaces during\nthe computation of Minkowski sums. In general, the time for computing cap\nfacets is greater than for computing facets representing real limits of bounded\ndisplacements. In order to deal with that, this paper proposes the use of the\ntheory of screws to determine the set of displacements that defines the\npositioning of one surface in relation to another. This set of displacements\ndefines the subspace of R6 in which the polytopes of the respective surfaces\nhave to be projected and operated to avoid calculating facets and vertices\nalong the directions of unbounded displacements. With this new strategy it is\npossible to decrease the complexity of the Minkowski sums by reducing the\ndimension of the operands and consequently reducing the computation time. An\nexample illustrates the method and shows the time reduction during the\ncomputations.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jul 2016 08:25:23 GMT"}], "update_date": "2016-08-01", "authors_parsed": [["Arroyave-Tob\u00f3n", "Santiago", "", "I2M"], ["Teissandier", "Denis", "", "I2M"], ["Delos", "Vincent", "", "I2M"]]}]