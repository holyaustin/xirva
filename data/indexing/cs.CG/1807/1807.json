[{"id": "1807.00112", "submitter": "Tal Wagner", "authors": "Piotr Indyk and Tal Wagner", "title": "Approximate Nearest Neighbors in Limited Space", "comments": "COLT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the $(1+\\epsilon)$-approximate nearest neighbor search problem:\ngiven a set $X$ of $n$ points in a $d$-dimensional space, build a data\nstructure that, given any query point $y$, finds a point $x \\in X$ whose\ndistance to $y$ is at most $(1+\\epsilon) \\min_{x \\in X} \\|x-y\\|$ for an\naccuracy parameter $\\epsilon \\in (0,1)$. Our main result is a data structure\nthat occupies only $O(\\epsilon^{-2} n \\log(n) \\log(1/\\epsilon))$ bits of space,\nassuming all point coordinates are integers in the range $\\{-n^{O(1)} \\ldots\nn^{O(1)}\\}$, i.e., the coordinates have $O(\\log n)$ bits of precision. This\nimproves over the best previously known space bound of $O(\\epsilon^{-2} n\n\\log(n)^2)$, obtained via the randomized dimensionality reduction method of\nJohnson and Lindenstrauss (1984). We also consider the more general problem of\nestimating all distances from a collection of query points to all data points\n$X$, and provide almost tight upper and lower bounds for the space complexity\nof this problem.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jun 2018 02:33:15 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Indyk", "Piotr", ""], ["Wagner", "Tal", ""]]}, {"id": "1807.00253", "submitter": "Chaojing Duan", "authors": "Chaojing Duan, Siheng Chen, Jelena Kova\\v{c}evi\\'c", "title": "Weighted Multi-projection: 3D Point Cloud Denoising with Estimated\n  Tangent Planes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a collection of 3D points sampled from surfaces of objects, a 3D point\ncloud is widely used in robotics, autonomous driving and augmented reality. Due\nto the physical limitations of 3D sensing devices, 3D point clouds are usually\nnoisy, which influences subsequent computations, such as surface\nreconstruction, recognition and many others. To denoise a 3D point cloud, we\npresent a novel algorithm, called weighted multi-projection. Compared to many\nprevious works on denoising, instead of directly smoothing the coordinates of\n3D points, we use a two-fold smoothing: We first estimate a local tangent plane\nat each 3D point and then reconstruct each 3D point by weighted averaging of\nits projections on multiple tangent planes. We also provide the theoretical\nanalysis for the surface normal estimation and achieve a tighter bound than in\na previous work. We validate the empirical performance on the dataset of\nShapeNetCore and show that weighted multi-projection outperforms its\ncompetitors in all nine classes.\n", "versions": [{"version": "v1", "created": "Sun, 1 Jul 2018 01:42:04 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Duan", "Chaojing", ""], ["Chen", "Siheng", ""], ["Kova\u010devi\u0107", "Jelena", ""]]}, {"id": "1807.00399", "submitter": "Konstantinos Zampogiannis", "authors": "Konstantinos Zampogiannis, Cornelia Fermuller, Yiannis Aloimonos", "title": "cilantro: A Lean, Versatile, and Efficient Library for Point Cloud Data\n  Processing", "comments": null, "journal-ref": null, "doi": "10.1145/3240508.3243655", "report-no": null, "categories": "cs.CV cs.CG cs.GR cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce cilantro, an open-source C++ library for geometric and\ngeneral-purpose point cloud data processing. The library provides functionality\nthat covers low-level point cloud operations, spatial reasoning, various\nmethods for point cloud segmentation and generic data clustering, flexible\nalgorithms for robust or local geometric alignment, model fitting, as well as\npowerful visualization tools. To accommodate all kinds of workflows, cilantro\nis almost fully templated, and most of its generic algorithms operate in\narbitrary data dimension. At the same time, the library is easy to use and\nhighly expressive, promoting a clean and concise coding style. cilantro is\nhighly optimized, has a minimal set of external dependencies, and supports\nrapid development of performant point cloud processing software in a wide\nvariety of contexts.\n", "versions": [{"version": "v1", "created": "Sun, 1 Jul 2018 21:47:51 GMT"}, {"version": "v2", "created": "Tue, 17 Jul 2018 17:51:26 GMT"}, {"version": "v3", "created": "Fri, 16 Nov 2018 17:30:17 GMT"}], "update_date": "2018-11-19", "authors_parsed": [["Zampogiannis", "Konstantinos", ""], ["Fermuller", "Cornelia", ""], ["Aloimonos", "Yiannis", ""]]}, {"id": "1807.00484", "submitter": "Guilherme D. da Fonseca", "authors": "Sunil Arya, Guilherme D. da Fonseca, David M. Mount", "title": "Approximate Convex Intersection Detection with Applications to Width and\n  Minkowski Sums", "comments": null, "journal-ref": "ESA 2018", "doi": "10.4230/LIPIcs.ESA.2018.3", "report-no": null, "categories": "cs.CG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Approximation problems involving a single convex body in $d$-dimensional\nspace have received a great deal of attention in the computational geometry\ncommunity. In contrast, works involving multiple convex bodies are generally\nlimited to dimensions $d \\leq 3$ and/or do not consider approximation. In this\npaper, we consider approximations to two natural problems involving multiple\nconvex bodies: detecting whether two polytopes intersect and computing their\nMinkowski sum. Given an approximation parameter $\\varepsilon > 0$, we show how\nto independently preprocess two polytopes $A,B$ into data structures of size\n$O(1/\\varepsilon^{(d-1)/2})$ such that we can answer in polylogarithmic time\nwhether $A$ and $B$ intersect approximately. More generally, we can answer this\nfor the images of $A$ and $B$ under affine transformations. Next, we show how\nto $\\varepsilon$-approximate the Minkowski sum of two given polytopes defined\nas the intersection of $n$ halfspaces in $O(n \\log(1/\\varepsilon) +\n1/\\varepsilon^{(d-1)/2 + \\alpha})$ time, for any constant $\\alpha > 0$.\nFinally, we present a surprising impact of these results to a well studied\nproblem that considers a single convex body. We show how to\n$\\varepsilon$-approximate the width of a set of $n$ points in $O(n\n\\log(1/\\varepsilon) + 1/\\varepsilon^{(d-1)/2 + \\alpha})$ time, for any constant\n$\\alpha > 0$, a major improvement over the previous bound of roughly $O(n +\n1/\\varepsilon^{d-1})$ time.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 06:35:07 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Arya", "Sunil", ""], ["da Fonseca", "Guilherme D.", ""], ["Mount", "David M.", ""]]}, {"id": "1807.01217", "submitter": "Henri Riihim\\\"aki", "authors": "Henri Riihim\\\"aki, Wojciech Chacholski", "title": "Generalized persistence analysis based on stable rank invariant", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG math.AT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We believe three ingredients are needed for further progress in persistence\nand its use: invariants not relying on decomposition theorems to go beyond\n1-dimension, outcomes suitable for statistical analysis and a setup adopted for\nsupervised and machine learning. Stable rank, a continuous invariant for\nmultidimensional persistence, was introduced in W. Chacholski et al. -\nMultidimensional persistence and noise, 2017. In the current paper we continue\nthis work by demonstrating how one builds an efficient computational pipeline\naround this invariant and uses it in inference in case of one parameter. We\ndemonstrate some computational evidence of the statistical stability of stable\nrank. We also show how our framework can be used in supervised learning.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2018 14:21:26 GMT"}], "update_date": "2018-07-04", "authors_parsed": [["Riihim\u00e4ki", "Henri", ""], ["Chacholski", "Wojciech", ""]]}, {"id": "1807.01247", "submitter": "Fabrizio Montecchiani", "authors": "Giuseppe Liotta, Fabrizio Montecchiani, Alessandra Tappini", "title": "Ortho-polygon Visibility Representations of 3-connected 1-plane Graphs", "comments": "Appears in the Proceedings of the 26th International Symposium on\n  Graph Drawing and Network Visualization (GD 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An ortho-polygon visibility representation $\\Gamma$ of a $1$-plane graph $G$\n(OPVR of $G$) is an embedding preserving drawing that maps each vertex of $G$\nto a distinct orthogonal polygon and each edge of $G$ to a vertical or\nhorizontal visibility between its end-vertices. The representation $\\Gamma$ has\nvertex complexity $k$ if every polygon of $\\Gamma$ has at most $k$ reflex\ncorners. It is known that $3$-connected $1$-plane graphs admit an OPVR with\nvertex complexity at most twelve, while vertex complexity at least two may be\nrequired in some cases. In this paper, we reduce this gap by showing that\nvertex complexity five is always sufficient, while vertex complexity four may\nbe required in some cases. These results are based on the study of the\ncombinatorial properties of the B-, T-, and W-configurations in $3$-connected\n$1$-plane graphs. An implication of the upper bound is the existence of a\n$\\tilde{O}(n^\\frac{10}{7})$-time drawing algorithm that computes an OPVR of an\n$n$-vertex $3$-connected $1$-plane graph on an integer grid of size $O(n)\n\\times O(n)$ and with vertex complexity at most five.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 15:46:30 GMT"}, {"version": "v2", "created": "Thu, 2 Aug 2018 15:11:47 GMT"}], "update_date": "2018-08-03", "authors_parsed": [["Liotta", "Giuseppe", ""], ["Montecchiani", "Fabrizio", ""], ["Tappini", "Alessandra", ""]]}, {"id": "1807.01410", "submitter": "Pavol Hell", "authors": "Tomas Feder, Pavol Hell, and Carlos Subi", "title": "Distance-Two Colorings of Barnette Graphs", "comments": "Expanded version of CCCG 2018 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Barnette identified two interesting classes of cubic polyhedral graphs for\nwhich he conjectured the existence of a Hamiltonian cycle. Goodey proved the\nconjecture for the intersection of the two classes. We examine these classes\nfrom the point of view of distance-two colorings. A distance-two $r$-coloring\nof a graph $G$ is an assignment of $r$ colors to the vertices of $G$ so that\nany two vertices at distance at most two have different colors. Note that a\ncubic graph needs at least four colors. The distance-two four-coloring problem\nfor cubic planar graphs is known to be NP-complete. We claim the problem\nremains NP-complete for tri-connected bipartite cubic planar graphs, which we\ncall type-one Barnette graphs, since they are the first class identified by\nBarnette. By contrast, we claim the problem is polynomial for cubic plane\ngraphs with face sizes $3, 4, 5,$ or $6$, which we call type-two Barnette\ngraphs, because of their relation to Barnette's second conjecture. We call\nGoodey graphs those type-two Barnette graphs all of whose faces have size $4$\nor $6$. We fully describe all Goodey graphs that admit a distance-two\nfour-coloring, and characterize the remaining type-two Barnette graphs that\nadmit a distance-two four-coloring according to their face size.\n  For quartic plane graphs, the analogue of type-two Barnette graphs are graphs\nwith face sizes $3$ or $4$. For this class, the distance-two four-coloring\nproblem is also polynomial; in fact, we can again fully describe all colorable\ninstances -- there are exactly two such graphs.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2018 00:33:52 GMT"}], "update_date": "2018-07-05", "authors_parsed": [["Feder", "Tomas", ""], ["Hell", "Pavol", ""], ["Subi", "Carlos", ""]]}, {"id": "1807.01584", "submitter": "Aaron Becker", "authors": "Arne Schmidt, Sheryl Manzoor, Li Huang, Aaron T. Becker, and S\\'andor\n  P. Fekete", "title": "Efficient Parallel Self-Assembly Under Uniform Control Inputs", "comments": "21 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that by successively combining subassemblies, we can achieve\nsublinear construction times for \"staged\" assembly of micro-scale objects from\na large number of tiny particles, for vast classes of shapes; this is a\nsignificant advance in the context of programmable matter and self-assembly for\nbuilding high-yield micro-factories.The underlying model has particles moving\nunder the influence of uniform external forces until they hit an obstacle;\nparticles bond when forced together with a compatible particle. Previous work\nconsidered sequential composition of objects, resulting in construction time\nthat is linear in the number N of particles, which is inefficient for large N.\nOur progress implies critical speedup for constructible shapes; for convex\npolyominoes, even a constant construction time is possible. We also show that\nour construction process can be used for pipelining, resulting in an amortized\nconstant production time.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2018 13:56:43 GMT"}], "update_date": "2018-07-05", "authors_parsed": [["Schmidt", "Arne", ""], ["Manzoor", "Sheryl", ""], ["Huang", "Li", ""], ["Becker", "Aaron T.", ""], ["Fekete", "S\u00e1ndor P.", ""]]}, {"id": "1807.02740", "submitter": "Wentai Zhang", "authors": "Wentai Zhang, Haoliang Jiang, Zhangsihao Yang, Soji Yamakawa, Kenji\n  Shimada, Levent Burak Kara", "title": "Data-driven Upsampling of Point Clouds", "comments": "Preprint submitted to CAD", "journal-ref": "Computer-Aided Design, Volume 112, Pages 1-13, 2019", "doi": "10.1016/j.cad.2019.02.006.", "report-no": null, "categories": "cs.CV cs.CG cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High quality upsampling of sparse 3D point clouds is critically useful for a\nwide range of geometric operations such as reconstruction, rendering, meshing,\nand analysis. In this paper, we propose a data-driven algorithm that enables an\nupsampling of 3D point clouds without the need for hard-coded rules. Our\napproach uses a deep network with Chamfer distance as the loss function,\ncapable of learning the latent features in point clouds belonging to different\nobject categories. We evaluate our algorithm across different amplification\nfactors, with upsampling learned and performed on objects belonging to the same\ncategory as well as different categories. We also explore the desirable\ncharacteristics of input point clouds as a function of the distribution of the\npoint samples. Finally, we demonstrate the performance of our algorithm in\nsingle-category training versus multi-category training scenarios. The final\nproposed model is compared against a baseline, optimization-based upsampling\nmethod. Results indicate that our algorithm is capable of generating more\nuniform and accurate upsamplings.\n", "versions": [{"version": "v1", "created": "Sun, 8 Jul 2018 02:19:09 GMT"}, {"version": "v2", "created": "Fri, 28 Dec 2018 03:49:16 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Zhang", "Wentai", ""], ["Jiang", "Haoliang", ""], ["Yang", "Zhangsihao", ""], ["Yamakawa", "Soji", ""], ["Shimada", "Kenji", ""], ["Kara", "Levent Burak", ""]]}, {"id": "1807.02773", "submitter": "Reuven Cohen", "authors": "Shai Gul, Eitan Tiktinsky, Slava Shamshanov, Reuven Cohen", "title": "Online exploration outside a convex obstacle", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A watchman path is a path such that a direct line of sight exists between\neach point in some region and some point along the path. Here, we study the\nonline watchman path problem outside a convex polygon, i.e., in\n$\\mathbb{R}^2\\setminus \\Omega$, where $\\Omega$ is a convex polygon that is not\nknown in advance. We present an algorithm for the exploration of the region\noutside the polygon. We prove that the presented algorithms guarantees a\n$\\approx 22.77$ competitive ratio compared to the optimal offline watchman\npath.\n", "versions": [{"version": "v1", "created": "Sun, 8 Jul 2018 07:57:54 GMT"}, {"version": "v2", "created": "Tue, 20 Apr 2021 08:10:47 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Gul", "Shai", ""], ["Tiktinsky", "Eitan", ""], ["Shamshanov", "Slava", ""], ["Cohen", "Reuven", ""]]}, {"id": "1807.03464", "submitter": "Ravi Kumar Thakur", "authors": "Ravi Kumar Thakur and Snehasis Mukherjee", "title": "SceneEDNet: A Deep Learning Approach for Scene Flow Estimation", "comments": null, "journal-ref": "ICARCV (2018) 394-399", "doi": "10.1109/ICARCV.2018.8581172", "report-no": null, "categories": "cs.CV cs.CG cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating scene flow in RGB-D videos is attracting much interest of the\ncomputer vision researchers, due to its potential applications in robotics. The\nstate-of-the-art techniques for scene flow estimation, typically rely on the\nknowledge of scene structure of the frame and the correspondence between\nframes. However, with the increasing amount of RGB-D data captured from\nsophisticated sensors like Microsoft Kinect, and the recent advances in the\narea of sophisticated deep learning techniques, introduction of an efficient\ndeep learning technique for scene flow estimation, is becoming important. This\npaper introduces a first effort to apply a deep learning method for direct\nestimation of scene flow by presenting a fully convolutional neural network\nwith an encoder-decoder (ED) architecture. The proposed network SceneEDNet\ninvolves estimation of three dimensional motion vectors of all the scene points\nfrom sequence of stereo images. The training for direct estimation of scene\nflow is done using consecutive pairs of stereo images and corresponding scene\nflow ground truth. The proposed architecture is applied on a huge dataset and\nprovides meaningful results.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 03:26:55 GMT"}], "update_date": "2019-04-26", "authors_parsed": [["Thakur", "Ravi Kumar", ""], ["Mukherjee", "Snehasis", ""]]}, {"id": "1807.03655", "submitter": "Tamal Dey", "authors": "Tamal K. Dey", "title": "Computing Height Persistence and Homology Generators in $\\mathbb{R}^3$\n  Efficiently", "comments": null, "journal-ref": "SODA 2019", "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently it has been shown that computing the dimension of the first homology\ngroup $H_1(K)$ of a simplicial $2$-complex $K$ embedded linearly in\n$\\mathbb{R}^4$ is as hard as computing the rank of a sparse $0-1$ matrix. This\nputs a major roadblock to computing persistence and a homology basis\n(generators) for complexes embedded in $\\mathbb{R}^4$ and beyond in less than\nquadratic or even near-quadratic time. But, what about dimension three? It is\nknown that persistence for piecewise linear functions on a complex $K$ with $n$\nsimplices can be computed in $O(n\\log n)$ time and a set of generators of total\nsize $k$ can be computed in $O(n+k)$ time when $K$ is a graph or a surface\nlinearly embedded in $\\mathbb{R}^3$. But, the question for general simplicial\ncomplexes $K$ linearly embedded in $\\mathbb{R}^3$ is not completely settled. No\nalgorithm with a complexity better than that of the matrix multiplication is\nknown for this important case. We show that the persistence for {\\em height\nfunctions} on such complexes, hence called {\\em height persistence}, can be\ncomputed in $O(n\\log n)$ time. This allows us to compute a basis (generators)\nof $H_i(K)$, $i=1,2$, in $O(n\\log n+k)$ time where $k$ is the size of the\noutput. This improves significantly the current best bound of $O(n^{\\omega})$,\n$\\omega$ being the matrix multiplication exponent. We achieve these improved\nbounds by leveraging recent results on zigzag persistence in computational\ntopology, new observations about Reeb graphs, and some efficient geometric data\nstructures.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 14:02:35 GMT"}, {"version": "v2", "created": "Thu, 14 Mar 2019 18:47:53 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Dey", "Tamal K.", ""]]}, {"id": "1807.03678", "submitter": "Vincent Divol", "authors": "Vincent Divol, Wolfgang Polonik", "title": "On the choice of weight functions for linear representations of\n  persistence diagrams", "comments": null, "journal-ref": "J Appl. and Comput. Topology 3, 249-283 (2019)", "doi": "10.1007/s41468-019-00032-z", "report-no": null, "categories": "math.PR cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Persistence diagrams are efficient descriptors of the topology of a point\ncloud. As they do not naturally belong to a Hilbert space, standard statistical\nmethods cannot be directly applied to them. Instead, feature maps (or\nrepresentations) are commonly used for the analysis. A large class of feature\nmaps, which we call linear, depends on some weight functions, the choice of\nwhich is a critical issue. An important criterion to choose a weight function\nis to ensure stability of the feature maps with respect to Wasserstein\ndistances on diagrams. We improve known results on the stability of such maps,\nand extend it to general weight functions. We also address the choice of the\nweight function by considering an asymptotic setting; assume that\n$\\mathbb{X}_n$ is an i.i.d. sample from a density on $[0,1]^d$. For the\n\\v{C}ech and Rips filtrations, we characterize the weight functions for which\nthe corresponding feature maps converge as $n$ approaches infinity, and by\ndoing so, we prove laws of large numbers for the total persistences of such\ndiagrams. Those two approaches (stability and convergence) lead to the same\nsimple heuristic for tuning weight functions: if the data lies near a\n$d$-dimensional manifold, then a sensible choice of weight function is the\npersistence to the power $\\alpha$ with $\\alpha \\geq d$.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 14:38:49 GMT"}, {"version": "v2", "created": "Wed, 11 Jul 2018 07:18:50 GMT"}, {"version": "v3", "created": "Thu, 25 Apr 2019 12:47:34 GMT"}, {"version": "v4", "created": "Wed, 11 Nov 2020 12:34:43 GMT"}, {"version": "v5", "created": "Mon, 30 Nov 2020 10:52:35 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Divol", "Vincent", ""], ["Polonik", "Wolfgang", ""]]}, {"id": "1807.04181", "submitter": "Martin Wilhelm", "authors": "Martin Wilhelm", "title": "On error representation in exact-decisions number types", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accuracy-driven computation is a strategy widely used in exact-decisions\nnumber types for robust geometric algorithms. This work provides an overview on\nthe usage of error bounds in accuracy-driven computation, compares different\napproaches on the representation and computation of these error bounds and\npoints out some caveats. The stated claims are supported by experiments.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 15:01:39 GMT"}], "update_date": "2018-07-12", "authors_parsed": [["Wilhelm", "Martin", ""]]}, {"id": "1807.04818", "submitter": "Matthew Patitz", "authors": "Jerome Durand-Lose and Jacob Hendricks and Matthew J. Patitz and Ian\n  Perkins and Michael Sharp", "title": "Self-Assembly of 3-D Structures Using 2-D Folding Tiles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-assembly is a process which is ubiquitous in natural, especially\nbiological systems. It occurs when groups of relatively simple components\nspontaneously combine to form more complex structures. While such systems have\ninspired a large amount of research into designing theoretical models of\nself-assembling systems, and even laboratory-based implementations of them,\nthese artificial models and systems often tend to be lacking in one of the\npowerful features of natural systems (e.g. the assembly and folding of\nproteins), namely the dynamic reconfigurability of structures. In this paper,\nwe present a new mathematical model of self-assembly, based on the abstract\nTile Assembly Model (aTAM), called the Flexible Tile Assembly Model (FTAM). In\nthe FTAM, the individual components are 2-dimensional square tiles as in the\naTAM, but in the FTAM, bonds between the edges of tiles can be flexible,\nallowing bonds to flex and entire structures to reconfigure, thus allowing\n2-dimensional components to form 3-dimensional structures. We analyze the\npowers and limitations of FTAM systems by (1) demonstrating how flexibility can\nbe controlled to carefully build desired structures, and (2) showing how\nflexibility can be beneficially harnessed to form structures which can\n\"efficiently\" reconfigure into many different configurations and/or greatly\nvarying configurations. We also show that with such power comes a heavy burden\nin terms of computational complexity of simulation and prediction by proving\nthat, for important properties of FTAM systems, determining their existence is\nintractable, even for properties which are easily computed for systems in less\ndynamic models.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 20:57:16 GMT"}, {"version": "v2", "created": "Tue, 17 Jul 2018 18:07:26 GMT"}], "update_date": "2018-07-19", "authors_parsed": [["Durand-Lose", "Jerome", ""], ["Hendricks", "Jacob", ""], ["Patitz", "Matthew J.", ""], ["Perkins", "Ian", ""], ["Sharp", "Michael", ""]]}, {"id": "1807.04831", "submitter": "Jacob Hendricks PhD", "authors": "Jacob Hendricks, Joseph Opseth, Matthew Patitz, Scott Summers", "title": "Hierarchical Growth is Necessary and (Sometimes) Sufficient to\n  Self-Assemble Discrete Self-Similar Fractals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we prove that in the abstract Tile Assembly Model (aTAM), an\naccretion-based model which only allows for a single tile to attach to a\ngrowing assembly at each step, there are no tile assembly systems capable of\nself-assembling the discrete self-similar fractals known as the \"H\" and \"U\"\nfractals. We then show that in a related model which allows for hierarchical\nself-assembly, the 2-Handed Assembly Model (2HAM), there does exist a tile\nassembly systems which self-assembles the \"U\" fractal and conjecture that the\nsame holds for the \"H\" fractal. This is the first example of discrete self\nsimilar fractals which self-assemble in the 2HAM but not in the aTAM, providing\na direct comparison of the models and greater understanding of the power of\nhierarchical assembly.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 21:28:40 GMT"}, {"version": "v2", "created": "Tue, 17 Jul 2018 01:34:37 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Hendricks", "Jacob", ""], ["Opseth", "Joseph", ""], ["Patitz", "Matthew", ""], ["Summers", "Scott", ""]]}, {"id": "1807.04881", "submitter": "Diego Ihara", "authors": "Diego Ihara Centurion, Neshat Mohammadi and Anastasios Sidiropoulos", "title": "Algorithms for metric learning via contrastive embeddings", "comments": "22 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of supervised learning a metric space under\ndiscriminative constraints. Given a universe $X$ and sets ${\\cal S}, {\\cal\nD}\\subset {X \\choose 2}$ of similar and dissimilar pairs, we seek to find a\nmapping $f:X\\to Y$, into some target metric space $M=(Y,\\rho)$, such that\nsimilar objects are mapped to points at distance at most $u$, and dissimilar\nobjects are mapped to points at distance at least $\\ell$. More generally, the\ngoal is to find a mapping of maximum accuracy (that is, fraction of correctly\nclassified pairs). We propose approximation algorithms for various versions of\nthis problem, for the cases of Euclidean and tree metric spaces. For both of\nthese target spaces, we obtain fully polynomial-time approximation schemes\n(FPTAS) for the case of perfect information. In the presence of imperfect\ninformation we present approximation algorithms that run in quasipolynomial\ntime (QPTAS). Our algorithms use a combination of tools from metric embeddings\nand graph partitioning, that could be of independent interest.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jul 2018 01:35:40 GMT"}, {"version": "v2", "created": "Fri, 7 Dec 2018 03:22:40 GMT"}, {"version": "v3", "created": "Mon, 18 Mar 2019 23:12:57 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Centurion", "Diego Ihara", ""], ["Mohammadi", "Neshat", ""], ["Sidiropoulos", "Anastasios", ""]]}, {"id": "1807.05172", "submitter": "Hannah Schreiber", "authors": "Cl\\'ement Maria, Hannah Schreiber", "title": "Discrete Morse Theory for Computing Zigzag Persistence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG math.AT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a theoretical and computational framework to use discrete Morse\ntheory as an efficient preprocessing in order to compute zigzag persistent\nhomology.\n  From a zigzag filtration of complexes $(K_i)$, we introduce a zigzag Morse\nfiltration whose complexes $(A_i)$ are Morse reductions of the original\ncomplexes $(K_i)$, and we prove that they both have same persistent homology.\nThis zigzag Morse filtration generalizes the filtered Morse complex of\nMischaikow and Nanda, defined for standard persistence.\n  The maps in the zigzag Morse filtration are forward and backward inclusions,\nas is standard in zigzag persistence, as well as a new type of map inducing non\ntrivial changes in the boundary operator of the Morse complex. We study in\ndetails this last map, and design algorithms to compute the update both at the\ncomplex level and at the homology matrix level when computing zigzag\npersistence. We deduce an algorithm to compute the zigzag persistence of a\nfiltration that depends mostly on the number of critical cells of the\ncomplexes, and show experimentally that it performs better in practice.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jul 2018 16:43:28 GMT"}, {"version": "v2", "created": "Thu, 11 Jul 2019 12:55:06 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Maria", "Cl\u00e9ment", ""], ["Schreiber", "Hannah", ""]]}, {"id": "1807.05428", "submitter": "Israela Solomon", "authors": "Israela Solomon and Dan Halperin", "title": "Motion Planning for Multiple Unit-Ball Robots in $\\mathbb{R}^d$", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a decoupled algorithm for motion planning for a collection of\nunit-balls moving among polyhedral obstacles in $\\mathbb{R}^d$, for any $d \\ge\n2$. We assume that the robots have revolving areas in the vicinity of their\nstart and target positions: Revolving areas are regions where robots can\nmaneuver in order to give way to another moving robot. Given that this\nassumption is fulfilled, the algorithm is complete, namely it is guaranteed to\nfind a solution or report that none exists. A key goal in our design is to make\nthe revolving areas as economical as possible and in particular to allow\ndifferent revolving areas to overlap. This makes the analysis rather involved\nbut in return makes the algorithm conceptually fairly simple. We show that for\nthe case of $m$ unit-discs moving among polygonal obstacles of total complexity\n$n$ in $\\mathbb{R}^2$, the algorithm can be executed in $O(n^2m +\nm(m+n)\\log(m+n))$ time. We implemented the algorithm for this case and tested\nit on several scenarios, for which we show experimental results for up to\n$1000$ robots. Finally, we address the problem of choosing the order of\nexecution of the paths in decoupled algorithms that locally solve interferences\nand show that finding the optimal order of execution is NP-hard. This motivated\nus to develop a heuristic for choosing the order; we describe the heuristic and\ndemonstrate its effectiveness in certain scenarios.\n", "versions": [{"version": "v1", "created": "Sat, 14 Jul 2018 18:49:56 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Solomon", "Israela", ""], ["Halperin", "Dan", ""]]}, {"id": "1807.06053", "submitter": "Senja Barthel", "authors": "Senja Barthel", "title": "Note on minimal number of skewed unit cells for periodic distance\n  calculation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How many copies of a parallelepiped are needed to ensure that for every point\nin the parallelepiped a copy of each other point exists, such that the distance\nbetween them equals the distance of the pair of points when the opposite sites\nof the parallelepiped are identified? This question is answered in Euclidean\nspace by constructing the smallest domain that fulfills the above condition. We\nalso describe how to obtain all primitive cells of a lattice (i.e., closures of\nfundamental domains) that realise the smallest number of copies needed and give\nthem explicitly in 2D and 3D.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 18:40:58 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Barthel", "Senja", ""]]}, {"id": "1807.06279", "submitter": "David Orden", "authors": "Omar Aloui, David Orden, Landolf Rhode-Barbarigos", "title": "Generation of planar tensegrity structures through cellular\n  multiplication", "comments": "29 pages, 19 figures, to appear at Applied Mathematical Modeling", "journal-ref": "Applied Mathematical Modelling 64 (2018), 71-92", "doi": "10.1016/j.apm.2018.07.024", "report-no": null, "categories": "cs.CE cs.CG cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tensegrity structures are frameworks in a stable self-equilibrated prestress\nstate that have been applied in various fields in science and engineering.\nResearch into tensegrity structures has resulted in reliable techniques for\ntheir form finding and analysis. However, most techniques address topology and\nform separately. This paper presents a bio-inspired approach for the combined\ntopology identification and form finding of planar tensegrity structures.\nTensegrity structures are generated using tensegrity cells (elementary stable\nself-stressed units that have been proven to compose any tensegrity structure)\naccording to two multiplication mechanisms: cellular adhesion and fusion.\nChanges in the dimension of the self-stress space of the structure are found to\ndepend on the number of adhesion and fusion steps conducted as well as on the\ninteraction among the cells composing the system. A methodology for defining a\nbasis of the self-stress space is also provided. Through the definition of the\nequilibrium shape, the number of nodes and members as well as the number of\nself-stress states, the cellular multiplication method can integrate design\nconsiderations, providing great flexibility and control over the tensegrity\nstructure designed and opening the door to the development of a whole new realm\nof planar tensegrity systems with controllable characteristics.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 08:44:37 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Aloui", "Omar", ""], ["Orden", "David", ""], ["Rhode-Barbarigos", "Landolf", ""]]}, {"id": "1807.06435", "submitter": "Josue Tonelli-Cueto", "authors": "Peter B\\\"urgisser and Felipe Cucker and Josu\\'e Tonelli-Cueto", "title": "Computing the Homology of Semialgebraic Sets I: Lax Formulas", "comments": "43 pages", "journal-ref": "Found Comput Math 20, 71-118 (2020)", "doi": "10.1007/s10208-019-09418-y", "report-no": null, "categories": "cs.CG math.AG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe and analyze an algorithm for computing the homology (Betti\nnumbers and torsion coefficients) of closed semialgebraic sets given by Boolean\nformulas without negations over lax polynomial inequalities. The algorithm\nworks in weak exponential time. This means that outside a subset of data having\nexponentially small measure, the cost of the algorithm is single exponential in\nthe size of the data.\n  All previous algorithms solving this problem have doubly exponential\ncomplexity (and this is so for almost all input data). Our algorithm thus\nrepresents an exponential acceleration over state-of-the-art algorithms for all\ninput data outside a set that vanishes exponentially fast.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 12:53:32 GMT"}, {"version": "v2", "created": "Thu, 6 Dec 2018 11:31:02 GMT"}, {"version": "v3", "created": "Tue, 19 Mar 2019 13:38:23 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["B\u00fcrgisser", "Peter", ""], ["Cucker", "Felipe", ""], ["Tonelli-Cueto", "Josu\u00e9", ""]]}, {"id": "1807.06580", "submitter": "Joshua Zahl", "authors": "Joshua Zahl", "title": "Counting higher order tangencies for plane curves", "comments": "8 pages, 0 figures. v2: to appear in Combin. Probab. Comput", "journal-ref": "Combinator. Probab. Comp. 29 (2020) 310-317", "doi": "10.1017/S096354831900035X", "report-no": null, "categories": "math.CO cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that $n$ plane algebraic curves determine $O(n^{(k+2)/(k+1)})$\npoints of $k$-th order tangency. This generalizes an earlier result of\nEllenberg, Solymosi, and Zahl on the number of (first order) tangencies\ndetermined by $n$ plane algebraic curves.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 17:50:09 GMT"}, {"version": "v2", "created": "Tue, 3 Dec 2019 23:43:29 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Zahl", "Joshua", ""]]}, {"id": "1807.06845", "submitter": "Josep Diaz Prof", "authors": "Josep Diaz, Mordecai Golin", "title": "Smoothed Analysis of the Expected Number of Maximal Points in Two\n  Dimensions", "comments": "95 pages, 35 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The {\\em Maximal} points in a set S are those that aren't {\\em dominated} by\nany other point in S. Such points arise in multiple application settings in\nwhich they are called by a variety of different names, e.g., maxima, Pareto\noptimums, skylines. Because of their ubiquity, there is a large literature on\nthe {\\em expected} number of maxima in a set S of n points chosen IID from some\ndistribution. Most such results assume that the underlying distribution is\nuniform over some spatial region and strongly use this uniformity in their\nanalysis. This work was initially motivated by the question of how this\nexpected number changes if the input distribution is perturbed by random noise.\nMore specifically, let Ballp denote the uniform distribution from the 2-d unit\nLp ball, delta Ballq denote the 2-d Lq-ball, of radius delta and Ballpq be the\nconvolution of the two distributions, i.e., a point v in Ballp is reported with\nan error chosen from delta Ballq. The question is how the expected number of\nmaxima change as a function of delta. Although the original motivation is for\nsmall delta the problem is well defined for any delta and our analysis treats\nthe general case. More specifically, we study, as a function of n,\\delta, the\nexpected number of maximal points when the n points in S are chosen IID from\ndistributions of the type Ballpq where p,q in {1,2,infty} for delta > 0 and\nalso of the type Ballp infty-q, where q in [1,infty) for delta > 0.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 10:17:52 GMT"}], "update_date": "2018-07-19", "authors_parsed": [["Diaz", "Josep", ""], ["Golin", "Mordecai", ""]]}, {"id": "1807.06933", "submitter": "Sandor Kisfaludi-Bak", "authors": "Mark de Berg, Hans L. Bodlaender, S\\'andor Kisfaludi-Bak, Sudeshna\n  Kolay", "title": "An ETH-Tight Exact Algorithm for Euclidean TSP", "comments": "To appear in FOCS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study exact algorithms for {\\sc Euclidean TSP} in $\\mathbb{R}^d$. In the\nearly 1990s algorithms with $n^{O(\\sqrt{n})}$ running time were presented for\nthe planar case, and some years later an algorithm with $n^{O(n^{1-1/d})}$\nrunning time was presented for any $d\\geq 2$. Despite significant interest in\nsubexponential exact algorithms over the past decade, there has been no\nprogress on {\\sc Euclidean TSP}, except for a lower bound stating that the\nproblem admits no $2^{O(n^{1-1/d-\\epsilon})}$ algorithm unless ETH fails. Up to\nconstant factors in the exponent, we settle the complexity of {\\sc Euclidean\nTSP} by giving a $2^{O(n^{1-1/d})}$ algorithm and by showing that a\n$2^{o(n^{1-1/d})}$ algorithm does not exist unless ETH fails.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 13:52:28 GMT"}, {"version": "v2", "created": "Fri, 3 Aug 2018 09:48:44 GMT"}], "update_date": "2018-08-06", "authors_parsed": [["de Berg", "Mark", ""], ["Bodlaender", "Hans L.", ""], ["Kisfaludi-Bak", "S\u00e1ndor", ""], ["Kolay", "Sudeshna", ""]]}, {"id": "1807.07920", "submitter": "Nicholas` Cavanna", "authors": "Nicholas J. Cavanna, Donald R. Sheehy", "title": "The Generalized Persistent Nerve Theorem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AT cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper a parameterized generalization of a good cover filtration is\nintroduced called an {\\epsilon}-good cover, defined as a cover filtration in\nwhich the reduced homology groups of the image of the inclusions between the\nintersections of the cover filtration at two scales {\\epsilon} apart are\ntrivial. Assuming that one has an {\\epsilon}-good cover filtration of a finite\nsimplicial filtration, we prove a tight bound on the bottleneck distance\nbetween the persistence diagrams of the nerve filtration and the simplicial\nfiltration that is linear with respect to {\\epsilon} and the homology\ndimension. This bound is the result of a computable chain map from the nerve\nfiltration to the space filtration's chain complexes at a further scale.\nQuantitative guarantees for covers that are not good are useful for when one is\nworking a non-convex metric space, or one has more simplicial covers that are\nnot the result of triangulations of metric balls. The Persistent Nerve Lemma is\nalso a corollary of our theorem as good covers are 0-good covers. Lastly, a\ntechnique is introduced that symmetrizes the asymmetric interleaving used to\nprove the bound by shifting the nerve filtration's persistence module,\nimproving the interleaving constant by a factor of 2.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jul 2018 16:25:52 GMT"}], "update_date": "2018-07-23", "authors_parsed": [["Cavanna", "Nicholas J.", ""], ["Sheehy", "Donald R.", ""]]}, {"id": "1807.07924", "submitter": "Nabil Mustafa", "authors": "Monika Csikos and Andrey Kupavskii and Nabil H. Mustafa", "title": "Optimal Bounds on the VC-dimension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The VC-dimension of a set system is a way to capture its complexity and has\nbeen a key parameter studied extensively in machine learning and geometry\ncommunities. In this paper, we resolve two longstanding open problems on\nbounding the VC-dimension of two fundamental set systems: $k$-fold\nunions/intersections of half-spaces, and the simplices set system. Among other\nimplications, it settles an open question in machine learning that was first\nstudied in the 1989 foundational paper of Blumer, Ehrenfeucht, Haussler and\nWarmuth as well as by Eisenstat and Angluin and Johnson.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jul 2018 16:32:22 GMT"}], "update_date": "2018-07-23", "authors_parsed": [["Csikos", "Monika", ""], ["Kupavskii", "Andrey", ""], ["Mustafa", "Nabil H.", ""]]}, {"id": "1807.08078", "submitter": "Benjamin Raichel", "authors": "Chenglin Fan, Benjamin Raichel, Gregory Van Buskirk", "title": "Metric Violation Distance: Revisited and Extended", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Metric data plays an important role in various settings such as metric-based\nindexing, clustering, classification, and approximation algorithms in general.\nDue to measurement error, noise, or an inability to completely gather all the\ndata, a collection of distances may not satisfy the basic metric requirements,\nmost notably the triangle inequality. Thus last year the authors introduced the\nMetric Violation Distance (MVD) problem, where the input is an undirected and\npositively-weighted complete graph, and the goal is to identify a minimum\ncardinality subset of edges whose weights can be modified such that the\nresulting graph is its own metric completion. This problem was shown to be\nAPX-hard, and moreover an $O(OPT^{1/3})$-approximation was shown, where $OPT$\nis the size of the optimal solution.\n  In this paper we introduce the Generalized Metric Violation Distance (GMVD)\nproblem, where the goal is the same, but the input graph is no longer required\nto be complete. For GMVD we prove stronger hardness results, and provide a\nsignificantly faster approximation algorithm with an improved approximation\nguarantee. In particular, we give an approximation-preserving reduction from\nthe well studied MultiCut problem, which is hard to approximate within any\nconstant factor assuming the Unique Games Conjecture. Our approximation factor\ndepends on deficit values, which for a given cycle is the largest single edge\nweight minus the sum of the weights of all its other edges. Note that no cycle\nhas positive deficit in a metric complete graph. We give an $O(c \\log\nn)$-approximation algorithm for \\gmvd, where $c$ is the number of distinct\npositive cycle deficit values in the input graph.\n", "versions": [{"version": "v1", "created": "Sat, 21 Jul 2018 03:41:52 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Fan", "Chenglin", ""], ["Raichel", "Benjamin", ""], ["Van Buskirk", "Gregory", ""]]}, {"id": "1807.08208", "submitter": "Nicholas` Cavanna", "authors": "Nicholas J. Cavanna, Donald R. Sheehy", "title": "Adaptive Metrics for Adaptive Samples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider adaptive sampling's local-feature size, used in\nsurface reconstruction and geometric inference, with respect to an arbitrary\nlandmark set rather than the medial axis and relate it to a path-based adaptive\nmetric on Euclidean space. We prove a near-duality between adaptive samples in\nthe Euclidean metric space and uniform samples in this alternate metric space\nwhich results in topological interleavings between the offsets generated by\nthis metric and those generated by an linear approximation of it. After\nsmoothing the distance function associated to the adaptive metric, we apply a\nresult from the theory of critical points of distance functions to the\ninterleaved spaces which yields a computable homology inference scheme assuming\none has Hausdorff-close samples of the domain and the landmark set.\n", "versions": [{"version": "v1", "created": "Sat, 21 Jul 2018 22:48:11 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Cavanna", "Nicholas J.", ""], ["Sheehy", "Donald R.", ""]]}, {"id": "1807.08304", "submitter": "Pascal Laube", "authors": "Pascal Laube, Matthias O. Franz, Georg Umlauf", "title": "Deep Learning Parametrization for B-Spline Curve Approximation", "comments": "Accepted at 3DV 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a method using deep learning to compute\nparametrizations for B-spline curve approximation. Existing methods consider\nthe computation of parametric values and a knot vector as separate problems. We\npropose to train interdependent deep neural networks to predict parametric\nvalues and knots. We show that it is possible to include B-spline curve\napproximation directly into the neural network architecture. The resulting\nparametrizations yield tight approximations and are able to outperform\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sun, 22 Jul 2018 15:41:21 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Laube", "Pascal", ""], ["Franz", "Matthias O.", ""], ["Umlauf", "Georg", ""]]}, {"id": "1807.08350", "submitter": "Guillermo Laguna", "authors": "Guillermo J. Laguna and Sourabh Bhattacharya", "title": "Tracking Mobile Intruders in an Art Gallery: Guard Deployment\n  Strategies, Fundamental Limitations, and Performance Guarantees", "comments": "21 pages, submitted to Discrete & Computational Geometry journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of tracking mobile intruders in a polygonal\nenvironment. We assume that a team of diagonal guards is deployed inside the\npolygon to provide mobile coverage. First, we formulate the problem of tracking\na mobile intruder inside a polygonal environment as a multi-robot task\nallocation (MRTA) problem. Leveraging on guard deployment strategies in art\ngallery problems for mobile coverage, we show that the problem of finding the\nminimum speed of guards to persistently track a single mobile intruder is\nNP-hard. Next, for a given maximum speed of the intruder and the guards, we\npropose a technique to partition a polygon, and compute a feasible allocation\nof guards to the partitions. We prove the correctness of the proposed\nalgorithm, and show its completeness for a specific class of inputs. We\nclassify the guards based on the structural properties of the partitions\nallocated to them. Based on the classification, we propose motion strategy for\nthe guards to track the mobile intruder when it is located in the partition\nallocated to the guard. Finally, we extend the proposed technique to address\nguard deployment and allocation strategies for non-simple polygons and multiple\nintruders.\n", "versions": [{"version": "v1", "created": "Sun, 22 Jul 2018 19:18:28 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Laguna", "Guillermo J.", ""], ["Bhattacharya", "Sourabh", ""]]}, {"id": "1807.08354", "submitter": "Guillermo Laguna", "authors": "Guillermo J. Laguna and Sourabh Bhattacharya", "title": "Adaptive Target Tracking with a Mixed Team of Static and Mobile Guards:\n  Deployment and Activation Strategies", "comments": "Submitted to the Autonomous Robots journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work explores a variation of the art gallery problem in which a team of\nstatic and mobile guards track a mobile intruder with unknown maximum speed.\nFirst, we present an algorithm to identify {\\it candidate vertices} in a\npolygon at which either static guards can be placed or they can serve as\nendpoints of the trajectory of mobile guards. Based on the triangulation of the\npolygon and the deployment of the guards we propose an allocation technique for\nthe guards, such that each one of them is assigned to guard a subregion of the\nenvironment when the intruder is inside it. The allocation strategy leads to a\nclassification of the guards based on their task and coordination requirements.\nNext, we present an activation strategy for the static guards that is adaptive\nto the instantaneous speed of the intruder. The deployment and the activation\ntechnique guarantee that a variable speed intruder is successfully tracked.\nSimulation results are presented to validate the efficacy of the proposed\ntechniques.\n", "versions": [{"version": "v1", "created": "Sun, 22 Jul 2018 19:35:54 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Laguna", "Guillermo J.", ""], ["Bhattacharya", "Sourabh", ""]]}, {"id": "1807.08405", "submitter": "Trent Houliston", "authors": "Trent Houliston and Stephan K. Chalup", "title": "Visual Mesh: Real-time Object Detection Using Constant Sample Density", "comments": "12 pages, 6 figures, RoboCup International Symposium 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CG cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an enhancement of convolutional neural networks for\nobject detection in resource-constrained robotics through a geometric input\ntransformation called Visual Mesh. It uses object geometry to create a graph in\nvision space, reducing computational complexity by normalizing the pixel and\nfeature density of objects. The experiments compare the Visual Mesh with\nseveral other fast convolutional neural networks. The results demonstrate\nexecution times sixteen times quicker than the fastest competitor tested, while\nachieving outstanding accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2018 02:21:31 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Houliston", "Trent", ""], ["Chalup", "Stephan K.", ""]]}, {"id": "1807.08446", "submitter": "Ibrahim Jubran", "authors": "Ibrahim Jubran and Dan Feldman", "title": "Aligning Points to Lines: Provable Approximations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We suggest a new optimization technique for minimizing the sum $\\sum_{i=1}^n\nf_i(x)$ of $n$ non-convex real functions that satisfy a property that we call\npiecewise log-Lipschitz. This is by forging links between techniques in\ncomputational geometry, combinatorics and convex optimization. As an example\napplication, we provide the first constant-factor approximation algorithms\nwhose running-time is polynomial in $n$ for the fundamental problem of\n\\emph{Points-to-Lines alignment}: Given $n$ points $p_1,\\cdots,p_n$ and $n$\nlines $\\ell_1,\\cdots,\\ell_n$ on the plane and $z>0$, compute the matching\n$\\pi:[n]\\to[n]$ and alignment (rotation matrix $R$ and a translation vector\n$t$) that minimize the sum of Euclidean distances $\\sum_{i=1}^n\n\\mathrm{dist}(Rp_i-t,\\ell_{\\pi(i)})^z$ between each point to its corresponding\nline.\n  This problem is non-trivial even if $z=1$ and the matching $\\pi$ is given. If\n$\\pi$ is given, the running time of our algorithms is $O(n^3)$, and even\nnear-linear in $n$ using core-sets that support: streaming, dynamic, and\ndistributed parallel computations in poly-logarithmic update time.\nGeneralizations for handling e.g. outliers or pseudo-distances such as\n$M$-estimators for the problem are also provided.\n  Experimental results and open source code show that our provable algorithms\nimprove existing heuristics also in practice. A companion demonstration video\nin the context of Augmented Reality shows how such algorithms may be used in\nreal-time systems.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2018 06:45:15 GMT"}, {"version": "v2", "created": "Tue, 16 Oct 2018 09:10:27 GMT"}, {"version": "v3", "created": "Mon, 9 Sep 2019 16:47:33 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Jubran", "Ibrahim", ""], ["Feldman", "Dan", ""]]}, {"id": "1807.08699", "submitter": "Tim Ophelders", "authors": "Kevin Buchin, Tim Ophelders, Bettina Speckmann", "title": "SETH Says: Weak Fr\\'echet Distance is Faster, but only if it is\n  Continuous and in One Dimension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show by reduction from the Orthogonal Vectors problem that algorithms with\nstrongly subquadratic running time cannot approximate the Fr\\'echet distance\nbetween curves better than a factor $3$ unless SETH fails. We show that similar\nreductions cannot achieve a lower bound with a factor better than $3$. Our\nlower bound holds for the continuous, the discrete, and the weak discrete\nFr\\'echet distance even for curves in one dimension. Interestingly, the\ncontinuous weak Fr\\'echet distance behaves differently. Our lower bound still\nholds for curves in two dimensions and higher. However, for curves in one\ndimension, we provide an exact algorithm to compute the weak Fr\\'echet distance\nin linear time.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2018 16:23:20 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Buchin", "Kevin", ""], ["Ophelders", "Tim", ""], ["Speckmann", "Bettina", ""]]}, {"id": "1807.09392", "submitter": "Hemant Malik", "authors": "Ovidiu Daescu and Hemant Malik", "title": "Does a robot path have clearance c?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Most path planning problems among polygonal obstacles ask to find a path that\navoids the obstacles and is optimal with respect to some measure or a\ncombination of measures, for example an $u$-to-$v$ shortest path of clearance\nat least $c$, where $u$ and $v$ are points in the free space and $c$ is a\npositive constant. In practical applications, such as emergency\ninterventions/evacuations and medical treatment planning, a number of\n$u$-to-$v$ paths are suggested by experts and the question is whether such\npaths satisfy specific requirements, such as a given clearance from the\nobstacles. We address the following path query problem: Given a set $S$ of $m$\ndisjoint simple polygons in the plane, with a total of $n$ vertices, preprocess\nthem so that for a query consisting of a positive constant $c$ and a simple\npolygonal path $\\pi$ with $k$ vertices, from a point $u$ to a point $v$ in free\nspace, where $k$ is much smaller than $n$, one can quickly decide whether $\\pi$\nhas clearance at least $c$ (that is, there is no polygonal obstacle within\ndistance $c$ of $\\pi$). To do so, we show how to solve the following related\nproblem: Given a set $S$ of $m$ simple polygons in $\\Re^{2}$, preprocess $S$\ninto a data structure so that the polygon in $S$ closest to a query line\nsegment $s$ can be reported quickly. We present an $O(t \\log n)$ time, $O(t)$\nspace preprocessing, $O((n / \\sqrt{t}) \\log ^{7/2} n)$ query time solution for\nthis problem, for any $n ^{1 + \\epsilon} \\leq t \\leq n^{2}$. For a path with\n$k$ segments, this results in $O((n k / \\sqrt{t}) \\log ^{7/2} n)$ query time,\nwhich is a significant improvement over algorithms that can be derived from\nexisting computational geometry methods when $k$ is small.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2018 23:41:58 GMT"}], "update_date": "2018-07-26", "authors_parsed": [["Daescu", "Ovidiu", ""], ["Malik", "Hemant", ""]]}, {"id": "1807.09415", "submitter": "Jianfei Liu", "authors": "Shang Xiang and Jianfei Liu", "title": "A 36-Element Solution To Schneiders' Pyramid Hex-Meshing Problem And A\n  Parity-Changing Template For Hex-Mesh Revision", "comments": "7 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a solution that uses the least number of hexahedra\nto build a pyramid, which is the key block required for one type of automatic\nhex-meshing method to be successful. When the initial result of a hex-meshing\nprogram is not appropriate for specific applications, some templates are used\nfor revision. The templates reported thus far are parity-preserving, which\nmeans that the parity of the number of hexahedra in a mesh is unchanged after a\nrevision following the templates. We present a parity-changing template that\nmakes the template set integral and more effective. These two findings are\nobtained by a program that we developed for this study, which is a tool for\nresearchers to observe the characteristics of small hexahedral packings.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jul 2018 02:11:25 GMT"}], "update_date": "2018-07-26", "authors_parsed": [["Xiang", "Shang", ""], ["Liu", "Jianfei", ""]]}, {"id": "1807.09483", "submitter": "Marcel Radermacher", "authors": "Almut Demel, Dominik D\\\"urrschnabel, Tamara Mchedlidze, Marcel\n  Radermacher, Lasse Wulf", "title": "A Greedy Heuristic for Crossing-Angle Maximization", "comments": "Appears in the Proceedings of the 26th International Symposium on\n  Graph Drawing and Network Visualization (GD 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The crossing angle of a straight-line drawing $\\Gamma$ of a graph $G=(V, E)$\nis the smallest angle between two crossing edges in $\\Gamma$. Deciding whether\na graph $G$ has a straight-line drawing with a crossing angle of $90^\\circ$ is\n$\\mathcal NP$-hard. We propose a simple heuristic to compute a drawing with a\nlarge crossing angle. The heuristic greedily selects the best position for a\nsingle vertex in a random set of points. The algorithm is accompanied by a\nspeed-up technique to compute the crossing angle of a straight-line drawing. We\nshow the effectiveness of the heuristic in an extensive empirical evaluation.\nOur heuristic was clearly the winning algorithm (CoffeeVM) in the Graph Drawing\nChallenge 2017.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jul 2018 08:43:03 GMT"}, {"version": "v2", "created": "Tue, 31 Jul 2018 09:42:41 GMT"}], "update_date": "2018-08-01", "authors_parsed": [["Demel", "Almut", ""], ["D\u00fcrrschnabel", "Dominik", ""], ["Mchedlidze", "Tamara", ""], ["Radermacher", "Marcel", ""], ["Wulf", "Lasse", ""]]}, {"id": "1807.09498", "submitter": "Jie Xue", "authors": "Jie Xue, Yuan Li, Saladi Rahul, Ravi Janardan", "title": "Searching for the closest-pair in a query translate", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a range-search variant of the closest-pair problem. Let\n$\\varGamma$ be a fixed shape in the plane. We are interested in storing a given\nset of $n$ points in the plane in some data structure such that for any\nspecified translate of $\\varGamma$, the closest pair of points contained in the\ntranslate can be reported efficiently. We present results on this problem for\ntwo important settings: when $\\varGamma$ is a polygon (possibly with holes) and\nwhen $\\varGamma$ is a general convex body whose boundary is smooth. When\n$\\varGamma$ is a polygon, we present a data structure using $O(n)$ space and\n$O(\\log n)$ query time, which is asymptotically optimal. When $\\varGamma$ is a\ngeneral convex body with a smooth boundary, we give a near-optimal data\nstructure using $O(n \\log n)$ space and $O(\\log^2 n)$ query time. Our results\nsettle some open questions posed by Xue et al. [SoCG 2018].\n", "versions": [{"version": "v1", "created": "Wed, 25 Jul 2018 09:29:41 GMT"}, {"version": "v2", "created": "Thu, 21 Mar 2019 18:59:50 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Xue", "Jie", ""], ["Li", "Yuan", ""], ["Rahul", "Saladi", ""], ["Janardan", "Ravi", ""]]}, {"id": "1807.09694", "submitter": "Tom Morgan", "authors": "Michael Mitzenmacher, Tom Morgan", "title": "Robust Set Reconciliation via Locality Sensitive Hashing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider variations of set reconciliation problems where two parties,\nAlice and Bob, each hold a set of points in a metric space, and the goal is for\nBob to conclude with a set of points that is close to Alice's set of points in\na well-defined way. This setting has been referred to as robust set\nreconciliation. More specifically, in one variation we examine the goal is for\nBob to end with a set of points that is close to Alice's in earth mover's\ndistance, and in another the goal is for Bob to have a point that is close to\neach of Alice's. The first problem has been studied before; our results scale\nbetter with the dimension of the space. The second problem appears new.\n  Our primary novelty is utilizing Invertible Bloom Lookup Tables in\ncombination with locality sensitive hashing. This combination allows us to cope\nwith the geometric setting in a communication-efficient manner.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jul 2018 16:13:48 GMT"}], "update_date": "2018-07-26", "authors_parsed": [["Mitzenmacher", "Michael", ""], ["Morgan", "Tom", ""]]}, {"id": "1807.09977", "submitter": "Jie Xue", "authors": "Jie Xue", "title": "Colored range closest-pair problem under general distance functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The range closest-pair (RCP) problem is the range-search version of the\nclassical closest-pair problem, which aims to store a given dataset of points\nin some data structure such that when a query range $X$ is specified, the\nclosest pair of points contained in $X$ can be reported efficiently. A natural\ngeneralization of the RCP problem is the {colored range closest-pair} (CRCP)\nproblem in which the given data points are colored and the goal is to find the\nclosest {bichromatic} pair contained in the query range. All the previous work\non the RCP problem was restricted to the uncolored version and the Euclidean\ndistance function. In this paper, we make the first progress on the CRCP\nproblem. We investigate the problem under a general distance function induced\nby a monotone norm; in particular, this covers all the $L_p$-metrics for $p >\n0$ and the $L_\\infty$-metric. We design efficient $(1+\\varepsilon)$-approximate\nCRCP data structures for orthogonal queries in $\\mathbb{R}^2$, where\n$\\varepsilon>0$ is a pre-specified parameter. The highlights are two data\nstructures for answering rectangle queries, one of which uses\n$O(\\varepsilon^{-1} n \\log^4 n)$ space and $O(\\log^4 n + \\varepsilon^{-1}\n\\log^3 n + \\varepsilon^{-2} \\log n)$ query time while the other uses\n$O(\\varepsilon^{-1} n \\log^3 n)$ space and $O(\\log^5 n + \\varepsilon^{-1}\n\\log^4 n + \\varepsilon^{-2} \\log^2 n)$ query time. In addition, we also apply\nour techniques to the CRCP problem in higher dimensions, obtaining efficient\ndata structures for slab, 2-box, and 3D dominance queries. Before this paper,\nalmost all the existing results for the RCP problem were achieved in\n$\\mathbb{R}^2$.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2018 07:01:13 GMT"}], "update_date": "2018-07-27", "authors_parsed": [["Xue", "Jie", ""]]}, {"id": "1807.09982", "submitter": "Hanne Hardering", "authors": "Bernhard Brehm and Hanne Hardering", "title": "Sparips", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Persistent homology of the Rips filtration allows to track topological\nfeatures of a point cloud over scales, and is a foundational tool of\ntopological data analysis. Unfortunately, the Rips-filtration is exponentially\nsized, when considered as a filtered simplicial complex. Hence, the computation\nof full persistence modules is impossible for all but the tiniest of datasets;\nwhen truncating the dimension of topological features, the situation becomes\nslightly less intractable, but still daunting for medium-sized datasets.\n  It is theoretically possible to approximate the Rips-filtration by a much\nsmaller and sparser, linear-sized simplicial complexs, however, possibly due to\nthe complexity of existing approaches, we are not aware of any existing\nimplementation.\n  We propose a different sparsification scheme, based on cover-trees, that is\neasy to implement, while giving similar guarantees on the computational\nscaling. We further propose a visualization that is adapted to approximate\npersistence diagrams, by incorporating a variant of error bars and keeping\ntrack of all approximation guarantees, explicitly.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2018 07:17:56 GMT"}], "update_date": "2018-07-27", "authors_parsed": [["Brehm", "Bernhard", ""], ["Hardering", "Hanne", ""]]}, {"id": "1807.10093", "submitter": "Rodrigo Silveira", "authors": "Delia Garijo, Alberto M\\'arquez, Natalia Rodr\\'iguez, Rodrigo I.\n  Silveira", "title": "Computing optimal shortcuts for networks", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study augmenting a plane Euclidean network with a segment, called a\nshortcut, to minimize the largest distance between any two points along the\nedges of the resulting network. Problems of this type have received\nconsiderable attention recently, mostly for discrete variants of the problem.\n  We consider a fully continuous setting, where the problem of computing\ndistances and placing a shortcut is much harder as all points on the network,\ninstead of only the vertices, must be taken into account. We present the first\nresults on the computation of optimal shortcuts for general networks in this\nmodel: a polynomial time algorithm and a discretization of the problem that\nleads to an approximation algorithm. We also improve the general method for\nnetworks that are paths, restricted to two types of shortcuts: those with a\nfixed orientation and simple shortcuts.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2018 12:30:29 GMT"}], "update_date": "2018-07-27", "authors_parsed": [["Garijo", "Delia", ""], ["M\u00e1rquez", "Alberto", ""], ["Rodr\u00edguez", "Natalia", ""], ["Silveira", "Rodrigo I.", ""]]}, {"id": "1807.10848", "submitter": "Manfred Scheucher", "authors": "Manfred Scheucher", "title": "Two Disjoint 5-Holes in Point Sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a set of points $S \\subseteq \\mathbb{R}^2$, a subset $X \\subseteq S$\nwith $|X|=k$ is called $k$-gon if all points of $X$ lie on the boundary of the\nconvex hull of $X$, and $k$-hole if, in addition, no point of $S \\setminus X$\nlies in the convex hull of $X$. We use computer assistance to show that every\nset of 17 points in general position admits two disjoint 5-holes, that is,\nholes with disjoint respective convex hulls. This answers a question of Hosono\nand Urabe (2001). We also provide new bounds for three and more pairwise\ndisjoint holes.\n  In a recent article, Hosono and Urabe (2018) present new results on\ninterior-disjoint holes -- a variant, which also has been investigated in the\nlast two decades. Using our program, we show that every set of 15 points\ncontains two interior-disjoint 5-holes.\n  Moreover, our program can be used to verify that every set of 17 points\ncontains a 6-gon within significantly smaller computation time than the\noriginal program by Szekeres and Peters (2006). Another independent\nverification of this result was done by Mari\\'c (2019).\n", "versions": [{"version": "v1", "created": "Fri, 27 Jul 2018 22:38:16 GMT"}, {"version": "v2", "created": "Wed, 14 Nov 2018 16:51:44 GMT"}, {"version": "v3", "created": "Mon, 25 Feb 2019 12:40:28 GMT"}, {"version": "v4", "created": "Wed, 20 May 2020 14:26:16 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Scheucher", "Manfred", ""]]}, {"id": "1807.10926", "submitter": "Saeed Asaeedi", "authors": "Saeed Asaeedi, Farzad Didehvar, Ali Mohades", "title": "An upper bound for min-max angle of polygons", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $S$ be a set of $n$ points in the plane, $\\wp(S)$ be the set of all\nsimple polygons crossing $S$, $\\gamma_P$ be the maximum angle of polygon $P \\in\n\\wp(S)$ and $\\theta =min_{P\\in\\wp(S)} \\gamma_P$. In this paper, we prove that\n$\\theta\\leq 2\\pi-\\frac{2\\pi}{r.m}$ where $m$ and $r$ are the number of edges\nand inner points of the convex hull of $S$, respectively. We also propose an\nalgorithm to construct a polygon with the said upper bound on its angles.\nConstructing a simple polygon with angular constraint on a given set of points\nin the plane can be used for path planning in robotics. Moreover, we improve\nour upper bound on $\\theta$ and prove that this is tight for $r=1$.\n", "versions": [{"version": "v1", "created": "Sat, 28 Jul 2018 11:27:36 GMT"}, {"version": "v2", "created": "Sat, 12 Jun 2021 20:25:39 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Asaeedi", "Saeed", ""], ["Didehvar", "Farzad", ""], ["Mohades", "Ali", ""]]}, {"id": "1807.11043", "submitter": "Torsten M\\\"utze", "authors": "Torsten M\\\"utze and Manfred Scheucher", "title": "On L-shaped point set embeddings of trees: first non-embeddable examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An L-shaped embedding of a tree in a point set is a planar drawing of the\ntree where the vertices are mapped to distinct points and every edge is drawn\nas a sequence of two axis-aligned line segments. There has been considerable\nwork on establishing upper bounds on the minimum cardinality of a point set to\nguarantee that any tree of the same size with maximum degree 4 admits an\nL-shaped embedding on the point set. However, no non-trivial lower bound is\nknown to this date, i.e., no known $n$-vertex tree requires more than $n$\npoints to be embedded. In this paper, we present the first examples of\n$n$-vertex trees for $n\\in\\{13,14,16,17,18,19,20\\}$ that require strictly more\npoints than vertices to admit an L-shaped embedding. Moreover, using computer\nhelp, we show that every tree on $n\\leq 12$ vertices admits an L-shaped\nembedding in every set of $n$ points. We also consider embedding ordered trees,\nwhere the cyclic order of the neighbors of each vertex in the embedding is\nprescribed. For this setting, we determine the smallest non-embeddable ordered\ntree on $n=10$ vertices, and we show that every ordered tree on $n\\leq 9$ or\n$n=11$ vertices admits an L-shaped embedding in every set of $n$ points. We\nalso construct an infinite family of ordered trees which do not always admit an\nL-shaped embedding, answering a question raised by Biedl, Chan, Derka, Jain,\nand Lubiw.\n", "versions": [{"version": "v1", "created": "Sun, 29 Jul 2018 11:43:07 GMT"}, {"version": "v2", "created": "Mon, 20 Aug 2018 10:03:15 GMT"}, {"version": "v3", "created": "Fri, 9 Nov 2018 07:40:58 GMT"}, {"version": "v4", "created": "Mon, 11 Nov 2019 13:06:52 GMT"}, {"version": "v5", "created": "Wed, 29 Apr 2020 20:07:06 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["M\u00fctze", "Torsten", ""], ["Scheucher", "Manfred", ""]]}, {"id": "1807.11212", "submitter": "Julien Tierny", "authors": "Guillaume Favelier, Noura Faraj, Brian Summa, Julien Tierny", "title": "Persistence Atlas for Critical Point Variability in Ensembles", "comments": null, "journal-ref": null, "doi": null, "report-no": "2344815-v2", "categories": "cs.GR cs.CG cs.CV eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new approach for the visualization and analysis of the\nspatial variability of features of interest represented by critical points in\nensemble data. Our framework, called Persistence Atlas, enables the\nvisualization of the dominant spatial patterns of critical points, along with\nstatistics regarding their occurrence in the ensemble. The persistence atlas\nrepresents in the geometrical domain each dominant pattern in the form of a\nconfidence map for the appearance of critical points. As a by-product, our\nmethod also provides 2-dimensional layouts of the entire ensemble, highlighting\nthe main trends at a global level. Our approach is based on the new notion of\nPersistence Map, a measure of the geometrical density in critical points which\nleverages the robustness to noise of topological persistence to better\nemphasize salient features. We show how to leverage spectral embedding to\nrepresent the ensemble members as points in a low-dimensional Euclidean space,\nwhere distances between points measure the dissimilarities between critical\npoint layouts and where statistical tasks, such as clustering, can be easily\ncarried out. Further, we show how the notion of mandatory critical point can be\nleveraged to evaluate for each cluster confidence regions for the appearance of\ncritical points. Most of the steps of this framework can be trivially\nparallelized and we show how to efficiently implement them. Extensive\nexperiments demonstrate the relevance of our approach. The accuracy of the\nconfidence regions provided by the persistence atlas is quantitatively\nevaluated and compared to a baseline strategy using an off-the-shelf clustering\napproach. We illustrate the importance of the persistence atlas in a variety of\nreal-life datasets, where clear trends in feature layouts are identified and\nanalyzed.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2018 07:46:27 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Favelier", "Guillaume", ""], ["Faraj", "Noura", ""], ["Summa", "Brian", ""], ["Tierny", "Julien", ""]]}, {"id": "1807.11617", "submitter": "David Wood", "authors": "Vida Dujmovi\\'c, Ken-ichi Kawarabayashi, Bojan Mohar, David R. Wood", "title": "Tight Upper Bounds on the Crossing Number in a Minor-Closed Class", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The crossing number of a graph is the minimum number of crossings in a\ndrawing of the graph in the plane. Our main result is that every graph $G$ that\ndoes not contain a fixed graph as a minor has crossing number $O(\\Delta n)$,\nwhere $G$ has $n$ vertices and maximum degree $\\Delta$. This dependence on $n$\nand $\\Delta$ is best possible. This result answers an open question of Wood and\nTelle [New York J. Mathematics, 2007], who proved the best previous bound of\n$O(\\Delta^2 n)$. We also study the convex and rectilinear crossing numbers, and\nprove an $O(\\Delta n)$ bound for the convex crossing number of bounded\npathwidth graphs, and a $\\sum_v\\deg(v)^2$ bound for the rectilinear crossing\nnumber of $K_{3,3}$-minor-free graphs.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jul 2018 00:44:34 GMT"}], "update_date": "2018-08-01", "authors_parsed": [["Dujmovi\u0107", "Vida", ""], ["Kawarabayashi", "Ken-ichi", ""], ["Mohar", "Bojan", ""], ["Wood", "David R.", ""]]}, {"id": "1807.11711", "submitter": "Marcel Radermacher", "authors": "Marcel Radermacher and Ignaz Rutter", "title": "Inserting an Edge into a Geometric Embedding", "comments": "Appears in the Proceedings of the 26th International Symposium on\n  Graph Drawing and Network Visualization (GD 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The algorithm of Gutwenger et al. to insert an edge $e$ in linear time into a\nplanar graph $G$ with a minimal number of crossings on $e$, is a helpful tool\nfor designing heuristics that minimize edge crossings in drawings of general\ngraphs. Unfortunately, some graphs do not have a geometric embedding $\\Gamma$\nsuch that $\\Gamma+e$ has the same number of crossings as the embedding $G+e$.\nThis motivates the study of the computational complexity of the following\nproblem: Given a combinatorially embedded graph $G$, compute a geometric\nembedding $\\Gamma$ that has the same combinatorial embedding as $G$ and that\nminimizes the crossings of $\\Gamma+e$. We give polynomial-time algorithms for\nspecial cases and prove that the general problem is fixed-parameter tractable\nin the number of crossings. Moreover, we show how to approximate the number of\ncrossings by a factor $(\\Delta-2)$, where $\\Delta$ is the maximum vertex degree\nof $G$.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jul 2018 09:17:43 GMT"}], "update_date": "2018-08-01", "authors_parsed": [["Radermacher", "Marcel", ""], ["Rutter", "Ignaz", ""]]}]