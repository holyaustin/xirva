[{"id": "1906.00191", "submitter": "Noushin Saeedi", "authors": "William Evans and Noushin Saeedi", "title": "On problems related to crossing families", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a set of points in the plane, a \\emph{crossing family} is a collection\nof segments, each joining two of the points, such that every two segments\nintersect internally. Aronov et al. [Combinatorica,~14(2):127-134,~1994] proved\nthat any set of $n$ points contains a crossing family of size\n$\\Omega(\\sqrt{n})$. They also mentioned that there exist point sets whose\nmaximum crossing family uses at most $\\frac{n}{2}$ of the points. We improve\nthe upper bound on the size of crossing families to $5\\lceil \\frac{n}{24}\n\\rceil$. We also introduce a few generalizations of crossing families, and give\nseveral lower and upper bounds on our generalized notions.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 09:25:39 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Evans", "William", ""], ["Saeedi", "Noushin", ""]]}, {"id": "1906.00692", "submitter": "Gabriel C. Drummond-Cole", "authors": "Gabriel C. Drummond-Cole", "title": "Betti numbers of unordered configuration spaces of small graphs", "comments": "728 pages. 724 graphs", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AT cs.CG math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of this document is to provide data about known Betti numbers of\nunordered configuration spaces of small graphs in order to guide research and\navoid duplicated effort. It contains information for connected multigraphs\nhaving at most nine edges which contain no loops, no bivalent vertices, and no\ninternal (i.e., non-leaf) bridges.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 10:32:58 GMT"}, {"version": "v2", "created": "Sat, 4 Jan 2020 18:38:22 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Drummond-Cole", "Gabriel C.", ""]]}, {"id": "1906.00958", "submitter": "Vincent Guigues", "authors": "Vincent Guigues", "title": "A library to compute the density of the distance between a point and a\n  random variable uniformly distributed in some sets", "comments": "arXiv admin note: text overlap with arXiv:1406.0005", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In [3], algorithms to compute the density of the distance to a random\nvariable uniformly distributed in (a) a ball, (b) a disk, (c) a line segment,\nor (d) a polygone were introduced. For case (d), the algorithm, based on\nGreen's theorem, has complexity nlog(n) where n is the number of vertices of\nthe polygone. In this paper, we present for case (d) another algorithm with the\nsame complexity, based on a triangulation of the polygone. We also describe an\nopen source library providing this algorithm as well as the algorithms from\n[3].\n  [3] V. Guigues, Computation of the cumulative distribution function of the\nEuclidean distance between a point and a random variable uniformly distributed\nin disks, balls, or polyhedrons and application to Probabilistic Seismic Hazard\nAnalysis, arXiv, available at arXiv:1809.02007, 2015.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 00:11:16 GMT"}, {"version": "v2", "created": "Wed, 5 Jun 2019 16:36:36 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Guigues", "Vincent", ""]]}, {"id": "1906.01114", "submitter": "Darren Strash", "authors": "Hee-Kap Ahn, Eunjin Oh, Lena Schlipf, Fabian Stehn, Darren Strash", "title": "On Romeo and Juliet Problems: Minimizing Distance-to-Sight", "comments": "12 pages, 8 figures; appeared in Proc. 16th Scandinavian Symposium\n  and Workshops on Algorithm Theory (SWAT 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a variant of the watchman route problem, which we call the\nquickest pair-visibility problem. Given two persons standing at points $s$ and\n$t$ in a simple polygon $P$ with no holes, we want to minimize the distance\nthey travel in order to see each other in $P$. We solve two variants of this\nproblem, one minimizing the longer distance the two persons travel (min-max)\nand one minimizing the total travel distance (min-sum), optimally in linear\ntime. We also consider a query version of this problem for the min-max variant.\nWe can preprocess a simple $n$-gon in linear time so that the minimum of the\nlonger distance the two persons travel can be computed in $O(\\log^2 n)$ time\nfor any two query positions $s,t$ where the two persons start.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 22:47:57 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Ahn", "Hee-Kap", ""], ["Oh", "Eunjin", ""], ["Schlipf", "Lena", ""], ["Stehn", "Fabian", ""], ["Strash", "Darren", ""]]}, {"id": "1906.01651", "submitter": "Russ Woodroofe", "authors": "Andr\\'es Santamar\\'ia-Galvis and Russ Woodroofe", "title": "Shellings from relative shellings, with an application to\n  NP-completeness", "comments": "17 pages, 5 figures; v2 has minor corrections, v3 has further\n  corrections for publication", "journal-ref": null, "doi": "10.1007/s00454-020-00273-1", "report-no": null, "categories": "math.CO cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shellings of simplicial complexes have long been a useful tool in topological\nand algebraic combinatorics. Shellings of a complex expose a large amount of\ninformation in a helpful way, but are not easy to construct, often requiring\ndeep information about the structure of the complex. It is natural to ask\nwhether shellings may be efficiently found computationally. In a recent paper,\nGoaoc, Pat\\'ak, Pat\\'akov\\'a, Tancer and Wagner gave a negative answer to this\nquestion (assuming P \\neq NP), showing that the problem of deciding whether a\nsimplicial complex is shellable is NP-complete.\n  In this paper, we give simplified constructions of various gadgets used in\nthe NP-completeness proof of these authors. Using these gadgets combined with\nrelative shellability and other ideas, we also exhibit a simpler proof of the\nNP-completeness of the shellability decision problem. Our method systematically\nuses relative shellings to build up large shellable complexes with desired\nproperties.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 18:00:10 GMT"}, {"version": "v2", "created": "Mon, 22 Jul 2019 09:21:11 GMT"}, {"version": "v3", "created": "Mon, 9 Nov 2020 12:06:21 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Santamar\u00eda-Galvis", "Andr\u00e9s", ""], ["Woodroofe", "Russ", ""]]}, {"id": "1906.01859", "submitter": "Francesco Silvestri", "authors": "Martin Aum\\\"uller and Rasmus Pagh and Francesco Silvestri", "title": "Fair Near Neighbor Search: Independent Range Sampling in High Dimensions", "comments": "Proceedings of the 39th ACM SIGMOD-SIGACT-SIGAI Symposium on\n  Principles of Database Systems (PODS), Pages 191-204, June 2020", "journal-ref": null, "doi": "10.1145/3375395.3387648", "report-no": null, "categories": "cs.DS cs.CG cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Similarity search is a fundamental algorithmic primitive, widely used in many\ncomputer science disciplines. There are several variants of the similarity\nsearch problem, and one of the most relevant is the $r$-near neighbor ($r$-NN)\nproblem: given a radius $r>0$ and a set of points $S$, construct a data\nstructure that, for any given query point $q$, returns a point $p$ within\ndistance at most $r$ from $q$. In this paper, we study the $r$-NN problem in\nthe light of fairness. We consider fairness in the sense of equal opportunity:\nall points that are within distance $r$ from the query should have the same\nprobability to be returned. In the low-dimensional case, this problem was first\nstudied by Hu, Qiao, and Tao (PODS 2014). Locality sensitive hashing (LSH), the\ntheoretically strongest approach to similarity search in high dimensions, does\nnot provide such a fairness guarantee. To address this, we propose efficient\ndata structures for $r$-NN where all points in $S$ that are near $q$ have the\nsame probability to be selected and returned by the query. Specifically, we\nfirst propose a black-box approach that, given any LSH scheme, constructs a\ndata structure for uniformly sampling points in the neighborhood of a query.\nThen, we develop a data structure for fair similarity search under inner\nproduct that requires nearly-linear space and exploits locality sensitive\nfilters. The paper concludes with an experimental evaluation that highlights\n(un)fairness in a recommendation setting on real-world datasets and discusses\nthe inherent unfairness introduced by solving other variants of the problem.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 07:27:48 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 13:13:00 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Aum\u00fcller", "Martin", ""], ["Pagh", "Rasmus", ""], ["Silvestri", "Francesco", ""]]}, {"id": "1906.02077", "submitter": "Stefan Kollmannsberger", "authors": "L\\'aszl\\'o Kudela and Stefan Kollmannsberger and Umut Almac and Ernst\n  Rank", "title": "Direct structural analysis of domains defined by point clouds", "comments": null, "journal-ref": null, "doi": "10.1016/j.cma.2019.112581", "report-no": null, "categories": "cs.CE cs.CG math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This contribution presents a method that aims at the numerical analysis of\nsolids represented by oriented point clouds. The proposed approach is based on\nthe Finite Cell Method, a high-order immersed boundary technique that computes\non a regular background grid of finite elements and requires only\ninside-outside information from the geometric model. It is shown that oriented\npoint clouds provide sufficient information for these point-membership\nclassifications. Further, we address a tessellation-free formulation of contour\nintegrals that allows to apply Neumann boundary conditions on point clouds\nwithout having to recover the underlying surface. Two-dimensional linear\nelastic benchmark examples demonstrate that the method is able to provide the\nsame accuracy as those computed with conventional, continuous surface\ndescriptions, because the associated error can be controlled by the density of\nthe cloud. Three-dimensional examples computed on point clouds of historical\nstructures show how the method can be employed to establish seamless\nconnections between digital shape measurement techniques and numerical\nanalyses.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 15:37:39 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Kudela", "L\u00e1szl\u00f3", ""], ["Kollmannsberger", "Stefan", ""], ["Almac", "Umut", ""], ["Rank", "Ernst", ""]]}, {"id": "1906.02640", "submitter": "Sariel Har-Peled", "authors": "Sariel Har-Peled and Sepideh Mahabadi", "title": "Near Neighbor: Who is the Fairest of Them All?", "comments": "To appear in NIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  $\\newcommand{\\ball}{\\mathbb{B}}\\newcommand{\\dsQ}{{\\mathcal{Q}}}\\newcommand{\\dsS}{{\\mathcal{S}}}$In\nthis work we study a fair variant of the near neighbor problem. Namely, given a\nset of $n$ points $P$ and a parameter $r$, the goal is to preprocess the\npoints, such that given a query point $q$, any point in the $r$-neighborhood of\nthe query, i.e., $\\ball(q,r)$, have the same probability of being reported as\nthe near neighbor.\n  We show that LSH based algorithms can be made fair, without a significant\nloss in efficiency. Specifically, we show an algorithm that reports a point in\nthe $r$-neighborhood of a query $q$ with almost uniform probability. The query\ntime is proportional to $O\\bigl( \\mathrm{dns}(q.r) \\dsQ(n,c) \\bigr)$, and its\nspace is $O(\\dsS(n,c))$, where $\\dsQ(n,c)$ and $\\dsS(n,c)$ are the query time\nand space of an LSH algorithm for $c$-approximate near neighbor, and\n$\\mathrm{dns}(q,r)$ is a function of the local density around $q$.\n  Our approach works more generally for sampling uniformly from a\nsub-collection of sets of a given collection and can be used in a few other\napplications. Finally, we run experiments to show performance of our approach\non real data.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 15:18:01 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 22:53:46 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Har-Peled", "Sariel", ""], ["Mahabadi", "Sepideh", ""]]}, {"id": "1906.03027", "submitter": "Tim Kuipers", "authors": "Tim Kuipers, Jun Wu and Charlie C. L. Wang", "title": "CrossFill: Foam Structures with Graded Density for Continuous Material\n  Extrusion", "comments": "Submission to Symposium on Solid and Physical Modeling 2019", "journal-ref": "Computer-Aided Design 114C (2019) pp. 37-50", "doi": null, "report-no": null, "categories": "cs.CG cs.GR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The fabrication flexibility of 3D printing has sparked a lot of interest in\ndesigning structures with spatially graded material properties. In this paper,\nwe propose a new type of density graded structure that is particularly designed\nfor 3D printing systems based on filament extrusion. In order to ensure\nhigh-quality fabrication results, extrusion-based 3D printing requires not only\nthat the structures are self-supporting, but also that extrusion toolpaths are\ncontinuous and free of self-overlap. The structure proposed in this paper,\ncalled CrossFill, complies with these requirements. In particular, CrossFill is\na self-supporting foam structure, for which each layer is fabricated by a\nsingle, continuous and overlap-free path of material extrusion. Our method for\ngenerating CrossFill is based on a space-filling surface that employs spatially\nvarying subdivision levels. Dithering of the subdivision levels is performed to\naccurately reproduce a prescribed density distribution. We demonstrate the\neffectiveness of CrossFill on a number of experimental tests and applications.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 11:52:52 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Kuipers", "Tim", ""], ["Wu", "Jun", ""], ["Wang", "Charlie C. L.", ""]]}, {"id": "1906.04401", "submitter": "David Eppstein", "authors": "David Eppstein", "title": "Bipartite and Series-Parallel Graphs Without Planar Lombardi Drawings", "comments": "10 pages, 6 figures. A preliminary version of this paper appeared at\n  the 31st Canadian Conference in Computational Geometry", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We find a family of planar bipartite graphs all of whose Lombardi drawings\n(drawings with circular arcs for edges, meeting at equal angles at the\nvertices) are nonplanar. We also find families of embedded series-parallel\ngraphs and apex-trees (graphs formed by adding one vertex to a tree) for which\nthere is no planar Lombardi drawing consistent with the given embedding.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 05:48:02 GMT"}, {"version": "v2", "created": "Thu, 8 Aug 2019 03:38:20 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Eppstein", "David", ""]]}, {"id": "1906.05404", "submitter": "Xiaoling Hu Mr", "authors": "Xiaoling Hu, Li Fuxin, Dimitris Samaras and Chao Chen", "title": "Topology-Preserving Deep Image Segmentation", "comments": "11 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Segmentation algorithms are prone to make topological errors on fine-scale\nstructures, e.g., broken connections. We propose a novel method that learns to\nsegment with correct topology. In particular, we design a continuous-valued\nloss function that enforces a segmentation to have the same topology as the\nground truth, i.e., having the same Betti number. The proposed\ntopology-preserving loss function is differentiable and we incorporate it into\nend-to-end training of a deep neural network. Our method achieves much better\nperformance on the Betti number error, which directly accounts for the\ntopological correctness. It also performs superiorly on other topology-relevant\nmetrics, e.g., the Adjusted Rand Index and the Variation of Information. We\nillustrate the effectiveness of the proposed method on a broad spectrum of\nnatural and biomedical datasets.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 22:12:44 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Hu", "Xiaoling", ""], ["Fuxin", "Li", ""], ["Samaras", "Dimitris", ""], ["Chen", "Chao", ""]]}, {"id": "1906.05921", "submitter": "Nicolas Guigui", "authors": "N. Guigui (EPIONE, UCA), Shuman Jia (EPIONE, UCA), Maxime Sermesant\n  (EPIONE, UCA), Xavier Pennec (EPIONE, UCA)", "title": "Symmetric Algorithmic Components for Shape Analysis with Diffeomorphisms", "comments": null, "journal-ref": "Geometric Science of Information 2019, Aug 2019, Toulouse, France", "doi": null, "report-no": null, "categories": "cs.GR cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In computational anatomy, the statistical analysis of temporal deformations\nand inter-subject variability relies on shape registration. However, the\nnumerical integration and optimization required in diffeomorphic registration\noften lead to important numerical errors. In many cases, it is well known that\nthe error can be drastically reduced in the presence of a symmetry. In this\nwork, the leading idea is to approximate the space of deformations and images\nwith a possibly non-metric symmetric space structure using an involution, with\nthe aim to perform parallel transport. Through basic properties of symmetries,\nwe investigate how the implementations of a midpoint and the involution compare\nwith the ones of the Riemannian exponential and logarithm on diffeomorphisms\nand propose a modification of these maps using registration errors. This leads\nus to identify transvections, the composition of two symmetries, as a mean to\nmeasure how far from symmetric the underlying structure is. We test our method\non a set of 138 cardiac shapes and demonstrate improved numerical consistency\nin the Pole Ladder scheme.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 09:29:46 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Guigui", "N.", "", "EPIONE, UCA"], ["Jia", "Shuman", "", "EPIONE, UCA"], ["Sermesant", "Maxime", "", "EPIONE, UCA"], ["Pennec", "Xavier", "", "EPIONE, UCA"]]}, {"id": "1906.05996", "submitter": "Felice De Luca", "authors": "Felice De Luca, Iqbal Hossain, Kathryn Gray, Stephen Kobourov, Katy\n  B\\\"orner", "title": "Multi-level tree based approach for interactive graph visualization with\n  semantic zoom", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human subject studies that map-like visualizations are as good or better than\nstandard node-link representations of graphs, in terms of task performance,\nmemorization and recall of the underlying data, and engagement [SSKB14,\nSSKB15]. With this in mind, we propose the Zoomable Multi-Level Tree (ZMLT)\nalgorithm for multi-level tree-based, map-like visualization of large graphs.\nWe propose seven desirable properties that such visualization should maintain\nand an algorithm that accomplishes them. (1) The abstract trees represent the\nunderlying graph appropriately at different level of details; (2) The embedded\ntrees represent the underlying graph appropriately at different levels of\ndetails; (3) At every level of detail we show real vertices and real paths from\nthe underlying graph; (4) If any node or edge appears in a given level, then\nthey also appear in all deeper levels; (5) All nodes at the current level and\nhigher levels are labeled and there are no label overlaps; (6) There are no\nedge crossings on any level; (7) The drawing area is proportional to the total\narea of the labels. This algorithm is implemented and we have a functional\nprototype for the interactive interface in a web browser.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 02:58:17 GMT"}, {"version": "v2", "created": "Mon, 9 Dec 2019 18:05:02 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["De Luca", "Felice", ""], ["Hossain", "Iqbal", ""], ["Gray", "Kathryn", ""], ["Kobourov", "Stephen", ""], ["B\u00f6rner", "Katy", ""]]}, {"id": "1906.06014", "submitter": "Eduardo Faccin Vernier", "authors": "Eduardo Vernier, Max Sondag, Joao Comba, Bettina Speckmann, Alexandru\n  Telea, and Kevin Verbeek", "title": "Quantitative Comparison of Time-Dependent Treemaps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Rectangular treemaps are often the method of choice to visualize large\nhierarchical datasets. Nowadays such datasets are available over time, hence\nthere is a need for (a) treemaps that can handle time-dependent data, and (b)\ncorresponding quality criteria that cover both a treemap's visual quality and\nits stability over time. In recent years a wide variety of (stable) treemapping\nalgorithms has been proposed, with various advantages and limitations. We aim\nto provide insights to researchers and practitioners to allow them to make an\ninformed choice when selecting a treemapping algorithm for specific\napplications and data. To this end, we perform an extensive quantitative\nevaluation of rectangular treemaps for time-dependent data. As part of this\nevaluation we propose a novel classification scheme for time-dependent\ndatasets. Specifically, we observe that the performance of treemapping\nalgorithms depends on the characteristics of the datasets used. We identify\nfour potential representative features that characterize time-dependent\nhierarchical datasets and classify all datasets used in our experiments\naccordingly. We experimentally test the validity of this classification on more\nthan 2000 datasets, and analyze the relative performance of 14 state-of-the-art\nrectangular treemapping algorithms across varying features. Finally, we\nvisually summarize our results with respect to both visual quality and\nstability to aid users in making an informed choice among treemapping\nalgorithms. All datasets, metrics, and algorithms are openly available to\nfacilitate reuse and further comparative studies.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 04:27:15 GMT"}, {"version": "v2", "created": "Thu, 9 Jan 2020 10:03:55 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Vernier", "Eduardo", ""], ["Sondag", "Max", ""], ["Comba", "Joao", ""], ["Speckmann", "Bettina", ""], ["Telea", "Alexandru", ""], ["Verbeek", "Kevin", ""]]}, {"id": "1906.06122", "submitter": "Debabrota Basu", "authors": "Naheed Anjum Arafat, Debabrota Basu, St\\'ephane Bressan", "title": "Topological Data Analysis with $\\epsilon$-net Induced Lazy Witness\n  Complex", "comments": "16 pages, 7 figures, Accepted in DEXA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG math.AT math.ST stat.TH", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Topological data analysis computes and analyses topological features of the\npoint clouds by constructing and studying a simplicial representation of the\nunderlying topological structure. The enthusiasm that followed the initial\nsuccesses of topological data analysis was curbed by the computational cost of\nconstructing such simplicial representations. The lazy witness complex is a\ncomputationally feasible approximation of the underlying topological structure\nof a point cloud. It is built in reference to a subset of points, called\nlandmarks, rather than considering all the points as in the \\v{C}ech and\nVietoris-Rips complexes. The choice and the number of landmarks dictate the\neffectiveness and efficiency of the approximation. We adopt the notion of\n$\\epsilon$-cover to define $\\epsilon$-net. We prove that $\\epsilon$-net, as a\nchoice of landmarks, is an $\\epsilon$-approximate representation of the point\ncloud and the induced lazy witness complex is a $3$-approximation of the\ninduced Vietoris-Rips complex. Furthermore, we propose three algorithms to\nconstruct $\\epsilon$-net landmarks. We establish the relationship of these\nalgorithms with the existing landmark selection algorithms. We empirically\nvalidate our theoretical claims. We empirically and comparatively evaluate the\neffectiveness, efficiency, and stability of the proposed algorithms on\nsynthetic and real datasets.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 10:51:33 GMT"}, {"version": "v2", "created": "Wed, 19 Jun 2019 19:38:35 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Arafat", "Naheed Anjum", ""], ["Basu", "Debabrota", ""], ["Bressan", "St\u00e9phane", ""]]}, {"id": "1906.06154", "submitter": "Yi-Jen Chiang", "authors": "Bo Zhou, Yi-Jen Chiang, Chee Yap", "title": "Soft Subdivision Motion Planning for Complex Planar Robots", "comments": "The conference version of this paper appeared in Proc. European\n  Symposium on Algorithms (ESA 2018), pages 73:1-73:14, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The design and implementation of theoretically-sound robot motion planning\nalgorithms is challenging. Within the framework of resolution-exact algorithms,\nit is possible to exploit soft predicates for collision detection. The design\nof soft predicates is a balancing act between easily implementable predicates\nand their accuracy/effectivity.\n  In this paper, we focus on the class of planar polygonal rigid robots with\narbitrarily complex geometry. We exploit the remarkable decomposability\nproperty of soft collision-detection predicates of such robots. We introduce a\ngeneral technique to produce such a decomposition. If the robot is an m-gon,\nthe complexity of this approach scales linearly in m. This contrasts with the\nO(m^3) complexity known for exact planners. It follows that we can now\nroutinely produce soft predicates for any rigid polygonal robot. This results\nin resolution-exact planners for such robots within the general Soft\nSubdivision Search (SSS) framework. This is a significant advancement in the\ntheory of sound and complete planners for planar robots.\n  We implemented such decomposed predicates in our open-source Core Library.\nThe experiments show that our algorithms are effective, perform in real time on\nnon-trivial environments, and can outperform many sampling-based methods.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 12:10:32 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Zhou", "Bo", ""], ["Chiang", "Yi-Jen", ""], ["Yap", "Chee", ""]]}, {"id": "1906.06208", "submitter": "Tom Hanika", "authors": "Dominik D\\\"urrschnabel and Tom Hanika and Gerd Stumme", "title": "Drawing Order Diagrams Through Two-Dimension Extension", "comments": "16 pages, 12 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Order diagrams are an important tool to visualize the complex structure of\nordered sets. Favorable drawings of order diagrams, i.e., easily readable for\nhumans, are hard to come by, even for small ordered sets. Many attempts were\nmade to transfer classical graph drawing approaches to order diagrams. Although\nthese methods produce satisfying results for some ordered sets, they\nunfortunately perform poorly in general. In this work we present the novel\nalgorithm DimDraw to draw order diagrams. This algorithm is based on a relation\nbetween the dimension of an ordered set and the bipartiteness of a\ncorresponding graph.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 13:58:37 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["D\u00fcrrschnabel", "Dominik", ""], ["Hanika", "Tom", ""], ["Stumme", "Gerd", ""]]}, {"id": "1906.06226", "submitter": "Arianna Rampini", "authors": "Arianna Rampini, Irene Tallini, Maks Ovsjanikov, Alex M. Bronstein,\n  Emanuele Rodol\\`a", "title": "Correspondence-Free Region Localization for Partial Shape Similarity via\n  Hamiltonian Spectrum Alignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of localizing relevant subsets of non-rigid geometric\nshapes given only a partial 3D query as the input. Such problems arise in\nseveral challenging tasks in 3D vision and graphics, including partial shape\nsimilarity, retrieval, and non-rigid correspondence. We phrase the problem as\none of alignment between short sequences of eigenvalues of basic differential\noperators, which are constructed upon a scalar function defined on the 3D\nsurfaces. Our method therefore seeks for a scalar function that entails this\nalignment. Differently from existing approaches, we do not require solving for\na correspondence between the query and the target, therefore greatly\nsimplifying the optimization process; our core technique is also\ndescriptor-free, as it is driven by the geometry of the two objects as encoded\nin their operator spectra. We further show that our spectral alignment\nalgorithm provides a remarkably simple alternative to the recent\nshape-from-spectrum reconstruction approaches. For both applications, we\ndemonstrate improvement over the state-of-the-art either in terms of accuracy\nor computational cost.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 14:40:25 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Rampini", "Arianna", ""], ["Tallini", "Irene", ""], ["Ovsjanikov", "Maks", ""], ["Bronstein", "Alex M.", ""], ["Rodol\u00e0", "Emanuele", ""]]}, {"id": "1906.06543", "submitter": "Hamid Laga", "authors": "Xian-Feng Han, Hamid Laga, Mohammed Bennamoun", "title": "Image-based 3D Object Reconstruction: State-of-the-Art and Trends in the\n  Deep Learning Era", "comments": "arXiv admin note: text overlap with arXiv:1806.06098,\n  arXiv:1712.06584, arXiv:1804.10975 by other authors", "journal-ref": "IEEE Transactions on Pattern Analysis and Machine Intelligence,\n  Nov. 2019", "doi": "10.1109/TPAMI.2019.2954885", "report-no": null, "categories": "cs.CV cs.CG cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  3D reconstruction is a longstanding ill-posed problem, which has been\nexplored for decades by the computer vision, computer graphics, and machine\nlearning communities. Since 2015, image-based 3D reconstruction using\nconvolutional neural networks (CNN) has attracted increasing interest and\ndemonstrated an impressive performance. Given this new era of rapid evolution,\nthis article provides a comprehensive survey of the recent developments in this\nfield. We focus on the works which use deep learning techniques to estimate the\n3D shape of generic objects either from a single or multiple RGB images. We\norganize the literature based on the shape representations, the network\narchitectures, and the training mechanisms they use. While this survey is\nintended for methods which reconstruct generic objects, we also review some of\nthe recent works which focus on specific object classes such as human body\nshapes and faces. We provide an analysis and comparison of the performance of\nsome key papers, summarize some of the open problems in this field, and discuss\npromising directions for future research.\n", "versions": [{"version": "v1", "created": "Sat, 15 Jun 2019 12:35:05 GMT"}, {"version": "v2", "created": "Tue, 18 Jun 2019 15:51:43 GMT"}, {"version": "v3", "created": "Fri, 1 Nov 2019 14:01:31 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Han", "Xian-Feng", ""], ["Laga", "Hamid", ""], ["Bennamoun", "Mohammed", ""]]}, {"id": "1906.06591", "submitter": "Dinesh Dash", "authors": "Dinesh Dash", "title": "Plane Sweep Algorithms for Data Collection in Wireless Sensor Network\n  using Mobile Sink", "comments": "13 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Usage of mobile sink(s) for data gathering in wireless sensor networks(WSNs)\nimproves the performance of WSNs in many respects such as power consumption,\nlifetime, etc. In some applications, the mobile sink $MS$ travels along a\npredefined path to collect data from the nearby sensors, which are referred as\nsub-sinks. Due to the slow speed of the $MS$, the data delivery latency is\nhigh. However, optimizing the {\\em data gathering schedule}, i.e. optimizing\nthe transmission schedule of the sub-sinks to the $MS$ and the movement speed\nof the $MS$ can reduce data gathering latency. We formulate two novel\noptimization problems for data gathering in minimum time. The first problem\ndetermines an optimal data gathering schedule of the $MS$ by controlling the\ndata transmission schedule and the speed of the $MS$, where the data\navailabilities of the sub-sinks are given. The second problem generalizes the\nfirst, where the data availabilities of the sub-sinks are unknown. Plane sweep\nalgorithms are proposed for finding optimal data gathering schedule and data\navailabilities of the sub-sinks. The performances of the proposed algorithms\nare evaluated through simulations. The simulation results reveal that the\noptimal distribution of data among the sub-sinks together with optimal data\ngathering schedule improves the data gathering time.\n", "versions": [{"version": "v1", "created": "Sat, 15 Jun 2019 17:15:39 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Dash", "Dinesh", ""]]}, {"id": "1906.06751", "submitter": "Adriano Raposo", "authors": "Adriano N. Raposo and Abel J.P. Gomes", "title": "Pi-surfaces: products of implicit surfaces towards constructive\n  composition of 3D objects", "comments": null, "journal-ref": "WSCG 2019 27. International Conference in Central Europe on\n  Computer Graphics, Visualization and Computer Vision", "doi": null, "report-no": null, "categories": "cs.GR cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Implicit functions provide a fundamental basis to model 3D objects, no matter\nthey are rigid or deformable, in computer graphics and geometric modeling. This\npaper introduces a new constructive scheme of implicitly-defined 3D objects\nbased on products of implicit functions. This scheme is in contrast with\npopular approaches like blobbies, meta balls and soft objects, which rely on\nthe sum of specific implicit functions to fit a 3D object to a set of spheres.\n", "versions": [{"version": "v1", "created": "Sun, 16 Jun 2019 18:52:31 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Raposo", "Adriano N.", ""], ["Gomes", "Abel J. P.", ""]]}, {"id": "1906.07158", "submitter": "Emanuel Florentin Olariu", "authors": "Emanuel Florentin Olariu", "title": "A Note on Sequences of Lattices", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": "Technical Reports of the Faculty of Computer Science, Alexandru Ioan\n  Cuza University Iasi TR 19-01", "categories": "cs.CG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We investigate the relation between the convergence of a sequence of lattices\nand the set-theoretic convergence of their corresponding Voronoi cells\nsequence. We prove that if a sequence of full rank lattices converges to a full\nrank lattice, then the closures of the limit infimum and limit supremum of the\nVoronoi cells converges to the corresponding Voronoi cell. It remains an open\nquestion if the converse is also true.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 06:07:24 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Olariu", "Emanuel Florentin", ""]]}, {"id": "1906.07631", "submitter": "Fehmi Cirak", "authors": "Ge Yin, Xiao Xiao, Fehmi Cirak", "title": "Topologically robust CAD model generation for structural optimisation", "comments": null, "journal-ref": null, "doi": "10.1016/j.cma.2020.113102", "report-no": null, "categories": "cs.GR cs.CE cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer-aided design (CAD) models play a crucial role in the design,\nmanufacturing and maintenance of products. Therefore, the mesh-based finite\nelement descriptions common in structural optimisation must be first translated\ninto CAD models. Currently, this can at best be performed semi-manually. We\npropose a fully automated and topologically accurate approach to synthesise a\nstructurally-sound parametric CAD model from topology optimised finite element\nmodels. Our solution is to first convert the topology optimised structure into\na spatial frame structure and then to regenerate it in a CAD system using\nstandard constructive solid geometry (CSG) operations. The obtained parametric\nCAD models are compact, that is, have as few as possible geometric parameters,\nwhich makes them ideal for editing and further processing within a CAD system.\nThe critical task of converting the topology optimised structure into an\noptimal spatial frame structure is accomplished in several steps. We first\ngenerate from the topology optimised voxel model a one-voxel-wide voxel chain\nmodel using a topology-preserving skeletonisation algorithm from digital\ntopology. The weighted undirected graph defined by the voxel chain model yields\na spatial frame structure after processing it with standard graph algorithms.\nSubsequently, we optimise the cross-sections and layout of the frame members to\nrecover its optimality, which may have been compromised during the conversion\nprocess. At last, we generate the obtained frame structure in a CAD system by\nrepeatedly combining primitive solids, like cylinders and spheres, using\nboolean operations. The resulting solid model is a boundary representation\n(B-Rep) consisting of trimmed non-uniform rational B-spline (NURBS) curves and\nsurfaces.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 15:09:02 GMT"}, {"version": "v2", "created": "Mon, 8 Jun 2020 22:20:33 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Yin", "Ge", ""], ["Xiao", "Xiao", ""], ["Cirak", "Fehmi", ""]]}, {"id": "1906.07813", "submitter": "Manuel Joseph Loquias", "authors": "Jose Capco, Manuel Joseph C. Loquias, Saraleen Mae M. Manongsong and\n  Fidel R. Nemenzo", "title": "Inverse Kinematics of Some General 6R/P Manipulators", "comments": "11 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop an algorithm that solves the inverse kinematics of general serial\n2RP3R, 2R2P2R, 3RP2R and 6R manipulators based on the HuPf algorithm. We\nidentify the workspaces of the 3-subchains of the manipulator with a\nquasi-projective variety in $\\mathbb{P}^7$ via dual quaternions. This allows us\nto compute linear forms that describe linear spaces containing the workspaces\nof these 3-subchains. We present numerical examples that illustrate the\nalgorithm and show the real solutions.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 16:24:07 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Capco", "Jose", ""], ["Loquias", "Manuel Joseph C.", ""], ["Manongsong", "Saraleen Mae M.", ""], ["Nemenzo", "Fidel R.", ""]]}, {"id": "1906.07919", "submitter": "Supanut Chaidee", "authors": "Supanut Chaidee, Kokichi Sugihara", "title": "Existence of a Convex Polyhedron with Respect to the Given Radii", "comments": "This paper is submitting to the journal 'Discrete and Computational\n  Geometry'", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a set of radii measured from a fixed point, the existence of a convex\nconfiguration with respect to the set of distinct radii in the two-dimensional\ncase is proved when radii are distinct or repeated at most four points.\nHowever, we proved that there always exists a convex configuration in the\nthree-dimensional case. In the application, we can imply the existence of the\nnon-empty spherical Laguerre Voronoi diagram.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 05:13:29 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Chaidee", "Supanut", ""], ["Sugihara", "Kokichi", ""]]}, {"id": "1906.08141", "submitter": "Leonie Ryvkin", "authors": "Hugo A. Akitaya, Leonie Ryvkin, Csaba D. T\\'oth", "title": "Rock Climber Distance: Frogs versus Dogs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The classical measure of similarity between two polygonal chains in Euclidean\nspace is the Fr\\'echet distance, which corresponds to the coordinated motion of\ntwo mobile agents along the chains while minimizing their maximum distance. As\ncomputing the Fr\\'echet distance takes near-quadratic time under the Strong\nExponential Time Hypothesis (SETH), we explore two new distance measures,\ncalled rock climber distance and $k$-station distance, in which the agents move\nalternately in their coordinated motion that traverses the polygonal chains. We\nshow that the new variants are equivalent to the Fr\\'echet or the Hausdorff\ndistance if the number of moves is unlimited. When the number of moves is\nlimited to a given parameter $k$, we show that it is NP-hard to determine the\ndistance between two curves. We also describe a 2-approximation algorithm to\nfind the minimum $k$ for which the distance drops below a given threshold.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 15:09:50 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Akitaya", "Hugo A.", ""], ["Ryvkin", "Leonie", ""], ["T\u00f3th", "Csaba D.", ""]]}, {"id": "1906.08256", "submitter": "Bala Krishnamoorthy", "authors": "Dustin L. Arendt, Matthew Broussard, Bala Krishnamoorthy, Nathaniel\n  Saul", "title": "Steinhaus Filtration and Stable Paths in the Mapper", "comments": "Context for stability result expanded; more details added to\n  Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CG math.AT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two central concepts from topological data analysis are persistence and the\nMapper construction. Persistence employs a sequence of objects built on data\ncalled a filtration. A Mapper produces insightful summaries of data, and has\nfound widespread applications in diverse areas.\n  We define a new filtration called the cover filtration built from a single\ncover based on a generalized Steinhaus distance, which is a generalization of\nJaccard distance. We prove a stability result: the cover filtrations of two\ncovers are $\\alpha/m$ interleaved, where $\\alpha$ is a bound on bottleneck\ndistance between covers and $m$ is the size of smallest set in either cover. We\nalso show our construction is equivalent to the Cech filtration under certain\nsettings, and the Vietoris-Rips filtration completely determines the cover\nfiltration in all cases. We then develop a theory for stable paths within this\nfiltration. Unlike standard results on stability in topological persistence,\nour definition of path stability aligns exactly with the above result on\nstability of cover filtration.\n  We demonstrate how our framework can be employed in a variety of applications\nwhere a metric is not obvious but a cover is readily available. First we\npresent a new model for recommendation systems using cover filtration. For an\nexplicit example, stable paths identified on a movies data set represent\nsequences of movies constituting gentle transitions from one genre to another.\nAs a second application in explainable machine learning, we apply the Mapper\nfor model induction, providing explanations in the form of paths between\nsubpopulations. Stable paths in the Mapper from a supervised machine learning\nmodel trained on the FashionMNIST data set provide improved explanations of\nrelationships between subpopulations of images.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 05:02:42 GMT"}, {"version": "v2", "created": "Mon, 14 Sep 2020 09:23:47 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Arendt", "Dustin L.", ""], ["Broussard", "Matthew", ""], ["Krishnamoorthy", "Bala", ""], ["Saul", "Nathaniel", ""]]}, {"id": "1906.08433", "submitter": "Qiang Zou", "authors": "Qiang Zou, Hsi-Yung Feng", "title": "A decision-support method for information inconsistency resolution in\n  direct modeling of CAD models", "comments": "20 pages, 14 figures", "journal-ref": null, "doi": "10.1016/j.aei.2020.101087", "report-no": null, "categories": "cs.CG cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Direct modeling is a very recent CAD paradigm that can provide unprecedented\nmodeling flexibility. It, however, lacks the parametric capability, which is\nindispensable to modern CAD systems. For direct modeling to have this\ncapability, an additional associativity information layer in the form of\ngeometric constraint systems needs to be incorporated into direct modeling.\nThis is no trivial matter due to the possible inconsistencies between the\nassociativity information and geometry information in a model after direct\nedits. The major issue of resolving such inconsistencies is that there often\nexist many resolution options. The challenge lies in avoiding invalid\nresolution options and prioritizing valid ones. This paper presents an\neffective method to support the user in making decisions among the resolution\noptions. In particular, the method can provide automatic information\ninconsistency reasoning, avoid invalid resolution options completely, and guide\nthe choice among valid resolution options. Case studies and comparisons have\nbeen conducted to demonstrate the effectiveness of the method.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 03:58:52 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Zou", "Qiang", ""], ["Feng", "Hsi-Yung", ""]]}, {"id": "1906.08455", "submitter": "Qiang Zou", "authors": "Qiang Zou, Hsi-Yung Feng", "title": "A robust direct modeling method for quadric B-rep models based on\n  geometry-topology inconsistency tracking", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Boundary representation (B-rep) model editing plays an essential role in\ncomputer-aided design and motivates the very recent direct modeling paradigm,\nwhich features intuitive push-pull manipulation of the model geometry. In\nmechanical design, a substantial part of B-rep models being used are quadric\nmodels (composed of linear and quadric surfaces). However, push-pulling such\nmodels is not trivial due to the possible smooth face-face connections in the\nmodels. The major issue is that, during push-pull moves, it is often desirable\nto preserve these connections for functional, manufacturing, or aesthetic\nreasons, but this could cause complex inconsistencies between the geometry and\ntopology in the model and lead to robustness issues in updating the model. The\nchallenge lies in effectiveness towards detecting the instants when\ngeometry-topology inconsistencies occur during push-pull moves. This paper\nproposes a novel reverse detection method to solve the challenge and then,\nbased on it, presents a robust method for push-pull direct modeling while\npreserving smooth connections. Case studies and comparisons have been conducted\nto demonstrate the effectiveness of the method.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 06:10:47 GMT"}, {"version": "v2", "created": "Wed, 1 Apr 2020 13:07:38 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Zou", "Qiang", ""], ["Feng", "Hsi-Yung", ""]]}, {"id": "1906.08484", "submitter": "Huang Lingxiao", "authors": "Lingxiao Huang, Shaofeng H.-C. Jiang, Nisheeth K. Vishnoi", "title": "Coresets for Clustering with Fairness Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a recent work, [19] studied the following \"fair\" variants of classical\nclustering problems such as $k$-means and $k$-median: given a set of $n$ data\npoints in $\\mathbb{R}^d$ and a binary type associated to each data point, the\ngoal is to cluster the points while ensuring that the proportion of each type\nin each cluster is roughly the same as its underlying proportion. Subsequent\nwork has focused on either extending this setting to when each data point has\nmultiple, non-disjoint sensitive types such as race and gender [6], or to\naddress the problem that the clustering algorithms in the above work do not\nscale well. The main contribution of this paper is an approach to clustering\nwith fairness constraints that involve multiple, non-disjoint types, that is\nalso scalable. Our approach is based on novel constructions of coresets: for\nthe $k$-median objective, we construct an $\\varepsilon$-coreset of size\n$O(\\Gamma k^2 \\varepsilon^{-d})$ where $\\Gamma$ is the number of distinct\ncollections of groups that a point may belong to, and for the $k$-means\nobjective, we show how to construct an $\\varepsilon$-coreset of size $O(\\Gamma\nk^3\\varepsilon^{-d-1})$. The former result is the first known coreset\nconstruction for the fair clustering problem with the $k$-median objective, and\nthe latter result removes the dependence on the size of the full dataset as in\n[39] and generalizes it to multiple, non-disjoint types. Plugging our coresets\ninto existing algorithms for fair clustering such as [5] results in the fastest\nalgorithms for several cases. Empirically, we assess our approach over the\n\\textbf{Adult}, \\textbf{Bank}, \\textbf{Diabetes} and \\textbf{Athlete} dataset,\nand show that the coreset sizes are much smaller than the full dataset. We also\nachieve a speed-up to recent fair clustering algorithms [5,6] by incorporating\nour coreset construction.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 08:00:39 GMT"}, {"version": "v2", "created": "Mon, 12 Aug 2019 08:22:18 GMT"}, {"version": "v3", "created": "Mon, 19 Aug 2019 14:02:48 GMT"}, {"version": "v4", "created": "Tue, 17 Dec 2019 16:52:07 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Huang", "Lingxiao", ""], ["Jiang", "Shaofeng H. -C.", ""], ["Vishnoi", "Nisheeth K.", ""]]}, {"id": "1906.08825", "submitter": "Colin Stephen", "authors": "Colin Stephen", "title": "Horizon Visibility Graphs and Time Series Merge Trees are Dual", "comments": "6 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.data-an cs.CG nlin.CD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce the horizon visibility graph, a simple extension\nto the popular horizontal visibility graph representation of a time series, and\nshow that it possesses a rigorous mathematical foundation in computational\nalgebraic topology. This fills a longstanding gap in the literature on the\nhorizontal visibility approach to nonlinear time series analysis which, despite\na suite of successful applications across multiple domains, lacks a formal\nsetting in which to prove general properties and develop natural extensions.\nThe main finding is that horizon visibility graphs are dual to merge trees\narising naturally over a filtered complex associated to a time series, while\nhorizontal visibility graphs are weak duals of these trees. Immediate\nconsequences include availability of tree-based reconstruction theorems,\nconnections to results on the statistics of self-similar trees, and relations\nbetween visibility graphs and the emerging field of applied persistent\nhomology.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 19:55:21 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Stephen", "Colin", ""]]}, {"id": "1906.09003", "submitter": "Christoph David Hofer M.Sc.", "authors": "Christoph Hofer, Roland Kwitt, Mandar Dixit, Marc Niethammer", "title": "Connectivity-Optimized Representation Learning via Persistent Homology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CG math.AT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning representations with controllable\nconnectivity properties. This is beneficial in situations when the imposed\nstructure can be leveraged upstream. In particular, we control the connectivity\nof an autoencoder's latent space via a novel type of loss, operating on\ninformation from persistent homology. Under mild conditions, this loss is\ndifferentiable and we present a theoretical analysis of the properties induced\nby the loss. We choose one-class learning as our upstream task and demonstrate\nthat the imposed structure enables informed parameter selection for modeling\nthe in-class distribution via kernel density estimators. Evaluated on computer\nvision data, these one-class models exhibit competitive performance and, in a\nlow sample size regime, outperform other methods by a large margin. Notably,\nour results indicate that a single autoencoder, trained on auxiliary\n(unlabeled) data, yields a mapping into latent space that can be reused across\ndatasets for one-class learning.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 08:23:57 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Hofer", "Christoph", ""], ["Kwitt", "Roland", ""], ["Dixit", "Mandar", ""], ["Niethammer", "Marc", ""]]}, {"id": "1906.09158", "submitter": "Wei Zeng", "authors": "Wei Zeng, Abdur B. Shahid, Keyan Zolfaghari, Aditya Shetty, Niki\n  Pissinou, and Sitharama S. Iyengar", "title": "$n$-VDD: Location Privacy Protection Based on Voronoi-Delaunay Duality", "comments": "12 pages, 19 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To date, location privacy protection is a critical issue in Location-Based\nServices (LBS). In this work, we propose a novel geometric framework based on\nthe classical discrete geometric structure, the Voronoi-Delaunay duality (VDD).\nWe utilize the fact that the user location cannot be recovered if only given an\nirregular $n$-sided Voronoi cell around it, and the anonymity zone is the\nintersection of all the parallel strips perpendicular to and bounded by $n$\nVoronoi edges. The irregular Voronoi cell and its variations can be used as the\nconcealing space to hide the user location or the region of interest and\nsubmitted to the LBS server. Within this framework, we propose multiple typical\nanonymizing models by introducing irregularity to the convex regular VDD\nstructure by shifting the interior Voronoi cell, exterior Delaunay polygon,\nsector rays, or their combinations. The proposed methods are efficient by\ntaking advantage of the VDD principle where main computations are linear\nline-line intersections. Experiments with various parameters demonstrate the\nefficiency and efficacy of the proposed $n$-VDD framework.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 14:15:21 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Zeng", "Wei", ""], ["Shahid", "Abdur B.", ""], ["Zolfaghari", "Keyan", ""], ["Shetty", "Aditya", ""], ["Pissinou", "Niki", ""], ["Iyengar", "Sitharama S.", ""]]}, {"id": "1906.09457", "submitter": "Paul Rosen", "authors": "Paul Rosen, Ashley Suh, Christopher Salgado, Mustafa Hajij", "title": "TopoLines: Topological Smoothing for Line Charts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CG cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Line charts are commonly used to visualize a series of data values. When the\ndata are noisy, smoothing is applied to make the signal more apparent.\nConventional methods used to smooth line charts, e.g., using subsampling or\nfilters, such as median, Gaussian, or low-pass, each optimize for different\nproperties of the data. The properties generally do not include retaining peaks\n(i.e., local minima and maxima) in the data, which is an important feature for\ncertain visual analytics tasks. We present TopoLines, a method for smoothing\nline charts using techniques from Topological Data Analysis. The design goal of\nTopoLines is to maintain prominent peaks in the data while minimizing any\nresidual error. We evaluate TopoLines for 2 visual analytics tasks by comparing\nto 5 popular line smoothing methods with data from 4 application domains.\n", "versions": [{"version": "v1", "created": "Sat, 22 Jun 2019 14:59:54 GMT"}, {"version": "v2", "created": "Fri, 3 Apr 2020 20:08:41 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Rosen", "Paul", ""], ["Suh", "Ashley", ""], ["Salgado", "Christopher", ""], ["Hajij", "Mustafa", ""]]}, {"id": "1906.09714", "submitter": "Aditya Vikram Singh", "authors": "Aditya V. Singh, Kunal N. Chaudhury", "title": "On Uniquely Registrable Networks", "comments": "10 pages, 8 figures, accepted for publication in the IEEE\n  Transactions on Network Science and Engineering", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a network with $N$ nodes in $d$-dimensional Euclidean space, and $M$\nsubsets of these nodes $P_1,\\cdots,P_M$. Assume that the nodes in a given $P_i$\nare observed in a local coordinate system. The registration problem is to\ncompute the coordinates of the $N$ nodes in a global coordinate system, given\nthe information about $P_1,\\cdots,P_M$ and the corresponding local coordinates.\nThe network is said to be uniquely registrable if the global coordinates can be\ncomputed uniquely (modulo Euclidean transforms). We formulate a necessary and\nsufficient condition for a network to be uniquely registrable in terms of\nrigidity of the body graph of the network. A particularly simple\ncharacterization of unique registrability is obtained for planar networks.\nFurther, we show that $k$-vertex-connectivity of the body graph is equivalent\nto quasi $k$-connectivity of the bipartite correspondence graph of the network.\nAlong with results from rigidity theory, this helps us resolve a recent\nconjecture due to Sanyal et al. (IEEE TSP, 2017) that quasi $3$-connectivity of\nthe correspondence graph is both necessary and sufficient for unique\nregistrability in two dimensions. We present counterexamples demonstrating that\nwhile quasi $(d+1)$-connectivity is necessary for unique registrability in any\ndimension, it fails to be sufficient in three and higher dimensions.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 04:17:20 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Singh", "Aditya V.", ""], ["Chaudhury", "Kunal N.", ""]]}, {"id": "1906.09783", "submitter": "Arnold Filtser", "authors": "Arnold Filtser", "title": "On Strong Diameter Padded Decompositions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a weighted graph $G=(V,E,w)$, a partition of $V$ is $\\Delta$-bounded if\nthe diameter of each cluster is bounded by $\\Delta$. A distribution over\n$\\Delta$-bounded partitions is a $\\beta$-padded decomposition if every ball of\nradius $\\gamma\\Delta$ is contained in a single cluster with probability at\nleast $e^{-\\beta\\cdot\\gamma}$. The weak diameter of a cluster $C$ is measured\nw.r.t. distances in $G$, while the strong diameter is measured w.r.t. distances\nin the induced graph $G[C]$. The decomposition is weak/strong according to the\ndiameter guarantee.\n  Formerly, it was proven that $K_r$ free graphs admit weak decompositions with\npadding parameter $O(r)$, while for strong decompositions only $O(r^2)$ padding\nparameter was known. Furthermore, for the case of a graph $G$, for which the\ninduced shortest path metric $d_G$ has doubling dimension $d$, a weak\n$O(d)$-padded decomposition was constructed, which is also known to be tight.\nFor the case of strong diameter, nothing was known.\n  We construct strong $O(r)$-padded decompositions for $K_r$ free graphs,\nmatching the state of the art for weak decompositions. Similarly, for graphs\nwith doubling dimension $d$ we construct a strong $O(d)$-padded decomposition,\nwhich is also tight. We use this decomposition to construct\n$(O(d),\\tilde{O}(d))$-sparse cover scheme for such graphs. Our new\ndecompositions and cover have implications to approximating unique games, the\nconstruction of light and sparse spanners, and for path reporting distance\noracles.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 08:41:08 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Filtser", "Arnold", ""]]}, {"id": "1906.10217", "submitter": "Wolfgang Mulzer", "authors": "Ke Chen and Adrian Dumitrescu and Wolfgang Mulzer and Csaba D. T\\'oth", "title": "On the Stretch Factor of Polygonal Chains", "comments": "16 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $P=(p_1, p_2, \\dots, p_n)$ be a polygonal chain. The stretch factor of\n$P$ is the ratio between the total length of $P$ and the distance of its\nendpoints, $\\sum_{i = 1}^{n-1} |p_i p_{i+1}|/|p_1 p_n|$. For a parameter $c\n\\geq 1$, we call $P$ a $c$-chain if $|p_ip_j|+|p_jp_k| \\leq c|p_ip_k|$, for\nevery triple $(i,j,k)$, $1 \\leq i<j<k \\leq n$. The stretch factor is a global\nproperty: it measures how close $P$ is to a straight line, and it involves all\nthe vertices of $P$; being a $c$-chain, on the other hand, is a\nfingerprint-property: it only depends on subsets of $O(1)$ vertices of the\nchain.\n  We investigate how the $c$-chain property influences the stretch factor in\nthe plane: (i) we show that for every $\\varepsilon > 0$, there is a noncrossing\n$c$-chain that has stretch factor $\\Omega(n^{1/2-\\varepsilon})$, for\nsufficiently large constant $c=c(\\varepsilon)$; (ii) on the other hand, the\nstretch factor of a $c$-chain $P$ is $O\\left(n^{1/2}\\right)$, for every\nconstant $c\\geq 1$, regardless of whether $P$ is crossing or noncrossing; and\n(iii) we give a randomized algorithm that can determine, for a polygonal chain\n$P$ in $\\mathbb{R}^2$ with $n$ vertices, the minimum $c\\geq 1$ for which $P$ is\na $c$-chain in $O\\left(n^{2.5}\\ {\\rm polylog}\\ n\\right)$ expected time and\n$O(n\\log n)$ space.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 20:13:31 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Chen", "Ke", ""], ["Dumitrescu", "Adrian", ""], ["Mulzer", "Wolfgang", ""], ["T\u00f3th", "Csaba D.", ""]]}, {"id": "1906.10669", "submitter": "Erva Ulu", "authors": "Erva Ulu, James McCann, Levent Burak Kara", "title": "Structural Design Using Laplacian Shells", "comments": "Eurographics Symposium on Geometry Processing (SGP) 2019 / Computer\n  Graphics Forum", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.GR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a method to design lightweight shell objects that are\nstructurally robust under the external forces they may experience during use.\nGiven an input 3D model and a general description of the external forces, our\nalgorithm generates a structurally-sound minimum weight shell object. Our\napproach works by altering the local shell thickness repeatedly based on the\nstresses that develop inside the object. A key issue in shell design is that\nlarge thickness values might result in self-intersections on the inner boundary\ncreating a significant computational challenge during optimization. To address\nthis, we propose a shape parametrization based on the solution to the Laplace's\nequation that guarantees smooth and intersection-free shell boundaries.\nCombined with our gradient-free optimization algorithm, our method provides a\npractical solution to the structural design of hollow objects with a single\ninner cavity. We demonstrate our method on a variety of problems with arbitrary\n3D models under complex force configurations and validate its performance with\nphysical experiments.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 17:06:07 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Ulu", "Erva", ""], ["McCann", "James", ""], ["Kara", "Levent Burak", ""]]}, {"id": "1906.11327", "submitter": "Omri Ben-Eliezer", "authors": "Omri Ben-Eliezer and Eylon Yogev", "title": "The Adversarial Robustness of Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG cs.CR cs.DB cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random sampling is a fundamental primitive in modern algorithms, statistics,\nand machine learning, used as a generic method to obtain a small yet\n\"representative\" subset of the data. In this work, we investigate the\nrobustness of sampling against adaptive adversarial attacks in a streaming\nsetting: An adversary sends a stream of elements from a universe $U$ to a\nsampling algorithm (e.g., Bernoulli sampling or reservoir sampling), with the\ngoal of making the sample \"very unrepresentative\" of the underlying data\nstream. The adversary is fully adaptive in the sense that it knows the exact\ncontent of the sample at any given point along the stream, and can choose which\nelement to send next accordingly, in an online manner.\n  Well-known results in the static setting indicate that if the full stream is\nchosen in advance (non-adaptively), then a random sample of size $\\Omega(d /\n\\varepsilon^2)$ is an $\\varepsilon$-approximation of the full data with good\nprobability, where $d$ is the VC-dimension of the underlying set system\n$(U,R)$. Does this sample size suffice for robustness against an adaptive\nadversary? The simplistic answer is \\emph{negative}: We demonstrate a set\nsystem where a constant sample size (corresponding to VC-dimension $1$)\nsuffices in the static setting, yet an adaptive adversary can make the sample\nvery unrepresentative, as long as the sample size is (strongly) sublinear in\nthe stream length, using a simple and easy-to-implement attack.\n  However, this attack is \"theoretical only\", requiring the set system size to\n(essentially) be exponential in the stream length. This is not a coincidence:\nWe show that to make Bernoulli or reservoir sampling robust against adaptive\nadversaries, the modification required is solely to replace the VC-dimension\nterm $d$ in the sample size with the cardinality term $\\log |R|$. This nearly\nmatches the bound imposed by the attack.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 20:15:54 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Ben-Eliezer", "Omri", ""], ["Yogev", "Eylon", ""]]}, {"id": "1906.11337", "submitter": "Madeleine Weinstein", "authors": "Madeline Brandt and Madeleine Weinstein", "title": "Voronoi Cells in Metric Algebraic Geometry of Plane Curves", "comments": "23 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.MG cs.CG math.AG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Voronoi cells of varieties encode many features of their metric geometry. We\nprove that each Voronoi or Delaunay cell of a plane curve appears as the limit\nof a sequence of cells obtained from point samples of the curve. We use this\nresult to study metric features of plane curves, including the medial axis,\ncurvature, evolute, bottlenecks, and reach. In each case, we provide algebraic\nequations defining the object and, where possible, give formulas for the\ndegrees of these algebraic varieties. We show how to identify the desired\nmetric feature from Voronoi or Delaunay cells, and therefore how to approximate\nit by a finite point sample from the variety.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 20:29:17 GMT"}, {"version": "v2", "created": "Fri, 1 Nov 2019 21:00:06 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Brandt", "Madeline", ""], ["Weinstein", "Madeleine", ""]]}, {"id": "1906.11447", "submitter": "Mira Shalah", "authors": "Gill Barequet and Mira Shalah", "title": "Improved Upper Bounds on the Growth Constants of Polyominoes and\n  Polycubes", "comments": "preliminary version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CG math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A $d$-dimensional polycube is a facet-connected set of cells (cubes) on the\n$d$-dimensional cubical lattice $\\mathbb{Z}^d$. Let $A_d(n)$ denote the number\nof $d$-dimensional polycubes (distinct up to translations) with $n$ cubes, and\n$\\lambda_d$ denote the limit of the ratio $A_d(n{+}1)/A_d(n)$ as $n \\to\n\\infty$. The exact value of $\\lambda_d$ is still unknown rigorously for any\ndimension $d \\geq 2$; the asymptotics of $\\lambda_d$, as $d \\to \\infty$, also\nremained elusive as of today. In this paper, we revisit and extend the approach\npresented by Klarner and Rivest in 1973 to bound $A_2(n)$ from above. Our\ncontributions are: Using available computing power, we prove that $\\lambda_2\n\\leq 4.5252$. This is the first improvement of the upper bound on $\\lambda_2$\nin almost half a century; We prove that $\\lambda_d \\leq (2d-2)e+o(1)$ for any\nvalue of $d \\geq 2$, using a novel construction of a rational generating\nfunction which dominates that of the sequence $\\left(A_d(n)\\right)$; For $d=3$,\nthis provides a subtantial improvement of the upper bound on $\\lambda_3$ from\n12.2071 to 9.8073; However, we implement an iterative process in three\ndimensions, which improves further the upper bound on $\\lambda_3$to $9.3835$.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 06:07:49 GMT"}, {"version": "v2", "created": "Fri, 28 Jun 2019 22:38:31 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Barequet", "Gill", ""], ["Shalah", "Mira", ""]]}, {"id": "1906.11948", "submitter": "Saeed Mehrabi", "authors": "Therese Biedl, Ahmad Biniaz, Anil Maheshwari, and Saeed Mehrabi", "title": "Packing Boundary-Anchored Rectangles and Squares", "comments": "18 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a set $P$ of $n$ points on the boundary of an axis-aligned square\n$Q$. We study the boundary-anchored packing problem on $P$ in which the goal is\nto find a set of interior-disjoint axis-aligned rectangles in $Q$ such that\neach rectangle is anchored (has a corner at some point in $P$), each point in\n$P$ is used to anchor at most one rectangle, and the total area of the\nrectangles is maximized. Here, a rectangle is anchored at a point $p$ in $P$ if\none of its corners coincides with $p$. In this paper, we show how to solve this\nproblem in time linear in $n$, provided that the points of $P$ are given in\nsorted order along the boundary of $Q$. We also consider the problem for\nanchoring squares and give an $O(n^4)$-time algorithm when the points in $P$\nlie on two opposite sides of $Q$.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 20:29:50 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Biedl", "Therese", ""], ["Biniaz", "Ahmad", ""], ["Maheshwari", "Anil", ""], ["Mehrabi", "Saeed", ""]]}, {"id": "1906.11999", "submitter": "Chaoyang He", "authors": "Chaoyang He, Ming Li", "title": "Efficient Spatial Anti-Aliasing Rendering for Line Joins on Vector Maps", "comments": "4 pages. Submitted to 1st ACM SIGSPATIAL International Workshop on\n  Spatial Gems (SpatialGems 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.CG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The spatial anti-aliasing technique for line joins (intersections of the road\nsegments) on vector maps is exclusively crucial to visual experience and system\nperformance. Due to limitations of OpenGL API, one common practice to achieve\nthe anti-aliased effect is splicing multiple triangles at varying scale levels\nto approximate the fan-shaped line joins. However, this approximation\ninevitably produces some unreality, and the system rendering performance is not\noptimal. To circumvent these drawbacks, in this paper, we propose a simple but\nefficient algorithm which uses only two triangles to substitute the multiple\ntriangles approximation and then renders a realistic fan-shaped curve with\nalpha operation based on geometrical relation computing. Our experiment shows\nit has advantages of a realistic anti-aliasing effect, less memory cost, higher\nframe rate, and drawing line joins without overlapping rendering. Our proposed\nspatial anti-aliasing technique has been widely used in Internet Maps such as\nTencent Mobile Maps and Tencent Automotive Maps.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 23:58:37 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["He", "Chaoyang", ""], ["Li", "Ming", ""]]}, {"id": "1906.12141", "submitter": "Deok-Soo Kim PhD", "authors": "Deok-Soo Kima, Joonghyun Ryua, Youngsong Choa, Mokwon Leeb, Jehyun\n  Cha, Chanyoung Song, Sangwha Kim, Roman A Laskowskid, Kokichi Sugihara, Jong\n  Bhak, Seong Eon Ryu", "title": "MGOS: A Library for Molecular Geometry and its Operating System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The geometry of atomic arrangement underpins the structural understanding of\nmolecules in many fields. However, no general framework of\nmathematical/computational theory for the geometry of atomic arrangement\nexists. Here we present \"Molecular Geometry (MG)\" as a theoretical framework\naccompanied by \"MG Operating System (MGOS)\" which consists of callable\nfunctions implementing the MG theory. MG allows researchers to model\ncomplicated molecular structure problems in terms of elementary yet standard\nnotions of volume, area, etc. and MGOS frees them from the hard and tedious\ntask of developing/implementing geometric algorithms so that they can focus\nmore on their primary research issues. MG facilitates simpler modeling of\nmolecular structure problems; MGOS functions can be conveniently embedded in\napplication programs for the efficient and accurate solution of geometric\nqueries involving atomic arrangements. The use of MGOS in problems involving\nspherical entities is akin to the use of math libraries in general purpose\nprogramming languages in science and engineering.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 11:34:09 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Kima", "Deok-Soo", ""], ["Ryua", "Joonghyun", ""], ["Choa", "Youngsong", ""], ["Leeb", "Mokwon", ""], ["Cha", "Jehyun", ""], ["Song", "Chanyoung", ""], ["Kim", "Sangwha", ""], ["Laskowskid", "Roman A", ""], ["Sugihara", "Kokichi", ""], ["Bhak", "Jong", ""], ["Ryu", "Seong Eon", ""]]}, {"id": "1906.12211", "submitter": "Martin Aum\\\"uller", "authors": "Martin Aum\\\"uller, Tobias Christiani, Rasmus Pagh, Michael Vesterli", "title": "PUFFINN: Parameterless and Universally Fast FInding of Nearest Neighbors", "comments": "Extended version of the ESA 2019 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present PUFFINN, a parameterless LSH-based index for solving the\n$k$-nearest neighbor problem with probabilistic guarantees. By parameterless we\nmean that the user is only required to specify the amount of memory the index\nis supposed to use and the result quality that should be achieved. The index\ncombines several heuristic ideas known in the literature. By small adaptions to\nthe query algorithm, we make heuristics rigorous. We perform experiments on\nreal-world and synthetic inputs to evaluate implementation choices and show\nthat the implementation satisfies the quality guarantees while being\ncompetitive with other state-of-the-art approaches to nearest neighbor search.\n  We describe a novel synthetic data set that is difficult to solve for almost\nall existing nearest neighbor search approaches, and for which PUFFINN\nsignificantly outperform previous methods.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 13:33:17 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Aum\u00fcller", "Martin", ""], ["Christiani", "Tobias", ""], ["Pagh", "Rasmus", ""], ["Vesterli", "Michael", ""]]}]