[{"id": "1109.0001", "submitter": "Toshiki Endo", "authors": "Toshiki Endo and Yuki Suzuki", "title": "Vertex unfoldings of tight polyhedra", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An unfolding of a polyhedron along its edges is called a vertex unfolding if\nadjacent faces are allowed to be connected at not only an edge but also a\nvertex. Demaine et al showed that every triangulated polyhedron has a vertex\nunfolding. We extend this result to a tight polyhedron, where a polyhedron is\ntight if all non-triangular faces are mutually non-adjacent parallelograms.\n", "versions": [{"version": "v1", "created": "Wed, 31 Aug 2011 12:55:17 GMT"}, {"version": "v2", "created": "Tue, 15 Nov 2011 09:59:43 GMT"}, {"version": "v3", "created": "Mon, 18 Feb 2013 14:09:54 GMT"}], "update_date": "2013-02-19", "authors_parsed": [["Endo", "Toshiki", ""], ["Suzuki", "Yuki", ""]]}, {"id": "1109.0129", "submitter": "Sheng-Gwo Chen", "authors": "Sheng-Gwo Chen, Jyh-Yang Wu", "title": "Discrete Conservation Law on Curved Surfaces", "comments": "18 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG math.NA physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we shall introduce a simple, effective numerical method for\nfinding differential operators for scalar and vector-valued functions on\nsurfaces. The key idea of our algorithm is to develop an intrinsic and unified\nway to compute directly the partial derivatives of functions defined on\ntriangular meshes which are the discretization of regular surfaces under\nconsideration. Most importantly, the divergence theorem and conservation laws\non triangular meshes are fulfilled.\n", "versions": [{"version": "v1", "created": "Thu, 1 Sep 2011 08:57:31 GMT"}], "update_date": "2011-09-02", "authors_parsed": [["Chen", "Sheng-Gwo", ""], ["Wu", "Jyh-Yang", ""]]}, {"id": "1109.0312", "submitter": "Joseph Simons", "authors": "Michael T. Goodrich and Joseph A. Simons", "title": "Fully Retroactive Approximate Range and Nearest Neighbor Searching", "comments": "24 pages, 4 figures. To appear at the 22nd International Symposium on\n  Algorithms and Computation (ISAAC 2011)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe fully retroactive dynamic data structures for approximate range\nreporting and approximate nearest neighbor reporting. We show how to maintain,\nfor any positive constant $d$, a set of $n$ points in $\\R^d$ indexed by time\nsuch that we can perform insertions or deletions at any point in the timeline\nin $O(\\log n)$ amortized time. We support, for any small constant $\\epsilon>0$,\n$(1+\\epsilon)$-approximate range reporting queries at any point in the timeline\nin $O(\\log n + k)$ time, where $k$ is the output size. We also show how to\nanswer $(1+\\epsilon)$-approximate nearest neighbor queries for any point in the\npast or present in $O(\\log n)$ time.\n", "versions": [{"version": "v1", "created": "Thu, 1 Sep 2011 21:57:42 GMT"}], "update_date": "2011-09-05", "authors_parsed": [["Goodrich", "Michael T.", ""], ["Simons", "Joseph A.", ""]]}, {"id": "1109.0345", "submitter": "Christian Duncan", "authors": "Christian A. Duncan and David Eppstein and Michael T. Goodrich and\n  Stephen G. Kobourov and Maarten L\\\"offler", "title": "Planar and Poly-Arc Lombardi Drawings", "comments": "Expanded version of paper appearing in the 19th International\n  Symposium on Graph Drawing (GD 2011). 16 pages, 8 figures", "journal-ref": "J. Computational Geometry 9 (1): 328-355, 2018", "doi": "10.20382/jocg.v9i1a11", "report-no": null, "categories": "cs.CG cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Lombardi drawings of graphs, edges are represented as circular arcs, and\nthe edges incident on vertices have perfect angular resolution. However, not\nevery graph has a Lombardi drawing, and not every planar graph has a planar\nLombardi drawing. We introduce k-Lombardi drawings, in which each edge may be\ndrawn with k circular arcs, noting that every graph has a smooth 2-Lombardi\ndrawing. We show that every planar graph has a smooth planar 3-Lombardi drawing\nand further investigate topics connecting planarity and Lombardi drawings.\n", "versions": [{"version": "v1", "created": "Fri, 2 Sep 2011 03:00:29 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Duncan", "Christian A.", ""], ["Eppstein", "David", ""], ["Goodrich", "Michael T.", ""], ["Kobourov", "Stephen G.", ""], ["L\u00f6ffler", "Maarten", ""]]}, {"id": "1109.0389", "submitter": "Kostas Tsichlas", "authors": "Athanasios Tsakalidis and Kostas Tsichlas", "title": "A Space-Optimal Hidden Surface Removal Algorithm for Iso-Oriented\n  Rectangles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem of finding the visible pieces of a scene of\nobjects from a specified viewpoint. In particular, we are interested in the\ndesign of an efficient hidden surface removal algorithm for a scene comprised\nof iso-oriented rectangles. We propose an algorithm where given a set of $n$\niso-oriented rectangles we report all visible surfaces in $O((n+k)\\log n)$ time\nand linear space, where $k$ is the number of surfaces reported. The previous\nbest result by Bern, has the same time complexity but uses $O(n\\log n)$ space.\n", "versions": [{"version": "v1", "created": "Fri, 2 Sep 2011 09:16:09 GMT"}], "update_date": "2011-09-05", "authors_parsed": [["Tsakalidis", "Athanasios", ""], ["Tsichlas", "Kostas", ""]]}, {"id": "1109.1152", "submitter": "Antoine Vigneron", "authors": "Herv\\'e Fournier and Antoine Vigneron", "title": "A deterministic algorithm for fitting a step function to a weighted\n  point-set", "comments": "5 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a set of n points in the plane, each point having a positive weight,\nand an integer k>0, we present an optimal O(n \\log n)-time deterministic\nalgorithm to compute a step function with k steps that minimizes the maximum\nweighted vertical distance to the input points. It matches the expected time\nbound of the best known randomized algorithm for this problem. Our approach\nrelies on Cole's improved parametric searching technique.\n", "versions": [{"version": "v1", "created": "Tue, 6 Sep 2011 11:55:08 GMT"}, {"version": "v2", "created": "Thu, 11 Oct 2012 12:05:50 GMT"}], "update_date": "2012-10-12", "authors_parsed": [["Fournier", "Herv\u00e9", ""], ["Vigneron", "Antoine", ""]]}, {"id": "1109.1517", "submitter": "Michael Burr", "authors": "Michael A. Burr and Eynat Rafalin and Diane L. Souvaine", "title": "Dynamic Maintenance of Half-Space Depth for Points and Contours", "comments": "31 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Half-space depth (also called Tukey depth or location depth) is one of the\nmost commonly studied data depth measures because it possesses many desirable\nproperties for data depth functions. The data depth contours bound regions of\nincreasing depth. For the sample case, there are two competing definitions of\ncontours: the rank-based contours and the cover-based contours.\n  In this paper, we present three dynamic algorithms for maintaining the\nhalf-space depth of points and contours: The first maintains the half-space\ndepth of a single point in a data set in $O(\\log n)$ time per update\n(insertion/deletion) and overall linear space. By maintaining such a data\nstructure for each data point, we present an algorithm for dynamically\nmaintaining the rank-based contours in $O(n\\cdot\\log n)$ time per update and\noverall quadratic space. The third dynamic algorithm maintains the cover-based\ncontours in $O(n\\cdot \\log^2 n)$ time per update and overall quadratic space.\n  We also augment our first algorithm to maintain the local cover-based\ncontours at data points while maintaining the same complexities. A corollary of\nthis discussion is a strong structural result of independent interest\ndescribing the behavior of dynamic cover-based contours near data points.\n", "versions": [{"version": "v1", "created": "Wed, 7 Sep 2011 17:29:06 GMT"}], "update_date": "2011-09-08", "authors_parsed": [["Burr", "Michael A.", ""], ["Rafalin", "Eynat", ""], ["Souvaine", "Diane L.", ""]]}, {"id": "1109.1705", "submitter": "Andre Schulz", "authors": "Immanuel Halupczok and Andre Schulz", "title": "Pinning Balloons with Perfect Angles and Optimal Area", "comments": "Full version of the Graph Drawing 2011 conference version, 16 pages,\n  9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of arranging a set of $n$ disks with prescribed radii on\n$n$ rays emanating from the origin such that two neighboring rays are separated\nby an angle of $2\\pi/n$. The center of the disks have to lie on the rays, and\nno two disk centers are allowed to lie on the same ray. We require that the\ndisks have disjoint interiors, and that for every ray the segment between the\norigin and the boundary of its associated disk avoids the interior of the\ndisks. Let $\\r$ be the sum of the disk radii. We introduce a greedy strategy\nthat constructs such a disk arrangement that can be covered with a disk\ncentered at the origin whose radius is at most $2\\r$, which is best possible.\nThe greedy strategy needs O(n) arithmetic operations.\n  As an application of our result we present an algorithm for embedding\nunordered trees with straight lines and perfect angular resolution such that it\ncan be covered with a disk of radius $n^{3.0367}$, while having no edge of\nlength smaller than 1. The tree drawing algorithm is an enhancement of a recent\nresult by Duncan et al. [Symp. of Graph Drawing, 2010] that exploits the\nheavy-edge tree decomposition technique to construct a drawing of the tree that\ncan be covered with a disk of radius $2 n^4$.\n", "versions": [{"version": "v1", "created": "Thu, 8 Sep 2011 12:50:24 GMT"}], "update_date": "2011-09-09", "authors_parsed": [["Halupczok", "Immanuel", ""], ["Schulz", "Andre", ""]]}, {"id": "1109.2158", "submitter": "Eric Berberich", "authors": "Eric Berberich, Dan Halperin, Michael Kerber, Roza Pogalnikova", "title": "Deconstructing Approximate Offsets", "comments": "18 pages, 11 figures, previous version accepted at SoCG 2011,\n  submitted to DCG", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the offset-deconstruction problem: Given a polygonal shape Q with\nn vertices, can it be expressed, up to a tolerance \\eps in Hausdorff distance,\nas the Minkowski sum of another polygonal shape P with a disk of fixed radius?\nIf it does, we also seek a preferably simple-looking solution P; then, P's\noffset constitutes an accurate, vertex-reduced, and smoothened approximation of\nQ. We give an O(n log n)-time exact decision algorithm that handles any\npolygonal shape, assuming the real-RAM model of computation. A variant of the\nalgorithm, which we have implemented using CGAL, is based on rational\narithmetic and answers the same deconstruction problem up to an uncertainty\nparameter \\delta; its running time additionally depends on \\delta. If the input\nshape is found to be approximable, this algorithm also computes an approximate\nsolution for the problem. It also allows us to solve parameter-optimization\nproblems induced by the offset-deconstruction problem. For convex shapes, the\ncomplexity of the exact decision algorithm drops to O(n), which is also the\ntime required to compute a solution P with at most one more vertex than a\nvertex-minimal one.\n", "versions": [{"version": "v1", "created": "Fri, 9 Sep 2011 20:53:39 GMT"}], "update_date": "2011-09-13", "authors_parsed": [["Berberich", "Eric", ""], ["Halperin", "Dan", ""], ["Kerber", "Michael", ""], ["Pogalnikova", "Roza", ""]]}, {"id": "1109.2323", "submitter": "Herman Haverkort", "authors": "Herman Haverkort", "title": "An inventory of three-dimensional Hilbert space-filling curves", "comments": "25 pages, 13 figures. Addition Oct 2016: Appendix C explaining what\n  parts of this article have been superseded by the more recent manuscript \"How\n  many three-dimensional Hilbert curves are there?\"\n  (http://arxiv.org/abs/1610.00155), and pointing out a minor error on page 7", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hilbert's two-dimensional space-filling curve is appreciated for its good\nlocality properties for many applications. However, it is not clear what is the\nbest way to generalize this curve to filling higher-dimensional spaces. We\nargue that the properties that make Hilbert's curve unique in two dimensions,\nare shared by 10694807 structurally different space-filling curves in three\ndimensions. These include several curves that have, in some sense, better\nlocality properties than any generalized Hilbert curve that has been considered\nin the literature before.\n", "versions": [{"version": "v1", "created": "Sun, 11 Sep 2011 15:56:33 GMT"}, {"version": "v2", "created": "Tue, 4 Oct 2016 07:12:45 GMT"}], "update_date": "2016-10-05", "authors_parsed": [["Haverkort", "Herman", ""]]}, {"id": "1109.2361", "submitter": "Marko Petkovic", "authors": "Marko D. Petkovic, Dragoljub Pokrajac, Longin Jan Latecki", "title": "Spherical coverage verification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CC math.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of covering hypersphere by a set of spherical\nhypercaps. This sort of problem has numerous practical applications such as\nerror correcting codes and reverse k-nearest neighbor problem. Using the\nreduction of non degenerated concave quadratic programming (QP) problem, we\ndemonstrate that spherical coverage verification is NP hard. We propose a\nrecursive algorithm based on reducing the problem to several lower dimension\nsubproblems. We test the performance of the proposed algorithm on a number of\ngenerated constellations. We demonstrate that the proposed algorithm, in spite\nof its exponential worst-case complexity, is applicable in practice. In\ncontrast, our results indicate that spherical coverage verification using QP\nsolvers that utilize heuristics, due to numerical instability, may produce\nfalse positives.\n", "versions": [{"version": "v1", "created": "Sun, 11 Sep 2011 23:09:41 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Petkovic", "Marko D.", ""], ["Pokrajac", "Dragoljub", ""], ["Latecki", "Longin Jan", ""]]}, {"id": "1109.2573", "submitter": "Liviu Nicolaescu", "authors": "Liviu I. Nicolaescu, Brandon Rowekamp", "title": "Pixelations of planar semialgebraic sets and shape recognition", "comments": "36 pages, 13 figures, to appear in Algebraic & Geometric Topology", "journal-ref": "Algebr. Geom. Topol. 14 (2014) 3345-3394", "doi": "10.2140/agt.2014.14.3345", "report-no": null, "categories": "math.DG cs.CG math.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe an algorithm that associates to each positive real number $r$ and\neach finite collection $C_r$ of planar pixels of size $r$ a planar piecewise\nlinear set $S_r$ with the following additional property: if $C_r$ is the\ncollection of pixels of size $r$ that touch a given compact semialgebraic set\n$S$, then the normal cycle of $S_r$ converges to the normal cycle of $S$ in the\nsense of currents. In particular, in the limit we can recover the homotopy type\nof $S$ and its geometric invariants such as area, perimeter and curvature\nmeasures. At its core, this algorithm is a discretization of stratified Morse\ntheory.\n", "versions": [{"version": "v1", "created": "Mon, 12 Sep 2011 19:23:10 GMT"}, {"version": "v2", "created": "Mon, 29 Oct 2012 15:14:29 GMT"}, {"version": "v3", "created": "Thu, 24 Apr 2014 14:45:39 GMT"}], "update_date": "2015-05-27", "authors_parsed": [["Nicolaescu", "Liviu I.", ""], ["Rowekamp", "Brandon", ""]]}, {"id": "1109.2763", "submitter": "Eliahu Levy", "authors": "Meir Katchalski, Eliahu Levy", "title": "No O(N) queries for checking if N intervals cover everything or for\n  piercing N pairs of intervals. An O(N log N)-steps algorithm for piercing", "comments": "8 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CG math.MG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The complexity of two related geometrical (indeed, combinatorial) problems is\nconsidered, measured by the number of queries needed to determine the solution.\nIt is proved that one cannot check in a linear in N number of queries whether N\nintervals cover a whole interval, or whether for N pairs of intervals on two\nlines there is a pair of points intersecting each of these pairs of intervals\n(\"piercing all pairs of intervals\"). The proofs are related to examples which\nshow that there is no \"Helly property\" here - the whole set of N may cover the\nwhole interval (resp. may have no pair of points piercing all pairs of\nintervals) while any proper subset does not. Also, for the piercing problem we\noutline an algorithm, taking O(N log N) steps, to check whether there is a pair\nof points piercing all pairs of intervals and if there is, to find it.\n", "versions": [{"version": "v1", "created": "Tue, 13 Sep 2011 12:50:26 GMT"}], "update_date": "2011-09-14", "authors_parsed": [["Katchalski", "Meir", ""], ["Levy", "Eliahu", ""]]}, {"id": "1109.3218", "submitter": "David Wood", "authors": "Ruy Fabila-Monroy and David R. Wood", "title": "Colouring the Triangles Determined by a Point Set", "comments": null, "journal-ref": "J. Computational Geometry 3:86-101, 2012", "doi": null, "report-no": null, "categories": "math.CO cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let P be a set of n points in general position in the plane. We study the\nchromatic number of the intersection graph of the open triangles determined by\nP. It is known that this chromatic number is at least n^3/27+O(n^2), and if P\nis in convex position, the answer is n^3/24+O(n^2). We prove that for arbitrary\nP, the chromatic number is at most n^3/19.259+O(n^2).\n", "versions": [{"version": "v1", "created": "Wed, 14 Sep 2011 22:10:21 GMT"}, {"version": "v2", "created": "Mon, 19 Sep 2011 03:52:17 GMT"}], "update_date": "2013-06-18", "authors_parsed": [["Fabila-Monroy", "Ruy", ""], ["Wood", "David R.", ""]]}, {"id": "1109.3316", "submitter": "Kevin Verbeek", "authors": "Kevin Buchin, Bettina Speckmann, Kevin Verbeek", "title": "Angle-Restricted Steiner Arborescences for Flow Map Layout", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new variant of the geometric Steiner arborescence problem,\nmotivated by the layout of flow maps. Flow maps show the movement of objects\nbetween places. They reduce visual clutter by bundling lines smoothly and\navoiding self-intersections. To capture these properties, our angle-restricted\nSteiner arborescences, or flux trees, connect several targets to a source with\na tree of minimal length whose arcs obey a certain restriction on the angle\nthey form with the source.\n  We study the properties of optimal flux trees and show that they are planar\nand consist of logarithmic spirals and straight lines. Flux trees have the\nshallow-light property. We show that computing optimal flux trees is NP-hard.\nHence we consider a variant of flux trees which uses only logarithmic spirals.\nSpiral trees approximate flux trees within a factor depending on the angle\nrestriction. Computing optimal spiral trees remains NP-hard, but we present an\nefficient 2-approximation, which can be extended to avoid \"positive monotone\"\nobstacles.\n", "versions": [{"version": "v1", "created": "Thu, 15 Sep 2011 11:22:51 GMT"}], "update_date": "2011-09-16", "authors_parsed": [["Buchin", "Kevin", ""], ["Speckmann", "Bettina", ""], ["Verbeek", "Kevin", ""]]}, {"id": "1109.3890", "submitter": "Yakov Nekrich Yakov Nekrich", "authors": "Yakov Nekrich", "title": "A Dynamic Stabbing-Max Data Structure with Sub-Logarithmic Query Time", "comments": "Extended version of a paper accepted to ISAAC 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we describe a dynamic data structure that answers\none-dimensional stabbing-max queries in optimal $O(\\log n/\\log\\log n)$ time.\nOur data structure uses linear space and supports insertions and deletions in\n$O(\\log n)$ and $O(\\log n/\\log \\log n)$ amortized time respectively.\n  We also describe a $O(n(\\log n/\\log\\log n)^{d-1})$ space data structure that\nanswers $d$-dimensional stabbing-max queries in $O((\\log n/\\log\\log n)^{d})$\ntime. Insertions and deletions are supported in $O((\\log n/\\log\\log\nn)^d\\log\\log n)$ and $O((\\log n/\\log\\log n)^d)$ amortized time respectively.\n", "versions": [{"version": "v1", "created": "Sun, 18 Sep 2011 17:17:01 GMT"}], "update_date": "2011-09-20", "authors_parsed": [["Nekrich", "Yakov", ""]]}, {"id": "1109.5052", "submitter": "Michael Kerber", "authors": "Herbert Edelsbrunner and Michael Kerber", "title": "Alexander Duality for Functions: the Persistent Behavior of Land and\n  Water and Shore", "comments": "Keywords: Algebraic topology, homology, Alexander duality,\n  Mayer-Vietoris sequences, persistent homology, point calculus", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AT cs.CG math.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This note contributes to the point calculus of persistent homology by\nextending Alexander duality to real-valued functions. Given a perfect Morse\nfunction $f: S^{n+1} \\to [0,1]$ and a decomposition $S^{n+1} = U \\cup V$ such\nthat $M = \\U \\cap V$ is an $n$-manifold, we prove elementary relationships\nbetween the persistence diagrams of $f$ restricted to $U$, to $V$, and to $M$.\n", "versions": [{"version": "v1", "created": "Fri, 23 Sep 2011 12:21:05 GMT"}], "update_date": "2011-09-26", "authors_parsed": [["Edelsbrunner", "Herbert", ""], ["Kerber", "Michael", ""]]}, {"id": "1109.5730", "submitter": "Diego Rother", "authors": "Diego Rother, Siddharth Mahendran, Ren\\'e Vidal", "title": "Hypothesize and Bound: A Computational Focus of Attention Mechanism for\n  Simultaneous 3D Shape Reconstruction, Pose Estimation and Classification from\n  a Single 2D Image", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents a mathematical framework to simultaneously tackle the\nproblems of 3D reconstruction, pose estimation and object classification, from\na single 2D image. In sharp contrast with state of the art methods that rely\nprimarily on 2D information and solve each of these three problems separately\nor iteratively, we propose a mathematical framework that incorporates prior\n\"knowledge\" about the 3D shapes of different object classes and solves these\nproblems jointly and simultaneously, using a hypothesize-and-bound (H&B)\nalgorithm. In the proposed H&B algorithm one hypothesis is defined for each\npossible pair [object class, object pose], and the algorithm selects the\nhypothesis H that maximizes a function L(H) encoding how well each hypothesis\n\"explains\" the input image. To find this maximum efficiently, the function L(H)\nis not evaluated exactly for each hypothesis H, but rather upper and lower\nbounds for it are computed at a much lower cost. In order to obtain bounds for\nL(H) that are tight yet inexpensive to compute, we extend the theory of shapes\ndescribed in [14] to handle projections of shapes. This extension allows us to\ndefine a probabilistic relationship between the prior knowledge given in 3D and\nthe 2D input image. This relationship is derived from first principles and is\nproven to be the only relationship having the properties that we intuitively\nexpect from a \"projection.\" In addition to the efficiency and optimality\ncharacteristics of H&B algorithms, the proposed framework has the desirable\nproperty of integrating information in the 2D image with information in the 3D\nprior to estimate the optimal reconstruction. While this article focuses\nprimarily on the problem mentioned above, we believe that the theory presented\nherein has multiple other potential applications.\n", "versions": [{"version": "v1", "created": "Mon, 26 Sep 2011 21:40:59 GMT"}], "update_date": "2011-09-28", "authors_parsed": [["Rother", "Diego", ""], ["Mahendran", "Siddharth", ""], ["Vidal", "Ren\u00e9", ""]]}, {"id": "1109.6535", "submitter": "Elizabeth Munch", "authors": "Elizabeth Munch, Michael Shapiro, John Harer", "title": "Failure Filtrations for Fenced Sensor Networks", "comments": null, "journal-ref": null, "doi": "10.1177/0278364912451671", "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider the question of sensor network coverage for a\n2-dimensional domain. We seek to compute the probability that a set of sensors\nfails to cover given only non-metric, local (who is talking to whom)\ninformation and a probability distribution of failure of each node. This builds\non the work of de Silva and Ghrist who analyzed this problem in the\ndeterministic situation. We first show that a it is part of a slightly larger\nclass of problems which is #P-complete, and thus fast algorithms likely do not\nexist unless P$=$NP. We then give a deterministic algorithm which is feasible\nin the case of a small set of sensors, and give a dynamic algorithm for an\narbitrary set of sensors failing over time which utilizes a new criterion for\ncoverage based on the one proposed by de Silva and Ghrist. These algorithms\nbuild on the theory of topological persistence.\n", "versions": [{"version": "v1", "created": "Thu, 29 Sep 2011 14:16:49 GMT"}], "update_date": "2016-04-12", "authors_parsed": [["Munch", "Elizabeth", ""], ["Shapiro", "Michael", ""], ["Harer", "John", ""]]}]