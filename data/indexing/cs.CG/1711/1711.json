[{"id": "1711.00068", "submitter": "Ljubomir Perkovi\\'c", "authors": "Michael Dennis, Ljubomir Perkovi\\'c, Duru T\\\"urko\\u{g}lu", "title": "The Stretch Factor of Hexagon-Delaunay Triangulations", "comments": "33 pages, 19 figures. This second ArXiV version of the paper is the\n  result of a thorough revision to improve the readability of the original\n  paper. This version is also the full version of the extended abstract to be\n  published in the proceedings of the 36th International Symposium on\n  Computational Geometry (SoCG 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of computing the exact stretch factor (i.e., the tight bound on\nthe worst case stretch factor) of a Delaunay triangulation is one of the\nlongstanding open problems in computational geometry. Over the years, a series\nof upper and lower bounds on the exact stretch factor have been obtained but\nthe gap between them is still large. An alternative approach to solving the\nproblem is to develop techniques for computing the exact stretch factor of\n``easier'' types of Delaunay triangulations, in particular those defined using\nregular-polygons instead of a circle. Tight bounds exist for Delaunay\ntriangulations defined using an equilateral triangle and a square. In this\npaper, we determine the exact stretch factor of Delaunay triangulations defined\nusing a regular hexagon: It is 2.\n  We think that the main contribution of this paper are the two techniques we\nhave developed to compute tight upper bounds for the stretch factor of\nHexagon-Delaunay triangulations.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 19:36:41 GMT"}, {"version": "v2", "created": "Sun, 22 Mar 2020 04:14:53 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Dennis", "Michael", ""], ["Perkovi\u0107", "Ljubomir", ""], ["T\u00fcrko\u011flu", "Duru", ""]]}, {"id": "1711.00181", "submitter": "Kai Jin", "authors": "Kai Jin", "title": "Finding all Maximal Area Parallelograms in a Convex Polygon", "comments": "The conference version of this paper was published in CCCG 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG math.AG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Polygon inclusion problems have been studied extensively in geometric\noptimization. In this paper, we consider the variant of computing the maximum\narea parallelograms (MAPs) and all the locally maximal area parallelograms\n(LMAPs) in a given convex polygon. By proving and utilizing several structural\nproperties of the LMAPs, we compute all of them (including all the MAPs) in\n$O(n^2)$ time, where $n$ denotes the number of edges of the given polygon. In\naddition, we prove that the LMAPs interleave each other and thus the number of\nLMAPs is $O(n)$. We discuss applications of our result to, among others, the\nproblem of computing the maximum area centrally-symmetric convex body inside a\nconvex polygon, and the simplest case of the Heilbronn triangle problem.\n", "versions": [{"version": "v1", "created": "Wed, 1 Nov 2017 03:00:36 GMT"}, {"version": "v2", "created": "Thu, 12 Jul 2018 04:33:54 GMT"}, {"version": "v3", "created": "Sat, 28 Jul 2018 14:19:07 GMT"}, {"version": "v4", "created": "Mon, 3 Sep 2018 08:06:17 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Jin", "Kai", ""]]}, {"id": "1711.00765", "submitter": "Barak Sober", "authors": "Barak Sober, Yariv Aizenbud, David Levin", "title": "Approximation of Functions over Manifolds: A Moving Least-Squares\n  Approach", "comments": "arXiv admin note: text overlap with arXiv:1606.07104", "journal-ref": null, "doi": "10.1016/j.cam.2020.113140", "report-no": null, "categories": "stat.ML cs.CG cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an algorithm for approximating a function defined over a\n$d$-dimensional manifold utilizing only noisy function values at locations\nsampled from the manifold with noise. To produce the approximation we do not\nrequire any knowledge regarding the manifold other than its dimension $d$. We\nuse the Manifold Moving Least-Squares approach of (Sober and Levin 2016) to\nreconstruct the atlas of charts and the approximation is built on-top of those\ncharts. The resulting approximant is shown to be a function defined over a\nneighborhood of a manifold, approximating the originally sampled manifold. In\nother words, given a new point, located near the manifold, the approximation\ncan be evaluated directly on that point. We prove that our construction yields\na smooth function, and in case of noiseless samples the approximation order is\n$\\mathcal{O}(h^{m+1})$, where $h$ is a local density of sample parameter (i.e.,\nthe fill distance) and $m$ is the degree of a local polynomial approximation,\nused in our algorithm. In addition, the proposed algorithm has linear time\ncomplexity with respect to the ambient-space's dimension. Thus, we are able to\navoid the computational complexity, commonly encountered in high dimensional\napproximations, without having to perform non-linear dimension reduction, which\ninevitably introduces distortions to the geometry of the data. Additionaly, we\nshow numerical experiments that the proposed approach compares favorably to\nstatistical approaches for regression over manifolds and show its potential.\n", "versions": [{"version": "v1", "created": "Thu, 2 Nov 2017 14:37:04 GMT"}, {"version": "v2", "created": "Tue, 23 Jan 2018 07:49:10 GMT"}, {"version": "v3", "created": "Wed, 8 May 2019 00:05:59 GMT"}, {"version": "v4", "created": "Fri, 17 Jan 2020 02:15:41 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Sober", "Barak", ""], ["Aizenbud", "Yariv", ""], ["Levin", "David", ""]]}, {"id": "1711.00788", "submitter": "Arnaud de Mesmay", "authors": "Erin Wolf Chambers and Arnaud de Mesmay and Tim Ophelders", "title": "On the complexity of optimal homotopies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we provide new structural results and algorithms for the\nHomotopy Height problem. In broad terms, this problem quantifies how much a\ncurve on a surface needs to be stretched to sweep continuously between two\npositions. More precisely, given two homotopic curves $\\gamma_1$ and $\\gamma_2$\non a combinatorial (say, triangulated) surface, we investigate the problem of\ncomputing a homotopy between $\\gamma_1$ and $\\gamma_2$ where the length of the\nlongest intermediate curve is minimized. Such optimal homotopies are relevant\nfor a wide range of purposes, from very theoretical questions in quantitative\nhomotopy theory to more practical applications such as similarity measures on\nmeshes and graph searching problems.\n  We prove that Homotopy Height is in the complexity class NP, and the\ncorresponding exponential algorithm is the best one known for this problem.\nThis result builds on a structural theorem on monotonicity of optimal\nhomotopies, which is proved in a companion paper. Then we show that this\nproblem encompasses the Homotopic Fr\\'echet distance problem which we therefore\nalso establish to be in NP, answering a question which has previously been\nconsidered in several different settings. We also provide an O(log\nn)-approximation algorithm for Homotopy Height on surfaces by adapting an\nearlier algorithm of Har-Peled, Nayyeri, Salvatipour and Sidiropoulos in the\nplanar setting.\n", "versions": [{"version": "v1", "created": "Thu, 2 Nov 2017 15:49:59 GMT"}], "update_date": "2017-11-03", "authors_parsed": [["Chambers", "Erin Wolf", ""], ["de Mesmay", "Arnaud", ""], ["Ophelders", "Tim", ""]]}, {"id": "1711.01171", "submitter": "Arnaud de Mesmay", "authors": "Vincent Cohen-Addad, Arnaud de Mesmay and Eva Rotenberg and Alan\n  Roytman", "title": "The Bane of Low-Dimensionality Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we give a conditional lower bound of $n^{\\Omega(k)}$ on\nrunning time for the classic k-median and k-means clustering objectives (where\nn is the size of the input), even in low-dimensional Euclidean space of\ndimension four, assuming the Exponential Time Hypothesis (ETH). We also\nconsider k-median (and k-means) with penalties where each point need not be\nassigned to a center, in which case it must pay a penalty, and extend our lower\nbound to at least three-dimensional Euclidean space.\n  This stands in stark contrast to many other geometric problems such as the\ntraveling salesman problem, or computing an independent set of unit spheres.\nWhile these problems benefit from the so-called (limited) blessing of\ndimensionality, as they can be solved in time $n^{O(k^{1-1/d})}$ or\n$2^{n^{1-1/d}}$ in d dimensions, our work shows that widely-used clustering\nobjectives have a lower bound of $n^{\\Omega(k)}$, even in dimension four.\n  We complete the picture by considering the two-dimensional case: we show that\nthere is no algorithm that solves the penalized version in time less than\n$n^{o(\\sqrt{k})}$, and provide a matching upper bound of $n^{O(\\sqrt{k})}$.\n  The main tool we use to establish these lower bounds is the placement of\npoints on the moment curve, which takes its inspiration from constructions of\npoint sets yielding Delaunay complexes of high complexity.\n", "versions": [{"version": "v1", "created": "Fri, 3 Nov 2017 14:05:48 GMT"}], "update_date": "2017-11-06", "authors_parsed": [["Cohen-Addad", "Vincent", ""], ["de Mesmay", "Arnaud", ""], ["Rotenberg", "Eva", ""], ["Roytman", "Alan", ""]]}, {"id": "1711.01228", "submitter": "Yong-Xian Wang", "authors": "Yong-Xian Wang and Zheng-Hua Wang", "title": "A Fast Successive Over-Relaxation Algorithm for Force-Directed Network\n  Graph Drawing", "comments": "17 pages, 4 figures, 1 table", "journal-ref": "Sci. China Inf. Sci. (2012) 55: 677", "doi": "10.1007/s11432-011-4208-9", "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Force-directed approach is one of the most widely used methods in graph\ndrawing research. There are two main problems with the traditional\nforce-directed algorithms. First, there is no mature theory to ensure the\nconvergence of iteration sequence used in the algorithm and further, it is hard\nto estimate the rate of convergence even if the convergence is satisfied.\nSecond, the running time cost is increased intolerablely in drawing large-\nscale graphs, and therefore the advantages of the force-directed approach are\nlimited in practice. This paper is focused on these problems and presents a\nsufficient condition for ensuring the convergence of iterations. We then\ndevelop a practical heuristic algorithm for speeding up the iteration in\nforce-directed approach using a successive over-relaxation (SOR) strategy. The\nresults of computational tests on the several benchmark graph datasets used\nwidely in graph drawing research show that our algorithm can dramatically\nimprove the performance of force-directed approach by decreasing both the\nnumber of iterations and running time, and is 1.5 times faster than the latter\non average.\n", "versions": [{"version": "v1", "created": "Fri, 3 Nov 2017 16:33:42 GMT"}, {"version": "v2", "created": "Fri, 9 Mar 2018 15:14:14 GMT"}], "update_date": "2018-03-12", "authors_parsed": [["Wang", "Yong-Xian", ""], ["Wang", "Zheng-Hua", ""]]}, {"id": "1711.01365", "submitter": "Braxton Osting", "authors": "Braxton Osting and Dong Wang", "title": "A generalized MBO diffusion generated motion for orthogonal\n  matrix-valued fields", "comments": "32 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AP cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of finding stationary points of the Dirichlet energy\nfor orthogonal matrix-valued fields. Following the Ginzburg-Landau approach,\nthis energy is relaxed by penalizing the matrix-valued field when it does not\ntake orthogonal matrix values. A generalization of the MBO diffusion generated\nmotion is introduced that effectively finds local minimizers of this energy by\niterating two steps until convergence. In the first step, as in the original\nmethod, the current matrix-valued field is evolved by the diffusion equation.\nIn the second step, the field is pointwise reassigned to the closest orthogonal\nmatrix, which can be computed via the singular value decomposition. We extend\nthe Lyapunov function of Esedoglu and Otto to show that the method is\nnon-increasing on iterates and hence, unconditionally stable. We also prove\nthat spatially discretized iterates converge to a stationary solution in a\nfinite number of iterations. The algorithm is implemented using the closest\npoint method and non-uniform fast Fourier transform. We conclude with several\nnumerical experiments on flat tori and closed surfaces, which, unsurprisingly,\nexhibit classical behavior from the Allen-Cahn and complex Ginzburg Landau\nequations, but also new phenomena.\n", "versions": [{"version": "v1", "created": "Fri, 3 Nov 2017 23:58:36 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Osting", "Braxton", ""], ["Wang", "Dong", ""]]}, {"id": "1711.02161", "submitter": "Eike Neumann", "authors": "Eike Neumann", "title": "On the computability of the Fr\\'echet distance of surfaces in the\n  bit-model of real computation", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the Fr\\'echet distance of two-dimensional parametrised surfaces\nin a metric space is computable in the bit-model of real computation. An\nanalogous result in the real RAM model for piecewise-linear surfaces has\nrecently been obtained by Nayyeri and Xu (2016).\n", "versions": [{"version": "v1", "created": "Mon, 6 Nov 2017 20:29:55 GMT"}, {"version": "v2", "created": "Mon, 2 Apr 2018 19:28:53 GMT"}], "update_date": "2018-04-04", "authors_parsed": [["Neumann", "Eike", ""]]}, {"id": "1711.02221", "submitter": "Nadav Dym", "authors": "Nadav Dym and Yaron Lipman and Raz Slutsky", "title": "A Linear Variational Principle for Riemann Mappings and Discrete\n  Conformality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG math.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider Riemann mappings from bounded Lipschitz domains in the plane to a\ntriangle. We show that in this case the Riemann mapping has a linear\nvariational principle: it is the minimizer of the Dirichlet energy over an\nappropriate affine space. By discretizing the variational principle in a\nnatural way we obtain discrete conformal maps which can be computed by solving\na sparse linear system. We show that these discrete conformal maps converge to\nthe Riemann mapping in $H^1$, even for non-Delaunay triangulations.\nAdditionally, for Delaunay triangulations the discrete conformal maps converge\nuniformly and are known to be bijective. As a consequence we show that the\nRiemann mapping between two bounded Lipschitz domains can be uniformly\napproximated by composing the Riemann mappings between each Lipschitz domain\nand the triangle.\n", "versions": [{"version": "v1", "created": "Mon, 6 Nov 2017 23:19:58 GMT"}, {"version": "v2", "created": "Sun, 11 Feb 2018 16:50:31 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Dym", "Nadav", ""], ["Lipman", "Yaron", ""], ["Slutsky", "Raz", ""]]}, {"id": "1711.02450", "submitter": "Christian Sch\\\"uller", "authors": "Christian Sch\\\"uller, Roi Poranne, Olga Sorkine-Hornung", "title": "Shape Representation by Zippable Ribbons", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shape fabrication from developable parts is the basis for arts such as\npapercraft and needlework, as well as modern architecture and CAD in general,\nand it has inspired much research. We observe that the assembly of complex 3D\nshapes created by existing methods often requires first fabricating many small\nflat parts and then carefully following instructions to assemble them together.\nDespite its significance, this error prone and tedious process is generally\nneglected in the discussion. We propose an approach for shape representation\nthrough a single developable part that attaches to itself and requires no\nassembly instructions. Our inspiration comes from the so-called zipit bags,\nwhich are made of a single, long ribbon with a zipper around its boundary. In\norder to \"assemble\" the bag, one simply needs to zip up the ribbon. Our method\noperates in the same fashion, but it can be used to approximate any shape.\nGiven a 3D model, our algorithm produces plans for a single 2D shape that can\nbe laser cut in few parts from flat fabric or paper. We can then attach a\nzipper along the boundary for quick assembly and disassembly, or apply more\ntraditional approaches, such as gluing and stitching. We show physical and\nvirtual results that demonstrate the capabilities of our method and the ease\nwith which shapes can be assembled.\n", "versions": [{"version": "v1", "created": "Tue, 7 Nov 2017 13:09:18 GMT"}], "update_date": "2017-11-08", "authors_parsed": [["Sch\u00fcller", "Christian", ""], ["Poranne", "Roi", ""], ["Sorkine-Hornung", "Olga", ""]]}, {"id": "1711.03795", "submitter": "Ali Gholami Rudi", "authors": "Ali Gholami Rudi", "title": "Time-Windowed Contiguous Hotspot Queries", "comments": "Updates after ICCG 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A hotspot of a moving entity is a region in which it spends a significant\namount of time. Given the location of a moving object through a certain time\ninterval, i.e. its trajectory, our goal is to find its hotspots. We consider\naxis-parallel square hotspots of fixed side length, which contain the longest\ncontiguous portion of the trajectory. Gudmundsson, van Kreveld, and Staals\n(2013) presented an algorithm to find a hotspot of a trajectory in $O(n \\log\nn)$, in which $n$ is the number of vertices of the trajectory. We present an\nalgorithm for answering \\emph{time-windowed} hotspot queries, to find a hotspot\nin any given time interval. The algorithm has an approximation factor of $1/2$\nand answers each query with the time complexity $O(\\log^2 n)$. The time\ncomplexity of the preprocessing step of the algorithm is $O(n)$. When the query\ncontains the whole trajectory, it implies an $O(n)$ algorithm for finding\napproximate contiguous hotspots.\n", "versions": [{"version": "v1", "created": "Fri, 10 Nov 2017 12:36:17 GMT"}, {"version": "v2", "created": "Sat, 26 May 2018 11:51:19 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Rudi", "Ali Gholami", ""]]}, {"id": "1711.04211", "submitter": "Samir Chowdhury", "authors": "Samir Chowdhury and Facundo M\\'emoli", "title": "Convergence of Hierarchical Clustering and Persistent Homology Methods\n  on Directed Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While there has been much interest in adapting conventional clustering\nprocedures---and in higher dimensions, persistent homology methods---to\ndirected networks, little is known about the convergence of such methods. In\norder to even formulate the problem of convergence for such methods, one needs\nto stipulate a reasonable model for a directed network together with a flexible\nsampling theory for such a model. In this paper we propose and study a\nparticular model of directed networks, and use this model to study the\nconvergence of certain hierarchical clustering and persistent homology methods\nthat accept any matrix of (possibly asymmetric) pairwise relations as input and\nproduce dendrograms and persistence barcodes as outputs. We show that as points\nare sampled from some probability distribution, the output of each method\nconverges almost surely to a dendrogram/barcode depending on the structure of\nthe distribution.\n", "versions": [{"version": "v1", "created": "Sun, 12 Nov 2017 00:21:00 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Chowdhury", "Samir", ""], ["M\u00e9moli", "Facundo", ""]]}, {"id": "1711.04473", "submitter": "Herman Haverkort", "authors": "Herman Haverkort", "title": "Sixteen space-filling curves and traversals for d-dimensional cubes and\n  simplices", "comments": "28 pages, 12 figures. v2: fixed a confusing typo on page 12, line 5", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article describes sixteen different ways to traverse d-dimensional space\nrecursively in a way that is well-defined for any number of dimensions. Each of\nthese traversals has distinct properties that may be beneficial for certain\napplications. Some of the traversals are novel, some have been known in\nprinciple but had not been described adequately for any number of dimensions,\nsome of the traversals have been known. This article is the first to present\nthem all in a consistent notation system. Furthermore, with this article, tools\nare provided to enumerate points in a regular grid in the order in which they\nare visited by each traversal. In particular, we cover: five discontinuous\ntraversals based on subdividing cubes into 2^d subcubes: Z-traversal (Morton\nindexing), U-traversal, Gray-code traversal, Double-Gray-code traversal, and\nInside-out traversal; two discontinuous traversals based on subdividing\nsimplices into 2^d subsimplices: the Hill-Z traversal and the Maehara-reflected\ntraversal; five continuous traversals based on subdividing cubes into 2^d\nsubcubes: the Base-camp Hilbert curve, the Harmonious Hilbert curve, the Alfa\nHilbert curve, the Beta Hilbert curve, and the Butz-Hilbert curve; four\ncontinuous traversals based on subdividing cubes into 3^d subcubes: the Peano\ncurve, the Coil curve, the Half-coil curve, and the Meurthe curve. All of these\ntraversals are self-similar in the sense that the traversal in each of the\nsubcubes or subsimplices of a cube or simplex, on any level of recursive\nsubdivision, can be obtained by scaling, translating, rotating, reflecting\nand/or reversing the traversal of the complete unit cube or simplex.\n", "versions": [{"version": "v1", "created": "Mon, 13 Nov 2017 09:07:41 GMT"}, {"version": "v2", "created": "Wed, 12 Sep 2018 14:30:01 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Haverkort", "Herman", ""]]}, {"id": "1711.04882", "submitter": "Tanmay Inamdar", "authors": "Tanmay Inamdar, Kasturi Varadarajan", "title": "On Partial Covering For Geometric Set Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a generalization of the Set Cover problem called the \\emph{Partial\nSet Cover} in the context of geometric set systems. The input to this problem\nis a set system $(X, \\mathcal{S})$, where $X$ is a set of elements and\n$\\mathcal{S}$ is a collection of subsets of $X$, and an integer $k \\le |X|$.\nThe goal is to cover at least $k$ elements of $X$ by using a minimum-weight\ncollection of sets from $\\mathcal{S}$. The main result of this article is an LP\nrounding scheme which shows that the integrality gap of the Partial Set Cover\nLP is at most a constant times that of the Set Cover LP for a certain\nprojection of the set system $(X, \\mathcal{S})$. As a corollary of this result,\nwe get improved approximation guarantees for the Partial Set Cover problem for\na large class of geometric set systems.\n", "versions": [{"version": "v1", "created": "Mon, 13 Nov 2017 22:50:49 GMT"}, {"version": "v2", "created": "Tue, 12 Dec 2017 17:03:09 GMT"}], "update_date": "2017-12-13", "authors_parsed": [["Inamdar", "Tanmay", ""], ["Varadarajan", "Kasturi", ""]]}, {"id": "1711.05016", "submitter": "Morad Behandish", "authors": "Morad Behandish and Horea T. Ilies", "title": "Peg-in-Hole Revisited: A Generic Force Model for Haptic Assembly", "comments": "A shorter version was presented in ASME Computers and Information in\n  Engineering Conference (CIE'2014) (Best Paper Award)", "journal-ref": "ASME Transactions, Journal of ASME Transactions, Journal of\n  Computing and Information Science in Engineering, 15(4), p.041004, 2015", "doi": "10.1115/1.4030749", "report-no": "CDL-TR-15-08", "categories": "cs.HC cs.CG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of a generic and effective force model for semi-automatic or\nmanual virtual assembly with haptic support is not a trivial task, especially\nwhen the assembly constraints involve complex features of arbitrary shape. The\nprimary challenge lies in a proper formulation of the guidance forces and\ntorques that effectively assist the user in the exploration of the virtual\nenvironment (VE), from repulsing collisions to attracting proper contact. The\nsecondary difficulty is that of efficient implementation that maintains the\nstandard 1 kHz haptic refresh rate. We propose a purely geometric model for an\nartificial energy field that favors spatial relations leading to proper\nassembly, differentiated to obtain forces and torques for general motions. The\nenergy function is expressed in terms of a cross-correlation of shape-dependent\naffinity fields, precomputed offline separately for each object. We test the\neffectiveness of the method using familiar peg-in-hole examples. We show that\nthe proposed technique unifies the two phases of free motion and precise\ninsertion into a single interaction mode and provides a generic model to\nreplace the ad hoc mating constraints or virtual fixtures, with no restrictive\nassumption on the types of the involved assembly features.\n", "versions": [{"version": "v1", "created": "Tue, 14 Nov 2017 09:30:49 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Behandish", "Morad", ""], ["Ilies", "Horea T.", ""]]}, {"id": "1711.05017", "submitter": "Morad Behandish", "authors": "Morad Behandish and Horea T. Ilies", "title": "Haptic Assembly Using Skeletal Densities and Fourier Transforms", "comments": "A shorter version was presented in ASME Computers and Information in\n  Engineering Conference (CIE'2015) (Best Paper Award)", "journal-ref": "ASME Transactions, Journal of ASME Transactions, Journal of\n  Computing and Information Science in Engineering, 16(2), p.021002, 2016", "doi": "10.1115/1.4032696", "report-no": "CDL-TR-16-01", "categories": "cs.HC cs.CG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Haptic-assisted virtual assembly and prototyping has seen significant\nattention over the past two decades. However, in spite of the appealing\nprospects, its adoption has been slower than expected. We identify the main\nroadblocks as the inherent geometric complexities faced when assembling objects\nof arbitrary shape, and the computation time limitation imposed by the\nnotorious 1 kHz haptic refresh rate. We addressed the first problem in a recent\nwork by introducing a generic energy model for geometric guidance and\nconstraints between features of arbitrary shape. In the present work, we\naddress the second challenge by leveraging Fourier transforms to compute the\nconstraint forces and torques. Our new concept of 'geometric energy' field is\ncomputed automatically from a cross-correlation of 'skeletal densities' in the\nfrequency domain, and serves as a generalization of the manually specified\nvirtual fixtures or heuristically identified mating constraints proposed in the\nliterature. The formulation of the energy field as a convolution enables\nefficient computation using fast Fourier transforms (FFT) on the graphics\nprocessing unit (GPU). We show that our method is effective for low-clearance\nassembly of objects of arbitrary geometric and syntactic complexity.\n", "versions": [{"version": "v1", "created": "Tue, 14 Nov 2017 09:30:56 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Behandish", "Morad", ""], ["Ilies", "Horea T.", ""]]}, {"id": "1711.05075", "submitter": "Morad Behandish", "authors": "Morad Behandish and Horea T. Ilies", "title": "Analytic Methods for Geometric Modeling via Spherical Decomposition", "comments": "Special Issue on SIAM/ACM symposium on Solid and Physical Modeling\n  (SPM'2015) (Best Paper Award, 2nd Place)", "journal-ref": "Journal of Computer-Aided Design, 70, pp.100-115, 2016", "doi": "10.1016/j.cad.2015.06.016", "report-no": "CDL-TR-15-07", "categories": "cs.CG cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analytic methods are emerging in solid and configuration modeling, while\nproviding new insights into a variety of shape and motion related problems by\nexploiting tools from group morphology, convolution algebras, and harmonic\nanalysis. However, most convolution-based methods have used uniform grid-based\nsampling to take advantage of the fast Fourier transform (FFT) algorithm. We\npropose a new paradigm for more efficient computation of analytic correlations\nthat relies on a grid-free discretization of arbitrary shapes as countable\nunions of balls, in turn described as sublevel sets of summations of smooth\nradial kernels at adaptively sampled 'knots'. Using a simple geometric lifting\ntrick, we interpret this combination as a convolution of an impulsive skeletal\ndensity and primitive kernels with conical support, which faithfully embeds\ninto the convolution formulation of interactions across different objects. Our\napproach enables fusion of search-efficient combinatorial data structures\nprevalent in time-critical collision and proximity queries with analytic\nmethods popular in path planning and protein docking, and outperforms uniform\ngrid-based FFT methods by leveraging nonequispaced FFTs. We provide example\napplications in formulating holonomic collision constraints, shape\ncomplementarity metrics, and morphological operations, unified within a single\nanalytic framework.\n", "versions": [{"version": "v1", "created": "Tue, 14 Nov 2017 12:16:34 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Behandish", "Morad", ""], ["Ilies", "Horea T.", ""]]}, {"id": "1711.05473", "submitter": "Bal\\'azs Keszegh", "authors": "Bal\\'azs Keszegh", "title": "Coloring intersection hypergraphs of pseudo-disks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that the intersection hypergraph of a family of $n$ pseudo-disks\nwith respect to another family of pseudo-disks admits a proper coloring with\n$4$ colors and a conflict-free coloring with $O(\\log n)$ colors. Along the way\nwe prove that the respective Delaunay-graph is planar. We also prove that the\nintersection hypergraph of a family of $n$ regions with linear union complexity\nwith respect to a family of pseudo-disks admits a proper coloring with\nconstantly many colors and a conflict-free coloring with $O(\\log n)$ colors.\nOur results serve as a common generalization and strengthening of many earlier\nresults, including ones about proper and conflict-free coloring points with\nrespect to pseudo-disks, coloring regions of linear union complexity with\nrespect to points and coloring disks with respect to disks.\n", "versions": [{"version": "v1", "created": "Wed, 15 Nov 2017 09:38:30 GMT"}, {"version": "v2", "created": "Tue, 18 Sep 2018 12:37:01 GMT"}], "update_date": "2018-09-19", "authors_parsed": [["Keszegh", "Bal\u00e1zs", ""]]}, {"id": "1711.06333", "submitter": "Jason Phipps Morgan", "authors": "J. M. Taram\\'on, J. P. Morgan, C. Shi, and J. Hasenclever", "title": "Generation of unstructured meshes in 2-D, 3-D, and spherical geometries\n  with embedded high resolution sub-regions", "comments": "20 pages + supplement, submitted to SIAM J. Sci. Comp", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CE math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present 2-D, 3-D, and spherical mesh generators for the Finite Element\nMethod (FEM) using triangular and tetrahedral elements. The mesh nodes are\ntreated as if they were linked by virtual springs that obey Hooke's law. Given\nthe desired length for the springs, the FEM is used to solve for the optimal\nnodal positions for the static equilibrium of this spring system. A\n'guide-mesh' approach allows the user to create embedded high resolution\nsub-regions within a coarser mesh. The method converges rapidly. For example,\nin 3-D, the algorithm is able to refine a specific region within an\nunstructured tetrahedral spherical shell so that the edge-length factor\n$l_{0r}/l_{0c} = 1/33$ within a few iterations, where $l_{0r}$ and $l_{0c}$ are\nthe desired spring length for elements inside the refined and coarse regions\nrespectively. One use for this type of mesh is to model regional problems as a\nfine region within a global mesh that has no fictitious boundaries, at only a\nsmall additional computational cost. The algorithm also includes routines to\nlocally improve the quality of the mesh and to avoid badly shaped\n'slivers-like' tetrahedra.\n", "versions": [{"version": "v1", "created": "Tue, 14 Nov 2017 20:01:38 GMT"}], "update_date": "2017-11-20", "authors_parsed": [["Taram\u00f3n", "J. M.", ""], ["Morgan", "J. P.", ""], ["Shi", "C.", ""], ["Hasenclever", "J.", ""]]}, {"id": "1711.07560", "submitter": "Peter Donelan", "authors": "P. Donelan and J. M. Selig", "title": "Hyperbolic pseudoinverses for kinematics in the Euclidean group", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.MG cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The kinematics of a robot manipulator are described in terms of the mapping\nconnecting its joint space and the 6-dimensional Euclidean group of motions\n$SE(3)$. The associated Jacobian matrices map into its Lie algebra\n$\\mathfrak{se}(3)$, the space of twists describing infinitesimal motion of a\nrigid body. Control methods generally require knowledge of an inverse for the\nJacobian. However for an arm with fewer or greater than six actuated joints or\nat singularities of the kinematic mapping this breaks down. The Moore-Penrose\npseudoinverse has frequently been used as a surrogate but is not invariant\nunder change of coordinates. Since the Euclidean Lie algebra carries a pencil\nof invariant bilinear forms that are indefinite, a family of alternative\nhyperbolic pseudoinverses is available. Generalised Gram matrices and the\nclassification of screw systems are used to determine conditions for their\nexistence. The existence or otherwise of these pseudoinverses also relates to a\nclassical problem addressed by Sylvester concerning the conditions for a system\nof lines to be in involution or, equivalently, the corresponding system of\ngeneralised forces to be in equilibrium.\n", "versions": [{"version": "v1", "created": "Mon, 20 Nov 2017 21:50:20 GMT"}], "update_date": "2017-11-22", "authors_parsed": [["Donelan", "P.", ""], ["Selig", "J. M.", ""]]}, {"id": "1711.07710", "submitter": "Arindam Khan", "authors": "Waldo G\\'alvez and Fabrizio Grandoni and Sandy Heydrich and Salvatore\n  Ingala and Arindam Khan and Andreas Wiese", "title": "Approximating Geometric Knapsack via L-packings", "comments": "64pages, full version of FOCS 2017 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the two-dimensional geometric knapsack problem (2DK) in which we are\ngiven a set of n axis-aligned rectangular items, each one with an associated\nprofit, and an axis-aligned square knapsack. The goal is to find a\n(non-overlapping) packing of a maximum profit subset of items inside the\nknapsack (without rotating items). The best-known polynomial-time approximation\nfactor for this problem (even just in the cardinality case) is (2 + \\epsilon)\n[Jansen and Zhang, SODA 2004].\n  In this paper, we break the 2 approximation barrier, achieving a\npolynomial-time (17/9 + \\epsilon) < 1.89 approximation, which improves to\n(558/325 + \\epsilon) < 1.72 in the cardinality case. Essentially all prior work\non 2DK approximation packs items inside a constant number of rectangular\ncontainers, where items inside each container are packed using a simple greedy\nstrategy. We deviate for the first time from this setting: we show that there\nexists a large profit solution where items are packed inside a constant number\nof containers plus one L-shaped region at the boundary of the knapsack which\ncontains items that are high and narrow and items that are wide and thin. As a\nsecond major and the main algorithmic contribution of this paper, we present a\nPTAS for this case. We believe that this will turn out to be useful in future\nwork in geometric packing problems.\n  We also consider the variant of the problem with rotations (2DKR), where\nitems can be rotated by 90 degrees. Also, in this case, the best-known\npolynomial-time approximation factor (even for the cardinality case) is (2 +\n\\epsilon) [Jansen and Zhang, SODA 2004]. Exploiting part of the machinery\ndeveloped for 2DK plus a few additional ideas, we obtain a polynomial-time (3/2\n+ \\epsilon)-approximation for 2DKR, which improves to (4/3 + \\epsilon) in the\ncardinality case.\n", "versions": [{"version": "v1", "created": "Tue, 21 Nov 2017 10:46:35 GMT"}], "update_date": "2017-11-22", "authors_parsed": [["G\u00e1lvez", "Waldo", ""], ["Grandoni", "Fabrizio", ""], ["Heydrich", "Sandy", ""], ["Ingala", "Salvatore", ""], ["Khan", "Arindam", ""], ["Wiese", "Andreas", ""]]}, {"id": "1711.07848", "submitter": "Hector J. Garcia", "authors": "H\\'ector J. Garc\\'ia, Igor L. Markov and Andrew W. Cross", "title": "On the Geometry of Stabilizer States", "comments": "38 pages, 10 figures, 2 Appendices. arXiv admin note: substantial\n  text overlap with arXiv:1210.6646", "journal-ref": "Quantum Information and Computation (QIC), vol. 14, no. 7-8, pp.\n  683-720, 2014", "doi": null, "report-no": null, "categories": "quant-ph cs.CG cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale quantum computation is likely to require massive quantum error\ncorrection (QEC). QEC codes and circuits are described via the stabilizer\nformalism, which represents stabilizer states by keeping track of the operators\nthat preserve them. Such states are obtained by stabilizer circuits (consisting\nof CNOT, Hadamard and Phase gates) and can be represented compactly on\nconventional computers using $O(n^2)$ bits, where $n$ is the number of qubits.\nAs an additional application, the work by Aaronson and Gottesman suggests the\nuse of superpositions of stabilizer states to represent arbitrary quantum\nstates. To aid in such applications and improve our understanding of stabilizer\nstates, we characterize and count nearest-neighbor stabilizer states, quantify\nthe distribution of angles between pairs of stabilizer states, study succinct\nstabilizer superpositions and stabilizer bivectors, explore the approximation\nof non-stabilizer states by single stabilizer states and short linear\ncombinations of stabilizer states, develop an improved inner-product\ncomputation for stabilizer states via synthesis of compact canonical stabilizer\ncircuits, propose an orthogonalization procedure for stabilizer states, and\nevaluate several of these algorithms empirically.\n", "versions": [{"version": "v1", "created": "Mon, 20 Nov 2017 18:54:51 GMT"}], "update_date": "2017-11-22", "authors_parsed": [["Garc\u00eda", "H\u00e9ctor J.", ""], ["Markov", "Igor L.", ""], ["Cross", "Andrew W.", ""]]}, {"id": "1711.08137", "submitter": "Zheng Liu", "authors": "Zheng Liu and Rongjie Lai and Huayan Zhang and Chunlin Wu", "title": "Triangulated Surface Denoising using High Order Regularization with\n  Dynamic Weights", "comments": "24 pages, 12 figures, 2 tables", "journal-ref": null, "doi": "10.1137/17M115743X", "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recovering high quality surfaces from noisy triangulated surfaces is a\nfundamental important problem in geometry processing.\n  Sharp features including edges and corners can not be well preserved in most\nexisting denoising methods except the recent total variation (TV) and $\\ell_0$\nregularization methods.\n  However, these two methods have suffered producing staircase artifacts in\nsmooth regions.\n  In this paper, we first introduce a second order regularization method for\nrestoring a surface normal vector field, and then propose a new vertex updating\nscheme to recover the desired surface according to the restored surface normal\nfield.\n  The proposed model can preserve sharp features and simultaneously suppress\nthe staircase effects in smooth regions which overcomes the drawback of the\nfirst order models.\n  In addition, the new vertex updating scheme can prevent ambiguities\nintroduced in existing vertex updating methods.\n  Numerically, the proposed high order model is solved by the augmented\nLagrangian method with a dynamic weighting strategy.\n  Intensive numerical experiments on a variety of surfaces demonstrate the\nsuperiority of our method by visually and quantitatively.\n", "versions": [{"version": "v1", "created": "Wed, 22 Nov 2017 05:39:34 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Liu", "Zheng", ""], ["Lai", "Rongjie", ""], ["Zhang", "Huayan", ""], ["Wu", "Chunlin", ""]]}, {"id": "1711.08436", "submitter": "Martin Tancer", "authors": "Xavier Goaoc, Pavel Pat\\'ak, Zuzana Pat\\'akov\\'a, Martin Tancer, Uli\n  Wagner", "title": "Shellability is NP-complete", "comments": "Version 2: 17 pages, 11 figures. Improved readability at various\n  places. Proof in Section 6 simplified", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CG math.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that for every $d\\geq 2$, deciding if a pure, $d$-dimensional,\nsimplicial complex is shellable is NP-hard, hence NP-complete. This resolves a\nquestion raised, e.g., by Danaraj and Klee in 1978. Our reduction also yields\nthat for every $d \\ge 2$ and $k \\ge 0$, deciding if a pure, $d$-dimensional,\nsimplicial complex is $k$-decomposable is NP-hard. For $d \\ge 3$, both problems\nremain NP-hard when restricted to contractible pure $d$-dimensional complexes.\nAnother simple corollary of our result is that it is NP-hard to decide whether\na given poset is CL-shellable.\n", "versions": [{"version": "v1", "created": "Wed, 22 Nov 2017 18:33:33 GMT"}, {"version": "v2", "created": "Wed, 24 Jan 2018 21:51:18 GMT"}], "update_date": "2018-01-26", "authors_parsed": [["Goaoc", "Xavier", ""], ["Pat\u00e1k", "Pavel", ""], ["Pat\u00e1kov\u00e1", "Zuzana", ""], ["Tancer", "Martin", ""], ["Wagner", "Uli", ""]]}, {"id": "1711.09593", "submitter": "Enea Zaffanella", "authors": "Anna Becchi and Enea Zaffanella", "title": "A Conversion Procedure for NNC Polyhedra", "comments": "36 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an alternative Double Description representation for the domain of\nNNC (not necessarily topologically closed) polyhedra, together with the\ncorresponding Chernikova-like conversion procedure. The representation differs\nfrom the ones adopted in the currently available implementations of the Double\nDescription method in that it uses no slack variable at all: this new approach\nprovides a solution to a few technical issues caused by the encoding of an NNC\npolyhedron as a closed polyhedron in a higher dimension space. A preliminary\nexperimental evaluation shows that the new conversion algorithm is able to\nachieve significant efficiency improvements with respect to state-of-the-art\nimplementations.\n", "versions": [{"version": "v1", "created": "Mon, 27 Nov 2017 09:29:53 GMT"}], "update_date": "2017-11-28", "authors_parsed": [["Becchi", "Anna", ""], ["Zaffanella", "Enea", ""]]}, {"id": "1711.10384", "submitter": "Fulvio Mastrogiovanni", "authors": "Xuenan Guo, Fulvio Mastrogiovanni", "title": "The robot skin placement problem: a new technique to place triangular\n  modules inside polygons", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Providing robots with large-scale robot skin is a challenging goal,\nespecially when considering surfaces characterized by different shapes and\ncurvatures. The problem originates from technological advances in tactile\nsensing, and in particular from two requirements: (i) covering the largest\npossible area of a robot's surface with tactile sensors, and (ii) doing it\nusing cheap, replicable hardware modules. Given modules of a specific shape,\nthe problem of optimally placing them requires to maximize the number of\nmodules that can be fixed on the selected robot body part. Differently from\nprevious approaches, which are based on methods inspired by computational\ngeometry (e.g., packing), we propose a novel layout design method inspired by\nphysical insights, referred to as Iterative Placement (ItPla), which arranges\nmodules as if physical forces acted on them. A number of case studies from the\nliterature are considered to evaluate the algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 28 Nov 2017 16:30:46 GMT"}], "update_date": "2017-11-29", "authors_parsed": [["Guo", "Xuenan", ""], ["Mastrogiovanni", "Fulvio", ""]]}, {"id": "1711.10414", "submitter": "Nikita Zhivotovskiy", "authors": "Andrey Kupavskii, Nikita Zhivotovskiy", "title": "When are epsilon-nets small?", "comments": "22 pages; minor changes, accepted version", "journal-ref": null, "doi": "10.1016/j.jcss.2019.12.006", "report-no": null, "categories": "cs.CG cs.LG math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many interesting situations the size of epsilon-nets depends only on\n$\\epsilon$ together with different complexity measures. The aim of this paper\nis to give a systematic treatment of such complexity measures arising in\nDiscrete and Computational Geometry and Statistical Learning, and to bridge the\ngap between the results appearing in these two fields. As a byproduct, we\nobtain several new upper bounds on the sizes of epsilon-nets that\ngeneralize/improve the best known general guarantees. In particular, our\nresults work with regimes when small epsilon-nets of size\n$o(\\frac{1}{\\epsilon})$ exist, which are not usually covered by standard upper\nbounds. Inspired by results in Statistical Learning we also give a short proof\nof the Haussler's upper bound on packing numbers.\n", "versions": [{"version": "v1", "created": "Tue, 28 Nov 2017 17:15:44 GMT"}, {"version": "v2", "created": "Wed, 7 Aug 2019 09:45:13 GMT"}, {"version": "v3", "created": "Thu, 6 Feb 2020 19:46:25 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Kupavskii", "Andrey", ""], ["Zhivotovskiy", "Nikita", ""]]}, {"id": "1711.11524", "submitter": "R Inkulu", "authors": "Tameem Choudhury and R. Inkulu", "title": "Computing a rectilinear shortest path amid splinegons in plane", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We reduce the problem of computing a rectilinear shortest path between two\ngiven points s and t in the splinegonal domain \\calS to the problem of\ncomputing a rectilinear shortest path between two points in the polygonal\ndomain. As part of this, we define a polygonal domain \\calP from \\calS and\ntransform a rectilinear shortest path computed in \\calP to a path between s and\nt amid splinegon obstacles in \\calS. When \\calS comprises of h pairwise\ndisjoint splinegons with a total of n vertices, excluding the time to compute a\nrectilinear shortest path amid polygons in \\calP, our reduction algorithm takes\nO(n + h \\lg{n}) time. For the special case of \\calS comprising of concave-in\nsplinegons, we have devised another algorithm in which the reduction procedure\ndoes not rely on the structures used in the algorithm to compute a rectilinear\nshortest path in polygonal domain. As part of these, we have characterized few\nof the properties of rectilinear shortest paths amid splinegons which could be\nof independent interest.\n", "versions": [{"version": "v1", "created": "Thu, 30 Nov 2017 17:29:00 GMT"}, {"version": "v2", "created": "Mon, 11 Dec 2017 04:56:10 GMT"}], "update_date": "2017-12-12", "authors_parsed": [["Choudhury", "Tameem", ""], ["Inkulu", "R.", ""]]}]