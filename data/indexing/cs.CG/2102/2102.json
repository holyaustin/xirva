[{"id": "2102.01895", "submitter": "Barak Or", "authors": "Barak Or and Liam Hazan", "title": "Length Learning for Planar Euclidean Curves", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.CG cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we used deep neural networks (DNNs) to solve a fundamental\nproblem in differential geometry. One can find many closed-form expressions for\ncalculating curvature, length, and other geometric properties in the\nliterature. As we know these concepts, we are highly motivated to reconstruct\nthem by using deep neural networks. In this framework, our goal is to learn\ngeometric properties from examples. The simplest geometric object is a curve.\nTherefore, this work focuses on learning the length of planar sampled curves\ncreated by a sine waves dataset. For this reason, the fundamental length axioms\nwere reconstructed using a supervised learning approach. Following these axioms\na simplified DNN model, we call ArcLengthNet, was established. The robustness\nto additive noise and discretization errors were tested.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 06:30:03 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Or", "Barak", ""], ["Hazan", "Liam", ""]]}, {"id": "2102.02013", "submitter": "Jonathan Klawitter", "authors": "Steven Chaplick, Philipp Kindermann, Jonathan Klawitter, Ignaz Rutter,\n  Alexander Wolff", "title": "Extending Partial Representations of Rectangular Duals with Given\n  Contact Orientations", "comments": "Appears in the special issue of the 12th International Conference on\n  Algorithms and Complexity (CIAC 2021); an earier version appeared in the\n  Proceedings of CIAC 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A rectangular dual of a graph $G$ is a contact representation of $G$ by\naxis-aligned rectangles such that (i) no four rectangles share a point and (ii)\nthe union of all rectangles is a rectangle. The partial representation\nextension problem for rectangular duals asks whether a given partial\nrectangular dual can be extended to a rectangular dual, that is, whether there\nexists a rectangular dual where some vertices are represented by prescribed\nrectangles. Combinatorially, a rectangular dual can be described by a regular\nedge labeling (REL), which determines the orientations of the rectangle\ncontacts.\n  We describe two approaches to solve the partial representation extension\nproblem for rectangular duals with given REL. One the one hand, we characterise\nthe RELs that admit an extension, which leads to a linear-time testing\nalgorithm. In the affirmative, we can construct an extension in linear time.\nThis partial representation extension problem can also be formulated as a\nlinear program (LP). We use this LP to solve the simultaneous representation\nproblem for the case of rectangular duals when each input graph is given\ntogether with a REL.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 11:26:55 GMT"}, {"version": "v2", "created": "Mon, 12 Jul 2021 15:34:58 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Chaplick", "Steven", ""], ["Kindermann", "Philipp", ""], ["Klawitter", "Jonathan", ""], ["Rutter", "Ignaz", ""], ["Wolff", "Alexander", ""]]}, {"id": "2102.02684", "submitter": "Dominik D\\\"urrschnabel", "authors": "Dominik D\\\"urrschnabel, Gerd Stumme", "title": "Force-Directed Layout of Order Diagrams using Dimensional Reduction", "comments": "16 pages, 6 figures, 4 algorithms, for source code refer to\n  https://github.com/domduerr/redraw", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Order diagrams allow human analysts to understand and analyze structural\nproperties of ordered data. While an experienced expert can create easily\nreadable order diagrams, the automatic generation of those remains a hard task.\nIn this work, we adapt force-directed approaches, which are known to generate\naesthetically-pleasing drawings of graphs, to the realm of order diagrams. Our\nalgorithm ReDraw thereby embeds the order in a high dimension and then\niteratively reduces the dimension until a two-dimensional drawing is achieved.\nTo improve aesthetics, this reduction is equipped with two force-directed steps\nwhere one optimizes on distances of nodes and the other on distances of lines\nin order to satisfy a set of a priori fixed conditions. By respecting an\ninvariant about the vertical position of the elements in each step of our\nalgorithm we ensure that the resulting drawings satisfy all necessary\nproperties of order diagrams. Finally, we present the results of a user study\nto demonstrate that our algorithm outperforms comparable approaches on drawings\nof lattices with a high degree of distributivity.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 15:25:39 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["D\u00fcrrschnabel", "Dominik", ""], ["Stumme", "Gerd", ""]]}, {"id": "2102.03069", "submitter": "Francois Protais", "authors": "Vladimir Garanzha (CCRAS, MIPT), Igor Kaporin (CCRAS, MIPT), Liudmila\n  Kudryavtseva (CCRAS, MIPT), Fran\\c{c}ois Protais, Nicolas Ray, Dmitry Sokolov", "title": "Foldover-free maps in 50 lines of code", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mapping a triangulated surface to 2D space (or a tetrahedral mesh to 3D\nspace) is the most fundamental problem in geometry processing.In computational\nphysics, untangling plays an important role in mesh generation: it takes a mesh\nas an input, and moves the vertices to get rid of foldovers.In fact, mesh\nuntangling can be considered as a special case of mapping where the geometry of\nthe object is to be defined in the map space and the geometric domain is not\nexplicit, supposing that each element is regular.In this paper, we propose a\nmapping method inspired by the untangling problem and compare its performance\nto the state of the art.The main advantage of our method is that the untangling\naims at producing locally injective maps, which is the major challenge of\nmapping.In practice, our method produces locally injective maps in very\ndifficult settings, and with less distortion than the previous work, both in 2D\nand 3D. We demonstrate it on a large reference database as well as on more\ndifficult stress tests.For a better reproducibility, we publish the code in\nPython for a basic evaluation, and in C++ for more advanced applications.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 09:24:46 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Garanzha", "Vladimir", "", "CCRAS, MIPT"], ["Kaporin", "Igor", "", "CCRAS, MIPT"], ["Kudryavtseva", "Liudmila", "", "CCRAS, MIPT"], ["Protais", "Fran\u00e7ois", ""], ["Ray", "Nicolas", ""], ["Sokolov", "Dmitry", ""]]}, {"id": "2102.03303", "submitter": "Alexei Uteshev", "authors": "Alexei Yu. Uteshev, Elizaveta A. Semenova", "title": "Length of a Full Steiner Tree as a Function of Terminal Coordinates", "comments": "12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Given the coordinates of the terminals $ \\{(x_j,y_j)\\}_{j=1}^n $ of the full\nEuclidean Steiner tree, its length equals $$ \\left| \\sum_{j=1}^n z_j U_j\n\\right| \\, , $$ where $ \\{z_j:=x_j+ \\mathbf i y_j\\}_{j=1}^n $ and $\n\\{U_j\\}_{j=1}^n $ are suitably chosen $ 6 $th roots of unity. We also extend\nthis result for the cost of the optimal Weber networks which are topologically\nequivalent to some full Steiner trees.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 17:22:37 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Uteshev", "Alexei Yu.", ""], ["Semenova", "Elizaveta A.", ""]]}, {"id": "2102.03455", "submitter": "Neeraj Kumar", "authors": "Neeraj Kumar, Stavros Sintos, and Subhash Suri", "title": "The Maximum Exposure Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Given a set of points $P$ and axis-aligned rectangles $\\mathcal{R}$ in the\nplane, a point $p \\in P$ is called \\emph{exposed} if it lies outside all\nrectangles in $\\mathcal{R}$. In the \\emph{max-exposure problem}, given an\ninteger parameter $k$, we want to delete $k$ rectangles from $\\mathcal{R}$ so\nas to maximize the number of exposed points. We show that the problem is\nNP-hard and assuming plausible complexity conjectures is also hard to\napproximate even when rectangles in $\\mathcal{R}$ are translates of two fixed\nrectangles. However, if $\\mathcal{R}$ only consists of translates of a single\nrectangle, we present a polynomial-time approximation scheme. For range space\ndefined by general rectangles, we present a simple $O(k)$ bicriteria\napproximation algorithm; that is by deleting $O(k^2)$ rectangles, we can expose\nat least $\\Omega(1/k)$ of the optimal number of points.\n", "versions": [{"version": "v1", "created": "Sat, 6 Feb 2021 00:12:12 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Kumar", "Neeraj", ""], ["Sintos", "Stavros", ""], ["Suri", "Subhash", ""]]}, {"id": "2102.03709", "submitter": "Rolando Kindelan Nu\\~nez", "authors": "Rolando Kindelan and Jos\\'e Fr\\'ias and Mauricio Cerda and Nancy\n  Hitschfeld", "title": "Classification based on Topological Data Analysis", "comments": "Preprint submitted to the Pattern Recognition Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Topological Data Analysis (TDA) is an emergent field that aims to discover\ntopological information hidden in a dataset. TDA tools have been commonly used\nto create filters and topological descriptors to improve Machine Learning (ML)\nmethods. This paper proposes an algorithm that applies TDA directly to\nmulti-class classification problems, even imbalanced datasets, without any\nfurther ML stage. The proposed algorithm built a filtered simplicial complex on\nthe dataset. Persistent homology is then applied to guide choosing a\nsub-complex where unlabeled points obtain the label with most votes from\nlabeled neighboring points. To assess the proposed method, 8 datasets were\nselected with several degrees of class entanglement, variability on the samples\nper class, and dimensionality. On average, the proposed TDABC method was\ncapable of overcoming baseline classifiers (wk-NN and k-NN) in each of the\ncomputed metrics, especially on classifying entangled and minority classes.\n", "versions": [{"version": "v1", "created": "Sun, 7 Feb 2021 03:47:28 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Kindelan", "Rolando", ""], ["Fr\u00edas", "Jos\u00e9", ""], ["Cerda", "Mauricio", ""], ["Hitschfeld", "Nancy", ""]]}, {"id": "2102.04262", "submitter": "Dan Halperin", "authors": "Dan Halperin, Micha Sharir, Itay Yehuda", "title": "Throwing a Sofa Through the Window", "comments": "This version incudes new results on translation with a prescribed\n  orientation (Section 5.2)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study several variants of the problem of moving a convex polytope $K$,\nwith $n$ edges, in three dimensions through a flat rectangular (and sometimes\nmore general) window. Specifically:\n  $\\bullet$ We study variants where the motion is restricted to translations\nonly, discuss situations where such a motion can be reduced to sliding\n(translation in a fixed direction), and present efficient algorithms for those\nvariants, which run in time close to $O(n^{8/3})$.\n  $\\bullet$ We consider the case of a `gate' (an unbounded window with two\nparallel infinite edges), and show that $K$ can pass through such a window, by\nany collision-free rigid motion, if and only if it can slide through it.\n  $\\bullet$ We consider arbitrary compact convex windows, and show that if $K$\ncan pass through such a window $W$ (by any motion) then $K$ can slide through a\ngate of width equal to the diameter of $W$.\n  $\\bullet$ We study the case of a circular window $W$, and show that, for the\nregular tetrahedron $K$ of edge length $1$, there are two thresholds $1 >\n\\delta_1\\approx 0.901388 > \\delta_2\\approx 0.895611$, such that (a) $K$ can\nslide through $W$ if the diameter $d$ of $W$ is $\\ge 1$, (b) $K$ cannot slide\nthrough $W$ but can pass through it by a purely translational motion when\n$\\delta_1\\le d < 1$, (c) $K$ cannot pass through $W$ by a purely translational\nmotion but can do it when rotations are allowed when $\\delta_2 \\le d <\n\\delta_1$, and (d) $K$ cannot pass through $W$ at all when $d < \\delta_2$.\n  $\\bullet$ Finally, we explore the general setup, where we want to plan a\ngeneral motion (with all six degrees of freedom) for $K$ through a rectangular\nwindow $W$, and present an efficient algorithm for this problem, with running\ntime close to $O(n^4)$.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 14:53:47 GMT"}, {"version": "v2", "created": "Fri, 26 Feb 2021 10:44:29 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Halperin", "Dan", ""], ["Sharir", "Micha", ""], ["Yehuda", "Itay", ""]]}, {"id": "2102.05705", "submitter": "Sarah Tymochko", "authors": "Tegan Emerson, Sarah Tymochko, George Stantchev, Jason A. Edelberg,\n  Michael Wilson, and Colin C. Olson", "title": "A Topological Approach for Motion Track Discrimination", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting small targets at range is difficult because there is not enough\nspatial information present in an image sub-region containing the target to use\ncorrelation-based methods to differentiate it from dynamic confusers present in\nthe scene. Moreover, this lack of spatial information also disqualifies the use\nof most state-of-the-art deep learning image-based classifiers. Here, we use\ncharacteristics of target tracks extracted from video sequences as data from\nwhich to derive distinguishing topological features that help robustly\ndifferentiate targets of interest from confusers. In particular, we calculate\npersistent homology from time-delayed embeddings of dynamic statistics\ncalculated from motion tracks extracted from a wide field-of-view video stream.\nIn short, we use topological methods to extract features related to target\nmotion dynamics that are useful for classification and disambiguation and show\nthat small targets can be detected at range with high probability.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 19:25:38 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Emerson", "Tegan", ""], ["Tymochko", "Sarah", ""], ["Stantchev", "George", ""], ["Edelberg", "Jason A.", ""], ["Wilson", "Michael", ""], ["Olson", "Colin C.", ""]]}, {"id": "2102.05747", "submitter": "Ruben Hoeksma", "authors": "Ruben Hoeksma and Matthew Maat", "title": "A better lower bound for Lower-Left Anchored Rectangle Packing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Given any set of points $S$ in the unit square that contains the origin, does\na set of axis aligned rectangles, one for each point in $S$, exist, such that\neach of them has a point in $S$ as its lower-left corner, they are pairwise\ninterior disjoint, and the total area that they cover is at least 1/2? This\nquestion is also known as Freedman's conjecture (conjecturing that such a set\nof rectangles does exist) and has been open since Allen Freedman posed it in\n1969. In this paper, we improve the best known lower bound on the total area\nthat can be covered from 0.09121 to 0.1039. Although this step is small, we\nintroduce new insights that push the limits of this analysis.\n  Our lower bound uses a greedy algorithm with a particular order of the points\nin $S$. Therefore, it also implies that this greedy algorithm achieves an\napproximation ratio of 0.1039. We complement the result with an upper bound of\n3/4 on the approximation ratio for a natural class of greedy algorithms that\nincludes the one that achieves the lower bound.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 21:42:14 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Hoeksma", "Ruben", ""], ["Maat", "Matthew", ""]]}, {"id": "2102.05844", "submitter": "Sampson Wong", "authors": "Joachim Gudmundsson, Andr\\'e van Renssen, Zeinab Saeidi, Sampson Wong", "title": "Translation Invariant Fr\\'echet Distance Queries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Fr\\'echet distance is a popular similarity measure between curves. For\nsome applications, it is desirable to match the curves under translation before\ncomputing the Fr\\'echet distance between them. This variant is called the\nTranslation Invariant Fr\\'echet distance, and algorithms to compute it are well\nstudied. The query version, however, is much less well understood.\n  We study Translation Invariant Fr\\'echet distance queries in a restricted\nsetting of horizontal query segments. More specifically, we prepocess a\ntrajectory in $O(n^2 \\log^2 n)$ time and space, such that for any subtrajectory\nand any horizontal query segment we can compute their Translation Invariant\nFr\\'echet distance in $O(\\text{polylog} \\, n)$ time. We hope this will be a\nstep towards answering Translation Invariant Fr\\'echet queries between\narbitrary trajectories.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 04:35:50 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Gudmundsson", "Joachim", ""], ["van Renssen", "Andr\u00e9", ""], ["Saeidi", "Zeinab", ""], ["Wong", "Sampson", ""]]}, {"id": "2102.05854", "submitter": "Venkata Naga Sreenivasulu Karnati", "authors": "Arindam Khan and Eklavya Sharma and K. V. N. Sreenivas", "title": "Approximation Algorithms for Generalized Multidimensional Knapsack", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study a generalization of the knapsack problem with geometric and vector\nconstraints. The input is a set of rectangular items, each with an associated\nprofit and $d$ nonnegative weights ($d$-dimensional vector), and a square\nknapsack. The goal is to find a non-overlapping axis-parallel packing of a\nsubset of items into the given knapsack such that the vector constraints are\nnot violated, i.e., the sum of weights of all the packed items in any of the\n$d$ dimensions does not exceed one. We consider two variants of the problem:\n$(i)$ the items are not allowed to be rotated, $(ii)$ items can be rotated by\n90 degrees.\n  We give a $(2+\\epsilon)$-approximation algorithm for this problem (both\nversions). In the process, we also study a variant of the maximum generalized\nassignment problem (Max-GAP), called Vector-Max-GAP, and design a PTAS for it.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 05:40:42 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Khan", "Arindam", ""], ["Sharma", "Eklavya", ""], ["Sreenivas", "K. V. N.", ""]]}, {"id": "2102.06134", "submitter": "Arnau Padrol", "authors": "Arnau Padrol and Eva Philippe", "title": "Sweeps, polytopes, oriented matroids, and allowable graphs of\n  permutations", "comments": "41 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CG cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A sweep of a point configuration is any ordered partition induced by a linear\nfunctional. Posets of sweeps of planar point configurations were formalized and\nabstracted by Goodman and Pollack under the theory of allowable sequences of\npermutations. We introduce two generalizations that model posets of sweeps of\nhigher dimensional configurations.\n  Mimicking the fact that sweep polytopes of point configurations (the monotone\npath polytopes of the associated zonotopes) are projections of permutahedra, we\ndefine sweep oriented matroids as strong maps of the braid oriented matroid.\nAllowable sequences are then the sweep oriented matroids of rank 2, and many of\ntheir properties extend to higher rank. We show strong ties between sweep\noriented matroids and both modular hyperplanes and Dilworth truncations from\n(unoriented) matroid theory. We also explore their connection with the\ngeneralized Baues problem for cellular strings, where sweep oriented matroids\ncan play the role of monotone path polytopes, even for non-realizable oriented\nmatroids. In particular, we show that for oriented matroids that admit a sweep\noriented matroid, their poset of pseudo-sweeps deformation retracts to a sphere\nof the appropriate dimension.\n  A second generalization are allowable graphs of permutations: symmetric sets\nof permutations pairwise connected by allowable sequences. They have the\nstructure of acycloids and include sweep oriented matroids.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 17:15:12 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Padrol", "Arnau", ""], ["Philippe", "Eva", ""]]}, {"id": "2102.07100", "submitter": "Haodi Ping", "authors": "Haodi Ping, Yongcai Wang, and Deying Li", "title": "IMF: Iterative Max-Flow for Node Localizability Detection in Barycentric\n  Linear Localization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Determining whether nodes can be uniquely localized, called localizability\ndetection, is a concomitant problem of network localization. Localizability\nunder traditional Non-Linear Localization (NLL) schema has been well explored,\nwhereas localizability under the emerging Barycentric coordinate-based Linear\nLocalization (BLL) schema has not been well touched. In this paper, we\ninvestigate the deficiency of existing localizability theories and algorithms\nin BLL, and then propose a necessary condition and a sufficient condition for\nBLL node localizability. Based on these two conditions, an efficient iterative\nmaximum flow (IMF) algorithm is designed to identify BLL localizable nodes.\nFinally, our algorithms are validated by both theoretical analysis and\nexperimental evaluations.\n", "versions": [{"version": "v1", "created": "Sun, 14 Feb 2021 08:23:41 GMT"}, {"version": "v2", "created": "Thu, 29 Jul 2021 09:19:18 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Ping", "Haodi", ""], ["Wang", "Yongcai", ""], ["Li", "Deying", ""]]}, {"id": "2102.07310", "submitter": "Micha Sharir", "authors": "Esther Ezra and Micha Sharir", "title": "On Ray Shooting for Triangles in 3-Space and Related Problems", "comments": "33 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider several problems that involve lines in three dimensions, and\npresent improved algorithms for solving them. The problems include (i) ray\nshooting amid triangles in $R^3$, (ii) reporting intersections between query\nlines (segments, or rays) and input triangles, as well as approximately\ncounting the number of such intersections, (iii) computing the intersection of\ntwo nonconvex polyhedra, (iv) detecting, counting, or reporting intersections\nin a set of lines in $R^3$, and (v) output-sensitive construction of an\narrangement of triangles in three dimensions.\n  Our approach is based on the polynomial partitioning technique.\n  For example, our ray-shooting algorithm processes a set of $n$ triangles in\n$R^3$ into a data structure for answering ray shooting queries amid the given\ntriangles, which uses $O(n^{3/2+\\varepsilon})$ storage and preprocessing, and\nanswers a query in $O(n^{1/2+\\varepsilon})$ time, for any $\\varepsilon>0$. This\nis a significant improvement over known results, obtained more than 25 years\nago, in which, with this amount of storage, the query time bound is roughly\n$n^{5/8}$. The algorithms for the other problems have similar performance\nbounds, with similar improvements over previous results.\n  We also derive a nontrivial improved tradeoff between storage and query time.\nUsing it, we obtain algorithms that answer $m$ queries on $n$ objects in \\[\n\\max \\left\\{ O(m^{2/3}n^{5/6+\\varepsilon} + n^{1+\\varepsilon}),\\;\nO(m^{5/6+\\varepsilon}n^{2/3} + m^{1+\\varepsilon}) \\right\\} \\] time, for any\n$\\varepsilon>0$, again an improvement over the earlier bounds.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 02:32:46 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Ezra", "Esther", ""], ["Sharir", "Micha", ""]]}, {"id": "2102.08181", "submitter": "Florian Schneider", "authors": "Christoph Damerius, Dominik Kaaser, Peter Kling, Florian Schneider", "title": "On Greedily Packing Anchored Rectangles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a set P of points in the unit square U, one of them being the\norigin. For each point p in P you may draw a rectangle in U with its lower-left\ncorner in p. What is the maximum area such rectangles can cover without\noverlapping each other? Freedman [1969] posed this problem in 1969, asking\nwhether one can always cover at least 50% of U. Over 40 years later, Dumitrescu\nand T\\'oth [2011] achieved the first constant coverage of 9.1%; since then, no\nsignificant progress was made. While 9.1% might seem low, the authors could not\nfind any instance where their algorithm covers less than 50%, nourishing the\nhope to eventually prove a 50% bound. While we indeed significantly raise the\nalgorithm's coverage to 39%, we extinguish the hope of reaching 50% by giving\npoints for which the coverage is below 43.3%. Our analysis studies the\nalgorithm's average and worst-case density of so-called tiles, which represent\nthe area where a given point can freely choose its maximum-area rectangle. Our\napproachis comparatively general and may potentially help in analyzing related\nalgorithms.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 14:30:17 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Damerius", "Christoph", ""], ["Kaaser", "Dominik", ""], ["Kling", "Peter", ""], ["Schneider", "Florian", ""]]}, {"id": "2102.08260", "submitter": "Primoz Skraba", "authors": "Gabriele Beltramo and Rayna Andreeva and Ylenia Giarratano and Miguel\n  O. Bernabeu and Rik Sarkar and Primoz Skraba", "title": "Euler Characteristic Surfaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AT cs.CG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the use of the Euler characteristic for multiparameter topological\ndata analysis. Euler characteristic is a classical, well-understood topological\ninvariant that has appeared in numerous applications, including in the context\nof random fields. The goal of this paper is to present the extension of using\nthe Euler characteristic in higher-dimensional parameter spaces. While\ntopological data analysis of higher-dimensional parameter spaces using stronger\ninvariants such as homology continues to be the subject of intense research,\nEuler characteristic is more manageable theoretically and computationally, and\nthis analysis can be seen as an important intermediary step in multi-parameter\ntopological data analysis. We show the usefulness of the techniques using\nartificially generated examples, and a real-world application of detecting\ndiabetic retinopathy in retinal images.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 16:33:31 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Beltramo", "Gabriele", ""], ["Andreeva", "Rayna", ""], ["Giarratano", "Ylenia", ""], ["Bernabeu", "Miguel O.", ""], ["Sarkar", "Rik", ""], ["Skraba", "Primoz", ""]]}, {"id": "2102.08623", "submitter": "Moo K. Chung", "authors": "Moo K. Chung, Alexander Smith, Gary Shiu", "title": "Reviews: Topological Distances and Losses for Brain Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG math.AT q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Almost all statistical and machine learning methods in analyzing brain\nnetworks rely on distances and loss functions, which are mostly Euclidean or\nmatrix norms. The Euclidean or matrix distances may fail to capture underlying\nsubtle topological differences in brain networks. Further, Euclidean distances\nare sensitive to outliers. A few extreme edge weights may severely affect the\ndistance. Thus it is necessary to use distances and loss functions that\nrecognize topology of data. In this review paper, we survey various topological\ndistance and loss functions from topological data analysis (TDA) and persistent\nhomology that can be used in brain network analysis more effectively. Although\nthere are many recent brain imaging studies that are based on TDA methods,\npossibly due to the lack of method awareness, TDA has not taken as the\nmainstream tool in brain imaging field yet. The main purpose of this paper is\nprovide the relevant technical survey of these powerful tools that are\nimmediately applicable to brain network data.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 08:23:20 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Chung", "Moo K.", ""], ["Smith", "Alexander", ""], ["Shiu", "Gary", ""]]}, {"id": "2102.10013", "submitter": "Erva Ulu", "authors": "Erva Ulu, Nurcan Gecer Ulu, Jiahao Li, Walter Hsiao", "title": "Curvy: An Interactive Design Tool for Varying Density Support Structures", "comments": "Submitted to Computer Graphics Forum", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.CG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce Curvy-an interactive design tool to generate varying density\nsupport structures for 3D printing. Support structures are essential for\nprinting models with extreme overhangs. Yet, they often cause defects on\ncontact areas, resulting in poor surface quality. Low-level design of support\nstructures may alleviate such negative effects. However, it is tedious and\nunintuitive for novice users as it is hard to predict the impact of changes to\nthe support structure on the final printed part. Curvy allows users to define\ntheir high-level preferences on the surface quality directly on the target\nobject rather than explicitly designing the supports. These preferences are\nthen automatically translated into low-level design parameters to generate the\nsupport structure. Underlying novel curvy zigzag toolpathing algorithm uses\nthese instructions to generate varying density supports by altering the spacing\nbetween individual paths in order to achieve prescribed quality. Combined with\nthe build orientation optimization, Curvy provides a practical solution to the\ndesign of support structures with minimal perceptual or functional impact on\nthe target part to be printed.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 16:27:17 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Ulu", "Erva", ""], ["Ulu", "Nurcan Gecer", ""], ["Li", "Jiahao", ""], ["Hsiao", "Walter", ""]]}, {"id": "2102.10317", "submitter": "Sharareh Alipour", "authors": "Sharareh Alipour", "title": "On guarding polygons with holes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There is an old conjecture by Shermer \\cite{sher} that in a polygon with $n$\nvertices and $h$ holes, $\\lfloor \\dfrac{n+h}{3} \\rfloor$ vertex guards are\nsufficient to guard the entire polygon. The conjecture is proved for $h=1$ by\nShermer \\cite{sher} and Aggarwal \\cite{aga} seperately.\n  In this paper, we prove a theorem similar to the Shermer's conjecture for a\nspecial case where the goal is to guard the vertices of the polygon (not the\nentire polygon) which is equivalent to finding a dominating set for the\nvisibility graph of the polygon. Our proof also guarantees that the selected\nvertex guards also cover the entire outer boundary (outer perimeter of the\npolygon) as well.\n", "versions": [{"version": "v1", "created": "Sat, 20 Feb 2021 11:37:59 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Alipour", "Sharareh", ""]]}, {"id": "2102.10754", "submitter": "Gary Pui-Tung Choi", "authors": "Lucy Liu, Gary P. T. Choi, L. Mahadevan", "title": "Wallpaper group kirigami", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.soft cond-mat.mtrl-sci cs.CG physics.app-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kirigami, the art of paper cutting, has become a paradigm for mechanical\nmetamaterials in recent years. The basic building blocks of any kirigami\nstructures are repetitive deployable patterns that derive inspiration from\ngeometric art forms and simple planar tilings. Here we complement these\napproaches by directly linking kirigami patterns to the symmetry associated\nwith the set of seventeen repeating patterns that fully characterize the space\nof periodic tilings of the plane. We start by showing how to construct\ndeployable kirigami patterns using any of the wallpaper groups, and then design\nsymmetry-preserving cut patterns to achieve arbitrary size changes via\ndeployment. We further prove that different symmetry changes can be achieved by\ncontrolling the shape and connectivity of the tiles and connect these results\nto the underlying kirigami-based lattice structures. All together, our work\nprovides a systematic approach for creating a broad range of kirigami-based\ndeployable structures with any prescribed size and symmetry properties.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 03:39:20 GMT"}, {"version": "v2", "created": "Sun, 4 Jul 2021 14:59:06 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Liu", "Lucy", ""], ["Choi", "Gary P. T.", ""], ["Mahadevan", "L.", ""]]}, {"id": "2102.11097", "submitter": "Joseph O'Rourke", "authors": "Joseph O'Rourke and Costin V\\^ilcu", "title": "Cut Locus Realizations on Convex Polyhedra", "comments": "16 pages, 7 figures, 16 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG math.MG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We prove that every positively-weighted tree T can be realized as the cut\nlocus C(x) of a point x on a convex polyhedron P, with T weights matching C(x)\nlengths. If T has n leaves, P has (in general) n+1 vertices. We show there are\nin fact a continuum of polyhedra P each realizing T for some x on P. Three main\ntools in the proof are properties of the star unfolding of P, Alexandrov's\ngluing theorem, and a cut-locus partition lemma. The construction of P from T\nis surprisingly simple.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 15:11:44 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["O'Rourke", "Joseph", ""], ["V\u00eelcu", "Costin", ""]]}, {"id": "2102.11393", "submitter": "Wei Zhou", "authors": "Wei Zhou, Jiahua Xu, Qiuping Jiang, Zhibo Chen", "title": "No-Reference Quality Assessment for 360-degree Images by Analysis of\n  Multi-frequency Information and Local-global Naturalness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CG cs.MM eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  360-degree/omnidirectional images (OIs) have achieved remarkable attentions\ndue to the increasing applications of virtual reality (VR). Compared to\nconventional 2D images, OIs can provide more immersive experience to consumers,\nbenefitting from the higher resolution and plentiful field of views (FoVs).\nMoreover, observing OIs is usually in the head mounted display (HMD) without\nreferences. Therefore, an efficient blind quality assessment method, which is\nspecifically designed for 360-degree images, is urgently desired. In this\npaper, motivated by the characteristics of the human visual system (HVS) and\nthe viewing process of VR visual contents, we propose a novel and effective\nno-reference omnidirectional image quality assessment (NR OIQA) algorithm by\nMulti-Frequency Information and Local-Global Naturalness (MFILGN).\nSpecifically, inspired by the frequency-dependent property of visual cortex, we\nfirst decompose the projected equirectangular projection (ERP) maps into\nwavelet subbands. Then, the entropy intensities of low and high frequency\nsubbands are exploited to measure the multi-frequency information of OIs.\nBesides, except for considering the global naturalness of ERP maps, owing to\nthe browsed FoVs, we extract the natural scene statistics features from each\nviewport image as the measure of local naturalness. With the proposed\nmulti-frequency information measurement and local-global naturalness\nmeasurement, we utilize support vector regression as the final image quality\nregressor to train the quality evaluation model from visual quality-related\nfeatures to human ratings. To our knowledge, the proposed model is the first\nno-reference quality assessment method for 360-degreee images that combines\nmulti-frequency information and image naturalness. Experimental results on two\npublicly available OIQA databases demonstrate that our proposed MFILGN\noutperforms state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 22:52:35 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Zhou", "Wei", ""], ["Xu", "Jiahua", ""], ["Jiang", "Qiuping", ""], ["Chen", "Zhibo", ""]]}, {"id": "2102.11578", "submitter": "Daniela Cabiddu", "authors": "Daniela Cabiddu, Giuseppe Patan\\`e, Michela Spagnuolo", "title": "PEMesh: a Graphical Framework for the Analysis of the InterplayBetween\n  Geometry and PEM Solvers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Partial differential equations can be solved on general polygonal and\npolyhedral meshes, through Polytopal Element Methods (PEMs). Unfortunately, the\nrelation between geometry and analysis is still unknown and subject to ongoing\nresearch in order to identify weaker shape-regularity criteria under which PEMs\ncan reliably work. We propose PEMesh, a graphical framework to support the\nanalysis of the relation between the geometric properties of polygonal meshes\nand the numerical performances of PEM solvers. PEMesh allows the design of\npolygonal meshes that increasingly stress some geometric properties, by\nexploiting any external PEM solver, and supports the study of the correlation\nbetween the performances of such a solver and geometric properties of the input\nmesh. Furthermore, it is highly modular, customisable, easy to use, and\nprovides the possibility to export analysis results both as numerical values\nand graphical plots. PEMesh has a potential practical impact on ongoing and\nfuture research activities related to PEM methods, polygonal mesh generation\nand processing.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 09:34:34 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Cabiddu", "Daniela", ""], ["Patan\u00e8", "Giuseppe", ""], ["Spagnuolo", "Michela", ""]]}, {"id": "2102.11684", "submitter": "Andrew Willis", "authors": "Pengcheng Liu, Nathan Hewitt, Waseem Shadid, Andrew Willis", "title": "A System for 3D Reconstruction Of Comminuted Tibial Plafond Bone\n  Fractures", "comments": "Elsevier Journal of Computerized Medical Imaging and Graphics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High energy impacts at joint locations often generate highly fragmented, or\ncomminuted, bone fractures. Current approaches for treatment require physicians\nto decide how to classify the fracture within a hierarchy fracture severity\ncategories. Each category then provides a best-practice treatment scenario to\nobtain the best possible prognosis for the patient. This article identifies\nshortcomings associated with qualitative-only evaluation of fracture severity\nand provides new quantitative metrics that serve to address these shortcomings.\nWe propose a system to semi-automatically extract quantitative metrics that are\nmajor indicators of fracture severity. These include: (i) fracture surface\narea, i.e., how much surface area was generated when the bone broke apart, and\n(ii) dispersion, i.e., how far the fragments have rotated and translated from\ntheir original anatomic positions. This article describes new computational\ntools to extract these metrics by computationally reconstructing 3D bone\nanatomy from CT images with a focus on tibial plafond fracture cases where\ndifficult qualitative fracture severity cases are more prevalent.\nReconstruction is accomplished within a single system that integrates several\nnovel algorithms that identify, extract and piece-together fractured fragments\nin a virtual environment. Doing so provides objective quantitative measures for\nthese fracture severity indicators. The availability of such measures provides\nnew tools for fracture severity assessment which may lead to improved fracture\ntreatment. This paper describes the system, the underlying algorithms and the\nmetrics of the reconstruction results by quantitatively analyzing six clinical\ntibial plafond fracture cases.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 13:26:55 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Liu", "Pengcheng", ""], ["Hewitt", "Nathan", ""], ["Shadid", "Waseem", ""], ["Willis", "Andrew", ""]]}, {"id": "2102.11727", "submitter": "Josue Tonelli-Cueto", "authors": "Felipe Cucker and Alperen A. Erg\\\"ur and Josu\\'e Tonelli-Cueto", "title": "Functional norms, condition numbers and numerical algorithms in\n  algebraic geometry", "comments": "53 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.CC cs.CG cs.NA math.AG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In numerical linear algebra, a well-established practice is to choose a norm\nthat exploits the structure of the problem at hand in order to optimize\naccuracy or computational complexity. In numerical polynomial algebra, a single\nnorm (attributed to Weyl) dominates the literature. This article initiates the\nuse of $L_p$ norms for numerical algebraic geometry, with an emphasis on\n$L_{\\infty}$. This classical idea yields strong improvements in the analysis of\nthe number of steps performed by numerous iterative algorithms. In particular,\nwe exhibit three algorithms where, despite the complexity of computing\n$L_{\\infty}$-norm, the use of $L_p$-norms substantially reduces computational\ncomplexity: a subdivision-based algorithm in real algebraic geometry for\ncomputing the homology of semialgebraic sets, a well-known meshing algorithm in\ncomputational geometry, and the computation of zeros of systems of complex\nquadratic polynomials (a particular case of Smale's 17th problem).\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 14:40:20 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Cucker", "Felipe", ""], ["Erg\u00fcr", "Alperen A.", ""], ["Tonelli-Cueto", "Josu\u00e9", ""]]}, {"id": "2102.11937", "submitter": "Chaya Keller", "authors": "Chaya Keller and Bal\\'azs Keszegh and D\\\"om\\\"ot\\\"or P\\'alv\\\"olgyi", "title": "On the number of hyperedges in the hypergraph of lines and pseudo-discs", "comments": "Significantly improved results, with two additional authors. 7 pages,\n  1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider the hypergraph whose vertex set is a family of $n$ lines in general\nposition in the plane, and whose hyperedges are induced by intersections with a\nfamily of pseudo-discs. We prove that the number of $t$-hyperedges is bounded\nby $O_t(n^2)$ and that the total number of hyperedges is bounded by $O(n^3)$.\nBoth bounds are tight.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 21:00:55 GMT"}, {"version": "v2", "created": "Mon, 5 Apr 2021 09:37:46 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Keller", "Chaya", ""], ["Keszegh", "Bal\u00e1zs", ""], ["P\u00e1lv\u00f6lgyi", "D\u00f6m\u00f6t\u00f6r", ""]]}, {"id": "2102.12589", "submitter": "Haitao Wang", "authors": "Haitao Wang", "title": "A New Algorithm for Euclidean Shortest Paths in the Plane", "comments": "To appear in STOC 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a set of pairwise disjoint polygonal obstacles in the plane, finding an\nobstacle-avoiding Euclidean shortest path between two points is a classical\nproblem in computational geometry and has been studied extensively. Previously,\nHershberger and Suri [SIAM J. Comput. 1999] gave an algorithm of $O(n\\log n)$\ntime and $O(n\\log n)$ space, where $n$ is the total number of vertices of all\nobstacles. Recently, by modifying Hershberger and Suri's algorithm, Wang [SODA\n2021] reduced the space to $O(n)$ while the runtime of the algorithm is still\n$O(n\\log n)$. In this paper, we present a new algorithm of $O(n+h\\log h)$ time\nand $O(n)$ space, provided that a triangulation of the free space is given,\nwhere $h$ is the number of obstacles. The algorithm, which improves the\nprevious work when $h=o(n)$, is optimal in both time and space as\n$\\Omega(n+h\\log h)$ is a lower bound on the runtime. Our algorithm builds a\nshortest path map for a source point $s$, so that given any query point $t$,\nthe shortest path length from $s$ to $t$ can be computed in $O(\\log n)$ time\nand a shortest $s$-$t$ path can be produced in additional time linear in the\nnumber of edges of the path.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 22:35:38 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Wang", "Haitao", ""]]}, {"id": "2102.12872", "submitter": "Boris Bukh", "authors": "Boris Bukh, Ting-Wei Chao", "title": "Digital almost nets", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Digital nets (in base $2$) are the subsets of $[0,1]^d$ that contain the\nexpected number of points in every not-too-small dyadic box. We construct sets\nthat contain almost the expected number of points in every such box, but which\nare exponentially smaller than the digital nets. We also establish a lower\nbound on the size of such almost nets.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 14:21:13 GMT"}, {"version": "v2", "created": "Tue, 9 Mar 2021 17:11:47 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Bukh", "Boris", ""], ["Chao", "Ting-Wei", ""]]}, {"id": "2102.12926", "submitter": "Mustafa Hajij", "authors": "Mustafa Hajij, Ghada Zamzmi, Xuanting Cai", "title": "Persistent Homology and Graphs Representation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CG cs.CV math.AT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article aims to study the topological invariant properties encoded in\nnode graph representational embeddings by utilizing tools available in\npersistent homology. Specifically, given a node embedding representation\nalgorithm, we consider the case when these embeddings are real-valued. By\nviewing these embeddings as scalar functions on a domain of interest, we can\nutilize the tools available in persistent homology to study the topological\ninformation encoded in these representations. Our construction effectively\ndefines a unique persistence-based graph descriptor, on both the graph and node\nlevels, for every node representation algorithm. To demonstrate the\neffectiveness of the proposed method, we study the topological descriptors\ninduced by DeepWalk, Node2Vec and Diff2Vec.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 15:26:21 GMT"}, {"version": "v2", "created": "Sun, 28 Feb 2021 15:07:37 GMT"}, {"version": "v3", "created": "Tue, 2 Mar 2021 04:59:27 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Hajij", "Mustafa", ""], ["Zamzmi", "Ghada", ""], ["Cai", "Xuanting", ""]]}, {"id": "2102.13068", "submitter": "Marios Papachristou", "authors": "Apostolos Chalkis, Vissarion Fisikopoulos, Marios Papachristou, Elias\n  Tsigaridas", "title": "Truncated Log-concave Sampling with Reflective Hamiltonian Monte Carlo", "comments": "Preprint version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We introduce Reflective Hamiltonian Monte Carlo (ReHMC), an HMC-based\nalgorithm, to sample from a log-concave distribution restricted to a convex\nbody. We prove that, starting from a warm start, the walk mixes to a\nlog-concave target distribution $\\pi(x) \\propto e^{-f(x)}$, where $f$ is\n$L$-smooth and $m$-strongly-convex, within accuracy $\\varepsilon$ after\n$\\widetilde O(\\kappa d^2 \\ell^2 \\log (1 / \\varepsilon))$ steps for a\nwell-rounded convex body where $\\kappa = L / m$ is the condition number of the\nnegative log-density, $d$ is the dimension, $\\ell$ is an upper bound on the\nnumber of reflections, and $\\varepsilon$ is the accuracy parameter. We also\ndeveloped an efficient open source implementation of ReHMC and we performed an\nexperimental study on various high-dimensional data-sets. The experiments\nsuggest that ReHMC outperfroms Hit-and-Run and Coordinate-Hit-and-Run regarding\nthe time it needs to produce an independent sample and introduces practical\ntruncated sampling in thousands of dimensions.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 18:34:45 GMT"}, {"version": "v2", "created": "Wed, 2 Jun 2021 19:58:08 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Chalkis", "Apostolos", ""], ["Fisikopoulos", "Vissarion", ""], ["Papachristou", "Marios", ""], ["Tsigaridas", "Elias", ""]]}]