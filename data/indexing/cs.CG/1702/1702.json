[{"id": "1702.00146", "submitter": "Hsien-Chih Chang", "authors": "Hsien-Chih Chang and Jeff Erickson", "title": "Untangling Planar Curves", "comments": "29 pages, 26 figures. This paper improves and extends over some of\n  the results from our earlier preprint \"Electrical Reduction, Homotopy Moves,\n  and Defect\" (arXiv:1510.00571), as well as the preliminary version appeared\n  in SoCG 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG math.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Any generic closed curve in the plane can be transformed into a simple closed\ncurve by a finite sequence of local transformations called homotopy moves. We\nprove that simplifying a planar closed curve with $n$ self-crossings requires\n$\\Theta(n^{3/2})$ homotopy moves in the worst case. Our algorithm improves the\nbest previous upper bound $O(n^2)$, which is already implicit in the classical\nwork of Steinitz; the matching lower bound follows from the construction of\nclosed curves with large defect, a topological invariant of generic closed\ncurves introduced by Aicardi and Arnold. Our lower bound also implies that\n$\\Omega(n^{3/2})$ facial electrical transformations are required to reduce any\nplane graph with treewidth $\\Omega(\\sqrt{n})$ to a single vertex, matching\nknown upper bounds for rectangular and cylindrical grid graphs. More generally,\nwe prove that transforming one immersion of $k$ circles with at most $n$\nself-crossings into another requires $\\Theta(n^{3/2} + nk + k^2)$ homotopy\nmoves in the worst case. Finally, we prove that transforming one\nnoncontractible closed curve to another on any orientable surface requires\n$\\Omega(n^2)$ homotopy moves in the worst case; this lower bound is tight if\nthe curve is homotopic to a simple closed curve.\n", "versions": [{"version": "v1", "created": "Wed, 1 Feb 2017 06:45:40 GMT"}], "update_date": "2017-02-02", "authors_parsed": [["Chang", "Hsien-Chih", ""], ["Erickson", "Jeff", ""]]}, {"id": "1702.00353", "submitter": "Damien Woods", "authors": "Pierre-\\'Etienne Meunier and Damien Woods", "title": "The non-cooperative tile assembly model is not intrinsically universal\n  or capable of bounded Turing machine simulation", "comments": "Extended version of STOC 2017 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field of algorithmic self-assembly is concerned with the computational\nand expressive power of nanoscale self-assembling molecular systems. In the\nwell-studied cooperative, or temperature 2, abstract tile assembly model it is\nknown that there is a tile set to simulate any Turing machine and an\nintrinsically universal tile set that simulates the shapes and dynamics of any\ninstance of the model, up to spatial rescaling. It has been an open question as\nto whether the seemingly simpler noncooperative, or temperature 1, model is\ncapable of such behaviour. Here we show that this is not the case, by showing\nthat there is no tile set in the noncooperative model that is intrinsically\nuniversal, nor one capable of time-bounded Turing machine simulation within a\nbounded region of the plane.\n  Although the noncooperative model intuitively seems to lack the complexity\nand power of the cooperative model it was not obvious how to prove this. One\nreason is that there have been few tools to analyse the structure of\ncomplicated paths in the plane. This paper provides a number of such tools. A\nsecond reason is that almost every obvious and small generalisation to the\nmodel (e.g. allowing error, 3D, non-square tiles, signals/wires on tiles, tiles\nthat repel each other, parallel synchronous growth) endows it with great\ncomputational, and sometimes simulation, power. Our main results show that all\nof these generalisations provably increase computational and/or simulation\npower. Our results hold for both deterministic and nondeterministic\nnoncooperative systems. Our first main result stands in stark contrast with the\nfact that for both the cooperative tile assembly model, and for 3D\nnoncooperative tile assembly, there are respective intrinsically universal\ntilesets. Our second main result gives a new technique (reduction to\nsimulation) for proving negative results about computation in tile assembly.\n", "versions": [{"version": "v1", "created": "Wed, 1 Feb 2017 16:55:41 GMT"}, {"version": "v2", "created": "Tue, 30 May 2017 17:13:57 GMT"}], "update_date": "2017-05-31", "authors_parsed": [["Meunier", "Pierre-\u00c9tienne", ""], ["Woods", "Damien", ""]]}, {"id": "1702.00849", "submitter": "Chaya Keller", "authors": "Chaya Keller and Shakhar Smorodinsky", "title": "On the union complexity of families of axis-parallel rectangles with a\n  low packing number", "comments": "7 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let R be a family of n axis-parallel rectangles with packing number p-1,\nmeaning that among any p of the rectangles, there are two with a non-empty\nintersection. We show that the union complexity of R is at most O(n+p^2), and\nthat the (<=k)-level complexity of R is at most O(kn+k^2p^2). Both upper bounds\nare tight.\n", "versions": [{"version": "v1", "created": "Thu, 2 Feb 2017 22:20:25 GMT"}], "update_date": "2017-02-06", "authors_parsed": [["Keller", "Chaya", ""], ["Smorodinsky", "Shakhar", ""]]}, {"id": "1702.01275", "submitter": "Matias Korman", "authors": "Alfredo Garc\\'ia, Ferran Hurtado, Matias Korman, In\\^es Matos, Maria\n  Saumell, Rodrigo I. Silveira, Javier Tejel, Csaba D. T\\'oth", "title": "Geometric Biplane Graphs I: Maximal Graphs", "comments": null, "journal-ref": "Graphs and Combinatorics 31(2) (2015), 407-425", "doi": "10.1007/s00373-015-1546-1", "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study biplane graphs drawn on a finite planar point set $S$ in general\nposition. This is the family of geometric graphs whose vertex set is $S$ and\ncan be decomposed into two plane graphs. We show that two maximal biplane\ngraphs---in the sense that no edge can be added while staying biplane---may\ndiffer in the number of edges, and we provide an efficient algorithm for adding\nedges to a biplane graph to make it maximal. We also study extremal properties\nof maximal biplane graphs such as the maximum number of edges and the largest\nmaximum connectivity over $n$-element point sets.\n", "versions": [{"version": "v1", "created": "Sat, 4 Feb 2017 11:51:44 GMT"}], "update_date": "2017-08-10", "authors_parsed": [["Garc\u00eda", "Alfredo", ""], ["Hurtado", "Ferran", ""], ["Korman", "Matias", ""], ["Matos", "In\u00eas", ""], ["Saumell", "Maria", ""], ["Silveira", "Rodrigo I.", ""], ["Tejel", "Javier", ""], ["T\u00f3th", "Csaba D.", ""]]}, {"id": "1702.01277", "submitter": "Matias Korman", "authors": "Alfredo Garc\\'ia, Ferran Hurtado, Matias Korman, In\\^es Matos, Maria\n  Saumell, Rodrigo I. Silveira, Javier Tejel, Csaba D. T\\'oth", "title": "Geometric Biplane Graphs II: Graph Augmentation", "comments": null, "journal-ref": "Graphs and Combinatorics 31(2) (2015), 427-452", "doi": "10.1007/s00373-015-1547-0", "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study biplane graphs drawn on a finite point set $S$ in the plane in\ngeneral position. This is the family of geometric graphs whose vertex set is\n$S$ and which can be decomposed into two plane graphs. We show that every\nsufficiently large point set admits a 5-connected biplane graph and that there\nare arbitrarily large point sets that do not admit any 6-connected biplane\ngraph. Furthermore, we show that every plane graph (other than a wheel or a\nfan) can be augmented into a 4-connected biplane graph. However, there are\narbitrarily large plane graphs that cannot be augmented to a 5-connected\nbiplane graph by adding pairwise noncrossing edges.\n", "versions": [{"version": "v1", "created": "Sat, 4 Feb 2017 11:51:50 GMT"}], "update_date": "2017-08-10", "authors_parsed": [["Garc\u00eda", "Alfredo", ""], ["Hurtado", "Ferran", ""], ["Korman", "Matias", ""], ["Matos", "In\u00eas", ""], ["Saumell", "Maria", ""], ["Silveira", "Rodrigo I.", ""], ["Tejel", "Javier", ""], ["T\u00f3th", "Csaba D.", ""]]}, {"id": "1702.01446", "submitter": "Nirman Kumar", "authors": "Pankaj K. Agarwal and Nirman Kumar and Stavros Sintos and Subhash Suri", "title": "Efficient Algorithms for k-Regret Minimizing Sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A regret minimizing set Q is a small size representation of a much larger\ndatabase P so that user queries executed on Q return answers whose scores are\nnot much worse than those on the full dataset. In particular, a k-regret\nminimizing set has the property that the regret ratio between the score of the\ntop-1 item in Q and the score of the top-k item in P is minimized, where the\nscore of an item is the inner product of the item's attributes with a user's\nweight (preference) vector. The problem is challenging because we want to find\na single representative set Q whose regret ratio is small with respect to all\npossible user weight vectors.\n  We show that k-regret minimization is NP-Complete for all dimensions d >= 3.\nThis settles an open problem from Chester et al. [VLDB 2014], and resolves the\ncomplexity status of the problem for all d: the problem is known to have\npolynomial-time solution for d <= 2. In addition, we propose two new\napproximation schemes for regret minimization, both with provable guarantees,\none based on coresets and another based on hitting sets. We also carry out\nextensive experimental evaluation, and show that our schemes compute\nregret-minimizing sets comparable in size to the greedy algorithm proposed in\n[VLDB 14] but our schemes are significantly faster and scalable to large data\nsets.\n", "versions": [{"version": "v1", "created": "Sun, 5 Feb 2017 19:30:44 GMT"}, {"version": "v2", "created": "Thu, 9 Feb 2017 01:46:20 GMT"}], "update_date": "2017-02-10", "authors_parsed": [["Agarwal", "Pankaj K.", ""], ["Kumar", "Nirman", ""], ["Sintos", "Stavros", ""], ["Suri", "Subhash", ""]]}, {"id": "1702.01524", "submitter": "Shunhao Oh", "authors": "Shunhao Oh, Hon Wai Leong", "title": "Edge N-Level Sparse Visibility Graphs: Fast Optimal Any-Angle\n  Pathfinding Using Hierarchical Taut Paths", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the Any-Angle Pathfinding problem, the goal is to find the shortest path\nbetween a pair of vertices on a uniform square grid, that is not constrained to\nany fixed number of possible directions over the grid. Visibility Graphs are a\nknown optimal algorithm for solving the problem with the use of pre-processing.\nHowever, Visibility Graphs are known to perform poorly in terms of running\ntime, especially on large, complex maps. In this paper, we introduce two\nimprovements over the Visibility Graph Algorithm to compute optimal paths.\nSparse Visibility Graphs (SVGs) are constructed by pruning unnecessary edges\nfrom the original Visibility Graph. Edge N-Level Sparse Visibility Graphs\n(ENLSVGs) is a hierarchical SVG built by iteratively pruning non-taut paths. We\nalso introduce Line-of-Sight Scans, a faster algorithm for building Visibility\nGraphs over a grid. SVGs run much faster than Visibility Graphs by reducing the\naverage vertex degree. ENLSVGs, a hierarchical algorithm, improves this\nfurther, especially on larger maps. On large maps, with the use of\npre-processing, these algorithms are orders of magnitude faster than existing\nalgorithms like Visibility Graphs and Theta*.\n", "versions": [{"version": "v1", "created": "Mon, 6 Feb 2017 08:01:16 GMT"}], "update_date": "2017-02-07", "authors_parsed": [["Oh", "Shunhao", ""], ["Leong", "Hon Wai", ""]]}, {"id": "1702.01719", "submitter": "Therese Biedl", "authors": "Therese Biedl and Philippe Demontigny", "title": "A 2-Approximation for the Height of Maximal Outerplanar Graph Drawings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study planar drawings of maximal outerplanar graphs with\nthe objective of achieving small height. A recent paper gave an algorithm for\nsuch drawings that is within a factor of 4 of the optimum height. In this\npaper, we substantially improve the approximation factor to become 2. The main\ningredient is to define a new parameter of outerplanar graphs (the so-called\numbrella depth, obtained by recursively splitting the graph into graphs called\numbrellas). We argue that the height of any poly-line drawing must be at least\nthe umbrella depth, and then devise an algorithm that achieves height at most\ntwice the umbrella depth.\n", "versions": [{"version": "v1", "created": "Mon, 6 Feb 2017 17:38:26 GMT"}], "update_date": "2017-02-07", "authors_parsed": [["Biedl", "Therese", ""], ["Demontigny", "Philippe", ""]]}, {"id": "1702.01799", "submitter": "Benjamin Niedermann", "authors": "Benjamin Niedermann, Martin N\\\"ollenburg, Ignaz Rutter", "title": "Radial Contour Labeling with Straight Leaders", "comments": "Extended version of a paper to appear at the 10th IEEE Pacific\n  Visualization Symposium (PacificVis 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The usefulness of technical drawings as well as scientific illustrations such\nas medical drawings of human anatomy essentially depends on the placement of\nlabels that describe all relevant parts of the figure. In order to not spoil or\nclutter the figure with text, the labels are often placed around the figure and\nare associated by thin connecting lines to their features, respectively. This\nlabeling technique is known as external label placement.\n  In this paper we introduce a flexible and general approach for external label\nplacement assuming a contour of the figure prescribing the possible positions\nof the labels. While much research on external label placement aims for fast\nlabeling procedures for interactive systems, we focus on highest-quality\nillustrations. Based on interviews with domain experts and a semi-automatic\nanalysis of 202 handmade anatomical drawings, we identify a set of 18 layout\nquality criteria, naturally not all of equal importance. We design a new\ngeometric label placement algorithm that is based only on the most important\ncriteria. Yet, other criteria can flexibly be included in the algorithm, either\nas hard constraints not to be violated or as soft constraints whose violation\nis penalized by a general cost function. We formally prove that our approach\nyields labelings that satisfy all hard constraints and have minimum overall\ncost. Introducing several speedup techniques, we further demonstrate how to\ndeploy our approach in practice. In an experimental evaluation on real-world\nanatomical drawings we show that the resulting labelings are of high quality\nand can be produced in adequate time.\n", "versions": [{"version": "v1", "created": "Mon, 6 Feb 2017 21:31:57 GMT"}], "update_date": "2017-02-08", "authors_parsed": [["Niedermann", "Benjamin", ""], ["N\u00f6llenburg", "Martin", ""], ["Rutter", "Ignaz", ""]]}, {"id": "1702.01836", "submitter": "Kai Jin", "authors": "Kai Jin, Jian Li, Haitao Wang, Bowei Zhang, Ningye Zhang", "title": "Linear Time Approximation Schemes for Geometric Maximum Coverage", "comments": "28pages; The conference version arXiv:1505.02591 of this paper was\n  published in COCOON 2015", "journal-ref": null, "doi": "10.1016/j.tcs.2017.11.026", "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study approximation algorithms for the following geometric version of the\nmaximum coverage problem: Let $\\mathcal{P}$ be a set of $n$ weighted points in\nthe plane. Let $D$ represent a planar object, such as a rectangle, or a disk.\nWe want to place $m$ copies of $D$ such that the sum of the weights of the\npoints in $\\mathcal{P}$ covered by these copies is maximized. For any fixed\n$\\varepsilon>0$, we present efficient approximation schemes that can find a\n$(1-\\varepsilon)$-approximation to the optimal solution. In particular, for\n$m=1$ and for the special case where $D$ is a rectangle, our algorithm runs in\ntime $O(n\\log (\\frac{1}{\\varepsilon}))$, improving on the previous result. For\n$m>1$ and the rectangular case, our algorithm runs in\n$O(\\frac{n}{\\varepsilon}\\log (\\frac{1}{\\varepsilon})+\\frac{m}{\\varepsilon}\\log\nm +m(\\frac{1}{\\varepsilon})^{O(\\min(\\sqrt{m},\\frac{1}{\\varepsilon}))})$ time.\nFor a more general class of shapes (including disks, polygons with $O(1)$\nedges), our algorithm runs in\n$O(n(\\frac{1}{\\varepsilon})^{O(1)}+\\frac{m}{\\epsilon}\\log m +\nm(\\frac{1}{\\varepsilon})^{O(\\min(m,\\frac{1}{\\varepsilon^2}))})$ time.\n", "versions": [{"version": "v1", "created": "Tue, 7 Feb 2017 01:11:38 GMT"}], "update_date": "2017-12-08", "authors_parsed": [["Jin", "Kai", ""], ["Li", "Jian", ""], ["Wang", "Haitao", ""], ["Zhang", "Bowei", ""], ["Zhang", "Ningye", ""]]}, {"id": "1702.02838", "submitter": "Claire Br\\'echeteau", "authors": "Claire Br\\'echeteau", "title": "The DTM-signature for a geometric comparison of metric-measure spaces\n  from samples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce the notion of DTM-signature, a measure on R +\nthat can be associated to any metric-measure space. This signature is based on\nthe distance to a measure (DTM) introduced by Chazal, Cohen-Steiner and\nM\\'erigot. It leads to a pseudo-metric between metric-measure spaces,\nupper-bounded by the Gromov-Wasserstein distance. Under some geometric\nassumptions, we derive lower bounds for this pseudo-metric. Given two\nN-samples, we also build an asymptotic statistical test based on the\nDTM-signature, to reject the hypothesis of equality of the two underlying\nmetric-measure spaces, up to a measure-preserving isometry. We give strong\ntheoretical justifications for this test and propose an algorithm for its\nimplementation.\n", "versions": [{"version": "v1", "created": "Thu, 9 Feb 2017 14:04:20 GMT"}], "update_date": "2017-02-10", "authors_parsed": [["Br\u00e9cheteau", "Claire", ""]]}, {"id": "1702.03187", "submitter": "Alfonso Cevallos", "authors": "Manuel Aprile, Alfonso Cevallos, Yuri Faenza", "title": "On 2-level polytopes arising in combinatorial settings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  2-level polytopes naturally appear in several areas of pure and applied\nmathematics, including combinatorial optimization, polyhedral combinatorics,\ncommunication complexity, and statistics. In this paper, we present a study of\nsome 2-level polytopes arising in combinatorial settings. Our first\ncontribution is proving that v(P)*f(P) is upper bounded by d*2^(d+1), for a\nlarge collection of families of such polytopes P. Here v(P) (resp. f(P)) is the\nnumber of vertices (resp. facets) of P, and d is its dimension. Whether this\nholds for all 2-level polytopes was asked in [Bohn et al., ESA 2015], and\nexperimental results from [Fiorini et al., ISCO 2016] showed it true up to\ndimension 7. The key to most of our proofs is a deeper understanding of the\nrelations among those polytopes and their underlying combinatorial structures.\nThis leads to a number of results that we believe to be of independent\ninterest: a trade-off formula for the number of cliques and stable sets in a\ngraph; a description of stable matching polytopes as affine projections of\ncertain order polytopes; and a linear-size description of the base polytope of\nmatroids that are 2-level in terms of cuts of an associated tree.\n", "versions": [{"version": "v1", "created": "Fri, 10 Feb 2017 14:37:00 GMT"}, {"version": "v2", "created": "Thu, 14 Dec 2017 17:43:03 GMT"}], "update_date": "2017-12-15", "authors_parsed": [["Aprile", "Manuel", ""], ["Cevallos", "Alfonso", ""], ["Faenza", "Yuri", ""]]}, {"id": "1702.03266", "submitter": "Sergio Cabello", "authors": "Sergio Cabello, Lazar Milinkovi\\'c", "title": "Two Optimization Problems for Unit Disks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an implementation of a recent algorithm to compute shortest-path\ntrees in unit disk graphs in $O(n\\log n)$ worst-case time, where $n$ is the\nnumber of disks.\n  In the minimum-separation problem, we are given $n$ unit disks and two points\n$s$ and $t$, not contained in any of the disks, and we want to compute the\nminimum number of disks one needs to retain so that any curve connecting $s$ to\n$t$ intersects some of the retained disks. We present a new algorithm solving\nthis problem in $O(n^2\\log^3 n)$ worst-case time and its implementation.\n", "versions": [{"version": "v1", "created": "Fri, 10 Feb 2017 17:54:59 GMT"}], "update_date": "2017-02-13", "authors_parsed": [["Cabello", "Sergio", ""], ["Milinkovi\u0107", "Lazar", ""]]}, {"id": "1702.03364", "submitter": "Bal Khadka", "authors": "Bal K. Khadka and Spyros M. Magliveras", "title": "Techniques in Lattice Basis Reduction", "comments": "Keywords: Lattice basis, unimodular matrices, right permutations, LLL\n  algorithm, random walk distribution", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The credit on {\\it reduction theory} goes back to the work of Lagrange,\nGauss, Hermite, Korkin, Zolotarev, and Minkowski. Modern reduction theory is\nvoluminous and includes the work of A. Lenstra, H. Lenstra and L. Lovasz who\ncreated the well known LLL algorithm, and many other researchers such as L.\nBabai and C. P. Schnorr who created significant new variants of basis reduction\nalgorithms. In this paper, we propose and investigate the efficacy of new\noptimization techniques to be used along with LLL algorithm. The techniques we\nhave proposed are: i) {\\it hill climbing (HC)}, ii) {\\it lattice diffusion-sub\nlattice fusion (LDSF)}, and iii) {\\it multistage hybrid LDSF-HC}. The first\ntechnique relies on the sensitivity of LLL to permutations of the input basis\n$B$, and optimization ideas over the symmetric group $S_m$ viewed as a metric\nspace. The second technique relies on partitioning the lattice into\nsublattices, performing basis reduction in the partition sublattice blocks,\nfusing the sublattices, and repeating. We also point out places where parallel\ncomputation can reduce run-times achieving almost linear speedup. The\nmultistage hybrid technique relies on the lattice diffusion and sublattice\nfusion and hill climbing algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 11 Feb 2017 01:20:50 GMT"}], "update_date": "2017-02-14", "authors_parsed": [["Khadka", "Bal K.", ""], ["Magliveras", "Spyros M.", ""]]}, {"id": "1702.03676", "submitter": "Nabil Mustafa", "authors": "Nabil H. Mustafa and Kasturi R. Varadarajan", "title": "Epsilon-approximations and epsilon-nets", "comments": "Chapter 47 in Handbook on Discrete and Computational Geometry, 3rd\n  edition. 27 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG math.CO math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of random samples to approximate properties of geometric\nconfigurations has been an influential idea for both combinatorial and\nalgorithmic purposes. This chapter considers two related\nnotions---$\\epsilon$-approximations and $\\epsilon$-nets---that capture the most\nimportant quantitative properties that one would expect from a random sample\nwith respect to an underlying geometric configuration.\n", "versions": [{"version": "v1", "created": "Mon, 13 Feb 2017 08:54:44 GMT"}, {"version": "v2", "created": "Sun, 19 Mar 2017 08:52:47 GMT"}, {"version": "v3", "created": "Tue, 8 Aug 2017 13:19:49 GMT"}], "update_date": "2017-08-09", "authors_parsed": [["Mustafa", "Nabil H.", ""], ["Varadarajan", "Kasturi R.", ""]]}, {"id": "1702.04259", "submitter": "Arkadiy Skopenkov", "authors": "A. Skopenkov", "title": "On the metastable Mabillard-Wagner conjecture", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.GT cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of this note is to attract attention to the following conjecture\n(metastable $r$-fold Whitney trick) by clarifying its status as not having a\ncomplete proof, in the sense described in the paper.\n  Assume that $D=D_1\\sqcup\\ldots\\sqcup D_r$ is disjoint union of $r$ disks of\ndimension $s$, $f:D\\to B^d$ a proper PL map such that $f\\partial\nD_1\\cap\\ldots\\cap f\\partial D_r=\\emptyset$, $rd\\ge (r+1)s+3$ and $d\\ge s+3$. If\nthe map $$f^r:\\partial(D_1\\times\\ldots\\times D_r)\\to\n(B^d)^r-\\{(x,x,\\ldots,x)\\in(B^d)^r\\ |\\ x\\in B^d\\}$$ extends to\n$D_1\\times\\ldots\\times D_r$, then there is a PL map $\\overline f:D\\to B^d$ such\nthat $$\\overline f=f \\quad\\text{on}\\quad D_r\\cup\\partial D\\quad\\text{and}\\quad\n\\overline fD_1\\cap\\ldots\\cap \\overline fD_r=\\emptyset.$$\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2017 15:20:23 GMT"}], "update_date": "2017-02-15", "authors_parsed": [["Skopenkov", "A.", ""]]}, {"id": "1702.04641", "submitter": "Franziska Lippoldt", "authors": "Franziska Lippoldt and Hartmut Schwandt", "title": "Filling missing data in point clouds by merging structured and\n  unstructured point clouds", "comments": "6 pages, 1 figure, in preparation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CV cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Point clouds arising from structured data, mainly as a result of CT scans,\nprovides special properties on the distribution of points and the distances\nbetween those. Yet often, the amount of data provided can not compare to\nunstructured point clouds, i.e. data that arises from 3D light scans or laser\nscans. This article hereby proposes an approach to extend structured data and\nenhance the quality by inserting selected points from an unstructured point\ncloud. The resulting point cloud still has a partial structure that is called\n\"half-structure\". In this way, missing data that can not be optimally recovered\nthrough other surface reconstruction methods can be completed.\n", "versions": [{"version": "v1", "created": "Wed, 15 Feb 2017 14:59:10 GMT"}], "update_date": "2017-02-16", "authors_parsed": [["Lippoldt", "Franziska", ""], ["Schwandt", "Hartmut", ""]]}, {"id": "1702.05265", "submitter": "Franz J. Brandenburg", "authors": "Franz J. Brandenburg", "title": "T-Shape Visibility Representations of 1-Planar Graphs", "comments": "26 pages, 8 figures", "journal-ref": null, "doi": "10.1016/j.comgeo.2017.10.007", "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A shape visibility representation displays a graph so that each vertex is\nrepresented by an orthogonal polygon of a particular shape and for each edge\nthere is a horizontal or vertical line of sight between the polygons assigned\nto its endvertices. Special shapes are rectangles, L, T, E and H-shapes, and\ncaterpillars. A flat rectangle is a horizontal bar of height $\\epsilon>0$. A\ngraph is 1-planar if there is a drawing in the plane such that each edge is\ncrossed at most once and is IC-planar if in addition no two crossing edges\nshare a vertex.\n  We show that every IC-planar graph has a flat rectangle visibility\nrepresentation and that every 1-planar graph has a T-shape visibility\nrepresentation. The representations use quadratic area and can be computed in\nlinear time from a given embedding.\n", "versions": [{"version": "v1", "created": "Fri, 17 Feb 2017 09:19:02 GMT"}], "update_date": "2018-01-25", "authors_parsed": [["Brandenburg", "Franz J.", ""]]}, {"id": "1702.05358", "submitter": "\\'Eric Colin de Verdi\\`ere", "authors": "\\'Eric Colin de Verdi\\`ere", "title": "Computational topology of graphs on surfaces", "comments": "To appear in the Handbook of Discrete and Computational Geometry, 3rd\n  edition. Minor changes compared to previous version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DM cs.DS math.AT math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational topology is an area that revisits topological problems from an\nalgorithmic point of view, and develops topological tools for improved\nalgorithms. We survey results in computational topology that are concerned with\ngraphs drawn on surfaces. Typical questions include representing surfaces and\ngraphs embedded on them computationally, deciding whether a graph embeds on a\nsurface, solving computational problems related to homotopy, optimizing curves\nand graphs on surfaces, and solving standard graph algorithm problems more\nefficiently in the case of surface-embedded graphs.\n", "versions": [{"version": "v1", "created": "Fri, 17 Feb 2017 14:34:08 GMT"}, {"version": "v2", "created": "Tue, 5 Sep 2017 14:57:55 GMT"}], "update_date": "2017-09-06", "authors_parsed": [["de Verdi\u00e8re", "\u00c9ric Colin", ""]]}, {"id": "1702.05633", "submitter": "Saeed Mehrabi", "authors": "Saeed Mehrabi", "title": "Approximation Algorithms for Independence and Domination on B$_1$-VPG\n  and B$_1$-EPG Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A graph $G$ is called B$_k$-VPG (resp., B$_k$-EPG), for some constant $k\\geq\n0$, if it has a string representation on a grid such that each vertex is an\northogonal path with at most $k$ bends and two vertices are adjacent in $G$ if\nand only if the corresponding strings intersect (resp., the corresponding\nstrings share at least one grid edge). If two adjacent strings of a B$_k$-VPG\ngraph intersect exactly once, then the graph is called a one-string B$_k$-VPG\ngraph.\n  In this paper, we study the Maximum Independent Set and Minimum Dominating\nSet problems on B$_1$-VPG and B$_1$-EPG graphs. We first give a simple $O(\\log\nn)$-approximation algorithm for the Maximum Independent Set problem on\nB$_1$-VPG graphs, improving the previous $O((\\log n)^2)$-approximation\nalgorithm of Lahiri et al. (COCOA 2015). Then, we consider the Minimum\nDominating Set problem. We give an $O(1)$-approximation algorithm for this\nproblem on one-string B$_1$-VPG graphs, providing the first constant-factor\napproximation algorithm for this problem. Moreover, we show that the Minimum\nDominating Set problem is APX-hard on B$_1$-EPG graphs, ruling out the\npossibility of a PTAS unless P=NP. Finally, we give constant-factor\napproximation algorithms for this problem on two non-trivial subclasses of\nB$_1$-EPG graphs. To our knowledge, these are the first results for the Minimum\nDominating Set problem on B$_1$-EPG graphs, partially answering a question\nposed by Epstein et al. (WADS 2013).\n", "versions": [{"version": "v1", "created": "Sat, 18 Feb 2017 17:02:58 GMT"}], "update_date": "2017-02-21", "authors_parsed": [["Mehrabi", "Saeed", ""]]}, {"id": "1702.05760", "submitter": "Thijs Laarhoven", "authors": "Thijs Laarhoven", "title": "Hypercube LSH for approximate near neighbors", "comments": "18 pages, 4 figures", "journal-ref": "42nd International Symposium on Mathematical Foundations of\n  Computer Science (MFCS 2017), pp. 7:1-7:20, 2017", "doi": "10.4230/LIPIcs.MFCS.2017.7", "report-no": null, "categories": "cs.DS cs.CC cs.CG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A celebrated technique for finding near neighbors for the angular distance\ninvolves using a set of \\textit{random} hyperplanes to partition the space into\nhash regions [Charikar, STOC 2002]. Experiments later showed that using a set\nof \\textit{orthogonal} hyperplanes, thereby partitioning the space into the\nVoronoi regions induced by a hypercube, leads to even better results [Terasawa\nand Tanaka, WADS 2007]. However, no theoretical explanation for this\nimprovement was ever given, and it remained unclear how the resulting hypercube\nhash method scales in high dimensions.\n  In this work, we provide explicit asymptotics for the collision probabilities\nwhen using hypercubes to partition the space. For instance, two near-orthogonal\nvectors are expected to collide with probability $(\\frac{1}{\\pi})^{d + o(d)}$\nin dimension $d$, compared to $(\\frac{1}{2})^d$ when using random hyperplanes.\nVectors at angle $\\frac{\\pi}{3}$ collide with probability\n$(\\frac{\\sqrt{3}}{\\pi})^{d + o(d)}$, compared to $(\\frac{2}{3})^d$ for random\nhyperplanes, and near-parallel vectors collide with similar asymptotic\nprobabilities in both cases.\n  For $c$-approximate nearest neighbor searching, this translates to a decrease\nin the exponent $\\rho$ of locality-sensitive hashing (LSH) methods of a factor\nup to $\\log_2(\\pi) \\approx 1.652$ compared to hyperplane LSH. For $c = 2$, we\nobtain $\\rho \\approx 0.302 + o(1)$ for hypercube LSH, improving upon the $\\rho\n\\approx 0.377$ for hyperplane LSH. We further describe how to use hypercube LSH\nin practice, and we consider an example application in the area of lattice\nalgorithms.\n", "versions": [{"version": "v1", "created": "Sun, 19 Feb 2017 15:48:11 GMT"}], "update_date": "2017-12-08", "authors_parsed": [["Laarhoven", "Thijs", ""]]}, {"id": "1702.05900", "submitter": "Paz Carmi Dr.", "authors": "Gali Bar-On and Paz Carmi", "title": "$\\delta$-Greedy $t$-spanner", "comments": "14 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new geometric spanner, $\\delta$-Greedy, whose construction is\nbased on a generalization of the known Path-Greedy and Gap-Greedy spanners. The\n$\\delta$-Greedy spanner combines the most desirable properties of geometric\nspanners both in theory and in practice. More specifically, it has the same\ntheoretical and practical properties as the Path-Greedy spanner: a natural\ndefinition, small degree, linear number of edges, low weight, and strong\n$(1+\\varepsilon)$-spanner for every $\\varepsilon>0$. The $\\delta$-Greedy\nalgorithm is an improvement over the Path-Greedy algorithm with respect to the\nnumber of shortest path queries and hence with respect to its construction\ntime. We show how to construct such a spanner for a set of $n$ points in the\nplane in $O(n^2 \\log n)$ time.\n  The $\\delta$-Greedy spanner has an additional parameter, $\\delta$, which\nindicates how close it is to the Path-Greedy spanner on the account of the\nnumber of shortest path queries. For $\\delta = t$ the output spanner is\nidentical to the Path-Greedy spanner, while the number of shortest path queries\nis, in practice, linear.\n  Finally, we show that for a set of $n$ points placed independently at random\nin a unit square the expected construction time of the $\\delta$-Greedy\nalgorithm is $O(n \\log n)$. Our analysis indicates that the $\\delta$-Greedy\nspanner gives the best results among the known spanners of expected $O(n \\log\nn)$ time for random point sets. Moreover, the analysis implies that by setting\n$\\delta = t$, the $\\delta$-Greedy algorithm provides a spanner identical to the\nPath-Greedy spanner in expected $O(n \\log n)$ time.\n", "versions": [{"version": "v1", "created": "Mon, 20 Feb 2017 08:56:40 GMT"}], "update_date": "2017-02-21", "authors_parsed": [["Bar-On", "Gali", ""], ["Carmi", "Paz", ""]]}, {"id": "1702.06163", "submitter": "Philipp Kindermann", "authors": "Patrizio Angelini, Michael A. Bekos, Michael Kaufmann, Philipp\n  Kindermann and Thomas Schneck", "title": "1-Fan-Bundle-Planar Drawings of Graphs", "comments": "Appears in the Proceedings of the 25th International Symposium on\n  Graph Drawing and Network Visualization (GD 2017)", "journal-ref": "Theor. Comput. Sci. 723: 23-50 (2018)", "doi": "10.1016/j.tcs.2018.03.005", "report-no": null, "categories": "cs.CG math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Edge bundling is an important concept heavily used for graph visualization\npurposes. To enable the comparison with other established near-planarity models\nin graph drawing, we formulate a new edge-bundling model which is inspired by\nthe recently introduced fan-planar graphs. In particular, we restrict the\nbundling to the end segments of the edges. Similarly to 1-planarity, we call\nour model 1-fan-bundle-planarity, as we allow at most one crossing per bundle.\n  For the two variants where we allow either one or, more naturally, both end\nsegments of each edge to be part of bundles, we present edge density results\nand consider various recognition questions, not only for general graphs, but\nalso for the outer and 2-layer variants. We conclude with a series of\nchallenging questions.\n", "versions": [{"version": "v1", "created": "Mon, 20 Feb 2017 20:14:46 GMT"}, {"version": "v2", "created": "Sun, 28 May 2017 18:15:26 GMT"}, {"version": "v3", "created": "Tue, 8 Aug 2017 14:09:22 GMT"}, {"version": "v4", "created": "Thu, 6 Sep 2018 21:53:41 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Angelini", "Patrizio", ""], ["Bekos", "Michael A.", ""], ["Kaufmann", "Michael", ""], ["Kindermann", "Philipp", ""], ["Schneck", "Thomas", ""]]}, {"id": "1702.06188", "submitter": "Hamid Hamraz", "authors": "Hamid Hamraz, Marco A. Contreras, Jun Zhang", "title": "Forest understory trees can be segmented accurately within sufficiently\n  dense airborne laser scanning point clouds", "comments": "arXiv admin note: text overlap with arXiv:1701.00169", "journal-ref": "Scientific Reports, 7(1), 6770 (2017)", "doi": "10.1038/s41598-017-07200-0", "report-no": null, "categories": "cs.CV cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Airborne laser scanning (LiDAR) point clouds over large forested areas can be\nprocessed to segment individual trees and subsequently extract tree-level\ninformation. Existing segmentation procedures typically detect more than 90% of\noverstory trees, yet they barely detect 60% of understory trees because of the\nocclusion effect of higher canopy layers. Although understory trees provide\nlimited financial value, they are an essential component of ecosystem\nfunctioning by offering habitat for numerous wildlife species and influencing\nstand development. Here we model the occlusion effect in terms of point\ndensity. We estimate the fractions of points representing different canopy\nlayers (one overstory and multiple understory) and also pinpoint the required\ndensity for reasonable tree segmentation (where accuracy plateaus). We show\nthat at a density of ~170 pt/m-sqr understory trees can likely be segmented as\naccurately as overstory trees. Given the advancements of LiDAR sensor\ntechnology, point clouds will affordably reach this required density. Using\nmodern computational approaches for big data, the denser point clouds can\nefficiently be processed to ultimately allow accurate remote quantification of\nforest resources. The methodology can also be adopted for other similar remote\nsensing or advanced imaging applications such as geological subsurface\nmodelling or biomedical tissue analysis.\n", "versions": [{"version": "v1", "created": "Fri, 17 Feb 2017 16:07:53 GMT"}, {"version": "v2", "created": "Thu, 3 Aug 2017 01:32:01 GMT"}], "update_date": "2017-08-04", "authors_parsed": [["Hamraz", "Hamid", ""], ["Contreras", "Marco A.", ""], ["Zhang", "Jun", ""]]}, {"id": "1702.06829", "submitter": "Raimi Rufai", "authors": "Raimi A. Rufai and Dana S. Richards", "title": "A Simple Convex Layers Algorithm", "comments": "12 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a set of $n$ points $P$ in the plane, the first layer $L_1$ of $P$ is\nformed by the points that appear on $P$'s convex hull. In general, a point\nbelongs to layer $L_i$, if it lies on the convex hull of the set $P \\setminus\n\\bigcup_{j<i}\\{L_j\\}$. The \\emph{convex layers problem} is to compute the\nconvex layers $L_i$. Existing algorithms for this problem either do not achieve\nthe optimal $\\mathcal{O}\\left(n\\log n\\right)$ runtime and linear space, or are\noverly complex and difficult to apply in practice. We propose a new algorithm\nthat is both optimal and simple. The simplicity is achieved by independently\ncomputing four sets of monotone convex chains in $\\mathcal{O}\\left(n\\log\nn\\right)$ time and linear space. These are then merged in\n$\\mathcal{O}\\left(n\\log n\\right)$ time.\n", "versions": [{"version": "v1", "created": "Wed, 22 Feb 2017 15:03:08 GMT"}, {"version": "v2", "created": "Thu, 16 Mar 2017 14:38:10 GMT"}], "update_date": "2017-03-17", "authors_parsed": [["Rufai", "Raimi A.", ""], ["Richards", "Dana S.", ""]]}, {"id": "1702.07399", "submitter": "Rasoul Shahsavarifar", "authors": "David Bremner and Rasoul Shahsavarifar", "title": "An Optimal Algorithm for Computing the Spherical Depth of Points in the\n  Plane", "comments": "The paper consisting of 11 pages, containing 11 figures. This paper\n  is submitted to WADS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  For a distribution function $F$ on $\\mathbb{R}^d$ and a point $q\\in\n\\mathbb{R}^d$, the \\emph{spherical depth} $\\SphD(q;F)$ is defined to be the\nprobability that a point $q$ is contained inside a random closed hyper-ball\nobtained from a pair of points from $F$. The spherical depth $\\SphD(q;S)$ is\nalso defined for an arbitrary data set $S\\subseteq \\mathbb{R}^d$ and $q\\in\n\\mathbb{R}^d$. This definition is based on counting all of the closed\nhyper-balls, obtained from pairs of points in $S$, that contain $q$. The\nsignificant advantage of using the spherical depth in multivariate data\nanalysis is related to its complexity of computation. Unlike most other data\ndepths, the time complexity of the spherical depth grows linearly rather than\nexponentially in the dimension $d$. The straightforward algorithm for computing\nthe spherical depth in dimension $d$ takes $O(dn^2)$. The main result of this\npaper is an optimal algorithm that we present for computing the bivariate\nspherical depth. The algorithm takes $O(n \\log n)$ time. By reducing the\nproblem of \\textit{Element Uniqueness}, we prove that computing the spherical\ndepth requires $\\Omega(n \\log n)$ time. Some geometric properties of spherical\ndepth are also investigated in this paper. These properties indicate that\n\\emph{simplicial depth} ($\\SD$) (Liu, 1990) is linearly bounded by spherical\ndepth (in particular, $\\SphD\\geq \\frac{2}{3}SD$). To illustrate this\nrelationship between the spherical depth and the simplicial depth, some\nexperimental results are provided. The obtained experimental bound ($\\SphD\\geq\n2\\SD$) indicates that, perhaps, a stronger theoretical bound can be achieved.\n", "versions": [{"version": "v1", "created": "Thu, 23 Feb 2017 21:32:10 GMT"}], "update_date": "2017-02-27", "authors_parsed": [["Bremner", "David", ""], ["Shahsavarifar", "Rasoul", ""]]}, {"id": "1702.07555", "submitter": "Patrick Schnider", "authors": "Patrick Schnider", "title": "A generalization of crossing families", "comments": "14 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a set of points in the plane, a \\emph{crossing family} is a set of line\nsegments, each joining two of the points, such that any two line segments\ncross. We investigate the following generalization of crossing families: a\n\\emph{spoke set} is a set of lines drawn through a point set such that each\nunbounded region of the induced line arrangement contains at least one point of\nthe point set. We show that every point set has a spoke set of size\n$\\sqrt{\\frac{n}{8}}$. We also characterize the matchings obtained by selecting\nexactly one point in each unbounded region and connecting every such point to\nthe point in the antipodal unbounded region.\n", "versions": [{"version": "v1", "created": "Fri, 24 Feb 2017 12:25:43 GMT"}], "update_date": "2017-02-27", "authors_parsed": [["Schnider", "Patrick", ""]]}, {"id": "1702.07589", "submitter": "Benjamin L\\'ev\\^eque", "authors": "Benjamin L\\'ev\\^eque", "title": "Generalization of Schnyder woods to orientable surfaces and applications", "comments": "200 pages, Habilitation manuscript", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CG math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Schnyder woods are particularly elegant combinatorial structures with\nnumerous applications concerning planar triangulations and more generally\n3-connected planar maps. We propose a simple generalization of Schnyder woods\nfrom the plane to maps on orientable surfaces of any genus with a special\nemphasis on the toroidal case. We provide a natural partition of the set of\nSchnyder woods of a given map into distributive lattices depending on the\nsurface homology. In the toroidal case we show the existence of particular\nSchnyder woods with some global properties that are useful for optimal encoding\nor graph drawing purpose.\n", "versions": [{"version": "v1", "created": "Fri, 24 Feb 2017 14:06:31 GMT"}], "update_date": "2017-02-27", "authors_parsed": [["L\u00e9v\u00eaque", "Benjamin", ""]]}, {"id": "1702.07893", "submitter": "Facundo Memoli", "authors": "Patrizio Frosini, Claudia Landi, Facundo Memoli", "title": "The Persistent Homotopy Type Distance", "comments": "version 2: Extended dHT to vector-valued functions and reworked\n  Section 5", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG math.AT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the persistent homotopy type distance dHT to compare real valued\nfunctions defined on possibly different homotopy equivalent topological spaces.\nThe underlying idea in the definition of dHT is to measure the minimal shift\nthat is necessary to apply to one of the two functions in order that the\nsublevel sets of the two functions become homotopically equivalent. This\ndistance is interesting in connection with persistent homology. Indeed, our\nmain result states that dHT still provides an upper bound for the bottleneck\ndistance between the persistence diagrams of the intervening functions.\nMoreover, because homotopy equivalences are weaker than homeomorphisms, this\nimplies a lifting of the standard stability results provided by the L-infty\ndistance and the natural pseudo-distance dNP. From a different standpoint, we\nprove that dHT extends the L-infty distance and dNP in two ways. First, we show\nthat, appropriately restricting the category of objects to which dHT applies,\nit can be made to coincide with the other two distances. Finally, we show that\ndHT has an interpretation in terms of interleavings that naturally places it in\nthe family of distances used in persistence theory.\n", "versions": [{"version": "v1", "created": "Sat, 25 Feb 2017 13:55:53 GMT"}, {"version": "v2", "created": "Sun, 4 Mar 2018 16:15:19 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Frosini", "Patrizio", ""], ["Landi", "Claudia", ""], ["Memoli", "Facundo", ""]]}, {"id": "1702.08380", "submitter": "Debajyoti Mondal", "authors": "Yeganeh Bahoo, Stephane Durocher, Sahar Mehrpour, Debajyoti Mondal", "title": "Exploring Increasing-Chord Paths and Trees", "comments": "A preliminary version appeared at the 29th Canadian Conference on\n  Computational Geometry (CCCG 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A straight-line drawing $\\Gamma$ of a graph $G=(V,E)$ is a drawing of $G$ in\nthe Euclidean plane, where every vertex in $G$ is mapped to a distinct point,\nand every edge in $G$ is mapped to a straight line segment between their\nendpoints. A path $P$ in $\\Gamma$ is called increasing-chord if for every four\npoints (not necessarily vertices) $a,b,c,d$ on $P$ in this order, the Euclidean\ndistance between $b,c$ is at most the Euclidean distance between $a,d$. A\nspanning tree $T$ rooted at some vertex $r$ in $\\Gamma$ is called\nincreasing-chord if $T$ contains an increasing-chord path from $r$ to every\nvertex in $T$. In this paper we prove that given a vertex $r$ in a\nstraight-line drawing $\\Gamma$, it is NP-complete to determine whether $\\Gamma$\ncontains an increasing-chord spanning tree rooted at $r$. We conjecture that\nfinding an increasing-chord path between a pair of vertices in $\\Gamma$, which\nis an intriguing open problem posed by Alamdari et al., is also NP-complete,\nand show a (non-polynomial) reduction from the 3-SAT problem.\n", "versions": [{"version": "v1", "created": "Mon, 27 Feb 2017 17:07:31 GMT"}, {"version": "v2", "created": "Sat, 1 Jul 2017 15:55:29 GMT"}], "update_date": "2017-07-04", "authors_parsed": [["Bahoo", "Yeganeh", ""], ["Durocher", "Stephane", ""], ["Mehrpour", "Sahar", ""], ["Mondal", "Debajyoti", ""]]}, {"id": "1702.08593", "submitter": "Andrew Banman", "authors": "Andrew Banman and Lori Ziegelmeier", "title": "Mind the Gap: A Study in Global Development through Persistent Homology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AT cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Gapminder project set out to use statistics to dispel simplistic notions\nabout global development. In the same spirit, we use persistent homology, a\ntechnique from computational algebraic topology, to explore the relationship\nbetween country development and geography. For each country, four indicators,\ngross domestic product per capita; average life expectancy; infant mortality;\nand gross national income per capita, were used to quantify the development.\nTwo analyses were performed. The first considers clusters of the countries\nbased on these indicators, and the second uncovers cycles in the data when\ncombined with geographic border structure. Our analysis is a multi-scale\napproach that reveals similarities and connections among countries at a variety\nof levels. We discover localized development patterns that are invisible in\nstandard statistical methods.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2017 01:14:43 GMT"}, {"version": "v2", "created": "Thu, 11 Jan 2018 00:55:51 GMT"}], "update_date": "2018-01-12", "authors_parsed": [["Banman", "Andrew", ""], ["Ziegelmeier", "Lori", ""]]}, {"id": "1702.08607", "submitter": "Marcel Roeloffzen", "authors": "Mark de Berg, Ade Gunawan, Marcel Roeloffzen", "title": "Faster DB-scan and HDB-scan in Low-Dimensional Euclidean Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new algorithm for the widely used density-based clustering\nmethod DBscan. Our algorithm computes the DBscan-clustering in $O(n\\log n)$\ntime in $\\mathbb{R}^2$, irrespective of the scale parameter $\\varepsilon$ (and\nassuming the second parameter MinPts is set to a fixed constant, as is the case\nin practice). Experiments show that the new algorithm is not only fast in\ntheory, but that a slightly simplified version is competitive in practice and\nmuch less sensitive to the choice of $\\varepsilon$ than the original DBscan\nalgorithm. We also present an $O(n\\log n)$ randomized algorithm for HDBscan in\nthe plane---HDBscan is a hierarchical version of DBscan introduced\nrecently---and we show how to compute an approximate version of HDBscan in\nnear-linear time in any fixed dimension.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2017 02:18:54 GMT"}], "update_date": "2017-03-01", "authors_parsed": [["de Berg", "Mark", ""], ["Gunawan", "Ade", ""], ["Roeloffzen", "Marcel", ""]]}, {"id": "1702.08654", "submitter": "Ali Gholami Rudi", "authors": "Ali Gholami Rudi", "title": "An Improved Lower Bound for General Position Subset Selection", "comments": "Minor improvements in the presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the General Position Subset Selection (GPSS) problem, the goal is to find\nthe largest possible subset of a set of points such that no three of its\nmembers are collinear. If $s_{\\mathrm{GPSS}}$ is the size of the optimal\nsolution, $\\sqrt{s_{\\mathrm{GPSS}}}$ is the current best guarantee for the size\nof the solution obtained using a polynomial time algorithm. In this paper we\npresent an algorithm for GPSS to improve this bound based on the number of\ncollinear pairs of points. We experimentally evaluate this and few other GPSS\nalgorithms; the result of these experiments suggests further opportunities for\nobtaining tighter lower bounds for GPSS.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2017 05:47:10 GMT"}, {"version": "v2", "created": "Wed, 14 Jun 2017 12:12:07 GMT"}, {"version": "v3", "created": "Tue, 6 Mar 2018 16:00:06 GMT"}], "update_date": "2018-03-07", "authors_parsed": [["Rudi", "Ali Gholami", ""]]}, {"id": "1702.08662", "submitter": "Danny Nguyen", "authors": "Danny Nguyen and Igor Pak", "title": "The computational complexity of integer programming with alternations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CC cs.CG cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that integer programming with three quantifier alternations is\n$NP$-complete, even for a fixed number of variables. This complements earlier\nresults by Lenstra and Kannan, which together say that integer programming with\nat most two quantifier alternations can be done in polynomial time for a fixed\nnumber of variables. As a byproduct of the proof, we show that for two\npolytopes $P,Q \\subset \\mathbb{R}^4$ , counting the projection of integer\npoints in $Q \\backslash P$ is $\\#P$-complete. This contrasts the 2003 result by\nBarvinok and Woods, which allows counting in polynomial time the projection of\ninteger points in $P$ and $Q$ separately.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2017 06:26:44 GMT"}, {"version": "v2", "created": "Wed, 1 Mar 2017 04:25:03 GMT"}, {"version": "v3", "created": "Sun, 5 Mar 2017 02:18:12 GMT"}, {"version": "v4", "created": "Wed, 3 May 2017 01:06:41 GMT"}], "update_date": "2017-05-04", "authors_parsed": [["Nguyen", "Danny", ""], ["Pak", "Igor", ""]]}, {"id": "1702.08716", "submitter": "Fabrizio Montecchiani", "authors": "Patrizio Angelini, Michael A. Bekos, Franz J. Brandenburg, Giordano Da\n  Lozzo, Giuseppe Di Battista, Walter Didimo, Giuseppe Liotta, Fabrizio\n  Montecchiani, Ignaz Rutter", "title": "On the Relationship between $k$-Planar and $k$-Quasi Planar Graphs", "comments": "Superseded by arXiv:1909.00223 as a result of merging with\n  arXiv:1705.05569", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A graph is $k$-planar $(k \\geq 1)$ if it can be drawn in the plane such that\nno edge is crossed more than $k$ times. A graph is $k$-quasi planar $(k \\geq\n2)$ if it can be drawn in the plane with no $k$ pairwise crossing edges. The\nfamilies of $k$-planar and $k$-quasi planar graphs have been widely studied in\nthe literature, and several bounds have been proven on their edge density.\nNonetheless, only trivial results are known about the relationship between\nthese two graph families. In this paper we prove that, for $k \\geq 3$, every\n$k$-planar graph is $(k+1)$-quasi planar.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2017 09:44:01 GMT"}, {"version": "v2", "created": "Wed, 4 Sep 2019 16:41:50 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Angelini", "Patrizio", ""], ["Bekos", "Michael A.", ""], ["Brandenburg", "Franz J.", ""], ["Da Lozzo", "Giordano", ""], ["Di Battista", "Giuseppe", ""], ["Didimo", "Walter", ""], ["Liotta", "Giuseppe", ""], ["Montecchiani", "Fabrizio", ""], ["Rutter", "Ignaz", ""]]}]