[{"id": "2010.00371", "submitter": "Paul Samuel Ignacio", "authors": "Paul Samuel Ignacio, Jay-Anne Bulauan, David Uminsky", "title": "LUM\\'AWIG: An Efficient Algorithm for Dimension Zero Bottleneck Distance\n  Computation in Topological Data Analysis", "comments": "13 pages, submitted to Algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stability of persistence diagrams under slight perturbations is a key\ncharacteristic behind the validity and growing popularity of topological data\nanalysis in exploring real-world data. Central to this stability is the use of\nBottleneck distance which entails matching points between diagrams. Use of this\nmetric in practical studies has, however, been few and sparingly because of the\ncomputational obstruction, especially in dimension zero where the computational\ncost explodes with the growth of data size. We present LUM\\'AWIG, a novel\nefficient algorithm to compute dimension zero bottleneck distance between two\npersistent diagrams which runs significantly faster and provides significantly\nsharper approximates with respect to the output of the original algorithm than\nany other available algorithm. We bypass the overwhelming matching problem in\nprevious implementations of the bottleneck distance, and prove that the zero\ndimensional bottleneck distance can be recovered from a very small number of\nmatching cases. We show that LUM\\'AWIG generally enjoys linear complexity as\nshown by empirical tests. We also present an application that leverages\ndimension zero persistence diagrams and the bottleneck distance to produce\nfeatures for classification tasks.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 13:06:32 GMT"}, {"version": "v2", "created": "Fri, 9 Oct 2020 06:17:08 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Ignacio", "Paul Samuel", ""], ["Bulauan", "Jay-Anne", ""], ["Uminsky", "David", ""]]}, {"id": "2010.00478", "submitter": "Pablo Sober\\'on", "authors": "Edgardo Rold\\'an-Pensado and Pablo Sober\\'on", "title": "A survey of mass partitions", "comments": "37 pages, 8 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CG math.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mass partition problems describe the partitions we can induce on a family of\nmeasures or finite sets of points in Euclidean spaces by dividing the ambient\nspace into pieces. In this survey we describe recent progress in the area in\naddition to its connections to topology, discrete geometry, and computer\nscience.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 15:13:40 GMT"}, {"version": "v2", "created": "Wed, 7 Oct 2020 13:39:18 GMT"}, {"version": "v3", "created": "Wed, 2 Dec 2020 23:24:17 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Rold\u00e1n-Pensado", "Edgardo", ""], ["Sober\u00f3n", "Pablo", ""]]}, {"id": "2010.00743", "submitter": "Mustafa Hajij", "authors": "Mustafa Hajij, Kyle Istvan, Ghada Zamzmi", "title": "Cell Complex Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CG cs.CV math.AT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cell complexes are topological spaces constructed from simple blocks called\ncells. They generalize graphs, simplicial complexes, and polyhedral complexes\nthat form important domains for practical applications. They also provide a\ncombinatorial formalism that allows the inclusion of complicated relationships\nof restrictive structures such as graphs and meshes. In this paper, we propose\n\\textbf{Cell Complexes Neural Networks (CXNs)}, a general, combinatorial and\nunifying construction for performing neural network-type computations on cell\ncomplexes. We introduce an inter-cellular message passing scheme on cell\ncomplexes that takes the topology of the underlying space into account and\ngeneralizes message passing scheme to graphs. Finally, we introduce a unified\ncell complex encoder-decoder framework that enables learning representation of\ncells for a given complex inside the Euclidean spaces. In particular, we show\nhow our cell complex autoencoder construction can give, in the special case\n\\textbf{cell2vec}, a generalization for node2vec.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 01:38:12 GMT"}, {"version": "v2", "created": "Mon, 12 Oct 2020 06:35:37 GMT"}, {"version": "v3", "created": "Sat, 27 Feb 2021 17:11:18 GMT"}, {"version": "v4", "created": "Tue, 2 Mar 2021 03:50:54 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Hajij", "Mustafa", ""], ["Istvan", "Kyle", ""], ["Zamzmi", "Ghada", ""]]}, {"id": "2010.00973", "submitter": "Rao Fu", "authors": "Rao Fu, Jie Yang, Jiawei Sun, Fang-Lue Zhang, Yu-Kun Lai and Lin Gao", "title": "RISA-Net: Rotation-Invariant Structure-Aware Network for Fine-Grained 3D\n  Shape Retrieval", "comments": "The code and dataset are available at:\n  https://github.com/IGLICT/RisaNET", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fine-grained 3D shape retrieval aims to retrieve 3D shapes similar to a query\nshape in a repository with models belonging to the same class, which requires\nshape descriptors to be capable of representing detailed geometric information\nto discriminate shapes with globally similar structures. Moreover, 3D objects\ncan be placed with arbitrary position and orientation in real-world\napplications, which further requires shape descriptors to be robust to rigid\ntransformations. The shape descriptions used in existing 3D shape retrieval\nsystems fail to meet the above two criteria. In this paper, we introduce a\nnovel deep architecture, RISA-Net, which learns rotation invariant 3D shape\ndescriptors that are capable of encoding fine-grained geometric information and\nstructural information, and thus achieve accurate results on the task of\nfine-grained 3D object retrieval. RISA-Net extracts a set of compact and\ndetailed geometric features part-wisely and discriminatively estimates the\ncontribution of each semantic part to shape representation. Furthermore, our\nmethod is able to learn the importance of geometric and structural information\nof all the parts when generating the final compact latent feature of a 3D shape\nfor fine-grained retrieval. We also build and publish a new 3D shape dataset\nwith sub-class labels for validating the performance of fine-grained 3D shape\nretrieval methods. Qualitative and quantitative experiments show that our\nRISA-Net outperforms state-of-the-art methods on the fine-grained object\nretrieval task, demonstrating its capability in geometric detail extraction.\nThe code and dataset are available at: https://github.com/IGLICT/RisaNET.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 13:06:12 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Fu", "Rao", ""], ["Yang", "Jie", ""], ["Sun", "Jiawei", ""], ["Zhang", "Fang-Lue", ""], ["Lai", "Yu-Kun", ""], ["Gao", "Lin", ""]]}, {"id": "2010.01391", "submitter": "Dan Reznik", "authors": "Dan Reznik and Ronaldo Garcia", "title": "An Infinite, Converging, Sequence of Brocard Porisms", "comments": "20 pages, 6 figures, 2 tables, 4 video links", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.MG cs.CG cs.GR cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Brocard porism is a known 1d family of triangles inscribed in a circle\nand circumscribed about an ellipse. Remarkably, the Brocard angle is invariant\nand the Brocard points are stationary at the foci of the ellipse. In this paper\nwe show that a certain derived triangle spawns off a second, smaller, Brocard\nporism so that repeating this calculation produces an infinite, converging\nsequence of porisms. We also show that this sequence is embedded in a\ncontinuous family of porisms.\n", "versions": [{"version": "v1", "created": "Sat, 3 Oct 2020 17:06:39 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 11:54:43 GMT"}, {"version": "v3", "created": "Wed, 7 Oct 2020 16:36:04 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Reznik", "Dan", ""], ["Garcia", "Ronaldo", ""]]}, {"id": "2010.01881", "submitter": "Jonas Cleve", "authors": "Man-Kwun Chiu, Jonas Cleve, Martin N\\\"ollenburg", "title": "Recognizing embedded caterpillars with weak unit disk contact\n  representations is NP-hard", "comments": "Appeared in EuroCG 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weak unit disk contact graphs are graphs that admit a representation of the\nnodes as a collection of internally disjoint unit disks whose boundaries touch\nif there is an edge between the corresponding nodes. We provide a gadget-based\nreduction to show that recognizing embedded caterpillars that admit a weak unit\ndisk contact representation is NP-hard.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 09:31:28 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Chiu", "Man-Kwun", ""], ["Cleve", "Jonas", ""], ["N\u00f6llenburg", "Martin", ""]]}, {"id": "2010.01886", "submitter": "Jonas Cleve", "authors": "Jonas Cleve", "title": "Weak Unit Disk Contact Representations for Graphs without Embedding", "comments": "Appeared in EuroCG 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weak unit disk contact graphs are graphs that admit representing nodes as a\ncollection of internally disjoint unit disks whose boundaries touch if there is\nan edge between the corresponding nodes. In this work we focus on graphs\nwithout embedding, i.e., the neighbor order can be chosen arbitrarily. We give\na linear time algorithm to recognize whether a caterpillar, a graph where every\nnode is adjacent to or on a central path, allows a weak unit disk contact\nrepresentation. On the other hand, we show that it is NP-hard to decide whether\na tree allows such a representation.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 09:44:24 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Cleve", "Jonas", ""]]}, {"id": "2010.02379", "submitter": "Yiqiu Wang", "authors": "Yiqiu Wang, Shangdi Yu, Yan Gu, Julian Shun", "title": "A Parallel Batch-Dynamic Data Structure for the Closest Pair Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a theoretically-efficient and practical parallel batch-dynamic\ndata structure for the closest pair problem. Our solution is based on a serial\ndynamic closest pair data structure by Golin et al., and supports batches of\ninsertions and deletions in parallel. For a data set of size $n$, our data\nstructure supports a batch of insertions or deletions of size $m$ in\n$O(m(1+\\log ((n+m)/m)))$ expected work and $O(\\log (n+m)\\log^*(n+m))$ depth\nwith high probability, and takes linear space. The key techniques for achieving\nthese bounds are a new work-efficient parallel batch-dynamic binary heap, and\ncareful management of the computation across sets of points to minimize work\nand depth.\n  We provide an optimized multicore implementation of our data structure using\ndynamic hash tables, parallel heaps, and dynamic $k$-d trees. Our experiments\non a variety of synthetic and real-world data sets show that it achieves a\nparallel speedup of up to 38.57x (15.10x on average) on 48 cores with\nhyper-threading. In addition, we also implement and compare four parallel\nalgorithms for static closest pair problem, for which we are not aware of any\nexisting practical implementations. On 48 cores with hyper-threading, the\nstatic algorithms achieve up to 51.45x (29.42x on average) speedup, and Rabin's\nalgorithm performs the best on average. Comparing our dynamic algorithm to the\nfastest static algorithm, we find that it is advantageous to use the dynamic\nalgorithm for batch sizes of up to 20\\% of the data set. As far as we know, our\nwork is the first to experimentally evaluate parallel closest pair algorithms,\nin both the static and the dynamic settings.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 22:50:33 GMT"}, {"version": "v2", "created": "Thu, 18 Mar 2021 22:30:41 GMT"}, {"version": "v3", "created": "Tue, 23 Mar 2021 23:26:51 GMT"}], "update_date": "2021-03-25", "authors_parsed": [["Wang", "Yiqiu", ""], ["Yu", "Shangdi", ""], ["Gu", "Yan", ""], ["Shun", "Julian", ""]]}, {"id": "2010.02449", "submitter": "Nadav Dym", "authors": "Nadav Dym and Haggai Maron", "title": "On the Universality of Rotation Equivariant Point Cloud Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning functions on point clouds has applications in many fields, including\ncomputer vision, computer graphics, physics, and chemistry. Recently, there has\nbeen a growing interest in neural architectures that are invariant or\nequivariant to all three shape-preserving transformations of point clouds:\ntranslation, rotation, and permutation.\n  In this paper, we present a first study of the approximation power of these\narchitectures. We first derive two sufficient conditions for an equivariant\narchitecture to have the universal approximation property, based on a novel\ncharacterization of the space of equivariant polynomials. We then use these\nconditions to show that two recently suggested models are universal, and for\ndevising two other novel universal architectures.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 03:14:16 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Dym", "Nadav", ""], ["Maron", "Haggai", ""]]}, {"id": "2010.02863", "submitter": "Dominique Beaini", "authors": "Dominique Beaini, Saro Passaro, Vincent L\\'etourneau, William L.\n  Hamilton, Gabriele Corso, Pietro Li\\`o", "title": "Directional Graph Networks", "comments": "11 pages, 10 pages appendix, 6 figures, subtitle: Anisotropic\n  aggregation in graph neural networks via directional vector fields", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CG cs.SI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The lack of anisotropic kernels in graph neural networks (GNNs) strongly\nlimits their expressiveness, contributing to well-known issues such as\nover-smoothing. To overcome this limitation, we propose the first globally\nconsistent anisotropic kernels for GNNs, allowing for graph convolutions that\nare defined according to topologicaly-derived directional flows. First, by\ndefining a vector field in the graph, we develop a method of applying\ndirectional derivatives and smoothing by projecting node-specific messages into\nthe field. Then, we propose the use of the Laplacian eigenvectors as such\nvector field. We show that the method generalizes CNNs on an $n$-dimensional\ngrid and is provably more discriminative than standard GNNs regarding the\nWeisfeiler-Lehman 1-WL test. We evaluate our method on different standard\nbenchmarks and see a relative error reduction of 8% on the CIFAR10 graph\ndataset and 11% to 32% on the molecular ZINC dataset, and a relative increase\nin precision of 1.6% on the MolPCBA dataset. An important outcome of this work\nis that it enables graph networks to embed directions in an unsupervised way,\nthus allowing a better representation of the anisotropic features in different\nphysical or biological problems.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 16:31:27 GMT"}, {"version": "v2", "created": "Thu, 10 Dec 2020 00:16:03 GMT"}, {"version": "v3", "created": "Mon, 29 Mar 2021 21:39:56 GMT"}, {"version": "v4", "created": "Wed, 7 Apr 2021 18:50:16 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Beaini", "Dominique", ""], ["Passaro", "Saro", ""], ["L\u00e9tourneau", "Vincent", ""], ["Hamilton", "William L.", ""], ["Corso", "Gabriele", ""], ["Li\u00f2", "Pietro", ""]]}, {"id": "2010.02908", "submitter": "Csaba D. Toth", "authors": "Sujoy Bhore, Csaba D. T\\'oth", "title": "On Euclidean Steiner $(1+\\epsilon)$-Spanners", "comments": "16 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lightness and sparsity are two natural parameters for Euclidean\n$(1+\\varepsilon)$-spanners. Classical results show that, when the dimension\n$d\\in \\mathbb{N}$ and $\\varepsilon>0$ are constant, every set $S$ of $n$ points\nin $d$-space admits an $(1+\\varepsilon)$-spanners with $O(n)$ edges and weight\nproportional to that of the Euclidean MST of $S$. Tight bounds on the\ndependence on $\\varepsilon>0$ for constant $d\\in \\mathbb{N}$ have been\nestablished only recently. Le and Solomon (FOCS 2019) showed that Steiner\npoints can substantially improve the lightness and sparsity of a\n$(1+\\varepsilon)$-spanner. They gave upper bounds of\n$\\tilde{O}(\\varepsilon^{-(d+1)/2})$ for the minimum lightness in dimensions\n$d\\geq 3$, and $\\tilde{O}(\\varepsilon^{-(d-1))/2})$ for the minimum sparsity in\n$d$-space for all $d\\geq 1$. They obtained lower bounds only in the plane\n($d=2$). Le and Solomon (ESA 2020) also constructed Steiner\n$(1+\\varepsilon)$-spanners of lightness $O(\\varepsilon^{-1}\\log\\Delta)$ in the\nplane, where $\\Delta\\in \\Omega(\\sqrt{n})$ is the \\emph{spread} of $S$, defined\nas the ratio between the maximum and minimum distance between a pair of points.\n  In this work, we improve several bounds on the lightness and sparsity of\nEuclidean Steiner $(1+\\varepsilon)$-spanners. Using a new geometric analysis,\nwe establish lower bounds of $\\Omega(\\varepsilon^{-d/2})$ for the lightness and\n$\\Omega(\\varepsilon^{-(d-1)/2})$ for the sparsity of such spanners in Euclidean\n$d$-space for all $d\\geq 2$. We use the geometric insight from our lower bound\nanalysis to construct Steiner $(1+\\varepsilon)$-spanners of lightness\n$O(\\varepsilon^{-1}\\log n)$ for $n$ points in Euclidean plane.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 17:40:32 GMT"}, {"version": "v2", "created": "Thu, 25 Feb 2021 04:01:31 GMT"}, {"version": "v3", "created": "Sat, 13 Mar 2021 16:59:52 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Bhore", "Sujoy", ""], ["T\u00f3th", "Csaba D.", ""]]}, {"id": "2010.03817", "submitter": "Elias Tsigaridas", "authors": "Apostolos Chalkis (DI), Ioannis Emiris (DI, AROMATH), Vissarion\n  Fisikopoulos (DI), Panagiotis Repouskos (DI), Elias Tsigaridas (OURAGAN, SU)", "title": "Efficient Sampling from Feasible Sets of SDPs and Volume Approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present algorithmic, complexity, and implementation results on the problem\nof sampling points from a spectrahedron, that is the feasible region of a\nsemidefinite program. Our main tool is geometric random walks. We analyze the\narithmetic and bit complexity of certain primitive geometric operations that\nare based on the algebraic properties of spectrahedra and the polynomial\neigenvalue problem. This study leads to the implementation of a broad\ncollection of random walks for sampling from spectrahedra that experimentally\nshow faster mixing times than methods currently employed either in theoretical\nstudies or in applications, including the popular family of Hit-and-Run walks.\nThe different random walks offer a variety of advantages , thus allowing us to\nefficiently sample from general probability distributions, for example the\nfamily of log-concave distributions which arise in numerous applications. We\nfocus on two major applications of independent interest: (i) approximate the\nvolume of a spectrahedron, and (ii) compute the expectation of functions coming\nfrom robust optimal control. We exploit efficient linear algebra algorithms and\nimplementations to address the aforemen-tioned computations in very high\ndimension. In particular, we provide a C++ open source implementation of our\nmethods that scales efficiently, for the first time, up to dimension 200. We\nillustrate its efficiency on various data sets.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 07:42:26 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Chalkis", "Apostolos", "", "DI"], ["Emiris", "Ioannis", "", "DI, AROMATH"], ["Fisikopoulos", "Vissarion", "", "DI"], ["Repouskos", "Panagiotis", "", "DI"], ["Tsigaridas", "Elias", "", "OURAGAN, SU"]]}, {"id": "2010.03870", "submitter": "Ahmad Biniaz", "authors": "Ahmad Biniaz", "title": "Improved approximation ratios for two Euclidean maximum spanning tree\n  problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the following two maximization problems related to spanning trees in\nthe Euclidean plane. It is not known whether or not these problems are NP-hard.\nWe present approximation algorithms with better approximation ratios for both\nproblems. The improved ratios are obtained mainly by employing the Steiner\nratio, which has not been used in this context earlier.\n  (i) Longest noncrossing spanning tree: Given a set of points in the plane,\nthe goal is to find a maximum-length noncrossing spanning tree. Alon,\nRajagopalan, and Suri (SoCG 1993) studied this problem for the first time and\ngave a $0.5$-approximation algorithm. Over the years, the approximation ratio\nhas been successively improved to $0.502$, $0.503$, and to $0.512$ which is the\ncurrent best ratio, due to Cabello et al.. We revisit this problem and improve\nthe ratio further to $0.519$. The improvement is achieved by a collection of\nideas, some from previous works and some new ideas (including the use of the\nSteiner ratio), along with a more refined analysis.\n  (ii) Longest spanning tree with neighborhoods: Given a collection of regions\n(neighborhoods) in the plane, the goal is to select a point in each\nneighborhood so that the longest spanning tree on selected points has maximum\nlength. We present an algorithm with approximation ratio $0.524$ for this\nproblem. The previous best ratio, due to Chen and Dumitrescu, is $0.511$ which\nis in turn the first improvement beyond the trivial ratio $0.5$. Our algorithm\nis fairly simple, its analysis is relatively short, and it takes linear time\nafter computing a diametral pair of points. The simplicity comes from the fact\nthat our solution belongs to a set containing three stars and one double-star.\nThe shortness and the improvement come from the use of the Steiner ratio.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 09:53:32 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Biniaz", "Ahmad", ""]]}, {"id": "2010.03894", "submitter": "Paul Samuel Ignacio", "authors": "Paul Samuel P. Ignacio", "title": "Intrinsic Hierarchical Clustering Behavior Recovers Higher Dimensional\n  Shape Information", "comments": "10 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that specific higher dimensional shape information of point cloud\ndata can be recovered by observing lower dimensional hierarchical clustering\ndynamics. We generate multiple point samples from point clouds and perform\nhierarchical clustering within each sample to produce dendrograms. From these\ndendrograms, we take cluster evolution and merging data that capture clustering\nbehavior to construct simplified diagrams that record the lifetime of clusters\nakin to what zero dimensional persistence diagrams do in topological data\nanalysis. We compare differences between these diagrams using the bottleneck\nmetric, and examine the resulting distribution. Finally, we show that\nstatistical features drawn from these bottleneck distance distributions detect\nartefacts of, and can be tapped to recover higher dimensional shape\ncharacteristics.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 10:43:14 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Ignacio", "Paul Samuel P.", ""]]}, {"id": "2010.04135", "submitter": "Pablo Sober\\'on", "authors": "John A. Messina and Pablo Sober\\'on", "title": "Isometric and affine copies of a set in volumetric Helly results", "comments": "10 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.MG cs.CG math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that for any compact convex set $K$ in $\\mathbb{R}^d$ and any finite\nfamily $\\mathcal{F}$ of convex sets in $\\mathbb{R}^d$, if the intersection of\nevery sufficiently small subfamily of $\\mathcal{F}$ contains an isometric copy\nof $K$ of volume $1$, then the intersection of the whole family contains an\nisometric copy of $K$ scaled by a factor of $(1-\\varepsilon)$, where\n$\\varepsilon$ is positive and fixed in advance. Unless $K$ is very similar to a\ndisk, the shrinking factor is unavoidable. We prove similar results for affine\ncopies of $K$. We show how our results imply the existence of randomized\nalgorithms that approximate the largest copy of $K$ that fits inside a given\npolytope $P$ whose expected runtime is linear on the number of facets of $P$.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 17:25:20 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Messina", "John A.", ""], ["Sober\u00f3n", "Pablo", ""]]}, {"id": "2010.04638", "submitter": "Christopher Hahne", "authors": "Christopher Hahne, Amar Aggoun, Vladan Velisavljevic, Susanne Fiebig,\n  Matthias Pesch", "title": "Baseline and Triangulation Geometry in a Standard Plenoptic Camera", "comments": "clarified remarks around Eqs.(16-17)", "journal-ref": "International Journal of Computer Vision, volume 126, pages 21-35\n  (2018)", "doi": "10.1007/s11263-017-1036-4", "report-no": null, "categories": "cs.IR cs.CG cs.CV physics.optics", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we demonstrate light field triangulation to determine depth\ndistances and baselines in a plenoptic camera. Advances in micro lenses and\nimage sensors have enabled plenoptic cameras to capture a scene from different\nviewpoints with sufficient spatial resolution. While object distances can be\ninferred from disparities in a stereo viewpoint pair using triangulation, this\nconcept remains ambiguous when applied in the case of plenoptic cameras. We\npresent a geometrical light field model allowing the triangulation to be\napplied to a plenoptic camera in order to predict object distances or specify\nbaselines as desired. It is shown that distance estimates from our novel method\nmatch those of real objects placed in front of the camera. Additional benchmark\ntests with an optical design software further validate the model's accuracy\nwith deviations of less than +-0.33 % for several main lens types and focus\nsettings. A variety of applications in the automotive and robotics field can\nbenefit from this estimation model.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 15:31:14 GMT"}, {"version": "v2", "created": "Wed, 20 Jan 2021 12:02:36 GMT"}], "update_date": "2021-01-21", "authors_parsed": [["Hahne", "Christopher", ""], ["Aggoun", "Amar", ""], ["Velisavljevic", "Vladan", ""], ["Fiebig", "Susanne", ""], ["Pesch", "Matthias", ""]]}, {"id": "2010.05780", "submitter": "Chad M. Topaz", "authors": "Lu Xian, Henry Adams, Chad M. Topaz, Lori Ziegelmeier", "title": "Capturing Dynamics of Time-Varying Data via Topology", "comments": "35 pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CG math.AT math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One approach to understanding complex data is to study its shape through the\nlens of algebraic topology. While the early development of topological data\nanalysis focused primarily on static data, in recent years, theoretical and\napplied studies have turned to data that varies in time. A time-varying\ncollection of metric spaces as formed, for example, by a moving school of fish\nor flock of birds, can contain a vast amount of information. There is often a\nneed to simplify or summarize the dynamic behavior. We provide an introduction\nto topological summaries of time-varying metric spaces including vineyards\n[19], crocker plots [56], and multiparameter rank functions [37]. We then\nintroduce a new tool to summarize time-varying metric spaces: a crocker stack.\nCrocker stacks are convenient for visualization, amenable to machine learning,\nand satisfy a desirable continuity property which we prove. We demonstrate the\nutility of crocker stacks for a parameter identification task involving an\ninfluential model of biological aggregations [58]. Altogether, we aim to bring\nthe broader applied mathematics community up-to-date on topological summaries\nof time-varying metric spaces.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 20:07:40 GMT"}, {"version": "v2", "created": "Mon, 28 Jun 2021 14:10:20 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Xian", "Lu", ""], ["Adams", "Henry", ""], ["Topaz", "Chad M.", ""], ["Ziegelmeier", "Lori", ""]]}, {"id": "2010.06463", "submitter": "Michiel Smid", "authors": "Abrar Kazi, Michiel Smid", "title": "Closest-Pair Queries and Minimum-Weight Queries are Equivalent for\n  Squares", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Let $S$ be a set of $n$ weighted points in the plane and let $R$ be a query\nrange in the plane. In the range closest pair problem, we want to report the\nclosest pair in the set $R \\cap S$. In the range minimum weight problem, we\nwant to report the minimum weight of any point in the set $R \\cap S$. We show\nthat these two query problems are equivalent for query ranges that are squares,\nfor data structures having $\\Omega(\\log n)$ query times. As a result, we obtain\nnew data structures for range closest pair queries with squares.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 15:17:19 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Kazi", "Abrar", ""], ["Smid", "Michiel", ""]]}, {"id": "2010.07337", "submitter": "Amit Patel", "authors": "Alexander McCleary and Amit Patel", "title": "Edit Distance and Persistence Diagrams Over Lattices", "comments": "We made several improvements to the paper. We also added a new\n  theorem proving that the edit distance is strongly equivalent to the\n  bottleneck distance", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AT cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We build a functorial pipeline for persistent homology. The input to this\npipeline is a filtered simplicial complex indexed by any finite metric lattice\nand the output is a persistence diagram defined as the M\\\"obius inversion of\nits birth-death function. We adapt the Reeb graph edit distance to each of our\ncategories and prove that both functors in our pipeline are $1$-Lipschitz\nmaking our pipeline stable. Our constructions generalize the classical\npersistence diagram and, in this setting, the bottleneck distance is strongly\nequivalent to the edit distance.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 18:11:12 GMT"}, {"version": "v2", "created": "Sun, 2 May 2021 19:19:47 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["McCleary", "Alexander", ""], ["Patel", "Amit", ""]]}, {"id": "2010.08276", "submitter": "Biao Zhang", "authors": "Biao Zhang, Peter Wonka", "title": "Training Data Generating Networks: Linking 3D Shapes and Few-Shot\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CG cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel 3d shape representation for 3d shape reconstruction from a\nsingle image. Rather than predicting a shape directly, we train a network to\ngenerate a training set which will be feed into another learning algorithm to\ndefine the shape. Training data generating networks establish a link between\nfew-shot learning and 3d shape analysis. We propose a novel meta-learning\nframework to jointly train the data generating network and other components. We\nimprove upon recent work on standard benchmarks for 3d shape reconstruction,\nbut our novel shape representation has many applications.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 09:52:13 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Zhang", "Biao", ""], ["Wonka", "Peter", ""]]}, {"id": "2010.08356", "submitter": "Mathieu Carri\\`ere", "authors": "Mathieu Carri\\`ere, Fr\\'ed\\'eric Chazal, Marc Glisse, Yuichi Ike,\n  Hariprasad Kannan", "title": "Optimizing persistent homology based functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG math.AT math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solving optimization tasks based on functions and losses with a topological\nflavor is a very active, growing field of research in data science and\nTopological Data Analysis, with applications in non-convex optimization,\nstatistics and machine learning. However, the approaches proposed in the\nliterature are usually anchored to a specific application and/or topological\nconstruction, and do not come with theoretical guarantees. To address this\nissue, we study the differentiability of a general map associated with the most\ncommon topological construction, that is, the persistence map. Building on real\nanalytic geometry arguments, we propose a general framework that allows us to\ndefine and compute gradients for persistence-based functions in a very simple\nway. We also provide a simple, explicit and sufficient condition for\nconvergence of stochastic subgradient methods for such functions. This result\nencompasses all the constructions and applications of topological optimization\nin the literature. Finally, we provide associated code, that is easy to handle\nand to mix with other non-topological methods and constraints, as well as some\nexperiments showcasing the versatility of our approach.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 12:48:30 GMT"}, {"version": "v2", "created": "Wed, 17 Feb 2021 19:35:59 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Carri\u00e8re", "Mathieu", ""], ["Chazal", "Fr\u00e9d\u00e9ric", ""], ["Glisse", "Marc", ""], ["Ike", "Yuichi", ""], ["Kannan", "Hariprasad", ""]]}, {"id": "2010.08691", "submitter": "Elizabeth Munch", "authors": "Kayla Makela and Tim Ophelders and Michelle Quigley and Elizabeth\n  Munch and Daniel Chitwood and Asia Dowtin", "title": "Automatic Tree Ring Detection using Jacobi Sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tree ring widths are an important source of climatic and historical data, but\nmeasuring these widths typically requires extensive manual work. Computer\nvision techniques provide promising directions towards the automation of tree\nring detection, but most automated methods still require a substantial amount\nof user interaction to obtain high accuracy. We perform analysis on 3D X-ray CT\nimages of a cross-section of a tree trunk, known as a tree disk. We present\nnovel automated methods for locating the pith (center) of a tree disk, and ring\nboundaries. Our methods use a combination of standard image processing\ntechniques and tools from topological data analysis. We evaluate the efficacy\nof our method for two different CT scans by comparing its results to manually\nlocated rings and centers and show that it is better than current automatic\nmethods in terms of correctly counting each ring and its location. Our methods\nhave several parameters, which we optimize experimentally by minimizing edit\ndistances to the manually obtained locations.\n", "versions": [{"version": "v1", "created": "Sat, 17 Oct 2020 01:28:16 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Makela", "Kayla", ""], ["Ophelders", "Tim", ""], ["Quigley", "Michelle", ""], ["Munch", "Elizabeth", ""], ["Chitwood", "Daniel", ""], ["Dowtin", "Asia", ""]]}, {"id": "2010.09115", "submitter": "Haitao Wang", "authors": "Haitao Wang", "title": "Shortest Paths Among Obstacles in the Plane Revisited", "comments": "Published in SODA 2021. Observation 2 in the previous version (and\n  also in SODA proceedings) is not correct. The issue is addressed in this\n  version with slightly different analysis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a set of pairwise disjoint polygonal obstacles in the plane, finding an\nobstacle-avoiding Euclidean shortest path between two points is a classical\nproblem in computational geometry and has been studied extensively. The\nprevious best algorithm was given by Hershberger and Suri [FOCS 1993, SIAM J.\nComput. 1999] and the algorithm runs in $O(n\\log n)$ time and $O(n\\log n)$\nspace, where $n$ is the total number of vertices of all obstacles. The\nalgorithm is time-optimal because $\\Omega(n\\log n)$ is a lower bound. It has\nbeen an open problem for over two decades whether the space can be reduced to\n$O(n)$. In this paper, we settle it by solving the problem in $O(n\\log n)$ time\nand $O(n)$ space, which is optimal in both time and space; we achieve this by\nmodifying the algorithm of Hershberger and Suri. Like their original algorithm,\nour new algorithm can build a shortest path map for a source point $s$ in\n$O(n\\log n)$ time and $O(n)$ space, such that given any query point $t$, the\nlength of a shortest path from $s$ to $t$ can be computed in $O(\\log n)$ time\nand a shortest path can be produced in additional time linear in the number of\nedges of the path.\n", "versions": [{"version": "v1", "created": "Sun, 18 Oct 2020 21:54:15 GMT"}, {"version": "v2", "created": "Sat, 29 May 2021 18:23:23 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Wang", "Haitao", ""]]}, {"id": "2010.09408", "submitter": "Dan Reznik", "authors": "Mark Helman and Ronaldo Garcia and Dan Reznik", "title": "Intriguing Invariants of Centers of Ellipse-Inscribed Triangles", "comments": "17 pages, 10 figures, 3 tables, 6 video links", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.MG cs.CG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe invariants of centers of ellipse-inscribed triangle families with\ntwo vertices fixed to the ellipse boundary and a third one which sweeps it. We\nprove that: (i) if a triangle center is a fixed affine combination of\nbarycenter and orthocenter, its locus is an ellipse; (ii) and that over the\nfamily of said affine combinations, the centers of said loci sweep a line;\n(iii) over the family of parallel fixed vertices, said loci rigidly translate\nalong a second line. Additionally, we study invariants of the envelope of\nelliptic loci over combinations of two fixed vertices on the ellipse.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 11:59:48 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 03:02:48 GMT"}, {"version": "v3", "created": "Wed, 2 Dec 2020 16:50:55 GMT"}, {"version": "v4", "created": "Fri, 16 Apr 2021 20:31:40 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Helman", "Mark", ""], ["Garcia", "Ronaldo", ""], ["Reznik", "Dan", ""]]}, {"id": "2010.09580", "submitter": "William Lochet", "authors": "Eduard Eiben, Fedor V. Fomin, Petr A. Golovach, William Lochet, Fahad\n  Panolan and Kirill Simonov", "title": "EPTAS for $k$-means Clustering of Affine Subspaces", "comments": "To be published in Symposium on Discrete Algorithms (SODA) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a generalization of the fundamental $k$-means clustering for data\nwith incomplete or corrupted entries. When data objects are represented by\npoints in $\\mathbb{R}^d$, a data point is said to be incomplete when some of\nits entries are missing or unspecified. An incomplete data point with at most\n$\\Delta$ unspecified entries corresponds to an axis-parallel affine subspace of\ndimension at most $\\Delta$, called a $\\Delta$-point. Thus we seek a partition\nof $n$ input $\\Delta$-points into $k$ clusters minimizing the $k$-means\nobjective. For $\\Delta=0$, when all coordinates of each point are specified,\nthis is the usual $k$-means clustering. We give an algorithm that finds an $(1+\n\\epsilon)$-approximate solution in time $f(k,\\epsilon, \\Delta) \\cdot n^2 \\cdot\nd$ for some function $f$ of $k,\\epsilon$, and $\\Delta$ only.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 15:04:30 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Eiben", "Eduard", ""], ["Fomin", "Fedor V.", ""], ["Golovach", "Petr A.", ""], ["Lochet", "William", ""], ["Panolan", "Fahad", ""], ["Simonov", "Kirill", ""]]}, {"id": "2010.09628", "submitter": "Michael Lesnick", "authors": "Andrew J. Blumberg, Michael Lesnick", "title": "Stability of 2-Parameter Persistent Homology", "comments": "45 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AT cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The \\v{C}ech and Rips constructions of persistent homology are stable with\nrespect to perturbations of the input data. However, neither is robust to\noutliers, and both can be insensitive to topological structure of high-density\nregions of the data. A natural solution is to consider 2-parameter persistence.\nThis paper studies the stability of 2-parameter persistent homology: We show\nthat several related density-sensitive constructions of bifiltrations from data\nsatisfy stability properties accommodating the addition and removal of\noutliers. Specifically, we consider the multicover bifiltration, Sheehy's\nsubdivision bifiltrations, and the degree bifiltrations. For the multicover and\nsubdivision bifiltrations, we get 1-Lipschitz stability results closely\nanalogous to the standard stability results for 1-parameter persistent\nhomology. Our results for the degree bifiltrations are weaker, but they are\ntight, in a sense. As an application of our theory, we prove a law of large\nnumbers for subdivision bifiltrations of random data.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 16:07:07 GMT"}, {"version": "v2", "created": "Sat, 20 Feb 2021 20:54:36 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Blumberg", "Andrew J.", ""], ["Lesnick", "Michael", ""]]}, {"id": "2010.09774", "submitter": "Nitin Agarwal", "authors": "Nitin Agarwal and M Gopi", "title": "GAMesh: Guided and Augmented Meshing for Deep Point Networks", "comments": "Accepted to 3DV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CG cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new meshing algorithm called guided and augmented meshing,\nGAMesh, which uses a mesh prior to generate a surface for the output points of\na point network. By projecting the output points onto this prior and\nsimplifying the resulting mesh, GAMesh ensures a surface with the same topology\nas the mesh prior but whose geometric fidelity is controlled by the point\nnetwork. This makes GAMesh independent of both the density and distribution of\nthe output points, a common artifact in traditional surface reconstruction\nalgorithms. We show that such a separation of geometry from topology can have\nseveral advantages especially in single-view shape prediction, fair evaluation\nof point networks and reconstructing surfaces for networks which output sparse\npoint clouds. We further show that by training point networks with GAMesh, we\ncan directly optimize the vertex positions to generate adaptive meshes with\narbitrary topologies.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 18:23:53 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Agarwal", "Nitin", ""], ["Gopi", "M", ""]]}, {"id": "2010.10454", "submitter": "Milad Bakhshizadeh", "authors": "Milad Bakhshizadeh, Ali Kamalinejad, Mina Latifi", "title": "A practical algorithm to calculate Cap Discrepancy", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS cs.LG cs.NA math.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uniform distribution of the points has been of interest to researchers for a\nlong time and has applications in different areas of Mathematics and Computer\nScience. One of the well-known measures to evaluate the uniformity of a given\ndistribution is Discrepancy, which assesses the difference between the Uniform\ndistribution and the empirical distribution given by putting mass points at the\npoints of the given set. While Discrepancy is very useful to measure\nuniformity, it is computationally challenging to be calculated accurately. We\nintroduce the concept of directed Discrepancy based on which we have developed\nan algorithm, called Directional Discrepancy, that can offer accurate\napproximation for the cap Discrepancy of a finite set distributed on the unit\nSphere, $\\mathbb{S}^2.$ We also analyze the time complexity of the Directional\nDiscrepancy algorithm precisely; and practically evaluate its capacity by\ncalculating the Cap Discrepancy of a specific distribution, Polar Coordinates,\nwhich aims to distribute points uniformly on the Sphere.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 17:11:26 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Bakhshizadeh", "Milad", ""], ["Kamalinejad", "Ali", ""], ["Latifi", "Mina", ""]]}, {"id": "2010.10726", "submitter": "Jesus Tordesillas Torres", "authors": "Jesus Tordesillas, Jonathan P. How", "title": "MINVO Basis: Finding Simplexes with Minimum Volume Enclosing Polynomial\n  Curves", "comments": "25 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.GR cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the problem of finding the smallest $n$-simplex enclosing\na given $n^{\\text{th}}$-degree polynomial curve. Although the Bernstein and\nB-Spline polynomial bases provide feasible solutions to this problem, the\nsimplexes obtained by these bases are not the smallest possible, which leads to\nundesirably conservative results in many applications. We first prove that the\npolynomial basis that solves this problem (MINVO basis) also solves for the\n$n^\\text{th}$-degree polynomial curve with largest convex hull enclosed in a\ngiven $n$-simplex. Then, we present a formulation that is \\emph{independent} of\nthe $n$-simplex or $n^{\\text{th}}$-degree polynomial curve given. By using\nSum-Of-Squares (SOS) programming, branch and bound, and moment relaxations, we\nobtain high-quality feasible solutions for any $n\\in\\mathbb{N}$ and prove\nnumerical global optimality for $n=1,2,3$. The results obtained for $n=3$ show\nthat, for any given $3^{\\text{rd}}$-degree polynomial curve, the MINVO basis is\nable to obtain an enclosing simplex whose volume is $2.36$ and $254.9$ times\nsmaller than the ones obtained by the Bernstein and B-Spline bases,\nrespectively. When $n=7$, these ratios increase to $902.7$ and\n$2.997\\cdot10^{21}$, respectively.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 02:35:23 GMT"}, {"version": "v2", "created": "Thu, 10 Dec 2020 23:34:02 GMT"}, {"version": "v3", "created": "Thu, 8 Apr 2021 22:35:57 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Tordesillas", "Jesus", ""], ["How", "Jonathan P.", ""]]}, {"id": "2010.10879", "submitter": "Bernd Sturmfels", "authors": "Taylor Brysiewicz, Claudia Fevola and Bernd Sturmfels", "title": "Tangent Quadrics in Real 3-Space", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AG cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine quadratic surfaces in 3-space that are tangent to nine given\nfigures. These figures can be points, lines, planes or quadrics. The numbers of\ntangent quadrics were determined by Hermann Schubert in 1879. We study the\nassociated systems of polynomial equations, also in the space of complete\nquadrics, and we solve them using certified numerical methods. Our aim is to\nshow that Schubert's problems are fully real.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 10:21:41 GMT"}, {"version": "v2", "created": "Wed, 19 May 2021 14:59:12 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Brysiewicz", "Taylor", ""], ["Fevola", "Claudia", ""], ["Sturmfels", "Bernd", ""]]}, {"id": "2010.11571", "submitter": "Matthew Katz", "authors": "Stav Ashur and Matthew J. Katz", "title": "A 4-Approximation of the $\\frac{2\\pi}{3}$-MST", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bounded-angle (minimum) spanning trees were first introduced in the context\nof wireless networks with directional antennas. They are reminiscent of\nbounded-degree spanning trees, which have received significant attention. Let\n$P = \\{p_1,\\ldots,p_n\\}$ be a set of $n$ points in the plane, let $\\Pi$ be the\npolygonal path $(p_1,\\ldots,p_n)$, and let $0 < \\alpha < 2\\pi$ be an angle. An\n$\\alpha$-spanning tree ($\\alpha$-ST) of $P$ is a spanning tree of the complete\nEuclidean graph over $P$, with the following property: For each vertex $p_i \\in\nP$, the (smallest) angle that is spanned by all the edges incident to $p_i$ is\nat most $\\alpha$. An $\\alpha$-minimum spanning tree ($\\alpha$-MST) is an\n$\\alpha$-ST of $P$ of minimum weight, where the weight of an $\\alpha$-ST is the\nsum of the lengths of its edges. In this paper, we consider the problem of\ncomputing an $\\alpha$-MST, for the important case where $\\alpha =\n\\frac{2\\pi}{3}$. We present a simple 4-approximation algorithm, thus improving\nupon the previous results of Aschner and Katz and Biniaz et al., who presented\nalgorithms with approximation ratios 6 and $\\frac{16}{3}$, respectively.\n  In order to obtain this result, we devise a simple $O(n)$-time algorithm for\nconstructing a $\\frac{2\\pi}{3}$-ST\\, ${\\cal T}$ of $P$, such that ${\\cal T}$'s\nweight is at most twice that of $\\Pi$ and, moreover, ${\\cal T}$ is a 3-hop\nspanner of $\\Pi$. This latter result is optimal in the sense that for any\n$\\varepsilon > 0$ there exists a polygonal path for which every\n$\\frac{2\\pi}{3}$-ST has weight greater than $2-\\varepsilon$ times the weight of\nthe path.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 10:04:14 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Ashur", "Stav", ""], ["Katz", "Matthew J.", ""]]}, {"id": "2010.12227", "submitter": "Abidha V P", "authors": "Abidha V P and Pradeesha Ashok", "title": "Geometric Separability using Orthogonal Objects", "comments": "15 pages, 6 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a bichromatic point set $P=\\textbf{R}$ $ \\cup$ $ \\textbf{B}$ of red and\nblue points, a separator is an object of a certain type that separates\n$\\textbf{R}$ and $\\textbf{B}$. We study the geometric separability problem when\nthe separator is a) rectangular annulus of fixed orientation b) rectangular\nannulus of arbitrary orientation c) square annulus of fixed orientation d)\northogonal convex polygon. In this paper, we give polynomial time algorithms to\nconstruct separators of each of the above type that also optimizes a given\nparameter. Specifically, we give an $O(n^3 \\log n)$ algorithm that computes\n(non-uniform width) separating rectangular annulus in arbitrary orientation, of\nminimum possible width. Further, when the orientation is fixed, we give an\n$O(n\\log n)$ algorithm that constructs a uniform width separating rectangular\nannulus of minimum possible width and an $O(n\\log^2 n)$ algorithm that\nconstructs a minimum width separating concentric square annulus. We also give\nan optimal algorithm that computes a separating orthogonal convex polygon with\nminimum number of edges, that runs in $O(n\\log n)$ time.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 08:21:58 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["P", "Abidha V", ""], ["Ashok", "Pradeesha", ""]]}, {"id": "2010.12455", "submitter": "Antonio Loquercio", "authors": "Francesco Milano, Antonio Loquercio, Antoni Rosinol, Davide\n  Scaramuzza, Luca Carlone", "title": "Primal-Dual Mesh Convolutional Neural Networks", "comments": "Accepted to the 34th Conference on Neural Information Processing\n  Systems (NeurIPS 2020), Vancouver, Canada. Code available at:\n  https://github.com/MIT-SPARK/PD-MeshNet", "journal-ref": "34th Conference on Neural Information Processing Systems (NeurIPS\n  2020)", "doi": null, "report-no": null, "categories": "cs.CV cs.CG cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works in geometric deep learning have introduced neural networks that\nallow performing inference tasks on three-dimensional geometric data by\ndefining convolution, and sometimes pooling, operations on triangle meshes.\nThese methods, however, either consider the input mesh as a graph, and do not\nexploit specific geometric properties of meshes for feature aggregation and\ndownsampling, or are specialized for meshes, but rely on a rigid definition of\nconvolution that does not properly capture the local topology of the mesh. We\npropose a method that combines the advantages of both types of approaches,\nwhile addressing their limitations: we extend a primal-dual framework drawn\nfrom the graph-neural-network literature to triangle meshes, and define\nconvolutions on two types of graphs constructed from an input mesh. Our method\ntakes features for both edges and faces of a 3D mesh as input and dynamically\naggregates them using an attention mechanism. At the same time, we introduce a\npooling operation with a precise geometric interpretation, that allows handling\nvariations in the mesh connectivity by clustering mesh faces in a task-driven\nfashion. We provide theoretical insights of our approach using tools from the\nmesh-simplification literature. In addition, we validate experimentally our\nmethod in the tasks of shape classification and shape segmentation, where we\nobtain comparable or superior performance to the state of the art.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 14:49:02 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Milano", "Francesco", ""], ["Loquercio", "Antonio", ""], ["Rosinol", "Antoni", ""], ["Scaramuzza", "Davide", ""], ["Carlone", "Luca", ""]]}, {"id": "2010.12928", "submitter": "Guido Br\\\"uckner", "authors": "Guido Br\\\"uckner and Vera Chekan", "title": "Drawing Two Posets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem of drawing two posets of the same ground set so\nthat one is drawn from left to right and the other one is drawn from the bottom\nup. The input to this problem is a directed graph $G = (V, E)$ and two sets $X,\nY$ with $X \\cup Y = E$, each of which can be interpreted as a partial order of\n$V$. The task is to find a planar drawing of $G$ such that each directed edge\nin $X$ is drawn as an $x$-monotone edge, and each directed edge in $Y$ is drawn\nas a $y$-monotone edge. Such a drawing is called an $xy$-planar drawing.\n  Testing whether a graph admits an $xy$-planar drawing is NP-complete in\ngeneral. We consider the case that the planar embedding of $G$ is fixed and the\nsubgraph of $G$ induced by the edges in $Y$ is a connected spanning subgraph of\n$G$ whose upward embedding is fixed. For this case we present a linear-time\nalgorithm that determines whether $G$ admits an $xy$-planar drawing and, if so,\nproduces an $xy$-planar polyline drawing with at most three bends per edge.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2020 16:38:37 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Br\u00fcckner", "Guido", ""], ["Chekan", "Vera", ""]]}, {"id": "2010.13136", "submitter": "Riccardo Marin", "authors": "Riccardo Marin, Marie-Julie Rakotosaona, Simone Melzi, Maks Ovsjanikov", "title": "Correspondence Learning via Linearly-invariant Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CG cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a fully differentiable pipeline for estimating\naccurate dense correspondences between 3D point clouds. The proposed pipeline\nis an extension and a generalization of the functional maps framework. However,\ninstead of using the Laplace-Beltrami eigenfunctions as done in virtually all\nprevious works in this domain, we demonstrate that learning the basis from data\ncan both improve robustness and lead to better accuracy in challenging\nsettings. We interpret the basis as a learned embedding into a higher\ndimensional space. Following the functional map paradigm the optimal\ntransformation in this embedding space must be linear and we propose a separate\narchitecture aimed at estimating the transformation by learning optimal\ndescriptor functions. This leads to the first end-to-end trainable functional\nmap-based correspondence approach in which both the basis and the descriptors\nare learned from data. Interestingly, we also observe that learning a\n\\emph{canonical} embedding leads to worse results, suggesting that leaving an\nextra linear degree of freedom to the embedding network gives it more\nrobustness, thereby also shedding light onto the success of previous methods.\nFinally, we demonstrate that our approach achieves state-of-the-art results in\nchallenging non-rigid 3D point cloud correspondence applications.\n", "versions": [{"version": "v1", "created": "Sun, 25 Oct 2020 15:31:53 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Marin", "Riccardo", ""], ["Rakotosaona", "Marie-Julie", ""], ["Melzi", "Simone", ""], ["Ovsjanikov", "Maks", ""]]}, {"id": "2010.13147", "submitter": "Nikolai Zolotykh", "authors": "S. O. Semenov and N. Yu. Zolotykh", "title": "How to Find the Convex Hull of All Integer Points in a Polyhedron?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a cut-based algorithm for finding all vertices and all facets of\nthe convex hull of all integer points of a polyhedron defined by a system of\nlinear inequalities. Our algorithm DDM Cuts is based on the Gomory cuts and the\ndynamic version of the double description method. We describe the computer\nimplementation of the algorithm and present the results of computational\nexperiments comparing our algorithm with a naive one.\n", "versions": [{"version": "v1", "created": "Sun, 25 Oct 2020 16:09:25 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Semenov", "S. O.", ""], ["Zolotykh", "N. Yu.", ""]]}, {"id": "2010.13473", "submitter": "C\\'edric Pilatte", "authors": "Damien Galant and C\\'edric Pilatte", "title": "A note on optimal degree-three spanners of the square lattice", "comments": "6 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this short note, we prove that the degree-three dilation of the square\nlattice $\\mathbb{Z}^2$ is $1+\\sqrt{2}$. This disproves a conjecture of\nDumitrescu and Ghosh. We give a computer-assisted proof of a local-global\nproperty for the uncountable set of geometric graphs achieving the optimal\ndilation.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 10:30:39 GMT"}, {"version": "v2", "created": "Tue, 27 Oct 2020 09:17:11 GMT"}, {"version": "v3", "created": "Sun, 8 Nov 2020 15:48:12 GMT"}, {"version": "v4", "created": "Sat, 30 Jan 2021 14:26:16 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Galant", "Damien", ""], ["Pilatte", "C\u00e9dric", ""]]}, {"id": "2010.14316", "submitter": "Owen Rouille", "authors": "Cl\\'ement Maria and Owen Rouill\\'e", "title": "Computation of Large Asymptotics of 3-Manifold Quantum Invariants", "comments": "Proceedings of ALENEX21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG math.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum topological invariants have played an important role in computational\ntopology, and they are at the heart of major modern mathematical conjectures.\nIn this article, we study the experimental problem of computing large $r$\nvalues of Turaev-Viro invariants $\\mathrm{TV}_r$. We base our approach on an\noptimized backtracking algorithm, consisting of enumerating combinatorial data\non a triangulation of a 3-manifold. We design an easily computable parameter to\nestimate the complexity of the enumeration space, based on lattice point\ncounting in polytopes, and show experimentally its accuracy. We apply this\nparameter to a preprocessing strategy on the triangulation, and combine it with\nmulti-precision arithmetics in order to compute the Turaev-Viro invariants. We\nfinally study the improvements brought by these optimizations compared to\nstate-of-the-art implementations, and verify experimentally Chen and Yang's\nvolume conjecture on a census of closed 3-manifolds.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 14:24:25 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Maria", "Cl\u00e9ment", ""], ["Rouill\u00e9", "Owen", ""]]}, {"id": "2010.14338", "submitter": "Lukas N\\\"olke", "authors": "Antonios Antoniadis, Margarita Capretto, Parinya Chalermsook,\n  Christoph Damerius, Peter Kling, Lukas N\\\"olke, Nidia Obscura, Joachim\n  Spoerhase", "title": "On Minimum Generalized Manhattan Connections", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider minimum-cardinality Manhattan connected sets with arbitrary\ndemands: Given a collection of points $P$ in the plane, together with a subset\nof pairs of points in $P$ (which we call demands), find a minimum-cardinality\nsuperset of $P$ such that every demand pair is connected by a path whose length\nis the $\\ell_1$-distance of the pair. This problem is a variant of three\nwell-studied problems that have arisen in computational geometry, data\nstructures, and network design: (i) It is a node-cost variant of the classical\nManhattan network problem, (ii) it is an extension of the binary search tree\nproblem to arbitrary demands, and (iii) it is a special case of the directed\nSteiner forest problem. Since the problem inherits basic structural properties\nfrom the context of binary search trees, an $O(\\log n)$-approximation is\ntrivial. We show that the problem is NP-hard and present an $O(\\sqrt{\\log\nn})$-approximation algorithm. Moreover, we provide an $O(\\log\\log\nn)$-approximation algorithm for complete bipartite demands as well as improved\nresults for unit-disk demands and several generalizations. Our results\ncrucially rely on a new lower bound on the optimal cost that could potentially\nbe useful in the context of BSTs.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 14:54:13 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Antoniadis", "Antonios", ""], ["Capretto", "Margarita", ""], ["Chalermsook", "Parinya", ""], ["Damerius", "Christoph", ""], ["Kling", "Peter", ""], ["N\u00f6lke", "Lukas", ""], ["Obscura", "Nidia", ""], ["Spoerhase", "Joachim", ""]]}, {"id": "2010.14824", "submitter": "Namwoo Kang", "authors": "Soyoung Yoo, Namwoo Kang", "title": "Explainable Artificial Intelligence for Manufacturing Cost Estimation\n  and Machining Feature Visualization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Studies on manufacturing cost prediction based on deep learning have begun in\nrecent years, but the cost prediction rationale cannot be explained because the\nmodels are still used as a black box. This study aims to propose a\nmanufacturing cost prediction process for 3D computer-aided design (CAD) models\nusing explainable artificial intelligence. The proposed process can visualize\nthe machining features of the 3D CAD model that are influencing the increase in\nmanufacturing costs. The proposed process consists of (1) data collection and\npre-processing, (2) 3D deep learning architecture exploration, and (3)\nvisualization to explain the prediction results. The proposed deep learning\nmodel shows high predictability of manufacturing cost for the computer\nnumerical control (CNC) machined parts. In particular, using 3D\ngradient-weighted class activation mapping proves that the proposed model not\nonly can detect the CNC machining features but also can differentiate the\nmachining difficulty for the same feature. Using the proposed process, we can\nprovide a design guidance to engineering designers in reducing manufacturing\ncosts during the conceptual design phase. We can also provide real-time\nquotations and redesign proposals to online manufacturing platform customers.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 08:58:09 GMT"}, {"version": "v2", "created": "Sun, 13 Jun 2021 05:31:01 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Yoo", "Soyoung", ""], ["Kang", "Namwoo", ""]]}, {"id": "2010.15221", "submitter": "Emil Saucan", "authors": "Vladislav Barkanass, J\\\"urgen Jost and Emil Saucan", "title": "Geometric Sampling of Networks", "comments": "50 pages, 16 figures Corrections made, experiments and further\n  material added", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.DG cs.CG cs.SI math.MG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Motivated by the methods and results of manifold sampling based on Ricci\ncurvature, we propose a similar approach for networks. To this end we make\nappeal to three types of discrete curvature, namely the graph Forman-, full\nForman- and Haantjes-Ricci curvatures for edge-based and node-based sampling.\nWe present the results of experiments on real life networks, as well as for\nsquare grids arising in Image Processing. Moreover, we consider fitting Ricci\nflows and we employ them for the detection of networks' backbone. We also\ndevelop embedding kernels related to the Forman-Ricci curvatures and employ\nthem for the detection of the coarse structure of networks, as well as for\nnetwork visualization with applications to SVM. The relation between the Ricci\ncurvature of the original manifold and that of a Ricci curvature driven\ndiscretization is also studied.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 20:38:37 GMT"}, {"version": "v2", "created": "Wed, 3 Mar 2021 20:09:13 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Barkanass", "Vladislav", ""], ["Jost", "J\u00fcrgen", ""], ["Saucan", "Emil", ""]]}, {"id": "2010.15399", "submitter": "Gary Pui-Tung Choi", "authors": "Gary P. T. Choi, Yechen Liu, Lok Ming Lui", "title": "Free-boundary conformal parameterization of point clouds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.GR cs.NA math.CV math.DG math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advancement in 3D scanning technology, there has been a surge of\ninterest in the use of point clouds in science and engineering. To facilitate\nthe computations and analyses of point clouds, prior works have considered\nparameterizing them onto some simple planar domains with a fixed boundary shape\nsuch as a unit circle or a rectangle. However, the geometry of the fixed shape\nmay lead to some undesirable distortion in the parameterization. It is\ntherefore more natural to consider free-boundary conformal parameterizations of\npoint clouds, which minimize the local geometric distortion of the mapping\nwithout constraining the overall shape. In this work, we develop a\nfree-boundary conformal parameterization method for disk-type point clouds,\nwhich involves a novel approximation scheme of the point cloud Laplacian with\naccumulated cotangent weights together with a special treatment at the boundary\npoints. With the aid of the free-boundary conformal parameterization,\nhigh-quality point cloud meshing can be easily achieved. Furthermore, we show\nthat using the idea of conformal welding in complex analysis, the point cloud\nconformal parameterization can be computed in a divide-and-conquer manner.\nExperimental results are presented to demonstrate the effectiveness of the\nproposed method.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2020 07:48:58 GMT"}, {"version": "v2", "created": "Fri, 25 Jun 2021 18:49:29 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Choi", "Gary P. T.", ""], ["Liu", "Yechen", ""], ["Lui", "Lok Ming", ""]]}, {"id": "2010.15833", "submitter": "Arthur Bikeev Igorevich", "authors": "Arthur Bikeev Igorevich", "title": "The realizability of discs with ribbons on a M\\\"obius strip", "comments": "in Russian", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CG cs.DM math.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An hieroglyph on n letters is a cyclic sequence of the letters 1,2, . . . , n\nof length 2n such that each letter appears in the sequence twice.Take an\nhieroglyph H. Take a convex polygon with 2n sides. Put the letters in the\nsequence of letters of the hieroglyph on the sides of the convexpolygon in the\nsame order. For each letter i glue the ends of a ribbon to thepair of sides\ncorresponding to the letter i. Call the resulting surface a disk with ribbons\ncorresponding to the hieroglyph H. An hieroglyph H is weakly realizable on the\nM\\\"obius strip if some disk with ribbons corresponding to H can be cut out of\nthe M\\\"obius strip. We give a criterion for weak realizability, which gives a\nquadratic (in the number of letters) algorithm. Our criterion is based on the\nMohar criterion for realizability of a disk with ribbons in the M\\\"obius strip.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2020 18:24:47 GMT"}, {"version": "v2", "created": "Tue, 22 Dec 2020 14:44:35 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Igorevich", "Arthur Bikeev", ""]]}, {"id": "2010.16381", "submitter": "Alexis Macq", "authors": "Alexis Macq, Maxence Reberol, Fran\\c{c}ois Henrotte, Pierre-Alexandre\n  Beaufort, Alexandre Chemin, Jean-Fran\\c{c}ois Remacle, Jean Van Schaftingen", "title": "Ginzburg-Landau energy and placement of singularities in generated cross\n  fields", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.CG cs.NA", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Cross field generation is often used as the basis for the construction of\nblock-structured quadrangular meshes, and the field singularities have a key\nimpact on the structure of the resulting meshes. In this paper, we extend\nGinzburg-Landau cross field generation methods with a new formulation that\nallows a user to impose inner singularities. The cross field is computed via\nthe optimization of a linear objective function with localized quadratic\nconstraints. This method consists in fixing singularities in small holes\ndrilled in the computational domain with specific degree conditions on their\nboundaries, which leads to non-singular cross fields on the drilled domain. We\nalso propose a way to calculate the Ginzburg-Landau energy of these cross\nfields on the perforated domain by solving a Neumann linear problem. This\nenergy converges to the energy of the Ginzburg-Landau functional as epsilon and\nthe radius of the holes tend to zero. To obtain insights concerning the sum of\nthe inner singularity degrees, we give: (i) an extension of the Ginzburg-Landau\nenergy to the piecewise smooth domain allowing to identify the positions and\ndegrees of the boundary singularities, and (ii) an interpretation of the\nPoincar\\'e-Hopf theorem focusing on internal singularities.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 17:21:57 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Macq", "Alexis", ""], ["Reberol", "Maxence", ""], ["Henrotte", "Fran\u00e7ois", ""], ["Beaufort", "Pierre-Alexandre", ""], ["Chemin", "Alexandre", ""], ["Remacle", "Jean-Fran\u00e7ois", ""], ["Van Schaftingen", "Jean", ""]]}]