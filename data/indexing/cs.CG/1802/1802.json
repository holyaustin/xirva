[{"id": "1802.00533", "submitter": "Benjamin Schweinhart", "authors": "Benjamin Schweinhart", "title": "Persistent Homology and the Upper Box Dimension", "comments": "39 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.MG cs.CG math.AT math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a fractal dimension for a metric space defined in terms of the\npersistent homology of extremal subsets of that space. We exhibit hypotheses\nunder which this dimension is comparable to the upper box dimension; in\nparticular, the dimensions coincide for subsets of $\\mathbb{R}^2$ whose upper\nbox dimension exceeds $1.5.$ These results are related to extremal questions\nabout the number of persistent homology intervals of a set of $n$ points in a\nmetric space.\n", "versions": [{"version": "v1", "created": "Fri, 2 Feb 2018 01:44:13 GMT"}, {"version": "v2", "created": "Sat, 17 Feb 2018 00:33:53 GMT"}, {"version": "v3", "created": "Fri, 23 Feb 2018 01:47:18 GMT"}, {"version": "v4", "created": "Thu, 8 Mar 2018 22:50:58 GMT"}, {"version": "v5", "created": "Thu, 6 Sep 2018 00:12:42 GMT"}, {"version": "v6", "created": "Fri, 1 Mar 2019 04:29:04 GMT"}, {"version": "v7", "created": "Mon, 29 Jul 2019 23:05:45 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Schweinhart", "Benjamin", ""]]}, {"id": "1802.01152", "submitter": "Andrew Blumberg", "authors": "Andrew J. Blumberg, Prithwish Bhaumik, Stephen G. Walker", "title": "Testing to distinguish measures on metric spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.CG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of distinguishing between two distributions on a metric\nspace; i.e., given metric measure spaces $({\\mathbb X}, d, \\mu_1)$ and\n$({\\mathbb X}, d, \\mu_2)$, we are interested in the problem of determining from\nfinite data whether or not $\\mu_1$ is $\\mu_2$. The key is to use pairwise\ndistances between observations and, employing a reconstruction theorem of\nGromov, we can perform such a test using a two sample Kolmogorov--Smirnov test.\nA real analysis using phylogenetic trees and flu data is presented.\n", "versions": [{"version": "v1", "created": "Sun, 4 Feb 2018 16:25:53 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["Blumberg", "Andrew J.", ""], ["Bhaumik", "Prithwish", ""], ["Walker", "Stephen G.", ""]]}, {"id": "1802.01515", "submitter": "Bahman Kalantari", "authors": "Pranjal Awasthi and Bahman Kalantari and Yikai Zhang", "title": "Robust Vertex Enumeration for Convex Hulls in High Dimensions", "comments": "34 pages, 12 figures, 8 tables, A conference version to appear in the\n  proceedings of AISTAT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computation of the vertices of the convex hull of a set $S$ of $n$ points in\n$\\mathbb{R} ^m$ is a fundamental problem in computational geometry,\noptimization, machine learning and more. We present \"All Vertex Triangle\nAlgorithm\" (AVTA), a robust and efficient algorithm for computing the subset\n$\\overline S$ of all $K$ vertices of $conv(S)$, the convex hull of $S$. If\n$\\Gamma_*$ is the minimum of the distances from each vertex to the convex hull\nof the remaining vertices, given any $\\gamma \\leq \\gamma_* = \\Gamma_*/R$, $R$\nthe diameter of $S$, $AVTA$ computes $\\overline S$ in $O(nK(m+ \\gamma^{-2}))$\noperations. If $\\gamma_*$ is unknown but $K$ is known, AVTA computes $\\overline\nS$ in $O(nK(m+ \\gamma_*^{-2})) \\log(\\gamma_*^{-1})$ operations. More generally,\ngiven $t \\in (0,1)$, AVTA computes a subset $\\overline S^t$ of $\\overline S$ in\n$O(n |\\overline S^t|(m+ t^{-2}))$ operations, where the distance between any $p\n\\in conv(S)$ to $conv(\\overline S^t)$ is at most $t R$. Next we consider AVTA\nwhere input is $S_\\varepsilon$, an $\\varepsilon$ perturbation of $S$. Assuming\na bound on $\\varepsilon$ in terms of the minimum of the distances of vertices\nof $conv(S)$ to the convex hull of the remaining point of $S$, we derive\nanalogous complexity bounds for computing $\\overline S_\\varepsilon$. We also\nanalyze AVTA under random projections of $S$ or $S_\\varepsilon$. Finally, via\nAVTA we design new practical algorithms for two popular machine learning\nproblems: topic modeling and non-negative matrix factorization. For topic\nmodels AVTA leads to significantly better reconstruction of the topic-word\nmatrix than state of the art approaches~\\cite{arora2013practical,\nbansal2014provable}. For non-negative matrix AVTA is competitive with existing\nmethods~\\cite{arora2012computing}. Empirically AVTA is robust and can handle\nlarger amounts of noise than existing methods.\n", "versions": [{"version": "v1", "created": "Mon, 5 Feb 2018 17:13:16 GMT"}, {"version": "v2", "created": "Mon, 24 Sep 2018 18:52:43 GMT"}], "update_date": "2018-09-26", "authors_parsed": [["Awasthi", "Pranjal", ""], ["Kalantari", "Bahman", ""], ["Zhang", "Yikai", ""]]}, {"id": "1802.01621", "submitter": "Joseph O'Rourke", "authors": "Joseph O'Rourke", "title": "Un-unzippable Convex Caps", "comments": "14 pages, 14 figures, 10 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An unzipping of a polyhedron P is a cut-path through its vertices that\nunfolds P to a non-overlapping shape in the plane. It is an open problem to\ndecide if every convex P has an unzipping. Here we show that there are nearly\nflat convex caps that have no unzipping. A convex cap is a \"top\" portion of a\nconvex polyhedron; it has a boundary, i.e., it is not closed by a base.\n", "versions": [{"version": "v1", "created": "Mon, 5 Feb 2018 19:48:19 GMT"}], "update_date": "2018-02-07", "authors_parsed": [["O'Rourke", "Joseph", ""]]}, {"id": "1802.01698", "submitter": "Jingwei Huang", "authors": "Jingwei Huang, Hao Su, Leonidas Guibas", "title": "Robust Watertight Manifold Surface Generation Method for ShapeNet Models", "comments": "Algorithm for generating manifolds of ShapeNet Models", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe a robust algorithm for 2-Manifold generation of\nvarious kinds of ShapeNet Models. The input of our pipeline is a triangle mesh,\nwith a set of vertices and triangular faces. The output of our pipeline is a\n2-Manifold with vertices roughly uniformly distributed on the geometry surface.\nOur algorithm uses an octree to represent the original mesh, and construct the\nsurface by isosurface extraction. Finally, we project the vertices to the\noriginal mesh to achieve high precision. As a result, our method can be adopted\nefficiently to all ShapeNet models with the guarantee of correct 2-Manifold\ntopology.\n", "versions": [{"version": "v1", "created": "Mon, 5 Feb 2018 21:31:21 GMT"}], "update_date": "2018-02-07", "authors_parsed": [["Huang", "Jingwei", ""], ["Su", "Hao", ""], ["Guibas", "Leonidas", ""]]}, {"id": "1802.01751", "submitter": "Wai Ming Tai", "authors": "Jeff M. Phillips, Wai Ming Tai", "title": "Near-Optimal Coresets of Kernel Density Estimates", "comments": "This paper is combined with arXiv:1710.04325", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We construct near-optimal coresets for kernel density estimates for points in\n$\\mathbb{R}^d$ when the kernel is positive definite. Specifically we show a\npolynomial time construction for a coreset of size $O(\\sqrt{d}/\\varepsilon\\cdot\n\\sqrt{\\log 1/\\varepsilon} )$, and we show a near-matching lower bound of size\n$\\Omega(\\min\\{\\sqrt{d}/\\varepsilon, 1/\\varepsilon^2\\})$. When $d\\geq\n1/\\varepsilon^2$, it is known that the size of coreset can be\n$O(1/\\varepsilon^2)$. The upper bound is a polynomial-in-$(1/\\varepsilon)$\nimprovement when $d \\in [3,1/\\varepsilon^2)$ and the lower bound is the first\nknown lower bound to depend on $d$ for this problem. Moreover, the upper bound\nrestriction that the kernel is positive definite is significant in that it\napplies to a wide-variety of kernels, specifically those most important for\nmachine learning. This includes kernels for information distances and the sinc\nkernel which can be negative.\n", "versions": [{"version": "v1", "created": "Tue, 6 Feb 2018 01:06:47 GMT"}, {"version": "v2", "created": "Wed, 14 Mar 2018 17:04:17 GMT"}, {"version": "v3", "created": "Thu, 21 Jun 2018 13:34:29 GMT"}, {"version": "v4", "created": "Fri, 29 Mar 2019 00:45:09 GMT"}, {"version": "v5", "created": "Thu, 11 Apr 2019 23:06:34 GMT"}], "update_date": "2019-04-15", "authors_parsed": [["Phillips", "Jeff M.", ""], ["Tai", "Wai Ming", ""]]}, {"id": "1802.02664", "submitter": "Valentin Khrulkov", "authors": "Valentin Khrulkov and Ivan Oseledets", "title": "Geometry Score: A Method For Comparing Generative Adversarial Networks", "comments": "ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the biggest challenges in the research of generative adversarial\nnetworks (GANs) is assessing the quality of generated samples and detecting\nvarious levels of mode collapse. In this work, we construct a novel measure of\nperformance of a GAN by comparing geometrical properties of the underlying data\nmanifold and the generated one, which provides both qualitative and\nquantitative means for evaluation. Our algorithm can be applied to datasets of\nan arbitrary nature and is not limited to visual data. We test the obtained\nmetric on various real-life models and datasets and demonstrate that our method\nprovides new insights into properties of GANs.\n", "versions": [{"version": "v1", "created": "Wed, 7 Feb 2018 22:44:37 GMT"}, {"version": "v2", "created": "Fri, 9 Feb 2018 21:00:36 GMT"}, {"version": "v3", "created": "Sat, 9 Jun 2018 14:44:41 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Khrulkov", "Valentin", ""], ["Oseledets", "Ivan", ""]]}, {"id": "1802.02682", "submitter": "Braxton Osting", "authors": "Dong Wang and Braxton Osting", "title": "A diffusion generated method for computing Dirichlet partitions", "comments": "24 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Dirichlet $k$-partition of a closed $d$-dimensional surface is a collection\nof $k$ pairwise disjoint open subsets such that the sum of their first\nLaplace-Beltrami-Dirichlet eigenvalues is minimal. In this paper, we develop a\nsimple and efficient diffusion generated method to compute Dirichlet\n$k$-partitions for $d$-dimensional flat tori and spheres. For the $2d$ flat\ntorus, for most values of $k=3$-9,11,12,15,16, and 20, we obtain hexagonal\nhoneycombs. For the $3d$ flat torus and $k=2,4,8,16$, we obtain the rhombic\ndodecahedral honeycomb, the Weaire-Phelan honeycomb, and Kelvin's tessellation\nby truncated octahedra. For the $4d$ flat torus, for $k=4$, we obtain a\nconstant extension of the rhombic dodecahedral honeycomb along the fourth\ndirection and for $k=8$, we obtain a 24-cell honeycomb. For the $2d$ sphere, we\nalso compute Dirichlet partitions for $k=3$-7,9,10,12,14,20. Our computational\nresults agree with previous studies when a comparison is available. As far as\nwe are aware, these are the first published results for Dirichlet partitions of\nthe $4d$ flat torus.\n", "versions": [{"version": "v1", "created": "Thu, 8 Feb 2018 01:06:57 GMT"}], "update_date": "2018-02-09", "authors_parsed": [["Wang", "Dong", ""], ["Osting", "Braxton", ""]]}, {"id": "1802.02731", "submitter": "Julien Tierny", "authors": "Maxime Soler and Melanie Plainchault and Bruno Conche and Julien\n  Tierny", "title": "Topologically Controlled Lossy Compression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CG cs.CV cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new algorithm for the lossy compression of scalar data\ndefined on 2D or 3D regular grids, with topological control. Certain techniques\nallow users to control the pointwise error induced by the compression. However,\nin many scenarios it is desirable to control in a similar way the preservation\nof higher-level notions, such as topological features , in order to provide\nguarantees on the outcome of post-hoc data analyses. This paper presents the\nfirst compression technique for scalar data which supports a strictly\ncontrolled loss of topological features. It provides users with specific\nguarantees both on the preservation of the important features and on the size\nof the smaller features destroyed during compression. In particular, we present\na simple compression strategy based on a topologically adaptive quantization of\nthe range. Our algorithm provides strong guarantees on the bottleneck distance\nbetween persistence diagrams of the input and decompressed data, specifically\nthose associated with extrema. A simple extension of our strategy additionally\nenables a control on the pointwise error. We also show how to combine our\napproach with state-of-the-art compressors, to further improve the geometrical\nreconstruction. Extensive experiments, for comparable compression rates,\ndemonstrate the superiority of our algorithm in terms of the preservation of\ntopological features. We show the utility of our approach by illustrating the\ncompatibility between the output of post-hoc topological data analysis\npipelines, executed on the input and decompressed data, for simulated or\nacquired data sets. We also provide a lightweight VTK-based C++ implementation\nof our approach for reproduction purposes.\n", "versions": [{"version": "v1", "created": "Thu, 8 Feb 2018 07:35:43 GMT"}], "update_date": "2018-02-09", "authors_parsed": [["Soler", "Maxime", ""], ["Plainchault", "Melanie", ""], ["Conche", "Bruno", ""], ["Tierny", "Julien", ""]]}, {"id": "1802.03415", "submitter": "Maria Saumell", "authors": "Ruy Fabila-Monroy and Alfredo Garc\\'ia and Ferran Hurtado and Rafel\n  Jaume and Pablo P\\'erez-Lantero and Maria Saumell and Rodrigo I. Silveira and\n  Javier Tejel and Jorge Urrutia", "title": "Colored ray configurations", "comments": null, "journal-ref": "Computational Geometry: Theory and Applications (68):292-308, 2018", "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the cyclic color sequences induced at infinity by colored rays with\napices being a given balanced finite bichromatic point set. We first study the\ncase in which the rays are required to be pairwise disjoint. We derive a lower\nbound on the number of color sequences that can be realized from any such fixed\npoint set and examine color sequences that can be realized regardless of the\npoint set, exhibiting negative examples as well. We also provide a tight upper\nbound on the number of configurations that can be realized from a point set,\nand point sets for which there are asymptotically less configurations than that\nnumber. In addition, we provide algorithms to decide whether a color sequence\nis realizable from a given point set in a line or in general position. We\naddress afterwards the variant of the problem where the rays are allowed to\nintersect. We prove that for some configurations and point sets, the number of\nray crossings must be $\\Theta(n^2)$ and study then configurations that can be\nrealized by rays that pairwise cross. We show that there are point sets for\nwhich the number of configurations that can be realized by pairwise-crossing\nrays is asymptotically smaller than the number of configurations realizable by\npairwise-disjoint rays. We provide also point sets from which any configuration\ncan be realized by pairwise-crossing rays and show that there is no\nconfiguration that can be realized by pairwise-crossing rays from every point\nset.\n", "versions": [{"version": "v1", "created": "Fri, 9 Feb 2018 19:09:52 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Fabila-Monroy", "Ruy", ""], ["Garc\u00eda", "Alfredo", ""], ["Hurtado", "Ferran", ""], ["Jaume", "Rafel", ""], ["P\u00e9rez-Lantero", "Pablo", ""], ["Saumell", "Maria", ""], ["Silveira", "Rodrigo I.", ""], ["Tejel", "Javier", ""], ["Urrutia", "Jorge", ""]]}, {"id": "1802.03426", "submitter": "Leland McInnes", "authors": "Leland McInnes, John Healy and James Melville", "title": "UMAP: Uniform Manifold Approximation and Projection for Dimension\n  Reduction", "comments": "Reference implementation available at http://github.com/lmcinnes/umap", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CG cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  UMAP (Uniform Manifold Approximation and Projection) is a novel manifold\nlearning technique for dimension reduction. UMAP is constructed from a\ntheoretical framework based in Riemannian geometry and algebraic topology. The\nresult is a practical scalable algorithm that applies to real world data. The\nUMAP algorithm is competitive with t-SNE for visualization quality, and\narguably preserves more of the global structure with superior run time\nperformance. Furthermore, UMAP has no computational restrictions on embedding\ndimension, making it viable as a general purpose dimension reduction technique\nfor machine learning.\n", "versions": [{"version": "v1", "created": "Fri, 9 Feb 2018 19:39:33 GMT"}, {"version": "v2", "created": "Thu, 6 Dec 2018 18:54:07 GMT"}, {"version": "v3", "created": "Fri, 18 Sep 2020 01:56:41 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["McInnes", "Leland", ""], ["Healy", "John", ""], ["Melville", "James", ""]]}, {"id": "1802.03649", "submitter": "Jakub Marecek", "authors": "Jakub Marecek, Stathis Maroulis, Vana Kalogeraki, Dimitrios Gunopulos", "title": "Low-Rank Methods in Event Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monitoring of streamed data to detect abnormal behavior (variously known as\nevent detection, anomaly detection, change detection, or outlier detection)\nunderlies many applications of the Internet of Things. Here, we propose a novel\nframework for event detection in high-dimensional data across a variety of\nsources, with asynchronous sampling and missing data, to instantly predict\nabnormal behavior. We assume that normal observations come from a low-rank\nsubspace, prior to being corrupted by a uniformly distributed noise.\nCorrespondingly, we aim to recover a representation of the subspace and perform\nevent detection by running point-to-subspace distance queries on this subspace\nfor incoming data. In particular, we use a variant of low-rank factorisation,\nwhich considers interval uncertainty sets around \"known entries\", on a suitable\nflattening of the input data to obtain a low-rank model. On-line, we compute\nthe distance of incoming data to the low-rank \"normal\" subspace and update the\nsubspace to keep it consistent with the seasonal changes present. For the\ndistance computation, we present an algorithm with a one-sided error bounded by\na function of the number of coordinates employed. In our experimental\nevaluation, we have tested the ability of the proposed algorithm to identify\nsamples of abnormal behavior in induction-loop data from Dublin, Ireland.\n", "versions": [{"version": "v1", "created": "Sat, 10 Feb 2018 20:32:28 GMT"}, {"version": "v2", "created": "Fri, 5 Mar 2021 12:07:24 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Marecek", "Jakub", ""], ["Maroulis", "Stathis", ""], ["Kalogeraki", "Vana", ""], ["Gunopulos", "Dimitrios", ""]]}, {"id": "1802.03730", "submitter": "Pintu Chauhan", "authors": "Pintu Chauhan, Manjish Pal, Napendra Solanki", "title": "Rederiving the Upper Bound for Halving Edges using Cardano's Formula", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we rederive an old upper bound on the number of halving edges\npresent in the halving graph of an arbitrary set of $n$ points in 2-dimensions\nwhich are placed in general position. We provide a different analysis of an\nidentity discovered by Andrejak et al, to rederive this upper bound of\n$O(n^{4/3})$. In the original paper of Andrejak et al. the proof is based on a\nnaive analysis whereas in this paper we obtain the same upper bound by\ntightening the analysis thereby opening a new door to derive these upper bounds\nusing the identity. Our analysis is based on a result of Cardano for finding\nthe roots of a cubic equation. We believe that our technique has the potential\nto derive improved bounds on the number of halving edges.\n", "versions": [{"version": "v1", "created": "Sun, 11 Feb 2018 12:15:09 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Chauhan", "Pintu", ""], ["Pal", "Manjish", ""], ["Solanki", "Napendra", ""]]}, {"id": "1802.04443", "submitter": "William Guss", "authors": "William H. Guss, Ruslan Salakhutdinov", "title": "On Characterizing the Capacity of Neural Networks using Algebraic\n  Topology", "comments": "13 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CG cs.NE math.AT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The learnability of different neural architectures can be characterized\ndirectly by computable measures of data complexity. In this paper, we reframe\nthe problem of architecture selection as understanding how data determines the\nmost expressive and generalizable architectures suited to that data, beyond\ninductive bias. After suggesting algebraic topology as a measure for data\ncomplexity, we show that the power of a network to express the topological\ncomplexity of a dataset in its decision region is a strictly limiting factor in\nits ability to generalize. We then provide the first empirical characterization\nof the topological capacity of neural networks. Our empirical analysis shows\nthat at every level of dataset complexity, neural networks exhibit topological\nphase transitions. This observation allowed us to connect existing theory to\nempirically driven conjectures on the choice of architectures for\nfully-connected neural networks.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 02:32:10 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Guss", "William H.", ""], ["Salakhutdinov", "Ruslan", ""]]}, {"id": "1802.04572", "submitter": "Riccardo Mengoni", "authors": "Alessandra Di Pierro, Stefano Mancini, Laleh Memarzadeh, Riccardo\n  Mengoni", "title": "Homological analysis of multi-qubit entanglement", "comments": null, "journal-ref": "EPL, 123 3 (2018) 30006", "doi": "10.1209/0295-5075/123/30006", "report-no": null, "categories": "quant-ph cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the usage of persistent homologies to characterize multipartite\nentanglement. On a multi-qubit data set we introduce metric-like measures\ndefined only in terms of bipartite entanglement and then we derive barcodes. We\nshow that they are able to provide a good classification of entangled states,\nat least for a small number of qubit.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 11:35:32 GMT"}, {"version": "v2", "created": "Thu, 8 Mar 2018 16:00:55 GMT"}, {"version": "v3", "created": "Mon, 27 Aug 2018 18:17:01 GMT"}], "update_date": "2018-09-26", "authors_parsed": [["Di Pierro", "Alessandra", ""], ["Mancini", "Stefano", ""], ["Memarzadeh", "Laleh", ""], ["Mengoni", "Riccardo", ""]]}, {"id": "1802.04968", "submitter": "Bala Krishnamoorthy", "authors": "Yunfeng Hu and Matthew Hudelson and Bala Krishnamoorthy and Altansuren\n  Tumurbaatar and Kevin R. Vixie", "title": "Median Shapes", "comments": "Several minor edits; Step 2 in Proof of Theorem 4.1.3 rewritten", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.DG cs.CG math.AT math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce and begin to explore the mean and median of finite sets of\nshapes represented as integral currents. The median can be computed efficiently\nin practice, and we focus most of our theoretical and computational attention\non medians. We consider questions on the existence and regularity of medians.\nWhile the median might not exist in all cases, we show that a mass-regularized\nmedian is guaranteed to exist. When the input shapes are modeled by integral\ncurrents with shared boundaries in codimension $1$, we show that the median is\nguaranteed to exist, and is contained in the \\emph{envelope} of the input\ncurrents. On the other hand, we show that medians can be \\emph{wild} in this\nsetting, and smooth inputs can generate non-smooth medians.\n  For higher codimensions, we show that \\emph{books} are minimizing for a\nfinite set of $1$-currents in $\\Bbb{R}^3$ with shared boundaries. As part of\nthis proof, we present a new result in graph theory---that \\emph{cozy} graphs\nare \\emph{comfortable}---which should be of independent interest. Further, we\nshow that regular points on the median have book-like tangent cones in this\ncase.\n  From the point of view of computation, we study the median shape in the\nsettings of a finite simplicial complex. When the input shapes are represented\nby chains of the simplicial complex, we show that the problem of finding the\nmedian shape can be formulated as an integer linear program. This optimization\nproblem can be solved as a linear program in practice, thus allowing one to\ncompute median shapes efficiently.\n  We provide open source code implementing our methods, which could also be\nused by anyone to experiment with ideas of their own. The software could be\naccessed at https://github.com/tbtraltaa/medianshape.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 06:55:44 GMT"}, {"version": "v2", "created": "Sun, 9 Dec 2018 17:21:37 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Hu", "Yunfeng", ""], ["Hudelson", "Matthew", ""], ["Krishnamoorthy", "Bala", ""], ["Tumurbaatar", "Altansuren", ""], ["Vixie", "Kevin R.", ""]]}, {"id": "1802.05873", "submitter": "Shunhao Oh", "authors": "Shunhao Oh and Seth Gilbert", "title": "A Reallocation Algorithm for Online Split Packing of Circles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Split Packing algorithm \\cite{splitpacking_ws, splitpackingsoda,\nsplitpacking} is an offline algorithm that packs a set of circles into\ntriangles and squares up to critical density. In this paper, we develop an\nonline alternative to Split Packing to handle an online sequence of insertions\nand deletions, where the algorithm is allowed to reallocate circles into new\npositions at a cost proportional to their areas. The algorithm can be used to\npack circles into squares and right angled triangles. If only insertions are\nconsidered, our algorithm is also able to pack to critical density, with an\namortised reallocation cost of $O(c\\log \\frac{1}{c})$ for squares, and\n$O(c(1+s^2)\\log_{1+s^2}\\frac{1}{c})$ for right angled triangles, where $s$ is\nthe ratio of the lengths of the second shortest side to the shortest side of\nthe triangle, when inserting a circle of area $c$. When insertions and\ndeletions are considered, we achieve a packing density of $(1-\\epsilon)$ of the\ncritical density, where $\\epsilon>0$ can be made arbitrarily small, with an\namortised reallocation cost of $O(c(1+s^2)\\log_{1+s^2}\\frac{1}{c} +\nc\\frac{1}{\\epsilon})$.\n", "versions": [{"version": "v1", "created": "Fri, 16 Feb 2018 09:21:58 GMT"}, {"version": "v2", "created": "Tue, 24 Apr 2018 02:38:04 GMT"}, {"version": "v3", "created": "Wed, 21 Nov 2018 07:40:13 GMT"}], "update_date": "2018-11-22", "authors_parsed": [["Oh", "Shunhao", ""], ["Gilbert", "Seth", ""]]}, {"id": "1802.05995", "submitter": "David Orden", "authors": "Alejandra Martinez-Moraian, David Orden, Leonidas Palios, Carlos\n  Seara, Pawe{\\l} \\.Zyli\\'nski", "title": "Optimizing generalized kernels of polygons", "comments": "26 pages, 18 figures, version submitted to Journal of Global\n  Optimization (the accepted version including minor changes)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $\\mathcal{O}$ be a set of $k$ orientations in the plane, and let $P$ be a\nsimple polygon in the plane. Given two points $p,q$ inside $P$, we say that $p$\n$\\mathcal{O}$-\\emph{sees} $q$ if there is an $\\mathcal{O}$-\\emph{staircase}\ncontained in $P$ that connects $p$ and $q$. The $\\mathcal{O}$-${\\rm Kernel }$\nof the polygon $P$, denoted by $\\mathcal{O}$-${\\rm Kernel }(P)$, is the subset\nof points which $\\mathcal{O}$-see all the other points in $P$. This work\ninitiates the study of the computation and maintenance of $\\mathcal{O}$-${\\rm\nKernel }(P)$ as we rotate the set $\\mathcal{O}$ by an angle $\\theta$, denoted\n$\\mathcal{O}$-${\\rm Kernel }_{\\theta}(P)$. In particular, we consider the case\nwhen the set $\\mathcal{O}$ is formed by either one or two orthogonal\norientations, $\\mathcal{O}=\\{0^\\circ\\}$ or $\\mathcal{O}=\\{0^\\circ,90^\\circ\\}$.\nFor these cases and $P$ being a simple polygon, we design efficient algorithms\nfor computing and maintaining the $\\mathcal{O}$-${\\rm Kernel }_{\\theta}(P)$\nwhile $\\theta$ varies in $[-\\frac{\\pi}{2},\\frac{\\pi}{2})$, obtaining the\nangular intervals where: (i) $\\mathcal{O}$-${\\rm Kernel }_{\\theta}(P)$ is not\nempty, (ii) $\\mathcal{O}$-${\\rm Kernel }_{\\theta}(P)$ optimizes area or\nperimeter. Further, we show how the algorithms can be improved when $P$ is a\nsimple orthogonal polygon.\n", "versions": [{"version": "v1", "created": "Fri, 16 Feb 2018 16:03:15 GMT"}, {"version": "v2", "created": "Fri, 26 Mar 2021 09:33:46 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Martinez-Moraian", "Alejandra", ""], ["Orden", "David", ""], ["Palios", "Leonidas", ""], ["Seara", "Carlos", ""], ["\u017byli\u0144ski", "Pawe\u0142", ""]]}, {"id": "1802.06204", "submitter": "Bin Fu", "authors": "Bin Fu, Pengfei Gu, and Yuming Zhao", "title": "Approximate Set Union Via Approximate Randomization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.CG cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop an randomized approximation algorithm for the size of set union\nproblem $\\arrowvert A_1\\cup A_2\\cup...\\cup A_m\\arrowvert$, which given a list\nof sets $A_1,...,A_m$ with approximate set size $m_i$ for $A_i$ with $m_i\\in\n\\left((1-\\beta_L)|A_i|, (1+\\beta_R)|A_i|\\right)$, and biased random generators\nwith $Prob(x=\\randomElm(A_i))\\in \\left[{1-\\alpha_L\\over |A_i|},{1+\\alpha_R\\over\n|A_i|}\\right]$ for each input set $A_i$ and element $x\\in A_i,$ where $i=1, 2,\n..., m$. The approximation ratio for $\\arrowvert A_1\\cup A_2\\cup...\\cup\nA_m\\arrowvert$ is in the range $[(1-\\epsilon)(1-\\alpha_L)(1-\\beta_L),\n(1+\\epsilon)(1+\\alpha_R)(1+\\beta_R)]$ for any $\\epsilon\\in (0,1)$, where\n$\\alpha_L, \\alpha_R, \\beta_L,\\beta_R\\in (0,1)$. The complexity of the algorithm\nis measured by both time complexity, and round complexity. The algorithm is\nallowed to make multiple membership queries and get random elements from the\ninput sets in one round. Our algorithm makes adaptive accesses to input sets\nwith multiple rounds. Our algorithm gives an approximation scheme with\n$O(\\setCount\\cdot(\\log \\setCount)^{O(1)})$ running time and $O(\\log m)$ rounds,\nwhere $m$ is the number of sets. Our algorithm can handle input sets that can\ngenerate random elements with bias, and its approximation ratio depends on the\nbias. Our algorithm gives a flexible tradeoff with time complexity\n$O\\left(\\setCount^{1+\\xi}\\right)$ and round complexity $O\\left({1\\over\n\\xi}\\right)$ for any $\\xi\\in(0,1)$.\n", "versions": [{"version": "v1", "created": "Sat, 17 Feb 2018 07:37:40 GMT"}, {"version": "v2", "created": "Mon, 19 Mar 2018 02:02:57 GMT"}, {"version": "v3", "created": "Fri, 15 Jun 2018 03:52:43 GMT"}], "update_date": "2018-06-18", "authors_parsed": [["Fu", "Bin", ""], ["Gu", "Pengfei", ""], ["Zhao", "Yuming", ""]]}, {"id": "1802.06223", "submitter": "Eunjin Oh", "authors": "Eunjin Oh and Luis Barba and Hee-Kap Ahn", "title": "The Geodesic Farthest-point Voronoi Diagram in a Simple Polygon", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a set of point sites in a simple polygon, the geodesic farthest-point\nVoronoi diagram partitions the polygon into cells, at most one cell per site,\nsuch that every point in a cell has the same farthest site with respect to the\ngeodesic metric. We present an $O(n\\log\\log n+m\\log m)$- time algorithm to\ncompute the geodesic farthest-point Voronoi diagram of $m$ point sites in a\nsimple $n$-gon. This improves the previously best known algorithm by Aronov et\nal. [Discrete Comput. Geom. 9(3):217-255, 1993]. In the case that all point\nsites are on the boundary of the simple polygon, we can compute the geodesic\nfarthest-point Voronoi diagram in $O((n + m) \\log \\log n)$ time.\n", "versions": [{"version": "v1", "created": "Sat, 17 Feb 2018 11:36:42 GMT"}], "update_date": "2018-02-20", "authors_parsed": [["Oh", "Eunjin", ""], ["Barba", "Luis", ""], ["Ahn", "Hee-Kap", ""]]}, {"id": "1802.06301", "submitter": "Marko Savi\\'c", "authors": "Marko Savi\\'c, Milo\\v{s} Stojakovi\\'c", "title": "Structural Properties of Bichromatic Non-crossing Matchings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a set of $n$ red and $n$ blue points in the plane, we are interested in\nmatching red points with blue points by straight line segments so that the\nsegments do not cross. We develop a range of tools for dealing with the\nnon-crossing matchings of points in convex position. It turns out that the\npoints naturally partition into groups that we refer to as orbits, with a\nnumber of properties that prove useful for studying and efficiently processing\nthe non-crossing matchings.\n  Bottleneck matching is such a matching that minimizes the length of the\nlongest segment. Illustrating the use of the developed tools, we solve the\nproblem of finding bottleneck matchings of points in convex position in\n$O(n^2)$ time. Subsequently, combining our tools with a geometric analysis we\ndesign an $O(n)$-time algorithm for the case where the given points lie on a\ncircle. Previously best known results were $O(n^3)$ for points in convex\nposition, and $O(n \\log n$) for points on a circle.\n", "versions": [{"version": "v1", "created": "Sat, 17 Feb 2018 21:50:47 GMT"}, {"version": "v2", "created": "Thu, 15 Mar 2018 04:26:26 GMT"}, {"version": "v3", "created": "Fri, 12 Mar 2021 00:11:47 GMT"}], "update_date": "2021-03-15", "authors_parsed": [["Savi\u0107", "Marko", ""], ["Stojakovi\u0107", "Milo\u0161", ""]]}, {"id": "1802.06415", "submitter": "Andreas Haas", "authors": "Andreas Haas", "title": "Solving Large-Scale Minimum-Weight Triangulation Instances to Provable\n  Optimality", "comments": "To appear in SoCG 2018. Full version with appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider practical methods for the problem of finding a minimum-weight\ntriangulation (MWT) of a planar point set, a classic problem of computational\ngeometry with many applications. While Mulzer and Rote proved in 2006 that\ncomputing an MWT is NP-hard, Beirouti and Snoeyink showed in 1998 that\ncomputing provably optimal solutions for MWT instances of up to 80,000\nuniformly distributed points is possible, making use of clever heuristics that\nare based on geometric insights. We show that these techniques can be refined\nand extended to instances of much bigger size and different type, based on an\narray of modifications and parallelizations in combination with more efficient\ngeometric encodings and data structures. As a result, we are able to solve MWT\ninstances with up to 30,000,000 uniformly distributed points in less than 4\nminutes to provable optimality. Moreover, we can compute optimal solutions for\na vast array of other benchmark instances that are not uniformly distributed,\nincluding normally distributed instances (up to 30,000,000 points), all point\nsets in the TSPLIB (up to 85,900 points), and VLSI instances with up to 744,710\npoints. This demonstrates that from a practical point of view, MWT instances\ncan be handled quite well, despite their theoretical difficulty.\n", "versions": [{"version": "v1", "created": "Sun, 18 Feb 2018 18:00:32 GMT"}], "update_date": "2018-02-20", "authors_parsed": [["Haas", "Andreas", ""]]}, {"id": "1802.06579", "submitter": "Boris Klemz", "authors": "Linda Kleist, Boris Klemz, Anna Lubiw, Lena Schlipf, Frank Staals,\n  Darren Strash", "title": "Convexity-Increasing Morphs of Planar Graphs", "comments": "Preliminary version in Proc. WG 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of convexifying drawings of planar graphs. Given any\nplanar straight-line drawing of an internally 3-connected graph, we show how to\nmorph the drawing to one with strictly convex faces while maintaining planarity\nat all times. Our morph is convexity-increasing, meaning that once an angle is\nconvex, it remains convex. We give an efficient algorithm that constructs such\na morph as a composition of a linear number of steps where each step either\nmoves vertices along horizontal lines or moves vertices along vertical lines.\nMoreover, we show that a linear number of steps is worst-case optimal.\n  To obtain our result, we use a well-known technique by Hong and Nagamochi for\nfinding redrawings with convex faces while preserving y-coordinates. Using a\nvariant of Tutte's graph drawing algorithm, we obtain a new proof of Hong and\nNagamochi's result which comes with a better running time. This is of\nindependent interest, as Hong and Nagamochi's technique serves as a building\nblock in existing morphing algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 19 Feb 2018 10:43:16 GMT"}, {"version": "v2", "created": "Tue, 20 Feb 2018 09:39:34 GMT"}, {"version": "v3", "created": "Mon, 6 Aug 2018 09:39:24 GMT"}, {"version": "v4", "created": "Mon, 28 Jan 2019 14:22:17 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Kleist", "Linda", ""], ["Klemz", "Boris", ""], ["Lubiw", "Anna", ""], ["Schlipf", "Lena", ""], ["Staals", "Frank", ""], ["Strash", "Darren", ""]]}, {"id": "1802.06699", "submitter": "Anna Lubiw", "authors": "Anna Lubiw and Tillmann Miltzow and Debajyoti Mondal", "title": "The Complexity of Drawing a Graph in a Polygonal Region", "comments": "Appears in the Proceedings of the 26th International Symposium on\n  Graph Drawing and Network Visualization (GD 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CG cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that the following problem is complete for the existential theory of\nthe reals: Given a planar graph and a polygonal region, with some vertices of\nthe graph assigned to points on the boundary of the region, place the remaining\nvertices to create a planar straight-line drawing of the graph inside the\nregion. This strengthens an NP-hardness result by Patrignani on extending\npartial planar graph drawings. Our result is one of the first showing that a\nproblem of drawing planar graphs with straight-line edges is hard for the\nexistential theory of the reals. The complexity of the problem is open in the\ncase of a simply connected region.\n  We also show that, even for integer input coordinates, it is possible that\ndrawing a graph in a polygonal region requires some vertices to be placed at\nirrational coordinates. By contrast, the coordinates are known to be bounded in\nthe special case of a convex region, or for drawing a path in any polygonal\nregion.\n", "versions": [{"version": "v1", "created": "Mon, 19 Feb 2018 16:55:28 GMT"}, {"version": "v2", "created": "Tue, 28 Aug 2018 13:23:29 GMT"}, {"version": "v3", "created": "Wed, 5 Sep 2018 23:47:18 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Lubiw", "Anna", ""], ["Miltzow", "Tillmann", ""], ["Mondal", "Debajyoti", ""]]}, {"id": "1802.06712", "submitter": "Martin Wilhelm", "authors": "Martin Wilhelm", "title": "Multithreading for the expression-dag-based number type Real_algebraic", "comments": "Technical Report", "journal-ref": null, "doi": null, "report-no": "FIN-001-2018", "categories": "cs.DC cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many algorithms, especially in the field of computational geometry, are based\non the premise that arithmetic operations are performed exactly. Real machines\nare based on inexact floating-point arithmetic. Various number types have been\ndeveloped to close this gap by providing exact computation or ensuring exact\ndecisions. In this report we describe the implementation of an extension to the\nexact-decisions number type Real_algebraic that enables us to take advantage of\nmultiple processing units.\n", "versions": [{"version": "v1", "created": "Mon, 19 Feb 2018 17:13:11 GMT"}, {"version": "v2", "created": "Tue, 3 Apr 2018 11:28:04 GMT"}], "update_date": "2018-04-04", "authors_parsed": [["Wilhelm", "Martin", ""]]}, {"id": "1802.07487", "submitter": "Stephane Guinard", "authors": "Stephane Guinard and Bruno Vallet", "title": "Sensor-topology based simplicial complex reconstruction", "comments": "8 pages, 14 figures, ISPRS Technical Commission II Symposium 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new method for the reconstruction of simplicial complexes\n(combining points, edges and triangles) from 3D point clouds from Mobile Laser\nScanning (MLS). Our main goal is to produce a reconstruction of a scene that is\nadapted to the local geometry of objects. Our method uses the inherent topology\nof the MLS sensor to define a spatial adjacency relationship between points. We\nthen investigate each possible connexion between adjacent points and filter\nthem by searching collinear structures in the scene, or structures\nperpendicular to the laser beams. Next, we create triangles for each triplet of\nself-connected edges. Last, we improve this method with a regularization based\non the co-planarity of triangles and collinearity of remaining edges. We\ncompare our results to a naive simplicial complexes reconstruction based on\nedge length.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 10:00:09 GMT"}, {"version": "v2", "created": "Mon, 9 Apr 2018 07:27:15 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Guinard", "Stephane", ""], ["Vallet", "Bruno", ""]]}, {"id": "1802.07502", "submitter": "Dinesh Dash", "authors": "Dinesh Dash", "title": "Approximation Algorithms for Road Coverage Using Wireless Sensor\n  Networks for Moving Objects Monitoring", "comments": "11 pages, 12 figures", "journal-ref": null, "doi": "10.1109/TITS.2019.2948061", "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coverage problem in wireless sensor networks measures how well a region or\nparts of it is sensed by the deployed sensors. Definition of coverage metric\ndepends on its applications for which sensors are deployed. In this paper, we\nintroduce a new quality control metric/measure called road coverage. It will be\nused for measuring efficiency of a sensor network, which is deployed for\ntracking moving/mobile objects in a road network. A road segment is a sub-part\nof a road network. A road segment is said to be road covered if an object\ntravels through the entire road segment then it must be detected somewhere on\nthe road segment by a sensor. First, we propose different definitions of road\ncoverage metrics. Thereafter, algorithms are proposed to measure those proposed\nroad coverage metrics. It is shown that the problem of deploying minimum number\nof sensors to road cover a set of road segments is NP-hard. Constant factor\napproximation algorithms are proposed for road covering axis-parallel road\nsegments. Experimental performance analysis of our algorithms are evaluated\nthrough simulations.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 10:38:30 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Dash", "Dinesh", ""]]}, {"id": "1802.07625", "submitter": "Michael Gastner", "authors": "Michael T. Gastner, Vivien Seguy and Pratyush More", "title": "Fast flow-based algorithm for creating density-equalizing map\n  projections", "comments": "16 pages (including supplementary text), 8 figures", "journal-ref": "Proc. Natl. Acad. Sci. U.S.A.115(10):E2156-E2164 (2018)", "doi": "10.1073/pnas.1712674115", "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cartograms are maps that rescale geographic regions (e.g., countries,\ndistricts) such that their areas are proportional to quantitative demographic\ndata (e.g., population size, gross domestic product). Unlike conventional bar\nor pie charts, cartograms can represent correctly which regions share common\nborders, resulting in insightful visualizations that can be the basis for\nfurther spatial statistical analysis. Computer programs can assist data\nscientists in preparing cartograms, but developing an algorithm that can\nquickly transform every coordinate on the map (including points that are not\nexactly on a border) while generating recognizable images has remained a\nchallenge. Methods that translate the cartographic deformations into\nphysics-inspired equations of motion have become popular, but solving these\nequations with sufficient accuracy can still take several minutes on current\nhardware. Here we introduce a flow-based algorithm whose equations of motion\nare numerically easier to solve compared with previous methods. The equations\nallow straightforward parallelization so that the calculation takes only a few\nseconds even for complex and detailed input. Despite the speedup, the proposed\nalgorithm still keeps the advantages of previous techniques: with comparable\nquantitative measures of shape distortion, it accurately scales all areas,\ncorrectly fits the regions together and generates a map projection for every\npoint. We demonstrate the use of our algorithm with applications to the 2016 US\nelection results, the gross domestic products of Indian states and Chinese\nprovinces, and the spatial distribution of deaths in the London borough of\nKensington and Chelsea between 2011 and 2014.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 15:54:46 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Gastner", "Michael T.", ""], ["Seguy", "Vivien", ""], ["More", "Pratyush", ""]]}, {"id": "1802.07967", "submitter": "Ofer Neiman", "authors": "Michael Elkin and Ofer Neiman", "title": "Near Isometric Terminal Embeddings for Doubling Metrics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a metric space $(X,d)$, a set of terminals $K\\subseteq X$, and a\nparameter $t\\ge 1$, we consider metric structures (e.g., spanners, distance\noracles, embedding into normed spaces) that preserve distances for all pairs in\n$K\\times X$ up to a factor of $t$, and have small size (e.g. number of edges\nfor spanners, dimension for embeddings). While such terminal (aka source-wise)\nmetric structures are known to exist in several settings, no terminal spanner\nor embedding with distortion close to 1, i.e., $t=1+\\epsilon$ for some small\n$0<\\epsilon<1$, is currently known.\n  Here we devise such terminal metric structures for {\\em doubling} metrics,\nand show that essentially any metric structure with distortion $1+\\epsilon$ and\nsize $s(|X|)$ has its terminal counterpart, with distortion $1+O(\\epsilon)$ and\nsize $s(|K|)+1$. In particular, for any doubling metric on $n$ points, a set of\n$k=o(n)$ terminals, and constant $0<\\epsilon<1$, there exists:\n  (1) A spanner with stretch $1+\\epsilon$ for pairs in $K\\times X$, with\n$n+o(n)$ edges.\n  (2) A labeling scheme with stretch $1+\\epsilon$ for pairs in $K\\times X$,\nwith label size $\\approx \\log k$.\n  (3) An embedding into $\\ell_\\infty^d$ with distortion $1+\\epsilon$ for pairs\nin $K\\times X$, where $d=O(\\log k)$.\n  Moreover, surprisingly, the last two results apply if only $K$ is a doubling\nmetric, while $X$ can be arbitrary.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 10:26:17 GMT"}], "update_date": "2018-02-23", "authors_parsed": [["Elkin", "Michael", ""], ["Neiman", "Ofer", ""]]}, {"id": "1802.08442", "submitter": "Laurent Decreusefond", "authors": "Anais Vergne (LTCI), Laurent Decreusefond (LTCI), Philippe Martins\n  (LTCI)", "title": "Building a coverage hole-free communication tree", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wireless networks are present everywhere but their management can be tricky\nsince their coverage may contain holes even if the network is fully connected.\nIn this paper we propose an algorithm that can build a communication tree\nbetween nodes of a wireless network with guarantee that there is no coverage\nhole in the tree. We use simplicial homology to compute mathematically the\ncoverage, and Prim's algorithm principle to build the communication tree. Some\nsimulation results are given to study the performance of the algorithm and\ncompare different metrics. In the end, we show that our algorithm can be used\nto create coverage hole-free communication groups with a limited number of\nhops.\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 08:40:49 GMT"}], "update_date": "2018-02-26", "authors_parsed": [["Vergne", "Anais", "", "LTCI"], ["Decreusefond", "Laurent", "", "LTCI"], ["Martins", "Philippe", "", "LTCI"]]}, {"id": "1802.08683", "submitter": "Henry Van Den Bedem", "authors": "Dominik Budday, Sigrid Leyendecker and Henry van den Bedem", "title": "Kinematic Flexibility Analysis: Hydrogen Bonding Patterns Impart a\n  Spatial Hierarchy of Protein Motion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.BM cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Elastic network models (ENM) and constraint-based, topological rigidity\nanalysis are two distinct, coarse-grained approaches to study conformational\nflexibility of macromolecules. In the two decades since their introduction,\nboth have contributed significantly to insights into protein molecular\nmechanisms and function. However, despite a shared purpose of these approaches,\nthe topological nature of rigidity analysis, and thereby the absence of motion\nmodes, has impeded a direct comparison. Here, we present an alternative,\nkinematic approach to rigidity analysis, which circumvents these drawbacks. We\nintroduce a novel protein hydrogen bond network spectral decomposition, which\nprovides an orthonormal basis for collective motions modulated by non-covalent\ninteractions, analogous to the eigenspectrum of normal modes, and decomposes\nproteins into rigid clusters identical to those from topological rigidity. Our\nkinematic flexibility analysis bridges topological rigidity theory and ENM, and\nenables a detailed analysis of motion modes obtained from both approaches. Our\nanalysis reveals that collectivity of protein motions, reported by the Shannon\nentropy, is significantly lower for rigidity theory versus normal mode\napproaches. Strikingly, kinematic flexibility analysis suggests that the\nhydrogen bonding network encodes a protein-fold specific, spatial hierarchy of\nmotions, which goes nearly undetected in ENM. This hierarchy reveals distinct\nmotion regimes that rationalize protein stiffness changes observed from\nexperiment and molecular dynamics simulations. A formal expression for changes\nin free energy derived from the spectral decomposition indicates that motions\nacross nearly 40% of modes obey enthalpy-entropy compensation. Taken together,\nour analysis suggests that hydrogen bond networks have evolved to modulate\nprotein structure and dynamics.\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 06:08:13 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Budday", "Dominik", ""], ["Leyendecker", "Sigrid", ""], ["Bedem", "Henry van den", ""]]}, {"id": "1802.08799", "submitter": "Boris Aronov", "authors": "Boris Aronov and Anirudh Donakonda and Esther Ezra and Rom Pinchasi", "title": "On Pseudo-disk Hypergraphs", "comments": "Submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $F$ be a family of pseudo-disks in the plane, and $P$ be a finite subset\nof $F$. Consider the hypergraph $H(P,F)$ whose vertices are the pseudo-disks in\n$P$ and the edges are all subsets of $P$ of the form $\\{D \\in P \\mid D \\cap S\n\\neq \\emptyset\\}$, where $S$ is a pseudo-disk in $F$. We give an upper bound of\n$O(nk^3)$ for the number of edges in $H(P,F)$ of cardinality at most $k$. This\ngeneralizes a result of Buzaglo et al. (2013).\n  As an application of our bound, we obtain an algorithm that computes a\nconstant-factor approximation to the smallest _weighted_ dominating set in a\ncollection of pseudo-disks in the plane, in expected polynomial time.\n", "versions": [{"version": "v1", "created": "Sat, 24 Feb 2018 04:51:48 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Aronov", "Boris", ""], ["Donakonda", "Anirudh", ""], ["Ezra", "Esther", ""], ["Pinchasi", "Rom", ""]]}, {"id": "1802.09505", "submitter": "Ahmad Biniaz", "authors": "Ahmad Biniaz, Prosenjit Bose, Paz Carmi, Anil Maheshwari, J. Ian\n  Munro, and Michiel Smid", "title": "Faster Algorithms for some Optimization Problems on Collinear Points", "comments": "To appear in SoCG 2018. Full version (15 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose faster algorithms for the following three optimization problems on\n$n$ collinear points, i.e., points in dimension one. The first two problems are\nknown to be NP-hard in higher dimensions.\n  1- Maximizing total area of disjoint disks: In this problem the goal is to\nmaximize the total area of nonoverlapping disks centered at the points.\nAcharyya, De, and Nandy (2017) presented an $O(n^2)$-time algorithm for this\nproblem. We present an optimal $\\Theta(n)$-time algorithm.\n  2- Minimizing sum of the radii of client-server coverage: The $n$ points are\npartitioned into two sets, namely clients and servers. The goal is to minimize\nthe sum of the radii of disks centered at servers such that every client is in\nsome disk, i.e., in the coverage range of some server. Lev-Tov and Peleg (2005)\npresented an $O(n^3)$-time algorithm for this problem. We present an\n$O(n^2)$-time algorithm, thereby improving the running time by a factor of\n$\\Theta(n)$.\n  3- Minimizing total area of point-interval coverage: The $n$ input points\nbelong to an interval $I$. The goal is to find a set of $n$ disks of minimum\ntotal area, covering $I$, such that every disk contains at least one input\npoint. We present an algorithm that solves this problem in $O(n^2)$ time.\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2018 18:40:05 GMT"}, {"version": "v2", "created": "Thu, 26 Jul 2018 13:43:42 GMT"}], "update_date": "2018-07-27", "authors_parsed": [["Biniaz", "Ahmad", ""], ["Bose", "Prosenjit", ""], ["Carmi", "Paz", ""], ["Maheshwari", "Anil", ""], ["Munro", "J. Ian", ""], ["Smid", "Michiel", ""]]}, {"id": "1802.10457", "submitter": "Vincent Divol", "authors": "Fr\\'ed\\'eric Chazal, Vincent Divol", "title": "The density of expected persistence diagrams and its kernel based\n  estimation", "comments": "Extended version of a paper published in the proceedings of the\n  Symposium of Computational Geometry 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Persistence diagrams play a fundamental role in Topological Data Analysis\nwhere they are used as topological descriptors of filtrations built on top of\ndata. They consist in discrete multisets of points in the plane $\\mathbb{R}^2$\nthat can equivalently be seen as discrete measures in $\\mathbb{R}^2$. When the\ndata come as a random point cloud, these discrete measures become random\nmeasures whose expectation is studied in this paper. First, we show that for a\nwide class of filtrations, including the \\v{C}ech and Rips-Vietoris\nfiltrations, the expected persistence diagram, that is a deterministic measure\non $\\mathbb{R}^2$ , has a density with respect to the Lebesgue measure. Second,\nbuilding on the previous result we show that the persistence surface recently\nintroduced in [Adams & al., Persistence images: a stable vector representation\nof persistent homology] can be seen as a kernel estimator of this density. We\npropose a cross-validation scheme for selecting an optimal bandwidth, which is\nproven to be a consistent procedure to estimate the density.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 14:58:19 GMT"}, {"version": "v2", "created": "Fri, 22 Mar 2019 16:11:31 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Chazal", "Fr\u00e9d\u00e9ric", ""], ["Divol", "Vincent", ""]]}]