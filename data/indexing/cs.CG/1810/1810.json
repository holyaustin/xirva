[{"id": "1810.00455", "submitter": "Meng-Tsung Tsai", "authors": "Martin Farach-Colton, Meng Li, and Meng-Tsung Tsai", "title": "Streaming Algorithms for Planar Convex Hulls", "comments": "This is the full version of a conference paper to appear in the\n  Proceedings of 29th International Symposium on Algorithms and Computation\n  (ISAAC 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many classical algorithms are known for computing the convex hull of a set of\n$n$ point in $\\mathbb{R}^2$ using $O(n)$ space. For large point sets, whose\nsize exceeds the size of the working space, these algorithms cannot be directly\nused. The current best streaming algorithm for computing the convex hull is\ncomputationally expensive, because it needs to solve a set of linear programs.\nIn this paper, we propose simpler and faster streaming and W-stream algorithms\nfor computing the convex hull. Our streaming algorithm has small pass\ncomplexity, which is roughly a square root of the current best bound, and it is\nsimpler in the sense that our algorithm mainly relies on computing the convex\nhulls of smaller point sets. Our W-stream algorithms, one of which is\ndeterministic and the other of which is randomized, have nearly-optimal\ntradeoff between the pass complexity and space usage, as we established by a\nnew unconditional lower bound.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 19:36:23 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Farach-Colton", "Martin", ""], ["Li", "Meng", ""], ["Tsai", "Meng-Tsung", ""]]}, {"id": "1810.00621", "submitter": "Karl Bringmann", "authors": "Karl Bringmann, Bhaskar Ray Chaudhury", "title": "Polyline Simplification has Cubic Complexity", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the classic polyline simplification problem we want to replace a given\npolygonal curve $P$, consisting of $n$ vertices, by a subsequence $P'$ of $k$\nvertices from $P$ such that the polygonal curves $P$ and $P'$ are as close as\npossible. Closeness is usually measured using the Hausdorff or Fr\\'echet\ndistance. These distance measures can be applied \"globally\", i.e., to the whole\ncurves $P$ and $P'$, or \"locally\", i.e., to each simplified subcurve and the\nline segment that it was replaced with separately (and then taking the\nmaximum). This gives rise to four problem variants: Global-Hausdorff (known to\nbe NP-hard), Local-Hausdorff (in time $O(n^3)$), Global-Fr\\'echet (in time $O(k\nn^5)$), and Local-Fr\\'echet (in time $O(n^3)$).\n  Our contribution is as follows.\n  - Cubic time for all variants: For Global-Fr\\'echet we design an algorithm\nrunning in time $O(n^3)$. This shows that all three problems (Local-Hausdorff,\nLocal-Fr\\'echet, and Global-Fr\\'echet) can be solved in cubic time. All these\nalgorithms work over a general metric space such as $(\\mathbb{R}^d,L_p)$, but\nthe hidden constant depends on $p$ and (linearly) on $d$.\n  - Cubic conditional lower bound: We provide evidence that in high dimensions\ncubic time is essentially optimal for all three problems (Local-Hausdorff,\nLocal-Fr\\'echet, and Global-Fr\\'echet). Specifically, improving the cubic time\nto $O(n^{3-\\epsilon} \\textrm{poly}(d))$ for polyline simplification over\n$(\\mathbb{R}^d,L_p)$ for $p = 1$ would violate plausible conjectures. We obtain\nsimilar results for all $p \\in [1,\\infty), p \\ne 2$.\n  In total, in high dimensions and over general $L_p$-norms we resolve the\ncomplexity of polyline simplification with respect to Local-Hausdorff,\nLocal-Fr\\'echet, and Global-Fr\\'echet, by providing new algorithms and\nconditional lower bounds.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 11:15:37 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Bringmann", "Karl", ""], ["Chaudhury", "Bhaskar Ray", ""]]}, {"id": "1810.00715", "submitter": "Siu-Wing Cheng", "authors": "Siu-Wing Cheng and Man-Kit Lau", "title": "Adaptive Planar Point Location", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present self-adjusting data structures for answering point location\nqueries in convex and connected subdivisions. Let $n$ be the number of vertices\nin a convex or connected subdivision. Our structures use $O(n)$ space. For any\nconvex subdivision $S$, our method processes any online query sequence $\\sigma$\nin $O(\\mathrm{OPT} + n)$ time, where $\\mathrm{OPT}$ is the minimum time\nrequired by any linear decision tree for answering point location queries in\n$S$ to process $\\sigma$. For connected subdivisions, the processing time is\n$O(\\mathrm{OPT} + n + |\\sigma|\\log(\\log^* n))$. In both cases, the time bound\nincludes the $O(n)$ preprocessing time.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 14:17:40 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Cheng", "Siu-Wing", ""], ["Lau", "Man-Kit", ""]]}, {"id": "1810.00794", "submitter": "Jules Wulms", "authors": "Ivor van der Hoog, Marc van Kreveld, Wouter Meulemans, Kevin Verbeek,\n  Jules Wulms", "title": "Topological Stability of Kinetic $k$-Centers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the $k$-center problem in a kinetic setting: given a set of\ncontinuously moving points $P$ in the plane, determine a set of $k$ (moving)\ndisks that cover $P$ at every time step, such that the disks are as small as\npossible at any point in time. Whereas the optimal solution over time may\nexhibit discontinuous changes, many practical applications require the solution\nto be stable: the disks must move smoothly over time. Existing results on this\nproblem require the disks to move with a bounded speed, but this model allows\npositive results only for $k<3$. Hence, the results are limited and offer\nlittle theoretical insight. Instead, we study the topological stability of\n$k$-centers. Topological stability was recently introduced and simply requires\nthe solution to change continuously, but may do so arbitrarily fast. We prove\nupper and lower bounds on the ratio between the radii of an optimal but\nunstable solution and the radii of a topologically stable solution -- the\ntopological stability ratio -- considering various metrics and various\noptimization criteria. For $k = 2$ we provide tight bounds, and for small $k >\n2$ we can obtain nontrivial lower and upper bounds. Finally, we provide an\nalgorithm to compute the topological stability ratio in polynomial time for\nconstant $k$.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 16:24:56 GMT"}, {"version": "v2", "created": "Mon, 12 Jul 2021 09:18:18 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["van der Hoog", "Ivor", ""], ["van Kreveld", "Marc", ""], ["Meulemans", "Wouter", ""], ["Verbeek", "Kevin", ""], ["Wulms", "Jules", ""]]}, {"id": "1810.01049", "submitter": "Hu Ding", "authors": "Hu Ding and Jinhui Xu", "title": "A Unified Framework for Clustering Constrained Data without Locality\n  Property", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider a class of constrained clustering problems of\npoints in $\\mathbb{R}^{d}$, where $d$ could be rather high. A common feature of\nthese problems is that their optimal clusterings no longer have the locality\nproperty (due to the additional constraints), which is a key property required\nby many algorithms for their unconstrained counterparts. To overcome the\ndifficulty caused by the loss of locality, we present in this paper a unified\nframework, called {\\em Peeling-and-Enclosing (PnE)}, to iteratively solve two\nvariants of the constrained clustering problems, {\\em constrained $k$-means\nclustering} ($k$-CMeans) and {\\em constrained $k$-median clustering}\n($k$-CMedian). Our framework is based on two standalone geometric techniques,\ncalled {\\em Simplex Lemma} and {\\em Weaker Simplex Lemma}, for $k$-CMeans and\n$k$-CMedian, respectively. The simplex lemma (or weaker simplex lemma) enables\nus to efficiently approximate the mean (or median) point of an unknown set of\npoints by searching a small-size grid, independent of the dimensionality of the\nspace, in a simplex (or the surrounding region of a simplex), and thus can be\nused to handle high dimensional data. If $k$ and $\\frac{1}{\\epsilon}$ are fixed\nnumbers, our framework generates, in nearly linear time ({\\em i.e.,} $O(n(\\log\nn)^{k+1}d)$), $O((\\log n)^{k})$ $k$-tuple candidates for the $k$ mean or median\npoints, and one of them induces a $(1+\\epsilon)$-approximation for $k$-CMeans\nor $k$-CMedian, where $n$ is the number of points. Combining this unified\nframework with a problem-specific selection algorithm (which determines the\nbest $k$-tuple candidate), we obtain a $(1+\\epsilon)$-approximation for each of\nthe constrained clustering problems. We expect that our technique will be\napplicable to other constrained clustering problems without locality.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 03:18:15 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["Ding", "Hu", ""], ["Xu", "Jinhui", ""]]}, {"id": "1810.01393", "submitter": "Themistoklis Melissourgos", "authors": "Argyrios Deligkas, John Fearnley, Themistoklis Melissourgos, and Paul\n  G. Spirakis", "title": "Approximating the Existential Theory of the Reals", "comments": "In the proceedings of the 14th Conference on Web and Internet\n  Economics (WINE 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CG cs.GT math.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Existential Theory of the Reals (ETR) consists of existentially\nquantified Boolean formulas over equalities and inequalities of polynomial\nfunctions of variables in $\\mathbb{R}$. In this paper we propose and study the\napproximate existential theory of the reals ($\\epsilon$-ETR), in which the\nconstraints only need to be satisfied approximately. We first show that when\nthe domain of the variables is $\\mathbb{R}$ then $\\epsilon$-ETR = ETR under\npolynomial time reductions, and then study the constrained $\\epsilon$-ETR\nproblem when the variables are constrained to lie in a given bounded convex\nset. Our main theorem is a sampling theorem, similar to those that have been\nproved for approximate equilibria in normal form games. It discretizes the\ndomain in a grid-like manner whose density depends on various properties of the\nformula. A consequence of our theorem is that we obtain a quasi-polynomial time\napproximation scheme (QPTAS) for a fragment of constrained $\\epsilon$-ETR. We\nuse our theorem to create several new PTAS and QPTAS algorithms for problems\nfrom a variety of fields.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 17:33:46 GMT"}, {"version": "v2", "created": "Fri, 19 Oct 2018 11:23:45 GMT"}, {"version": "v3", "created": "Thu, 19 Mar 2020 18:16:20 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Deligkas", "Argyrios", ""], ["Fearnley", "John", ""], ["Melissourgos", "Themistoklis", ""], ["Spirakis", "Paul G.", ""]]}, {"id": "1810.01546", "submitter": "Nina Amenta", "authors": "Nina Amenta and Carlos Rojas", "title": "Dihedral Rigidity and Deformation", "comments": "Appeared in the Canadian Computational Geometry Conference, CCCG '18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider defining the embedding of a triangle mesh into $R^3$, up to\ntranslation, rotation, and scale, by its vector of dihedral angles.\nTheoretically, we show that locally, almost everywhere, the map from realizable\nvectors of dihedrals to mesh embeddings is one-to-one. We experiment with a\nheuristic method for mapping straight-line interpolations in dihedral space to\ninterpolations between mesh embeddings and produce smooth and intuitively\nappealing morphs between three-dimensional shapes.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 00:18:00 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Amenta", "Nina", ""], ["Rojas", "Carlos", ""]]}, {"id": "1810.01575", "submitter": "Omid Poursaeed", "authors": "Omid Poursaeed, Guandao Yang, Aditya Prakash, Qiuren Fang, Hanqing\n  Jiang, Bharath Hariharan, Serge Belongie", "title": "Deep Fundamental Matrix Estimation without Correspondences", "comments": "ECCV 2018, Geometry Meets Deep Learning Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CG cs.GR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating fundamental matrices is a classic problem in computer vision.\nTraditional methods rely heavily on the correctness of estimated key-point\ncorrespondences, which can be noisy and unreliable. As a result, it is\ndifficult for these methods to handle image pairs with large occlusion or\nsignificantly different camera poses. In this paper, we propose novel neural\nnetwork architectures to estimate fundamental matrices in an end-to-end manner\nwithout relying on point correspondences. New modules and layers are introduced\nin order to preserve mathematical properties of the fundamental matrix as a\nhomogeneous rank-2 matrix with seven degrees of freedom. We analyze performance\nof the proposed models using various metrics on the KITTI dataset, and show\nthat they achieve competitive performance with traditional methods without the\nneed for extracting correspondences.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 03:59:15 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Poursaeed", "Omid", ""], ["Yang", "Guandao", ""], ["Prakash", "Aditya", ""], ["Fang", "Qiuren", ""], ["Jiang", "Hanqing", ""], ["Hariharan", "Bharath", ""], ["Belongie", "Serge", ""]]}, {"id": "1810.01587", "submitter": "Md Salman Nazir", "authors": "Md Salman Nazir, Ian A. Hiskens, Andrey Bernstein, Emiliano Dall'Anese", "title": "Inner Approximation of Minkowski Sums: A Union-Based Approach and\n  Applications to Aggregated Energy Resources", "comments": "Accepted for presentation at the 57th IEEE Conference on Decision and\n  Control", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops and compares algorithms to compute inner approximations\nof the Minkowski sum of convex polytopes. As an application, the paper\nconsiders the computation of the feasibility set of aggregations of distributed\nenergy resources (DERs), such as solar photovoltaic inverters, controllable\nloads, and storage devices. To fully account for the heterogeneity in the DERs\nwhile ensuring an acceptable approximation accuracy, the paper leverages a\nunion-based computation and advocates homothet-based polytope decompositions.\nHowever, union-based approaches can in general lead to high-dimensionality\nconcerns; to alleviate this issue, this paper shows how to define candidate\nsets to reduce the computational complexity. Accuracy and trade-offs are\nanalyzed through numerical simulations for illustrative examples.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 05:31:14 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Nazir", "Md Salman", ""], ["Hiskens", "Ian A.", ""], ["Bernstein", "Andrey", ""], ["Dall'Anese", "Emiliano", ""]]}, {"id": "1810.01786", "submitter": "Paul Bell", "authors": "Paul C. Bell and Igor Potapov", "title": "Towards Uniform Online Spherical Tessellations", "comments": "18 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of uniformly placing N points onto a sphere finds applications in\nmany areas. For example, points on the sphere correspond to unit quaternions as\nwell as to the group of rotations SO(3) and the online version of generating\nuniform rotations (known as \"incremental generation\") plays a crucial role in a\nlarge number of engineering applications ranging from robotics and aeronautics\nto computer graphics. An online version of this problem was recently studied\nwith respect to the gap ratio as a measure of uniformity. The first online\nalgorithm of Chen et al. was upper-bounded by 5.99 and later improved to 3.69,\nwhich is achieved by considering a circumscribed dodecahedron followed by a\nrecursive decomposition of each face.\n  In this paper we provide a more efficient tessellation technique based on the\nregular icosahedron, which improves the upper-bound for the online version of\nthis problem, decreasing it to approximately 2.84. Moreover, we show that the\nlower bound for the gap ratio of placing at least three points is the golden\nratio, approx. 1.618, and for at least four points is no less than 1.726.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 15:11:11 GMT"}, {"version": "v2", "created": "Wed, 13 May 2020 16:08:31 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Bell", "Paul C.", ""], ["Potapov", "Igor", ""]]}, {"id": "1810.02303", "submitter": "Adrien Poulenard", "authors": "Adrien Poulenard, Maks Ovsjanikov", "title": "Multi-directional Geodesic Neural Networks via Equivariant Convolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.CG cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel approach for performing convolution of signals on curved\nsurfaces and show its utility in a variety of geometric deep learning\napplications. Key to our construction is the notion of directional functions\ndefined on the surface, which extend the classic real-valued signals and which\ncan be naturally convolved with with real-valued template functions. As a\nresult, rather than trying to fix a canonical orientation or only keeping the\nmaximal response across all alignments of a 2D template at every point of the\nsurface, as done in previous works, we show how information across all\nrotations can be kept across different layers of the neural network. Our\nconstruction, which we call multi-directional geodesic convolution, or\ndirectional convolution for short, allows, in particular, to propagate and\nrelate directional information across layers and thus different regions on the\nshape. We first define directional convolution in the continuous setting, prove\nits key properties and then show how it can be implemented in practice, for\nshapes represented as triangle meshes. We evaluate directional convolution in a\nwide variety of learning scenarios ranging from classification of signals on\nsurfaces, to shape segmentation and shape matching, where we show a significant\nimprovement over several baselines.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 18:03:24 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Poulenard", "Adrien", ""], ["Ovsjanikov", "Maks", ""]]}, {"id": "1810.02999", "submitter": "Kuo Kan Liang", "authors": "Kuo Kan Liang", "title": "Efficient conversion from rotating matrix to rotation axis and angle by\n  extending Rodrigues' formula", "comments": "9 pages, 1 figure, minor typo corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.RO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In computational 3D geometric problems involving rotations, it is often that\npeople have to convert back and forth between a rotational matrix and a\nrotation described by an axis and a corresponding angle. For this purpose,\nRodrigues' rotation formula is a very popular expression to use because of its\nsimplicity and efficiency. Nevertheless, while converting a rotation matrix to\nan axis of rotation and the rotation angle, there exists ambiguity. Further\njudgement or even manual interference may be necessary in some situations. An\nextension of the Rodrigues' formula helps to find the sine and cosine values of\nthe rotation angle with respect to a given rotation axis is found and this\nsimple extension may help to accelerate many applications.\n", "versions": [{"version": "v1", "created": "Sat, 6 Oct 2018 13:08:29 GMT"}, {"version": "v2", "created": "Tue, 9 Oct 2018 04:02:34 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Liang", "Kuo Kan", ""]]}, {"id": "1810.03084", "submitter": "Shahin Pourbahrami", "authors": "Shahin Pourbahrami, Leyli Mohammad Khanli, Sohrab Azimpour", "title": "NCARD: Improving Neighborhood Construction by Apollonius Region\n  Algorithm based on Density", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Due to the increased rate of information in the present era, local\nidentification of similar and related data points by using neighborhood\nconstruction algorithms is highly significant for processing information in\nvarious sciences. Geometric methods are especially useful for their accuracy in\nlocating highly similar neighborhood points using efficient geometric\nstructures. Geometric methods should be examined for each individual point in\nneighborhood data set so that similar groups would be formed. Those algorithms\nare not highly accurate for high dimension of data. Due to the important\nchallenges in data point analysis, we have used geometric method in which the\nApollonius circle is used to achieve high local accuracy with high dimension\ndata. In this paper, we propose a neighborhood construction algorithm, namely\nNeighborhood Construction by Apollonius Region Density (NCARD). In this study,\nthe neighbors of data points are determined using not only the geometric\nstructures, but also the density information. Apollonius circle, one of the\nstate-of-the-art proximity geometry methods, Apollonius circle, is used for\nthis purpose. For efficient clustering, our algorithm works better with high\ndimension of data than the previous methods; it is also able to identify the\nlocal outlier data. We have no prior information about the data in the proposed\nalgorithm. Moreover, after locating similar data points with Apollonius circle,\nwe will extract density and relationship among the points, and a unique and\naccurate neighborhood is created in this way. The proposed algorithm is more\naccurate than the state-of-the-art and well-known algorithms up to almost 8-13%\nin real and artificial data sets.\n", "versions": [{"version": "v1", "created": "Sun, 7 Oct 2018 04:52:11 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Pourbahrami", "Shahin", ""], ["Khanli", "Leyli Mohammad", ""], ["Azimpour", "Sohrab", ""]]}, {"id": "1810.03305", "submitter": "Hao-Chiang Shao", "authors": "Hao-Chiang Shao", "title": "A Coarse-to-Fine Multiscale Mesh Representation and its Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel coarse-to-fine framework that derives a semi-regular\nmultiscale mesh representation of an original input mesh via remeshing. Our\napproach differs from the conventional mesh wavelet transform strategy in two\nways. First, based on a lazy wavelet framework, it can convert an input mesh\ninto a multiresolution representation through a single remeshing procedure. By\ncontrast, the conventional strategy requires two steps: remeshing and mesh\nwavelet transform. Second, the proposed method can conditionally convert input\nmesh models into ones sharing the same adjacency matrix, so it is able be\ninvariant against the triangular tilings of the inputs. Our experiment results\nshow that the proposed multiresolution representation method is efficient in\nvarious applications, such as 3D shape property analysis, mesh scalable coding\nand mesh morphing.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 08:12:10 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Shao", "Hao-Chiang", ""]]}, {"id": "1810.04321", "submitter": "Assaf Naor", "authors": "Subhash Khot and Assaf Naor", "title": "The Andoni--Krauthgamer--Razenshteyn characterization of sketchable\n  norms fails for sketchable metrics", "comments": "To appear in SODA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG math.FA math.MG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Andoni, Krauthgamer and Razenshteyn (AKR) proved (STOC 2015) that a\nfinite-dimensional normed space $(X,\\|\\cdot\\|_X)$ admits a $O(1)$ sketching\nalgorithm (namely, with $O(1)$ sketch size and $O(1)$ approximation) if and\nonly if for every $\\varepsilon\\in (0,1)$ there exist $\\alpha\\geqslant 1$ and an\nembedding $f:X\\to \\ell_{1-\\varepsilon}$ such that $\\|x-y\\|_X\\leqslant\n\\|f(x)-f(y)\\|_{1-\\varepsilon}\\leqslant \\alpha \\|x-y\\|_X$ for all $x,y\\in X$.\nThe \"if part\" of this theorem follows from a sketching algorithm of Indyk (FOCS\n2000). The contribution of AKR is therefore to demonstrate that the mere\navailability of a sketching algorithm implies the existence of the\naforementioned geometric realization. Indyk's algorithm shows that the \"if\npart\" of the AKR characterization holds true for any metric space whatsoever,\ni.e., the existence of an embedding as above implies sketchability even when\n$X$ is not a normed space. Due to this, a natural question that AKR posed was\nwhether the assumption that the underlying space is a normed space is needed\nfor their characterization of sketchability. We resolve this question by\nproving that for arbitrarily large $n\\in \\mathbb{N}$ there is an $n$-point\nmetric space $(M(n),d_{M(n)})$ which is $O(1)$-sketchable yet for every\n$\\varepsilon\\in (0,\\frac12)$, if $\\alpha(n)\\geqslant 1$ and $f_n:M(n)\\to\n\\ell_{1-\\varepsilon}$ are such that $d_{M(n)}(x,y)\\leqslant\n\\|f_n(x)-f_n(y)\\|_{1-\\varepsilon}\\leqslant \\alpha(n) d_{M(n)}(x,y)$ for all\n$x,y\\in M(n)$, then necessarily $\\lim_{n\\to \\infty} \\alpha(n)= \\infty$.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 00:56:59 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["Khot", "Subhash", ""], ["Naor", "Assaf", ""]]}, {"id": "1810.04388", "submitter": "Ryan Slechta", "authors": "Tamal K. Dey and Ryan Slechta", "title": "Filtration Simplification for Persistent Homology via Edge Contraction", "comments": "15 pages including proofs and references, 5 figures, 2 tables. Full\n  version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG math.AT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Persistent homology is a popular data analysis technique that is used to\ncapture the changing topology of a filtration associated with some simplicial\ncomplex $K$. These topological changes are summarized in persistence diagrams.\nWe propose two contraction operators which when applied to $K$ and its\nassociated filtration, bound the perturbation in the persistence diagrams. The\nfirst assumes that the underlying space of $K$ is a $2$-manifold and ensures\nthat simplices are paired with the same simplices in the contracted complex as\nthey are in the original. The second is for arbitrary $d$-complexes, and bounds\nthe bottleneck distance between the initial and contracted $p$-dimensional\npersistence diagrams. This is accomplished by defining interleaving maps\nbetween persistence modules which arise from chain maps defined over the\nfiltrations. In addition, we show how the second operator can efficiently\ncompose across multiple contractions. We conclude with experiments\ndemonstrating the second operator's utility on manifolds.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 06:42:36 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["Dey", "Tamal K.", ""], ["Slechta", "Ryan", ""]]}, {"id": "1810.04625", "submitter": "Kai Suto", "authors": "Kai Suto, Akito Adachi, Tomohiro Tachi, Yasushi Yamaguchi", "title": "An Edge Extrusion-Approach to Generate Extruded Miura-Ori and Its Double\n  Tiling Origami Patterns", "comments": "16 pages, 17 figures, 7th International Meeting on Origami in\n  Science, Mathematics and Education (7OSME), September 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper proposes a family of origami tessellations called extruded\nMiura-Ori, whose folded state lies between two parallel planes with some faces\non the planes, potentially useful for folded core materials because of face\nbonding. An extruded Miura-Ori is obtained by cutting Miura-Ori apart along the\nedges and face diagonals before inserting the extrusion of the section edges.\nWe compute the extrusion direction to obtain a valid extruded Miura-Ori. The\nextruded Miura-Ori usually has three valid states. We analyse the third state\n(final folded state) in depth to show that a continuous family of parameters\ncan produce origami tessellations that can completely tile the top and bottom\nplanes.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 16:33:25 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Suto", "Kai", ""], ["Adachi", "Akito", ""], ["Tachi", "Tomohiro", ""], ["Yamaguchi", "Yasushi", ""]]}, {"id": "1810.04646", "submitter": "Aubrey Jaffer", "authors": "Aubrey G. Jaffer", "title": "The Lamb-Oseen Vortex and Paint Marbling", "comments": "7 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The displacement pattern arising from the decay of a two-dimensional\nLamb-Oseen vortex in a Newtonian fluid can be closely modeled by the\nclosed-form expression presented here. This formula enables Lamb-Oseen vortex\nsimulation orders of magnitude faster than can be accomplished using\nfinite-element methods, and without the accumulation of errors. \"French Curl\"\nmarbling patterns look as though they are created by a vortex. Analysis and\nsimulation of a nineteenth century example of French Curl finds that the\npattern was created without a vortex. True vortexes are rarely seen in paint\nmarbling because, in order to reach Reynolds numbers larger than 90, viscosity\nof the fluid bath must be much lower than is customarily used.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 17:10:30 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Jaffer", "Aubrey G.", ""]]}, {"id": "1810.04807", "submitter": "Tao Hou", "authors": "Tamal K. Dey, Tao Hou, Sayan Mandal", "title": "Persistent 1-Cycles: Definition, Computation, and Its Application", "comments": "Correct the algorithm numbering issue", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG math.AT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Persistence diagrams, which summarize the birth and death of homological\nfeatures extracted from data, are employed as stable signatures for\napplications in image analysis and other areas. Besides simply considering the\nmultiset of intervals included in a persistence diagram, some applications need\nto find representative cycles for the intervals. In this paper, we address the\nproblem of computing these representative cycles, termed as persistent\n1-cycles, for $\\text{H}_1$-persistent homology with $\\mathbb{Z}_2$\ncoefficients. The definition of persistent cycles is based on the interval\nmodule decomposition of persistence modules, which reveals the structure of\npersistent homology. After showing that the computation of the optimal\npersistent 1-cycles is NP-hard, we propose an alternative set of meaningful\npersistent 1-cycles that can be computed with an efficient polynomial time\nalgorithm. We also inspect the stability issues of the optimal persistent\n1-cycles and the persistent 1-cycles computed by our algorithm with the\nobservation that the perturbations of both cannot be properly bounded. We\ndesign a software which applies our algorithm to various datasets. Experiments\non 3D point clouds, mineral structures, and images show the effectiveness of\nour algorithm in practice.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 01:03:33 GMT"}, {"version": "v2", "created": "Mon, 15 Oct 2018 15:30:43 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Dey", "Tamal K.", ""], ["Hou", "Tao", ""], ["Mandal", "Sayan", ""]]}, {"id": "1810.04833", "submitter": "Zicong Zhou", "authors": "Zicong Zhou and Ben Hildebrandt and Xi Chen and Guojun Liao", "title": "Computational Technologies for Brain Morphometry", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we described a set of computational technologies for image\nanalysis with applications in Brain Morphometry. The proposed technologies are\nbased on a new Variational Principle which constructs a transformation with\nprescribed Jacobian determinant (which models local size changes) and\nprescribed curl-vector (which models local rotations). The goal of this\nresearch is to convince the image research community that Jacobian determinant\nas well as curl-vector should be used in all steps of image analysis.\nSpecifically, we develop an optimal control method for non-rigid registration;\na new concept and construction of average transformation; and a general robust\nmethod for construction of unbiased template from a set of images.\nComputational examples are presented to show the effects of curl-vector and the\neffectiveness of optimal control methods for non-rigid registration and our\nmethod for construction of unbiased template.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 03:38:02 GMT"}, {"version": "v2", "created": "Mon, 29 Oct 2018 20:18:38 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Zhou", "Zicong", ""], ["Hildebrandt", "Ben", ""], ["Chen", "Xi", ""], ["Liao", "Guojun", ""]]}, {"id": "1810.06514", "submitter": "Anpei Chen", "authors": "Anpei Chen, Minye Wu, Yingliang Zhang, Nianyi Li, Jie Lu, Shenghua\n  Gao, and Jingyi Yu", "title": "Deep Surface Light Fields", "comments": null, "journal-ref": null, "doi": "10.1145/3203192", "report-no": null, "categories": "cs.CG cs.CV cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A surface light field represents the radiance of rays originating from any\npoints on the surface in any directions. Traditional approaches require\nultra-dense sampling to ensure the rendering quality. In this paper, we present\na novel neural network based technique called deep surface light field or DSLF\nto use only moderate sampling for high fidelity rendering. DSLF automatically\nfills in the missing data by leveraging different sampling patterns across the\nvertices and at the same time eliminates redundancies due to the network's\nprediction capability. For real data, we address the image registration problem\nas well as conduct texture-aware remeshing for aligning texture edges with\nvertices to avoid blurring. Comprehensive experiments show that DSLF can\nfurther achieve high data compression ratio while facilitating real-time\nrendering on the GPU.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 16:56:58 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Chen", "Anpei", ""], ["Wu", "Minye", ""], ["Zhang", "Yingliang", ""], ["Li", "Nianyi", ""], ["Lu", "Jie", ""], ["Gao", "Shenghua", ""], ["Yu", "Jingyi", ""]]}, {"id": "1810.07072", "submitter": "Therese Biedl", "authors": "Therese Biedl", "title": "Segment representations with small resolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A segment representation of a graph is an assignment of line segments in 2D\nto the vertices in such a way that two segments intersect if and only if the\ncorresponding vertices are adjacent. Not all graphs have such segment\nrepresentations, but they exist, for example, for all planar graphs.\n  In this note, we study the resolution that can be achieved for segment\nrepresentations, presuming the ends of segments must be on integer grid points.\nWe show that any planar graph (and more generally, any graph that has a\nso-called $L$-representation) has a segment representation in a grid of width\nand height $4^n$.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 15:18:53 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Biedl", "Therese", ""]]}, {"id": "1810.07346", "submitter": "Bahman Kalantari", "authors": "Bahman Kalantari and Yikai Zhang", "title": "Spherical Triangle Algorithm: A Fast Oracle for Convex Hull Membership\n  Queries", "comments": "21 pages, 8 figures, 9 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The it Convex Hull Membership(CHM) problem is: Given a point $p$ and a subset\n$S$ of $n$ points in $\\mathbb{R}^m$, is $p \\in conv(S)$? CHM is not only a\nfundamental problem in Linear Programming, Computational Geometry, Machine\nLearning and Statistics, it also serves as a query problem in many applications\ne.g. Topic Modeling, LP Feasibility, Data Reduction. The {\\it Triangle\nAlgorithm} (TA) \\cite{kalantari2015characterization} either computes an\napproximate solution in the convex hull, or a separating hyperplane. The {\\it\nSpherical}-CHM is a CHM, where $p=0$ and each point in $S$ has unit norm.\nFirst, we prove the equivalence of exact and approximate versions of CHM and\nSpherical-CHM. On the one hand, this makes it possible to state a simple\nversion of the original TA. On the other hand, we prove that under the\nsatisfiability of a simple condition in each iteration, the complexity improves\nto $O(1/\\varepsilon)$. The analysis also suggests a strategy for when the\nproperty does not hold at an iterate. This suggests the \\textit{Spherical-TA}\nwhich first converts a given CHM into a Spherical-CHM before applying the\nalgorithm. Next we introduce a series of applications of Spherical-TA. In\nparticular, Spherical-TA serves as a fast version of vanilla TA to boost its\nefficiency. As an example, this results in a fast version of \\emph{AVTA}\n\\cite{awasthi2018robust}, called \\emph{AVTA$^+$} for solving exact or\napproximate irredundancy problem. Computationally, we have considered CHM, LP\nand Strict LP Feasibility and the Irredundancy problem. Based on substantial\namount of computing, Spherical-TA achieves better efficiency than state of the\nart algorithms. Leveraging on the efficiency of Spherical-TA, we propose\nAVTA$^+$ as a pre-processing step for data reduction which arises in such\napplications as in computing the Minimum Volume Enclosing Ellipsoid\n\\cite{moshtagh2005minimum}.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 01:36:01 GMT"}, {"version": "v2", "created": "Fri, 5 Apr 2019 18:05:01 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Kalantari", "Bahman", ""], ["Zhang", "Yikai", ""]]}, {"id": "1810.08008", "submitter": "Esther Galby", "authors": "Nicolas Champseix, Esther Galby, Bernard Ries", "title": "Planar CPG graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that for any $k \\geq 0$, there exists a planar graph which is\n$B_{k+1}$-CPG but not $B_k$-CPG. As a consequence, we obtain that $B_k$-CPG is\na strict subclass of $B_{k+1}$-CPG.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 12:26:03 GMT"}], "update_date": "2018-10-19", "authors_parsed": [["Champseix", "Nicolas", ""], ["Galby", "Esther", ""], ["Ries", "Bernard", ""]]}, {"id": "1810.08218", "submitter": "Luciano A. Romero Calla", "authors": "Luciano A. Romero Calla and Lizeth J. Fuentes Perez and Anselmo A.\n  Montenegro", "title": "A minimalistic approach for fast computation of geodesic distances on\n  triangular meshes", "comments": "Preprint submitted to Computers & Graphics", "journal-ref": null, "doi": "10.1016/j.cag.2019.08.014", "report-no": null, "categories": "cs.CG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The computation of geodesic distances is an important research topic in\nGeometry Processing and 3D Shape Analysis as it is a basic component of many\nmethods used in these areas. In this work, we present a minimalistic parallel\nalgorithm based on front propagation to compute approximate geodesic distances\non meshes. Our method is practical and simple to implement and does not require\nany heavy pre-processing. The convergence of our algorithm depends on the\nnumber of discrete level sets around the source points from which distance\ninformation propagates. To appropriately implement our method on GPUs taking\ninto account memory coalescence problems, we take advantage of a graph\nrepresentation based on a breadth-first search traversal that works\nharmoniously with our parallel front propagation approach. We report\nexperiments that show how our method scales with the size of the problem. We\ncompare the mean error and processing time obtained by our method with such\nmeasures computed using other methods. Our method produces results in\ncompetitive times with almost the same accuracy, especially for large meshes.\nWe also demonstrate its use for solving two classical geometry processing\nproblems: the regular sampling problem and the Voronoi tessellation on meshes.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 18:01:13 GMT"}, {"version": "v2", "created": "Tue, 16 Apr 2019 16:33:01 GMT"}, {"version": "v3", "created": "Sun, 23 Jun 2019 02:42:30 GMT"}, {"version": "v4", "created": "Wed, 31 Jul 2019 08:06:00 GMT"}, {"version": "v5", "created": "Fri, 23 Aug 2019 21:38:42 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Calla", "Luciano A. Romero", ""], ["Perez", "Lizeth J. Fuentes", ""], ["Montenegro", "Anselmo A.", ""]]}, {"id": "1810.08266", "submitter": "Luciano A. Romero Calla", "authors": "Lizeth J. Fuentes Perez, Luciano A. Romero Calla, Anselmo A.\n  Montenegro, Claudio Mura, Renato Pajarola", "title": "A Robust Feature-aware Sparse Mesh Representation", "comments": "Preprint submitted to Pacific Graphics", "journal-ref": null, "doi": "10.2312/pg.20201226", "report-no": null, "categories": "cs.CG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The sparse representation of signals defined on Euclidean domains has been\nsuccessfully applied in signal processing. Bringing the power of sparse\nrepresentations to non-regular domains is still a challenge, but promising\napproaches have started emerging recently. In this paper, we investigate the\nproblem of sparsely representing discrete surfaces and propose a new\nrepresentation that is capable of providing tools for solving different\ngeometry processing problems. The sparse discrete surface representation is\nobtained by combining innovative approaches into an integrated method. First,\nto deal with irregular mesh domains, we devised a new way to subdivide discrete\nmeshes into a set of patches using a feature-aware seed sampling. Second, we\nachieve good surface approximation with over-fitting control by combining the\npower of a continuous global dictionary representation with a modified\nOrthogonal Marching Pursuit. The discrete surface approximation results\nproduced were able to preserve the shape features while being robust to\nover-fitting. Our results show that the method is quite promising for\napplications like surface re-sampling and mesh compression.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 20:19:27 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2020 22:25:46 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Perez", "Lizeth J. Fuentes", ""], ["Calla", "Luciano A. Romero", ""], ["Montenegro", "Anselmo A.", ""], ["Mura", "Claudio", ""], ["Pajarola", "Renato", ""]]}, {"id": "1810.08310", "submitter": "Mustafa Hajij", "authors": "Mustafa Hajij, Paul Rosen", "title": "An Efficient Data Retrieval Parallel Reeb Graph Algorithm", "comments": "30 pages, 25 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Reeb graph of a scalar function defined on a domain gives a topologically\nmeaningful summary of that domain. Reeb graphs have been shown in the past\ndecade to be of great importance in geometric processing, image processing,\ncomputer graphics, and computational topology. The demand for analyzing large\ndata sets has increased in the last decade. Hence the parallelization of\ntopological computations needs to be more fully considered. We propose a\nparallel augmented Reeb graph algorithm on triangulated meshes with and without\na boundary. That is, in addition to our parallel algorithm for computing a Reeb\ngraph, we describe a method for extracting the original manifold data from the\nReeb graph structure. We demonstrate the running time of our algorithm on\nstandard datasets. As an application, we show how our algorithm can be utilized\nin mesh segmentation algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 23:49:26 GMT"}, {"version": "v2", "created": "Tue, 26 Nov 2019 05:09:51 GMT"}, {"version": "v3", "created": "Thu, 13 Aug 2020 02:47:37 GMT"}, {"version": "v4", "created": "Mon, 12 Oct 2020 04:30:47 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Hajij", "Mustafa", ""], ["Rosen", "Paul", ""]]}, {"id": "1810.08383", "submitter": "Minghao Tian", "authors": "Matthew Kahle, Minghao Tian, Yusu Wang", "title": "Local cliques in ER-perturbed random geometric graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random graphs are mathematical models that have applications in a wide range\nof domains. We study the following model where one adds Erd\\H{o}s--R\\'enyi (ER)\ntype perturbation to a random geometric graph. More precisely, assume\n$G_\\mathcal{X}^{*}$ is a random geometric graph sampled from a nice measure on\na metric space $\\mathcal{X} = (X,d)$. The input observed graph\n$\\widehat{G}(p,q)$ is generated by removing each existing edge from\n$G_\\mathcal{X}^*$ with probability $p$, while inserting each non-existent edge\nto $G_\\mathcal{X}^{*}$ with probability $q$. We refer to such random\n$p$-deletion and $q$-insertion as ER-perturbation. Although these graphs are\nrelated to the objects in the continuum percolation theory, our understanding\nof them is still rather limited. In this paper we consider a localized version\nof the classical notion of clique number for the aforementioned ER-perturbed\nrandom geometric graphs: Specifically, we study the edge clique number for each\nedge in a graph, defined as the size of the largest clique(s) in the graph\ncontaining that edge. The clique number of the graph is simply the largest edge\nclique number. Interestingly, given a ER-perturbed random geometric graph, we\nshow that the edge clique number presents two fundamentally different types of\nbehaviors, depending on which \"type\" of randomness it is generated from. As an\napplication of the above results, we show that by using a filtering process\nbased on the edge clique number, we can recover the shortest-path metric of the\nrandom geometric graph $G_\\mathcal{X}^*$ within a multiplicative factor of $3$,\nfrom an ER-perturbed observed graph $\\widehat{G}(p,q)$, for a significantly\nwider range of insertion probability $q$ than in previous work.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 07:56:04 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 21:20:08 GMT"}, {"version": "v3", "created": "Sun, 16 Jun 2019 18:51:34 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Kahle", "Matthew", ""], ["Tian", "Minghao", ""], ["Wang", "Yusu", ""]]}, {"id": "1810.08661", "submitter": "Olivier Coulaud", "authors": "Alain Franc (BioGeCo, PLEIADE), Pierre Blanchard (PLEIADE, HiePACS),\n  Olivier Coulaud (HiePACS)", "title": "Nonlinear Mapping and Distance Geometry", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG math.MG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distance Geometry Problem (DGP) and Nonlinear Mapping (NLM) are two well\nestablished questions: Distance Geometry Problem is about finding a Euclidean\nrealization of an incomplete set of distances in a Euclidean space, whereas\nNonlinear Mapping is a weighted Least Square Scaling (LSS) method. We show how\nall these methods (LSS, NLM, DGP) can be assembled in a common framework, being\neach identified as an instance of an optimization problem with a choice of a\nweight matrix. We study the continuity between the solutions (which are point\nclouds) when the weight matrix varies, and the compactness of the set of\nsolutions (after centering). We finally study a numerical example, showing that\nsolving the optimization problem is far from being simple and that the\nnumerical solution for a given procedure may be trapped in a local minimum.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 08:23:55 GMT"}, {"version": "v2", "created": "Thu, 9 May 2019 11:50:40 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Franc", "Alain", "", "BioGeCo, PLEIADE"], ["Blanchard", "Pierre", "", "PLEIADE, HiePACS"], ["Coulaud", "Olivier", "", "HiePACS"]]}, {"id": "1810.09232", "submitter": "Ahmad Biniaz", "authors": "Ahmad Biniaz, Sergio Cabello, Paz Carmi, Jean-Lou De Carufel, Anil\n  Maheshwari, Saeed Mehrabi, and Michiel Smid", "title": "On the Minimum Consistent Subset Problem", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $P$ be a set of $n$ colored points in the plane. Introduced by Hart\n(1968), a consistent subset of $P$, is a set $S\\subseteq P$ such that for every\npoint $p$ in $P\\setminus S$, the closest point of $p$ in $S$ has the same color\nas $p$. The consistent subset problem is to find a consistent subset of $P$\nwith minimum cardinality. This problem is known to be NP-complete even for\ntwo-colored point sets. Since the initial presentation of this problem, aside\nfrom the hardness results, there has not been a significant progress from the\nalgorithmic point of view. In this paper we present the following algorithmic\nresults:\n  1. The first subexponential-time algorithm for the consistent subset problem.\n  2. An $O(n\\log n)$-time algorithm that finds a consistent subset of size two\nin two-colored point sets (if such a subset exists). Towards our proof of this\nrunning time we present a deterministic $O(n \\log n)$-time algorithm for\ncomputing a variant of the compact Voronoi diagram; this improves the\npreviously claimed expected running time.\n  3. An $O(n\\log^2 n)$-time algorithm that finds a minimum consistent subset in\ntwo-colored point sets where one color class contains exactly one point; this\nimproves the previous best known $O(n^2)$ running time which is due to Wilfong\n(SoCG 1991).\n  4. An $O(n)$-time algorithm for the consistent subset problem on collinear\npoints; this improves the previous best known $O(n^2)$ running time.\n  5. A non-trivial $O(n^6)$-time dynamic programming algorithm for the\nconsistent subset problem on points arranged on two parallel lines.\n  To obtain these results, we combine tools from planar separators,\nadditively-weighted Voronoi diagrams with respect to convex distance functions,\npoint location in farthest-point Voronoi diagrams, range trees, paraboloid\nlifting, minimum covering of a circle with arcs, and several geometric\ntransformations.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 13:10:05 GMT"}, {"version": "v2", "created": "Mon, 26 Nov 2018 14:19:04 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Biniaz", "Ahmad", ""], ["Cabello", "Sergio", ""], ["Carmi", "Paz", ""], ["De Carufel", "Jean-Lou", ""], ["Maheshwari", "Anil", ""], ["Mehrabi", "Saeed", ""], ["Smid", "Michiel", ""]]}, {"id": "1810.09482", "submitter": "Brendan Mumey", "authors": "Brendan Mumey", "title": "A Note on Indexing Point Sets for Approximate Bottleneck Distance\n  Queries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The {\\em bottleneck distance} is a natural measure of the distance between\ntwo finite point sets of equal cardinality, defined as the minimum over all\nbijections between the point sets of the maximum distance between any pair of\npoints put in correspondence by the bijection. In this work, we consider the\nproblem of building a data structure $\\mathbb{D}$ that indexes a collection of\n$m$ planar point sets (of varying sizes) and supports nearest bottleneck\ndistance queries: given a query point set $Q$ of size $n$, we would like to\nfind the point set(s) $P \\in \\mathbb{D}$ of size $n$ that are closest in terms\nof bottleneck distance. Without loss of generality, we assume that all point\nsets belong to the unit box $[0,1]^2$ in the plane and focus on the $L_\\infty$\nnorm, although the techniques can also be used for other norms. The main\ncontribution is a {\\em trie}-based data structure finds a $6$-approximate\nnearest neighbor in $O(-\\lg(d_B(\\mathbb{D},Q)) n)$ time, where\n$d_B(\\mathbb{D},Q)$ is the minimum bottleneck distance from $Q$ to any point\nset in $\\mathbb{D}$.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 18:10:06 GMT"}, {"version": "v2", "created": "Fri, 4 Jan 2019 02:16:02 GMT"}, {"version": "v3", "created": "Wed, 5 May 2021 17:55:40 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Mumey", "Brendan", ""]]}, {"id": "1810.09948", "submitter": "Jonathan Zheng", "authors": "Jonathan X. Zheng, Samraat Pawar, Dan F. M. Goodman", "title": "Further Towards Unambiguous Edge Bundling: Investigating Power-Confluent\n  Drawings for Network Visualization", "comments": "Resubmitted to IEEE Transactions on Visualization and Computer\n  Graphics on 02/09/19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Bach et al. [1] recently presented an algorithm for constructing confluent\ndrawings, by leveraging power graph decomposition to generate an auxiliary\nrouting graph. We identify two issues with their method which we call the node\nsplit and short-circuit problems, and solve both by modifying the routing graph\nto retain the hierarchical structure of power groups. We also classify the\nexact type of confluent drawings that the algorithm can produce as\n'power-confluent', and prove that it is a subclass of the previously studied\n'strict confluent' drawing. A description and source code of our implementation\nis also provided, which additionally includes an improved method for power\ngraph construction.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 16:27:41 GMT"}, {"version": "v2", "created": "Fri, 29 Mar 2019 17:11:47 GMT"}, {"version": "v3", "created": "Tue, 25 Jun 2019 13:39:14 GMT"}, {"version": "v4", "created": "Mon, 2 Sep 2019 14:49:35 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Zheng", "Jonathan X.", ""], ["Pawar", "Samraat", ""], ["Goodman", "Dan F. M.", ""]]}, {"id": "1810.10231", "submitter": "Alexander Pilz", "authors": "Alexander Pilz, Patrick Schnider", "title": "Extending the centerpoint theorem to multiple points", "comments": "Presented at the 29th International Symposium on Algorithms and\n  Computation (ISAAC 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The centerpoint theorem is a well-known and widely used result in discrete\ngeometry. It states that for any point set $P$ of $n$ points in $\\mathbb{R}^d$,\nthere is a point $c$, not necessarily from $P$, such that each halfspace\ncontaining $c$ contains at least $\\frac{n}{d+1}$ points of $P$. Such a point\n$c$ is called a centerpoint, and it can be viewed as a generalization of a\nmedian to higher dimensions. In other words, a centerpoint can be interpreted\nas a good representative for the point set $P$. But what if we allow more than\none representative? For example in one-dimensional data sets, often certain\nquantiles are chosen as representatives instead of the median. We present a\npossible extension of the concept of quantiles to higher dimensions. The idea\nis to find a set $Q$ of (few) points such that every halfspace that contains\none point of $Q$ contains a large fraction of the points of $P$ and every\nhalfspace that contains more of $Q$ contains an even larger fraction of $P$.\nThis setting is comparable to the well-studied concepts of weak\n$\\varepsilon$-nets and weak $\\varepsilon$-approximations, where it is stronger\nthan the former but weaker than the latter.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 07:55:16 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Pilz", "Alexander", ""], ["Schnider", "Patrick", ""]]}, {"id": "1810.10466", "submitter": "Wolfgang Mulzer", "authors": "Pankaj K. Agarwal, Haim Kaplan, Geva Kipper, Wolfgang Mulzer, G\\\"unter\n  Rote, Micha Sharir, Allen Xiao", "title": "Approximate Minimum-Weight Matching with Outliers under Translation", "comments": "13 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our goal is to compare two planar point sets by finding subsets of a given\nsize such that a minimum-weight matching between them has the smallest weight.\nThis can be done by a translation of one set that minimizes the weight of the\nmatching. We give efficient algorithms (a) for finding approximately optimal\nmatchings, when the cost of a matching is the $L_p$-norm of the tuple of the\nEuclidean distances between the pairs of matched points, for any $p\\in\n[1,\\infty]$, and (b)~for constructing small-size approximate minimization (or\nmatching) diagrams: partitions of the translation space into regions, together\nwith an approximate optimal matching for each region.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 16:02:52 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Agarwal", "Pankaj K.", ""], ["Kaplan", "Haim", ""], ["Kipper", "Geva", ""], ["Mulzer", "Wolfgang", ""], ["Rote", "G\u00fcnter", ""], ["Sharir", "Micha", ""], ["Xiao", "Allen", ""]]}, {"id": "1810.10795", "submitter": "Martin Siggel", "authors": "Martin Siggel, Jan Kleinert, Tobias Stollenwerk, and Reinhold Maierl", "title": "TiGL - An Open Source Computational Geometry Library for Parametric\n  Aircraft Design", "comments": null, "journal-ref": "Math.Comput.Sci. (2019)", "doi": "10.1007/s11786-019-00401-y", "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the software TiGL: TiGL is an open source high-fidelity\ngeometry modeler that is used in the conceptual and preliminary aircraft and\nhelicopter design phase. It creates full three-dimensional models of aircraft\nfrom their parametric CPACS description. Due to its parametric nature, it is\ntypically used for aircraft design analysis and optimization. First, we present\nthe use-case and architecture of TiGL. Then, we discuss it's geometry module,\nwhich is used to generate the B-spline based surfaces of the aircraft. The\nbackbone of TiGL is its surface generator for curve network interpolation,\nbased on Gordon surfaces. One major part of this paper explains the\nmathematical foundation of Gordon surfaces on B-splines and how we achieve the\nrequired curve network compatibility. Finally, TiGL's aircraft component module\nis introduced, which is used to create the external and internal parts of\naircraft, such as wings, flaps, fuselages, engines or structural elements.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 09:13:10 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Siggel", "Martin", ""], ["Kleinert", "Jan", ""], ["Stollenwerk", "Tobias", ""], ["Maierl", "Reinhold", ""]]}, {"id": "1810.10813", "submitter": "Steve Oudot", "authors": "Steve Oudot and Elchanan Solomon", "title": "Inverse Problems in Topological Persistence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AT cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this survey, we review the literature on inverse problems in topological\npersistence theory. The first half of the survey is concerned with the question\nof surjectivity, i.e. the existence of right inverses, and the second half\nfocuses on injectivity, i.e. left inverses. Throughout, we highlight the tools\nand theorems that underlie these advances, and direct the reader's attention to\nopen problems, both theoretical and applied.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 09:59:40 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Oudot", "Steve", ""], ["Solomon", "Elchanan", ""]]}, {"id": "1810.10933", "submitter": "Reed Williams", "authors": "Reed M. Williams, Horea T. Ilie\\c{s}", "title": "Practical Shape Analysis and Segmentation Methods for Point Cloud Models", "comments": "21 pages, 20 figures. To appear in The Journal of Computer Aided\n  Geometric Design's Special Issue on Heat Diffusion Equation and Optimal\n  Transport in Geometry Processing and Computer Graphics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CV cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current point cloud processing algorithms do not have the capability to\nautomatically extract semantic information from the observed scenes, except in\nvery specialized cases. Furthermore, existing mesh analysis paradigms cannot be\ndirectly employed to automatically perform typical shape analysis tasks\ndirectly on point cloud models.\n  We present a potent framework for shape analysis, similarity, and\nsegmentation of noisy point cloud models for real objects of engineering\ninterest, models that may be incomplete. The proposed framework relies on\nspectral methods and the heat diffusion kernel to construct compact shape\nsignatures, and we show that the framework supports a variety of clustering\ntechniques that have traditionally been applied only on mesh models. We\ndeveloped and implemented one practical and convergent estimate of the\nLaplace-Beltrami operator for point clouds as well as a number of clustering\ntechniques adapted to work directly on point clouds to produce geometric\nfeatures of engineering interest. The key advantage of this framework is that\nit supports practical shape analysis capabilities that operate directly on\npoint cloud models of objects without requiring surface reconstruction or\nglobal meshing. We show that the proposed technique is robust against typical\nnoise present in possibly incomplete point clouds, and segment point clouds\nscanned by depth cameras (e.g. Kinect) into semantically-meaningful sub-shapes.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 15:38:30 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Williams", "Reed M.", ""], ["Ilie\u015f", "Horea T.", ""]]}, {"id": "1810.10977", "submitter": "Erva Ulu", "authors": "Yining Wang and Erva Ulu and Aarti Singh and Levent Burak Kara", "title": "Efficient Load Sampling for Worst-Case Structural Analysis Under Force\n  Location Uncertainty", "comments": "Proceedings of the ASME 2018 International Design Engineering\n  Technical Conferences & Computers and Information in Engineering Conference\n  (IDETC/CIE 2018) (In Print)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CG cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important task in structural design is to quantify the structural\nperformance of an object under the external forces it may experience during its\nuse. The problem proves to be computationally very challenging as the external\nforces' contact locations and magnitudes may exhibit significant variations. We\npresent an efficient analysis approach to determine the most critical force\ncontact location in such problems with force location uncertainty. Given an\ninput 3D model and regions on its boundary where arbitrary normal forces may\nmake contact, our algorithm predicts the worst-case force configuration\nresponsible for creating the highest stress within the object. Our approach\nuses a computationally tractable experimental design method to select number of\nsample force locations based on geometry only, without inspecting the stress\nresponse that requires computationally expensive finite-element analysis. Then,\nwe construct a simple regression model on these samples and corresponding\nmaximum stresses. Combined with a simple ranking based post-processing step,\nour method provides a practical solution to worst-case structural analysis\nproblem. The results indicate that our approach achieves significant\nimprovements over the existing work and brute force approaches. We demonstrate\nthat further speed- up can be obtained when small amount of an error tolerance\nin maximum stress is allowed.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 16:55:23 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Wang", "Yining", ""], ["Ulu", "Erva", ""], ["Singh", "Aarti", ""], ["Kara", "Levent Burak", ""]]}, {"id": "1810.11517", "submitter": "Woojin Kim", "authors": "Woojin Kim and Facundo Memoli", "title": "Generalized Persistence Diagrams for Persistence Modules over Posets", "comments": "47 pages, 8 Figures. Made changes suggested by anonymous reviewers", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AT cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When a category $\\mathcal{C}$ satisfies certain conditions, we define the\nnotion of \\emph{rank invariant} for arbitrary poset-indexed functors\n$F:\\mathbf{P} \\rightarrow \\mathcal{C}$ from a category theory perspective. This\ngeneralizes the standard notion of rank invariant as well as Patel's recent\nextension. Specifically, the barcode of any interval decomposable persistence\nmodules $F:\\mathbf{P} \\rightarrow \\mathbf{vec}$ of finite dimensional vector\nspaces can be extracted from the rank invariant by the principle of\ninclusion-exclusion. Generalizing this idea allows freedom of choosing the\nindexing poset $\\mathbf{P}$ of $F: \\mathbf{P} \\rightarrow \\mathcal{C}$ in\ndefining Patel's generalized persistence diagram of $F$. Of particular\nimportance is the fact that the generalized persistence diagram of $F$ is\ndefined regardless of whether $F$ is interval decomposable or not. By\nspecializing our idea to zigzag persistence modules, we also show that the\nbarcode of a Reeb graph can be obtained in a purely set-theoretic setting\nwithout passing to the category of vector spaces. This leads to a promotion of\nPatel's semicontinuity theorem about type $\\mathcal{A}$ persistence diagram to\nLipschitz continuity theorem for the category of sets.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 20:05:09 GMT"}, {"version": "v2", "created": "Thu, 25 Apr 2019 13:40:41 GMT"}, {"version": "v3", "created": "Thu, 1 Aug 2019 21:46:50 GMT"}, {"version": "v4", "created": "Tue, 7 Jul 2020 20:34:02 GMT"}, {"version": "v5", "created": "Sat, 21 Nov 2020 05:17:26 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Kim", "Woojin", ""], ["Memoli", "Facundo", ""]]}, {"id": "1810.11628", "submitter": "Mahdi Imanparast", "authors": "Mahdi Imanparast, Seyed Naser Hashemi", "title": "Better approximation algorithm for point-set diameter", "comments": "arXiv admin note: substantial text overlap with arXiv:1610.08543", "journal-ref": "IAENG International Journal of Computer Science 46 (4), 594-598,\n  2019", "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new $(1+O(\\varepsilon))$-approximation algorithm with $O(n+\n1/\\varepsilon^{\\frac{(d-1)}{2}})$ running time for computing the diameter of a\nset of $n$ points in the $d$-dimensional Euclidean space for a fixed dimension\n$d$, where $0 < \\varepsilon\\leqslant 1$. This result provides some improvements\nin the running time of this problem in comparison with previous algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 27 Oct 2018 10:46:04 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Imanparast", "Mahdi", ""], ["Hashemi", "Seyed Naser", ""]]}, {"id": "1810.11704", "submitter": "Noah Giansiracusa", "authors": "Noah Giansiracusa and Cameron Ricciardi", "title": "Computational geometry and the U.S. Supreme Court", "comments": "14 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CY physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use the United States Supreme Court as an illuminative context in which to\ndiscuss three different spatial voting preference models: an instance of the\nwidely used single-peaked preferences, and two models that are more novel in\nwhich vote outcomes have a strength in addition to a location. We introduce\neach model from a formal axiomatic perspective, briefly discuss practical\nmotivation for each in terms of judicial behavior, prove mathematical\nrelationships among the voting coalitions compatible with each model, and then\nstudy the two-dimensional setting by presenting computational tools for working\nwith the models and by exploring these with judicial voting data from the\nSupreme Court.\n", "versions": [{"version": "v1", "created": "Sat, 27 Oct 2018 20:57:06 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Giansiracusa", "Noah", ""], ["Ricciardi", "Cameron", ""]]}, {"id": "1810.12826", "submitter": "Sariel Har-Peled", "authors": "Sariel Har-Peled and Soham Mazumdar", "title": "Coresets for $k$-Means and $k$-Median Clustering and their Applications", "comments": "Paper appeared in STOC 2004", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  $\\renewcommand{\\Re}{{\\rm I\\!\\hspace{-0.025em} R}}\n\\newcommand{\\eps}{{\\varepsilon}} \\newcommand{\\Coreset}{{\\mathcal{S}}} $ In this\npaper, we show the existence of small coresets for the problems of computing\n$k$-median and $k$-means clustering for points in low dimension. In other\nwords, we show that given a point set $P$ in $\\Re^d$, one can compute a\nweighted set $\\Coreset \\subseteq P$, of size $O(k \\eps^{-d} \\log{n})$, such\nthat one can compute the $k$-median/means clustering on $\\Coreset$ instead of\non $P$, and get an $(1+\\eps)$-approximation.\n  As a result, we improve the fastest known algorithms for\n$(1+\\eps)$-approximate $k$-means and $k$-median clustering. Our algorithms have\nlinear running time for a fixed $k$ and $\\eps$. In addition, we can maintain\nthe $(1+\\eps)$-approximate $k$-median or $k$-means clustering of a stream when\npoints are being only inserted, using polylogarithmic space and update time.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 15:55:58 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Har-Peled", "Sariel", ""], ["Mazumdar", "Soham", ""]]}, {"id": "1810.13251", "submitter": "Ryo Suzuki", "authors": "Ryo Suzuki, Koji Yatani, Mark D. Gross, Tom Yeh", "title": "Tabby: Explorable Design for 3D Printing Textures", "comments": "Pacific Graphics 2018. arXiv admin note: substantial text overlap\n  with arXiv:1703.05700", "journal-ref": null, "doi": "10.2312/pg.20181273", "report-no": null, "categories": "cs.HC cs.CG cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents Tabby, an interactive and explorable design tool for 3D\nprinting textures. Tabby allows texture design with direct manipulation in the\nfollowing workflow: 1) select a target surface, 2) sketch and manipulate a\ntexture with 2D drawings, and then 3) generate 3D printing textures onto an\narbitrary curved surface. To enable efficient texture creation, Tabby leverages\nan auto-completion approach which automates the tedious, repetitive process of\napplying texture, while allowing flexible customization. Our user evaluation\nstudy with seven participants confirms that Tabby can effectively support the\ndesign exploration of different patterns for both novice and experienced users.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 17:40:06 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Suzuki", "Ryo", ""], ["Yatani", "Koji", ""], ["Gross", "Mark D.", ""], ["Yeh", "Tom", ""]]}, {"id": "1810.13297", "submitter": "Marcel Radermacher", "authors": "Lukas Barth, Guido Br\\\"uckner, Paul Jungeblut, Marcel Radermacher", "title": "Multilevel Planarity", "comments": "Preliminary work appeared in the Proceedings of the 13th\n  International Conference and Workshops on Algorithms and Computation (WALCOM\n  2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce and study the multilevel-planarity testing\nproblem, which is a generalization of upward planarity and level planarity. Let\n$G = (V, E)$ be a directed graph and let $\\ell: V \\to \\mathcal P(\\mathbb Z)$ be\na function that assigns a finite set of integers to each vertex. A\nmultilevel-planar drawing of $G$ is a planar drawing of $G$ such that the\n$y$-coordinate of each vertex $v \\in V$ is $y(v) \\in \\ell(v)$, and each edge is\ndrawn as a strictly $y$-monotone curve. We present linear-time algorithms for\ntesting multilevel planarity of embedded graphs with a single source and of\noriented cycles. Complementing these algorithmic results, we show that\nmultilevel-planarity testing is NP-complete even in very restricted cases.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 14:18:11 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Barth", "Lukas", ""], ["Br\u00fcckner", "Guido", ""], ["Jungeblut", "Paul", ""], ["Radermacher", "Marcel", ""]]}]