[{"id": "1612.00343", "submitter": "Da Chen", "authors": "Da Chen and Jean-Marie Mirebeau and Laurent D. Cohen", "title": "Global Minimum for a Finsler Elastica Minimal Path Approach", "comments": "Improve the clarity of this manuscript", "journal-ref": "International Journal of Computer Vision, Volume 122, Issue 3, pp\n  458-483, 2017", "doi": "10.1007/s11263-016-0975-5", "report-no": null, "categories": "cs.CG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel curvature-penalized minimal path model via\nan orientation-lifted Finsler metric and the Euler elastica curve. The original\nminimal path model computes the globally minimal geodesic by solving an Eikonal\npartial differential equation (PDE). Essentially, this first-order model is\nunable to penalize curvature which is related to the path rigidity property in\nthe classical active contour models. To solve this problem, we present an\nEikonal PDE-based Finsler elastica minimal path approach to address the\ncurvature-penalized geodesic energy minimization problem. We were successful at\nadding the curvature penalization to the classical geodesic energy. The basic\nidea of this work is to interpret the Euler elastica bending energy via a novel\nFinsler elastica metric that embeds a curvature penalty. This metric is\nnon-Riemannian, anisotropic and asymmetric, and is defined over an\norientation-lifted space by adding to the image domain the orientation as an\nextra space dimension. Based on this orientation lifting, the proposed minimal\npath model can benefit from both the curvature and orientation of the paths.\nThanks to the fast marching method, the global minimum of the\ncurvature-penalized geodesic energy can be computed efficiently. We introduce\ntwo anisotropic image data-driven speed functions that are computed by\nsteerable filters. Based on these orientation-dependent speed functions, we can\napply the proposed Finsler elastica minimal path model to the applications of\nclosed contour detection, perceptual grouping and tubular structure extraction.\nNumerical experiments on both synthetic and real images show that these\napplications of the proposed model indeed obtain promising results.\n", "versions": [{"version": "v1", "created": "Thu, 1 Dec 2016 16:45:30 GMT"}, {"version": "v2", "created": "Tue, 23 May 2017 16:57:04 GMT"}, {"version": "v3", "created": "Mon, 21 May 2018 11:44:20 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Chen", "Da", ""], ["Mirebeau", "Jean-Marie", ""], ["Cohen", "Laurent D.", ""]]}, {"id": "1612.00908", "submitter": "Artem Chernikov", "authors": "Artem Chernikov, David Galvin and Sergei Starchenko", "title": "Cutting lemma and Zarankiewicz's problem in distal structures", "comments": "v.2: 29 pages, 3 figures; minor corrections/clarifications throughout\n  the article; Theorem 5.7 has been generalized to allow distal cell\n  decompositions of arbitrary exponent t, and more details were added in the\n  proof; accepted to Selecta Mathematica", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.CG math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We establish a cutting lemma for definable families of sets in distal\nstructures, as well as the optimality of the distal cell decomposition for\ndefinable families of sets on the plane in $o$-minimal expansions of fields.\nUsing it, we generalize the results in [J. Fox, J. Pach, A. Sheffer, A. Suk,\nand J. Zahl. \"A semi-algebraic version of Zarankiewicz's problem\"] on the\nsemialgebraic planar Zarankiewicz problem to arbitrary $o$-minimal structures,\nin particular obtaining an $o$-minimal generalization of the\nSzemer\\'edi-Trotter theorem.\n", "versions": [{"version": "v1", "created": "Sat, 3 Dec 2016 01:20:25 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 21:54:48 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Chernikov", "Artem", ""], ["Galvin", "David", ""], ["Starchenko", "Sergei", ""]]}, {"id": "1612.01335", "submitter": "Elena Arseneva", "authors": "Elena Khramtcova and Evanthia Papadopoulou", "title": "Randomized Incremental Construction for the Hausdorff Voronoi Diagram of\n  point clusters", "comments": "18 pages, 4 figures", "journal-ref": null, "doi": "10.1007/s10878-018-0347-x", "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper applies the randomized incremental construction (RIC) framework to\ncomputing the Hausdorff Voronoi diagram of a family of k clusters of points in\nthe plane. The total number of points is n. The diagram is a generalization of\nVoronoi diagrams based on the Hausdorff distance function. The combinatorial\ncomplexity of the Hausdorff Voronoi diagram is O(n+m), where m is the total\nnumber of crossings between pairs of clusters. For non-crossing clusters (m=0),\nour algorithm works in expected O(n log n + k log n log k) time and\ndeterministic\n  O(n) space. For arbitrary clusters (m=O(n^2)), the algorithm runs in expected\nO((m+n log k) log n) time and O(m +n log k) space. When clusters cross,\nbisectors are disconnected curves resulting in disconnected Voronoi regions\nthat challenge the incremental construction. This paper applies the RIC\nparadigm to a Voronoi diagram with disconnected regions and disconnected\nbisectors, for the first time.\n", "versions": [{"version": "v1", "created": "Mon, 5 Dec 2016 13:02:30 GMT"}, {"version": "v2", "created": "Mon, 3 Sep 2018 15:38:01 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Khramtcova", "Elena", ""], ["Papadopoulou", "Evanthia", ""]]}, {"id": "1612.01370", "submitter": "Carsten Grimm", "authors": "Jean-Lou De Carufel, Carsten Grimm, Anil Maheshwari, Stefan Schirra,\n  and Michiel Smid", "title": "Minimizing the Continuous Diameter when Augmenting a Geometric Tree with\n  a Shortcut", "comments": "A preliminary version of this work was presented at the 15th\n  International Symposium on Algorithms and Data Structures (WADS~2017), July\n  31 to August 2, 2017, St. John's, NL, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We augment a tree $T$ with a shortcut $pq$ to minimize the largest distance\nbetween any two points along the resulting augmented tree $T+pq$. We study this\nproblem in a continuous and geometric setting where $T$ is a geometric tree in\nthe Euclidean plane, where a shortcut is a line segment connecting any two\npoints along the edges of $T$, and we consider all points on $T+pq$ (i.e.,\nvertices and points along edges) when determining the largest distance along\n$T+pq$. We refer to the largest distance between any two points along edges as\nthe continuous diameter to distinguish it from the discrete diameter, i.e., the\nlargest distance between any two vertices.\n  We establish that a single shortcut is sufficient to reduce the continuous\ndiameter of a geometric tree $T$ if and only if the intersection of all\ndiametral paths of $T$ is neither a line segment nor a single point. We\ndetermine an optimal shortcut for a geometric tree with $n$ straight-line edges\nin $O(n \\log n)$ time. Apart from the running time, our results extend to\ngeometric trees whose edges are rectifiable curves. The algorithm for trees\ngeneralizes our algorithm for paths.\n", "versions": [{"version": "v1", "created": "Mon, 5 Dec 2016 14:29:01 GMT"}, {"version": "v2", "created": "Fri, 25 Aug 2017 15:28:00 GMT"}, {"version": "v3", "created": "Mon, 28 Aug 2017 18:56:48 GMT"}, {"version": "v4", "created": "Fri, 20 Oct 2017 12:24:35 GMT"}], "update_date": "2017-10-23", "authors_parsed": [["De Carufel", "Jean-Lou", ""], ["Grimm", "Carsten", ""], ["Maheshwari", "Anil", ""], ["Schirra", "Stefan", ""], ["Smid", "Michiel", ""]]}, {"id": "1612.01400", "submitter": "Shrisha Rao", "authors": "Apoorva Honnegowda Roopa and Shrisha Rao", "title": "A Distance Function for Comparing Straight-Edge Geometric Figures", "comments": "29 pages, 12 figures including appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper defines a distance function that measures the dissimilarity\nbetween planar geometric figures formed with straight lines. This function can\nin turn be used in partial matching of different geometric figures. For a given\npair of geometric figures that are graphically isomorphic, one function\nmeasures the angular dissimilarity and another function measures the edge\nlength disproportionality. The distance function is then defined as the convex\nsum of these two functions. The novelty of the presented function is that it\nsatisfies all properties of a distance function and the computation of the same\nis done by projecting appropriate features to a cartesian plane. To compute the\ndeviation from the angular similarity property, the Euclidean distance between\nthe given angular pairs and the corresponding points on the $y=x$ line is\nmeasured. Further while computing the deviation from the edge length\nproportionality property, the best fit line, for the set of edge lengths, which\npasses through the origin is found, and the Euclidean distance between the\ngiven edge length pairs and the corresponding point on a $y=mx$ line is\ncalculated. Iterative Proportional Fitting Procedure (IPFP) is used to find\nthis best fit line. We demonstrate the behavior of the defined function for\nsome sample pairs of figures.\n", "versions": [{"version": "v1", "created": "Fri, 25 Nov 2016 01:19:55 GMT"}], "update_date": "2016-12-06", "authors_parsed": [["Roopa", "Apoorva Honnegowda", ""], ["Rao", "Shrisha", ""]]}, {"id": "1612.01507", "submitter": "Santosh Vempala", "authors": "Yin Tat Lee and Santosh S. Vempala", "title": "Eldan's Stochastic Localization and the KLS Conjecture: Isoperimetry,\n  Concentration and Mixing", "comments": "This version merges arXiv:1612.01507 and arXiv:1712.01791", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.FA cs.CG cs.DS math.MG math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the Cheeger constant for $n$-dimensional isotropic logconcave\nmeasures is $O(n^{1/4})$, improving on the previous best bound of\n$O(n^{1/3}\\sqrt{\\log n}).$ As corollaries we obtain the same improved bound on\nthe thin-shell estimate, Poincar\\'{e} constant and Lipschitz concentration\nconstant and an alternative proof of this bound for the isotropic (slicing)\nconstant; it also follows that the ball walk for sampling from an isotropic\nlogconcave density in ${\\bf R}^{n}$ converges in $O^{*}(n^{2.5})$ steps from a\nwarm start. The proof is based on gradually transforming any logconcave density\nto one that has a significant Gaussian factor via a Martingale process.\n  Extending this proof technique, we prove that the log-Sobolev constant of any\nisotropic logconcave density in ${\\bf R}^{n}$ with support of diameter $D$ is\n$\\Omega(1/D)$, resolving a question posed by Frieze and Kannan in 1997. This is\nasymptotically the best possible estimate and improves on the previous bound of\n$\\Omega(1/D^{2})$ by Kannan-Lov\\'{a}sz-Montenegro. It follows that for any\nisotropic logconcave density, the ball walk with step size\n$\\delta=\\Theta(1/\\sqrt{n})$ mixes in $O\\left(n^{2}D\\right)$ proper steps from\n\\emph{any }starting point. This improves on the previous best bound of\n$O(n^{2}D^{2})$ and is also asymptotically tight.\n  The new bound leads to the following large deviation inequality for an\n$L$-Lipschitz function $g$ over an isotropic logconcave density $p$: for any\n$t>0$, \\[ Pr_{x\\sim p}\\left(\\left|g(x)-\\bar{g}\\right|\\geq L\\cdot\nt\\right)\\leq\\exp(-\\frac{c\\cdot t^{2}}{t+\\sqrt{n}}) \\] where $\\bar{g}$ is the\nmedian or mean of $g$ for $x\\sim p$; this generalizes and improves on previous\nbounds by Paouris and by Guedon-Milman. The technique also bounds the ``small\nball'' probability in terms of the Cheeger constant, and recovers the current\nbest bound.\n", "versions": [{"version": "v1", "created": "Mon, 5 Dec 2016 20:36:28 GMT"}, {"version": "v2", "created": "Fri, 9 Dec 2016 20:40:47 GMT"}, {"version": "v3", "created": "Sun, 27 Jan 2019 04:40:54 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Lee", "Yin Tat", ""], ["Vempala", "Santosh S.", ""]]}, {"id": "1612.01696", "submitter": "Guilherme D. da Fonseca", "authors": "Sunil Arya, Guilherme D. da Fonseca, David M. Mount", "title": "Optimal Approximate Polytope Membership", "comments": "SODA 2017", "journal-ref": null, "doi": "10.1137/1.9781611974782.18", "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the polytope membership problem, a convex polytope $K$ in $R^d$ is given,\nand the objective is to preprocess $K$ into a data structure so that, given a\nquery point $q \\in R^d$, it is possible to determine efficiently whether $q \\in\nK$. We consider this problem in an approximate setting and assume that $d$ is a\nconstant. Given an approximation parameter $\\varepsilon > 0$, the query can be\nanswered either way if the distance from $q$ to $K$'s boundary is at most\n$\\varepsilon$ times $K$'s diameter. Previous solutions to the problem were on\nthe form of a space-time trade-off, where logarithmic query time demands\n$O(1/\\varepsilon^{d-1})$ storage, whereas storage $O(1/\\varepsilon^{(d-1)/2})$\nadmits roughly $O(1/\\varepsilon^{(d-1)/8})$ query time. In this paper, we\npresent a data structure that achieves logarithmic query time with storage of\nonly $O(1/\\varepsilon^{(d-1)/2})$, which matches the worst-case lower bound on\nthe complexity of any $\\varepsilon$-approximating polytope. Our data structure\nis based on a new technique, a hierarchy of ellipsoids defined as\napproximations to Macbeath regions.\n  As an application, we obtain major improvements to approximate Euclidean\nnearest neighbor searching. Notably, the storage needed to answer\n$\\varepsilon$-approximate nearest neighbor queries for a set of $n$ points in\n$O(\\log \\frac{n}{\\varepsilon})$ time is reduced to $O(n/\\varepsilon^{d/2})$.\nThis halves the exponent in the $\\varepsilon$-dependency of the existing space\nbound of roughly $O(n/\\varepsilon^d)$, which has stood for 15 years (Har-Peled,\n2001).\n", "versions": [{"version": "v1", "created": "Tue, 6 Dec 2016 08:07:36 GMT"}], "update_date": "2018-01-11", "authors_parsed": [["Arya", "Sunil", ""], ["da Fonseca", "Guilherme D.", ""], ["Mount", "David M.", ""]]}, {"id": "1612.01944", "submitter": "Ke Liu", "authors": "Ke Liu, Ye Guo, Zeyun Yu", "title": "Porous Structure Design in Tissue Engineering Using Anisotropic Radial\n  Basis Function", "comments": "Department of Computer Science, University of Wisconsin Milwaukee", "journal-ref": "International Symposium on Visual Computing (ISVC) 2018, Advances\n  in Visual Computing, Lecture Notes in Computer Science, vol. 11241, pp. 79-90", "doi": "10.1007/978-3-030-03801-4_8", "report-no": null, "categories": "cs.GR cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Development of additive manufacturing in last decade greatly improves tissue\nengineering. During the manufacturing of porous scaffold, simplified but\nfunctionally equivalent models are getting focused for practically reasons.\nScaffolds can be classified into regular porous scaffolds and irregular porous\nscaffolds. Several methodologies are developed to design these scaffolds. A\nnovel method is proposed in this paper using anisotropic radial basis function\n(ARBF) interpolation. This is method uses geometric models such as volumetric\nmeshes as input and proves to be flexible because geometric models are able to\ncapture the characteristics of complex tissues easily. Moreover, this method is\nstraightforward and easy to implement.\n", "versions": [{"version": "v1", "created": "Tue, 6 Dec 2016 18:42:44 GMT"}, {"version": "v2", "created": "Mon, 23 Jan 2017 22:00:34 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Liu", "Ke", ""], ["Guo", "Ye", ""], ["Yu", "Zeyun", ""]]}, {"id": "1612.02149", "submitter": "Sergio Cabello", "authors": "Mark de Berg, Sergio Cabello, Otfried Cheong, David Eppstein,\n  Christian Knauer", "title": "Covering many points with a small-area box", "comments": null, "journal-ref": "J. Computational Geometry 10 (1): 207-222, 2019", "doi": "10.20382/jocg.v10i1a8", "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $P$ be a set of $n$ points in the plane. We show how to find, for a given\ninteger $k>0$, the smallest-area axis-parallel rectangle that covers $k$ points\nof $P$ in $O(nk^2 \\log n+ n\\log^2 n)$ time. We also consider the problem of,\ngiven a value $\\alpha>0$, covering as many points of $P$ as possible with an\naxis-parallel rectangle of area at most $\\alpha$. For this problem we give a\nprobabilistic $(1-\\varepsilon)$-approximation that works in near-linear time:\nIn $O((n/\\varepsilon^4)\\log^3 n \\log (1/\\varepsilon))$ time we find an\naxis-parallel rectangle of area at most $\\alpha$ that, with high probability,\ncovers at least $(1-\\varepsilon)\\mathrm{\\kappa^*}$ points, where\n$\\mathrm{\\kappa^*}$ is the maximum possible number of points that could be\ncovered.\n", "versions": [{"version": "v1", "created": "Wed, 7 Dec 2016 08:41:46 GMT"}, {"version": "v2", "created": "Fri, 25 May 2018 08:24:15 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["de Berg", "Mark", ""], ["Cabello", "Sergio", ""], ["Cheong", "Otfried", ""], ["Eppstein", "David", ""], ["Knauer", "Christian", ""]]}, {"id": "1612.02158", "submitter": "D\\\"om\\\"ot\\\"or P\\'alv\\\"olgyi", "authors": "Bal\\'azs Keszegh and D\\\"om\\\"ot\\\"or P\\'alv\\\"olgyi", "title": "Proper Coloring of Geometric Hypergraphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study whether for a given planar family F there is an m such that any\nfinite set of points can be 3-colored such that any member of F that contains\nat least m points contains two points with different colors. We conjecture that\nif F is a family of pseudo-disks, then such an m exists. We prove this in the\nspecial case when F is the family of all homothetic copies of a given convex\npolygon. We also study the problem in higher dimensions.\n", "versions": [{"version": "v1", "created": "Wed, 7 Dec 2016 09:12:00 GMT"}, {"version": "v2", "created": "Mon, 15 Apr 2019 21:30:30 GMT"}], "update_date": "2019-04-17", "authors_parsed": [["Keszegh", "Bal\u00e1zs", ""], ["P\u00e1lv\u00f6lgyi", "D\u00f6m\u00f6t\u00f6r", ""]]}, {"id": "1612.02261", "submitter": "Julie Digne", "authors": "Julie Digne and S\\'ebastien Valette and Rapha\\\"elle Chaine", "title": "Sparse Geometric Representation Through Local Shape Probing", "comments": null, "journal-ref": "IEEE Transactions on Visualization and Computer Graphics, 2017", "doi": "10.1109/TVCG.2017.2719024", "report-no": null, "categories": "cs.CG cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new shape analysis approach based on the non-local analysis of\nlocal shape variations. Our method relies on a novel description of shape\nvariations, called Local Probing Field (LPF), which describes how a local\nprobing operator transforms a pattern onto the shape. By carefully optimizing\nthe position and orientation of each descriptor, we are able to capture shape\nsimilarities and gather them into a geometrically relevant dictionary over\nwhich the shape decomposes sparsely. This new representation permits to handle\nshapes with mixed intrinsic dimensionality (e.g. shapes containing both\nsurfaces and curves) and to encode various shape features such as boundaries.\nOur shape representation has several potential applications; here we\ndemonstrate its efficiency for shape resampling and point set denoising for\nboth synthetic and real data.\n", "versions": [{"version": "v1", "created": "Wed, 7 Dec 2016 14:26:36 GMT"}, {"version": "v2", "created": "Thu, 2 Nov 2017 15:37:46 GMT"}], "update_date": "2017-11-03", "authors_parsed": [["Digne", "Julie", ""], ["Valette", "S\u00e9bastien", ""], ["Chaine", "Rapha\u00eblle", ""]]}, {"id": "1612.02412", "submitter": "Otfried Cheong", "authors": "Sang Won Bae, Mark de Berg, Otfried Cheong, Joachim Gudmundsson,\n  Christos Levcopoulos", "title": "Shortcuts for the Circle", "comments": "An extended abstract appeared in ISAAC 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.MG cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $C$ be the unit circle in $\\mathbb{R}^2$. We can view $C$ as a plane\ngraph whose vertices are all the points on $C$, and the distance between any\ntwo points on $C$ is the length of the smaller arc between them. We consider a\ngraph augmentation problem on $C$, where we want to place $k\\geq 1$\n\\emph{shortcuts} on $C$ such that the diameter of the resulting graph is\nminimized.\n  We analyze for each $k$ with $1\\leq k\\leq 7$ what the optimal set of\nshortcuts is. Interestingly, the minimum diameter one can obtain is not a\nstrictly decreasing function of~$k$. For example, with seven shortcuts one\ncannot obtain a smaller diameter than with six shortcuts. Finally, we prove\nthat the optimal diameter is $2 + \\Theta(1/k^{\\frac{2}{3}})$ for any~$k$.\n", "versions": [{"version": "v1", "created": "Wed, 7 Dec 2016 20:44:21 GMT"}, {"version": "v2", "created": "Wed, 25 Oct 2017 03:36:15 GMT"}], "update_date": "2017-10-26", "authors_parsed": [["Bae", "Sang Won", ""], ["de Berg", "Mark", ""], ["Cheong", "Otfried", ""], ["Gudmundsson", "Joachim", ""], ["Levcopoulos", "Christos", ""]]}, {"id": "1612.02483", "submitter": "Man-Kwun Chiu", "authors": "Man-Kwun Chiu, Matias Korman", "title": "High Dimensional Consistent Digital Segments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of digitalizing Euclidean line segments from\n$\\mathbb{R}^d$ to $\\mathbb{Z}^d$. Christ {\\em et al.} (DCG, 2012) showed how to\nconstruct a set of {\\em consistent digital segment} (CDS) for $d=2$: a\ncollection of segments connecting any two points in $\\mathbb{Z}^2$ that\nsatisfies the natural extension of the Euclidean axioms to $\\mathbb{Z}^d$. In\nthis paper we study the construction of CDSs in higher dimensions.\n  We show that any total order can be used to create a set of {\\em consistent\ndigital rays} CDR in $\\mathbb{Z}^d$ (a set of rays emanating from a fixed point\n$p$ that satisfies the extension of the Euclidean axioms). We fully\ncharacterize for which total orders the construction holds and study their\nHausdorff distance, which in particular positively answers the question posed\nby Christ {\\em et al.}.\n", "versions": [{"version": "v1", "created": "Wed, 7 Dec 2016 23:24:33 GMT"}], "update_date": "2016-12-09", "authors_parsed": [["Chiu", "Man-Kwun", ""], ["Korman", "Matias", ""]]}, {"id": "1612.02509", "submitter": "Ayushi Sinha", "authors": "Ayushi Sinha, Michael Kazhdan", "title": "Geodesics using Waves: Computing Distances using Wave Propagation", "comments": "10 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a new method for computing approximate geodesic\ndistances. We introduce the wave method for approximating geodesic distances\nfrom a point on a manifold mesh. Our method involves the solution of two linear\nsystems of equations. One system of equations is solved repeatedly to propagate\nthe wave on the entire mesh, and one system is solved once after wave\npropagation is complete in order to compute the approximate geodesic distances\nup to an additive constant. However, these systems need to be pre-factored only\nonce, and can be solved efficiently at each iteration. All of our tests\nrequired approximately between 300 and 400 iterations, which were completed in\na few seconds. Therefore, this method can approximate geodesic distances\nquickly, and the approximation is highly accurate.\n", "versions": [{"version": "v1", "created": "Thu, 8 Dec 2016 01:57:47 GMT"}], "update_date": "2016-12-09", "authors_parsed": [["Sinha", "Ayushi", ""], ["Kazhdan", "Michael", ""]]}, {"id": "1612.02861", "submitter": "Jose Perea", "authors": "Jose A. Perea", "title": "Multiscale Projective Coordinates via Persistent Cohomology of Sparse\n  Filtrations", "comments": "Final version to appear in Discrete & Computational Geometry", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AT cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present in this paper a framework which leverages the underlying topology\nof a data set, in order to produce appropriate coordinate representations. In\nparticular, we show how to construct maps to real and complex projective\nspaces, given appropriate persistent cohomology classes. An initial map is\nobtained in two steps: First, the persistent cohomology of a sparse filtration\nis used to compute systems of transition functions for (real and complex) line\nbundles over neighborhoods of the data. Next, the transition functions are used\nto produce explicit classifying maps for the induced bundles. A framework for\ndimensionality reduction in projective space (Principal Projective Components)\nis also developed, aimed at decreasing the target dimension of the original\nmap. Several examples are provided as well as theorems addressing choices in\nthe construction.\n", "versions": [{"version": "v1", "created": "Thu, 8 Dec 2016 22:33:16 GMT"}, {"version": "v2", "created": "Mon, 12 Dec 2016 17:12:07 GMT"}, {"version": "v3", "created": "Wed, 9 Aug 2017 15:34:26 GMT"}], "update_date": "2017-08-10", "authors_parsed": [["Perea", "Jose A.", ""]]}, {"id": "1612.02905", "submitter": "Ramsay Dyer", "authors": "Jean-Daniel Boissonnat and Ramsay Dyer and Arijit Ghosh and Nikolay\n  Martynchuk", "title": "An obstruction to Delaunay triangulations in Riemannian manifolds", "comments": "This is a revision and extension of a note that appeared as an\n  appendix in the (otherwise unpublished) report arXiv:1303.6493", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG math.DG math.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Delaunay has shown that the Delaunay complex of a finite set of points $P$ of\nEuclidean space $\\mathbb{R}^m$ triangulates the convex hull of $P$, provided\nthat $P$ satisfies a mild genericity property. Voronoi diagrams and Delaunay\ncomplexes can be defined for arbitrary Riemannian manifolds. However,\nDelaunay's genericity assumption no longer guarantees that the Delaunay complex\nwill yield a triangulation; stronger assumptions on $P$ are required. A natural\none is to assume that $P$ is sufficiently dense. Although results in this\ndirection have been claimed, we show that sample density alone is insufficient\nto ensure that the Delaunay complex triangulates a manifold of dimension\ngreater than 2.\n", "versions": [{"version": "v1", "created": "Fri, 9 Dec 2016 04:10:03 GMT"}], "update_date": "2016-12-12", "authors_parsed": [["Boissonnat", "Jean-Daniel", ""], ["Dyer", "Ramsay", ""], ["Ghosh", "Arijit", ""], ["Martynchuk", "Nikolay", ""]]}, {"id": "1612.02967", "submitter": "Aleksejs Fomins", "authors": "Aleksejs Fomins and Benedikt Oswald", "title": "Dune-CurvilinearGrid: Parallel Dune Grid Manager for Unstructured\n  Tetrahedral Curvilinear Meshes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the dune-curvilineargrid module. The module provides the\nself-contained, parallel grid manager, as well as the underlying elementary\ncurvilinear geometry module dune-curvilineargeometry. This work is motivated by\nthe need for reliable and scalable electromagnetic design of nanooptical\ndevices. Curvilinear geometries improve both the accuracy of modeling smooth\nmaterial boundaries, and the h/p-convergence rate of PDE solutions, reducing\nthe necessary computational effort. dune-curvilineargrid provides a large\nspectrum of features for scalable parallel implementations of Finite Element\nand Boundary Integral methods over curvilinear tetrahedral geometries,\nincluding symbolic polynomial mappings and operations, recursive integration,\nsparse and dense grid communication, parallel timing and memory footprint\ndiagnostics utilities. It is written in templated C++ using MPI for\nparallelization and ParMETIS for grid partitioning, and is provided as a module\nfor the DUNE interface. The dune-curvilineargrid grid manager is continuously\ndeveloped and improved, and so is this documentation. For the most recent\nversion of the documentation, as well as the source code, please refer to the\nprovided repositories and our website.\n", "versions": [{"version": "v1", "created": "Fri, 9 Dec 2016 10:31:04 GMT"}], "update_date": "2016-12-12", "authors_parsed": [["Fomins", "Aleksejs", ""], ["Oswald", "Benedikt", ""]]}, {"id": "1612.03195", "submitter": "Or Yair", "authors": "Or Yair, Ronen Talmon, Ronald R. Coifman, and Ioannis G. Kevrekidis", "title": "No equations, no parameters, no variables: data, and the reconstruction\n  of normal forms by learning informed observation geometries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "nlin.PS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The discovery of physical laws consistent with empirical observations lies at\nthe heart of (applied) science and engineering. These laws typically take the\nform of nonlinear differential equations depending on parameters, dynamical\nsystems theory provides, through the appropriate normal forms, an \"intrinsic\",\nprototypical characterization of the types of dynamical regimes accessible to a\ngiven model. Using an implementation of data-informed geometry learning we\ndirectly reconstruct the relevant \"normal forms\": a quantitative mapping from\nempirical observations to prototypical realizations of the underlying dynamics.\nInterestingly, the state variables and the parameters of these realizations are\ninferred from the empirical observations, without prior knowledge or\nunderstanding, they parametrize the dynamics {\\em intrinsically}, without\nexplicit reference to fundamental physical quantities.\n", "versions": [{"version": "v1", "created": "Wed, 30 Nov 2016 14:27:53 GMT"}], "update_date": "2016-12-13", "authors_parsed": [["Yair", "Or", ""], ["Talmon", "Ronen", ""], ["Coifman", "Ronald R.", ""], ["Kevrekidis", "Ioannis G.", ""]]}, {"id": "1612.03638", "submitter": "Tillmann Miltzow", "authors": "Jean Cardinal and Stefan Felsner and Tillmann Miltzow and Casey\n  Tompkins and Birgit Vogtenhuber", "title": "Intersection Graphs of Rays and Grounded Segments", "comments": "16 pages 12 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CC cs.CG math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider several classes of intersection graphs of line segments in the\nplane and prove new equality and separation results between those classes. In\nparticular, we show that: (1) intersection graphs of grounded segments and\nintersection graphs of downward rays form the same graph class, (2) not every\nintersection graph of rays is an intersection graph of downward rays, and (3)\nnot every intersection graph of rays is an outer segment graph. The first\nresult answers an open problem posed by Cabello and Jej\\v{c}i\\v{c}. The third\nresult confirms a conjecture by Cabello. We thereby completely elucidate the\nremaining open questions on the containment relations between these classes of\nsegment graphs. We further characterize the complexity of the recognition\nproblems for the classes of outer segment, grounded segment, and ray\nintersection graphs. We prove that these recognition problems are complete for\nthe existential theory of the reals. This holds even if a 1-string realization\nis given as additional input.\n", "versions": [{"version": "v1", "created": "Mon, 12 Dec 2016 12:10:02 GMT"}], "update_date": "2016-12-13", "authors_parsed": [["Cardinal", "Jean", ""], ["Felsner", "Stefan", ""], ["Miltzow", "Tillmann", ""], ["Tompkins", "Casey", ""], ["Vogtenhuber", "Birgit", ""]]}, {"id": "1612.03735", "submitter": "Israela Solomon", "authors": "Israela Solomon", "title": "A Note on Testing Intersection of Convex Sets in Sublinear Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a simple sublinear time algorithm for testing the following\ngeometric property. Let $P_1, ..., P_n$ be $n$ convex sets in $\\mathbb{R}^d$\n($n \\gg d$), such as polytopes, balls, etc. We assume that the complexity of\neach set depends only on $d$ (and not on the number of sets $n$). We test the\nproperty that there exists a common point in all sets, i.e. that their\nintersection is nonempty. Our goal is to distinguish between the case where the\nintersection is nonempty, and the case where even after removing many of the\nsets the intersection is empty. In particular, our algorithm returns PASS if\nall of the $n$ sets intersect, and returns FAIL with probability at least\n$1-\\epsilon$ if no point belongs to $\\frac{\\alpha}{d+1} n$ sets, for any given\n$0 < \\alpha, \\epsilon < 1$.\n", "versions": [{"version": "v1", "created": "Sun, 4 Dec 2016 23:36:09 GMT"}], "update_date": "2016-12-13", "authors_parsed": [["Solomon", "Israela", ""]]}, {"id": "1612.03854", "submitter": "Therese Biedl", "authors": "Therese Biedl, Markus Chimani, Martin Derka, Petra Mutzel", "title": "Crossing Number for Graphs With Bounded Pathwidth", "comments": "Full version of paper that will appear at ISAAC'17", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The crossing number is the smallest number of pairwise edge-crossings when\ndrawing a graph into the plane. There are only very few graph classes for which\nthe exact crossing number is known or for which there at least exist constant\napproximation ratios. Furthermore, up to now, general crossing number\ncomputations have never been successfully tackled using bounded width of graph\ndecompositions, like treewidth or pathwidth.\n  In this paper, we for the first time show that crossing number is tractable\n(even in linear time) for maximal graphs of bounded pathwidth~3. The technique\nalso shows that the crossing number and the rectilinear (a.k.a. straight-line)\ncrossing number are identical for this graph class, and that we require only an\n$O(n)\\times O(n)$-grid to achieve such a drawing.\n  Our techniques can further be extended to devise a 2-approximation for\ngeneral graphs with pathwidth 3, and a $4w^3$-approximation for maximal graphs\nof pathwidth $w$. This is a constant approximation for bounded pathwidth\ngraphs.\n", "versions": [{"version": "v1", "created": "Mon, 12 Dec 2016 19:12:47 GMT"}, {"version": "v2", "created": "Thu, 12 Oct 2017 00:18:11 GMT"}], "update_date": "2017-10-13", "authors_parsed": [["Biedl", "Therese", ""], ["Chimani", "Markus", ""], ["Derka", "Martin", ""], ["Mutzel", "Petra", ""]]}, {"id": "1612.04304", "submitter": "Aleksandar Nikolov", "authors": "Daniel Dadush, Shashwat Garg, Shachar Lovett, Aleksandar Nikolov", "title": "Towards a Constructive Version of Banaszczyk's Vector Balancing Theorem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG math.FA math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important theorem of Banaszczyk (Random Structures & Algorithms `98)\nstates that for any sequence of vectors of $\\ell_2$ norm at most $1/5$ and any\nconvex body $K$ of Gaussian measure $1/2$ in $\\mathbb{R}^n$, there exists a\nsigned combination of these vectors which lands inside $K$. A major open\nproblem is to devise a constructive version of Banaszczyk's vector balancing\ntheorem, i.e. to find an efficient algorithm which constructs the signed\ncombination.\n  We make progress towards this goal along several fronts. As our first\ncontribution, we show an equivalence between Banaszczyk's theorem and the\nexistence of $O(1)$-subgaussian distributions over signed combinations. For the\ncase of symmetric convex bodies, our equivalence implies the existence of a\nuniversal signing algorithm (i.e. independent of the body), which simply\nsamples from the subgaussian sign distribution and checks to see if the\nassociated combination lands inside the body. For asymmetric convex bodies, we\nprovide a novel recentering procedure, which allows us to reduce to the case\nwhere the body is symmetric.\n  As our second main contribution, we show that the above framework can be\nefficiently implemented when the vectors have length $O(1/\\sqrt{\\log n})$,\nrecovering Banaszczyk's results under this stronger assumption. More precisely,\nwe use random walk techniques to produce the required $O(1)$-subgaussian\nsigning distributions when the vectors have length $O(1/\\sqrt{\\log n})$, and\nuse a stochastic gradient ascent method to implement the recentering procedure\nfor asymmetric bodies.\n", "versions": [{"version": "v1", "created": "Tue, 13 Dec 2016 18:12:44 GMT"}], "update_date": "2016-12-14", "authors_parsed": [["Dadush", "Daniel", ""], ["Garg", "Shashwat", ""], ["Lovett", "Shachar", ""], ["Nikolov", "Aleksandar", ""]]}, {"id": "1612.04571", "submitter": "Wenlong Mou", "authors": "Wenlong Mou, Liwei Wang", "title": "A Refined Analysis of LSH for Well-dispersed Data Points", "comments": "Paper accepted to SIAM Conference on Analytic Algorithmics and\n  Combinatorics (ANALCO) 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Near neighbor problems are fundamental in algorithms for high-dimensional\nEuclidean spaces. While classical approaches suffer from the curse of\ndimensionality, locality sensitive hashing (LSH) can effectively solve\na-approximate r-near neighbor problem, and has been proven to be optimal in the\nworst case. However, for real-world data sets, LSH can naturally benefit from\nwell-dispersed data and low doubling dimension, leading to significantly\nimproved performance. In this paper, we address this issue and propose a\nrefined analyses for running time of approximating near neighbors queries via\nLSH. We characterize dispersion of data using N_b, the number of b*r-near pairs\namong the data points. Combined with optimal data-oblivious LSH scheme, we get\na new query time bound depending on N_b and doubling dimension. For many\nnatural scenarios where points are well-dispersed or lying in a\nlow-doubling-dimension space, our result leads to sharper performance than\nexisting worst-case analysis. This paper not only present first rigorous proof\non how LSHs make use of the structure of data points, but also provide\nimportant insights into parameter setting in the practice of LSH beyond worst\ncase. Besides, the techniques in our analysis involve a generalized version of\nsphere packing problem, which might be of some independent interest.\n", "versions": [{"version": "v1", "created": "Wed, 14 Dec 2016 10:52:01 GMT"}], "update_date": "2016-12-15", "authors_parsed": [["Mou", "Wenlong", ""], ["Wang", "Liwei", ""]]}, {"id": "1612.04774", "submitter": "Xu Xu", "authors": "Xu Xu, Sinisa Todorovic", "title": "Beam Search for Learning a Deep Convolutional Neural Network of 3D\n  Shapes", "comments": "ICPR 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses 3D shape recognition. Recent work typically represents a\n3D shape as a set of binary variables corresponding to 3D voxels of a uniform\n3D grid centered on the shape, and resorts to deep convolutional neural\nnetworks(CNNs) for modeling these binary variables. Robust learning of such\nCNNs is currently limited by the small datasets of 3D shapes available, an\norder of magnitude smaller than other common datasets in computer vision.\nRelated work typically deals with the small training datasets using a number of\nad hoc, hand-tuning strategies. To address this issue, we formulate CNN\nlearning as a beam search aimed at identifying an optimal CNN architecture,\nnamely, the number of layers, nodes, and their connectivity in the network, as\nwell as estimating parameters of such an optimal CNN. Each state of the beam\nsearch corresponds to a candidate CNN. Two types of actions are defined to add\nnew convolutional filters or new convolutional layers to a parent CNN, and thus\ntransition to children states. The utility function of each action is\nefficiently computed by transferring parameter values of the parent CNN to its\nchildren, thereby enabling an efficient beam search. Our experimental\nevaluation on the 3D ModelNet dataset demonstrates that our model pursuit using\nthe beam search yields a CNN with superior performance on 3D shape\nclassification than the state of the art.\n", "versions": [{"version": "v1", "created": "Wed, 14 Dec 2016 19:06:05 GMT"}], "update_date": "2016-12-15", "authors_parsed": [["Xu", "Xu", ""], ["Todorovic", "Sinisa", ""]]}, {"id": "1612.04780", "submitter": "Csaba D. Toth", "authors": "Hugo A. Akitaya, Rajasekhar Inkulu, Torrie L. Nichols, Diane L.\n  Souvaine, Csaba D. T\\'oth, Charles R. Winston", "title": "Minimum Weight Connectivity Augmentation for Planar Straight-Line Graphs", "comments": "15 pages, 7 figures, to appear in the Proceedings of WALCOM 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider edge insertion and deletion operations that increase the\nconnectivity of a given planar straight-line graph (PSLG), while minimizing the\ntotal edge length of the output. We show that every connected PSLG $G=(V,E)$ in\ngeneral position can be augmented to a 2-connected PSLG $(V,E\\cup E^+)$ by\nadding new edges of total Euclidean length $\\|E^+\\|\\leq 2\\|E\\|$, and this bound\nis the best possible. An optimal edge set $E^+$ can be computed in $O(|V|^4)$\ntime; however the problem becomes NP-hard when $G$ is disconnected. Further,\nthere is a sequence of edge insertions and deletions that transforms a\nconnected PSLG $G=(V,E)$ into a planar straight-line cycle $G'=(V,E')$ such\nthat $\\|E'\\|\\leq 2\\|{\\rm MST}(V)\\|$, and the graph remains connected with edge\nlength below $\\|E\\|+\\|{\\rm MST}(V)\\|$ at all stages. These bounds are the best\npossible.\n", "versions": [{"version": "v1", "created": "Wed, 14 Dec 2016 19:33:00 GMT"}], "update_date": "2016-12-15", "authors_parsed": [["Akitaya", "Hugo A.", ""], ["Inkulu", "Rajasekhar", ""], ["Nichols", "Torrie L.", ""], ["Souvaine", "Diane L.", ""], ["T\u00f3th", "Csaba D.", ""], ["Winston", "Charles R.", ""]]}, {"id": "1612.04861", "submitter": "Anna Lubiw", "authors": "Cody Barnson, Dawn Chandler, Qiao Chen, Christina Chung, Andrew\n  Coccimiglio, Sean La, Lily Li, A\\\"ina Linn, Anna Lubiw, Clare Lyle, Shikha\n  Mahajan, Gregory Mierzwinski, Simon Pratt, Yoon Su (Matthias) Yoo, Hongbo\n  Zhang, Kevin Zhang", "title": "Some Counterexamples for Compatible Triangulations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the conjecture by Aichholzer, Aurenhammer, Hurtado, and Krasser\nthat any two points sets with the same cardinality and the same size convex\nhull can be triangulated in the \"same\" way, more precisely via \\emph{compatible\ntriangulations}. We show counterexamples to various strengthened versions of\nthis conjecture.\n", "versions": [{"version": "v1", "created": "Fri, 9 Dec 2016 13:00:53 GMT"}], "update_date": "2016-12-16", "authors_parsed": [["Barnson", "Cody", "", "Matthias"], ["Chandler", "Dawn", "", "Matthias"], ["Chen", "Qiao", "", "Matthias"], ["Chung", "Christina", "", "Matthias"], ["Coccimiglio", "Andrew", "", "Matthias"], ["La", "Sean", "", "Matthias"], ["Li", "Lily", "", "Matthias"], ["Linn", "A\u00efna", "", "Matthias"], ["Lubiw", "Anna", "", "Matthias"], ["Lyle", "Clare", "", "Matthias"], ["Mahajan", "Shikha", "", "Matthias"], ["Mierzwinski", "Gregory", "", "Matthias"], ["Pratt", "Simon", "", "Matthias"], ["Su", "Yoon", "", "Matthias"], ["Yoo", "", ""], ["Zhang", "Hongbo", ""], ["Zhang", "Kevin", ""]]}, {"id": "1612.04890", "submitter": "Yuan Li", "authors": "Jie Xue, Yuan Li", "title": "Stochastic closest-pair problem and most-likely nearest-neighbor search\n  in tree spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $T$ be a tree space (or tree network) represented by a weighted tree with\n$t$ vertices, and $S$ be a set of $n$ stochastic points in $T$, each of which\nhas a fixed location with an independent existence probability. We investigate\ntwo fundamental problems under such a stochastic setting, the closest-pair\nproblem and the nearest-neighbor search. For the former, we study the\ncomputation of the $\\ell$-threshold probability and the expectation of the\nclosest-pair distance of a realization of $S$. We propose the first algorithm\nto compute the $\\ell$-threshold probability in $O(t+n\\log n+ \\min\\{tn,n^2\\})$\ntime for any given threshold $\\ell$, which immediately results in an\n$O(t+\\min\\{tn^3,n^4\\})$-time algorithm for computing the expected closest-pair\ndistance. Based on this, we further show that one can compute a\n$(1+\\varepsilon)$-approximation for the expected closest-pair distance in\n$O(t+\\varepsilon^{-1}\\min\\{tn^2,n^3\\})$ time, by arguing that the expected\nclosest-pair distance can be approximated via $O(\\varepsilon^{-1}n)$ threshold\nprobability queries. For the latter, we study the $k$ most-likely\nnearest-neighbor search ($k$-LNN) via a notion called $k$ most-likely Voronoi\nDiagram ($k$-LVD). We show that the size of the $k$-LVD $\\varPsi_T^S$ of $S$ on\n$T$ is bounded by $O(kn)$ if the existence probabilities of the points in $S$\nare constant-far from 0. Furthermore, we establish an $O(kn)$ average-case\nupper bound for the size of $\\varPsi_T^S$, by regarding the existence\nprobabilities as i.i.d. random variables drawn from some fixed distribution.\nOur results imply the existence of an LVD data structure which answers $k$-LNN\nqueries in $O(\\log n+k)$ time using average-case $O(t+k^2n)$ space, and\nworst-case $O(t+kn^2)$ space if the existence probabilities are constant-far\nfrom 0. Finally, we also give an $O(t+ n^2\\log n+n^2k)$-time algorithm to\nconstruct the LVD data structure.\n", "versions": [{"version": "v1", "created": "Thu, 15 Dec 2016 00:17:43 GMT"}], "update_date": "2016-12-16", "authors_parsed": [["Xue", "Jie", ""], ["Li", "Yuan", ""]]}, {"id": "1612.05101", "submitter": "Oren Salzman", "authors": "Oren Salzman, Siddhartha Srinivasa", "title": "Open problem on risk-aware planning in the plane", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of planning a collision-free path of a robot in the\npresence of risk zones. The robot is allowed to travel in these zones but is\npenalized in a super-linear fashion for consecutive accumulative time spent\nthere. We recently suggested a natural cost function that balances path length\nand risk-exposure time. When no risk zones exists, our problem resorts to\ncomputing minimal-length paths which is known to be computationally hard in the\nnumber of dimensions. It is well known that in two-dimensions computing\nminimal-length paths can be done efficiently. Thus, a natural question we pose\nis \"Is our problem computationally hard or not?\" If the problem is hard, we\nwish to find an approximation algorithm to compute a near-optimal path. If not,\nthen a polynomial-time algorithm should be found.\n", "versions": [{"version": "v1", "created": "Thu, 15 Dec 2016 15:03:57 GMT"}, {"version": "v2", "created": "Thu, 9 Mar 2017 14:09:06 GMT"}], "update_date": "2017-03-10", "authors_parsed": [["Salzman", "Oren", ""], ["Srinivasa", "Siddhartha", ""]]}, {"id": "1612.06954", "submitter": "Yuan Li", "authors": "Jie Xue, Yuan Li", "title": "On Dominance-Free Samples of a (Colored) Stochastic Dataset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A point $p \\in \\mathbb{R}^d$ is said to dominate another point $q \\in\n\\mathbb{R}^d$ if the coordinate of $p$ is greater than or equal to the\ncoordinate of $q$ in every dimension. A set of points in $\\mathbb{R}^d$ is\ndominance-free if any two points do not dominate each other. We consider the\nproblem of counting the dominance-free subsets of a given dataset in\n$\\mathbb{R}^d$, or more generally, computing the probability that a random\nsample of a stochastic dataset in $\\mathbb{R}^d$ where each point is sampled\nindependently with its existence probability is dominance-free. In fact, we\ninvestigate a colored generalization of the problem, in which the points in the\ngiven stochastic dataset are colored and we are interested in the random\nsamples that are inter-color dominance-free (i.e., any two points with\ndifferent colors do not dominate each other). We propose the first algorithm\nthat solves the problem for $d=2$ in near-quadratic time. On the other hand, we\nshow that the problem is #P-hard for any $d \\geq 3$, even if the points have a\nrestricted color pattern; this implies the #P-hardness of the uncolored version\n(i.e., computing the dominance-free probability of a uncolored stochastic\ndataset) for $d \\geq 3$. In addition, we show that even when the existence\nprobabilities of the points are all equal to 0.5, the problem remains #P-hard\nfor any $d \\geq 7$; this implies the #P-hardness of counting dominance-free\nsubsets for $d \\geq 7$. In order to prove our hardness results, we establish\nsome results about embedding the vertices a graph into low-dimensional\nEuclidean space such that two vertices are connected by an edge in the graph\niff they form a dominance pair in the embedding. These results may be of\nindependent interest and can possibly be applied to other problems.\n", "versions": [{"version": "v1", "created": "Wed, 21 Dec 2016 02:43:53 GMT"}, {"version": "v2", "created": "Tue, 3 Jan 2017 14:51:30 GMT"}, {"version": "v3", "created": "Sun, 25 Feb 2018 04:17:30 GMT"}, {"version": "v4", "created": "Fri, 18 Dec 2020 05:20:45 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Xue", "Jie", ""], ["Li", "Yuan", ""]]}, {"id": "1612.07276", "submitter": "Martin Derka", "authors": "Martin Derka, Therese Biedl", "title": "Splitting $B_2$-VPG graphs into outer-string and co-comparability graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we show that any $B_2$-VPG graph (i.e., an intersection graph\nof orthogonal curves with at most 2 bends) can be decomposed into $O(\\log n)$\nouterstring graphs or $O(\\log^3 n)$ permutation graphs. This leads to better\napproximation algorithms for hereditary graph problems, such as independent\nset, clique and clique cover, on $B_2$-VPG graphs.\n", "versions": [{"version": "v1", "created": "Wed, 21 Dec 2016 18:58:17 GMT"}], "update_date": "2016-12-22", "authors_parsed": [["Derka", "Martin", ""], ["Biedl", "Therese", ""]]}, {"id": "1612.07405", "submitter": "Ioannis Psarros", "authors": "Georgia Avarikioti, Ioannis Z. Emiris, Ioannis Psarros, and Georgios\n  Samaras", "title": "Practical linear-space Approximate Near Neighbors in high dimension", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The $c$-approximate Near Neighbor problem in high dimensional spaces has been\nmainly addressed by Locality Sensitive Hashing (LSH), which offers polynomial\ndependence on the dimension, query time sublinear in the size of the dataset,\nand subquadratic space requirement. For practical applications, linear space is\ntypically imperative. Most previous work in the linear space regime focuses on\nthe case that $c$ exceeds $1$ by a constant term. In a recently accepted paper,\noptimal bounds have been achieved for any $c>1$ \\cite{ALRW17}.\n  Towards practicality, we present a new and simple data structure using linear\nspace and sublinear query time for any $c>1$ including $c\\to 1^+$. Given an LSH\nfamily of functions for some metric space, we randomly project points to the\nHamming cube of dimension $\\log n$, where $n$ is the number of input points.\nThe projected space contains strings which serve as keys for buckets containing\nthe input points. The query algorithm simply projects the query point, then\nexamines points which are assigned to the same or nearby vertices on the\nHamming cube. We analyze in detail the query time for some standard LSH\nfamilies.\n  To illustrate our claim of practicality, we offer an open-source\nimplementation in {\\tt C++}, and report on several experiments in dimension up\nto 1000 and $n$ up to $10^6$. Our algorithm is one to two orders of magnitude\nfaster than brute force search. Experiments confirm the sublinear dependence on\n$n$ and the linear dependence on the dimension. We have compared against\nstate-of-the-art LSH-based library {\\tt FALCONN}: our search is somewhat\nslower, but memory usage and preprocessing time are significantly smaller.\n", "versions": [{"version": "v1", "created": "Thu, 22 Dec 2016 00:55:29 GMT"}], "update_date": "2016-12-23", "authors_parsed": [["Avarikioti", "Georgia", ""], ["Emiris", "Ioannis Z.", ""], ["Psarros", "Ioannis", ""], ["Samaras", "Georgios", ""]]}, {"id": "1612.08030", "submitter": "Danny Nguyen", "authors": "Danny Nguyen, Igor Pak", "title": "Enumerating projections of integer points in unbounded polyhedra", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CG cs.DM cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the Barvinok-Woods algorithm for enumerating projections of integer\npoints in polytopes to unbounded polyhedra. For this, we obtain a new\nstructural result on projections of semilinear subsets of the integer lattice.\nWe extend the results to general formulas in Presburger Arithmetic. We also\ngive an application to the k-Frobenius problem.\n", "versions": [{"version": "v1", "created": "Fri, 23 Dec 2016 16:34:45 GMT"}, {"version": "v2", "created": "Tue, 28 Feb 2017 06:04:28 GMT"}, {"version": "v3", "created": "Fri, 28 Apr 2017 23:31:09 GMT"}, {"version": "v4", "created": "Mon, 12 Jun 2017 04:58:28 GMT"}, {"version": "v5", "created": "Sun, 4 Mar 2018 05:23:51 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Nguyen", "Danny", ""], ["Pak", "Igor", ""]]}, {"id": "1612.08153", "submitter": "Shervin Ardeshir", "authors": "Shervin Ardeshir, Sandesh Sharma, Ali Broji", "title": "EgoReID: Cross-view Self-Identification and Human Re-identification in\n  Egocentric and Surveillance Videos", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human identification remains to be one of the challenging tasks in computer\nvision community due to drastic changes in visual features across different\nviewpoints, lighting conditions, occlusion, etc. Most of the literature has\nbeen focused on exploring human re-identification across viewpoints that are\nnot too drastically different in nature. Cameras usually capture oblique or\nside views of humans, leaving room for a lot of geometric and visual reasoning.\nGiven the recent popularity of egocentric and top-view vision,\nre-identification across these two drastically different views can now be\nexplored. Having an egocentric and a top view video, our goal is to identify\nthe cameraman in the content of the top-view video, and also re-identify the\npeople visible in the egocentric video, by matching them to the identities\npresent in the top-view video. We propose a CRF-based method to address the two\nproblems. Our experimental results demonstrates the efficiency of the proposed\napproach over a variety of video recorded from two views.\n", "versions": [{"version": "v1", "created": "Sat, 24 Dec 2016 09:00:37 GMT"}], "update_date": "2016-12-28", "authors_parsed": [["Ardeshir", "Shervin", ""], ["Sharma", "Sandesh", ""], ["Broji", "Ali", ""]]}, {"id": "1612.09277", "submitter": "Fabrizio Frati", "authors": "Giordano Da Lozzo and Anthony D'Angelo and Fabrizio Frati", "title": "On Planar Greedy Drawings of 3-Connected Planar Graphs", "comments": "36 pages, 24 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A graph drawing is $\\textit{greedy}$ if, for every ordered pair of vertices\n$(x,y)$, there is a path from $x$ to $y$ such that the Euclidean distance to\n$y$ decreases monotonically at every vertex of the path. Greedy drawings\nsupport a simple geometric routing scheme, in which any node that has to send a\npacket to a destination \"greedily\" forwards the packet to any neighbor that is\ncloser to the destination than itself, according to the Euclidean distance in\nthe drawing. In a greedy drawing such a neighbor always exists and hence this\nrouting scheme is guaranteed to succeed.\n  In 2004 Papadimitriou and Ratajczak stated two conjectures related to greedy\ndrawings. The $\\textit{greedy embedding conjecture}$ states that every\n$3$-connected planar graph admits a greedy drawing. The $\\textit{convex greedy\nembedding conjecture}$ asserts that every $3$-connected planar graph admits a\nplanar greedy drawing in which the faces are delimited by convex polygons. In\n2008 the greedy embedding conjecture was settled in the positive by Leighton\nand Moitra.\n  In this paper we prove that every $3$-connected planar graph admits a\n$\\textit{planar}$ greedy drawing. Apart from being a strengthening of Leighton\nand Moitra's result, this theorem constitutes a natural intermediate step\ntowards a proof of the convex greedy embedding conjecture.\n", "versions": [{"version": "v1", "created": "Thu, 29 Dec 2016 20:22:16 GMT"}, {"version": "v2", "created": "Mon, 2 Jan 2017 14:15:21 GMT"}], "update_date": "2017-01-03", "authors_parsed": [["Da Lozzo", "Giordano", ""], ["D'Angelo", "Anthony", ""], ["Frati", "Fabrizio", ""]]}, {"id": "1612.09434", "submitter": "Frederic Chazal", "authors": "Fr\\'ed\\'eric Chazal (DATASHAPE), Ilaria Giulini (DATASHAPE), Bertrand\n  Michel (LSTA)", "title": "Data driven estimation of Laplace-Beltrami operator", "comments": null, "journal-ref": "30th Conference on Neural Information Processing Systems (NIPS\n  2016), Dec 2016, Barcelona, Spain. 30th Conference on Neural Information\n  Processing Systems (NIPS 2016), Barcelona, Spain., 2016", "doi": null, "report-no": null, "categories": "cs.CG cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approximations of Laplace-Beltrami operators on manifolds through graph\nLapla-cians have become popular tools in data analysis and machine learning.\nThese discretized operators usually depend on bandwidth parameters whose tuning\nremains a theoretical and practical problem. In this paper, we address this\nproblem for the unnormalized graph Laplacian by establishing an oracle\ninequality that opens the door to a well-founded data-driven procedure for the\nbandwidth selection. Our approach relies on recent results by Lacour and\nMassart [LM15] on the so-called Lepski's method.\n", "versions": [{"version": "v1", "created": "Fri, 30 Dec 2016 09:33:07 GMT"}], "update_date": "2017-01-02", "authors_parsed": [["Chazal", "Fr\u00e9d\u00e9ric", "", "DATASHAPE"], ["Giulini", "Ilaria", "", "DATASHAPE"], ["Michel", "Bertrand", "", "LSTA"]]}]