[{"id": "1805.00506", "submitter": "Cheng Peng", "authors": "Cheng Peng and Volkan Isler", "title": "Adaptive View Planning for Aerial 3D Reconstruction", "comments": null, "journal-ref": "The 2019 International Conference on Robotics and Automation\n  (ICRA)", "doi": null, "report-no": null, "categories": "cs.CV cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the proliferation of small aerial vehicles, acquiring close up aerial\nimagery for high quality reconstruction of complex scenes is gaining\nimportance. We present an adaptive view planning method to collect such images\nin an automated fashion. We start by sampling a small set of views to build a\ncoarse proxy to the scene. We then present (i)~a method that builds a view\nmanifold for view selection, and (ii) an algorithm to select a sparse set of\nviews. The vehicle then visits these viewpoints to cover the scene, and the\nprocedure is repeated until reconstruction quality converges or a desired level\nof quality is achieved. The view manifold provides an effective\nefficiency/quality compromise between using the entire 6 degree of freedom pose\nspace and using a single view hemisphere to select the views.\n  Our results show that, in contrast to existing \"explore and exploit\" methods\nwhich collect only two sets of views, reconstruction quality can be drastically\nimproved by adding a third set. They also indicate that three rounds of data\ncollection is sufficient even for very complex scenes. We compare our algorithm\nto existing methods in three challenging scenes. We require each algorithm to\nselect the same number of views. Our algorithm generates views which produce\nthe least reconstruction error.\n", "versions": [{"version": "v1", "created": "Tue, 1 May 2018 18:28:23 GMT"}, {"version": "v2", "created": "Fri, 20 Sep 2019 18:28:48 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Peng", "Cheng", ""], ["Isler", "Volkan", ""]]}, {"id": "1805.00719", "submitter": "Elia Moscoso Thompson", "authors": "Elia Moscoso Thompson, Silvia Biasotti", "title": "Description and Retrieval of Geometric Patterns on Surface Meshes using\n  an edge-based LBP approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  While texture analysis is largely addressed for images, the comparison of the\ngeometric reliefs on surfaces embedded in the 3D space is still an open\nchallenge. Starting from the Local Binary Pattern (LBP) description originally\ndefined for images, we introduce the edge-Local Binary Pattern (edgeLBP) as a\nlocal description able to capture the evolution of repeated, geometric patterns\non surface meshes. Our extension is independent of the surface representation,\nindeed the edgeLBP is able to deal with surface tessellations characterized by\nnon-uniform vertex distributions and different types of faces, such as\ntriangles, quadrangles and, in general, convex polygons. Besides the desirable\nrobustness properties the edgeLBP exhibits over a number of examples, we show\nhow this description performs well for 3D pattern retrieval and compare our\nperformances with the participants to a recent 3D pattern retrieval and\nclassification contest.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 10:36:19 GMT"}], "update_date": "2018-05-03", "authors_parsed": [["Thompson", "Elia Moscoso", ""], ["Biasotti", "Silvia", ""]]}, {"id": "1805.00858", "submitter": "Ignasi Sau", "authors": "Luerbio Faria, Sulamita Klein, Ignasi Sau, U\\'everton S. Souza, Rubens\n  Sucupira", "title": "Maximum cuts in edge-colored graphs", "comments": "15 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The input of the Maximum Colored Cut problem consists of a graph $G=(V,E)$\nwith an edge-coloring $c:E\\to \\{1,2,3,\\ldots , p\\}$ and a positive integer $k$,\nand the question is whether $G$ has a nontrivial edge cut using at least $k$\ncolors. The Colorful Cut problem has the same input but asks for a nontrivial\nedge cut using all $p$ colors. Unlike what happens for the classical Maximum\nCut problem, we prove that both problems are NP-complete even on complete,\nplanar, or bounded treewidth graphs. Furthermore, we prove that Colorful Cut is\nNP-complete even when each color class induces a clique of size at most 3, but\nis trivially solvable when each color induces a $K_2$. On the positive side, we\nprove that Maximum Colored Cut is fixed-parameter tractable when parameterized\nby either $k$ or $p$, by constructing a cubic kernel in both cases.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 15:08:53 GMT"}], "update_date": "2018-05-03", "authors_parsed": [["Faria", "Luerbio", ""], ["Klein", "Sulamita", ""], ["Sau", "Ignasi", ""], ["Souza", "U\u00e9verton S.", ""], ["Sucupira", "Rubens", ""]]}, {"id": "1805.01547", "submitter": "Kevin Buchin", "authors": "Kevin Buchin, Anne Driemel, Joachim Gudmundsson, Michael Horton, Irina\n  Kostitsyna, Maarten L\\\"offler and Martijn Struijs", "title": "Approximating $(k,\\ell)$-center clustering for curves", "comments": "24 pages; results on minimum-enclosing ball added, additional author\n  added, general revision", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Euclidean $k$-center problem is a classical problem that has been\nextensively studied in computer science. Given a set $\\mathcal{G}$ of $n$\npoints in Euclidean space, the problem is to determine a set $\\mathcal{C}$ of\n$k$ centers (not necessarily part of $\\mathcal{G}$) such that the maximum\ndistance between a point in $\\mathcal{G}$ and its nearest neighbor in\n$\\mathcal{C}$ is minimized. In this paper we study the corresponding\n$(k,\\ell)$-center problem for polygonal curves under the Fr\\'echet distance,\nthat is, given a set $\\mathcal{G}$ of $n$ polygonal curves in $\\mathbb{R}^d$,\neach of complexity $m$, determine a set $\\mathcal{C}$ of $k$ polygonal curves\nin $\\mathbb{R}^d$, each of complexity $\\ell$, such that the maximum Fr\\'echet\ndistance of a curve in $\\mathcal{G}$ to its closest curve in $\\mathcal{C}$ is\nminimized. In this paper, we substantially extend and improve the known\napproximation bounds for curves in dimension $2$ and higher. We show that, if\n$\\ell$ is part of the input, then there is no polynomial-time approximation\nscheme unless $\\mathsf{P}=\\mathsf{NP}$. Our constructions yield different\nbounds for one and two-dimensional curves and the discrete and continuous\nFr\\'echet distance. In the case of the discrete Fr\\'echet distance on\ntwo-dimensional curves, we show hardness of approximation within a factor close\nto $2.598$. This result also holds when $k=1$, and the $\\mathsf{NP}$-hardness\nextends to the case that $\\ell=\\infty$, i.e., for the problem of computing the\nminimum-enclosing ball under the Fr\\'echet distance. Finally, we observe that a\ncareful adaptation of Gonzalez' algorithm in combination with a curve\nsimplification yields a $3$-approximation in any dimension, provided that an\noptimal simplification can be computed exactly. We conclude that our\napproximation bounds are close to being tight.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 21:32:41 GMT"}, {"version": "v2", "created": "Fri, 20 Jul 2018 15:25:36 GMT"}], "update_date": "2018-07-23", "authors_parsed": [["Buchin", "Kevin", ""], ["Driemel", "Anne", ""], ["Gudmundsson", "Joachim", ""], ["Horton", "Michael", ""], ["Kostitsyna", "Irina", ""], ["L\u00f6ffler", "Maarten", ""], ["Struijs", "Martijn", ""]]}, {"id": "1805.02066", "submitter": "Chih-Hung Liu", "authors": "Chih-Hung Liu", "title": "Nearly Optimal Planar k Nearest Neighbors Queries under General Distance\n  Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the k nearest neighbors problem in the plane for general, convex,\npairwise disjoint sites of constant description complexity such as line\nsegments, disks, and quadrilaterals and with respect to a general family of\ndistance functions including the L_p-norms and additively weighted Euclidean\ndistances. For point sites in the Euclidean metric, after four decades of\neffort, an optimal data structure has recently been developed with O( n )\nspace, O( log n + k ) query time, and O( n log n ) preprocessing time. We\ndevelop a static data structure for the general setting with nearly optimal O(\nn log log n ) space, the optimal O( log n + k ) query time, and expected O( n\npolylog n ) preprocessing time. The O( n log log n ) space approaches the\nlinear space, whose achievability is still unknown with the optimal query time,\nand improves the so far best O( n ( log^2 n )( log log n )^2 ) space of Bohler\net al.'s work. Our dynamic version (that allows insertions and deletions of\nsites) also reduces the space of Kaplan et al.'s work from O( n log^3 n ) to O(\nn log n ).\n  To obtain these progresses, we devise shallow cuttings of linear size for\ngeneral distance functions. Shallow cuttings are a key technique to deal with\nthe k nearest neighbors problem for point sites in the Euclidean metric.\nAgarwal et al. already designed linear-size shallow cuttings for general\ndistance functions, but their shallow cuttings could not be applied to the k\nnearest neighbors problem. Recently, Kaplan et al. constructed shallow cuttings\nthat are feasible for the k nearest neighbors problem, while the size of their\nshallow cuttings has an extra double logarithmic factor. Our innovation is a\nnew random sampling technique for the analysis of geometric structures. Since\nour new technique provides a new way to develop and analyze geometric\nalgorithms, we believe it is of independent interest.\n", "versions": [{"version": "v1", "created": "Sat, 5 May 2018 14:59:00 GMT"}, {"version": "v2", "created": "Sun, 27 Oct 2019 16:12:51 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Liu", "Chih-Hung", ""]]}, {"id": "1805.02447", "submitter": "Wei-Yu Lai", "authors": "Wei-Yu Lai and Tien-Ruey Hsiang", "title": "Continuous Terrain Guarding with Two-Sided Guards", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Herein, we consider the continuous 1.5-dimensional(1.5D) terrain guarding\nproblem with two-sided guarding. We provide an x-monotone chain T and determine\nthe minimal number of vertex guards such that all points of T have been\ntwo-sided guarded. A point p is two-sided guarded if there exist two vertices\nvi (left of p) and (right of p) that both see p. A vertex vi sees a point p on\nT if the line segment connecting vi to p is on or above T. We demonstrate that\nthe continuous 1.5D terrain guarding problem can be transformed to the discrete\nterrain guarding problem with a finite point set X and that if X is two-sided\nguarded, then T is also two-sided guarded. Through this transformation, we\nachieve an optimal algorithm that solves the continuous 1.5D terrain guarding\nproblem under two-sided guarding.\n", "versions": [{"version": "v1", "created": "Mon, 7 May 2018 11:22:36 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Lai", "Wei-Yu", ""], ["Hsiang", "Tien-Ruey", ""]]}, {"id": "1805.02538", "submitter": "Aleksandar Markovic", "authors": "Boris Aronov, Mark de Berg, Aleksandar Markovic, Gerhard Woeginger", "title": "Non-Monochromatic and Conflict-Free Coloring on Tree Spaces and Planar\n  Network Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CG math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that any set of n intervals in $\\mathbb{R}^1$ admits a\nnon-monochromatic coloring with two colors and a conflict-free coloring with\nthree colors. We investigate generalizations of this result to colorings of\nobjects in more complex 1-dimensional spaces, namely so-called tree spaces and\nplanar network spaces.\n", "versions": [{"version": "v1", "created": "Mon, 7 May 2018 14:19:08 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Aronov", "Boris", ""], ["de Berg", "Mark", ""], ["Markovic", "Aleksandar", ""], ["Woeginger", "Gerhard", ""]]}, {"id": "1805.02570", "submitter": "David Orden", "authors": "Carlos Alegr\\'ia-Galicia, David Orden, Leonidas Palios, Carlos Seara,\n  and Jorge Urrutia", "title": "Capturing points with a rotating polygon (and a 3D extension)", "comments": "25 pages, 12 figures, submitted to journal in February 2017", "journal-ref": "Theory of Computing Systems 63:3 (2019), 543-566", "doi": "10.1007/s00224-018-9885-y", "report-no": null, "categories": "cs.CG math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of rotating a simple polygon to contain the maximum\nnumber of elements from a given point set in the plane. We consider variations\nof this problem where the rotation center is a given point or lies on a line\nsegment, a line, or a polygonal chain. We also solve an extension to 3D where\nwe rotate a polyhedron around a given point to contain the maximum number of\nelements from a set of points in the space.\n", "versions": [{"version": "v1", "created": "Mon, 7 May 2018 15:24:30 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Alegr\u00eda-Galicia", "Carlos", ""], ["Orden", "David", ""], ["Palios", "Leonidas", ""], ["Seara", "Carlos", ""], ["Urrutia", "Jorge", ""]]}, {"id": "1805.03252", "submitter": "Victor Milenkovic", "authors": "Victor Milenkovic and Elisha Sacks", "title": "Geometric Rounding and Feature Separation in Meshes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Geometric rounding of a mesh is the task of approximating its vertex\ncoordinates by floating point numbers while preserving mesh structure.\nGeometric rounding allows algorithms of computational geometry to interface\nwith numerical algorithms. We present a practical geometric rounding algorithm\nfor 3D triangle meshes that preserves the topology of the mesh. The basis of\nthe algorithm is a novel strategy: 1) modify the mesh to achieve a feature\nseparation that prevents topology changes when the coordinates change by the\nrounding unit; and 2) round each vertex coordinate to the closest floating\npoint number. Feature separation is also useful on its own, for example for\nsatisfying minimum separation rules in CAD models. We demonstrate a robust,\naccurate implementation.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2018 19:42:18 GMT"}], "update_date": "2018-05-10", "authors_parsed": [["Milenkovic", "Victor", ""], ["Sacks", "Elisha", ""]]}, {"id": "1805.04223", "submitter": "Javiel Rojas-Ledesma", "authors": "J\\'er\\'emy Barbay and Pablo P\\'erez-Lantero and Javiel Rojas-Ledesma", "title": "Computing Coverage Kernels Under Restricted Settings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the Minimum Coverage Kernel problem: given a set $B$ of\n$d$-dimensional boxes, find a subset of $B$ of minimum size covering the same\nregion as $B$. This problem is $\\mathsf{NP}$-hard, but as for many\n$\\mathsf{NP}$-hard problems on graphs, the problem becomes solvable in\npolynomial time under restrictions on the graph induced by $B$. We consider\nvarious classes of graphs, show that Minimum Coverage Kernel remains\n$\\mathsf{NP}$-hard even for severely restricted instances, and provide two\npolynomial time approximation algorithms for this problem.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2018 02:08:49 GMT"}, {"version": "v2", "created": "Tue, 15 May 2018 19:27:04 GMT"}], "update_date": "2018-05-17", "authors_parsed": [["Barbay", "J\u00e9r\u00e9my", ""], ["P\u00e9rez-Lantero", "Pablo", ""], ["Rojas-Ledesma", "Javiel", ""]]}, {"id": "1805.04433", "submitter": "Aurelien Goudjo", "authors": "Mohamed Allaoui and Aur\\'elien Goudjo", "title": "A new class of curves of rational B-spline type", "comments": "72 pages, 32 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new class of rational parametrization has been developed and it was used to\ngenerate a new family of rational functions B-splines\n$\\displaystyle{{\\left({}^{\\alpha}{\\mathbf B}_{i}^{k} \\right)}_{i=0}^{k}}$ which\ndepends on an index $\\alpha \\in (-\\infty,0)\\cup (1,+\\infty)$. This family of\nfunctions verifies, among other things, the properties of positivity, of\npartition of the unit and, for a given degree k, constitutes a true basis\napproximation of continuous functions. We loose, however, the regularity\nclassical optimal linked to the multiplicity of nodes, which we recover in the\nasymptotic case, when $\\alpha \\longrightarrow \\infty$. The associated\n\\mbox{B-splines} curves verify the traditional properties particularly that of\na convex hull and we see a certain \"conjugated symmetry\" related to $\\alpha$.\nThe case of open knot vectors without an inner node leads to a new family of\nrational Bezier curves that will be separately, object of in-depth analysis.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2018 14:55:59 GMT"}], "update_date": "2018-05-14", "authors_parsed": [["Allaoui", "Mohamed", ""], ["Goudjo", "Aur\u00e9lien", ""]]}, {"id": "1805.04997", "submitter": "Xu Li", "authors": "Suyi Wang, Xu Li, Partha Mitra, Yusu Wang", "title": "Topological Skeletonization and Tree-Summarization of Neurons Using\n  Discrete Morse Theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Neuroscientific data analysis has classically involved methods for\nstatistical signal and image processing, drawing on linear algebra and\nstochastic process theory. However, digitized neuroanatomical data sets\ncontaining labelled neurons, either individually or in groups labelled by\ntracer injections, do not fully fit into this classical framework. The\ntree-like shapes of neurons cannot mathematically be adequately described as\npoints in a vector space. There is therefore a need for new approaches. Methods\nfrom computational topology and geometry are naturally suited to the analysis\nof neuronal shapes. Here we introduce methods from Discrete Morse Theory to\nextract tree-skeletons of individual neurons from volumetric brain image data,\nor to summarize collections of neurons labelled by localized anterograde tracer\ninjections. Since individual neurons are topologically trees, it is sensible to\nsummarize the collection of neurons labelled by a localized anterograde tracer\ninjection using a consensus tree-shape. The algorithmic procedure includes an\ninitial pre-processing step to extract a density field from the raw volumetric\nimage data, followed by initial skeleton extraction from the density field\nusing a discrete version of a 1-(un)stable manifold of the density field.\nHeuristically, if the density field is regarded as a mountainous landscape,\nthen the 1-(un)stable manifold follows the \"mountain ridges\" connecting the\nmaxima of the density field. We then simplify this skeleton-graph into a tree\nusing a shortest-path approach and methods derived from persistent homology.\nThe advantage of this approach is that it uses global information about the\ndensity field and is therefore robust to local fluctuations and non-uniformly\ndistributed input signals. To be able to handle large data sets, we use a\ndivide-and-conquer approach. The resulting software DiMorSC is available on\nGithub.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2018 03:15:25 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Wang", "Suyi", ""], ["Li", "Xu", ""], ["Mitra", "Partha", ""], ["Wang", "Yusu", ""]]}, {"id": "1805.06148", "submitter": "Charmin Asirimath Pingamage Don", "authors": "Charmin Asirimath, Jayampathy Ratnayake, Chathuranga Weeraddana", "title": "Critical Points to Determine Persistence Homology", "comments": "11 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computation of the simplicial complexes of a large point cloud often relies\non extracting a sample, to reduce the associated computational burden. The\nstudy considers sampling critical points of a Morse function associated to a\npoint cloud, to approximate the Vietoris-Rips complex or the witness complex\nand compute persistence homology. The effectiveness of the novel approach is\ncompared with the farthest point sampling, in a context of classifying human\nface images into ethnics groups using persistence homology.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2018 06:25:21 GMT"}], "update_date": "2018-05-17", "authors_parsed": [["Asirimath", "Charmin", ""], ["Ratnayake", "Jayampathy", ""], ["Weeraddana", "Chathuranga", ""]]}, {"id": "1805.06403", "submitter": "Elizabeth Munch", "authors": "Firas A. Khasawneh, and Elizabeth Munch", "title": "Topological Data Analysis for True Step Detection in Piecewise Constant\n  Signals", "comments": null, "journal-ref": null, "doi": "10.1098/rspa.2018.0027", "report-no": null, "categories": "eess.SP cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a simple yet powerful approach based on topological\ndata analysis (TDA) for detecting the true steps in a piecewise constant (PWC)\nsignal. The signal is a two-state square wave with randomly varying\nin-between-pulse spacing, and subject to spurious steps at the rising or\nfalling edges which we refer to as digital ringing. We use persistent homology\nto derive mathematical guarantees for the resulting change detection which\nenables accurate identification and counting of the true pulses. The approach\nis described and tested using both synthetic and experimental data obtained\nusing an engine lathe instrumented with a laser tachometer. The described\nalgorithm enables the accurate calculation of the spindle speed with the\nappropriate error bounds. The results of the described approach are compared to\nthe frequency domain approach via Fourier transform. It is found that both our\napproach and the Fourier analysis yield comparable results for numerical and\nexperimental pulses with regular spacing and digital ringing. However, the\ndescribed approach significantly outperforms Fourier analysis when the spacing\nbetween the peaks is varied. We also generalize the approach to higher\ndimensional PWC signals, although utilizing this extension remains an\ninteresting question for future research.\n", "versions": [{"version": "v1", "created": "Tue, 1 May 2018 18:44:33 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Khasawneh", "Firas A.", ""], ["Munch", "Elizabeth", ""]]}, {"id": "1805.06780", "submitter": "Lutz Oettershagen", "authors": "Petra Mutzel and Lutz Oettershagen", "title": "The Crossing Number of Semi-Pair-Shellable Drawings of Complete Graphs", "comments": "arXiv admin note: substantial text overlap with arXiv:1803.07515\n  Changes in updated version: - Title was changed: The reason is that the new\n  class of drawings is not a superset of seq-shellable drawings and is only\n  defined for odd n. Therefore the new name is a better fit. - Minor\n  corrections of typos and language - Clearer introduction", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Harary-Hill Conjecture states that for $n\\geq 3$ every drawing of $K_n$\nhas at least \\begin{align*}\n  H(n) :=\n\\frac{1}{4}\\Big\\lfloor\\frac{n}{2}\\Big\\rfloor\\Big\\lfloor\\frac{n-1}{2}\\Big\\rfloor\\Big\\lfloor\\frac{n-2}{2}\\Big\\rfloor\\Big\\lfloor\\frac{n-3}{2}\\Big\\rfloor\n\\end{align*} crossings. In general the problem remains unsolved, however there\nhas been some success in proving the conjecture for restricted classes of\ndrawings. The most recent and most general of these classes is\nseq-shellability. In this work, we improve these results and introduce the new\nclass of semi-pair-shellable drawings. We prove the Harary-Hill Conjecture for\nthis new class using novel results on $k$-edges. So far, approaches for proving\nthe Harary-Hill Conjecture for specific classes rely on a fixed reference face.\nWe successfully apply new techniques in order to loosen this restriction, which\nenables us to select different reference faces when considering subdrawings.\nFurthermore, we introduce the notion of $k$-deviations as the difference\nbetween an optimal and the actual number of $k$-edges. Using $k$-deviations, we\ngain interesting insights into the essence of $k$-edges, and we further relax\nthe necessity of fixed reference faces.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2018 10:00:11 GMT"}, {"version": "v2", "created": "Wed, 11 Jul 2018 15:42:57 GMT"}], "update_date": "2018-07-12", "authors_parsed": [["Mutzel", "Petra", ""], ["Oettershagen", "Lutz", ""]]}, {"id": "1805.07035", "submitter": "Morad Behandish", "authors": "Morad Behandish, Saigopal Nelaturi, and Johan de Kleer", "title": "Automated Process Planning for Hybrid Manufacturing", "comments": "Special Issue on symposium on Solid and Physical Modeling (SPM'2018)", "journal-ref": "Journal of Computer-Aided Design, 2018", "doi": "10.1016/j.cad.2018.04.022", "report-no": null, "categories": "cs.CG cs.AI cs.GR cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hybrid manufacturing (HM) technologies combine additive and subtractive\nmanufacturing (AM/SM) capabilities, leveraging AM's strengths in fabricating\ncomplex geometries and SM's precision and quality to produce finished parts. We\npresent a systematic approach to automated computer-aided process planning\n(CAPP) for HM that can identify non-trivial, qualitatively distinct, and\ncost-optimal combinations of AM/SM modalities. A multimodal HM process plan is\nrepresented by a finite Boolean expression of AM and SM manufacturing\nprimitives, such that the expression evaluates to an 'as-manufactured'\nartifact. We show that primitives that respect spatial constraints such as\naccessibility and collision avoidance may be constructed by solving inverse\nconfiguration space problems on the 'as-designed' artifact and manufacturing\ninstruments. The primitives generate a finite Boolean algebra (FBA) that\nenumerates the entire search space for planning. The FBA's canonical\nintersection terms (i.e., 'atoms') provide the complete domain decomposition to\nreframe manufacturability analysis and process planning into purely symbolic\nreasoning, once a subcollection of atoms is found to be interchangeable with\nthe design target. The approach subsumes unimodal (all-AM or all-SM) process\nplanning as special cases. We demonstrate the practical potency of our\nframework and its computational efficiency when applied to process planning of\ncomplex 3D parts with dramatically different AM and SM instruments.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 03:27:35 GMT"}], "update_date": "2018-05-21", "authors_parsed": [["Behandish", "Morad", ""], ["Nelaturi", "Saigopal", ""], ["de Kleer", "Johan", ""]]}, {"id": "1805.07373", "submitter": "Rasoul Shahsavarifar", "authors": "Rasoul Shahsavarifar and David Bremner", "title": "Approximate Data Depth Revisited", "comments": "This paper is submitted to CCCG2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Halfspace depth and $\\beta$-skeleton depth are two types of depth functions\nin nonparametric data analysis. The halfspace depth of a query point $q\\in\n\\mathbb{R}^d$ with respect to $S\\subset\\mathbb{R}^d$ is the minimum portion of\nthe elements of $S$ which are contained in a halfspace which passes through\n$q$. For $\\beta \\geq 1$, the $\\beta$-skeleton depth of $q$ with respect to $S$\nis defined to be the total number of \\emph{$\\beta$-skeleton influence regions}\nthat contain $q$, where each of these influence regions is the intersection of\ntwo hyperballs obtained from a pair of points in $S$. The $\\beta$-skeleton\ndepth introduces a family of depth functions that contain \\emph{spherical\ndepth} and \\emph{lens depth} if $\\beta=1$ and $\\beta=2$, respectively. The main\nresults of this paper include approximating the planar halfspace depth and\n$\\beta$-skeleton depth using two different approximation methods. First, the\nhalfspace depth is approximated by the $\\beta$-skeleton depth values. For this\nmethod, two dissimilarity measures based on the concepts of \\emph{fitting\nfunction} and \\emph{Hamming distance} are defined to train the halfspace depth\nfunction by the $\\beta$-skeleton depth values obtaining from a given data set.\nThe goodness of this approximation is measured by a function of error values.\nSecondly, computing the planar $\\beta$-skeleton depth is reduced to a\ncombination of some range counting problems. Using existing results on range\ncounting approximations, the planar $\\beta$-skeleton depth of a query point is\napproximated in $O(n\\;poly(1/\\varepsilon,\\log n))$, $\\beta\\geq 1$. Regarding\nthe $\\beta$-skeleton depth functions, it is also proved that this family of\ndepth functions converge when $\\beta \\to \\infty$. Finally, some experimental\nresults are provided to support the proposed method of approximation and\nconvergence of $\\beta$-skeleton depth functions.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 18:09:19 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Shahsavarifar", "Rasoul", ""], ["Bremner", "David", ""]]}, {"id": "1805.07450", "submitter": "Rahul Prabhu", "authors": "Aysegul Ozkan, Rahul Prabhu, Troy Baker, James Pence, Jorg Peters,\n  Meera Sitharam", "title": "Efficient Atlasing and Search of Configuration Spaces of Point-Sets\n  Constrained by Distance Intervals", "comments": "The first version of this article has serious unintended display and\n  typesetting issues that were overlooked before the upload; it should be\n  considered withdrawn", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For configurations of point-sets that are pairwise constrained by distance\nintervals, the EASAL software implements a suite of algorithms that\ncharacterize the structure and geometric properties of the configuration space.\nThe algorithms generate, describe and explore these configuration spaces using\ngeneric rigidity properties, classical results for stratification of\nsemi-algebraic sets, and new results for efficient sampling by convex\nparametrization. The paper reviews the key theoretical underpinnings, major\nalgorithms and their implementation. The paper outlines the main applications\nsuch as the computation of free energy and kinetics of assembly of\nsupramolecular structures or of clusters in colloidal and soft materials. In\naddition, the paper surveys select experimental results and comparisons.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 21:35:40 GMT"}, {"version": "v2", "created": "Mon, 4 Jun 2018 18:44:10 GMT"}], "update_date": "2018-06-06", "authors_parsed": [["Ozkan", "Aysegul", ""], ["Prabhu", "Rahul", ""], ["Baker", "Troy", ""], ["Pence", "James", ""], ["Peters", "Jorg", ""], ["Sitharam", "Meera", ""]]}, {"id": "1805.07589", "submitter": "Jesse Anderton", "authors": "Jesse Anderton, Virgil Pavlu, Javed Aslam", "title": "Revealing the Basis: Ordinal Embedding Through Geometry", "comments": "Reviewed but not accepted for AISTATS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ordinal Embedding places n objects into R^d based on comparisons such as \"a\nis closer to b than c.\" Current optimization-based approaches suffer from\nscalability problems and an abundance of low quality local optima. We instead\nconsider a computational geometric approach based on selecting comparisons to\ndiscover points close to nearly-orthogonal \"axes\" and embed the whole set by\ntheir projections along each axis. We thus also estimate the dimensionality of\nthe data. Our embeddings are of lower quality than the global optima of\noptimization-based approaches, but are more scalable computationally and more\nreliable than local optima often found via optimization. Our method uses\n\\Theta(n d \\log n) comparisons and \\Theta(n^2 d^2) total operations, and can\nalso be viewed as selecting constraints for an optimizer which, if successful,\nwill produce an almost-perfect embedding for sufficiently dense datasets.\n", "versions": [{"version": "v1", "created": "Sat, 19 May 2018 13:23:54 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Anderton", "Jesse", ""], ["Pavlu", "Virgil", ""], ["Aslam", "Javed", ""]]}, {"id": "1805.07724", "submitter": "Sharareh Alipour", "authors": "Sharareh Alipour and Salman Parsa", "title": "Hardness of Segment Cover, Contiguous SAT and Visibility with Uncertain\n  Obstacles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define the problem segment cover as follows. We are given a set of pairs\nof sub-intervals of the unit interval. The problem asks if there is a choice of\na single interval from each pair such that the union of the chosen intervals\ncovers the entire unit interval. This problem arises naturally while attempting\nto compute visibility between a point and a line segment in the plane in the\npresence of uncertain obstacles. Segment cover is equivalent to a restricted\nversion of SAT which we call contiguous SAT. Consider a SAT with the following\nrestrictions. An input formula is in CNF form and an ordering of the clauses is\ngiven in which clauses containing any fixed literal appear contiguously. We\ncall this restricted problem contiguous SAT. Our main result is that the\nproblems segment cover and contiguous SAT are NP-hard. We also discuss hardness\nof approximation for these problems.\n", "versions": [{"version": "v1", "created": "Sun, 20 May 2018 07:54:07 GMT"}, {"version": "v2", "created": "Sun, 18 Oct 2020 02:01:32 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Alipour", "Sharareh", ""], ["Parsa", "Salman", ""]]}, {"id": "1805.08331", "submitter": "Th\\'eo Lacombe", "authors": "Th\\'eo Lacombe and Marco Cuturi and Steve Oudot", "title": "Large Scale computation of Means and Clusters for Persistence Diagrams\n  using Optimal Transport", "comments": "17 pages, 9 figures (9 pages for the main content). To appear in NIPS\n  2018 proceedings. Version updated following reviewing process: correction of\n  typo, clarification of some details, addition of two illustrations (Fig.1 and\n  7 in this version)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CG cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Persistence diagrams (PDs) are now routinely used to summarize the underlying\ntopology of complex data. Despite several appealing properties, incorporating\nPDs in learning pipelines can be challenging because their natural geometry is\nnot Hilbertian. Indeed, this was recently exemplified in a string of papers\nwhich show that the simple task of averaging a few PDs can be computationally\nprohibitive. We propose in this article a tractable framework to carry out\nstandard tasks on PDs at scale, notably evaluating distances, estimating\nbarycenters and performing clustering. This framework builds upon a\nreformulation of PD metrics as optimal transport (OT) problems. Doing so, we\ncan exploit recent computational advances: the OT problem on a planar grid,\nwhen regularized with entropy, is convex can be solved in linear time using the\nSinkhorn algorithm and convolutions. This results in scalable computations that\ncan stream on GPUs. We demonstrate the efficiency of our approach by carrying\nout clustering with diagrams metrics on several thousands of PDs, a scale never\nseen before in the literature.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 00:23:22 GMT"}, {"version": "v2", "created": "Tue, 13 Nov 2018 15:08:33 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Lacombe", "Th\u00e9o", ""], ["Cuturi", "Marco", ""], ["Oudot", "Steve", ""]]}, {"id": "1805.08453", "submitter": "Thom Fruehwirth", "authors": "Thom Fruehwirth", "title": "Rule-Based Drawing, Analysis and Generation of Graphs for Mason's Mark\n  Design", "comments": "Under submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are developing a rule-based implementation of a tool to analyse and\ngenerate graphs. It is currently used in the domain of mason's marks. For\nthousands of years, stonemasons have been inscribing these symbolic signs on\ndressed stone. Geometrically, mason's marks are line drawings. They consist of\na pattern of straight lines, sometimes circles and arcs. We represent mason's\nmarks by connected planar graphs. Our prototype tool for analysis and\ngeneration of graphs is written in the rule-based declarative language\nConstraint Handling Rules. It features - a vertex-centric logical graph\nrepresentation as constraints, - derivation of properties and statistics from\ngraphs, - recognition of (sub)graphs and patterns in a graph, - automatic\ngeneration of graphs from given constrained subgraphs, - drawing graphs by\nvisualization using svg graphics. In particular, we started to use the tool to\nclassify and to invent mason's marks. In principe, our tool can be applied to\nany problem domain that admits a modeling as graphs.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 08:30:51 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Fruehwirth", "Thom", ""]]}, {"id": "1805.08602", "submitter": "Yakov Nekrich", "authors": "Timothy M. Chan, Yakov Nekrich, Saladi Rahul, Konstantinos Tsakalidis", "title": "Orthogonal Point Location and Rectangle Stabbing Queries in 3-d", "comments": "Full version of the ICALP'18 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present a collection of new results on two fundamental\nproblems in geometric data structures: orthogonal point location and rectangle\nstabbing.\n  -We give the first linear-space data structure that supports 3-d point\nlocation queries on $n$ disjoint axis-aligned boxes with optimal $O\\left( \\log\nn\\right)$ query time in the (arithmetic) pointer machine model. This improves\nthe previous $O\\left( \\log^{3/2} n \\right)$ bound of Rahul [SODA 2015]. We\nsimilarly obtain the first linear-space data structure in the I/O model with\noptimal query cost, and also the first linear-space data structure in the word\nRAM model with sub-logarithmic query time.\n  -We give the first linear-space data structure that supports 3-d $4$-sided\nand $5$-sided rectangle stabbing queries in optimal $O(\\log_wn+k)$ time in the\nword RAM model. We similarly obtain the first optimal data structure for the\nclosely related problem of 2-d top-$k$ rectangle stabbing in the word RAM\nmodel, and also improved results for 3-d 6-sided rectangle stabbing.\n  For point location, our solution is simpler than previous methods, and is\nbased on an interesting variant of the van Emde Boas recursion, applied in a\nround-robin fashion over the dimensions, combined with bit-packing techniques.\nFor rectangle stabbing, our solution is a variant of Alstrup, Brodal, and\nRauhe's grid-based recursive technique (FOCS 2000), combined with a number of\nnew ideas.\n", "versions": [{"version": "v1", "created": "Sat, 19 May 2018 14:23:51 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Chan", "Timothy M.", ""], ["Nekrich", "Yakov", ""], ["Rahul", "Saladi", ""], ["Tsakalidis", "Konstantinos", ""]]}, {"id": "1805.08831", "submitter": "C\\'elestin Marot", "authors": "C\\'elestin Marot, Jeanne Pellerin, Jean-Fran\\c{c}ois Remacle", "title": "One machine, one minute, three billion tetrahedra", "comments": null, "journal-ref": null, "doi": "10.1002/nme.5987", "report-no": null, "categories": "cs.CG cs.GR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper presents a new scalable parallelization scheme to generate the 3D\nDelaunay triangulation of a given set of points. Our first contribution is an\nefficient serial implementation of the incremental Delaunay insertion\nalgorithm. A simple dedicated data structure, an efficient sorting of the\npoints and the optimization of the insertion algorithm have permitted to\naccelerate reference implementations by a factor three. Our second contribution\nis a multi-threaded version of the Delaunay kernel that is able to concurrently\ninsert vertices. Moore curve coordinates are used to partition the point set,\navoiding heavy synchronization overheads. Conflicts are managed by modifying\nthe partitions with a simple rescaling of the space-filling curve. The\nperformances of our implementation have been measured on three different\nprocessors, an Intel core-i7, an Intel Xeon Phi and an AMD EPYC, on which we\nhave been able to compute 3 billion tetrahedra in 53 seconds. This corresponds\nto a generation rate of over 55 million tetrahedra per second. We finally show\nhow this very efficient parallel Delaunay triangulation can be integrated in a\nDelaunay refinement mesh generator which takes as input the triangulated\nsurface boundary of the volume to mesh.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 19:40:50 GMT"}, {"version": "v2", "created": "Mon, 5 Nov 2018 16:10:21 GMT"}, {"version": "v3", "created": "Tue, 6 Nov 2018 13:34:33 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Marot", "C\u00e9lestin", ""], ["Pellerin", "Jeanne", ""], ["Remacle", "Jean-Fran\u00e7ois", ""]]}, {"id": "1805.09110", "submitter": "Joshua Levine", "authors": "Julien Tierny, Guillaume Favelier, Joshua A. Levine, Charles Gueunet,\n  and Michael Michaux", "title": "The Topology ToolKit", "comments": null, "journal-ref": "IEEE Trans. Vis. Comput. Graph. 24(1) (2018) 832-842", "doi": "10.1109/TVCG.2017.2743938", "report-no": null, "categories": "cs.GR cs.CG cs.CV eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This system paper presents the Topology ToolKit (TTK), a software platform\ndesigned for topological data analysis in scientific visualization. TTK\nprovides a unified, generic, efficient, and robust implementation of key\nalgorithms for the topological analysis of scalar data, including: critical\npoints, integral lines, persistence diagrams, persistence curves, merge trees,\ncontour trees, Morse-Smale complexes, fiber surfaces, continuous scatterplots,\nJacobi sets, Reeb spaces, and more. TTK is easily accessible to end users due\nto a tight integration with ParaView. It is also easily accessible to\ndevelopers through a variety of bindings (Python, VTK/C++) for fast prototyping\nor through direct, dependence-free, C++, to ease integration into pre-existing\ncomplex systems. While developing TTK, we faced several algorithmic and\nsoftware engineering challenges, which we document in this paper. In\nparticular, we present an algorithm for the construction of a discrete gradient\nthat complies to the critical points extracted in the piecewise-linear setting.\nThis algorithm guarantees a combinatorial consistency across the topological\nabstractions supported by TTK, and importantly, a unified implementation of\ntopological data simplification for multi-scale exploration and analysis. We\nalso present a cached triangulation data structure, that supports time\nefficient and generic traversals, which self-adjusts its memory usage on demand\nfor input simplicial meshes and which implicitly emulates a triangulation for\nregular grids with no memory overhead. Finally, we describe an original\nsoftware architecture, which guarantees memory efficient and direct accesses to\nTTK features, while still allowing for researchers powerful and easy bindings\nand extensions. TTK is open source (BSD license) and its code, online\ndocumentation and video tutorials are available on TTK's website.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 10:27:24 GMT"}, {"version": "v2", "created": "Tue, 16 Jul 2019 22:53:53 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Tierny", "Julien", ""], ["Favelier", "Guillaume", ""], ["Levine", "Joshua A.", ""], ["Gueunet", "Charles", ""], ["Michaux", "Michael", ""]]}, {"id": "1805.09694", "submitter": "Nicolas Berkouk", "authors": "Nicolas Berkouk, Gr\\'egory Ginot", "title": "A derived isometry theorem for constructible sheaves on $\\mathbb{R}$", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AT cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Persistent homology has been recently studied with the tools of sheaf theory\nin the derived setting by Kashiwara and Schapira, after J. Curry has made the\nfirst link between persistent homology and sheaves.\n  We prove the isometry theorem in this derived setting, thus expressing the\nconvolution distance of sheaves as a matching distance between combinatorial\nobjects associated to them that we call graded barcodes. This allows to\nconsider sheaf-theoretical constructions as combinatorial, stable topological\ndescriptors of data, and generalizes the situation of persistence with one\nparameter. To achieve so, we explicitly compute all morphisms in\n$D^b_{\\mathbb{R} c}(\\textbf{k}_\\mathbb{R})$, which enables us to compute\ndistances between indecomposable objects. Then we adapt Bjerkevik's stability\nproof to this derived setting.\n  As a byproduct of our isometry theorem, we prove that the convolution\ndistance is closed, give a precise description of connected components of\n$D^b_{\\mathbb{R} c}(\\textbf{k}_\\mathbb{R})$and provide some explicit examples\nof computation of the convolution distance.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 14:22:37 GMT"}, {"version": "v2", "created": "Mon, 24 Sep 2018 15:14:32 GMT"}, {"version": "v3", "created": "Mon, 14 Jun 2021 16:21:57 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Berkouk", "Nicolas", ""], ["Ginot", "Gr\u00e9gory", ""]]}, {"id": "1805.09719", "submitter": "Aryeh Kontorovich", "authors": "Lee-Ad Gottlieb, Eran Kaufman, Aryeh Kontorovich, Gabriel Nivasch", "title": "Learning convex polytopes with margin", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.CG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an improved algorithm for properly learning convex polytopes in\nthe realizable PAC setting from data with a margin. Our learning algorithm\nconstructs a consistent polytope as an intersection of about $t \\log t$\nhalfspaces with margins in time polynomial in $t$ (where $t$ is the number of\nhalfspaces forming an optimal polytope).\n  We also identify distinct generalizations of the notion of margin from\nhyperplanes to polytopes and investigate how they relate geometrically; this\nresult may be of interest beyond the learning setting.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 15:07:14 GMT"}, {"version": "v2", "created": "Fri, 16 Nov 2018 13:29:21 GMT"}], "update_date": "2018-11-19", "authors_parsed": [["Gottlieb", "Lee-Ad", ""], ["Kaufman", "Eran", ""], ["Kontorovich", "Aryeh", ""], ["Nivasch", "Gabriel", ""]]}, {"id": "1805.10051", "submitter": "Stefano Facchini", "authors": "Pablo Arrighi, Cl\\'ement Chouteau, Stefano Facchini and Simon Martiel", "title": "Causal dynamics of discrete manifolds", "comments": "19 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CG math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend Cellular Automata to time-varying discrete geometries. In other\nwords we formalize, and prove theorems about, the intuitive idea of a discrete\nmanifold which evolves in time, subject to two natural constraints: the\nevolution does not propagate information too fast; and it acts everywhere the\nsame. For this purpose we develop a correspondence between complexes and\nlabeled graphs. In particular we reformulate the properties that characterize\ndiscrete manifolds amongst complexes, solely in terms of graphs. In dimensions\n$n<4$, over bounded-star graphs, it is decidable whether a Cellular Automaton\nmaps discrete manifolds into discrete manifolds.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 09:24:03 GMT"}, {"version": "v2", "created": "Mon, 16 Jul 2018 07:31:16 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Arrighi", "Pablo", ""], ["Chouteau", "Cl\u00e9ment", ""], ["Facchini", "Stefano", ""], ["Martiel", "Simon", ""]]}, {"id": "1805.10136", "submitter": "Alexander Cowen-Rivers", "authors": "Alexander Imani Cowen-Rivers, Matthew England", "title": "Towards Incremental Cylindrical Algebraic Decomposition in Maple", "comments": "FLoC 2018. arXiv admin note: substantial text overlap with\n  arXiv:1804.08564", "journal-ref": "In: A. Bigatti and M. Brain eds. Proceedings of the 3rd Workshop\n  on Satisfiability Checking and Symbolic Computation (SC2 '18), pp. 3-18. CEUR\n  Workshop Proceedings 2189, 2018", "doi": null, "report-no": null, "categories": "cs.SC cs.CG math.AG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cylindrical Algebraic Decomposition (CAD) is an important tool within\ncomputational real algebraic geometry, capable of solving many problems for\npolynomial systems over the reals. It has long been studied by the Symbolic\nComputation community and has found recent interest in the Satisfiability\nChecking community. The present report describes a proof of concept\nimplementation of an Incremental CAD algorithm in Maple, where CADs are built\nand then refined as additional polynomial constraints are added. The aim is to\nmake CAD suitable for use as a theory solver for SMT tools who search for\nsolutions by continually reformulating logical formula and querying whether a\nlogical solution is admissible. We describe experiments for the proof of\nconcept, which clearly display the computational advantages compared to\niterated re-computation. In addition, the project implemented this work under\nthe recently verified Lazard projection scheme (with corresponding Lazard\nvaluation).\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 10:57:18 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Cowen-Rivers", "Alexander Imani", ""], ["England", "Matthew", ""]]}, {"id": "1805.10210", "submitter": "Samy Blusseau", "authors": "Jos\\'e Lezama (CMLA), Samy Blusseau (CMLA), Jean-Michel Morel (CMLA),\n  Gregory Randall (IIE), Rafael Grompone von Gioi (CMLA)", "title": "Psychophysics, Gestalts and Games", "comments": null, "journal-ref": "Giovanna Citti, Alessandro Sarti. Neuromathematics of Vision,\n  Springer Berlin Heidelberg, pp.217-242, 2014, Lecture Notes in Morphogenesis", "doi": "10.1007/978-3-642-34444-2_6", "report-no": null, "categories": "cs.CV cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many psychophysical studies are dedicated to the evaluation of the human\ngestalt detection on dot or Gabor patterns, and to model its dependence on the\npattern and background parameters. Nevertheless, even for these constrained\npercepts, psychophysics have not yet reached the challenging prediction stage,\nwhere human detection would be quantitatively predicted by a (generic) model.\nOn the other hand, Computer Vision has attempted at defining automatic\ndetection thresholds. This chapter sketches a procedure to confront these two\nmethodologies inspired in gestaltism. Using a computational quantitative\nversion of the non-accidentalness principle, we raise the possibility that the\npsychophysical and the (older) gestaltist setups, both applicable on dot or\nGabor patterns, find a useful complement in a Turing test. In our perceptual\nTuring test, human performance is compared by the scientist to the detection\nresult given by a computer. This confrontation permits to revive the abandoned\nmethod of gestaltic games. We sketch the elaboration of such a game, where the\nsubjects of the experiment are confronted to an alignment detection algorithm,\nand are invited to draw examples that will fool it. We show that in that way a\nmore precise definition of the alignment gestalt and of its computational\nformulation seems to emerge. Detection algorithms might also be relevant to\nmore classic psychophysical setups, where they can again play the role of a\nTuring test. To a visual experiment where subjects were invited to detect\nalignments in Gabor patterns, we associated a single function measuring the\nalignment detectability in the form of a number of false alarms (NFA). The\nfirst results indicate that the values of the NFA, as a function of all\nsimulation parameters, are highly correlated to the human detection. This fact,\nthat we intend to support by further experiments , might end up confirming that\nhuman alignment detection is the result of a single mechanism.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 15:48:14 GMT"}], "update_date": "2018-05-28", "authors_parsed": [["Lezama", "Jos\u00e9", "", "CMLA"], ["Blusseau", "Samy", "", "CMLA"], ["Morel", "Jean-Michel", "", "CMLA"], ["Randall", "Gregory", "", "IIE"], ["von Gioi", "Rafael Grompone", "", "CMLA"]]}, {"id": "1805.10237", "submitter": "Arkadiy Skopenkov", "authors": "A. Skopenkov", "title": "Invariants of graph drawings in the plane", "comments": "48 pages, many figures. References are updated (in particular,\n  according to a mistake found in [FWZ]); exposition is improved", "journal-ref": "Arnold Math. J., 6 (2020) 21-55 (abridged version)", "doi": "10.1007/s40598-019-00128-5", "report-no": null, "categories": "math.GT cs.CG math.AT math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a simplified exposition of some classical and modern results on\ngraph drawings in the plane. These results are chosen so that they illustrate\nsome spectacular recent higher-dimensional results on the border of topology\nand combinatorics. We define a mod2-valued self-intersection invariant (i.e.\nthe van Kampen number) and its generalizations. We present elementary\nformulations and arguments accessible to mathematicians not specialized in any\nof the areas discussed. So most part of this survey could be studied before\ntextbooks on algebraic topology, as an introduction to starting ideas of\nalgebraic topology motivated by algorithmic, combinatorial and geometric\nproblems.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 16:29:15 GMT"}, {"version": "v2", "created": "Sun, 27 Oct 2019 14:33:42 GMT"}, {"version": "v3", "created": "Tue, 22 Dec 2020 10:57:07 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Skopenkov", "A.", ""]]}, {"id": "1805.10716", "submitter": "Rostik Mertz Anton", "authors": "Robin Lynne Belton and Brittany Terese Fasy and Rostik Mertz and\n  Samuel Micka and David L. Millman and Daniel Salinas and Anna Schenfisch and\n  Jordan Schupbach and Lucia Williams", "title": "Learning Simplicial Complexes from Persistence Diagrams", "comments": "Updated our document for clarity in response to comments by reviewers\n  at CCCG. This paper will appear at CCCG 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG math.AT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topological Data Analysis (TDA) studies the shape of data. A common\ntopological descriptor is the persistence diagram, which encodes topological\nfeatures in a topological space at different scales. Turner, Mukeherjee, and\nBoyer showed that one can reconstruct a simplicial complex embedded in R^3\nusing persistence diagrams generated from all possible height filtrations (an\nuncountably infinite number of directions). In this paper, we present an\nalgorithm for reconstructing plane graphs K=(V,E) in R^2 , i.e., a planar graph\nwith vertices in general position and a straight-line embedding, from a\nquadratic number height filtrations and their respective persistence diagrams.\n", "versions": [{"version": "v1", "created": "Sun, 27 May 2018 23:54:59 GMT"}, {"version": "v2", "created": "Tue, 31 Jul 2018 22:34:27 GMT"}], "update_date": "2018-08-02", "authors_parsed": [["Belton", "Robin Lynne", ""], ["Fasy", "Brittany Terese", ""], ["Mertz", "Rostik", ""], ["Micka", "Samuel", ""], ["Millman", "David L.", ""], ["Salinas", "Daniel", ""], ["Schenfisch", "Anna", ""], ["Schupbach", "Jordan", ""], ["Williams", "Lucia", ""]]}, {"id": "1805.10847", "submitter": "Pablo P\\'erez-Lantero", "authors": "Luis H. Herrera and Pablo P\\'erez-Lantero", "title": "On the intersection graph of the disks with diameters the sides of a\n  convex $n$-gon", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a convex $n$-gon, we can draw $n$ disks (called side disks) where each\ndisk has a different side of the polygon as diameter and the midpoint of the\nside as its center. The intersection graph of such disks is the undirected\ngraph with vertices the $n$ disks and two disks are adjacent if and only if\nthey have a point in common. Such a graph was introduced by Huemer and\nP\\'erez-Lantero in 2016, proved to be planar and Hamiltonian. In this paper we\nstudy further combinatorial properties of this graph. We prove that the\ntreewidth is at most 3, by showing an $O(n)$-time algorithm that builds a tree\ndecomposition of width at most 3, given the polygon as input. This implies that\nwe can construct the intersection graph of the side disks in $O(n)$ time. We\nfurther study the independence number of this graph, which is the maximum\nnumber of pairwise disjoint disks. The planarity condition implies that for\nevery convex $n$-gon we can select at least $\\lceil n/4 \\rceil$ pairwise\ndisjoint disks, and we prove that for every $n\\ge 3$ there exist convex\n$n$-gons in which we cannot select more than this number. Finally, we show that\nour class of graphs includes all outerplanar Hamiltonian graphs except the\ncycle of length four, and that it is a proper subclass of the planar\nHamiltonian graphs.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 10:03:58 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Herrera", "Luis H.", ""], ["P\u00e9rez-Lantero", "Pablo", ""]]}, {"id": "1805.11190", "submitter": "Alex Elchesen", "authors": "Alexander Elchesen and Facundo M\\'emoli", "title": "The reflection distance between zigzag persistence modules", "comments": "30 pages, 2 figures. Final version; to appear in the Journal of\n  Applied and Computational Topology", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AT cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By invoking the reflection functors introduced by Bernstein, Gelfand, and\nPonomarev in 1973, in this paper we define a metric on the space of all zigzag\nmodules of a given length, which we call the reflection distance. We show that\nthe reflection distance between two given zigzag modules of the same length is\nan upper bound for the $\\ell^1$-bottleneck distance between their respective\npersistence diagrams.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 22:13:14 GMT"}, {"version": "v2", "created": "Sat, 16 Mar 2019 23:18:23 GMT"}, {"version": "v3", "created": "Mon, 1 Jul 2019 16:34:01 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Elchesen", "Alexander", ""], ["M\u00e9moli", "Facundo", ""]]}, {"id": "1805.11436", "submitter": "Xavier Pennec", "authors": "Xavier Pennec (EPIONE, UCA)", "title": "Parallel Transport with Pole Ladder: a Third Order Scheme in Affine\n  Connection Spaces which is Exact in Affine Symmetric Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.DG cs.CG math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parallel transport is an important step in many discrete algorithms for\nstatistical computing on manifolds. Numerical methods based on Jacobi fields or\ngeodesics parallelograms are currently used in geometric data processing. In\nthis last class, pole ladder is a simplification of Schild's ladder for the\nparallel transport along geodesics that was shown to be particularly simple and\nnumerically stable in Lie groups. So far, these methods were shown to be first\norder approximations of the Riemannian parallel transport, but higher order\nerror terms are difficult to establish. In this paper, we build on a BCH-type\nformula on affine connection spaces to establish the behavior of one pole\nladder step up to order 5. It is remarkable that the scheme is of order three\nin general affine connection spaces with a symmetric connection, much higher\nthan expected. Moreover, the fourth-order term involves the covariant\nderivative of the curvature only, which is vanishing in locally symmetric\nspace. We show that pole ladder is actually locally exact in these spaces, and\neven almost surely globally exact in Riemannian symmetric manifolds. These\nproperties make pole ladder a very attractive alternative to other methods in\ngeneral affine manifolds with a symmetric connection.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 13:28:11 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Pennec", "Xavier", "", "EPIONE, UCA"]]}, {"id": "1805.11679", "submitter": "Yaar Solomon", "authors": "Michael Boshernitzan and Yaar Solomon", "title": "On Visibility Problems with an Infinite Discrete, set of Obstacles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.MG cs.CG math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies visibility problems in Euclidean spaces $\\mathbb{R}^d$\nwhere the obstacles are the points of infinite discrete sets\n$Y\\subseteq\\mathbb{R}^d$. A point $x\\in\\mathbb{R}^d$ is called\n$\\varepsilon$-visible for $Y$ (notation: $x\\in\\mathbf{vis}(Y, \\varepsilon))$ if\nthere exists a ray $L\\subseteq\\mathbb{R}^d$ emanating from $x$ such that\n$||y-z||\\geq\\varepsilon$, for all $y\\in Y\\setminus\\{x\\}$ and $z\\in L$. A point\n$x\\in\\mathbb{R}^d$ is called visible for $Y$ (notation: $x\\in\\mathbf{vis}(Y))$\nif $x\\in\\mathbf{vis}(Y, \\varepsilon))$, for some $\\varepsilon>0$.\\\\ Our main\nresult is the following. For every $\\varepsilon>0$ and every relatively dense\nset $Y\\subseteq\\mathbb{R}^2$, $\\mathbf{vis}(Y, \\varepsilon))\\neq\\mathbb{R}^2$.\nThis result generalizes a theorem of Dumitrescu and Jiang, which settled\nMitchell's dark forest conjecture. On the other hand, we show that there exists\na relatively dense subset $Y\\subseteq \\mathbb{Z}^d$ such that\n$\\mathbf{vis}(Y)=\\mathbb{R}^d$. (One easily verifies that\n$\\mathbf{vis}(\\mathbb{Z}^d)=\\mathbb{R}^d\\setminus\\mathbb{Z}^d$, for all $d\\geq\n2$). We derive a number of other results clarifying how the size of a sets\n$Y\\subseteq\\mathbb{R}^d$ may affect the sets $\\mathbf{vis}(Y)$ and\n$\\mathbf{vis}(Y,\\varepsilon)$. We present a Ramsey type result concerning\nuniformly separated subsets of $\\mathbb{R}^2$ whose growth is faster than\nlinear.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 19:31:02 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Boshernitzan", "Michael", ""], ["Solomon", "Yaar", ""]]}, {"id": "1805.12279", "submitter": "Tolga Birdal", "authors": "Tolga Birdal, Umut \\c{S}im\\c{s}ekli, M. Onur Eken, Slobodan Ilic", "title": "Bayesian Pose Graph Optimization via Bingham Distributions and Tempered\n  Geodesic MCMC", "comments": "Published at NeurIPS 2018, 25 pages with supplements", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Tempered Geodesic Markov Chain Monte Carlo (TG-MCMC) algorithm\nfor initializing pose graph optimization problems, arising in various scenarios\nsuch as SFM (structure from motion) or SLAM (simultaneous localization and\nmapping). TG-MCMC is first of its kind as it unites asymptotically global\nnon-convex optimization on the spherical manifold of quaternions with posterior\nsampling, in order to provide both reliable initial poses and uncertainty\nestimates that are informative about the quality of individual solutions. We\ndevise rigorous theoretical convergence guarantees for our method and\nextensively evaluate it on synthetic and real benchmark datasets. Besides its\nelegance in formulation and theory, we show that our method is robust to\nmissing data, noise and the estimated uncertainties capture intuitive\nproperties of the data.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2018 01:14:57 GMT"}, {"version": "v2", "created": "Sat, 30 Mar 2019 17:23:30 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Birdal", "Tolga", ""], ["\u015eim\u015fekli", "Umut", ""], ["Eken", "M. Onur", ""], ["Ilic", "Slobodan", ""]]}]