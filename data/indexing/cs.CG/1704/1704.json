[{"id": "1704.00142", "submitter": "Alberto Paoluzzi", "authors": "Alberto Paoluzzi, Vadim Shapiro, Antonio DiCarlo", "title": "Regularized arrangements of cellular complexes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a novel algorithm to combine two or more cellular\ncomplexes, providing a minimal fragmentation of the cells of the resulting\ncomplex. We introduce here the idea of arrangement generated by a collection of\ncellular complexes, producing a cellular decomposition of the embedding space.\nThe algorithm that executes this computation is called \\emph{Merge} of\ncomplexes. The arrangements of line segments in 2D and polygons in 3D are\nspecial cases, as well as the combination of closed triangulated surfaces or\nmeshed models. This algorithm has several important applications, including\nBoolean and other set operations over large geometric models, the extraction of\nsolid models of biomedical structures at the cellular scale, the detailed\ngeometric modeling of buildings, the combination of 3D meshes, and the repair\nof graphical models. The algorithm is efficiently implemented using the Linear\nAlgebraic Representation (LAR) of argument complexes, i.e., on sparse\nrepresentation of binary characteristic matrices of $d$-cell bases, well-suited\nfor implementation in last generation accelerators and GPGPU applications.\n", "versions": [{"version": "v1", "created": "Sat, 1 Apr 2017 08:45:58 GMT"}, {"version": "v2", "created": "Mon, 15 May 2017 14:37:45 GMT"}, {"version": "v3", "created": "Fri, 9 Jun 2017 15:27:41 GMT"}, {"version": "v4", "created": "Fri, 25 Aug 2017 19:10:42 GMT"}], "update_date": "2017-08-29", "authors_parsed": [["Paoluzzi", "Alberto", ""], ["Shapiro", "Vadim", ""], ["DiCarlo", "Antonio", ""]]}, {"id": "1704.00143", "submitter": "Arkadiy Skopenkov", "authors": "Arkadiy Skopenkov", "title": "Eliminating higher-multiplicity intersections in the metastable\n  dimension range", "comments": "20 pages, 2 figures, exposition improved, appendix added. arXiv admin\n  note: text overlap with arXiv:1702.04259", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.GT cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The $r$-fold analogues of Whitney trick were `in the air' since 1960s.\nHowever, only in this century they were stated, proved and applied to obtain\ninteresting results. Here we prove and apply a version of the $r$-fold Whitney\ntrick when general position $r$-tuple intersections have positive dimension.\n  Theorem. Assume that $D=D_1\\sqcup\\ldots\\sqcup D_r$ is disjoint union of\n$k$-dimensional disks, $rd\\ge (r+1)k+3$, and $f:D\\to B^d$ a proper PL (smooth)\nmap such that $f\\partial D_1\\cap\\ldots\\cap f\\partial D_r=\\emptyset$. If the map\n$$f^r:\\partial(D_1\\times\\ldots\\times D_r)\\to\n(B^d)^r-\\{(x,x,\\ldots,x)\\in(B^d)^r\\ |\\ x\\in B^d\\}$$ extends to\n$D_1\\times\\ldots\\times D_r$, then there is a proper PL (smooth) map $\\overline\nf:D\\to B^d$ such that $\\overline f=f$ on $\\partial D$ and $\\overline\nfD_1\\cap\\ldots\\cap \\overline fD_r=\\emptyset$.\n", "versions": [{"version": "v1", "created": "Sat, 1 Apr 2017 09:05:32 GMT"}, {"version": "v2", "created": "Sun, 8 Mar 2020 12:38:54 GMT"}, {"version": "v3", "created": "Wed, 27 Jan 2021 14:02:37 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Skopenkov", "Arkadiy", ""]]}, {"id": "1704.00229", "submitter": "Istv\\'an Kov\\'acs", "authors": "Istv\\'an Kov\\'acs and G\\'eza T\\'oth", "title": "Dense point sets with many halving lines", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A planar point set of $n$ points is called {\\em $\\gamma$-dense} if the ratio\nof the largest and smallest distances among the points is at most\n$\\gamma\\sqrt{n}$. We construct a dense set of $n$ points in the plane with\n$ne^{\\Omega\\left({\\sqrt{\\log n}}\\right)}$ halving lines. This improves the\nbound $\\Omega(n\\log n)$ of Edelsbrunner, Valtr and Welzl from 1997.\n  Our construction can be generalized to higher dimensions, for any $d$ we\nconstruct a dense point set of $n$ points in $\\mathbb{R}^d$ with\n$n^{d-1}e^{\\Omega\\left({\\sqrt{\\log n}}\\right)}$ halving hyperplanes. Our lower\nbounds are asymptotically the same as the best known lower bounds for general\npoint sets.\n", "versions": [{"version": "v1", "created": "Sat, 1 Apr 2017 21:00:43 GMT"}, {"version": "v2", "created": "Fri, 29 Mar 2019 14:19:56 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Kov\u00e1cs", "Istv\u00e1n", ""], ["T\u00f3th", "G\u00e9za", ""]]}, {"id": "1704.00300", "submitter": "Arkadiy Skopenkov", "authors": "A. Skopenkov", "title": "On van Kampen-Flores, Conway-Gordon-Sachs and Radon theorems", "comments": "5 pages", "journal-ref": "published as \\S4 of Russian Math. Surveys, 73:2 (2018), 323-353", "doi": null, "report-no": null, "categories": "math.GT cs.CG math.AT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We exhibit relations between van Kampen-Flores, Conway-Gordon-Sachs and Radon\ntheorems, by presenting direct proofs of some implications between them. The\nkey idea is an interesting relation between the van Kampen and the\nConway-Gordon-Sachs numbers for restrictions of a map of $(d+2)$-simplex to\n$\\mathbb R^d$ to the $(d+1)$-face and to the $[d/2]$-skeleton.\n", "versions": [{"version": "v1", "created": "Sun, 2 Apr 2017 14:01:53 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["Skopenkov", "A.", ""]]}, {"id": "1704.00565", "submitter": "Eva Rotenberg", "authors": "Jacob Holm, Eva Rotenberg", "title": "Dynamic Planar Embeddings of Dynamic Graphs", "comments": "Announced at STACS'15", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an algorithm to support the dynamic embedding in the plane of a\ndynamic graph. An edge can be inserted across a face between two vertices on\nthe face boundary (we call such a vertex pair linkable), and edges can be\ndeleted. The planar embedding can also be changed locally by flipping\ncomponents that are connected to the rest of the graph by at most two vertices.\n  Given vertices $u,v$, linkable$(u,v)$ decides whether $u$ and $v$ are\nlinkable in the current embedding, and if so, returns a list of suggestions for\nthe placement of $(u,v)$ in the embedding. For non-linkable vertices $u,v$, we\ndefine a new query, one-flip-linkable$(u,v)$ providing a suggestion for a flip\nthat will make them linkable if one exists. We support all updates and queries\nin O(log$^2 n$) time. Our time bounds match those of Italiano et al. for a\nstatic (flipless) embedding of a dynamic graph.\n  Our new algorithm is simpler, exploiting that the complement of a spanning\ntree of a connected plane graph is a spanning tree of the dual graph. The\nprimal and dual trees are interpreted as having the same Euler tour, and a main\nidea of the new algorithm is an elegant interaction between top trees over the\ntwo trees via their common Euler tour.\n", "versions": [{"version": "v1", "created": "Mon, 3 Apr 2017 13:15:59 GMT"}], "update_date": "2017-04-04", "authors_parsed": [["Holm", "Jacob", ""], ["Rotenberg", "Eva", ""]]}, {"id": "1704.00683", "submitter": "Joseph Lemley", "authors": "Joseph Lemley, Filip Jagodzinski, Razvan Andonie", "title": "Big Holes in Big Data: A Monte Carlo Algorithm for Detecting Large\n  Hyper-rectangles in High Dimensional Data", "comments": "Accepted: Computer Software and Applications Conference (COMPSAC),\n  2016 IEEE 40th Annual http://ieeexplore.ieee.org/abstract/document/7552073/", "journal-ref": null, "doi": "10.1109/COMPSAC.2016.73", "report-no": null, "categories": "cs.CG physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the first algorithm for finding holes in high dimensional data\nthat runs in polynomial time with respect to the number of dimensions. Previous\nalgorithms are exponential. Finding large empty rectangles or boxes in a set of\npoints in 2D and 3D space has been well studied. Efficient algorithms exist to\nidentify the empty regions in these low-dimensional spaces. Unfortunately such\nefficiency is lacking in higher dimensions where the problem has been shown to\nbe NP-complete when the dimensions are included in the input. Applications for\nalgorithms that find large empty spaces include big data analysis, recommender\nsystems, automated knowledge discovery, and query optimization. Our Monte\nCarlo-based algorithm discovers interesting maximal empty hyper-rectangles in\ncases where dimensionality and input size would otherwise make analysis\nimpractical. The run-time is polynomial in the size of the input and the number\nof dimensions. We apply the algorithm on a 39-dimensional data set for protein\nstructures and discover interesting properties that we think could not be\ninferred otherwise.\n", "versions": [{"version": "v1", "created": "Mon, 3 Apr 2017 16:51:44 GMT"}], "update_date": "2017-04-04", "authors_parsed": [["Lemley", "Joseph", ""], ["Jagodzinski", "Filip", ""], ["Andonie", "Razvan", ""]]}, {"id": "1704.01687", "submitter": "Nathan Chadder", "authors": "Nathan Chadder, Antoine Deza", "title": "Computational determination of the largest lattice polytope diameter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A lattice (d, k)-polytope is the convex hull of a set of points in dimension\nd whose coordinates are integers between 0 and k. Let {\\delta}(d, k) be the\nlargest diameter over all lattice (d, k)-polytopes. We develop a computational\nframework to determine {\\delta}(d, k) for small instances. We show that\n{\\delta}(3, 4) = 7 and {\\delta}(3, 5) = 9; that is, we verify for (d, k) = (3,\n4) and (3, 5) the conjecture whereby {\\delta}(d, k) is at most (k + 1)d/2 and\nis achieved, up to translation, by a Minkowski sum of lattice vectors.\n", "versions": [{"version": "v1", "created": "Thu, 6 Apr 2017 02:02:25 GMT"}], "update_date": "2017-04-07", "authors_parsed": [["Chadder", "Nathan", ""], ["Deza", "Antoine", ""]]}, {"id": "1704.02515", "submitter": "Hu Ding", "authors": "Hu Ding", "title": "Balanced $k$-Center Clustering When $k$ Is A Constant", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of constrained $k$-center clustering has attracted significant\nattention in the past decades. In this paper, we study balanced $k$-center\ncluster where the size of each cluster is constrained by the given lower and\nupper bounds. The problem is motivated by the applications in processing and\nanalyzing large-scale data in high dimension. We provide a simple nearly linear\ntime $4$-approximation algorithm when the number of clusters $k$ is assumed to\nbe a constant. Comparing with existing method, our algorithm improves the\napproximation ratio and significantly reduces the time complexity. Moreover,\nour result can be easily extended to any metric space.\n", "versions": [{"version": "v1", "created": "Sat, 8 Apr 2017 17:30:26 GMT"}], "update_date": "2017-04-11", "authors_parsed": [["Ding", "Hu", ""]]}, {"id": "1704.02525", "submitter": "Gary Pui-Tung Choi", "authors": "Gary P. T. Choi, Chris H. Rycroft", "title": "Density-equalizing maps for simply-connected open surfaces", "comments": null, "journal-ref": "SIAM Journal on Imaging Sciences 11, 1134-1178 (2018)", "doi": "10.1137/17M1124796", "report-no": null, "categories": "cs.CG cs.GR math.DG math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we are concerned with the problem of creating flattening maps\nof simply-connected open surfaces in $\\mathbb{R}^3$. Using a natural principle\nof density diffusion in physics, we propose an effective algorithm for\ncomputing density-equalizing flattening maps with any prescribed density\ndistribution. By varying the initial density distribution, a large variety of\nmappings with different properties can be achieved. For instance,\narea-preserving parameterizations of simply-connected open surfaces can be\neasily computed. Experimental results are presented to demonstrate the\neffectiveness of our proposed method. Applications to data visualization and\nsurface remeshing are explored.\n", "versions": [{"version": "v1", "created": "Sat, 8 Apr 2017 19:08:08 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Choi", "Gary P. T.", ""], ["Rycroft", "Chris H.", ""]]}, {"id": "1704.02546", "submitter": "Sariel Har-Peled", "authors": "Sariel Har-Peled and Sepideh Mahabadi", "title": "LSH on the Hypercube Revisited", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  LSH (locality sensitive hashing) had emerged as a powerful technique in\nnearest-neighbor search in high dimensions [IM98, HIM12]. Given a point set $P$\nin a metric space, and given parameters $r$ and $\\varepsilon > 0$, the task is\nto preprocess the point set, such that given a query point $q$, one can quickly\ndecide if $q$ is in distance at most $\\leq r$ or $\\geq (1+\\varepsilon)r$ from\nthe point set $P$. Once such a near-neighbor data-structure is available, one\ncan reduce the general nearest-neighbor search to logarithmic number of queries\nin such structures [IM98, Har01, HIM12].\n  In this note, we revisit the most basic settings, where $P$ is a set of\npoints in the binary hypercube $\\{0,1\\}^d$, under the $L_1$/Hamming metric, and\npresent a short description of the LSH scheme in this case. We emphasize that\nthere is no new contribution in this note, except (maybe) the presentation\nitself, which is inspired by the authors recent work [HM17].\n", "versions": [{"version": "v1", "created": "Sun, 9 Apr 2017 00:46:49 GMT"}], "update_date": "2017-04-11", "authors_parsed": [["Har-Peled", "Sariel", ""], ["Mahabadi", "Sepideh", ""]]}, {"id": "1704.02793", "submitter": "Shay Mozes", "authors": "Pawe{\\l} Gawrychowski, Haim Kaplan, Shay Mozes, Micha Sharir, Oren\n  Weimann", "title": "Voronoi diagrams on planar graphs, and computing the diameter in\n  deterministic $\\tilde{O}(n^{5/3})$ time", "comments": "SODA 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an explicit and efficient construction of additively weighted\nVoronoi diagrams on planar graphs. Let $G$ be a planar graph with $n$ vertices\nand $b$ sites that lie on a constant number of faces. We show how to preprocess\n$G$ in $\\tilde O(nb^2)$ time (footnote: The $\\tilde O$ notation hides\npolylogarithmic factors.) so that one can compute any additively weighted\nVoronoi diagram for these sites in $\\tilde O(b)$ time.\n  We use this construction to compute the diameter of a directed planar graph\nwith real arc lengths in $\\tilde{O}(n^{5/3})$ time. This improves the recent\nbreakthrough result of Cabello (SODA'17), both by improving the running time\n(from $\\tilde{O}(n^{11/6})$), and by providing a deterministic algorithm. It is\nin fact the first truly subquadratic {\\em deterministic} algorithm for this\nproblem. Our use of Voronoi diagrams to compute the diameter follows that of\nCabello, but he used abstract Voronoi diagrams, which makes his diameter\nalgorithm more involved, more expensive, and randomized.\n  As in Cabello's work, our algorithm can compute, for every vertex $v$, both\nthe farthest vertex from $v$ (i.e., the eccentricity of $v$), and the sum of\ndistances from $v$ to all other vertices. Hence, our algorithm can also compute\nthe radius, median, and Wiener index (sum of all pairwise distances) of a\nplanar graph within the same time bounds. Our construction of Voronoi diagrams\nfor planar graphs is of independent interest.\n", "versions": [{"version": "v1", "created": "Mon, 10 Apr 2017 10:35:42 GMT"}, {"version": "v2", "created": "Sun, 25 Feb 2018 14:46:20 GMT"}, {"version": "v3", "created": "Wed, 24 Jun 2020 20:43:52 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Gawrychowski", "Pawe\u0142", ""], ["Kaplan", "Haim", ""], ["Mozes", "Shay", ""], ["Sharir", "Micha", ""], ["Weimann", "Oren", ""]]}, {"id": "1704.03103", "submitter": "EPTCS", "authors": "Benoit Desrochers (DGA-TN), Luc Jaulin (Ensta Bretagne, Lab-Sticc)", "title": "Minkowski Operations of Sets with Application to Robot Localization", "comments": "In Proceedings SNR 2017, arXiv:1704.02421", "journal-ref": "EPTCS 247, 2017, pp. 34-45", "doi": "10.4204/EPTCS.247.3", "report-no": null, "categories": "cs.RO cs.AI cs.CG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This papers shows that using separators, which is a pair of two complementary\ncontractors, we can easily and efficiently solve the localization problem of a\nrobot with sonar measurements in an unstructured environment. We introduce\nseparators associated with the Minkowski sum and the Minkowski difference in\norder to facilitate the resolution. A test-case is given in order to illustrate\nthe principle of the approach.\n", "versions": [{"version": "v1", "created": "Tue, 11 Apr 2017 00:56:51 GMT"}], "update_date": "2017-04-12", "authors_parsed": [["Desrochers", "Benoit", "", "DGA-TN"], ["Jaulin", "Luc", "", "Ensta Bretagne, Lab-Sticc"]]}, {"id": "1704.03132", "submitter": "Yifei Jin", "authors": "Yifei Jin, Jian Li, Wei Zhan", "title": "Odd Yao-Yao Graphs are Not Spanners", "comments": "29 pages, 26 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is a long standing open problem whether Yao-Yao graphs $\\mathsf{YY}_{k}$\nare all spanners [li2002sparse]. Bauer and Damian [bauer2013infinite] showed\nthat all $\\mathsf{YY}_{6k}$ for $k \\geq 6$ are spanners. Li and Zhan\n[li2016almost] generalized their result and proved that all even Yao-Yao graphs\n$\\mathsf{YY}_{2k}$ are spanners (for $k\\geq 42$). However, their technique\ncannot be extended to odd Yao-Yao graphs, and whether they are spanners are\nstill elusive. In this paper, we show that, surprisingly, for any integer $k\n\\geq 1$, there exist odd Yao-Yao graph $\\mathsf{YY}_{2k+1}$ instances, which\nare not spanners.\n", "versions": [{"version": "v1", "created": "Tue, 11 Apr 2017 03:50:11 GMT"}, {"version": "v2", "created": "Sun, 18 Mar 2018 22:46:53 GMT"}, {"version": "v3", "created": "Tue, 20 Mar 2018 02:04:12 GMT"}, {"version": "v4", "created": "Sun, 12 Aug 2018 08:07:13 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Jin", "Yifei", ""], ["Li", "Jian", ""], ["Zhan", "Wei", ""]]}, {"id": "1704.03140", "submitter": "Chun Pong Lau", "authors": "Chun Pong Lau, Yu Hin Lai, Lok Ming Lui", "title": "Restoration of Atmospheric Turbulence-distorted Images via RPCA and\n  Quasiconformal Maps", "comments": "21 pages, 24 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CG cs.GR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We address the problem of restoring a high-quality image from an observed\nimage sequence strongly distorted by atmospheric turbulence. A novel algorithm\nis proposed in this paper to reduce geometric distortion as well as\nspace-and-time-varying blur due to strong turbulence. By considering a suitable\nenergy functional, our algorithm first obtains a sharp reference image and a\nsubsampled image sequence containing sharp and mildly distorted image frames\nwith respect to the reference image. The subsampled image sequence is then\nstabilized by applying the Robust Principal Component Analysis (RPCA) on the\ndeformation fields between image frames and warping the image frames by a\nquasiconformal map associated with the low-rank part of the deformation matrix.\nAfter image frames are registered to the reference image, the low-rank part of\nthem are deblurred via a blind deconvolution, and the deblurred frames are then\nfused with the enhanced sparse part. Experiments have been carried out on both\nsynthetic and real turbulence-distorted video. Results demonstrate that our\nmethod is effective in alleviating distortions and blur, restoring image\ndetails and enhancing visual quality.\n", "versions": [{"version": "v1", "created": "Tue, 11 Apr 2017 04:24:44 GMT"}, {"version": "v2", "created": "Tue, 19 Sep 2017 03:40:28 GMT"}], "update_date": "2017-09-20", "authors_parsed": [["Lau", "Chun Pong", ""], ["Lai", "Yu Hin", ""], ["Lui", "Lok Ming", ""]]}, {"id": "1704.03564", "submitter": "Shay Moran", "authors": "Daniel M. Kane and Shachar Lovett and Shay Moran and Jiapeng Zhang", "title": "Active classification with comparison queries", "comments": "23 pages (not including references), 1 figure. The new version\n  contains a minor fix in the proof of Lemma 4.2", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study an extension of active learning in which the learning algorithm may\nask the annotator to compare the distances of two examples from the boundary of\ntheir label-class. For example, in a recommendation system application (say for\nrestaurants), the annotator may be asked whether she liked or disliked a\nspecific restaurant (a label query); or which one of two restaurants did she\nlike more (a comparison query).\n  We focus on the class of half spaces, and show that under natural\nassumptions, such as large margin or bounded bit-description of the input\nexamples, it is possible to reveal all the labels of a sample of size $n$ using\napproximately $O(\\log n)$ queries. This implies an exponential improvement over\nclassical active learning, where only label queries are allowed. We complement\nthese results by showing that if any of these assumptions is removed then, in\nthe worst case, $\\Omega(n)$ queries are required.\n  Our results follow from a new general framework of active learning with\nadditional queries. We identify a combinatorial dimension, called the\n\\emph{inference dimension}, that captures the query complexity when each\nadditional query is determined by $O(1)$ examples (such as comparison queries,\neach of which is determined by the two compared examples). Our results for half\nspaces follow by bounding the inference dimension in the cases discussed above.\n", "versions": [{"version": "v1", "created": "Tue, 11 Apr 2017 22:55:29 GMT"}, {"version": "v2", "created": "Fri, 2 Jun 2017 00:49:37 GMT"}], "update_date": "2017-06-05", "authors_parsed": [["Kane", "Daniel M.", ""], ["Lovett", "Shachar", ""], ["Moran", "Shay", ""], ["Zhang", "Jiapeng", ""]]}, {"id": "1704.03596", "submitter": "Andr\\'e Van Renssen", "authors": "Prosenjit Bose, Rolf Fagerberg, Andr\\'e van Renssen, Sander\n  Verdonschot", "title": "On Plane Constrained Bounded-Degree Spanners", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $P$ be a finite set of points in the plane and $S$ a set of non-crossing\nline segments with endpoints in $P$. The visibility graph of $P$ with respect\nto $S$, denoted $Vis(P,S)$, has vertex set $P$ and an edge for each pair of\nvertices $u,v$ in $P$ for which no line segment of $S$ properly intersects\n$uv$. We show that the constrained half-$\\theta_6$-graph (which is identical to\nthe constrained Delaunay graph whose empty visible region is an equilateral\ntriangle) is a plane 2-spanner of $Vis(P,S)$. We then show how to construct a\nplane 6-spanner of $Vis(P,S)$ with maximum degree $6+c$, where $c$ is the\nmaximum number of segments of $S$ incident to a vertex.\n", "versions": [{"version": "v1", "created": "Wed, 12 Apr 2017 02:05:47 GMT"}, {"version": "v2", "created": "Fri, 22 Jun 2018 01:11:25 GMT"}], "update_date": "2018-06-25", "authors_parsed": [["Bose", "Prosenjit", ""], ["Fagerberg", "Rolf", ""], ["van Renssen", "Andr\u00e9", ""], ["Verdonschot", "Sander", ""]]}, {"id": "1704.03965", "submitter": "Facundo Memoli", "authors": "Facundo Memoli", "title": "A Distance Between Filtered Spaces Via Tripods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AT cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a simplified treatment of stability of filtrations on finite\nspaces. Interestingly, we can lift the stability result for combinatorial\nfiltrations from [CSEM06] to the case when two filtrations live on different\nspaces without directly invoking the concept of interleaving. We then prove\nthat this distance is intrinsic by constructing explicit geodesics between any\npair of filtered spaces. Finally we use this construction to obtain a\nstrengthening of the stability result.\n", "versions": [{"version": "v1", "created": "Thu, 13 Apr 2017 01:29:09 GMT"}, {"version": "v2", "created": "Tue, 12 Dec 2017 19:37:13 GMT"}], "update_date": "2017-12-14", "authors_parsed": [["Memoli", "Facundo", ""]]}, {"id": "1704.05123", "submitter": "Ching-Hsiang Hsu", "authors": "Chee K. Yap, Zhongdi Luo, and Ching-Hsiang Hsu", "title": "Resolution-Exact Planner for Thick Non-Crossing 2-Link Robots", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the path planning problem for a 2-link robot amidst polygonal\nobstacles. Our robot is parametrizable by the lengths $\\ell_1, \\ell_2>0$ of its\ntwo links, the thickness $\\tau \\ge 0$ of the links, and an angle $\\kappa$ that\nconstrains the angle between the 2 links to be strictly greater than $\\kappa$.\nThe case $\\tau>0$ and $\\kappa \\ge 0$ corresponds to \"thick non-crossing\"\nrobots. This results in a novel 4DOF configuration space ${\\mathbb R}^2\\times\n({\\mathbb T}\\setminus\\Delta(\\kappa))$ where ${\\mathbb T}$ is the torus and\n$\\Delta(\\kappa)$ the diagonal band of width $\\kappa$. We design a\nresolution-exact planner for this robot using the framework of Soft Subdivision\nSearch (SSS). First, we provide an analysis of the space of forbidden angles,\nleading to a soft predicate for classifying configuration boxes. We further\nexploit the T/R splitting technique which was previously introduced for\nself-crossing thin 2-link robots. Our open-source implementation in Core\nLibrary achieves real-time performance for a suite of combinatorially\nnon-trivial obstacle sets. Experimentally, our algorithm is significantly\nbetter than any of the state-of-art sampling algorithms we looked at, in timing\nand in success rate.\n", "versions": [{"version": "v1", "created": "Mon, 17 Apr 2017 21:06:41 GMT"}], "update_date": "2017-04-19", "authors_parsed": [["Yap", "Chee K.", ""], ["Luo", "Zhongdi", ""], ["Hsu", "Ching-Hsiang", ""]]}, {"id": "1704.05909", "submitter": "James  Peters Ph.D.", "authors": "J.F. Peters", "title": "Proximal Nerve Complexes. A Computational Topology Approach", "comments": "16 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article introduces a theory of proximal nerve complexes and nerve\nspokes, restricted to the triangulation of finite regions in the Euclidean\nplane. A nerve complex is a collection of filled triangles with a common\nvertex, covering a finite region of the plane. Structures called $k$-spokes,\n$k\\geq 1$, are a natural extension of nerve complexes. A $k$-spoke is the union\nof a collection of filled triangles that pairwise either have a common edge or\na common vertex. A consideration of the closeness of nerve complexes leads to a\nproximal view of simplicial complexes. A practical application of proximal\nnerve complexes is given, briefly, in terms of object shape geometry in digital\nimages.\n", "versions": [{"version": "v1", "created": "Wed, 22 Mar 2017 23:15:17 GMT"}], "update_date": "2017-04-21", "authors_parsed": [["Peters", "J. F.", ""]]}, {"id": "1704.05964", "submitter": "Alfred Rossi", "authors": "Tamal K. Dey, Alfred Rossi, Anastasios Sidiropoulos", "title": "Temporal Clustering", "comments": "27 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of clustering sequences of unlabeled point sets taken\nfrom a common metric space. Such scenarios arise naturally in applications\nwhere a system or process is observed in distinct time intervals, such as\nbiological surveys and contagious disease surveillance. In this more general\nsetting existing algorithms for classical (i.e.~static) clustering problems are\nnot applicable anymore.\n  We propose a set of optimization problems which we collectively refer to as\n'temporal clustering'. The quality of a solution to a temporal clustering\ninstance can be quantified using three parameters: the number of clusters $k$,\nthe spatial clustering cost $r$, and the maximum cluster displacement $\\delta$\nbetween consecutive time steps. We consider spatial clustering costs which\ngeneralize the well-studied $k$-center, discrete $k$-median, and discrete\n$k$-means objectives of classical clustering problems. We develop new\nalgorithms that achieve trade-offs between the three objectives $k$, $r$, and\n$\\delta$. Our upper bounds are complemented by inapproximability results.\n", "versions": [{"version": "v1", "created": "Thu, 20 Apr 2017 00:17:43 GMT"}], "update_date": "2017-10-17", "authors_parsed": [["Dey", "Tamal K.", ""], ["Rossi", "Alfred", ""], ["Sidiropoulos", "Anastasios", ""]]}, {"id": "1704.06823", "submitter": "Yingkai Li", "authors": "Jing Chen, Bo Li, Yingkai Li", "title": "Efficient Approximations for the Online Dispersion Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The dispersion problem has been widely studied in computational geometry and\nfacility location, and is closely related to the packing problem. The goal is\nto locate n points (e.g., facilities or persons) in a k-dimensional polytope,\nso that they are far away from each other and from the boundary of the\npolytope. In many real-world scenarios however, the points arrive and depart at\ndifferent times, and decisions must be made without knowing future events.\nTherefore we study, for the first time in the literature, the online dispersion\nproblem in Euclidean space.\n  There are two natural objectives when time is involved: the all-time\nworst-case (ATWC) problem tries to maximize the minimum distance that ever\nappears at any time; and the cumulative distance (CD) problem tries to maximize\nthe integral of the minimum distance throughout the whole time interval.\nInterestingly, the online problems are highly non-trivial even on a segment.\nFor cumulative distance, this remains the case even when the problem is\ntime-dependent but offline, with all the arriving and departure times given in\nadvance.\n  For the online ATWC problem on a segment, we construct a deterministic\npolynomial-time algorithm which is (2ln2+epsilon)-competitive, where epsilon>0\ncan be arbitrarily small and the algorithm's running time is polynomial in\n1/epsilon. We show this algorithm is actually optimal. For the same problem in\na square, we provide a 1.591-competitive algorithm and a 1.183 lower-bound.\nFurthermore, for arbitrary k-dimensional polytopes with k>=2, we provide a\n2/(1-epsilon)-competitive algorithm and a 7/6 lower-bound. Interestingly, for\nthe offline CD problem in arbitrary k-dimensional polytopes, we provide a\npolynomial-time black-box reduction to the online ATWC problem, and the\nresulting competitive ratio increases by a factor of at most 2.\n", "versions": [{"version": "v1", "created": "Sat, 22 Apr 2017 17:29:58 GMT"}], "update_date": "2017-04-25", "authors_parsed": [["Chen", "Jing", ""], ["Li", "Bo", ""], ["Li", "Yingkai", ""]]}, {"id": "1704.06856", "submitter": "Adam Strzebonski", "authors": "Adam Strzebonski", "title": "CAD Adjacency Computation Using Validated Numerics", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SC cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an algorithm for computation of cell adjacencies for well-based\ncylindrical algebraic decomposition. Cell adjacency information can be used to\ncompute topological operations e.g. closure, boundary, connected components,\nand topological properties e.g. homology groups. Other applications include\nvisualization and path planning. Our algorithm determines cell adjacency\ninformation using validated numerical methods similar to those used in CAD\nconstruction, thus computing CAD with adjacency information in time comparable\nto that of computing CAD without adjacency information. We report on\nimplementation of the algorithm and present empirical data.\n", "versions": [{"version": "v1", "created": "Sat, 22 Apr 2017 23:26:57 GMT"}], "update_date": "2017-04-25", "authors_parsed": [["Strzebonski", "Adam", ""]]}, {"id": "1704.06870", "submitter": "Haitao Wang", "authors": "Shimin Li and Haitao Wang", "title": "Algorithms for Covering Multiple Barriers", "comments": "This version will be published in TCS. This version corrects an\n  algorithm time analysis error in the previous version for the\n  line-constrained problem", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problems for covering multiple intervals on a\nline. Given a set $B$ of $m$ line segments (called \"barriers\") on a horizontal\nline $L$ and another set $S$ of $n$ horizontal line segments of the same length\nin the plane, we want to move all segments of $S$ to $L$ so that their union\ncovers all barriers and the maximum movement of all segments of $S$ is\nminimized. Previously, an $O(n^3\\log n)$-time algorithm was given for the case\n$m=1$. In this paper, we propose an $O(n^2\\log n\\log \\log n+nm\\log m)$-time\nalgorithm for a more general setting with any $m\\geq 1$, which also improves\nthe previous work when $m=1$. We then consider a line-constrained version of\nthe problem in which the segments of $S$ are all initially on the line $L$.\nPreviously, an $O(n\\log n)$-time algorithm was known for the case $m=1$. We\npresent an algorithm of $O(m\\log m+n\\log m \\log n)$ time for any $m\\geq 1$.\nThese problems may have applications in mobile sensor barrier coverage in\nwireless sensor networks.\n", "versions": [{"version": "v1", "created": "Sun, 23 Apr 2017 01:36:58 GMT"}, {"version": "v2", "created": "Fri, 18 Aug 2017 22:07:46 GMT"}, {"version": "v3", "created": "Wed, 8 Aug 2018 17:39:33 GMT"}], "update_date": "2018-08-09", "authors_parsed": [["Li", "Shimin", ""], ["Wang", "Haitao", ""]]}, {"id": "1704.06969", "submitter": "Mikkel Abrahamsen", "authors": "Mikkel Abrahamsen, Anna Adamaszek, Tillmann Miltzow", "title": "The Art Gallery Problem is $\\exists \\mathbb{R}$-complete", "comments": "To appear at STOC 2018. The paper has been reorganized a bit since\n  previous version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that the art gallery problem is equivalent under polynomial time\nreductions to deciding whether a system of polynomial equations over the real\nnumbers has a solution. The art gallery problem is a classical problem in\ncomputational geometry. Given a simple polygon $P$ and an integer $k$, the goal\nis to decide if there exists a set $G$ of $k$ guards within $P$ such that every\npoint $p\\in P$ is seen by at least one guard $g\\in G$. Each guard corresponds\nto a point in the polygon $P$, and we say that a guard $g$ sees a point $p$ if\nthe line segment $pg$ is contained in $P$.\n  The art gallery problem has stimulated extensive research in geometry and in\nalgorithms. However, the complexity status of the art gallery problem has not\nbeen resolved. It has long been known that the problem is $\\text{NP}$-hard, but\nno one has been able to show that it lies in $\\text{NP}$. Recently, the\ncomputational geometry community became more aware of the complexity class\n$\\exists \\mathbb{R}$. The class $\\exists \\mathbb{R}$ consists of problems that\ncan be reduced in polynomial time to the problem of deciding whether a system\nof polynomial equations with integer coefficients and any number of real\nvariables has a solution. It can be easily seen that $\\text{NP}\\subseteq\n\\exists \\mathbb{R}$. We prove that the art gallery problem is $\\exists\n\\mathbb{R}$-complete, implying that (1) any system of polynomial equations over\nthe real numbers can be encoded as an instance of the art gallery problem, and\n(2) the art gallery problem is not in the complexity class $\\text{NP}$ unless\n$\\text{NP}=\\exists \\mathbb{R}$. As a corollary of our construction, we prove\nthat for any real algebraic number $\\alpha$ there is an instance of the art\ngallery problem where one of the coordinates of the guards equals $\\alpha$ in\nany guard set of minimum cardinality. That rules out many geometric approaches\nto the problem.\n", "versions": [{"version": "v1", "created": "Sun, 23 Apr 2017 20:05:13 GMT"}, {"version": "v2", "created": "Thu, 11 Jan 2018 05:26:41 GMT"}, {"version": "v3", "created": "Tue, 8 May 2018 15:50:52 GMT"}, {"version": "v4", "created": "Wed, 9 May 2018 06:52:37 GMT"}], "update_date": "2018-05-10", "authors_parsed": [["Abrahamsen", "Mikkel", ""], ["Adamaszek", "Anna", ""], ["Miltzow", "Tillmann", ""]]}, {"id": "1704.07028", "submitter": "Yuan Li", "authors": "Jie Xue, Yuan Li, Ravi Janardan", "title": "On the expected diameter, width, and complexity of a stochastic\n  convex-hull", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate several computational problems related to the stochastic\nconvex hull (SCH). Given a stochastic dataset consisting of $n$ points in\n$\\mathbb{R}^d$ each of which has an existence probability, a SCH refers to the\nconvex hull of a realization of the dataset, i.e., a random sample including\neach point with its existence probability. We are interested in computing\ncertain expected statistics of a SCH, including diameter, width, and\ncombinatorial complexity. For diameter, we establish the first deterministic\n1.633-approximation algorithm with a time complexity polynomial in both $n$ and\n$d$. For width, two approximation algorithms are provided: a deterministic\n$O(1)$-approximation running in $O(n^{d+1} \\log n)$ time, and a fully\npolynomial-time randomized approximation scheme (FPRAS). For combinatorial\ncomplexity, we propose an exact $O(n^d)$-time algorithm. Our solutions exploit\nmany geometric insights in Euclidean space, some of which might be of\nindependent interest.\n", "versions": [{"version": "v1", "created": "Mon, 24 Apr 2017 03:33:24 GMT"}, {"version": "v2", "created": "Mon, 1 May 2017 05:36:14 GMT"}], "update_date": "2017-05-02", "authors_parsed": [["Xue", "Jie", ""], ["Li", "Yuan", ""], ["Janardan", "Ravi", ""]]}, {"id": "1704.07279", "submitter": "Fahad Panolan", "authors": "Fedor V. Fomin, Daniel Lokshtanov, Fahad Panolan, Saket Saurabh,\n  Meirav Zehavi", "title": "Finding, Hitting and Packing Cycles in Subexponential Time on Unit Disk\n  Graphs", "comments": "30 pages. To appear in ICALP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give algorithms with running time $2^{O({\\sqrt{k}\\log{k}})} \\cdot\nn^{O(1)}$ for the following problems. Given an $n$-vertex unit disk graph $G$\nand an integer $k$, decide whether $G$ contains (1) a path on exactly/at least\n$k$ vertices, (2) a cycle on exactly $k$ vertices, (3) a cycle on at least $k$\nvertices, (4) a feedback vertex set of size at most $k$, and (5) a set of $k$\npairwise vertex-disjoint cycles. For the first three problems, no\nsubexponential time parameterized algorithms were previously known. For the\nremaining two problems, our algorithms significantly outperform the previously\nbest known parameterized algorithms that run in time $2^{O(k^{0.75}\\log{k})}\n\\cdot n^{O(1)}$. Our algorithms are based on a new kind of tree decompositions\nof unit disk graphs where the separators can have size up to $k^{O(1)}$ and\nthere exists a solution that crosses every separator at most $O(\\sqrt{k})$\ntimes. The running times of our algorithms are optimal up to the $\\log{k}$\nfactor in the exponent, assuming the Exponential Time Hypothesis.\n", "versions": [{"version": "v1", "created": "Mon, 24 Apr 2017 15:18:40 GMT"}], "update_date": "2017-04-25", "authors_parsed": [["Fomin", "Fedor V.", ""], ["Lokshtanov", "Daniel", ""], ["Panolan", "Fahad", ""], ["Saurabh", "Saket", ""], ["Zehavi", "Meirav", ""]]}, {"id": "1704.07497", "submitter": "Jingru Zhang", "authors": "Haitao Wang and Jingru Zhang", "title": "Covering Uncertain Points in a Tree", "comments": "A preliminary version will appear in WADS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider a coverage problem for uncertain points in a tree.\nLet T be a tree containing a set P of n (weighted) demand points, and the\nlocation of each demand point P_i\\in P is uncertain but is known to appear in\none of m_i points on T each associated with a probability. Given a covering\nrange \\lambda, the problem is to find a minimum number of points (called\ncenters) on T to build facilities for serving (or covering) these demand points\nin the sense that for each uncertain point P_i\\in P, the expected distance from\nP_i to at least one center is no more than $\\lambda$. The problem has not been\nstudied before. We present an O(|T|+M\\log^2 M) time algorithm for the problem,\nwhere |T| is the number of vertices of T and M is the total number of locations\nof all uncertain points of P, i.e., M=\\sum_{P_i\\in P}m_i. In addition, by using\nthis algorithm, we solve a k-center problem on T for the uncertain points of P.\n", "versions": [{"version": "v1", "created": "Mon, 24 Apr 2017 23:58:10 GMT"}], "update_date": "2017-04-26", "authors_parsed": [["Wang", "Haitao", ""], ["Zhang", "Jingru", ""]]}, {"id": "1704.07580", "submitter": "Wolfgang Mulzer", "authors": "Hee-Kap Ahn, Sang Won Bae, Jongmin Choi, Matias Korman, Wolfgang\n  Mulzer, Eunjin Oh, Ji-won Park, Andr\\'e van Renssen, Antoine Vigneron", "title": "Faster Algorithms for Growing Prioritized Disks and Rectangles", "comments": "21 pages, 8 figures; a preliminary version appeared at ISAAC 2017", "journal-ref": "Computational Geometry: Theory and Applications (CGTA), 80, 2019,\n  pp. 23-39", "doi": "10.1016/j.comgeo.2019.02.001", "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by map labeling, Funke, Krumpe, and Storandt [IWOCA 2016]\nintroduced the following problem: we are given a sequence of $n$ disks in the\nplane. Initially, all disks have radius $0$, and they grow at constant, but\npossibly different, speeds. Whenever two disks touch, the one with the higher\nindex disappears. The goal is to determine the elimination order, i.e., the\norder in which the disks disappear. We provide the first general subquadratic\nalgorithm for this problem. Our solution extends to other shapes (e.g.,\nrectangles), and it works in any fixed dimension.\n  We also describe an alternative algorithm that is based on quadtrees. Its\nrunning time is $O\\big(n \\big(\\log n + \\min \\{ \\log \\Delta, \\log \\Phi\n\\}\\big)\\big)$, where $\\Delta$ is the ratio of the fastest and the slowest\ngrowth rate and $\\Phi$ is the ratio of the largest and the smallest distance\nbetween two disk centers. This improves the running times of previous\nalgorithms by Funke, Krumpe, and Storandt [IWOCA 2016], Bahrdt et al. [ALENEX\n2017], and Funke and Storandt [EuroCG 2017].\n  Finally, we give an $\\Omega(n\\log n)$ lower bound, showing that our quadtree\nalgorithms are almost tight.\n", "versions": [{"version": "v1", "created": "Tue, 25 Apr 2017 08:23:08 GMT"}, {"version": "v2", "created": "Tue, 13 Aug 2019 10:31:10 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Ahn", "Hee-Kap", ""], ["Bae", "Sang Won", ""], ["Choi", "Jongmin", ""], ["Korman", "Matias", ""], ["Mulzer", "Wolfgang", ""], ["Oh", "Eunjin", ""], ["Park", "Ji-won", ""], ["van Renssen", "Andr\u00e9", ""], ["Vigneron", "Antoine", ""]]}, {"id": "1704.07688", "submitter": "Gelasio Salazar", "authors": "\\'Eric Colin de Verdi\\`ere, Carolina Medina, Edgardo Rold\\'an-Pensado,\n  Gelasio Salazar", "title": "Embeddability of arrangements of pseudocircles and graphs on surfaces", "comments": "This is a major revised version of \"Arrangements of pseudocircles in\n  surfaces\". \\'{E}ric Colin de Verdi\\`{e}re is now also a co-author. the title\n  has changed slightly", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CG math.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A pseudocircle is a simple closed curve on some surface; an arrangement of\npseudocircles is a collection of pseudocircles that pairwise intersect in\nexactly two points, at which they cross. Ortner proved that an arrangement of\npseudocircles is embeddable into the sphere if and only if all of its\nsubarrangements of size at most four are embeddable into the sphere, and asked\nif an analogous result holds for embeddability into orientable surfaces of\nhigher genus. We answer this question positively: An arrangement of\npseudocircles is embeddable into an orientable surface of genus~$g$ if and only\nif all of its subarrangements of size at most $4g+4$ are. Moreover, this bound\nis tight. We actually have similar results for a much general notion of\narrangement, which we call an \\emph{arrangement of graphs}.\n", "versions": [{"version": "v1", "created": "Tue, 25 Apr 2017 13:33:57 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2019 15:06:18 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["de Verdi\u00e8re", "\u00c9ric Colin", ""], ["Medina", "Carolina", ""], ["Rold\u00e1n-Pensado", "Edgardo", ""], ["Salazar", "Gelasio", ""]]}, {"id": "1704.08000", "submitter": "Jules Wulms", "authors": "Wouter Meulemans, Bettina Speckmann, Kevin Verbeek, Jules Wulms", "title": "A Framework for Algorithm Stability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We say that an algorithm is stable if small changes in the input result in\nsmall changes in the output. This kind of algorithm stability is particularly\nrelevant when analyzing and visualizing time-varying data. Stability in general\nplays an important role in a wide variety of areas, such as numerical analysis,\nmachine learning, and topology, but is poorly understood in the context of\n(combinatorial) algorithms. In this paper we present a framework for analyzing\nthe stability of algorithms. We focus in particular on the tradeoff between the\nstability of an algorithm and the quality of the solution it computes. Our\nframework allows for three types of stability analysis with increasing degrees\nof complexity: event stability, topological stability, and Lipschitz stability.\nWe demonstrate the use of our stability framework by applying it to kinetic\nEuclidean minimum spanning trees.\n", "versions": [{"version": "v1", "created": "Wed, 26 Apr 2017 07:56:38 GMT"}, {"version": "v2", "created": "Tue, 6 Feb 2018 12:23:04 GMT"}], "update_date": "2018-02-07", "authors_parsed": [["Meulemans", "Wouter", ""], ["Speckmann", "Bettina", ""], ["Verbeek", "Kevin", ""], ["Wulms", "Jules", ""]]}, {"id": "1704.08049", "submitter": "Daniela Cabiddu", "authors": "Daniela Cabiddu and Marco Attene", "title": "Epsilon-shapes: characterizing, detecting and thickening thin features\n  in geometric models", "comments": null, "journal-ref": "In Computers & Graphics, Volume 66, 2017, Pages 143-153, ISSN\n  0097-8493", "doi": "10.1016/j.cag.2017.05.014", "report-no": null, "categories": "cs.CG cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on the analysis of planar shapes and solid objects having thin\nfeatures and propose a new mathematical model to characterize them. Based on\nour model, that we call an epsilon-shape, we show how thin parts can be\neffectively and efficiently detected by an algorithm, and propose a novel\napproach to thicken these features while leaving all the other parts of the\nshape unchanged. When compared with state-of-the-art solutions, our proposal\nproves to be particularly flexible, efficient and stable, and does not require\nany unintuitive parameter to fine-tune the process. Furthermore, our method is\nable to detect thin features both in the object and in its complement, thus\nproviding a useful tool to detect thin cavities and narrow channels. We discuss\nthe importance of this kind of analysis in the design of robust structures and\nin the creation of geometry to be fabricated with modern additive manufacturing\ntechnology.\n", "versions": [{"version": "v1", "created": "Wed, 26 Apr 2017 10:33:15 GMT"}, {"version": "v2", "created": "Mon, 8 Jan 2018 13:46:41 GMT"}], "update_date": "2018-01-09", "authors_parsed": [["Cabiddu", "Daniela", ""], ["Attene", "Marco", ""]]}, {"id": "1704.08219", "submitter": "R Inkulu", "authors": "R. Inkulu, K. Sowmya, N. P. Thakur", "title": "Dynamic algorithms for visibility polygons in simple polygons", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We devise the following dynamic algorithms for both maintaining as well as\nquerying for the visibility and weak visibility polygons amid vertex insertions\nand/or deletions to the simple polygon. * A fully-dynamic algorithm for\nmaintaining the visibility polygon of a fixed point located interior to the\nsimple polygon amid vertex insertions and deletions to the simple polygon. The\ntime complexity to update the visibility polygon of a point $q$ due to the\ninsertion (resp. deletion) of vertex $v$ to (resp. from) the current simple\npolygon is expressed in terms of the number of combinatorial changes needed to\nthe visibility polygon of $q$ due to the insertion (resp. deletion) of $v$. *\nAn output-sensitive query algorithm to answer the visibility polygon query\ncorresponding to any point $p$ in $\\mathbb{R}^2$ amid vertex insertions and\ndeletions to the simple polygon. If $p$ is not exterior to the current simple\npolygon, then the visibility polygon of $p$ is computed. Otherwise, our\nalgorithm outputs the visibility polygon corresponding to the exterior\nvisibility of $p$. * An incremental algorithm to maintain the weak visibility\npolygon of a fixed-line segment located interior to the simple polygon amid\nvertex insertions to the simple polygon. The time complexity to update the weak\nvisibility polygon of a line segment $pq$ due to the insertion of vertex $v$ to\nthe current simple polygon is expressed in terms of the sum of the number of\ncombinatorial updates needed to the geodesic shortest path trees rooted at $p$\nand $q$ due to the insertion of $v$. * An output-sensitive algorithm to compute\nthe weak visibility polygon corresponding to any query line segment located\ninterior to the simple polygon amid both the vertex insertions and deletions to\nthe simple polygon. Each of these algorithms requires preprocessing the initial\nsimple polygon.\n", "versions": [{"version": "v1", "created": "Wed, 26 Apr 2017 17:11:29 GMT"}, {"version": "v2", "created": "Sat, 1 Jul 2017 12:47:27 GMT"}, {"version": "v3", "created": "Mon, 20 Apr 2020 16:08:50 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Inkulu", "R.", ""], ["Sowmya", "K.", ""], ["Thakur", "N. P.", ""]]}]