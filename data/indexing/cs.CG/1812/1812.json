[{"id": "1812.00003", "submitter": "Yu-Ki Lee", "authors": "Yu-Ki Lee, Zhonghua Xi, Young-Joo Lee, Yun-Hyeong Kim, Yue Hao,\n  Young-Chang Joo, Changsoon Kim, Jyh-Ming Lien, In-Suk Choi", "title": "Computational paper wrapping transforms non-stretchable 2D devices into\n  wearable and conformable 3D devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cond-mat.soft cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study starts from the counter-intuitive question of how we can render a\nconventional stiff, non-stretchable and even brittle material conformable so\nthat it can fully wrap around a curved surface, such as a sphere, without\nfailure. Here, we answer this conundrum by extending geometrical design in\ncomputational kirigami (paper cutting and folding) to paper wrapping. Our\ncomputational paper wrapping-based approach provides the more robust and\nreliable fabrication of conformal devices than paper folding approaches. This\nin turn leads to a significant increase in the applicability of computational\nkirigami to real-world fabrication. This new computer-aided design transforms\n2D-based conventional materials, such as Si and copper, into a variety of\ntargeted conformal structures that can fully wrap the desired 3D structure\nwithout plastic deformation or fracture. We further demonstrated that our novel\napproach enables a pluripotent design platform to transform conventional\nnon-stretchable 2D-based devices, such as electroluminescent lighting and a\npaper battery, into wearable and conformable 3D curved devices.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 05:13:50 GMT"}, {"version": "v2", "created": "Thu, 27 Dec 2018 13:56:18 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Lee", "Yu-Ki", ""], ["Xi", "Zhonghua", ""], ["Lee", "Young-Joo", ""], ["Kim", "Yun-Hyeong", ""], ["Hao", "Yue", ""], ["Joo", "Young-Chang", ""], ["Kim", "Changsoon", ""], ["Lien", "Jyh-Ming", ""], ["Choi", "In-Suk", ""]]}, {"id": "1812.00901", "submitter": "Karthik C. S.", "authors": "Karthik C. S. and Pasin Manurangsi", "title": "On Closest Pair in Euclidean Metric: Monochromatic is as Hard as\n  Bichromatic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a set of $n$ points in $\\mathbb R^d$, the (monochromatic) Closest Pair\nproblem asks to find a pair of distinct points in the set that are closest in\nthe $\\ell_p$-metric. Closest Pair is a fundamental problem in Computational\nGeometry and understanding its fine-grained complexity in the Euclidean metric\nwhen $d=\\omega(\\log n)$ was raised as an open question in recent works\n(Abboud-Rubinstein-Williams [FOCS'17], Williams [SODA'18],\nDavid-Karthik-Laekhanukit [SoCG'18]).\n  In this paper, we show that for every $p\\in\\mathbb R_{\\ge 1}\\cup\\{0\\}$, under\nthe Strong Exponential Time Hypothesis (SETH), for every $\\varepsilon>0$, the\nfollowing holds:\n  $\\bullet$ No algorithm running in time $O(n^{2-\\varepsilon})$ can solve the\nClosest Pair problem in $d=(\\log n)^{\\Omega_{\\varepsilon}(1)}$ dimensions in\nthe $\\ell_p$-metric.\n  $\\bullet$ There exists $\\delta = \\delta(\\varepsilon)>0$ and $c =\nc(\\varepsilon)\\ge 1$ such that no algorithm running in time\n$O(n^{1.5-\\varepsilon})$ can approximate Closest Pair problem to a factor of\n$(1+\\delta)$ in $d\\ge c\\log n$ dimensions in the $\\ell_p$-metric.\n  At the heart of all our proofs is the construction of a dense bipartite graph\nwith low contact dimension, i.e., we construct a balanced bipartite graph on\n$n$ vertices with $n^{2-\\varepsilon}$ edges whose vertices can be realized as\npoints in a $(\\log n)^{\\Omega_\\varepsilon(1)}$-dimensional Euclidean space such\nthat every pair of vertices which have an edge in the graph are at distance\nexactly 1 and every other pair of vertices are at distance greater than 1. This\ngraph construction is inspired by the construction of locally dense codes\nintroduced by Dumer-Miccancio-Sudan [IEEE Trans. Inf. Theory'03].\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 17:01:06 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["S.", "Karthik C.", ""], ["Manurangsi", "Pasin", ""]]}, {"id": "1812.00949", "submitter": "Woojin Kim", "authors": "Woojin Kim, Facundo Memoli", "title": "Spatio-temporal Persistent Homology for Dynamic Metric Spaces", "comments": "45 pages, Reorganization of the paper with minor edits", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AT cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Characterizing the dynamics of time-evolving data within the framework of\ntopological data analysis (TDA) has been attracting increasingly more\nattention. Popular instances of time-evolving data include flocking/swarming\nbehaviors in animals and social networks in the human sphere. A natural\nmathematical model for such collective behaviors is a dynamic point cloud, or\nmore generally a dynamic metric space (DMS).\n  In this paper we extend the Rips filtration stability result for (static)\nmetric spaces to the setting of DMSs. We do this by devising a certain\nthree-parameter \"spatiotemporal\" filtration of a DMS. Applying the homology\nfunctor to this filtration gives rise to multidimensional persistence module\nderived from the DMS. We show that this multidimensional module enjoys\nstability under a suitable generalization of the Gromov-Hausdorff distance\nwhich permits metrizing the collection of all DMSs.\n  On the other hand, it is recognized that, in general, comparing two\nmultidimensional persistence modules leads to intractable computational\nproblems. For the purpose of practical comparison of DMSs, we focus on both the\nrank invariant or the dimension function of the multidimensional persistence\nmodule that is derived from a DMS. We specifically propose to utilize a certain\nmetric d for comparing these invariants: In our work this d is either (1) a\ncertain generalization of the erosion distance by Patel, or (2) a specialized\nversion of the well known interleaving distance. We also study the\ncomputational complexity associated to both choices of d.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 18:18:18 GMT"}, {"version": "v2", "created": "Sat, 8 Dec 2018 20:16:34 GMT"}, {"version": "v3", "created": "Wed, 13 Nov 2019 18:57:44 GMT"}, {"version": "v4", "created": "Thu, 14 Nov 2019 16:31:16 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Kim", "Woojin", ""], ["Memoli", "Facundo", ""]]}, {"id": "1812.01082", "submitter": "Zhiyu Sun", "authors": "Zhiyu Sun, Ethan Rooke, Jerome Charton, Yusen He, Jia Lu and Stephen\n  Baek", "title": "ZerNet: Convolutional Neural Networks on Arbitrary Surfaces via Zernike\n  Local Tangent Space Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel formulation to extend CNNs to\ntwo-dimensional (2D) manifolds using orthogonal basis functions, called Zernike\npolynomials. In many areas, geometric features play a key role in understanding\nscientific phenomena. Thus, an ability to codify geometric features into a\nmathematical quantity can be critical. Recently, convolutional neural networks\n(CNNs) have demonstrated the promising capability of extracting and codifying\nfeatures from visual information. However, the progress has been concentrated\nin computer vision applications where there exists an inherent grid-like\nstructure. In contrast, many geometry processing problems are defined on curved\nsurfaces, and the generalization of CNNs is not quite trivial. The difficulties\nare rooted in the lack of key ingredients such as the canonical grid-like\nrepresentation, the notion of consistent orientation, and a compatible local\ntopology across the domain. In this paper, we prove that the convolution of two\nfunctions can be represented as a simple dot product between Zernike polynomial\ncoefficients; and the rotation of a convolution kernel is essentially a set of\n2-by-2 rotation matrices applied to the coefficients. As such, the key\ncontribution of this work resides in a concise but rigorous mathematical\ngeneralization of the CNN building blocks.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 21:11:48 GMT"}, {"version": "v2", "created": "Sat, 13 Apr 2019 03:44:26 GMT"}, {"version": "v3", "created": "Fri, 4 Oct 2019 07:40:15 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Sun", "Zhiyu", ""], ["Rooke", "Ethan", ""], ["Charton", "Jerome", ""], ["He", "Yusen", ""], ["Lu", "Jia", ""], ["Baek", "Stephen", ""]]}, {"id": "1812.01160", "submitter": "Erik Demaine", "authors": "Hugo Akitaya and Erik D. Demaine and Takashi Horiyama and Thomas C.\n  Hull and Jason S. Ku and Tomohiro Tachi", "title": "Rigid Foldability is NP-Hard", "comments": "23 pages, 12 figures", "journal-ref": "Journal of Computational Geometry, Vol 11, No 1 (2020), pp. 93-124", "doi": null, "report-no": null, "categories": "cs.CG math.MG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we show that deciding rigid foldability of a given crease\npattern using all creases is weakly NP-hard by a reduction from Partition, and\nthat deciding rigid foldability with optional creases is strongly NP-hard by a\nreduction from 1-in-3 SAT. Unlike flat foldability of origami or flexibility of\nother kinematic linkages, whose complexity originates in the complexity of the\nlayer ordering and possible self-intersection of the material, rigid\nfoldability from a planar state is hard even though there is no potential\nself-intersection. In fact, the complexity comes from the combinatorial\nbehavior of the different possible rigid folding configurations at each vertex.\nThe results underpin the fact that it is harder to fold from an unfolded sheet\nof paper than to unfold a folded state back to a plane, frequently encountered\nproblem when realizing folding-based systems such as self-folding matter and\nreconfigurable robots.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 01:35:30 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Akitaya", "Hugo", ""], ["Demaine", "Erik D.", ""], ["Horiyama", "Takashi", ""], ["Hull", "Thomas C.", ""], ["Ku", "Jason S.", ""], ["Tachi", "Tomohiro", ""]]}, {"id": "1812.01167", "submitter": "Erik Demaine", "authors": "Erik D. Demaine and Martin L. Demaine and David A. Huffman and Duks\n  Koschitz and Tomohiro Tachi", "title": "Conic Crease Patterns with Reflecting Rule Lines", "comments": "17 pages, 12 figures. In Origami^7: Proceedings of the 7th\n  International Meeting on Origami in Science, Mathematics and Education", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We characterize when two conic curved creases are compatible with each other,\nwhen the rule lines must converge to conic foci and reflect at the crease.\nNamely, two conics are compatible (can be connected by rule segments in a\nfoldable curved crease pattern) if and only if they have equal or reciprocal\neccentricity. Thus, circles (eccentricity 0) and parabolas (eccentricity 1) are\ncompatible with only themselves (when scaled from a focus), and ellipses\n(eccentricity strictly between 0 and 1) and hyperbolas (eccentricity above 1)\nare compatible with themselves and each other (but only in specific pairings).\nThe foundation of this result is a general condition relating any two curved\ncreases connected by rule segments. We also use our characterization to analyze\nseveral curved crease designs.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 02:18:12 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["Demaine", "Erik D.", ""], ["Demaine", "Martin L.", ""], ["Huffman", "David A.", ""], ["Koschitz", "Duks", ""], ["Tachi", "Tomohiro", ""]]}, {"id": "1812.01332", "submitter": "Herman Haverkort", "authors": "Herman Haverkort", "title": "Finding the vertices of the convex hull, even unordered, takes Omega(n\n  log n) time -- a proof by reduction from epsilon-closeness", "comments": "4 pages, 1 figure, not submitted anywhere, more references welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of computing, given a set S of n points in the plane,\nwhich points of S are vertices of the convex hull of S. For certain variations\nof this problem, different proofs exist that the complexity of this problem in\nthe algebraic decision tree model is Omega(n log n). This paper provides a\nrelatively simple proof by reduction from epsilon-closeness.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 11:02:09 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["Haverkort", "Herman", ""]]}, {"id": "1812.01360", "submitter": "Mathieu Carri\\`ere", "authors": "Mathieu Carriere and Raul Rabadan", "title": "Topological Data Analysis of Single-cell Hi-C Contact Maps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG math.AT q-bio.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we show how the recent statistical techniques developed in\nTopological Data Analysis for the Mapper algorithm can be extended and\nleveraged to formally define and statistically quantify the presence of\ntopological structures coming from biological phenomena in datasets of CCC\ncontact maps.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 12:13:05 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["Carriere", "Mathieu", ""], ["Rabadan", "Raul", ""]]}, {"id": "1812.01564", "submitter": "Jeff Erickson", "authors": "Jeff Erickson and Yipu Wang", "title": "Topologically Trivial Closed Walks in Directed Surface Graphs", "comments": "30 pages, 18 figures; fixed several minor bugs and added one figure.\n  An extended abstraction of this paper will appear at SOCG 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $G$ be a directed graph with $n$ vertices and $m$ edges, embedded on a\nsurface $S$, possibly with boundary, with first Betti number $\\beta$. We\nconsider the complexity of finding closed directed walks in $G$ that are either\ncontractible (trivial in homotopy) or bounding (trivial in integer homology) in\n$S$. Specifically, we describe algorithms to determine whether $G$ contains a\nsimple contractible cycle in $O(n+m)$ time, or a contractible closed walk in\n$O(n+m)$ time, or a bounding closed walk in $O(\\beta (n+m))$ time. Our\nalgorithms rely on subtle relationships between strong connectivity in $G$ and\nin the dual graph $G^*$; our contractible-closed-walk algorithm also relies on\na seminal topological result of Hass and Scott. We also prove that detecting\nsimple bounding cycles is NP-hard.\n  We also describe three polynomial-time algorithms to compute shortest\ncontractible closed walks, depending on whether the fundamental group of the\nsurface is free, abelian, or hyperbolic. A key step in our algorithm for\nhyperbolic surfaces is the construction of a context-free grammar with\n$O(g^2L^2)$ non-terminals that generates all contractible closed walks of\nlength at most L, and only contractible closed walks, in a system of quads of\ngenus $g\\ge2$. Finally, we show that computing shortest simple contractible\ncycles, shortest simple bounding cycles, and shortest bounding closed walks are\nall NP-hard.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 18:09:24 GMT"}, {"version": "v2", "created": "Wed, 5 Dec 2018 18:53:05 GMT"}, {"version": "v3", "created": "Thu, 21 Mar 2019 16:18:04 GMT"}], "update_date": "2019-03-22", "authors_parsed": [["Erickson", "Jeff", ""], ["Wang", "Yipu", ""]]}, {"id": "1812.01595", "submitter": "Manuel Wettstein", "authors": "Alexander Pilz, Emo Welzl, Manuel Wettstein", "title": "From Crossing-Free Graphs on Wheel Sets to Embracing Simplices and\n  Polytopes with Few Vertices", "comments": "Full version of a contribution presented in Proc. of the 33rd\n  International Symposium on Computational Geometry (SoCG 2017), volume 77 of\n  LIPIcs, pages 54:1-54:16. Schloss Dagstuhl - Leibniz-Zentrum fuer Informatik,\n  2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A set $P = H \\cup \\{w\\}$ of $n+1$ points in general position in the plane is\ncalled a wheel set if all points but $w$ are extreme. We show that for the\npurpose of counting crossing-free geometric graphs on such a set $P$, it\nsuffices to know the frequency vector of $P$. While there are roughly $2^n$\ndistinct order types that correspond to wheel sets, the number of frequency\nvectors is only about $2^{n/2}$.\n  We give simple formulas in terms of the frequency vector for the number of\ncrossing-free spanning cycles, matchings, triangulations, and many more. Based\non that, the corresponding numbers of graphs can be computed efficiently. In\nparticular, we rediscover an already known formula for $w$-embracing triangles\nspanned by $H$.\n  Also in higher dimensions, wheel sets turn out to be a suitable model to\napproach the problem of computing the simplicial depth of a point $w$ in a set\n$H$, i.e., the number of $w$-embracing simplices. While our previous arguments\nin the plane do not generalize easily, we show how to use similar ideas in\n$\\mathbb{R}^d$ for any fixed $d$. The result is an $O(n^{d-1})$ time algorithm\nfor computing the simplicial depth of a point $w$ in a set $H$ of $n$ points,\nimproving on the previously best bound of $O(n^d\\log n)$.\n  Based on our result about simplicial depth, we can compute the number of\nfacets of the convex hull of $n=d+k$ points in general position in\n$\\mathbb{R}^d$ in time $O(n^{\\max\\{\\omega,k-2\\}})$ where $\\omega \\approx\n2.373$, even though the asymptotic number of facets may be as large as $n^k$.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 18:52:01 GMT"}, {"version": "v2", "created": "Fri, 30 Aug 2019 10:54:06 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Pilz", "Alexander", ""], ["Welzl", "Emo", ""], ["Wettstein", "Manuel", ""]]}, {"id": "1812.01845", "submitter": "Somnath Chakraborty", "authors": "Somnath Chakraborty, Hariharan Narayanan", "title": "Generating an equidistributed net on a unit n-sphere using random\n  rotations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a randomized algorithm (that succeeds with high probability) for\ngenerating an $\\epsilon$-net in a sphere of dimension n. The basic scheme is to\npick $O(n \\ln(1/n) + \\ln(1/\\delta))$ random rotations and take all possible\nwords of length $O(n \\ln(1/\\epsilon))$ in the same alphabet and act them on a\nfixed point. We show this set of points is equidistributed at a scale of\n$\\epsilon$. Our main application is to approximate integration of Lipschitz\nfunctions over an n-sphere.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2018 07:47:49 GMT"}, {"version": "v2", "created": "Tue, 11 Dec 2018 00:27:09 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Chakraborty", "Somnath", ""], ["Narayanan", "Hariharan", ""]]}, {"id": "1812.02099", "submitter": "J\\'er\\'emie Chalopin", "authors": "J\\'er\\'emie Chalopin and Victor Chepoi and Shay Moran and Manfred K.\n  Warmuth", "title": "Unlabeled sample compression schemes and corner peelings for ample and\n  maximum classes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CG cs.LG math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine connections between combinatorial notions that arise in machine\nlearning and topological notions in cubical/simplicial geometry. These\nconnections enable to export results from geometry to machine learning.\n  Our first main result is based on a geometric construction by Tracy Hall\n(2004) of a partial shelling of the cross-polytope which can not be extended.\nWe use it to derive a maximum class of VC dimension 3 that has no corners. This\nrefutes several previous works in machine learning from the past 11 years. In\nparticular, it implies that all previous constructions of optimal unlabeled\nsample compression schemes for maximum classes are erroneous.\n  On the positive side we present a new construction of an unlabeled sample\ncompression scheme for maximum classes. We leave as open whether our unlabeled\nsample compression scheme extends to ample (a.k.a. lopsided or extremal)\nclasses, which represent a natural and far-reaching generalization of maximum\nclasses. Towards resolving this question, we provide a geometric\ncharacterization in terms of unique sink orientations of the 1-skeletons of\nassociated cubical complexes.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2018 16:42:48 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Chalopin", "J\u00e9r\u00e9mie", ""], ["Chepoi", "Victor", ""], ["Moran", "Shay", ""], ["Warmuth", "Manfred K.", ""]]}, {"id": "1812.02329", "submitter": "Luigi Santocanale", "authors": "Maria Jo\\~ao Gouveia (ULISBOA), Luigi Santocanale (LIS)", "title": "The continuous weak order", "comments": "arXiv admin note: text overlap with arXiv:1807.06862", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CG math.CT math.LO math.RA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The set of permutations on a finite set can be given the lattice structure\nknown as the weak Bruhat order. This lattice structure is generalized to the\nset of words on a fixed alphabet $\\Sigma$ = {x,y,z,...}, where each letter has\na fixed number of occurrences. These lattices are known as multinomial lattices\nand, when card($\\Sigma$) = 2, as lattices of lattice paths. By interpreting the\nletters x, y, z, . . . as axes, these words can be interpreted as discrete\nincreasing paths on a grid of a d-dimensional cube, with d = card($\\Sigma$).We\nshow how to extend this ordering to images of continuous monotone functions\nfrom the unit interval to a d-dimensional cube and prove that this ordering is\na lattice, denoted by L(I^d). This construction relies on a few algebraic\nproperties of the quantale of join-continuous functions from the unit interval\nof the reals to itself: it is cyclic $\\star$-autonomous and it satisfies the\nmix rule.We investigate structural properties of these lattices, which are\nself-dual and not distributive. We characterize join-irreducible elements and\nshow that these lattices are generated under infinite joins from their\njoin-irreducible elements, they have no completely join-irreducible elements\nnor compact elements. We study then embeddings of the d-dimensional multinomial\nlattices into L(I^d). We show that these embeddings arise functorially from\nsubdivisions of the unit interval and observe that L(I^d) is the\nDedekind-MacNeille completion of the colimit of these embeddings. Yet, if we\nrestrict to embeddings that take rational values and if d > 2, then every\nelement of L(I^d) is only a join of meets of elements from the colimit of these\nembeddings.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2018 15:51:24 GMT"}, {"version": "v2", "created": "Mon, 17 Dec 2018 07:33:26 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Gouveia", "Maria Jo\u00e3o", "", "ULISBOA"], ["Santocanale", "Luigi", "", "LIS"]]}, {"id": "1812.02412", "submitter": "Bala Krishnamoorthy", "authors": "Prashant Gupta and Bala Krishnamoorthy", "title": "Euler Transformation of Polyhedral Complexes", "comments": "Modifications to Section 5.1 and minor improvements in other places;\n  to appear in IJCGA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an Euler transformation that transforms a given $d$-dimensional\ncell complex $K$ for $d=2,3$ into a new $d$-complex $\\hat{K}$ in which every\nvertex is part of a uniform even number of edges. Hence every vertex in the\ngraph $\\hat{G}$ that is the $1$-skeleton of $\\hat{K}$ has an even degree, which\nmakes $\\hat{G}$ Eulerian, i.e., it is guaranteed to contain an Eulerian tour.\nMeshes whose edges admit Eulerian tours are crucial in coverage problems\narising in several applications including 3D printing and robotics.\n  For $2$-complexes in $\\mathbb{R}^2$ ($d=2$) under mild assumptions (that no\ntwo adjacent edges of a $2$-cell in $K$ are boundary edges), we show that the\nEuler transformed $2$-complex $\\hat{K}$ has a geometric realization in\n$\\mathbb{R}^2$, and that each vertex in its $1$-skeleton has degree $4$. We\nbound the numbers of vertices, edges, and $2$-cells in $\\hat{K}$ as small\nscalar multiples of the corresponding numbers in $K$. We prove corresponding\nresults for $3$-complexes in $\\mathbb{R}^3$ under an additional assumption that\nthe degree of a vertex in each $3$-cell containing it is $3$. In this setting,\nevery vertex in $\\hat{G}$ is shown to have a degree of $6$.\n  We also present bounds on parameters measuring geometric quality (aspect\nratios, minimum edge length, and maximum angle) of $\\hat{K}$ in terms of the\ncorresponding parameters of $K$ (for $d=2, 3$). Finally, we illustrate a direct\napplication of the proposed Euler transformation in additive manufacturing.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 09:21:44 GMT"}, {"version": "v2", "created": "Thu, 24 Sep 2020 07:14:26 GMT"}, {"version": "v3", "created": "Tue, 27 Apr 2021 02:44:19 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Gupta", "Prashant", ""], ["Krishnamoorthy", "Bala", ""]]}, {"id": "1812.02987", "submitter": "Kwangho Kim", "authors": "Kwangho Kim, Jisu Kim, Alessandro Rinaldo", "title": "Time Series Featurization via Topological Data Analysis", "comments": "28 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a novel algorithm for feature extraction in time series data by\nleveraging tools from topological data analysis. Our algorithm provides a\nsimple, efficient way to successfully harness topological features of the\nattractor of the underlying dynamical system for an observed time series. The\nproposed methodology relies on the persistent landscapes and silhouette of the\nRips complex obtained after a de-noising step based on principal components\napplied to a time-delayed embedding of a noisy, discrete time series sample. We\nanalyze the stability properties of the proposed approach and show that the\nresulting TDA-based features are robust to sampling noise. Experiments on\nsynthetic and real-world data demonstrate the effectiveness of our approach. We\nexpect our method to provide new insights on feature extraction from granular,\nnoisy time series data.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2018 11:49:00 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 02:26:42 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Kim", "Kwangho", ""], ["Kim", "Jisu", ""], ["Rinaldo", "Alessandro", ""]]}, {"id": "1812.03174", "submitter": "Milica Bogicevic", "authors": "Milica Bogi\\'cevi\\'c, Milan Merkle", "title": "Approximate Calculation of Tukey's Depth and Median With\n  High-dimensional Data", "comments": null, "journal-ref": "Yugoslav Journal of Operations Research 28 (2018), Number 4,\n  475--499", "doi": "10.2298/YJOR180520022B", "report-no": null, "categories": "cs.DS cs.CG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We present a new fast approximate algorithm for Tukey (halfspace) depth level\nsets and its implementation-ABCDepth. Given a $d$-dimensional data set for any\n$d\\geq 1$, the algorithm is based on a representation of level sets as\nintersections of balls in $\\mathbb{R}^d$. Our approach does not need\ncalculations of projections of sample points to directions. This novel idea\nenables calculations of approximate level sets in very high dimensions with\ncomplexity which is linear in $d$, which provides a great advantage over all\nother approximate algorithms. Using different versions of this algorithm we\ndemonstrate approximate calculations of the deepest set of points (\"Tukey\nmedian\") and Tukey's depth of a sample point or out-of-sample point, all with a\nlinear in $d$ complexity. An additional theoretical advantage of this approach\nis that the data points are not assumed to be in \"general position\". Examples\nwith real and synthetic data show that the executing time of the algorithm in\nall mentioned versions in high dimensions is much smaller than the time of\nother implemented algorithms. Also, our algorithms can be used with thousands\nof multidimensional observations.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2018 10:27:14 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Bogi\u0107evi\u0107", "Milica", ""], ["Merkle", "Milan", ""]]}, {"id": "1812.03374", "submitter": "Henry Adams", "authors": "Henry Adams, Ethan Coldren, Sean Willmot", "title": "The persistent homology of cyclic graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG math.AT math.MG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give an $O(n^2(k+\\log n))$ algorithm for computing the $k$-dimensional\npersistent homology of a filtration of clique complexes of cyclic graphs on $n$\nvertices. This is nearly quadratic in the number of vertices $n$, and therefore\na large improvement upon the traditional persistent homology algorithm, which\nis cubic in the number of simplices of dimension at most $k+1$, and hence of\nrunning time $O(n^{3(k+2)})$ in the number of vertices $n$. Our algorithm\napplies, for example, to Vietoris--Rips complexes of points sampled from a\ncurve in $\\mathbb{R}^d$ when the scale is bounded depending on the geometry of\nthe curve, but still large enough so that the Vietoris--Rips complex may have\nnon-trivial homology in arbitrarily high dimensions $k$. In the case of the\nplane $\\mathbb{R}^2$, we prove that our algorithm applies for all scale\nparameters if the $n$ vertices are sampled from a convex closed differentiable\ncurve whose convex hull contains its evolute. We ask if there are other\ngeometric settings in which computing persistent homology is (say) quadratic or\ncubic in the number of vertices, instead of in the number of simplices.\n", "versions": [{"version": "v1", "created": "Sat, 8 Dec 2018 19:28:22 GMT"}, {"version": "v2", "created": "Sun, 13 Oct 2019 16:07:34 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Adams", "Henry", ""], ["Coldren", "Ethan", ""], ["Willmot", "Sean", ""]]}, {"id": "1812.03434", "submitter": "Gary Pui-Tung Choi", "authors": "Gary P. T. Choi, Bernard Chiu, Chris H. Rycroft", "title": "Area-preserving mapping of 3D ultrasound carotid artery images using\n  density-equalizing reference map", "comments": null, "journal-ref": "IEEE Transactions on Biomedical Engineering, 67(9), 1507-1517\n  (2020)", "doi": "10.1109/TBME.2019.2963783", "report-no": null, "categories": "cs.CG cs.CV math.NA physics.med-ph q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Carotid atherosclerosis is a focal disease at the bifurcations of the carotid\nartery. To quantitatively monitor the local changes in the\nvessel-wall-plus-plaque thickness (VWT) and compare the VWT distributions for\ndifferent patients or for the same patients at different ultrasound scanning\nsessions, a mapping technique is required to adjust for the geometric\nvariability of different carotid artery models. In this work, we propose a\nnovel method called density-equalizing reference map (DERM) for mapping 3D\ncarotid surfaces to a standardized 2D carotid template, with an emphasis on\npreserving the local geometry of the carotid surface by minimizing the local\narea distortion. The initial map was generated by a previously described\narc-length scaling (ALS) mapping method, which projects a 3D carotid surface\nonto a 2D non-convex L-shaped domain. A smooth and area-preserving flattened\nmap was subsequently constructed by deforming the ALS map using the proposed\nalgorithm that combines the density-equalizing map and the reference map\ntechniques. This combination allows, for the first time, one-to-one mapping\nfrom a 3D surface to a standardized non-convex planar domain in an\narea-preserving manner. Evaluations using 20 carotid surface models show that\nthe proposed method reduced the area distortion of the flattening maps by over\n80% as compared to the ALS mapping method.\n", "versions": [{"version": "v1", "created": "Sun, 9 Dec 2018 06:35:15 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Choi", "Gary P. T.", ""], ["Chiu", "Bernard", ""], ["Rycroft", "Chris H.", ""]]}, {"id": "1812.03960", "submitter": "Sandor Kisfaludi-Bak", "authors": "S\\'andor Kisfaludi-Bak", "title": "Hyperbolic intersection graphs and (quasi)-polynomial time", "comments": "Short version appears in SODA 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study unit ball graphs (and, more generally, so-called noisy uniform ball\ngraphs) in $d$-dimensional hyperbolic space, which we denote by $\\mathbb{H}^d$.\nUsing a new separator theorem, we show that unit ball graphs in $\\mathbb{H}^d$\nenjoy similar properties as their Euclidean counterparts, but in one dimension\nlower: many standard graph problems, such as Independent Set, Dominating Set,\nSteiner Tree, and Hamiltonian Cycle can be solved in $2^{O(n^{1-1/(d-1)})}$\ntime for any fixed $d\\geq 3$, while the same problems need $2^{O(n^{1-1/d})}$\ntime in $\\mathbb{R}^d$. We also show that these algorithms in $\\mathbb{H}^d$\nare optimal up to constant factors in the exponent under ETH.\n  This drop in dimension has the largest impact in $\\mathbb{H}^2$, where we\nintroduce a new technique to bound the treewidth of noisy uniform disk graphs.\nThe bounds yield quasi-polynomial ($n^{O(\\log n)}$) algorithms for all of the\nstudied problems, while in the case of Hamiltonian Cycle and $3$-Coloring we\neven get polynomial time algorithms. Furthermore, if the underlying noisy disks\nin $\\mathbb{H}^2$ have constant maximum degree, then all studied problems can\nbe solved in polynomial time. This contrasts with the fact that these problems\nrequire $2^{\\Omega(\\sqrt{n})}$ time under ETH in constant maximum degree\nEuclidean unit disk graphs.\n  Finally, we complement our quasi-polynomial algorithm for Independent Set in\nnoisy uniform disk graphs with a matching $n^{\\Omega(\\log n)}$ lower bound\nunder ETH. This shows that the hyperbolic plane is a potential source of\nNP-intermediate problems.\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2018 18:15:49 GMT"}, {"version": "v2", "created": "Mon, 30 Sep 2019 13:07:40 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Kisfaludi-Bak", "S\u00e1ndor", ""]]}, {"id": "1812.04263", "submitter": "Alexander Wolff", "authors": "Steven Chaplick, Thomas C. van Dijk, Myroslav Kryven, Ji-won Park,\n  Alexander Ravsky, Alexander Wolff", "title": "Bundled Crossings Revisited", "comments": "Appears in the Proceedings of the 27th International Symposium on\n  Graph Drawing and Network Visualization (GD 2019)", "journal-ref": "J. Graph Algorithms Appl., special issue on GD 2019, 35 pages", "doi": "10.7155/jgaa.00535", "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An effective way to reduce clutter in a graph drawing that has (many)\ncrossings is to group edges that travel in parallel into \\emph{bundles}. Each\nedge can participate in many such bundles. Any crossing in this bundled graph\noccurs between two bundles, i.e., as a \\emph{bundled crossing}. We consider the\nproblem of bundled crossing minimization: A graph is given and the goal is to\nfind a bundled drawing with at most $k$ bundled crossings. We show that the\nproblem is NP-hard when we require a simple drawing. Our main result is an FPT\nalgorithm (in $k$) when we require a simple circular layout. These results make\nuse of the connection between bundled crossings and graph genus.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2018 08:20:47 GMT"}, {"version": "v2", "created": "Tue, 27 Aug 2019 07:11:02 GMT"}, {"version": "v3", "created": "Wed, 11 Sep 2019 17:47:45 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Chaplick", "Steven", ""], ["van Dijk", "Thomas C.", ""], ["Kryven", "Myroslav", ""], ["Park", "Ji-won", ""], ["Ravsky", "Alexander", ""], ["Wolff", "Alexander", ""]]}, {"id": "1812.04911", "submitter": "Bernd G\\\"artner", "authors": "Radoslav Fulek, Bernd G\\\"artner, Andrey Kupavskii, Pavel Valtr, Uli\n  Wagner", "title": "The Crossing Tverberg Theorem", "comments": "13 pages, 7 figures", "journal-ref": null, "doi": "10.4230/LIPIcs.SoCG.2019.38", "report-no": null, "categories": "cs.CG math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tverberg's theorem is one of the cornerstones of discrete geometry. It states\nthat, given a set $X$ of at least $(d+1)(r-1)+1$ points in $\\mathbb R^d$, one\ncan find a partition $X=X_1\\cup \\ldots \\cup X_r$ of $X$, such that the convex\nhulls of the $X_i$, $i=1,\\ldots,r$, all share a common point. In this paper, we\nprove a strengthening of this theorem that guarantees a partition which, in\naddition to the above, has the property that the boundaries of full-dimensional\nconvex hulls have pairwise nonempty intersections. Possible generalizations and\nalgorithmic aspects are also discussed.\n  As a concrete application, we show that any $n$ points in the plane in\ngeneral position span $\\lfloor n/3\\rfloor$ vertex-disjoint triangles that are\npairwise crossing, meaning that their boundaries have pairwise nonempty\nintersections; this number is clearly best possible. A previous result of\nRebollar et al.\\ guarantees $\\lfloor n/6\\rfloor$ pairwise crossing triangles.\nOur result generalizes to a result about simplices in $\\mathbb R^d,d\\ge2$.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2018 12:09:47 GMT"}, {"version": "v2", "created": "Sun, 11 Apr 2021 10:47:51 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Fulek", "Radoslav", ""], ["G\u00e4rtner", "Bernd", ""], ["Kupavskii", "Andrey", ""], ["Valtr", "Pavel", ""], ["Wagner", "Uli", ""]]}, {"id": "1812.04966", "submitter": "Aruni Choudhary", "authors": "Aruni Choudhary, Michael Kerber, Sharath Raghvendra", "title": "Improved Topological Approximations by Digitization", "comments": "To appear at SODA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG math.AT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \\v{C}ech complexes are useful simplicial complexes for computing and\nanalyzing topological features of data that lies in Euclidean space.\nUnfortunately, computing these complexes becomes prohibitively expensive for\nlarge-sized data sets even for medium-to-low dimensional data. We present an\napproximation scheme for $(1+\\epsilon)$-approximating the topological\ninformation of the \\v{C}ech complexes for $n$ points in $\\mathbb{R}^d$, for\n$\\epsilon\\in(0,1]$. Our approximation has a total size of\n$n\\left(\\frac{1}{\\epsilon}\\right)^{O(d)}$ for constant dimension $d$, improving\nall the currently available $(1+\\epsilon)$-approximation schemes of simplicial\nfiltrations in Euclidean space. Perhaps counter-intuitively, we arrive at our\nresult by adding additional $n\\left(\\frac{1}{\\epsilon}\\right)^{O(d)}$ sample\npoints to the input. We achieve a bound that is independent of the spread of\nthe point set by pre-identifying the scales at which the \\v{C}ech complexes\nchanges and sampling accordingly.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2018 14:27:12 GMT"}], "update_date": "2018-12-13", "authors_parsed": [["Choudhary", "Aruni", ""], ["Kerber", "Michael", ""], ["Raghvendra", "Sharath", ""]]}, {"id": "1812.05143", "submitter": "Jose Perea", "authors": "Jose A. Perea", "title": "Topological Time Series Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AT cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series are ubiquitous in our data rich world. In what follows I will\ndescribe how ideas from dynamical systems and topological data analysis can be\ncombined to gain insights from time-varying data. We will see several\napplications to the live sciences and engineering, as well as some of the\ntheoretical underpinnings.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 10:10:55 GMT"}], "update_date": "2018-12-14", "authors_parsed": [["Perea", "Jose A.", ""]]}, {"id": "1812.05282", "submitter": "Emilie Purvine", "authors": "Ellen Gasparovic, Maria Gommel, Emilie Purvine, Radmila Sazdanovic,\n  Bei Wang, Yusu Wang, Lori Ziegelmeier", "title": "The Relationship Between the Intrinsic Cech and Persistence Distortion\n  Distances for Metric Graphs", "comments": "18 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AT cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Metric graphs are meaningful objects for modeling complex structures that\narise in many real-world applications, such as road networks, river systems,\nearthquake faults, blood vessels, and filamentary structures in galaxies. To\nstudy metric graphs in the context of comparison, we are interested in\ndetermining the relative discriminative capabilities of two topology-based\ndistances between a pair of arbitrary finite metric graphs: the persistence\ndistortion distance and the intrinsic Cech distance. We explicitly show how to\ncompute the intrinsic Cech distance between two metric graphs based solely on\nknowledge of the shortest systems of loops for the graphs. Our main theorem\nestablishes an inequality between the intrinsic Cech and persistence distortion\ndistances in the case when one of the graphs is a bouquet graph and the other\nis arbitrary. The relationship also holds when both graphs are constructed via\nwedge sums of cycles and edges.\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2018 06:20:24 GMT"}], "update_date": "2018-12-14", "authors_parsed": [["Gasparovic", "Ellen", ""], ["Gommel", "Maria", ""], ["Purvine", "Emilie", ""], ["Sazdanovic", "Radmila", ""], ["Wang", "Bei", ""], ["Wang", "Yusu", ""], ["Ziegelmeier", "Lori", ""]]}, {"id": "1812.05410", "submitter": "Loic Crombez", "authors": "Lo\\\"ic Crombez and Guilherme D. da Fonseca and Yan G\\'erard", "title": "Peeling Digital Potatoes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The potato-peeling problem (also known as convex skull) is a fundamental\ncomputational geometry problem and the fastest algorithm to date runs in\n$O(n^8)$ time for a polygon with $n$ vertices that may have holes. In this\npaper, we consider a digital version of the problem. A set $K \\subset\n\\mathbb{Z}^2$ is digital convex if $conv(K) \\cap \\mathbb{Z}^2 = K$, where\n$conv(K)$ denotes the convex hull of $K$. Given a set $S$ of $n$ lattice\npoints, we present polynomial time algorithms to the problems of finding the\nlargest digital convex subset $K$ of $S$ (digital potato-peeling problem) and\nthe largest union of two digital convex subsets of $S$. The two algorithms take\nroughly $O(n^3)$ and $O(n^9)$ time, respectively. We also show that those\nalgorithms provide an approximation to the continuous versions.\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2018 13:19:40 GMT"}, {"version": "v2", "created": "Mon, 24 Jun 2019 08:59:41 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Crombez", "Lo\u00efc", ""], ["da Fonseca", "Guilherme D.", ""], ["G\u00e9rard", "Yan", ""]]}, {"id": "1812.05528", "submitter": "Jonathan Spreer", "authors": "Krist\\'of Husz\\'ar and Jonathan Spreer", "title": "3-Manifold triangulations with small treewidth", "comments": "34 pages, 30 figures, 1 table", "journal-ref": "35th International Symposium on Computational Geometry (SoCG\n  2019). Leibniz International Proceedings in Informatics (LIPICS), vol. 129,\n  pg. 44:1-44:20, 2019", "doi": "10.4230/LIPIcs.SoCG.2019.44", "report-no": null, "categories": "math.GT cs.CG math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by fixed-parameter tractable (FPT) problems in computational\ntopology, we consider the treewidth of a compact, connected 3-manifold $M$\ndefined by \\[\n  \\operatorname{tw}(M) =\n\\min\\{\\operatorname{tw}(\\Gamma(\\mathcal{T})):\\mathcal{T}~\\text{is a\ntriangulation of }M\\}, \\] where $\\Gamma(\\mathcal{T})$ denotes the dual graph of\n$\\mathcal{T}$. In this setting the relationship between the topology of a\n3-manifold and its treewidth is of particular interest.\n  First, as a corollary of work of Jaco and Rubinstein, we prove that for any\nclosed, orientable 3-manifold $M$ the treewidth $\\operatorname{tw}(M)$ is at\nmost $4\\mathfrak{g}(M)-2$ where $\\mathfrak{g}(M)$ denotes the Heegaard genus of\n$M$. In combination with our earlier work with Wagner, this yields that for\nnon-Haken manifolds the Heegaard genus and the treewidth are within a constant\nfactor.\n  Second, we characterize all 3-manifolds of treewidth one: These are precisely\nthe lens spaces and a single other Seifert fibered space. Furthermore, we show\nthat all remaining orientable Seifert fibered spaces over the 2-sphere or a\nnon-orientable surface have treewidth two. In particular, for every spherical\n3-manifold we exhibit a triangulation of treewidth at most two.\n  Our results further validate the parameter of treewidth (and other related\nparameters such as cutwidth, or congestion) to be useful for topological\ncomputing, and also shed more light on the scope of existing FPT algorithms in\nthe field.\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2018 17:17:46 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Husz\u00e1r", "Krist\u00f3f", ""], ["Spreer", "Jonathan", ""]]}, {"id": "1812.05656", "submitter": "Saeed Mehrabi", "authors": "Yeganeh Bahoo, Stephane Durocher, J. Mark Keil, Debajyoti Mondal,\n  Saeed Mehrabi, and Sahar Mehrpour", "title": "Polygon Simplification by Minimizing Convex Corners", "comments": "15 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $P$ be a polygon with $r>0$ reflex vertices and possibly with holes and\nislands. A subsuming polygon of $P$ is a polygon $P'$ such that $P \\subseteq\nP'$, each connected component $R$ of $P$ is a subset of a distinct connected\ncomponent $R'$ of $P'$, and the reflex corners of $R$ coincide with those of\n$R'$. A subsuming chain of $P'$ is a minimal path on the boundary of $P'$ whose\ntwo end edges coincide with two edges of $P$. Aichholzer et al. proved that\nevery polygon $P$ has a subsuming polygon with $O(r)$ vertices, and posed an\nopen problem to determine the computational complexity of computing subsuming\npolygons with the minimum number of convex vertices.\n  We prove that the problem of computing an optimal subsuming polygon is\nNP-complete, but the complexity remains open for simple polygons (i.e.,\npolygons without holes). Our NP-hardness result holds even when the subsuming\nchains are restricted to have constant length and lie on the arrangement of\nlines determined by the edges of the input polygon. We show that this\nrestriction makes the problem polynomial-time solvable for simple polygons.\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2018 19:52:30 GMT"}], "update_date": "2018-12-17", "authors_parsed": [["Bahoo", "Yeganeh", ""], ["Durocher", "Stephane", ""], ["Keil", "J. Mark", ""], ["Mondal", "Debajyoti", ""], ["Mehrabi", "Saeed", ""], ["Mehrpour", "Sahar", ""]]}, {"id": "1812.06216", "submitter": "Sebastian Koch", "authors": "Sebastian Koch, Albert Matveev, Zhongshi Jiang, Francis Williams,\n  Alexey Artemov, Evgeny Burnaev, Marc Alexa, Denis Zorin, Daniele Panozzo", "title": "ABC: A Big CAD Model Dataset For Geometric Deep Learning", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.CG cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce ABC-Dataset, a collection of one million Computer-Aided Design\n(CAD) models for research of geometric deep learning methods and applications.\nEach model is a collection of explicitly parametrized curves and surfaces,\nproviding ground truth for differential quantities, patch segmentation,\ngeometric feature detection, and shape reconstruction. Sampling the parametric\ndescriptions of surfaces and curves allows generating data in different formats\nand resolutions, enabling fair comparisons for a wide range of geometric\nlearning algorithms. As a use case for our dataset, we perform a large-scale\nbenchmark for estimation of surface normals, comparing existing data driven\nmethods and evaluating their performance against both the ground truth and\ntraditional normal estimation methods.\n", "versions": [{"version": "v1", "created": "Sat, 15 Dec 2018 01:21:48 GMT"}, {"version": "v2", "created": "Tue, 30 Apr 2019 07:18:44 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Koch", "Sebastian", ""], ["Matveev", "Albert", ""], ["Jiang", "Zhongshi", ""], ["Williams", "Francis", ""], ["Artemov", "Alexey", ""], ["Burnaev", "Evgeny", ""], ["Alexa", "Marc", ""], ["Zorin", "Denis", ""], ["Panozzo", "Daniele", ""]]}, {"id": "1812.06232", "submitter": "Michael McCabe", "authors": "Michael McCabe", "title": "Mapper Comparison with Wasserstein Metrics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The challenge of describing model drift is an open question in unsupervised\nlearning. It can be difficult to evaluate at what point an unsupervised model\nhas deviated beyond what would be expected from a different sample from the\nsame population. This is particularly true for models without a probabilistic\ninterpretation. One such family of techniques, Topological Data Analysis, and\nthe Mapper algorithm in particular, has found use in a variety of fields, but\ndescribing model drift for Mapper graphs is an understudied area as even\nexisting techniques for measuring distances between related constructs like\ngraphs or simplicial complexes fail to account for the fact that Mapper graphs\nrepresent a combination of topological, metric, and density information. In\nthis paper, we develop an optimal transport based metric which we call the\nNetwork Augmented Wasserstein Distance for evaluating distances between Mapper\ngraphs and demonstrate the value of the metric for model drift analysis by\nusing the metric to transform the model drift problem into an anomaly detection\nproblem over dynamic graphs.\n", "versions": [{"version": "v1", "created": "Sat, 15 Dec 2018 04:00:17 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["McCabe", "Michael", ""]]}, {"id": "1812.06254", "submitter": "Guanghua Pan", "authors": "Guanghua Pan and Jun Wang and Rendong Ying and Peilin Liu", "title": "3DTI-Net: Learn Inner Transform Invariant 3D Geometry Features using\n  Dynamic GCN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning on point clouds has made a lot of progress recently. Many point\ncloud dedicated deep learning frameworks, such as PointNet and PointNet++, have\nshown advantages in accuracy and speed comparing to those using traditional 3D\nconvolution algorithms. However, nearly all of these methods face a challenge,\nsince the coordinates of the point cloud are decided by the coordinate system,\nthey cannot handle the problem of 3D transform invariance properly. In this\npaper, we propose a general framework for point cloud learning. We achieve\ntransform invariance by learning inner 3D geometry feature based on local graph\nrepresentation, and propose a feature extraction network based on graph\nconvolution network. Through experiments on classification and segmentation\ntasks, our method achieves state-of-the-art performance in rotated 3D object\nclassification, and achieve competitive performance with the state-of-the-art\nin classification and segmentation tasks with fixed coordinate value.\n", "versions": [{"version": "v1", "created": "Sat, 15 Dec 2018 08:37:04 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Pan", "Guanghua", ""], ["Wang", "Jun", ""], ["Ying", "Rendong", ""], ["Liu", "Peilin", ""]]}, {"id": "1812.06491", "submitter": "Mikael Vejdemo-Johansson", "authors": "Mikael Vejdemo-Johansson and Sayan Mukherjee", "title": "Multiple testing with persistent homology", "comments": "18 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG math.AT stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a computationally efficient multiple hypothesis\ntesting procedure for persistence homology. Most current approaches to\nhypothesis testing using persistence homology is based on resampling or\npermutation procedures, this is because there exists little distribution theory\nthat provides a natural null model for persistence diagrams. In this paper we\npropose a null model based based approach to testing for acyclicity, coupled\nwith a Family-Wise Error Rate (FWER) control method that does not suffer from\nthe computational costs associated to resampling and permutation based\napproaches. We adapt standard False Discovery Rate (FDR) control procedures to\nthe topological setting, and use our null model for hypothesis testing using\npersistent homology. A key idea in our paper is that one can compute an\nempirical distribution under a null hypothesis model that can be used for\nhypothesis testing in the same way that a normal or t-distribution is used in\nclassical statistics. A argument for the use of this empirical null is based on\nsimulations and limit theorems for persistent homology for point processes.\n", "versions": [{"version": "v1", "created": "Sun, 16 Dec 2018 15:54:13 GMT"}, {"version": "v2", "created": "Thu, 7 Nov 2019 01:15:22 GMT"}, {"version": "v3", "created": "Sat, 19 Dec 2020 20:50:56 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Vejdemo-Johansson", "Mikael", ""], ["Mukherjee", "Sayan", ""]]}, {"id": "1812.06740", "submitter": "Daniel Kraft", "authors": "Daniel Kraft", "title": "Computing the Hausdorff Distance of Two Sets from Their Signed Distance\n  Functions", "comments": "Originally published as preprint IGDK-2015-03 at\n  http://igdk1754.ma.tum.de/IGDK1754/Preprints", "journal-ref": "International Journal of Computational Geometry & Applications,\n  vol 30(01), 2020", "doi": "10.1142/S0218195920500028", "report-no": null, "categories": "math.MG cs.CG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The Hausdorff distance is a measure of (dis-)similarity between two sets\nwhich is widely used in various applications. Most of the applied literature is\ndevoted to the computation for sets consisting of a finite number of points.\nThis has applications, for instance, in image processing. However, we would\nlike to apply the Hausdorff distance to control and evaluate optimisation\nmethods in level-set based shape optimisation. In this context, the involved\nsets are not finite point sets but characterised by level-set or signed\ndistance functions. This paper discusses the computation of the Hausdorff\ndistance between two such sets. We recall fundamental properties of the\nHausdorff distance, including a characterisation in terms of distance\nfunctions. In numerical applications, this result gives at least an exact lower\nbound on the Hausdorff distance. We also derive an upper bound, and\nconsequently a precise error estimate. By giving an example, we show that our\nerror estimate cannot be further improved for a general situation. On the other\nhand, we also show that much better accuracy can be expected for\nnon-pathological situations that are more likely to occur in practice. The\nresulting error estimate can be improved even further if one assumes that the\ngrid is rotated randomly with respect to the involved sets.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2018 13:02:54 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Kraft", "Daniel", ""]]}, {"id": "1812.06907", "submitter": "Pat Morin", "authors": "Paz Carmi, Matthew J. Katz, Pat Morin", "title": "Stabbing Pairwise Intersecting Disks by Four Points", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In their seminal work, Danzer (1956, 1986) and Stach\\'{o} (1981) established\nthat every set of pairwise intersecting disks in the plane can be stabbed by\nfour points. However, both these proofs are non-constructive, at least in the\nsense that they do not seem to imply an efficient algorithm for finding the\nstabbing points, given such a set of disks $D$. Recently, Har-Peled \\etal\n(2018) presented a relatively simple linear-time algorithm for finding five\npoints that stab $D$. We present an alternative proof (and the first in\nEnglish) to the assertion that four points are sufficient to stab $D$.\nMoreover, our proof is constructive and provides a simple linear-time algorithm\nfor finding the stabbing points. As a warmup, we present a nearly-trivial\nliner-time algorithm with an elementary proof for finding five points that stab\n$D$.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2018 17:27:03 GMT"}, {"version": "v2", "created": "Thu, 20 Dec 2018 16:03:40 GMT"}, {"version": "v3", "created": "Fri, 21 Dec 2018 12:58:04 GMT"}, {"version": "v4", "created": "Tue, 9 Jul 2019 20:20:23 GMT"}, {"version": "v5", "created": "Tue, 11 Aug 2020 00:01:22 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Carmi", "Paz", ""], ["Katz", "Matthew J.", ""], ["Morin", "Pat", ""]]}, {"id": "1812.07431", "submitter": "Mor Joseph-Rivlin", "authors": "Mor Joseph-Rivlin, Alon Zvirin and Ron Kimmel", "title": "Momen(e)t: Flavor the Moments in Learning to Classify Shapes", "comments": null, "journal-ref": "GMDL Workshop, ICCV 2019", "doi": null, "report-no": null, "categories": "cs.CG cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental question in learning to classify 3D shapes is how to treat the\ndata in a way that would allow us to construct efficient and accurate geometric\nprocessing and analysis procedures. Here, we restrict ourselves to networks\nthat operate on point clouds. There were several attempts to treat point clouds\nas non-structured data sets by which a neural network is trained to extract\ndiscriminative properties. The idea of using 3D coordinates as class\nidentifiers motivated us to extend this line of thought to that of shape\nclassification by comparing attributes that could easily account for the shape\nmoments. Here, we propose to add polynomial functions of the coordinates\nallowing the network to account for higher order moments of a given shape.\nExperiments on two benchmarks show that the suggested network is able to\nprovide state of the art results and at the same token learn more efficiently\nin terms of memory and computational complexity.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2018 15:25:04 GMT"}, {"version": "v2", "created": "Thu, 3 Oct 2019 05:25:51 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Joseph-Rivlin", "Mor", ""], ["Zvirin", "Alon", ""], ["Kimmel", "Ron", ""]]}, {"id": "1812.07721", "submitter": "Vincent Cohen-Addad", "authors": "Vincent Cohen-Addad", "title": "Approximation Schemes for Capacitated Clustering in Doubling Metrics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by applications in redistricting, we consider the uniform\ncapacitated k-median and uniform capacitated k-means problems in bounded\ndoubling metrics. We provide the first QPTAS for both problems and the first\nPTAS for the uniform capacitated k-median problem for points in R^2 . This is\nthe first improvement over the bicriteria QPTAS for capacitated k-median in\nlow-dimensional Euclidean space of Arora, Raghavan, Rao [STOC 1998] (1 +\n{\\epsilon}-approximation, 1 + {\\epsilon}-capacity violation) and arguably the\nfirst polynomial-time approximation algorithm for a non-trivial metric.\n", "versions": [{"version": "v1", "created": "Wed, 19 Dec 2018 01:14:09 GMT"}, {"version": "v2", "created": "Wed, 6 Nov 2019 14:57:34 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Cohen-Addad", "Vincent", ""]]}, {"id": "1812.08525", "submitter": "Xavier Goaoc", "authors": "Olivier Devillers (GAMBLE), Philippe Duchon (LaBRI), Marc Glisse\n  (DATASHAPE), Xavier Goaoc (GAMBLE)", "title": "On Order Types of Random Point Sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A simple method to produce a random order type is to take the order type of a\nrandom point set. We conjecture that many probability distributions on order\ntypes defined in this way are heavily concentrated and therefore sample\ninefficiently the space of order types. We present two results on this\nquestion. First, we study experimentally the bias in the order types of $n$\nrandom points chosen uniformly and independently in a square, for $n$ up to\n$16$. Second, we study algorithms for determining the order type of a point set\nin terms of the number of coordinate bits they require to know. We give an\nalgorithm that requires on average $4n \\log\\_2 n+O(n)$ bits to determine the\norder type of $P$, and show that any algorithm requires at least $4n \\log\\_2 n\n- O(n \\log\\log n)$ bits. This implies that the concentration conjecture cannot\nbe proven by an \"efficient encoding\" argument.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2018 12:42:36 GMT"}, {"version": "v2", "created": "Fri, 13 Sep 2019 08:12:01 GMT"}, {"version": "v3", "created": "Thu, 4 Jun 2020 12:15:32 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Devillers", "Olivier", "", "GAMBLE"], ["Duchon", "Philippe", "", "LaBRI"], ["Glisse", "Marc", "", "DATASHAPE"], ["Goaoc", "Xavier", "", "GAMBLE"]]}, {"id": "1812.08644", "submitter": "Gary Pui-Tung Choi", "authors": "Gary P. T. Choi, Levi H. Dudte, L. Mahadevan", "title": "Programming shape using kirigami tessellations", "comments": null, "journal-ref": "Nature Materials 18, 999-1004 (2019)", "doi": "10.1038/s41563-019-0452-y", "report-no": null, "categories": "cond-mat.soft cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kirigami tessellations, regular planar patterns formed by cutting flat, thin\nsheets, have attracted recent scientific interest for their rich geometries,\nsurprising material properties and promise for technologies. Here we pose and\nsolve the inverse problem of designing the number, size, and orientation of\ncuts that allows us to convert a closed, compact regular kirigami tessellation\nof the plane into a deployment that conforms approximately to any prescribed\ntarget shape in two and three dimensions. We do this by first identifying the\nconstraints on the lengths and angles of generalized kirigami tessellations\nwhich guarantee that their reconfigured face geometries can be contracted from\na non-trivial deployed shape to a novel planar cut pattern. We encode these\nconditions in a flexible constrained optimization framework which allows us to\ndeform the geometry of periodic kirigami tesselations with three, four, and\nsixfold symmetry, among others, into generalized kirigami patterns that deploy\nto a wide variety of prescribed boundary target shapes. Physically fabricated\nmodels verify our inverse design approach and allow us to determine the tunable\nmaterial response of the resulting structures. We then extend our framework to\ncreate generalized kirigami patterns that deploy to approximate curved surfaces\nin $\\mathbb{R}^3$. Altogether, this work illustrates a novel framework for\ndesigning complex, shape-changing sheets from simple cuts showing the power of\nkirigami tessellations as flexible mechanical metamaterials.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2018 15:45:52 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Choi", "Gary P. T.", ""], ["Dudte", "Levi H.", ""], ["Mahadevan", "L.", ""]]}, {"id": "1812.08664", "submitter": "David Saulpic", "authors": "Vincent Cohen-Addad, Andreas Emil Feldmann, David Saulpic", "title": "Near-Linear Time Approximation Schemes for Clustering in Doubling\n  Metrics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the classic Facility Location, $k$-Median, and $k$-Means problems\nin metric spaces of doubling dimension $d$. We give nearly linear-time\napproximation schemes for each problem. The complexity of our algorithms is\n$2^{(\\log(1/\\eps)/\\eps)^{O(d^2)}} n \\log^4 n + 2^{O(d)} n \\log^9 n$, making a\nsignificant improvement over the state-of-the-art algorithms which run in time\n$n^{(d/\\eps)^{O(d)}}$.\n  Moreover, we show how to extend the techniques used to get the first\nefficient approximation schemes for the problems of prize-collecting\n$k$-Medians and $k$-Means, and efficient bicriteria approximation schemes for\n$k$-Medians with outliers, $k$-Means with outliers and $k$-Center.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2018 16:12:00 GMT"}, {"version": "v2", "created": "Sun, 23 Dec 2018 16:53:02 GMT"}, {"version": "v3", "created": "Tue, 11 Jun 2019 16:11:17 GMT"}, {"version": "v4", "created": "Wed, 20 May 2020 14:07:43 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Cohen-Addad", "Vincent", ""], ["Feldmann", "Andreas Emil", ""], ["Saulpic", "David", ""]]}, {"id": "1812.09085", "submitter": "Michael Kerber", "authors": "Michael Kerber, Michael Lesnick, Steve Oudot", "title": "Exact computation of the matching distance on 2-parameter persistence\n  modules", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AT cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The matching distance is a pseudometric on multi-parameter persistence\nmodules, defined in terms of the weighted bottleneck distance on the\nrestriction of the modules to affine lines. It is known that this distance is\nstable in a reasonable sense, and can be efficiently approximated, which makes\nit a promising tool for practical applications. In this work, we show that in\nthe 2-parameter setting, the matching distance can be computed exactly in\npolynomial time. Our approach subdivides the space of affine lines into\nregions, via a line arrangement. In each region, the matching distance\nrestricts to a simple analytic function, whose maximum is easily computed. As a\nbyproduct, our analysis establishes that the matching distance is a rational\nnumber, if the bigrades of the input modules are rational.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2018 12:39:24 GMT"}, {"version": "v2", "created": "Tue, 28 May 2019 10:15:13 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Kerber", "Michael", ""], ["Lesnick", "Michael", ""], ["Oudot", "Steve", ""]]}, {"id": "1812.09095", "submitter": "Bernhard Kilgus", "authors": "Hugo A. Akitaya, Maike Buchin, Bernhard Kilgus, Stef Sijben, Carola\n  Wenk", "title": "Distance Measures for Embedded Graphs", "comments": "27 pages, 14 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce new distance measures for comparing straight-line embedded\ngraphs based on the Fr\\'echet distance and the weak Fr\\'echet distance. These\ngraph distances are defined using continuous mappings and thus take the\ncombinatorial structure as well as the geometric embeddings of the graphs into\naccount. We present a general algorithmic approach for computing these graph\ndistances. Although we show that deciding the distances is NP-hard for general\nembedded graphs, we prove that our approach yields polynomial time algorithms\nif the graphs are trees, and for the distance based on the weak Fr\\'echet\ndistance if the graphs are planar embedded. Moreover, we prove that deciding\nthe distances based on the Fr\\'echet distance remains NP-hard for planar\nembedded graphs and show how our general algorithmic approach yields an\nexponential time algorithm and a polynomial time approximation algorithm for\nthis case.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2018 13:03:08 GMT"}, {"version": "v2", "created": "Mon, 25 Mar 2019 09:23:09 GMT"}, {"version": "v3", "created": "Fri, 26 Apr 2019 12:22:23 GMT"}, {"version": "v4", "created": "Wed, 11 Sep 2019 14:32:22 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Akitaya", "Hugo A.", ""], ["Buchin", "Maike", ""], ["Kilgus", "Bernhard", ""], ["Sijben", "Stef", ""], ["Wenk", "Carola", ""]]}, {"id": "1812.09413", "submitter": "Fedor Manin", "authors": "Fedor Manin and Shmuel Weinberger", "title": "Algorithmic aspects of immersibility and embeddability", "comments": "15 pages; comments welcome!", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.GT cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze an algorithmic question about immersion theory: for which $m$,\n$n$, and $CAT=\\mathbf{Diff}$ or $\\mathbf{PL}$ is the question of whether an\n$m$-dimensional $CAT$-manifold is immersible in $\\mathbb{R}^n$ decidable? As a\ncorollary, we show that the smooth embeddability of an $m$-manifold with\nboundary in $\\mathbb{R}^n$ is undecidable when $n-m$ is even and $11m \\geq\n10n+1$.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2018 23:34:29 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Manin", "Fedor", ""], ["Weinberger", "Shmuel", ""]]}, {"id": "1812.09913", "submitter": "Pat Morin", "authors": "Prosenjit Bose, Paz Carmi, Vida Dujmovic, and Pat Morin", "title": "Near-Optimal $O(k)$-Robust Geometric Spanners", "comments": "New version with streamlined construction and fewer edges", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For any constants $d\\ge 1$, $\\epsilon >0$, $t>1$, and any $n$-point set\n$P\\subset\\mathbb{R}^d$, we show that there is a geometric graph $G=(P,E)$\nhaving $O(n\\log^2 n\\log\\log n)$ edges with the following property: For any\n$F\\subseteq P$, there exists $F^+\\supseteq F$, $|F^+| \\le (1+\\epsilon)|F|$ such\nthat, for any pair $p,q\\in P\\setminus F^+$, the graph $G-F$ contains a path\nfrom $p$ to $q$ whose (Euclidean) length is at most $t$ times the Euclidean\ndistance between $p$ and $q$.\n  In the terminology of robust spanners (Bose \\et al, SICOMP, 42(4):1720--1736,\n2013) the graph $G$ is a $(1+\\epsilon)k$-robust $t$-spanner of $P$. This\nconstruction is sparser than the recent constructions of Buchin, Ol\\`ah, and\nHar-Peled (arXiv:1811.06898) who prove the existence of $(1+\\epsilon)k$-robust\n$t$-spanners with $n\\log^{O(d)} n$ edges.\n", "versions": [{"version": "v1", "created": "Mon, 24 Dec 2018 13:08:31 GMT"}, {"version": "v2", "created": "Sun, 6 Jan 2019 12:35:55 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Bose", "Prosenjit", ""], ["Carmi", "Paz", ""], ["Dujmovic", "Vida", ""], ["Morin", "Pat", ""]]}, {"id": "1812.09951", "submitter": "Lucas Bueno", "authors": "Lucas Moutinho Bueno", "title": "3-Colorable Delaunay Triangulations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an algorithm to create a 3-colorable Delaunay Triangulation. The\ninput of the problem we are trying to solve is a set X of n twodimensional\npoints. The output is a 3-colorable two-dimensional Delaunay triangulation T\nfor X U Y , where Y is a set of m new points. We want to m be as few as\npossible.\n", "versions": [{"version": "v1", "created": "Mon, 24 Dec 2018 16:33:27 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Bueno", "Lucas Moutinho", ""]]}, {"id": "1812.10111", "submitter": "Hamid Laga", "authors": "Hamid Laga", "title": "A Survey on Non-rigid 3D Shape Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.CG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shape is an important physical property of natural and manmade 3D objects\nthat characterizes their external appearances. Understanding differences\nbetween shapes and modeling the variability within and across shape classes,\nhereinafter referred to as \\emph{shape analysis}, are fundamental problems to\nmany applications, ranging from computer vision and computer graphics to\nbiology and medicine. This chapter provides an overview of some of the recent\ntechniques that studied the shape of 3D objects that undergo non-rigid\ndeformations including bending and stretching. Recent surveys that covered some\naspects such classification, retrieval, recognition, and rigid or nonrigid\nregistration, focused on methods that use shape descriptors. Descriptors,\nhowever, provide abstract representations that do not enable the exploration of\nshape variability. In this chapter, we focus on recent techniques that treated\nthe shape of 3D objects as points in some high dimensional space where paths\ndescribe deformations. Equipping the space with a suitable metric enables the\nquantification of the range of deformations of a given shape, which in turn\nenables (1) comparing and classifying 3D objects based on their shape, (2)\ncomputing smooth deformations, i.e. geodesics, between pairs of objects, and\n(3) modeling and exploring continuous shape variability in a collection of 3D\nmodels. This article surveys and classifies recent developments in this field,\noutlines fundamental issues, discusses their potential applications in computer\nvision and graphics, and highlights opportunities for future research. Our\nprimary goal is to bridge the gap between various techniques that have been\noften independently proposed by different communities including mathematics and\nstatistics, computer vision and graphics, and medical image analysis.\n", "versions": [{"version": "v1", "created": "Tue, 25 Dec 2018 14:33:42 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Laga", "Hamid", ""]]}, {"id": "1812.10162", "submitter": "Saeed Mehrabi", "authors": "Huda Chuangpishit, Saeed Mehrabi, Lata Narayanan, and Jaroslav Opatrny", "title": "Evacuating Equilateral Triangles and Squares in the Face-to-Face Model", "comments": "28 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider $k$ robots initially located at a point inside a region $T$. Each\nrobot can move anywhere in $T$ independently of other robots with maximum speed\none. The goal of the robots is to \\emph{evacuate} $T$ through an exit at an\nunknown location on the boundary of $T$. The objective is to minimize the\n\\emph{evacuation time}, which is defined as the time the \\emph{last} robot\nreaches the exit. We consider the \\emph{face-to-face} communication model for\nthe robots: a robot can communicate with another robot only when they meet in\n$T$.\n  In this paper, we give upper and lower bounds for the face-to-face evacuation\ntime by $k$ robots that are initially located at the centroid of a unit-sided\nequilateral triangle or square. For the case of a triangle with $k=2$ robots,\nwe give a lower bound of $1+2/\\sqrt{3} \\approx 2.154$, and an algorithm with\nupper bound of 2.3367 on the worst-case evacuation time. We show that for any\n$k$, any algorithm for evacuating $k\\geq 2$ robots requires at least $\\sqrt{3}$\ntime. This bound is asymptotically optimal, as we show that even a\nstraightforward strategy of evacuation by $k$ robots gives an upper bound of\n$\\sqrt{3} + 3/k$. For $k=3$ and $4$, we give better algorithms with evacuation\ntimes of 2.0887 and 1.9816, respectively. For the case of the square and $k=2$,\nwe give an algorithm with evacuation time of $3.4645$ and show that any\nalgorithm requires time at least $3.118$ to evacuate in the worst-case.\nMoreover, for $k=3$, and $4$, we give algorithms with evacuation times 3.1786\nand 2.6646, respectively. The algorithms given for $k=3$ and $4$ for evacuation\nin the triangle or the square can be easily generalized for larger values of\n$k$.\n", "versions": [{"version": "v1", "created": "Tue, 25 Dec 2018 19:40:49 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Chuangpishit", "Huda", ""], ["Mehrabi", "Saeed", ""], ["Narayanan", "Lata", ""], ["Opatrny", "Jaroslav", ""]]}, {"id": "1812.10269", "submitter": "Joshua Zahl", "authors": "Pankaj K. Agarwal, Boris Aronov, Esther Ezra, Joshua Zahl", "title": "An Efficient Algorithm for Generalized Polynomial Partitioning and Its\n  Applications", "comments": "30 pages, 0 figures. v2: final version, to appear in SIAM J. Comput", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 2015, Guth proved that if $S$ is a collection of $n$ $g$-dimensional\nsemi-algebraic sets in $\\mathbb{R}^d$ and if $D\\geq 1$ is an integer, then\nthere is a $d$-variate polynomial $P$ of degree at most $D$ so that each\nconnected component of $\\mathbb{R}^d\\setminus Z(P)$ intersects $O(n/D^{d-g})$\nsets from $S$. Such a polynomial is called a generalized partitioning\npolynomial. We present a randomized algorithm that computes such polynomials\nefficiently -- the expected running time of our algorithm is linear in $|S|$.\nOur approach exploits the technique of quantifier elimination combined with\nthat of $\\epsilon$-samples. We also present an extension of our construction to\nmulti-level polynomial partitioning for semi-algebraic sets in $\\mathbb{R}^d$.\n  We present five applications of our result. The first is a data structure for\nanswering point-enclosure queries among a family of semi-algebraic sets in\n$\\mathbb{R}^d$ in $O(\\log n)$ time, with storage complexity and expected\npreprocessing time of $O(n^{d+\\epsilon})$. The second is a data structure for\nanswering range-searching queries with semi-algebraic ranges in $\\mathbb{R}^d$\nin $O(\\log n)$ time, with $O(n^{t+\\epsilon})$ storage and expected\npreprocessing time, where $t > 0$ is an integer that depends on $d$ and the\ndescription complexity of the ranges. The third is a data structure for\nanswering vertical ray-shooting queries among semi-algebraic sets in\n$\\mathbb{R}^{d}$ in $O(\\log^2 n)$ time, with $O(n^{d+\\epsilon})$ storage and\nexpected preprocessing time. The fourth is an efficient algorithm for cutting\nalgebraic curves in $\\mathbb{R}^2$ into pseudo-segments. The fifth application\nis for eliminating depth cycles among triangles in $\\mathbb{R}^3$, where we\nshow a nearly-optimal algorithm to cut $n$ pairwise disjoint non-vertical\ntriangles in $\\mathbb{R}^3$ into pieces that form a depth order.\n", "versions": [{"version": "v1", "created": "Wed, 26 Dec 2018 09:38:01 GMT"}, {"version": "v2", "created": "Sat, 23 Jan 2021 05:54:38 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Agarwal", "Pankaj K.", ""], ["Aronov", "Boris", ""], ["Ezra", "Esther", ""], ["Zahl", "Joshua", ""]]}, {"id": "1812.10530", "submitter": "Matias Korman", "authors": "Y. Diez, M. Fort, M. Korman, J.A. Sellar\\`es", "title": "Group evolution patterns in running races", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of tracking and detecting interactions between the\ndifferent groups of runners that form during a race. In athletic races control\npoints are set to monitor the progress of athletes over the course.\nIntuitively, a {\\it group} is a sufficiently large set of athletes that cross a\ncontrol point together. After adapting an existing definition of group to our\nsetting we go on to study two types of group evolution patterns. The primary\nfocus of this work are {\\it evolution patterns}, i.e. the transformation and\ninteraction of groups of athletes between two consecutive control points. We\nprovide an accurate geometric model of the following evolution patterns:\nsurvives, appears, disappears, expands, shrinks, merges, splits, coheres and\ndisbands, and present algorithms to efficiently compute these patterns. Next,\nbased on the algorithms introduced for identifying evolution patterns,\nalgorithms to detect {\\it long-term patterns} are introduced. These patterns\ntrack global properties over several control points: surviving, traceable\nforward, traceable backward and related forward and backward. Experimental\nevaluation of the algorithms provided is presented using real and synthetic\ndata. Using the data currently available, our experiments show how our\nalgorithms can provide valuable insight into how running races develop.\nMoreover, we also show how, even if dense (synthetic) data is considered, our\nalgorithms are also able to process it in real time.\n", "versions": [{"version": "v1", "created": "Wed, 26 Dec 2018 20:31:48 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Diez", "Y.", ""], ["Fort", "M.", ""], ["Korman", "M.", ""], ["Sellar\u00e8s", "J. A.", ""]]}, {"id": "1812.11177", "submitter": "Patrick Andersen", "authors": "Patrick J. Andersen and Charl J. Ras", "title": "Degree Bounded Bottleneck Spanning Trees in Three Dimensions", "comments": "35 pages, 22 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The geometric $\\delta$-minimum spanning tree problem ($\\delta$-MST) is the\nproblem of finding a minimum spanning tree for a set of points in a normed\nvector space, such that no vertex in the tree has a degree which exceeds\n$\\delta$, and the sum of the lengths of the edges in the tree is minimum. The\nsimilarly defined geometric $\\delta$-minimum bottleneck spanning tree problem\n($\\delta$-MBST), is the problem of finding a degree bounded spanning tree such\nthat the length of the longest edge is minimum. For point sets that lie in the\nEuclidean plane, both of these problems have been shown to be NP-hard for\ncertain specific values of $\\delta$. In this paper, we investigate the\n$\\delta$-MBST problem in $3$-dimensional Euclidean space and $3$-dimensional\nrectilinear space. We show that the problems are NP-hard for certain values of\n$\\delta$, and we provide inapproximability results for these cases. We also\ndescribe new approximation algorithms for solving these $3$-dimensional\nvariants, and then analyse their worst-case performance.\n", "versions": [{"version": "v1", "created": "Fri, 28 Dec 2018 05:00:39 GMT"}, {"version": "v2", "created": "Fri, 18 Jan 2019 12:30:35 GMT"}, {"version": "v3", "created": "Fri, 25 Jan 2019 14:00:22 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Andersen", "Patrick J.", ""], ["Ras", "Charl J.", ""]]}, {"id": "1812.11257", "submitter": "Brittany Terese Fasy", "authors": "Brittany Terese Fasy, Xiaozhou He, Zhihui Liu, Samuel Micka, David L.\n  Millman, Binhai Zhu", "title": "Approximate Nearest Neighbors in the Space of Persistence Diagrams", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Persistence diagrams are important tools in the field of topological data\nanalysis that describe the presence and magnitude of features in a filtered\ntopological space. However, current approaches for comparing a persistence\ndiagram to a set of other persistence diagrams is linear in the number of\ndiagrams or do not offer performance guarantees. In this paper, we apply\nconcepts from locality-sensitive hashing to support approximate nearest\nneighbor search in the space of persistence diagrams. Given a set $\\Gamma$ of\n$n$ $(M,m)$-bounded persistence diagrams, each with at most $m$ points, we\nsnap-round the points of each diagram to points on a cubical lattice and\nproduce a key for each possible snap-rounding. Specifically, we fix a grid over\neach diagram at several resolutions and consider the snap-roundings of each\ndiagram to the four nearest lattice points. Then, we propose a data structure\nwith $\\tau$ levels $\\mathbb{D}_{\\tau}$ that stores all snap-roundings of each\npersistence diagram in $\\Gamma$ at each resolution. This data structure has\nsize $O(n5^m\\tau)$ to account for varying lattice resolutions as well as\nsnap-roundings and the deletion of points with low persistence. To search for a\npersistence diagram, we compute a key for a query diagram by snapping each\npoint to a lattice and deleting points of low persistence. Furthermore, as the\nlattice parameter decreases, searching our data structure yields a\nsix-approximation of the nearest diagram in $\\Gamma$ in\n$O((m\\log{n}+m^2)\\log\\tau)$ time and a constant factor approximation of the\n$k$th nearest diagram in $O((m\\log{n}+m^2+k)\\log\\tau)$ time.\n", "versions": [{"version": "v1", "created": "Sat, 29 Dec 2018 01:15:19 GMT"}, {"version": "v2", "created": "Mon, 22 Mar 2021 19:48:06 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Fasy", "Brittany Terese", ""], ["He", "Xiaozhou", ""], ["Liu", "Zhihui", ""], ["Micka", "Samuel", ""], ["Millman", "David L.", ""], ["Zhu", "Binhai", ""]]}, {"id": "1812.11258", "submitter": "Xiaojun Zheng", "authors": "So Mang Han, Taylor Okonek, Nikesh Yadav, Xiaojun Zheng", "title": "Distributions of Matching Distances in Topological Data Analysis", "comments": "21 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG math.AT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In topological data analysis, we want to discern topological and geometric\nstructure of data, and to understand whether or not certain features of data\nare significant as opposed to simply random noise. While progress has been made\non statistical techniques for single-parameter persistence, the case of\ntwo-parameter persistence, which is highly desirable for real-world\napplications, has been less studied. This paper provides an accessible\nintroduction to two-parameter persistent homology and presents results about\nmatching distance between 2-D persistence modules obtained from families of\npoint clouds. Results include observations of how differences in geometric\nstructure of point clouds affect the matching distance between persistence\nmodules. We offer these results as a starting point for the investigation of\nmore complex data.\n", "versions": [{"version": "v1", "created": "Sat, 29 Dec 2018 01:16:09 GMT"}, {"version": "v2", "created": "Thu, 9 Jan 2020 17:42:07 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Han", "So Mang", ""], ["Okonek", "Taylor", ""], ["Yadav", "Nikesh", ""], ["Zheng", "Xiaojun", ""]]}, {"id": "1812.11332", "submitter": "Claire Pennarun", "authors": "Jean-Lou De Carufel, Adrian Dumitrescu (CS), Wouter Meulemans, Tim\n  Ophelders, Claire Pennarun (ALGCO), Csaba Toth (CPSC), Sander Verdonschot", "title": "Convex Polygons in Cartesian Products", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study several problems concerning convex polygons whose vertices lie in a\nCartesian product (for short, grid) of two sets of n real numbers. First, we\nprove that every such grid contains a convex polygon with $\\Omega$(log n)\nvertices and that this bound is tight up to a constant factor. We generalize\nthis result to d dimensions (for a fixed d $\\in$ N), and obtain a tight lower\nbound of $\\Omega$(log d--1 n) for the maximum number of points in convex\nposition in a d-dimensional grid. Second, we present polynomial-time algorithms\nfor computing the largest convex chain in a grid that contains no two points of\nthe same x-or y-coordinate. We show how to efficiently approximate the maximum\nsize of a supported convex polygon up to a factor of 2. Finally, we present\nexponential bounds on the maximum number of convex polygons in these grids, and\nfor some restricted variants. These bounds are tight up to polynomial factors.\n", "versions": [{"version": "v1", "created": "Sat, 29 Dec 2018 10:45:56 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["De Carufel", "Jean-Lou", "", "CS"], ["Dumitrescu", "Adrian", "", "CS"], ["Meulemans", "Wouter", "", "ALGCO"], ["Ophelders", "Tim", "", "ALGCO"], ["Pennarun", "Claire", "", "ALGCO"], ["Toth", "Csaba", "", "CPSC"], ["Verdonschot", "Sander", ""]]}]