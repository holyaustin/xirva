[{"id": "1904.00526", "submitter": "Qiang Zou", "authors": "Qiang Zou and Hsi-Yung Feng", "title": "On Limitations of the Witness Configuration Method for Geometric\n  Constraint Solving in CAD Modeling", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents discussions on the limitations of the witness\nconfiguration method. These limitations have rarely been reported in previous\nstudies. The witness configuration method is a very recent approach for\ngeometric constraint solving, which is of critical importance for modern\ncomputer-aided design systems. The witness configuration method may be the most\npromising method to solve satisfactorily the challenges of geometric constraint\nsolving. This method, in the current form, is however found to be limited for\nthe three essential tasks in the geometric constraint solving domain. Examples\nare given to validate this work's statements on these limitations.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 01:18:52 GMT"}, {"version": "v2", "created": "Mon, 15 Apr 2019 21:34:53 GMT"}, {"version": "v3", "created": "Fri, 21 Jun 2019 00:52:59 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Zou", "Qiang", ""], ["Feng", "Hsi-Yung", ""]]}, {"id": "1904.02034", "submitter": "Martin Wilhelm", "authors": "Hanna Geppert and Martin Wilhelm", "title": "Internal versus external balancing in the evaluation of graph-based\n  number types", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Number types for exact computation are usually based on directed acyclic\ngraphs. A poor graph structure can impair the efficency of their evaluation. In\nsuch cases the performance of a number type can be drastically improved by\nrestructuring the graph or by internally balancing error bounds with respect to\nthe graph's structure. We compare advantages and disadvantages of these two\nconcepts both theoretically and experimentally.\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2019 14:41:19 GMT"}, {"version": "v2", "created": "Fri, 12 Apr 2019 12:20:38 GMT"}, {"version": "v3", "created": "Wed, 21 Aug 2019 12:49:43 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Geppert", "Hanna", ""], ["Wilhelm", "Martin", ""]]}, {"id": "1904.02204", "submitter": "Nadav Dym", "authors": "Nadav Dym and Shahar Ziv Kovalsky", "title": "Linearly Converging Quasi Branch and Bound Algorithms for Global Rigid\n  Registration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, several branch-and-bound (BnB) algorithms have been proposed\nto globally optimize rigid registration problems. In this paper, we suggest a\ngeneral framework to improve upon the BnB approach, which we name Quasi BnB.\nQuasi BnB replaces the linear lower bounds used in BnB algorithms with\nquadratic quasi-lower bounds which are based on the quadratic behavior of the\nenergy in the vicinity of the global minimum. While quasi-lower bounds are not\ntruly lower bounds, the Quasi-BnB algorithm is globally optimal. In fact we\nprove that it exhibits linear convergence -- it achieves $\\epsilon$-accuracy in\n$~O(\\log(1/\\epsilon)) $ time while the time complexity of other rigid\nregistration BnB algorithms is polynomial in $1/\\epsilon $. Our experiments\nverify that Quasi-BnB is significantly more efficient than state-of-the-art BnB\nalgorithms, especially for problems where high accuracy is desired.\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2019 19:07:25 GMT"}, {"version": "v2", "created": "Sun, 14 Apr 2019 04:30:34 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Dym", "Nadav", ""], ["Kovalsky", "Shahar Ziv", ""]]}, {"id": "1904.02404", "submitter": "Martin Tancer", "authors": "Pavel Pat\\'ak and Martin Tancer", "title": "Embeddings of $k$-complexes into $2k$-manifolds", "comments": "Version 2: Some fixes of typos. Added a Helly type theorem", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AT cs.CG math.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $K$ be a simplicial $k$-complex and $M$ be a closed PL $2k$-manifold. Our\naim is to describe an obstruction for embeddability of $K$ into $M$ via the\nintersection form on $M$. For description of the obstruction, we need a\ntechnical condition that every map $f\\colon |K| \\to M$ is homotopic to a map\n$f'\\colon |K| \\to M$ such that $f'(|K^{(k-1)}|)$ fits into some $2k$-ball in\n$M$, where $K^{(k-1)}$ stands for the $(k-1)$-skeleton of $K$. The technical\ncondition is satisfied, in particular, either if $M$ is $(k-1)$-connected or if\n$K$ is the $k$-skeleton of $n$-simplex, $\\Delta_n^{(k)}$, for some $n$. Under\nthe technical condition, if $K$ embeds in $M$, then our obstruction vanishes.\nIn addition, if $M$ is $(k-1)$-connected and $k \\geq 3$, then the obstruction\nis complete, that is, we get the reverse implication.\n  If $M = S^{2k}$ (or $\\mathbb{R}^{2k}$) then the intersection form on $M$\nvanishes and our obstruction coincides with the standard van Kampen\nobstruction. However, if the intersection form is nontrivial, then our\nobstruction is not linear (a cohomology class) but rather `quadratic' in a\nsense that it vanishes if and only if a certain system of quadratic equations\nover integers is solvable. It remains to be determined whether these systems\ncan be solved algorithmically.\n  Finally, the $\\mathbb{Z}_2$-reduction of the obstruction shows how to obtain\na non-trivial upper bound for the K\\\"{u}hnel problem: determine the smallest\n$n$ so that $\\Delta_n^{(k)}$ does not embed into $M$. Also, the\n$\\mathbb{Z}_2$-reduction is computable and, if $M$ is $(k-1)$-connected, it\ndetermines whether there is a map $f\\colon |K| \\to M$ which has an even number\nof crossings of $f(\\sigma)$ and $f(\\tau)$ for each pair $(\\sigma, \\tau)$ of\ndisjoint $k$-simplices of $K$.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2019 08:30:23 GMT"}, {"version": "v2", "created": "Wed, 24 Jul 2019 12:56:06 GMT"}, {"version": "v3", "created": "Wed, 12 Feb 2020 10:16:27 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Pat\u00e1k", "Pavel", ""], ["Tancer", "Martin", ""]]}, {"id": "1904.02502", "submitter": "Patrick Schnider", "authors": "Luis Barba, Alexander Pilz, Patrick Schnider", "title": "Sharing a pizza: bisecting masses with two cuts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Assume you have a pizza consisting of four ingredients (e.g., bread,\ntomatoes, cheese and olives) that you want to share with your friend. You want\nto do this fairly, meaning that you and your friend should get the same amount\nof each ingredient. How many times do you need to cut the pizza so that this is\npossible? We will show that two straight cuts always suffice. More formally, we\nwill show the following extension of the well-known Ham-sandwich theorem: Given\nfour mass distributions in the plane, they can be simultaneously bisected with\ntwo lines. That is, there exist two oriented lines with the following property:\nlet $R^+_1$ be the region of the plane that lies to the positive side of both\nlines and let $R^+_2$ be the region of the plane that lies to the negative side\nof both lines. Then $R^+=R^+_1\\cup R^+_2$ contains exactly half of each mass\ndistribution.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2019 11:59:00 GMT"}], "update_date": "2019-04-05", "authors_parsed": [["Barba", "Luis", ""], ["Pilz", "Alexander", ""], ["Schnider", "Patrick", ""]]}, {"id": "1904.03015", "submitter": "Fatemeh Rajabi-Alni", "authors": "Fatemeh Rajabi-Alni and Alireza Bagheri", "title": "A Faster Algorithm for the Limited-Capacity Many-to-Many Point Matching\n  in One Dimension", "comments": "18 pages, 7 figures. arXiv admin note: text overlap with\n  arXiv:1702.01083", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given two point sets S and T on a line, we present the first linear time\nalgorithm for finding the limited capacity many-to-many matching (LCMM) between\nS and T improving the previous best known quadratic time algorithm. The aim of\nthe LCMM is to match each point of S (T) to at least one point of T (S) such\nthat the matching costs is minimized and the number of the points matched to\neach point is limited to a given number.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2019 06:22:09 GMT"}, {"version": "v2", "created": "Sat, 13 Apr 2019 21:22:24 GMT"}, {"version": "v3", "created": "Wed, 17 Apr 2019 13:04:11 GMT"}, {"version": "v4", "created": "Thu, 4 Jul 2019 03:41:01 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Rajabi-Alni", "Fatemeh", ""], ["Bagheri", "Alireza", ""]]}, {"id": "1904.03039", "submitter": "Martin N\\\"ollenburg", "authors": "Soeren Nickel and Martin N\\\"ollenburg", "title": "Towards Data-Driven Multilinear Metro Maps", "comments": "Full version of a paper accepted at Diagrams 2020; replaces an\n  earlier workshop paper from the 2nd Schematic Mapping Workshop, Vienna, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditionally, most schematic metro maps in practice as well as metro map\nlayout algorithms adhere to an octolinear layout style with all paths composed\nof horizontal, vertical, and 45{\\deg}-diagonal edges. Despite growing interest\nin more general multilinear metro maps, generic algorithms to draw metro maps\nbased on a system of $k \\ge 2$ not necessarily equidistant slopes have not been\ninvestigated thoroughly. In this paper we present and implement an adaptation\nof the octolinear mixed-integer linear programming approach of N\\\"ollenburg and\nWolff (2011) that can draw metro maps schematized to any set C of arbitrary\norientations. We further present a data-driven approach to determine a suitable\nset C by either detecting the best rotation of an equidistant orientation\nsystem or by clustering the input edge orientations using a k-means algorithm.\nWe demonstrate the new possibilities of our method using several real-world\nexamples.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2019 12:54:29 GMT"}, {"version": "v2", "created": "Thu, 14 May 2020 19:39:10 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Nickel", "Soeren", ""], ["N\u00f6llenburg", "Martin", ""]]}, {"id": "1904.03050", "submitter": "Jonas Cleve", "authors": "Jonas Cleve and Wolfgang Mulzer", "title": "An Experimental Study of Algorithms for Geodesic Shortest Paths in the\n  Constant-Workspace Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We perform an experimental evaluation of algorithms for finding geodesic\nshortest paths between two points inside a simple polygon in the\nconstant-workspace model. In this model, the input resides in a read-only array\nthat can be accessed at random. In addition, the algorithm may use a constant\nnumber of words for reading and for writing. The constant-workspace model has\nbeen studied extensively in recent years, and algorithms for geodesic shortest\npaths have received particular attention.\n  We have implemented three such algorithms in Python, and we compare them to\nthe classic algorithm by Lee and Preparata that uses linear time and linear\nspace. We also clarify a few implementation details that were missing in the\noriginal description of the algorithms. Our experiments show that all\nalgorithms perform as advertised in the original works and according to the\ntheoretical guarantees. However, the constant factors in the running times turn\nout to be rather large for the algorithms to be fully useful in practice.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2019 13:20:09 GMT"}], "update_date": "2019-04-08", "authors_parsed": [["Cleve", "Jonas", ""], ["Mulzer", "Wolfgang", ""]]}, {"id": "1904.03611", "submitter": "Lee-Ad Gottlieb", "authors": "Lee-Ad Gottlieb and Yair Bartal", "title": "Near-linear time approximation schemes for Steiner tree and forest in\n  low-dimensional spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give an algorithm that computes a $(1+\\epsilon)$-approximate Steiner\nforest in near-linear time $n \\cdot 2^{(1/\\epsilon)^{O(ddim^2)} (\\log \\log\nn)^2}$. This is a dramatic improvement upon the best previous result due to\nChan et al., who gave a runtime of $n^{2^{O(ddim)}} \\cdot\n2^{(ddim/\\epsilon)^{O(ddim)} \\sqrt{\\log n}}$.\n  For Steiner tree our methods achieve an even better runtime $n (\\log\nn)^{(1/\\epsilon)^{O(ddim^2)}}$ in doubling spaces. For Euclidean space the\nruntime can be reduced to $2^{(1/\\epsilon)^{O(d^2)}} n \\log n$, improving upon\nthe result of Arora in fixed dimension $d$.\n", "versions": [{"version": "v1", "created": "Sun, 7 Apr 2019 09:17:30 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Gottlieb", "Lee-Ad", ""], ["Bartal", "Yair", ""]]}, {"id": "1904.03764", "submitter": "Man-Kwun Chiu", "authors": "Siu-Wing Cheng and Man-Kwun Chiu", "title": "Implicit Manifold Reconstruction", "comments": "A preliminary version appears in Proceedings of the 25th Annual\n  ACM-SIAM Symposium on Discrete Algorithms, 2014, 161--173", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let ${\\cal M} \\subset \\mathbb{R}^d$ be a compact, smooth and boundaryless\nmanifold with dimension $m$ and unit reach. We show how to construct a function\n$\\varphi: \\mathbb{R}^d \\rightarrow \\mathbb{R}^{d-m}$ from a uniform\n$(\\varepsilon,\\kappa)$-sample $P$ of $\\cal M$ that offers several guarantees.\nLet $Z_\\varphi$ denote the zero set of $\\varphi$. Let $\\widehat{{\\cal M}}$\ndenote the set of points at distance $\\varepsilon$ or less from $\\cal M$. There\nexists $\\varepsilon_0 \\in (0,1)$ that decreases as $d$ increases such that if\n$\\varepsilon \\leq \\varepsilon_0$, the following guarantees hold. First,\n$Z_\\varphi \\cap \\widehat{\\cal M}$ is a faithful approximation of $\\cal M$ in\nthe sense that $Z_\\varphi \\cap \\widehat{\\cal M}$ is homeomorphic to $\\cal M$,\nthe Hausdorff distance between $Z_\\varphi \\cap \\widehat{\\cal M}$ and $\\cal M$\nis $O(m^{5/2}\\varepsilon^{2})$, and the normal spaces at nearby points in\n$Z_\\varphi \\cap \\widehat{\\cal M}$ and $\\cal M$ make an angle\n$O(m^2\\sqrt{\\kappa\\varepsilon})$. Second, $\\varphi$ has local support; in\nparticular, the value of $\\varphi$ at a point is affected only by sample points\nin $P$ that lie within a distance of $O(m\\varepsilon)$. Third, we give a\nprojection operator that only uses sample points in $P$ at distance\n$O(m\\varepsilon)$ from the initial point. The projection operator maps any\ninitial point near $P$ onto $Z_\\varphi \\cap \\widehat{\\cal M}$ in the limit by\nrepeated applications.\n", "versions": [{"version": "v1", "created": "Sun, 7 Apr 2019 22:45:15 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Cheng", "Siu-Wing", ""], ["Chiu", "Man-Kwun", ""]]}, {"id": "1904.03766", "submitter": "Tamal Dey", "authors": "Tamal K. Dey and Cheng Xin", "title": "Generalized Persistence Algorithm for Decomposing Multi-parameter\n  Persistence Modules", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AT cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The classical persistence algorithm virtually computes the unique\ndecomposition of a persistence module implicitly given by an input simplicial\nfiltration. Based on matrix reduction, this algorithm is a cornerstone of the\nemergent area of topological data analysis. Its input is a simplicial\nfiltration defined over the integers $\\mathbb{Z}$ giving rise to a\n$1$-parameter persistence module. It has been recognized that multi-parameter\nversion of persistence modules given by simplicial filtrations over\n$d$-dimensional integer grids $\\mathbb{Z}^d$ is equally or perhaps more\nimportant in data science applications. However, in the multi-parameter\nsetting, one of the main challenges is that topological summaries based on\nalgebraic structure such as decompositions and bottleneck distances cannot be\nas efficiently computed as in the $1$-parameter case because there is no known\nextension of the persistence algorithm to multi-parameter persistence modules.\nWe present an efficient algorithm to compute the unique decomposition of a\nfinitely presented persistence module $M$ defined over the multiparameter\n$\\mathbb{Z}^d$.The algorithm first assumes that the module is presented with a\nset of $N$ generators and relations that are \\emph{distinctly graded}. Based on\na generalized matrix reduction technique it runs in $O(N^{2\\omega+1})$ time\nwhere $\\omega<2.373$ is the exponent for matrix multiplication. This is much\nbetter than the well known algorithm called Meataxe which runs in\n$\\tilde{O}(N^{6(d+1)})$ time on such an input. In practice, persistence modules\nare usually induced by simplicial filtrations. With such an input consisting of\n$n$ simplices, our algorithm runs in $O(n^{2\\omega+1})$ time for $d=2$ and in\n$O(n^{d(2\\omega + 1)})$ time for $d>2$.\n", "versions": [{"version": "v1", "created": "Sun, 7 Apr 2019 23:04:37 GMT"}, {"version": "v2", "created": "Tue, 28 May 2019 19:21:21 GMT"}, {"version": "v3", "created": "Tue, 4 Jun 2019 17:50:24 GMT"}, {"version": "v4", "created": "Fri, 12 Jul 2019 22:01:53 GMT"}, {"version": "v5", "created": "Mon, 24 Feb 2020 02:20:50 GMT"}, {"version": "v6", "created": "Thu, 29 Apr 2021 22:38:01 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Dey", "Tamal K.", ""], ["Xin", "Cheng", ""]]}, {"id": "1904.03796", "submitter": "Hu Ding", "authors": "Hu Ding", "title": "Minimum Enclosing Ball Revisited: Stability and Sub-linear Time\n  Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we revisit the Minimum Enclosing Ball (MEB) problem and its\nrobust version, MEB with outliers, in Euclidean space $\\mathbb{R}^d$. Though\nthe problem has been extensively studied before, most of the existing\nalgorithms need at least linear time (in the number of input points $n$ and the\ndimensionality $d$) to achieve a $(1+\\epsilon)$-approximation. Motivated by\nsome recent developments on beyond worst-case analysis, we introduce the notion\nof stability for MEB (with outliers), which is natural and easy to understand.\nRoughly speaking, an instance of MEB is stable, if the radius of the resulting\nball cannot be significantly reduced by removing a small fraction of the input\npoints. Under the stability assumption, we present two sampling algorithms for\ncomputing approximate MEB with sample complexities independent of the number of\ninput points $n$. In particular, the second algorithm has the sample complexity\neven independent of the dimensionality $d$. Further, we extend the idea to\nachieve a sub-linear time approximation algorithm for the MEB with outliers\nproblem. Note that most existing sub-linear time algorithms for the problems of\nMEB and MEB with outliers usually result in bi-criteria approximations, where\nthe \"bi-criteria\" means that the solution has to allow the approximations on\nthe radius and the number of covered points. Differently, all the algorithms\nproposed in this paper yield single-criterion approximations (with respect to\nradius). We expect that our proposed notion of stability and techniques will be\napplicable to design sub-linear time algorithms for other optimization\nproblems.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 01:39:23 GMT"}, {"version": "v2", "created": "Sun, 14 Jul 2019 03:23:20 GMT"}, {"version": "v3", "created": "Fri, 1 May 2020 01:19:59 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Ding", "Hu", ""]]}, {"id": "1904.04045", "submitter": "Thomas Dybdahl Ahle", "authors": "Thomas Dybdahl Ahle, Jakob B{\\ae}k Tejs Knudsen", "title": "Subsets and Supermajorities: Optimal Hashing-based Set Similarity Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formulate and optimally solve a new generalized Set Similarity Search\nproblem, which assumes the size of the database and query sets are known in\nadvance. By creating polylog copies of our data-structure, we optimally solve\nany symmetric Approximate Set Similarity Search problem, including approximate\nversions of Subset Search, Maximum Inner Product Search (MIPS), Jaccard\nSimilarity Search and Partial Match.\n  Our algorithm can be seen as a natural generalization of previous work on Set\nas well as Euclidean Similarity Search, but conceptually it differs by\noptimally exploiting the information present in the sets as well as their\ncomplements, and doing so asymmetrically between queries and stored sets. Doing\nso we improve upon the best previous work: MinHash [J. Discrete Algorithms\n1998], SimHash [STOC 2002], Spherical LSF [SODA 2016, 2017] and Chosen Path\n[STOC 2017] by as much as a factor $n^{0.14}$ in both time and space; or in the\nnear-constant time regime, in space, by an arbitrarily large polynomial factor.\n  Turning the geometric concept, based on Boolean supermajority functions, into\na practical algorithm requires ideas from branching random walks on $\\mathbb\nZ^2$, for which we give the first non-asymptotic near tight analysis.\n  Our lower bounds follow from new hypercontractive arguments, which can be\nseen as characterizing the exact family of similarity search problems for which\nsupermajorities are optimal. The optimality holds for among all hashing based\ndata structures in the random setting, and by reductions, for 1 cell and 2 cell\nprobe data structures. As a side effect, we obtain new hypercontractive bounds\non the directed noise operator $T^{p_1 \\to p_2}_\\rho$.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 13:23:03 GMT"}, {"version": "v2", "created": "Mon, 20 Apr 2020 11:14:54 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Ahle", "Thomas Dybdahl", ""], ["Knudsen", "Jakob B\u00e6k Tejs", ""]]}, {"id": "1904.05081", "submitter": "Sara Scaramuccia", "authors": "Claudia Landi, Sara Scaramuccia", "title": "Relative-perfectness of discrete gradient vector fields and\n  multi-parameter persistent homology", "comments": "Keywords: Multiparameter persistent homology; discrete Morse theory;\n  persistence modules; Betti tables; Morse inequalities", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The combination of persistent homology and discrete Morse theory has proven\nvery effective in visualizing and analyzing big and heterogeneous data. Indeed,\ntopology provides computable and coarse summaries of data independently from\nspecific coordinate systems and does so robustly to noise. Moreover, the\ngeometric content of a discrete gradient vector field is very useful for\nvisualization purposes. The specific case of multivariate data still demands\nfor further investigations, on the one hand, for computational reasons, it is\nimportant to reduce the necessary amount of data to be processed. On the other\nhand, for analysis reasons, the multivariate case requires the detection and\ninterpretation of the possible interdepedance among data components. To this\nend, in this paper we introduce and study a notion of perfectness for discrete\ngradient vector fields with respect to multi-parameter persistent homology,\ncalled relative-perfectness. As a natural generalization of usual perfectness\nin Morse theory for homology, relative-perfectness entails having the least\nnumber of critical cells relevant for multi-parameter persistence. As a first\ncontribution, we support our definition of relative-perfectness by generalizing\nMorse inequalities to the filtration structure where homology groups involved\nare relative with respect to subsequent sublevel sets. In order to allow for an\ninterpretation of critical cells in $2$-parameter persistence, our second\ncontribution consists of two inequalities bounding Betti tables of persistence\nmodules from above and below, via the number of critical cells. Our last result\nis the proof that existing algorithms based on local homotopy expansions allow\nfor efficient computability over simplicial complexes up to dimension $2$.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 09:21:45 GMT"}, {"version": "v2", "created": "Thu, 11 Feb 2021 12:38:47 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Landi", "Claudia", ""], ["Scaramuccia", "Sara", ""]]}, {"id": "1904.05173", "submitter": "Stanis{\\l}aw Ambroszkiewicz", "authors": "Stanislaw Ambroszkiewicz", "title": "Combinatorial constructions of intrinsic geometries", "comments": "The final version (hopefully)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG math.DG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A generic method for combinatorial constructions of intrinsic geometrical\nspaces is presented. It is based on the well known inverse sequences of finite\ngraphs that determine (in the limit) topological spaces. If a pattern of the\nconstruction is sufficiently regular and uniform, then the notions of metric,\ngeodesic and curvature can be defined in the space as the limits of their\nfinite versions in the graphs. This gives rise to consider the graphs with\nmetrics as finite approximations of the geometry of the space. On the basis of\nsimple and generic examples, several nonstandard and novel notions are proposed\nfor the Foundations of Geometry. They may be considered as a subject of a\ncritical discussion.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 13:21:08 GMT"}, {"version": "v2", "created": "Tue, 9 Jul 2019 20:07:11 GMT"}, {"version": "v3", "created": "Mon, 23 Sep 2019 19:14:57 GMT"}, {"version": "v4", "created": "Wed, 6 Nov 2019 15:36:29 GMT"}, {"version": "v5", "created": "Sat, 7 Dec 2019 11:12:42 GMT"}, {"version": "v6", "created": "Mon, 27 Apr 2020 11:10:15 GMT"}, {"version": "v7", "created": "Thu, 8 Oct 2020 15:57:59 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Ambroszkiewicz", "Stanislaw", ""]]}, {"id": "1904.05184", "submitter": "Fatemeh Rajabi-Alni", "authors": "Fatemeh Rajabi-Alni and Alireza Bagheri", "title": "A Fast and Efficient algorithm for Many-To-Many Matching of Points with\n  Demands in One Dimension", "comments": "14 pages,8 figures. arXiv admin note: substantial text overlap with\n  arXiv:1702.01083", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given two point sets S and T, a many-to-many matching with demands (MMD)\nproblem is the problem of finding a minimum-cost many-to-many matching between\nS and T such that each point of S (respectively T) is matched to at least a\ngiven number of the points of T (respectively S). We propose the first O(n^2)\ntime algorithm for computing a one dimensional MMD (OMMD) of minimum cost\nbetween S and T, where |S|+|T| = n. In an OMMD problem, the input point sets S\nand T lie on the real line and the cost of matching a point to another point\nequals the distance between the two points. We also study a generalized version\nof the MMD problem, the many-to-many matching with demands and capacities\n(MMDC) problem, that in which each point has a limited capacity in addition to\na demand. We give the first O(n^2) time algorithm for the minimum-cost one\ndimensional MMDC (OMMDC) problem.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 13:44:41 GMT"}, {"version": "v2", "created": "Sun, 14 Jul 2019 04:44:30 GMT"}, {"version": "v3", "created": "Sun, 1 Dec 2019 09:42:27 GMT"}, {"version": "v4", "created": "Fri, 14 Aug 2020 23:14:50 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Rajabi-Alni", "Fatemeh", ""], ["Bagheri", "Alireza", ""]]}, {"id": "1904.06079", "submitter": "David Monniaux", "authors": "Camille Coti (LIPN), David Monniaux (VERIMAG - IMAG), Hang Yu", "title": "Parallel parametric linear programming solving, and application to\n  polyhedral computations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parametric linear programming is central in polyhedral computations and in\ncertain control applications.We propose a task-based scheme for parallelizing\nit, with quasi-linear speedup over large problems.\n", "versions": [{"version": "v1", "created": "Fri, 12 Apr 2019 07:37:50 GMT"}], "update_date": "2019-04-15", "authors_parsed": [["Coti", "Camille", "", "LIPN"], ["Monniaux", "David", "", "VERIMAG - IMAG"], ["Yu", "Hang", ""]]}, {"id": "1904.06760", "submitter": "Saeed Mehrabi", "authors": "Stephane Durocher, Stefan Felsner, Saeed Mehrabi, and Debajyoti Mondal", "title": "Drawing HV-Restricted Planar Graphs", "comments": "17 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A strict orthogonal drawing of a graph $G=(V, E)$ in $\\mathbb{R}^2$ is a\ndrawing of $G$ such that each vertex is mapped to a distinct point and each\nedge is mapped to a horizontal or vertical line segment. A graph $G$ is\n$HV$-restricted if each of its edges is assigned a horizontal or vertical\norientation. A strict orthogonal drawing of an $HV$-restricted graph $G$ is\ngood if it is planar and respects the edge orientations of $G$. In this paper,\nwe give a polynomial-time algorithm to check whether a given $HV$-restricted\nplane graph (i.e., a planar graph with a fixed combinatorial embedding) admits\na good orthogonal drawing preserving the input embedding, which settles an open\nquestion posed by Ma\\v{n}uch et al. (Graph Drawing 2010). We then examine\n$HV$-restricted planar graphs (i.e., when the embedding is not fixed), and give\na complete characterization of the $HV$-restricted biconnected outerplanar\ngraphs that admit good orthogonal drawings.\n", "versions": [{"version": "v1", "created": "Sun, 14 Apr 2019 21:13:48 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Durocher", "Stephane", ""], ["Felsner", "Stefan", ""], ["Mehrabi", "Saeed", ""], ["Mondal", "Debajyoti", ""]]}, {"id": "1904.06832", "submitter": "Sang Won Bae", "authors": "Sang Won Bae", "title": "On the Minimum-Area Rectangular and Square Annulus Problem", "comments": "22 pages; 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we address the minimum-area rectangular and square annulus\nproblem, which asks a rectangular or square annulus of minimum area, either in\na fixed orientation or over all orientations, that encloses a set $P$ of $n$\ninput points in the plane. To our best knowledge, no nontrivial results on the\nproblem have been discussed in the literature, while its minimum-width variants\nhave been intensively studied. For a fixed orientation, we show reductions to\nwell-studied problems: the minimum-width square annulus problem and the largest\nempty rectangle problem, yielding algorithms of time complexity $O(n\\log^2 n)$\nand $O(n\\log n)$ for the rectangular and square cases, respectively. In\narbitrary orientation, we present $O(n^3)$-time algorithms for the rectangular\nand square annulus problem by enumerating all maximal empty rectangles over all\norientations. The same approach is shown to apply also to the minimum-width\nsquare annulus problem and the largest empty square problem over all\norientations, resulting in $O(n^3)$-time algorithms for both problems.\nConsequently, we improve the previously best algorithm for the minimum-width\nsquare annulus problem by a factor of logarithm, and present the first\nalgorithm for the largest empty square problem in arbitrary orientation. We\nalso consider bicriteria optimization variants, computing a minimum-width\nminimum-area or minimum-area minimum-width annulus.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 04:07:03 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Bae", "Sang Won", ""]]}, {"id": "1904.06833", "submitter": "Sang Won Bae", "authors": "Sang Won Bae", "title": "Computing a Minimum-Width Cubic and Hypercubic Shell", "comments": "13 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of computing a minimum-width axis-aligned\ncubic shell that encloses a given set of $n$ points in a three-dimensional\nspace. A cubic shell is a closed volume between two concentric and\nface-parallel cubes. Prior to this work, there was no known algorithm for this\nproblem in the literature. We present the first nontrivial algorithm whose\nrunning time is $O(n \\log^2 n)$. Our approach easily extends to higher\ndimension, resulting in an $O(n^{\\lfloor d/2 \\rfloor} \\log^{d-1} n)$-time\nalgorithm for the hypercubic shell problem in $d\\geq 3$ dimension.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 04:08:43 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Bae", "Sang Won", ""]]}, {"id": "1904.07172", "submitter": "Jan Eric Lenssen", "authors": "Jan Eric Lenssen, Christian Osendorfer, Jonathan Masci", "title": "Deep Iterative Surface Normal Estimation", "comments": "Presented at CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an end-to-end differentiable algorithm for robust and\ndetail-preserving surface normal estimation on unstructured point-clouds. We\nutilize graph neural networks to iteratively parameterize an adaptive\nanisotropic kernel that produces point weights for weighted least-squares plane\nfitting in local neighborhoods. The approach retains the interpretability and\nefficiency of traditional sequential plane fitting while benefiting from\nadaptation to data set statistics through deep learning. This results in a\nstate-of-the-art surface normal estimator that is robust to noise, outliers and\npoint density variation, preserves sharp features through anisotropic kernels\nand equivariance through a local quaternion-based spatial transformer. Contrary\nto previous deep learning methods, the proposed approach does not require any\nhand-crafted features or preprocessing. It improves on the state-of-the-art\nresults while being more than two orders of magnitude faster and more parameter\nefficient.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 16:40:38 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2020 12:51:28 GMT"}, {"version": "v3", "created": "Tue, 23 Jun 2020 13:01:36 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Lenssen", "Jan Eric", ""], ["Osendorfer", "Christian", ""], ["Masci", "Jonathan", ""]]}, {"id": "1904.07403", "submitter": "Audun Myers", "authors": "Audun Myers and Elizabeth Munch and Firas A. Khasawneh", "title": "Persistent Homology of Complex Networks for Dynamic State Detection", "comments": null, "journal-ref": "Phys. Rev. E 100, 022314 (2019)", "doi": "10.1103/PhysRevE.100.022314", "report-no": null, "categories": "nlin.CD cs.CG cs.IT math.IT physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we develop a novel Topological Data Analysis (TDA) approach for\nstudying graph representations of time series of dynamical systems.\nSpecifically, we show how persistent homology, a tool from TDA, can be used to\nyield a compressed, multi-scale representation of the graph that can\ndistinguish between dynamic states such as periodic and chaotic behavior. We\nshow the approach for two graph constructions obtained from the time series. In\nthe first approach the time series is embedded into a point cloud which is then\nused to construct an undirected $k$-nearest neighbor graph. The second\nconstruct relies on the recently developed ordinal partition framework. In\neither case, a pairwise distance matrix is then calculated using the shortest\npath between the graph's nodes, and this matrix is utilized to define a\nfiltration of a simplicial complex that enables tracking the changes in\nhomology classes over the course of the filtration. These changes are\nsummarized in a persistence diagram---a two-dimensional summary of changes in\nthe topological features. We then extract existing as well as new geometric and\nentropy point summaries from the persistence diagram and compare to other\ncommonly used network characteristics. Our results show that persistence-based\npoint summaries yield a clearer distinction of the dynamic behavior and are\nmore robust to noise than existing graph-based scores, especially when combined\nwith ordinal graphs.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 02:08:59 GMT"}, {"version": "v2", "created": "Mon, 27 Jan 2020 13:59:01 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Myers", "Audun", ""], ["Munch", "Elizabeth", ""], ["Khasawneh", "Firas A.", ""]]}, {"id": "1904.07601", "submitter": "Yongcheng Liu", "authors": "Yongcheng Liu, Bin Fan, Shiming Xiang and Chunhong Pan", "title": "Relation-Shape Convolutional Neural Network for Point Cloud Analysis", "comments": "Accepted to CVPR 2019 as an oral presentation. Project page at\n  https://yochengliu.github.io/Relation-Shape-CNN", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CG cs.GR cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Point cloud analysis is very challenging, as the shape implied in irregular\npoints is difficult to capture. In this paper, we propose RS-CNN, namely,\nRelation-Shape Convolutional Neural Network, which extends regular grid CNN to\nirregular configuration for point cloud analysis. The key to RS-CNN is learning\nfrom relation, i.e., the geometric topology constraint among points.\nSpecifically, the convolutional weight for local point set is forced to learn a\nhigh-level relation expression from predefined geometric priors, between a\nsampled point from this point set and the others. In this way, an inductive\nlocal representation with explicit reasoning about the spatial layout of points\ncan be obtained, which leads to much shape awareness and robustness. With this\nconvolution as a basic operator, RS-CNN, a hierarchical architecture can be\ndeveloped to achieve contextual shape-aware learning for point cloud analysis.\nExtensive experiments on challenging benchmarks across three tasks verify\nRS-CNN achieves the state of the arts.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 11:28:51 GMT"}, {"version": "v2", "created": "Mon, 22 Apr 2019 06:56:46 GMT"}, {"version": "v3", "created": "Sun, 26 May 2019 03:55:11 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Liu", "Yongcheng", ""], ["Fan", "Bin", ""], ["Xiang", "Shiming", ""], ["Pan", "Chunhong", ""]]}, {"id": "1904.07657", "submitter": "Martin Do\\v{s}k\\'a\\v{r}", "authors": "Martin Do\\v{s}k\\'a\\v{r} (1), Jan Zeman (1 and 2), Daniel Rypl (1), Jan\n  Nov\\'ak (1) ((1) Faculty of Civil Engineering, Czech Technical University in\n  Prague, (2) Institute of Information Theory and Automation)", "title": "Level-set based design of Wang tiles for modelling complex\n  microstructures", "comments": "16 pages, 16 figures. Abstract has been shortened to match the\n  arXiv.org's limit of 1920 characters", "journal-ref": "Computer-Aided Design 123 (2020) 102827", "doi": "10.1016/j.cad.2020.102827", "report-no": null, "categories": "cs.CG cond-mat.mtrl-sci", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Microstructural geometry plays a critical role in the response of\nheterogeneous materials. Consequently, methods for generating microstructural\nsamples are increasingly crucial to advanced numerical analyses. We extend\nSonon et al.'s unified framework, developed originally for generating\nparticulate and foam-like microstructural geometries of Periodic Unit Cells, to\nnon-periodic microstructural representations based on the formalism of Wang\ntiles. This formalism has been recently proposed in order to generalize the\nPeriodic Unit Cell approach, enabling a fast synthesis of arbitrarily large,\nstochastic microstructural samples from a handful of domains with predefined\ncompatibility constraints. However, a robust procedure capable of designing\ncomplex, three-dimensional, foam-like and cellular morphologies of Wang tiles\nhas not yet been proposed. This contribution fills the gap by significantly\nbroadening the applicability of the tiling concept.\n  Since the original Sonon et al.'s framework builds on a random sequential\naddition of particles enhanced with an implicit representation of particle\nboundaries by the level-set field, we first devise an analysis based on a\nconnectivity graph of a tile set, resolving the question where a particle\nshould be copied when it intersects a tile boundary. Next, we introduce several\nmodifications to the original algorithm that are necessary to ensure\nmicrostructural compatibility in the generalized periodicity setting of Wang\ntiles. Having established a universal procedure for generating tile\nmorphologies, we compare strictly aperiodic and stochastic sets with the same\ncardinality in terms of reducing the artificial periodicity in reconstructed\nmicrostructural samples. We demonstrate the superiority of the vertex-defined\ntile sets for two-dimensional problems and illustrate the capabilities of the\nalgorithm with two- and three-dimensional examples.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 11:36:52 GMT"}, {"version": "v2", "created": "Wed, 11 Mar 2020 18:43:40 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Do\u0161k\u00e1\u0159", "Martin", "", "1 and 2"], ["Zeman", "Jan", "", "1 and 2"], ["Rypl", "Daniel", ""], ["Nov\u00e1k", "Jan", ""]]}, {"id": "1904.07768", "submitter": "Austin Lawson", "authors": "Yu-Min Chung and Austin Lawson", "title": "Persistence Curves: A canonical framework for summarizing persistence\n  diagrams", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CV math.AT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Persistence diagrams are one of the main tools in the field of Topological\nData Analysis (TDA). They contain fruitful information about the shape of data.\nThe use of machine learning algorithms on the space of persistence diagrams\nproves to be challenging as the space is complicated. For that reason,\ntransforming these diagrams in a way that is compatible with machine learning\nis an important topic currently researched in TDA. In this paper, our main\ncontribution consists of three components. First, we develop a general and\nunifying framework of vectorizing diagrams that we call the Persistence Curves\n(PCs), and show that several well-known summaries, such as Persistence\nLandscapes, fall under the PC framework. Second, we propose several new\nsummaries based on PC framework and provide a theoretical foundation for their\nstability analysis. Finally, we apply proposed PCs to two\napplications---texture classification and determining the parameters of a\ndiscrete dynamical system; their performances are competitive with other TDA\nmethods.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 15:38:41 GMT"}, {"version": "v2", "created": "Mon, 18 Nov 2019 20:54:31 GMT"}, {"version": "v3", "created": "Tue, 2 Jun 2020 14:47:33 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Chung", "Yu-Min", ""], ["Lawson", "Austin", ""]]}, {"id": "1904.07964", "submitter": "Wentai Zhang", "authors": "Wentai Zhang, Zhangsihao Yang, Haoliang Jiang, Suyash Nigam, Soji\n  Yamakawa, Tomotake Furuhata, Kenji Shimada, Levent Burak Kara", "title": "3D Shape Synthesis for Conceptual Design and Optimization Using\n  Variational Autoencoders", "comments": "Preprint accepted by ASME IDETC/CIE 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a data-driven 3D shape design method that can learn a generative\nmodel from a corpus of existing designs, and use this model to produce a wide\nrange of new designs. The approach learns an encoding of the samples in the\ntraining corpus using an unsupervised variational autoencoder-decoder\narchitecture, without the need for an explicit parametric representation of the\noriginal designs. To facilitate the generation of smooth final surfaces, we\ndevelop a 3D shape representation based on a distance transformation of the\noriginal 3D data, rather than using the commonly utilized binary voxel\nrepresentation. Once established, the generator maps the latent space\nrepresentations to the high-dimensional distance transformation fields, which\nare then automatically surfaced to produce 3D representations amenable to\nphysics simulations or other objective function evaluation modules. We\ndemonstrate our approach for the computational design of gliders that are\noptimized to attain prescribed performance scores. Our results show that when\ncombined with genetic optimization, the proposed approach can generate a rich\nset of candidate concept designs that achieve prescribed functional goals, even\nwhen the original dataset has only a few or no solutions that achieve these\ngoals.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 20:26:53 GMT"}], "update_date": "2019-04-18", "authors_parsed": [["Zhang", "Wentai", ""], ["Yang", "Zhangsihao", ""], ["Jiang", "Haoliang", ""], ["Nigam", "Suyash", ""], ["Yamakawa", "Soji", ""], ["Furuhata", "Tomotake", ""], ["Shimada", "Kenji", ""], ["Kara", "Levent Burak", ""]]}, {"id": "1904.08624", "submitter": "Petr Hlin\\v{e}n\\'y", "authors": "Onur \\c{C}a\\u{g}{\\i}r{\\i}c{\\i} and Subir Kumar Ghosh and Petr\n  Hlin\\v{e}n\\'y and Bodhayan Roy", "title": "On conflict-free chromatic guarding of simple polygons", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of colouring the vertices of a polygon, such that every\nviewer in it can see a unique colour. The goal is to minimise the number of\ncolours used. This is also known as the conflict-free chromatic guarding\nproblem with vertex guards, and is motivated, e.g., by the problem of radio\nfrequency assignment to sensors placed at the polygon vertices. We first study\nthe scenario in which viewers can be all points of the polygon (such as a\nmobile robot which moves in the interior of the polygon). We efficiently solve\nthe related problem of minimising the number of guards and approximate (up to\nonly an additive error) the number of colours required in the special case of\npolygons called funnels. Then we give an upper bound of O(log^2 n) colours on\nn-vertex weak visibility polygons, by decomposing the problem into sub-funnels.\nThis bound generalises to all simple polygons. We briefly look also at the\nsecond scenario, in which the viewers are only the vertices of the polygon. We\nshow a lower bound of 3 colours in the general case of simple polygons and\nconjecture that this is tight. We also prove that already deciding whether 1 or\n2 colours are enough is NP-complete.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2019 07:50:32 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 21:04:51 GMT"}, {"version": "v3", "created": "Sun, 5 Apr 2020 19:44:05 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["\u00c7a\u011f\u0131r\u0131c\u0131", "Onur", ""], ["Ghosh", "Subir Kumar", ""], ["Hlin\u011bn\u00fd", "Petr", ""], ["Roy", "Bodhayan", ""]]}, {"id": "1904.08746", "submitter": "Malte Renken", "authors": "Vincent Froese and Malte Renken", "title": "Advancing Through Terrains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study terrain visibility graphs, a well-known graph class closely related\nto polygon visibility graphs in computational geometry, for which a precise\ngraph-theoretical characterization is still unknown. Over the last decade,\nterrain visibility graphs attracted attention in the context of time series\nanalysis with various practical applications in areas such as physics,\ngeography and medical sciences. We make progress in understanding terrain\nvisibility graphs by providing several graph-theoretic results. For example, we\nshow that they cannot contain antiholes of size larger than five. Moreover, we\nobtain two algorithmic results. We devise a fast output-sensitive shortest path\nalgorithm on terrain-like graphs and a polynomial-time algorithm for\n\\textsc{Dominating Set} on special terrain visibility graphs (called funnel\nvisibility graphs).\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2019 13:07:35 GMT"}, {"version": "v2", "created": "Wed, 26 Jun 2019 12:04:21 GMT"}, {"version": "v3", "created": "Tue, 25 Aug 2020 09:41:46 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Froese", "Vincent", ""], ["Renken", "Malte", ""]]}, {"id": "1904.08845", "submitter": "Natan Rubin", "authors": "J\\'anos Pach, Natan Rubin, and G\\'abor Tardos", "title": "Planar Point Sets Determine Many Pairwise Crossing Segments", "comments": "A preliminary version to appear in the proceedings of STOC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that any set of $n$ points in general position in the plane\ndetermines $n^{1-o(1)}$ pairwise crossing segments. The best previously known\nlower bound, $\\Omega\\left(\\sqrt n\\right)$, was proved more than 25 years ago by\nAronov, Erd\\H os, Goddard, Kleitman, Klugerman, Pach, and Schulman. Our proof\nis fully constructive, and extends to dense geometric graphs.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2019 15:34:58 GMT"}], "update_date": "2019-04-22", "authors_parsed": [["Pach", "J\u00e1nos", ""], ["Rubin", "Natan", ""], ["Tardos", "G\u00e1bor", ""]]}, {"id": "1904.09216", "submitter": "Mehrdad Ghadiri", "authors": "Mehrdad Ghadiri, Richard Santiago, Bruce Shepherd", "title": "Beyond Submodular Maximization via One-Sided Smoothness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The multilinear framework has achieved the breakthrough $1-1/e$ approximation\nfor maximizing a monotone submodular function subject to a matroid constraint.\nThis framework has a continuous optimization part and a rounding part. We\nextend both parts to a wider array of problems. In particular, we make a\nconceptual contribution by identifying a family of parameterized functions. As\na running example we focus on solving diversity problems $\\max\nf(S)=\\frac{1}{2}\\sum_{i,j\\in A}A_{ij}:S\\in\\mathcal{M}$, where $\\mathcal{M}$ is\na matroid. These diversity functions have $A_{ij}\\geq 0$ as a measure of\ndissimilarity of $i,j$, and $A$ has $0$-diagonal. The multilinear framework\ncannot be directly applied to the multilinear extension of such functions. We\nintroduce a new parameter for functions $F\\in{\\bf C}^2$ which measures the\napproximability of the associated problem $\\max\\{F(x):x\\in P\\}$, for solvable\ndownwards-closed polytopes $P$. A function $F$ is called one-sided\n$\\sigma$-smooth if $\\frac{1}{2}u^T\\nabla^2 F(x)\nu\\leq\\sigma\\cdot\\frac{||u||_1}{||x||_1}u^T\\nabla F(x)$ for all $u,x\\geq 0$,\n$x\\neq 0$.\n  We give an $\\Omega(1/\\sigma)$-approximation for the maximization problem of\nmonotone, normalized one-sided $\\sigma$-smooth $F$ with an additional property:\nnon-positive third order partial derivatives. Using the multilinear framework\nand new matroid rounding techniques for quadratic objectives, we give an\n$\\Omega(1/\\sigma^{3/2})$-approximation for maximizing a $\\sigma$-semi-metric\ndiversity function subject to matroid constraint. This improves upon the\nprevious best bound of $\\Omega(1/\\sigma^2)$ and we give evidence that it may be\ntight. For general one-sided smooth functions, we show the continuous process\ngives an $\\Omega(1/3^{2\\sigma})$-approximation, independent of $n$. In this\nsetting, by discretizing, we present a poly-time algorithm for multilinear\none-sided $\\sigma$-smooth functions.\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2019 14:47:01 GMT"}, {"version": "v2", "created": "Tue, 23 Apr 2019 18:30:53 GMT"}, {"version": "v3", "created": "Tue, 2 Jun 2020 11:36:26 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Ghadiri", "Mehrdad", ""], ["Santiago", "Richard", ""], ["Shepherd", "Bruce", ""]]}, {"id": "1904.09378", "submitter": "Mathieu Carri\\`ere", "authors": "Mathieu Carri\\`ere and Fr\\'ed\\'eric Chazal and Yuichi Ike and Th\\'eo\n  Lacombe and Martin Royer and Yuhei Umeda", "title": "PersLay: A Neural Network Layer for Persistence Diagrams and New Graph\n  Topological Signatures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CG cs.LG math.AT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Persistence diagrams, the most common descriptors of Topological Data\nAnalysis, encode topological properties of data and have already proved pivotal\nin many different applications of data science. However, since the (metric)\nspace of persistence diagrams is not Hilbert, they end up being difficult\ninputs for most Machine Learning techniques. To address this concern, several\nvectorization methods have been put forward that embed persistence diagrams\ninto either finite-dimensional Euclidean space or (implicit) infinite\ndimensional Hilbert space with kernels. In this work, we focus on persistence\ndiagrams built on top of graphs. Relying on extended persistence theory and the\nso-called heat kernel signature, we show how graphs can be encoded by\n(extended) persistence diagrams in a provably stable way. We then propose a\ngeneral and versatile framework for learning vectorizations of persistence\ndiagrams, which encompasses most of the vectorization techniques used in the\nliterature. We finally showcase the experimental strength of our setup by\nachieving competitive scores on classification tasks on real-life graph\ndatasets.\n", "versions": [{"version": "v1", "created": "Sat, 20 Apr 2019 00:21:59 GMT"}, {"version": "v2", "created": "Wed, 5 Jun 2019 02:14:57 GMT"}, {"version": "v3", "created": "Thu, 17 Oct 2019 23:16:02 GMT"}, {"version": "v4", "created": "Mon, 9 Mar 2020 03:15:26 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Carri\u00e8re", "Mathieu", ""], ["Chazal", "Fr\u00e9d\u00e9ric", ""], ["Ike", "Yuichi", ""], ["Lacombe", "Th\u00e9o", ""], ["Royer", "Martin", ""], ["Umeda", "Yuhei", ""]]}, {"id": "1904.09526", "submitter": "Joshua Zahl", "authors": "Boris Aronov, Esther Ezra, and Joshua Zahl", "title": "Constructive Polynomial Partitioning for Algebraic Curves in\n  $\\mathbb{R}^3$ with Applications", "comments": "20 pages, 0 figures. v2: final version, to appear in SIAM J. Comput.\n  A preliminary version of this work was presented in Proc. 30th Annual\n  ACM-SIAM Sympos. Discrete Algorithms, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 2015, Guth proved that for any set of $k$-dimensional bounded complexity\nvarieties in $\\mathbb{R}^d$ and for any positive integer $D$, there exists a\npolynomial of degree at most $D$ whose zero set divides $\\mathbb{R}^d$ into\nopen connected sets, so that only a small fraction of the given varieties\nintersect each of these sets. Guth's result generalized an earlier result of\nGuth and Katz for points.\n  Guth's proof relies on a variant of the Borsuk-Ulam theorem, and for $k>0$,\nit is unknown how to obtain an explicit representation of such a partitioning\npolynomial and how to construct it efficiently. In particular, it is unknown\nhow to effectively construct such a polynomial for bounded-degree algebraic\ncurves (or even lines) in $\\mathbb{R}^3$.\n  We present an efficient algorithmic construction for this setting. Given a\nset of $n$ input algebraic curves and a positive integer $D$, we efficiently\nconstruct a decomposition of space into $O(D^3\\log^3{D})$ open \"cells,\" each of\nwhich meets $O(n/D^2)$ curves from the input. The construction time is\n$O(n^2)$. For the case of lines in $3$-space we present an improved\nimplementation, whose running time is $O(n^{4/3} \\log^{O(1)} n)$. The constant\nof proportionality in both time bounds depends on $D$ and the maximum degree of\nthe polynomials defining the input curves.\n  As an application, we revisit the problem of eliminating depth cycles among\nnon-vertical lines in $3$-space, recently studied by Aronov and Sharir (2018),\nand show an algorithm that cuts $n$ such lines into $O(n^{3/2+\\epsilon})$\npieces that are depth-cycle free, for any $\\epsilon > 0$. The algorithm runs in\n$O(n^{3/2+\\epsilon})$ time, which is a considerable improvement over the\npreviously known algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 21 Apr 2019 01:45:00 GMT"}, {"version": "v2", "created": "Thu, 23 Jul 2020 20:58:34 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Aronov", "Boris", ""], ["Ezra", "Esther", ""], ["Zahl", "Joshua", ""]]}, {"id": "1904.11026", "submitter": "Michael Horton", "authors": "Boris Aronov, Omrit Filtser, Michael Horton, Matthew J. Katz, Khadijeh\n  Sheikhan", "title": "Efficient Nearest-Neighbor Query and Clustering of Planar Curves", "comments": "22 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study two fundamental problems dealing with curves in the plane, namely,\nthe nearest-neighbor problem and the center problem. Let $\\mathcal{C}$ be a set\nof $n$ polygonal curves, each of size $m$. In the nearest-neighbor problem, the\ngoal is to construct a compact data structure over $\\mathcal{C}$, such that,\ngiven a query curve $Q$, one can efficiently find the curve in $\\mathcal{C}$\nclosest to $Q$. In the center problem, the goal is to find a curve $Q$, such\nthat the maximum distance between $Q$ and the curves in $\\mathcal{C}$ is\nminimized. We use the well-known discrete Frechet distance function, both\nunder~$L_\\infty$ and under $L_2$, to measure the distance between two curves.\n  For the nearest-neighbor problem, despite discouraging previous results, we\nidentify two important cases for which it is possible to obtain practical\nbounds, even when $m$ and $n$ are large. In these cases, either $Q$ is a line\nsegment or $\\mathcal{C}$ consists of line segments, and the bounds on the size\nof the data structure and query time are nearly linear in the size of the input\nand query curve, respectively. The returned answer is either exact under\n$L_\\infty$, or approximated to within a factor of $1+\\varepsilon$ under~$L_2$.\nWe also consider the variants in which the location of the input curves is only\nfixed up to translation, and obtain similar bounds, under $L_\\infty$.\n  As for the center problem, we study the case where the center is a line\nsegment, i.e., we seek the line segment that represents the given set as well\nas possible. We present near-linear time exact algorithms under $L_\\infty$,\neven when the location of the input curves is only fixed up to translation.\nUnder $L_2$, we present a roughly $O(n^2m^3)$-time exact algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 19:15:31 GMT"}], "update_date": "2019-04-26", "authors_parsed": [["Aronov", "Boris", ""], ["Filtser", "Omrit", ""], ["Horton", "Michael", ""], ["Katz", "Matthew J.", ""], ["Sheikhan", "Khadijeh", ""]]}, {"id": "1904.11037", "submitter": "Ruy Fabila-Monroy", "authors": "Frank Duque, Ruy Fabila-Monroy, C\\'esar Hern\\'andez-V\\'elez, Carlos\n  Hidalgo-Toscano", "title": "Counting the Number of Crossings in Geometric Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A geometric graph is a graph whose vertices are points in general position in\nthe plane and its edges are straight line segments joining these points. In\nthis paper we give an $O(n^2 \\log n)$ algorithm to compute the number of pairs\nof edges that cross in a geometric graph on $n$ points. For layered, and convex\ngeometric graphs the algorithm takes $O(n^2)$ time.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 19:43:17 GMT"}, {"version": "v2", "created": "Wed, 2 Sep 2020 18:56:54 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Duque", "Frank", ""], ["Fabila-Monroy", "Ruy", ""], ["Hern\u00e1ndez-V\u00e9lez", "C\u00e9sar", ""], ["Hidalgo-Toscano", "Carlos", ""]]}, {"id": "1904.11229", "submitter": "Kilian Verhetsel", "authors": "Kilian Verhetsel, Jeanne Pellerin, Jean-Fran\\c{c}ois Remacle", "title": "Finding Hexahedrizations for Small Quadrangulations of the Sphere", "comments": "Accepted for SIGGRAPH 2019", "journal-ref": null, "doi": "10.1145/3306346.3323017", "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper tackles the challenging problem of constrained hexahedral meshing.\nAn algorithm is introduced to build combinatorial hexahedral meshes whose\nboundary facets exactly match a given quadrangulation of the topological\nsphere. This algorithm is the first practical solution to the problem. It is\nable to compute small hexahedral meshes of quadrangulations for which the\npreviously known best solutions could only be built by hand or contained\nthousands of hexahedra. These challenging quadrangulations include the\nboundaries of transition templates that are critical for the success of general\nhexahedral meshing algorithms.\n  The algorithm proposed in this paper is dedicated to building combinatorial\nhexahedral meshes of small quadrangulations and ignores the geometrical\nproblem. The key idea of the method is to exploit the equivalence between quad\nflips in the boundary and the insertion of hexahedra glued to this boundary.\nThe tree of all sequences of flipping operations is explored, searching for a\npath that transforms the input quadrangulation Q into a new quadrangulation for\nwhich a hexahedral mesh is known. When a small hexahedral mesh exists, a\nsequence transforming Q into the boundary of a cube is found; otherwise, a set\nof pre-computed hexahedral meshes is used.\n  A novel approach to deal with the large number of problem symmetries is\nproposed. Combined with an efficient backtracking search, it allows small\nshellable hexahedral meshes to be found for all even quadrangulations with up\nto 20 quadrangles. All 54,943 such quadrangulations were meshed using no more\nthan 72 hexahedra. This algorithm is also used to find a construction to fill\narbitrary domains, thereby proving that any ball-shaped domain bounded by n\nquadrangles can be meshed with no more than 78 n hexahedra. This very\nsignificantly lowers the previous upper bound of 5396 n.\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2019 09:26:00 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Verhetsel", "Kilian", ""], ["Pellerin", "Jeanne", ""], ["Remacle", "Jean-Fran\u00e7ois", ""]]}, {"id": "1904.12042", "submitter": "Hung Le", "authors": "Hung Le and Shay Solomon", "title": "Truly Optimal Euclidean Spanners", "comments": "59 pages, 23 figures, rewriting section 6", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Euclidean spanners are important geometric structures, having found numerous\napplications over the years. Cornerstone results in this area from the late 80s\nand early 90s state that for any $d$-dimensional $n$-point Euclidean space,\nthere exists a $(1+\\epsilon)$-spanner with $nO(\\epsilon^{-d+1})$ edges and\nlightness $O(\\epsilon^{-2d})$. Surprisingly, the fundamental question of\nwhether or not these dependencies on $\\epsilon$ and $d$ for small $d$ can be\nimproved has remained elusive, even for $d = 2$. This question naturally arises\nin any application of Euclidean spanners where precision is a necessity.\n  The state-of-the-art bounds $nO(\\epsilon^{-d+1})$ and $O(\\epsilon^{-2d})$ on\nthe size and lightness of spanners are realized by the {\\em greedy} spanner. In\n2016, Filtser and Solomon proved that, in low dimensional spaces, the greedy\nspanner is near-optimal. The question of whether the greedy spanner is truly\noptimal remained open to date.\n  The contribution of this paper is two-fold. We resolve these longstanding\nquestions by nailing down the exact dependencies on $\\epsilon$ and $d$ and\nshowing that the greedy spanner is truly optimal. Specifically, for any $d=\nO(1), \\epsilon = \\Omega({n}^{-\\frac{1}{d-1}})$:\n  - We show that any $(1+\\epsilon)$-spanner must have $n\n\\Omega(\\epsilon^{-d+1})$ edges, implying that the greedy (and other) spanners\nachieve the optimal size.\n  - We show that any $(1+\\epsilon)$-spanner must have lightness\n$\\Omega(\\epsilon^{-d})$, and then improve the upper bound on the lightness of\nthe greedy spanner from $O(\\epsilon^{-2d})$ to $O(\\epsilon^{-d})$.\n  We then complement our negative result for the size of spanners with a rather\ncounterintuitive positive result: Steiner points lead to a quadratic\nimprovement in the size of spanners! Our bound for the size of Steiner spanners\nis tight as well (up to lower-order terms).\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 20:45:24 GMT"}, {"version": "v2", "created": "Thu, 30 Apr 2020 05:21:37 GMT"}, {"version": "v3", "created": "Mon, 5 Apr 2021 04:09:59 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Le", "Hung", ""], ["Solomon", "Shay", ""]]}, {"id": "1904.12061", "submitter": "Haitao Wang", "authors": "Christopher Johnson and Haitao Wang", "title": "A Linear-Time Algorithm for Radius-Optimally Augmenting Paths in a\n  Metric Space", "comments": "A preliminary version to appear in WADS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $P$ be a path graph of $n$ vertices embedded in a metric space. We\nconsider the problem of adding a new edge to $P$ to minimize the radius of the\nresulting graph. Previously, a similar problem for minimizing the diameter of\nthe graph was solved in $O(n\\log n)$ time. To the best of our knowledge, the\nproblem of minimizing the radius has not been studied before. In this paper, we\npresent an $O(n)$ time algorithm for the problem, which is optimal.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 22:10:17 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Johnson", "Christopher", ""], ["Wang", "Haitao", ""]]}, {"id": "1904.12117", "submitter": "Morad Behandish", "authors": "Saigopal Nelaturi, Morad Behandish, Amir M. Mirzendehdel, Johan de\n  Kleer", "title": "Automatic Support Removal for Additive Manufacturing Post Processing", "comments": "Special Issue on symposium on Solid and Physical Modeling (SPM'2019)", "journal-ref": "Journal of Computer-Aided Design, 2019", "doi": "10.1016/j.cad.2019.05.030", "report-no": null, "categories": "cs.CG cs.GR cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An additive manufacturing (AM) process often produces a {\\it near-net} shape\nthat closely conforms to the intended design to be manufactured. It sometimes\ncontains additional support structure (also called scaffolding), which has to\nbe removed in post-processing. We describe an approach to automatically\ngenerate process plans for support removal using a multi-axis machining\ninstrument. The goal is to fracture the contact regions between each support\ncomponent and the part, and to do it in the most cost-effective order while\navoiding collisions with evolving near-net shape, including the remaining\nsupport components. A recursive algorithm identifies a maximal collection of\nsupport components whose connection regions to the part are accessible as well\nas the orientations at which they can be removed at a given round. For every\nsuch region, the accessible orientations appear as a 'fiber' in the\ncollision-free space of the evolving near-net shape and the tool assembly. To\norder the removal of accessible supports, the algorithm constructs a search\ngraph whose edges are weighted by the Riemannian distance between the fibers.\nThe least expensive process plan is obtained by solving a traveling salesman\nproblem (TSP) over the search graph. The sequence of configurations obtained by\nsolving TSP is used as the input to a motion planner that finds collision free\npaths to visit all accessible features. The resulting part without the support\nstructure can then be finished using traditional machining to produce the\nintended design. The effectiveness of the method is demonstrated through\nbenchmark examples in 3D.\n", "versions": [{"version": "v1", "created": "Sat, 27 Apr 2019 06:45:42 GMT"}, {"version": "v2", "created": "Thu, 23 May 2019 03:33:32 GMT"}, {"version": "v3", "created": "Tue, 28 May 2019 22:37:55 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Nelaturi", "Saigopal", ""], ["Behandish", "Morad", ""], ["Mirzendehdel", "Amir M.", ""], ["de Kleer", "Johan", ""]]}, {"id": "1904.12142", "submitter": "Alejandro Flores Velazco", "authors": "Alejandro Flores-Velazco, David Mount", "title": "Guarantees on Nearest-Neighbor Condensation heuristics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of nearest-neighbor (NN) condensation aims to reduce the size of\na training set of a nearest-neighbor classifier while maintaining its\nclassification accuracy. Although many condensation techniques have been\nproposed, few bounds have been proved on the amount of reduction achieved. In\nthis paper, we present one of the first theoretical results for practical NN\ncondensation algorithms. We propose two condensation algorithms, called RSS and\nVSS, along with provable upper-bounds on the size of their selected subsets.\nAdditionally, we shed light on the selection size of two other state-of-the-art\nalgorithms, called MSS and FCNN, and compare them to the new algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 27 Apr 2019 10:42:26 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Flores-Velazco", "Alejandro", ""], ["Mount", "David", ""]]}, {"id": "1904.12189", "submitter": "Qi Zhao", "authors": "Qi Zhao, Yusu Wang", "title": "Learning metrics for persistence-based summaries and applications for\n  graph classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently a new feature representation and data analysis methodology based on\na topological tool called persistent homology (and its corresponding\npersistence diagram summary) has started to attract momentum. A series of\nmethods have been developed to map a persistence diagram to a vector\nrepresentation so as to facilitate the downstream use of machine learning\ntools, and in these approaches, the importance (weight) of different\npersistence features are often preset. However often in practice, the choice of\nthe weight function should depend on the nature of the specific type of data\none considers, and it is thus highly desirable to learn a best weight function\n(and thus metric for persistence diagrams) from labelled data. We study this\nproblem and develop a new weighted kernel, called WKPI, for persistence\nsummaries, as well as an optimization framework to learn a good metric for\npersistence summaries. Both our kernel and optimization problem have nice\nproperties. We further apply the learned kernel to the challenging task of\ngraph classification, and show that our WKPI-based classification framework\nobtains similar or (sometimes significantly) better results than the best\nresults from a range of previous graph classification frameworks on a\ncollection of benchmark datasets.\n", "versions": [{"version": "v1", "created": "Sat, 27 Apr 2019 18:01:35 GMT"}, {"version": "v2", "created": "Thu, 12 Dec 2019 01:31:23 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Zhao", "Qi", ""], ["Wang", "Yusu", ""]]}, {"id": "1904.12240", "submitter": "Francisca Gil-Ureta", "authors": "Francisca Gil-Ureta, Nico Pietroni, Denis Zorin", "title": "Structurally optimized shells", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shells, i.e., objects made of a thin layer of material following a surface,\nare among the most common structures in use. They are highly efficient, in\nterms of material required to maintain strength, but also prone to deformation\nand failure. We introduce an efficient method for reinforcing shells, that is,\nadding material to the shell to increase its resilience to external loads. Our\ngoal is to produce a reinforcement structure of minimal weight. It has been\ndemonstrated that optimal reinforcement structures may be qualitatively\ndifferent, depending on external loads and surface shape. In some cases, it\nnaturally consists of discrete protruding ribs; in other cases, a smooth shell\nthickness variation allows to save more material.\n  Most previously proposed solutions, starting from classical Michell trusses,\nare not able to handle a full range of shells (e.g., are restricted to\nself-supporting structures) or are unable to reproduce this range of behaviors,\nresulting in suboptimal structures.\n  We propose a new method that works for any input surface with any load\nconfigurations, taking into account both in-plane (tensile/compression) and\nout-of-plane (bending) forces. By using a more precise volume model, we are\ncapable of producing optimized structures with the full range of qualitative\nbehaviors. Our method includes new algorithms for determining the layout of\nreinforcement structure elements, and an efficient algorithm to optimize their\nshape, minimizing a non-linear non-convex functional at a fraction of the cost\nand with better optimality compared to standard solvers.\n  We demonstrate the optimization results for a variety of shapes, and the\nimprovements it yields in the strength of 3D-printed objects.\n", "versions": [{"version": "v1", "created": "Sun, 28 Apr 2019 01:41:56 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Gil-Ureta", "Francisca", ""], ["Pietroni", "Nico", ""], ["Zorin", "Denis", ""]]}, {"id": "1904.12761", "submitter": "Edgardo Rold\\'an-Pensado", "authors": "Luis Montejano and Eric Pauli and Miguel Raggi and Edgardo\n  Rold\\'an-Pensado", "title": "The graphs behind Reuleaux polyhedra", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work is about graphs arising from Reuleaux polyhedra. Such graphs must\nnecessarily be planar, $3$-connected and strongly self-dual. We study the\nquestion of when these conditions are sufficient.\n  If $G$ is any such a graph with isomorphism $\\tau : G \\to G^*$ (where $G^*$\nis the unique dual graph), a metric mapping is a map $\\eta : V(G) \\to \\mathbb\nR^3$ such that the diameter of $\\eta(G)$ is $1$ and for every pair of vertices\n$(u,v)$ such that $u\\in \\tau(v)$ we have dist$(\\eta(u),\\eta(v)) = 1$. If $\\eta$\nis injective, it is called a metric embedding. Note that a metric embedding\ngives rise to a Reuleaux Polyhedra.\n  Our contributions are twofold: Firstly, we prove that any planar,\n$3$-connected, strongly self-dual graph has a metric mapping by proving that\nthe chromatic number of the diameter graph (whose vertices are $V(G)$ and whose\nedges are pairs $(u,v)$ such that $u\\in \\tau(v)$) is at most $4$, which means\nthere exists a metric mapping to the tetrahedron. Furthermore, we use the\nLov\\'asz neighborhood-complex theorem in algebraic topology to prove that the\nchromatic number of the diameter graph is exactly $4$.\n  Secondly, we develop algorithms that allow us to obtain every such graph with\nup to $14$ vertices. Furthermore, we numerically construct metric embeddings\nfor every such graph. From the theorem and this computational evidence we\nconjecture that every such graph is realizable as a Reuleaux polyhedron in\n$\\mathbb R^3$.\n  In previous work the first and last authors described a method to construct a\nconstant-width body from a Reuleaux polyhedron. So in essence, we also\nconstruct hundreds of new examples of constant-width bodies.\n  This is related to a problem of V\\'azsonyi, and also to a problem of\nBlaschke-Lebesgue.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2019 15:06:13 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Montejano", "Luis", ""], ["Pauli", "Eric", ""], ["Raggi", "Miguel", ""], ["Rold\u00e1n-Pensado", "Edgardo", ""]]}, {"id": "1904.13210", "submitter": "Morad Behandish", "authors": "Morad Behandish, Amir M. Mirzendehdel, Saigopal Nelaturi", "title": "A Classification of Topological Discrepancies in Additive Manufacturing", "comments": "Special Issue on symposium on Solid and Physical Modeling (SPM'2019)", "journal-ref": "Journal of Computer-Aided Design, 2019", "doi": "10.1016/j.cad.2019.05.032", "report-no": null, "categories": "cs.CG cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Additive manufacturing (AM) enables enormous freedom for design of complex\nstructures. However, the process-dependent limitations that result in\ndiscrepancies between as-designed and as-manufactured shapes are not fully\nunderstood. The tradeoffs between infinitely many different ways to approximate\na design by a manufacturable replica are even harder to characterize. To\nsupport design for AM (DfAM), one has to quantify local discrepancies\nintroduced by AM processes, identify the detrimental deviations (if any) to the\noriginal design intent, and prescribe modifications to the design and/or\nprocess parameters to countervail their effects. Our focus in this work will be\non topological analysis. There is ample evidence in many applications that\npreserving local topology (e.g., connectivity of beams in a lattice) is\nimportant even when slight geometric deviations can be tolerated. We first\npresent a generic method to characterize local topological discrepancies due to\nmaterial under- and over-deposition in AM, and show how it captures various\ntypes of defects in the as-manufactured structures. We use this information to\nsystematically modify the as-manufactured outcomes within the limitations of\navailable 3D printer resolution(s), which often comes at the expense of\nintroducing more geometric deviations (e.g., thickening a beam to avoid\ndisconnection). We validate the effectiveness of the method on 3D examples with\nnontrivial topologies such as lattice structures and foams.\n", "versions": [{"version": "v1", "created": "Sat, 27 Apr 2019 17:30:30 GMT"}, {"version": "v2", "created": "Thu, 23 May 2019 02:36:58 GMT"}, {"version": "v3", "created": "Tue, 28 May 2019 22:39:14 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Behandish", "Morad", ""], ["Mirzendehdel", "Amir M.", ""], ["Nelaturi", "Saigopal", ""]]}, {"id": "1904.13369", "submitter": "Sayan Bandyapadhyay", "authors": "Sayan Bandyapadhyay, Saeed Mehrabi", "title": "Constrained Orthogonal Segment Stabbing", "comments": "to appear at CCCG 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $S$ and $D$ each be a set of orthogonal line segments in the plane. A\nline segment $s\\in S$ \\emph{stabs} a line segment $s'\\in D$ if $s\\cap\ns'\\neq\\emptyset$. It is known that the problem of stabbing the line segments in\n$D$ with the minimum number of line segments of $S$ is NP-hard. However, no\nbetter than $O(\\log |S\\cup D|)$-approximation is known for the problem. In this\npaper, we introduce a constrained version of this problem in which every\nhorizontal line segment of $S\\cup D$ intersects a common vertical line. We\nstudy several versions of the problem, depending on which line segments are\nused for stabbing and which line segments must be stabbed. We obtain several\nNP-hardness and constant approximation results for these versions. Our finding\nimplies, the problem remains NP-hard even under the extra assumption on input,\nbut small constant approximation algorithms can be designed.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 17:04:08 GMT"}, {"version": "v2", "created": "Sat, 22 Jun 2019 14:34:56 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Bandyapadhyay", "Sayan", ""], ["Mehrabi", "Saeed", ""]]}]