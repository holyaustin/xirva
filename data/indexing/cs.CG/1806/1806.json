[{"id": "1806.01022", "submitter": "Kilian Verhetsel", "authors": "Kilian Verhetsel, Jeanne Pellerin, Jean-fran\\c{c}ois Remacle", "title": "A 44-element mesh of Schneiders' pyramid: bounding the difficulty of\n  hex-meshing problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper shows that constraint programming techniques can successfully be\nused to solve challenging hex-meshing problems. Schneiders' pyramid is a\nsquare-based pyramid whose facets are subdivided into three or four quadrangles\nby adding vertices at edge midpoints and facet centroids. In this paper, we\nprove that Schneiders' pyramid has no hexahedral meshes with fewer than 18\ninterior vertices and 17 hexahedra, and introduce a valid mesh with 44\nhexahedra. We also construct the smallest known mesh of the octagonal spindle,\nwith 40 hexahedra and 42 interior vertices. These results were obtained through\na general purpose algorithm that computes the hexahedral meshes conformal to a\ngiven quadrilateral surface boundary. The lower bound for Schneiders' pyramid\nis obtained by exhaustively listing the hexahedral meshes with up to 17\ninterior vertices and which have the same boundary as the pyramid. Our\n44-element mesh is obtained by modifying a prior solution with 88 hexahedra.\nThe number of elements was reduced using an algorithm which locally simplifies\ngroups of hexahedra. Given the boundary of such a group, our algorithm is used\nto find a mesh of its interior that has fewer elements than the initial\nsubdivision. The resulting mesh is untangled to obtain a valid hexahedral mesh.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jun 2018 09:20:25 GMT"}, {"version": "v2", "created": "Fri, 21 Sep 2018 09:31:23 GMT"}], "update_date": "2018-09-24", "authors_parsed": [["Verhetsel", "Kilian", ""], ["Pellerin", "Jeanne", ""], ["Remacle", "Jean-fran\u00e7ois", ""]]}, {"id": "1806.01226", "submitter": "J\\'er\\'emy Barbay", "authors": "J\\'er\\'emy Barbay", "title": "Adaptive Computation of the Discrete Fr\\'echet Distance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The discrete Fr{\\'e}chet distance is a measure of similarity between point\nsequences which permits to abstract differences of resolution between the two\ncurves, approximating the original Fr{\\'e}chet distance between curves. Such\ndistance between sequences of respective length $n$ and $m$ can be computed in\ntime within $O(nm)$ and space within $O(n+m)$ using classical dynamic\nprograming techniques, a complexity likely to be optimal in the worst case over\nsequences of similar lenght unless the Strong Exponential Hypothesis is proved\nincorrect. We propose a parameterized analysis of the computational complexity\nof the discrete Fr{\\'e}chet distance in fonction of the area of the dynamic\nprogram matrix relevant to the computation, measured by its \\emph{certificate\nwidth} $\\omega$. We prove that the discrete Fr{\\'e}chet distance can be\ncomputed in time within $((n+m)\\omega)$ and space within $O(n+m+\\omega)$.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jun 2018 17:10:42 GMT"}], "update_date": "2018-06-05", "authors_parsed": [["Barbay", "J\u00e9r\u00e9my", ""]]}, {"id": "1806.02647", "submitter": "Maximilian Konzack", "authors": "Kevin Buchin, Maximilian Konzack, Wim Reddingius", "title": "Progressive Simplification of Polygonal Curves", "comments": "20 pages, 20 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Simplifying polygonal curves at different levels of detail is an important\nproblem with many applications. Existing geometric optimization algorithms are\nonly capable of minimizing the complexity of a simplified curve for a single\nlevel of detail. We present an $O(n^3m)$-time algorithm that takes a polygonal\ncurve of n vertices and produces a set of consistent simplifications for m\nscales while minimizing the cumulative simplification complexity. This\nalgorithm is compatible with distance measures such as the Hausdorff, the\nFr\\'echet and area-based distances, and enables simplification for continuous\nscaling in $O(n^5)$ time. To speed up this algorithm in practice, we present\nnew techniques for constructing and representing so-called shortcut graphs.\nExperimental evaluation of these techniques on trajectory data reveals a\nsignificant improvement of using shortcut graphs for progressive and\nnon-progressive curve simplification, both in terms of running time and memory\nusage.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jun 2018 12:51:07 GMT"}], "update_date": "2018-06-08", "authors_parsed": [["Buchin", "Kevin", ""], ["Konzack", "Maximilian", ""], ["Reddingius", "Wim", ""]]}, {"id": "1806.02851", "submitter": "Krzysztof Fleszar", "authors": "Timothy M. Chan, Thomas C. van Dijk, Krzysztof Fleszar, Joachim\n  Spoerhase, Alexander Wolff", "title": "Stabbing Rectangles by Line Segments - How Decomposition Reduces the\n  Shallow-Cell Complexity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We initiate the study of the following natural geometric optimization\nproblem. The input is a set of axis-aligned rectangles in the plane. The\nobjective is to find a set of horizontal line segments of minimum total length\nso that every rectangle is stabbed by some line segment. A line segment stabs a\nrectangle if it intersects its left and its right boundary. The problem, which\nwe call Stabbing, can be motivated by a resource allocation problem and has\napplications in geometric network design. To the best of our knowledge, only\nspecial cases of this problem have been considered so far.\n  Stabbing is a weighted geometric set cover problem, which we show to be\nNP-hard. A constrained variant of Stabbing turns out to be even APX-hard. While\nfor general set cover the best possible approximation ratio is $\\Theta(\\log\nn)$, it is an important field in geometric approximation algorithms to obtain\nbetter ratios for geometric set cover problems. Chan et al. [SODA'12]\ngeneralize earlier results by Varadarajan [STOC'10] to obtain sub-logarithmic\nperformances for a broad class of weighted geometric set cover instances that\nare characterized by having low shallow-cell complexity. The shallow-cell\ncomplexity of Stabbing instances, however, can be high so that a direct\napplication of the framework of Chan et al. gives only logarithmic bounds. We\nstill achieve a constant-factor approximation by decomposing general instances\ninto what we call laminar instances that have low enough complexity.\n  Our decomposition technique yields constant-factor approximations also for\nthe variant where rectangles can be stabbed by horizontal and vertical segments\nand for two further geometric set cover problems.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jun 2018 18:20:53 GMT"}], "update_date": "2018-06-11", "authors_parsed": [["Chan", "Timothy M.", ""], ["van Dijk", "Thomas C.", ""], ["Fleszar", "Krzysztof", ""], ["Spoerhase", "Joachim", ""], ["Wolff", "Alexander", ""]]}, {"id": "1806.03053", "submitter": "Fabien Feschet", "authors": "Fabien Feschet (IP)", "title": "The Saturated Subpaths Decomposition in Z 2 : a short note on\n  generalized Tangential Cover", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this short note, we generalized the Tangential Cover used in Digital\nGeometry in order to use very general geometric predicates. We present the\nrequired notions of saturated $\\alpha$-paths of a digital curve as well as\nconservative predicates which indeed cover nearly all geometric digital\nprimitives published so far. The goal of this note is to prove that under a\nvery general situation, the size of the Tangential Cover is linear with the\nnumber of points of the input curve. The computation complexity of the\nTangential Cover depends on the complexity of incremental recognition of\ngeometric predicates. Moreover, in the discussion, we show that our approach\ndoes not rely on connectivity of points as it might be though first.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jun 2018 09:56:38 GMT"}], "update_date": "2018-06-11", "authors_parsed": [["Feschet", "Fabien", "", "IP"]]}, {"id": "1806.03931", "submitter": "Bal\\'azs Keszegh", "authors": "Eyal Ackerman and Bal\\'azs Keszegh and D\\\"om\\\"ot\\\"or P\\'alv\\\"olgyi", "title": "Coloring Delaunay-Edges and their Generalizations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider geometric hypergraphs whose vertex set is a finite set of points\n(e.g., in the plane), and whose hyperedges are the intersections of this set\nwith a family of geometric regions (e.g., axis-parallel rectangles). A typical\ncoloring problem for such geometric hypergraphs asks, given an integer $k$, for\nthe existence of an integer $m=m(k)$, such that every set of points can be\n$k$-colored such that every hyperedge of size at least $m$ contains points of\ndifferent (or all $k$) colors. We generalize this notion by introducing\ncoloring of \\emph{$t$-subsets} of points such that every hyperedge that\ncontains enough points contains $t$-subsets of different (or all) colors. In\nparticular, we consider all $t$-subsets and $t$-subsets that are themselves\nhyperedges. The latter, with $t=2$, is equivalent to coloring the edges of the\nso-called \\emph{Delaunay-graph}. In this paper we study colorings of\nDelaunay-edges with respect to halfplanes, pseudo-disks, axis-parallel and\nbottomless rectangles, and also discuss colorings of $t$-subsets of geometric\nand abstract hypergraphs, and connections between the standard coloring of\nvertices and coloring of $t$-subsets of vertices.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jun 2018 12:04:15 GMT"}, {"version": "v2", "created": "Tue, 18 Sep 2018 12:31:40 GMT"}, {"version": "v3", "created": "Tue, 26 Jan 2021 08:55:08 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Ackerman", "Eyal", ""], ["Keszegh", "Bal\u00e1zs", ""], ["P\u00e1lv\u00f6lgyi", "D\u00f6m\u00f6t\u00f6r", ""]]}, {"id": "1806.04217", "submitter": "Bal\\'azs Keszegh", "authors": "Bal\\'azs Keszegh and D\\\"om\\\"ot\\\"or P\\'alv\\\"olgyi", "title": "Aligned plane drawings of the generalized Delaunay-graphs for\n  pseudo-disks", "comments": null, "journal-ref": "Journal of Computational Geometry 11(1) (2020), 354-370", "doi": null, "report-no": null, "categories": "cs.CG math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study general Delaunay-graphs, which are natural generalizations of\nDelaunay triangulations to arbitrary families, in particular to pseudo-disks.\nWe prove that for any finite pseudo-disk family and point set, there is a plane\ndrawing of their Delaunay-graph such that every edge lies inside every\npseudo-disk that contains its endpoints.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jun 2018 19:57:51 GMT"}, {"version": "v2", "created": "Mon, 24 Aug 2020 12:35:32 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Keszegh", "Bal\u00e1zs", ""], ["P\u00e1lv\u00f6lgyi", "D\u00f6m\u00f6t\u00f6r", ""]]}, {"id": "1806.04720", "submitter": "Konstantinos Mastakas", "authors": "Konstantinos Mastakas", "title": "Drawing a Rooted Tree as a Rooted $y-$Monotone Minimum Spanning Tree", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a rooted point set $P$, the rooted $y-$Monotone Minimum Spanning Tree\n(rooted $y-$MMST) of $P$ is the spanning geometric graph of $P$ in which all\nthe vertices are connected to the root by some $y-$monotone path and the sum of\nthe Euclidean lengths of its edges is the minimum. We show that the maximum\ndegree of a rooted $y-$MMST is not bounded by a constant number. We give a\nlinear time algorithm that draws any rooted tree as a rooted $y-$MMST and also\nshow that there exist rooted trees that can be drawn as rooted $y-$MMSTs only\nin a grid of exponential area.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jun 2018 19:03:53 GMT"}], "update_date": "2018-06-14", "authors_parsed": [["Mastakas", "Konstantinos", ""]]}, {"id": "1806.04742", "submitter": "Kshitij Jain", "authors": "Sergio Cabello, Kshitij Jain, Anna Lubiw, Debajyoti Mondal", "title": "Minimum Shared-Power Edge Cut", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce a problem called the Minimum Shared-Power Edge Cut (MSPEC). The\ninput to the problem is an undirected edge-weighted graph with distinguished\nvertices s and t, and the goal is to find an s-t cut by assigning \"powers\" at\nthe vertices and removing an edge if the sum of the powers at its endpoints is\nat least its weight. The objective is to minimize the sum of the assigned\npowers.\n  MSPEC is a graph generalization of a barrier coverage problem in a wireless\nsensor network: given a set of unit disks with centers in a rectangle, what is\nthe minimum total amount by which we must shrink the disks to permit an\nintruder to cross the rectangle undetected, i.e. without entering any disc.\nThis is a more sophisticated measure of barrier coverage than the minimum\nnumber of disks whose removal breaks the barrier.\n  We develop a fully polynomial time approximation scheme (FPTAS) for MSPEC. We\ngive polynomial time algorithms for the special cases where the edge weights\nare uniform, or the power values are restricted to a bounded set. Although\nMSPEC is related to network flow and matching problems, its computational\ncomplexity (in P or NP-hard) remains open.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jun 2018 20:03:05 GMT"}], "update_date": "2018-06-14", "authors_parsed": [["Cabello", "Sergio", ""], ["Jain", "Kshitij", ""], ["Lubiw", "Anna", ""], ["Mondal", "Debajyoti", ""]]}, {"id": "1806.05145", "submitter": "Danny Hermes", "authors": "Danny Hermes", "title": "A Curious Case of Curbed Condition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In computer aided geometric design a polynomial is usually represented in\nBernstein form. The de Casteljau algorithm is the most well-known algorithm for\nevaluating a polynomial in this form. Evaluation via the de Casteljau algorithm\nhas relative forward error proportional to the condition number of evaluation.\nHowever, for a particular family of polynomials, a curious phenomenon occurs:\nthe observed error is much smaller than the expected error bound. We examine\nthis family and prove a much stronger error bound than the one that applies to\nthe general case. Then we provide a few examples to demonstrate the difference\nin rounding.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2018 16:56:35 GMT"}], "update_date": "2018-08-22", "authors_parsed": [["Hermes", "Danny", ""]]}, {"id": "1806.05528", "submitter": "Jeremy Youngquist", "authors": "Meera Sitharam, Jeremy Youngquist, Maxwell Nolan, J\\\"org Peters", "title": "Corner-Sharing Tetrahedra for Modeling Micro-Structure", "comments": null, "journal-ref": null, "doi": "10.1016/j.cad.2019.05.015", "report-no": null, "categories": "cs.CG cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art representations of volumetric multi-scale shape and\nstructure can be classified into three broad categories: continuous,\ncontinuous-from-discrete, and discrete representations. We propose modeling\nmicro-structure with a class of discrete Corner-Sharing Tetrahedra (CoSTs).\nCoSTs can represent bar-joint, tensegrity, line-incidence, and similar\nconstraint systems that capture local physical constraints and global\nmulti-scale properties for design and analysis. The paper develops a palette of\nsimple geometry processing operations on CoSTs including graph manipulation,\nhierarchical refinement, randomization, and generating associated continuous\nrepresentations.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jun 2018 03:02:33 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Sitharam", "Meera", ""], ["Youngquist", "Jeremy", ""], ["Nolan", "Maxwell", ""], ["Peters", "J\u00f6rg", ""]]}, {"id": "1806.05737", "submitter": "Shay Moran", "authors": "Zeev Dvir and Shay Moran", "title": "A Sauer-Shelah-Perles Lemma for Sumsets", "comments": "6 pages, fixed a few typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CG cs.DM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that any family of subsets $A\\subseteq 2^{[n]}$ satisfies $\\lvert\nA\\rvert \\leq O\\bigl(n^{\\lceil{d}/{2}\\rceil}\\bigr)$, where $d$ is the VC\ndimension of $\\{S\\triangle T \\,\\vert\\, S,T\\in A\\}$, and $\\triangle$ is the\nsymmetric difference operator. We also observe that replacing $\\triangle$ by\neither $\\cup$ or $\\cap$ fails to satisfy an analogous statement. Our proof is\nbased on the polynomial method; specifically, on an argument due to [Croot,\nLev, Pach '17].\n", "versions": [{"version": "v1", "created": "Thu, 14 Jun 2018 20:39:06 GMT"}, {"version": "v2", "created": "Tue, 19 Jun 2018 22:01:25 GMT"}], "update_date": "2018-06-21", "authors_parsed": [["Dvir", "Zeev", ""], ["Moran", "Shay", ""]]}, {"id": "1806.05797", "submitter": "Bin Fu", "authors": "Bin Fu, Pengfei Gu, and Yuming Zhao", "title": "Polyhedra Circuits and Their Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce polyhedra circuits. Each polyhedra circuit characterizes a\ngeometric region in $\\mathbb{R}^d$. They can be applied to represent a rich\nclass of geometric objects, which include all polyhedra and the union of a\nfinite number of polyhedra. They can be used to approximate a large class of\n$d$-dimensional manifolds in $\\mathbb{R}^d$. Barvinok developed polynomial time\nalgorithms to compute the volume of a rational polyhedra, and to count the\nnumber of lattice points in a rational polyhedra in a fixed dimensional space\n$\\mathbb{R}^d$ with a fix $d$. Define $T_V(d,\\, n)$ be the polynomial time in\n$n$ to compute the volume of one rational polyhedra, $T_L(d,\\, n)$ be the\npolynomial time in $n$ to count the number of lattice points in one rational\npolyhedra with $d$ be a fixed dimensional number, $T_I(d,\\, n)$ be the\npolynomial time in $n$ to solve integer linear programming time with $d$ be the\nfixed dimensional number, where $n$ is the total number of linear inequalities\nfrom input polyhedra. We develop algorithms to count the number of lattice\npoints in the geometric region determined by a polyhedra circuit in\n$O\\left(nd\\cdot r_d(n)\\cdot T_V(d,\\, n)\\right)$ time and to compute the volume\nof the geometric region determined by a polyhedra circuit in $O\\left(n\\cdot\nr_d(n)\\cdot T_I(d,\\, n)+r_d(n)T_L(d,\\, n)\\right)$ time, where $n$ is the number\nof input linear inequalities, $d$ is number of variables and $r_d(n)$ be the\nmaximal number of regions that $n$ linear inequalities with $d$ variables\npartition $\\mathbb{R}^d$.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jun 2018 03:28:34 GMT"}], "update_date": "2018-06-18", "authors_parsed": [["Fu", "Bin", ""], ["Gu", "Pengfei", ""], ["Zhao", "Yuming", ""]]}, {"id": "1806.05827", "submitter": "Jan Vr\\v{s}ek", "authors": "Michal Bizzarri and Miroslav L\\'avi\\v{c}ka and Jan Vr\\v{s}ek", "title": "Computing projective equivalences of special algebraic varieties", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG math.AG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is devoted to the investigation of selected situations when the\ncomputation of projective (and other) equivalences of algebraic varieties can\nbe efficiently solved with the help of finding projective equivalences of\nfinite sets on the projective line. In particular, we design a unifying\napproach that finds for two algebraic varieties $X,Y$ from special classes an\nassociated set of automorphisms of the projective line (the so called good\ncandidate set) consisting of candidates for the construction of possible\nmappings $X\\rightarrow Y$. The functionality of the designed method is\npresented on computing projective equivalences of rational curves, on\ndetermining projective equivalences of rational ruled surfaces, on the\ndetection of affine transformations between planar curves, and on computing\nsimilarities between two implicitly given algebraic surfaces. When possible,\nsymmetries of given shapes are also discussed as special cases.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jun 2018 07:05:38 GMT"}], "update_date": "2018-06-18", "authors_parsed": [["Bizzarri", "Michal", ""], ["L\u00e1vi\u010dka", "Miroslav", ""], ["Vr\u0161ek", "Jan", ""]]}, {"id": "1806.05868", "submitter": "Wolfgang Mulzer", "authors": "Bahareh Banyassady, Matias Korman, Wolfgang Mulzer", "title": "Geometric Algorithms with Limited Workspace: A Survey", "comments": "18 pages, 3 figures", "journal-ref": "ACM SIGACT News, 49(2), June 2018, pp. 77-94", "doi": "10.1145/3232679.3232692", "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the limited workspace model, we consider algorithms whose input resides in\nread-only memory and that use only a constant or sublinear amount of writable\nmemory to accomplish their task. We survey recent results in computational\ngeometry that fall into this model and that strive to achieve the lowest\npossible running time. In addition to discussing the state of the art, we give\nsome illustrative examples and mention open problems for further research.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jun 2018 09:27:35 GMT"}], "update_date": "2018-06-18", "authors_parsed": [["Banyassady", "Bahareh", ""], ["Korman", "Matias", ""], ["Mulzer", "Wolfgang", ""]]}, {"id": "1806.06772", "submitter": "Aubrey Jaffer", "authors": "Aubrey G. Jaffer and Martin S. Jaffer", "title": "Fractal Scaling of Population Counts Over Time Spans", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attributes which are infrequently expressed in a population can require weeks\nor months of counting to reach statistical significance. But replacement in a\nstable population increases long-term counts to a degree determined by the\nprobability distribution of lifetimes.\n  If the lifetimes are in a Pareto distribution with shape factor $1-r$ between\n0 and 1, then the expected counts for a stable population are proportional to\ntime raised to the $r$ power. Thus $r$ is the fractal dimension of counts\nversus time for this population.\n  Furthermore, the counts from a series of consecutive measurement intervals\ncan be combined using the $L^p$-norm where $p=1/r$ to approximate the\npopulation count over the combined time span.\n  Data from digital advertising support these assertions and find that fractal\nscaling is useful for early estimates of reach, and that the largest reachable\nfraction of an audience over a long time span is about $1-r$.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2018 15:29:50 GMT"}, {"version": "v2", "created": "Mon, 20 Aug 2018 15:51:10 GMT"}], "update_date": "2018-08-21", "authors_parsed": [["Jaffer", "Aubrey G.", ""], ["Jaffer", "Martin S.", ""]]}, {"id": "1806.06805", "submitter": "Miguel Brozos-V\\'azquez", "authors": "Miguel Brozos-V\\'azquez, Mar\\'ia Jos\\'e Pereira-S\\'aez, Mar\\'ia Jos\\'e\n  Souto-Salorio, Ana D. Tarr\\'io-Tobar", "title": "Classification of the relative positions between an ellipsoid and an\n  elliptic paraboloid", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG math.AG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We classify all the relative positions between an ellipsoid and an elliptic\nparaboloid when the ellipsoid is small in comparison with the paraboloid ({\\it\nsmall} meaning that the ellipsoid cannot be tangent to the paraboloid at two\npoints simultaneously). This provides an easy way to detect contact between the\ntwo surfaces by a direct analysis of the coefficients of a fourth degree\npolynomial.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jun 2018 10:13:52 GMT"}], "update_date": "2018-06-19", "authors_parsed": [["Brozos-V\u00e1zquez", "Miguel", ""], ["Pereira-S\u00e1ez", "Mar\u00eda Jos\u00e9", ""], ["Souto-Salorio", "Mar\u00eda Jos\u00e9", ""], ["Tarr\u00edo-Tobar", "Ana D.", ""]]}, {"id": "1806.06924", "submitter": "Mathieu Carri\\`ere", "authors": "Mathieu Carriere and Ulrich Bauer", "title": "On the Metric Distortion of Embedding Persistence Diagrams into\n  separable Hilbert spaces", "comments": "Small change in proof of Lemma 3.4", "journal-ref": "35th International Symposium on Computational Geometry (SoCG\n  2019), 21:1-15", "doi": "10.4230/LIPIcs.SoCG.2019.21", "report-no": null, "categories": "cs.LG cs.CG math.AT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Persistence diagrams are important descriptors in Topological Data Analysis.\nDue to the nonlinearity of the space of persistence diagrams equipped with\ntheir {\\em diagram distances}, most of the recent attempts at using persistence\ndiagrams in machine learning have been done through kernel methods, i.e.,\nembeddings of persistence diagrams into Reproducing Kernel Hilbert Spaces, in\nwhich all computations can be performed easily. Since persistence diagrams\nenjoy theoretical stability guarantees for the diagram distances, the {\\em\nmetric properties} of the feature map, i.e., the relationship between the\nHilbert distance and the diagram distances, are of central interest for\nunderstanding if the persistence diagram guarantees carry over to the\nembedding. In this article, we study the possibility of embedding persistence\ndiagrams into separable Hilbert spaces, with bi-Lipschitz maps. In particular,\nwe show that for several stable embeddings into infinite-dimensional Hilbert\nspaces defined in the literature, any lower bound must depend on the\ncardinalities of the persistence diagrams, and that when the Hilbert space is\nfinite dimensional, finding a bi-Lipschitz embedding is impossible, even when\nrestricting the persistence diagrams to have bounded cardinalities.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jun 2018 02:49:08 GMT"}, {"version": "v2", "created": "Tue, 4 Dec 2018 11:55:41 GMT"}, {"version": "v3", "created": "Wed, 7 Aug 2019 22:01:55 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Carriere", "Mathieu", ""], ["Bauer", "Ulrich", ""]]}, {"id": "1806.07072", "submitter": "Sauradip Nag", "authors": "Sauradip Nag, Palaiahnakote Shivakumara, Wu Yirui, Umapada Pal, and\n  Tong Lu", "title": "A New COLD Feature based Handwriting Analysis for Ethnicity/Nationality\n  Identification", "comments": "Accepted in ICFHR18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying crime for forensic investigating teams when crimes involve people\nof different nationals is challenging. This paper proposes a new method for\nethnicity (nationality) identification based on Cloud of Line Distribution\n(COLD) features of handwriting components. The proposed method, at first,\nexplores tangent angle for the contour pixels in each row and the mean of\nintensity values of each row in an image for segmenting text lines. For\nsegmented text lines, we use tangent angle and direction of base lines to\nremove rule lines in the image. We use polygonal approximation for finding\ndominant points for contours of edge components. Then the proposed method\nconnects the nearest dominant points of every dominant point, which results in\nline segments of dominant point pairs. For each line segment, the proposed\nmethod estimates angle and length, which gives a point in polar domain. For all\nthe line segments, the proposed method generates dense points in polar domain,\nwhich results in COLD distribution. As character component shapes change,\naccording to nationals, the shape of the distribution changes. This observation\nis extracted based on distance from pixels of distribution to Principal Axis of\nthe distribution. Then the features are subjected to an SVM classifier for\nidentifying nationals. Experiments are conducted on a complex dataset, which\nshow the proposed method is effective and outperforms the existing method\n", "versions": [{"version": "v1", "created": "Tue, 19 Jun 2018 07:14:54 GMT"}], "update_date": "2018-06-20", "authors_parsed": [["Nag", "Sauradip", ""], ["Shivakumara", "Palaiahnakote", ""], ["Yirui", "Wu", ""], ["Pal", "Umapada", ""], ["Lu", "Tong", ""]]}, {"id": "1806.08126", "submitter": "Julien Tierny", "authors": "Guillaume Favelier (PEQUAN), Charles Gueunet (PEQUAN), Attila Gyulassy\n  (SCI Institute), Julien Kitware, Joshua Levine, Jonas Lukasczyk (TU\n  Kaiserslautern), Daisuke Sakurai (ZIB), Maxime Soler (PEQUAN), Julien Tierny\n  (PEQUAN), Will Usher (SCI Institute), Qi Wu (SCI Institute, UC Davis)", "title": "Topological Data Analysis Made Easy with the Topology ToolKit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CG cs.CV cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This tutorial presents topological methods for the analysis and visualization\nof scientific data from a user's perspective, with the Topology ToolKit (TTK),\na recently released open-source library for topological data analysis.\nTopological methods have gained considerably in popularity and maturity over\nthe last twenty years and success stories of established methods have been\ndocumented in a wide range of applications (combustion, chemistry,\nastrophysics, material sciences, etc.) with both acquired and simulated data,\nin both post-hoc and in-situ contexts. While reference textbooks have been\npublished on the topic, no tutorial at IEEE VIS has covered this area in recent\nyears, and never at a software level and from a user's point-of-view. This\ntutorial fills this gap by providing a beginner's introduction to topological\nmethods for practitioners, researchers, students, and lecturers. In particular,\ninstead of focusing on theoretical aspects and algorithmic details, this\ntutorial focuses on how topological methods can be useful in practice for\nconcrete data analysis tasks such as segmentation, feature extraction or\ntracking. The tutorial describes in detail how to achieve these tasks with TTK.\nFirst, after an introduction to topological methods and their application in\ndata analysis, a brief overview of TTK's main entry point for end users, namely\nParaView, will be presented. Second, an overview of TTK's main features will be\ngiven. A running example will be described in detail, showcasing how to access\nTTK's features via ParaView, Python, VTK/C++, and C++. Third, hands-on sessions\nwill concretely show how to use TTK in ParaView for multiple, representative\ndata analysis tasks. Fourth, the usage of TTK will be presented for developers,\nin particular by describing several examples of visualization and data analysis\nprojects that were built on top of TTK. Finally, some feedback regarding the\nusage of TTK as a teaching platform for topological analysis will be given.\nPresenters of this tutorial include experts in topological methods, core\nauthors of TTK as well as active users, coming from academia, labs, or\nindustry. A large part of the tutorial will be dedicated to hands-on exercises\nand a rich material package (including TTK pre-installs in virtual machines,\ncode, data, demos, video tutorials, etc.) will be provided to the participants.\nThis tutorial mostly targets students, practitioners and researchers who are\nnot experts in topological methods but who are interested in using them in\ntheir daily tasks. We also target researchers already familiar to topological\nmethods and who are interested in using or contributing to TTK.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jun 2018 09:18:58 GMT"}], "update_date": "2018-06-22", "authors_parsed": [["Favelier", "Guillaume", "", "PEQUAN"], ["Gueunet", "Charles", "", "PEQUAN"], ["Gyulassy", "Attila", "", "SCI Institute"], ["Kitware", "Julien", "", "TU\n  Kaiserslautern"], ["Levine", "Joshua", "", "TU\n  Kaiserslautern"], ["Lukasczyk", "Jonas", "", "TU\n  Kaiserslautern"], ["Sakurai", "Daisuke", "", "ZIB"], ["Soler", "Maxime", "", "PEQUAN"], ["Tierny", "Julien", "", "PEQUAN"], ["Usher", "Will", "", "SCI Institute"], ["Wu", "Qi", "", "SCI Institute, UC Davis"]]}, {"id": "1806.08460", "submitter": "Lin Yan", "authors": "Lin Yan, Yaodong Zhao, Paul Rosen, Carlos Scheidegger, Bei Wang", "title": "Homology-Preserving Dimensionality Reduction via Manifold Landmarking\n  and Tearing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dimensionality reduction is an integral part of data visualization. It is a\nprocess that obtains a structure preserving low-dimensional representation of\nthe high-dimensional data. Two common criteria can be used to achieve a\ndimensionality reduction: distance preservation and topology preservation.\nInspired by recent work in topological data analysis, we are on the quest for a\ndimensionality reduction technique that achieves the criterion of homology\npreservation, a generalized version of topology preservation. Specifically, we\nare interested in using topology-inspired manifold landmarking and manifold\ntearing to aid such a process and evaluate their effectiveness.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jun 2018 00:44:23 GMT"}], "update_date": "2018-06-25", "authors_parsed": [["Yan", "Lin", ""], ["Zhao", "Yaodong", ""], ["Rosen", "Paul", ""], ["Scheidegger", "Carlos", ""], ["Wang", "Bei", ""]]}, {"id": "1806.08725", "submitter": "Karim Alexander Adiprasito", "authors": "Karim Adiprasito, Imre B\\'ar\\'any, Nabil H. Mustafa, and Tam\\'as\n  Terpai", "title": "Theorems of Carath\\'eodory, Helly, and Tverberg without dimension", "comments": "23 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.MG cs.CG math.CO math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove a no-dimensional version of Carath\\'edory's theorem: given an\n$n$-element set $P\\subset \\Re^d$, a point $a \\in \\conv P$, and an integer $r\\le\nd$, $r \\le n$, there is a subset $Q\\subset P$ of $r$ elements such that the\ndistance between $a$ and $\\conv Q$ is less than $\\diam P/\\sqrt {2r}$. A general\nno-dimension Helly type result is also proved with colourful and fractional\nconsequences. Similar versions of Tverberg's theorem and some of their\nextensions are also established.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jun 2018 15:22:14 GMT"}, {"version": "v2", "created": "Sun, 7 Oct 2018 11:49:46 GMT"}, {"version": "v3", "created": "Wed, 28 Aug 2019 11:38:39 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Adiprasito", "Karim", ""], ["B\u00e1r\u00e1ny", "Imre", ""], ["Mustafa", "Nabil H.", ""], ["Terpai", "Tam\u00e1s", ""]]}, {"id": "1806.08770", "submitter": "Konstantinos Mastakas", "authors": "Konstantinos Mastakas", "title": "Uniform 2D-Monotone Minimum Spanning Graphs", "comments": "Appears in the Proceedings of the CCCG 2018. Compared to v2: the\n  enumeration of Propositions, Lemmas and Theorems is changed to follow the\n  CCCG 2018 format, Figure 2(b) was changed, and some further small additions\n  and changes were made", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A geometric graph $G$ is $xy-$monotone if each pair of vertices of $G$ is\nconnected by a $xy-$monotone path. We study the problem of producing the\n$xy-$monotone spanning geometric graph of a point set $P$ that (i) has the\nminimum cost, where the cost of a geometric graph is the sum of the Euclidean\nlengths of its edges, and (ii) has the least number of edges, in the cases that\nthe Cartesian System $xy$ is specified or freely selected. Building upon\nprevious results, we easily obtain that the two solutions coincide when the\nCartesian System is specified and are both equal to the rectangle of influence\ngraph of $P$. The rectangle of influence graph of $P$ is the geometric graph\nwith vertex set $P$ such that two points $p,q \\in P$ are adjacent if and only\nif the rectangle with corners $p$ and $q$ does not include any other point of\n$P$. When the Cartesian System can be freely chosen, we note that the two\nsolutions do not necessarily coincide, however we show that they can both be\nobtained in $O(|P|^3)$ time. We also give a simple $2-$approximation algorithm\nfor the problem of computing the spanning geometric graph of a $k-$rooted point\nset $P$, in which each root is connected to all the other points (including the\nother roots) of $P$ by $y-$monotone paths, that has the minimum cost.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jun 2018 17:07:02 GMT"}, {"version": "v2", "created": "Mon, 25 Jun 2018 15:32:41 GMT"}, {"version": "v3", "created": "Wed, 26 Sep 2018 15:13:51 GMT"}], "update_date": "2018-09-27", "authors_parsed": [["Mastakas", "Konstantinos", ""]]}, {"id": "1806.09562", "submitter": "Hugo Akitaya", "authors": "Hugo A. Akitaya, Matthew D. Jones, David Stalfa, Csaba D. T\\'oth", "title": "Maximum Area Axis-Aligned Square Packings", "comments": "20 pages, 13 figures. A 15-page extended abstract appears in the\n  Proceedings of the 43rd International Symposium on Mathematical Foundations\n  of Computer Science (Liverpool, UK, 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a point set $S=\\{s_1,\\ldots , s_n\\}$ in the unit square $U=[0,1]^2$, an\nanchored square packing is a set of $n$ interior-disjoint empty squares in $U$\nsuch that $s_i$ is a corner of the $i$th square. The reach $R(S)$ of $S$ is the\nset of points that may be covered by such a packing, that is, the union of all\nempty squares anchored at points in $S$. It is shown that area$(R(S))\\geq\n\\frac12$ for every finite set $S\\subset U$, and this bound is the best\npossible. The region $R(S)$ can be computed in $O(n\\log n)$ time. Finally, we\nprove that finding a maximum area anchored square packing is NP-complete. This\nis the first hardness proof for a geometric packing problem where the size of\ngeometric objects in the packing is unrestricted.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jun 2018 16:51:34 GMT"}], "update_date": "2018-06-26", "authors_parsed": [["Akitaya", "Hugo A.", ""], ["Jones", "Matthew D.", ""], ["Stalfa", "David", ""], ["T\u00f3th", "Csaba D.", ""]]}, {"id": "1806.09823", "submitter": "Ilya Razenshteyn", "authors": "Alexandr Andoni, Piotr Indyk, Ilya Razenshteyn", "title": "Approximate Nearest Neighbor Search in High Dimensions", "comments": "27 pages, no figures; to appear in the proceedings of ICM 2018\n  (accompanying the talk by P. Indyk)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The nearest neighbor problem is defined as follows: Given a set $P$ of $n$\npoints in some metric space $(X,D)$, build a data structure that, given any\npoint $q$, returns a point in $P$ that is closest to $q$ (its \"nearest\nneighbor\" in $P$). The data structure stores additional information about the\nset $P$, which is then used to find the nearest neighbor without computing all\ndistances between $q$ and $P$. The problem has a wide range of applications in\nmachine learning, computer vision, databases and other fields.\n  To reduce the time needed to find nearest neighbors and the amount of memory\nused by the data structure, one can formulate the {\\em approximate} nearest\nneighbor problem, where the the goal is to return any point $p' \\in P$ such\nthat the distance from $q$ to $p'$ is at most $c \\cdot \\min_{p \\in P} D(q,p)$,\nfor some $c \\geq 1$. Over the last two decades, many efficient solutions to\nthis problem were developed. In this article we survey these developments, as\nwell as their connections to questions in geometric functional analysis and\ncombinatorial geometry.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jun 2018 07:35:45 GMT"}], "update_date": "2018-06-27", "authors_parsed": [["Andoni", "Alexandr", ""], ["Indyk", "Piotr", ""], ["Razenshteyn", "Ilya", ""]]}, {"id": "1806.10044", "submitter": "Johannes Zink", "authors": "Steven Chaplick, Fabian Lipp, Alexander Wolff, Johannes Zink", "title": "Compact Drawings of 1-Planar Graphs with Right-Angle Crossings and Few\n  Bends", "comments": null, "journal-ref": null, "doi": "10.1016/j.comgeo.2019.07.006", "report-no": null, "categories": "cs.CG cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the following classes of beyond-planar graphs: 1-planar, IC-planar,\nand NIC-planar graphs. These are the graphs that admit a 1-planar, IC-planar,\nand NIC-planar drawing, respectively. A drawing of a graph is 1-planar if every\nedge is crossed at most once. A 1-planar drawing is IC-planar if no two pairs\nof crossing edges share a vertex. A 1-planar drawing is NIC-planar if no two\npairs of crossing edges share two vertices. We study the relations of these\nbeyond-planar graph classes (beyond-planar graphs is a collective term for the\nprimary attempts to generalize the planar graphs) to right-angle crossing (RAC)\ngraphs that admit compact drawings on the grid with few bends. We present four\ndrawing algorithms that preserve the given embeddings. First, we show that\nevery $n$-vertex NIC-planar graph admits a NIC-planar RAC drawing with at most\none bend per edge on a grid of size $O(n) \\times O(n)$. Then, we show that\nevery $n$-vertex 1-planar graph admits a 1-planar RAC drawing with at most two\nbends per edge on a grid of size $O(n^3) \\times O(n^3)$. Finally, we make two\nknown algorithms embedding-preserving; for drawing 1-planar RAC graphs with at\nmost one bend per edge and for drawing IC-planar RAC graphs straight-line.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jun 2018 15:02:36 GMT"}, {"version": "v2", "created": "Fri, 6 Jul 2018 11:57:24 GMT"}, {"version": "v3", "created": "Tue, 28 Aug 2018 15:01:59 GMT"}, {"version": "v4", "created": "Mon, 3 Sep 2018 13:58:52 GMT"}, {"version": "v5", "created": "Thu, 8 Aug 2019 16:33:07 GMT"}], "update_date": "2019-08-12", "authors_parsed": [["Chaplick", "Steven", ""], ["Lipp", "Fabian", ""], ["Wolff", "Alexander", ""], ["Zink", "Johannes", ""]]}, {"id": "1806.10164", "submitter": "R\\'emi Imbach", "authors": "R\\'emi Imbach, Marc Pouget and Chee Yap", "title": "Clustering Complex Zeros of Triangular Systems of Polynomials", "comments": "Research report V6: description of the main algorithm updated", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper gives the first algorithm for finding a set of natural\n$\\epsilon$-clusters of complex zeros of a triangular system of polynomials\nwithin a given polybox in $\\mathbb{C}^n$, for any given $\\epsilon>0$. Our\nalgorithm is based on a recent near-optimal algorithm of Becker et al (2016)\nfor clustering the complex roots of a univariate polynomial where the\ncoefficients are represented by number oracles.\n  Our algorithm is numeric, certified and based on subdivision. We implemented\nit and compared it with two well-known homotopy solvers on various triangular\nsystems. Our solver always gives correct answers, is often faster than the\nhomotopy solver that often gives correct answers, and sometimes faster than the\none that gives sometimes correct results.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jun 2018 18:40:12 GMT"}, {"version": "v2", "created": "Thu, 4 Oct 2018 20:40:18 GMT"}, {"version": "v3", "created": "Mon, 25 Mar 2019 21:11:23 GMT"}, {"version": "v4", "created": "Wed, 27 Mar 2019 12:39:26 GMT"}, {"version": "v5", "created": "Mon, 8 Apr 2019 13:34:32 GMT"}, {"version": "v6", "created": "Thu, 26 Sep 2019 22:33:28 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Imbach", "R\u00e9mi", ""], ["Pouget", "Marc", ""], ["Yap", "Chee", ""]]}, {"id": "1806.10309", "submitter": "Minhaeng Lee", "authors": "Minhaeng Lee and Charless C. Fowlkes", "title": "CeMNet: Self-supervised learning for accurate continuous ego-motion\n  estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel self-supervised learning model for\nestimating continuous ego-motion from video. Our model learns to estimate\ncamera motion by watching RGBD or RGB video streams and determining\ntranslational and rotation velocities that correctly predict the appearance of\nfuture frames. Our approach differs from other recent work on self-supervised\nstructure-from-motion in its use of a continuous motion formulation and\nrepresentation of rigid motion fields rather than direct prediction of camera\nparameters. To make estimation robust in dynamic environments with multiple\nmoving objects, we introduce a simple two-component segmentation process that\nisolates the rigid background environment from dynamic scene elements. We\ndemonstrate state-of-the-art accuracy of the self-trained model on several\nbenchmark ego-motion datasets and highlight the ability of the model to provide\nsuperior rotational accuracy and handling of non-rigid scene motions.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2018 06:00:07 GMT"}], "update_date": "2018-06-28", "authors_parsed": [["Lee", "Minhaeng", ""], ["Fowlkes", "Charless C.", ""]]}, {"id": "1806.10714", "submitter": "Chao Chen", "authors": "Chao Chen, Xiuyan Ni, Qinxun Bai, Yusu Wang", "title": "A Topological Regularizer for Classifiers via Persistent Homology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regularization plays a crucial role in supervised learning. Most existing\nmethods enforce a global regularization in a structure agnostic manner. In this\npaper, we initiate a new direction and propose to enforce the structural\nsimplicity of the classification boundary by regularizing over its topological\ncomplexity. In particular, our measurement of topological complexity\nincorporates the importance of topological features (e.g., connected\ncomponents, handles, and so on) in a meaningful manner, and provides a direct\ncontrol over spurious topological structures. We incorporate the new\nmeasurement as a topological penalty in training classifiers. We also pro- pose\nan efficient algorithm to compute the gradient of such penalty. Our method pro-\nvides a novel way to topologically simplify the global structure of the model,\nwithout having to sacrifice too much of the flexibility of the model. We\ndemonstrate the effectiveness of our new topological regularizer on a range of\nsynthetic and real-world datasets.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2018 23:42:37 GMT"}, {"version": "v2", "created": "Tue, 9 Oct 2018 19:25:33 GMT"}, {"version": "v3", "created": "Tue, 16 Oct 2018 13:49:56 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Chen", "Chao", ""], ["Ni", "Xiuyan", ""], ["Bai", "Qinxun", ""], ["Wang", "Yusu", ""]]}]