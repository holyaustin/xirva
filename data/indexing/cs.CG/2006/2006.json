[{"id": "2006.00187", "submitter": "Lipu Zhou", "authors": "Lipu Zhou, Daniel Koppel, Hui Ju, Frank Steinbruecker, Michael Kaess", "title": "An Efficient Planar Bundle Adjustment Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an efficient algorithm for the least-squares problem\nusing the point-to-plane cost, which aims to jointly optimize depth sensor\nposes and plane parameters for 3D reconstruction. We call this least-squares\nproblem \\textbf{Planar Bundle Adjustment} (PBA), due to the similarity between\nthis problem and the original Bundle Adjustment (BA) in visual reconstruction.\nAs planes ubiquitously exist in the man-made environment, they are generally\nused as landmarks in SLAM algorithms for various depth sensors. PBA is\nimportant to reduce drift and improve the quality of the map. However, directly\nadopting the well-established BA framework in visual reconstruction will result\nin a very inefficient solution for PBA. This is because a 3D point only has one\nobservation at a camera pose. In contrast, a depth sensor can record hundreds\nof points in a plane at a time, which results in a very large nonlinear\nleast-squares problem even for a small-scale space. Fortunately, we find that\nthere exist a special structure of the PBA problem. We introduce a reduced\nJacobian matrix and a reduced residual vector, and prove that they can replace\nthe original Jacobian matrix and residual vector in the generally adopted\nLevenberg-Marquardt (LM) algorithm. This significantly reduces the\ncomputational cost. Besides, when planes are combined with other features for\n3D reconstruction, the reduced Jacobian matrix and residual vector can also\nreplace the corresponding parts derived from planes. Our experimental results\nverify that our algorithm can significantly reduce the computational time\ncompared to the solution using the traditional BA framework. Besides, our\nalgorithm is faster, more accuracy, and more robust to initialization errors\ncompared to the start-of-the-art solution using the plane-to-plane cost\n", "versions": [{"version": "v1", "created": "Sat, 30 May 2020 05:54:22 GMT"}, {"version": "v2", "created": "Sun, 16 Aug 2020 07:52:42 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Zhou", "Lipu", ""], ["Koppel", "Daniel", ""], ["Ju", "Hui", ""], ["Steinbruecker", "Frank", ""], ["Kaess", "Michael", ""]]}, {"id": "2006.00285", "submitter": "Michael Gastner", "authors": "Shi Tingsheng, Ian K. Duncan, Yen-Ning Chang, Michael T. Gastner", "title": "Motivating Good Practices for the Creation of Contiguous Area Cartograms", "comments": "10 pages, 6 figures, to appear in the Proceedings of the 8th\n  International Conference on Cartography and GIS", "journal-ref": "Proc. 8th Int. Conf. Cartogr. GIS (eds: T. Bandrova, M.\n  Kone\\v{c}n\\'y, S. Marinova), vol. 1, pp. 589--598 (Bulgarian Cartographic\n  Association, Sofia, 2020). ISSN: 1314-0604. URL:\n  https://tinyurl.com/icc8-2020-pdf", "doi": null, "report-no": null, "categories": "cs.HC cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cartograms are maps in which the areas of regions (e.g., countries or\nprovinces) are proportional to a thematic mapping variable (e.g., population or\ngross domestic product). A cartogram is called contiguous if it keeps\ngeographically adjacent regions connected. Over the past few years, several web\ntools have been developed for the creation of contiguous cartograms. However,\nmost of these tools do not advise how to use cartograms correctly. To mitigate\nthese shortcomings, we attempt to establish good practices through our recently\ndeveloped web application go-cart.io: (1) use cartograms to show numeric data\nthat add up to an interpretable total, (2) present a cartogram alongside a\nconventional map that uses the same color scheme, (3) indicate whether the data\nfor a region are missing, (4) include a legend so that readers can infer the\nmagnitude of the mapping variable, (5) if a cartogram is presented\nelectronically, assist readers with interactive graphics.\n", "versions": [{"version": "v1", "created": "Sat, 30 May 2020 14:41:56 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Tingsheng", "Shi", ""], ["Duncan", "Ian K.", ""], ["Chang", "Yen-Ning", ""], ["Gastner", "Michael T.", ""]]}, {"id": "2006.01202", "submitter": "Jayson Lynch", "authors": "Zachary Abel, Hugo A. Akitaya, Erik D. Demaine, Martin L. Demaine,\n  Adam Hesterberg, Matias Korman, Jason S. Ku, Jayson Lynch", "title": "Negative Instance for the Edge Patrolling Beacon Problem", "comments": "Full version of a JCDCGGG2018 paper, 8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can an infinite-strength magnetic beacon always ``catch'' an iron ball, when\nthe beacon is a point required to be remain nonstrictly outside a polygon, and\nthe ball is a point always moving instantaneously and maximally toward the\nbeacon subject to staying nonstrictly within the same polygon? Kouhestani and\nRappaport [JCDCG 2017] gave an algorithm for determining whether a\nball-capturing beacon strategy exists, while conjecturing that such a strategy\nalways exists. We disprove this conjecture by constructing orthogonal and\ngeneral-position polygons in which the ball and the beacon can never be united.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 19:01:33 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Abel", "Zachary", ""], ["Akitaya", "Hugo A.", ""], ["Demaine", "Erik D.", ""], ["Demaine", "Martin L.", ""], ["Hesterberg", "Adam", ""], ["Korman", "Matias", ""], ["Ku", "Jason S.", ""], ["Lynch", "Jayson", ""]]}, {"id": "2006.01428", "submitter": "Sanjeev Saxena", "authors": "Sanjeev Saxena", "title": "Zone Theorem for Arrangements in three dimensions", "comments": null, "journal-ref": "Information Processing Letters Volume 172, December 2021, 106161", "doi": "10.1016/j.ipl.2021.106161", "report-no": null, "categories": "cs.CG cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note, a simple description of zone theorem in three dimensions is\ngiven.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 07:15:40 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Saxena", "Sanjeev", ""]]}, {"id": "2006.01570", "submitter": "Ruben Wiersma", "authors": "Ruben Wiersma, Elmar Eisemann, Klaus Hildebrandt", "title": "CNNs on Surfaces using Rotation-Equivariant Features", "comments": "12 pages, 14 figures, 5 tables, to be published in ACM ToG (SIGGRAPH\n  2020)", "journal-ref": null, "doi": "10.1145/3386569.3392437", "report-no": null, "categories": "cs.CV cs.CG cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with a fundamental problem in geometric deep learning\nthat arises in the construction of convolutional neural networks on surfaces.\nDue to curvature, the transport of filter kernels on surfaces results in a\nrotational ambiguity, which prevents a uniform alignment of these kernels on\nthe surface. We propose a network architecture for surfaces that consists of\nvector-valued, rotation-equivariant features. The equivariance property makes\nit possible to locally align features, which were computed in arbitrary\ncoordinate systems, when aggregating features in a convolution layer. The\nresulting network is agnostic to the choices of coordinate systems for the\ntangent spaces on the surface. We implement our approach for triangle meshes.\nBased on circular harmonic functions, we introduce convolution filters for\nmeshes that are rotation-equivariant at the discrete level. We evaluate the\nresulting networks on shape correspondence and shape classifications tasks and\ncompare their performance to other approaches.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 12:46:00 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Wiersma", "Ruben", ""], ["Eisemann", "Elmar", ""], ["Hildebrandt", "Klaus", ""]]}, {"id": "2006.02027", "submitter": "Peter Englert", "authors": "Peter Englert, Isabel M. Rayas Fern\\'andez, Ragesh K. Ramachandran,\n  Gaurav S. Sukhatme", "title": "Sampling-Based Motion Planning on Sequenced Manifolds", "comments": null, "journal-ref": null, "doi": "10.15607/RSS.2021.XVII.039", "report-no": null, "categories": "cs.RO cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of planning robot motions in constrained configuration\nspaces where the constraints change throughout the motion. The problem is\nformulated as a fixed sequence of intersecting manifolds, which the robot needs\nto traverse in order to solve the task. We specify a class of sequential motion\nplanning problems that fulfill a particular property of the change in the free\nconfiguration space when transitioning between manifolds. For this problem\nclass, we develop the algorithm Planning on Sequenced Manifolds (PSM*) which\nsearches for optimal intersection points between manifolds by using RRT* in an\ninner loop with a novel steering strategy. We provide a theoretical analysis\nregarding PSM*s probabilistic completeness and asymptotic optimality. Further,\nwe evaluate its planning performance on multi-robot object transportation\ntasks.\n  Video: https://youtu.be/Q8kbILTRxfU\n  Code: https://github.com/etpr/sequential-manifold-planning\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2020 03:39:09 GMT"}, {"version": "v2", "created": "Tue, 25 Aug 2020 07:54:29 GMT"}, {"version": "v3", "created": "Mon, 5 Oct 2020 18:20:35 GMT"}, {"version": "v4", "created": "Fri, 19 Mar 2021 01:55:53 GMT"}, {"version": "v5", "created": "Tue, 29 Jun 2021 00:18:59 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Englert", "Peter", ""], ["Fern\u00e1ndez", "Isabel M. Rayas", ""], ["Ramachandran", "Ragesh K.", ""], ["Sukhatme", "Gaurav S.", ""]]}, {"id": "2006.02399", "submitter": "Nave Frost", "authors": "Nave Frost, Michal Moshkovitz, Cyrus Rashtchian", "title": "ExKMC: Expanding Explainable $k$-Means Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the popularity of explainable AI, there is limited work on effective\nmethods for unsupervised learning. We study algorithms for $k$-means\nclustering, focusing on a trade-off between explainability and accuracy.\nFollowing prior work, we use a small decision tree to partition a dataset into\n$k$ clusters. This enables us to explain each cluster assignment by a short\nsequence of single-feature thresholds. While larger trees produce more accurate\nclusterings, they also require more complex explanations. To allow flexibility,\nwe develop a new explainable $k$-means clustering algorithm, ExKMC, that takes\nan additional parameter $k' \\geq k$ and outputs a decision tree with $k'$\nleaves. We use a new surrogate cost to efficiently expand the tree and to label\nthe leaves with one of $k$ clusters. We prove that as $k'$ increases, the\nsurrogate cost is non-increasing, and hence, we trade explainability for\naccuracy. Empirically, we validate that ExKMC produces a low cost clustering,\noutperforming both standard decision tree methods and other algorithms for\nexplainable clustering. Implementation of ExKMC available at\nhttps://github.com/navefr/ExKMC.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2020 17:14:55 GMT"}, {"version": "v2", "created": "Thu, 2 Jul 2020 01:24:51 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Frost", "Nave", ""], ["Moshkovitz", "Michal", ""], ["Rashtchian", "Cyrus", ""]]}, {"id": "2006.03499", "submitter": "Yujie Hu", "authors": "Yujie Hu, Harvey J Miller, Xiang Li", "title": "Detecting and Analyzing Mobility Hotspots using Surface Networks", "comments": null, "journal-ref": "Transactions in GIS, 18(6), 911-935 (2014)", "doi": "10.1111/tgis.12076", "report-no": null, "categories": "stat.AP cs.CG cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Capabilities for collecting and storing data on mobile objects have increased\ndramatically over the past few decades. A persistent difficulty is summarizing\nlarge collections of mobile objects. This paper develops methods for extracting\nand analyzing hotspots or locations with relatively high levels of mobility\nactivity. We use kernel density estimation (KDE) to convert a large collection\nof mobile objects into a smooth, continuous surface. We then develop a\ntopological algorithm to extract critical geometric features of the surface;\nthese include critical points (peaks, pits and passes) and critical lines\n(ridgelines and course-lines). We connect the peaks and corresponding\nridgelines to produce a surface network that summarizes the topological\nstructure of the surface. We apply graph theoretic indices to analytically\ncharacterize the surface and its changes over time. To illustrate our approach,\nwe apply the techniques to taxi cab data collected in Shanghai, China. We find\nincreases in the complexity of the hotspot spatial distribution during normal\nactivity hours in the late morning, afternoon and evening and a spike in the\nconnectivity of the hotspot spatial distribution in the morning as taxis\nconcentrate on servicing travel to work. These results match with scientific\nand anecdotal knowledge about human activity patterns in the study area.\n", "versions": [{"version": "v1", "created": "Sat, 30 May 2020 14:11:26 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Hu", "Yujie", ""], ["Miller", "Harvey J", ""], ["Li", "Xiang", ""]]}, {"id": "2006.03819", "submitter": "Ajeet Srivastav", "authors": "Ajeet K. Srivastav", "title": "A generalized expression for filling congruent circles in a circle", "comments": "11 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper reports a generalized expression for filling the congruent circles\n(of radius r) in a circle (of radius R). First, a generalized expression for\nthe biggest circle (r) inscribed in the nth part of the bigger circle (R) was\ndeveloped. Further, it was extended as n such circles (r) touching each other\nand the bigger circle (R). To fill the bigger circle (R), the exercise was\nfurther repeated by considering the bigger circle radius as R-2r, R-4r and so\non. In the process, a generalized expression was deduced for the total no. of\nsuch circles (r) which could be inscribed in this way of filling the bigger\ncircle (R). The approach does not claim the closest packing always though it\ncould be helpful for practical purposes.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jun 2020 09:20:00 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Srivastav", "Ajeet K.", ""]]}, {"id": "2006.03840", "submitter": "Claudio Ferrari", "authors": "Claudio Ferrari, Stefano Berretti, Pietro Pala, Alberto Del Bimbo", "title": "A Sparse and Locally Coherent Morphable Face Model for Dense Semantic\n  Correspondence Across Heterogeneous 3D Faces", "comments": "Accepted for publication in IEEE Transactions on Pattern Analysis and\n  Machine Intelligence (TPAMI)", "journal-ref": null, "doi": "10.1109/TPAMI.2021.3090942", "report-no": null, "categories": "cs.CV cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The 3D Morphable Model (3DMM) is a powerful statistical tool for representing\n3D face shapes. To build a 3DMM, a training set of face scans in full\npoint-to-point correspondence is required, and its modeling capabilities\ndirectly depend on the variability contained in the training data. Thus, to\nincrease the descriptive power of the 3DMM, establishing a dense correspondence\nacross heterogeneous scans with sufficient diversity in terms of identities,\nethnicities, or expressions becomes essential. In this manuscript, we present a\nfully automatic approach that leverages a 3DMM to transfer its dense semantic\nannotation across raw 3D faces, establishing a dense correspondence between\nthem. We propose a novel formulation to learn a set of sparse deformation\ncomponents with local support on the face that, together with an original\nnon-rigid deformation algorithm, allow the 3DMM to precisely fit unseen faces\nand transfer its semantic annotation. We extensively experimented our approach,\nshowing it can effectively generalize to highly diverse samples and accurately\nestablish a dense correspondence even in presence of complex facial\nexpressions. The accuracy of the dense registration is demonstrated by building\na heterogeneous, large-scale 3DMM from more than 9,000 fully registered scans\nobtained by joining three large datasets together.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jun 2020 10:52:07 GMT"}, {"version": "v2", "created": "Wed, 25 Nov 2020 15:24:54 GMT"}, {"version": "v3", "created": "Thu, 24 Jun 2021 13:52:18 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Ferrari", "Claudio", ""], ["Berretti", "Stefano", ""], ["Pala", "Pietro", ""], ["Del Bimbo", "Alberto", ""]]}, {"id": "2006.04046", "submitter": "Gil Kur", "authors": "Gil Kur, Alexander Rakhlin and Adityanand Guntuboyina", "title": "On Suboptimality of Least Squares with Application to Estimation of\n  Convex Bodies", "comments": "To appaer in Conference on Learning Theory (COLT) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.CG cs.LG math.MG stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a technique for establishing lower bounds on the sample complexity\nof Least Squares (or, Empirical Risk Minimization) for large classes of\nfunctions. As an application, we settle an open problem regarding optimality of\nLeast Squares in estimating a convex set from noisy support function\nmeasurements in dimension $d\\geq 6$. Specifically, we establish that Least\nSquares is mimimax sub-optimal, and achieves a rate of\n$\\tilde{\\Theta}_d(n^{-2/(d-1)})$ whereas the minimax rate is\n$\\Theta_d(n^{-4/(d+3)})$.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jun 2020 05:19:00 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Kur", "Gil", ""], ["Rakhlin", "Alexander", ""], ["Guntuboyina", "Adityanand", ""]]}, {"id": "2006.04402", "submitter": "Golan Miglioli-Levy", "authors": "Dan Halperin (1), Marc van Kreveld (2), Golan Miglioli-Levy (1), Micha\n  Sharir (1) ((1) The Blavatnik School of Computer Science, Tel Aviv\n  University, Israel, (2) Dept. of Information and Computing Sciences, Utrecht\n  University, the Netherlands)", "title": "Space-Aware Reconfiguration", "comments": "To appear in Proc. of the 14th International Workshop on the\n  Algorithmic Foundations of Robotics (2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of reconfiguring a set of physical objects into a\ndesired target configuration, a typical (sub)task in robotics and automation,\narising in product assembly, packaging, stocking store shelves, and more. In\nthis paper we address a variant, which we call space-aware reconfiguration,\nwhere the goal is to minimize the physical space needed for the\nreconfiguration, while obeying constraints on the allowable collision-free\nmotions of the objects. Since for given start and target configurations,\nreconfiguration may be impossible, we translate the entire target configuration\nrigidly into a location that admits a valid sequence of moves, where each\nobject moves in turn just once, along a straight line, from its starting to its\ntarget location, so that the overall physical space required by the start, all\nintermediate, and target configurations for all the objects is minimized.\n  We investigate two variants of space-aware reconfiguration for the often\nexamined setting of $n$ unit discs in the plane, depending on whether the discs\nare distinguishable (labeled) or indistinguishable (unlabeled). For the labeled\ncase, we propose a representation of size $O(n^4)$ of the space of all feasible\ninitial rigid translations, and use it to find, in $O(n^6)$ time, a shortest\nvalid translation, or one that minimizes the enclosing disc or axis-aligned\nrectangle of both the start and target configurations. For the significantly\nharder unlabeled case, we show that for almost every direction, there exists a\ntranslation in this direction that makes the problem feasible. We use this to\ndevise heuristic solutions, where we optimize the translation under stricter\nnotions of feasibility. We present an implementation of such a heuristic, which\nsolves unlabeled instances with hundreds of discs in seconds.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 08:05:36 GMT"}, {"version": "v2", "created": "Sun, 30 Aug 2020 11:41:05 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Halperin", "Dan", ""], ["van Kreveld", "Marc", ""], ["Miglioli-Levy", "Golan", ""], ["Sharir", "Micha", ""]]}, {"id": "2006.04423", "submitter": "Josue Tonelli-Cueto", "authors": "Josu\\'e Tonelli-Cueto, Elias Tsigaridas", "title": "Condition Numbers for the Cube. I: Univariate Polynomials and\n  Hypersurfaces", "comments": "34 pages. Version 1, conference version; from version 2, journal\n  version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The condition-based complexity analysis framework is one of the gems of\nmodern numerical algebraic geometry and theoretical computer science. One of\nthe challenges that it poses is to expand the currently limited range of random\npolynomials that we can handle. Despite important recent progress, the\navailable tools cannot handle random sparse polynomials and Gaussian\npolynomials, that is polynomials whose coefficients are i.i.d. Gaussian random\nvariables.\n  We initiate a condition-based complexity framework based on the norm of the\ncube that is a step in this direction. We present this framework for real\nhypersurfaces and univariate polynomials. We demonstrate its capabilities in\ntwo problems, under very mild probabilistic assumptions. On the one hand, we\nshow that the average run-time of the Plantinga-Vegter algorithm is polynomial\nin the degree for random sparse (alas a restricted sparseness structure)\npolynomials and random Gaussian polynomials. On the other hand, we study the\nsize of the subdivision tree for Descartes' solver and run-time of the solver\nby Jindal and Sagraloff (arXiv:1704.06979). In both cases, we provide a bound\nthat is polynomial in the size of the input (size of the support plus logarithm\nof the degree) for not only on the average, but all higher moments.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 09:09:40 GMT"}, {"version": "v2", "created": "Sat, 19 Dec 2020 00:49:38 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Tonelli-Cueto", "Josu\u00e9", ""], ["Tsigaridas", "Elias", ""]]}, {"id": "2006.05353", "submitter": "Alon Lahav", "authors": "Alon Lahav, Ayellet Tal", "title": "MeshWalker: Deep Mesh Understanding by Random Walks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CG cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most attempts to represent 3D shapes for deep learning have focused on\nvolumetric grids, multi-view images and point clouds. In this paper we look at\nthe most popular representation of 3D shapes in computer graphics - a\ntriangular mesh - and ask how it can be utilized within deep learning. The few\nattempts to answer this question propose to adapt convolutions & pooling to\nsuit Convolutional Neural Networks (CNNs). This paper proposes a very different\napproach, termed MeshWalker, to learn the shape directly from a given mesh. The\nkey idea is to represent the mesh by random walks along the surface, which\n\"explore\" the mesh's geometry and topology. Each walk is organized as a list of\nvertices, which in some manner imposes regularity on the mesh. The walk is fed\ninto a Recurrent Neural Network (RNN) that \"remembers\" the history of the walk.\nWe show that our approach achieves state-of-the-art results for two fundamental\nshape analysis tasks: shape classification and semantic segmentation.\nFurthermore, even a very small number of examples suffices for learning. This\nis highly important, since large datasets of meshes are difficult to acquire.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 15:35:41 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 05:39:22 GMT"}, {"version": "v3", "created": "Thu, 10 Dec 2020 15:39:51 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Lahav", "Alon", ""], ["Tal", "Ayellet", ""]]}, {"id": "2006.05660", "submitter": "Thomas Espitau", "authors": "Thomas Espitau, Paul Kirchner", "title": "The nearest-colattice algorithm", "comments": "19 pages, presented at the Algorithmic Number Theory Symposium (ANTS\n  2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we exhibit a hierarchy of polynomial time algorithms solving\napproximate variants of the Closest Vector Problem (CVP). Our first\ncontribution is a heuristic algorithm achieving the same distance tradeoff as\nHSVP algorithms, namely $\\approx\n  \\beta^{\\frac{n}{2\\beta}}\\textrm{covol}(\\Lambda)^{\\frac{1}{n}}$ for a random\nlattice $\\Lambda$ of rank $n$. Compared to the so-called Kannan's embedding\ntechnique, our algorithm allows using precomputations and can be used for\nefficient batch CVP instances. This implies that some attacks on lattice-based\nsignatures lead to very cheap forgeries, after a precomputation. Our second\ncontribution is a proven reduction from approximating the closest vector with a\nfactor $\\approx n^{\\frac32}\\beta^{\\frac{3n}{2\\beta}}$ to the Shortest Vector\nProblem (SVP) in dimension $\\beta$.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 05:26:09 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 01:44:59 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Espitau", "Thomas", ""], ["Kirchner", "Paul", ""]]}, {"id": "2006.06200", "submitter": "Yi Fang", "authors": "Lingjing Wang, Xiang Li, Yi Fang", "title": "Unsupervised Learning of 3D Point Set Registration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CV eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Point cloud registration is the process of aligning a pair of point sets via\nsearching for a geometric transformation. Recent works leverage the power of\ndeep learning for registering a pair of point sets. However, unfortunately,\ndeep learning models often require a large number of ground truth labels for\ntraining. Moreover, for a pair of source and target point sets, existing deep\nlearning mechanisms require explicitly designed encoders to extract both deep\nspatial features from unstructured point clouds and their spatial correlation\nrepresentation, which is further fed to a decoder to regress the desired\ngeometric transformation for point set alignment. To further enhance deep\nlearning models for point set registration, this paper proposes Deep-3DAligner,\na novel unsupervised registration framework based on a newly introduced deep\nSpatial Correlation Representation (SCR) feature. The SCR feature describes the\ngeometric essence of the spatial correlation between source and target point\nsets in an encoding-free manner. More specifically, our method starts with\noptimizing a randomly initialized latent SCR feature, which is then decoded to\na geometric transformation (i.e., rotation and translation) to align source and\ntarget point sets. Our Deep-3DAligner jointly updates the SCR feature and\nweights of the transformation decoder towards the minimization of an\nunsupervised alignment loss. We conducted experiments on the ModelNet40\ndatasets to validate the performance of our unsupervised Deep-3DAligner for\npoint set registration. The results demonstrated that, even without ground\ntruth and any assumption of a direct correspondence between source and target\npoint sets for training, our proposed approach achieved comparative performance\ncompared to most recent supervised state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 05:21:38 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Wang", "Lingjing", ""], ["Li", "Xiang", ""], ["Fang", "Yi", ""]]}, {"id": "2006.06951", "submitter": "Fabrizio Frati", "authors": "Fabrizio Frati", "title": "Planar Rectilinear Drawings of Outerplanar Graphs in Linear Time", "comments": "Appears in the Proceedings of the 28th International Symposium on\n  Graph Drawing and Network Visualization (GD 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how to test in linear time whether an outerplanar graph admits a\nplanar rectilinear drawing, both if the graph has a prescribed plane embedding\nthat the drawing has to respect and if it does not. Our algorithm returns a\nplanar rectilinear drawing if the graph admits one.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 05:33:09 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 20:57:06 GMT"}, {"version": "v3", "created": "Thu, 20 Aug 2020 13:40:26 GMT"}, {"version": "v4", "created": "Fri, 21 Aug 2020 13:18:49 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Frati", "Fabrizio", ""]]}, {"id": "2006.07020", "submitter": "Frank Nielsen", "authors": "Frank Nielsen", "title": "On Voronoi diagrams and dual Delaunay complexes on the\n  information-geometric Cauchy manifolds", "comments": "34 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the Voronoi diagrams of a finite set of Cauchy distributions and\ntheir dual complexes from the viewpoint of information geometry by considering\nthe Fisher-Rao distance, the Kullback-Leibler divergence, the chi square\ndivergence, and a flat divergence derived from Tsallis' quadratic entropy\nrelated to the conformal flattening of the Fisher-Rao curved geometry. We prove\nthat the Voronoi diagrams of the Fisher-Rao distance, the chi square\ndivergence, and the Kullback-Leibler divergences all coincide with a hyperbolic\nVoronoi diagram on the corresponding Cauchy location-scale parameters, and that\nthe dual Cauchy hyperbolic Delaunay complexes are Fisher orthogonal to the\nCauchy hyperbolic Voronoi diagrams. The dual Voronoi diagrams with respect to\nthe dual forward/reverse flat divergences amount to dual Bregman Voronoi\ndiagrams, and their dual complexes are regular triangulations. The primal\nBregman-Tsallis Voronoi diagram corresponds to the hyperbolic Voronoi diagram\nand the dual Bregman-Tsallis Voronoi diagram coincides with the ordinary\nEuclidean Voronoi diagram. Besides, we prove that the square root of the\nKullback-Leibler divergence between Cauchy distributions yields a metric\ndistance which is Hilbertian for the Cauchy scale families.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 09:05:15 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2020 10:34:42 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Nielsen", "Frank", ""]]}, {"id": "2006.07392", "submitter": "Ka Wai Wong", "authors": "Ka Wai Wong", "title": "Application of Mean Curvature Flow for Surface Parametrizations", "comments": "5 pages, 13 figures", "journal-ref": "In \"Mean Curvature Flow\", Proceedings of the John H. Barrett\n  Memorial Lectures Held at the University of Tennessee, Knoxville, May 29 -\n  June 1, 2018", "doi": null, "report-no": null, "categories": "cs.CG math.DG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is an expository article describing the conformalized mean curvature\nflow, originally introduced by Kazhdan, Solomon, and Ben-Chen. We are\ninterested in applying mean curvature flow to surface parametrizations. We\ndiscuss our own implementation of their algorithm and some limitations.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 18:08:54 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Wong", "Ka Wai", ""]]}, {"id": "2006.07746", "submitter": "Giovanni Sutanto", "authors": "Isabel M. Rayas Fern\\'andez, Giovanni Sutanto, Peter Englert, Ragesh\n  K. Ramachandran, Gaurav S. Sukhatme", "title": "Learning Manifolds for Sequential Motion Planning", "comments": "Accepted for presentation at the Robotics: Science and Systems (RSS)\n  2020 Workshop for Learning (in) Task and Motion Planning. Paper length is 4\n  pages (i.e. 3 pages of technical content and 1 page of the references)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motion planning with constraints is an important part of many real-world\nrobotic systems. In this work, we study manifold learning methods to learn such\nconstraints from data. We explore two methods for learning implicit constraint\nmanifolds from data: Variational Autoencoders (VAE), and a new method, Equality\nConstraint Manifold Neural Network (ECoMaNN). With the aim of incorporating\nlearned constraints into a sampling-based motion planning framework, we\nevaluate the approaches on their ability to learn representations of\nconstraints from various datasets and on the quality of paths produced during\nplanning.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jun 2020 23:56:47 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 03:01:34 GMT"}, {"version": "v3", "created": "Sat, 4 Jul 2020 05:48:38 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Fern\u00e1ndez", "Isabel M. Rayas", ""], ["Sutanto", "Giovanni", ""], ["Englert", "Peter", ""], ["Ramachandran", "Ragesh K.", ""], ["Sukhatme", "Gaurav S.", ""]]}, {"id": "2006.07757", "submitter": "Fan Yang", "authors": "Hu Ding, Fan Yang, Jiawei Huang", "title": "Defending SVMs against Poisoning Attacks: the Hardness and DBSCAN\n  Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial machine learning has attracted a great amount of attention in\nrecent years. In a poisoning attack, the adversary can inject a small number of\nspecially crafted samples into the training data which make the decision\nboundary severely deviate and cause unexpected misclassification. Due to the\ngreat importance and popular use of support vector machines (SVM), we consider\ndefending SVM against poisoning attacks in this paper. We study two commonly\nused strategies for defending: designing robust SVM algorithms and data\nsanitization. Though several robust SVM algorithms have been proposed before,\nmost of them either are in lack of adversarial-resilience, or rely on strong\nassumptions about the data distribution or the attacker's behavior. Moreover,\nthe research on their complexities is still quite limited. We are the first, to\nthe best of our knowledge, to prove that even the simplest hard-margin\none-class SVM with outliers problem is NP-complete, and has no fully PTAS\nunless P$=$NP (that means it is hard to achieve an even approximate algorithm).\nFor the data sanitization defense, we link it to the intrinsic dimensionality\nof data; in particular, we provide a sampling theorem in doubling metrics for\nexplaining the effectiveness of DBSCAN (as a density-based outlier removal\nmethod) for defending against poisoning attacks. In our empirical experiments,\nwe compare several defenses including the DBSCAN and robust SVM methods, and\ninvestigate the influences from the intrinsic dimensionality and data density\nto their performances.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jun 2020 01:19:38 GMT"}, {"version": "v2", "created": "Tue, 1 Sep 2020 02:30:47 GMT"}, {"version": "v3", "created": "Thu, 10 Sep 2020 12:46:48 GMT"}, {"version": "v4", "created": "Wed, 16 Sep 2020 06:01:23 GMT"}, {"version": "v5", "created": "Sat, 20 Feb 2021 12:36:59 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Ding", "Hu", ""], ["Yang", "Fan", ""], ["Huang", "Jiawei", ""]]}, {"id": "2006.07839", "submitter": "Da Chen", "authors": "Da Chen, Jack Spencer, Jean-Marie Mirebeau, Ke Chen, Minglei Shu and\n  Laurent D. Cohen", "title": "A Generalized Asymmetric Dual-front Model for Active Contours and Image\n  Segmentation", "comments": "Published in IEEE Transactions on Image Processing", "journal-ref": null, "doi": "10.1109/TIP.2021.3078102", "report-no": null, "categories": "cs.CV cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Voronoi diagram-based dual-front active contour models are known as a\npowerful and efficient way for addressing the image segmentation and domain\npartitioning problems. In the basic formulation of the dual-front models, the\nevolving contours can be considered as the interfaces of adjacent Voronoi\nregions. Among these dual-front models, a crucial ingredient is regarded as the\ngeodesic metrics by which the geodesic distances and the corresponding Voronoi\ndiagram can be estimated. In this paper, we introduce a type of asymmetric\nquadratic metrics dual-front model. The metrics considered are built by the\nintegration of the image features and a vector field derived from the evolving\ncontours. The use of the asymmetry enhancement can reduce the risk of contour\nshortcut or leakage problems especially when the initial contours are far away\nfrom the target boundaries or the images have complicated intensity\ndistributions. Moreover, the proposed dual-front model can be applied for image\nsegmentation in conjunction with various region-based homogeneity terms. The\nnumerical experiments on both synthetic and real images show that the proposed\ndual-front model indeed achieves encouraging results.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jun 2020 08:24:01 GMT"}, {"version": "v2", "created": "Fri, 26 Feb 2021 13:25:28 GMT"}, {"version": "v3", "created": "Tue, 4 May 2021 09:19:18 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Chen", "Da", ""], ["Spencer", "Jack", ""], ["Mirebeau", "Jean-Marie", ""], ["Chen", "Ke", ""], ["Shu", "Minglei", ""], ["Cohen", "Laurent D.", ""]]}, {"id": "2006.08012", "submitter": "Jason Altschuler", "authors": "Jason M. Altschuler, Enric Boix-Adsera", "title": "Wasserstein barycenters can be computed in polynomial time in fixed\n  dimension", "comments": "15 pages + refs, 5 figs. Improved exposition. Title has been updated\n  for clarity", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CG cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computing Wasserstein barycenters is a fundamental geometric problem with\nwidespread applications in machine learning, statistics, and computer graphics.\nHowever, it is unknown whether Wasserstein barycenters can be computed in\npolynomial time, either exactly or to high precision (i.e., with\n$\\textrm{polylog}(1/\\varepsilon)$ runtime dependence). This paper answers these\nquestions in the affirmative for any fixed dimension. Our approach is to solve\nan exponential-size linear programming formulation by efficiently implementing\nthe corresponding separation oracle using techniques from computational\ngeometry.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jun 2020 20:24:27 GMT"}, {"version": "v2", "created": "Wed, 9 Dec 2020 22:15:32 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Altschuler", "Jason M.", ""], ["Boix-Adsera", "Enric", ""]]}, {"id": "2006.08886", "submitter": "Joshua Zahl", "authors": "Adam Sheffer and Joshua Zahl", "title": "Distinct distances in the complex plane", "comments": "41 pages, 0 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that if $P$ is a set of $n$ points in $\\mathbb{C}^2$, then either\nthe points in $P$ determine $\\Omega(n^{1-\\epsilon})$ complex distances, or $P$\nis contained in a line with slope $\\pm i$. If the latter occurs then each pair\nof points in $P$ have complex distance 0.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 02:52:44 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Sheffer", "Adam", ""], ["Zahl", "Joshua", ""]]}, {"id": "2006.09197", "submitter": "Dr. Suryansh Kumar", "authors": "Suryansh Kumar, Luc Van Gool, Carlos E. P. de Oliveira, Anoop Cherian,\n  Yuchao Dai, Hongdong Li", "title": "Dense Non-Rigid Structure from Motion: A Manifold Viewpoint", "comments": "A comprehensive version that combines our cvpr 2018 and cvpr 2019\n  work (Still under development and refinement, Initial Version). 13 Figures, 1\n  Table. arXiv admin note: text overlap with arXiv:1902.01077", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-Rigid Structure-from-Motion (NRSfM) problem aims to recover 3D geometry\nof a deforming object from its 2D feature correspondences across multiple\nframes. Classical approaches to this problem assume a small number of feature\npoints and, ignore the local non-linearities of the shape deformation, and\ntherefore, struggles to reliably model non-linear deformations. Furthermore,\navailable dense NRSfM algorithms are often hurdled by scalability,\ncomputations, noisy measurements and, restricted to model just global\ndeformation. In this paper, we propose algorithms that can overcome these\nlimitations with the previous methods and, at the same time, can recover a\nreliable dense 3D structure of a non-rigid object with higher accuracy.\nAssuming that a deforming shape is composed of a union of local linear subspace\nand, span a global low-rank space over multiple frames enables us to\nefficiently model complex non-rigid deformations. To that end, each local\nlinear subspace is represented using Grassmannians and, the global 3D shape\nacross multiple frames is represented using a low-rank representation. We show\nthat our approach significantly improves accuracy, scalability, and robustness\nagainst noise. Also, our representation naturally allows for simultaneous\nreconstruction and clustering framework which in general is observed to be more\nsuitable for NRSfM problems. Our method currently achieves leading performance\non the standard benchmark datasets.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 09:15:54 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Kumar", "Suryansh", ""], ["Van Gool", "Luc", ""], ["de Oliveira", "Carlos E. P.", ""], ["Cherian", "Anoop", ""], ["Dai", "Yuchao", ""], ["Li", "Hongdong", ""]]}, {"id": "2006.09956", "submitter": "Yuhan Jiang", "authors": "Yuhan Jiang and Bernd Sturmfels", "title": "Bad Projections of the PSD Cone", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AG cs.CG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The image of the cone of positive semidefinite matrices under a linear map is\na convex cone. Pataki characterized the set of linear maps for which that image\nis not closed. The Zariski closure of this set is a hypersurface in the\nGrassmannian. Its components are the coisotropic hypersurfaces of symmetric\ndeterminantal varieties. We develop the convex algebraic geometry of such bad\nprojections, with focus on explicit computations.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 16:09:31 GMT"}, {"version": "v2", "created": "Tue, 23 Feb 2021 21:16:05 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Jiang", "Yuhan", ""], ["Sturmfels", "Bernd", ""]]}, {"id": "2006.10012", "submitter": "Siddharth Vishwanath", "authors": "Siddharth Vishwanath and Kenji Fukumizu and Satoshi Kuriki and Bharath\n  Sriperumbudur", "title": "Robust Persistence Diagrams using Reproducing Kernels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.CG cs.LG math.AT stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Persistent homology has become an important tool for extracting geometric and\ntopological features from data, whose multi-scale features are summarized in a\npersistence diagram. From a statistical perspective, however, persistence\ndiagrams are very sensitive to perturbations in the input space. In this work,\nwe develop a framework for constructing robust persistence diagrams from\nsuperlevel filtrations of robust density estimators constructed using\nreproducing kernels. Using an analogue of the influence function on the space\nof persistence diagrams, we establish the proposed framework to be less\nsensitive to outliers. The robust persistence diagrams are shown to be\nconsistent estimators in bottleneck distance, with the convergence rate\ncontrolled by the smoothness of the kernel. This, in turn, allows us to\nconstruct uniform confidence bands in the space of persistence diagrams.\nFinally, we demonstrate the superiority of the proposed approach on benchmark\ndatasets.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 17:16:52 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Vishwanath", "Siddharth", ""], ["Fukumizu", "Kenji", ""], ["Kuriki", "Satoshi", ""], ["Sriperumbudur", "Bharath", ""]]}, {"id": "2006.10085", "submitter": "Samira Samadi", "authors": "Mehrdad Ghadiri, Samira Samadi, Santosh Vempala", "title": "Socially Fair k-Means Clustering", "comments": "12 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the popular k-means clustering algorithm (Lloyd's heuristic),\nused for a variety of scientific data, can result in outcomes that are\nunfavorable to subgroups of data (e.g., demographic groups). Such biased\nclusterings can have deleterious implications for human-centric applications\nsuch as resource allocation. We present a fair k-means objective and algorithm\nto choose cluster centers that provide equitable costs for different groups.\nThe algorithm, Fair-Lloyd, is a modification of Lloyd's heuristic for k-means,\ninheriting its simplicity, efficiency, and stability. In comparison with\nstandard Lloyd's, we find that on benchmark datasets, Fair-Lloyd exhibits\nunbiased performance by ensuring that all groups have equal costs in the output\nk-clustering, while incurring a negligible increase in running time, thus\nmaking it a viable fair option wherever k-means is currently used.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 18:05:17 GMT"}, {"version": "v2", "created": "Thu, 29 Oct 2020 16:03:50 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Ghadiri", "Mehrdad", ""], ["Samadi", "Samira", ""], ["Vempala", "Santosh", ""]]}, {"id": "2006.10286", "submitter": "Igor V. Netay", "authors": "Igor V. Netay", "title": "Cyclic space-filling curves and their clustering property", "comments": "19 pages, 13 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce an algorithm of construction of cyclic\nspace-filling curves. One particular construction provides a family of\nspace-filling curves in all dimensions (H-curves). They are compared here with\nthe Hilbert curve in the sense of clustering properties, and it turns out that\nthe constructed curve is very close and sometimes a bit better than the Hilbert\ncurve. At the same time, its construction is more simple and evaluation is\nsignificantly faster.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2020 05:35:47 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Netay", "Igor V.", ""]]}, {"id": "2006.10365", "submitter": "Hee-Kap Ahn", "authors": "Jongmin Choi, Hee-Kap Ahn", "title": "Efficient Planar Two-Center Algorithms", "comments": "13 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the planar Euclidean two-center problem in which given $n$ points\nin the plane we are to find two congruent disks of the smallest radius covering\nthe points. We present a deterministic $O(n \\log n)$-time algorithm for the\ncase that the centers of the two optimal disks are close to each other, that\nis, the overlap of the two optimal disks is a constant fraction of the disk\narea. We also present a deterministic $O(n\\log n)$-time algorithm for the case\nthat the input points are in convex position. Both results improve the previous\nbest $O(n\\log n\\log\\log n)$ bound on the problems.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2020 08:50:42 GMT"}, {"version": "v2", "created": "Tue, 7 Jul 2020 23:25:11 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Choi", "Jongmin", ""], ["Ahn", "Hee-Kap", ""]]}, {"id": "2006.11262", "submitter": "Csaba D. Toth", "authors": "Fabrizio Frati, Michael Hoffmann, Csaba D. T\\'oth", "title": "Universal Geometric Graphs", "comments": "20 pages, 8 figures; a 12-page extended abstracts of this paper will\n  appear in the Proceedings of the 46th Workshop on Graph-Theoretic Concepts in\n  Computer Science (WG 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce and study the problem of constructing geometric graphs that have\nfew vertices and edges and that are universal for planar graphs or for some\nsub-class of planar graphs; a geometric graph is \\emph{universal} for a class\n$\\mathcal H$ of planar graphs if it contains an embedding, i.e., a\ncrossing-free drawing, of every graph in $\\mathcal H$.\n  Our main result is that there exists a geometric graph with $n$ vertices and\n$O(n \\log n)$ edges that is universal for $n$-vertex forests; this extends to\nthe geometric setting a well-known graph-theoretic result by Chung and Graham,\nwhich states that there exists an $n$-vertex graph with $O(n \\log n)$ edges\nthat contains every $n$-vertex forest as a subgraph. Our $O(n \\log n)$ bound on\nthe number of edges cannot be improved, even if more than $n$ vertices are\nallowed.\n  We also prove that, for every positive integer $h$, every $n$-vertex convex\ngeometric graph that is universal for $n$-vertex outerplanar graphs has a\nnear-quadratic number of edges, namely $\\Omega_h(n^{2-1/h})$; this almost\nmatches the trivial $O(n^2)$ upper bound given by the $n$-vertex complete\nconvex geometric graph.\n  Finally, we prove that there exists an $n$-vertex convex geometric graph with\n$n$ vertices and $O(n \\log n)$ edges that is universal for $n$-vertex\ncaterpillars.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 17:50:28 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Frati", "Fabrizio", ""], ["Hoffmann", "Michael", ""], ["T\u00f3th", "Csaba D.", ""]]}, {"id": "2006.11523", "submitter": "Leo Liberti", "authors": "Leo Liberti, Gabriele Iommazzo, Carlile Lavor, Nelson Maculan", "title": "Cycle-based formulations in Distance Geometry", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The distance geometry problem asks to find a realization of a given simple\nedge-weighted graph in a Euclidean space of given dimension K, where the edges\nare realized as straight segments of lengths equal (or as close as possible) to\nthe edge weights. The problem is often modelled as a mathematical programming\nformulation involving decision variables that determine the position of the\nvertices in the given Euclidean space. Solution algorithms are generally\nconstructed using local or global nonlinear optimization techniques. We present\na new modelling technique for this problem where, instead of deciding vertex\npositions, formulations decide the length of the segments representing the\nedges in each cycle in the graph, projected in every dimension. We propose an\nexact formulation and a relaxation based on a Eulerian cycle. We then compare\ncomputational results from protein conformation instances obtained with\nstochastic global optimization techniques on the new cycle-based formulation\nand on the existing edge-based formulation. While edge-based formulations take\nless time to reach termination, cycle-based formulations are generally better\non solution quality measures.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jun 2020 08:48:08 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Liberti", "Leo", ""], ["Iommazzo", "Gabriele", ""], ["Lavor", "Carlile", ""], ["Maculan", "Nelson", ""]]}, {"id": "2006.12023", "submitter": "Benjamin Filippenko", "authors": "Gunnar Carlsson, Benjamin Filippenko", "title": "The space of sections of a smooth function", "comments": "38 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AT cs.CG cs.RO math.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a compact manifold $X$ with boundary and a submersion $f : X\n\\rightarrow Y$ whose restriction to the boundary of $X$ has isolated critical\npoints with distinct critical values and where $Y$ is $[0,1]$ or $S^1$, the\nconnected components of the space of sections of $f$ are computed from $\\pi_0$\nand $\\pi_1$ of the fibers of $f$. This computation is then leveraged to provide\nnew results on a smoothed version of the evasion path problem for mobile sensor\nnetworks: From the time-varying homology of the covered region and the\ntime-varying cup-product on cohomology of the boundary, a necessary and\nsufficient condition for existence of an evasion path and a lower bound on the\nnumber of homotopy classes of evasion paths are computed. No connectivity\nassumptions are required.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 06:26:36 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Carlsson", "Gunnar", ""], ["Filippenko", "Benjamin", ""]]}, {"id": "2006.12318", "submitter": "Dror Aiger", "authors": "Dror Aiger, Haim Kaplan, Micha Sharir", "title": "Duality-based approximation algorithms for depth queries and maximum\n  depth", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We design an efficient data structure for computing a suitably defined\napproximate depth of any query point in the arrangement $\\mathcal{A}(S)$ of a\ncollection $S$ of $n$ halfplanes or triangles in the plane or of halfspaces or\nsimplices in higher dimensions. We then use this structure to find a point of\nan approximate maximum depth in $\\mathcal{A}(S)$. Specifically, given an error\nparameter $\\epsilon>0$, we compute, for any query point $q$, an underestimate\n$d^-(q)$ of the depth of $q$, that counts only objects containing $q$, but is\nallowed to exclude objects when $q$ is $\\epsilon$-close to their boundary.\nSimilarly, we compute an overestimate $d^+(q)$ that counts all objects\ncontaining $q$ but may also count objects that do not contain $q$ but $q$ is\n$\\epsilon$-close to their boundary. Our algorithms for halfplanes and\nhalfspaces are linear in the number of input objects and in the number of\nqueries, and the dependence of their running time on $\\epsilon$ is considerably\nbetter than that of earlier techniques. Our improvements are particularly\nsubstantial for triangles and in higher dimensions.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 14:58:22 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Aiger", "Dror", ""], ["Kaplan", "Haim", ""], ["Sharir", "Micha", ""]]}, {"id": "2006.12454", "submitter": "Sayan Bandyapadhyay", "authors": "Sayan Bandyapadhyay", "title": "Improved Bounds for Metric Capacitated Covering Problems", "comments": "To appear at European Symposia on Algorithms 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the Metric Capacitated Covering (MCC) problem, given a set of balls\n$\\mathcal{B}$ in a metric space $P$ with metric $d$ and a capacity parameter\n$U$, the goal is to find a minimum sized subset $\\mathcal{B}'\\subseteq\n\\mathcal{B}$ and an assignment of the points in $P$ to the balls in\n$\\mathcal{B}'$ such that each point is assigned to a ball that contains it and\neach ball is assigned with at most $U$ points. MCC achieves an $O(\\log\n|P|)$-approximation using a greedy algorithm. On the other hand, it is hard to\napproximate within a factor of $o(\\log |P|)$ even with $\\beta < 3$ factor\nexpansion of the balls. Bandyapadhyay~{et al.} [SoCG 2018, DCG 2019] showed\nthat one can obtain an $O(1)$-approximation for the problem with $6.47$ factor\nexpansion of the balls. An open question left by their work is to reduce the\ngap between the lower bound $3$ and the upper bound $6.47$. In this current\nwork, we show that it is possible to obtain an $O(1)$-approximation with only\n$4.24$ factor expansion of the balls. We also show a similar upper bound of $5$\nfor a more generalized version of MCC for which the best previously known bound\nwas $9$.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 17:36:52 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Bandyapadhyay", "Sayan", ""]]}, {"id": "2006.12838", "submitter": "Moritz Lehmann M.Sc.", "authors": "Moritz Lehmann and Stephan Gekle", "title": "Analytic Solution to the Piecewise Linear Interface Construction Problem\n  and its Application in Curvature Calculation for Volume-of-Fluid Simulation\n  Codes", "comments": "18 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.CG physics.flu-dyn", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The plane-cube intersection problem has been around in literature since 1984\nand iterative solutions to it have been used as part of piecewise linear\ninterface construction (PLIC) in computational fluid dynamics simulation codes\never since. In many cases, PLIC is the bottleneck of these simulations\nregarding compute time, so a faster, analytic solution to the plane-cube\nintersection would greatly reduce compute time for such simulations. We derive\nan analytic solution for all intersection cases and compare it to the one\nprevious solution from Scardovelli and Zaleski (Ruben Scardovelli and Stephane\nZaleski. \"Analytical relations connecting linear interfaces and volume\nfractions in rectangular grids\". In: Journal of Computational Physics 164.1\n(2000), pp. 228-237.), which we further improve to include edge cases and\nmicro-optimize to reduce arithmetic operations and branching. We then extend\nour comparison regarding compute time and accuracy to include two different\niterative solutions as well. We find that the best choice depends on the\nemployed hardware platform: on the CPU, Newton-Raphson is fastest with\nvectorization while analytic solutions perform better without. The reason for\nthis is that vectorization instruction sets do not include trigonometric\nfunctions as used in the analytic solutions. On the GPU, the fastest method is\nour optimized version of the analytic SZ solution. We finally provide details\non one of the applications of PLIC: curvature calculation for the\nVolume-of-Fluid model used for free surface fluid simulations in combination\nwith the lattice Boltzmann method.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 08:54:36 GMT"}, {"version": "v2", "created": "Thu, 18 Feb 2021 13:01:33 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Lehmann", "Moritz", ""], ["Gekle", "Stephan", ""]]}, {"id": "2006.13166", "submitter": "Dan Reznik", "authors": "Ronaldo Garcia and Dan Reznik and Hellmuth Stachel and Mark Helman", "title": "Steiner's Hat: a Constant-Area Deltoid Associated with the Ellipse", "comments": "23 pages, 16 figures, 4 tables, 6 video links", "journal-ref": "KoG, 24. (24.), 12-28 (2020)", "doi": "10.31896/k.24.2", "report-no": null, "categories": "math.DS cs.CG cs.GR math.DG math.MG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Negative Pedal Curve (NPC) of the Ellipse with respect to a boundary\npoint M is a 3-cusp closed-curve which is the affine image of the Steiner\nDeltoid. Over all M the family has invariant area and displays an array of\ninteresting properties.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 17:15:18 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 10:33:05 GMT"}, {"version": "v3", "created": "Mon, 6 Jul 2020 00:44:14 GMT"}, {"version": "v4", "created": "Tue, 7 Jul 2020 13:55:03 GMT"}, {"version": "v5", "created": "Mon, 5 Oct 2020 15:36:26 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Garcia", "Ronaldo", ""], ["Reznik", "Dan", ""], ["Stachel", "Hellmuth", ""], ["Helman", "Mark", ""]]}, {"id": "2006.13266", "submitter": "Vin\\'icius da Silva", "authors": "Vin\\'icius da Silva, Claudio Esperan\\c{c}a and Ricardo Marroquim", "title": "OMiCroN -- Oblique Multipass Hierarchy Creation while Navigating", "comments": "13 pages, 15 figures", "journal-ref": "Computers & Graphics, Volume 84, November 2019, Pages 42-54", "doi": "10.1016/j.cag.2019.08.016", "report-no": null, "categories": "cs.GR cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rendering large point clouds ordinarily requires building a hierarchical data\nstructure for accessing the points that best represent the object for a given\nviewing frustum and level-of-detail. The building of such data structures\nfrequently represents a large portion of the cost of the rendering pipeline\nboth in terms of time and space complexity, especially when rendering is done\nfor inspection purposes only. This problem has been addressed in the past by\nincremental construction approaches, but these either result in low quality\nhierarchies or in longer construction times. In this work we present OMiCroN --\nOblique Multipass Hierarchy Creation while Navigating -- which is the first\nalgorithm capable of immediately displaying partial renders of the geometry,\nprovided the cloud is made available sorted in Morton order. OMiCroN is fast,\nbeing capable of building the entire data structure in memory spending an\namount of time that is comparable to that of just reading the cloud from disk.\nThus, there is no need for storing an expensive hierarchy, nor for delaying the\nrendering until the whole hierarchy is read from disk. In fact, a pipeline\ncoupling OMiCroN with an incremental sorting algorithm running in parallel can\nstart rendering as soon as the first sorted prefix is produced, making this\nsetup very convenient for streamed viewing.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 18:46:16 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["da Silva", "Vin\u00edcius", ""], ["Esperan\u00e7a", "Claudio", ""], ["Marroquim", "Ricardo", ""]]}, {"id": "2006.13712", "submitter": "Arijit Ghosh", "authors": "Anup Bhattacharya, Sourav Chakraborty, Arijit Ghosh, Gopinath Mishra,\n  and Manaswi Paraashar", "title": "Disjointness through the Lens of Vapnik-Chervonenkis Dimension: Sparsity\n  and Beyond", "comments": "To appear in RANDOM 2020. Pages: 15", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The disjointness problem - where Alice and Bob are given two subsets of $\\{1,\n\\dots, n\\}$ and they have to check if their sets intersect - is a central\nproblem in the world of communication complexity. While both deterministic and\nrandomized communication complexities for this problem are known to be\n$\\Theta(n)$, it is also known that if the sets are assumed to be drawn from\nsome restricted set systems then the communication complexity can be much\nlower. In this work, we explore how communication complexity measures change\nwith respect to the complexity of the underlying set system. The complexity\nmeasure for the set system that we use in this work is the Vapnik-Chervonenkis\n(VC) dimension. More precisely, on any set system with VC dimension bounded by\n$d$, we analyze how large can the deterministic and randomized communication\ncomplexities be, as a function of $d$ and $n$.\n  In this paper, we construct two natural set systems of VC dimension $d$,\nmotivated from geometry. Using these set systems we show that the deterministic\nand randomized communication complexity can be $\\widetilde{\\Theta}\\left(d\\log\n\\left( n/d \\right)\\right)$ for set systems of VC dimension $d$ and this matches\nthe deterministic upper bound for all set systems of VC dimension $d$. We also\nstudy the deterministic and randomized communication complexities of the set\nintersection problem when sets belong to a set system of bounded VC dimension.\nWe show that there exists set systems of VC dimension $d$ such that both\ndeterministic and randomized (one-way and multi-round) complexity for the set\nintersection problem can be as high as $\\Theta\\left( d\\log \\left( n/d \\right)\n\\right)$, and this is tight among all set systems of VC dimension $d$.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 13:19:53 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Bhattacharya", "Anup", ""], ["Chakraborty", "Sourav", ""], ["Ghosh", "Arijit", ""], ["Mishra", "Gopinath", ""], ["Paraashar", "Manaswi", ""]]}, {"id": "2006.13754", "submitter": "Mehrdad Ghadiri", "authors": "Mehrdad Ghadiri, Richard Santiago, Bruce Shepherd", "title": "A Parameterized Family of Meta-Submodular Functions", "comments": "arXiv admin note: text overlap with arXiv:1904.09216", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG cs.DM cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Submodular function maximization has found a wealth of new applications in\nmachine learning models during the past years. The related supermodular\nmaximization models (submodular minimization) also offer an abundance of\napplications, but they appeared to be highly intractable even under simple\ncardinality constraints. Hence, while there are well-developed tools for\nmaximizing a submodular function subject to a matroid constraint, there is much\nless work on the corresponding supermodular maximization problems.\n  We give a broad parameterized family of monotone functions which includes\nsubmodular functions and a class of supermodular functions containing diversity\nfunctions. Functions in this parameterized family are called\n\\emph{$\\gamma$-meta-submodular}. We develop local search algorithms with\napproximation factors that depend only on the parameter $\\gamma$. We show that\nthe $\\gamma$-meta-submodular families include well-known classes of functions\nsuch as meta-submodular functions ($\\gamma=0$), metric diversity functions and\nproportionally submodular functions (both with $\\gamma=1$), diversity functions\nbased on negative-type distances or Jensen-Shannon divergence (both with\n$\\gamma=2$), and $\\sigma$-semi metric diversity functions ($\\gamma = \\sigma$).\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 16:45:12 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Ghadiri", "Mehrdad", ""], ["Santiago", "Richard", ""], ["Shepherd", "Bruce", ""]]}, {"id": "2006.14059", "submitter": "Man-Kwun Chiu", "authors": "Man-Kwun Chiu, Matias Korman, Martin Suderland, Takeshi Tokuyama", "title": "Distance bounds for high dimensional consistent digital rays and 2-D\n  partially-consistent digital rays", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of digitalizing Euclidean segments. Specifically, we\nlook for a constructive method to connect any two points in $\\mathbb{Z}^d$. The\nconstruction must be {\\em consistent} (that is, satisfy the natural extension\nof the Euclidean axioms) while resembling them as much as possible. Previous\nwork has shown asymptotically tight results in two dimensions with $\\Theta(\\log\nN)$ error, where resemblance between segments is measured with the Hausdorff\ndistance, and $N$ is the $L_1$ distance between the two points. This\nconstruction was considered tight because of a $\\Omega(\\log N)$ lower bound\nthat applies to any consistent construction in $\\mathbb{Z}^2$.\n  In this paper we observe that the lower bound does not directly extend to\nhigher dimensions. We give an alternative argument showing that any consistent\nconstruction in $d$ dimensions must have $\\Omega(\\log^{1/(d-1)} N)$ error. We\ntie the error of a consistent construction in high dimensions to the error of\nsimilar {\\em weak} constructions in two dimensions (constructions for which\nsome points need not satisfy all the axioms). This not only opens the\npossibility for having constructions with $o(\\log N)$ error in high dimensions,\nbut also opens up an interesting line of research in the tradeoff between the\nnumber of axiom violations and the error of the construction. In order to show\nour lower bound, we also consider a colored variation of the concept of\ndiscrepancy of a set of points that we find of independent interest.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 21:25:07 GMT"}, {"version": "v2", "created": "Fri, 26 Jun 2020 22:45:26 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Chiu", "Man-Kwun", ""], ["Korman", "Matias", ""], ["Suderland", "Martin", ""], ["Tokuyama", "Takeshi", ""]]}, {"id": "2006.14093", "submitter": "Yiming Zhao", "authors": "Haitao Wang, Yiming Zhao", "title": "A Linear-Time Algorithm for Discrete Radius Optimally Augmenting Paths\n  in a Metric Space", "comments": "A preliminary version to appear in CCCG 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $P$ be a path graph of $n$ vertices embedded in a metric space. We\nconsider the problem of adding a new edge to $P$ so that the radius of the\nresulting graph is minimized, where any center is constrained to be one of the\nvertices of $P$. Previously, the \"continuous\" version of the problem where a\ncenter may be a point in the interior of an edge of the graph was studied and a\nlinear-time algorithm was known. Our \"discrete\" version of the problem has not\nbeen studied before. We present a linear-time algorithm for the problem.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 22:57:20 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Wang", "Haitao", ""], ["Zhao", "Yiming", ""]]}, {"id": "2006.14182", "submitter": "Pinki Pinki", "authors": "Pinki and Krishnendra Shekhawat", "title": "A linear time algorithm for constructing orthogonal floor plans with\n  minimum number of bends", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let G = (V, E) be a planar triangulated graph (PTG) having every face\ntriangular. A rectilinear dual or an orthogonal floor plan (OFP) of G is\nobtained by partitioning a rectangle into \\mid V \\mid rectilinear regions\n(modules) where two modules are adjacent if and only if there is an edge\nbetween the corresponding vertices in G. In this paper, a linear-time algorithm\nis presented for constructing an OFP for a given G such that the obtained OFP\nhas B_{min} bends, where a bend in a concave corner in an OFP. Further, it has\nbeen proved that at least B_{min} bends are required to construct an OFP for G,\nwhere \\rho - 2 \\leq B_{min} \\leq \\rho + 1 and \\rho is the sum of the number of\nleaves of the containment tree of G and the number of K_4 (4-vertex complete\ngraph) in G.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 05:17:17 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Pinki", "", ""], ["Shekhawat", "Krishnendra", ""]]}, {"id": "2006.14298", "submitter": "Stefan De Lorenzo", "authors": "Martin Held and Stefan de Lorenzo", "title": "An Efficient, Practical Algorithm and Implementation for Computing\n  Multiplicatively Weighted Voronoi Diagrams", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a simple wavefront-like approach for computing multiplicatively\nweighted Voronoi diagrams of points and straight-line segments in the Euclidean\nplane. If the input sites may be assumed to be randomly weighted points then\nthe use of a so-called overlay arrangement [Har-Peled&Raichel, Discrete Comput.\nGeom. 53:547-568, 2015] allows to achieve an expected runtime complexity of\n$O(n\\log^4 n)$, while still maintaining the simplicity of our approach. We\nimplemented the full algorithm for weighted points as input sites, based on\nCGAL. The results of an experimental evaluation of our implementation suggest\n$O(n\\log^2 n)$ as a practical bound on the runtime. Our algorithm can be\nextended to handle also additive weights in addition to multiplicative weights,\nand it yields a truly simple $O(n\\log n)$ solution for solving the\none-dimensional version of this problem.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 10:35:52 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Held", "Martin", ""], ["de Lorenzo", "Stefan", ""]]}, {"id": "2006.14677", "submitter": "Yuxin Chen", "authors": "Akash Kumar, Adish Singla, Yisong Yue, Yuxin Chen", "title": "Average-case Complexity of Teaching Convex Polytopes via Halfspace\n  Queries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CG math.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine the task of locating a target region among those induced by\nintersections of $n$ halfspaces in $\\mathbb{R}^d$. This generic task connects\nto fundamental machine learning problems, such as training a perceptron and\nlearning a $\\phi$-separable dichotomy. We investigate the average teaching\ncomplexity of the task, i.e., the minimal number of samples (halfspace queries)\nrequired by a teacher to help a version-space learner in locating a randomly\nselected target. As our main result, we show that the average-case teaching\ncomplexity is $\\Theta(d)$, which is in sharp contrast to the worst-case\nteaching complexity of $\\Theta(n)$. If instead, we consider the average-case\nlearning complexity, the bounds have a dependency on $n$ as $\\Theta(n)$ for\n\\tt{i.i.d.} queries and $\\Theta(d \\log(n))$ for actively chosen queries by the\nlearner. Our proof techniques are based on novel insights from computational\ngeometry, which allow us to count the number of convex polytopes and faces in a\nEuclidean space depending on the arrangement of halfspaces. Our insights allow\nus to establish a tight bound on the average-case complexity for\n$\\phi$-separable dichotomies, which generalizes the known $\\mathcal{O}(d)$\nbound on the average number of \"extreme patterns\" in the classical\ncomputational geometry literature (Cover, 1965).\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 19:59:24 GMT"}, {"version": "v2", "created": "Sun, 25 Oct 2020 23:58:40 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Kumar", "Akash", ""], ["Singla", "Adish", ""], ["Yue", "Yisong", ""], ["Chen", "Yuxin", ""]]}, {"id": "2006.15089", "submitter": "Rathish Das", "authors": "Esther M. Arkin, Rathish Das, Jie Gao, Mayank Goswami, Joseph S. B.\n  Mitchell, Valentin Polishchuk, Csaba D. Toth", "title": "Cutting Polygons into Small Pieces with Chords: Laser-Based Localization", "comments": "This paper will appear in ESA2020, Track A proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by indoor localization by tripwire lasers, we study the problem of\ncutting a polygon into small-size pieces, using the chords of the polygon.\nSeveral versions are considered, depending on the definition of the \"size\" of a\npiece. In particular, we consider the area, the diameter, and the radius of the\nlargest inscribed circle as a measure of the size of a piece. We also consider\ndifferent objectives, either minimizing the maximum size of a piece for a given\nnumber of chords, or minimizing the number of chords that achieve a given size\nthreshold for the pieces. We give hardness results for polygons with holes and\napproximation algorithms for multiple variants of the problem.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2020 16:38:09 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Arkin", "Esther M.", ""], ["Das", "Rathish", ""], ["Gao", "Jie", ""], ["Goswami", "Mayank", ""], ["Mitchell", "Joseph S. B.", ""], ["Polishchuk", "Valentin", ""], ["Toth", "Csaba D.", ""]]}, {"id": "2006.15650", "submitter": "Alejandro Flores Velazco", "authors": "Alejandro Flores-Velazco", "title": "Social Distancing is Good for Points too!", "comments": "To appear in CCCG 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The nearest-neighbor rule is a well-known classification technique that,\ngiven a training set P of labeled points, classifies any unlabeled query point\nwith the label of its closest point in P. The nearest-neighbor condensation\nproblem aims to reduce the training set without harming the accuracy of the\nnearest-neighbor rule.\n  FCNN is the most popular algorithm for condensation. It is heuristic in\nnature, and theoretical results for it are scarce. In this paper, we settle the\nquestion of whether reasonable upper-bounds can be proven for the size of the\nsubset selected by FCNN. First, we show that the algorithm can behave poorly\nwhen points are too close to each other, forcing it to select many more points\nthan necessary. We then successfully modify the algorithm to avoid such cases,\nthus imposing that selected points should \"keep some distance\". This\nmodification is sufficient to prove useful upper-bounds, along with\napproximation guarantees for the algorithm.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jun 2020 16:49:59 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Flores-Velazco", "Alejandro", ""]]}, {"id": "2006.15664", "submitter": "Jared Coleman", "authors": "Jared Coleman, Evangelos Kranakis, Oscar Morales-Ponce, Jaroslav\n  Opatrny, Jorge Urrutia, Birgit Vogtenhuber", "title": "Minimizing The Maximum Distance Traveled To Form Patterns With Systems\n  of Mobile Robots", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the pattern formation problem, robots in a system must self-coordinate to\nform a given pattern, regardless of translation, rotation, uniform-scaling,\nand/or reflection. In other words, a valid final configuration of the system is\na formation that is \\textit{similar} to the desired pattern. While there has\nbeen no shortage of research in the pattern formation problem under a variety\nof assumptions, models, and contexts, we consider the additional constraint\nthat the maximum distance traveled among all robots in the system is minimum.\nExisting work in pattern formation and closely related problems are typically\napplication-specific or not concerned with optimality (but rather feasibility).\nWe show the necessary conditions any optimal solution must satisfy and present\na solution for systems of three robots. Our work also led to an interesting\nresult that has applications beyond pattern formation. Namely, a metric for\ncomparing two triangles where a distance of $0$ indicates the triangles are\nsimilar, and $1$ indicates they are \\emph{fully dissimilar}.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jun 2020 17:48:45 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Coleman", "Jared", ""], ["Kranakis", "Evangelos", ""], ["Morales-Ponce", "Oscar", ""], ["Opatrny", "Jaroslav", ""], ["Urrutia", "Jorge", ""], ["Vogtenhuber", "Birgit", ""]]}, {"id": "2006.16573", "submitter": "Rameshwar Pratap", "authors": "Amit Deshpande and Rameshwar Pratap", "title": "Subspace approximation with outliers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The subspace approximation problem with outliers, for given $n$ points in $d$\ndimensions $x_{1},\\ldots, x_{n} \\in R^{d}$, an integer $1 \\leq k \\leq d$, and\nan outlier parameter $0 \\leq \\alpha \\leq 1$, is to find a $k$-dimensional\nlinear subspace of $R^{d}$ that minimizes the sum of squared distances to its\nnearest $(1-\\alpha)n$ points. More generally, the $\\ell_{p}$ subspace\napproximation problem with outliers minimizes the sum of $p$-th powers of\ndistances instead of the sum of squared distances. Even the case of robust PCA\nis non-trivial, and previous work requires additional assumptions on the input.\nAny multiplicative approximation algorithm for the subspace approximation\nproblem with outliers must solve the robust subspace recovery problem, a\nspecial case in which the $(1-\\alpha)n$ inliers in the optimal solution are\npromised to lie exactly on a $k$-dimensional linear subspace. However, robust\nsubspace recovery is Small Set Expansion (SSE)-hard.\n  We show how to extend dimension reduction techniques and bi-criteria\napproximations based on sampling to the problem of subspace approximation with\noutliers. To get around the SSE-hardness of robust subspace recovery, we assume\nthat the squared distance error of the optimal $k$-dimensional subspace summed\nover the optimal $(1-\\alpha)n$ inliers is at least $\\delta$ times its\nsquared-error summed over all $n$ points, for some $0 < \\delta \\leq 1 -\n\\alpha$. With this assumption, we give an efficient algorithm to find a subset\nof $poly(k/\\epsilon) \\log(1/\\delta) \\log\\log(1/\\delta)$ points whose span\ncontains a $k$-dimensional subspace that gives a multiplicative\n$(1+\\epsilon)$-approximation to the optimal solution. The running time of our\nalgorithm is linear in $n$ and $d$. Interestingly, our results hold even when\nthe fraction of outliers $\\alpha$ is large, as long as the obvious condition $0\n< \\delta \\leq 1 - \\alpha$ is satisfied.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 07:22:33 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Deshpande", "Amit", ""], ["Pratap", "Rameshwar", ""]]}, {"id": "2006.16651", "submitter": "R Inkulu", "authors": "Debangshu Banerjee, R. Inkulu", "title": "Vertex Guarding for Dynamic Orthogonal Art Galleries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We devise an algorithm for surveying a dynamic orthogonal polygonal domain\n$\\cal P$ by placing one guard at each vertex in a subset of vertices of $\\cal\nP$, i.e., whenever an orthogonal polygon domain $\\cal P'$ is modified to result\nin another orthogonal polygonal domain $\\cal P$, our algorithm updates the set\nof (vertex) guards surveying $\\cal P'$ so that the updated guard set surveys\n$\\cal P$. Our algorithm modifies the guard placement in $O(k \\lg{(n+n')})$\namortized time, while ensuring the updated orthogonal polygon with $h$ holes\nand $n$ vertices is guarded using at most $\\lfloor (n+2h)/4 \\rfloor$ vertex\nguards. For the special case of the initial orthogonal polygon being hole-free\nand each update resulting in a hole-free orthogonal polygon, our guard updation\nalgorithm takes $O(k\\lg{(n+n')})$ worst-case time. Here, $n'$ and $n$ are the\nnumber of vertices of the orthogonal polygon before and after the update,\nrespectively; and, $k$ is the sum of $|n - n'|$ and the number of updates in a\nfew structures maintained by our algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 10:21:21 GMT"}, {"version": "v2", "created": "Wed, 10 Mar 2021 08:20:20 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Banerjee", "Debangshu", ""], ["Inkulu", "R.", ""]]}]