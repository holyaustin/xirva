[{"id": "1208.0053", "submitter": "Adam Sheffer", "authors": "Micha Sharir, Adam Sheffer, and Joshua Zahl", "title": "Improved bounds for incidences between points and circles", "comments": null, "journal-ref": "Combinator. Probab. Comp. 24 (2015) 490-520", "doi": "10.1017/S0963548314000534", "report-no": null, "categories": "math.CO cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We establish an improved upper bound for the number of incidences between m\npoints and n circles in three dimensions. The previous best known bound,\noriginally established for the planar case and later extended to any dimension\n$\\ge 2$, is $O*(m^{2/3}n^{2/3} + m^{6/11}n^{9/11}+m+n)$, where the $O*(\\cdot)$\nnotation hides sub-polynomial factors. Since all the points and circles may lie\non a common plane (or sphere), it is impossible to improve the bound in R^3\nwithout first improving it in the plane.\n  Nevertheless, we show that if the set of circles is required to be \"truly\nthree-dimensional\" in the sense that no sphere or plane contains more than $q$\nof the circles, for some $q << n$, then the bound can be improved to\n\\[O*(m^{3/7}n^{6/7} + m^{2/3}n^{1/2}q^{1/6} + m^{6/11}n^{15/22}q^{3/22} + m +\nn). \\]\n  For various ranges of parameters (e.g., when $m=\\Theta(n)$ and $q =\no(n^{7/9})$), this bound is smaller than the lower bound\n$\\Omega*(m^{2/3}n^{2/3}+m+n)$, which holds in two dimensions.\n  We present several extensions and applications of the new bound: (i) For the\nspecial case where all the circles have the same radius, we obtain the improved\nbound $O*(m^{5/11}n^{9/11} + m^{2/3}n^{1/2}q^{1/6} + m + n$. (ii) We present an\nimproved analysis that removes the subpolynomial factors from the bound when\n$m=O(n^{3/2-\\eps})$ for any fixed $\\varepsilon >0$. (iii) We use our results to\nobtain the improved bound $O(m^{15/7})$ for the number of mutually similar\ntriangles determined by any set of $m$ points in R^3.\n  Our result is obtained by applying the polynomial partitioning technique of\nGuth and Katz using a constant-degree partitioning polynomial (as was also\nrecently used by Solymosi and Tao). We also rely on various additional tools\nfrom analytic, algebraic, and combinatorial geometry.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jul 2012 23:20:20 GMT"}, {"version": "v2", "created": "Mon, 1 Jul 2013 16:50:17 GMT"}, {"version": "v3", "created": "Mon, 16 Jun 2014 18:25:57 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Sharir", "Micha", ""], ["Sheffer", "Adam", ""], ["Zahl", "Joshua", ""]]}, {"id": "1208.0202", "submitter": "Sandor P. Fekete", "authors": "S\\'andor P. Fekete", "title": "The Complexity of MaxMin Length Triangulation", "comments": "7 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 1991, Edelsbrunner and Tan gave an O(n^2) algorithm for finding the MinMax\nLength triangulation of a set of points in the plane. In this paper we resolve\none of the open problems stated in that paper, by showing that finding a MaxMin\nLength triangulation is an NP-complete problem. The proof implies that (unless\nP=NP), there is no polynomial-time approximation algorithm that can approximate\nthe problem within any polynomial factor.\n", "versions": [{"version": "v1", "created": "Wed, 1 Aug 2012 13:20:32 GMT"}], "update_date": "2012-08-02", "authors_parsed": [["Fekete", "S\u00e1ndor P.", ""]]}, {"id": "1208.0395", "submitter": "Marko Savi\\'c", "authors": "Marko Savi\\'c, Milo\\v{s} Stojakovi\\'c", "title": "Linear Time Algorithm for Optimal Feed-link Placement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a polygon representing a transportation network together with a point p\nin its interior, we aim to extend the network by inserting a line segment,\ncalled a feed-link, which connects p to the boundary of the polygon. Once a\nfeed link is fixed, the geometric dilation of some point q on the boundary is\nthe ratio between the length of the shortest path from p to q through the\nextended network, and their Euclidean distance. The utility of a feed-link is\ninversely proportional to the maximal dilation over all boundary points.\n  We give a linear time algorithm for computing the feed-link with the minimum\noverall dilation, thus improving upon the previously known algorithm of\ncomplexity that is roughly O(n log n).\n", "versions": [{"version": "v1", "created": "Thu, 2 Aug 2012 04:15:47 GMT"}, {"version": "v2", "created": "Mon, 29 Jul 2013 16:26:22 GMT"}], "update_date": "2013-07-30", "authors_parsed": [["Savi\u0107", "Marko", ""], ["Stojakovi\u0107", "Milo\u0161", ""]]}, {"id": "1208.1565", "submitter": "Robert Schweller", "authors": "Robert Schweller, Michael Sherman", "title": "Fuel Efficient Computation in Passive Self-Assembly", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we show that passive self-assembly in the context of the tile\nself-assembly model is capable of performing fuel efficient, universal\ncomputation. The tile self-assembly model is a premiere model of self-assembly\nin which particles are modeled by four-sided squares with glue types assigned\nto each tile edge. The assembly process is driven by positive and negative\nforce interactions between glue types, allowing for tile assemblies floating in\nthe plane to combine and break apart over time. We refer to this type of\nassembly model as passive in that the constituent parts remain unchanged\nthroughout the assembly process regardless of their interactions. A\ncomputationally universal system is said to be fuel efficient if the number of\ntiles used up per computation step is bounded by a constant. Work within this\nmodel has shown how fuel guzzling tile systems can perform universal\ncomputation with only positive strength glue interactions. Recent work has\nintroduced space-efficient, fuel-guzzling universal computation with the\naddition of negative glue interactions and the use of a powerful non-diagonal\nclass of glue interactions. Other recent work has shown how to achieve fuel\nefficient computation within active tile self-assembly. In this paper we\nutilize negative interactions in the tile self-assembly model to achieve the\nfirst computationally universal passive tile self-assembly system that is both\nspace and fuel-efficient. In addition, we achieve this result using a limited\ndiagonal class of glue interactions.\n", "versions": [{"version": "v1", "created": "Wed, 8 Aug 2012 02:33:30 GMT"}], "update_date": "2012-08-09", "authors_parsed": [["Schweller", "Robert", ""], ["Sherman", "Michael", ""]]}, {"id": "1208.2113", "submitter": "Pavel Bazovkin", "authors": "Karl Mosler and Pavel Bazovkin", "title": "Stochastic linear programming with a distortion risk constraint", "comments": null, "journal-ref": "OR Spectrum 36 (2014), 949 - 969", "doi": null, "report-no": null, "categories": "stat.ME cs.CG", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Linear optimization problems are investigated whose parameters are uncertain.\nWe apply coherent distortion risk measures to capture the possible violation of\na restriction. Each risk constraint induces an uncertainty set of coefficients,\nwhich is shown to be a weighted-mean trimmed region. Given an external sample\nof the coefficients, an uncertainty set is a convex polytope that can be\nexactly calculated. We construct an efficient geometrical algorithm to solve\nstochastic linear programs that have a single distortion risk constraint. The\nalgorithm is available as an R-package. Also the algorithm's asymptotic\nbehavior is investigated, when the sample is i.i.d. from a general probability\ndistribution. Finally, we present some computational experience.\n", "versions": [{"version": "v1", "created": "Fri, 10 Aug 2012 08:42:23 GMT"}], "update_date": "2017-12-18", "authors_parsed": [["Mosler", "Karl", ""], ["Bazovkin", "Pavel", ""]]}, {"id": "1208.2245", "submitter": "Xizhong Zheng", "authors": "Xizhong Zheng (Jiangsu University and Arcadia University), Robert\n  Rettinger (Hagen University)", "title": "Point-Separable Classes of Simple Computable Planar Curves", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 8, Issue 3 (September\n  13, 2012) lmcs:941", "doi": "10.2168/LMCS-8(3:15)2012", "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In mathematics curves are typically defined as the images of continuous real\nfunctions (parametrizations) defined on a closed interval. They can also be\ndefined as connected one-dimensional compact subsets of points. For simple\ncurves of finite lengths, parametrizations can be further required to be\ninjective or even length-normalized. All of these four approaches to curves are\nclassically equivalent. In this paper we investigate four different versions of\ncomputable curves based on these four approaches. It turns out that they are\nall different, and hence, we get four different classes of computable curves.\nMore interestingly, these four classes are even point-separable in the sense\nthat the sets of points covered by computable curves of different versions are\nalso different. However, if we consider only computable curves of computable\nlengths, then all four versions of computable curves become equivalent. This\nshows that the definition of computable curves is robust, at least for those of\ncomputable lengths. In addition, we show that the class of computable curves of\ncomputable lengths is point-separable from the other four classes of computable\ncurves.\n", "versions": [{"version": "v1", "created": "Wed, 8 Aug 2012 21:34:33 GMT"}, {"version": "v2", "created": "Wed, 12 Sep 2012 07:26:47 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Zheng", "Xizhong", "", "Jiangsu University and Arcadia University"], ["Rettinger", "Robert", "", "Hagen University"]]}, {"id": "1208.2447", "submitter": "Rishi Gupta", "authors": "Rishi Gupta, Piotr Indyk, Eric Price, and Yaron Rachlin", "title": "Compressive Sensing with Local Geometric Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  We propose a framework for compressive sensing of images with local\ndistinguishable objects, such as stars, and apply it to solve a problem in\ncelestial navigation. Specifically, let x be an N-pixel real-valued image,\nconsisting of a small number of local distinguishable objects plus noise. Our\ngoal is to design an m-by-N measurement matrix A with m << N, such that we can\nrecover an approximation to x from the measurements Ax.\n  We construct a matrix A and recovery algorithm with the following properties:\n(i) if there are k objects, the number of measurements m is O((k log N)/(log\nk)), undercutting the best known bound of O(k log(N/k)) (ii) the matrix A is\nvery sparse, which is important for hardware implementations of compressive\nsensing algorithms, and (iii) the recovery algorithm is empirically fast and\nruns in time polynomial in k and log(N).\n  We also present a comprehensive study of the application of our algorithm to\nattitude determination, or finding one's orientation in space. Spacecraft\ntypically use cameras to acquire an image of the sky, and then identify stars\nin the image to compute their orientation. Taking pictures is very expensive\nfor small spacecraft, since camera sensors use a lot of power. Our algorithm\noptically compresses the image before it reaches the camera's array of pixels,\nreducing the number of sensors that are required.\n", "versions": [{"version": "v1", "created": "Sun, 12 Aug 2012 18:12:58 GMT"}], "update_date": "2012-08-14", "authors_parsed": [["Gupta", "Rishi", ""], ["Indyk", "Piotr", ""], ["Price", "Eric", ""], ["Rachlin", "Yaron", ""]]}, {"id": "1208.2504", "submitter": "Benjamin Burton", "authors": "Benjamin A. Burton", "title": "Computational topology with Regina: Algorithms, heuristics and\n  implementations", "comments": "29 pages, 10 figures; v2: minor revisions. To appear in \"Geometry &\n  Topology Down Under\", Contemporary Mathematics, AMS", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.GT cs.CG cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regina is a software package for studying 3-manifold triangulations and\nnormal surfaces. It includes a graphical user interface and Python bindings,\nand also supports angle structures, census enumeration, combinatorial\nrecognition of triangulations, and high-level functions such as 3-sphere\nrecognition, unknot recognition and connected sum decomposition.\n  This paper brings 3-manifold topologists up-to-date with Regina as it appears\ntoday, and documents for the first time in the literature some of the key\nalgorithms, heuristics and implementations that are central to Regina's\nperformance. These include the all-important simplification heuristics, key\nchoices of data structures and algorithms to alleviate bottlenecks in normal\nsurface enumeration, modern implementations of 3-sphere recognition and\nconnected sum decomposition, and more. We also give some historical background\nfor the project, including the key role played by Rubinstein in its genesis 15\nyears ago, and discuss current directions for future development.\n", "versions": [{"version": "v1", "created": "Mon, 13 Aug 2012 06:22:37 GMT"}, {"version": "v2", "created": "Fri, 22 Feb 2013 10:24:48 GMT"}], "update_date": "2013-02-25", "authors_parsed": [["Burton", "Benjamin A.", ""]]}, {"id": "1208.2785", "submitter": "Sathish Govindarajan", "authors": "Pradeesha Ashok, Umair Azmi, Sathish Govindarajan", "title": "Small Strong Epsilon Nets", "comments": "19 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let P be a set of n points in $\\mathbb{R}^d$. A point x is said to be a\ncenterpoint of P if x is contained in every convex object that contains more\nthan $dn\\over d+1$ points of P. We call a point x a strong centerpoint for a\nfamily of objects $\\mathcal{C}$ if $x \\in P$ is contained in every object $C\n\\in \\mathcal{C}$ that contains more than a constant fraction of points of P. A\nstrong centerpoint does not exist even for halfspaces in $\\mathbb{R}^2$. We\nprove that a strong centerpoint exists for axis-parallel boxes in\n$\\mathbb{R}^d$ and give exact bounds. We then extend this to small strong\n$\\epsilon$-nets in the plane and prove upper and lower bounds for\n$\\epsilon_i^\\mathcal{S}$ where $\\mathcal{S}$ is the family of axis-parallel\nrectangles, halfspaces and disks. Here $\\epsilon_i^\\mathcal{S}$ represents the\nsmallest real number in $[0,1]$ such that there exists an\n$\\epsilon_i^\\mathcal{S}$-net of size i with respect to $\\mathcal{S}$.\n", "versions": [{"version": "v1", "created": "Tue, 14 Aug 2012 05:05:11 GMT"}], "update_date": "2012-08-15", "authors_parsed": [["Ashok", "Pradeesha", ""], ["Azmi", "Umair", ""], ["Govindarajan", "Sathish", ""]]}, {"id": "1208.3124", "submitter": "Daniel Reem", "authors": "Daniel Reem", "title": "On the computation of zone and double zone diagrams", "comments": "Very slight improvements (mainly correction of a few typos); add DOI;\n  Ref [51] points to a freely available computer application which implements\n  the algorithms; to appear in Discrete & Computational Geometry (available\n  online)", "journal-ref": "Discrete Comput. Geom. 59 (2018), 253--292", "doi": "10.1007/s00454-017-9958-8", "report-no": null, "categories": "cs.CG math.FA math.MG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical objects in computational geometry are defined by explicit\nrelations. Several years ago the pioneering works of T. Asano, J. Matousek and\nT. Tokuyama introduced \"implicit computational geometry\", in which the\ngeometric objects are defined by implicit relations involving sets. An\nimportant member in this family is called \"a zone diagram\". The implicit nature\nof zone diagrams implies, as already observed in the original works, that their\ncomputation is a challenging task. In a continuous setting this task has been\naddressed (briefly) only by these authors in the Euclidean plane with point\nsites. We discuss the possibility to compute zone diagrams in a wide class of\nspaces and also shed new light on their computation in the original setting.\nThe class of spaces, which is introduced here, includes, in particular,\nEuclidean spheres and finite dimensional strictly convex normed spaces. Sites\nof a general form are allowed and it is shown that a generalization of the\niterative method suggested by Asano, Matousek and Tokuyama converges to a\ndouble zone diagram, another implicit geometric object whose existence is known\nin general. Occasionally a zone diagram can be obtained from this procedure.\nThe actual (approximate) computation of the iterations is based on a simple\nalgorithm which enables the approximate computation of Voronoi diagrams in a\ngeneral setting. Our analysis also yields a few byproducts of independent\ninterest, such as certain topological properties of Voronoi cells (e.g., that\nin the considered setting their boundaries cannot be \"fat\").\n", "versions": [{"version": "v1", "created": "Tue, 14 Aug 2012 16:19:13 GMT"}, {"version": "v2", "created": "Tue, 4 Dec 2012 19:19:36 GMT"}, {"version": "v3", "created": "Mon, 29 Apr 2013 04:03:25 GMT"}, {"version": "v4", "created": "Tue, 25 Apr 2017 12:33:11 GMT"}, {"version": "v5", "created": "Wed, 29 Nov 2017 18:10:54 GMT"}, {"version": "v6", "created": "Sun, 31 Dec 2017 18:59:07 GMT"}], "update_date": "2018-02-08", "authors_parsed": [["Reem", "Daniel", ""]]}, {"id": "1208.3324", "submitter": "Alexei Uteshev", "authors": "Alexei Yu. Uteshev", "title": "Analytical Solution for the Generalized Fermat-Torricelli Problem", "comments": "15 pages, 3 figures", "journal-ref": "Amer.Math.Monthly. 121(4), 318-331, 2014", "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present explicit analytical solution for the problem of minimization of\nthe function $ F(x,y)= \\sum_{j=1}^3 m_j \\sqrt{(x-x_j)^2+(y-y_j)^2} $, i.e. we\nfind the coordinates of stationary point and the corresponding critical value\nof $ F(x,y) $ as functions of $ {m_j,x_j,y_j}_{j=1}^3 $. In addition, we also\ndiscuss inverse problem of finding such values of $ m_1,m_2,m_3 $ with the aim\nfor the corresponding function $ F $ to posses a prescribed position of\nstationary point.\n", "versions": [{"version": "v1", "created": "Thu, 16 Aug 2012 09:37:39 GMT"}], "update_date": "2014-04-08", "authors_parsed": [["Uteshev", "Alexei Yu.", ""]]}, {"id": "1208.3384", "submitter": "Pankaj Agarwal", "authors": "Pankaj K. Agarwal, Jiri Matousek, Micha Sharir", "title": "On Range Searching with Semialgebraic Sets II", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $P$ be a set of $n$ points in $\\R^d$. We present a linear-size data\nstructure for answering range queries on $P$ with constant-complexity\nsemialgebraic sets as ranges, in time close to $O(n^{1-1/d})$. It essentially\nmatches the performance of similar structures for simplex range searching, and,\nfor $d\\ge 5$, significantly improves earlier solutions by the first two authors\nobtained in~1994. This almost settles a long-standing open problem in range\nsearching.\n  The data structure is based on the polynomial-partitioning technique of Guth\nand Katz [arXiv:1011.4105], which shows that for a parameter $r$, $1 < r \\le\nn$, there exists a $d$-variate polynomial $f$ of degree $O(r^{1/d})$ such that\neach connected component of $\\R^d\\setminus Z(f)$ contains at most $n/r$ points\nof $P$, where $Z(f)$ is the zero set of $f$. We present an efficient randomized\nalgorithm for computing such a polynomial partition, which is of independent\ninterest and is likely to have additional applications.\n", "versions": [{"version": "v1", "created": "Thu, 16 Aug 2012 14:42:38 GMT"}, {"version": "v2", "created": "Sun, 16 Sep 2012 03:01:47 GMT"}, {"version": "v3", "created": "Thu, 30 May 2013 18:35:17 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Agarwal", "Pankaj K.", ""], ["Matousek", "Jiri", ""], ["Sharir", "Micha", ""]]}, {"id": "1208.3663", "submitter": "Matias Korman", "authors": "Luis Barba, Matias Korman, Stefan Langerman, Kunikiko Sadakane and\n  Rodrigo Silveira", "title": "Space-Time Trade-offs for Stack-Based Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In memory-constrained algorithms we have read-only access to the input, and\nthe number of additional variables is limited. In this paper we introduce the\ncompressed stack technique, a method that allows to transform algorithms whose\nspace bottleneck is a stack into memory-constrained algorithms. Given an\nalgorithm \\alg\\ that runs in O(n) time using $\\Theta(n)$ variables, we can\nmodify it so that it runs in $O(n^2/s)$ time using a workspace of O(s)\nvariables (for any $s\\in o(\\log n)$) or $O(n\\log n/\\log p)$ time using $O(p\\log\nn/\\log p)$ variables (for any $2\\leq p\\leq n$). We also show how the technique\ncan be applied to solve various geometric problems, namely computing the convex\nhull of a simple polygon, a triangulation of a monotone polygon, the shortest\npath between two points inside a monotone polygon, 1-dimensional pyramid\napproximation of a 1-dimensional vector, and the visibility profile of a point\ninside a simple polygon. Our approach exceeds or matches the best-known results\nfor these problems in constant-workspace models (when they exist), and gives\nthe first trade-off between the size of the workspace and running time. To the\nbest of our knowledge, this is the first general framework for obtaining\nmemory-constrained algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 17 Aug 2012 19:39:34 GMT"}, {"version": "v2", "created": "Mon, 20 Aug 2012 17:20:35 GMT"}, {"version": "v3", "created": "Mon, 8 Apr 2013 13:11:26 GMT"}, {"version": "v4", "created": "Thu, 11 Apr 2013 08:04:14 GMT"}, {"version": "v5", "created": "Wed, 25 Jun 2014 14:08:38 GMT"}], "update_date": "2014-06-26", "authors_parsed": [["Barba", "Luis", ""], ["Korman", "Matias", ""], ["Langerman", "Stefan", ""], ["Sadakane", "Kunikiko", ""], ["Silveira", "Rodrigo", ""]]}, {"id": "1208.5018", "submitter": "Tamal Dey", "authors": "Tamal K. Dey, Fengtao Fan, Yusu Wang", "title": "Computing Topological Persistence for Simplicial Maps", "comments": "This is the revised and full version of the paper that is going to\n  appear in the Proceedings of 30th Annual Symposium on Computational Geometry", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG math.AT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithms for persistent homology and zigzag persistent homology are\nwell-studied for persistence modules where homomorphisms are induced by\ninclusion maps. In this paper, we propose a practical algorithm for computing\npersistence under $\\mathbb{Z}_2$ coefficients for a sequence of general\nsimplicial maps and show how these maps arise naturally in some applications of\ntopological data analysis.\n  First, we observe that it is not hard to simulate simplicial maps by\ninclusion maps but not necessarily in a monotone direction. This, combined with\nthe known algorithms for zigzag persistence, provides an algorithm for\ncomputing the persistence induced by simplicial maps.\n  Our main result is that the above simple minded approach can be improved for\na sequence of simplicial maps given in a monotone direction. A simplicial map\ncan be decomposed into a set of elementary inclusions and vertex collapses--two\natomic operations that can be supported efficiently with the notion of simplex\nannotations for computing persistent homology. A consistent annotation through\nthese atomic operations implies the maintenance of a consistent cohomology\nbasis, hence a homology basis by duality. While the idea of maintaining a\ncohomology basis through an inclusion is not new, maintaining them through a\nvertex collapse is new, which constitutes an important atomic operation for\nsimulating simplicial maps. Annotations support the vertex collapse in addition\nto the usual inclusion quite naturally.\n  Finally, we exhibit an application of this new tool in which we approximate\nthe persistence diagram of a filtration of Rips complexes where vertex\ncollapses are used to tame the blow-up in size.\n", "versions": [{"version": "v1", "created": "Fri, 24 Aug 2012 17:46:21 GMT"}, {"version": "v2", "created": "Wed, 7 Nov 2012 16:40:22 GMT"}, {"version": "v3", "created": "Tue, 2 Apr 2013 15:22:14 GMT"}, {"version": "v4", "created": "Tue, 25 Mar 2014 17:26:00 GMT"}], "update_date": "2014-03-26", "authors_parsed": [["Dey", "Tamal K.", ""], ["Fan", "Fengtao", ""], ["Wang", "Yusu", ""]]}, {"id": "1208.5045", "submitter": "Daniel Reem", "authors": "Daniel Reem", "title": "On the existence of a neutral region", "comments": "22 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG math.FA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a given space, e.g., the Euclidean plane, and its decomposition into\nVoronoi regions induced by given sites. It seems intuitively clear that each\npoint in the space belongs to at least one of the regions, i.e., no neutral\nregion can exist. As simple counterexamples show this is not true in general,\nbut we present a simple necessary and sufficient condition ensuring the\nnon-existence of a neutral region. We discuss a similar phenomenon concerning\nrecent variations of Voronoi diagrams called zone diagrams, double zone\ndiagrams, and (double) territory diagrams. These objects are defined in a\nsomewhat implicit way and they also induce a decomposition of the space into\nregions. In several works it was claimed without providing a proof that some of\nthese objects induce a decomposition in which a neutral region must exist. We\nshow that this assertion is true in a wide class of cases but not in general.\nWe also discuss other properties related to the neutral region, among them a\none related to the concentration of measure phenomenon.\n", "versions": [{"version": "v1", "created": "Fri, 17 Aug 2012 19:28:36 GMT"}], "update_date": "2012-08-27", "authors_parsed": [["Reem", "Daniel", ""]]}, {"id": "1208.5247", "submitter": "Tsvi Kopelowitz", "authors": "Tsvi Kopelowitz and Robert Krauthgamer", "title": "Faster Clustering via Preprocessing", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine the efficiency of clustering a set of points, when the\nencompassing metric space may be preprocessed in advance. In computational\nproblems of this genre, there is a first stage of preprocessing, whose input is\na collection of points $M$; the next stage receives as input a query set\n$Q\\subset M$, and should report a clustering of $Q$ according to some\nobjective, such as 1-median, in which case the answer is a point $a\\in M$\nminimizing $\\sum_{q\\in Q} d_M(a,q)$.\n  We design fast algorithms that approximately solve such problems under\nstandard clustering objectives like $p$-center and $p$-median, when the metric\n$M$ has low doubling dimension. By leveraging the preprocessing stage, our\nalgorithms achieve query time that is near-linear in the query size $n=|Q|$,\nand is (almost) independent of the total number of points $m=|M|$.\n", "versions": [{"version": "v1", "created": "Sun, 26 Aug 2012 20:03:04 GMT"}], "update_date": "2012-08-28", "authors_parsed": [["Kopelowitz", "Tsvi", ""], ["Krauthgamer", "Robert", ""]]}, {"id": "1208.5289", "submitter": "David Wood", "authors": "Michael S. Payne and David R. Wood", "title": "On the general position subset selection problem", "comments": null, "journal-ref": "SIAM J. Discrete Math. 27:1727-1733, 2013", "doi": "10.1137/120897493", "report-no": null, "categories": "math.CO cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $f(n,\\ell)$ be the maximum integer such that every set of $n$ points in\nthe plane with at most $\\ell$ collinear contains a subset of $f(n,\\ell)$ points\nwith no three collinear. First we prove that if $\\ell \\leq O(\\sqrt{n})$ then\n$f(n,\\ell)\\geq \\Omega(\\sqrt{\\frac{n}{\\ln \\ell}})$. Second we prove that if\n$\\ell \\leq O(n^{(1-\\epsilon)/2})$ then $f(n,\\ell) \\geq \\Omega(\\sqrt{n\\log_\\ell\nn})$, which implies all previously known lower bounds on $f(n,\\ell)$ and\nimproves them when $\\ell$ is not fixed. A more general problem is to consider\nsubsets with at most $k$ collinear points in a point set with at most $\\ell$\ncollinear. We also prove analogous results in this setting.\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2012 04:08:33 GMT"}, {"version": "v2", "created": "Tue, 23 Oct 2012 21:54:54 GMT"}], "update_date": "2016-02-09", "authors_parsed": [["Payne", "Michael S.", ""], ["Wood", "David R.", ""]]}, {"id": "1208.5752", "submitter": "Carolyn Phillips", "authors": "Carolyn L. Phillips, Joshua A. Anderson, Elizabeth R. Chen, Sharon C.\n  Glotzer", "title": "Optimal Fillings - A new spatial subdivision problem related to packing\n  and covering", "comments": "38 pages, 21 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cond-mat.soft cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present filling as a new type of spatial subdivision problem that is\nrelated to covering and packing. Filling addresses the optimal placement of\noverlapping objects lying entirely inside an arbitrary shape so as to cover the\nmost interior volume. In n-dimensional space, if the objects are polydisperse\nn-balls, we show that solutions correspond to sets of maximal n-balls and the\nsolution space can reduced to the medial axis of a shape. We examine the\nstructure of the solution space in two dimensions. For the filling of polygons,\nwe provide detailed descriptions of a heuristic and a genetic algorithm for\nfinding solutions of maximal discs. We also consider the properties of ideal\ndistributions of N discs in polygons as N approaches infinity.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2012 19:15:33 GMT"}], "update_date": "2012-08-29", "authors_parsed": [["Phillips", "Carolyn L.", ""], ["Anderson", "Joshua A.", ""], ["Chen", "Elizabeth R.", ""], ["Glotzer", "Sharon C.", ""]]}, {"id": "1208.6188", "submitter": "Dara Shayda", "authors": "Dara O. Shayda", "title": "G2 Matrix Manifold: A Software Construct", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An ensemble of symbolic, numeric and graphic computations developed to\nconstruct the Octonionic and compact G2 structures in Mathematica 8.0.\nCayley-Dickenson Construction symbolically applied from Reals to Octonions.\nBaker- Campbell-Hausdorff formula (BCH) in bracket form verified for Octonions.\nAlgorithms for both exponentiation and logarithm of Octonions developed.\nExclusive validity of vector Product verified for 0, 1, 3 and 7 dimensions.\nSymbolic exponential computations carried out for two distinct g2 basis(s) and\narbitrary precision BCH for G2 was coded. Example and counter-example Maximal\nTorus for G2 was uncovered. Densely coiled shapes of actions of G2 rendered.\nKolmogorov Complexity for BCH investigated and upper bounds computed:\nComplexity of non-commutative non- associative algebraic expression is at most\nthe Complexity of corresponding commutative associative algebra plus K(BCH).\n", "versions": [{"version": "v1", "created": "Tue, 14 Aug 2012 21:00:07 GMT"}], "update_date": "2012-08-31", "authors_parsed": [["Shayda", "Dara O.", ""]]}, {"id": "1208.6523", "submitter": "David Guenther", "authors": "Jan Reininghaus (1) and David G\\\"unther (2) and Ingrid Hotz (3) and\n  Tino Weinkauf (2) and Hans Peter Seidel (2) ((1) Institute for Science and\n  Technology Austria, (2) MPI for Informatics Germany, (3) Zuse-Insitute Berlin\n  Germany)", "title": "Combinatorial Gradient Fields for 2D Images with Empirically Convergent\n  Separatrices", "comments": "17 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CG cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an efficient probabilistic method that computes\ncombinatorial gradient fields for two dimensional image data. In contrast to\nexisting algorithms, this approach yields a geometric Morse-Smale complex that\nconverges almost surely to its continuous counterpart when the image resolution\nis increased. This approach is motivated using basic ideas from probability\ntheory and builds upon an algorithm from discrete Morse theory with a strong\nmathematical foundation. While a formal proof is only hinted at, we do provide\na thorough numerical evaluation of our method and compare it to established\nalgorithms.\n", "versions": [{"version": "v1", "created": "Fri, 31 Aug 2012 15:19:09 GMT"}], "update_date": "2012-09-03", "authors_parsed": [["Reininghaus", "Jan", ""], ["G\u00fcnther", "David", ""], ["Hotz", "Ingrid", ""], ["Weinkauf", "Tino", ""], ["Seidel", "Hans Peter", ""]]}]