[{"id": "1204.0547", "submitter": "Ruy Fabila-Monroy", "authors": "Jos\\'e M. D\\'iaz-Ba\\~nez and Ruy Fabila-Monroy and Pablo\n  P\\'erez-Lantero", "title": "On the number of radial orderings of planar point sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a set $S$ of $n$ points in the plane, a \\emph{radial ordering} of $S$\nwith respect to a point $p$ (not in $S$) is a clockwise circular ordering of\nthe elements in $S$ by angle around $p$. If $S$ is two-colored, a \\emph{colored\nradial ordering} is a radial ordering of $S$ in which only the colors of the\npoints are considered. In this paper, we obtain bounds on the number of\ndistinct non-colored and colored radial orderings of $S$. We assume a strong\ngeneral position on $S$, not three points are collinear and not three\nlines---each passing through a pair of points in $S$---intersect in a point of\n$\\R^2\\setminus S$. In the colored case, $S$ is a set of $2n$ points partitioned\ninto $n$ red and $n$ blue points, and $n$ is even. We prove that: the number of\ndistinct radial orderings of $S$ is at most $O(n^4)$ and at least\n$\\Omega(n^3)$; the number of colored radial orderings of $S$ is at most\n$O(n^4)$ and at least $\\Omega(n)$; there exist sets of points with\n$\\Theta(n^4)$ colored radial orderings and sets of points with only $O(n^2)$\ncolored radial orderings.\n", "versions": [{"version": "v1", "created": "Mon, 2 Apr 2012 22:15:57 GMT"}], "update_date": "2012-04-04", "authors_parsed": [["D\u00edaz-Ba\u00f1ez", "Jos\u00e9 M.", ""], ["Fabila-Monroy", "Ruy", ""], ["P\u00e9rez-Lantero", "Pablo", ""]]}, {"id": "1204.0660", "submitter": "Sergio Cabello", "authors": "Sergio Cabello", "title": "Hardness of approximation for crossing number", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that, if P\\not=NP, there is a constant c > 1 such that there is no\nc-approximation algorithm for the crossing number, even when restricted to\n3-regular graphs.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2012 11:32:13 GMT"}], "update_date": "2012-04-04", "authors_parsed": [["Cabello", "Sergio", ""]]}, {"id": "1204.0747", "submitter": "Anil Hirani", "authors": "Anil N. Hirani, Kaushik Kalyanaraman, Evan B. VanderZee", "title": "Delaunay Hodge Star", "comments": "Corrected error in Figure 1 (columns 3 and 4) and Figure 6 and a\n  formula error in Section 2. All mathematical statements (theorems and lemmas)\n  are unchanged. The previous arXiv version v3 (minus the Appendix) appeared in\n  the journal Computer-Aided Design", "journal-ref": "Computer-Aided Design, Volume 45, Issue 2, 2013, pages 540-544", "doi": "10.1016/j.cad.2012.10.038", "report-no": null, "categories": "cs.CG math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define signed dual volumes at all dimensions for circumcentric dual\nmeshes. We show that for pairwise Delaunay triangulations with mild boundary\nassumptions these signed dual volumes are positive. This allows the use of such\nDelaunay meshes for Discrete Exterior Calculus (DEC) because the discrete Hodge\nstar operator can now be correctly defined for such meshes. This operator is\ncrucial for DEC and is a diagonal matrix with the ratio of primal and dual\nvolumes along the diagonal. A correct definition requires that all entries be\npositive. DEC is a framework for numerically solving differential equations on\nmeshes and for geometry processing tasks and has had considerable impact in\ncomputer graphics and scientific computing. Our result allows the use of DEC\nwith a much larger class of meshes than was previously considered possible.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2012 17:51:07 GMT"}, {"version": "v2", "created": "Fri, 22 Jun 2012 19:38:35 GMT"}, {"version": "v3", "created": "Fri, 10 Aug 2012 18:11:25 GMT"}, {"version": "v4", "created": "Wed, 9 Aug 2017 15:02:08 GMT"}], "update_date": "2017-08-10", "authors_parsed": [["Hirani", "Anil N.", ""], ["Kalyanaraman", "Kaushik", ""], ["VanderZee", "Evan B.", ""]]}, {"id": "1204.0824", "submitter": "C. Seshadhri", "authors": "Kenneth L. Clarkson, Wolfgang Mulzer, C. Seshadhri", "title": "Self-improving Algorithms for Coordinate-wise Maxima", "comments": "To appear in Symposium of Computational Geometry 2012 (17 pages, 2\n  figures)", "journal-ref": "SIAM Journal on Computing (SICOMP), 43(2), 2014, pp. 617-653", "doi": "10.1137/12089702X", "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computing the coordinate-wise maxima of a planar point set is a classic and\nwell-studied problem in computational geometry. We give an algorithm for this\nproblem in the \\emph{self-improving setting}. We have $n$ (unknown) independent\ndistributions $\\cD_1, \\cD_2, ..., \\cD_n$ of planar points. An input pointset\n$(p_1, p_2, ..., p_n)$ is generated by taking an independent sample $p_i$ from\neach $\\cD_i$, so the input distribution $\\cD$ is the product $\\prod_i \\cD_i$. A\nself-improving algorithm repeatedly gets input sets from the distribution $\\cD$\n(which is \\emph{a priori} unknown) and tries to optimize its running time for\n$\\cD$. Our algorithm uses the first few inputs to learn salient features of the\ndistribution, and then becomes an optimal algorithm for distribution $\\cD$. Let\n$\\OPT_\\cD$ denote the expected depth of an \\emph{optimal} linear comparison\ntree computing the maxima for distribution $\\cD$. Our algorithm eventually has\nan expected running time of $O(\\text{OPT}_\\cD + n)$, even though it did not\nknow $\\cD$ to begin with.\n  Our result requires new tools to understand linear comparison trees for\ncomputing maxima. We show how to convert general linear comparison trees to\nvery restricted versions, which can then be related to the running time of our\nalgorithm. An interesting feature of our algorithm is an interleaved search,\nwhere the algorithm tries to determine the likeliest point to be maximal with\nminimal computation. This allows the running time to be truly optimal for the\ndistribution $\\cD$.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2012 22:42:57 GMT"}], "update_date": "2014-04-29", "authors_parsed": [["Clarkson", "Kenneth L.", ""], ["Mulzer", "Wolfgang", ""], ["Seshadhri", "C.", ""]]}, {"id": "1204.0905", "submitter": "Jin-San Cheng", "authors": "Jin-San Cheng, Kai Jin, Xiao-Shan Gao and Daniel Lazard", "title": "Certified Rational Parametric Approximation of Real Algebraic Space\n  Curves with Local Generic Position Method", "comments": "12 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, an algorithm to compute a certified $G^1$ rational parametric\napproximation for algebraic space curves is given by extending the local\ngeneric position method for solving zero dimensional polynomial equation\nsystems to the case of dimension one. By certified, we mean the approximation\ncurve and the original curve have the same topology and their Hausdauff\ndistance is smaller than a given precision. Thus, the method also gives a new\nalgorithm to compute the topology for space algebraic curves. The main\nadvantage of the algorithm, inhering from the local generic method, is that\ntopology computation and approximation for a space curve is directly reduced to\nthe same tasks for two plane curves. In particular, the error bound of the\napproximation space curve is obtained from the error bounds of the\napproximation plane curves explicitly. Nontrivial examples are used to show the\neffectivity of the method.\n", "versions": [{"version": "v1", "created": "Wed, 4 Apr 2012 09:54:59 GMT"}], "update_date": "2012-04-05", "authors_parsed": [["Cheng", "Jin-San", ""], ["Jin", "Kai", ""], ["Gao", "Xiao-Shan", ""], ["Lazard", "Daniel", ""]]}, {"id": "1204.1086", "submitter": "Seth Pettie", "authors": "Seth Pettie", "title": "Sharp Bounds on Davenport-Schinzel Sequences of Every Order", "comments": "A 10-page extended abstract will appear in the Proceedings of the\n  Symposium on Computational Geometry, 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CG math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the longest-standing open problems in computational geometry is to\nbound the lower envelope of $n$ univariate functions, each pair of which\ncrosses at most $s$ times, for some fixed $s$. This problem is known to be\nequivalent to bounding the length of an order-$s$ Davenport-Schinzel sequence,\nnamely a sequence over an $n$-letter alphabet that avoids alternating\nsubsequences of the form $a \\cdots b \\cdots a \\cdots b \\cdots$ with length\n$s+2$. These sequences were introduced by Davenport and Schinzel in 1965 to\nmodel a certain problem in differential equations and have since been applied\nto bounding the running times of geometric algorithms, data structures, and the\ncombinatorial complexity of geometric arrangements.\n  Let $\\lambda_s(n)$ be the maximum length of an order-$s$ DS sequence over $n$\nletters. What is $\\lambda_s$ asymptotically? This question has been answered\nsatisfactorily (by Hart and Sharir, Agarwal, Sharir, and Shor, Klazar, and\nNivasch) when $s$ is even or $s\\le 3$. However, since the work of Agarwal,\nSharir, and Shor in the mid-1980s there has been a persistent gap in our\nunderstanding of the odd orders.\n  In this work we effectively close the problem by establishing sharp bounds on\nDavenport-Schinzel sequences of every order $s$. Our results reveal that,\ncontrary to one's intuition, $\\lambda_s(n)$ behaves essentially like\n$\\lambda_{s-1}(n)$ when $s$ is odd. This refutes conjectures due to Alon et al.\n(2008) and Nivasch (2010).\n", "versions": [{"version": "v1", "created": "Wed, 4 Apr 2012 22:24:14 GMT"}, {"version": "v2", "created": "Sat, 18 May 2013 18:05:53 GMT"}], "update_date": "2013-05-21", "authors_parsed": [["Pettie", "Seth", ""]]}, {"id": "1204.1672", "submitter": "Gabriele Fici", "authors": "Gabriele Fici", "title": "A Characterization of Bispecial Sturmian Words", "comments": "Accepted to MFCS 2012", "journal-ref": "LNCS 7464, pp. 383-394, 2012", "doi": "10.1007/978-3-642-32589-2_35", "report-no": null, "categories": "cs.FL cs.CG cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A finite Sturmian word w over the alphabet {a,b} is left special (resp. right\nspecial) if aw and bw (resp. wa and wb) are both Sturmian words. A bispecial\nSturmian word is a Sturmian word that is both left and right special. We show\nas a main result that bispecial Sturmian words are exactly the maximal internal\nfactors of Christoffel words, that are words coding the digital approximations\nof segments in the Euclidean plane. This result is an extension of the known\nrelation between central words and primitive Christoffel words. Our\ncharacterization allows us to give an enumerative formula for bispecial\nSturmian words. We also investigate the minimal forbidden words for the set of\nSturmian words.\n", "versions": [{"version": "v1", "created": "Sat, 7 Apr 2012 18:56:05 GMT"}, {"version": "v2", "created": "Wed, 11 Apr 2012 20:08:21 GMT"}, {"version": "v3", "created": "Mon, 11 Jun 2012 11:47:23 GMT"}, {"version": "v4", "created": "Mon, 18 Jun 2012 16:25:36 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Fici", "Gabriele", ""]]}, {"id": "1204.1873", "submitter": "Bahman Kalantari", "authors": "Bahman Kalantari", "title": "A Characterization Theorem and An Algorithm for A Convex Hull Problem", "comments": "42 pages, 17 figures, 2 tables. This revision only corrects minor\n  typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given $S= \\{v_1, \\dots, v_n\\} \\subset \\mathbb{R} ^m$ and $p \\in \\mathbb{R}\n^m$, testing if $p \\in conv(S)$, the convex hull of $S$, is a fundamental\nproblem in computational geometry and linear programming. First, we prove a\nEuclidean {\\it distance duality}, distinct from classical separation theorems\nsuch as Farkas Lemma: $p$ lies in $conv(S)$ if and only if for each $p' \\in\nconv(S)$ there exists a {\\it pivot}, $v_j \\in S$ satisfying $d(p',v_j) \\geq\nd(p,v_j)$. Equivalently, $p \\not \\in conv(S)$ if and only if there exists a\n{\\it witness}, $p' \\in conv(S)$ whose Voronoi cell relative to $p$ contains\n$S$. A witness separates $p$ from $conv(S)$ and approximate $d(p, conv(S))$ to\nwithin a factor of two. Next, we describe the {\\it Triangle Algorithm}: given\n$\\epsilon \\in (0,1)$, an {\\it iterate}, $p' \\in conv(S)$, and $v \\in S$, if\n$d(p, p') < \\epsilon d(p,v)$, it stops. Otherwise, if there exists a pivot\n$v_j$, it replace $v$ with $v_j$ and $p'$ with the projection of $p$ onto the\nline $p'v_j$. Repeating this process, the algorithm terminates in $O(mn \\min\n\\{\\epsilon^{-2}, c^{-1}\\ln \\epsilon^{-1} \\})$ arithmetic operations, where $c$\nis the {\\it visibility factor}, a constant satisfying $c \\geq \\epsilon^2$ and\n$\\sin (\\angle pp'v_j) \\leq 1/\\sqrt{1+c}$, over all iterates $p'$. Additionally,\n(i) we prove a {\\it strict distance duality} and a related minimax theorem,\nresulting in more effective pivots; (ii) describe $O(mn \\ln\n\\epsilon^{-1})$-time algorithms that may compute a witness or a good\napproximate solution; (iii) prove {\\it generalized distance duality} and\ndescribe a corresponding generalized Triangle Algorithm; (iv) prove a {\\it\nsensitivity theorem} to analyze the complexity of solving LP feasibility via\nthe Triangle Algorithm. The Triangle Algorithm is practical and competitive\nwith the simplex method, sparse greedy approximation and first-order methods.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2012 13:44:44 GMT"}, {"version": "v2", "created": "Fri, 12 Oct 2012 03:59:32 GMT"}, {"version": "v3", "created": "Fri, 19 Jul 2013 05:54:06 GMT"}, {"version": "v4", "created": "Sun, 13 Oct 2013 20:51:04 GMT"}], "update_date": "2013-10-15", "authors_parsed": [["Kalantari", "Bahman", ""]]}, {"id": "1204.2034", "submitter": "Pablo P\\'erez-Lantero", "authors": "J. Barbay and G. Navarro and P. P\\'erez-Lantero", "title": "Adaptive Techniques to find Optimal Planar Boxes", "comments": "18 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a set $P$ of $n$ planar points, two axes and a real-valued score\nfunction $f()$ on subsets of $P$, the Optimal Planar Box problem consists in\nfinding a box (i.e. axis-aligned rectangle) $H$ maximizing $f(H\\cap P)$. We\nconsider the case where $f()$ is monotone decomposable, i.e. there exists a\ncomposition function $g()$ monotone in its two arguments such that\n$f(A)=g(f(A_1),f(A_2))$ for every subset $A\\subseteq P$ and every partition\n$\\{A_1,A_2\\}$ of $A$. In this context we propose a solution for the Optimal\nPlanar Box problem which performs in the worst case $O(n^2\\lg n)$ score\ncompositions and coordinate comparisons, and much less on other classes of\ninstances defined by various measures of difficulty. A side result of its own\ninterest is a fully dynamic \\textit{MCS Splay tree} data structure supporting\ninsertions and deletions with the \\emph{dynamic finger} property, improving\nupon previous results [Cort\\'es et al., J.Alg. 2009].\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2012 02:58:52 GMT"}], "update_date": "2012-04-11", "authors_parsed": [["Barbay", "J.", ""], ["Navarro", "G.", ""], ["P\u00e9rez-Lantero", "P.", ""]]}, {"id": "1204.2214", "submitter": "Bata Vasic Mr.", "authors": "Bata Vasic and Bane Vasic", "title": "Simplification Resilient LDPC-Coded Sparse-QIM Watermarking for\n  3D-Meshes", "comments": "Submitted, revised and Copyright transfered to IEEE Transactions on\n  Multimedia, October 9th 2012", "journal-ref": null, "doi": "10.1109/TMM.2013.2265673", "report-no": "MM-004273 - 11984709_File000000_225764737", "categories": "cs.MM cs.CG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a blind watermarking scheme for 3-D meshes which combines sparse\nquantization index modulation (QIM) with deletion correction codes. The QIM\noperates on the vertices in rough concave regions of the surface thus ensuring\nimpeccability, while the deletion correction code recovers the data hidden in\nthe vertices which is removed by mesh optimization and/or simplification. The\nproposed scheme offers two orders of magnitude better performance in terms of\nrecovered watermark bit error rate compared to the existing schemes of similar\npayloads and fidelity constraints.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2012 16:41:33 GMT"}, {"version": "v2", "created": "Tue, 6 Nov 2012 18:04:51 GMT"}, {"version": "v3", "created": "Thu, 25 Jul 2013 17:25:32 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Vasic", "Bata", ""], ["Vasic", "Bane", ""]]}, {"id": "1204.2260", "submitter": "Jeff Jones mr", "authors": "Emanuele Strano, Andrew Adamatzky, Jeff Jones", "title": "Vie Physarale: Evaluation of Roman roads with slime mould", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Roman Empire is renowned for sharp logical design and outstanding building\nquality of its road system. Many roads built by Romans are still use in\ncontinental Europe and UK. The Roman roads were built for military\ntransportations with efficiency in mind, as straight as possible. Thus the\nroads make an ideal test-bed for developing experimental laboratory techniques\nfor evaluating man-made transport systems using living creatures. We imitate\ndevelopment of road networks in Iron Age Italy using slime mould Physarum\npolycephalum. We represent ten Roman cities with oat flakes, inoculate the\nslime mould in Roma, wait till slime mould spans all flakes-cities with its\nnetwork of protoplasmic tubes, and analyse structures of the protoplasmic\nnetworks. We found that most Roman roads, apart of those linking Placentia to\nBononia and Genua to Florenzia are represented in development of Physarum\npolycephalum. Transport networks developed by Romans and by slime mould show\nstrong affinity of planar proximity graphs, and particular minimum spanning\ntree. Based on laboratory experiments we reconstructed a speculative sequence\nof road development in Iron Age Italy.\n", "versions": [{"version": "v1", "created": "Sun, 8 Apr 2012 18:17:05 GMT"}], "update_date": "2012-04-11", "authors_parsed": [["Strano", "Emanuele", ""], ["Adamatzky", "Andrew", ""], ["Jones", "Jeff", ""]]}, {"id": "1204.2634", "submitter": "Subhas Nandy C.", "authors": "Minati De, Anil Maheshwari and Subhas C. Nandy", "title": "Space-efficient Algorithms for Visibility Problems in Simple Polygon", "comments": "15 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a simple polygon $P$ consisting of $n$ vertices, we study the problem\nof designing space-efficient algorithms for computing (i) the visibility\npolygon of a point inside $P$, (ii) the weak visibility polygon of a line\nsegment inside $P$ and (iii) the minimum link path between a pair of points\ninside $P$. For problem (i) two algorithms are proposed. The first one is an\nin-place algorithm where the input array may be lost. It uses only O(1) extra\nspace apart from the input array. The second one assumes that the input is\ngiven in a read-only array, and it needs $O(\\sqrt{n})$ extra space. The time\ncomplexity of both the algorithms are O(n). For problem (ii), we have assumed\nthat the input polygon is given in a read-only array. Our proposed algorithm\nruns in $O(n^2)$ time using O(1) extra space. For problem (iii) the time and\nspace complexities of our proposed algorithm are $O(kn)$ and O(1) respectively;\n$k$ is the length (number of links) in a minimum link path between the given\npair of points.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2012 07:07:33 GMT"}], "update_date": "2012-04-13", "authors_parsed": [["De", "Minati", ""], ["Maheshwari", "Anil", ""], ["Nandy", "Subhas C.", ""]]}, {"id": "1204.3105", "submitter": "Yuancheng Luo", "authors": "Yuancheng Luo and Ramani Duraiswami", "title": "Alternative Tilings for the Fast Multipole Method on the Plane", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fast multipole method (FMM) performs fast approximate kernel summation to\na specified tolerance $\\epsilon$ by using a hierarchical division of the\ndomain, which groups source and receiver points into regions that satisfy local\nseparation and the well-separated pair decomposition properties. While square\ntilings and quadtrees are commonly used in 2D, we investigate alternative\ntilings and associated spatial data structures: regular hexagons (septree) and\ntriangles (triangle-quadtree). We show that both structures satisfy separation\nproperties for the FMM and prove their theoretical error bounds and\ncomputational costs. Empirical runtime and error analysis of our\nimplementations are provided.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2012 20:49:34 GMT"}], "update_date": "2012-04-17", "authors_parsed": [["Luo", "Yuancheng", ""], ["Duraiswami", "Ramani", ""]]}, {"id": "1204.3569", "submitter": "Federico Librino", "authors": "Federico Librino, Marco Levorato and Michele Zorzi", "title": "An Algorithmic Solution for Computing Circle Intersection Areas and its\n  Applications to Wireless Communications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel iterative algorithm for the efficient computation of the intersection\nareas of an arbitrary number of circles is presented. The algorithm, based on a\ntrellis-structure, hinges on two geometric results which allow the\nexistence-check and the computation of the area of the intersection regions\ngenerated by more than three circles by simple algebraic manipulations of the\nintersection areas of a smaller number of circles. The presented algorithm is a\npowerful tool for the performance analysis of wireless networks, and finds many\napplications, ranging from sensor to cellular networks. As an example of\npractical application, an insightful study of the uplink outage probability of\nin a wireless network with cooperative access points as a function of the\ntransmission power and access point density is presented.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2012 16:55:50 GMT"}, {"version": "v2", "created": "Wed, 1 Aug 2012 16:33:01 GMT"}], "update_date": "2012-08-02", "authors_parsed": [["Librino", "Federico", ""], ["Levorato", "Marco", ""], ["Zorzi", "Michele", ""]]}, {"id": "1204.3850", "submitter": "Yann Disser", "authors": "J\\'er\\'emie Chalopin, Shantanu Das, Yann Disser, Mat\\'u\\v{s}\n  Mihal\\'ak, Peter Widmayer", "title": "Simple Agents Learn to Find Their Way: An Introduction on Mapping\n  Polygons", "comments": null, "journal-ref": "Discrete Applied Mathematics 161(10-11) (2013) 1287-1307", "doi": "10.1016/j.dam.2013.01.006", "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper gives an introduction to the problem of mapping simple polygons\nwith autonomous agents. We focus on minimalistic agents that move from vertex\nto vertex along straight lines inside a polygon, using their sensors to gather\nlocal observations at each vertex. Our attention revolves around the question\nwhether a given configuration of sensors and movement capabilities of the\nagents allows them to capture enough data in order to draw conclusions\nregarding the global layout of the polygon. In particular, we study the problem\nof reconstructing the visibility graph of a simple polygon by an agent moving\neither inside or on the boundary of the polygon. Our aim is to provide insight\nabout the algorithmic challenges faced by an agent trying to map a polygon. We\npresent an overview of techniques for solving this problem with agents that are\nequipped with simple sensorial capabilities. We illustrate these techniques on\nexamples with sensors that mea- sure angles between lines of sight or identify\nthe previous location. We give an overview over related problems in\ncombinatorial geometry as well as graph exploration.\n", "versions": [{"version": "v1", "created": "Thu, 16 Feb 2012 11:17:25 GMT"}], "update_date": "2018-12-10", "authors_parsed": [["Chalopin", "J\u00e9r\u00e9mie", ""], ["Das", "Shantanu", ""], ["Disser", "Yann", ""], ["Mihal\u00e1k", "Mat\u00fa\u0161", ""], ["Widmayer", "Peter", ""]]}, {"id": "1204.4107", "submitter": "Richard Preen", "authors": "Richard J. Preen and Larry Bull", "title": "Towards the Evolution of Vertical-Axis Wind Turbines using Supershapes", "comments": null, "journal-ref": "Evolutionary Intelligence (2014), 7(3):155-167", "doi": "10.1007/s12065-014-0116-4", "report-no": null, "categories": "cs.NE cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We have recently presented an initial study of evolutionary algorithms used\nto design vertical-axis wind turbines (VAWTs) wherein candidate prototypes are\nevaluated under approximated wind tunnel conditions after being physically\ninstantiated by a 3D printer. That is, unlike other approaches such as\ncomputational fluid dynamics simulations, no mathematical formulations are used\nand no model assumptions are made. However, the representation used\nsignificantly restricted the range of morphologies explored. In this paper, we\npresent initial explorations into the use of a simple generative encoding,\nknown as Gielis superformula, that produces a highly flexible 3D shape\nrepresentation to design VAWT. First, the target-based evolution of 3D\nartefacts is investigated and subsequently initial design experiments are\nperformed wherein each VAWT candidate is physically instantiated and evaluated\nunder approximated wind tunnel conditions. It is shown possible to produce very\nclosely matching designs of a number of 3D objects through the evolution of\nsupershapes produced by Gielis superformula. Moreover, it is shown possible to\nuse artificial physical evolution to identify novel and increasingly efficient\nsupershape VAWT designs.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2012 15:22:26 GMT"}, {"version": "v2", "created": "Sun, 22 Apr 2012 18:22:51 GMT"}, {"version": "v3", "created": "Sun, 20 Jul 2014 11:23:09 GMT"}, {"version": "v4", "created": "Mon, 15 Feb 2016 19:20:48 GMT"}], "update_date": "2016-02-16", "authors_parsed": [["Preen", "Richard J.", ""], ["Bull", "Larry", ""]]}, {"id": "1204.4374", "submitter": "Andreas Gemsa", "authors": "Andreas Gemsa, D. T. Lee, Chih-Hung Liu, Dorothea Wagner", "title": "Higher Order City Voronoi Diagrams", "comments": "15 pages, extended version of paper to appear in Proc. 13th\n  Scandinavian Symposium and Workshops on Algorithm Theory (SWAT'12), Helsinki,\n  Finland, 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate higher-order Voronoi diagrams in the city metric. This metric\nis induced by quickest paths in the L1 metric in the presence of an\naccelerating transportation network of axis-parallel line segments. For the\nstructural complexity of kth-order city Voronoi diagrams of n point sites, we\nshow an upper bound of O(k(n - k) + kc) and a lower bound of {\\Omega}(n + kc),\nwhere c is the complexity of the transportation network. This is quite\ndifferent from the bound O(k(n - k)) in the Euclidean metric. For the special\ncase where k = n - 1 the complexity in the Euclidean metric is O(n), while that\nin the city metric is {\\Theta}(nc).\n  Furthermore, we develop an O(k^2(n + c) log n)-time iterative algorithm to\ncompute the kth-order city Voronoi diagram and an O(nc log^2(n + c) log n)-time\ndivide-and-conquer algorithm to compute the farthest-site city Voronoi diagram.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2012 15:20:38 GMT"}], "update_date": "2012-04-20", "authors_parsed": [["Gemsa", "Andreas", ""], ["Lee", "D. T.", ""], ["Liu", "Chih-Hung", ""], ["Wagner", "Dorothea", ""]]}, {"id": "1204.4509", "submitter": "Yakov Nekrich", "authors": "Yakov Nekrich and Gonzalo Navarro", "title": "Sorted Range Reporting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider a variant of the orthogonal range reporting problem\nwhen all points should be reported in the sorted order of their\n$x$-coordinates. We show that reporting two-dimensional points with this\nadditional condition can be organized (almost) as efficiently as the standard\nrange reporting.\n  Moreover, our results generalize and improve the previously known results for\nthe orthogonal range successor problem and can be used to obtain better\nsolutions for some stringology problems.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2012 00:54:14 GMT"}, {"version": "v2", "created": "Wed, 25 Apr 2012 02:18:05 GMT"}], "update_date": "2012-04-26", "authors_parsed": [["Nekrich", "Yakov", ""], ["Navarro", "Gonzalo", ""]]}, {"id": "1204.4679", "submitter": "Pat Morin", "authors": "Prosenjit Bose, Vida Dujmovic, Pat Morin, and Michiel Smid", "title": "Robust Geometric Spanners", "comments": "18 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Highly connected and yet sparse graphs (such as expanders or graphs of high\ntreewidth) are fundamental, widely applicable and extensively studied\ncombinatorial objects. We initiate the study of such highly connected graphs\nthat are, in addition, geometric spanners. We define a property of spanners\ncalled robustness. Informally, when one removes a few vertices from a robust\nspanner, this harms only a small number of other vertices. We show that robust\nspanners must have a superlinear number of edges, even in one dimension. On the\npositive side, we give constructions, for any dimension, of robust spanners\nwith a near-linear number of edges.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2012 17:19:13 GMT"}, {"version": "v2", "created": "Fri, 14 Jun 2013 14:44:51 GMT"}], "update_date": "2013-06-17", "authors_parsed": [["Bose", "Prosenjit", ""], ["Dujmovic", "Vida", ""], ["Morin", "Pat", ""], ["Smid", "Michiel", ""]]}, {"id": "1204.4714", "submitter": "Joseph Simons", "authors": "Maarten L\\\"offler, Joe Simons, Darren Strash", "title": "Dynamic Planar Point Location with Sub-Logarithmic Local Updates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study planar point location in a collection of disjoint fat regions, and\ninvestigate the complexity of \\emph {local updates}: replacing any region by a\ndifferent region that is \"similar\" to the original region. (i.e., the size\ndiffers by at most a constant factor, and distance between the two regions is a\nconstant times that size). We show that it is possible to create a linear size\ndata structure that allows for insertions, deletions, and queries in\nlogarithmic time, and allows for local updates in sub-logarithmic time on a\npointer machine.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2012 19:47:45 GMT"}, {"version": "v2", "created": "Fri, 22 Feb 2013 23:21:09 GMT"}], "update_date": "2013-02-26", "authors_parsed": [["L\u00f6ffler", "Maarten", ""], ["Simons", "Joe", ""], ["Strash", "Darren", ""]]}, {"id": "1204.4753", "submitter": "Thomas Rothvoss", "authors": "Thomas Rothvoss and Laura Sanita", "title": "0/1 Polytopes with Quadratic Chvatal Rank", "comments": "15 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CG cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a polytope P, the Chvatal closure P' is obtained by simultaneously\nstrengthening all feasible inequalities cx <= b (with integral c) to cx <=\nfloor(b). The number of iterations of this procedure that are needed until the\nintegral hull of P is reached is called the Chvatal rank. If P is a subset of\n[0,1]^n, then it is known that O(n^2 log n) iterations always suffice\n(Eisenbrand and Schulz (1999)) and at least (1+1/e-o(1))n iterations are\nsometimes needed (Pokutta and Stauffer (2011)), leaving a huge gap between\nlower and upper bounds.\n  We prove that there is a polytope contained in the 0/1 cube that has Chvatal\nrank Omega(n^2), closing the gap up to a logarithmic factor. In fact, even a\nsuperlinear lower bound was mentioned as an open problem by several authors.\nOur choice of P is the convex hull of a semi-random Knapsack polytope and a\nsingle fractional vertex. The main technical ingredient is linking the Chvatal\nrank to simultaneous Diophantine approximations w.r.t. the L1-norm of the\nnormal vector defining P.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2012 22:01:17 GMT"}], "update_date": "2012-04-27", "authors_parsed": [["Rothvoss", "Thomas", ""], ["Sanita", "Laura", ""]]}, {"id": "1204.4826", "submitter": "Christian Klein", "authors": "C. Kalla, C. Klein", "title": "Computation of the topological type of a real Riemann surface", "comments": "23 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AG cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an algorithm for the computation of the topological type of a real\ncompact Riemann surface associated to an algebraic curve, i.e., its genus and\nthe properties of the set of fixed points of the anti-holomorphic involution\n$\\tau$, namely, the number of its connected components, and whether this set\ndivides the surface into one or two connected components. This is achieved by\ntransforming an arbitrary canonical homology basis to a homology basis where\nthe $\\mathcal{A}$-cycles are invariant under the anti-holomorphic involution\n$\\tau$.\n", "versions": [{"version": "v1", "created": "Sat, 21 Apr 2012 16:50:07 GMT"}], "update_date": "2012-04-24", "authors_parsed": [["Kalla", "C.", ""], ["Klein", "C.", ""]]}, {"id": "1204.5333", "submitter": "Rinat Ben Avraham", "authors": "Pankaj K. Agarwal, Rinat Ben Avraham, Haim Kaplan, Micha Sharir", "title": "Computing the Discrete Fr\\'echet Distance in Subquadratic Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Fr\\'echet distance is a similarity measure between two curves $A$ and\n$B$: Informally, it is the minimum length of a leash required to connect a dog,\nconstrained to be on $A$, and its owner, constrained to be on $B$, as they walk\nwithout backtracking along their respective curves from one endpoint to the\nother. The advantage of this measure on other measures such as the Hausdorff\ndistance is that it takes into account the ordering of the points along the\ncurves.\n  The discrete Fr\\'echet distance replaces the dog and its owner by a pair of\nfrogs that can only reside on $n$ and $m$ specific pebbles on the curves $A$\nand $B$, respectively. These frogs hop from a pebble to the next without\nbacktracking. The discrete Fr\\'echet distance can be computed by a rather\nstraightforward quadratic dynamic programming algorithm. However, despite a\nconsiderable amount of work on this problem and its variations, there is no\nsubquadratic algorithm known, even for approximation versions of the problem.\n  In this paper we present a subquadratic algorithm for computing the discrete\nFr\\'echet distance between two sequences of points in the plane, of respective\nlengths $m\\le n$. The algorithm runs in $O(\\dfrac{mn\\log\\log n}{\\log n})$ time\nand uses $O(n+m)$ storage. Our approach uses the geometry of the problem in a\nsubtle way to encode legal positions of the frogs as states of a finite\nautomata.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2012 11:05:07 GMT"}], "update_date": "2012-04-25", "authors_parsed": [["Agarwal", "Pankaj K.", ""], ["Avraham", "Rinat Ben", ""], ["Kaplan", "Haim", ""], ["Sharir", "Micha", ""]]}, {"id": "1204.5828", "submitter": "Adrian Dumitrescu", "authors": "Adrian Dumitrescu", "title": "The traveling salesman problem for lines and rays in the plane", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG math.MG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the Euclidean TSP with neighborhoods (TSPN), we are given a collection of\n$n$ regions (neighborhoods) and we seek a shortest tour that visits each\nregion. In the path variant, we seek a shortest path that visits each region.\nWe present several linear-time approximation algorithms with improved ratios\nfor these problems for two cases of neighborhoods that are (infinite) lines,\nand respectively, (half-infinite) rays. Along the way we derive a tight bound\non the minimum perimeter of a rectangle enclosing an open curve of length $L$.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2012 04:56:56 GMT"}], "update_date": "2012-04-27", "authors_parsed": [["Dumitrescu", "Adrian", ""]]}, {"id": "1204.6389", "submitter": "Peter Csermely", "authors": "Merse E. Gaspar and Peter Csermely", "title": "Rigidity and flexibility of biological networks", "comments": "21 pages, 4 figures, 1 table", "journal-ref": "Briefings in Functional Genomics (2012) 11: 443-456", "doi": "10.1093/bfgp/els023", "report-no": null, "categories": "physics.bio-ph cond-mat.dis-nn cs.CE cs.CG nlin.PS q-bio.MN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The network approach became a widely used tool to understand the behaviour of\ncomplex systems in the last decade. We start from a short description of\nstructural rigidity theory. A detailed account on the combinatorial rigidity\nanalysis of protein structures, as well as local flexibility measures of\nproteins and their applications in explaining allostery and thermostability is\ngiven. We also briefly discuss the network aspects of cytoskeletal tensegrity.\nFinally, we show the importance of the balance between functional flexibility\nand rigidity in protein-protein interaction, metabolic, gene regulatory and\nneuronal networks. Our summary raises the possibility that the concepts of\nflexibility and rigidity can be generalized to all networks.\n", "versions": [{"version": "v1", "created": "Sat, 28 Apr 2012 09:30:48 GMT"}, {"version": "v2", "created": "Sun, 2 Dec 2012 14:54:02 GMT"}], "update_date": "2012-12-04", "authors_parsed": [["Gaspar", "Merse E.", ""], ["Csermely", "Peter", ""]]}, {"id": "1204.6508", "submitter": "Neeraj Sharma", "authors": "Neeraj Sharma, Sandeep Sen", "title": "Efficient cache oblivious algorithms for randomized divide-and-conquer\n  on the multicore model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present randomized algorithms for sorting and convex hull\nthat achieves optimal performance (for speed-up and cache misses) on the\nmulticore model with private cache model. Our algorithms are cache oblivious\nand generalize the randomized divide and conquer strategy given by Reischuk and\nReif and Sen. Although the approach yielded optimal speed-up in the PRAM model,\nwe require additional techniques to optimize cache-misses in an oblivious\nsetting. Under a mild assumption on input and number of processors our\nalgorithm will have optimal time and cache misses with high probability.\nAlthough similar results have been obtained recently for sorting, we feel that\nour approach is simpler and general and we apply it to obtain an optimal\nparallel algorithm for 3D convex hulls with similar bounds. We also present a\nsimple randomized processor allocation technique without the explicit knowledge\nof the number of processors that is likely to find additional applications in\nresource oblivious environments.\n", "versions": [{"version": "v1", "created": "Sun, 29 Apr 2012 19:31:01 GMT"}, {"version": "v2", "created": "Sun, 27 May 2012 19:41:29 GMT"}], "update_date": "2012-05-29", "authors_parsed": [["Sharma", "Neeraj", ""], ["Sen", "Sandeep", ""]]}, {"id": "1204.6527", "submitter": "Stylianos Despotakis", "authors": "Stylianos C. Despotakis, Ioannis Z. Emiris", "title": "An upper bound on Euclidean embeddings of rigid graphs with 8 vertices", "comments": "This paper has been withdrawn by the authors because there was a bug\n  in the code used to produce the sub-systems in Section 4. More specifically\n  some of the sub-systems don't satisfy the Laman property. For an update on\n  this problem, see arXiv:1402.1484", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A graph is called (generically) rigid in R^d if, for any choice of\nsufficiently generic edge lengths, it can be embedded in R^d in a finite number\nof distinct ways, modulo rigid transformations. Here, we deal with the problem\nof determining the maximum number of planar Euclidean embeddings of minimally\nrigid graphs with 8 vertices, because this is the smallest unknown case in the\nplane.\n", "versions": [{"version": "v1", "created": "Sun, 29 Apr 2012 23:04:49 GMT"}, {"version": "v2", "created": "Thu, 23 Oct 2014 00:43:15 GMT"}], "update_date": "2014-10-24", "authors_parsed": [["Despotakis", "Stylianos C.", ""], ["Emiris", "Ioannis Z.", ""]]}, {"id": "1204.6699", "submitter": "Hu Ding", "authors": "Hu Ding and Jinhui Xu", "title": "Chromatic Clustering in High Dimensional Space", "comments": "20 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study a new type of clustering problem, called {\\em\nChromatic Clustering}, in high dimensional space. Chromatic clustering seeks to\npartition a set of colored points into groups (or clusters) so that no group\ncontains points with the same color and a certain objective function is\noptimized. In this paper, we consider two variants of the problem, chromatic\n$k$-means clustering (denoted as $k$-CMeans) and chromatic $k$-medians\nclustering (denoted as $k$-CMedians), and investigate their hardness and\napproximation solutions. For $k$-CMeans, we show that the additional coloring\nconstraint destroys several key properties (such as the locality property) used\nin existing $k$-means techniques (for ordinary points), and significantly\ncomplicates the problem. There is no FPTAS for the chromatic clustering\nproblem, even if $k=2$. To overcome the additional difficulty, we develop a\nstandalone result, called {\\em Simplex Lemma}, which enables us to efficiently\napproximate the mean point of an unknown point set through a fixed dimensional\nsimplex. A nice feature of the simplex is its independence with the\ndimensionality of the original space, and thus can be used for problems in very\nhigh dimensional space. With the simplex lemma, together with several random\nsampling techniques, we show that a $(1+\\epsilon)$-approximation of $k$-CMeans\ncan be achieved in near linear time through a sphere peeling algorithm. For\n$k$-CMedians, we show that a similar sphere peeling algorithm exists for\nachieving constant approximation solutions.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2012 16:45:20 GMT"}, {"version": "v2", "created": "Wed, 12 Sep 2012 05:27:50 GMT"}], "update_date": "2012-09-13", "authors_parsed": [["Ding", "Hu", ""], ["Xu", "Jinhui", ""]]}, {"id": "1204.6717", "submitter": "Hu Ding", "authors": "Hu Ding and Jinhui Xu", "title": "Linear Time Algorithm for Projective Clustering", "comments": "22 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Projective clustering is a problem with both theoretical and practical\nimportance and has received a great deal of attentions in recent years. Given a\nset of points $P$ in $\\mathbb{R}^{d}$ space, projective clustering is to find a\nset $\\mathbb{F}$ of $k$ lower dimensional $j$-flats so that the average\ndistance (or squared distance) from points in $P$ to their closest flats is\nminimized. Existing approaches for this problem are mainly based on\nadaptive/volume sampling or core-sets techniques which suffer from several\nlimitations. In this paper, we present the first uniform random sampling based\napproach for this challenging problem and achieve linear time solutions for\nthree cases, general projective clustering, regular projective clustering, and\n$L_{\\tau}$ sense projective clustering. For the general projective clustering\nproblem, we show that for any given small numbers $0<\\gamma, \\epsilon <1$, our\napproach first removes $\\gamma|P|$ points as outliers and then determines $k$\n$j$-flats to cluster the remaining points into $k$ clusters with an objective\nvalue no more than $(1+\\epsilon)$ times of the optimal for all points. For\nregular projective clustering, we demonstrate that when the input points\nsatisfy some reasonable assumption on its input, our approach for the general\ncase can be extended to yield a PTAS for all points. For $L_{\\tau}$ sense\nprojective clustering, we show that our techniques for both the general and\nregular cases can be naturally extended to the $L_{\\tau}$ sense projective\nclustering problem for any $1 \\le \\tau < \\infty$. Our results are based on\nseveral novel techniques, such as slab partition, $\\Delta$-rotation, symmetric\nsampling, and recursive projection, and can be easily implemented for\napplications.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2012 18:06:53 GMT"}, {"version": "v2", "created": "Wed, 12 Sep 2012 05:13:18 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Ding", "Hu", ""], ["Xu", "Jinhui", ""]]}]