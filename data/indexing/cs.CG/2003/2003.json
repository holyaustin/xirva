[{"id": "2003.00202", "submitter": "Jie Xue", "authors": "Pankaj K. Agarwal, Hsien-Chih Chang, Subhash Suri, Allen Xiao, Jie Xue", "title": "Dynamic geometric set cover and hitting set", "comments": "A preliminary version will appear in SoCG'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate dynamic versions of geometric set cover and hitting set where\npoints and ranges may be inserted or deleted, and we want to efficiently\nmaintain an (approximately) optimal solution for the current problem instance.\nWhile their static versions have been extensively studied in the past,\nsurprisingly little is known about dynamic geometric set cover and hitting set.\nFor instance, even for the most basic case of one-dimensional interval set\ncover and hitting set, no nontrivial results were known. The main contribution\nof our paper are two frameworks that lead to efficient data structures for\ndynamically maintaining set covers and hitting sets in $\\mathbb{R}^1$ and\n$\\mathbb{R}^2$. The first framework uses bootstrapping and gives a\n$(1+\\varepsilon)$-approximate data structure for dynamic interval set cover in\n$\\mathbb{R}^1$ with $O(n^\\alpha/\\varepsilon)$ amortized update time for any\nconstant $\\alpha > 0$; in $\\mathbb{R}^2$, this method gives $O(1)$-approximate\ndata structures for unit-square (and quadrant) set cover and hitting set with\n$O(n^{1/2+\\alpha})$ amortized update time. The second framework uses local\nmodification, and leads to a $(1+\\varepsilon)$-approximate data structure for\ndynamic interval hitting set in $\\mathbb{R}^1$ with\n$\\widetilde{O}(1/\\varepsilon)$ amortized update time; in $\\mathbb{R}^2$, it\ngives $O(1)$-approximate data structures for unit-square (and quadrant) set\ncover and hitting set in the \\textit{partially} dynamic settings with\n$\\widetilde{O}(1)$ amortized update time.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 07:47:04 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Agarwal", "Pankaj K.", ""], ["Chang", "Hsien-Chih", ""], ["Suri", "Subhash", ""], ["Xiao", "Allen", ""], ["Xue", "Jie", ""]]}, {"id": "2003.00269", "submitter": "Xuhui Fan", "authors": "Xuhui Fan, Bin Li, Scott A. Sisson", "title": "Online Binary Space Partitioning Forests", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CG cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Binary Space Partitioning-Tree~(BSP-Tree) process was recently proposed\nas an efficient strategy for space partitioning tasks. Because it uses more\nthan one dimension to partition the space, the BSP-Tree Process is more\nefficient and flexible than conventional axis-aligned cutting strategies.\nHowever, due to its batch learning setting, it is not well suited to\nlarge-scale classification and regression problems. In this paper, we develop\nan online BSP-Forest framework to address this limitation. With the arrival of\nnew data, the resulting online algorithm can simultaneously expand the space\ncoverage and refine the partition structure, with guaranteed universal\nconsistency for both classification and regression problems. The effectiveness\nand competitive performance of the online BSP-Forest is verified via\nsimulations on real-world datasets.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 14:35:44 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Fan", "Xuhui", ""], ["Li", "Bin", ""], ["Sisson", "Scott A.", ""]]}, {"id": "2003.00287", "submitter": "Xiaoyang Guo", "authors": "Xiaoyang Guo, Anuj Srivastava", "title": "Representations, Metrics and Statistics For Shape Analysis of Elastic\n  Graphs", "comments": "Visualization improved", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Past approaches for statistical shape analysis of objects have focused mainly\non objects within the same topological classes, e.g., scalar functions,\nEuclidean curves, or surfaces, etc. For objects that differ in more complex\nways, the current literature offers only topological methods. This paper\nintroduces a far-reaching geometric approach for analyzing shapes of graphical\nobjects, such as road networks, blood vessels, brain fiber tracts, etc. It\nrepresents such objects, exhibiting differences in both geometries and\ntopologies, as graphs made of curves with arbitrary shapes (edges) and\nconnected at arbitrary junctions (nodes). To perform statistical analyses, one\nneeds mathematical representations, metrics and other geometrical tools, such\nas geodesics, means, and covariances. This paper utilizes a quotient structure\nto develop efficient algorithms for computing these quantities, leading to\nuseful statistical tools, including principal component analysis and analytical\nstatistical testing and modeling of graphical shapes. The efficacy of this\nframework is demonstrated using various simulated as well as the real data from\nneurons and brain arterial networks.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 16:07:48 GMT"}, {"version": "v2", "created": "Fri, 15 May 2020 00:34:06 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Guo", "Xiaoyang", ""], ["Srivastava", "Anuj", ""]]}, {"id": "2003.00518", "submitter": "Sariel Har-Peled", "authors": "Dan Halperin, Sariel Har-Peled, Kurt Mehlhorn, Eunjin Oh, Micha Sharir", "title": "The Maximum-Level Vertex in an Arrangement of Lines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $L$ be a set of $n$ lines in the plane, not necessarily in general\nposition. We present an efficient algorithm for finding all the vertices of the\narrangement $A(L)$ of maximum level, where the level of a vertex $v$ is the\nnumber of lines of $L$ that pass strictly below $v$. The problem, posed in\nExercise~8.13 in de Berg etal [BCKO08], appears to be much harder than it\nseems, as this vertex might not be on the upper envelope of the lines.\n  We first assume that all the lines of $L$ are distinct, and distinguish\nbetween two cases, depending on whether or not the upper envelope of $L$\ncontains a bounded edge. In the former case, we show that the number of lines\nof $L$ that pass above any maximum level vertex $v_0$ is only $O(\\log n)$. In\nthe latter case, we establish a similar property that holds after we remove\nsome of the lines that are incident to the single vertex of the upper envelope.\nWe present algorithms that run, in both cases, in optimal $O(n\\log n)$ time.\n  We then consider the case where the lines of $L$ are not necessarily\ndistinct. This setup is more challenging, and the best we have is an algorithm\nthat computes all the maximum-level vertices in time $O(n^{4/3}\\log^{3}n)$.\n  Finally, we consider a related combinatorial question for degenerate\narrangements, where many lines may intersect in a single point, but all the\nlines are distinct: We bound the complexity of the weighted $k$-level in such\nan arrangement, where the weight of a vertex is the number of lines that pass\nthrough the vertex. We show that the bound in this case is $O(n^{4/3})$, which\nmatches the corresponding bound for non-degenerate arrangements, and we use\nthis bound in the analysis of one of our algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 1 Mar 2020 16:33:49 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Halperin", "Dan", ""], ["Har-Peled", "Sariel", ""], ["Mehlhorn", "Kurt", ""], ["Oh", "Eunjin", ""], ["Sharir", "Micha", ""]]}, {"id": "2003.00524", "submitter": "Guillermo Esteban", "authors": "Guillermo Esteban, Clemens Huemer, Rodrigo I. Silveira", "title": "New production matrices for geometric graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use production matrices to count several classes of geometric graphs. We\npresent novel production matrices for non-crossing partitions, connected\ngeometric graphs, and k-angulations, which provide another way of counting the\nnumber of such objects. Counting geometric graphs is then equivalent to\ncalculating the powers of a production matrix. Applying the technique of\nRiordan Arrays to these production matrices, we establish new formulas for the\nnumbers of geometric graphs as well as combinatorial identities derived from\nthe production matrices. Further, we obtain the characteristic polynomial and\nthe eigenvectors of such production matrices.\n", "versions": [{"version": "v1", "created": "Sun, 1 Mar 2020 17:03:36 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Esteban", "Guillermo", ""], ["Huemer", "Clemens", ""], ["Silveira", "Rodrigo I.", ""]]}, {"id": "2003.00556", "submitter": "Fabrizio Frati", "authors": "Giordano Da Lozzo, Anthony D'Angelo, and Fabrizio Frati", "title": "On the Area Requirements of Planar Greedy Drawings of Triconnected\n  Planar Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DM cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the area requirements of planar greedy drawings of\ntriconnected planar graphs. Cao, Strelzoff, and Sun exhibited a family $\\cal H$\nof subdivisions of triconnected plane graphs and claimed that every planar\ngreedy drawing of the graphs in $\\mathcal H$ respecting the prescribed plane\nembedding requires exponential area. However, we show that every $n$-vertex\ngraph in $\\cal H$ actually has a planar greedy drawing respecting the\nprescribed plane embedding on an $O(n)\\times O(n)$ grid. This reopens the\nquestion whether triconnected planar graphs admit planar greedy drawings on a\npolynomial-size grid. Further, we provide evidence for a positive answer to the\nabove question by proving that every $n$-vertex Halin graph admits a planar\ngreedy drawing on an $O(n)\\times O(n)$ grid. Both such results are obtained by\nactually constructing drawings that are convex and angle-monotone. Finally, we\nconsider $\\alpha$-Schnyder drawings, which are angle-monotone and hence greedy\nif $\\alpha\\leq 30^\\circ$, and show that there exist planar triangulations for\nwhich every $\\alpha$-Schnyder drawing with a fixed $\\alpha<60^\\circ$ requires\nexponential area for any resolution rule.\n", "versions": [{"version": "v1", "created": "Sun, 1 Mar 2020 19:04:27 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 16:29:39 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Da Lozzo", "Giordano", ""], ["D'Angelo", "Anthony", ""], ["Frati", "Fabrizio", ""]]}, {"id": "2003.00649", "submitter": "Hsien-Chih Chang", "authors": "Hsien-Chih Chang and Arnaud de Mesmay", "title": "Tightening Curves on Surfaces Monotonically with Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.GT cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove the first polynomial bound on the number of monotonic homotopy moves\nrequired to tighten a collection of closed curves on any compact orientable\nsurface, where the number of crossings in the curve is not allowed to increase\nat any time during the process. The best known upper bound before was\nexponential, which can be obtained by combining the algorithm of de Graaf and\nSchrijver [J. Comb. Theory Ser. B, 1997] together with an exponential upper\nbound on the number of possible surface maps. To obtain the new upper bound we\napply tools from hyperbolic geometry, as well as operations in graph drawing\nalgorithms---the cluster and pipe expansions---to the study of curves on\nsurfaces.\n  As corollaries, we present two efficient algorithms for curves and graphs on\nsurfaces. First, we provide a polynomial-time algorithm to convert any given\nmulticurve on a surface into minimal position. Such an algorithm only existed\nfor single closed curves, and it is known that previous techniques do not\ngeneralize to the multicurve case. Second, we provide a polynomial-time\nalgorithm to reduce any $k$-terminal plane graph (and more generally, surface\ngraph) using degree-1 reductions, series-parallel reductions, and $\\Delta\nY$-transformations for arbitrary integer $k$. Previous algorithms only existed\nin the planar setting when $k \\le 4$, and all of them rely on extensive\ncase-by-case analysis based on different values of $k$. Our algorithm makes use\nof the connection between electrical transformations and homotopy moves, and\nthus solves the problem in a unified fashion.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 04:09:48 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Chang", "Hsien-Chih", ""], ["de Mesmay", "Arnaud", ""]]}, {"id": "2003.00909", "submitter": "Manfred Scheucher", "authors": "Martin Balko, Manfred Scheucher, Pavel Valtr", "title": "Holes and islands in random point sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CG cs.DM math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For $d \\in \\mathbb{N}$, let $S$ be a finite set of points in $\\mathbb{R}^d$\nin general position. A set $H$ of $k$ points from $S$ is a \\emph{$k$-hole}\nin~$S$ if all points from $H$ lie on the boundary of the convex hull\n$\\mathrm{conv}(H)$ of $H$ and the interior of $\\mathrm{conv}(H)$ does not\ncontain any point from $S$. A set $I$ of $k$ points from $S$ is a\n\\emph{$k$-island} in $S$ if $\\mathrm{conv} (I) \\cap S = I$. Note that each\n$k$-hole in $S$ is a $k$-island in $S$.\n  For fixed positive integers $d$, $k$ and a convex body $K$ in~$\\mathbb{R}^d$\nwith $d$-dimensional Lebesgue measure $1$, let $S$ be a set of $n$ points\nchosen uniformly and independently at random from~$K$. We show that the\nexpected number of $k$-islands in $S$ is in $O(n^d)$. In the case $k=d+1$, we\nprove that the expected number of empty simplices (that is, $(d+1)$-holes) in\n$S$ is at most $2^{d-1} \\cdot d! \\cdot \\binom{n}{d}$. Our results improve and\ngeneralize previous bounds by B\\'{a}r\\'{a}ny and F\\\"{u}redi (1987), Valtr\n(1995), Fabila-Monroy and Huemer (2012), and Fabila-Monroy, Huemer, and Mitsche\n(2015).\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 13:35:00 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Balko", "Martin", ""], ["Scheucher", "Manfred", ""], ["Valtr", "Pavel", ""]]}, {"id": "2003.00938", "submitter": "Meirav Zehavi", "authors": "Fedor V. Fomin, Daniel Lokshtanov, Fahad Panolan, Saket Saurabh,\n  Meirav Zehavi", "title": "ETH-Tight Algorithms for Long Path and Cycle on Unit Disk Graphs", "comments": "Extended version to appear in SoCG'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an algorithm for the extensively studied Long Path and Long Cycle\nproblems on unit disk graphs that runs in time $2^{O(\\sqrt{k})}(n+m)$. Under\nthe Exponential Time Hypothesis, Long Path and Long Cycle on unit disk graphs\ncannot be solved in time $2^{o(\\sqrt{k})}(n+m)^{O(1)}$ [de Berg et al., STOC\n2018], hence our algorithm is optimal. Besides the\n$2^{O(\\sqrt{k})}(n+m)^{O(1)}$-time algorithm for the (arguably) much simpler\nVertex Cover problem by de Berg et al. [STOC 2018] (which easily follows from\nthe existence of a $2k$-vertex kernel for the problem), this is the only known\nETH-optimal fixed-parameter tractable algorithm on UDGs. Previously, Long Path\nand Long Cycle on unit disk graphs were only known to be solvable in time\n$2^{O(\\sqrt{k}\\log k)}(n+m)$. This algorithm involved the introduction of a new\ntype of a tree decomposition, entailing the design of a very tedious dynamic\nprogramming procedure. Our algorithm is substantially simpler: we completely\navoid the use of this new type of tree decomposition. Instead, we use a marking\nprocedure to reduce the problem to (a weighted version of) itself on a standard\ntree decomposition of width $O(\\sqrt{k})$.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 14:34:53 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Fomin", "Fedor V.", ""], ["Lokshtanov", "Daniel", ""], ["Panolan", "Fahad", ""], ["Saurabh", "Saket", ""], ["Zehavi", "Meirav", ""]]}, {"id": "2003.01357", "submitter": "Gary Pui-Tung Choi", "authors": "Gary P. T. Choi, Di Qiu, Lok Ming Lui", "title": "Shape analysis via inconsistent surface registration", "comments": null, "journal-ref": "Proceedings of the Royal Society A, 476(2242), 20200147 (2020)", "doi": "10.1098/rspa.2020.0147", "report-no": null, "categories": "cs.CG cs.CV q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we develop a framework for shape analysis using inconsistent\nsurface mapping. Traditional landmark-based geometric morphometrics methods\nsuffer from the limited degrees of freedom, while most of the more advanced\nnon-rigid surface mapping methods rely on a strong assumption of the global\nconsistency of two surfaces. From a practical point of view, given two\nanatomical surfaces with prominent feature landmarks, it is more desirable to\nhave a method that automatically detects the most relevant parts of the two\nsurfaces and finds the optimal landmark-matching alignment between those parts,\nwithout assuming any global 1-1 correspondence between the two surfaces. Our\nmethod is capable of solving this problem using inconsistent surface\nregistration based on quasi-conformal theory. It further enables us to quantify\nthe dissimilarity of two shapes using quasi-conformal distortion and\ndifferences in mean and Gaussian curvatures, thereby providing a natural way\nfor shape classification. Experiments on Platyrrhine molars demonstrate the\neffectiveness of our method and shed light on the interplay between function\nand shape in nature.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 06:58:16 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Choi", "Gary P. T.", ""], ["Qiu", "Di", ""], ["Lui", "Lok Ming", ""]]}, {"id": "2003.01390", "submitter": "Evgeny Shchepin", "authors": "Evgeny Shchepin", "title": "About the Serpinsky-Knopp curve", "comments": "An abridged version of this article is accepted for publication in\n  Russian Mathematical Surveys", "journal-ref": null, "doi": "10.1070/RM9944", "report-no": null, "categories": "math.MG cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Serpinsky-Knopp curve is characterized as the only curve (up to isometry)\nthat maps a unit segment onto a triangle of a unit area, so for any pair of\npoints in the segment, the square of the distance between their images does not\nexceed four times the distance between them.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 08:33:47 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Shchepin", "Evgeny", ""]]}, {"id": "2003.01408", "submitter": "Jimmy Etienne", "authors": "Jimmy Etienne (MFX), Sylvain Lefebvre (MFX)", "title": "Procedural band patterns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We seek to cover a parametric domain with a set of evenly spaced bands which\nnumber and widthvaries according to a density field. We propose an implicit\nprocedural algorithm, that generates theband pattern from a pixel shader and\nadapts to changes to the control fields in real time. Each band isuniquely\nidentified by an integer. This allows a wide range of texturing effects,\nincluding specifying adifferent appearance in each individual bands. Our\ntechnique also affords for progressive gradationsof scales, avoiding the abrupt\ndoubling of the number of lines of typical subdivision approaches. Thisleads to\na general approach for drawing bands, drawing splitting and merging curves, and\ndrawingevenly spaced streamlines. Using these base ingredients, we demonstrate\na wide variety of texturingeffects.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 09:47:52 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Etienne", "Jimmy", "", "MFX"], ["Lefebvre", "Sylvain", "", "MFX"]]}, {"id": "2003.01900", "submitter": "Zhengyang Guo", "authors": "Zhengyang Guo and Yi Li", "title": "Minimum Enclosing Parallelogram with Outliers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of minimum enclosing rectangle with outliers, which asks\nto find, for a given set of $n$ planar points, a rectangle with minimum area\nthat encloses at least $(n-t)$ points. The uncovered points are regarded as\noutliers. We present an exact algorithm with $O(kt^3+kt^2\\log{n} + n^2\\log n)$\nruntime, assuming that no three points lie on the same line. Here $k$ denotes\nthe number of points on the first $(t+1)$ convex layers. We further propose a\nsampling algorithm with runtime $O(n+\\mbox{poly}(\\log{n}, t, 1/\\epsilon))$,\nwhich with high probability finds a rectangle covering at least\n$(1-\\epsilon)(n-t)$ points with at most the exact optimal area.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 05:37:02 GMT"}, {"version": "v2", "created": "Fri, 5 Mar 2021 05:45:04 GMT"}, {"version": "v3", "created": "Sun, 23 May 2021 13:19:12 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Guo", "Zhengyang", ""], ["Li", "Yi", ""]]}, {"id": "2003.02190", "submitter": "Micha Sharir", "authors": "Micha Sharir and Noam Solomon and Oleg Zlydenko", "title": "Incidences between points and curves with almost two degrees of freedom", "comments": "Author Noam Solomon added. Some revisions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study incidences between points and algebraic curves in three dimensions,\ntaken from a family $C$ of curves that have almost two degrees of freedom,\nmeaning that every pair of curves intersect in $O(1)$ points, for any pair of\npoints $p$, $q$, there are only $O(1)$ curves of $C$ that pass through both\npoints, and a pair $p$, $q$ of points admit a curve of $C$ that passes through\nboth of them iff $F(p,q)=0$ for some polynomial $F$.\n  We study two specific instances, one involving unit circles in $R^3$ that\npass through some fixed point (so called anchored unit circles), and the other\ninvolving tangencies between directed points (points and directions) and\ncircles in the plane; a directed point is tangent to a circle if the point lies\non the circle and the direction is the tangent direction. A lifting\ntransformation of Ellenberg et al. maps these tangencies to incidences between\npoints and curves in three dimensions. In both instances the curves in $R^3$\nhave almost two degrees of freedom.\n  We show that the number of incidences between $m$ points and $n$ anchored\nunit circles in $R^3$, as well as the number of tangencies between $m$ directed\npoints and $n$ arbitrary circles in the plane, is $O(m^{3/5}n^{3/5}+m+n)$.\n  We derive a similar incidence bound, with a few additional terms, for more\ngeneral families of curves in $R^3$ with almost two degrees of freedom.\n  The proofs follow standard techniques, based on polynomial partitioning, but\nface a novel issue involving surfaces that are infinitely ruled by the\nrespective family of curves, as well as surfaces in a dual 3D space that are\ninfinitely ruled by the respective family of suitably defined dual curves.\n  The general bound that we obtain is $O(m^{3/5}n^{3/5}+m+n)$ plus additional\nterms that depend on how many curves or dual curves can lie on an\ninfinitely-ruled surface.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 17:04:10 GMT"}, {"version": "v2", "created": "Sun, 15 Mar 2020 16:01:41 GMT"}, {"version": "v3", "created": "Tue, 23 Jun 2020 06:22:58 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Sharir", "Micha", ""], ["Solomon", "Noam", ""], ["Zlydenko", "Oleg", ""]]}, {"id": "2003.02475", "submitter": "Tom\\'a\\v{s} Masa\\v{r}\\'ik", "authors": "Stefan Kratsch and Tom\\'a\\v{s} Masa\\v{r}\\'ik and Irene Muzi and Marcin\n  Pilipczuk and Manuel Sorge", "title": "Optimal Discretization is Fixed-parameter Tractable", "comments": "Accepted to ACM-SIAM Symposium on Discrete Algorithms (SODA 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given two disjoint sets $W_1$ and $W_2$ of points in the plane, the Optimal\nDiscretization problem asks for the minimum size of a family of horizontal and\nvertical lines that separate $W_1$ from $W_2$, that is, in every region into\nwhich the lines partition the plane there are either only points of $W_1$, or\nonly points of $W_2$, or the region is empty. Equivalently, Optimal\nDiscretization can be phrased as a task of discretizing continuous variables:\nwe would like to discretize the range of $x$-coordinates and the range of\n$y$-coordinates into as few segments as possible, maintaining that no pair of\npoints from $W_1 \\times W_2$ are projected onto the same pair of segments under\nthis discretization.\n  We provide a fixed-parameter algorithm for the problem, parameterized by the\nnumber of lines in the solution. Our algorithm works in time $2^{O(k^2 \\log k)}\nn^{O(1)}$, where $k$ is the bound on the number of lines to find and $n$ is the\nnumber of points in the input.\n  Our result answers in positive a question of Bonnet, Giannopolous, and Lampis\n[IPEC 2017] and of Froese (PhD thesis, 2018) and is in contrast with the known\nintractability of two closely related generalizations: the Rectangle Stabbing\nproblem and the generalization in which the selected lines are not required to\nbe axis-parallel.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 08:09:16 GMT"}, {"version": "v2", "created": "Fri, 20 Nov 2020 06:15:02 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Kratsch", "Stefan", ""], ["Masa\u0159\u00edk", "Tom\u00e1\u0161", ""], ["Muzi", "Irene", ""], ["Pilipczuk", "Marcin", ""], ["Sorge", "Manuel", ""]]}, {"id": "2003.02583", "submitter": "\\'Edouard Bonnet", "authors": "\\'Edouard Bonnet, Nicolas Grelier, Tillmann Miltzow", "title": "Maximum Clique in Disk-Like Intersection Graphs", "comments": "23 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the complexity of Maximum Clique in intersection graphs of convex\nobjects in the plane. On the algorithmic side, we extend the polynomial-time\nalgorithm for unit disks [Clark '90, Raghavan and Spinrad '03] to translates of\nany fixed convex set. We also generalize the efficient polynomial-time\napproximation scheme (EPTAS) and subexponential algorithm for disks [Bonnet et\nal. '18, Bonamy et al. '18] to homothets of a fixed centrally symmetric convex\nset. The main open question on that topic is the complexity of Maximum Clique\nin disk graphs. It is not known whether this problem is NP-hard. We observe\nthat, so far, all the hardness proofs for Maximum Clique in intersection graph\nclasses $\\mathcal I$ follow the same road. They show that, for every graph $G$\nof a large-enough class $\\mathcal C$, the complement of an even subdivision of\n$G$ belongs to the intersection class $\\mathcal I$. Then they conclude invoking\nthe hardness of Maximum Independent Set on the class $\\mathcal C$, and the fact\nthat the even subdivision preserves that hardness. However there is a strong\nevidence that this approach cannot work for disk graphs [Bonnet et al. '18]. We\nsuggest a new approach, based on a problem that we dub Max Interval Permutation\nAvoidance, which we prove unlikely to have a subexponential-time approximation\nscheme. We transfer that hardness to Maximum Clique in intersection graphs of\nobjects which can be either half-planes (or unit disks) or axis-parallel\nrectangles. That problem is not amenable to the previous approach. We hope that\na scaled down (merely NP-hard) variant of Max Interval Permutation Avoidance\ncould help making progress on the disk case, for instance by showing the\nNP-hardness for (convex) pseudo-disks.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 12:56:26 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Bonnet", "\u00c9douard", ""], ["Grelier", "Nicolas", ""], ["Miltzow", "Tillmann", ""]]}, {"id": "2003.02605", "submitter": "Stefan Neumann", "authors": "Monika Henzinger, Stefan Neumann, Andreas Wiese", "title": "Dynamic Approximate Maximum Independent Set of Intervals, Hypercubes and\n  Hyperrectangles", "comments": "The conference version of this paper will appear at the Symposium on\n  Computational Geometry (SoCG) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Independent set is a fundamental problem in combinatorial optimization. While\nin general graphs the problem is essentially inapproximable, for many important\ngraph classes there are approximation algorithms known in the offline setting.\nThese graph classes include interval graphs and geometric intersection graphs,\nwhere vertices correspond to intervals/geometric objects and an edge indicates\nthat the two corresponding objects intersect.\n  We present dynamic approximation algorithms for independent set of intervals,\nhypercubes and hyperrectangles in $d$ dimensions. They work in the fully\ndynamic model where each update inserts or deletes a geometric object. All our\nalgorithms are deterministic and have worst-case update times that are\npolylogarithmic for constant $d$ and $\\epsilon> 0$, assuming that the\ncoordinates of all input objects are in $[0, N]^d$ and each of their edges has\nlength at least 1. We obtain the following results:\n  $\\bullet$ For weighted intervals, we maintain a $(1+\\epsilon)$-approximate\nsolution.\n  $\\bullet$ For $d$-dimensional hypercubes we maintain a\n$(1+\\epsilon)2^{d}$-approximate solution in the unweighted case and a\n$O(2^{d})$-approximate solution in the weighted case. Also, we show that for\nmaintaining an unweighted $(1+\\epsilon)$-approximate solution one needs\npolynomial update time for $d\\ge2$ if the ETH holds.\n  $\\bullet$ For weighted $d$-dimensional hyperrectangles we present a dynamic\nalgorithm with approximation ratio $(1+\\epsilon)\\log^{d-1}N$.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 13:33:40 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Henzinger", "Monika", ""], ["Neumann", "Stefan", ""], ["Wiese", "Andreas", ""]]}, {"id": "2003.02801", "submitter": "William Maxwell", "authors": "Glencora Borradaile, William Maxwell, Amir Nayyeri", "title": "Minimum bounded chains and minimum homologous chains in embedded\n  simplicial complexes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG math.AT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study two optimization problems on simplicial complexes with homology over\n$\\mathbb{Z}_2$, the minimum bounded chain problem: given a $d$-dimensional\ncomplex $\\mathcal{K}$ embedded in $\\mathbb{R}^{d+1}$ and a null-homologous\n$(d-1)$-cycle $C$ in $\\mathcal{K}$, find the minimum $d$-chain with boundary\n$C$, and the minimum homologous chain problem: given a $(d+1)$-manifold\n$\\mathcal{M}$ and a $d$-chain $D$ in $\\mathcal{M}$, find the minimum $d$-chain\nhomologous to $D$. We show strong hardness results for both problems even for\nsmall values of $d$; $d = 2$ for the former problem, and $d=1$ for the latter\nproblem. We show that both problems are APX-hard, and hard to approximate\nwithin any constant factor assuming the unique games conjecture. On the\npositive side, we show that both problems are fixed parameter tractable with\nrespect to the size of the optimal solution. Moreover, we provide an\n$O(\\sqrt{\\log \\beta_d})$-approximation algorithm for the minimum bounded chain\nproblem where $\\beta_d$ is the $d$th Betti number of $\\mathcal{K}$. Finally, we\nprovide an $O(\\sqrt{\\log n_{d+1}})$-approximation algorithm for the minimum\nhomologous chain problem where $n_{d+1}$ is the number of $d$-simplices in\n$\\mathcal{M}$.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 18:06:31 GMT"}, {"version": "v2", "created": "Mon, 30 Mar 2020 15:56:32 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Borradaile", "Glencora", ""], ["Maxwell", "William", ""], ["Nayyeri", "Amir", ""]]}, {"id": "2003.03632", "submitter": "Kiril Solovey", "authors": "Kiril Solovey", "title": "Complexity of Planning", "comments": "To appear as a chapter in Motion Planning, the Encyclopedia of\n  Robotics, Eds. Marcelo H. Ang Jr., Oussama Khatib, and Bruno Siciliano.\n  Section Ed. Lydia E. Kavraki. Springer Press", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is a chapter in the Encyclopedia of Robotics. It is devoted to the study\nof complexity of complete (or exact) algorithms for robot motion planning. The\nterm ``complete'' indicates that an approach is guaranteed to find the correct\nsolution (a motion path or trajectory in our setting), or to report that none\nexists otherwise (in case that for instance, no feasible path exists).\nComplexity theory is a fundamental tool in computer science for analyzing the\nperformance of algorithms, in terms of the amount of resources they require.\n(While complexity can express different quantities such as space and\ncommunication effort, our focus in this chapter is on time complexity.)\nMoreover, complexity theory helps to identify ``hard'' problems which require\nexcessive amount of computation time to solve. In the context of motion\nplanning, complexity theory can come in handy in various ways, some of which\nare illustrated here.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 18:37:56 GMT"}, {"version": "v2", "created": "Fri, 27 Mar 2020 19:34:22 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Solovey", "Kiril", ""]]}, {"id": "2003.04523", "submitter": "Woojin Kim", "authors": "Chen Cai, Woojin Kim, Facundo Memoli, Yusu Wang", "title": "Elder-Rule-Staircodes for Augmented Metric Spaces", "comments": "A few important questions considered in the previous version have\n  been settled; see Example 4.12 and Section 4.3 in particular. The paper has\n  been reorganized. This is the full version of the paper in the Proceedings of\n  the 36th International Symposium on Computational Geometry (SoCG 2020); 41\n  pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AT cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An augmented metric space is a metric space $(X, d_X)$ equipped with a\nfunction $f_X: X \\to \\mathbb{R}$. This type of data arises commonly in\npractice, e.g, a point cloud $X$ in $\\mathbb{R}^d$ where each point $x\\in X$\nhas a density function value $f_X(x)$ associated to it. An augmented metric\nspace $(X, d_X, f_X)$ naturally gives rise to a 2-parameter filtration\n$\\mathcal{K}$. However, the resulting 2-parameter persistent homology\n$\\mathrm{H}_{\\bullet}(\\mathcal{K})$ could still be of wild representation type,\nand may not have simple indecomposables. In this paper, motivated by the\nelder-rule for the zeroth homology of 1-parameter filtration, we propose a\nbarcode-like summary, called the elder-rule-staircode, as a way to encode\n$\\mathrm{H}_0(\\mathcal{K})$. Specifically, if $n = |X|$, the\nelder-rule-staircode consists of $n$ number of staircase-like blocks in the\nplane. We show that if $\\mathrm{H}_0(\\mathcal{K})$ is interval decomposable,\nthen the barcode of $\\mathrm{H}_0(\\mathcal{K})$ is equal to the\nelder-rule-staircode. Furthermore, regardless of the interval decomposability,\nthe fibered barcode, the dimension function (a.k.a. the Hilbert function), and\nthe graded Betti numbers of $\\mathrm{H}_0(\\mathcal{K})$ can all be efficiently\ncomputed once the elder-rule-staircode is given. Finally, we develop and\nimplement an efficient algorithm to compute the elder-rule-staircode in\n$O(n^2\\log n)$ time, which can be improved to $O(n^2\\alpha(n))$ if $X$ is from\na fixed dimensional Euclidean space $\\mathbb{R}^d$, where $\\alpha(n)$ is the\ninverse Ackermann function.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 03:48:50 GMT"}, {"version": "v2", "created": "Sun, 12 Jul 2020 21:01:55 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Cai", "Chen", ""], ["Kim", "Woojin", ""], ["Memoli", "Facundo", ""], ["Wang", "Yusu", ""]]}, {"id": "2003.04740", "submitter": "Myroslav Kryven", "authors": "Steven Chaplick, Henry F\\\"orster, Myroslav Kryven, Alexander Wolff", "title": "Drawing Graphs with Circular Arcs and Right-Angle Crossings", "comments": null, "journal-ref": "Proc. 17th Scandinavian Symposium and Workshops on Algorithm\n  Theory (SWAT 2020), LIPIcs 162, pages 21:1-21:14", "doi": "10.4230/LIPIcs.SWAT.2020.21", "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a RAC drawing of a graph, vertices are represented by points in the plane,\nadjacent vertices are connected by line segments, and crossings must form right\nangles. Graphs that admit such drawings are RAC graphs. RAC graphs are\nbeyond-planar graphs and have been studied extensively. In particular, it is\nknown that a RAC graph with n vertices has at most 4n - 10 edges.\n  We introduce a superclass of RAC graphs, which we call arc-RAC graphs. A\ngraph is arc-RAC if it admits a drawing where edges are represented by circular\narcs and crossings form right angles. We provide a Tur\\'an-type result showing\nthat an arc-RAC graph with n vertices has at most 14n - 12 edges and that there\nare n-vertex arc-RAC graphs with 4.5n - o(n) edges.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 13:56:23 GMT"}, {"version": "v2", "created": "Fri, 24 Apr 2020 10:44:09 GMT"}, {"version": "v3", "created": "Thu, 9 Jul 2020 10:43:50 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Chaplick", "Steven", ""], ["F\u00f6rster", "Henry", ""], ["Kryven", "Myroslav", ""], ["Wolff", "Alexander", ""]]}, {"id": "2003.05152", "submitter": "Shir Peleg", "authors": "Shir Peleg and Amir Shpilka", "title": "A generalized Sylvester-Gallai type theorem for quadratic polynomials", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we prove a version of the Sylvester-Gallai theorem for quadratic\npolynomials that takes us one step closer to obtaining a deterministic\npolynomial time algorithm for testing zeroness of\n$\\Sigma^{[3]}\\Pi\\Sigma\\Pi^{[2]}$ circuits. Specifically, we prove that if a\nfinite set of irreducible quadratic polynomials $\\mathcal{Q}$ satisfy that for\nevery two polynomials $Q_1,Q_2\\in \\mathcal{Q}$ there is a subset\n$\\mathcal{K}\\subset \\mathcal{Q}$, such that $Q_1,Q_2 \\notin \\mathcal{K}$ and\nwhenever $Q_1$ and $Q_2$ vanish then also $\\prod_{i\\in \\mathcal{K}} Q_i$\nvanishes, then the linear span of the polynomials in $\\mathcal{Q}$ has\ndimension $O(1)$. This extends the earlier result [Shpilka19] that showed a\nsimilar conclusion when $|\\mathcal{K}| = 1$.\n  An important technical step in our proof is a theorem classifying all the\npossible cases in which a product of quadratic polynomials can vanish when two\nother quadratic polynomials vanish. I.e., when the product is in the radical of\nthe ideal generates by the two quadratics. This step extends a result from\n[Shpilka19]that studied the case when one quadratic polynomial is in the\nradical of two other quadratics.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 08:06:52 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Peleg", "Shir", ""], ["Shpilka", "Amir", ""]]}, {"id": "2003.05332", "submitter": "Henry F\\\"orster", "authors": "Steven Chaplick, Henry F\\\"orster, Michael Hoffmann and Michael\n  Kaufmann", "title": "Monotone Arc Diagrams with few Biarcs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that every planar graph can be represented by a monotone topological\n2-page book embedding where at most 15n/16 (of potentially 3n-6) edges cross\nthe spine exactly once.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 14:37:31 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Chaplick", "Steven", ""], ["F\u00f6rster", "Henry", ""], ["Hoffmann", "Michael", ""], ["Kaufmann", "Michael", ""]]}, {"id": "2003.05579", "submitter": "Ryan Slechta", "authors": "Tamal K. Dey, Marian Mrozek, Ryan Slechta", "title": "Persistence of the Conley Index in Combinatorial Dynamical Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AT cs.CG math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A combinatorial framework for dynamical systems provides an avenue for\nconnecting classical dynamics with data-oriented, algorithmic methods.\nCombinatorial vector fields introduced by Forman and their recent\ngeneralization to multivector fields have provided a starting point for\nbuilding such a connection. In this work, we strengthen this relationship by\nplacing the Conley index in the persistent homology setting. Conley indices are\nhomological features associated with so-called isolated invariant sets, so a\nchange in the Conley index is a response to perturbation in an underlying\nmultivector field. We show how one can use zigzag persistence to summarize\nchanges to the Conley index, and we develop techniques to capture such changes\nin the presence of noise. We conclude by developing an algorithm to track\nfeatures in a changing multivector field.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 02:32:51 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Dey", "Tamal K.", ""], ["Mrozek", "Marian", ""], ["Slechta", "Ryan", ""]]}, {"id": "2003.06096", "submitter": "Richard Goldstone", "authors": "Richard Goldstone, Rachel Roca, and Robert Suzzi Valli", "title": "Shortest Paths on Cubes", "comments": "35 pages, including 3 appendices and program files", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.HO cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 1903, noted puzzle-maker Henry Dudeney published The Spider and the Fly\npuzzle, which asks for the shortest path along the surfaces of a square prism\nbetween two points (source and target) located on the square faces, and\nsurprisingly showed that the shortest path traverses five faces. Dudeney's\nsource and target points had very symmetrical locations; in this article, we\nallow the source and target points to be anywhere in the interior of opposite\nfaces, but now require the square prism to be a cube. In this context, we find\nthat, depending on source and target locations, a shortest path can traverse\neither three or four faces, and we investigate the conditions that lead to\nfour-face solutions and estimate the probability of getting a four-face\nshortest path. We utilize a combination of numerical calculations, elementary\ngeometry, and transformations we call corner moves of cube unfolding diagrams,\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 03:42:09 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Goldstone", "Richard", ""], ["Roca", "Rachel", ""], ["Valli", "Robert Suzzi", ""]]}, {"id": "2003.06462", "submitter": "Austin Lawson", "authors": "Yu-Min Chung, William Cruse, and Austin Lawson", "title": "A Persistent Homology Approach to Time Series Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topological Data Analysis (TDA) is a rising field of computational topology\nin which the topological structure of a data set can be observed by persistent\nhomology. By considering a sequence of sublevel sets, one obtains a filtration\nthat tracks changes in topological information. These changes can be recorded\nin multi-sets known as {\\it persistence diagrams}. Converting information\nstored in persistence diagrams into a form compatible with modern machine\nlearning algorithms is a major vein of research in TDA. {\\it Persistence\ncurves}, a recently developed framework, provides a canonical and flexible way\nto encode the information presented in persistence diagrams into vectors. In\nthis work, we propose a new set of metrics based on persistence curves. We\nprove the stability of the proposed metrics. Finally, we apply these metrics to\nthe UCR Time Series Classification Archive. These empirical results show that\nour metrics perform better than the relevant benchmark in most cases and\nwarrant further study.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 19:45:20 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Chung", "Yu-Min", ""], ["Cruse", "William", ""], ["Lawson", "Austin", ""]]}, {"id": "2003.06742", "submitter": "Yakov Nekrich", "authors": "Yakov Nekrich", "title": "Four-Dimensional Dominance Range Reporting in Linear Space", "comments": "Extended version of a SoCG'20 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the four-dimensional dominance range reporting problem\nand present data structures with linear or almost-linear space usage. Our\nresults can be also used to answer four-dimensional queries that are bounded on\nfive sides. The first data structure presented in this paper uses linear space\nand answers queries in $O(\\log^{1+\\varepsilon}n + k\\log^{\\varepsilon} n)$ time,\nwhere $k$ is the number of reported points, $n$ is the number of points in the\ndata structure, and $\\varepsilon$ is an arbitrarily small positive constant.\nOur second data structure uses $O(n \\log^{\\varepsilon} n)$ space and answers\nqueries in $O(\\log n+k)$ time.\n  These are the first data structures for this problem that use linear (resp.\n$O(n\\log^{\\varepsilon} n)$) space and answer queries in poly-logarithmic time.\nFor comparison the fastest previously known linear-space or\n$O(n\\log^{\\varepsilon} n)$-space data structure supports queries in\n$O(n^{\\varepsilon} + k)$ time (Bentley and Mauer, 1980). Our results can be\ngeneralized to $d\\ge 4$ dimensions. For example, we can answer $d$-dimensional\ndominance range reporting queries in $O(\\log\\log n (\\log n/\\log\\log n)^{d-3} +\nk)$ time using $O(n\\log^{d-4+\\varepsilon}n)$ space. Compared to the fastest\npreviously known result (Chan, 2013), our data structure reduces the space\nusage by $O(\\log n)$ without increasing the query time.\n", "versions": [{"version": "v1", "created": "Sun, 15 Mar 2020 03:00:13 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Nekrich", "Yakov", ""]]}, {"id": "2003.07061", "submitter": "Yelena Yuditsky", "authors": "Noga Alon, Bruno Jartoux, Chaya Keller, Shakhar Smorodinsky, Yelena\n  Yuditsky", "title": "The $\\epsilon$-$t$-Net Problem", "comments": "This is the full version of the paper to appear in the Proceedings of\n  the 36th International Symposium on Computational Geometry (SoCG 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CG math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a natural generalization of the classical $\\epsilon$-net problem\n(Haussler--Welzl 1987), which we call the \"$\\epsilon$-$t$-net problem\": Given a\nhypergraph on $n$ vertices and parameters $t$ and $\\epsilon\\geq \\frac t n$,\nfind a minimum-sized family $S$ of $t$-element subsets of vertices such that\neach hyperedge of size at least $\\epsilon n$ contains a set in $S$. When $t=1$,\nthis corresponds to the $\\epsilon$-net problem.\n  We prove that any sufficiently large hypergraph with VC-dimension $d$ admits\nan $\\epsilon$-$t$-net of size $O(\\frac{ (1+\\log t)d}{\\epsilon} \\log\n\\frac{1}{\\epsilon})$. For some families of geometrically-defined hypergraphs\n(such as the dual hypergraph of regions with linear union complexity), we prove\nthe existence of $O(\\frac{1}{\\epsilon})$-sized $\\epsilon$-$t$-nets.\n  We also present an explicit construction of $\\epsilon$-$t$-nets (including\n$\\epsilon$-nets) for hypergraphs with bounded VC-dimension. In comparison to\nprevious constructions for the special case of $\\epsilon$-nets (i.e., for\n$t=1$), it does not rely on advanced derandomization techniques. To this end we\nintroduce a variant of the notion of VC-dimension which is of independent\ninterest.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 07:47:15 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Alon", "Noga", ""], ["Jartoux", "Bruno", ""], ["Keller", "Chaya", ""], ["Smorodinsky", "Shakhar", ""], ["Yuditsky", "Yelena", ""]]}, {"id": "2003.07341", "submitter": "Mazlum Ferhat Arslan", "authors": "M. Ferhat Arslan (1), Sibel Tari (1) ((1) Middle East Technical\n  University)", "title": "Complexity of Shapes Embedded in ${\\mathbb Z^n}$ with a Bias Towards\n  Squares", "comments": "13 pages, 14 figures, submitted to IEEE Transactions on Image\n  Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CG cs.GR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Shape complexity is a hard-to-quantify quality, mainly due to its relative\nnature. Biased by Euclidean thinking, circles are commonly considered as the\nsimplest. However, their constructions as digital images are only\napproximations to the ideal form. Consequently, complexity orders computed in\nreference to circle are unstable. Unlike circles which lose their circleness in\ndigital images, squares retain their qualities. Hence, we consider squares\n(hypercubes in $\\mathbb Z^n$) to be the simplest shapes relative to which\ncomplexity orders are constructed. Using the connection between $L^\\infty$ norm\nand squares we effectively encode squareness-adapted simplification through\nwhich we obtain multi-scale complexity measure, where scale determines the\nlevel of interest to the boundary. The emergent scale above which the effect of\na boundary feature (appendage) disappears is related to the ratio of the\ncontacting width of the appendage to that of the main body. We discuss what\nzero complexity implies in terms of information repetition and constructibility\nand what kind of shapes in addition to squares have zero complexity.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 17:24:22 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Arslan", "M. Ferhat", ""], ["Tari", "Sibel", ""]]}, {"id": "2003.07513", "submitter": "Michael Horton", "authors": "Boris Aronov and Mark de Berg and Joachim Gudmundsson and Michael\n  Horton", "title": "On beta-Plurality Points in Spatial Voting Games", "comments": "21 pages, 10 figures, SoCG'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $V$ be a set of $n$ points in $\\mathbb{R}^d$, called voters. A point\n$p\\in \\mathbb{R}^d$ is a plurality point for $V$ when the following holds: for\nevery $q\\in\\mathbb{R}^d$ the number of voters closer to $p$ than to $q$ is at\nleast the number of voters closer to $q$ than to $p$. Thus, in a vote where\neach $v\\in V$ votes for the nearest proposal (and voters for which the\nproposals are at equal distance abstain), proposal $p$ will not lose against\nany alternative proposal $q$. For most voter sets a plurality point does not\nexist. We therefore introduce the concept of $\\beta$-plurality points, which\nare defined similarly to regular plurality points except that the distance of\neach voter to $p$ (but not to $q$) is scaled by a factor $\\beta$, for some\nconstant $0<\\beta\\leq 1$. We investigate the existence and computation of\n$\\beta$-plurality points, and obtain the following.\n  * Define $\\beta^*_d := \\sup \\{ \\beta : \\text{any finite multiset $V$ in\n$\\mathbb{R}^d$ admits a $\\beta$-plurality point} \\}$. We prove that $\\beta^*_2\n= \\sqrt{3}/2$, and that $1/\\sqrt{d} \\leq \\beta^*_d \\leq \\sqrt{3}/2$ for all\n$d\\geq 3$.\n  * Define $\\beta(p, V) := \\sup \\{ \\beta : \\text{$p$ is a $\\beta$-plurality\npoint for $V$}\\}$. Given a voter set $V \\in \\mathbb{R}^2$, we provide an\nalgorithm that runs in $O(n \\log n)$ time and computes a point $p$ such that\n$\\beta(p, V) \\geq \\beta^*_2$. Moreover, for $d\\geq 2$ we can compute a point\n$p$ with $\\beta(p,V) \\geq 1/\\sqrt{d}$ in $O(n)$ time.\n  * Define $\\beta(V) := \\sup \\{ \\beta : \\text{$V$ admits a $\\beta$-plurality\npoint}\\}$. We present an algorithm that, given a voter set $V$ in\n$\\mathbb{R}^d$, computes an $(1-\\varepsilon)\\cdot \\beta(V)$ plurality point in\ntime $O(\\frac{n^2}{\\varepsilon^{3d-2}} \\cdot \\log \\frac{n}{\\varepsilon^{d-1}}\n\\cdot \\log^2 \\frac {1}{\\varepsilon})$.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 03:32:01 GMT"}, {"version": "v2", "created": "Mon, 18 May 2020 16:16:38 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Aronov", "Boris", ""], ["de Berg", "Mark", ""], ["Gudmundsson", "Joachim", ""], ["Horton", "Michael", ""]]}, {"id": "2003.07655", "submitter": "Michael Bekos", "authors": "Michael A. Bekos, Giordano Da Lozzo, Svenja Griesbach, Martin\n  Gronemann, Fabrizio Montecchiani, Chrysanthi Raftopoulou", "title": "Book Embeddings of Nonplanar Graphs with Small Faces in Few Pages", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An embedding of a graph in a book, called book embedding, consists of a\nlinear ordering of its vertices along the spine of the book and an assignment\nof its edges to the pages of the book, so that no two edges on the same page\ncross. The book thickness of a graph is the minimum number of pages over all\nits book embeddings. For planar graphs, a fundamental result is due to\nYannakakis, who proposed an algorithm to compute embeddings of planar graphs in\nbooks with four pages. Our main contribution is a technique that generalizes\nthis result to a much wider family of nonplanar graphs, which is characterized\nby a biconnected skeleton of crossing-free edges whose faces have bounded\ndegree. Notably, this family includes all 1-planar and all optimal 2-planar\ngraphs as subgraphs. We prove that this family of graphs has bounded book\nthickness, and as a corollary, we obtain the first constant upper bound for the\nbook thickness of optimal 2-planar graphs.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 12:07:06 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Bekos", "Michael A.", ""], ["Da Lozzo", "Giordano", ""], ["Griesbach", "Svenja", ""], ["Gronemann", "Martin", ""], ["Montecchiani", "Fabrizio", ""], ["Raftopoulou", "Chrysanthi", ""]]}, {"id": "2003.07793", "submitter": "Akanksha Agrawal", "authors": "Akanksha Agrawal, Kristine V.K. Knudsen, Daniel Lokshtanov, Saket\n  Saurabh, and Meirav Zehavi", "title": "The Parameterized Complexity of Guarding Almost Convex Polygons", "comments": "To appear in SoCG 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Art Gallery is a fundamental visibility problem in Computational Geometry.\nThe input consists of a simple polygon P, (possibly infinite) sets G and C of\npoints within P, and an integer k; the task is to decide if at most k guards\ncan be placed on points in G so that every point in C is visible to at least\none guard. In the classic formulation of Art Gallery, G and C consist of all\nthe points within P. Other well-known variants restrict G and C to consist\neither of all the points on the boundary of P or of all the vertices of P.\nRecently, three new important discoveries were made: the above mentioned\nvariants of Art Gallery are all W[1]-hard with respect to k [Bonnet and\nMiltzow, ESA'16], the classic variant has an O(log k)-approximation algorithm\n[Bonnet and Miltzow, SoCG'17], and it may require irrational guards [Abrahamsen\net al., SoCG'17]. Building upon the third result, the classic variant and the\ncase where G consists only of all the points on the boundary of P were both\nshown to be \\exists R-complete~[Abrahamsen et al., STOC'18]. Even when both G\nand C consist only of all the points on the boundary of P, the problem is not\nknown to be in NP.\n  Given the first discovery, the following question was posed by Giannopoulos\n[Lorentz Center Workshop, 2016]: Is Art Gallery FPT with respect to r, the\nnumber of reflex vertices? We focus on the variant where G and C are all the\nvertices of P, called Vertex-Vertex Art Gallery. We show that Vertex-Vertex Art\nGallery is solvable in time r^{O(r^2)}n^{O(1)}. Our approach also extends to\nassert that Vertex-Boundary Art Gallery and Boundary-Vertex Art Gallery are\nboth FPT. We utilize structural properties of \"almost convex polygons\" to\npresent a two-stage reduction from Vertex-Vertex Art Gallery to a new\nconstraint satisfaction problem (whose solution is also provided in this paper)\nwhere constraints have arity 2 and involve monotone functions.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 16:16:07 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Agrawal", "Akanksha", ""], ["Knudsen", "Kristine V. K.", ""], ["Lokshtanov", "Daniel", ""], ["Saurabh", "Saket", ""], ["Zehavi", "Meirav", ""]]}, {"id": "2003.07989", "submitter": "Simon Zhang", "authors": "Simon Zhang, Mengbai Xiao and Hao Wang", "title": "GPU-Accelerated Computation of Vietoris-Rips Persistence Barcodes", "comments": "36 pages, 15 figures. To be published in Symposium on Computational\n  Geometry 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The computation of Vietoris-Rips persistence barcodes is both\nexecution-intensive and memory-intensive. In this paper, we study the\ncomputational structure of Vietoris-Rips persistence barcodes, and identify\nseveral unique mathematical properties and algorithmic opportunities with\nconnections to the GPU. Mathematically and empirically, we look into the\nproperties of apparent pairs, which are independently identifiable persistence\npairs comprising up to 99% of persistence pairs. We give theoretical upper and\nlower bounds of the apparent pair rate and model the average case. We also\ndesign massively parallel algorithms to take advantage of the very large number\nof simplices that can be processed independently of each other. Having\nidentified these opportunities, we develop a GPU-accelerated software for\ncomputing Vietoris-Rips persistence barcodes, called Ripser++. The software\nachieves up to 30x speedup over the total execution time of the original Ripser\nand also reduces CPU-memory usage by up to 2.0x. We believe our\nGPU-acceleration based efforts open a new chapter for the advancement of\ntopological data analysis in the post-Moore's Law era.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 23:57:37 GMT"}, {"version": "v2", "created": "Tue, 24 Mar 2020 14:14:06 GMT"}, {"version": "v3", "created": "Sat, 3 Oct 2020 03:49:34 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Zhang", "Simon", ""], ["Xiao", "Mengbai", ""], ["Wang", "Hao", ""]]}, {"id": "2003.08149", "submitter": "Arnab Bhadra", "authors": "Arnab Bhadra and Kalidas Y", "title": "Site2Vec: a reference frame invariant algorithm for vector embedding of\n  protein-ligand binding sites", "comments": null, "journal-ref": null, "doi": "10.1088/2632-2153/abad88", "report-no": null, "categories": "q-bio.BM cs.CG cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Protein-ligand interactions are one of the fundamental types of molecular\ninteractions in living systems. Ligands are small molecules that interact with\nprotein molecules at specific regions on their surfaces called binding sites.\nTasks such as assessment of protein functional similarity and detection of side\neffects of drugs need identification of similar binding sites of disparate\nproteins across diverse pathways. Machine learning methods for similarity\nassessment require feature descriptors of binding sites. Traditional methods\nbased on hand engineered motifs and atomic configurations are not scalable\nacross several thousands of sites. In this regard, deep neural network\nalgorithms are now deployed which can capture very complex input feature space.\nHowever, one fundamental challenge in applying deep learning to structures of\nbinding sites is the input representation and the reference frame. We report\nhere a novel algorithm Site2Vec that derives reference frame invariant vector\nembedding of a protein-ligand binding site. The method is based on pairwise\ndistances between representative points and chemical compositions in terms of\nconstituent amino acids of a site. The vector embedding serves as a locality\nsensitive hash function for proximity queries and determining similar sites.\nThe method has been the top performer with more than 95% quality scores in\nextensive benchmarking studies carried over 10 datasets and against 23 other\nsite comparison methods. The algorithm serves for high throughput processing\nand has been evaluated for stability with respect to reference frame shifts,\ncoordinate perturbations and residue mutations. We provide Site2Vec as a stand\nalone executable and a web service hosted at\n\\url{http://services.iittp.ac.in/bioinfo/home}.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 10:56:27 GMT"}, {"version": "v2", "created": "Mon, 27 Jul 2020 10:30:14 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Bhadra", "Arnab", ""], ["Y", "Kalidas", ""]]}, {"id": "2003.08236", "submitter": "Phillip Keldenich", "authors": "S\\'andor P. Fekete, Utkarsh Gupta, Phillip Keldenich, Christian\n  Scheffer, Sahil Shah", "title": "Worst-Case Optimal Covering of Rectangles by Disks", "comments": "45 pages, 26 figures. Full version of an extended abstract with the\n  same title accepted for publication in the proceedings of the 36th Symposium\n  on Computational Geometry (SoCG 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide the solution for a fundamental problem of geometric optimization\nby giving a complete characterization of worst-case optimal disk coverings of\nrectangles: For any $\\lambda\\geq 1$, the critical covering area $A^*(\\lambda)$\nis the minimum value for which any set of disks with total area at least\n$A^*(\\lambda)$ can cover a rectangle of dimensions $\\lambda\\times 1$.\n  We show that there is a threshold value $\\lambda_2 = \\sqrt{\\sqrt{7}/2 - 1/4}\n\\approx 1.035797\\ldots$, such that for $\\lambda<\\lambda_2$ the critical\ncovering area $A^*(\\lambda)$ is $A^*(\\lambda)=3\\pi\\left(\\frac{\\lambda^2}{16}\n+\\frac{5}{32} + \\frac{9}{256\\lambda^2}\\right)$, and for $\\lambda\\geq\n\\lambda_2$, the critical area is $A^*(\\lambda)=\\pi(\\lambda^2+2)/4$; these\nvalues are tight.\n  For the special case $\\lambda=1$, i.e., for covering a unit square, the\ncritical covering area is $\\frac{195\\pi}{256}\\approx 2.39301\\ldots$. The proof\nuses a careful combination of manual and automatic analysis, demonstrating the\npower of the employed interval arithmetic technique.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 14:20:39 GMT"}], "update_date": "2020-03-19", "authors_parsed": [["Fekete", "S\u00e1ndor P.", ""], ["Gupta", "Utkarsh", ""], ["Keldenich", "Phillip", ""], ["Scheffer", "Christian", ""], ["Shah", "Sahil", ""]]}, {"id": "2003.08288", "submitter": "Siu-Wing Cheng", "authors": "Siu-Wing Cheng and Man-Kit Lau", "title": "Dynamic Distribution-Sensitive Point Location", "comments": "To appear in Proceedings of the International Symposium of\n  Computational Geometry, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a dynamic data structure for the distribution-sensitive point\nlocation problem. Suppose that there is a fixed query distribution in\n$\\mathbb{R}^2$, and we are given an oracle that can return in $O(1)$ time the\nprobability of a query point falling into a polygonal region of constant\ncomplexity. We can maintain a convex subdivision $\\cal S$ with $n$ vertices\nsuch that each query is answered in $O(\\mathrm{OPT})$ expected time, where OPT\nis the minimum expected time of the best linear decision tree for point\nlocation in $\\cal S$. The space and construction time are $O(n\\log^2 n)$. An\nupdate of $\\cal S$ as a mixed sequence of $k$ edge insertions and deletions\ntakes $O(k\\log^5 n)$ amortized time. As a corollary, the randomized incremental\nconstruction of the Voronoi diagram of $n$ sites can be performed in $O(n\\log^5\nn)$ expected time so that, during the incremental construction, a nearest\nneighbor query at any time can be answered optimally with respect to the\nintermediate Voronoi diagram at that time.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 15:51:52 GMT"}, {"version": "v2", "created": "Sat, 28 Mar 2020 03:01:49 GMT"}, {"version": "v3", "created": "Wed, 1 Apr 2020 04:37:46 GMT"}, {"version": "v4", "created": "Sat, 25 Apr 2020 06:38:38 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Cheng", "Siu-Wing", ""], ["Lau", "Man-Kit", ""]]}, {"id": "2003.08329", "submitter": "Kai Jin", "authors": "Siu-Wing Cheng and Man-Kwun Chiu and Kai Jin and Man Ting Wong", "title": "A Generalization of Self-Improving Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ailon et al. [SICOMP'11] proposed self-improving algorithms for sorting and\nDelaunay triangulation (DT) when the input instances $x_1,\\cdots,x_n$ follow\nsome unknown \\emph{product distribution}. That is, $x_i$ comes from a fixed\nunknown distribution $\\mathsf{D}_i$, and the $x_i$'s are drawn independently.\nAfter spending $O(n^{1+\\varepsilon})$ time in a learning phase, the subsequent\nexpected running time is $O((n+ H)/\\varepsilon)$, where $H \\in\n\\{H_\\mathrm{S},H_\\mathrm{DT}\\}$, and $H_\\mathrm{S}$ and $H_\\mathrm{DT}$ are the\nentropies of the distributions of the sorting and DT output, respectively. In\nthis paper, we allow dependence among the $x_i$'s under the \\emph{group product\ndistribution}. There is a hidden partition of $[1,n]$ into groups; the $x_i$'s\nin the $k$-th group are fixed unknown functions of the same hidden variable\n$u_k$; and the $u_k$'s are drawn from an unknown product distribution. We\ndescribe self-improving algorithms for sorting and DT under this model when the\nfunctions that map $u_k$ to $x_i$'s are well-behaved. After an\n$O(\\mathrm{poly}(n))$-time training phase, we achieve $O(n + H_\\mathrm{S})$ and\n$O(n\\alpha(n) + H_\\mathrm{DT})$ expected running times for sorting and DT,\nrespectively, where $\\alpha(\\cdot)$ is the inverse Ackermann function.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 16:47:31 GMT"}, {"version": "v2", "created": "Fri, 21 Aug 2020 14:22:19 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Cheng", "Siu-Wing", ""], ["Chiu", "Man-Kwun", ""], ["Jin", "Kai", ""], ["Wong", "Man Ting", ""]]}, {"id": "2003.08331", "submitter": "Jeffrey Bosboom", "authors": "Aviv Adler, Jeffrey Bosboom, Erik D. Demaine, Martin L. Demaine,\n  Quanquan C. Liu, Jayson Lynch", "title": "Tatamibari is NP-complete", "comments": "26 pages, 21 figures. New discussion of safe placement of wires in\n  Sections 3.2 and 3.5. To appear at the 10th International Conference on Fun\n  with Algorithms (FUN 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the Nikoli pencil-and-paper game Tatamibari, a puzzle consists of an $m\n\\times n$ grid of cells, where each cell possibly contains a clue among +, -,\n|. The goal is to partition the grid into disjoint rectangles, where every\nrectangle contains exactly one clue, rectangles containing + are square,\nrectangles containing - are strictly longer horizontally than vertically,\nrectangles containing | are strictly longer vertically than horizontally, and\nno four rectangles share a corner. We prove this puzzle NP-complete,\nestablishing a Nikoli gap of 16 years. Along the way, we introduce a gadget\nframework for proving hardness of similar puzzles involving area coverage, and\nshow that it applies to an existing NP-hardness proof for Spiral Galaxies. We\nalso present a mathematical puzzle font for Tatamibari.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 16:54:28 GMT"}, {"version": "v2", "created": "Thu, 7 May 2020 18:49:14 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Adler", "Aviv", ""], ["Bosboom", "Jeffrey", ""], ["Demaine", "Erik D.", ""], ["Demaine", "Martin L.", ""], ["Liu", "Quanquan C.", ""], ["Lynch", "Jayson", ""]]}, {"id": "2003.08456", "submitter": "Xavier Goaoc", "authors": "Xavier Goaoc and Emo Welzl", "title": "Convex Hulls of Random Order Types", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We establish the following two main results on order types of points in\ngeneral position in the plane (realizable simple planar order types, realizable\nuniform acyclic oriented matroids of rank $3$):\n  (a) The number of extreme points in an $n$-point order type, chosen uniformly\nat random from all such order types, is on average $4+o(1)$. For labeled order\ntypes, this number has average $4- \\frac{8}{n^2 - n +2}$ and variance at most\n$3$.\n  (b) The (labeled) order types read off a set of $n$ points sampled\nindependently from the uniform measure on a convex planar domain, smooth or\npolygonal, or from a Gaussian distribution are concentrated, i.e. such sampling\ntypically encounters only a vanishingly small fraction of all order types of\nthe given size.\n  Result (a) generalizes to arbitrary dimension $d$ for labeled order types\nwith the average number of extreme points $2d+o(1)$ and constant variance. We\nalso discuss to what extent our methods generalize to the abstract setting of\nuniform acyclic oriented matroids. Moreover, our methods allow to show the\nfollowing relative of the Erd\\H{o}s-Szekeres theorem: for any fixed $k$, as $n\n\\to \\infty$, a proportion $1 - O(1/n)$ of the $n$-point simple order types\ncontain a triangle enclosing a convex $k$-chain over an edge.\n  For the unlabeled case in (a), we prove that for any antipodal, finite subset\nof the $2$-dimensional sphere, the group of orientation preserving bijections\nis cyclic, dihedral or one of $A_4$, $S_4$ or $A_5$ (and each case is\npossible). These are the finite subgroups of $SO(3)$ and our proof follows the\nlines of their characterization by Felix Klein.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 20:11:41 GMT"}, {"version": "v2", "created": "Thu, 30 Jul 2020 08:35:59 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Goaoc", "Xavier", ""], ["Welzl", "Emo", ""]]}, {"id": "2003.08468", "submitter": "Franz J. Brandenburg", "authors": "Franz J. Brandenburg", "title": "Fan-Crossing Free Graphs and Their Relationship to other Beyond-Planar\n  Graphs", "comments": "23 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A graph is \\emph{fan-crossing free} if it has a drawing in the plane so that\neach edge is crossed by independent edges, that is the crossing edges have\ndistinct vertices. On the other hand, it is \\emph{fan-crossing} if the crossing\nedges have a common vertex, that is they form a fan. Both are prominent\nexamples for beyond-planar graphs. Further well-known beyond-planar classes are\nthe $k$-planar, $k$-gap-planar, quasi-planar, and right angle crossing graphs.\nWe use the subdivision, node-to-circle expansion and path-addition operations\nto distinguish all these graph classes. In particular, we show that the\n2-subdivision and the node-to-circle expansion of any graph is fan-crossing\nfree, which does not hold for fan-crossing and $k$-(gap)-planar graphs,\nrespectively. Thereby, we obtain graphs that are fan-crossing free and neither\nfan-crossing nor $k$-(gap)-planar. Finally, we show that some graphs have a\nunique fan-crossing free embedding, that there are thinned maximal fan-crossing\nfree graphs, and that the recognition problem for fan-crossing free graphs is\nNP-complete.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 20:53:50 GMT"}, {"version": "v2", "created": "Thu, 10 Dec 2020 21:10:13 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Brandenburg", "Franz J.", ""]]}, {"id": "2003.08624", "submitter": "Kaichun Mo", "authors": "Kaichun Mo, He Wang, Xinchen Yan, Leonidas J. Guibas", "title": "PT2PC: Learning to Generate 3D Point Cloud Shapes from Part Tree\n  Conditions", "comments": "ECCV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CG cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  3D generative shape modeling is a fundamental research area in computer\nvision and interactive computer graphics, with many real-world applications.\nThis paper investigates the novel problem of generating 3D shape point cloud\ngeometry from a symbolic part tree representation. In order to learn such a\nconditional shape generation procedure in an end-to-end fashion, we propose a\nconditional GAN \"part tree\"-to-\"point cloud\" model (PT2PC) that disentangles\nthe structural and geometric factors. The proposed model incorporates the part\ntree condition into the architecture design by passing messages top-down and\nbottom-up along the part tree hierarchy. Experimental results and user study\ndemonstrate the strengths of our method in generating perceptually plausible\nand diverse 3D point clouds, given the part tree condition. We also propose a\nnovel structural measure for evaluating if the generated shape point clouds\nsatisfy the part tree conditions.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 08:27:25 GMT"}, {"version": "v2", "created": "Thu, 16 Jul 2020 01:28:18 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Mo", "Kaichun", ""], ["Wang", "He", ""], ["Yan", "Xinchen", ""], ["Guibas", "Leonidas J.", ""]]}, {"id": "2003.08816", "submitter": "Dominik Michael Krupke", "authors": "S\\'andor P. Fekete and Linda Kleist and Dominik Krupke", "title": "Minimum Scan Cover with Angular Transition Costs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a comprehensive study of a natural geometric optimization problem\nmotivated by questions in the context of satellite communication and\nastrophysics. In the problem Minimum Scan Cover with Angular Costs (MSC), we\nare given a graph $G$ that is embedded in Euclidean space. The edges of $G$\nneed to be scanned, i.e., probed from both of their vertices. In order to scan\ntheir edge, two vertices need to face each other; changing the heading of a\nvertex takes some time proportional to the corresponding turn angle. Our goal\nis to minimize the time until all scans are completed, i.e., to compute a\nschedule of minimum makespan.\n  We show that MSC is closely related to both graph coloring and the minimum\n(directed and undirected) cut cover problem; in particular, we show that the\nminimum scan time for instances in 1D and 2D lies in $\\Theta(\\log \\chi (G))$,\nwhile for 3D the minimum scan time is not upper bounded by $\\chi (G)$. We use\nthis relationship to prove that the existence of a constant-factor\napproximation implies $P=NP$, even for one-dimensional instances. In 2D, we\nshow that it is NP-hard to approximate a minimum scan cover within less than a\nfactor of $\\frac{3}{2}$, even for bipartite graphs; conversely, we present a\n$\\frac{9}{2}$-approximation algorithm for this scenario. Generally, we give an\n$O(c)$-approximation for $k$-colored graphs with $k\\leq \\chi(G)^c$. For general\nmetric cost functions, we provide approximation algorithms whose performance\nguarantee depend on the arboricity of the graph.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 14:27:17 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Fekete", "S\u00e1ndor P.", ""], ["Kleist", "Linda", ""], ["Krupke", "Dominik", ""]]}, {"id": "2003.08981", "submitter": "Chiyu Jiang", "authors": "Chiyu Max Jiang, Avneesh Sud, Ameesh Makadia, Jingwei Huang, Matthias\n  Nie{\\ss}ner, Thomas Funkhouser", "title": "Local Implicit Grid Representations for 3D Scenes", "comments": "CVPR 2020. Supplementary Video: https://youtu.be/XCyl1-vxfII", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CG cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shape priors learned from data are commonly used to reconstruct 3D objects\nfrom partial or noisy data. Yet no such shape priors are available for indoor\nscenes, since typical 3D autoencoders cannot handle their scale, complexity, or\ndiversity. In this paper, we introduce Local Implicit Grid Representations, a\nnew 3D shape representation designed for scalability and generality. The\nmotivating idea is that most 3D surfaces share geometric details at some scale\n-- i.e., at a scale smaller than an entire object and larger than a small\npatch. We train an autoencoder to learn an embedding of local crops of 3D\nshapes at that size. Then, we use the decoder as a component in a shape\noptimization that solves for a set of latent codes on a regular grid of\noverlapping crops such that an interpolation of the decoded local shapes\nmatches a partial or noisy observation. We demonstrate the value of this\nproposed approach for 3D surface reconstruction from sparse point observations,\nshowing significantly better results than alternative approaches.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 18:58:13 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Jiang", "Chiyu Max", ""], ["Sud", "Avneesh", ""], ["Makadia", "Ameesh", ""], ["Huang", "Jingwei", ""], ["Nie\u00dfner", "Matthias", ""], ["Funkhouser", "Thomas", ""]]}, {"id": "2003.09266", "submitter": "Aruni Choudhary", "authors": "Man-Kwun Chiu and Aruni Choudhary and Wolfgang Mulzer", "title": "Computational Complexity of the $\\alpha$-Ham-Sandwich Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The classic Ham-Sandwich theorem states that for any $d$ measurable sets in\n$\\mathbb{R}^d$, there is a hyperplane that bisects them simultaneously. An\nextension by B\\'ar\\'any, Hubard, and Jer\\'onimo [DCG 2008] states that if the\nsets are convex and \\emph{well-separated}, then for any given $\\alpha_1, \\dots,\n\\alpha_d \\in [0, 1]$, there is a unique oriented hyperplane that cuts off a\nrespective fraction $\\alpha_1, \\dots, \\alpha_d$ from each set. Steiger and Zhao\n[DCG 2010] proved a discrete analogue of this theorem, which we call the\n\\emph{$\\alpha$-Ham-Sandwich theorem}. They gave an algorithm to find the\nhyperplane in time $O(n (\\log n)^{d-3})$, where $n$ is the total number of\ninput points. The computational complexity of this search problem in high\ndimensions is open, quite unlike the complexity of the Ham-Sandwich problem,\nwhich is now known to be PPA-complete (Filos-Ratsikas and Goldberg [STOC\n2019]).\n  Recently, Fearley, Gordon, Mehta, and Savani [ICALP 2019] introduced a new\nsub-class of CLS (Continuous Local Search) called \\emph{Unique End-of-Potential\nLine} (UEOPL). This class captures problems in CLS that have unique solutions.\nWe show that for the $\\alpha$-Ham-Sandwich theorem, the search problem of\nfinding the dividing hyperplane lies in UEOPL. This gives the first non-trivial\ncontainment of the problem in a complexity class and places it in the company\nof classic search problems such as finding the fixed point of a contraction\nmap, the unique sink orientation problem and the $P$-matrix linear\ncomplementarity problem.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 13:29:28 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Chiu", "Man-Kwun", ""], ["Choudhary", "Aruni", ""], ["Mulzer", "Wolfgang", ""]]}, {"id": "2003.09533", "submitter": "Esther Ezra", "authors": "Boris Aronov, Esther Ezra, and Micha Sharir", "title": "Testing Polynomials for Vanishing on Cartesian Products of Planar Point\n  Sets: Collinearity Testing and Related Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present subquadratic algorithms, in the algebraic decision-tree model of\ncomputation, for detecting whether there exists a triple of points, belonging\nto three respective sets $A$, $B$, and $C$ of points in the plane, that satisfy\na certain polynomial equation or two equations. The best known instance of such\na problem is testing for the existence of a collinear triple of points in\n$A\\times B\\times C$, a classical 3SUM-hard problem that has so far defied any\nattempt to obtain a subquadratic solution, whether in the (uniform) real RAM\nmodel, or in the algebraic decision-tree model. While we are still unable to\nsolve this problem, in full generality, in subquadratic time, we obtain such a\nsolution, in the algebraic decision-tree model, that uses only roughly\n$O(n^{28/15})$ constant-degree polynomial sign tests, for the special case\nwhere two of the sets lie on two respective one-dimensional curves and the\nthird is placed arbitrarily in the plane. Our technique is fairly general, and\napplies to many other problems where we seek a triple that satisfies a single\npolynomial equation, e.g., determining whether $A\\times B\\times C$ contains a\ntriple spanning a unit-area triangle. This result extends recent work by Barba\n\\etal~(2017) and by Chan (2018), where all three sets $A$,~$B$, and~$C$ are\nassumed to be one-dimensional.\n  As a second application of our technique, we again have three $n$-point sets\n$A$, $B$, and $C$ in the plane, and we want to determine whether there exists a\ntriple $(a,b,c) \\in A\\times B\\times C$ that simultaneously satisfies two\nindependent real polynomial equations. For example, this is the setup when\ntesting for collinearity in the complex plane, when each of the sets $A$, $B$,\n$C$ lies on some constant-degree algebraic curve. We show that problems of this\nkind can be solved with roughly $O(n^{24/13})$ constant-degree polynomial sign\ntests.\n", "versions": [{"version": "v1", "created": "Sat, 21 Mar 2020 00:06:37 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 23:35:01 GMT"}, {"version": "v3", "created": "Mon, 28 Sep 2020 20:14:48 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Aronov", "Boris", ""], ["Ezra", "Esther", ""], ["Sharir", "Micha", ""]]}, {"id": "2003.09725", "submitter": "Gary Pui-Tung Choi", "authors": "Gary P. T. Choi, Chris H. Rycroft", "title": "Volumetric density-equalizing reference map with applications", "comments": null, "journal-ref": "Journal of Scientific Computing, 86(3), 41 (2021)", "doi": "10.1007/s10915-021-01411-4", "report-no": null, "categories": "math.NA cs.CG cs.GR cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The density-equalizing map, a technique developed for cartogram creation, has\nbeen widely applied to data visualization but only for 2D applications. In this\nwork, we propose a novel method called the volumetric density-equalizing\nreference map (VDERM) for computing density-equalizing map for volumetric\ndomains. Given a prescribed density distribution in a volumetric domain in\n$\\mathbb{R}^3$, the proposed method continuously deforms the domain, with\ndifferent volume elements enlarged or shrunk according to the density\ndistribution. With the aid of the proposed method, medical and sociological\ndata can be visualized via deformations of 3D objects. The method can also be\napplied to adaptive remeshing and shape modeling. Furthermore, by exploiting\nthe time-dependent nature of the proposed method, applications to shape\nmorphing can be easily achieved. Experimental results are presented to\ndemonstrate the effectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Sat, 21 Mar 2020 18:58:51 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Choi", "Gary P. T.", ""], ["Rycroft", "Chris H.", ""]]}, {"id": "2003.09904", "submitter": "Georg Nawratil", "authors": "Georg Nawratil", "title": "On the snappability and singularity-distance of frameworks with bars and\n  triangular plates", "comments": "8 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a recent article the author presented a method to measure the snapping\ncapability -- shortly called snappability -- of bar-joint frameworks based on\nthe total elastic strain energy by computing the deformation of all bars using\nHooke's law and the definition of Cauchy/Engineering strain. Within the paper\nat hand, we extend this approach to isostatic frameworks composed of bars and\ntriangular plates by using the physical concept of Green-Lagrange strain. An\nintrinsic pseudometric based on the resulting total elastic strain energy\ndensity cannot only be used for evaluating the snappability but also for\nmeasuring the distance to the closest singular configuration. The presented\nmethods are demonstrated on the basis of the 3-legged planar parallel\nmanipulator.\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2020 14:19:10 GMT"}, {"version": "v2", "created": "Mon, 31 Aug 2020 10:27:27 GMT"}, {"version": "v3", "created": "Tue, 1 Sep 2020 14:55:44 GMT"}, {"version": "v4", "created": "Mon, 11 Jan 2021 07:51:35 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Nawratil", "Georg", ""]]}, {"id": "2003.09914", "submitter": "Erik Demaine", "authors": "Josh Brunner, Lily Chung, Erik D. Demaine, Dylan Hendrickson, Adam\n  Hesterberg, Adam Suhl, Avi Zeff", "title": "1 x 1 Rush Hour with Fixed Blocks is PSPACE-complete", "comments": "15 pages, 11 figures. Improved figures and writing. To appear at FUN\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider $n^2-1$ unit-square blocks in an $n \\times n$ square board, where\neach block is labeled as movable horizontally (only), movable vertically\n(only), or immovable -- a variation of Rush Hour with only $1 \\times 1$ cars\nand fixed blocks. We prove that it is PSPACE-complete to decide whether a given\nblock can reach the left edge of the board, by reduction from Nondeterministic\nConstraint Logic via 2-color oriented Subway Shuffle. By contrast,\npolynomial-time algorithms are known for deciding whether a given block can be\nmoved by one space, or when each block either is immovable or can move both\nhorizontally and vertically. Our result answers a 15-year-old open problem by\nTromp and Cilibrasi, and strengthens previous PSPACE-completeness results for\nRush Hour with vertical $1 \\times 2$ and horizontal $2 \\times 1$ movable blocks\nand 4-color Subway Shuffle.\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2020 14:55:11 GMT"}, {"version": "v2", "created": "Fri, 1 May 2020 19:22:15 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Brunner", "Josh", ""], ["Chung", "Lily", ""], ["Demaine", "Erik D.", ""], ["Hendrickson", "Dylan", ""], ["Hesterberg", "Adam", ""], ["Suhl", "Adam", ""], ["Zeff", "Avi", ""]]}, {"id": "2003.09948", "submitter": "Mark De Berg", "authors": "Henk Alkema and Mark de Berg and S\\'andor Kisfaludi-Bak", "title": "Euclidean TSP in Narrow Strip", "comments": "To appear in: Proceedings 36th International Symposium on\n  Computational Geometry (SoCG 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate how the complexity of Euclidean TSP for point sets $P$ inside\nthe strip $(-\\infty,+\\infty)\\times [0,\\delta]$ depends on the strip width\n$\\delta$. We obtain two main results. First, for the case where the points have\ndistinct integer $x$-coordinates, we prove that a shortest bitonic tour (which\ncan be computed in $O(n\\log^2 n)$ time using an existing algorithm) is\nguaranteed to be a shortest tour overall when $\\delta\\leq 2\\sqrt{2}$, a bound\nwhich is best possible. Second, we present an algorithm that is fixed-parameter\ntractable with respect to $\\delta$. More precisely, our algorithm has running\ntime $2^{O(\\sqrt{\\delta})} n^2$ for sparse point sets, where each\n$1\\times\\delta$ rectangle inside the strip contains $O(1)$ points. For random\npoint sets, where the points are chosen uniformly at random from the\nrectangle~$[0,n]\\times [0,\\delta]$, it has an expected running time of\n$2^{O(\\sqrt{\\delta})} n^2 + O(n^3)$.\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2020 17:08:31 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Alkema", "Henk", ""], ["de Berg", "Mark", ""], ["Kisfaludi-Bak", "S\u00e1ndor", ""]]}, {"id": "2003.10057", "submitter": "Patrick Lin", "authors": "Jeff Erickson and Patrick Lin", "title": "A Toroidal Maxwell-Cremona-Delaunay Correspondence", "comments": "24 pages, 6 figures. The correct title uses en-dashes (which arXiv\n  does not support) instead of hyphens. Preliminary version appeared at SoCG\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.MG cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider three classes of geodesic embeddings of graphs on Euclidean flat\ntori: (1) A torus graph $G$ is equilibrium if it is possible to place positive\nweights on the edges, such that the weighted edge vectors incident to each\nvertex of G sum to zero. (2) A torus graph $G$ is reciprocal if there is a\ngeodesic embedding of the dual graph $G^*$ on the same flat torus, where each\nedge of $G$ is orthogonal to the corresponding dual edge in $G^*$. (3) A torus\ngraph $G$ is coherent if it is possible to assign weights to the vertices, so\nthat $G$ is the (intrinsic) weighted Delaunay graph of its vertices. The\nclassical Maxwell-Cremona correspondence and the well-known correspondence\nbetween convex hulls and weighted Delaunay triangulations imply that the\nanalogous concepts for plane graphs (with convex outer faces) are equivalent.\nIndeed, all three conditions are equivalent to $G$ being the projection of the\n1-skeleton of the lower convex hull of points in $\\mathbb{R}^3$. However, this\nthree-way equivalence does not extend directly to geodesic graphs on flat tori.\nOn any flat torus, reciprocal and coherent graphs are equivalent, and every\nreciprocal graph is equilibrium, but not every equilibrium graph is reciprocal.\nWe establish a weaker correspondence: Every equilibrium graph on any flat torus\nis affinely equivalent to a reciprocal/coherent graph on some flat torus.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 02:38:58 GMT"}, {"version": "v2", "created": "Sat, 1 Aug 2020 04:31:34 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Erickson", "Jeff", ""], ["Lin", "Patrick", ""]]}, {"id": "2003.10983", "submitter": "Rohan Chabra", "authors": "Rohan Chabra, Jan Eric Lenssen, Eddy Ilg, Tanner Schmidt, Julian\n  Straub, Steven Lovegrove, Richard Newcombe", "title": "Deep Local Shapes: Learning Local SDF Priors for Detailed 3D\n  Reconstruction", "comments": "Accepted at ECCV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CG cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficiently reconstructing complex and intricate surfaces at scale is a\nlong-standing goal in machine perception. To address this problem we introduce\nDeep Local Shapes (DeepLS), a deep shape representation that enables encoding\nand reconstruction of high-quality 3D shapes without prohibitive memory\nrequirements. DeepLS replaces the dense volumetric signed distance function\n(SDF) representation used in traditional surface reconstruction systems with a\nset of locally learned continuous SDFs defined by a neural network, inspired by\nrecent work such as DeepSDF. Unlike DeepSDF, which represents an object-level\nSDF with a neural network and a single latent code, we store a grid of\nindependent latent codes, each responsible for storing information about\nsurfaces in a small local neighborhood. This decomposition of scenes into local\nshapes simplifies the prior distribution that the network must learn, and also\nenables efficient inference. We demonstrate the effectiveness and\ngeneralization power of DeepLS by showing object shape encoding and\nreconstructions of full scenes, where DeepLS delivers high compression,\naccuracy, and local shape completion.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 17:21:50 GMT"}, {"version": "v2", "created": "Sat, 11 Apr 2020 09:27:30 GMT"}, {"version": "v3", "created": "Fri, 21 Aug 2020 21:52:09 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Chabra", "Rohan", ""], ["Lenssen", "Jan Eric", ""], ["Ilg", "Eddy", ""], ["Schmidt", "Tanner", ""], ["Straub", "Julian", ""], ["Lovegrove", "Steven", ""], ["Newcombe", "Richard", ""]]}, {"id": "2003.11381", "submitter": "Marek Kaluba", "authors": "Marek Kaluba, Benjamin Lorenz and Sascha Timme", "title": "Polymake.jl: A new interface to polymake", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CG math.MG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the Julia interface Polymake.jl to polymake, a software for\nresearch in polyhedral geometry. We describe the technical design and how the\nintegration into Julia makes it possible to combine polymake with\nstate-of-the-art numerical software.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 15:16:56 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Kaluba", "Marek", ""], ["Lorenz", "Benjamin", ""], ["Timme", "Sascha", ""]]}, {"id": "2003.11490", "submitter": "Zolt\\'an Kov\\'acs", "authors": "Zolt\\'an Kov\\'acs", "title": "Two almost-circles, and two real ones", "comments": "13 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.HO cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Implicit locus equations in GeoGebra allow the user to do experiments with\ngeneralization of the concept of ellipses, namely with $n$-ellipses. By\nexperimenting we obtain a geometric object that is very similar to a set of two\ncircles.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 16:46:16 GMT"}, {"version": "v2", "created": "Thu, 26 Mar 2020 11:11:00 GMT"}, {"version": "v3", "created": "Sat, 23 May 2020 14:33:46 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Kov\u00e1cs", "Zolt\u00e1n", ""]]}, {"id": "2003.11527", "submitter": "Cl\\'ement Laroche", "authors": "Cl\\'ement Laroche", "title": "An Implicit Representation of Swept Volumes based on Local Shapes and\n  Movements", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new way to implicitly represent swept volumes in 3D. We first\nimplicitize the base volume and then apply the time-dependent rigid\ntransformation to build an implicit representation of the swept volume. This\nway, we build a fitting representation, where geometric details generated by\nthe rigid transformation and details of the base volume itself are both taken\ninto account. This representation relies on a partition of a boundary box of\nthe swept volume according to portions of the space related either to parts of\nthe base volume or to time span of the transformation.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 17:46:15 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Laroche", "Cl\u00e9ment", ""]]}, {"id": "2003.11604", "submitter": "Yakov Nekrich", "authors": "Timothy M. Chan, Qizheng He, Yakov Nekrich", "title": "Further Results on Colored Range Searching", "comments": "full version of a SoCG'20 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a number of new results about range searching for colored (or\n\"categorical\") data:\n  1. For a set of $n$ colored points in three dimensions, we describe\nrandomized data structures with $O(n\\mathop{\\rm polylog}n)$ space that can\nreport the distinct colors in any query orthogonal range (axis-aligned box) in\n$O(k\\mathop{\\rm polyloglog} n)$ expected time, where $k$ is the number of\ndistinct colors in the range, assuming that coordinates are in\n$\\{1,\\ldots,n\\}$. Previous data structures require $O(\\frac{\\log n}{\\log\\log n}\n+ k)$ query time. Our result also implies improvements in higher constant\ndimensions.\n  2. Our data structures can be adapted to halfspace ranges in three dimensions\n(or circular ranges in two dimensions), achieving $O(k\\log n)$ expected query\ntime. Previous data structures require $O(k\\log^2n)$ query time.\n  3. For a set of $n$ colored points in two dimensions, we describe a data\nstructure with $O(n\\mathop{\\rm polylog}n)$ space that can answer colored\n\"type-2\" range counting queries: report the number of occurrences of every\ndistinct color in a query orthogonal range. The query time is $O(\\frac{\\log\nn}{\\log\\log n} + k\\log\\log n)$, where $k$ is the number of distinct colors in\nthe range. Naively performing $k$ uncolored range counting queries would\nrequire $O(k\\frac{\\log n}{\\log\\log n})$ time.\n  Our data structures are designed using a variety of techniques, including\ncolored variants of randomized incremental construction (which may be of\nindependent interest), colored variants of shallow cuttings, and bit-packing\ntricks.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 20:04:20 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Chan", "Timothy M.", ""], ["He", "Qizheng", ""], ["Nekrich", "Yakov", ""]]}, {"id": "2003.11890", "submitter": "Jean Cardinal", "authors": "Boris Aronov and Jean Cardinal", "title": "Geometric Pattern Matching Reduces to k-SUM", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that some exact geometric pattern matching problems reduce in linear\ntime to $k$-SUM when the pattern has a fixed size $k$. This holds in the real\nRAM model for searching for a similar copy of a set of $k\\geq 3$ points within\na set of $n$ points in the plane, and for searching for an affine image of a\nset of $k\\geq d+2$ points within a set of $n$ points in $d$-space.\n  As corollaries, we obtain improved real RAM algorithms and decision trees for\nthe two problems. In particular, they can be solved by algebraic decision trees\nof near-linear height.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 13:30:58 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Aronov", "Boris", ""], ["Cardinal", "Jean", ""]]}, {"id": "2003.11914", "submitter": "Sivan Toledo", "authors": "Nir Goren, Dan Halperin, and Sivan Toledo", "title": "Geometric Sparsification of Closeness Relations: Eigenvalue Clustering\n  for Computing Matrix Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.MS cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how to efficiently solve a clustering problem that arises in a method\nto evaluate functions of matrices. The problem requires finding the connected\ncomponents of a graph whose vertices are eigenvalues of a real or complex\nmatrix and whose edges are pairs of eigenvalues that are at most \\delta away\nfrom each other. Davies and Higham proposed solving this problem by enumerating\nthe edges of the graph, which requires at least $\\Omega(n^{2})$ work. We show\nthat the problem can be solved by computing the Delaunay triangulation of the\neigenvalues, removing from it long edges, and computing the connected\ncomponents of the remaining edges in the triangulation. This leads to an\n$O(n\\log n)$ algorithm. We have implemented both algorithms using CGAL, a\nmature and sophisticated computational-geometry software library, and we\ndemonstrate that the new algorithm is much faster in practice than the naive\nalgorithm. We also present a tight analysis of the naive algorithm, showing\nthat it performs $\\Theta(n^{2})$ work, and correct a misrepresentation in the\noriginal statement of the problem. To the best of our knowledge, this is the\nfirst application of computational geometry to solve a real-world problem in\nnumerical linear algebra.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 08:21:58 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Goren", "Nir", ""], ["Halperin", "Dan", ""], ["Toledo", "Sivan", ""]]}, {"id": "2003.11974", "submitter": "Alexandros Hollender", "authors": "Aris Filos-Ratsikas, Alexandros Hollender, Katerina Sotiraki, Manolis\n  Zampetakis", "title": "A Topological Characterization of Modulo-$p$ Arguments and Implications\n  for Necklace Splitting", "comments": "v2: improved presentation based on reviewer comments and suggestions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CG cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The classes PPA-$p$ have attracted attention lately, because they are the\nmain candidates for capturing the complexity of Necklace Splitting with $p$\nthieves, for prime $p$. However, these classes were not known to have complete\nproblems of a topological nature, which impedes any progress towards settling\nthe complexity of the Necklace Splitting problem. On the contrary, topological\nproblems have been pivotal in obtaining completeness results for PPAD and PPA,\nsuch as the PPAD-completeness of finding a Nash equilibrium [Daskalakis et al.,\n2009, Chen et al., 2009b] and the PPA-completeness of Necklace Splitting with 2\nthieves [Filos-Ratsikas and Goldberg, 2019].\n  In this paper, we provide the first topological characterization of the\nclasses PPA-$p$. First, we show that the computational problem associated with\na simple generalization of Tucker's Lemma, termed $p$-polygon-Tucker, as well\nas the associated Borsuk-Ulam-type theorem, $p$-polygon-Borsuk-Ulam, are\nPPA-$p$-complete. Then, we show that the computational version of the\nwell-known BSS Theorem [Barany et al., 1981], as well as the associated\nBSS-Tucker problem are PPA-$p$-complete. Finally, using a different\ngeneralization of Tucker's Lemma (termed $\\mathbb{Z}_p$-star-Tucker), which we\nprove to be PPA-$p$-complete, we prove that $p$-thief Necklace Splitting is in\nPPA-$p$. This latter result gives a new combinatorial proof for the Necklace\nSplitting theorem, the only proof of this nature other than that of Meunier\n[2014].\n  All of our containment results are obtained through a new combinatorial proof\nfor $\\mathbb{Z}_p$-versions of Tucker's lemma that is a natural generalization\nof the standard combinatorial proof of Tucker's lemma by Freund and Todd\n[1981]. We believe that this new proof technique is of independent interest.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 15:15:07 GMT"}, {"version": "v2", "created": "Mon, 18 Jan 2021 19:40:24 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Filos-Ratsikas", "Aris", ""], ["Hollender", "Alexandros", ""], ["Sotiraki", "Katerina", ""], ["Zampetakis", "Manolis", ""]]}, {"id": "2003.12283", "submitter": "Antonio Norelli", "authors": "Luca Cosmo, Antonio Norelli, Oshri Halimi, Ron Kimmel, Emanuele\n  Rodol\\`a", "title": "LIMP: Learning Latent Shape Representations with Metric Preservation\n  Priors", "comments": "24 pages (main article 14 + main bibliography 3 + supplementary 6 +\n  supplementary bibliography 1)", "journal-ref": null, "doi": "10.1007/978-3-030-58580-8_2", "report-no": null, "categories": "cs.LG cs.CG cs.GR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we advocate the adoption of metric preservation as a powerful\nprior for learning latent representations of deformable 3D shapes. Key to our\nconstruction is the introduction of a geometric distortion criterion, defined\ndirectly on the decoded shapes, translating the preservation of the metric on\nthe decoding to the formation of linear paths in the underlying latent space.\nOur rationale lies in the observation that training samples alone are often\ninsufficient to endow generative models with high fidelity, motivating the need\nfor large training datasets. In contrast, metric preservation provides a\nrigorous way to control the amount of geometric distortion incurring in the\nconstruction of the latent space, leading in turn to synthetic samples of\nhigher quality. We further demonstrate, for the first time, the adoption of\ndifferentiable intrinsic distances in the backpropagation of a geodesic loss.\nOur geometric priors are particularly relevant in the presence of scarce\ntraining data, where learning any meaningful latent structure can be especially\nchallenging. The effectiveness and potential of our generative model is\nshowcased in applications of style transfer, content generation, and shape\ncompletion.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 08:53:34 GMT"}, {"version": "v2", "created": "Wed, 2 Sep 2020 13:14:57 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Cosmo", "Luca", ""], ["Norelli", "Antonio", ""], ["Halimi", "Oshri", ""], ["Kimmel", "Ron", ""], ["Rodol\u00e0", "Emanuele", ""]]}, {"id": "2003.12745", "submitter": "Herman Haverkort", "authors": "Herman Haverkort", "title": "Plane-filling trails", "comments": "Full version (9 pages) of a submission that is conditionally accepted\n  to the 2020 Computational Geometry Week Media Exposition", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG math.MG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The order in which plane-filling curves visit points in the plane can be\nexploited to design efficient algorithms. Typically, the curves are useful\nbecause they preserve locality: points that are close to each other along the\ncurve tend to be close to each other in the plane, and vice versa. However,\nsketches of plane-filling curves do not show this well: they are hard to read\non different levels of detail and it is hard to see how far apart points are\nalong the curve. This paper presents a software tool to produce compelling\nvisualisations that may give more insight in the structure of the curves.\n", "versions": [{"version": "v1", "created": "Sat, 28 Mar 2020 08:52:25 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Haverkort", "Herman", ""]]}, {"id": "2003.12778", "submitter": "Mohammad Reza Zarrabi", "authors": "Mohammad Reza Zarrabi, Nasrollah Moghaddam Charkari", "title": "Single-Point Visibility Constraint Minimum Link Paths in Simple Polygons", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the following problem: Given a simple polygon $P$ with $n$\nvertices and two points $s$ and $t$ inside it, find a minimum link path between\nthem such that a given target point $q$ is visible from at least one point on\nthe path. The method is based on partitioning a portion of $P$ into a number of\nfaces of equal link distance from a source point. This partitioning is\nessentially a shortest path map (SPM). In this paper, we present an optimal\nalgorithm with $O(n)$ time bound, which is the same as the time complexity of\nthe standard minimum link paths problem.\n", "versions": [{"version": "v1", "created": "Sat, 28 Mar 2020 12:18:22 GMT"}, {"version": "v2", "created": "Sun, 3 May 2020 11:19:55 GMT"}, {"version": "v3", "created": "Tue, 30 Jun 2020 12:57:14 GMT"}, {"version": "v4", "created": "Sun, 28 Feb 2021 17:07:19 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Zarrabi", "Mohammad Reza", ""], ["Charkari", "Nasrollah Moghaddam", ""]]}, {"id": "2003.13097", "submitter": "Tim Wylie", "authors": "David Caballero, Angel A. Cantu, Timothy Gomez, Austin Luchsinger,\n  Robert Schweller, Tim Wylie", "title": "Hardness of Reconfiguring Robot Swarms with Uniform External Control in\n  Limited Directions", "comments": "A short abstract of this was presented at the 22nd Japan Conference\n  on Discrete and Computational Geometry, Graphs, and Games (JCDCG3'19), 39-40,\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.ET", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Motivated by advances is nanoscale applications and simplistic robot agents,\nwe look at problems based on using a global signal to move all agents when\ngiven a limited number of directional signals and immovable geometry. We study\na model where unit square particles move within a 2D grid based on uniform\nexternal forces. Movement is based on a sequence of uniform commands which\ncause all particles to move 1 step in a specific direction. The 2D grid board\nadditionally contains \"blocked\" spaces which prevent particles from entry.\nWithin this model, we investigate the complexity of deciding 1) whether a\ntarget location on the board can be occupied (by any) particle (\\emph{occupancy\nproblem}), 2) whether a specific particle can be relocated to another specific\nposition in the board (\\emph{relocation problem}), and 3) whether a board\nconfiguration can be transformed into another configuration\n(\\emph{reconfiguration problem}). We prove that while occupancy is solvable in\npolynomial time, the relocation and reconfiguration problems are both\nNP-Complete even when restricted to only 2 or 3 movement directions. We further\ndefine a hierarchy of board geometries and show that this hardness holds for\neven very restricted classes of board geometry.\n", "versions": [{"version": "v1", "created": "Sun, 29 Mar 2020 18:11:37 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Caballero", "David", ""], ["Cantu", "Angel A.", ""], ["Gomez", "Timothy", ""], ["Luchsinger", "Austin", ""], ["Schweller", "Robert", ""], ["Wylie", "Tim", ""]]}, {"id": "2003.13192", "submitter": "Uri Stemmer", "authors": "Haim Kaplan, Micha Sharir, Uri Stemmer", "title": "How to Find a Point in the Convex Hull Privately", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the question of how to compute a point in the convex hull of an\ninput set $S$ of $n$ points in ${\\mathbb R}^d$ in a differentially private\nmanner. This question, which is trivial non-privately, turns out to be quite\ndeep when imposing differential privacy. In particular, it is known that the\ninput points must reside on a fixed finite subset $G\\subseteq{\\mathbb R}^d$,\nand furthermore, the size of $S$ must grow with the size of $G$. Previous works\nfocused on understanding how $n$ needs to grow with $|G|$, and showed that\n$n=O\\left(d^{2.5}\\cdot8^{\\log^*|G|}\\right)$ suffices (so $n$ does not have to\ngrow significantly with $|G|$). However, the available constructions exhibit\nrunning time at least $|G|^{d^2}$, where typically $|G|=X^d$ for some (large)\ndiscretization parameter $X$, so the running time is in fact $\\Omega(X^{d^3})$.\n  In this paper we give a differentially private algorithm that runs in\n$O(n^d)$ time, assuming that $n=\\Omega(d^4\\log X)$. To get this result we study\nand exploit some structural properties of the Tukey levels (the regions $D_{\\ge\nk}$ consisting of points whose Tukey depth is at least $k$, for $k=0,1,...$).\nIn particular, we derive lower bounds on their volumes for point sets $S$ in\ngeneral position, and develop a rather subtle mechanism for handling point sets\n$S$ in degenerate position (where the deep Tukey regions have zero volume). A\nnaive approach to the construction of the Tukey regions requires $n^{O(d^2)}$\ntime. To reduce the cost to $O(n^d)$, we use an approximation scheme for\nestimating the volumes of the Tukey regions (within their affine spans in case\nof degeneracy), and for sampling a point from such a region, a scheme that is\nbased on the volume estimation framework of Lov\\'asz and Vempala (FOCS 2003)\nand of Cousins and Vempala (STOC 2015). Making this framework differentially\nprivate raises a set of technical challenges that we address.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 02:42:48 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Kaplan", "Haim", ""], ["Sharir", "Micha", ""], ["Stemmer", "Uri", ""]]}, {"id": "2003.13253", "submitter": "Sebastian Feld", "authors": "Sebastian Feld, Markus Friedrich, Claudia Linnhoff-Popien", "title": "Optimizing Geometry Compression using Quantum Annealing", "comments": "6 pages, 3 figures", "journal-ref": "2018 IEEE Globecom Workshops (GC Wkshps), Abu Dhabi, United Arab\n  Emirates, 2018, pp. 1-6", "doi": "10.1109/GLOCOMW.2018.8644358", "report-no": null, "categories": "quant-ph cs.CG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The compression of geometry data is an important aspect of\nbandwidth-efficient data transfer for distributed 3d computer vision\napplications. We propose a quantum-enabled lossy 3d point cloud compression\npipeline based on the constructive solid geometry (CSG) model representation.\nKey parts of the pipeline are mapped to NP-complete problems for which an\nefficient Ising formulation suitable for the execution on a Quantum Annealer\nexists. We describe existing Ising formulations for the maximum clique search\nproblem and the smallest exact cover problem, both of which are important\nbuilding blocks of the proposed compression pipeline. Additionally, we discuss\nthe properties of the overall pipeline regarding result optimality and\ndescribed Ising formulations.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 07:56:34 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Feld", "Sebastian", ""], ["Friedrich", "Markus", ""], ["Linnhoff-Popien", "Claudia", ""]]}, {"id": "2003.13291", "submitter": "Wolfgang Mulzer", "authors": "Wolfgang Mulzer and Pavel Valtr", "title": "Long Alternating Paths Exist", "comments": "26 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $P$ be a set of $2n$ points in convex position, such that $n$ points are\ncolored red and $n$ points are colored blue. A non-crossing alternating path on\n$P$ of length $\\ell$ is a sequence $p_1, \\dots, p_\\ell$ of $\\ell$ points from\n$P$ so that (i) all points are pairwise distinct; (ii) any two consecutive\npoints $p_i$, $p_{i+1}$ have different colors; and (iii) any two segments $p_i\np_{i+1}$ and $p_j p_{j+1}$ have disjoint relative interiors, for $i \\neq j$.\n  We show that there is an absolute constant $\\varepsilon > 0$, independent of\n$n$ and of the coloring, such that $P$ always admits a non-crossing alternating\npath of length at least $(1 + \\varepsilon)n$. The result is obtained through a\nslightly stronger statement: there always exists a non-crossing bichromatic\nseparated matching on at least $(1 + \\varepsilon)n$ points of $P$. This is a\nproperly colored matching whose segments are pairwise disjoint and intersected\nby common line. For both versions, this is the first improvement of the easily\nobtained lower bound of $n$ by an additive term linear in $n$. The best known\npublished upper bounds are asymptotically of order $4n/3+o(n)$.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 09:24:16 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Mulzer", "Wolfgang", ""], ["Valtr", "Pavel", ""]]}, {"id": "2003.13420", "submitter": "Qizheng He", "authors": "Timothy M. Chan and Qizheng He", "title": "Faster Approximation Algorithms for Geometric Set Cover", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We improve the running times of $O(1)$-approximation algorithms for the set\ncover problem in geometric settings, specifically, covering points by disks in\nthe plane, or covering points by halfspaces in three dimensions. In the\nunweighted case, Agarwal and Pan [SoCG 2014] gave a randomized $O(n\\log^4\nn)$-time, $O(1)$-approximation algorithm, by using variants of the\nmultiplicative weight update (MWU) method combined with geometric data\nstructures. We simplify the data structure requirement in one of their methods\nand obtain a deterministic $O(n\\log^3 n\\log\\log n)$-time algorithm. With\nfurther new ideas, we obtain a still faster randomized $O(n\\log n(\\log\\log\nn)^{O(1)})$-time algorithm.\n  For the weighted problem, we also give a randomized $O(n\\log^4n\\log\\log\nn)$-time, $O(1)$-approximation algorithm, by simple modifications to the MWU\nmethod and the quasi-uniform sampling technique.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 22:49:17 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Chan", "Timothy M.", ""], ["He", "Qizheng", ""]]}, {"id": "2003.13536", "submitter": "Martin Tancer", "authors": "Zuzana Pat\\'akov\\'a and Martin Tancer and Uli Wagner", "title": "Barycentric cuts through a convex body", "comments": "19 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CG math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $K$ be a convex body in $\\mathbb{R}^n$ (i.e., a compact convex set with\nnonempty interior). Given a point $p$ in the interior of $K$, a hyperplane $h$\npassing through $p$ is called barycentric if $p$ is the barycenter of $K \\cap\nh$. In 1961, Gr\\\"{u}nbaum raised the question whether, for every $K$, there\nexists an interior point $p$ through which there are at least $n+1$ distinct\nbarycentric hyperplanes. Two years later, this was seemingly resolved\naffirmatively by showing that this is the case if $p=p_0$ is the point of\nmaximal depth in $K$. However, while working on a related question, we noticed\nthat one of the auxiliary claims in the proof is incorrect. Here, we provide a\ncounterexample; this re-opens Gr\\\"unbaum's question. It follows from known\nresults that for $n \\geq 2$, there are always at least three distinct\nbarycentric cuts through the point $p_0 \\in K$ of maximal depth. Using tools\nrelated to Morse theory we are able to improve this bound: four distinct\nbarycentric cuts through $p_0$ are guaranteed if $n \\geq 3$.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 16:11:58 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Pat\u00e1kov\u00e1", "Zuzana", ""], ["Tancer", "Martin", ""], ["Wagner", "Uli", ""]]}, {"id": "2003.13557", "submitter": "Emo Welzl", "authors": "Uli Wagner and Emo Welzl", "title": "Connectivity of Triangulation Flip Graphs in the Plane", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a finite point set P in general position in the plane, a full\ntriangulation is a maximal straight-line embedded plane graph on P. A partial\ntriangulation is a full triangulation of some subset P' of P containing all\nextreme points in P. A bistellar flip on a partial triangulation flips an edge\n(an edge flip), removes a non-extreme point of degree 3, or adds a point in P \\\nP' as vertex of degree 3. The bistellar flip graph has all partial\ntriangulations as vertices, and a pair of partial triangulations is adjacent if\nthey can be obtained from one another by a bistellar flip. The edge flip graph\nis defined with full triangulations as vertices, and edge flips determining the\nadjacencies. Lawson showed in the early 70s that these graphs are connected.\nOur goal is to investigate these graphs, with emphasis on vertex connectivity.\n  For sets of n points in the plane in general position, we show that the edge\nflip graph is (n/2-2)-connected, and the bistellar flip graph is\n(n-3)-connected; both results are tight. The latter bound matches the situation\nfor the subfamily of regular triangulations, ie. partial triangulations\nobtained by lifting the points to 3-space and projecting back the lower convex\nhull. Here (n-3)-connectivity has been known since the late 80s via the\nsecondary polytope due to Gelfand, Kapranov & Zelevinsky and Balinski's\nTheorem. For the edge flip-graphs, the vertex connectivity can be shown to be\nat least as large as (and hence equal to) the minimum degree, provided n is\nlarge enough. Our methods yield several other results.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 15:31:47 GMT"}, {"version": "v2", "created": "Fri, 14 Aug 2020 17:52:43 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Wagner", "Uli", ""], ["Welzl", "Emo", ""]]}, {"id": "2003.13595", "submitter": "Carola Wenk", "authors": "Parker Evans and Carola Wenk", "title": "Combinatorial Properties of Self-Overlapping Curves and Interior\n  Boundaries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the interplay between the recently defined concept of minimum\nhomotopy area and the classical topic of self-overlapping curves. The latter\nare plane curves which are the image of the boundary of an immersed disk. Our\nfirst contribution is to prove new sufficient combinatorial conditions for a\ncurve to be self-overlapping. We show that a curve $\\gamma$ with Whitney index\n1 and without any self-overlapping subcurves is self-overlapping. As a\ncorollary, we obtain sufficient conditions for self-overlappingness solely in\nterms of the Whitney index of the curve and its subcurves. These results follow\nfrom our second contribution, which shows that any plane curve $\\gamma$, modulo\na basepoint condition, is transformed into an interior boundary by wrapping\naround $\\gamma$ with Jordan curves. Equivalently, the minimum homotopy area of\n$\\gamma$ is reduced to the minimal possible threshold, namely the winding area,\nthrough wrapping. In fact, we show that $n+1$ wraps suffice, where $\\gamma$ has\n$n$ vertices. Our third contribution is to prove the equivalence of various\ndefinitions of self-overlapping curves and interior boundaries, often implicit\nin the literature. We also introduce and characterize zero-obstinance curves,\nfurther generalizations of interior boundaries defined by optimality in minimum\nhomotopy area.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 16:24:11 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Evans", "Parker", ""], ["Wenk", "Carola", ""]]}, {"id": "2003.14034", "submitter": "Siyuan Xiang", "authors": "Wenyu Han, Siyuan Xiang, Chenhui Liu, Ruoyu Wang, Chen Feng", "title": "SPARE3D: A Dataset for SPAtial REasoning on Three-View Line Drawings", "comments": "This paper has been accepted in CVPR'20. The first two authors\n  contributed equally. Chen Feng is the corresponding author", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CG cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatial reasoning is an important component of human intelligence. We can\nimagine the shapes of 3D objects and reason about their spatial relations by\nmerely looking at their three-view line drawings in 2D, with different levels\nof competence. Can deep networks be trained to perform spatial reasoning tasks?\nHow can we measure their \"spatial intelligence\"? To answer these questions, we\npresent the SPARE3D dataset. Based on cognitive science and psychometrics,\nSPARE3D contains three types of 2D-3D reasoning tasks on view consistency,\ncamera pose, and shape generation, with increasing difficulty. We then design a\nmethod to automatically generate a large number of challenging questions with\nground truth answers for each task. They are used to provide supervision for\ntraining our baseline models using state-of-the-art architectures like ResNet.\nOur experiments show that although convolutional networks have achieved\nsuperhuman performance in many visual learning tasks, their spatial reasoning\nperformance on SPARE3D tasks is either lower than average human performance or\neven close to random guesses. We hope SPARE3D can stimulate new problem\nformulations and network designs for spatial reasoning to empower intelligent\nrobots to operate effectively in the 3D world via 2D sensors. The dataset and\ncode are available at https://ai4ce.github.io/SPARE3D.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 09:01:27 GMT"}, {"version": "v2", "created": "Wed, 2 Sep 2020 14:18:47 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Han", "Wenyu", ""], ["Xiang", "Siyuan", ""], ["Liu", "Chenhui", ""], ["Wang", "Ruoyu", ""], ["Feng", "Chen", ""]]}, {"id": "2003.14413", "submitter": "Therese Biedl", "authors": "Therese Biedl and Milap Sheth", "title": "Drawing Halin-graphs with small height", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study how to draw Halin-graphs, i.e., planar graphs that\nconsist of a tree $T$ and a cycle among the leaves of that tree. Based on\ntree-drawing algorithms and the pathwidth $ pw(T) $, a well-known graph\nparameter, we find poly-line drawings of height at most $6pw(T)+3\\in O(\\log\nn)$. We also give an algorithm for straight-line drawings, and achieve height\nat most $12pw(T)+1$ for Halin-graphs, and smaller if the Halin-graph is cubic.\nWe show that the height achieved by our algorithms is optimal in the worst case\n(i.e. for some Halin-graphs).\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 17:56:54 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Biedl", "Therese", ""], ["Sheth", "Milap", ""]]}]