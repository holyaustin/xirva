[{"id": "1007.0120", "submitter": "Olivier Laurent", "authors": "Thomas Ehrhard (PPS (CNRS - Univ Paris 7)), Olivier Laurent (PPS (CNRS\n  - Univ Paris 7))", "title": "Acyclic Solos and Differential Interaction Nets", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 6, Issue 3 (September\n  1, 2010) lmcs:771", "doi": "10.2168/LMCS-6(3:11)2010", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a restriction of the solos calculus which is stable under\nreduction and expressive enough to contain an encoding of the pi-calculus. As a\nconsequence, it is shown that equalizing names that are already equal is not\nrequired by the encoding of the pi-calculus. In particular, the induced solo\ndiagrams bear an acyclicity property that induces a faithful encoding into\ndifferential interaction nets. This gives a (new) proof that differential\ninteraction nets are expressive enough to contain an encoding of the\npi-calculus. All this is worked out in the case of finitary (replication free)\nsystems without sum, match nor mismatch.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2010 10:23:59 GMT"}, {"version": "v2", "created": "Mon, 26 Jul 2010 17:50:06 GMT"}, {"version": "v3", "created": "Wed, 1 Sep 2010 14:36:19 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Ehrhard", "Thomas", "", "PPS"], ["Laurent", "Olivier", "", "PPS"]]}, {"id": "1007.0159", "submitter": "Marcus Denker", "authors": "Adrian Kuhn, David Erni, Marcus Denker", "title": "Empowering Collections with Swarm Behavior", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Often, when modelling a system there are properties and operations that are\nrelated to a group of objects rather than to a single object. In this paper we\nextend Java with Swarm Behavior, a new composition operator that associates\nbehavior with a collection of instances. The lookup resolution of swarm\nbehavior is based on the element type of a collection and is thus orthogonal to\nthe collection hierarchy.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2010 13:14:39 GMT"}], "update_date": "2010-07-02", "authors_parsed": [["Kuhn", "Adrian", ""], ["Erni", "David", ""], ["Denker", "Marcus", ""]]}, {"id": "1007.2123", "submitter": "Serguei Mokhov", "authors": "Joey Paquet and Serguei A. Mokhov", "title": "Comparative Studies of Programming Languages; Course Lecture Notes", "comments": "66 pages; index; revision 1.9 -- more copy-editing (Type Systems) and\n  index updates; expected to evolve frequently while the course is in progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Lecture notes for the Comparative Studies of Programming Languages course,\nCOMP6411, taught at the Department of Computer Science and Software\nEngineering, Faculty of Engineering and Computer Science, Concordia University,\nMontreal, QC, Canada. These notes include a compiled book of primarily related\narticles from the Wikipedia, the Free Encyclopedia, as well as Comparative\nProgramming Languages book and other resources, including our own. The original\nnotes were compiled by Dr. Paquet.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2010 17:22:54 GMT"}, {"version": "v2", "created": "Mon, 19 Jul 2010 19:59:45 GMT"}, {"version": "v3", "created": "Tue, 20 Jul 2010 16:21:44 GMT"}, {"version": "v4", "created": "Thu, 22 Jul 2010 14:29:41 GMT"}, {"version": "v5", "created": "Tue, 27 Jul 2010 03:22:02 GMT"}, {"version": "v6", "created": "Wed, 4 Aug 2010 19:04:49 GMT"}], "update_date": "2010-08-05", "authors_parsed": [["Paquet", "Joey", ""], ["Mokhov", "Serguei A.", ""]]}, {"id": "1007.2885", "submitter": "Adam  Megacz", "authors": "Adam Megacz", "title": "Multi-Level Languages are Generalized Arrows", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-level languages and Arrows both facilitate metaprogramming, the act of\nwriting a program which generates a program. The arr function required of all\nArrows turns arbitrary host language expressions into guest language\nexpressions; because of this, Arrows may be used for metaprogramming only when\nthe guest language is a superset of the host language. This restriction is also\npresent in multi-level languages which offer unlimited cross-level persistence.\n<p> This paper introduces generalized arrows and proves that they generalize\nArrows in the following sense: every Arrow in a programming language arises\nfrom a generalized arrow with that language's term category as its codomain.\nGeneralized arrows impose no containment relationship between the guest\nlanguage and host language; they facilitate heterogeneous metaprogramming. The\ncategory having all generalized arrows as its morphisms and the category having\nall multi-level languages as its morphisms are isomorphic categories. This is\nproven formally in Coq, and the proof is offered as justification for the\nassertion that multi-level languages are generalized arrows. <p> Combined with\nthe existence of a particular kind of retraction in the host language, this\nproof can be used to define an invertible translation from two-level terms to\none-level terms parameterized by a generalized arrow instance. This is\nergonomically significant: it lets guest language providers write generalized\narrow instances while the users of those guest languages write multi-level\nterms. This is beneficial because implementing a generalized arrow instance is\neasier than modifying a compiler, whereas writing two-level terms is easier\nthan manipulating generalized arrow terms.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2010 22:42:04 GMT"}, {"version": "v2", "created": "Tue, 12 Apr 2011 02:24:13 GMT"}], "update_date": "2011-04-13", "authors_parsed": [["Megacz", "Adam", ""]]}, {"id": "1007.3023", "submitter": "Steven Obua", "authors": "Steven Obua", "title": "Purely Functional Structured Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The idea of functional programming has played a big role in shaping today's\nlandscape of mainstream programming languages. Another concept that dominates\nthe current programming style is Dijkstra's structured programming. Both\nconcepts have been successfully married, for example in the programming\nlanguage Scala. This paper proposes how the same can be achieved for structured\nprogramming and PURELY functional programming via the notion of LINEAR SCOPE.\nOne advantage of this proposal is that mainstream programmers can reap the\nbenefits of purely functional programming like easily exploitable parallelism\nwhile using familiar structured programming syntax and without knowing concepts\nlike monads. A second advantage is that professional purely functional\nprogrammers can often avoid hard to read functional code by using structured\nprogramming syntax that is often easier to parse mentally.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2010 17:29:53 GMT"}, {"version": "v2", "created": "Thu, 10 Feb 2011 17:57:10 GMT"}], "update_date": "2011-02-11", "authors_parsed": [["Obua", "Steven", ""]]}, {"id": "1007.3133", "submitter": "Laurent Hubert", "authors": "Laurent Hubert (INRIA - IRISA), Thomas Jensen (INRIA - IRISA), Vincent\n  Monfort (INRIA - IRISA), David Pichardie (INRIA - IRISA)", "title": "Enforcing Secure Object Initialization in Java", "comments": null, "journal-ref": "15th European Symposium on Research in Computer Security (ESORICS)\n  6345 (2010) 101-115", "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sun and the CERT recommend for secure Java development to not allow partially\ninitialized objects to be accessed. The CERT considers the severity of the\nrisks taken by not following this recommendation as high. The solution\ncurrently used to enforce object initialization is to implement a coding\npattern proposed by Sun, which is not formally checked. We propose a modular\ntype system to formally specify the initialization policy of libraries or\nprograms and a type checker to statically check at load time that all loaded\nclasses respect the policy. This allows to prove the absence of bugs which have\nallowed some famous privilege escalations in Java. Our experimental results\nshow that our safe default policy allows to prove 91% of classes of java.lang,\njava.security and javax.security safe without any annotation and by adding 57\nsimple annotations we proved all classes but four safe. The type system and its\nsoundness theorem have been formalized and machine checked using Coq.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2010 12:40:38 GMT"}], "update_date": "2010-11-22", "authors_parsed": [["Hubert", "Laurent", "", "INRIA - IRISA"], ["Jensen", "Thomas", "", "INRIA - IRISA"], ["Monfort", "Vincent", "", "INRIA - IRISA"], ["Pichardie", "David", "", "INRIA - IRISA"]]}, {"id": "1007.3183", "submitter": "Laurent Hubert", "authors": "Laurent Hubert (INRIA - IRISA)", "title": "A Non-Null Annotation Inferencer for Java Bytecode", "comments": null, "journal-ref": "PASTE: Program analysis for software tools and engineering,\n  Atlanta, Georgia : United States (2008)", "doi": "10.1145/1512475.1512484", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a non-null annotations inferencer for the Java bytecode language.\nWe previously proposed an analysis to infer non-null annotations and proved it\nsoundness and completeness with respect to a state of the art type system. This\npaper proposes extensions to our former analysis in order to deal with the Java\nbytecode language. We have implemented both analyses and compared their\nbehaviour on several benchmarks. The results show a substantial improvement in\nthe precision and, despite being a whole-program analysis, production\napplications can be analyzed within minutes.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2010 15:28:00 GMT"}], "update_date": "2010-07-26", "authors_parsed": [["Hubert", "Laurent", "", "INRIA - IRISA"]]}, {"id": "1007.3249", "submitter": "Laurent Hubert", "authors": "Laurent Hubert (INRIA - IRISA), David Pichardie (INRIA - IRISA)", "title": "Soundly Handling Static Fields: Issues, Semantics and Analysis", "comments": "Proceedings of the Fourth Workshop on Bytecode Semantics,\n  Verification, Analysis and Transformation (BYTECODE 2009)", "journal-ref": "Electronic Notes in Theoretical Computer Science 253, 5 (2009) 15\n  - 30", "doi": "10.1016/j.entcs.2009.11.012", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although in most cases class initialization works as expected, some static\nfields may be read before being initialized, despite being initialized in their\ncorresponding class initializer. We propose an analysis which compute, for each\nprogram point, the set of static fields that must have been initialized and\ndiscuss its soundness. We show that such an analysis can be directly applied to\nidentify the static fields that may be read before being initialized and to\nimprove the precision while preserving the soundness of a null-pointer\nanalysis.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2010 19:45:02 GMT"}, {"version": "v2", "created": "Tue, 20 Jul 2010 10:01:57 GMT"}], "update_date": "2010-07-21", "authors_parsed": [["Hubert", "Laurent", "", "INRIA - IRISA"], ["Pichardie", "David", "", "INRIA - IRISA"]]}, {"id": "1007.3250", "submitter": "Laurent Hubert", "authors": "Elvira Albert, Miguel G\\'omez-Zamalloa, Laurent Hubert, German Puebla", "title": "Verification of Java Bytecode using Analysis and Transformation of Logic\n  Programs", "comments": null, "journal-ref": "The International Symposium on Practical Aspects of Declarative\n  Languages 4354 (2007) 124-139", "doi": "10.1007/978-3-540-69611-7_8", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State of the art analyzers in the Logic Programming (LP) paradigm are\nnowadays mature and sophisticated. They allow inferring a wide variety of\nglobal properties including termination, bounds on resource consumption, etc.\nThe aim of this work is to automatically transfer the power of such analysis\ntools for LP to the analysis and verification of Java bytecode (JVML). In order\nto achieve our goal, we rely on well-known techniques for meta-programming and\nprogram specialization. More precisely, we propose to partially evaluate a JVML\ninterpreter implemented in LP together with (an LP representation of) a JVML\nprogram and then analyze the residual program. Interestingly, at least for the\nexamples we have studied, our approach produces very simple LP representations\nof the original JVML programs. This can be seen as a decompilation from JVML to\nhigh-level LP source. By reasoning about such residual programs, we can\nautomatically prove in the CiaoPP system some non-trivial properties of JVML\nprograms such as termination, run-time error freeness and infer bounds on its\nresource consumption. We are not aware of any other system which is able to\nverify such advanced properties of Java bytecode.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2010 19:46:43 GMT"}], "update_date": "2010-11-22", "authors_parsed": [["Albert", "Elvira", ""], ["G\u00f3mez-Zamalloa", "Miguel", ""], ["Hubert", "Laurent", ""], ["Puebla", "German", ""]]}, {"id": "1007.3353", "submitter": "Laurent Hubert", "authors": "Laurent Hubert (INRIA - IRISA), Nicolas Barr\\'e (INRIA - IRISA),\n  Fr\\'ed\\'eric Besson (INRIA - IRISA), Delphine Demange (INRIA - IRISA), Thomas\n  Jensen (INRIA - IRISA), Vincent Monfort (INRIA - IRISA), David Pichardie\n  (INRIA - IRISA), Tiphaine Turpin (INRIA - IRISA)", "title": "Sawja: Static Analysis Workshop for Java", "comments": null, "journal-ref": "The International Conference on Formal Verification of\n  Object-Oriented Software 2010.13 (2010) 253--267", "doi": "10.1007/978-3-642-18070-5_7", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Static analysis is a powerful technique for automatic verification of\nprograms but raises major engineering challenges when developing a full-fledged\nanalyzer for a realistic language such as Java. This paper describes the Sawja\nlibrary: a static analysis framework fully compliant with Java 6 which provides\nOCaml modules for efficiently manipulating Java bytecode programs. We present\nthe main features of the library, including (i) efficient functional\ndata-structures for representing program with implicit sharing and lazy\nparsing, (ii) an intermediate stack-less representation, and (iii) fast\ncomputation and manipulation of complete programs.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2010 07:03:59 GMT"}], "update_date": "2015-05-19", "authors_parsed": [["Hubert", "Laurent", "", "INRIA - IRISA"], ["Barr\u00e9", "Nicolas", "", "INRIA - IRISA"], ["Besson", "Fr\u00e9d\u00e9ric", "", "INRIA - IRISA"], ["Demange", "Delphine", "", "INRIA - IRISA"], ["Jensen", "Thomas", "", "INRIA - IRISA"], ["Monfort", "Vincent", "", "INRIA - IRISA"], ["Pichardie", "David", "", "INRIA - IRISA"], ["Turpin", "Tiphaine", "", "INRIA - IRISA"]]}, {"id": "1007.3629", "submitter": "Carlos A. Romero-Diaz", "authors": "Mario Rodr\\'iguez-Artalejo and Carlos A. Romero-D\\'iaz", "title": "A Declarative Semantics for CLP with Qualification and Proximity", "comments": "17 pages, 26th Int'l. Conference on Logic Programming (ICLP'10)", "journal-ref": "Theory and Practice of Logic Programming, 26th Int'l. Conference\n  on Logic Programming (ICLP'10) Special Issue, 10(4-6):627-642, 2010", "doi": "10.1017/S1471068410000323", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uncertainty in Logic Programming has been investigated during the last\ndecades, dealing with various extensions of the classical LP paradigm and\ndifferent applications. Existing proposals rely on different approaches, such\nas clause annotations based on uncertain truth values, qualification values as\na generalization of uncertain truth values, and unification based on proximity\nrelations. On the other hand, the CLP scheme has established itself as a\npowerful extension of LP that supports efficient computation over specialized\ndomains while keeping a clean declarative semantics. In this paper we propose a\nnew scheme SQCLP designed as an extension of CLP that supports qualification\nvalues and proximity relations. We show that several previous proposals can be\nviewed as particular cases of the new scheme, obtained by partial\ninstantiation. We present a declarative semantics for SQCLP that is based on\nobservables, providing fixpoint and proof-theoretical characterizations of\nleast program models as well as an implementation-independent notion of goal\nsolutions.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2010 12:25:10 GMT"}], "update_date": "2010-07-22", "authors_parsed": [["Rodr\u00edguez-Artalejo", "Mario", ""], ["Romero-D\u00edaz", "Carlos A.", ""]]}, {"id": "1007.3835", "submitter": "Nuno P. Lopes", "authors": "Nuno P. Lopes, Juan A. Navarro, Andrey Rybalchenko, Atul Singh", "title": "Applying Prolog to Develop Distributed Systems", "comments": null, "journal-ref": "Theory and Practice of Logic Programming, 26th Int'l. Conference\n  on Logic Programming (ICLP'10) Special Issue, 10(4-6):691-707, July 2010", "doi": "10.1017/S1471068410000360", "report-no": null, "categories": "cs.PL cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Development of distributed systems is a difficult task. Declarative\nprogramming techniques hold a promising potential for effectively supporting\nprogrammer in this challenge. While Datalog-based languages have been actively\nexplored for programming distributed systems, Prolog received relatively little\nattention in this application area so far. In this paper we present a\nProlog-based programming system, called DAHL, for the declarative development\nof distributed systems. DAHL extends Prolog with an event-driven control\nmechanism and built-in networking procedures. Our experimental evaluation using\na distributed hash-table data structure, a protocol for achieving Byzantine\nfault tolerance, and a distributed software model checker - all implemented in\nDAHL - indicates the viability of the approach.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2010 09:28:10 GMT"}], "update_date": "2010-07-23", "authors_parsed": [["Lopes", "Nuno P.", ""], ["Navarro", "Juan A.", ""], ["Rybalchenko", "Andrey", ""], ["Singh", "Atul", ""]]}, {"id": "1007.3858", "submitter": "Jon Sneyers", "authors": "Jon Sneyers, Wannes Meert, Joost Vennekens, Yoshitaka Kameya and\n  Taisuke Sato", "title": "CHR(PRISM)-based Probabilistic Logic Learning", "comments": null, "journal-ref": "Theory and Practice of Logic Programming, 10(4-6), 433-447, 2010", "doi": "10.1017/S1471068410000207", "report-no": null, "categories": "cs.PL cs.AI cs.LG cs.LO", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  PRISM is an extension of Prolog with probabilistic predicates and built-in\nsupport for expectation-maximization learning. Constraint Handling Rules (CHR)\nis a high-level programming language based on multi-headed multiset rewrite\nrules.\n  In this paper, we introduce a new probabilistic logic formalism, called\nCHRiSM, based on a combination of CHR and PRISM. It can be used for high-level\nrapid prototyping of complex statistical models by means of \"chance rules\". The\nunderlying PRISM system can then be used for several probabilistic inference\ntasks, including probability computation and parameter learning. We define the\nCHRiSM language in terms of syntax and operational semantics, and illustrate it\nwith examples. We define the notion of ambiguous programs and define a\ndistribution semantics for unambiguous programs. Next, we describe an\nimplementation of CHRiSM, based on CHR(PRISM). We discuss the relation between\nCHRiSM and other probabilistic logic programming languages, in particular PCHR.\nFinally we identify potential application domains.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2010 11:32:21 GMT"}], "update_date": "2010-07-23", "authors_parsed": [["Sneyers", "Jon", ""], ["Meert", "Wannes", ""], ["Vennekens", "Joost", ""], ["Kameya", "Yoshitaka", ""], ["Sato", "Taisuke", ""]]}, {"id": "1007.3878", "submitter": "Michael Laurence", "authors": "Sebastian Danicic, Robert M Hierons, Michael R Laurence", "title": "Complexity of Data Dependence problems for Program Schemas with\n  Concurrency", "comments": "21 pages, 6 figures (all included in cncurr.acm.tex source file)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of deciding whether one point in a program is data dependent upon\nanother is fundamental to program analysis and has been widely studied. In this\npaper we consider this problem at the abstraction level of program schemas in\nwhich computations occur in the Herbrand domain of terms and predicate symbols,\nwhich represent arbitrary predicate functions, are allowed. Given a vertex l in\nthe flowchart of a schema S having only equality (variable copying) assignments\nand variables v,w, we show that it is PSPACE-hard to decide whether there\nexists an execution of a program defined by S in which v holds the initial\nvalue of w at at least one occurrence of l on the path of execution, with\nmembership in PSPACE holding provided there is a constant upper bound on the\narity of any predicate in S. We also consider the `dual' problem in which v is\nrequired to hold the initial value of w at every occurrence of l, for which the\nanalogous results hold. Additionally, the former problem for programs with\nnon-deterministic branching (in effect, free schemas) in which assignments with\nfunctions are allowed is proved to be polynomial-time decidable provided a\nconstant upper bound is placed upon the number of occurrences of the\nconcurrency operator in the schemas being considered. This result is promising\nsince many concurrent systems have a relatively small number of threads\n(concurrent processes), especially when compared with the number of statements\nthey have.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2010 13:10:18 GMT"}, {"version": "v2", "created": "Tue, 1 Mar 2011 20:36:15 GMT"}, {"version": "v3", "created": "Tue, 8 Mar 2011 15:25:40 GMT"}, {"version": "v4", "created": "Tue, 12 Apr 2011 15:41:46 GMT"}], "update_date": "2011-04-13", "authors_parsed": [["Danicic", "Sebastian", ""], ["Hierons", "Robert M", ""], ["Laurence", "Michael R", ""]]}, {"id": "1007.3961", "submitter": "Pablo Chico de Guzman Huerta", "authors": "Pablo Chico de Guzman, Manuel Carro and David S. Warren", "title": "Swapping Evaluation: A Memory-Scalable Solution for Answer-On-Demand\n  Tabling", "comments": "16 pages, 5 figures, published in TPLP 2010", "journal-ref": "Swapping Evaluation in TPLP, volume 10, number 4-6, year 2010,\n  pages 401-416", "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the differences among the various approaches to suspension-based\ntabled evaluation is the scheduling strategy. The two most popular strategies\nare local and batched evaluation.\n  The former collects all the solutions to a tabled predicate before making any\none of them available outside the tabled computation. The latter returns\nanswers one by one before computing them all, which in principle is better if\nonly one answer (or a subset of the answers) is desired.\n  Batched evaluation is closer to SLD evaluation in that it computes solutions\nlazily as they are demanded, but it may need arbitrarily more memory than local\nevaluation, which is able to reclaim memory sooner. Some programs which in\npractice can be executed under the local strategy quickly run out of memory\nunder batched evaluation. This has led to the general adoption of local\nevaluation at the expense of the more depth-first batched strategy.\n  In this paper we study the reasons for the high memory consumption of batched\nevaluation and propose a new scheduling strategy which we have termed swapping\nevaluation. Swapping evaluation also returns answers one by one before\ncompleting a tabled call, but its memory usage can be orders of magnitude less\nthan batched evaluation. An experimental implementation in the XSB system shows\nthat swapping evaluation is a feasible memory-scalable strategy that need not\ncompromise execution speed.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2010 18:26:48 GMT"}], "update_date": "2010-07-23", "authors_parsed": [["de Guzman", "Pablo Chico", ""], ["Carro", "Manuel", ""], ["Warren", "David S.", ""]]}, {"id": "1007.4157", "submitter": "Valerio Senni", "authors": "Alberto Pettorossi, Maurizio Proietti, and Valerio Senni", "title": "Transformations of Logic Programs on Infinite Lists", "comments": "37 pages, including the appendix with proofs. This is an extended\n  version of a paper published in Theory and Practice of Logic Programming, see\n  below", "journal-ref": "Theory and Practice of Logic Programming, Volume 10, Special Issue\n  4-6, 383-399, 2010", "doi": "10.1017/S1471068410000177", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider an extension of logic programs, called \\omega-programs, that can\nbe used to define predicates over infinite lists. \\omega-programs allow us to\nspecify properties of the infinite behavior of reactive systems and, in\ngeneral, properties of infinite sequences of events. The semantics of\n\\omega-programs is an extension of the perfect model semantics. We present\nvariants of the familiar unfold/fold rules which can be used for transforming\n\\omega-programs. We show that these new rules are correct, that is, their\napplication preserves the perfect model semantics. Then we outline a general\nmethodology based on program transformation for verifying properties of\n\\omega-programs. We demonstrate the power of our transformation-based\nverification methodology by proving some properties of Buechi automata and\n\\omega-regular languages.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2010 15:29:40 GMT"}], "update_date": "2010-07-26", "authors_parsed": [["Pettorossi", "Alberto", ""], ["Proietti", "Maurizio", ""], ["Senni", "Valerio", ""]]}, {"id": "1007.4268", "submitter": "David Van Horn", "authors": "Christopher Earl, Matthew Might, David Van Horn", "title": "Pushdown Control-Flow Analysis of Higher-Order Programs", "comments": "The 2010 Workshop on Scheme and Functional Programming", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Context-free approaches to static analysis gain precision over classical\napproaches by perfectly matching returns to call sites---a property that\neliminates spurious interprocedural paths. Vardoulakis and Shivers's recent\nformulation of CFA2 showed that it is possible (if expensive) to apply\ncontext-free methods to higher-order languages and gain the same boost in\nprecision achieved over first-order programs.\n  To this young body of work on context-free analysis of higher-order programs,\nwe contribute a pushdown control-flow analysis framework, which we derive as an\nabstract interpretation of a CESK machine with an unbounded stack. One\ninstantiation of this framework marks the first polyvariant pushdown analysis\nof higher-order programs; another marks the first polynomial-time analysis. In\nthe end, we arrive at a framework for control-flow analysis that can\nefficiently compute pushdown generalizations of classical control-flow\nanalyses.\n", "versions": [{"version": "v1", "created": "Sat, 24 Jul 2010 13:28:46 GMT"}], "update_date": "2010-07-27", "authors_parsed": [["Earl", "Christopher", ""], ["Might", "Matthew", ""], ["Van Horn", "David", ""]]}, {"id": "1007.4446", "submitter": "David Van Horn", "authors": "David Van Horn and Matthew Might", "title": "Abstracting Abstract Machines", "comments": "The 15th ACM SIGPLAN International Conference on Functional\n  Programming (ICFP'10), Baltimore, Maryland, September, 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a derivational approach to abstract interpretation that yields\nnovel and transparently sound static analyses when applied to well-established\nabstract machines. To demonstrate the technique and support our claim, we\ntransform the CEK machine of Felleisen and Friedman, a lazy variant of\nKrivine's machine, and the stack-inspecting CM machine of Clements and\nFelleisen into abstract interpretations of themselves. The resulting analyses\nbound temporal ordering of program events; predict return-flow and\nstack-inspection behavior; and approximate the flow and evaluation of by-need\nparameters. For all of these machines, we find that a series of well-known\nconcrete machine refactorings, plus a technique we call store-allocated\ncontinuations, leads to machines that abstract into static analyses simply by\nbounding their stores. We demonstrate that the technique scales up uniformly to\nallow static analysis of realistic language features, including tail calls,\nconditionals, side effects, exceptions, first-class continuations, and even\ngarbage collection.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2010 13:05:10 GMT"}, {"version": "v2", "created": "Tue, 7 Sep 2010 22:22:26 GMT"}], "update_date": "2010-09-09", "authors_parsed": [["Van Horn", "David", ""], ["Might", "Matthew", ""]]}, {"id": "1007.4908", "submitter": "J\\\"urgen Giesl", "authors": "Peter Schneider-Kamp, J\\\"urgen Giesl, Thomas Str\\\"oder, Alexander\n  Serebrenik, Ren\\'e Thiemann", "title": "Automated Termination Analysis for Logic Programs with Cut", "comments": null, "journal-ref": "Theory and Practice of Logic Programming, 10(4-6), 365-381, 2010", "doi": "10.1017/S1471068410000165", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Termination is an important and well-studied property for logic programs.\nHowever, almost all approaches for automated termination analysis focus on\ndefinite logic programs, whereas real-world Prolog programs typically use the\ncut operator. We introduce a novel pre-processing method which automatically\ntransforms Prolog programs into logic programs without cuts, where termination\nof the cut-free program implies termination of the original program. Hence\nafter this pre-processing, any technique for proving termination of definite\nlogic programs can be applied. We implemented this pre-processing in our\ntermination prover AProVE and evaluated it successfully with extensive\nexperiments.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2010 09:27:52 GMT"}], "update_date": "2010-07-29", "authors_parsed": [["Schneider-Kamp", "Peter", ""], ["Giesl", "J\u00fcrgen", ""], ["Str\u00f6der", "Thomas", ""], ["Serebrenik", "Alexander", ""], ["Thiemann", "Ren\u00e9", ""]]}, {"id": "1007.4958", "submitter": "Pavol Cerny", "authors": "Rajeev Alur and Pavol Cerny", "title": "Algorithmic Verification of Single-Pass List Processing Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce streaming data string transducers that map input data strings to\noutput data strings in a single left-to-right pass in linear time. Data strings\nare (unbounded) sequences of data values, tagged with symbols from a finite\nset, over a potentially infinite data domain that supports only the operations\nof equality and ordering. The transducer uses a finite set of states, a finite\nset of variables ranging over the data domain, and a finite set of variables\nranging over data strings. At every step, it can make decisions based on the\nnext input symbol, updating its state, remembering the input data value in its\ndata variables, and updating data-string variables by concatenating data-string\nvariables and new symbols formed from data variables, while avoiding\nduplication. We establish that the problems of checking functional equivalence\nof two streaming transducers, and of checking whether a streaming transducer\nsatisfies pre/post verification conditions specified by streaming acceptors\nover input/output data-strings, are in PSPACE. We identify a class of\nimperative and a class of functional programs, manipulating lists of data\nitems, which can be effectively translated to streaming data-string\ntransducers. The imperative programs dynamically modify a singly-linked heap by\nchanging next-pointers of heap-nodes and by adding new nodes. The main\nrestriction specifies how the next-pointers can be used for traversal. We also\nidentify an expressively equivalent fragment of functional programs that\ntraverse a list using syntactically restricted recursive calls. Our results\nlead to algorithms for assertion checking and for checking functional\nequivalence of two programs, written possibly in different programming styles,\nfor commonly used routines such as insert, delete, and reverse.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2010 13:20:17 GMT"}, {"version": "v2", "created": "Mon, 14 Feb 2011 15:46:16 GMT"}], "update_date": "2011-02-15", "authors_parsed": [["Alur", "Rajeev", ""], ["Cerny", "Pavol", ""]]}, {"id": "1007.4986", "submitter": "Johannes Oetsch", "authors": "Johannes Oetsch, J\\\"org P\\\"uhrer, and Hans Tompits", "title": "Catching the Ouroboros: On Debugging Non-ground Answer-Set Programs", "comments": null, "journal-ref": "Theory and Practice of Logic Programming, Volume 10, Special Issue\n  4-6, July 2010, pp 513-529", "doi": "10.1017/S1471068410000256", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important issue towards a broader acceptance of answer-set programming\n(ASP) is the deployment of tools which support the programmer during the coding\nphase. In particular, methods for debugging an answer-set program are\nrecognised as a crucial step in this regard. Initial work on debugging in ASP\nmainly focused on propositional programs, yet practical debuggers need to\nhandle programs with variables as well. In this paper, we discuss a debugging\ntechnique that is directly geared towards non-ground programs. Following\nprevious work, we address the central debugging question why some\ninterpretation is not an answer set. The explanations provided by our method\nare computed by means of a meta-programming technique, using a uniform encoding\nof a debugging request in terms of ASP itself. Our method also permits programs\ncontaining comparison predicates and integer arithmetics, thus covering a\nrelevant language class commonly supported by all state-of-the-art ASP solvers.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2010 14:18:32 GMT"}], "update_date": "2010-07-29", "authors_parsed": [["Oetsch", "Johannes", ""], ["P\u00fchrer", "J\u00f6rg", ""], ["Tompits", "Hans", ""]]}, {"id": "1007.4993", "submitter": "EPTCS", "authors": "MohammadReza Mousavi (Eindhoven University of Technology), Gwen\n  Sala\\\"un (INRIA Grenoble - Rhone-Alpes)", "title": "Proceedings Ninth International Workshop on the Foundations of\n  Coordination Languages and Software Architectures", "comments": null, "journal-ref": "EPTCS 30, 2010", "doi": "10.4204/EPTCS.30", "report-no": null, "categories": "cs.SE cs.DC cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the proceedings of FOCLASA 2010, the 9th International\nWorkshop on the Foundations of Coordination Languages and Software\nArchitectures. FOCLASA 2010 was held in Paris, France on July 30th, 2010 as a\nsatellite event of the 21st International Conference on Concurrency Theory,\nCONCUR 2010. The papers presented in this proceedings tackle different issues\nthat are currently central to our community, namely software adaptation, sensor\nnetworks, distributed control, non-functional aspects of coordination such as\nresources, timing and stochastics.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2010 14:39:30 GMT"}], "update_date": "2010-07-29", "authors_parsed": [["Mousavi", "MohammadReza", "", "Eindhoven University of Technology"], ["Sala\u00fcn", "Gwen", "", "INRIA Grenoble - Rhone-Alpes"]]}, {"id": "1007.5089", "submitter": "EPTCS", "authors": "Mayleen Lacouture (ASCOLA Research Team (Mines de Nantes-INRIA, LINA)\n  - Ecole des Mines de Nantes, France), Herv\\'e Grall (ASCOLA Research Team\n  (Mines de Nantes-INRIA, LINA) - Ecole des Mines de Nantes, France), Thomas\n  Ledoux (ASCOLA Research Team (Mines de Nantes-INRIA, LINA) - INRIA\n  Rennes-Bretagne Atlantique, France)", "title": "CREOLE: a Universal Language for Creating, Requesting, Updating and\n  Deleting Resources", "comments": "In Proceedings FOCLASA 2010, arXiv:1007.4993", "journal-ref": "EPTCS 30, 2010, pp. 16-30", "doi": "10.4204/EPTCS.30.2", "report-no": null, "categories": "cs.PL cs.NI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of Service-Oriented Computing, applications can be developed\nfollowing the REST (Representation State Transfer) architectural style. This\nstyle corresponds to a resource-oriented model, where resources are manipulated\nvia CRUD (Create, Request, Update, Delete) interfaces. The diversity of CRUD\nlanguages due to the absence of a standard leads to composition problems\nrelated to adaptation, integration and coordination of services. To overcome\nthese problems, we propose a pivot architecture built around a universal\nlanguage to manipulate resources, called CREOLE, a CRUD Language for Resource\nEdition. In this architecture, scripts written in existing CRUD languages, like\nSQL, are compiled into Creole and then executed over different CRUD interfaces.\nAfter stating the requirements for a universal language for manipulating\nresources, we formally describe the language and informally motivate its\ndefinition with respect to the requirements. We then concretely show how the\narchitecture solves adaptation, integration and coordination problems in the\ncase of photo management in Flickr and Picasa, two well-known service-oriented\napplications. Finally, we propose a roadmap for future work.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2010 00:12:43 GMT"}], "update_date": "2010-07-30", "authors_parsed": [["Lacouture", "Mayleen", "", "ASCOLA Research Team"], ["Grall", "Herv\u00e9", "", "ASCOLA Research Team"], ["Ledoux", "Thomas", "", "ASCOLA Research Team"]]}, {"id": "1007.5090", "submitter": "EPTCS", "authors": "Imene Ben-Hafaiedh (Universite Joseph Fourier/VERIMAG), Susanne Graf\n  (Universite Joseph Fourier/VERIMAG), Hammadi Khairallah (Tunisia Polytechnic\n  School)", "title": "Implementing Distributed Controllers for Systems with Priorities", "comments": "In Proceedings FOCLASA 2010, arXiv:1007.4993", "journal-ref": "EPTCS 30, 2010, pp. 31-46", "doi": "10.4204/EPTCS.30.3", "report-no": null, "categories": "cs.DC cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Implementing a component-based system in a distributed way so that it ensures\nsome global constraints is a challenging problem. We consider here abstract\nspecifications consisting of a composition of components and a controller given\nin the form of a set of interactions and a priority order amongst them. In the\ncontext of distributed systems, such a controller must be executed in a\ndistributed fashion while still respecting the global constraints imposed by\ninteractions and priorities.\n  We present in this paper an implementation of an algorithm that allows a\ndistributed execution of systems with (binary) interactions and priorities. We\nalso present a comprehensive simulation analysis that shows how sensitive to\nchanges our algorithm is, in particular changes related to the degree of\nconflict in the system.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2010 00:12:49 GMT"}], "update_date": "2010-07-30", "authors_parsed": [["Ben-Hafaiedh", "Imene", "", "Universite Joseph Fourier/VERIMAG"], ["Graf", "Susanne", "", "Universite Joseph Fourier/VERIMAG"], ["Khairallah", "Hammadi", "", "Tunisia Polytechnic\n  School"]]}, {"id": "1007.5180", "submitter": "Alessandro Dal Pal\\`u", "authors": "Alessandro Dal Palu', Agostino Dovier, Federico Fogolari, Enrico\n  Pontelli", "title": "CLP-based protein fragment assembly", "comments": "special issue dedicated to ICLP 2010", "journal-ref": "Theory and Practice of Logic Programming, special issue dedicated\n  to ICLP 2010. 10(4-6): pp 709-724, July 2010", "doi": "10.1017/S1471068410000372", "report-no": null, "categories": "cs.AI cs.CE cs.PL q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper investigates a novel approach, based on Constraint Logic\nProgramming (CLP), to predict the 3D conformation of a protein via fragments\nassembly. The fragments are extracted by a preprocessor-also developed for this\nwork- from a database of known protein structures that clusters and classifies\nthe fragments according to similarity and frequency. The problem of assembling\nfragments into a complete conformation is mapped to a constraint solving\nproblem and solved using CLP. The constraint-based model uses a medium\ndiscretization degree Ca-side chain centroid protein model that offers\nefficiency and a good approximation for space filling. The approach adapts\nexisting energy models to the protein representation used and applies a large\nneighboring search strategy. The results shows the feasibility and efficiency\nof the method. The declarative nature of the solution allows to include future\nextensions, e.g., different size fragments for better accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2010 10:44:49 GMT"}], "update_date": "2010-08-02", "authors_parsed": [["Palu'", "Alessandro Dal", ""], ["Dovier", "Agostino", ""], ["Fogolari", "Federico", ""], ["Pontelli", "Enrico", ""]]}, {"id": "1007.5195", "submitter": "Miguel Gomez-Zamalloa", "authors": "Miguel G\\'omez-Zamalloa, Elvira Albert and Germ\\'an Puebla", "title": "Test Case Generation for Object-Oriented Imperative Languages in CLP", "comments": null, "journal-ref": "Miguel G\\'omez-Zamalloa, Elvira Albert, Germ\\'an Puebla: Test Case\n  Generation for Object-Oriented Imperative Languages in CLP. TPLP 10(4-6):\n  659-674 (2010)", "doi": "10.1017/S1471068410000347", "report-no": null, "categories": "cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Testing is a vital part of the software development process. Test Case\nGeneration (TCG) is the process of automatically generating a collection of\ntest cases which are applied to a system under test. White-box TCG is usually\nperformed by means of symbolic execution, i.e., instead of executing the\nprogram on normal values (e.g., numbers), the program is executed on symbolic\nvalues representing arbitrary values. When dealing with an object-oriented (OO)\nimperative language, symbolic execution becomes challenging as, among other\nthings, it must be able to backtrack, complex heap-allocated data structures\nshould be created during the TCG process and features like inheritance, virtual\ninvocations and exceptions have to be taken into account. Due to its inherent\nsymbolic execution mechanism, we pursue in this paper that Constraint Logic\nProgramming (CLP) has a promising unexploited application field in TCG. We will\nsupport our claim by developing a fully CLP-based framework to TCG of an OO\nimperative language, and by assessing it on a corresponding implementation on a\nset of challenging Java programs. A unique characteristic of our approach is\nthat it handles all language features using only CLP and without the need of\ndeveloping specific constraint operators (e.g., to model the heap).\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2010 11:53:56 GMT"}], "update_date": "2010-07-30", "authors_parsed": [["G\u00f3mez-Zamalloa", "Miguel", ""], ["Albert", "Elvira", ""], ["Puebla", "Germ\u00e1n", ""]]}, {"id": "1007.5421", "submitter": "Matthieu Petit", "authors": "Henning Christiansen, Christian Theil Have, Ole Torp Lassen and\n  Matthieu Petit", "title": "Inference with Constrained Hidden Markov Models in PRISM", "comments": null, "journal-ref": "TPLP 2010, 10 (4-6) 449-464", "doi": null, "report-no": null, "categories": "cs.AI cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Hidden Markov Model (HMM) is a common statistical model which is widely\nused for analysis of biological sequence data and other sequential phenomena.\nIn the present paper we show how HMMs can be extended with side-constraints and\npresent constraint solving techniques for efficient inference. Defining HMMs\nwith side-constraints in Constraint Logic Programming have advantages in terms\nof more compact expression and pruning opportunities during inference.\n  We present a PRISM-based framework for extending HMMs with side-constraints\nand show how well-known constraints such as cardinality and all different are\nintegrated. We experimentally validate our approach on the biologically\nmotivated problem of global pairwise alignment.\n", "versions": [{"version": "v1", "created": "Fri, 30 Jul 2010 11:55:05 GMT"}], "update_date": "2010-08-02", "authors_parsed": [["Christiansen", "Henning", ""], ["Have", "Christian Theil", ""], ["Lassen", "Ole Torp", ""], ["Petit", "Matthieu", ""]]}]