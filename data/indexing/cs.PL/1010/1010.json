[{"id": "1010.0019", "submitter": "Byung-Gon Chun", "authors": "Byung-Gon Chun, Ling Huang, Sangmin Lee, Petros Maniatis, Mayur Naik", "title": "Mantis: Predicting System Performance through Program Analysis and\n  Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.AI cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Mantis, a new framework that automatically predicts program\nperformance with high accuracy. Mantis integrates techniques from programming\nlanguage and machine learning for performance modeling, and is a radical\ndeparture from traditional approaches. Mantis extracts program features, which\nare information about program execution runs, through program instrumentation.\nIt uses machine learning techniques to select features relevant to performance\nand creates prediction models as a function of the selected features. Through\nprogram analysis, it then generates compact code slices that compute these\nfeature values for prediction. Our evaluation shows that Mantis can achieve\nmore than 93% accuracy with less than 10% training data set, which is a\nsignificant improvement over models that are oblivious to program features. The\nsystem generates code slices that are cheap to compute feature values.\n", "versions": [{"version": "v1", "created": "Thu, 30 Sep 2010 21:02:04 GMT"}], "update_date": "2010-10-05", "authors_parsed": [["Chun", "Byung-Gon", ""], ["Huang", "Ling", ""], ["Lee", "Sangmin", ""], ["Maniatis", "Petros", ""], ["Naik", "Mayur", ""]]}, {"id": "1010.0371", "submitter": "Anolan Milanes", "authors": "Anolan Milan\\'es, Noemi Rodriguez, Roberto Ierusalimschy", "title": "Reflection-based language support for the heterogeneous capture and\n  restoration of running computations", "comments": "26 pages, 3 figures. Submitted to Computer Languages, Systems &\n  Structures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work is devoted to the study of the problem of user-level capture and\nrestoration of running computations in heterogeneous environments. Support for\nthose operations has traditionally been offered through ready-made solutions\nfor specific applications, which are difficult to tailor or adapt to different\nneeds. We believe that a more promising approach would be to build specific\nsolutions as needed, over a more general framework for capture and restoration.\nIn this work, in order to explore the basic mechanisms a language should\nprovide to support the implementation of different policies, we extend the Lua\nprogramming language with an API that allows the programmer to reify the\ninternal structures of execution into fine-grained language values.\n", "versions": [{"version": "v1", "created": "Sun, 3 Oct 2010 00:06:41 GMT"}, {"version": "v2", "created": "Tue, 5 Oct 2010 17:44:37 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Milan\u00e9s", "Anolan", ""], ["Rodriguez", "Noemi", ""], ["Ierusalimschy", "Roberto", ""]]}, {"id": "1010.1234", "submitter": "Arthur Sorkin", "authors": "Arthur Sorkin and Peter Donovan", "title": "LR(1) Parser Generation System: LR(1) Error Recovery, Oracles, and\n  Generic Tokens", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The LR(1) Parser Generation System generates full LR(1) parsers that are\ncomparable in speed and size to those generated by LALR(1) parser generators,\nsuch as yacc [5]. LR contains a number of novel feature. This paper discusses\nthree of them in detail: an LR(1) grammar specified automatic error recovery\nalgorithm, oracles, and generic tokens.\n", "versions": [{"version": "v1", "created": "Wed, 6 Oct 2010 19:13:38 GMT"}, {"version": "v2", "created": "Fri, 1 Jun 2012 01:00:59 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Sorkin", "Arthur", ""], ["Donovan", "Peter", ""]]}, {"id": "1010.1697", "submitter": "Roberto Amadio", "authors": "Roberto M. Amadio (PPS), Nicolas Ayache (PPS, INRIA Paris -\n  Rocquencourt), Yann R\\'egis-Gianas (PPS, INRIA Paris - Rocquencourt), Ronan\n  Saillard (PPS, INRIA Paris - Rocquencourt)", "title": "Certifying cost annotations in compilers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss the problem of building a compiler which can lift in a provably\ncorrect way pieces of information on the execution cost of the object code to\ncost annotations on the source code. To this end, we need a clear and flexible\npicture of: (i) the meaning of cost annotations, (ii) the method to prove them\nsound and precise, and (iii) the way such proofs can be composed. We propose a\nso-called labelling approach to these three questions. As a first step, we\nexamine its application to a toy compiler. This formal study suggests that the\nlabelling approach has good compositionality and scalability properties. In\norder to provide further evidence for this claim, we report our successful\nexperience in implementing and testing the labelling approach on top of a\nprototype compiler written in OCAML for (a large fragment of) the C language.\n", "versions": [{"version": "v1", "created": "Fri, 8 Oct 2010 14:13:09 GMT"}], "update_date": "2010-10-11", "authors_parsed": [["Amadio", "Roberto M.", "", "PPS"], ["Ayache", "Nicolas", "", "PPS, INRIA Paris -\n  Rocquencourt"], ["R\u00e9gis-Gianas", "Yann", "", "PPS, INRIA Paris - Rocquencourt"], ["Saillard", "Ronan", "", "PPS, INRIA Paris - Rocquencourt"]]}, {"id": "1010.2196", "submitter": "Jan Hubi\\v{c}ka", "authors": "T. Glek, J. Hubicka", "title": "Optimizing real world applications with GCC Link Time Optimization", "comments": "21 pages, published version", "journal-ref": "Proceedings of the 2010 GCC Developers' Summit", "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  GCC has a new infrastructure to support a link time optimization (LTO). The\ninfrastructure is designed to allow linking of large applications using a\nspecial mode (WHOPR) which support parallelization of the compilation process.\nIn this paper we present overview of the design and implementation of WHOPR and\npresent test results of its behavior when optimizing large applications. We\ngive numbers on compile time, memory usage and code quality comparisons to the\nclassical file by file based optimization model. In particular we focus on\nFirefox web browser. We show main problems seen only when compiling a large\napplication, such as startup time and code size growth.\n", "versions": [{"version": "v1", "created": "Mon, 11 Oct 2010 19:30:25 GMT"}, {"version": "v2", "created": "Wed, 3 Nov 2010 22:41:27 GMT"}], "update_date": "2010-11-05", "authors_parsed": [["Glek", "T.", ""], ["Hubicka", "J.", ""]]}, {"id": "1010.2511", "submitter": "Serguei Mokhov", "authors": "Serguei A. Mokhov", "title": "The use of machine learning with signal- and NLP processing of source\n  code to fingerprint, detect, and classify vulnerabilities and weaknesses with\n  MARFCAT", "comments": "33 pages, 11 tables; some results presented at SATE2010; NIST,\n  October 2011; shorter version of v5 appears in the NIST technical report at\n  http://samate.nist.gov/docs/NIST_Special_Publication_500-283.pdf#page=49\n  where its presentation is found at\n  http://samate.nist.gov/docs/SATE2010/SATE10_13_Marfcat_Mokhov.pdf and the\n  MARFCAT OSS release at\n  http://sourceforge.net/projects/marf/files/Applications/MARFCAT/", "journal-ref": null, "doi": null, "report-no": "NIST SP 500-283", "categories": "cs.CR cs.PL", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  We present a machine learning approach to static code analysis and\nfingerprinting for weaknesses related to security, software engineering, and\nothers using the open-source MARF framework and the MARFCAT application based\non it for the NIST's SATE2010 static analysis tool exposition workshop found at\nhttp://samate.nist.gov/SATE2010Workshop.html\n", "versions": [{"version": "v1", "created": "Tue, 12 Oct 2010 20:37:06 GMT"}, {"version": "v2", "created": "Wed, 22 Dec 2010 04:20:49 GMT"}, {"version": "v3", "created": "Thu, 13 Jan 2011 22:06:00 GMT"}, {"version": "v4", "created": "Mon, 17 Jan 2011 20:46:47 GMT"}, {"version": "v5", "created": "Mon, 6 Jun 2011 23:35:39 GMT"}, {"version": "v6", "created": "Sun, 6 Nov 2011 18:49:49 GMT"}], "update_date": "2011-11-08", "authors_parsed": [["Mokhov", "Serguei A.", ""]]}, {"id": "1010.2850", "submitter": "Jan Bergstra", "authors": "Jan A.Bergstra", "title": "Steering Fragments of Instruction Sequences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A steering fragment of an instruction sequence consists of a sequence of\nsteering instructions. These are decision points involving the check of a\npropositional statement in sequential logic. The question is addressed why\ncomposed propositional statements occur in steering fragments given the fact\nthat a straightforward transformation allows their elimination. A survey is\nprovided of constraints that may be implicitly assumed when composed\npropositional statements occur in a meaningful instruction sequence.\n", "versions": [{"version": "v1", "created": "Thu, 14 Oct 2010 08:14:10 GMT"}], "update_date": "2010-10-15", "authors_parsed": [["Bergstra", "Jan A.", ""]]}, {"id": "1010.3806", "submitter": "Takeshi Tsukada", "authors": "Takeshi Tsukada (Tohoku University), Atsushi Igarashi (Kyoto\n  University)", "title": "A Logical Foundation for Environment Classifiers", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 6, Issue 4 (December\n  18, 2010) lmcs:1065", "doi": "10.2168/LMCS-6(4:8)2010", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Taha and Nielsen have developed a multi-stage calculus {\\lambda}{\\alpha} with\na sound type system using the notion of environment classifiers. They are\nspecial identifiers, with which code fragments and variable declarations are\nannotated, and their scoping mechanism is used to ensure statically that\ncertain code fragments are closed and safely runnable. In this paper, we\ninvestigate the Curry-Howard isomorphism for environment classifiers by\ndeveloping a typed {\\lambda}-calculus {\\lambda}|>. It corresponds to\nmulti-modal logic that allows quantification by transition variables---a\ncounterpart of classifiers---which range over (possibly empty) sequences of\nlabeled transitions between possible worlds. This interpretation will reduce\nthe \"run\" construct---which has a special typing rule in\n{\\lambda}{\\alpha}---and embedding of closed code into other code fragments of\ndifferent stages---which would be only realized by the cross-stage persistence\noperator in {\\lambda}{\\alpha}---to merely a special case of classifier\napplication. {\\lambda}|> enjoys not only basic properties including subject\nreduction, confluence, and strong normalization but also an important property\nas a multi-stage calculus: time-ordered normalization of full reduction. Then,\nwe develop a big-step evaluation semantics for an ML-like language based on\n{\\lambda}|> with its type system and prove that the evaluation of a well-typed\n{\\lambda}|> program is properly staged. We also identify a fragment of the\nlanguage, where erasure evaluation is possible. Finally, we show that the proof\nsystem augmented with a classical axiom is sound and complete with respect to a\nKripke semantics of the logic.\n", "versions": [{"version": "v1", "created": "Tue, 19 Oct 2010 06:22:16 GMT"}, {"version": "v2", "created": "Sat, 18 Dec 2010 22:35:54 GMT"}, {"version": "v3", "created": "Mon, 27 Dec 2010 20:43:53 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Tsukada", "Takeshi", "", "Tohoku University"], ["Igarashi", "Atsushi", "", "Kyoto\n  University"]]}, {"id": "1010.4423", "submitter": "Dominik Steenken", "authors": "Dominik Steenken (1) and Heike Wehrheim (1) and Daniel Wonisch (1)\n  ((1) University of Paderborn)", "title": "Towards A Shape Analysis for Graph Transformation Systems", "comments": "17 pages, 7 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphs and graph transformation systems are a frequently used modelling\ntechnique for a wide range of different domains, cover- ing areas as diverse as\nrefactorings, network topologies or reconfigurable software. Being a formal\nmethod, graph transformation systems lend themselves to a formal analysis. This\nhas inspired the development of various verification methods, in particular\nalso model checking tools. In this paper, we present a verification technique\nfor infinite-state graph transformation systems. The technique employs the\nabstraction principle used in shape analysis of programs, summarising possibly\ninfinitely many nodes thus giving shape graphs. The technique has been\nimplemented using the 3-valued logical foundations of standard shape analysis.\nWe exemplify the approach on an example from the railway domain.\n", "versions": [{"version": "v1", "created": "Thu, 21 Oct 2010 10:54:54 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Steenken", "Dominik", "", "University of Paderborn"], ["Wehrheim", "Heike", "", "University of Paderborn"], ["Wonisch", "Daniel", "", "University of Paderborn"]]}, {"id": "1010.4533", "submitter": "Puri Arenas", "authors": "Elvira Albert, Puri Arenas, Germ\\'an Puebla, Manuel Hermenegildo", "title": "Certificate size reduction in Abstraction-Carrying Code", "comments": "35 pages, 1 figure, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Carrying Code (ACC) has recently been proposed as a framework for mobile code\nsafety in which the code supplier provides a program together with an\nabstraction (or abstract model of the program) whose validity entails\ncompliance with a predefined safety policy. The advantage of providing a\n(fixpoint) abstraction to the code consumer is that its validity is checked in\na single pass (i.e., one iteration) of an abstract interpretation-based\nchecker. A main challenge to make ACC useful in practice is to reduce the size\nof certificates as much as possible while at the same time not increasing\nchecking time. The intuitive idea is to only include in the certificate\ninformation that the checker is unable to reproduce without iterating. We\nintroduce the notion of reduced certificate which characterizes the subset of\nthe abstraction which a checker needs in order to validate (and re-construct)\nthe full certificate in a single pass. Based on this notion, we instrument a\ngeneric analysis algorithm with the necessary extensions in order to identify\nthe information relevant to the checker. Interestingly, the fact that the\nreduced certificate omits (parts of) the abstraction has implications in the\ndesign of the checker. We provide the sufficient conditions which allow us to\nensure that 1) if the checker succeeds in validating the certificate, then the\ncertificate is valid for the program (correctness) and 2) the checker will\nsucceed for any reduced certificate which is valid (completeness). Our approach\nhas been implemented and benchmarked within the ciaopp system. The experimental\nresults show that our proposal is able to greatly reduce the size of\ncertificates in practice.To appear in Theory and Practice of Logic Programming\n(TPLP).\n", "versions": [{"version": "v1", "created": "Wed, 13 Oct 2010 10:46:13 GMT"}], "update_date": "2010-10-22", "authors_parsed": [["Albert", "Elvira", ""], ["Arenas", "Puri", ""], ["Puebla", "Germ\u00e1n", ""], ["Hermenegildo", "Manuel", ""]]}, {"id": "1010.5023", "submitter": "Matthew Might", "authors": "Matthew Might and David Darais", "title": "Yacc is dead", "comments": "18 pages; submitted October 2009 to ESOP; rejected", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present two novel approaches to parsing context-free languages. The first\napproach is based on an extension of Brzozowski's derivative from regular\nexpressions to context-free grammars. The second approach is based on a\ngeneralization of the derivative to parser combinators. The payoff of these\ntechniques is a small (less than 250 lines of code), easy-to-implement parsing\nlibrary capable of parsing arbitrary context-free grammars into lazy parse\nforests. Implementations for both Scala and Haskell are provided. Preliminary\nexperiments with S-Expressions parsed millions of tokens per second, which\nsuggests this technique is efficient enough for use in practice.\n", "versions": [{"version": "v1", "created": "Sun, 24 Oct 2010 23:12:28 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Might", "Matthew", ""], ["Darais", "David", ""]]}, {"id": "1010.5566", "submitter": "EPTCS", "authors": "Marco Carbone (IT University of Copenhagen), S{\\o}ren Debois (IT\n  University of Copenhagen)", "title": "A Graphical Approach to Progress for Structured Communication in Web\n  Services", "comments": "In Proceedings ICE 2010, arXiv:1010.5308", "journal-ref": "EPTCS 38, 2010, pp. 13-27", "doi": "10.4204/EPTCS.38.4", "report-no": null, "categories": "cs.PL cs.LO cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate a graphical representation of session invocation\ninterdependency in order to prove progress for the pi-calculus with sessions\nunder the usual session typing discipline. We show that those processes whose\nassociated dependency graph is acyclic can be brought to reduce. We call such\nprocesses transparent processes. Additionally, we prove that for well-typed\nprocesses where services contain no free names, such acyclicity is preserved by\nthe reduction semantics.\n  Our results encompass programs (processes containing neither free nor\nrestricted session channels) and higher-order sessions (delegation).\nFurthermore, we give examples suggesting that transparent processes constitute\na large enough class of processes with progress to have applications in modern\nsession-based programming languages for web services.\n", "versions": [{"version": "v1", "created": "Wed, 27 Oct 2010 05:04:12 GMT"}], "update_date": "2010-10-28", "authors_parsed": [["Carbone", "Marco", "", "IT University of Copenhagen"], ["Debois", "S\u00f8ren", "", "IT\n  University of Copenhagen"]]}, {"id": "1010.5567", "submitter": "EPTCS", "authors": "Alejandro Mario Hernandez (Technical University of Denmark), Flemming\n  Nielson (Technical University of Denmark)", "title": "History-sensitive versus future-sensitive approaches to security in\n  distributed systems", "comments": "In Proceedings ICE 2010, arXiv:1010.5308", "journal-ref": "EPTCS 38, 2010, pp. 29-43", "doi": "10.4204/EPTCS.38.5", "report-no": null, "categories": "cs.CR cs.DC cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the use of aspect-oriented techniques as a flexible way to deal\nwith security policies in distributed systems. Recent work suggests to use\naspects for analysing the future behaviour of programs and to make access\ncontrol decisions based on this; this gives the flavour of dealing with\ninformation flow rather than mere access control. We show in this paper that it\nis beneficial to augment this approach with history-based components as is the\ntraditional approach in reference monitor-based approaches to mandatory access\ncontrol. Our developments are performed in an aspect-oriented coordination\nlanguage aiming to describe the Bell-LaPadula policy as elegantly as possible.\nFurthermore, the resulting language has the capability of combining both\nhistory- and future-sensitive policies, providing even more flexibility and\npower.\n", "versions": [{"version": "v1", "created": "Wed, 27 Oct 2010 05:04:17 GMT"}], "update_date": "2010-10-28", "authors_parsed": [["Hernandez", "Alejandro Mario", "", "Technical University of Denmark"], ["Nielson", "Flemming", "", "Technical University of Denmark"]]}, {"id": "1010.5569", "submitter": "EPTCS", "authors": "Ivan Lanese (Focus Team, University of Bologna/INRIA)", "title": "Static vs Dynamic SAGAs", "comments": "In Proceedings ICE 2010, arXiv:1010.5308", "journal-ref": "EPTCS 38, 2010, pp. 51-65", "doi": "10.4204/EPTCS.38.7", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SAGAs calculi (or simply SAGAs) have been proposed by Bruni et al. as a model\nfor long-running transactions. The approach therein can be considered static,\nwhile a dynamic approach has been proposed by Lanese and Zavattaro. In this\npaper we first extend both static SAGAs (in the centralized interruption\npolicy) and dynamic SAGAs to deal with nesting, then we compare the two\napproaches.\n", "versions": [{"version": "v1", "created": "Wed, 27 Oct 2010 05:04:27 GMT"}], "update_date": "2010-10-28", "authors_parsed": [["Lanese", "Ivan", "", "Focus Team, University of Bologna/INRIA"]]}, {"id": "1010.5570", "submitter": "EPTCS", "authors": "Massimo Bartoletti (Dipartimento di Matematica e Informatica,\n  Universit\\`a degli Studi di Cagliari), Roberto Zunino (Dipartimento di\n  Ingegneria e Scienza dell'Informazione, Universit\\`a degli studi di Trento)", "title": "Primitives for Contract-based Synchronization", "comments": "In Proceedings ICE 2010, arXiv:1010.5308", "journal-ref": "EPTCS 38, 2010, pp. 67-82", "doi": "10.4204/EPTCS.38.8", "report-no": null, "categories": "cs.PL cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate how contracts can be used to regulate the interaction between\nprocesses. To do that, we study a variant of the concurrent constraints\ncalculus presented in [1], featuring primitives for multi-party synchronization\nvia contracts. We proceed in two directions. First, we exploit our primitives\nto model some contract-based interactions. Then, we discuss how several models\nfor concurrency can be expressed through our primitives. In particular, we\nencode the pi-calculus and graph rewriting.\n", "versions": [{"version": "v1", "created": "Wed, 27 Oct 2010 05:04:32 GMT"}], "update_date": "2010-10-28", "authors_parsed": [["Bartoletti", "Massimo", "", "Dipartimento di Matematica e Informatica,\n  Universit\u00e0 degli Studi di Cagliari"], ["Zunino", "Roberto", "", "Dipartimento di\n  Ingegneria e Scienza dell'Informazione, Universit\u00e0 degli studi di Trento"]]}, {"id": "1010.5582", "submitter": "Xavier Leroy", "authors": "Xavier Leroy (INRIA Rocquencourt)", "title": "Mechanized semantics", "comments": null, "journal-ref": "Logics and languages for reliability and security, J. Esparza and\n  B. Spanfelner and O. Grumberg (Ed.) (2010) 195-224", "doi": "10.3233/978-1-60750-100-8-195", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this lecture is to show how modern theorem provers---in this\ncase, the Coq proof assistant---can be used to mechanize the specification of\nprogramming languages and their semantics, and to reason over individual\nprograms and over generic program transformations, as typically found in\ncompilers. The topics covered include: operational semantics (small-step,\nbig-step, definitional interpreters); a simple form of denotational semantics;\naxiomatic semantics and Hoare logic; generation of verification conditions,\nwith application to program proof; compilation to virtual machine code and its\nproof of correctness; an example of an optimizing program transformation (dead\ncode elimination) and its proof of correctness.\n", "versions": [{"version": "v1", "created": "Wed, 27 Oct 2010 06:12:50 GMT"}], "update_date": "2010-10-28", "authors_parsed": [["Leroy", "Xavier", "", "INRIA Rocquencourt"]]}, {"id": "1010.5694", "submitter": "Akim Demaille", "authors": "Jean-Christophe Baillie, Akim Demaille, Quentin Hocquet, Matthieu\n  Nottale", "title": "Events! (Reactivity in urbiscript)", "comments": "DSLRob'10", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Urbi SDK is a software platform for the development of portable robotic\napplications. It features the Urbi UObject C++ middleware, to manage hardware\ndrivers and/or possibly remote software components, and urbiscript, a domain\nspecific programming language to orchestrate them. Reactivity is a key feature\nof Urbi SDK, embodied in events in urbiscript. This paper presents the support\nfor events in urbiscript.\n", "versions": [{"version": "v1", "created": "Wed, 27 Oct 2010 14:20:46 GMT"}], "update_date": "2010-10-28", "authors_parsed": [["Baillie", "Jean-Christophe", ""], ["Demaille", "Akim", ""], ["Hocquet", "Quentin", ""], ["Nottale", "Matthieu", ""]]}]