[{"id": "1405.0033", "submitter": "Matthijs V\\'ak\\'ar", "authors": "Matthijs V\\'ak\\'ar", "title": "Syntax and Semantics of Linear Dependent Types", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A type theory is presented that combines (intuitionistic) linear types with\ntype dependency, thus properly generalising both intuitionistic dependent type\ntheory and full linear logic. A syntax and complete categorical semantics are\ndeveloped, the latter in terms of (strict) indexed symmetric monoidal\ncategories with comprehension. Various optional type formers are treated in a\nmodular way. In particular, we will see that the historically much-debated\nmultiplicative quantifiers and identity types arise naturally from categorical\nconsiderations. These new multiplicative connectives are further characterised\nby several identities relating them to the usual connectives from dependent\ntype theory and linear logic. Finally, one important class of models, given by\nfamilies with values in some symmetric monoidal category, is investigated in\ndetail.\n", "versions": [{"version": "v1", "created": "Wed, 30 Apr 2014 20:58:03 GMT"}, {"version": "v2", "created": "Thu, 21 Aug 2014 22:25:08 GMT"}, {"version": "v3", "created": "Tue, 7 Oct 2014 20:48:27 GMT"}, {"version": "v4", "created": "Fri, 16 Jan 2015 19:28:48 GMT"}], "update_date": "2015-01-19", "authors_parsed": [["V\u00e1k\u00e1r", "Matthijs", ""]]}, {"id": "1405.0166", "submitter": "Pierre de Buyl", "authors": "Pierre de Buyl and Nelle Varoquaux", "title": "Proceedings of the 6th European Conference on Python in Science\n  (EuroSciPy 2013)", "comments": null, "journal-ref": null, "doi": null, "report-no": "euroscipy-proceedings2013-00", "categories": "cs.PL", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  These are the proceedings of the 6th European Conference on Python in\nScience, EuroSciPy 2013, that was held in Brussels (21-25 August 2013).\n", "versions": [{"version": "v1", "created": "Thu, 1 May 2014 14:22:09 GMT"}], "update_date": "2014-05-02", "authors_parsed": [["de Buyl", "Pierre", ""], ["Varoquaux", "Nelle", ""]]}, {"id": "1405.1116", "submitter": "EPTCS", "authors": "David Hauzar (Department of Distributed and Dependable Systems,\n  Faculty of Mathematics and Physics, Charles University in Prague, Czech\n  Republic), Jan Kofro\\v{n} (Department of Distributed and Dependable Systems,\n  Faculty of Mathematics and Physics, Charles University in Prague, Czech\n  Republic), Pavel Ba\\v{s}teck\\'y (Department of Distributed and Dependable\n  Systems, Faculty of Mathematics and Physics, Charles University in Prague,\n  Czech Republic)", "title": "Data-flow Analysis of Programs with Associative Arrays", "comments": "In Proceedings ESSS 2014, arXiv:1405.0554", "journal-ref": "EPTCS 150, 2014, pp. 56-70", "doi": "10.4204/EPTCS.150.6", "report-no": null, "categories": "cs.SE cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic programming languages, such as PHP, JavaScript, and Python, provide\nbuilt-in data structures including associative arrays and objects with similar\nsemantics-object properties can be created at run-time and accessed via\narbitrary expressions. While a high level of security and safety of\napplications written in these languages can be of a particular importance\n(consider a web application storing sensitive data and providing its\nfunctionality worldwide), dynamic data structures pose significant challenges\nfor data-flow analysis making traditional static verification methods both\nunsound and imprecise. In this paper, we propose a sound and precise approach\nfor value and points-to analysis of programs with associative arrays-like data\nstructures, upon which data-flow analyses can be built. We implemented our\napproach in a web-application domain-in an analyzer of PHP code.\n", "versions": [{"version": "v1", "created": "Tue, 6 May 2014 00:54:14 GMT"}], "update_date": "2014-05-07", "authors_parsed": [["Hauzar", "David", "", "Department of Distributed and Dependable Systems,\n  Faculty of Mathematics and Physics, Charles University in Prague, Czech\n  Republic"], ["Kofro\u0148", "Jan", "", "Department of Distributed and Dependable Systems,\n  Faculty of Mathematics and Physics, Charles University in Prague, Czech\n  Republic"], ["Ba\u0161teck\u00fd", "Pavel", "", "Department of Distributed and Dependable\n  Systems, Faculty of Mathematics and Physics, Charles University in Prague,\n  Czech Republic"]]}, {"id": "1405.1302", "submitter": "Brijender Kahanwal Dr.", "authors": "Brijender kahanwal", "title": "Comparative Study of the Function Overloading and Function Overriding\n  Using C++", "comments": "4 pages, 5 figures, 1 table", "journal-ref": "International Journal of Advances in Engineering Sciences, 2014,\n  Vol. 4(1), PP 5-8", "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the Object-Oriented Programming Systems (OOPS), these two concepts namely\nfunction overloading and function overriding are a bit confusing to the\nprogrammers. In this article this confusion is tried to be removed. Both of\nthese are the concepts which come under the polymorphism (poly means many and\nmorph mean forms). In the article the comparison is done in between them. For\nthe new programmers and the learners, it is important to understand them. The\nfunction overloading [1] is achieved at the time of the compile and the\nfunction overriding is achieved at the run time. The function overriding always\ntakes place in inheritance, but the function overloading can also take place\nwithout inheritance.\n", "versions": [{"version": "v1", "created": "Fri, 21 Mar 2014 05:33:03 GMT"}], "update_date": "2014-05-07", "authors_parsed": [["kahanwal", "Brijender", ""]]}, {"id": "1405.1618", "submitter": "Victor Sadikov", "authors": "Victor Sadikov and Walter Pidkameny", "title": "Complete Separation of the 3 Tiers - Divide and Conquer", "comments": "9 pages with code examples", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most Java applications, including web based ones, follow the 3-tier\narchitecture. Although Java provides standard tools for tier-to-tier\ninterfaces, the separation of the tiers is usually not perfect. E.g. the\ndatabase interface, JDBC, assumes that SQL statements are issued from the\napplication server. Similarly, in web based Java applications, HTML code is\nassumed to be produced by servlets. In terms of syntax, this turns Java source\ncode into mixtures of languages: Java and SQL, Java and HTML. These language\nmixtures are difficult to read, modify, and maintain.\n  In this paper we examine criteria and methods to achieve a good separation of\nthe 3 tiers and propose a technique to provide a clean separation. Our proposed\ntechnique requires an explicit Interface and Data Definitions. These allow\nisolation of the back-end, application server, and front-end development. The\nDefinitions also enable application design in terms of aggregated data\nstructures. As a result significant amounts of auxiliary code can be generated\nfrom the Definitions, enabling the developers to concentrate on the business\nlogic. By and large the proposed approach greatly facilitates development and\nmaintenance, and overall improves the quality of the products.\n", "versions": [{"version": "v1", "created": "Fri, 2 May 2014 20:01:38 GMT"}], "update_date": "2014-05-09", "authors_parsed": [["Sadikov", "Victor", ""], ["Pidkameny", "Walter", ""]]}, {"id": "1405.1992", "submitter": "Victor Sadikov", "authors": "John Francisco and Victor Sadikov", "title": "Structured Approach to Web Development", "comments": "eight pages with example code", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In today's world of Web application development, programmers are commonly\ncalled upon to use the Hypertext Markup Language (HTML) as a programming\nlanguage, something for which it was never intended and for which it is\nwoefully inadequate. HTML is a data language, nothing more. It lacks high level\nprogramming constructions like procedures, conditions, and loops. Moreover it\nprovides no intrinsic mechanism to insert or associate dynamic application\ndata. Lastly, despite the visibly apparent structure of a web page when viewed\nin a browser, the responsible HTML code bears little to no discernible\ncorresponding structure, making it very difficult to read, augment, and\nmaintain.\n  This paper examines the various drawbacks inherent in HTML when used in Web\ndevelopment and examines the various augmenting technologies available in the\nindustry today and their drawbacks. It then proposes an alternative, complete\nwith the necessary constructs, structure, and data associating facilities based\nupon server-side, Extensible Stylesheet Language Transforms (XSLT). This\nalternative approach gives rise to an entirely new, higher level, markup\nlanguage that can be readily used in web development.\n", "versions": [{"version": "v1", "created": "Thu, 8 May 2014 16:05:34 GMT"}], "update_date": "2014-05-13", "authors_parsed": [["Francisco", "John", ""], ["Sadikov", "Victor", ""]]}, {"id": "1405.2538", "submitter": "Neng-Fa Zhou", "authors": "Neng-Fa Zhou", "title": "Combinatorial Search With Picat", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Picat, a new member of the logic programming family, follows a different\ndoctrine than Prolog in offering the core logic programming concepts: arrays\nand maps as built-in data types; implicit pattern matching with explicit\nunification and explicit non-determinism; functions for deterministic\ncomputations; and loops for convenient scripting and modeling purposes. Picat\nprovides facilities for solving combinatorial search problems, including a\ncommon interface with CP, SAT, and MIP solvers, tabling for dynamic\nprogramming, and a module for planning. Picat's planner module, which is\nimplemented by the use of tabling, has produced surprising and encouraging\nresults. Thanks to term-sharing and resource-bounded tabled search, Picat\noverwhelmingly outperforms the cutting-edge ASP and PDDL planners on the\nplanning benchmarks used in recent ASP competitions.\n", "versions": [{"version": "v1", "created": "Sun, 11 May 2014 14:45:07 GMT"}], "update_date": "2014-05-13", "authors_parsed": [["Zhou", "Neng-Fa", ""]]}, {"id": "1405.2564", "submitter": "Anderson Faustino Silva", "authors": "George Souza Oliveira and Anderson Faustino da Silva", "title": "Towards an Efficient Prolog System by Code Introspection", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To appear in Theory and Practice of Logic Programming (TPLP). Several Prolog\ninterpreters are based on the Warren Abstract Machine (WAM), an elegant model\nto compile Prolog programs. In order to improve the performance several\nstrategies have been proposed, such as: optimize the selection of clauses,\nspecialize the unification, global analysis, native code generation and\ntabling. This paper proposes a different strategy to implement an efficient\nProlog System, the creation of specialized emulators on the fly. The proposed\nstrategy was implemented and evaluated at YAP Prolog System, and the\nexperimental evaluation showed interesting results.\n", "versions": [{"version": "v1", "created": "Sun, 11 May 2014 18:39:26 GMT"}], "update_date": "2014-05-13", "authors_parsed": [["Oliveira", "George Souza", ""], ["da Silva", "Anderson Faustino", ""]]}, {"id": "1405.2693", "submitter": "Paulo Moura", "authors": "Sergio Castro, Kim Mens, Paulo Moura", "title": "Customisable Handling of Java References in Prolog Programs", "comments": "10 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Integration techniques for combining programs written in distinct language\nparadigms facilitate the implementation of specialised modules in the best\nlanguage for their task. In the case of Java-Prolog integration, a known\nproblem is the proper representation of references to Java objects on the\nProlog side. To solve it adequately, multiple dimensions should be considered,\nincluding reference representation, opacity of the representation, identity\npreservation, reference life span, and scope of the inter-language conversion\npolicies. This paper presents an approach that addresses all these dimensions,\ngeneralising and building on existing representation patterns of foreign\nreferences in Prolog, and taking inspiration from similar inter-language\nrepresentation techniques found in other domains. Our approach maximises\nportability by making few assumptions about the Prolog engine interacting with\nJava (e.g., embedded or executed as an external process). We validate our work\nby extending JPC, an open-source integration library, with features supporting\nour approach. Our JPC library is currently compatible with three different open\nsource Prolog engines (SWI, YAP} and XSB) by means of drivers. To appear in\nTheory and Practice of Logic Programming (TPLP).\n", "versions": [{"version": "v1", "created": "Mon, 12 May 2014 10:12:14 GMT"}, {"version": "v2", "created": "Thu, 29 May 2014 13:59:30 GMT"}], "update_date": "2014-05-30", "authors_parsed": [["Castro", "Sergio", ""], ["Mens", "Kim", ""], ["Moura", "Paulo", ""]]}, {"id": "1405.2794", "submitter": "Theofrastos Mantadelis", "authors": "Thepfrastos Mantadelis, Ricardo Rocha and Paulo Moura", "title": "Tabling, Rational Terms, and Coinduction Finally Together!", "comments": "To appear in Theory and Practice of Logic Programming (TPLP)", "journal-ref": "Theory and Practice of Logic Programming 14 (2014) 429-443", "doi": "10.1017/S147106841400012X", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To appear in Theory and Practice of Logic Programming (TPLP). Tabling is a\ncommonly used technique in logic programming for avoiding cyclic behavior of\nlogic programs and enabling more declarative program definitions. Furthermore,\ntabling often improves computational performance. Rational term are terms with\none or more infinite sub-terms but with a finite representation. Rational terms\ncan be generated in Prolog by omitting the occurs check when unifying two\nterms. Applications of rational terms include definite clause grammars,\nconstraint handling systems, and coinduction. In this paper, we report our\nextension of YAP's Prolog tabling mechanism to support rational terms. We\ndescribe the internal representation of rational terms within the table space\nand prove its correctness. We then use this extension to implement a tabling\nbased approach to coinduction. We compare our approach with current coinductive\ntransformations and describe the implementation. In addition, we present an\nalgorithm that ensures a canonical representation for rational terms.\n", "versions": [{"version": "v1", "created": "Fri, 9 May 2014 17:07:26 GMT"}, {"version": "v2", "created": "Thu, 15 May 2014 18:05:13 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Mantadelis", "Thepfrastos", ""], ["Rocha", "Ricardo", ""], ["Moura", "Paulo", ""]]}, {"id": "1405.2850", "submitter": "Miguel Areias", "authors": "Miguel Areias and Ricardo Rocha", "title": "A Simple and Efficient Lock-Free Hash Trie Design for Concurrent Tabling", "comments": "To appear in Theory and Practice of Logic Programming (TPLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A critical component in the implementation of a concurrent tabling system is\nthe design of the table space. One of the most successful proposals for\nrepresenting tables is based on a two-level trie data structure, where one trie\nlevel stores the tabled subgoal calls and the other stores the computed\nanswers. In this work, we present a simple and efficient lock-free design where\nboth levels of the tries can be shared among threads in a concurrent\nenvironment. To implement lock-freedom we took advantage of the CAS atomic\ninstruction that nowadays can be widely found on many common architectures. CAS\nreduces the granularity of the synchronization when threads access concurrent\nareas, but still suffers from low-level problems such as false sharing or cache\nmemory side-effects. In order to be as effective as possible in the concurrent\nsearch and insert operations over the table space data structures, we based our\ndesign on a hash trie data structure in such a way that it minimizes potential\nlow-level synchronization problems by dispersing as much as possible the\nconcurrent areas. Experimental results in the Yap Prolog system show that our\nnew lock-free hash trie design can effectively reduce the execution time and\nscale better than previous designs.\n", "versions": [{"version": "v1", "created": "Fri, 9 May 2014 19:19:21 GMT"}, {"version": "v2", "created": "Wed, 14 May 2014 17:02:45 GMT"}], "update_date": "2014-05-15", "authors_parsed": [["Areias", "Miguel", ""], ["Rocha", "Ricardo", ""]]}, {"id": "1405.3072", "submitter": "Raphael kena Poss", "authors": "Raphael Poss", "title": "Haskell for OCaml programmers", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This introduction to Haskell is written to optimize learning by programmers\nwho already know OCaml.\n", "versions": [{"version": "v1", "created": "Tue, 13 May 2014 09:10:32 GMT"}, {"version": "v2", "created": "Mon, 21 Jul 2014 14:52:39 GMT"}], "update_date": "2014-07-22", "authors_parsed": [["Poss", "Raphael", ""]]}, {"id": "1405.3099", "submitter": "Joachim Breitner", "authors": "Joachim Breitner", "title": "The Correctness of Launchbury's Natural Semantics for Lazy Evaluation", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In his seminal paper \"A Natural Semantics for Lazy Evaluation\", John\nLaunchbury proves his semantics correct with respect to a denotational\nsemantics. We machine-checked the proof and found it to fail, and provide two\nways to fix it: One by taking a detour via a modified natural semantics with an\nexplicit stack, and one by adjusting the denotational semantics of heaps.\n", "versions": [{"version": "v1", "created": "Tue, 13 May 2014 10:47:12 GMT"}], "update_date": "2014-05-14", "authors_parsed": [["Breitner", "Joachim", ""]]}, {"id": "1405.3323", "submitter": "Niall Douglas", "authors": "Niall Douglas", "title": "Large Code Base Change Ripple Management in C++: My thoughts on how a\n  new Boost C++ Library could help", "comments": "Proceedings of the C++ Now 2014 Conference, Aspen, Colorado, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  C++ 98/03 already has a reputation for overwhelming complexity compared to\nother programming languages. The raft of new features in C++ 11/14 suggests\nthat the complexity in the next generation of C++ code bases will overwhelm\nstill further. The planned C++ 17 will probably worsen matters in ways\ndifficult to presently imagine.\n  Countervailing against this rise in software complexity is the hard\nde-exponentialisation of computer hardware capacity growth expected no later\nthan 2020, and which will have even harder to imagine consequences on all\ncomputer software. WG21 C++ 17 study groups SG2 (Modules), SG7 (Reflection),\nSG8 (Concepts), and to a lesser extent SG10 (Feature Test) and SG12 (Undefined\nBehaviour), are all fundamentally about significantly improving complexity\nmanagement in C++ 17, yet WG21's significant work on improving C++ complexity\nmanagement is rarely mentioned explicitly.\n  This presentation pitches a novel implementation solution for some of these\ncomplexity scaling problems, tying together SG2 and SG7 with parts of SG3\n(Filesystem): a standardised but very lightweight transactional graph database\nbased on Boost.ASIO, Boost.AFIO and Boost.Graph at the very core of the C++\nruntime, making future C++ codebases considerably more tractable and affordable\nto all users of C++.\n", "versions": [{"version": "v1", "created": "Tue, 13 May 2014 22:44:11 GMT"}], "update_date": "2014-05-15", "authors_parsed": [["Douglas", "Niall", ""]]}, {"id": "1405.3365", "submitter": "Yi Bi", "authors": "Yi Bi, Jia-Huai You, Zhiyong Feng", "title": "A Well-Founded Semantics for FOL-Programs", "comments": "10 pages, ICLP2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An FOL-program consists of a background theory in a decidable fragment of\nfirst-order logic and a collection of rules possibly containing first-order\nformulas. The formalism stems from recent approaches to tight integrations of\nASP with description logics. In this paper, we define a well-founded semantics\nfor FOL-programs based on a new notion of unfounded sets on consistent as well\nas inconsistent sets of literals, and study some of its properties. The\nsemantics is defined for all FOL-programs, including those where it is\nnecessary to represent inconsistencies explicitly. The semantics supports a\nform of combined reasoning by rules under closed world as well as open world\nassumptions, and it is a generalization of the standard well-founded semantics\nfor normal logic programs. We also show that the well-founded semantics defined\nhere approximates the well-supported answer set semantics for normal DL\nprograms.\n", "versions": [{"version": "v1", "created": "Wed, 14 May 2014 05:29:40 GMT"}], "update_date": "2014-05-15", "authors_parsed": [["Bi", "Yi", ""], ["You", "Jia-Huai", ""], ["Feng", "Zhiyong", ""]]}, {"id": "1405.3393", "submitter": "Gregory Duck", "authors": "Gregory J. Duck and Remy Haemmerle and Martin Sulzmann", "title": "On Termination, Confluence and Consistent CHR-based Type Inference", "comments": null, "journal-ref": "Theory and Practice of Logic Programming 14 (2014) 619-632", "doi": "10.1017/S1471068414000246", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the application of Constraint Handling Rules (CHR) for the\nspecification of type inference systems, such as that used by Haskell.\nConfluence of CHR guarantees that the answer provided by type inference is\ncorrect and consistent. The standard method for establishing confluence relies\non an assumption that the CHR program is terminating. However, many examples in\npractice give rise to non-terminating CHR programs, rendering this method\ninapplicable. Despite no guarantee of termination or confluence, the Glasgow\nHaskell Compiler (GHC) supports options that allow the user to proceed with\ntype inference anyway, e.g. via the use of the UndecidableInstances flag. In\nthis paper we formally identify and verify a set of relaxed criteria, namely\nrange-restrictedness, local confluence, and ground termination, that ensure the\nconsistency of CHR-based type inference that maps to potentially\nnon-terminating CHR programs.\n", "versions": [{"version": "v1", "created": "Wed, 14 May 2014 07:51:39 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Duck", "Gregory J.", ""], ["Haemmerle", "Remy", ""], ["Sulzmann", "Martin", ""]]}, {"id": "1405.3547", "submitter": "Terrance Swift", "authors": "Terrance Swift", "title": "Incremental Tabling in Support of Knowledge Representation and Reasoning", "comments": "Theory and Practice of Logic Programming Volume 14 2014", "journal-ref": "Theory and Practice of Logic Programming 14 (2014) 553-567", "doi": "10.1017/S1471068414000209", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Resolution-based Knowledge Representation and Reasoning (KRR) systems, such\nas Flora-2, Silk or Ergo, can scale to tens or hundreds of millions of facts,\nwhile supporting reasoning that includes Hilog, inheritance, defeasibility\ntheories, and equality theories. These systems handle the termination and\ncomplexity issues that arise from the use of these features by a heavy use of\ntabled resolution. In fact, such systems table by default all rules defined by\nusers, unless they are simple facts.\n  Performing dynamic updates within such systems is nearly impossible unless\nthe tables themselves can be made to react to changes. Incremental tabling as\nfirst implemented in XSB (Saha 2006) partially addressed this problem, but the\nimplementation was limited in scope and not always easy to use. In this paper,\nwe introduce transparent incremental tabling which at the semantic level\nsupports updates in the 3-valued well-founded semantics, while guaranteeing\nfull consistency of all tabled queries. Transparent incremental tabling also\nhas significant performance improvements over previous implementations,\nincluding lazy recomputation, and control over the dependency structures used\nto determine how tables are updated.\n", "versions": [{"version": "v1", "created": "Wed, 14 May 2014 15:49:49 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Swift", "Terrance", ""]]}, {"id": "1405.3556", "submitter": "Flavio Cruz", "authors": "Flavio Cruz, Ricardo Rocha, Seth Copen Goldstein and Frank Pfenning", "title": "A Linear Logic Programming Language for Concurrent Programming over\n  Graph Structures", "comments": "ICLP 2014, TPLP 2014", "journal-ref": "Theory and Practice of Logic Programming 14 (2014) 493-507", "doi": "10.1017/S1471068414000167", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We have designed a new logic programming language called LM (Linear Meld) for\nprogramming graph-based algorithms in a declarative fashion. Our language is\nbased on linear logic, an expressive logical system where logical facts can be\nconsumed. Because LM integrates both classical and linear logic, LM tends to be\nmore expressive than other logic programming languages. LM programs are\nnaturally concurrent because facts are partitioned by nodes of a graph data\nstructure. Computation is performed at the node level while communication\nhappens between connected nodes. In this paper, we present the syntax and\noperational semantics of our language and illustrate its use through a number\nof examples.\n", "versions": [{"version": "v1", "created": "Wed, 14 May 2014 16:02:41 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Cruz", "Flavio", ""], ["Rocha", "Ricardo", ""], ["Goldstein", "Seth Copen", ""], ["Pfenning", "Frank", ""]]}, {"id": "1405.3675", "submitter": "Marco Comini PhD", "authors": "Marco Comini, Laura Titolo, Alicia Villanueva", "title": "Abstract Diagnosis for tccp using a Linear Temporal Logic", "comments": null, "journal-ref": "Theory and Practice of Logic Programming 14 (2014) 787-801", "doi": "10.1017/S1471068414000349", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic techniques for program verification usually suffer the well-known\nstate explosion problem. Most of the classical approaches are based on browsing\nthe structure of some form of model (which represents the behavior of the\nprogram) to check if a given specification is valid. This implies that a part\nof the model has to be built, and sometimes the needed fragment is quite huge.\n  In this work, we provide an alternative automatic decision method to check\nwhether a given property, specified in a linear temporal logic, is valid w.r.t.\na tccp program. Our proposal (based on abstract interpretation techniques) does\nnot require to build any model at all. Our results guarantee correctness but,\nas usual when using an abstract semantics, completeness is lost.\n", "versions": [{"version": "v1", "created": "Wed, 14 May 2014 20:18:48 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Comini", "Marco", ""], ["Titolo", "Laura", ""], ["Villanueva", "Alicia", ""]]}, {"id": "1405.3694", "submitter": "Martin Gebser", "authors": "Martin Gebser, Roland Kaminski, Benjamin Kaufmann, Torsten Schaub", "title": "Clingo = ASP + Control: Preliminary Report", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the new ASP system clingo 4. Unlike its predecessors, being mere\nmonolithic combinations of the grounder gringo with the solver clasp, the new\nclingo 4 series offers high-level constructs for realizing complex reasoning\nprocesses. Among others, such processes feature advanced forms of search, as in\noptimization or theory solving, or even interact with an environment, as in\nrobotics or query-answering. Common to them is that the problem specification\nevolves during the reasoning process, either because data or constraints are\nadded, deleted, or replaced. In fact, clingo 4 carries out such complex\nreasoning within a single integrated ASP grounding and solving process. This\navoids redundancies in relaunching grounder and solver programs and benefits\nfrom the solver's learning capacities. clingo 4 accomplishes this by\ncomplementing ASP's declarative input language by control capacities expressed\nvia the embedded scripting languages lua and python. On the declarative side,\nclingo 4 offers a new directive that allows for structuring logic programs into\nnamed and parameterizable subprograms. The grounding and integration of these\nsubprograms into the solving process is completely modular and fully\ncontrollable from the procedural side, viz. the scripting languages. By\nstrictly separating logic and control programs, clingo 4 also abolishes the\nneed for dedicated systems for incremental and reactive reasoning, like iclingo\nand oclingo, respectively, and its flexibility goes well beyond the advanced\nyet still rigid solving processes of the latter.\n", "versions": [{"version": "v1", "created": "Wed, 14 May 2014 21:33:07 GMT"}], "update_date": "2014-05-16", "authors_parsed": [["Gebser", "Martin", ""], ["Kaminski", "Roland", ""], ["Kaufmann", "Benjamin", ""], ["Schaub", "Torsten", ""]]}, {"id": "1405.3791", "submitter": "Gheorghe Stefanescu", "authors": "Iulia Teodora Banu-Demergian and Gheorghe Stefanescu", "title": "On contour representation of two dimensional patterns", "comments": "To appear in: Carpathian J. Math., 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two-dimensional patterns are used in many research areas in computer science,\nranging from image processing to specification and verification of complex\nsoftware systems (via scenarios). The contribution of this paper is twofold.\nFirst, we present the basis of a new formal representation of two-dimensional\npatterns based on contours and their compositions. Then, we present efficient\nalgorithms to verify correctness of the contour-representation. Finally, we\nbriefly discuss possible applications, in particular using them as a basic\ninstrument in developing software tools for handling two dimensional words.\n", "versions": [{"version": "v1", "created": "Thu, 15 May 2014 10:27:52 GMT"}], "update_date": "2014-05-16", "authors_parsed": [["Banu-Demergian", "Iulia Teodora", ""], ["Stefanescu", "Gheorghe", ""]]}, {"id": "1405.3792", "submitter": "Angelos Charalambidis", "authors": "Angelos Charalambidis, Zolt\\'an \\'Esik, Panos Rondogiannis", "title": "Minimum Model Semantics for Extensional Higher-order Logic Programming\n  with Negation", "comments": null, "journal-ref": "Theory and Practice of Logic Programming 14 (2014) 725-737", "doi": "10.1017/S1471068414000313", "report-no": null, "categories": "cs.PL cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extensional higher-order logic programming has been introduced as a\ngeneralization of classical logic programming. An important characteristic of\nthis paradigm is that it preserves all the well-known properties of traditional\nlogic programming. In this paper we consider the semantics of negation in the\ncontext of the new paradigm. Using some recent results from non-monotonic\nfixed-point theory, we demonstrate that every higher-order logic program with\nnegation has a unique minimum infinite-valued model. In this way we obtain the\nfirst purely model-theoretic semantics for negation in extensional higher-order\nlogic programming. Using our approach, we resolve an old paradox that was\nintroduced by W. W. Wadge in order to demonstrate the semantic difficulties of\nhigher-order logic programming.\n", "versions": [{"version": "v1", "created": "Thu, 15 May 2014 10:37:42 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Charalambidis", "Angelos", ""], ["\u00c9sik", "Zolt\u00e1n", ""], ["Rondogiannis", "Panos", ""]]}, {"id": "1405.3793", "submitter": "Nada Sharaf Ms.", "authors": "Nada Sharaf, Slim Abdennadher, Thom Fruehwirth", "title": "Visualization of Constraint Handling Rules", "comments": "An extended abstract / full version of a paper accepted to be\n  presented at the Doctoral Consortium of the 30th International Conference on\n  Logic Programming (ICLP 2014), July 19-22, Vienna, Austria", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constraint Handling Rules (CHR) has matured into a general purpose language\nover the past two decades. Any general purpose language requires its own\ndevelopment tools. Visualization tools, in particular, facilitate many tasks\nfor programmers as well as beginners to the language. The article presents\non-going work towards the visualization of CHR programs. The process is done\nthrough source-to-source transformation. It aims towards reaching a generic\ntransformer to visualize different algorithms implemented in CHR. Note: An\nextended abstract / full version of a paper accepted to be presented at the\nDoctoral Consortium of the 30th International Conference on Logic Programming\n(ICLP 2014), July 19-22, Vienna, Austria.\n", "versions": [{"version": "v1", "created": "Thu, 15 May 2014 10:42:42 GMT"}], "update_date": "2014-05-16", "authors_parsed": [["Sharaf", "Nada", ""], ["Abdennadher", "Slim", ""], ["Fruehwirth", "Thom", ""]]}, {"id": "1405.3795", "submitter": "Grzegorz Ja\\'skiewicz", "authors": "Grzegorz Ja\\'skiewicz", "title": "Logic Programming as Scripting Language for Bots in Computer Games --\n  Research Overview", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This publication is to present a summary of research (referred as Klabs -\nhttp://www.kappalabs.org) carried out in author's Ph.D studies on topic of\napplication of Logic Programming as scripting language for virtual character\nbehavior control in First Person Shooter (FPS) games. The research goal is to\napply reasoning and knowledge representation techniques to create character\nbehavior, which results in increased players' engagement. An extended abstract\n/ full version of a paper accepted to be presented at the Doctoral Consortium\nof the 30th International Conference on Logic Programming (ICLP 2014), July\n19-22, Vienna, Austria\n", "versions": [{"version": "v1", "created": "Thu, 15 May 2014 10:48:10 GMT"}], "update_date": "2014-05-16", "authors_parsed": [["Ja\u015bkiewicz", "Grzegorz", ""]]}, {"id": "1405.3883", "submitter": "Bishoksan Kafle", "authors": "John P. Gallagher and Bishoksan Kafle", "title": "Analysis and Transformation Tools for Constrained Horn Clause\n  Verification", "comments": "To appear in Theory and Practice of Logic Programming (TPLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several techniques and tools have been developed for verification of\nproperties expressed as Horn clauses with constraints over a background theory\n(CHC). Current CHC verification tools implement intricate algorithms and are\noften limited to certain subclasses of CHC problems. Our aim in this work is to\ninvestigate the use of a combination of off-the-shelf techniques from the\nliterature in analysis and transformation of Constraint Logic Programs (CLPs)\nto solve challenging CHC verification problems. We find that many problems can\nbe solved using a combination of tools based on well-known techniques from\nabstract interpretation, semantics-preserving transformations, program\nspecialisation and query-answer transformations. This gives insights into the\ndesign of automatic, more general CHC verification tools based on a library of\ncomponents.\n", "versions": [{"version": "v1", "created": "Thu, 15 May 2014 15:39:46 GMT"}], "update_date": "2014-05-16", "authors_parsed": [["Gallagher", "John P.", ""], ["Kafle", "Bishoksan", ""]]}, {"id": "1405.3953", "submitter": "Jan Wielemaker", "authors": "Torbj\\\"orn Lager, Jan Wielemaker", "title": "Pengines: Web Logic Programming Made Easy", "comments": "To appear in Theory and Practice of Logic Programming", "journal-ref": "Theory and Practice of Logic Programming 14 (2014) 539-552", "doi": "10.1017/S1471068414000192", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When developing a (web) interface for a deductive database, functionality\nrequired by the client is provided by means of HTTP handlers that wrap the\nlogical data access predicates. These handlers are responsible for converting\nbetween client and server data representations and typically include options\nfor paginating results. Designing the web accessible API is difficult because\nit is hard to predict the exact requirements of clients. Pengines changes this\npicture. The client provides a Prolog program that selects the required data by\naccessing the logical API of the server. The pengine infrastructure provides\ngeneral mechanisms for converting Prolog data and handling Prolog\nnon-determinism. The Pengines library is small (2000 lines Prolog, 150 lines\nJavaScript). It greatly simplifies defining an AJAX based client for a Prolog\nprogram and provides non-deterministic RPC between Prolog processes as well as\ninteraction with Prolog engines similar to Paul Tarau's engines. Pengines are\navailable as a standard package for SWI-Prolog 7.\n", "versions": [{"version": "v1", "created": "Wed, 14 May 2014 15:22:30 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Lager", "Torbj\u00f6rn", ""], ["Wielemaker", "Jan", ""]]}, {"id": "1405.4041", "submitter": "Ethan Jackson", "authors": "Ethan K. Jackson", "title": "A Module System for Domain-Specific Languages", "comments": "Appearing in International Conference on Logic Programming (ICLP)\n  2014", "journal-ref": "Theory and Practice of Logic Programming 14 (2014) 771-785", "doi": "10.1017/S1471068414000337", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain-specific languages (DSLs) are routinely created to simplify difficult\nor specialized programming tasks. They expose useful abstractions and design\npatterns in the form of language constructs, provide static semantics to\neagerly detect misuse of these constructs, and dynamic semantics to completely\ndefine how language constructs interact. However, implementing and composing\nDSLs is a non-trivial task, and there is a lack of tools and techniques.\n  We address this problem by presenting a complete module system over LP for\nDSL construction, reuse, and composition. LP is already useful for DSL design,\nbecause it supports executable language specifications using notations familiar\nto language designers. We extend LP with a module system that is simple (with a\nfew concepts), succinct (for key DSL specification scenarios), and composable\n(on the level of languages, compilers, and programs). These design choices\nreflect our use of LP for industrial DSL design. Our module system has been\nimplemented in the FORMULA language, and was used to build key Windows 8 device\ndrivers via DSLs. Though we present our module system as it actually appears in\nour FORMULA language, our emphasis is on concepts adaptable to other LP\nlanguages.\n", "versions": [{"version": "v1", "created": "Fri, 16 May 2014 00:47:10 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Jackson", "Ethan K.", ""]]}, {"id": "1405.4256", "submitter": "Pedro Lopez-Garcia", "authors": "Alejandro Serrano, Pedro Lopez-Garcia and Manuel V. Hermenegildo", "title": "Resource Usage Analysis of Logic Programs via Abstract Interpretation\n  Using Sized Types", "comments": "To appear in Theory and Practice of Logic Programming (TPLP),\n  improved version of arXiv:1308.3940 (which was conference version)", "journal-ref": "Theory and Practice of Logic Programming 14 (2014) 739-754", "doi": "10.1017/S147106841400057X", "report-no": null, "categories": "cs.PL cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel general resource analysis for logic programs based on\nsized types. Sized types are representations that incorporate structural\n(shape) information and allow expressing both lower and upper bounds on the\nsize of a set of terms and their subterms at any position and depth. They also\nallow relating the sizes of terms and subterms occurring at different argument\npositions in logic predicates. Using these sized types, the resource analysis\ncan infer both lower and upper bounds on the resources used by all the\nprocedures in a program as functions on input term (and subterm) sizes,\novercoming limitations of existing resource analyses and enhancing their\nprecision. Our new resource analysis has been developed within the abstract\ninterpretation framework, as an extension of the sized types abstract domain,\nand has been integrated into the Ciao preprocessor, CiaoPP. The abstract domain\noperations are integrated with the setting up and solving of recurrence\nequations for inferring both size and resource usage functions. We show that\nthe analysis is an improvement over the previous resource analysis present in\nCiaoPP and compares well in power to state of the art systems.\n", "versions": [{"version": "v1", "created": "Fri, 16 May 2014 17:59:17 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Serrano", "Alejandro", ""], ["Lopez-Garcia", "Pedro", ""], ["Hermenegildo", "Manuel V.", ""]]}, {"id": "1405.4401", "submitter": "Mohamed El-Zawawy Dr.", "authors": "Mohamed A. El-Zawawy, Mohammad N. Alanazi", "title": "Probabilistic Alias Analysis for Parallel Programming in SSA Forms", "comments": "7 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Static alias analysis of different type of programming languages has been\ndrawing researcher attention. However most of the results of existing\ntechniques for alias analysis are not precise enough compared to needs of\nmodern compilers. Probabilistic versions of these results, in which result\nelements are associated with occurrence probabilities, are required in\noptimizations techniques of modern compilers.\n  This paper presents a new probabilistic approach for alias analysis of\nparallel programs. The treated parallelism model is that of SPMD where in SPMD,\na program is executed using a fixed number of program threads running on\ndistributed machines on different data. The analyzed programs are assumed to be\nin the static single assignment (SSA) form which is a program representation\nform facilitating program analysis. The proposed technique has the form of\nsimply-strictured system of inference rules. This enables using the system in\napplications like Proof-Carrying Code (PPC) which is a general technique for\nproving the safety characteristics of modern programs.\n", "versions": [{"version": "v1", "created": "Sat, 17 May 2014 14:33:49 GMT"}], "update_date": "2014-05-20", "authors_parsed": [["El-Zawawy", "Mohamed A.", ""], ["Alanazi", "Mohammad N.", ""]]}, {"id": "1405.4443", "submitter": "Mingsheng Ying", "authors": "Mingsheng Ying", "title": "Quantum Recursion and Second Quantisation", "comments": "talk at Tsinghua Software Day 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new notion of quantum recursion of which the control\nflow of the computation is quantum rather than classical as in the notions of\nrecursion considered in the previous studies of quantum programming. A typical\nexample is recursive quantum walks, which are obtained by slightly modifying\nthe construction of the ordinary quantum walks. The operational and\ndenotational semantics of quantum recursions are defined by employing the\nsecond quantisation method, and they are proved to be equivalent.\n", "versions": [{"version": "v1", "created": "Sat, 17 May 2014 22:41:08 GMT"}, {"version": "v2", "created": "Wed, 6 Aug 2014 10:51:45 GMT"}], "update_date": "2014-08-07", "authors_parsed": [["Ying", "Mingsheng", ""]]}, {"id": "1405.4565", "submitter": "Jeremy Morse", "authors": "Neville Grech, Kyriakos Georgiou, James Pallister, Steve Kerrison,\n  Jeremy Morse and Kerstin Eder", "title": "Static analysis of energy consumption for LLVM IR programs", "comments": null, "journal-ref": null, "doi": "10.1145/2764967.2764974", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Energy models can be constructed by characterizing the energy consumed by\nexecuting each instruction in a processor's instruction set. This can be used\nto determine how much energy is required to execute a sequence of assembly\ninstructions, without the need to instrument or measure hardware.\n  However, statically analyzing low-level program structures is hard, and the\ngap between the high-level program structure and the low-level energy models\nneeds to be bridged. We have developed techniques for performing a static\nanalysis on the intermediate compiler representations of a program.\nSpecifically, we target LLVM IR, a representation used by modern compilers,\nincluding Clang. Using these techniques we can automatically infer an estimate\nof the energy consumed when running a function under different platforms, using\ndifferent compilers.\n  One of the challenges in doing so is that of determining an energy cost of\nexecuting LLVM IR program segments, for which we have developed two different\napproaches. When this information is used in conjunction with our analysis, we\nare able to infer energy formulae that characterize the energy consumption for\na particular program. This approach can be applied to any languages targeting\nthe LLVM toolchain, including C and XC or architectures such as ARM Cortex-M or\nXMOS xCORE, with a focus towards embedded platforms. Our techniques are\nvalidated on these platforms by comparing the static analysis results to the\nphysical measurements taken from the hardware. Static energy consumption\nestimation enables energy-aware software development, without requiring\nhardware knowledge.\n", "versions": [{"version": "v1", "created": "Sun, 18 May 2014 23:32:10 GMT"}, {"version": "v2", "created": "Fri, 15 May 2015 14:19:28 GMT"}, {"version": "v3", "created": "Thu, 16 Jul 2015 10:36:45 GMT"}], "update_date": "2015-07-17", "authors_parsed": [["Grech", "Neville", ""], ["Georgiou", "Kyriakos", ""], ["Pallister", "James", ""], ["Kerrison", "Steve", ""], ["Morse", "Jeremy", ""], ["Eder", "Kerstin", ""]]}, {"id": "1405.5590", "submitter": "Mukund Raghothaman", "authors": "Mukund Raghothaman, Abhishek Udupa", "title": "Language to Specify Syntax-Guided Synthesis Problems", "comments": "Fixed small typo in the SyGuS grammar specification pointed out by\n  Sergey Mechtaev", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a language to specify syntax guided synthesis (SyGuS) problems.\nSyntax guidance is a prominent theme in contemporary program synthesis\napproaches, and SyGuS was first described in [1]. This paper describes\nconcretely the input format of a SyGuS solver.\n  [1] Rajeev Alur, Rastislav Bodik, Garvit Juniwal, Milo M. K. Martin, Mukund\nRaghothaman, Sanjit A. Seshia, Rishabh Singh, Armando Solar-Lezama, Emina\nTorlak, and Abhishek Udupa. Syntax-guided synthesis. In FMCAD, pages 1--17,\n2013.\n", "versions": [{"version": "v1", "created": "Thu, 22 May 2014 01:50:47 GMT"}, {"version": "v2", "created": "Sun, 23 Oct 2016 19:45:46 GMT"}], "update_date": "2016-10-25", "authors_parsed": [["Raghothaman", "Mukund", ""], ["Udupa", "Abhishek", ""]]}, {"id": "1405.6334", "submitter": "Renato dos Santos", "authors": "Renato P. dos Santos", "title": "TATI -- A Logo-like interface for microworlds and simulations for\n  physics teaching in Second Life", "comments": "12 pages, 4 figures, Proceedings of ESERA 2013 - 10th biannual\n  Conference of the European Science Education Research Association, September\n  2nd - 7th 2013, Nicosia, Cyprus. Nicosia: University of Cyprus, 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.ed-ph cs.CY cs.HC cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Student difficulties in learning Physics have been thoroughly discussed in\nthe scientific literature. Already in 1980, Papert complained that schools\nteach Newtonian motion by manipulating equations rather than by manipulating\nthe Newtonian objects themselves, what would be possible in a 'physics\nmicroworld'. On the other hand, Second Life and its scripting language have a\nremarkable learning curve that discourages most teachers at using it as an\nenvironment for educational computer simulations and microworlds. The objective\nof this work is to describe TATI, a textual interface which, through TATILogo,\nan accessible Logo language extension, allows the generation of various physics\nmicroworlds in Second Life, containing different types of objects that follow\ndifferent physical laws, providing a learning path into Newtonian Physics.\n", "versions": [{"version": "v1", "created": "Sat, 24 May 2014 19:08:29 GMT"}], "update_date": "2014-05-27", "authors_parsed": [["Santos", "Renato P. dos", ""]]}, {"id": "1405.6646", "submitter": "S\\'ergio Medeiros", "authors": "Andr\\'e Murbach Maidl, S\\'ergio Medeiros, Fabio Mascarenhas, Roberto\n  Ierusalimschy", "title": "Error Reporting in Parsing Expression Grammars", "comments": "Preprint (plus appendix) submitted to Science of Computer Programming", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parsing Expression Grammars (PEGs) describe top-down parsers. Unfortunately,\nthe error-reporting techniques used in conventional top-down parsers do not\ndirectly apply to parsers based on Parsing Expression Grammars (PEGs), so they\nhave to be somehow simulated. While the PEG formalism has no account of\nsemantic actions, actual PEG implementations add them, and we show how to\nsimulate an error-reporting heuristic through these semantic actions.\n  We also propose a complementary error reporting strategy that may lead to\nbetter error messages: labeled failures. This approach is inspired by exception\nhandling of programming languages, and lets a PEG define different kinds of\nfailure, with each ordered choice operator specifying which kinds it catches.\nLabeled failures give a way to annotate grammars for better error reporting, to\nexpress some of the error reporting strategies used by deterministic parser\ncombinators, and to encode predictive top-down parsing in a PEG.\n", "versions": [{"version": "v1", "created": "Mon, 26 May 2014 17:14:52 GMT"}, {"version": "v2", "created": "Tue, 23 Feb 2016 13:24:53 GMT"}, {"version": "v3", "created": "Wed, 13 Jul 2016 15:33:47 GMT"}], "update_date": "2016-07-14", "authors_parsed": [["Maidl", "Andr\u00e9 Murbach", ""], ["Medeiros", "S\u00e9rgio", ""], ["Mascarenhas", "Fabio", ""], ["Ierusalimschy", "Roberto", ""]]}, {"id": "1405.7058", "submitter": "Asiri Rathnayake", "authors": "Asiri Rathnayake and Hayo Thielecke", "title": "Static Analysis for Regular Expression Exponential Runtime via\n  Substructural Logics (Extended)", "comments": "Extended version with a sketch of the completeness proof - work in\n  progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regular expression matching using backtracking can have exponential runtime,\nleading to an algorithmic complexity attack known as REDoS in the systems\nsecurity literature. In this paper, we build on a recently published static\nanalysis that detects whether a given regular expression can have exponential\nruntime for some inputs. We systematically construct a more accurate analysis\nby forming powers and products of transition relations and thereby reducing the\nREDoS problem to reachability. The correctness of the analysis is proved using\na substructural calculus of search trees, where the branching of the tree\ncausing exponential blowup is characterized as a form of non-linearity.\n", "versions": [{"version": "v1", "created": "Tue, 27 May 2014 20:33:14 GMT"}, {"version": "v2", "created": "Sun, 13 Aug 2017 11:41:37 GMT"}], "update_date": "2017-08-15", "authors_parsed": [["Rathnayake", "Asiri", ""], ["Thielecke", "Hayo", ""]]}, {"id": "1405.7153", "submitter": "Sebastian Nanz", "authors": "Scott West and Sebastian Nanz and Bertrand Meyer", "title": "Efficient and Reasonable Object-Oriented Concurrency", "comments": "Proceedings of the 10th Joint Meeting of the European Software\n  Engineering Conference and the ACM SIGSOFT Symposium on the Foundations of\n  Software Engineering (ESEC/FSE '15). ACM, 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Making threaded programs safe and easy to reason about is one of the chief\ndifficulties in modern programming. This work provides an efficient execution\nmodel for SCOOP, a concurrency approach that provides not only data race\nfreedom but also pre/postcondition reasoning guarantees between threads. The\nextensions we propose influence both the underlying semantics to increase the\namount of concurrent execution that is possible, exclude certain classes of\ndeadlocks, and enable greater performance. These extensions are used as the\nbasis an efficient runtime and optimization pass that improve performance 15x\nover a baseline implementation. This new implementation of SCOOP is also 2x\nfaster than other well-known safe concurrent languages. The measurements are\nbased on both coordination-intensive and data-manipulation-intensive benchmarks\ndesigned to offer a mixture of workloads.\n", "versions": [{"version": "v1", "created": "Wed, 28 May 2014 08:30:43 GMT"}, {"version": "v2", "created": "Mon, 27 Jul 2015 07:59:46 GMT"}], "update_date": "2015-07-28", "authors_parsed": [["West", "Scott", ""], ["Nanz", "Sebastian", ""], ["Meyer", "Bertrand", ""]]}, {"id": "1405.7470", "submitter": "Andreas Kl\\\"ockner", "authors": "Andreas Kl\\\"ockner", "title": "Loo.py: transformation-based code generation for GPUs and CPUs", "comments": null, "journal-ref": "Proceedings of ARRAY 2014: ACM SIGPLAN Workshop on Libraries,\n  Languages, and Compilers for Array Programming", "doi": "10.1145/2627373.2627387", "report-no": null, "categories": "cs.PL cs.MS math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today's highly heterogeneous computing landscape places a burden on\nprogrammers wanting to achieve high performance on a reasonably broad\ncross-section of machines. To do so, computations need to be expressed in many\ndifferent but mathematically equivalent ways, with, in the worst case, one\nvariant per target machine.\n  Loo.py, a programming system embedded in Python, meets this challenge by\ndefining a data model for array-style computations and a library of\ntransformations that operate on this model. Offering transformations such as\nloop tiling, vectorization, storage management, unrolling, instruction-level\nparallelism, change of data layout, and many more, it provides a convenient way\nto capture, parametrize, and re-unify the growth among code variants. Optional,\ndeep integration with numpy and PyOpenCL provides a convenient computing\nenvironment where the transition from prototype to high-performance\nimplementation can occur in a gradual, machine-assisted form.\n", "versions": [{"version": "v1", "created": "Thu, 29 May 2014 05:53:56 GMT"}], "update_date": "2014-06-02", "authors_parsed": [["Kl\u00f6ckner", "Andreas", ""]]}, {"id": "1405.7898", "submitter": "Nataliia Stulova", "authors": "Nataliia Stulova, Jos\\'e F. Morales and Manuel V. Hermenegildo", "title": "Towards Assertion-based Debugging of Higher-Order (C)LP Programs", "comments": "2 pages, to be published as a technical communication in the on-line\n  addendum of the special issue(s) of the TPLP journal for ICLP14. To appear in\n  Theory and Practice of Logic Programming (TPLP). arXiv admin note:\n  substantial text overlap with arXiv:1404.4246; corrected the header\n  publication info and submission, revision and acceptance dates", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Higher-order constructs extend the expressiveness of first-order (Constraint)\nLogic Programming ((C)LP) both syntactically and semantically. At the same time\nassertions have been in use for some time in (C)LP systems helping programmers\ndetect errors and validate programs. However, these assertion-based extensions\nto (C)LP have not been integrated well with higher order to date. Our work\ncontributes to filling this gap by extending the assertion-based approach to\nerror detection and program validation to the higher-order context, within\n(C)LP. It is based on an extension of properties and assertions as used in\n(C)LP in order to be able to fully describe arguments that are predicates.\n", "versions": [{"version": "v1", "created": "Wed, 14 May 2014 08:25:55 GMT"}, {"version": "v2", "created": "Mon, 2 Jun 2014 12:12:51 GMT"}], "update_date": "2014-06-03", "authors_parsed": [["Stulova", "Nataliia", ""], ["Morales", "Jos\u00e9 F.", ""], ["Hermenegildo", "Manuel V.", ""]]}, {"id": "1405.7962", "submitter": "David Monniaux", "authors": "Julien Henry (VERIMAG - IMAG), Mihail Asavoae (VERIMAG - IMAG), David\n  Monniaux (VERIMAG - IMAG), Claire Ma\\\"iza (VERIMAG - IMAG)", "title": "How to Compute Worst-Case Execution Time by Optimization Modulo Theory\n  and a Clever Encoding of Program Semantics", "comments": "ACM SIGPLAN/SIGBED Conference on Languages, Compilers and Tools for\n  Embedded Systems 2014, Edimbourg : United Kingdom (2014)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In systems with hard real-time constraints, it is necessary to compute upper\nbounds on the worst-case execution time (WCET) of programs; the closer the\nbound to the real WCET, the better. This is especially the case of synchronous\nreactive control loops with a fixed clock; the WCET of the loop body must not\nexceed the clock period. We compute the WCET (or at least a close upper bound\nthereof) as the solution of an optimization modulo theory problem that takes\ninto account the semantics of the program, in contrast to other methods that\ncompute the longest path whether or not it is feasible according to these\nsemantics. Optimization modulo theory extends satisfiability modulo theory\n(SMT) to maximization problems. Immediate encodings of WCET problems into SMT\nyield formulas intractable for all current production-grade solvers; this is\ninherent to the DPLL(T) approach to SMT implemented in these solvers. By\nconjoining some appropriate \"cuts\" to these formulas, we considerably reduce\nthe computation time of the SMT-solver. We experimented our approach on a\nvariety of control programs, using the OTAWA analyzer both as baseline and as\nunderlying microarchitectural analysis for our analysis, and show notable\nimprovement on the WCET bound on a variety of benchmarks and control programs.\n", "versions": [{"version": "v1", "created": "Fri, 30 May 2014 19:29:16 GMT"}], "update_date": "2014-06-02", "authors_parsed": [["Henry", "Julien", "", "VERIMAG - IMAG"], ["Asavoae", "Mihail", "", "VERIMAG - IMAG"], ["Monniaux", "David", "", "VERIMAG - IMAG"], ["Ma\u00efza", "Claire", "", "VERIMAG - IMAG"]]}]