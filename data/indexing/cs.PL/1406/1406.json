[{"id": "1406.0582", "submitter": "Gcg Equipe", "authors": "Lukasz Domagala (INRIA Grenoble Rh\\^one-Alpes), Fabrice Rastello\n  (INRIA Grenoble Rh\\^one-Alpes), Sadayappan Ponnuswany, Duco Van Amstel (INRIA\n  Grenoble Rh\\^one-Alpes)", "title": "A Tiling Perspective for Register Optimization", "comments": null, "journal-ref": "N&deg; RR-8541 (2014)", "doi": null, "report-no": "RR-8541", "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Register allocation is a much studied problem. A particularly important\ncontext for optimizing register allocation is within loops, since a significant\nfraction of the execution time of programs is often inside loop code. A variety\nof algorithms have been proposed in the past for register allocation, but the\ncomplexity of the problem has resulted in a decoupling of several important\naspects, including loop unrolling, register promotion, and instruction\nreordering. In this paper, we develop an approach to register allocation and\npromotion in a unified optimization framework that simultaneously considers the\nimpact of loop unrolling and instruction scheduling. This is done via a novel\ninstruction tiling approach where instructions within a loop are represented\nalong one dimension and innermost loop iterations along the other dimension. By\nexploiting the regularity along the loop dimension, and imposing essential\ndependence based constraints on intra-tile execution order, the problem of\noptimizing register pressure is cast in a constraint programming formalism.\nExperimental results are provided from thousands of innermost loops extracted\nfrom the SPEC benchmarks, demonstrating improvements over the current\nstate-of-the-art.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jun 2014 06:04:52 GMT"}], "update_date": "2014-06-04", "authors_parsed": [["Domagala", "Lukasz", "", "INRIA Grenoble Rh\u00f4ne-Alpes"], ["Rastello", "Fabrice", "", "INRIA Grenoble Rh\u00f4ne-Alpes"], ["Ponnuswany", "Sadayappan", "", "INRIA\n  Grenoble Rh\u00f4ne-Alpes"], ["Van Amstel", "Duco", "", "INRIA\n  Grenoble Rh\u00f4ne-Alpes"]]}, {"id": "1406.1224", "submitter": "Xuhui Li", "authors": "Xuhui Li, Mengchi Liu, Shanfeng Zhu, Arif Ghafoor", "title": "XTQ: A Declarative Functional XML Query Language", "comments": "65 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.DB", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Various query languages have been proposed to extract and restructure\ninformation in XML documents. These languages, usually claiming to be\ndeclarative, mainly consider the conjunctive relationships among data elements.\nIn order to present the operations where the hierarchical and the disjunctive\nrelationships need to be considered, such as restructuring hierarchy and\nhandling heterogeneity, the programs in these languages often exhibit a\nprocedural style and thus the declarativeness in them is not so prominent as in\nconventional query languages like SQL.\n  In this paper, we propose a declarative pattern-based functional XML query\nlanguage named XML Tree Query (XTQ). XTQ adopts expressive composite patterns\nto present data extraction, meanwhile establishing the conjunctive, the\ndisjunctive and the hierarchical relationships among data elements. It uses the\nmatching terms, a composite structure of the variables bound to the matched\ndata elements, to present a global sketch of the extracted data, and develops a\ndeductive restructuring mechanism of matching terms to indicate data\ntransformation, especially for restructuring hierarchy and handling\nheterogeneity. Based on matching terms, XTQ employs a coherent approach to\nfunction declaration and invocation to consistently extract and construct\ncomposite data structure, which integrates features of conventional functional\nlanguages and pattern-based query languages. Additionally, XTQ also supports\ndata filtering on composite data structure such as hierarchical data, which is\nseldom deliberately considered in other studies. We demonstrate with various\nexamples that XTQ can declaratively present complex XML queries which are\ncommon in practice.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jun 2014 22:03:20 GMT"}], "update_date": "2014-06-06", "authors_parsed": [["Li", "Xuhui", ""], ["Liu", "Mengchi", ""], ["Zhu", "Shanfeng", ""], ["Ghafoor", "Arif", ""]]}, {"id": "1406.1393", "submitter": "Paul Tarau", "authors": "Paul Tarau and Fahmida Hamid", "title": "Interclausal Logic Variables", "comments": "to appear as a ICLP'14 technical contribution", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unification of logic variables instantly connects present and future\nobservations of their value, independently of their location in the data areas\nof the runtime system. The paper extends this property to \"interclausal logic\nvariables\", an easy to implement Prolog extension that supports instant global\ninformation exchanges without dynamic database updates. We illustrate their\nusefulness with two of algorithms, {\\em graph coloring} and {\\em minimum\nspanning tree}. Implementations of interclausal variables as source-level\ntransformations and as abstract machine adaptations are given. To address the\nneed for globally visible chained transitions of logic variables we describe a\nDCG-based program transformation that extends the functionality of interclausal\nvariables.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jun 2014 14:09:30 GMT"}], "update_date": "2014-06-06", "authors_parsed": [["Tarau", "Paul", ""], ["Hamid", "Fahmida", ""]]}, {"id": "1406.1510", "submitter": "Remy Haemmerle", "authors": "R\\'emy Haemmerl\\'e and Jon Sneyers", "title": "Proceedings of the Eleventh Workshop on Constraint Handling Rules", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the papers presented at the eleventh Workshop on\nConstraint Handling Rules (CHR 2014), which will be held in Vienna at the\noccasion of the Vienna Summer of Logic (VSL)\n", "versions": [{"version": "v1", "created": "Thu, 5 Jun 2014 20:11:27 GMT"}], "update_date": "2014-06-09", "authors_parsed": [["Haemmerl\u00e9", "R\u00e9my", ""], ["Sneyers", "Jon", ""]]}, {"id": "1406.1534", "submitter": "EPTCS", "authors": "Paul Levy (University of Birmingham), Neel Krishnaswami (University of\n  Birmingham)", "title": "Proceedings 5th Workshop on Mathematically Structured Functional\n  Programming", "comments": null, "journal-ref": "EPTCS 153, 2014", "doi": "10.4204/EPTCS.153", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the proceedings of the Fifth Workshop on Mathematically\nStructured Functional Programming (MSFP 2014), taking place on 12 April, 2014\nin Grenoble, France, as a satellite event of the European Joint Conferences on\nTheory and Practice of Software, ETAPS 2014.\n  MSFP is devoted to the derivation of functionality from structure. It\nhighlights concepts from algebra, semantics and type theory as they are\nincreasingly reflected in programming practice, especially functional\nprogramming. As the range of papers presented in this year's workshop shows,\nthis continues to be a fruitful interface.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jun 2014 22:07:03 GMT"}], "update_date": "2014-06-09", "authors_parsed": [["Levy", "Paul", "", "University of Birmingham"], ["Krishnaswami", "Neel", "", "University of\n  Birmingham"]]}, {"id": "1406.1557", "submitter": "EPTCS", "authors": "Harsh Raju Chamarthi (Northeastern Univeristy), Peter C. Dillinger\n  (Northeastern Univeristy), Panagiotis Manolios (Northeastern Univeristy)", "title": "Data Definitions in the ACL2 Sedan", "comments": "In Proceedings ACL2 2014, arXiv:1406.1238", "journal-ref": "EPTCS 152, 2014, pp. 27-48", "doi": "10.4204/EPTCS.152.3", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a data definition framework that enables the convenient\nspecification of data types in ACL2s, the ACL2 Sedan. Our primary motivation\nfor developing the data definition framework was pedagogical. We were teaching\nundergraduate students how to reason about programs using ACL2s and wanted to\nprovide them with an effective method for defining, testing, and reasoning\nabout data types in the context of an untyped theorem prover. Our framework is\nnow routinely used not only for pedagogical purposes, but also by advanced\nusers.\n  Our framework concisely supports common data definition patterns, e.g. list\ntypes, map types, and record types. It also provides support for polymorphic\nfunctions. A distinguishing feature of our approach is that we maintain both a\npredicative and an enumerative characterization of data definitions.\n  In this paper we present our data definition framework via a sequence of\nexamples. We give a complete characterization in terms of tau rules of the\ninclusion/exclusion relations a data definition induces, under suitable\nrestrictions. The data definition framework is a key component of\ncounterexample generation support in ACL2s, but can be independently used in\nACL2, and is available as a community book.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jun 2014 01:47:21 GMT"}], "update_date": "2014-06-09", "authors_parsed": [["Chamarthi", "Harsh Raju", "", "Northeastern Univeristy"], ["Dillinger", "Peter C.", "", "Northeastern Univeristy"], ["Manolios", "Panagiotis", "", "Northeastern Univeristy"]]}, {"id": "1406.1558", "submitter": "EPTCS", "authors": "Benjamin Selfridge (University of Texas at Austin), Eric Smith\n  (Kestrel Institute)", "title": "Polymorphic Types in ACL2", "comments": "In Proceedings ACL2 2014, arXiv:1406.1238", "journal-ref": "EPTCS 152, 2014, pp. 49-59", "doi": "10.4204/EPTCS.152.4", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a tool suite for the ACL2 programming language which\nincorporates certain ideas from the Hindley-Milner paradigm of functional\nprogramming (as exemplified in popular languages like ML and Haskell),\nincluding a \"typed\" style of programming with the ability to define polymorphic\ntypes. These ideas are introduced via macros into the language of ACL2, taking\nadvantage of ACL2's guard-checking mechanism to perform type checking on both\nfunction definitions and theorems. Finally, we discuss how these macros were\nused to implement features of Specware, a software specification and\nimplementation system.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jun 2014 01:47:31 GMT"}], "update_date": "2014-06-09", "authors_parsed": [["Selfridge", "Benjamin", "", "University of Texas at Austin"], ["Smith", "Eric", "", "Kestrel Institute"]]}, {"id": "1406.1562", "submitter": "EPTCS", "authors": "Disha Puri (Dept. of Computer Science, Portland State University),\n  Sandip Ray (Strategic CAD Labs, Intel Corporation), Kecheng Hao (Dept. of\n  Computer Science, Portland State University), Fei Xie (Dept. of Computer\n  Science, Portland State University)", "title": "Using ACL2 to Verify Loop Pipelining in Behavioral Synthesis", "comments": "In Proceedings ACL2 2014, arXiv:1406.1238", "journal-ref": "EPTCS 152, 2014, pp. 111-128", "doi": "10.4204/EPTCS.152.10", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Behavioral synthesis involves compiling an Electronic System-Level (ESL)\ndesign into its Register-Transfer Level (RTL) implementation. Loop pipelining\nis one of the most critical and complex transformations employed in behavioral\nsynthesis. Certifying the loop pipelining algorithm is challenging because\nthere is a huge semantic gap between the input sequential design and the output\npipelined implementation making it infeasible to verify their equivalence with\nautomated sequential equivalence checking techniques. We discuss our ongoing\neffort using ACL2 to certify loop pipelining transformation. The completion of\nthe proof is work in progress. However, some of the insights developed so far\nmay already be of value to the ACL2 community. In particular, we discuss the\nkey invariant we formalized, which is very different from that used in most\npipeline proofs. We discuss the needs for this invariant, its formalization in\nACL2, and our envisioned proof using the invariant. We also discuss some\ntrade-offs, challenges, and insights developed in course of the project.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jun 2014 01:48:26 GMT"}], "update_date": "2014-06-09", "authors_parsed": [["Puri", "Disha", "", "Dept. of Computer Science, Portland State University"], ["Ray", "Sandip", "", "Strategic CAD Labs, Intel Corporation"], ["Hao", "Kecheng", "", "Dept. of\n  Computer Science, Portland State University"], ["Xie", "Fei", "", "Dept. of Computer\n  Science, Portland State University"]]}, {"id": "1406.1565", "submitter": "EPTCS", "authors": "John W. O'Leary (Intel Corp.), David M. Russinoff (Intel Corp)", "title": "Modeling Algorithms in SystemC and ACL2", "comments": "In Proceedings ACL2 2014, arXiv:1406.1238", "journal-ref": "EPTCS 152, 2014, pp. 145-162", "doi": "10.4204/EPTCS.152.12", "report-no": null, "categories": "cs.AR cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe the formal language MASC, based on a subset of SystemC and\nintended for modeling algorithms to be implemented in hardware. By means of a\nspecial-purpose parser, an algorithm coded in SystemC is converted to a MASC\nmodel for the purpose of documentation, which in turn is translated to ACL2 for\nformal verification. The parser also generates a SystemC variant that is\nsuitable as input to a high-level synthesis tool. As an illustration of this\nmethodology, we describe a proof of correctness of a simple 32-bit radix-4\nmultiplier.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jun 2014 01:48:45 GMT"}], "update_date": "2014-06-09", "authors_parsed": [["O'Leary", "John W.", "", "Intel Corp."], ["Russinoff", "David M.", "", "Intel Corp"]]}, {"id": "1406.1566", "submitter": "EPTCS", "authors": "David S. Hardin (Rockwell Collins), Jennifer A. Davis (Rockwell\n  Collins), David A. Greve (Rockwell Collins), Jedidiah R. McClurg (University\n  of Colorado)", "title": "Development of a Translator from LLVM to ACL2", "comments": "In Proceedings ACL2 2014, arXiv:1406.1238", "journal-ref": "EPTCS 152, 2014, pp. 163-177", "doi": "10.4204/EPTCS.152.13", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In our current work a library of formally verified software components is to\nbe created, and assembled, using the Low-Level Virtual Machine (LLVM)\nintermediate form, into subsystems whose top-level assurance relies on the\nassurance of the individual components. We have thus undertaken a project to\nbuild a translator from LLVM to the applicative subset of Common Lisp accepted\nby the ACL2 theorem prover. Our translator produces executable ACL2 formal\nmodels, allowing us to both prove theorems about the translated models as well\nas validate those models by testing. The resulting models can be translated and\ncertified without user intervention, even for code with loops, thanks to the\nuse of the def::ung macro which allows us to defer the question of termination.\nInitial measurements of concrete execution for translated LLVM functions\nindicate that performance is nearly 2.4 million LLVM instructions per second on\na typical laptop computer. In this paper we overview the translation process\nand illustrate the translator's capabilities by way of a concrete example,\nincluding both a functional correctness theorem as well as a validation test\nfor that example.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jun 2014 01:48:55 GMT"}], "update_date": "2014-06-09", "authors_parsed": [["Hardin", "David S.", "", "Rockwell Collins"], ["Davis", "Jennifer A.", "", "Rockwell\n  Collins"], ["Greve", "David A.", "", "Rockwell Collins"], ["McClurg", "Jedidiah R.", "", "University\n  of Colorado"]]}, {"id": "1406.1633", "submitter": "EPTCS", "authors": "Philip Atzemoglou (University of Oxford)", "title": "The dagger lambda calculus", "comments": "In Proceedings QPL 2014, arXiv:1412.8102", "journal-ref": "EPTCS 172, 2014, pp. 217-235", "doi": "10.4204/EPTCS.172.15", "report-no": null, "categories": "cs.LO cs.PL math.CT quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel lambda calculus that casts the categorical approach to the\nstudy of quantum protocols into the rich and well established tradition of type\ntheory. Our construction extends the linear typed lambda calculus with a linear\nnegation of \"trivialised\" De Morgan duality. Reduction is realised through\nexplicit substitution, based on a symmetric notion of binding of global scope,\nwith rules acting on the entire typing judgement instead of on a specific\nsubterm. Proofs of subject reduction, confluence, strong normalisation and\nconsistency are provided, and the language is shown to be an internal language\nfor dagger compact categories.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jun 2014 10:24:48 GMT"}, {"version": "v2", "created": "Tue, 30 Dec 2014 03:02:25 GMT"}], "update_date": "2014-12-31", "authors_parsed": [["Atzemoglou", "Philip", "", "University of Oxford"]]}, {"id": "1406.2058", "submitter": "EPTCS", "authors": "Jules Hedges (Queen Mary University of London)", "title": "Monad Transformers for Backtracking Search", "comments": "In Proceedings MSFP 2014, arXiv:1406.1534", "journal-ref": "EPTCS 153, 2014, pp. 31-50", "doi": "10.4204/EPTCS.153.3", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper extends Escardo and Oliva's selection monad to the selection monad\ntransformer, a general monadic framework for expressing backtracking search\nalgorithms in Haskell. The use of the closely related continuation monad\ntransformer for similar purposes is also discussed, including an implementation\nof a DPLL-like SAT solver with no explicit recursion. Continuing a line of work\nexploring connections between selection functions and game theory, we use the\nselection monad transformer with the nondeterminism monad to obtain an\nintuitive notion of backward induction for a certain class of nondeterministic\ngames.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jun 2014 03:29:29 GMT"}], "update_date": "2014-06-10", "authors_parsed": [["Hedges", "Jules", "", "Queen Mary University of London"]]}, {"id": "1406.2059", "submitter": "EPTCS", "authors": "Andreas Abel (Gothenburg University), James Chapman (Institute of\n  Cybernetics, Tallinn)", "title": "Normalization by Evaluation in the Delay Monad: A Case Study for\n  Coinduction via Copatterns and Sized Types", "comments": "In Proceedings MSFP 2014, arXiv:1406.1534", "journal-ref": "EPTCS 153, 2014, pp. 51-67", "doi": "10.4204/EPTCS.153.4", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present an Agda formalization of a normalizer for\nsimply-typed lambda terms. The normalizer consists of two coinductively defined\nfunctions in the delay monad: One is a standard evaluator of lambda terms to\nclosures, the other a type-directed reifier from values to eta-long beta-normal\nforms. Their composition, normalization-by-evaluation, is shown to be a total\nfunction a posteriori, using a standard logical-relations argument.\n  The successful formalization serves as a proof-of-concept for coinductive\nprogramming and reasoning using sized types and copatterns, a new and presently\nexperimental feature of Agda.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jun 2014 03:29:45 GMT"}], "update_date": "2014-06-10", "authors_parsed": [["Abel", "Andreas", "", "Gothenburg University"], ["Chapman", "James", "", "Institute of\n  Cybernetics, Tallinn"]]}, {"id": "1406.2060", "submitter": "EPTCS", "authors": "Michael Hicks (University of Maryland, College Park), Gavin Bierman\n  (Microsoft Research), Nataliya Guts (University of Maryland, College Park),\n  Daan Leijen (Microsoft Research), Nikhil Swamy (Microsoft Research)", "title": "Polymonadic Programming", "comments": "In Proceedings MSFP 2014, arXiv:1406.1534", "journal-ref": "EPTCS 153, 2014, pp. 79-99", "doi": "10.4204/EPTCS.153.7", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monads are a popular tool for the working functional programmer to structure\neffectful computations. This paper presents polymonads, a generalization of\nmonads. Polymonads give the familiar monadic bind the more general type forall\na,b. L a -> (a -> M b) -> N b, to compose computations with three different\nkinds of effects, rather than just one. Polymonads subsume monads and\nparameterized monads, and can express other constructions, including precise\ntype-and-effect systems and information flow tracking; more generally,\npolymonads correspond to Tate's productoid semantic model. We show how to equip\na core language (called lambda-PM) with syntactic support for programming with\npolymonads. Type inference and elaboration in lambda-PM allows programmers to\nwrite polymonadic code directly in an ML-like syntax--our algorithms compute\nprincipal types and produce elaborated programs wherein the binds appear\nexplicitly. Furthermore, we prove that the elaboration is coherent: no matter\nwhich (type-correct) binds are chosen, the elaborated program's semantics will\nbe the same. Pleasingly, the inferred types are easy to read: the polymonad\nlaws justify (sometimes dramatic) simplifications, but with no effect on a\ntype's generality.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jun 2014 03:30:05 GMT"}], "update_date": "2014-06-10", "authors_parsed": [["Hicks", "Michael", "", "University of Maryland, College Park"], ["Bierman", "Gavin", "", "Microsoft Research"], ["Guts", "Nataliya", "", "University of Maryland, College Park"], ["Leijen", "Daan", "", "Microsoft Research"], ["Swamy", "Nikhil", "", "Microsoft Research"]]}, {"id": "1406.2061", "submitter": "EPTCS", "authors": "Daan Leijen (Microsoft Research)", "title": "Koka: Programming with Row Polymorphic Effect Types", "comments": "In Proceedings MSFP 2014, arXiv:1406.1534", "journal-ref": "EPTCS 153, 2014, pp. 100-126", "doi": "10.4204/EPTCS.153.8", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a programming model where effects are treated in a disciplined\nway, and where the potential side-effects of a function are apparent in its\ntype signature. The type and effect of expressions can also be inferred\nautomatically, and we describe a polymorphic type inference system based on\nHindley-Milner style inference. A novel feature is that we support polymorphic\neffects through row-polymorphism using duplicate labels. Moreover, we show that\nour effects are not just syntactic labels but have a deep semantic connection\nto the program. For example, if an expression can be typed without an exn\neffect, then it will never throw an unhandled exception. Similar to Haskell's\n`runST` we show how we can safely encapsulate stateful operations. Through the\nstate effect, we can also safely combine state with let-polymorphism without\nneeding either imperative type variables or a syntactic value restriction.\nFinally, our system is implemented fully in a new language called Koka and has\nbeen used successfully on various small to medium-sized sample programs ranging\nfrom a Markdown processor to a tier-splitted chat application. You can try out\nKoka live at www.rise4fun.com/koka/tutorial.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jun 2014 03:30:31 GMT"}], "update_date": "2014-06-10", "authors_parsed": [["Leijen", "Daan", "", "Microsoft Research"]]}, {"id": "1406.2062", "submitter": "EPTCS", "authors": "Wolfgang Jeltsch (TT\\\"U K\\\"uberneetika Instituut)", "title": "Categorical Semantics for Functional Reactive Programming with Temporal\n  Recursion and Corecursion", "comments": "In Proceedings MSFP 2014, arXiv:1406.1534", "journal-ref": "EPTCS 153, 2014, pp. 127-142", "doi": "10.4204/EPTCS.153.9", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Functional reactive programming (FRP) makes it possible to express temporal\naspects of computations in a declarative way. Recently we developed two kinds\nof categorical models of FRP: abstract process categories (APCs) and concrete\nprocess categories (CPCs). Furthermore we showed that APCs generalize CPCs. In\nthis paper, we extend APCs with additional structure. This structure models\nrecursion and corecursion operators that are related to time. We show that the\nresulting categorical models generalize those CPCs that impose an additional\nconstraint on time scales. This constraint boils down to ruling out\n$\\omega$-supertasks, which are closely related to Zeno's paradox of Achilles\nand the tortoise.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jun 2014 03:30:38 GMT"}], "update_date": "2014-06-10", "authors_parsed": [["Jeltsch", "Wolfgang", "", "TT\u00dc K\u00fcberneetika Instituut"]]}, {"id": "1406.2063", "submitter": "EPTCS", "authors": "Baltasar Tranc\\'on y Widemann (Ilmenau University of Technology),\n  Markus Lepper (<semantics/> GmbH)", "title": "Foundations of Total Functional Data-Flow Programming", "comments": "In Proceedings MSFP 2014, arXiv:1406.1534", "journal-ref": "EPTCS 153, 2014, pp. 143-167", "doi": "10.4204/EPTCS.153.10", "report-no": null, "categories": "cs.PL cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field of declarative stream programming (discrete time, clocked\nsynchronous, modular, data-centric) is divided between the data-flow graph\nparadigm favored by domain experts, and the functional reactive paradigm\nfavored by academics. In this paper, we describe the foundations of a framework\nfor unifying functional and data-flow styles that differs from FRP proper in\nsignificant ways: It is based on set theory to match the expectations of domain\nexperts, and the two paradigms are reduced symmetrically to a low-level middle\nground, with strongly compositional semantics. The design of the framework is\nderived from mathematical first principles, in particular coalgebraic\ncoinduction and a standard relational model of stateful computation. The\nabstract syntax and semantics introduced here constitute the full core of a\nnovel stream programming language.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jun 2014 03:30:43 GMT"}], "update_date": "2014-06-10", "authors_parsed": [["Widemann", "Baltasar Tranc\u00f3n y", "", "Ilmenau University of Technology"], ["Lepper", "Markus", "", "<semantics/> GmbH"]]}, {"id": "1406.2064", "submitter": "EPTCS", "authors": "Tarmo Uustalu", "title": "Coherence for Skew-Monoidal Categories", "comments": "In Proceedings MSFP 2014, arXiv:1406.1534", "journal-ref": "EPTCS 153, 2014, pp. 68-77", "doi": "10.4204/EPTCS.153.5", "report-no": null, "categories": "cs.LO cs.PL math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  I motivate a variation (due to K. Szlach\\'{a}nyi) of monoidal categories\ncalled skew-monoidal categories where the unital and associativity laws are not\nrequired to be isomorphisms, only natural transformations. Coherence has to be\nformulated differently than in the well-known monoidal case. In my (to my\nknowledge new) version, it becomes a statement of uniqueness of normalizing\nrewrites. I present a proof of this coherence theorem and also formalize it\nfully in the dependently typed programming language Agda.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jun 2014 03:45:29 GMT"}], "update_date": "2014-08-26", "authors_parsed": [["Uustalu", "Tarmo", ""]]}, {"id": "1406.2065", "submitter": "EPTCS", "authors": "Diego Latella (ISTI - CNR), Michele Loreti (Universit\\`a di Firenze),\n  Mieke Massink (ISTI - CNR), Valerio Senni (IMT Lucca)", "title": "Stochastically timed predicate-based communication primitives for\n  autonomic computing", "comments": "In Proceedings QAPL 2014, arXiv:1406.1567", "journal-ref": "EPTCS 154, 2014, pp. 1-16", "doi": "10.4204/EPTCS.154.1", "report-no": null, "categories": "cs.PL cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicate-based communication allows components of a system to send messages\nand requests to ensembles of components that are determined at execution time\nthrough the evaluation of a predicate, in a multicast fashion. Predicate-based\ncommunication can greatly simplify the programming of autonomous and adaptive\nsystems. We present a stochastically timed extension of the Software Component\nEnsemble Language (SCEL) that was introduced in previous work. Such an\nextension raises a number of non-trivial design and formal semantics issues\nwith different options as possible solutions at different levels of\nabstraction. We discuss four of these options, of which two in more detail. We\nprovide a formal semantics definition and an illustration of the use of the\nlanguage modeling a bike sharing system, together with some preliminary\nanalysis of the system performance.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jun 2014 03:47:33 GMT"}], "update_date": "2014-06-10", "authors_parsed": [["Latella", "Diego", "", "ISTI - CNR"], ["Loreti", "Michele", "", "Universit\u00e0 di Firenze"], ["Massink", "Mieke", "", "ISTI - CNR"], ["Senni", "Valerio", "", "IMT Lucca"]]}, {"id": "1406.2066", "submitter": "EPTCS", "authors": "Marino Miculan (DiMI, University of Udine), Marco Peressotti (DiMI,\n  University of Udine)", "title": "GSOS for non-deterministic processes with quantitative aspects", "comments": "In Proceedings QAPL 2014, arXiv:1406.1567", "journal-ref": "EPTCS 154, 2014, pp. 17-33", "doi": "10.4204/EPTCS.154.2", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, some general frameworks have been proposed as unifying theories for\nprocesses combining non-determinism with quantitative aspects (such as\nprobabilistic or stochastically timed executions), aiming to provide general\nresults and tools. This paper provides two contributions in this respect.\nFirst, we present a general GSOS specification format (and a corresponding\nnotion of bisimulation) for non-deterministic processes with quantitative\naspects. These specifications define labelled transition systems according to\nthe ULTraS model, an extension of the usual LTSs where the transition relation\nassociates any source state and transition label with state reachability weight\nfunctions (like, e.g., probability distributions). This format, hence called\nWeight Function SOS (WFSOS), covers many known systems and their bisimulations\n(e.g. PEPA, TIPP, PCSP) and GSOS formats (e.g. GSOS, Weighted GSOS,\nSegala-GSOS, among others).\n  The second contribution is a characterization of these systems as coalgebras\nof a class of functors, parametric on the weight structure. This result allows\nus to prove soundness of the WFSOS specification format, and that\nbisimilarities induced by these specifications are always congruences.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jun 2014 03:47:46 GMT"}], "update_date": "2014-06-10", "authors_parsed": [["Miculan", "Marino", "", "DiMI, University of Udine"], ["Peressotti", "Marco", "", "DiMI,\n  University of Udine"]]}, {"id": "1406.2099", "submitter": "Zahid Halim", "authors": "Tufail Muhammad, Zahid Halim and Majid Ali Khan", "title": "ClassSpy: Java Object Pattern Visualization Tool", "comments": "ICOMS-2013. International Conference on Modeling and Simulation,\n  25-27 November, Islamabad", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern java programs consist of large number of classes as well as vast\namount of objects instantiated during program execution. Software developers\nare always keen to know the number of objects created for each class. This\ninformation is helpful for a developer in understanding the packages/classes of\na program and optimizing their code. However, understanding such a vast amount\nof information is not a trivial task. Visualization helps to depict this\ninformation on a single screen and to comprehend it efficiently. This paper\npresents a visualization approach that depicts information about all the\nobjects instantiated during the program execution. The proposed technique is\nmore space efficient and scalable to handle vast datasets, at the same time\nhelpful to identify the key program components. This easy to use interface\nprovides user an environment to glimpse the entire objects on a single screen.\nThe proposed approach allows sorting objects at class, thread and method\nlevels. Effectiveness and usability of the proposed approach is shown through\ncase studies.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jun 2014 07:44:56 GMT"}], "update_date": "2014-06-10", "authors_parsed": [["Muhammad", "Tufail", ""], ["Halim", "Zahid", ""], ["Khan", "Majid Ali", ""]]}, {"id": "1406.2121", "submitter": "Remy Haemmerle", "authors": "Edmund S. L. Lam and Iliano Cervesato", "title": "Constraint Handling Rules with Multiset Comprehension Patterns", "comments": "Part of CHR 2014 proceedings (arXiv:1406.1510)", "journal-ref": null, "doi": null, "report-no": "CHR/2014/3", "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  CHR is a declarative, concurrent and committed choice rule-based constraint\nprogramming language. We extend CHR with multiset comprehension patterns,\nproviding the programmer with the ability to write multiset rewriting rules\nthat can match a variable number of constraints in the store. This enables\nwriting more readable, concise and declarative code for algorithms that\ncoordinate large amounts of data or require aggregate operations. We call this\nextension $\\mathit{CHR}^\\mathit{cp}$. We give a high-level abstract semantics\nof $\\mathit{CHR}^\\mathit{cp}$, followed by a lower-level operational semantics.\nWe then show the soundness of this operational semantics with respect to the\nabstract semantics.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jun 2014 10:03:26 GMT"}], "update_date": "2014-06-10", "authors_parsed": [["Lam", "Edmund S. L.", ""], ["Cervesato", "Iliano", ""]]}, {"id": "1406.2122", "submitter": "Remy Haemmerle", "authors": "Ralf Gerlich", "title": "Automatic Test Data Generation and Model Checking with CHR", "comments": "Part of CHR 2014 proceedings (arXiv:1406.1510)", "journal-ref": null, "doi": null, "report-no": "CHR/2014/1", "categories": "cs.SE cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an example for application of Constraint Handling Rules to\nautomated test data generation and model checking in verification of mission\ncritical software for satellite control.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jun 2014 10:12:18 GMT"}], "update_date": "2014-06-10", "authors_parsed": [["Gerlich", "Ralf", ""]]}, {"id": "1406.2125", "submitter": "Remy Haemmerle", "authors": "Falco Nogatz and Thom Fr\\\"uhwirth", "title": "From XML Schema to JSON Schema: Translation with CHR", "comments": "Part of CHR 2014 proceedings (arXiv:1406.1510)", "journal-ref": null, "doi": null, "report-no": "CHR/2014/2", "categories": "cs.DB cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite its rising popularity as data format especially for web services, the\nsoftware ecosystem around the JavaScript Object Notation (JSON) is not as\nwidely distributed as that of XML. For both data formats there exist schema\nlanguages to specify the structure of instance documents, but there is\ncurrently no opportunity to translate already existing XML Schema documents\ninto equivalent JSON Schemas.\n  In this paper we introduce an implementation of a language translator. It\ntakes an XML Schema and creates its equivalent JSON Schema document. Our\napproach is based on Prolog and CHR. By unfolding the XML Schema document into\nCHR constraints, it is possible to specify the concrete translation rules in a\ndeclarative way.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jun 2014 10:33:41 GMT"}], "update_date": "2014-06-10", "authors_parsed": [["Nogatz", "Falco", ""], ["Fr\u00fchwirth", "Thom", ""]]}, {"id": "1406.2370", "submitter": "Beniamino Accattoli", "authors": "Beniamino Accattoli, Pablo Barenbaum, Damiano Mazza", "title": "Distilling Abstract Machines (Long Version)", "comments": "63 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well-known that many environment-based abstract machines can be seen as\nstrategies in lambda calculi with explicit substitutions (ES). Recently,\ngraphical syntaxes and linear logic led to the linear substitution calculus\n(LSC), a new approach to ES that is halfway between big-step calculi and\ntraditional calculi with ES. This paper studies the relationship between the\nLSC and environment-based abstract machines. While traditional calculi with ES\nsimulate abstract machines, the LSC rather distills them: some transitions are\nsimulated while others vanish, as they map to a notion of structural\ncongruence. The distillation process unveils that abstract machines in fact\nimplement weak linear head reduction, a notion of evaluation having a central\nrole in the theory of linear logic. We show that such a pattern applies\nuniformly in call-by-name, call-by-value, and call-by-need, catching many\nmachines in the literature. We start by distilling the KAM, the CEK, and the\nZINC, and then provide simplified versions of the SECD, the lazy KAM, and\nSestoft's machine. Along the way we also introduce some new machines with\nglobal environments. Moreover, we show that distillation preserves the time\ncomplexity of the executions, i.e. the LSC is a complexity-preserving\nabstraction of abstract machines.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jun 2014 21:44:34 GMT"}], "update_date": "2014-06-11", "authors_parsed": [["Accattoli", "Beniamino", ""], ["Barenbaum", "Pablo", ""], ["Mazza", "Damiano", ""]]}, {"id": "1406.3313", "submitter": "EPTCS", "authors": "Alastair F. Donaldson (Imperial College London), Vasco T. Vasconcelos\n  (University of Lisbon)", "title": "Proceedings 7th Workshop on Programming Language Approaches to\n  Concurrency and Communication-cEntric Software", "comments": null, "journal-ref": "EPTCS 155, 2014", "doi": "10.4204/EPTCS.155", "report-no": null, "categories": "cs.DC cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the post-proceedings of PLACES 2014, the seventh\nWorkshop on Programming Language Approaches to Concurrency and\nCommunication-cEntric Software, which was held in Grenoble, France, on April\n12th 2014, and co-located with ETAPS, the European Joint Conferences on Theory\nand Practice of Software. The PLACES workshop series aims to offer a forum\nwhere researchers from different fields exchange new ideas on one of the\ncentral challenges for programming in the near future: the development of\nprogramming languages, methodologies and infrastructures where concurrency and\ndistribution are the norm rather than a marginal concern. Previous editions of\nPLACES were held in Rome (2013), Tallin (2012), Saarbrueken (2011), Paphos\n(2010) and York (2009), all co-located with ETAPS, and the first PLACES was\nheld in Oslo and co-located with DisCoTec (2008).\n  The Program Committee, after a careful and thorough reviewing process,\nselected nine papers out of 12 submissions for presentation at the workshop and\ninclusion in this post-proceedings. Each submission was evaluated by three\nreferees (with one paper receiving a fourth review), and the accepted papers\nwere selected during a week-long electronic discussion. One of the nine\naccepted papers was conditionally accepted subject to a process of shepherding\nby a PC member, which was successful and led to the paper's full acceptance.\n  In addition to the contributed papers, the workshop will feature an invited\ntalk by Akash Lal, Microsoft Research India, entitled \"Finding Concurrency Bugs\nUnder Imprecise Harnesses\".\n", "versions": [{"version": "v1", "created": "Thu, 12 Jun 2014 18:39:04 GMT"}], "update_date": "2014-06-13", "authors_parsed": [["Donaldson", "Alastair F.", "", "Imperial College London"], ["Vasconcelos", "Vasco T.", "", "University of Lisbon"]]}, {"id": "1406.3478", "submitter": "EPTCS", "authors": "Dimitris Mostrous (LaSIGE, Faculty of Sciences, University of Lisbon)", "title": "Multiparty Sessions based on Proof Nets", "comments": "In Proceedings PLACES 2014, arXiv:1406.3313", "journal-ref": "EPTCS 155, 2014, pp. 1-8", "doi": "10.4204/EPTCS.155.1", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We interpret Linear Logic Proof Nets in a term language based on Solos\ncalculus. The system includes a synchronisation mechanism, obtained by a\nconservative extension of the logic, that enables to define non-deterministic\nbehaviours and multiparty sessions.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jun 2014 10:16:34 GMT"}], "update_date": "2014-06-16", "authors_parsed": [["Mostrous", "Dimitris", "", "LaSIGE, Faculty of Sciences, University of Lisbon"]]}, {"id": "1406.3479", "submitter": "EPTCS", "authors": "Sam Lindley (The University of Edinburgh), J. Garrett Morris (The\n  University of Edinburgh)", "title": "Sessions as Propositions", "comments": "In Proceedings PLACES 2014, arXiv:1406.3313", "journal-ref": "EPTCS 155, 2014, pp. 9-16", "doi": "10.4204/EPTCS.155.2", "report-no": null, "categories": "cs.PL cs.DC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, Wadler presented a continuation-passing translation from a\nsession-typed functional language, GV, to a process calculus based on classical\nlinear logic, CP. However, this translation is one-way: CP is more expressive\nthan GV. We propose an extension of GV, called HGV, and give translations\nshowing that it is as expressive as CP. The new translations shed light both on\nthe original translation from GV to CP, and on the limitations in\nexpressiveness of GV.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jun 2014 10:16:41 GMT"}], "update_date": "2014-06-16", "authors_parsed": [["Lindley", "Sam", "", "The University of Edinburgh"], ["Morris", "J. Garrett", "", "The\n  University of Edinburgh"]]}, {"id": "1406.3480", "submitter": "EPTCS", "authors": "Francesco Tiezzi (IMT Institute for Advanced Studies, Lucca, Italy),\n  Nobuko Yoshida (Imperial College, London, U.K.)", "title": "Towards Reversible Sessions", "comments": "In Proceedings PLACES 2014, arXiv:1406.3313", "journal-ref": "EPTCS 155, 2014, pp. 17-24", "doi": "10.4204/EPTCS.155.3", "report-no": null, "categories": "cs.PL cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we incorporate reversibility into structured\ncommunication-based programming, to allow parties of a session to automatically\nundo, in a rollback fashion, the effect of previously executed interactions.\nThis permits taking different computation paths along the same session, as well\nas reverting the whole session and starting a new one. Our aim is to define a\ntheoretical basis for examining the interplay in concurrent systems between\nreversible computation and session-based interaction. We thus enrich a\nsession-based variant of pi-calculus with memory devices, dedicated to keep\ntrack of the computation history of sessions in order to reverse it. We discuss\nour initial investigation concerning the definition of a session type\ndiscipline for the proposed reversible calculus, and its practical advantages\nfor static verification of safe composition in communication-centric\ndistributed software performing reversible computations.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jun 2014 10:16:51 GMT"}], "update_date": "2014-06-16", "authors_parsed": [["Tiezzi", "Francesco", "", "IMT Institute for Advanced Studies, Lucca, Italy"], ["Yoshida", "Nobuko", "", "Imperial College, London, U.K."]]}, {"id": "1406.3481", "submitter": "EPTCS", "authors": "Dimitrios Kouzapas (University of Glasgow), Ram\\=unas Gutkovas\n  (Uppsala University), Simon J. Gay (University of Glasgow)", "title": "Session Types for Broadcasting", "comments": "In Proceedings PLACES 2014, arXiv:1406.3313", "journal-ref": "EPTCS 155, 2014, pp. 25-31", "doi": "10.4204/EPTCS.155.4", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Up to now session types have been used under the assumptions of point to\npoint communication, to ensure the linearity of session endpoints, and reliable\ncommunication, to ensure send/receive duality. In this paper we define a\nsession type theory for broadcast communication semantics that by definition do\nnot assume point to point and reliable communication. Our session framework\nlies on top of the parametric framework of broadcasting psi-calculi, giving\ninsights on developing session types within a parametric framework. Our session\ntype theory enjoys the properties of soundness and safety. We further believe\nthat the solutions proposed will eventually provide a deeper understanding of\nhow session types principles should be applied in the general case of\ncommunication semantics.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jun 2014 10:17:02 GMT"}], "update_date": "2014-06-16", "authors_parsed": [["Kouzapas", "Dimitrios", "", "University of Glasgow"], ["Gutkovas", "Ram\u016bnas", "", "Uppsala University"], ["Gay", "Simon J.", "", "University of Glasgow"]]}, {"id": "1406.3483", "submitter": "EPTCS", "authors": "Tzu-chun Chen (Dipartimento di Informatica, Universita' di Torino,\n  Italy)", "title": "Lightening Global Types", "comments": "In Proceedings PLACES 2014, arXiv:1406.3313", "journal-ref": "EPTCS 155, 2014, pp. 38-46", "doi": "10.4204/EPTCS.155.6", "report-no": null, "categories": "cs.PL cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Global session types prevent participants from waiting for never coming\nmessages. Some interactions take place just for the purpose of informing\nreceivers that some message will never arrive or the session is terminated. By\ndecomposing a big global type into several light global types, one can avoid\nsuch kind of redundant interactions. Lightening global types gives us cleaner\nglobal types, which keep all necessary communications. This work proposes a\nframework which allows to easily decompose global types into light global\ntypes, preserving the interaction sequences of the original ones but for\nredundant interactions.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jun 2014 10:17:23 GMT"}], "update_date": "2014-06-16", "authors_parsed": [["Chen", "Tzu-chun", "", "Dipartimento di Informatica, Universita' di Torino,\n  Italy"]]}, {"id": "1406.3484", "submitter": "EPTCS", "authors": "Stefan Blom (University of Twente), Saeed Darabi (University of\n  Twente), Marieke Huisman (University of Twente)", "title": "Verifying Parallel Loops with Separation Logic", "comments": "In Proceedings PLACES 2014, arXiv:1406.3313", "journal-ref": "EPTCS 155, 2014, pp. 47-53", "doi": "10.4204/EPTCS.155.7", "report-no": null, "categories": "cs.SE cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a technique to specify and verify whether a loop can be\nparallelised. Our approach can be used as an additional step in a parallelising\ncompiler to verify user annotations about loop dependences. Essentially, our\ntechnique requires each loop iteration to be specified with the locations it\nwill read and write. From the loop iteration specifications, the loop\n(in)dependences can be derived. Moreover, the loop iteration specifications\nalso reveal where synchronisation is needed in the parallelised program. The\nloop iteration specifications can be verified using permission-based separation\nlogic.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jun 2014 10:17:34 GMT"}], "update_date": "2014-06-16", "authors_parsed": [["Blom", "Stefan", "", "University of Twente"], ["Darabi", "Saeed", "", "University of\n  Twente"], ["Huisman", "Marieke", "", "University of Twente"]]}, {"id": "1406.3485", "submitter": "EPTCS", "authors": "Janwillem Swalens (Vrije Universiteit Brussel), Stefan Marr (Vrije\n  Universiteit Brussel), Joeri De Koster (Vrije Universiteit Brussel), Tom Van\n  Cutsem (Vrije Universiteit Brussel)", "title": "Towards Composable Concurrency Abstractions", "comments": "In Proceedings PLACES 2014, arXiv:1406.3313", "journal-ref": "EPTCS 155, 2014, pp. 54-60", "doi": "10.4204/EPTCS.155.8", "report-no": null, "categories": "cs.PL cs.DC cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past decades, many different programming models for managing\nconcurrency in applications have been proposed, such as the actor model,\nCommunicating Sequential Processes, and Software Transactional Memory. The\nubiquity of multi-core processors has made harnessing concurrency even more\nimportant. We observe that modern languages, such as Scala, Clojure, or F#,\nprovide not one, but multiple concurrency models that help developers manage\nconcurrency. Large end-user applications are rarely built using just a single\nconcurrency model. Programmers need to manage a responsive UI, deal with file\nor network I/O, asynchronous workflows, and shared resources. Different\nconcurrency models facilitate different requirements. This raises the issue of\nhow these concurrency models interact, and whether they are composable. After\nall, combining different concurrency models may lead to subtle bugs or\ninconsistencies.\n  In this paper, we perform an in-depth study of the concurrency abstractions\nprovided by the Clojure language. We study all pairwise combinations of the\nabstractions, noting which ones compose without issues, and which do not. We\nmake an attempt to abstract from the specifics of Clojure, identifying the\ngeneral properties of concurrency models that facilitate or hinder composition.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jun 2014 10:17:43 GMT"}], "update_date": "2014-06-16", "authors_parsed": [["Swalens", "Janwillem", "", "Vrije Universiteit Brussel"], ["Marr", "Stefan", "", "Vrije\n  Universiteit Brussel"], ["De Koster", "Joeri", "", "Vrije Universiteit Brussel"], ["Van Cutsem", "Tom", "", "Vrije Universiteit Brussel"]]}, {"id": "1406.4087", "submitter": "Artem Melentyev", "authors": "Artem Melentyev", "title": "Java Modular Extension for Operator Overloading", "comments": "International Journal of Programming Languages and Applications,\n  Volume 4, Number 2, (2014)", "journal-ref": null, "doi": "10.5121/ijpla.2014.4201", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper introduces a modular extension (plugin) for Java language compilers\nand Integrated Development Environments (IDE) which adds operator overloading\nfeature to Java language while preserving backward compatibility.\n  The extension use the idea of library-based language extensibility similar to\nSugarJ. But unlike most language extensions, it works directly inside the\ncompiler and does not have any external preprocessors. This gives much faster\ncompilation, better language compatibility and support of native developer\ntools (IDE, build tools).\n  The extension plugs into javac and Eclipse Java compilers as well as in all\ntools whose use the compilers such as IDEs (Netbeans, Eclipse, IntelliJ IDEA),\nbuild tools (ant, maven, gradle), etc. No compiler, IDE, build tools\nmodification needed. Just add a jar library to classpath and/or install a\nplugin to your IDE.\n  The paper also discuss on how to build such Java compiler extensions.\n  The extension source code is open on http://amelentev.github.io/java-oo/\n", "versions": [{"version": "v1", "created": "Mon, 16 Jun 2014 18:04:54 GMT"}], "update_date": "2014-06-17", "authors_parsed": [["Melentyev", "Artem", ""]]}, {"id": "1406.4291", "submitter": "Christopher Meiklejohn", "authors": "Christopher Meiklejohn", "title": "Vector Clocks in Coq: An Experience Report", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This report documents the process of implementing vector clocks in the Coq\nproof assistant for extraction and use in the distributed Dynamo-inspired data\nstore, Riak. In this report, we focus on the technical challenges of using Core\nErlang code extracted from the proof assistant in a production-grade Erlang\napplication, as opposed to verification of the model itself.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jun 2014 09:32:16 GMT"}], "update_date": "2014-06-18", "authors_parsed": [["Meiklejohn", "Christopher", ""]]}, {"id": "1406.4823", "submitter": "Mauro Jaskelioff", "authors": "Exequiel Rivas and Mauro Jaskelioff", "title": "Notions of Computation as Monoids", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are different notions of computation, the most popular being monads,\napplicative functors, and arrows. In this article we show that these three\nnotions can be seen as monoids in a monoidal category. We demonstrate that at\nthis level of abstraction one can obtain useful results which can be\ninstantiated to the different notions of computation. In particular, we show\nhow free constructions and Cayley representations for monoids translate into\nuseful constructions for monads, applicative functors, and arrows. Moreover,\nthe uniform presentation of all three notions helps in the analysis of the\nrelation between them.\n", "versions": [{"version": "v1", "created": "Thu, 29 May 2014 13:08:42 GMT"}], "update_date": "2014-06-19", "authors_parsed": [["Rivas", "Exequiel", ""], ["Jaskelioff", "Mauro", ""]]}, {"id": "1406.5106", "submitter": "David Van Horn", "authors": "J. Ian Johnson, Ilya Sergey, Christopher Earl, Matthew Might, David\n  Van Horn", "title": "Pushdown flow analysis with abstract garbage collection", "comments": null, "journal-ref": "Journal of Functional Programming, Volume 24, Special Issue 2-3,\n  May 2014, pp 218-283", "doi": "10.1017/S0956796814000100 10.1017/S0956796814000100\n  10.1017/S0956796814000100 10.1017/S0956796814000100 10.1017/S0956796814000100", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the static analysis of functional programs, pushdown flow analysis and\nabstract garbage collection push the boundaries of what we can learn about\nprograms statically. This work illuminates and poses solutions to theoretical\nand practical challenges that stand in the way of combining the power of these\ntechniques. Pushdown flow analysis grants unbounded yet computable polyvariance\nto the analysis of return-flow in higher-order programs. Abstract garbage\ncollection grants unbounded polyvariance to abstract addresses which become\nunreachable between invocations of the abstract contexts in which they were\ncreated. Pushdown analysis solves the problem of precisely analyzing recursion\nin higher-order languages; abstract garbage collection is essential in solving\nthe \"stickiness\" problem. Alone, our benchmarks demonstrate that each method\ncan reduce analysis times and boost precision by orders of magnitude. We\ncombine these methods. The challenge in marrying these techniques is not\nsubtle: computing the reachable control states of a pushdown system relies on\nlimiting access during transition to the top of the stack; abstract garbage\ncollection, on the other hand, needs full access to the entire stack to compute\na root set, just as concrete collection does. Conditional pushdown systems were\ndeveloped for just such a conundrum, but existing methods are ill-suited for\nthe dynamic nature of garbage collection. We show fully precise and approximate\nsolutions to the feasible paths problem for pushdown garbage-collecting\ncontrol-flow analysis. Experiments reveal synergistic interplay between garbage\ncollection and pushdown techniques, and the fusion demonstrates\n\"better-than-both-worlds\" precision.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jun 2014 16:51:12 GMT"}], "update_date": "2014-06-20", "authors_parsed": [["Johnson", "J. Ian", ""], ["Sergey", "Ilya", ""], ["Earl", "Christopher", ""], ["Might", "Matthew", ""], ["Van Horn", "David", ""]]}, {"id": "1406.5457", "submitter": "Helmut Seidl", "authors": "Thomas M. Gawlitza, Martin D. Schwarz, Helmut Seidl", "title": "Parametric Strategy Iteration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Program behavior may depend on parameters, which are either configured before\ncompilation time, or provided at run-time, e.g., by sensors or other input\ndevices. Parametric program analysis explores how different parameter settings\nmay affect the program behavior.\n  In order to infer invariants depending on parameters, we introduce parametric\nstrategy iteration. This algorithm determines the precise least solution of\nsystems of integer equations depending on surplus parameters. Conceptually, our\nalgorithm performs ordinary strategy iteration on the given integer system for\nall possible parameter settings in parallel. This is made possible by means of\nregion trees to represent the occurring piecewise affine functions. We indicate\nthat each required operation on these trees is polynomial-time if only\nconstantly many parameters are involved.\n  Parametric strategy iteration for systems of integer equations allows to\nconstruct parametric integer interval analysis as well as parametric analysis\nof differences of integer variables. It thus provides a general technique to\nrealize precise parametric program analysis if numerical properties of integer\nvariables are of concern.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jun 2014 19:35:27 GMT"}], "update_date": "2014-06-23", "authors_parsed": [["Gawlitza", "Thomas M.", ""], ["Schwarz", "Martin D.", ""], ["Seidl", "Helmut", ""]]}, {"id": "1406.5572", "submitter": "Emery Berger", "authors": "Emma Tosch and Emery D. Berger", "title": "SurveyMan: Programming and Automatically Debugging Surveys", "comments": "Submitted version; accepted to OOPSLA 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Surveys can be viewed as programs, complete with logic, control flow, and\nbugs. Word choice or the order in which questions are asked can unintentionally\nbias responses. Vague, confusing, or intrusive questions can cause respondents\nto abandon a survey. Surveys can also have runtime errors: inattentive\nrespondents can taint results. This effect is especially problematic when\ndeploying surveys in uncontrolled settings, such as on the web or via\ncrowdsourcing platforms. Because the results of surveys drive business\ndecisions and inform scientific conclusions, it is crucial to make sure they\nare correct.\n  We present SurveyMan, a system for designing, deploying, and automatically\ndebugging surveys. Survey authors write their surveys in a lightweight\ndomain-specific language aimed at end users. SurveyMan statically analyzes the\nsurvey to provide feedback to survey authors before deployment. It then\ncompiles the survey into JavaScript and deploys it either to the web or a\ncrowdsourcing platform. SurveyMan's dynamic analyses automatically find survey\nbugs, and control for the quality of responses. We evaluate SurveyMan's\nalgorithms analytically and empirically, demonstrating its effectiveness with\ncase studies of social science surveys conducted via Amazon's Mechanical Turk.\n", "versions": [{"version": "v1", "created": "Sat, 21 Jun 2014 02:52:48 GMT"}], "update_date": "2014-06-24", "authors_parsed": [["Tosch", "Emma", ""], ["Berger", "Emery D.", ""]]}, {"id": "1406.5715", "submitter": "Alexander Kaiser", "authors": "Alexander Kaiser, Daniel Kroening, Thomas Wahl", "title": "Lost in Abstraction: Monotonicity in Multi-Threaded Programs (Extended\n  Technical Report)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monotonicity in concurrent systems stipulates that, in any global state,\nextant system actions remain executable when new processes are added to the\nstate. This concept is not only natural and common in multi-threaded software,\nbut also useful: if every thread's memory is finite, monotonicity often\nguarantees the decidability of safety property verification even when the\nnumber of running threads is unknown. In this paper, we show that the act of\nobtaining finite-data thread abstractions for model checking can be at odds\nwith monotonicity: Predicate-abstracting certain widely used monotone software\nresults in non-monotone multi-threaded Boolean programs - the monotonicity is\nlost in the abstraction. As a result, well-established sound and complete\nsafety checking algorithms become inapplicable; in fact, safety checking turns\nout to be undecidable for the obtained class of unbounded-thread Boolean\nprograms. We demonstrate how the abstract programs can be modified into\nmonotone ones, without affecting safety properties of the non-monotone\nabstraction. This significantly improves earlier approaches of enforcing\nmonotonicity via overapproximations.\n", "versions": [{"version": "v1", "created": "Sun, 22 Jun 2014 12:34:17 GMT"}, {"version": "v2", "created": "Tue, 24 Jun 2014 20:25:25 GMT"}], "update_date": "2014-06-26", "authors_parsed": [["Kaiser", "Alexander", ""], ["Kroening", "Daniel", ""], ["Wahl", "Thomas", ""]]}, {"id": "1406.6163", "submitter": "Daniel Merkle", "authors": "Felix P. Hargreaves, Daniel Merkle, Peter Schneider-Kamp", "title": "Group Communication Patterns for High Performance Computing in Scala", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We developed a Functional object-oriented Parallel framework (FooPar) for\nhigh-level high-performance computing in Scala. Central to this framework are\nDistributed Memory Parallel Data structures (DPDs), i.e., collections of data\ndistributed in a shared nothing system together with parallel operations on\nthese data. In this paper, we first present FooPar's architecture and the idea\nof DPDs and group communications. Then, we show how DPDs can be implemented\nelegantly and efficiently in Scala based on the Traversable/Builder pattern,\nunifying Functional and Object-Oriented Programming. We prove the correctness\nand safety of one communication algorithm and show how specification testing\n(via ScalaCheck) can be used to bridge the gap between proof and\nimplementation. Furthermore, we show that the group communication operations of\nFooPar outperform those of the MPJ Express open source MPI-bindings for Java,\nboth asymptotically and empirically. FooPar has already been shown to be\ncapable of achieving close-to-optimal performance for dense matrix-matrix\nmultiplication via JNI. In this article, we present results on a parallel\nimplementation of the Floyd-Warshall algorithm in FooPar, achieving more than\n94 % efficiency compared to the serial version on a cluster using 100 cores for\nmatrices of dimension 38000 x 38000.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jun 2014 08:04:36 GMT"}], "update_date": "2014-06-25", "authors_parsed": [["Hargreaves", "Felix P.", ""], ["Merkle", "Daniel", ""], ["Schneider-Kamp", "Peter", ""]]}, {"id": "1406.6631", "submitter": "Aggelos Biboudis", "authors": "Aggelos Biboudis, Nick Palladinos and Yannis Smaragdakis", "title": "Clash of the Lambdas", "comments": "In the revised version: 1) we used a fixed heap with 3GB. The GC\n  throughput was improved and results are more balanced, 2) we discussed\n  briefly why we chose not to use targeted JVM flags, 3) we discussed\n  @specialized and miniboxing, 4) we added a new benchmark that tests a\n  streaming operation that avoids automatic boxing of our input data and 5) a\n  subtitle was added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The introduction of lambdas in Java 8 completes the slate of\nstatically-typed, mainstream languages with both object-oriented and functional\nfeatures. The main motivation for lambdas in Java has been to facilitate\nstream-based declarative APIs, and, therefore, easier parallelism. In this\npaper, we evaluate the performance impact of lambda abstraction employed in\nstream processing, for a variety of high-level languages that run on a virtual\nmachine (C#, F#, Java and Scala) and runtime platforms (JVM on Linux and\nWindows, .NET CLR for Windows, Mono for Linux). Furthermore, we evaluate the\nperformance gain that two optimizing libraries (ScalaBlitz and LinqOptimizer)\ncan offer for C#, F# and Scala. Our study is based on small-scale\nthroughput-benchmarking, with significant care to isolate different factors,\nconsult experts on the systems involved, and identify causes and opportunities.\nWe find that Java exhibits high implementation maturity, which is a dominant\nfactor in benchmarks. At the same time, optimizing frameworks can be highly\neffective for common query patterns.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jun 2014 16:33:11 GMT"}, {"version": "v2", "created": "Mon, 14 Jul 2014 11:24:58 GMT"}], "update_date": "2014-07-15", "authors_parsed": [["Biboudis", "Aggelos", ""], ["Palladinos", "Nick", ""], ["Smaragdakis", "Yannis", ""]]}, {"id": "1406.7497", "submitter": "Moez AbdelGawad", "authors": "Moez A. AbdelGawad", "title": "Domain Theory for Modeling OOP: A Summary", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain theory is `a mathematical theory that serves as a foundation for the\nsemantics of programming languages'. Domains form the basis of a theory of\npartial information, which extends the familiar notion of partial function to\nencompass a whole spectrum of \"degrees of definedness\", so as to model\nincremental higher-order computation (i.e., computing with infinite data\nvalues, such as functions defined over an infinite domain like the domain of\nintegers, infinite trees, and such as objects of object-oriented programming).\nGeneral considerations from recursion theory dictate that partial functions are\nunavoidable in any discussion of computability. Domain theory provides an\nappropriately abstract setting in which the notion of a partial function can be\nlifted and used to give meaning to higher types, recursive types, etc. NOOP is\na domain-theoretic model of nominally-typed OOP. NOOP was used to prove the\nidentification of inheritance and subtyping in mainstream nominally-typed OO\nprogramming languages and the validity of this identification. In this report\nwe first present the definitions of basic domain theoretic notions and domain\nconstructors used in the construction of NOOP, then we present the construction\nof a simple structural model of OOP called COOP as a step towards the\nconstruction of NOOP. Like the construction of NOOP, the construction of COOP\nuses earlier presented domain constructors.\n", "versions": [{"version": "v1", "created": "Sun, 29 Jun 2014 12:23:25 GMT"}], "update_date": "2014-07-01", "authors_parsed": [["AbdelGawad", "Moez A.", ""]]}]