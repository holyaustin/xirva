[{"id": "1203.0681", "submitter": "Florentina Pintea", "authors": "Mohammed Fadle Abdulla", "title": "Manual and Fast C Code Optimization", "comments": "16 pages", "journal-ref": "Ann. Univ. Tibiscus Comp. Sci. Series VIII / 1 (2010), 93-108", "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developing an application with high performance through the code optimization\nplaces a greater responsibility on the programmers. While most of the existing\ncompilers attempt to automatically optimize the program code, manual techniques\nremain the predominant method for performing optimization. Deciding where to\ntry to optimize code is difficult, especially for large complex applications.\nFor manual optimization, the programmers can use his experiences in writing the\ncode, and then he can use a software profiler in order to collect and analyze\nthe performance data from the code. In this work, we have gathered the most\nexperiences which can be applied to improve the style of writing programs in C\nlanguage as well as we present an implementation of the manual optimization of\nthe codes using the Intel VTune profiler. The paper includes two case studies\nto illustrate our optimization on the Heap Sort and Factorial functions.\n", "versions": [{"version": "v1", "created": "Sat, 3 Mar 2012 20:42:37 GMT"}], "update_date": "2012-03-06", "authors_parsed": [["Abdulla", "Mohammed Fadle", ""]]}, {"id": "1203.0780", "submitter": "Luca Padovani", "authors": "Giuseppe Castagna (CNRS, PPS, Univ Paris Diderot, Sorbonne Paris\n  Cit\\'e, Paris, France), Mariangiola Dezani-Ciancaglini (Dipartimento di\n  Informatica, Universit`a degli Studi di Torino, Torino, Italy), Luca Padovani\n  (Dipartimento di Informatica, Universit`a degli Studi di Torino, Torino,\n  Italy)", "title": "On Global Types and Multi-Party Session", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 8, Issue 1 (March 15,\n  2012) lmcs:773", "doi": "10.2168/LMCS-8(1:24)2012", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Global types are formal specifications that describe communication protocols\nin terms of their global interactions. We present a new, streamlined language\nof global types equipped with a trace-based semantics and whose features and\nrestrictions are semantically justified. The multi-party sessions obtained\nprojecting our global types enjoy a liveness property in addition to the\ntraditional progress and are shown to be sound and complete with respect to the\nset of traces of the originating global type. Our notion of completeness is\nless demanding than the classical ones, allowing a multi-party session to leave\nout redundant traces from an underspecified global type. In addition to the\ntechnical content, we discuss some limitations of our language of global types\nand provide an extensive comparison with related specification languages\nadopted in different communities.\n", "versions": [{"version": "v1", "created": "Sun, 4 Mar 2012 22:05:29 GMT"}, {"version": "v2", "created": "Tue, 13 Mar 2012 21:23:23 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Castagna", "Giuseppe", "", "CNRS, PPS, Univ Paris Diderot, Sorbonne Paris\n  Cit\u00e9, Paris, France"], ["Dezani-Ciancaglini", "Mariangiola", "", "Dipartimento di\n  Informatica, Universit`a degli Studi di Torino, Torino, Italy"], ["Padovani", "Luca", "", "Dipartimento di Informatica, Universit`a degli Studi di Torino, Torino,\n  Italy"]]}, {"id": "1203.0835", "submitter": "Ronald de Haan", "authors": "Ronald de Haan", "title": "Functional Logic Programming with Generalized Circular Coinduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method to adapt functional logic programming to deal with\nreasoning on coinductively interpreted programs as well as on inductively\ninterpreted programs. In order to do so, we consider a class of objects\ninteresting for this coinductive interpretation, namely regular terms. We show\nhow the usual data structures can be adapted to capture these objects. We adapt\nthe operational semantics of Curry to interpret programs coinductively. We\nillustrate this method with several examples that show the working of our\nmethod and several cases in which it could be useful. Finally, we suggest how\nthe declarative semantics can be adapted suitably.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2012 09:07:18 GMT"}], "update_date": "2012-03-06", "authors_parsed": [["de Haan", "Ronald", ""]]}, {"id": "1203.1392", "submitter": "Zoltan Somogyi", "authors": "Quan Phan, Gerda Janssens and Zoltan Somogyi", "title": "Region-based memory management for Mercury programs", "comments": "74 pages, 23 figures, 11 tables. A shorter version of this paper,\n  without proofs, is to appear in the journal Theory and Practice of Logic\n  Programming (TPLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Region-based memory management (RBMM) is a form of compile time memory\nmanagement, well-known from the functional programming world. In this paper we\ndescribe our work on implementing RBMM for the logic programming language\nMercury. One interesting point about Mercury is that it is designed with strong\ntype, mode, and determinism systems. These systems not only provide Mercury\nprogrammers with several direct software engineering benefits, such as\nself-documenting code and clear program logic, but also give language\nimplementors a large amount of information that is useful for program analyses.\nIn this work, we make use of this information to develop program analyses that\ndetermine the distribution of data into regions and transform Mercury programs\nby inserting into them the necessary region operations. We prove the\ncorrectness of our program analyses and transformation. To execute the\nannotated programs, we have implemented runtime support that tackles the two\nmain challenges posed by backtracking. First, backtracking can require regions\nremoved during forward execution to be \"resurrected\"; and second, any memory\nallocated during a computation that has been backtracked over must be recovered\npromptly and without waiting for the regions involved to come to the end of\ntheir life. We describe in detail our solution of both these problems. We study\nin detail how our RBMM system performs on a selection of benchmark programs,\nincluding some well-known difficult cases for RBMM. Even with these difficult\ncases, our RBMM-enabled Mercury system obtains clearly faster runtimes for 15\nout of 18 benchmarks compared to the base Mercury system with its Boehm runtime\ngarbage collector, with an average runtime speedup of 24%, and an average\nreduction in memory requirements of 95%. In fact, our system achieves optimal\nmemory consumption in some programs.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2012 07:28:08 GMT"}], "update_date": "2012-03-08", "authors_parsed": [["Phan", "Quan", ""], ["Janssens", "Gerda", ""], ["Somogyi", "Zoltan", ""]]}, {"id": "1203.1448", "submitter": "Barak Pearlmutter", "authors": "Alexey Radul and Barak A. Pearlmutter and Jeffrey Mark Siskind", "title": "AD in Fortran, Part 1: Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.MS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose extensions to Fortran which integrate forward and reverse\nAutomatic Differentiation (AD) directly into the programming model.\nIrrespective of implementation technology, embedding AD constructs directly\ninto the language extends the reach and convenience of AD while allowing\nabstraction of concepts of interest to scientific-computing practice, such as\nroot finding, optimization, and finding equilibria of continuous games.\nMultiple different subprograms for these tasks can share common interfaces,\nregardless of whether and how they use AD internally. A programmer can maximize\na function F by calling a library maximizer, XSTAR=ARGMAX(F,X0), which\ninternally constructs derivatives of F by AD, without having to learn how to\nuse any particular AD tool. We illustrate the utility of these extensions by\nexample: programs become much more concise and closer to traditional\nmathematical notation. A companion paper describes how these extensions can be\nimplemented by a program that generates input to existing Fortran-based AD\ntools.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2012 12:04:05 GMT"}, {"version": "v2", "created": "Thu, 8 Mar 2012 09:51:03 GMT"}], "update_date": "2012-03-09", "authors_parsed": [["Radul", "Alexey", ""], ["Pearlmutter", "Barak A.", ""], ["Siskind", "Jeffrey Mark", ""]]}, {"id": "1203.1450", "submitter": "Barak Pearlmutter", "authors": "Alexey Radul and Barak A. Pearlmutter and Jeffrey Mark Siskind", "title": "AD in Fortran, Part 2: Implementation via Prepreprocessor", "comments": null, "journal-ref": "Recent Advances in Algorithmic Differentiation, Springer Lecture\n  Notes in Computational Science and Engineering volume 87, 2012, ISBN\n  978-3-642-30022-6, pages 273-284", "doi": "10.1007/978-3-642-30023-3_25", "report-no": null, "categories": "cs.PL cs.MS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe an implementation of the Farfel Fortran AD extensions. These\nextensions integrate forward and reverse AD directly into the programming\nmodel, with attendant benefits to flexibility, modularity, and ease of use. The\nimplementation we describe is a \"prepreprocessor\" that generates input to\nexisting Fortran-based AD tools. In essence, blocks of code which are targeted\nfor AD by Farfel constructs are put into subprograms which capture their\nlexical variable context, and these are closure-converted into top-level\nsubprograms and specialized to eliminate EXTERNAL arguments, rendering them\namenable to existing AD preprocessors, which are then invoked, possibly\nrepeatedly if the AD is nested.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2012 12:16:30 GMT"}, {"version": "v2", "created": "Thu, 8 Mar 2012 09:56:48 GMT"}], "update_date": "2016-02-09", "authors_parsed": [["Radul", "Alexey", ""], ["Pearlmutter", "Barak A.", ""], ["Siskind", "Jeffrey Mark", ""]]}, {"id": "1203.1539", "submitter": "Andrej Bauer", "authors": "Andrej Bauer, Matija Pretnar", "title": "Programming with Algebraic Effects and Handlers", "comments": null, "journal-ref": "Journal of Logical and Algebraic Methods in Programming. Volume\n  84, Issue 1, January 2015, Pages 108-123", "doi": "10.1016/j.jlamp.2014.02.001", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Eff is a programming language based on the algebraic approach to\ncomputational effects, in which effects are viewed as algebraic operations and\neffect handlers as homomorphisms from free algebras. Eff supports first-class\neffects and handlers through which we may easily define new computational\neffects, seamlessly combine existing ones, and handle them in novel ways. We\ngive a denotational semantics of eff and discuss a prototype implementation\nbased on it. Through examples we demonstrate how the standard effects are\ntreated in eff, and how eff supports programming techniques that use various\nforms of delimited continuations, such as backtracking, breadth-first search,\nselection functionals, cooperative multi-threading, and others.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2012 17:05:09 GMT"}], "update_date": "2015-07-17", "authors_parsed": [["Bauer", "Andrej", ""], ["Pretnar", "Matija", ""]]}, {"id": "1203.1986", "submitter": "Neal Glew", "authors": "Neal Glew and Leaf Petersen", "title": "Type-Preserving Flow Analysis and Interprocedural Unboxing (Extended\n  Version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interprocedural flow analysis can be used to eliminate otherwise unnecessary\nheap allocated objects (unboxing), and in previous work we have shown how to do\nso while maintaining correctness with respect to the garbage collector. In this\npaper, we extend the notion of flow analysis to incorporate types, enabling\nanalysis and optimization of typed programs. We apply this typed analysis to\nspecify a type preserving interprocedural unboxing optimization, and prove that\nthe optimization preserves both type and GC safety along with program\nsemantics. We also show that the unboxing optimization can be applied\nindependently to separately compiled program modules, and prove via a\ncontextual equivalence result that unboxing a module in isolation preserves\nprogram semantics.\n", "versions": [{"version": "v1", "created": "Fri, 9 Mar 2012 04:19:19 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Glew", "Neal", ""], ["Petersen", "Leaf", ""]]}, {"id": "1203.2296", "submitter": "M. H. van Emden", "authors": "M.H. van Emden", "title": "Discovering Algorithms with Matrix Code", "comments": "8 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": "DCS-345-IR", "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In first-year programming courses it is often difficult to show students how\nan algorithm can be discovered. In this paper we present a program format that\nsupports the development from specification to code in small and obvious steps;\nthat is, a discovery process. The format, called Matrix Code, can be\ninterpreted as a proof according to the Floyd-Hoare program verification\nmethod. The process consists of expressing the specification of a function body\nas an initial code matrix and then growing the matrix by adding rows and\ncolumns until the completed matrix is translated in a routine fashion to\ncompilable code. As worked example we develop a Java program that generates the\ntable of the first N prime numbers.\n", "versions": [{"version": "v1", "created": "Sun, 11 Mar 2012 00:12:56 GMT"}, {"version": "v2", "created": "Tue, 8 May 2012 16:04:16 GMT"}], "update_date": "2012-05-09", "authors_parsed": [["van Emden", "M. H.", ""]]}, {"id": "1203.2431", "submitter": "Adri\\'an Riesco", "authors": "Adri\\'an Riesco and Juan Rodr\\'iguez-Hortal\\'a", "title": "Singular and Plural Functions for Functional Logic Programming", "comments": "53 pages, 5 figures", "journal-ref": "Theory and Practice of Logic Programming 14 (2014) 65-116", "doi": "10.1017/S147106841200004X", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Functional logic programming (FLP) languages use non-terminating and\nnon-confluent constructor systems (CS's) as programs in order to define\nnon-strict non-determi-nistic functions. Two semantic alternatives have been\nusually considered for parameter passing with this kind of functions: call-time\nchoice and run-time choice. While the former is the standard choice of modern\nFLP languages, the latter lacks some properties---mainly\ncompositionality---that have prevented its use in practical FLP systems.\nTraditionally it has been considered that call-time choice induces a singular\ndenotational semantics, while run-time choice induces a plural semantics. We\nhave discovered that this latter identification is wrong when pattern matching\nis involved, and thus we propose two novel compositional plural semantics for\nCS's that are different from run-time choice.\n  We study the basic properties of our plural semantics---compositionality,\npolarity, monotonicity for substitutions, and a restricted form of the bubbling\nproperty for constructor systems---and the relation between them and to\nprevious proposals, concluding that these semantics form a hierarchy in the\nsense of set inclusion of the set of computed values. We have also identified a\nclass of programs characterized by a syntactic criterion for which the proposed\nplural semantics behave the same, and a program transformation that can be used\nto simulate one of them by term rewriting. At the practical level, we study how\nto use the expressive capabilities of these semantics for improving the\ndeclarative flavour of programs. We also propose a language which combines\ncall-time choice and our plural semantics, that we have implemented in Maude.\nThe resulting interpreter is employed to test several significant examples\nshowing the capabilities of the combined semantics.\n  To appear in Theory and Practice of Logic Programming (TPLP)\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2012 09:23:07 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Riesco", "Adri\u00e1n", ""], ["Rodr\u00edguez-Hortal\u00e1", "Juan", ""]]}, {"id": "1203.3724", "submitter": "Antoine Mine", "authors": "Antoine Min\\'e", "title": "Static Analysis of Run-Time Errors in Embedded Real-Time Parallel C\n  Programs", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 8, Issue 1 (March 26,\n  2012) lmcs:799", "doi": "10.2168/LMCS-8(1:26)2012", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  We present a static analysis by Abstract Interpretation to check for run-time\nerrors in parallel and multi-threaded C programs. Following our work on\nAstr\\'ee, we focus on embedded critical programs without recursion nor dynamic\nmemory allocation, but extend the analysis to a static set of threads\ncommunicating implicitly through a shared memory and explicitly using a finite\nset of mutual exclusion locks, and scheduled according to a real-time\nscheduling policy and fixed priorities. Our method is thread-modular. It is\nbased on a slightly modified non-parallel analysis that, when analyzing a\nthread, applies and enriches an abstract set of thread interferences. An\niterator then re-analyzes each thread in turn until interferences stabilize. We\nprove the soundness of our method with respect to the sequential consistency\nsemantics, but also with respect to a reasonable weakly consistent memory\nsemantics. We also show how to take into account mutual exclusion and thread\npriorities through a partitioning over an abstraction of the scheduler state.\nWe present preliminary experimental results analyzing an industrial program\nwith our prototype, Th\\'es\\'ee, and demonstrate the scalability of our\napproach.\n", "versions": [{"version": "v1", "created": "Fri, 16 Mar 2012 14:55:20 GMT"}, {"version": "v2", "created": "Thu, 22 Mar 2012 20:05:00 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Min\u00e9", "Antoine", ""]]}, {"id": "1203.4499", "submitter": "Tom Schrijvers", "authors": "Bruno C. d. S. Oliveira, Tom Schrijvers, Wontae Choi, Wonchan Lee,\n  Kwangkeun Yi", "title": "Extended Report: The Implicit Calculus", "comments": "13 pages, extended report of paper accepted at PLDI 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generic programming (GP) is an increasingly important trend in programming\nlanguages. Well-known GP mechanisms, such as type classes and the C++0x\nconcepts proposal, usually combine two features: 1) a special type of\ninterfaces; and 2) implicit instantiation of implementations of those\ninterfaces.\n  Scala implicits are a GP language mechanism, inspired by type classes, that\nbreak with the tradition of coupling implicit instantiation with a special type\nof interface. Instead, implicits provide only implicit instantiation, which is\ngeneralized to work for any types. This turns out to be quite powerful and\nuseful to address many limitations that show up in other GP mechanisms.\n  This paper synthesizes the key ideas of implicits formally in a minimal and\ngeneral core calculus called the implicit calculus, and it shows how to build\nsource languages supporting implicit instantiation on top of it. A novelty of\nthe calculus is its support for partial resolution and higher-order rules (a\nfeature that has been proposed before, but was never formalized or\nimplemented). Ultimately, the implicit calculus provides a formal model of\nimplicits, which can be used by language designers to study and inform\nimplementations of similar mechanisms in their own languages.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2012 16:44:27 GMT"}], "update_date": "2012-03-21", "authors_parsed": [["Oliveira", "Bruno C. d. S.", ""], ["Schrijvers", "Tom", ""], ["Choi", "Wontae", ""], ["Lee", "Wonchan", ""], ["Yi", "Kwangkeun", ""]]}, {"id": "1203.4716", "submitter": "Andreas Abel", "authors": "Andreas Abel (Department of Computer Science,\n  Ludwig-Maximilians-University Munich), Gabriel Scherer (Department of\n  Computer Science, Ludwig-Maximilians-University Munich)", "title": "On Irrelevance and Algorithmic Equality in Predicative Type Theory", "comments": "36 pages, superseds the FoSSaCS 2011 paper of the first author,\n  titled \"Irrelevance in Type Theory with a Heterogeneous Equality Judgement\"", "journal-ref": "Logical Methods in Computer Science, Volume 8, Issue 1 (March 27,\n  2012) lmcs:1045", "doi": "10.2168/LMCS-8(1:29)2012", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dependently typed programs contain an excessive amount of static terms which\nare necessary to please the type checker but irrelevant for computation. To\nseparate static and dynamic code, several static analyses and type systems have\nbeen put forward. We consider Pfenning's type theory with irrelevant\nquantification which is compatible with a type-based notion of equality that\nrespects eta-laws. We extend Pfenning's theory to universes and large\neliminations and develop its meta-theory. Subject reduction, normalization and\nconsistency are obtained by a Kripke model over the typed equality judgement.\nFinally, a type-directed equality algorithm is described whose completeness is\nproven by a second Kripke model.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2012 11:53:19 GMT"}, {"version": "v2", "created": "Fri, 23 Mar 2012 20:51:52 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Abel", "Andreas", "", "Department of Computer Science,\n  Ludwig-Maximilians-University Munich"], ["Scherer", "Gabriel", "", "Department of\n  Computer Science, Ludwig-Maximilians-University Munich"]]}, {"id": "1203.5303", "submitter": "Florian Zuleger", "authors": "Florian Zuleger and Sumit Gulwani and Moritz Sinn and Helmut Veith", "title": "Bound Analysis of Imperative Programs with the Size-change Abstraction\n  (extended version)", "comments": "Extended version of SAS 2011 conference article", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The size-change abstraction (SCA) is an important program abstraction for\ntermination analysis, which has been successfully implemented in many tools for\nfunctional and logic programs. In this paper, we demonstrate that SCA is also a\nhighly effective abstract domain for the bound analysis of imperative programs.\n  We have implemented a bound analysis tool based on SCA for imperative\nprograms. We abstract programs in a pathwise and context dependent manner,\nwhich enables our tool to analyze real-world programs effectively. Our work\nshows that SCA captures many of the essential ideas of previous termination and\nbound analysis and goes beyond in a conceptually simpler framework.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2012 17:22:06 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Zuleger", "Florian", ""], ["Gulwani", "Sumit", ""], ["Sinn", "Moritz", ""], ["Veith", "Helmut", ""]]}, {"id": "1203.5423", "submitter": "EPTCS", "authors": "Simona Ronchi della Rocca (UNITO), Elaine Pimentel (UFMG)", "title": "Proceedings 6th Workshop on Logical and Semantic Frameworks with\n  Applications", "comments": null, "journal-ref": "EPTCS 81, 2012", "doi": "10.4204/EPTCS.81", "report-no": null, "categories": "cs.LO cs.CC cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the proceedings of the Sixth Workshop on Logical and\nSemantic Frameworks with Applications (LSFA 2011). The workshop will be hold in\nBelo Horizonte, on August 27th 2011.\n  Logical and semantic frameworks are formal languages used to represent\nlogics, languages and systems. These frameworks provide foundations for formal\nspecification of systems and programming languages, supporting tool development\nand reasoning.\n  The objective of this one-day workshop is to put together theoreticians and\npractitioners to promote new techniques and results, from the theoretical side,\nand feedback on the implementation and the use of such techniques and results,\nfrom the practical side.\n", "versions": [{"version": "v1", "created": "Sat, 24 Mar 2012 15:27:21 GMT"}], "update_date": "2012-03-27", "authors_parsed": [["della Rocca", "Simona Ronchi", "", "UNITO"], ["Pimentel", "Elaine", "", "UFMG"]]}, {"id": "1203.6102", "submitter": "Zhiqiang Ren", "authors": "Zhiqiang Ren, Hongwei Xi", "title": "A Programmer-Centric Approach to Program Verification in ATS", "comments": "15 pages, 11 figures. Examples available on-line\n  http://www.ats-lang.org/EXAMPLE/PCPV", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Formal specification is widely employed in the construction of high-quality\nsoftware. However, there is often a huge gap between formal specification and\nactual implementation. While there is already a vast body of work on software\ntesting and verification, the task to ensure that an implementation indeed\nmeets its specification is still undeniably of great difficulty. ATS is a\nprogramming language equipped with a highly expressive type system that allows\nthe programmer to specify and implement and then verify within the language\nitself that an implementation meets its specification. In this paper, we\npresent largely through examples a programmer-centric style of program\nverification that puts emphasis on requesting the programmer to explain in a\nliterate fashion why his or her code works. This is a solid step in the pursuit\nof software construction that is verifiably correct according to specification.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2012 22:49:34 GMT"}], "update_date": "2012-03-29", "authors_parsed": [["Ren", "Zhiqiang", ""], ["Xi", "Hongwei", ""]]}, {"id": "1203.6158", "submitter": "EPTCS", "authors": "Favio Ezequiel Miranda-Perea (Facultad de Ciencias UNAM), Lourdes del\n  Carmen Gonz\\'alez-Huesca (Facultad de Ciencias UNAM)", "title": "Mendler-style Iso-(Co)inductive predicates: a strongly normalizing\n  approach", "comments": "In Proceedings LSFA 2011, arXiv:1203.5423", "journal-ref": "EPTCS 81, 2012, pp. 30-46", "doi": "10.4204/EPTCS.81.3", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an extension of the second-order logic AF2 with iso-style\ninductive and coinductive definitions specifically designed to extract programs\nfrom proofs a la Krivine-Parigot by means of primitive (co)recursion\nprinciples. Our logic includes primitive constructors of least and greatest\nfixed points of predicate transformers, but contrary to the common approach, we\ndo not restrict ourselves to positive operators to ensure monotonicity, instead\nwe use the Mendler-style, motivated here by the concept of monotonization of an\narbitrary operator on a complete lattice. We prove an adequacy theorem with\nrespect to a realizability semantics based on saturated sets and\nsaturated-valued functions and as a consequence we obtain the strong\nnormalization property for the proof-term reduction, an important feature which\nis absent in previous related work.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2012 05:06:14 GMT"}], "update_date": "2012-03-29", "authors_parsed": [["Miranda-Perea", "Favio Ezequiel", "", "Facultad de Ciencias UNAM"], ["Gonz\u00e1lez-Huesca", "Lourdes del Carmen", "", "Facultad de Ciencias UNAM"]]}, {"id": "1203.6459", "submitter": "Damien Cassou", "authors": "Damien Cassou (INRIA Bordeaux - Sud-Ouest), Julien Bruneau (INRIA\n  Bordeaux - Sud-Ouest), Charles Consel (INRIA Bordeaux - Sud-Ouest), Emilie\n  Balland (INRIA Bordeaux - Sud-Ouest)", "title": "Towards a Tool-based Development Methodology for Pervasive Computing\n  Applications", "comments": null, "journal-ref": "IEEE TSE: Transactions on Software Engineering (2011)", "doi": "10.1109/TSE.2011.107", "report-no": null, "categories": "cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite much progress, developing a pervasive computing application remains a\nchallenge because of a lack of conceptual frameworks and supporting tools. This\nchallenge involves coping with heterogeneous devices, overcoming the\nintricacies of distributed systems technologies, working out an architecture\nfor the application, encoding it in a program, writing specific code to test\nthe application, and finally deploying it. This paper presents a design\nlanguage and a tool suite covering the development life-cycle of a pervasive\ncomputing application. The design language allows to define a taxonomy of\narea-specific building-blocks, abstracting over their heterogeneity. This\nlanguage also includes a layer to define the architecture of an application,\nfollowing an architectural pattern commonly used in the pervasive computing\ndomain. Our underlying methodology assigns roles to the stakeholders, providing\nseparation of concerns. Our tool suite includes a compiler that takes design\nartifacts written in our language as input and generates a programming\nframework that supports the subsequent development stages, namely\nimplementation, testing, and deployment. Our methodology has been applied on a\nwide spectrum of areas. Based on these experiments, we assess our approach\nthrough three criteria: expressiveness, usability, and productivity.\n", "versions": [{"version": "v1", "created": "Thu, 29 Mar 2012 07:49:42 GMT"}], "update_date": "2012-03-30", "authors_parsed": [["Cassou", "Damien", "", "INRIA Bordeaux - Sud-Ouest"], ["Bruneau", "Julien", "", "INRIA\n  Bordeaux - Sud-Ouest"], ["Consel", "Charles", "", "INRIA Bordeaux - Sud-Ouest"], ["Balland", "Emilie", "", "INRIA Bordeaux - Sud-Ouest"]]}, {"id": "1203.6859", "submitter": "Matthew J. Parkinson", "authors": "Matthew J. Parkinson (Microsoft Research), Alexander J. Summers (ETH\n  Zurich)", "title": "The Relationship Between Separation Logic and Implicit Dynamic Frames", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 8, Issue 3 (July 31,\n  2012) lmcs:802", "doi": "10.2168/LMCS-8(3:1)2012", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Separation logic is a concise method for specifying programs that manipulate\ndynamically allocated storage. Partially inspired by separation logic, Implicit\nDynamic Frames has recently been proposed, aiming at first-order tool support.\nIn this paper, we precisely connect the semantics of these two logics. We\ndefine a logic whose syntax subsumes both that of a standard separation logic,\nand that of implicit dynamic frames as sub-syntaxes. We define a total heap\nsemantics for our logic, and, for the separation logic subsyntax, prove it\nequivalent the standard partial heaps model. In order to define a semantics\nwhich works uniformly for both subsyntaxes, we define the novel concept of a\nminimal state extension, which provides a different (but equivalent) definition\nof the semantics of separation logic implication and magic wand connectives,\nwhile also giving a suitable semantics for these connectives in implicit\ndynamic frames. We show that our resulting semantics agrees with the existing\ndefinition of weakest pre-condition semantics for the implicit dynamic frames\nfragment. Finally, we show that we can encode the separation logic fragment of\nour logic into the implicit dynamic frames fragment, preserving semantics. For\nthe connectives typically supported by tools, this shows that separation logic\ncan be faithfully encoded in a first-order automatic verification tool\n(Chalice).\n", "versions": [{"version": "v1", "created": "Fri, 30 Mar 2012 17:01:11 GMT"}, {"version": "v2", "created": "Mon, 2 Apr 2012 07:35:48 GMT"}, {"version": "v3", "created": "Sun, 29 Jul 2012 23:07:10 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Parkinson", "Matthew J.", "", "Microsoft Research"], ["Summers", "Alexander J.", "", "ETH\n  Zurich"]]}]