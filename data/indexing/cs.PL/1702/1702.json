[{"id": "1702.00364", "submitter": "Samir Genaim", "authors": "Jes\\'us Dom\\'enech, Samir Genaim, Einar Broch Johnsen, Rudolf Schlatte", "title": "EasyInterface: A toolkit for rapid development of GUIs for research\n  prototype tools", "comments": "Preprint of a FASE'17 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we describe EasyInterface, an open-source toolkit for rapid\ndevelopment of web-based graphical user interfaces (GUIs). This toolkit\naddresses the need of researchers to make their research prototype tools\navailable to the community, and integrating them in a common environment,\nrapidly and without being familiar with web programming or GUI libraries in\ngeneral. If a tool can be executed from a command-line and its output goes to\nthe standard output, then in few minutes one can make it accessible via a\nweb-interface or within Eclipse. Moreover, the toolkit defines a text-based\nlanguage that can be used to get more sophisticated GUIs, e.g., syntax\nhighlighting, dialog boxes, user interactions, etc. EasyInterface was\noriginally developed for building a common frontend for tools developed in the\nEnvisage project.\n", "versions": [{"version": "v1", "created": "Wed, 1 Feb 2017 17:20:31 GMT"}], "update_date": "2017-02-02", "authors_parsed": [["Dom\u00e9nech", "Jes\u00fas", ""], ["Genaim", "Samir", ""], ["Johnsen", "Einar Broch", ""], ["Schlatte", "Rudolf", ""]]}, {"id": "1702.00374", "submitter": "Justin Hsu", "authors": "Arthur Azevedo de Amorim, Marco Gaboardi, Justin Hsu, Shin-ya\n  Katsumata, Ikram Cherigui", "title": "A Semantic Account of Metric Preservation", "comments": null, "journal-ref": null, "doi": "10.1145/3009837.3009890", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Program sensitivity measures how robust a program is to small changes in its\ninput, and is a fundamental notion in domains ranging from differential privacy\nto cyber-physical systems. A natural way to formalize program sensitivity is in\nterms of metrics on the input and output spaces, requiring that an\n$r$-sensitive function map inputs that are at distance $d$ to outputs that are\nat distance at most $r \\cdot d$. Program sensitivity is thus an analogue of\nLipschitz continuity for programs.\n  Reed and Pierce introduced Fuzz, a functional language with a linear type\nsystem that can express program sensitivity. They show soundness operationally,\nin the form of a metric preservation property. Inspired by their work, we study\nprogram sensitivity and metric preservation from a denotational point of view.\nIn particular, we introduce metric CPOs, a novel semantic structure for\nreasoning about computation on metric spaces, by endowing CPOs with a\ncompatible notion of distance. This structure is useful for reasoning about\nmetric properties of programs, and specifically about program sensitivity. We\ndemonstrate metric CPOs by giving a model for the deterministic fragment of\nFuzz.\n", "versions": [{"version": "v1", "created": "Wed, 1 Feb 2017 17:50:42 GMT"}, {"version": "v2", "created": "Tue, 11 Jul 2017 16:29:58 GMT"}], "update_date": "2018-03-16", "authors_parsed": [["de Amorim", "Arthur Azevedo", ""], ["Gaboardi", "Marco", ""], ["Hsu", "Justin", ""], ["Katsumata", "Shin-ya", ""], ["Cherigui", "Ikram", ""]]}, {"id": "1702.00562", "submitter": "Amey Karkare", "authors": "Amey Karkare, Nimisha Agarwal", "title": "ParseIT: A Question-Answer based Tool to Learn Parsing Techniques", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parsing (also called syntax analysis) techniques cover a substantial portion\nof any undergraduate Compiler Design course. We present ParseIT, a tool to help\nstudents understand the parsing techniques through question-answering. ParseIT\nautomates the generation of tutorial questions based on the Context Free\nGrammar provided by the student and generates feedback for the student\nsolutions. The tool generates multiple-choice questions (MCQs) and fill in the\nblank type questions, and evaluates students' attempts. It provides hints for\nincorrect attempts, again in terms of MCQs. The hints questions are generated\nfor any correct choice that is missed or any incorrect choice that is selected.\nAnother interesting form of hint generated is an input string that helps the\nstudents identify incorrectly filled cells of a parsing table. We also present\nresults of a user study conducted to measure the effectiveness of ParseIT.\n", "versions": [{"version": "v1", "created": "Thu, 2 Feb 2017 07:37:35 GMT"}], "update_date": "2017-02-03", "authors_parsed": [["Karkare", "Amey", ""], ["Agarwal", "Nimisha", ""]]}, {"id": "1702.01168", "submitter": "Navid Yaghmazadeh", "authors": "Navid Yaghmazadeh, Yuepeng Wang, Isil Dillig, Thomas Dillig", "title": "Type- and Content-Driven Synthesis of SQL Queries from Natural Language", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new technique for automatically synthesizing SQL\nqueries from natural language. Our technique is fully automated, works for any\ndatabase without requiring additional customization, and does not require users\nto know the underlying database schema. Our method achieves these goals by\ncombining natural language processing, program synthesis, and automated program\nrepair. Given the user's English description, our technique first uses semantic\nparsing to generate a query sketch, which is subsequently completed using\ntype-directed program synthesis and assigned a confidence score using database\ncontents. However, since the user's description may not accurately reflect the\nactual database schema, our approach also performs fault localization and\nrepairs the erroneous part of the sketch. This synthesize-repair loop is\nrepeated until the algorithm infers a query with a sufficiently high confidence\nscore. We have implemented the proposed technique in a tool called Sqlizer and\nevaluate it on three different databases. Our experiments show that the desired\nquery is ranked within the top 5 candidates in close to 90% of the cases.\n", "versions": [{"version": "v1", "created": "Fri, 3 Feb 2017 21:26:43 GMT"}], "update_date": "2017-02-07", "authors_parsed": [["Yaghmazadeh", "Navid", ""], ["Wang", "Yuepeng", ""], ["Dillig", "Isil", ""], ["Dillig", "Thomas", ""]]}, {"id": "1702.01655", "submitter": "Tuan Phong Ngo", "authors": "Parosh Aziz Abdulla, Mohamed Faouzi Atig, Ahmed Bouajjani, Tuan Phong\n  Ngo", "title": "Context-Bounded Model Checking for POWER", "comments": "A preliminary version of this article will appear at TACAS'17", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an under-approximate reachability analysis algorithm for programs\nrunning under the POWER memory model, in the spirit of the work on\ncontext-bounded analysis intitiated by Qadeer et al. in 2005 for detecting bugs\nin concurrent programs (supposed to be running under the classical SC model).\n  To that end, we first introduce a new notion of context-bounding that is\nsuitable for reasoning about computations under POWER, which generalizes the\none defined by Atig et al. in 2011 for the TSO memory model. Then, we provide a\npolynomial size reduction of the context-bounded state reachability problem\nunder POWER to the same problem under SC: Given an input concurrent program P,\nour method produces a concurrent program P' such that, for a fixed number of\ncontext switches, running P' under SC yields the same set of reachable states\nas running P under POWER. The generated program P' contains the same number of\nprocesses as P, and operates on the same data domain. By leveraging the\nstandard model checker CBMC, we have implemented a prototype tool and applied\nit on a set of benchmarks, showing the feasibility of our approach.\n", "versions": [{"version": "v1", "created": "Fri, 3 Feb 2017 15:02:13 GMT"}, {"version": "v2", "created": "Thu, 9 Feb 2017 13:29:31 GMT"}, {"version": "v3", "created": "Mon, 14 May 2018 11:44:06 GMT"}, {"version": "v4", "created": "Sat, 1 Dec 2018 08:10:05 GMT"}, {"version": "v5", "created": "Fri, 11 Jan 2019 15:50:01 GMT"}, {"version": "v6", "created": "Sat, 31 Aug 2019 22:12:38 GMT"}, {"version": "v7", "created": "Tue, 24 Sep 2019 03:04:46 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Abdulla", "Parosh Aziz", ""], ["Atig", "Mohamed Faouzi", ""], ["Bouajjani", "Ahmed", ""], ["Ngo", "Tuan Phong", ""]]}, {"id": "1702.01695", "submitter": "EPTCS", "authors": "Dan R Ghica (University of Birmingham), Aliaume Lopez (ENS Cachan)", "title": "A Structural and Nominal Syntax for Diagrams", "comments": "In Proceedings QPL 2017, arXiv:1802.09737", "journal-ref": "EPTCS 266, 2018, pp. 71-83", "doi": "10.4204/EPTCS.266.4", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The correspondence between monoidal categories and graphical languages of\ndiagrams has been studied extensively, leading to applications in quantum\ncomputing and communication, systems theory, circuit design and more. From the\ncategorical perspective, diagrams can be specified using (name-free)\ncombinators which enjoy elegant equational properties. However, conventional\nnotations for diagrammatic structures, such as hardware description languages\n(VHDL, Verilog) or graph languages (Dot), use a different style, which is flat,\nrelational, and reliant on extensive use of names (labels). Such languages are\nnot known to enjoy nice syntactic equational properties. However, since they\nmake it relatively easy to specify (and modify) arbitrary diagrammatic\nstructures they are more popular than the combinator style. In this paper we\nshow how the two approaches to diagram syntax can be reconciled and unified in\na way that does not change the semantics and the existing equational theory.\nAdditionally, we give sound and complete equational theories for the combined\nsyntax.\n", "versions": [{"version": "v1", "created": "Mon, 6 Feb 2017 16:40:00 GMT"}, {"version": "v2", "created": "Fri, 2 Mar 2018 03:45:32 GMT"}], "update_date": "2018-03-05", "authors_parsed": [["Ghica", "Dan R", "", "University of Birmingham"], ["Lopez", "Aliaume", "", "ENS Cachan"]]}, {"id": "1702.01872", "submitter": "Jeremy Yallop", "authors": "Jeremy Yallop (University of Cambridge) and Damien Doligez (INRIA)", "title": "Proceedings ML Family / OCaml Users and Developers workshops", "comments": null, "journal-ref": "EPTCS 241, 2017", "doi": "10.4204/EPTCS.241", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the joint post-proceedings of the 2015 edition of the ML\nFamily Workshop and OCaml Users and Developers Workshop, held in Vancouver,\nBritish Columbia, Canada, in affiliation with ICFP 2015.\n", "versions": [{"version": "v1", "created": "Tue, 7 Feb 2017 03:55:07 GMT"}], "update_date": "2017-02-08", "authors_parsed": [["Yallop", "Jeremy", "", "University of Cambridge"], ["Doligez", "Damien", "", "INRIA"]]}, {"id": "1702.01874", "submitter": "EPTCS", "authors": "Naoki Kobayashi", "title": "Proceedings Eighth Workshop on Intersection Types and Related Systems", "comments": null, "journal-ref": "EPTCS 242, 2017", "doi": "10.4204/EPTCS.242", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains a final and revised selection of papers presented at the\nEighth Workshop on Intersection Types and Related Systems (ITRS 2016), held on\nJune 26, 2016 in Porto, in affiliation with FSCD 2016.\n", "versions": [{"version": "v1", "created": "Tue, 7 Feb 2017 04:21:28 GMT"}, {"version": "v2", "created": "Thu, 30 Mar 2017 06:10:25 GMT"}], "update_date": "2017-03-31", "authors_parsed": [["Kobayashi", "Naoki", ""]]}, {"id": "1702.02272", "submitter": "EPTCS", "authors": "Co\\c{s}ku Acay (Carnegie Mellon University), Frank Pfenning (Carnegie\n  Mellon University)", "title": "Intersections and Unions of Session Types", "comments": "In Proceedings ITRS 2016, arXiv:1702.01874", "journal-ref": "EPTCS 242, 2017, pp. 4-19", "doi": "10.4204/EPTCS.242.3", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prior work has extended the deep, logical connection between the linear\nsequent calculus and session-typed message-passing concurrent computation with\nequi-recursive types and a natural notion of subtyping. In this paper, we\nextend this further by intersection and union types in order to express\nmultiple behavioral properties of processes in a single type. We prove session\nfidelity and absence of deadlock and illustrate the expressive power of our\nsystem with some simple examples. We observe that we can represent internal and\nexternal choice by intersection and union, respectively, which was previously\nsuggested by Padovani for a different language of session types motivated by\noperational rather than logical concerns.\n", "versions": [{"version": "v1", "created": "Wed, 8 Feb 2017 04:19:35 GMT"}], "update_date": "2017-02-09", "authors_parsed": [["Acay", "Co\u015fku", "", "Carnegie Mellon University"], ["Pfenning", "Frank", "", "Carnegie\n  Mellon University"]]}, {"id": "1702.02280", "submitter": "EPTCS", "authors": "Oleg Kiselyov (Tohoku University, Japan)", "title": "Generating Code with Polymorphic let: A Ballad of Value Restriction,\n  Copying and Sharing", "comments": "In Proceedings ML/OCaml 2015, arXiv:1702.01872", "journal-ref": "EPTCS 241, 2017, pp. 1-22", "doi": "10.4204/EPTCS.241.1", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Getting polymorphism and effects such as mutation to live together in the\nsame language is a tale worth telling, under the recurring refrain of copying\nvs. sharing. We add new stanzas to the tale, about the ordeal to generate code\nwith polymorphism and effects, and be sure it type-checks. Generating\nwell-typed-by-construction polymorphic let-expressions is impossible in the\nHindley-Milner type system: even the author believed that.\n  The polymorphic-let generator turns out to exist. We present its derivation\nand the application for the lightweight implementation of quotation via a novel\nand unexpectedly simple source-to-source transformation to code-generating\ncombinators.\n  However, generating let-expressions with polymorphic functions demands more\nthan even the relaxed value restriction can deliver. We need a new deal for\nlet-polymorphism in ML. We conjecture the weaker restriction and implement it\nin a practically-useful code-generation library. Its formal justification is\nformulated as the research program.\n", "versions": [{"version": "v1", "created": "Wed, 8 Feb 2017 04:29:19 GMT"}], "update_date": "2017-02-09", "authors_parsed": [["Kiselyov", "Oleg", "", "Tohoku University, Japan"]]}, {"id": "1702.02281", "submitter": "EPTCS", "authors": "Jacques Garrigue (Nagoya University Graduate School of Mathematics),\n  Jacques Le Normand", "title": "GADTs and Exhaustiveness: Looking for the Impossible", "comments": "In Proceedings ML/OCaml 2015, arXiv:1702.01872", "journal-ref": "EPTCS 241, 2017, pp. 23-35", "doi": "10.4204/EPTCS.241.2", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sound exhaustiveness checking of pattern-matching is an essential feature of\nfunctional programming languages, and OCaml supports it for GADTs. However this\ncheck is incomplete, in that it may fail to detect that a pattern can match no\nconcrete value. In this paper we show that this problem is actually\nundecidable, but that we can strengthen the exhaustiveness and redundancy\nchecks so that they cover more practical cases. The new algorithm relies on a\nclever modification of type inference for patterns.\n", "versions": [{"version": "v1", "created": "Wed, 8 Feb 2017 04:29:39 GMT"}], "update_date": "2017-02-09", "authors_parsed": [["Garrigue", "Jacques", "", "Nagoya University Graduate School of Mathematics"], ["Normand", "Jacques Le", ""]]}, {"id": "1702.02282", "submitter": "EPTCS", "authors": "William Blair (Boston University), Hongwei Xi (Boston University)", "title": "Dependent Types for Multi-Rate Flows in Synchronous Programming", "comments": "In Proceedings ML/OCaml 2015, arXiv:1702.01872", "journal-ref": "EPTCS 241, 2017, pp. 36-44", "doi": "10.4204/EPTCS.241.3", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Synchronous programming languages emerged in the 1980s as tools for\nimplementing reactive systems, which interact with events from physical\nenvironments and often must do so under strict timing constraints. In this\nreport, we encode inside ATS various real-time primitives in an experimental\nsynchronous language called Prelude, where ATS is a statically typed language\nwith an ML-like functional core that supports both dependent types (of\nDML-style) and linear types. We show that the verification requirements imposed\non these primitives can be formally expressed in terms of dependent types in\nATS. Moreover, we modify the Prelude compiler to automatically generate ATS\ncode from Prelude source. This modified compiler allows us to solely rely on\ntypechecking in ATS to discharge proof obligations originating from the need to\ntypecheck Prelude code. Whereas ATS is typically used as a general purpose\nprogramming language, we hereby demonstrate that it can also be conveniently\nused to support some forms of advanced static checking in languages equipped\nwith less expressive types.\n", "versions": [{"version": "v1", "created": "Wed, 8 Feb 2017 04:29:53 GMT"}], "update_date": "2017-02-09", "authors_parsed": [["Blair", "William", "", "Boston University"], ["Xi", "Hongwei", "", "Boston University"]]}, {"id": "1702.02283", "submitter": "EPTCS", "authors": "Ryohei Tokuda (Graduate School of Information Sciences, Tohoku\n  University, Sendai, Japan), Eijiro Sumii (Graduate School of Information\n  Sciences, Tohoku University, Sendai, Japan), Akinori Abe (Graduate School of\n  Information Sciences, Tohoku University, Sendai, Japan)", "title": "Specialization of Generic Array Accesses After Inlining", "comments": "In Proceedings ML/OCaml 2015, arXiv:1702.01872", "journal-ref": "EPTCS 241, 2017, pp. 45-53", "doi": "10.4204/EPTCS.241.4", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We have implemented an optimization that specializes type-generic array\naccesses after inlining of polymorphic functions in the native-code OCaml\ncompiler. Polymorphic array operations (read and write) in OCaml require\nruntime type dispatch because of ad hoc memory representations of integer and\nfloat arrays. It cannot be removed even after being monomorphized by inlining\nbecause the intermediate language is mostly untyped. We therefore extended it\nwith explicit type application like System F (while keeping implicit type\nabstraction by means of unique identifiers for type variables). Our\noptimization has achieved up to 21% speed-up of numerical programs.\n", "versions": [{"version": "v1", "created": "Wed, 8 Feb 2017 04:30:07 GMT"}], "update_date": "2017-02-09", "authors_parsed": [["Tokuda", "Ryohei", "", "Graduate School of Information Sciences, Tohoku\n  University, Sendai, Japan"], ["Sumii", "Eijiro", "", "Graduate School of Information\n  Sciences, Tohoku University, Sendai, Japan"], ["Abe", "Akinori", "", "Graduate School of\n  Information Sciences, Tohoku University, Sendai, Japan"]]}, {"id": "1702.02406", "submitter": "Isabella Mastroeni", "authors": "Vincenzo Arceri, Mila Dalla Preda, Roberto Giacobazzi, Isabella\n  Mastroeni", "title": "SEA: String Executability Analysis by Abstract Interpretation", "comments": "28 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic languages often employ reflection primitives to turn dynamically\ngenerated text into executable code at run-time. These features make standard\nstatic analysis extremely hard if not impossible because its essential data\nstructures, i.e., the control-flow graph and the system of recursive equations\nassociated with the program to analyse, are themselves dynamically mutating\nobjects. We introduce SEA, an abstract interpreter for automatic sound string\nexecutability analysis of dynamic languages employing bounded (i.e, finitely\nnested) reflection and dynamic code generation. Strings are statically\napproximated in an abstract domain of finite state automata with basic\noperations implemented as symbolic transducers. SEA combines standard program\nanalysis together with string executability analysis. The analysis of a call to\nreflection determines a call to the same abstract interpreter over a code which\nis synthesised directly from the result of the static string executability\nanalysis at that program point. The use of regular languages for approximating\ndynamically generated code structures allows SEA to soundly approximate safety\nproperties of self modifying programs yet maintaining efficiency. Soundness\nhere means that the semantics of the code synthesised by the analyser to\nresolve reflection over-approximates the semantics of the code dynamically\nbuilt at run-rime by the program at that point.\n", "versions": [{"version": "v1", "created": "Wed, 8 Feb 2017 12:48:54 GMT"}], "update_date": "2017-02-09", "authors_parsed": [["Arceri", "Vincenzo", ""], ["Preda", "Mila Dalla", ""], ["Giacobazzi", "Roberto", ""], ["Mastroeni", "Isabella", ""]]}, {"id": "1702.02705", "submitter": "Constantin Enea", "authors": "Ahmed Bouajjani, Michael Emmi, Constantin Enea, Suha Orhun Mutluergil", "title": "Proving linearizability using forward simulations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linearizability is the standard correctness criterion concurrent data\nstructures such as stacks and queues. It allows to establish observational\nrefinement between a concurrent implementation and an atomic reference\nimplementation.Proving linearizability requires identifying linearization\npoints for each method invocation along all possible computations, leading to\nvalid sequential executions, or alternatively, establishing forward and\nbackward simulations. In both cases, carrying out proofs is hard and complex in\ngeneral. In particular, backward reasoning is difficult in the context of\nprograms with data structures, and strategies for identifying statically\nlinearization points cannot be defined for all existing implementations. In\nthis paper, we show that, contrary to common belief, many such complex\nimplementations, including, e.g., the Herlihy&Wing Queue and the Time-Stamped\nStack, can be proved correct using only forward simulation arguments. This\nleads to conceptually simple and natural correctness proofs for these\nimplementations that are amenable to automation.\n", "versions": [{"version": "v1", "created": "Thu, 9 Feb 2017 04:47:05 GMT"}], "update_date": "2017-02-10", "authors_parsed": [["Bouajjani", "Ahmed", ""], ["Emmi", "Michael", ""], ["Enea", "Constantin", ""], ["Mutluergil", "Suha Orhun", ""]]}, {"id": "1702.02951", "submitter": "Sergi Blanco-Cuaresma", "authors": "Sergi Blanco-Cuaresma and Emeline Bolmont", "title": "What can the programming language Rust do for astrophysics?", "comments": "To appear in the proceedings of the IAU Symposium 325 on\n  Astroinformatics", "journal-ref": null, "doi": "10.1017/S1743921316013168", "report-no": null, "categories": "astro-ph.IM cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The astrophysics community uses different tools for computational tasks such\nas complex systems simulations, radiative transfer calculations or big data.\nProgramming languages like Fortran, C or C++ are commonly present in these\ntools and, generally, the language choice was made based on the need for\nperformance. However, this comes at a cost: safety. For instance, a common\nsource of error is the access to invalid memory regions, which produces random\nexecution behaviors and affects the scientific interpretation of the results.\n  In 2015, Mozilla Research released the first stable version of a new\nprogramming language named Rust. Many features make this new language\nattractive for the scientific community, it is open source and it guarantees\nmemory safety while offering zero-cost abstraction.\n  We explore the advantages and drawbacks of Rust for astrophysics by\nre-implementing the fundamental parts of Mercury-T, a Fortran code that\nsimulates the dynamical and tidal evolution of multi-planet systems.\n", "versions": [{"version": "v1", "created": "Thu, 9 Feb 2017 19:00:07 GMT"}], "update_date": "2017-06-14", "authors_parsed": [["Blanco-Cuaresma", "Sergi", ""], ["Bolmont", "Emeline", ""]]}, {"id": "1702.02972", "submitter": "Nikos Tzevelekos", "authors": "Lars Birkedal, Thomas Dinsdale-Young, Guilhem Jaber, Kasper Svendsen,\n  Nikos Tzevelekos", "title": "Trace Properties from Separation Logic Specifications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a formal approach for relating abstract separation logic library\nspecifications with the trace properties they enforce on interactions between a\nclient and a library. Separation logic with abstract predicates enforces a\nresource discipline that constrains when and how calls may be made between a\nclient and a library. Intuitively, this can enforce a protocol on the\ninteraction trace. This intuition is broadly used in the separation logic\ncommunity but has not previously been formalised. We provide just such a\nformalisation. Our approach is based on using wrappers which instrument library\ncode to induce execution traces for the properties under examination. By\nconsidering a separation logic extended with trace resources, we prove that\nwhen a library satisfies its separation logic specification then its wrapped\nversion satisfies the same specification and, moreover, maintains the trace\nproperties as an invariant. Consequently, any client and library implementation\nthat are correct with respect to the separation logic specification will\nsatisfy the trace properties.\n", "versions": [{"version": "v1", "created": "Thu, 9 Feb 2017 20:26:10 GMT"}], "update_date": "2017-02-13", "authors_parsed": [["Birkedal", "Lars", ""], ["Dinsdale-Young", "Thomas", ""], ["Jaber", "Guilhem", ""], ["Svendsen", "Kasper", ""], ["Tzevelekos", "Nikos", ""]]}, {"id": "1702.03085", "submitter": "Pierre Lescanne", "authors": "Pierre Lescanne (LIP)", "title": "Quantitative aspects of linear and affine closed lambda terms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.LO cs.PL math.CO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Affine $\\lambda$-terms are $\\lambda$-terms in which each bound variable\noccurs at most once and linear $\\lambda$-terms are $\\lambda$-terms in which\neach bound variables occurs once. and only once. In this paper we count the\nnumber of closed affine $\\lambda$-terms of size $n$, closed linear\n$\\lambda$-terms of size $n$, affine $\\beta$-normal forms of size $n$ and linear\n$\\beta$-normal forms of ise $n$, for different ways of measuring the size of\n$\\lambda$-terms. From these formulas, we show how we can derive programs for\ngenerating all the terms of size $n$ for each class. For this we use a specific\ndata structure, which are contexts taking into account all the holes at levels\nof abstractions.\n", "versions": [{"version": "v1", "created": "Fri, 10 Feb 2017 07:32:08 GMT"}, {"version": "v2", "created": "Thu, 16 Feb 2017 14:46:00 GMT"}, {"version": "v3", "created": "Mon, 27 Feb 2017 14:02:40 GMT"}, {"version": "v4", "created": "Mon, 3 Apr 2017 15:21:15 GMT"}, {"version": "v5", "created": "Tue, 23 May 2017 06:10:51 GMT"}], "update_date": "2017-05-24", "authors_parsed": [["Lescanne", "Pierre", "", "LIP"]]}, {"id": "1702.03363", "submitter": "Yuting Wang", "authors": "Yuting Wang", "title": "A Higher-Order Abstract Syntax Approach to the Verified Compilation of\n  Functional Programs", "comments": "PhD thesis, Dec 2016, University of Minnesota", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We argue that the implementation and verification of compilers for functional\nprogramming languages are greatly simplified by employing a higher-order\nrepresentation of syntax known as Higher-Order Abstract Syntax or HOAS. The\nunderlying idea of HOAS is to use a meta-language that provides a built-in and\nlogical treatment of binding related notions. By embedding the meta-language\nwithin a larger programming or reasoning framework, it is possible to absorb\nthe treatment of binding structure in the object language into the meta-theory\nof the system, thereby greatly simplifying the overall implementation and\nreasoning processes.\n  We develop the above argument in this thesis by presenting and demonstrating\nthe effectiveness of an approach to the verified implementation of compiler\ntransformations for functional programs that exploits HOAS. In this approach,\ntransformations on functional programs are first articulated in the form of\nrule-based relational specifications. These specifications are rendered into\nprograms in the language lambda Prolog. On the one hand, these programs serve\ndirectly as implementations. On the other hand, they can be used as input to\nthe Abella system which allows us to prove properties about them and thereby\nabout the implementations. Both lambda Prolog and Abella support the use of the\nHOAS approach. Thus, they constitute a framework that can be used to test out\nthe benefits of the HOAS approach in verified compilation. We use them to\nimplement and verify a compiler for a representative functional programming\nlanguage that embodies the transformations that form the core of many compilers\nfor such languages. In both the programming and the reasoning phases, we show\nhow the use of the HOAS approach significantly simplifies the representation,\nmanipulation, analysis and reasoning of binding structure.\n", "versions": [{"version": "v1", "created": "Sat, 11 Feb 2017 01:10:54 GMT"}], "update_date": "2017-02-14", "authors_parsed": [["Wang", "Yuting", ""]]}, {"id": "1702.03511", "submitter": "Kees Middelburg", "authors": "J. A. Bergstra, C. A. Middelburg", "title": "Axioms for behavioural congruence of single-pass instruction sequences", "comments": "19 pages, this paper draws somewhat from the preliminaries of\n  arXiv:1502.00238 [cs.PL] and some earlier papers; some remarks added and some\n  remarks reformulated", "journal-ref": "Scientific Annals of Computer Science 27(2):111--135 (2017)", "doi": "10.7561/SACS.2017.2.111", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In program algebra, an algebraic theory of single-pass instruction sequences,\nthree congruences on instruction sequences are paid attention to: instruction\nsequence congruence, structural congruence, and behavioural congruence. Sound\nand complete axiom systems for the first two congruences were already given in\nearly papers on program algebra. The current paper is the first one that is\nconcerned with an axiom system for the third congruence. The presented axiom\nsystem is especially notable for its axioms that have to do with forward jump\ninstructions.\n", "versions": [{"version": "v1", "created": "Sun, 12 Feb 2017 10:32:38 GMT"}, {"version": "v2", "created": "Wed, 22 Nov 2017 09:13:17 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Bergstra", "J. A.", ""], ["Middelburg", "C. A.", ""]]}, {"id": "1702.04908", "submitter": "Ohad Kammar", "authors": "Ohad Kammar, Paul B. Levy, Sean K. Moss, Sam Staton", "title": "A monad for full ground reference cells", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a denotational account of dynamic allocation of potentially cyclic\nmemory cells using a monad on a functor category. We identify the collection of\nheaps as an object in a different functor category equipped with a monad for\nadding hiding/encapsulation capabilities to the heaps. We derive a monad for\nfull ground references supporting effect masking by applying a state monad\ntransformer to the encapsulation monad. To evaluate the monad, we present a\ndenotational semantics for a call-by-value calculus with full ground\nreferences, and validate associated code transformations.\n", "versions": [{"version": "v1", "created": "Thu, 16 Feb 2017 10:12:00 GMT"}, {"version": "v2", "created": "Wed, 19 Apr 2017 13:26:43 GMT"}], "update_date": "2017-04-20", "authors_parsed": [["Kammar", "Ohad", ""], ["Levy", "Paul B.", ""], ["Moss", "Sean K.", ""], ["Staton", "Sam", ""]]}, {"id": "1702.05437", "submitter": "Aws Albarghouthi", "authors": "Aws Albarghouthi and Loris D'Antoni and Samuel Drews and Aditya Nori", "title": "Quantifying Program Bias", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the range and sensitivity of algorithmic decisions expanding at a\nbreak-neck speed, it is imperative that we aggressively investigate whether\nprograms are biased. We propose a novel probabilistic program analysis\ntechnique and apply it to quantifying bias in decision-making programs.\nSpecifically, we (i) present a sound and complete automated verification\ntechnique for proving quantitative properties of probabilistic programs; (ii)\nshow that certain notions of bias, recently proposed in the fairness\nliterature, can be phrased as quantitative correctness properties; and (iii)\npresent FairSquare, the first verification tool for quantifying program bias,\nand evaluate it on a range of decision-making programs.\n", "versions": [{"version": "v1", "created": "Fri, 17 Feb 2017 17:02:29 GMT"}, {"version": "v2", "created": "Tue, 7 Mar 2017 03:21:07 GMT"}], "update_date": "2017-03-08", "authors_parsed": [["Albarghouthi", "Aws", ""], ["D'Antoni", "Loris", ""], ["Drews", "Samuel", ""], ["Nori", "Aditya", ""]]}, {"id": "1702.05463", "submitter": "Sergei Vostokin", "authors": "Sergey Vostokin, Ekaterina Skoryupina", "title": "A Performance Analysis of Simple Runtime System for Actor Programming in\n  C++", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose the Templet -- a runtime system for actor\nprogramming of high performance computing in C++. We provide a compact source\ncode of the runtime system, which uses standard library of C++11 only. We\ndemonstrate how it differs from the classic implementations of the actor model.\nThe practical significance of the Templet was examined by comparative study on\nthe performance of three applications: the reference code in C++, managed by\nthe OpenMP; the actor code in C++, managed by the Templet; the actor code in\nJava, managed by the Akka. As a test problem we used a numerical algorithm for\nsolving the heat equation.\n", "versions": [{"version": "v1", "created": "Fri, 17 Feb 2017 18:08:43 GMT"}], "update_date": "2017-02-20", "authors_parsed": [["Vostokin", "Sergey", ""], ["Skoryupina", "Ekaterina", ""]]}, {"id": "1702.05807", "submitter": "Ankush Das", "authors": "Ankush Das and Akash Lal", "title": "Precise Null Pointer Analysis Through Global Value Numbering", "comments": "17 pages, 1 section in Appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Precise analysis of pointer information plays an important role in many\nstatic analysis techniques and tools today. The precision, however, must be\nbalanced against the scalability of the analysis. This paper focusses on\nimproving the precision of standard context and flow insensitive alias analysis\nalgorithms at a low scalability cost. In particular, we present a\nsemantics-preserving program transformation that drastically improves the\nprecision of existing analyses when deciding if a pointer can alias NULL. Our\nprogram transformation is based on Global Value Numbering, a scheme inspired\nfrom compiler optimizations literature. It allows even a flow-insensitive\nanalysis to make use of branch conditions such as checking if a pointer is NULL\nand gain precision. We perform experiments on real-world code to measure the\noverhead in performing the transformation and the improvement in the precision\nof the analysis. We show that the precision improves from 86.56% to 98.05%,\nwhile the overhead is insignificant.\n", "versions": [{"version": "v1", "created": "Sun, 19 Feb 2017 22:10:29 GMT"}], "update_date": "2017-02-21", "authors_parsed": [["Das", "Ankush", ""], ["Lal", "Akash", ""]]}, {"id": "1702.06334", "submitter": "Sunbeom So", "authors": "Sunbeom So and Hakjoo Oh", "title": "Synthesizing Imperative Programs from Examples Guided by Static Analysis", "comments": "The paper is accepted in Static Analysis Symposium (SAS) '17. The\n  submission version is somewhat different from the version in arxiv. The final\n  version will be uploaded after the camera-ready version is ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present a novel algorithm that synthesizes imperative programs for\nintroductory programming courses. Given a set of input-output examples and a\npartial program, our algorithm generates a complete program that is consistent\nwith every example. Our key idea is to combine enumerative program synthesis\nand static analysis, which aggressively prunes out a large search space while\nguaranteeing to find, if any, a correct solution. We have implemented our\nalgorithm in a tool, called SIMPL, and evaluated it on 30 problems used in\nintroductory programming courses. The results show that SIMPL is able to solve\nthe benchmark problems in 6.6 seconds on average.\n", "versions": [{"version": "v1", "created": "Tue, 21 Feb 2017 11:29:28 GMT"}, {"version": "v2", "created": "Tue, 13 Jun 2017 09:13:33 GMT"}], "update_date": "2017-06-14", "authors_parsed": [["So", "Sunbeom", ""], ["Oh", "Hakjoo", ""]]}, {"id": "1702.06343", "submitter": "Satoshi Egi", "authors": "Satoshi Egi", "title": "Scalar and Tensor Parameters for Importing Tensor Index Notation\n  including Einstein Summation Notation", "comments": "Scheme and Functional Programming Workshop 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a method for importing tensor index notation,\nincluding Einstein summation notation, into functional programming. This method\ninvolves introducing two types of parameters, i.e, scalar and tensor\nparameters, and simplified tensor index rules that do not handle expressions\nthat are valid only for the Cartesian coordinate system, in which the index can\nmove up and down freely. An example of such an expression is \"c = A_i B_i\". As\nan ordinary function, when a tensor parameter obtains a tensor as an argument,\nthe function treats the tensor argument as a whole. In contrast, when a scalar\nparameter obtains a tensor as an argument, the function is applied to each\ncomponent of the tensor. In this paper, we show that introducing these two\ntypes of parameters and our simplified index rules enables us to apply\narbitrary user-defined functions to tensor arguments using index notation\nincluding Einstein summation notation without requiring an additional\ndescription to enable each function to handle tensors.\n", "versions": [{"version": "v1", "created": "Tue, 21 Feb 2017 12:05:59 GMT"}, {"version": "v2", "created": "Wed, 22 Feb 2017 12:03:34 GMT"}, {"version": "v3", "created": "Thu, 30 Mar 2017 09:26:02 GMT"}, {"version": "v4", "created": "Tue, 9 May 2017 01:30:28 GMT"}, {"version": "v5", "created": "Mon, 24 Jul 2017 07:34:39 GMT"}, {"version": "v6", "created": "Tue, 8 Aug 2017 00:35:19 GMT"}], "update_date": "2018-08-31", "authors_parsed": [["Egi", "Satoshi", ""]]}, {"id": "1702.06704", "submitter": "Hern\\'an Ponce-de-Le\\'on", "authors": "Hern\\'an Ponce-de-Le\\'on, Florian Furbach, Keijo Heljanko, Roland\n  Meyer", "title": "Portability Analysis for Axiomatic Memory Models. PORTHOS: One Tool for\n  all Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Porthos, the first tool that discovers porting bugs in\nperformance-critical code. Porthos takes as input a program and the memory\nmodels of the source architecture for which the program has been developed and\nthe target model to which it is ported. If the code is not portable, Porthos\nfinds a bug in the form of an unexpected execution - an execution that is\nconsistent with the target but inconsistent with the source memory model.\nTechnically, Porthos implements a bounded model checking method that reduces\nthe portability analysis problem to satisfiability modulo theories (SMT). There\nare two main problems in the reduction that we present novel and efficient\nsolutions for. First, the formulation of the portability problem contains a\nquantifier alternation (consistent + inconsistent). We introduce a formula that\nencodes both in a single existential query. Second, the supported memory models\n(e.g., Power) contain recursive definitions. We compute the required least\nfixed point semantics for recursion (a problem that was left open in [47])\nefficiently in SMT. Finally we present the first experimental analysis of\nportability from TSO to Power.\n", "versions": [{"version": "v1", "created": "Wed, 22 Feb 2017 08:34:54 GMT"}, {"version": "v2", "created": "Fri, 28 Apr 2017 15:33:39 GMT"}], "update_date": "2017-05-01", "authors_parsed": [["Ponce-de-Le\u00f3n", "Hern\u00e1n", ""], ["Furbach", "Florian", ""], ["Heljanko", "Keijo", ""], ["Meyer", "Roland", ""]]}, {"id": "1702.06806", "submitter": "Markus Raab", "authors": "Markus Raab and Gerg\\\"o Barany", "title": "Introducing Context Awareness in Unmodified, Context-unaware Software", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software tends to be highly configurable, but most applications are hardly\ncontext aware. For example, a web browser provides many settings to configure\nprinters and proxies, but nevertheless it is unable to dynamically adapt to a\nnew workplace. In this paper we aim to empirically demonstrate that by dynamic\nand automatic reconfiguration of unmodified software we can systematically\nintroduce context awareness. In 16 real-world applications comprising 50\nmillion lines of code we empirically investigate which of the 2,683 run-time\nconfiguration accesses (1) already take context into account, or (2) can be\nmanipulated at run-time to do so. The results show that context awareness can\nbe exploited far beyond the developers' initial intentions. Our tool Elektra\ndynamically intercepts the run-time configuration accesses and replaces them\nwith a context aware implementation. Users only need to specify contexts and\nadd context sensors to make use of this potential.\n", "versions": [{"version": "v1", "created": "Tue, 21 Feb 2017 17:39:10 GMT"}], "update_date": "2017-02-23", "authors_parsed": [["Raab", "Markus", ""], ["Barany", "Gerg\u00f6", ""]]}, {"id": "1702.07103", "submitter": "Saeid Tizpaz-Niari", "authors": "Saeid Tizpaz-Niari, Pavol Cerny, Bor-Yuh Evan Chang, Sriram\n  Sankaranarayanan, Ashutosh Trivedi", "title": "Discriminating Traces with Time", "comments": "Published in TACAS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.CR cs.FL cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What properties about the internals of a program explain the possible\ndifferences in its overall running time for different inputs? In this paper, we\npropose a formal framework for considering this question we dub trace-set\ndiscrimination. We show that even though the algorithmic problem of computing\nmaximum likelihood discriminants is NP-hard, approaches based on integer linear\nprogramming (ILP) and decision tree learning can be useful in zeroing-in on the\nprogram internals. On a set of Java benchmarks, we find that\ncompactly-represented decision trees scalably discriminate with high\naccuracy---more scalably than maximum likelihood discriminants and with\ncomparable accuracy. We demonstrate on three larger case studies how\ndecision-tree discriminants produced by our tool are useful for debugging\ntiming side-channel vulnerabilities (i.e., where a malicious observer infers\nsecrets simply from passively watching execution times) and availability\nvulnerabilities.\n", "versions": [{"version": "v1", "created": "Thu, 23 Feb 2017 05:48:22 GMT"}], "update_date": "2017-02-24", "authors_parsed": [["Tizpaz-Niari", "Saeid", ""], ["Cerny", "Pavol", ""], ["Chang", "Bor-Yuh Evan", ""], ["Sankaranarayanan", "Sriram", ""], ["Trivedi", "Ashutosh", ""]]}, {"id": "1702.07146", "submitter": "Manuel Mazzara", "authors": "Daniel de Carvalho, Manuel Mazzara, Bogdan Mingela, Larisa Safina,\n  Alexander Tchitchigin, Nikolay Troshkov", "title": "Jolie Static Type Checker: a prototype", "comments": "Modeling and Analysis of Information Systems, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Static verification of a program source code correctness is an important\nelement of software reliability. Formal verification of software programs\ninvolves proving that a program satisfies a formal specification of its\nbehavior. Many languages use both static and dynamic type checking. With such\napproach, the static type checker verifies everything possible at compile time,\nand dynamic checks the remaining. The current state of the Jolie programming\nlanguage includes a dynamic type system. Consequently, it allows avoidable\nrun-time errors. A static type system for the language has been formally\ndefined on paper but lacks an implementation yet. In this paper, we describe a\nprototype of Jolie Static Type Checker (JSTC), which employs a technique based\non a SMT solver. We describe the theory behind and the implementation, and the\nprocess of static analysis.\n", "versions": [{"version": "v1", "created": "Thu, 23 Feb 2017 09:38:11 GMT"}, {"version": "v2", "created": "Sat, 16 Sep 2017 08:20:53 GMT"}, {"version": "v3", "created": "Tue, 19 Sep 2017 07:51:20 GMT"}, {"version": "v4", "created": "Wed, 20 Sep 2017 11:30:33 GMT"}, {"version": "v5", "created": "Wed, 18 Oct 2017 15:53:47 GMT"}], "update_date": "2017-10-19", "authors_parsed": [["de Carvalho", "Daniel", ""], ["Mazzara", "Manuel", ""], ["Mingela", "Bogdan", ""], ["Safina", "Larisa", ""], ["Tchitchigin", "Alexander", ""], ["Troshkov", "Nikolay", ""]]}, {"id": "1702.07753", "submitter": "Craig DeForest", "authors": "C.E. DeForest, K. Glazebrook", "title": "Practical Magick with C, PDL, and PDL::PP -- a guide to compiled add-ons\n  for PDL", "comments": "42 pages, 1 figure, overview of the PDL::PP description language for\n  vectorized calculation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This guide is intended to knit together, and extend, the existing PP and C\ndocumentation on PDL internals. It draws heavily from prior work by the authors\nof the code. Special thanks go to Christian Soeller, and Tuomas Lukka, who\ntogether with Glazebrook conceived and implemented PDL and PP; and to Chris\nMarshall, who has led the PDL development team through several groundbreaking\nreleases and to new levels of usability.\n", "versions": [{"version": "v1", "created": "Fri, 24 Feb 2017 20:45:52 GMT"}], "update_date": "2017-02-28", "authors_parsed": [["DeForest", "C. E.", ""], ["Glazebrook", "K.", ""]]}, {"id": "1702.08154", "submitter": "Ashish Mishra", "authors": "Ashish Mishra, Y. N. Srikant", "title": "Beyond-Regular Typestate", "comments": "submitted to CAV'17", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an extension for regular typestates, called Beyond- Regular\nTypestate(BR-Typestate), which is expressive enough to model non-regular\nproperties of programs and protocols over data. We model the BR-Typestate\nsystem over a dependently typed, state based, impera- tive core language, and\nwe prove its soundness and tractability. We have implemented a prototype\ntypechecker for the language, and we show how several important, real world\nnon-regular properties of programs and protocols can be verified.\n", "versions": [{"version": "v1", "created": "Mon, 27 Feb 2017 06:01:12 GMT"}], "update_date": "2017-02-28", "authors_parsed": [["Mishra", "Ashish", ""], ["Srikant", "Y. N.", ""]]}, {"id": "1702.08342", "submitter": "Abbas Acar", "authors": "Z. Berkay Celik, Hidayet Aksu, Abbas Acar, Ryan Sheatsley, A. Selcuk\n  Uluagac, and Patrick McDaniel", "title": "Curie: Policy-based Secure Data Exchange", "comments": "updated (this version has been accepted to CODASPY 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data sharing among partners---users, organizations, companies---is crucial\nfor the advancement of data analytics in many domains. Sharing through secure\ncomputation and differential privacy allows these partners to perform private\ncomputations on their sensitive data in controlled ways. However, in reality,\nthere exist complex relationships among members. Politics, regulations,\ninterest, trust, data demands and needs are one of the many reasons. Thus,\nthere is a need for a mechanism to meet these conflicting relationships on data\nsharing. This paper presents Curie, an approach to exchange data among members\nwhose membership has complex relationships. The CPL policy language that allows\nmembers to define the specifications of data exchange requirements is\nintroduced. Members (partners) assert who and what to exchange through their\nlocal policies and negotiate a global sharing agreement. The agreement is\nimplemented in a multi-party computation that guarantees sharing among members\nwill comply with the policy as negotiated. The use of Curie is validated\nthrough an example of a health care application built on recently introduced\nsecure multi-party computation and differential privacy frameworks, and policy\nand performance trade-offs are explored.\n", "versions": [{"version": "v1", "created": "Mon, 27 Feb 2017 16:00:04 GMT"}, {"version": "v2", "created": "Tue, 28 Feb 2017 19:02:54 GMT"}, {"version": "v3", "created": "Sun, 10 Feb 2019 04:56:45 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Celik", "Z. Berkay", ""], ["Aksu", "Hidayet", ""], ["Acar", "Abbas", ""], ["Sheatsley", "Ryan", ""], ["Uluagac", "A. Selcuk", ""], ["McDaniel", "Patrick", ""]]}, {"id": "1702.08441", "submitter": "Lenz Belzner", "authors": "Lenz Belzner", "title": "Monte Carlo Action Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes Monte Carlo Action Programming, a programming language\nframework for autonomous systems that act in large probabilistic state spaces\nwith high branching factors. It comprises formal syntax and semantics of a\nnondeterministic action programming language. The language is interpreted\nstochastically via Monte Carlo Tree Search. Effectiveness of the approach is\nshown empirically.\n", "versions": [{"version": "v1", "created": "Sat, 25 Feb 2017 11:48:50 GMT"}], "update_date": "2017-03-01", "authors_parsed": [["Belzner", "Lenz", ""]]}]