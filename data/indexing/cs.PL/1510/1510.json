[{"id": "1510.00697", "submitter": "Catalin Hritcu", "authors": "Yannis Juglaret, Catalin Hritcu, Arthur Azevedo de Amorim, Benjamin C.\n  Pierce, Antal Spector-Zabusky, Andrew Tolmach", "title": "Towards a Fully Abstract Compiler Using Micro-Policies: Secure\n  Compilation for Mutually Distrustful Components", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Secure compilation prevents all low-level attacks on compiled code and allows\nfor sound reasoning about security in the source language. In this work we\npropose a new attacker model for secure compilation that extends the well-known\nnotion of full abstraction to ensure protection for mutually distrustful\ncomponents. We devise a compiler chain (compiler, linker, and loader) and a\nnovel security monitor that together defend against this strong attacker model.\nThe monitor is implemented using a recently proposed, generic tag-based\nprotection framework called micro-policies, which comes with hardware support\nfor efficient caching and with a formal verification methodology. Our monitor\nprotects the abstractions of a simple object-oriented language---class\nisolation, the method call discipline, and type safety---against arbitrary\nlow-level attackers.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2015 19:36:30 GMT"}], "update_date": "2015-10-05", "authors_parsed": [["Juglaret", "Yannis", ""], ["Hritcu", "Catalin", ""], ["de Amorim", "Arthur Azevedo", ""], ["Pierce", "Benjamin C.", ""], ["Spector-Zabusky", "Antal", ""], ["Tolmach", "Andrew", ""]]}, {"id": "1510.00925", "submitter": "Arjun Guha", "authors": "Arjun Guha, Claudiu Saftoiu, and Shriram Krishnamurthi", "title": "The Essence of JavaScript", "comments": "European Conference on Object-Oriented Programming (ECOOP) 2010", "journal-ref": null, "doi": "10.1007/978-3-642-14107-2_7", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We reduce JavaScript to a core calculus structured as a small-step\noperational semantics. We present several peculiarities of the language and\nshow that our calculus models them. We explicate the desugaring process that\nturns JavaScript programs into ones in the core. We demonstrate faithfulness to\nJavaScript using real-world test suites. Finally, we illustrate utility by\ndefining a security property, implementing it as a type system on the core, and\nextending it to the full language.\n", "versions": [{"version": "v1", "created": "Sun, 4 Oct 2015 11:23:12 GMT"}], "update_date": "2015-10-06", "authors_parsed": [["Guha", "Arjun", ""], ["Saftoiu", "Claudiu", ""], ["Krishnamurthi", "Shriram", ""]]}, {"id": "1510.01752", "submitter": "Luca Padovani", "authors": "Luca Padovani (Universit\\'a di Torino)", "title": "Type Reconstruction for the Linear \\pi-Calculus with Composite Regular\n  Types", "comments": "45 pages", "journal-ref": "Logical Methods in Computer Science, Volume 11, Issue 4 (December\n  22, 2015) lmcs:1614", "doi": "10.2168/LMCS-11(4:13)2015", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the linear {\\pi}-calculus with composite regular types in such a\nway that data containing linear values can be shared among several processes,\nif there is no overlapping access to such values. We describe a type\nreconstruction algorithm for the extended type system and discuss some\npractical aspects of its implementation.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2015 20:37:11 GMT"}, {"version": "v2", "created": "Sun, 20 Dec 2015 15:33:51 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Padovani", "Luca", "", "Universit\u00e1 di Torino"]]}, {"id": "1510.02229", "submitter": "Ilaria Castellani", "authors": "Massimo Bartoletti, Ilaria Castellani, Pierre-Malo Deni\\'elou,\n  Mariangiola Dezani-Ciancaglini, Silvia Ghilezan, Jovanka Pantovic, Jorge A.\n  P\\'erez, Peter Thiemann, Bernardo Toninho, Hugo Torres Vieira", "title": "Combining behavioural types with security analysis", "comments": null, "journal-ref": "Journal of Logical and Algebraic Methods in Programming, Elsevier,\n  2015, pp.18", "doi": "10.1016/j.jlamp.2015.09.003", "report-no": null, "categories": "cs.PL cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today's software systems are highly distributed and interconnected, and they\nincreasingly rely on communication to achieve their goals; due to their\nsocietal importance, security and trustworthiness are crucial aspects for the\ncorrectness of these systems. Behavioural types, which extend data types by\ndescribing also the structured behaviour of programs, are a widely studied\napproach to the enforcement of correctness properties in communicating systems.\nThis paper offers a unified overview of proposals based on behavioural types\nwhich are aimed at the analysis of security properties.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2015 08:23:35 GMT"}], "update_date": "2015-10-09", "authors_parsed": [["Bartoletti", "Massimo", ""], ["Castellani", "Ilaria", ""], ["Deni\u00e9lou", "Pierre-Malo", ""], ["Dezani-Ciancaglini", "Mariangiola", ""], ["Ghilezan", "Silvia", ""], ["Pantovic", "Jovanka", ""], ["P\u00e9rez", "Jorge A.", ""], ["Thiemann", "Peter", ""], ["Toninho", "Bernardo", ""], ["Vieira", "Hugo Torres", ""]]}, {"id": "1510.02419", "submitter": "Vivek Nigam", "authors": "Nick Benton, Martin Hofmann, Vivek Nigam", "title": "Effect-Dependent Transformations for Concurrent Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a denotational semantics for an abstract effect system for a\nhigher-order, shared-variable concurrent programming language. We prove the\nsoundness of a number of general effect-based program equivalences, including a\nparallelization equation that specifies sufficient conditions for replacing\nsequential composition with parallel composition. Effect annotations are\nrelative to abstract locations specified by contracts rather than physical\nfootprints allowing us in particular to show the soundness of some\ntransformations involving fine-grained concurrent data structures, such as\nMichael-Scott queues, that allow concurrent access to different parts of\nmutable data structures.\n  Our semantics is based on refining a trace-based semantics for first-order\nprograms due to Brookes. By moving from concrete to abstract locations, and\nadding type refinements that capture the possible side-effects of both\nexpressions and their concurrent environments, we are able to validate many\nequivalences that do not hold in an unrefined model. The meanings of types are\nexpressed using a game-based logical relation over sets of traces. Two programs\n$e_1$ and $e_2$ are logically related if one is able to solve a two-player\ngame: for any trace with result value $v_1$ in the semantics of $e_1$\n(challenge) that the player presents, the opponent can present an (response)\nequivalent trace in the semantics of $e_2$ with a logically related result\nvalue $v_2$.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2015 17:47:39 GMT"}], "update_date": "2015-10-12", "authors_parsed": [["Benton", "Nick", ""], ["Hofmann", "Martin", ""], ["Nigam", "Vivek", ""]]}, {"id": "1510.03271", "submitter": "Lu\\'is Cruz-Filipe", "authors": "Lu\\'is Cruz-Filipe, Fabrizio Montesi", "title": "A Core Model for Choreographic Programming", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-319-57666-4_3", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Choreographic Programming is a programming paradigm for building concurrent\nprograms that are deadlock-free by construction, as a result of programming\ncommunications declaratively and then synthesising process implementations\nautomatically. Despite strong interest on choreographies, a foundational model\nthat explains which computations can be performed with the hallmark constructs\nof choreographies is still missing.\n  In this work, we introduce Core Choreographies (CC), a model that includes\nonly the core primitives of choreographic programming. Every computable\nfunction can be implemented as a choreography in CC, from which we can\nsynthesise a process implementation where independent computations run in\nparallel. We discuss the design of CC and argue that it constitutes a canonical\nmodel for choreographic programming.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2015 13:09:58 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2016 13:42:42 GMT"}, {"version": "v3", "created": "Tue, 9 Oct 2018 09:20:09 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Cruz-Filipe", "Lu\u00eds", ""], ["Montesi", "Fabrizio", ""]]}, {"id": "1510.03637", "submitter": "Saverio Giallorenzo", "authors": "Saverio Giallorenzo, Fabrizio Montesi, Maurizio Gabbrielli", "title": "Applied Choreographies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Choreographic Programming is a correct-by-construction paradigm where a\ncompilation procedure synthesises deadlock-free, concurrent, and distributed\ncommunicating processes from global, declarative descriptions of\ncommunications, called choreographies. Previous work used choreographies for\nthe synthesis of programs. Alas, there is no formalisation that provides a\nchain of correctness from choreographies to their implementations. This problem\noriginates from the gap between existing theoretical models, which abstract\ncommunications using channel names (\\`a la CCS/{\\pi}-calculus), and their\nimplementations, which use low-level mechanisms for message routing. As a\nsolution, we propose the theoretical framework of Applied Choreographies. In\nthe framework, developers write choreographies in a language that follows the\nstandard syntax and name-based communication semantics of previous works. Then,\nthey use a compilation procedure to transform a choreography into a low-level,\nimplementation-adherent calculus of Service-Oriented Computing (SOC). To manage\nthe complexity of the compilation, we divide its formalisation and proof in\nthree stages, respectively dealing with: a) the translation of name-based\ncommunications into their SOC equivalents (namely, using correlation mechanisms\nbased on message data); b) the projection of a choreography into a composition\nof partial, single-participant choreographies (towards their translation into\nSOC processes); c) the translation of partial choreographies and the\ndistribution of choreography-level state into SOC processes. We provide results\nof behavioural correspondence for each stage. Thus, given a choreography\nspecification, we guarantee to synthesise its faithful and deadlock-free\nservice-oriented implementation.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2015 11:41:20 GMT"}, {"version": "v2", "created": "Thu, 19 Apr 2018 14:31:33 GMT"}, {"version": "v3", "created": "Mon, 14 Dec 2020 06:50:24 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Giallorenzo", "Saverio", ""], ["Montesi", "Fabrizio", ""], ["Gabbrielli", "Maurizio", ""]]}, {"id": "1510.03726", "submitter": "Simone Martini", "authors": "Simone Martini", "title": "Several types of types in programming languages", "comments": "History and Philosophy of Computing, HAPOC 2015. To appear in LNCS", "journal-ref": "History and Philosophy of Computing, HAPOC 2015, IFIP Advances in\n  Information and Communication Technology 487, 216-227, Springer 2016", "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Types are an important part of any modern programming language, but we often\nforget that the concept of type we understand nowadays is not the same it was\nperceived in the sixties. Moreover, we conflate the concept of \"type\" in\nprogramming languages with the concept of the same name in mathematical logic,\nan identification that is only the result of the convergence of two different\npaths, which started apart with different aims. The paper will present several\nremarks (some historical, some of more conceptual character) on the subject, as\na basis for a further investigation. The thesis we will argue is that there are\nthree different characters at play in programming languages, all of them now\ncalled types: the technical concept used in language design to guide\nimplementation; the general abstraction mechanism used as a modelling tool; the\nclassifying tool inherited from mathematical logic. We will suggest three\npossible dates ad quem for their presence in the programming language\nliterature, suggesting that the emergence of the concept of type in computer\nscience is relatively independent from the logical tradition, until the\nCurry-Howard isomorphism will make an explicit bridge between them.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2015 15:05:47 GMT"}, {"version": "v2", "created": "Thu, 16 Jun 2016 09:51:13 GMT"}], "update_date": "2017-03-30", "authors_parsed": [["Martini", "Simone", ""]]}, {"id": "1510.03929", "submitter": "Carlo Spaccasassi Mr", "authors": "Carlo Spaccasassi, Vasileios Koutavas", "title": "Type-Based Analysis for Session Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a type-based analysis to infer the session protocols of channels\nin an ML-like concurrent functional language. Combining and extending\nwell-known techniques, we develop a type-checking system that separates the\nunderlying ML type system from the typing of sessions. Without using linearity,\nour system guarantees communication safety and partial lock freedom. It also\nsupports provably complete session inference for finite sessions with no\nprogrammer annotations. We exhibit the usefulness of our system with\ninteresting examples, including one which is not typable in substructural type\nsystems.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2015 23:35:13 GMT"}, {"version": "v2", "created": "Sat, 17 Oct 2015 12:05:04 GMT"}, {"version": "v3", "created": "Tue, 23 Feb 2016 21:52:30 GMT"}, {"version": "v4", "created": "Wed, 13 Apr 2016 15:13:53 GMT"}], "update_date": "2016-04-14", "authors_parsed": [["Spaccasassi", "Carlo", ""], ["Koutavas", "Vasileios", ""]]}, {"id": "1510.04440", "submitter": "Silvia Crafa", "authors": "Silvia Crafa", "title": "Modelling the Evolution of Programming Languages", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Programming languages are engineered languages that allow to instruct a\nmachine and share algorithmic information; they have a great influence on the\nsociety since they underlie almost every information technology artefact, and\nthey are at the core of the current explosion of software technology. The\nhistory of programming languages is marked by innovations, diversifications,\nlateral transfers and social influences; moreover, it represents an\nintermediate case study between the evolution of human languages and the\nevolution of technology. In this paper we study the application of the\nDarwinian explanation to the programming languages evolution by discussing to\nwhat extent the evolutionary mechanisms distinctive of biology can be applied\nto this area. We show that a number of evolutionary building blocks can be\nrecognised in the realm of computer languages, but we also identify critical\nissues. Far from being crystal clear, this fine-grained study shows to be a\nuseful tool to assess recent results about programming languages phylogenies.\nFinally, we show that rich evolutionary patterns, such as co-evolution,\nmacro-evolutionary trends, niche construction and exaptation, can be\neffectively applied to programming languages and provide for interesting\nexplanatory tools.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2015 08:18:54 GMT"}], "update_date": "2015-10-16", "authors_parsed": [["Crafa", "Silvia", ""]]}, {"id": "1510.05201", "submitter": "Mingshuai Chen", "authors": "Yangjia Li, Naijun Zhan, Mingshuai Chen, Hui Lu, Guohua Wu and\n  Joost-Pieter Katoen", "title": "On Termination of Polynomial Programs with Equality Conditions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the termination problem of a family of multi-path polynomial\nprograms (MPPs), in which all assignments to program variables are polynomials,\nand test conditions of loops and conditional statements are polynomial\nequalities. We show that the set of non-terminating inputs (NTI) of such a\nprogram is algorithmically computable, thus leading to the decidability of its\ntermination. To the best of our knowledge, the considered family of MPPs is\nhitherto the largest one for which termination is decidable. We present an\nexplicit recursive function which is essentially Ackermannian, to compute the\nmaximal length of ascending chains of polynomial ideals under a control\nfunction, and thereby obtain a complete answer to the questions raised by\nSeidenberg. This maximal length facilitates a precise complexity analysis of\nour algorithms for computing the NTI and deciding termination of MPPs. We\nextend our method to programs with polynomial guarded commands and show how an\nincomplete procedure for MPPs with inequality guards can be obtained. An\napplication of our techniques to invariant generation of polynomial programs is\nfurther presented.\n", "versions": [{"version": "v1", "created": "Sun, 18 Oct 2015 06:21:35 GMT"}, {"version": "v2", "created": "Mon, 21 Mar 2016 02:47:01 GMT"}, {"version": "v3", "created": "Tue, 1 Sep 2020 17:06:09 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Li", "Yangjia", ""], ["Zhan", "Naijun", ""], ["Chen", "Mingshuai", ""], ["Lu", "Hui", ""], ["Wu", "Guohua", ""], ["Katoen", "Joost-Pieter", ""]]}, {"id": "1510.05216", "submitter": "Tiark Rompf", "authors": "Tiark Rompf, Nada Amin", "title": "From F to DOT: Type Soundness Proofs with Definitional Interpreters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scala's type system unifies ML modules, object-oriented, and functional\nprogramming. The Dependent Object Types (DOT) family of calculi has been\nproposed as a new foundation for Scala and similar languages. Unfortunately, it\nis not clear how DOT relates to any well-known type systems, and type soundness\nhas only been established for very restricted subsets. In fact, important Scala\nfeatures are known to break at least one key metatheoretic property such as\nenvironment narrowing or subtyping transitivity, which are usually required for\na type soundness proof.\n  First, and, perhaps surprisingly, we show how rich DOT calculi can still be\nproved sound. The key insight is that narrowing and subtyping transitivity only\nneed to hold for runtime objects, but not for code that is never executed.\nAlas, the dominant method of proving type soundness, Wright and Felleisen's\nsyntactic approach, is based on term rewriting, which does not a priori make a\ndistinction between runtime and type assignment time.\n  Second, we demonstrate how type soundness can be proved for advanced,\npolymorphic, type systems with respect to high-level, definitional\ninterpreters, implemented in Coq. We present the first mechanized soundness\nproof in this style for System F<: and several extensions, including mutable\nreferences. Our proofs use only simple induction: another surprising result, as\nthe combination of big-step semantics, mutable references, and polymorphism is\ncommonly believed to require co-inductive proof techniques.\n  Third, we show how DOT-like calculi emerge as generalizations of F<:,\nexposing a rich design space of calculi with path-dependent types which we\ncollectively call System D. Armed with insights from the definitional\ninterpreter semantics, we also show how equivalent small-step semantics and\nsoundness proofs in Wright-Felleisen-style can be derived for these systems.\n", "versions": [{"version": "v1", "created": "Sun, 18 Oct 2015 09:53:06 GMT"}, {"version": "v2", "created": "Thu, 4 Feb 2016 21:01:58 GMT"}], "update_date": "2016-02-08", "authors_parsed": [["Rompf", "Tiark", ""], ["Amin", "Nada", ""]]}, {"id": "1510.05527", "submitter": "David Naumann", "authors": "David A. Naumann", "title": "Towards Patterns for Heaps and Imperative Lambdas", "comments": null, "journal-ref": null, "doi": "10.1016/j.jlamp.2015.10.008", "report-no": null, "categories": "cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In functional programming, point-free relation calculi have been fruitful for\ngeneral theories of program construction, but for specific applications\npointwise expressions can be more convenient and comprehensible. In imperative\nprogramming, refinement calculi have been tied to pointwise expression in terms\nof state variables, with the curious exception of the ubiquitous but invisible\nheap. To integrate pointwise with point-free, de Moor and Gibbons extended\nlambda calculus with non-injective pattern matching interpreted using\nrelations. This article gives a semantics of that language using ``ideal\nrelations'' between partial orders, and a second semantics using predicate\ntransformers. The second semantics is motivated by its potential use with\nseparation algebra, for pattern matching in programs acting on the heap. Laws\nincluding lax beta and eta are proved in these models and a number of open\nproblems are posed.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2015 15:20:27 GMT"}], "update_date": "2015-10-20", "authors_parsed": [["Naumann", "David A.", ""]]}, {"id": "1510.06379", "submitter": "Viorel Preoteasa", "authors": "Viorel Preoteasa and Stavros Tripakis", "title": "Towards Compositional Feedback in Non-Deterministic and\n  Non-Input-Receptive Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feedback is an essential composition operator in many classes of reactive and\nother systems. This paper studies feedback in the context of compositional\ntheories with refinement. Such theories allow to reason about systems on a\ncomponent-by-component basis, and to characterize substitutability as a\nrefinement relation. Although compositional theories of feedback do exist, they\nare limited either to deterministic systems (functions) or input-receptive\nsystems (total relations). In this work we propose a compositional theory of\nfeedback which applies to non-deterministic and non-input-receptive systems\n(e.g., partial relations). To achieve this, we use the semantic frameworks of\npredicate and property transformers, and relations with fail and unknown\nvalues. We show how to define instantaneous feedback for stateless systems and\nfeedback with unit delay for stateful systems. Both operations preserve the\nrefinement relation, and both can be applied to non-deterministic and\nnon-input-receptive systems.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2015 19:24:42 GMT"}, {"version": "v2", "created": "Wed, 28 Oct 2015 12:58:58 GMT"}, {"version": "v3", "created": "Wed, 27 Apr 2016 19:35:38 GMT"}], "update_date": "2016-04-28", "authors_parsed": [["Preoteasa", "Viorel", ""], ["Tripakis", "Stavros", ""]]}, {"id": "1510.07095", "submitter": "Kyriakos Georgiou", "authors": "Kyriakos Georgiou, Steve Kerrison, Kerstin Eder", "title": "On the Value and Limits of Multi-level Energy Consumption Static\n  Analysis for Deeply Embedded Single and Multi-threaded Programs", "comments": "29 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is growing interest in lowering the energy consumption of computation.\nEnergy transparency is a concept that makes a program's energy consumption\nvisible from software to hardware through the different system layers. Such\ntransparency can enable energy optimizations at each layer and between layers,\nand help both programmers and operating systems make energy aware decisions.\nThe common methodology of extracting the energy consumption of a program is\nthrough direct measurement of the target hardware. This usually involves\nspecialized equipment and knowledge most programmers do not have. In this\npaper, we examine how existing methods for static resource analysis and energy\nmodeling can be utilized to perform Energy Consumption Static Analysis (ECSA)\nfor deeply embedded programs. To investigate this, we have developed ECSA\ntechniques that work at the instruction set level and at a higher level, the\nLLVM IR, through a novel mapping technique. We apply our ECSA to a\ncomprehensive set of mainly industrial benchmarks, including single-threaded\nand also multi-threaded embedded programs from two commonly used concurrency\npatterns, task farms and pipelines. We compare our ECSA results to hardware\nmeasurements and predictions obtained based on simulation traces. We discuss a\nnumber of application scenarios for which ECSA results can provide energy\ntransparency and conclude with a set of new research questions for future work.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2015 01:10:26 GMT"}], "update_date": "2015-10-27", "authors_parsed": [["Georgiou", "Kyriakos", ""], ["Kerrison", "Steve", ""], ["Eder", "Kerstin", ""]]}, {"id": "1510.07171", "submitter": "Daniel Poetzl", "authors": "Daniel Poetzl, Daniel Kroening", "title": "Formalizing and Checking Thread Refinement for Data-Race-Free Execution\n  Models (Extended Version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When optimizing a thread in a concurrent program (either done manually or by\nthe compiler), it must be guaranteed that the resulting thread is a refinement\nof the original thread. Most theories of valid optimizations are formulated in\nterms of valid syntactic transformations on the program code, or in terms of\nvalid transformations on thread execution traces. We present a new theory\nformulated instead in terms of the state of threads at synchronization\noperations, and show that it provides several advantages: it supports more\noptimizations, and leads to more efficient and simpler procedures for\nrefinement checking. We develop the theory for the SC-for-DRF execution model\n(using locks for synchronization), and show that its application in a compiler\ntesting setting leads to large performance improvements.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2015 18:22:05 GMT"}], "update_date": "2015-10-27", "authors_parsed": [["Poetzl", "Daniel", ""], ["Kroening", "Daniel", ""]]}, {"id": "1510.07253", "submitter": "Francesco Tiezzi", "authors": "Francesco Tiezzi and Nobuko Yoshida", "title": "Reversing Single Sessions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Session-based communication has gained a widespread acceptance in practice as\na means for developing safe communicating systems via structured interactions.\nIn this paper, we investigate how these structured interactions are affected by\nreversibility, which provides a computational model allowing executed\ninteractions to be undone. In particular, we provide a systematic study of the\nintegration of different notions of reversibility in both binary and multiparty\nsingle sessions. The considered forms of reversibility are: one for completely\nreversing a given session with one backward step, and another for also\nrestoring any intermediate state of the session with either one backward step\nor multiple ones. We analyse the costs of reversing a session in all these\ndifferent settings. Our results show that extending binary single sessions to\nmultiparty ones does not affect the reversibility machinery and its costs.\n", "versions": [{"version": "v1", "created": "Sun, 25 Oct 2015 14:41:33 GMT"}, {"version": "v2", "created": "Fri, 8 Apr 2016 13:14:14 GMT"}], "update_date": "2016-04-11", "authors_parsed": [["Tiezzi", "Francesco", ""], ["Yoshida", "Nobuko", ""]]}, {"id": "1510.07293", "submitter": "Peter Thiemann", "authors": "Martin Sulzmann and Peter Thiemann", "title": "Forkable Regular Expressions", "comments": "12 pages plus technical appendix, to appear in LATA 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider forkable regular expressions, which enrich regular expressions\nwith a fork operator, to establish a formal basis for static and dynamic\nanalysis of the communication behavior of concurrent programs. We define a\nnovel compositional semantics for forkable expressions, establish their\nfundamental properties, and define derivatives for them as a basis for the\ngeneration of automata, for matching, and for language containment tests.\nForkable expressions may give rise to non-regular languages, in general, but we\nidentify sufficient conditions on expressions that guarantee finiteness of the\nautomata construction via derivatives.\n", "versions": [{"version": "v1", "created": "Sun, 25 Oct 2015 19:42:43 GMT"}, {"version": "v2", "created": "Tue, 8 Dec 2015 20:23:31 GMT"}], "update_date": "2015-12-09", "authors_parsed": [["Sulzmann", "Martin", ""], ["Thiemann", "Peter", ""]]}, {"id": "1510.07565", "submitter": "Andreas Pavlogiannis", "authors": "Krishnendu Chatterjee and Amir Kafshdar Goharshady and Rasmus\n  Ibsen-Jensen and Andreas Pavlogiannis", "title": "Algorithms for Algebraic Path Properties in Concurrent Systems of\n  Constant Treewidth Components", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study algorithmic questions for concurrent systems where the transitions\nare labeled from a complete, closed semiring, and path properties are algebraic\nwith semiring operations. The algebraic path properties can model dataflow\nanalysis problems, the shortest path problem, and many other natural problems\nthat arise in program analysis. We consider that each component of the\nconcurrent system is a graph with constant treewidth, a property satisfied by\nthe controlflow graphs of most programs. We allow for multiple possible\nqueries, which arise naturally in demand driven dataflow analysis. The study of\nmultiple queries allows us to consider the tradeoff between the resource usage\nof the one-time preprocessing and for each individual query. The traditional\napproach constructs the product graph of all components and applies the\nbest-known graph algorithm on the product. In this approach, even the answer to\na single query requires the transitive closure, which provides no room for\ntradeoff between preprocessing and query time.\n  Our main contributions are algorithms that significantly improve the\nworst-case running time of the traditional approach, and provide various\ntradeoffs depending on the number of queries. For example, in a concurrent\nsystem of two components, the traditional approach requires hexic time in the\nworst case for answering one query as well as computing the transitive closure,\nwhereas we show that with one-time preprocessing in almost cubic time, each\nsubsequent query can be answered in at most linear time, and even the\ntransitive closure can be computed in almost quartic time. Furthermore, we\nestablish conditional optimality results showing that the worst-case running\ntime of our algorithms cannot be improved without achieving major breakthroughs\nin graph algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2015 17:50:00 GMT"}], "update_date": "2015-11-27", "authors_parsed": [["Chatterjee", "Krishnendu", ""], ["Goharshady", "Amir Kafshdar", ""], ["Ibsen-Jensen", "Rasmus", ""], ["Pavlogiannis", "Andreas", ""]]}, {"id": "1510.07995", "submitter": "Tom\\'a\\v{s} Vojnar", "authors": "Kamil Dudka, Luk\\'a\\v{s} Hol\\'ik, Petr Peringer, Marek Trt\\'ik,\n  Tom\\'a\\v{s} Vojnar", "title": "From Low-Level Pointers to High-Level Containers", "comments": "An extended version of a VMCAI'16 paper", "journal-ref": null, "doi": null, "report-no": "FIT BUT Technical Report Series, Technical Report No. FIT-TR-2015-03", "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method that transforms a C program manipulating containers using\nlow-level pointer statements into an equivalent program where the containers\nare manipulated via calls of standard high-level container operations like\npush_back or pop_front. The input of our method is a C program annotated by a\nspecial form of shape invariants which can be obtained from current automatic\nshape analysers after a slight modification. The resulting program where the\nlow-level pointer statements are summarized into high-level container\noperations is more understandable and (among other possible benefits) better\nsuitable for program analysis. We have implemented our approach and\nsuccessfully tested it through a number of experiments with list-based\ncontainers, including experiments with simplification of program analysis by\nseparating shape analysis from analysing data-related properties.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2015 17:30:22 GMT"}], "update_date": "2015-10-28", "authors_parsed": [["Dudka", "Kamil", ""], ["Hol\u00edk", "Luk\u00e1\u0161", ""], ["Peringer", "Petr", ""], ["Trt\u00edk", "Marek", ""], ["Vojnar", "Tom\u00e1\u0161", ""]]}, {"id": "1510.08121", "submitter": "Jonathan Frankle", "authors": "Jonathan Frankle", "title": "Type-Directed Synthesis of Products", "comments": "Master's Thesis at Princeton University", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software synthesis - the process of generating complete, general-purpose\nprograms from specifications - has become a hot research topic in the past few\nyears. For decades the problem was thought to be insurmountable: the search\nspace of possible programs is far too massive to efficiently traverse. Advances\nin efficient constraint solving have overcome this barrier, enabling a new\ngeneration of effective synthesis systems. Most existing systems compile\nsynthesis tasks down to low-level SMT instances, sacrificing high-level\nsemantic information while solving only first-order problems (i.e., filling\ninteger holes). Recent work takes an alternative approach, using the\nCurry-Howard isomorphism and techniques from automated theorem proving to\nconstruct higher-order programs with algebraic datatypes.\n  My thesis involved extending this type-directed synthesis engine to handle\nproduct types, which required significant modifications to both the underlying\ntheory and the tool itself. Product types streamline other language features,\neliminating variable-arity constructors among other workarounds employed in the\noriginal synthesis system. A form of logical conjunction, products are\ninvertible, making it possible to equip the synthesis system with an efficient\ntheorem-proving technique called focusing that eliminates many of the\nnondeterministic choices inherent in proof search. These theoretical\nenhancements informed a new version of the type-directed synthesis prototype\nimplementation, which remained performance-competitive with the original\nsynthesizer. A significant advantage of the type-directed synthesis framework\nis its extensibility; this thesis is a roadmap for future such efforts to\nincrease the expressive power of the system.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2015 22:40:01 GMT"}], "update_date": "2015-10-29", "authors_parsed": [["Frankle", "Jonathan", ""]]}, {"id": "1510.08419", "submitter": "Nadia Polikarpova", "authors": "Nadia Polikarpova and Ivan Kuraj and Armando Solar-Lezama", "title": "Program Synthesis from Polymorphic Refinement Types", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method for synthesizing recursive functions that provably\nsatisfy a given specification in the form of a polymorphic refinement type. We\nobserve that such specifications are particularly suitable for program\nsynthesis for two reasons. First, they offer a unique combination of expressive\npower and decidability, which enables automatic verification---and hence\nsynthesis---of nontrivial programs. Second, a type-based specification for a\nprogram can often be effectively decomposed into independent specifications for\nits components, causing the synthesizer to consider fewer component\ncombinations and leading to a combinatorial reduction in the size of the search\nspace. At the core of our synthesis procedure is a new algorithm for refinement\ntype checking, which supports specification decomposition.\n  We have evaluated our prototype implementation on a large set of synthesis\nproblems and found that it exceeds the state of the art in terms of both\nscalability and usability. The tool was able to synthesize more complex\nprograms than those reported in prior work (several sorting algorithms and\noperations on balanced search trees), as well as most of the benchmarks tackled\nby existing synthesizers, often starting from a more concise and intuitive user\ninput.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2015 19:05:11 GMT"}, {"version": "v2", "created": "Tue, 2 Feb 2016 22:01:58 GMT"}, {"version": "v3", "created": "Thu, 21 Apr 2016 16:06:38 GMT"}], "update_date": "2016-04-22", "authors_parsed": [["Polikarpova", "Nadia", ""], ["Kuraj", "Ivan", ""], ["Solar-Lezama", "Armando", ""]]}, {"id": "1510.08517", "submitter": "Hongfei Fu", "authors": "Krishnendu Chatterjee, Hongfei Fu, Petr Novotny, Rouzbeh Hasheminezhad", "title": "Algorithmic Analysis of Qualitative and Quantitative Termination\n  Problems for Affine Probabilistic Programs", "comments": "24 pages, full version to the conference paper on POPL 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider termination of probabilistic programs with\nreal-valued variables. The questions concerned are:\n  1. qualitative ones that ask (i) whether the program terminates with\nprobability 1 (almost-sure termination) and (ii) whether the expected\ntermination time is finite (finite termination); 2. quantitative ones that ask\n(i) to approximate the expected termination time (expectation problem) and (ii)\nto compute a bound B such that the probability to terminate after B steps\ndecreases exponentially (concentration problem).\n  To solve these questions, we utilize the notion of ranking supermartingales\nwhich is a powerful approach for proving termination of probabilistic programs.\nIn detail, we focus on algorithmic synthesis of linear ranking-supermartingales\nover affine probabilistic programs (APP's) with both angelic and demonic\nnon-determinism. An important subclass of APP's is LRAPP which is defined as\nthe class of all APP's over which a linear ranking-supermartingale exists.\n  Our main contributions are as follows. Firstly, we show that the membership\nproblem of LRAPP (i) can be decided in polynomial time for APP's with at most\ndemonic non-determinism, and (ii) is NP-hard and in PSPACE for APP's with\nangelic non-determinism; moreover, the NP-hardness result holds already for\nAPP's without probability and demonic non-determinism. Secondly, we show that\nthe concentration problem over LRAPP can be solved in the same complexity as\nfor the membership problem of LRAPP. Finally, we show that the expectation\nproblem over LRAPP can be solved in 2EXPTIME and is PSPACE-hard even for APP's\nwithout probability and non-determinism (i.e., deterministic programs). Our\nexperimental results demonstrate the effectiveness of our approach to answer\nthe qualitative and quantitative questions over APP's with at most demonic\nnon-determinism.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2015 22:37:28 GMT"}], "update_date": "2015-10-30", "authors_parsed": [["Chatterjee", "Krishnendu", ""], ["Fu", "Hongfei", ""], ["Novotny", "Petr", ""], ["Hasheminezhad", "Rouzbeh", ""]]}]