[{"id": "1712.00898", "submitter": "EPTCS", "authors": "Catherine Dubois, Bruno Woltzenlogel Paleo", "title": "Proceedings of the Fifth Workshop on Proof eXchange for Theorem Proving", "comments": null, "journal-ref": "EPTCS 262, 2017", "doi": "10.4204/EPTCS.262", "report-no": null, "categories": "cs.LO cs.AI cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume of EPTCS contains the proceedings of the Fifth Workshop on Proof\nExchange for Theorem Proving (PxTP 2017), held on September 23-24, 2017 as part\nof the Tableaux, FroCoS and ITP conferences in Brasilia, Brazil. The PxTP\nworkshop series brings together researchers working on various aspects of\ncommunication, integration, and cooperation between reasoning systems and\nformalisms, with a special focus on proofs. The progress in computer-aided\nreasoning, both automated and interactive, during the past decades, made it\npossible to build deduction tools that are increasingly more applicable to a\nwider range of problems and are able to tackle larger problems progressively\nfaster. In recent years, cooperation between such tools in larger systems has\ndemonstrated the potential to reduce the amount of manual intervention.\nCooperation between reasoning systems relies on availability of theoretical\nformalisms and practical tools to exchange problems, proofs, and models. The\nPxTP workshop series strives to encourage such cooperation by inviting\ncontributions on all aspects of cooperation between reasoning tools, whether\nautomatic or interactive.\n", "versions": [{"version": "v1", "created": "Mon, 4 Dec 2017 04:24:11 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Dubois", "Catherine", ""], ["Paleo", "Bruno Woltzenlogel", ""]]}, {"id": "1712.01014", "submitter": "Francesco Dagnino", "authors": "Francesco Dagnino", "title": "Generalizing inference systems by coaxioms", "comments": "Master Thesis supervised by Davide Ancona and Elena Zucca, University\n  of Genova, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  After surveying classical results, we introduce a generalized notion of\ninference system to support structural recursion on non-well-founded data\ntypes. Besides axioms and inference rules with the usual meaning, a generalized\ninference system allows coaxioms, which are, intuitively, axioms which can only\nbe applied \"at infinite depth\" in a proof tree. This notion nicely subsumes\nstandard inference systems and their inductive and coinductive interpretation,\nwhile providing more flexibility. Indeed, the classical results can be extended\nto our generalized framework, interpreting recursive definitions as fixed\npoints which are not necessarily the least, nor the greatest one. This allows\nformal reasoning in cases where the inductive and coinductive interpretation do\nnot provide the intended meaning, or are mixed together.\n", "versions": [{"version": "v1", "created": "Mon, 4 Dec 2017 11:25:20 GMT"}, {"version": "v2", "created": "Thu, 19 Apr 2018 19:43:58 GMT"}], "update_date": "2018-04-23", "authors_parsed": [["Dagnino", "Francesco", ""]]}, {"id": "1712.01024", "submitter": "Mat\\'u\\v{s} Sul\\'ir", "authors": "Mat\\'u\\v{s} Sul\\'ir, Jaroslav Porub\\\"an", "title": "A Quantitative Study of Java Software Buildability", "comments": null, "journal-ref": "Proceedings of the 7th International Workshop on Evaluation and\n  Usability of Programming Languages and Tools (PLATEAU 2016), pages 17-25.\n  ACM, 2016", "doi": "10.1145/3001878.3001882", "report-no": null, "categories": "cs.SE cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Researchers, students and practitioners often encounter a situation when the\nbuild process of a third-party software system fails. In this paper, we aim to\nconfirm this observation present mainly as anecdotal evidence so far. Using a\nvirtual environment simulating a programmer's one, we try to fully\nautomatically build target archives from the source code of over 7,200 open\nsource Java projects. We found that more than 38% of builds ended in failure.\nBuild log analysis reveals the largest portion of errors are\ndependency-related. We also conduct an association study of factors affecting\nbuild success.\n", "versions": [{"version": "v1", "created": "Mon, 4 Dec 2017 11:51:30 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Sul\u00edr", "Mat\u00fa\u0161", ""], ["Porub\u00e4n", "Jaroslav", ""]]}, {"id": "1712.01161", "submitter": "Laure Philips", "authors": "Laure Philips (Software Languages Lab, Belgium), Joeri De Koster\n  (Vrije Universiteit Brussel, Belgium), Wolfgang De Meuter (Vrije Universiteit\n  Brussel, Belgium), Coen De Roover (Vrije Universiteit Brussel, Belgium)", "title": "Search-based Tier Assignment for Optimising Offline Availability in\n  Multi-tier Web Applications", "comments": null, "journal-ref": "The Art, Science, and Engineering of Programming, 2018, Vol. 2,\n  Issue 2, Article 3", "doi": "10.22152/programming-journal.org/2018/2/3", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Web programmers are often faced with several challenges in the development\nprocess of modern, rich internet applications. Technologies for the different\ntiers of the application have to be selected: a server-side language, a\ncombination of JavaScript, HTML and CSS for the client, and a database\ntechnology. Meeting the expectations of contemporary web applications requires\neven more effort from the developer: many state of the art libraries must be\nmastered and glued together. This leads to an impedance mismatch problem\nbetween the different technologies and it is up to the programmer to align them\nmanually. Multi-tier or tierless programming is a web programming paradigm that\nprovides one language for the different tiers of the web application, allowing\nthe programmer to focus on the actual program logic instead of the accidental\ncomplexity that comes from combining several technologies. While current\ntierless approaches therefore relieve the burden of having to combine different\ntechnologies into one application, the distribution of the code is explicitly\ntied into the program. Certain distribution decisions have an impact on\ncrosscutting concerns such as information security or offline availability.\nMoreover, adapting the programs such that the application complies better with\nthese concerns often leads to code tangling, rendering the program more\ndifficult to understand and maintain. We introduce an approach to multi-tier\nprogramming where the tierless code is decoupled from the tier specification.\nThe developer implements the web application in terms of slices and an external\nspecification that assigns the slices to tiers. A recommender system completes\nthe picture for those slices that do not have a fixed placement and proposes\nslice refinements as well. This recommender system tries to optimise the tier\nspecification with respect to one or more crosscutting concerns. This is in\ncontrast with current cutting edge solutions that hide distribution decisions\nfrom the programmer. In this paper we show that slices, together with a\nrecommender system, enable the developer to experiment with different\nplacements of slices, until the distribution of the code satisfies the\nprogrammer's needs. We present a search-based recommender system that maximises\nthe offline availability of a web application and a concrete implementation of\nthese concepts in the tier-splitting tool Stip.js.\n", "versions": [{"version": "v1", "created": "Mon, 4 Dec 2017 15:53:57 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Philips", "Laure", "", "Software Languages Lab, Belgium"], ["De Koster", "Joeri", "", "Vrije Universiteit Brussel, Belgium"], ["De Meuter", "Wolfgang", "", "Vrije Universiteit\n  Brussel, Belgium"], ["De Roover", "Coen", "", "Vrije Universiteit Brussel, Belgium"]]}, {"id": "1712.01163", "submitter": "Manuel Rigger", "authors": "Manuel Rigger (Johannes Kepler University Linz, Austria), Rene\n  Mayrhofer (Johannes Kepler University Linz, Austria), Roland Schatz (Oracle\n  Labs, Austria), Matthias Grimmer (Oracle Labs, Austria), Hanspeter\n  M\\\"ossenb\\\"ock (Johannes Kepler University Linz, Austria)", "title": "Introspection for C and its Applications to Library Robustness", "comments": null, "journal-ref": "The Art, Science, and Engineering of Programming, 2018, Vol. 2,\n  Issue 2, Article 4", "doi": "10.22152/programming-journal.org/2018/2/4", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Context: In C, low-level errors, such as buffer overflow and use-after-free,\nare a major problem, as they cause security vulnerabilities and hard-to-find\nbugs. C lacks automatic checks, and programmers cannot apply defensive\nprogramming techniques because objects (e.g., arrays or structs) lack run-time\ninformation about bounds, lifetime, and types. Inquiry: Current approaches to\ntackling low-level errors include dynamic tools, such as bounds or type\ncheckers, that check for certain actions during program execution. If they\ndetect an error, they typically abort execution. Although they track run-time\ninformation as part of their runtimes, they do not expose this information to\nprogrammers. Approach: We devised an introspection interface that allows C\nprogrammers to access run-time information and to query object bounds, object\nlifetimes, object types, and information about variadic arguments. This enables\nlibrary writers to check for invalid input or program states and thus, for\nexample, to implement custom error handling that maintains system availability\nand does not terminate on benign errors. As we assume that introspection is\nused together with a dynamic tool that implements automatic checks, errors that\nare not handled in the application logic continue to cause the dynamic tool to\nabort execution. Knowledge: Using the introspection interface, we implemented a\nmore robust, source-compatible version of the C standard library that validates\nparameters to its functions. The library functions react to otherwise undefined\nbehavior; for example, they can detect lurking flaws, handle unterminated\nstrings, check format string arguments, and set errno when they detect benign\nusage errors. Grounding: Existing dynamic tools maintain run-time information\nthat can be used to implement the introspection interface, and we demonstrate\nits implementation in Safe Sulong, an interpreter and dynamic bug-finding tool\nfor C that runs on a Java Virtual Machine and can thus easily expose relevant\nrun-time information. Importance: Using introspection in user code is a novel\napproach to tackling the long-standing problem of low-level errors in C. As new\napproaches are lowering the performance overhead of run-time information\nmaintenance, the usage of dynamic runtimes for C could become more common,\nwhich could ultimately facilitate a more widespread implementation of such an\nintrospection interface.\n", "versions": [{"version": "v1", "created": "Mon, 4 Dec 2017 15:56:38 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Rigger", "Manuel", "", "Johannes Kepler University Linz, Austria"], ["Mayrhofer", "Rene", "", "Johannes Kepler University Linz, Austria"], ["Schatz", "Roland", "", "Oracle\n  Labs, Austria"], ["Grimmer", "Matthias", "", "Oracle Labs, Austria"], ["M\u00f6ssenb\u00f6ck", "Hanspeter", "", "Johannes Kepler University Linz, Austria"]]}, {"id": "1712.01281", "submitter": "Sergi Blanco-Cuaresma", "authors": "Sergi Blanco-Cuaresma, Emeline Bolmont", "title": "Studying tidal effects in planetary systems with Posidonius. A N-body\n  simulator written in Rust", "comments": "To appear in the \"EWASS Special Session 4 (2017): Star-planet\n  interactions\" proceedings", "journal-ref": null, "doi": "10.5281/zenodo.1095095", "report-no": null, "categories": "astro-ph.EP astro-ph.IM astro-ph.SR cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Planetary systems with several planets in compact orbital configurations such\nas TRAPPIST-1 are surely affected by tidal effects. Its study provides us with\nimportant insight about its evolution. We developed a second generation of a\nN-body code based on the tidal model used in Mercury-T, re-implementing and\nimproving its functionalities using Rust as programming language (including a\nPython interface for easy use) and the WHFAST integrator. The new open source\ncode ensures memory safety, reproducibility of numerical N-body experiments, it\nimproves the spin integration compared to Mercury-T and allows to take into\naccount a new prescription for the dissipation of tidal inertial waves in the\nconvective envelope of stars. Posidonius is also suitable for binary system\nsimulations with evolving stars.\n", "versions": [{"version": "v1", "created": "Mon, 4 Dec 2017 19:00:00 GMT"}], "update_date": "2017-12-20", "authors_parsed": [["Blanco-Cuaresma", "Sergi", ""], ["Bolmont", "Emeline", ""]]}, {"id": "1712.01718", "submitter": "Ronny Tschueter", "authors": "Ronny Tsch\\\"uter, Johannes Ziegenbalg, Bert Wesarg, Matthias Weber,\n  Christian Herold, Sebastian D\\\"obel, Ronny Brendel", "title": "An LLVM Instrumentation Plug-in for Score-P", "comments": "8 pages", "journal-ref": "LLVM-HPC'17: Proceedings of the Fourth Workshop on the LLVM\n  Compiler Infrastructure in HPC, 2017, 2:1--2:8", "doi": "10.1145/3148173.3148187", "report-no": null, "categories": "cs.SE cs.PF cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reducing application runtime, scaling parallel applications to higher numbers\nof processes/threads, and porting applications to new hardware architectures\nare tasks necessary in the software development process. Therefore, developers\nhave to investigate and understand application runtime behavior. Tools such as\nmonitoring infrastructures that capture performance relevant data during\napplication execution assist in this task. The measured data forms the basis\nfor identifying bottlenecks and optimizing the code. Monitoring infrastructures\nneed mechanisms to record application activities in order to conduct\nmeasurements. Automatic instrumentation of the source code is the preferred\nmethod in most application scenarios. We introduce a plug-in for the LLVM\ninfrastructure that enables automatic source code instrumentation at\ncompile-time. In contrast to available instrumentation mechanisms in\nLLVM/Clang, our plug-in can selectively include/exclude individual application\nfunctions. This enables developers to fine-tune the measurement to the required\nlevel of detail while avoiding large runtime overheads due to excessive\ninstrumentation.\n", "versions": [{"version": "v1", "created": "Fri, 1 Dec 2017 13:15:49 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Tsch\u00fcter", "Ronny", ""], ["Ziegenbalg", "Johannes", ""], ["Wesarg", "Bert", ""], ["Weber", "Matthias", ""], ["Herold", "Christian", ""], ["D\u00f6bel", "Sebastian", ""], ["Brendel", "Ronny", ""]]}, {"id": "1712.02869", "submitter": "Harold Boley", "authors": "Harold Boley, Gen Zou", "title": "Perspectival Knowledge in PSOA RuleML: Representation, Model Theory, and\n  Translation", "comments": "39 pages, 5 figures, 2 tables; updates for PSOATransRun 1.3.1 to\n  1.4.2; refined terminology and metamodel", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Positional-Slotted Object-Applicative (PSOA) RuleML, a predicate\napplication (atom) can have an Object IDentifier (OID) and descriptors that may\nbe positional arguments (tuples) or attribute-value pairs (slots). PSOA RuleML\nexplicitly specifies for each descriptor whether it is to be interpreted under\nthe perspective of the predicate in whose scope it occurs. This\npredicate-dependency dimension refines the space between oidless, positional\natoms (relationships) and oidful, slotted atoms (framepoints): While\nrelationships use only a predicate-scope-sensitive (predicate-dependent) tuple\nand framepoints use only predicate-scope-insensitive (predicate-independent)\nslots, PSOA uses a systematics of orthogonal constructs also permitting atoms\nwith (predicate-)independent tuples and atoms with (predicate-)dependent slots.\nThis supports data and knowledge representation where a slot attribute can have\ndifferent values depending on the predicate. PSOA thus extends object-oriented\nmulti-membership and multiple inheritance. Based on objectification, PSOA laws\nare given: Besides unscoping and centralization, the semantic restriction and\ntransformation of describution permits rescoping of one atom's independent\ndescriptors to another atom with the same OID but a different predicate. For\ninheritance, default descriptors are realized by rules. On top of a metamodel\nand a Grailog visualization, PSOA's atom systematics for facts, queries, and\nrules is explained. The presentation and (XML-)serialization syntaxes of PSOA\nRuleML are introduced. Its model-theoretic semantics is formalized by extending\nthe interpretation functions for dependent descriptors. The open-source\nPSOATransRun system realizes PSOA RuleML by a translator to runtime predicates,\nincluding for dependent tuples (prdtupterm) and slots (prdsloterm). Our tests\nshow efficiency advantages of dependent and tupled modeling.\n", "versions": [{"version": "v1", "created": "Thu, 7 Dec 2017 21:36:21 GMT"}, {"version": "v2", "created": "Wed, 2 May 2018 00:19:21 GMT"}, {"version": "v3", "created": "Sun, 21 Jul 2019 17:58:15 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Boley", "Harold", ""], ["Zou", "Gen", ""]]}, {"id": "1712.03112", "submitter": "Tim Besard", "authors": "Tim Besard, Christophe Foket, Bjorn De Sutter", "title": "Effective Extensible Programming: Unleashing Julia on GPUs", "comments": null, "journal-ref": null, "doi": "10.1109/TPDS.2018.2872064", "report-no": null, "categories": "cs.PL cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  GPUs and other accelerators are popular devices for accelerating\ncompute-intensive, parallelizable applications. However, programming these\ndevices is a difficult task. Writing efficient device code is challenging, and\nis typically done in a low-level programming language. High-level languages are\nrarely supported, or do not integrate with the rest of the high-level language\necosystem. To overcome this, we propose compiler infrastructure to efficiently\nadd support for new hardware or environments to an existing programming\nlanguage.\n  We evaluate our approach by adding support for NVIDIA GPUs to the Julia\nprogramming language. By integrating with the existing compiler, we\nsignificantly lower the cost to implement and maintain the new compiler, and\nfacilitate reuse of existing application code. Moreover, use of the high-level\nJulia programming language enables new and dynamic approaches for GPU\nprogramming. This greatly improves programmer productivity, while maintaining\napplication performance similar to that of the official NVIDIA CUDA toolkit.\n", "versions": [{"version": "v1", "created": "Fri, 8 Dec 2017 15:02:29 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Besard", "Tim", ""], ["Foket", "Christophe", ""], ["De Sutter", "Bjorn", ""]]}, {"id": "1712.03894", "submitter": "Andrew Bedford", "authors": "Andrew Bedford", "title": "Coqatoo: Generating Natural Language Versions of Coq Proofs", "comments": "International Workshop on Coq for Programming Languages (CoqPL 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to their numerous advantages, formal proofs and proof assistants, such as\nCoq, are becoming increasingly popular. However, one disadvantage of using\nproof assistants is that the resulting proofs can sometimes be hard to read and\nunderstand, particularly for less-experienced users. To address this issue, we\nhave implemented a tool capable of generating natural language versions of Coq\nproofs called Coqatoo, which we present in this paper.\n", "versions": [{"version": "v1", "created": "Mon, 11 Dec 2017 17:12:34 GMT"}], "update_date": "2017-12-12", "authors_parsed": [["Bedford", "Andrew", ""]]}, {"id": "1712.04706", "submitter": "Mehdi Mohammadi", "authors": "Mehdi Mohammadi, Ala Al-Fuqaha, Zijiang James Yang", "title": "A High-Level Rule-based Language for Software Defined Network\n  Programming based on OpenFlow", "comments": "4 pages. This paper has been presented in the poster section of GENI\n  Engineering Conference 22 (GEC 22), Washington D.C., March 23-26, 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes XML-Defined Network policies (XDNP), a new high-level\nlanguage based on XML notation, to describe network control rules in Software\nDefined Network environments. We rely on existing OpenFlow controllers\nspecifically Floodlight but the novelty of this project is to separate\ncomplicated language- and framework-specific APIs from policy descriptions.\nThis separation makes it possible to extend the current work as a northbound\nhigher level abstraction that can support a wide range of controllers who are\nbased on different programming languages. By this approach, we believe that\nnetwork administrators can develop and deploy network control policies easier\nand faster.\n", "versions": [{"version": "v1", "created": "Wed, 13 Dec 2017 11:14:51 GMT"}, {"version": "v2", "created": "Thu, 14 Dec 2017 17:21:02 GMT"}], "update_date": "2017-12-15", "authors_parsed": [["Mohammadi", "Mehdi", ""], ["Al-Fuqaha", "Ala", ""], ["Yang", "Zijiang James", ""]]}, {"id": "1712.05465", "submitter": "Marco Peressotti", "authors": "Fabrizio Montesi and Marco Peressotti", "title": "Choreographies meet Communication Failures", "comments": "IMADA-preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Choreographies are global descriptions of communication structures, inspired\nby the \"Alice and Bob\" notation of security protocols. They have been\nsuccessfully employed in the design and implementation of distributed systems.\nHowever, there is still limited evidence of the applicability of choreographies\nin the real-world setting of distributed programming, where communication\nactions may fail. In this work, we propose the first choreography model that\nallows for communication failures and the programming of user-defined code to\ndeal with such failures. We validate our model by implementing common\nstrategies for handling communication failures in a robust way, which in turn\ncan be used as a library by choreographies that assume reliable communication.\nWe equip our model with a typing discipline that can statically verify\nreliability properties, in particular at-most-once and exactly-once delivery.\nWe demonstrate the applicability of our model by defining a\nsemantics-preserving compilation procedure towards a process calculus equipped\nwith unreliable I/O actions.\n", "versions": [{"version": "v1", "created": "Thu, 14 Dec 2017 21:56:41 GMT"}, {"version": "v2", "created": "Fri, 9 Feb 2018 14:24:59 GMT"}], "update_date": "2018-02-12", "authors_parsed": [["Montesi", "Fabrizio", ""], ["Peressotti", "Marco", ""]]}, {"id": "1712.05513", "submitter": "Umang Mathur", "authors": "P. Madhusudan, Umang Mathur, Shambwaditya Saha, Mahesh Viswanathan", "title": "A Decidable Fragment of Second Order Logic With Applications to\n  Synthesis", "comments": null, "journal-ref": "27th EACSL Annual Conference on Computer Science Logic (CSL 2018),\n  http://drops.dagstuhl.de/opus/volltexte/2018/9698", "doi": "10.4230/LIPIcs.CSL.2018.31", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a fragment of many-sorted second order logic called EQSMT and show\nthat checking satisfiability of sentences in this fragment is decidable. EQSMT\nformulae have an $\\exists^*\\forall^*$ quantifier prefix (over variables,\nfunctions and relations) making EQSMT conducive for modeling synthesis\nproblems. Moreover, EQSMT allows reasoning using a combination of background\ntheories provided that they have a decidable satisfiability problem for the\n$\\exists^*\\forall^*$ FO-fragment (e.g., linear arithmetic). Our decision\nprocedure reduces the satisfiability of EQSMT formulae to satisfiability\nqueries of $\\exists^*\\forall^*$ formulae of each individual background theory,\nallowing us to use existing efficient SMT solvers supporting\n$\\exists^*\\forall^*$ reasoning for these theories; hence our procedure can be\nseen as effectively quantified SMT (EQSMT) reasoning.\n  Errata: We have modified the transformation step-2 (page 9) to correct for a\nslight error. Also, the description above Theorem 10 is different from the\npublished version.\n", "versions": [{"version": "v1", "created": "Fri, 15 Dec 2017 03:03:11 GMT"}, {"version": "v2", "created": "Mon, 25 Jun 2018 03:17:10 GMT"}, {"version": "v3", "created": "Thu, 27 Sep 2018 17:14:43 GMT"}], "update_date": "2018-09-28", "authors_parsed": [["Madhusudan", "P.", ""], ["Mathur", "Umang", ""], ["Saha", "Shambwaditya", ""], ["Viswanathan", "Mahesh", ""]]}, {"id": "1712.05581", "submitter": "Daniel Neider", "authors": "Daniel Neider, Pranav Garg, P. Madhusudan, Shambwaditya Saha, Daejun\n  Park", "title": "Invariant Synthesis for Incomplete Verification Engines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a framework for synthesizing inductive invariants for incomplete\nverification engines, which soundly reduce logical problems in undecidable\ntheories to decidable theories. Our framework is based on the counter-example\nguided inductive synthesis principle (CEGIS) and allows verification engines to\ncommunicate non-provability information to guide invariant synthesis. We show\nprecisely how the verification engine can compute such non-provability\ninformation and how to build effective learning algorithms when invariants are\nexpressed as Boolean combinations of a fixed set of predicates. Moreover, we\nevaluate our framework in two verification settings, one in which verification\nengines need to handle quantified formulas and one in which verification\nengines have to reason about heap properties expressed in an expressive but\nundecidable separation logic. Our experiments show that our invariant synthesis\nframework based on non-provability information can both effectively synthesize\ninductive invariants and adequately strengthen contracts across a large suite\nof programs.\n", "versions": [{"version": "v1", "created": "Fri, 15 Dec 2017 08:38:15 GMT"}, {"version": "v2", "created": "Fri, 12 Jan 2018 12:08:56 GMT"}], "update_date": "2018-01-15", "authors_parsed": [["Neider", "Daniel", ""], ["Garg", "Pranav", ""], ["Madhusudan", "P.", ""], ["Saha", "Shambwaditya", ""], ["Park", "Daejun", ""]]}, {"id": "1712.05590", "submitter": "Niels Reijers", "authors": "Niels Reijers, Chi-Sheng Shih", "title": "Improved Ahead-of-Time Compilation of Stack-Based JVM Bytecode on\n  Resource-Constrained Devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many virtual machines exist for sensor nodes with only a few KB RAM and tens\nto a few hundred KB flash memory. They pack an impressive set of features, but\nsuffer from a slowdown of one to two orders of magnitude compared to optimised\nnative code, reducing throughput and increasing power consumption.\n  Compiling bytecode to native code to improve performance has been studied\nextensively for larger devices, but the restricted resources on sensor nodes\nmean most modern techniques cannot be applied. Simply replacing bytecode\ninstructions with predefined sequences of native instructions is known to\nimprove performance, but produces code several times larger than the optimised\nC equivalent, limiting the size of programmes that can fit onto a device.\n  This paper identifies the major sources of overhead resulting from this basic\napproach, and presents optimisations to remove most of the remaining\nperformance overhead, and over half the size overhead, reducing them to 69% and\n91% respectively. While this increases the size of the VM, the break-even point\nat which this fixed cost is compensated for is well within the range of memory\navailable on a sensor device, allowing us to both improve performance and load\nmore code on a device.\n", "versions": [{"version": "v1", "created": "Fri, 15 Dec 2017 09:28:18 GMT"}, {"version": "v2", "created": "Mon, 18 Dec 2017 04:45:12 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Reijers", "Niels", ""], ["Shih", "Chi-Sheng", ""]]}, {"id": "1712.07388", "submitter": "Cristina David", "authors": "Cristina David, Pascal Kesseli, Daniel Kroening", "title": "Kayak: Safe Semantic Refactoring to Java Streams", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Refactorings are structured changes to existing software that leave its\nexternally observable behaviour unchanged. Their intent is to improve\nreadability, performance or other non-behavioural properties. State-of-the-art\nautomatic refactoring tools are syntax-driven and, therefore, overly\nconservative. In this paper we explore semantics-driven refactoring, which\nenables much more sophisticated refactoring schemata. As an exemplar of this\nbroader idea, we present Kayak, an automatic refactoring tool that transforms\nJava with external iteration over collections into code that uses Streams, a\nnew abstraction introduced by Java 8. Our refactoring procedure performs\nsemantic reasoning and search in the space of possible refactorings using\nautomated program synthesis. Our experimental results support the conjecture\nthat semantics-driven refactorings are more precise and are able to rewrite\nmore complex code scenarios when compared to syntax-driven refactorings.\n", "versions": [{"version": "v1", "created": "Wed, 20 Dec 2017 09:51:41 GMT"}], "update_date": "2017-12-21", "authors_parsed": [["David", "Cristina", ""], ["Kesseli", "Pascal", ""], ["Kroening", "Daniel", ""]]}, {"id": "1712.07447", "submitter": "Michael Bukatin", "authors": "Michael Bukatin, Jon Anthony", "title": "Dataflow Matrix Machines and V-values: a Bridge between Programs and\n  Neural Nets", "comments": "28 pages, 5 figures; appeared in \"K + K = 120: Papers dedicated to\n  Laszlo Kalman and Andras Kornai on the occasion of their 60th birthdays\"\n  Festschrift; http://www.nytud.hu/kk120", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  1) Dataflow matrix machines (DMMs) generalize neural nets by replacing\nstreams of numbers with linear streams (streams supporting linear\ncombinations), allowing arbitrary input and output arities for activation\nfunctions, countable-sized networks with finite dynamically changeable active\npart capable of unbounded growth, and a very expressive self-referential\nmechanism.\n  2) DMMs are suitable for general-purpose programming, while retaining the key\nproperty of recurrent neural networks: programs are expressed via matrices of\nreal numbers, and continuous changes to those matrices produce arbitrarily\nsmall variations in the associated programs.\n  3) Spaces of V-values (vector-like elements based on nested maps) are\nparticularly useful, enabling DMMs with variadic activation functions and\nconveniently representing conventional data structures.\n", "versions": [{"version": "v1", "created": "Wed, 20 Dec 2017 12:34:17 GMT"}, {"version": "v2", "created": "Wed, 23 May 2018 13:24:05 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Bukatin", "Michael", ""], ["Anthony", "Jon", ""]]}, {"id": "1712.08310", "submitter": "Ankush Das", "authors": "Ankush Das, Jan Hoffmann and Frank Pfenning", "title": "Work Analysis with Resource-Aware Session Types", "comments": "25 pages, 2 pages of references, 11 pages of appendix, Accepted at\n  LICS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While there exist several successful techniques for supporting programmers in\nderiving static resource bounds for sequential code, analyzing the resource\nusage of message-passing concurrent processes poses additional challenges. To\nmeet these challenges, this article presents an analysis for statically\nderiving worst-case bounds on the total work performed by message-passing\nprocesses. To decompose interacting processes into components that can be\nanalyzed in isolation, the analysis is based on novel resource-aware session\ntypes, which describe protocols and resource contracts for inter-process\ncommunication. A key innovation is that both messages and processes carry\npotential to share and amortize cost while communicating. To symbolically\nexpress resource usage in a setting without static data structures and\nintrinsic sizes, resource contracts describe bounds that are functions of\ninteractions between processes. Resource-aware session types combine standard\nbinary session types and type-based amortized resource analysis in a linear\ntype system. This type system is formulated for a core session-type calculus of\nthe language SILL and proved sound with respect to a multiset-based operational\ncost semantics that tracks the total number of messages that are exchanged in a\nsystem. The effectiveness of the analysis is demonstrated by analyzing standard\nexamples from amortized analysis and the literature on session types and by a\ncomparative performance analysis of different concurrent programs implementing\nthe same interface.\n", "versions": [{"version": "v1", "created": "Fri, 22 Dec 2017 05:39:26 GMT"}, {"version": "v2", "created": "Fri, 27 Apr 2018 03:44:28 GMT"}], "update_date": "2018-04-30", "authors_parsed": [["Das", "Ankush", ""], ["Hoffmann", "Jan", ""], ["Pfenning", "Frank", ""]]}, {"id": "1712.08753", "submitter": "Ashish Mishra", "authors": "Ashish Mishra, Deepak Dsouza, Y. N. Srikant", "title": "Presburger-Definable Parameterized Typestates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Typestates are good at capturing dynamic states of a program as compared to\nnormal types that can capture static structural properties of data and program.\nAlthough useful, typestates are suitable only for specifying and verifying\nprogram properties defined using finite-state abstractions. Many useful dynamic\nproperties of programs are not finite-state definable. To address these issues,\nwe introduce parameterized typestates (p-typestates). p-typestates associate a\nlogical property with each state of regular typestate, thereby allowing\nspecification of properties beyond finite-state abstractions. We present a\ndependent type system to express and verify p-typestate properties and a\ntypestate-oriented core programming language incorporating these dependent\ntypes. Automatic inductive type-checking of p-typestate properties usually\nrequires a programmer to provide loop invariants as annotations. Here we\npropose a way to calculate loop invariants automatically, using loop\nacceleration techniques for Presburger definable transition systems.\n\\keywords{Programming Languages, Typestates, Dependent Types, Non-Regular\nProgram Properties, Verification, Loop Invariants}\n", "versions": [{"version": "v1", "created": "Sat, 23 Dec 2017 10:44:14 GMT"}], "update_date": "2017-12-27", "authors_parsed": [["Mishra", "Ashish", ""], ["Dsouza", "Deepak", ""], ["Srikant", "Y. N.", ""]]}, {"id": "1712.09052", "submitter": "Mahmoud Fayed", "authors": "Mahmoud S. Fayed, Muhammad Al-Qurishi, Atif Alamri, Ahmad A.\n  Al-Daraiseh", "title": "PWCT: Visual Language for IoT and Cloud Computing Applications and\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developing IoT, Data Computing and Cloud Computing software requires\ndifferent programming skills and different programming languages. This cause a\nproblem for many companies and researchers that need to hires many programmers\nto develop a complete solution. The problem is related directly to the\nfinancial cost and the development time which are very important factors to\nmany research projects. In this paper we present and propose the PWCT visual\nprogramming tool for developing IoT, Data Computing and Cloud Computing\nApplications and Systems without writing textual code directly. Using PWCT\nincrease productivity and provide researchers with one visual programming tool\nto develop different solutions.\n", "versions": [{"version": "v1", "created": "Mon, 25 Dec 2017 10:31:12 GMT"}], "update_date": "2017-12-27", "authors_parsed": [["Fayed", "Mahmoud S.", ""], ["Al-Qurishi", "Muhammad", ""], ["Alamri", "Atif", ""], ["Al-Daraiseh", "Ahmad A.", ""]]}, {"id": "1712.09302", "submitter": "G. A. Kavvos", "authors": "G. A. Kavvos", "title": "On the Semantics of Intensionality and Intensional Recursion", "comments": "DPhil thesis, Department of Computer Science & St John's College,\n  University of Oxford", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL math.CT math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intensionality is a phenomenon that occurs in logic and computation. In the\nmost general sense, a function is intensional if it operates at a level finer\nthan (extensional) equality. This is a familiar setting for computer\nscientists, who often study different programs or processes that are\ninterchangeable, i.e. extensionally equal, even though they are not implemented\nin the same way, so intensionally distinct. Concomitant with intensionality is\nthe phenomenon of intensional recursion, which refers to the ability of a\nprogram to have access to its own code. In computability theory, intensional\nrecursion is enabled by Kleene's Second Recursion Theorem. This thesis is\nconcerned with the crafting of a logical toolkit through which these phenomena\ncan be studied. Our main contribution is a framework in which mathematical and\ncomputational constructions can be considered either extensionally, i.e. as\nabstract values, or intensionally, i.e. as fine-grained descriptions of their\nconstruction. Once this is achieved, it may be used to analyse intensional\nrecursion.\n", "versions": [{"version": "v1", "created": "Tue, 26 Dec 2017 16:29:51 GMT"}], "update_date": "2017-12-27", "authors_parsed": [["Kavvos", "G. A.", ""]]}, {"id": "1712.09402", "submitter": "Chun Tian", "authors": "Chun Tian", "title": "A Formalization of Unique Solutions of Equations in Process Algebra", "comments": "250 pages, Master degree thesis of Computer Science in University of\n  Bologna", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this thesis, a comprehensive formalization of Milner's Calculus of\nCommunicating Systems (also known as CCS) has been done in HOL theorem prover\n(HOL4), based on an old work in HOL88. This includes all classical properties\nof strong/weak bisimulation equivalences and observation congruence, a theory\nof congruence for CCS, various versions of \"bisimulation up to\" techniques, and\nseveral deep theorems, namely the \"coarsest congruence contained in weak\nequivalence\", and three versions of the \"unique solution of equations\" theorem\nin Milner's book.\n  This work is further extended to support recent developments in Concurrency\nTheory, namely the \"contraction\" relation and the related \"unique solutions of\ncontractions\" theorem found by Prof. Davide Sangiorgi, University of Bologna.\nAs a result, a rather complete theory of \"contraction\" (and a similar relation\ncalled \"expansion\") for CCS is also formalized in this thesis. Further more, a\nnew variant of contraction called \"observational contraction\" was found by the\nauthor during this work, based on existing contraction relation. It's formally\nproved that, this new relation is preserved by direct sums of CCS processes,\nand has a more elegant form of the \"unique solutions of contractions\" theorem\nwithout any restriction on the CCS grammar.\n", "versions": [{"version": "v1", "created": "Tue, 5 Dec 2017 21:33:40 GMT"}], "update_date": "2017-12-29", "authors_parsed": [["Tian", "Chun", ""]]}, {"id": "1712.09418", "submitter": "Daniel Neider", "authors": "Deepak D'Souza, P. Ezudheen, Pranav Garg, P. Madhusudan, Daniel Neider", "title": "Horn-ICE Learning for Synthesizing Invariants and Contracts", "comments": null, "journal-ref": null, "doi": "10.1145/3276501", "report-no": null, "categories": "cs.LO cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We design learning algorithms for synthesizing invariants using Horn\nimplication counterexamples (Horn-ICE), extending the ICE-learning model. In\nparticular, we describe a decision-tree learning algorithm that learns from\nHorn-ICE samples, works in polynomial time, and uses statistical heuristics to\nlearn small trees that satisfy the samples. Since most verification proofs can\nbe modeled using Horn clauses, Horn-ICE learning is a more robust technique to\nlearn inductive annotations that prove programs correct. Our experiments show\nthat an implementation of our algorithm is able to learn adequate inductive\ninvariants and contracts efficiently for a variety of sequential and concurrent\nprograms.\n", "versions": [{"version": "v1", "created": "Tue, 26 Dec 2017 21:14:09 GMT"}], "update_date": "2018-11-12", "authors_parsed": [["D'Souza", "Deepak", ""], ["Ezudheen", "P.", ""], ["Garg", "Pranav", ""], ["Madhusudan", "P.", ""], ["Neider", "Daniel", ""]]}, {"id": "1712.09958", "submitter": "Moez AbdelGawad", "authors": "Moez A. AbdelGawad", "title": "Object-Oriented Theorem Proving (OOTP): First Thoughts", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic (i.e., computer-assisted) theorem proving (ATP) can come in many\nflavors. This document presents early steps in our effort towards defining\nobject-oriented theorem proving (OOTP) as a new style of ATP.\n  Traditional theorem proving (TTP) is the only well-known flavor of ATP so\nfar. OOTP is a generalization of TTP. While TTP is strongly based on functional\nprogramming (FP), OOTP is strongly based on object-oriented programming (OOP)\ninstead. We believe OOTP is a style of theorem proving that is no less powerful\nand no less natural than TTP and thus likely will be no less practically useful\nthan TTP.\n", "versions": [{"version": "v1", "created": "Thu, 28 Dec 2017 18:07:46 GMT"}, {"version": "v2", "created": "Wed, 27 Feb 2019 16:51:19 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["AbdelGawad", "Moez A.", ""]]}, {"id": "1712.10281", "submitter": "Mahmoud Fayed", "authors": "Mahmoud Samir Fayed", "title": "General-Purpose Visual Language and Information System with Case-Studies\n  in Developing Business Applications", "comments": "Master of Science Thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CY cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning computer programming has been always challenging. Since the sixties\nof the last century, many researchers developed Visual Programming Languages\n(VPLs) to help in this regard. In this thesis, ten VPLs were specifically\nselected, studied, experimented with, and evaluated. A total of fifteen metrics\nwere used to evaluate the tools. Comparisons, classification, and gap analysis\nwere then presented. A list of requirements for a general-purpose VPL and a\nguide to help the novice programmer choose the right tool were generated and\nfinally the PWCT (Programming Without Coding Technology, a novel\ngeneral-purpose visual programming language) is developed and presented. PWCT\nhas been launched as a Sourceforge project, which currently has more than\n230,000 downloads for the language and more than 19,500,000 downloads for\nsamples, tutorials and movies. Many business applications and projects are\ndeveloped using PWCT, Also we developed the Supernova programming language and\nthe Ring programming language using PWCT to prove that it can be used for\nadvanced and large projects. Feedback from developers and results from the\nstudies indicate that PWCT is a very appealing, competitive, and powerful\nlanguage.\n", "versions": [{"version": "v1", "created": "Mon, 25 Dec 2017 20:51:55 GMT"}, {"version": "v2", "created": "Thu, 15 Mar 2018 22:03:35 GMT"}, {"version": "v3", "created": "Tue, 10 Nov 2020 15:04:13 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Fayed", "Mahmoud Samir", ""]]}]