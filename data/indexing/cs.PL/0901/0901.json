[{"id": "0901.0869", "submitter": "Irene Durand", "authors": "Ir\\`ene Durand (LaBRI), Aart Middeldorp", "title": "On the Complexity of Deciding Call-by-Need", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a recent paper we introduced a new framework for the study of call by need\ncomputations to normal form and root-stable form in term rewriting. Using\nelementary tree automata techniques and ground tree transducers we obtained\nsimple decidability proofs for classes of rewrite systems that are much larger\nthan earlier classes defined using the complicated sequentiality concept. In\nthis paper we show that we can do without ground tree transducers in order to\narrive at decidability proofs that are phrased in direct tree automata\nconstructions. This allows us to derive better complexity bounds.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jan 2009 20:17:25 GMT"}, {"version": "v2", "created": "Mon, 28 Nov 2011 10:12:42 GMT"}], "update_date": "2011-11-29", "authors_parsed": [["Durand", "Ir\u00e8ne", "", "LaBRI"], ["Middeldorp", "Aart", ""]]}, {"id": "0901.1230", "submitter": "Leslie De Koninck", "authors": "Leslie De Koninck", "title": "Logical Algorithms meets CHR: A meta-complexity result for Constraint\n  Handling Rules with rule priorities", "comments": "To appear in Theory and Practice of Logic Programming (TPLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the relationship between the Logical Algorithms\nlanguage (LA) of Ganzinger and McAllester and Constraint Handling Rules (CHR).\nWe present a translation schema from LA to CHR-rp: CHR with rule priorities,\nand show that the meta-complexity theorem for LA can be applied to a subset of\nCHR-rp via inverse translation. Inspired by the high-level implementation\nproposal for Logical Algorithm by Ganzinger and McAllester and based on a new\nscheduling algorithm, we propose an alternative implementation for CHR-rp that\ngives strong complexity guarantees and results in a new and accurate\nmeta-complexity theorem for CHR-rp. It is furthermore shown that the\ntranslation from Logical Algorithms to CHR-rp combined with the new CHR-rp\nimplementation, satisfies the required complexity for the Logical Algorithms\nmeta-complexity result to hold.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jan 2009 12:37:32 GMT"}], "update_date": "2009-01-12", "authors_parsed": [["De Koninck", "Leslie", ""]]}, {"id": "0901.2399", "submitter": "William Blum", "authors": "William Blum and C.-H. Luke Ong", "title": "The Safe Lambda Calculus", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 5, Issue 1 (February\n  19, 2009) lmcs:1145", "doi": "10.2168/LMCS-5(1:3)2009", "report-no": null, "categories": "cs.PL cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Safety is a syntactic condition of higher-order grammars that constrains\noccurrences of variables in the production rules according to their\ntype-theoretic order. In this paper, we introduce the safe lambda calculus,\nwhich is obtained by transposing (and generalizing) the safety condition to the\nsetting of the simply-typed lambda calculus. In contrast to the original\ndefinition of safety, our calculus does not constrain types (to be\nhomogeneous). We show that in the safe lambda calculus, there is no need to\nrename bound variables when performing substitution, as variable capture is\nguaranteed not to happen. We also propose an adequate notion of beta-reduction\nthat preserves safety. In the same vein as Schwichtenberg's 1976\ncharacterization of the simply-typed lambda calculus, we show that the numeric\nfunctions representable in the safe lambda calculus are exactly the\nmultivariate polynomials; thus conditional is not definable. We also give a\ncharacterization of representable word functions. We then study the complexity\nof deciding beta-eta equality of two safe simply-typed terms and show that this\nproblem is PSPACE-hard. Finally we give a game-semantic analysis of safety: We\nshow that safe terms are denoted by `P-incrementally justified strategies'.\nConsequently pointers in the game semantics of safe lambda-terms are only\nnecessary from order 4 onwards.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jan 2009 05:41:36 GMT"}, {"version": "v2", "created": "Tue, 17 Feb 2009 08:17:13 GMT"}, {"version": "v3", "created": "Thu, 19 Feb 2009 18:43:11 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Blum", "William", ""], ["Ong", "C. -H. Luke", ""]]}, {"id": "0901.2461", "submitter": "Andrey Breslav", "authors": "Andrey Breslav", "title": "Grammatic -- a tool for grammar definition reuse and modularity", "comments": "Submitted to DSL'09", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Grammatic is a tool for grammar definition and manipulation aimed to improve\nmodularity and reuse of grammars and related development artifacts. It is\nindependent from parsing technology and any other details of target system\nimplementation. Grammatic provides a way for annotating grammars with arbitrary\nmetadata (like associativity attributes, semantic actions or anything else). It\nmight be used as a front-end for external tools like parser generators to make\ntheir input grammars modular and reusable. This paper describes main principles\nbehind Grammatic and gives an overview of languages it provides and their\nability to separate concerns and define reusable modules. Also it presents\nsketches of possible use cases for the tool.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jan 2009 11:45:40 GMT"}], "update_date": "2009-01-19", "authors_parsed": [["Breslav", "Andrey", ""]]}, {"id": "0901.3619", "submitter": "Xavier Leroy", "authors": "Sandrine Blazy (CEDRIC, INRIA Rocquencourt), Xavier Leroy (INRIA\n  Rocquencourt)", "title": "Mechanized semantics for the Clight subset of the C language", "comments": "Journal of Automated Reasoning (2009)", "journal-ref": "Journal of Automated Reasoning 43, 3 (2009) 263-288", "doi": "10.1007/s10817-009-9148-3", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents the formal semantics of a large subset of the C\nlanguage called Clight. Clight includes pointer arithmetic, \"struct\" and\n\"union\" types, C loops and structured \"switch\" statements. Clight is the source\nlanguage of the CompCert verified compiler. The formal semantics of Clight is a\nbig-step operational semantics that observes both terminating and diverging\nexecutions and produces traces of input/output events. The formal semantics of\nClight is mechanized using the Coq proof assistant. In addition to the\nsemantics of Clight, this article describes its integration in the CompCert\nverified compiler and several ways by which the semantics was validated.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jan 2009 08:40:31 GMT"}], "update_date": "2009-09-18", "authors_parsed": [["Blazy", "Sandrine", "", "CEDRIC, INRIA Rocquencourt"], ["Leroy", "Xavier", "", "INRIA\n  Rocquencourt"]]}, {"id": "0901.3906", "submitter": "Manuel Carro", "authors": "Pablo Chico de Guzman, Manuel Carro, Manuel V. Hermenegildo", "title": "A Program Transformation for Continuation Call-Based Tabled Execution", "comments": "Part of the proceedings of CICLOPS 2008", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advantages of tabled evaluation regarding program termination and\nreduction of complexity are well known --as are the significant implementation,\nportability, and maintenance efforts that some proposals (especially those\nbased on suspension) require. This implementation effort is reduced by program\ntransformation-based continuation call techniques, at some efficiency cost.\nHowever, the traditional formulation of this proposal by Ramesh and Cheng\nlimits the interleaving of tabled and non-tabled predicates and thus cannot be\nused as-is for arbitrary programs. In this paper we present a complete\ntranslation for the continuation call technique which, using the runtime\nsupport needed for the traditional proposal, solves these problems and makes it\npossible to execute arbitrary tabled programs. We present performance results\nwhich show that CCall offers a useful tradeoff that can be competitive with\nstate-of-the-art implementations.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jan 2009 15:40:48 GMT"}], "update_date": "2009-01-27", "authors_parsed": [["de Guzman", "Pablo Chico", ""], ["Carro", "Manuel", ""], ["Hermenegildo", "Manuel V.", ""]]}]