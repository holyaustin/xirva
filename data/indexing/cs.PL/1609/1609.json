[{"id": "1609.00195", "submitter": "Robert Colvin", "authors": "Robert J. Colvin, Ian J. Hayes, Larissa A. Meinicke", "title": "Designing a semantic model for a wide-spectrum language with concurrency", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A wide-spectrum language integrates specification constructs into a\nprogramming language in a manner that treats a specification command just like\nany other command. This paper investigates a semantic model for a wide-spectrum\nlanguage that supports concurrency and a refinement calculus. In order to\nhandle specifications with rely and guarantee conditions, the model includes\nexplicit environment steps as well as program steps. A novelty of our approach\nis that we define a set of primitive commands and operators, from which more\ncomplex specification and programming language commands are built. The\nprimitives have simple algebraic properties which support proof using algebraic\nreasoning. The model is general enough to specify notions as diverse as\nrely-guarantee reasoning, temporal logic, and progress properties of programs,\nand supports refining specifications to code. It also forms an instance of an\nabstract concurrent program algebra, which facilitates reasoning about\nproperties of the model at a high level of abstraction.\n", "versions": [{"version": "v1", "created": "Thu, 1 Sep 2016 11:50:02 GMT"}], "update_date": "2016-09-02", "authors_parsed": [["Colvin", "Robert J.", ""], ["Hayes", "Ian J.", ""], ["Meinicke", "Larissa A.", ""]]}, {"id": "1609.00919", "submitter": "Quang-Trung Ta", "authors": "Quang-Trung Ta, Ton Chanh Le, Siau-Cheng Khoo, Wei-Ngan Chin", "title": "Automated Mutual Explicit Induction Proof in Separation Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present a sequent-based deductive system for automatically proving\nentailments in separation logic by using mathematical induction. Our technique,\ncalled mutual explicit induction proof, is an instance of Noetherian induction.\nSpecifically, we propose a novel induction principle on a well-founded relation\nof separation logic model and follow the explicit induction methods to\nimplement this principle as inference rules, so that it can be easily\nintegrated into a deductive system. We also support mutual induction, a natural\nfeature of implicit induction, where the goal entailment and other entailments\nderived during the proof search can be used as hypotheses to prove each other.\nWe have implemented a prototype prover and evaluated it on a benchmark of\nhandcrafted entailments as well as benchmarks from a separation logic\ncompetition.\n", "versions": [{"version": "v1", "created": "Sun, 4 Sep 2016 11:50:23 GMT"}, {"version": "v2", "created": "Tue, 6 Sep 2016 16:04:42 GMT"}], "update_date": "2017-10-30", "authors_parsed": [["Ta", "Quang-Trung", ""], ["Le", "Ton Chanh", ""], ["Khoo", "Siau-Cheng", ""], ["Chin", "Wei-Ngan", ""]]}, {"id": "1609.01171", "submitter": "Artem Khyzha", "authors": "Artem Khyzha, Alexey Gotsman, Matthew Parkinson", "title": "A Generic Logic for Proving Linearizability (Extended Version)", "comments": "Formal Methods 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.DC cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Linearizability is a commonly accepted notion of correctness for libraries of\nconcurrent algorithms, and recent years have seen a number of proposals of\nprogram logics for proving it. Although these logics differ in technical\ndetails, they embody similar reasoning principles. To explicate these\nprinciples, we propose a logic for proving linearizability that is generic: it\ncan be instantiated with different means of compositional reasoning about\nconcurrency, such as separation logic or rely-guarantee. To this end, we\ngeneralise the Views framework for reasoning about concurrency to handle\nrelations between programs, required for proving linearizability. We present\nsample instantiations of our generic logic and show that it is powerful enough\nto handle concurrent algorithms with challenging features, such as helping.\n", "versions": [{"version": "v1", "created": "Mon, 5 Sep 2016 14:12:03 GMT"}], "update_date": "2016-09-06", "authors_parsed": [["Khyzha", "Artem", ""], ["Gotsman", "Alexey", ""], ["Parkinson", "Matthew", ""]]}, {"id": "1609.01985", "submitter": "Roly Perera", "authors": "Roly Perera, Simon J. Gay", "title": "Behavioural Prototypes", "comments": "Extended abstract; presented at 0th Workshop on New Object-Oriented\n  Languages (NOOL) 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We sketch a simple language of concurrent objects which explores the design\nspace between type systems and continuous testing. In our language, programs\nare collections of communicating automata checked automatically for multiparty\ncompatibility. This property, taken from the session types literature but here\napplied to terms rather than types, guarantees that no state-related errors\narise during execution: no object gets stuck because it was sent the wrong\nmessage, and every message is processed.\n", "versions": [{"version": "v1", "created": "Sat, 3 Sep 2016 11:14:51 GMT"}], "update_date": "2016-09-08", "authors_parsed": [["Perera", "Roly", ""], ["Gay", "Simon J.", ""]]}, {"id": "1609.03146", "submitter": "Mathieu Guillame-Bert", "authors": "Mathieu Guillame-Bert", "title": "Honey: A dataflow programming language for the processing, featurization\n  and analysis of multivariate, asynchronous and non-uniformly sampled scalar\n  symbolic time sequences", "comments": "The source code of four presented tasks are available on the Honey\n  website", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce HONEY; a new specialized programming language designed to\nfacilitate the processing of multivariate, asynchronous and non-uniformly\nsampled symbolic and scalar time sequences. When compiled, a Honey program is\ntransformed into a static process flow diagram, which is then executed by a\nvirtual machine. Honey's most notable features are: (1) Honey introduces a new,\nefficient and non-prone to error paradigm for defining recursive process flow\ndiagrams from text input with the mindset of imperative programming. Honey's\nspecialized, high level and concise syntax allows fast and easy writing,\nreading and maintenance of complex processing of large scalar symbolic time\nsequence datasets. (2) Honey guarantees programs will be executed similarly on\nstatic or real-time streaming datasets. (3) Honey's IDE includes an interactive\nvisualization tool which allows for an interactive exploration of the\nintermediate and final outputs. This combination enables fast incremental\nprototyping, debugging, monitoring and maintenance of complex programs. (4) In\ncase of large datasets (larger than the available memory), Honey programs can\nbe executed to process input greedily. (5) The graphical structure of a\ncompiled program provides several desirable properties, including distributed\nand/or paralleled execution, memory optimization, and program structure\nvisualization. (6) Honey contains a large library of both common and novel\noperators developed through various research projects. An open source C++\nimplementation of Honey as well as the Honey IDE and the interactive data\nvisualizer are publicly available.\n", "versions": [{"version": "v1", "created": "Sun, 11 Sep 2016 10:18:29 GMT"}], "update_date": "2016-09-13", "authors_parsed": [["Guillame-Bert", "Mathieu", ""]]}, {"id": "1609.03640", "submitter": "EPTCS", "authors": "Ian Mackie (LIX, Ecole Polytechnique)", "title": "Compiling Process Networks to Interaction Nets", "comments": "In Proceedings TERMGRAPH 2016, arXiv:1609.03014", "journal-ref": "EPTCS 225, 2016, pp. 5-14", "doi": "10.4204/EPTCS.225.3", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kahn process networks are a model of computation based on a collection of\nsequential, deterministic processes that communicate by sending messages\nthrough unbounded channels. They are well suited for modelling stream-based\ncomputations, but are in no way restricted to this application. Interaction\nnets are graph rewriting systems that have many interesting properties for\nimplementation. In this paper we show how to encode process networks using\ninteraction nets, where we model both networks and messages in the same\nframework.\n", "versions": [{"version": "v1", "created": "Tue, 13 Sep 2016 00:17:01 GMT"}], "update_date": "2016-09-14", "authors_parsed": [["Mackie", "Ian", "", "LIX, Ecole Polytechnique"]]}, {"id": "1609.03641", "submitter": "EPTCS", "authors": "Ian Mackie (LIX, Ecole Polytechnique, France), Shinya Sato (Ibaraki\n  University, Japan)", "title": "In-place Graph Rewriting with Interaction Nets", "comments": "In Proceedings TERMGRAPH 2016, arXiv:1609.03014", "journal-ref": "EPTCS 225, 2016, pp. 15-24", "doi": "10.4204/EPTCS.225.4", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An algorithm is in-place, or runs in-situ, when it does not need any\nadditional memory to execute beyond a small constant amount. There are many\nalgorithms that are efficient because of this feature, therefore it is an\nimportant aspect of an algorithm. In most programming languages, it is not\nobvious when an algorithm can run in-place, and moreover it is often not clear\nthat the implementation respects that idea. In this paper we study interaction\nnets as a formalism where we can see directly, visually, that an algorithm is\nin-place, and moreover the implementation will respect that it is in-place. Not\nall algorithms can run in-place however. We can nevertheless still use the same\nlanguage, but now we can annotate parts of the algorithm that can run in-place.\nWe suggest an annotation for rules, and give an algorithm to find this\nautomatically through analysis of the interaction rules.\n", "versions": [{"version": "v1", "created": "Tue, 13 Sep 2016 00:17:10 GMT"}], "update_date": "2016-09-14", "authors_parsed": [["Mackie", "Ian", "", "LIX, Ecole Polytechnique, France"], ["Sato", "Shinya", "", "Ibaraki\n  University, Japan"]]}, {"id": "1609.03643", "submitter": "EPTCS", "authors": "Detlef Plump (The University of York, United Kingdom)", "title": "Reasoning about Graph Programs", "comments": "In Proceedings TERMGRAPH 2016, arXiv:1609.03014", "journal-ref": "EPTCS 225, 2016, pp. 35-44", "doi": "10.4204/EPTCS.225.6", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  GP 2 is a non-deterministic programming language for computing by graph\ntransformation. One of the design goals for GP 2 is syntactic and semantic\nsimplicity, to facilitate formal reasoning about programs. In this paper, we\ndemonstrate with four case studies how programmers can prove termination and\npartial correctness of their solutions. We argue that GP 2's graph\ntransformation rules, together with induction on the length of program\nexecutions, provide a convenient framework for program verification.\n", "versions": [{"version": "v1", "created": "Tue, 13 Sep 2016 00:17:26 GMT"}], "update_date": "2016-09-14", "authors_parsed": [["Plump", "Detlef", "", "The University of York, United Kingdom"]]}, {"id": "1609.04233", "submitter": "Roly Perera", "authors": "Roly Perera and Simon J. Gay", "title": "Liveness for Verification", "comments": "2nd Workshop on Live Programming Systems, LIVE 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the use of liveness for interactive program verification for a\nsimple concurrent object language. Our experimental IDE integrates two\n(formally dual) kinds of continuous testing into the development environment:\ncompatibility-checking, which verifies an object's use of other objects, and\ncompliance-checking, which verifies an object's claim to refine the behaviour\nof another object. Source code errors highlighted by the IDE are not static\ntype errors but the reflection back to the source of runtime errors that occur\nin some execution of the system. We demonstrate our approach, and discuss\nopportunities and challenges.\n", "versions": [{"version": "v1", "created": "Wed, 14 Sep 2016 12:16:24 GMT"}], "update_date": "2016-09-15", "authors_parsed": [["Perera", "Roly", ""], ["Gay", "Simon J.", ""]]}, {"id": "1609.05337", "submitter": "Matthew Hammer", "authors": "Dakota Fisher, Matthew A. Hammer, William Byrd, Matthew Might", "title": "miniAdapton: A Minimal Implementation of Incremental Computation in\n  Scheme", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a complete Scheme implementation of miniAdapton, which implements\nthe core functionality of the Adapton system for incremental computation (also\nknown as self-adjusting computation). Like Adapton, miniAdapton allows\nprogrammers to safely combine mutation and memoization. miniAdapton is built on\ntop of an even simpler system, microAdapton. Both miniAdapton and microAdapton\nare designed to be easy to understand, extend, and port to host languages other\nthan Scheme. We also present adapton variables, a new interface in Adapton for\nvariables intended to represent expressions.\n", "versions": [{"version": "v1", "created": "Sat, 17 Sep 2016 13:53:10 GMT"}], "update_date": "2016-09-20", "authors_parsed": [["Fisher", "Dakota", ""], ["Hammer", "Matthew A.", ""], ["Byrd", "William", ""], ["Might", "Matthew", ""]]}, {"id": "1609.05365", "submitter": "Nicolas Laurent", "authors": "Nicolas Laurent and Kim Mens", "title": "Taming Context-Sensitive Languages with Principled Stateful Parsing", "comments": "To appear in SLE 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Historically, true context-sensitive parsing has seldom been applied to\nprogramming languages, due to its inherent complexity. However, many mainstream\nprogramming and markup languages (C, Haskell, Python, XML, and more) possess\ncontext-sensitive features. These features are traditionally handled with\nad-hoc code (e.g., custom lexers), outside of the scope of parsing theory.\n  Current grammar formalisms struggle to express context-sensitive features.\nMost solutions lack context transparency: they make grammars hard to write,\nmaintain and compose by hardwiring context through the entire grammar. Instead,\nwe approach context-sensitive parsing through the idea that parsers may recall\npreviously matched input (or data derived therefrom) in order to make parsing\ndecisions. We make use of mutable parse state to enable this form of recall.\n  We introduce principled stateful parsing as a new transactional discipline\nthat makes state changes transparent to parsing mechanisms such as backtracking\nand memoization. To enforce this discipline, users specify parsers using\nformally specified primitive state manipulation operations.\n  Our solution is available as a parsing library named Autumn. We illustrate\nour solution by implementing some practical context-sensitive grammar features\nsuch as significant whitespace handling and namespace classification.\n", "versions": [{"version": "v1", "created": "Sat, 17 Sep 2016 17:09:42 GMT"}], "update_date": "2016-09-20", "authors_parsed": [["Laurent", "Nicolas", ""], ["Mens", "Kim", ""]]}, {"id": "1609.05687", "submitter": "J\\\"urgen Koslowski", "authors": "Rumyana Neykova and Nobuko Yoshida", "title": "Multiparty Session Actors", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 13, Issue 1 (March 29,\n  2017) lmcs:3227", "doi": "10.23638/LMCS-13(1:17)2017", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Actor coordination armoured with a suitable protocol description language has\nbeen a pressing problem in the actors community. We study the applicability of\nmultiparty session type (MPST) protocols for verification of actor programs. We\nincorporate sessions to actors by introducing minimum additions to the model\nsuch as the notion of actor roles and protocol mailboxes. The framework uses\nScribble, which is a protocol description language based on multiparty session\ntypes. Our programming model supports actor-like syntax and runtime\nverification mechanism guaranteeing communication safety of the participating\nentities. An actor can implement multiple roles in a similar way as an object\ncan implement multiple interfaces. Multiple roles allow for cooperative\ninter-concurrency in a single actor. We demonstrate our framework by designing\nand implementing a session actor library in Python and its runtime verification\nmechanism. Benchmark results demonstrate that the runtime checks induce\nnegligible overhead. We evaluate the applicability of our verification\nframework to specify actor interactions by implementing twelve examples from an\nactor benchmark suit.\n", "versions": [{"version": "v1", "created": "Mon, 19 Sep 2016 12:27:05 GMT"}, {"version": "v2", "created": "Tue, 28 Mar 2017 13:06:15 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Neykova", "Rumyana", ""], ["Yoshida", "Nobuko", ""]]}, {"id": "1609.06382", "submitter": "Mohammad Amin Alipour", "authors": "Mohammad Amin Alipour, Alex Groce, Chaoqiang Zhang, Anahita Sanadaji,\n  and Gokul Caushik", "title": "Finding Model-Checkable Needles in Large Source Code Haystacks: Modular\n  Bug-Finding via Static Analysis and Dynamic Invariant Discovery", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a novel marriage of static and dynamic analysis.\nGiven a large code base with many functions and a mature test suite, we propose\nusing static analysis to find functions 1) with assertions or other evident\ncorrectness properties (e.g., array bounds requirements or pointer access) and\n2) with simple enough control flow and data use to be amenable to\npredicate-abstraction based or bounded model checking without human\nintervention. Because most such functions in realistic software systems in fact\nrely on many input preconditions not specified by the language's type system\n(or annotated in any way), we propose using dynamically discovered invariants\nbased on a program's test suite to characterize likely preconditions, in order\nto reduce the problem of false positives. While providing little in the way of\nverification, this approach may provide an additional quick and highly scalable\nbug-finding method for programs that are usually considered \"too large to model\ncheck.\" We present a simple example showing that the technique can be useful\nfor a more typically \"model-checkable\" code base, even in the presence of a\npoorly designed test suite and bad invariants.\n", "versions": [{"version": "v1", "created": "Tue, 20 Sep 2016 23:22:53 GMT"}], "update_date": "2016-09-22", "authors_parsed": [["Alipour", "Mohammad Amin", ""], ["Groce", "Alex", ""], ["Zhang", "Chaoqiang", ""], ["Sanadaji", "Anahita", ""], ["Caushik", "Gokul", ""]]}, {"id": "1609.06622", "submitter": "Ellen Murphy", "authors": "Ellen Murphy (University of Bath, United Kingdom), Tom Crick (Cardiff\n  Metropolitan University, United Kingdom), James H. Davenport (University of\n  Bath, United Kingdom)", "title": "An Analysis of Introductory Programming Courses at UK Universities", "comments": null, "journal-ref": "The Art, Science, and Engineering of Programming, 2017, Vol. 1,\n  Issue 2, Article 18", "doi": "10.22152/programming-journal.org/2017/1/18", "report-no": null, "categories": "cs.CY cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Context: In the context of exploring the art, science and engineering of\nprogramming, the question of which programming languages should be taught first\nhas been fiercely debated since computer science teaching started in\nuniversities. Failure to grasp programming readily almost certainly implies\nfailure to progress in computer science. Inquiry: What first programming\nlanguages are being taught? There have been regular national-scale surveys in\nAustralia and New Zealand, with the only US survey reporting on a small subset\nof universities. This the first such national survey of universities in the UK.\nApproach: We report the results of the first survey of introductory programming\ncourses (N=80) taught at UK universities as part of their first year computer\nscience (or related) degree programmes, conducted in the first half of 2016. We\nreport on student numbers, programming paradigm, programming languages and\nenvironment/tools used, as well as the underpinning rationale for these\nchoices. Knowledge: The results in this first UK survey indicate a dominance of\nJava at a time when universities are still generally teaching students who are\nnew to programming (and computer science), despite the fact that Python is\nperceived, by the same respondents, to be both easier to teach as well as to\nlearn. Grounding: We compare the results of this survey with a related survey\nconducted since 2010 (as well as earlier surveys from 2001 and 2003) in\nAustralia and New Zealand. Importance: This survey provides a starting point\nfor valuable pedagogic baseline data for the analysis of the art, science and\nengineering of programming, in the context of substantial computer science\ncurriculum reform in UK schools, as well as increasing scrutiny of teaching\nexcellence and graduate employability for UK universities.\n", "versions": [{"version": "v1", "created": "Wed, 21 Sep 2016 16:23:39 GMT"}, {"version": "v2", "created": "Sat, 1 Apr 2017 00:09:47 GMT"}], "update_date": "2017-04-04", "authors_parsed": [["Murphy", "Ellen", "", "University of Bath, United Kingdom"], ["Crick", "Tom", "", "Cardiff\n  Metropolitan University, United Kingdom"], ["Davenport", "James H.", "", "University of\n  Bath, United Kingdom"]]}, {"id": "1609.07546", "submitter": "Xiaoxiao Yang", "authors": "Xiaoxiao Yang and Joost-Pieter Katoen and Huimin Lin and Hao Wu", "title": "Proving Linearizability via Branching Bisimulation", "comments": "In this paper, we conducted the experiment on 13 popular concurrent\n  data structures yielding promising results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linearizability and progress properties are key correctness notions for\nconcurrent objects. However, model checking linearizability has suffered from\nthe PSPACE-hardness of the trace inclusion problem. This paper proposes to\nexploit branching bisimulation, a fundamental semantic equivalence relation\ndeveloped for process algebras which can be computed efficiently, in checking\nthese properties. A quotient construction is provided which results in huge\nstate space reductions. We confirm the advantages of the proposed approach on\nmore than a dozen benchmark problems.\n", "versions": [{"version": "v1", "created": "Sat, 24 Sep 2016 01:03:34 GMT"}, {"version": "v2", "created": "Tue, 27 Sep 2016 04:36:50 GMT"}, {"version": "v3", "created": "Wed, 28 Sep 2016 00:36:27 GMT"}, {"version": "v4", "created": "Thu, 29 Sep 2016 00:58:00 GMT"}, {"version": "v5", "created": "Fri, 30 Sep 2016 02:42:55 GMT"}], "update_date": "2016-10-03", "authors_parsed": [["Yang", "Xiaoxiao", ""], ["Katoen", "Joost-Pieter", ""], ["Lin", "Huimin", ""], ["Wu", "Hao", ""]]}, {"id": "1609.09709", "submitter": "Francesco Mazzoli", "authors": "Francesco Mazzoli, Andreas Abel", "title": "Type checking through unification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we describe how to leverage higher-order unification to type\ncheck a dependently typed language with meta-variables. The literature usually\npresents the unification algorithm as a standalone component, however the need\nto check definitional equality of terms while type checking gives rise to a\ntight interplay between type checking and unification. This interplay is a\nmajor source of complexity in the type-checking algorithm for existing\ndependently typed programming languages. We propose an algorithm that encodes a\ntype-checking problem entirely in the form of unification constraints, reducing\nthe complexity of the type-checking code by taking advantage of higher order\nunification, which is already part of the implementation of many dependently\ntyped languages.\n", "versions": [{"version": "v1", "created": "Fri, 30 Sep 2016 13:03:25 GMT"}], "update_date": "2016-10-03", "authors_parsed": [["Mazzoli", "Francesco", ""], ["Abel", "Andreas", ""]]}, {"id": "1609.09718", "submitter": "Larisa Safina", "authors": "Alexey Bandura, Nikita Kurilenko, Manuel Mazzara, Victor Rivera,\n  Larisa Safina, Alexander Tchitchigin", "title": "Jolie Community on the Rise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Jolie is a programming language that follows the microservices paradigm. As\nan open source project, it has built a community of developers worldwide - both\nin the industry as well as in academia - taken care of the development,\ncontinuously improved its usability, and therefore broadened the adoption. In\nthis paper, we present some of the most recent results and work in progress\nthat has been made within our research team.\n", "versions": [{"version": "v1", "created": "Fri, 30 Sep 2016 13:25:05 GMT"}], "update_date": "2016-10-03", "authors_parsed": [["Bandura", "Alexey", ""], ["Kurilenko", "Nikita", ""], ["Mazzara", "Manuel", ""], ["Rivera", "Victor", ""], ["Safina", "Larisa", ""], ["Tchitchigin", "Alexander", ""]]}, {"id": "1609.09783", "submitter": "Paul-Andr\\'e Melli\\`es", "authors": "Paul-Andr\\'e Melli\\`es", "title": "Five Basic Concepts of Axiomatic Rewriting Theory", "comments": "6 pages, 4 figures, Invited talk at the International Workshop on\n  Confluence, Obergurgl 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL math.CT math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this invited talk, I will review five basic concepts of Axiomatic\nRewriting Theory, an axiomatic and diagrammatic theory of rewriting started 25\nyears ago in a LICS paper with Georges Gonthier and Jean-Jacques L\\'evy, and\ndeveloped along the subsequent years into a full-fledged 2-dimensional theory\nof causality and residuation in rewriting. I will give a contemporary view on\nthe theory, informed by my later work on categorical semantics and\nhigher-dimensional algebra, and also indicate a number of current research\ndirections in the field.\n", "versions": [{"version": "v1", "created": "Tue, 27 Sep 2016 18:47:22 GMT"}], "update_date": "2016-10-03", "authors_parsed": [["Melli\u00e8s", "Paul-Andr\u00e9", ""]]}]