[{"id": "1105.0069", "submitter": "Guido Salvaneschi", "authors": "Guido Salvaneschi, Carlo Ghezzi, Matteo Pradella", "title": "Context-Oriented Programming: A Programming Paradigm for Autonomic\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic software adaptability is one of the central features leveraged by\nautonomic computing. However, developing software that changes its behavior at\nrun time adapting to the operational conditions is a challenging task. Several\napproaches have been proposed in the literature to attack this problem at\ndifferent and complementary abstraction levels: software architecture,\nmiddleware, and programming level. We focus on the support that ad-hoc\nprogramming language constructs may provide to support dynamically adaptive\nbehaviors. We introduce context-oriented programming languages and we present a\nframework that positions the supported paradigm in the MAPE-K autonomic loop.\nWe discuss the advantages of using context-oriented programming languages\ninstead of other mainstream approaches based on dynamic aspect oriented\nprogramming languages and present a case study that shows how the proposed\nprogramming style naturally fits dynamic adaptation requirements. Finally, we\ndiscuss some known problems and outline a number of open research challenges.\n", "versions": [{"version": "v1", "created": "Sat, 30 Apr 2011 10:23:27 GMT"}, {"version": "v2", "created": "Fri, 30 Mar 2012 13:24:21 GMT"}], "update_date": "2012-04-02", "authors_parsed": [["Salvaneschi", "Guido", ""], ["Ghezzi", "Carlo", ""], ["Pradella", "Matteo", ""]]}, {"id": "1105.0106", "submitter": "David Van Horn", "authors": "Sam Tobin-Hochstadt and David Van Horn", "title": "Semantic Solutions to Program Analysis Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Problems in program analysis can be solved by developing novel program\nsemantics and deriving abstractions conventionally. For over thirty years,\nhigher-order program analysis has been sold as a hard problem. Its solutions\nhave required ingenuity and complex models of approximation. We claim that this\ndifficulty is due to premature focus on abstraction and propose a new approach\nthat emphasizes semantics. Its simplicity enables new analyses that are beyond\nthe current state of the art.\n", "versions": [{"version": "v1", "created": "Sat, 30 Apr 2011 18:26:49 GMT"}], "update_date": "2011-05-03", "authors_parsed": [["Tobin-Hochstadt", "Sam", ""], ["Van Horn", "David", ""]]}, {"id": "1105.0322", "submitter": "Toshio Fukui", "authors": "Toshio Fukui", "title": "A Computational Model for the Direct Execution of General Specifications\n  with Multi-way Constraints", "comments": "21 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a computational model for the direct execution of\ngeneral specifications with multi-way constraints. Although this computational\nmodel has a similar structure to existing constraint programming models, it is\nnot meant for solving constraint satisfaction problems but rather for the\nsimulation of social systems and to continue to execute assigned processes.\nBecause of this similar structure, it is applicable to the spectrum of the\nconstraint solver, which is purple in this model. Essentially, it is a\ntechnology that can speed up the construction of large-scale network systems.\nThis model can be efficiently executed to directly describe design content in a\nsimple way.\n", "versions": [{"version": "v1", "created": "Mon, 2 May 2011 13:33:57 GMT"}, {"version": "v2", "created": "Sun, 8 Jan 2012 06:41:42 GMT"}, {"version": "v3", "created": "Wed, 20 Feb 2013 02:23:14 GMT"}, {"version": "v4", "created": "Mon, 4 Mar 2013 02:35:20 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Fukui", "Toshio", ""]]}, {"id": "1105.0966", "submitter": "Aaron Turon", "authors": "Aaron Turon and Mitchell Wand", "title": "A resource analysis of the pi-calculus", "comments": "Preliminary version for MFPS 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a new treatment of the pi-calculus based on the semantic theory of\nseparation logic, continuing a research program begun by Hoare and O'Hearn.\nUsing a novel resource model that distinguishes between public and private\nownership, we refactor the operational semantics so that sending, receiving,\nand allocating are commands that influence owned resources. These ideas lead\nnaturally to two denotational models: one for safety and one for liveness. Both\nmodels are fully abstract for the corresponding observables, but more\nimportantly both are very simple. The close connections with the model theory\nof separation logic (in particular, with Brookes's action trace model) give\nrise to a logic of processes and resources.\n", "versions": [{"version": "v1", "created": "Thu, 5 May 2011 01:29:17 GMT"}], "update_date": "2011-05-06", "authors_parsed": [["Turon", "Aaron", ""], ["Wand", "Mitchell", ""]]}, {"id": "1105.1743", "submitter": "David Van Horn", "authors": "David Van Horn and Matthew Might", "title": "Abstracting Abstract Machines: A Systematic Approach to Higher-Order\n  Program Analysis", "comments": "Communications of the ACM, Research Highlight", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictive models are fundamental to engineering reliable software systems.\nHowever, designing conservative, computable approximations for the behavior of\nprograms (static analyses) remains a difficult and error-prone process for\nmodern high-level programming languages. What analysis designers need is a\nprincipled method for navigating the gap between semantics and analytic models:\nanalysis designers need a method that tames the interaction of complex\nlanguages features such as higher-order functions, recursion, exceptions,\ncontinuations, objects and dynamic allocation.\n  We contribute a systematic approach to program analysis that yields novel and\ntransparently sound static analyses. Our approach relies on existing\nderivational techniques to transform high-level language semantics into\nlow-level deterministic state-transition systems (with potentially infinite\nstate spaces). We then perform a series of simple machine refactorings to\nobtain a sound, computable approximation, which takes the form of a\nnon-deterministic state-transition systems with finite state spaces. The\napproach scales up uniformly to enable program analysis of realistic language\nfeatures, including higher-order functions, tail calls, conditionals, side\neffects, exceptions, first-class continuations, and even garbage collection.\n", "versions": [{"version": "v1", "created": "Mon, 9 May 2011 17:57:26 GMT"}], "update_date": "2011-05-10", "authors_parsed": [["Van Horn", "David", ""], ["Might", "Matthew", ""]]}, {"id": "1105.1985", "submitter": "Benedikt Meurer", "authors": "Benedikt Meurer", "title": "A Step-indexed Semantic Model of Types for the Call-by-Name Lambda\n  Calculus", "comments": "5 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Step-indexed semantic models of types were proposed as an alternative to\npurely syntactic safety proofs using subject-reduction. Building upon the work\nby Appel and others, we introduce a generalized step-indexed model for the\ncall-by-name lambda calculus. We also show how to prove type safety of general\nrecursion in our call-by-name model.\n", "versions": [{"version": "v1", "created": "Tue, 10 May 2011 15:59:09 GMT"}, {"version": "v2", "created": "Wed, 11 May 2011 08:38:07 GMT"}, {"version": "v3", "created": "Sun, 15 May 2011 11:24:39 GMT"}], "update_date": "2011-05-17", "authors_parsed": [["Meurer", "Benedikt", ""]]}, {"id": "1105.2279", "submitter": "Frank Winter", "authors": "Frank Winter", "title": "Accelerating QDP++ using GPUs", "comments": "6 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": "Edinburgh 2011/17", "categories": "hep-lat cs.DC cs.PL physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphic Processing Units (GPUs) are getting increasingly important as target\narchitectures in scientific High Performance Computing (HPC). NVIDIA\nestablished CUDA as a parallel computing architecture controlling and making\nuse of the compute power of GPUs. CUDA provides sufficient support for C++\nlanguage elements to enable the Expression Template (ET) technique in the\ndevice memory domain. QDP++ is a C++ vector class library suited for quantum\nfield theory which provides vector data types and expressions and forms the\nbasis of the lattice QCD software suite Chroma. In this work accelerating QDP++\nexpression evaluation to a GPU was successfully implemented leveraging the ET\ntechnique and using Just-In-Time (JIT) compilation. The Portable Expression\nTemplate Engine (PETE) and the C API for CUDA kernel arguments were used to\nbuild the bridge between host and device memory domains. This provides the\npossibility to accelerate Chroma routines to a GPU which are typically not\nsubject to special optimisation. As an application example a smearing routine\nwas accelerated to execute on a GPU. A significant speed-up compared to normal\nCPU execution could be measured.\n", "versions": [{"version": "v1", "created": "Wed, 11 May 2011 19:16:14 GMT"}], "update_date": "2011-05-12", "authors_parsed": [["Winter", "Frank", ""]]}, {"id": "1105.2554", "submitter": "Lars Bergstrom", "authors": "Sven Auhagen, Lars Bergstrom, Matthew Fluet, John Reppy", "title": "Garbage Collection for Multicore NUMA Machines", "comments": "To appear in Memory Systems Performance and Correctness 2011 (MSPC11)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern high-end machines feature multiple processor packages, each of which\ncontains multiple independent cores and integrated memory controllers connected\ndirectly to dedicated physical RAM. These packages are connected via a shared\nbus, creating a system with a heterogeneous memory hierarchy. Since this shared\nbus has less bandwidth than the sum of the links to memory, aggregate memory\nbandwidth is higher when parallel threads all access memory local to their\nprocessor package than when they access memory attached to a remote package.\nThis bandwidth limitation has traditionally limited the scalability of modern\nfunctional language implementations, which seldom scale well past 8 cores, even\non small benchmarks.\n  This work presents a garbage collector integrated with our strict, parallel\nfunctional language implementation, Manticore, and shows that it scales\neffectively on both a 48-core AMD Opteron machine and a 32-core Intel Xeon\nmachine.\n", "versions": [{"version": "v1", "created": "Thu, 12 May 2011 19:41:34 GMT"}], "update_date": "2011-05-13", "authors_parsed": [["Auhagen", "Sven", ""], ["Bergstrom", "Lars", ""], ["Fluet", "Matthew", ""], ["Reppy", "John", ""]]}, {"id": "1105.2576", "submitter": "Adam Koprowski", "authors": "Adam Koprowski (MLstate, Paris, France), Henri Binsztok (MLstate,\n  Paris, France)", "title": "TRX: A Formally Verified Parser Interpreter", "comments": "26 pages, LMCS", "journal-ref": "Logical Methods in Computer Science, Volume 7, Issue 2 (June 24,\n  2011) lmcs:686", "doi": "10.2168/LMCS-7(2:18)2011", "report-no": null, "categories": "cs.LO cs.FL cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parsing is an important problem in computer science and yet surprisingly\nlittle attention has been devoted to its formal verification. In this paper, we\npresent TRX: a parser interpreter formally developed in the proof assistant\nCoq, capable of producing formally correct parsers. We are using parsing\nexpression grammars (PEGs), a formalism essentially representing recursive\ndescent parsing, which we consider an attractive alternative to context-free\ngrammars (CFGs). From this formalization we can extract a parser for an\narbitrary PEG grammar with the warranty of total correctness, i.e., the\nresulting parser is terminating and correct with respect to its grammar and the\nsemantics of PEGs; both properties formally proven in Coq.\n", "versions": [{"version": "v1", "created": "Thu, 12 May 2011 20:43:38 GMT"}, {"version": "v2", "created": "Wed, 22 Jun 2011 20:51:51 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Koprowski", "Adam", "", "MLstate, Paris, France"], ["Binsztok", "Henri", "", "MLstate,\n  Paris, France"]]}, {"id": "1105.3414", "submitter": "Jia-Huai  You", "authors": "Guohua Liu and Jia-Huai You", "title": "Relating Weight Constraint and Aggregate Programs: Semantics and\n  Representation", "comments": "To appear in Theory and Practice of Logic Programming (TPLP), 2011.\n  30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weight constraint and aggregate programs are among the most widely used logic\nprograms with constraints. In this paper, we relate the semantics of these two\nclasses of programs, namely the stable model semantics for weight constraint\nprograms and the answer set semantics based on conditional satisfaction for\naggregate programs. Both classes of programs are instances of logic programs\nwith constraints, and in particular, the answer set semantics for aggregate\nprograms can be applied to weight constraint programs. We show that the two\nsemantics are closely related. First, we show that for a broad class of weight\nconstraint programs, called strongly satisfiable programs, the two semantics\ncoincide. When they disagree, a stable model admitted by the stable model\nsemantics may be circularly justified. We show that the gap between the two\nsemantics can be closed by transforming a weight constraint program to a\nstrongly satisfiable one, so that no circular models may be generated under the\ncurrent implementation of the stable model semantics. We further demonstrate\nthe close relationship between the two semantics by formulating a\ntransformation from weight constraint programs to logic programs with nested\nexpressions which preserves the answer set semantics. Our study on the\nsemantics leads to an investigation of a methodological issue, namely the\npossibility of compact representation of aggregate programs by weight\nconstraint programs. We show that almost all standard aggregates can be encoded\nby weight constraints compactly. This makes it possible to compute the answer\nsets of aggregate programs using the ASP solvers for weight constraint\nprograms. This approach is compared experimentally with the ones where\naggregates are handled more explicitly, which show that the weight constraint\nencoding of aggregates enables a competitive approach to answer set computation\nfor aggregate programs.\n", "versions": [{"version": "v1", "created": "Mon, 16 May 2011 05:36:39 GMT"}], "update_date": "2011-05-18", "authors_parsed": [["Liu", "Guohua", ""], ["You", "Jia-Huai", ""]]}, {"id": "1105.3843", "submitter": "James Hanlon", "authors": "James Hanlon and Simon J. Hollis", "title": "Fast Distributed Process Creation with the XMOS XS1 Architecture", "comments": "To appear in Communicating Process Architectures (CPA) 2011, 14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The provision of mechanisms for processor allocation in current distributed\nparallel programming models is very limited. This makes difficult, or even\nprohibits, the expression of a large class of programs which require a run-time\nassessment of their required resources. This includes programs whose structure\nis irregular, composite or unbounded. Efficient allocation of processors\nrequires a process creation mechanism able to initiate and terminate remote\ncomputations quickly. This paper presents the design, demonstration and\nanalysis of an explicit mechanism to do this, implemented on the XMOS XS1\narchitecture, as a foundation for a more dynamic scheme. It shows that process\ncreation can be made efficient so that it incurs only a fractional overhead of\nthe total runtime and that it can be combined naturally with recursion to\nenable rapid distribution of computations over a system.\n", "versions": [{"version": "v1", "created": "Thu, 19 May 2011 11:18:46 GMT"}], "update_date": "2011-05-20", "authors_parsed": [["Hanlon", "James", ""], ["Hollis", "Simon J.", ""]]}, {"id": "1105.6118", "submitter": "Amani Tahat", "authors": "Amani Tahat, Maurice HT Ling", "title": "Mapping Relational Operations onto Hypergraph Model", "comments": "21 pages", "journal-ref": "The Python Papers 6(1): 4,2011", "doi": null, "report-no": null, "categories": "cs.DB cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The relational model is the most commonly used data model for storing large\ndatasets, perhaps due to the simplicity of the tabular format which had\nrevolutionized database management systems. However, many real world objects\nare recursive and associative in nature which makes storage in the relational\nmodel difficult. The hypergraph model is a generalization of a graph model,\nwhere each hypernode can be made up of other nodes or graphs and each hyperedge\ncan be made up of one or more edges. It may address the recursive and\nassociative limitations of relational model. However, the hypergraph model is\nnon-tabular; thus, loses the simplicity of the relational model. In this study,\nwe consider the means to convert a relational model into a hypergraph model in\ntwo layers. At the bottom layer, each relational tuple can be considered as a\nstar graph centered where the primary key node is surrounded by non-primary key\nattributes. At the top layer, each tuple is a hypernode, and a relation is a\nset of hypernodes. We presented a reference implementation of relational\noperators (project, rename, select, inner join, natural join, left join, right\njoin, outer join and Cartesian join) on a hypergraph model. Using a simple\nexample, we demonstrate that a relation and relational operators can be\nimplemented on this hypergraph model.\n", "versions": [{"version": "v1", "created": "Mon, 30 May 2011 21:34:51 GMT"}], "update_date": "2011-06-01", "authors_parsed": [["Tahat", "Amani", ""], ["Ling", "Maurice HT", ""]]}]