[{"id": "1006.0030", "submitter": "Marco Gaboardi", "authors": "Marco Gaboardi and Jean-Yves Marion and Simona Ronchi Della Rocca", "title": "An Implicit Characterization of PSPACE", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a type system for an extension of lambda calculus with a\nconditional construction, named STAB, that characterizes the PSPACE class. This\nsystem is obtained by extending STA, a type assignment for lambda-calculus\ninspired by Lafont's Soft Linear Logic and characterizing the PTIME class. We\nextend STA by means of a ground type and terms for booleans and conditional.\nThe key issue in the design of the type system is to manage the contexts in the\nrule for conditional in an additive way. Thanks to this rule, we are able to\nprogram polynomial time Alternating Turing Machines. From the well-known result\nAPTIME = PSPACE, it follows that STAB is complete for PSPACE. Conversely,\ninspired by the simulation of Alternating Turing machines by means of\nDeterministic Turing machine, we introduce a call-by-name evaluation machine\nwith two memory devices in order to evaluate programs in polynomial space. As\nfar as we know, this is the first characterization of PSPACE that is based on\nlambda calculus and light logics.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2010 22:57:33 GMT"}], "update_date": "2010-06-02", "authors_parsed": [["Gaboardi", "Marco", ""], ["Marion", "Jean-Yves", ""], ["Della Rocca", "Simona Ronchi", ""]]}, {"id": "1006.1413", "submitter": "EPTCS", "authors": "Davide Ancona (DISI - University of Genova), Giovanni Lagorio (DISI -\n  University of Genova)", "title": "Coinductive subtyping for abstract compilation of object-oriented\n  languages into Horn formulas", "comments": null, "journal-ref": "EPTCS 25, 2010, pp. 214-230", "doi": "10.4204/EPTCS.25.20", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent work we have shown how it is possible to define very precise type\nsystems for object-oriented languages by abstractly compiling a program into a\nHorn formula f. Then type inference amounts to resolving a certain goal w.r.t.\nthe coinductive (that is, the greatest) Herbrand model of f.\n  Type systems defined in this way are idealized, since in the most interesting\ninstantiations both the terms of the coinductive Herbrand universe and goal\nderivations cannot be finitely represented. However, sound and quite expressive\napproximations can be implemented by considering only regular terms and\nderivations. In doing so, it is essential to introduce a proper subtyping\nrelation formalizing the notion of approximation between types.\n  In this paper we study a subtyping relation on coinductive terms built on\nunion and object type constructors. We define an interpretation of types as set\nof values induced by a quite intuitive relation of membership of values to\ntypes, and prove that the definition of subtyping is sound w.r.t. subset\ninclusion between type interpretations. The proof of soundness has allowed us\nto simplify the notion of contractive derivation and to discover that the\npreviously given definition of subtyping did not cover all possible\nrepresentations of the empty type.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2010 00:43:25 GMT"}], "update_date": "2010-06-09", "authors_parsed": [["Ancona", "Davide", "", "DISI - University of Genova"], ["Lagorio", "Giovanni", "", "DISI -\n  University of Genova"]]}, {"id": "1006.1497", "submitter": "Frank Raiser", "authors": "Frank Raiser and Thom Fr\\\"uhwirth", "title": "Analyzing Graph Transformation Systems through Constraint Handling Rules", "comments": "45 pages, 11 figures, to appear in Theory and Practice of Logic\n  Programming (TPLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph transformation systems (GTS) and constraint handling rules (CHR) are\nnon-deterministic rule-based state transition systems. CHR is well-known for\nits powerful confluence and program equivalence analyses, for which we provide\nthe basis in this work to apply them to GTS. We give a sound and complete\nembedding of GTS in CHR, investigate confluence of an embedded GTS, and provide\na program equivalence analysis for GTS via the embedding. The results confirm\nthe suitability of CHR-based program analyses for other formalisms embedded in\nCHR.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2010 09:25:33 GMT"}, {"version": "v2", "created": "Tue, 15 Jun 2010 07:25:59 GMT"}], "update_date": "2010-06-16", "authors_parsed": [["Raiser", "Frank", ""], ["Fr\u00fchwirth", "Thom", ""]]}, {"id": "1006.1549", "submitter": "Jaros{\\l}aw Miszczak", "authors": "P. Gawron and J. Klamka and J. A. Miszczak and R. Winiarczyk", "title": "Extending scientific computing system with structural quantum\n  programming capabilities", "comments": null, "journal-ref": "Bull. Pol. Acad. Sci., Technical Sciences, Vol. 58, No. 1 (2010)", "doi": "10.2478/v10175-010-0008-4", "report-no": null, "categories": "cs.PL quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a basic high-level structures used for developing quantum\nprogramming languages. The presented structures are commonly used in many\nexisting quantum programming languages and we use quantum pseudo-code based on\nQCL quantum programming language to describe them. We also present the\nimplementation of introduced structures in GNU Octave language for scientific\ncomputing. Procedures used in the implementation are available as a package\nquantum-octave, providing a library of functions, which facilitates the\nsimulation of quantum computing. This package allows also to incorporate\nhigh-level programming concepts into the simulation in GNU Octave and Matlab.\nAs such it connects features unique for high-level quantum programming\nlanguages, with the full palette of efficient computational routines commonly\navailable in modern scientific computing systems. To present the major features\nof the described package we provide the implementation of selected quantum\nalgorithms. We also show how quantum errors can be taken into account during\nthe simulation of quantum algorithms using quantum-octave package. This is\npossible thanks to the ability to operate on density matrices.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2010 13:23:39 GMT"}], "update_date": "2011-10-10", "authors_parsed": [["Gawron", "P.", ""], ["Klamka", "J.", ""], ["Miszczak", "J. A.", ""], ["Winiarczyk", "R.", ""]]}, {"id": "1006.1689", "submitter": "EPTCS", "authors": "Tom Van Cutsem (Vrije Universiteit Brussel), Mark Miller (Google)", "title": "Proceedings First International Workshop on Decentralized Coordination\n  of Distributed Processes", "comments": null, "journal-ref": "EPTCS 27, 2010", "doi": "10.4204/EPTCS.27", "report-no": null, "categories": "cs.DC cs.CR cs.NI cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the papers presented at the 1st International Workshop\non \"Decentralized Coordination of Distributed Processes\", DCDP 2010, held in\nAmsterdam, The Netherlands on June 10th, 2010 in conjunction with the 5th\nInternational Federated Conferences on Distributed Computing Techniques,\nDisCoTec 2010. The central theme of the workshop is the decentralized\ncoordination of distributed processes. Decentralized: there is no single\nauthority in the network that everything is vulnerable to. Coordinated:\nprocesses need to cooperate to achieve meaningful results, potentially in the\nface of mutual suspicion. Distributed: processes are separated by a potentially\nunreliable network.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2010 02:39:07 GMT"}], "update_date": "2010-06-10", "authors_parsed": [["Van Cutsem", "Tom", "", "Vrije Universiteit Brussel"], ["Miller", "Mark", "", "Google"]]}, {"id": "1006.2816", "submitter": "Jenny Blight", "authors": "Santosh Kumar Pani and Priya Arundhati", "title": "An approach to find dynamic slice for C++ Program", "comments": "Submitted to Journal of Computer Science and Engineering, see\n  http://sites.google.com/site/jcseuk/volume-1-issue-1-may-2010", "journal-ref": "Journal of Computer Science and Engineering, Volume 1, Issue 1,\n  p72-76, May 2010", "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Object-oriented programming has been considered a most promising method in\nprogram development and maintenance. An important feature of object-oriented\nprograms (OOPs) is their reusability which can be achieved through the\ninheritance of classes or reusable components.Dynamic program slicing is an\neffective technique for narrowing the errors to the relevant parts of a program\nwhen debugging. Given a slicing criterion, the dynamic slice contains only\nthose statements that actually affect the variables in the slicing criterion.\nThis paper proposes a method to dynamically slice object-oriented (00) programs\nbased on dependence analysis. It uses the Control Dependency Graph for object\nprogram and other static information to reduce the information to be traced\nduring program execution. In this paper we present a method to find the dynamic\nSlice of object oriented programs where we are finding the slices for object\nand in case of function overloading.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2010 19:42:24 GMT"}], "update_date": "2010-06-15", "authors_parsed": [["Pani", "Santosh Kumar", ""], ["Arundhati", "Priya", ""]]}, {"id": "1006.2993", "submitter": "EPTCS", "authors": "Luca Cardelli (Microsoft Research)", "title": "Two-Domain DNA Strand Displacement", "comments": null, "journal-ref": "EPTCS 26, 2010, pp. 47-61", "doi": "10.4204/EPTCS.26.5", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the computing power of a restricted class of DNA strand\ndisplacement structures: those that are made of double strands with nicks\n(interruptions) in the top strand. To preserve this structural invariant, we\nimpose restrictions on the single strands they interact with: we consider only\ntwo-domain single strands consisting of one toehold domain and one recognition\ndomain. We study fork and join signal-processing gates based on these\nstructures, and we show that these systems are amenable to formalization and to\nmechanical verification.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2010 01:16:25 GMT"}], "update_date": "2010-06-16", "authors_parsed": [["Cardelli", "Luca", "", "Microsoft Research"]]}, {"id": "1006.3035", "submitter": "Shay Cohen", "authors": "Shay B. Cohen, Robert J. Simmons, Noah A. Smith", "title": "Products of Weighted Logic Programs", "comments": null, "journal-ref": "TLP 11 (2-3): 263-296, 2011", "doi": "10.1017/S1471068410000529", "report-no": null, "categories": "cs.AI cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weighted logic programming, a generalization of bottom-up logic programming,\nis a well-suited framework for specifying dynamic programming algorithms. In\nthis setting, proofs correspond to the algorithm's output space, such as a path\nthrough a graph or a grammatical derivation, and are given a real-valued score\n(often interpreted as a probability) that depends on the real weights of the\nbase axioms used in the proof. The desired output is a function over all\npossible proofs, such as a sum of scores or an optimal score. We describe the\nPRODUCT transformation, which can merge two weighted logic programs into a new\none. The resulting program optimizes a product of proof scores from the\noriginal programs, constituting a scoring function known in machine learning as\na ``product of experts.'' Through the addition of intuitive constraining side\nconditions, we show that several important dynamic programming algorithms can\nbe derived by applying PRODUCT to weighted logic programs corresponding to\nsimpler weighted logic programs. In addition, we show how the computation of\nKullback-Leibler divergence, an information-theoretic measure, can be\ninterpreted using PRODUCT.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2010 17:22:55 GMT"}], "update_date": "2012-08-15", "authors_parsed": [["Cohen", "Shay B.", ""], ["Simmons", "Robert J.", ""], ["Smith", "Noah A.", ""]]}, {"id": "1006.3039", "submitter": "Martin Sulzmann", "authors": "Edmund S. L. Lam and Martin Sulzmann", "title": "Concurrent Goal-Based Execution of Constraint Handling Rules", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  (To appear in Theory and Practice of Logic Programming (TPLP)) We introduce a\nsystematic, concurrent execution scheme for Constraint Handling Rules (CHR)\nbased on a previously proposed sequential goal-based CHR semantics. We\nestablish strong correspondence results to the abstract CHR semantics, thus\nguaranteeing that any answer in the concurrent, goal-based CHR semantics is\nreproducible in the abstract CHR semantics. Our work provides the foundation to\nobtain efficient, parallel CHR execution schemes.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2010 17:44:15 GMT"}, {"version": "v2", "created": "Sun, 20 Jun 2010 19:23:06 GMT"}], "update_date": "2010-06-22", "authors_parsed": [["Lam", "Edmund S. L.", ""], ["Sulzmann", "Martin", ""]]}, {"id": "1006.3159", "submitter": "Alexandre Chapoutot", "authors": "Olivier Bouissou (LMeASI), Yassamine Seladji (LMeASI), Alexandre\n  Chapoutot (LIP6)", "title": "Abstract Fixpoint Computations with Numerical Acceleration Methods", "comments": null, "journal-ref": "Electronic Notes in Theoretical Computer Science (2010) 29-42", "doi": "10.1016/j.entcs.2010.09.004", "report-no": null, "categories": "cs.PL cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Static analysis by abstract interpretation aims at automatically proving\nproperties of computer programs. To do this, an over-approximation of program\nsemantics, defined as the least fixpoint of a system of semantic equations,\nmust be computed. To enforce the convergence of this computation, widening\noperator is used but it may lead to coarse results. We propose a new method to\naccelerate the computation of this fixpoint by using standard techniques of\nnumerical analysis. Our goal is to automatically and dynamically adapt the\nwidening operator in order to maintain precision.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2010 08:39:12 GMT"}], "update_date": "2013-05-02", "authors_parsed": [["Bouissou", "Olivier", "", "LMeASI"], ["Seladji", "Yassamine", "", "LMeASI"], ["Chapoutot", "Alexandre", "", "LIP6"]]}, {"id": "1006.3215", "submitter": "Roland Yap", "authors": "Yuanlin Zhang and Roland H.C. Yap", "title": "Solving Functional Constraints by Variable Substitution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Functional constraints and bi-functional constraints are an important\nconstraint class in Constraint Programming (CP) systems, in particular for\nConstraint Logic Programming (CLP) systems. CP systems with finite domain\nconstraints usually employ CSP-based solvers which use local consistency, for\nexample, arc consistency. We introduce a new approach which is based instead on\nvariable substitution. We obtain efficient algorithms for reducing systems\ninvolving functional and bi-functional constraints together with other\nnon-functional constraints. It also solves globally any CSP where there exists\na variable such that any other variable is reachable from it through a sequence\nof functional constraints. Our experiments on random problems show that\nvariable elimination can significantly improve the efficiency of solving\nproblems with functional constraints.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2010 13:49:16 GMT"}], "update_date": "2010-06-17", "authors_parsed": [["Zhang", "Yuanlin", ""], ["Yap", "Roland H. C.", ""]]}, {"id": "1006.3448", "submitter": "Graham Kirby", "authors": "Alan Dearle, Graham Kirby, Ron Morrison", "title": "Orthogonal Persistence Revisited", "comments": "2nd International Conference on Object Databases (ICOODB 2009),\n  Zurich, Switzerland. pp. 1-22", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The social and economic importance of large bodies of programs and data that\nare potentially long-lived has attracted much attention in the commercial and\nresearch communities. Here we concentrate on a set of methodologies and\ntechnologies called persistent programming. In particular we review programming\nlanguage support for the concept of orthogonal persistence, a technique for the\nuniform treatment of objects irrespective of their types or longevity. While\nresearch in persistent programming has become unfashionable, we show how the\nconcept is beginning to appear as a major component of modern systems. We\nrelate these attempts to the original principles of orthogonal persistence and\ngive a few hints about how the concept may be utilised in the future.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2010 12:35:55 GMT"}], "update_date": "2010-06-18", "authors_parsed": [["Dearle", "Alan", ""], ["Kirby", "Graham", ""], ["Morrison", "Ron", ""]]}, {"id": "1006.3481", "submitter": "Graham Kirby", "authors": "Graham Kirby", "title": "Reflection and Hyper-Programming in Persistent Programming Systems", "comments": "PhD Thesis, University of St Andrews. Supervisor: R. Morrison. (1992)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The work presented in this thesis seeks to improve programmer productivity in\nthe following ways:\n  - by reducing the amount of code that has to be written to construct an\napplication;\n  - by increasing the reliability of the code written; and\n  - by improving the programmer's understanding of the persistent environment\nin which applications are constructed. Two programming techniques that may be\nused to pursue these goals in a persistent environment are type-safe linguistic\nreflection and hyper-programming. The first provides a mechanism by which the\nprogrammer can write generators that, when executed, produce new program\nrepresentations. This allows the specification of programs that are highly\ngeneric yet depend in non-trivial ways on the types of the data on which they\noperate. Genericity promotes software reuse which in turn reduces the amount of\nnew code that has to be written. Hyper-programming allows a source program to\ncontain links to data items in the persistent store. This improves program\nreliability by allowing certain program checking to be performed earlier than\nis otherwise possible. It also reduces the amount of code written by permitting\ndirect links to data in the place of textual descriptions. Both techniques\ncontribute to the understanding of the persistent environment through\nsupporting the implementation of store browsing tools and allowing source\nrepresentations to be associated with all executable programs in the persistent\nstore. This thesis describes in detail the structure of type-safe linguistic\nreflection and hyper-programming, their benefits in the persistent context, and\na suite of programming tools that support reflective programming and\nhyper-programming. These tools may be used in conjunction to allow reflection\nover hyper-program representations. The implementation of the tools is\ndescribed.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2010 14:37:51 GMT"}], "update_date": "2010-06-18", "authors_parsed": [["Kirby", "Graham", ""]]}, {"id": "1006.4304", "submitter": "Mauricio Alba-Castro", "authors": "Mauricio Alba-Castro (1) (2), Mar\\'ia Alpuente (1), and Santiago\n  Escobar (1) ((1) ELP-DSIC, U. Polit\\'ecnica de Valencia, Spain.\n  alpuente,sescobar@dsic.upv.es. (2) U. Aut\\'onoma de Manizales, Colombia.\n  malba@autonoma.edu.co)", "title": "Abstract Certification of Global Non-Interference in Rewriting Logic", "comments": "26 pages. ACM class (full): D.2.4 [Software Engineering]:\n  Software/Program Verification---Formal Methods; F.3.2 [Logics and Meaning of\n  Programs]: Semantics of Programming Languages---Program Analysis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-interference is a semantic program property that assigns confidentiality\nlevels to data objects and prevents illicit information flows from occurring\nfrom high to low security levels. In this paper, we present a novel security\nmodel for global non-interference which approximates non-interference as a\nsafety property. We also propose a certification technique for global\nnon-interference of complete Java classes based on rewriting logic, a very\ngeneral logical and semantic framework that is efficiently implemented in the\nhigh-level programming language Maude. Starting from an existing Java semantics\nspecification written in Maude, we develop an extended, information-flow Java\nsemantics that allows us to correctly observe global non-interference policies.\nIn order to achieve a finite state transition system, we develop an abstract\nJava semantics that we use for secure and effective non-interference Java\nanalysis. The analysis produces certificates that are independently checkable\nand are small enough to be used in practice.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2010 14:43:10 GMT"}], "update_date": "2010-06-23", "authors_parsed": [["Alba-Castro", "Mauricio", ""], ["Alpuente", "Mar\u00eda", ""], ["Escobar", "Santiago", ""]]}, {"id": "1006.4442", "submitter": "Angelika Kimmig", "authors": "Angelika Kimmig, Bart Demoen, Luc De Raedt, V\\'itor Santos Costa and\n  Ricardo Rocha", "title": "On the Implementation of the Probabilistic Logic Programming Language\n  ProbLog", "comments": "28 pages; To appear in Theory and Practice of Logic Programming\n  (TPLP)", "journal-ref": "Theory and Practice of Logic Programming, 11, 235-262, 2011", "doi": "10.1017/S1471068410000566", "report-no": null, "categories": "cs.PL cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The past few years have seen a surge of interest in the field of\nprobabilistic logic learning and statistical relational learning. In this\nendeavor, many probabilistic logics have been developed. ProbLog is a recent\nprobabilistic extension of Prolog motivated by the mining of large biological\nnetworks. In ProbLog, facts can be labeled with probabilities. These facts are\ntreated as mutually independent random variables that indicate whether these\nfacts belong to a randomly sampled program. Different kinds of queries can be\nposed to ProbLog programs. We introduce algorithms that allow the efficient\nexecution of these queries, discuss their implementation on top of the\nYAP-Prolog system, and evaluate their performance in the context of large\nnetworks of biological entities.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2010 08:05:34 GMT"}], "update_date": "2011-03-04", "authors_parsed": [["Kimmig", "Angelika", ""], ["Demoen", "Bart", ""], ["De Raedt", "Luc", ""], ["Costa", "V\u00edtor Santos", ""], ["Rocha", "Ricardo", ""]]}, {"id": "1006.4943", "submitter": "Adrien Pi\\'erard", "authors": "Adrien Pi\\'erard and Eijiro Sumii", "title": "Sound Bisimulations for Higher-Order Distributed Process Calculus", "comments": "15 pages, uses mathpartir and tikz, appendix at\n  [http://www.kb.ecei.tohoku.ac.jp/~adrien/pubs/SoundAppendix.pdf], the final\n  publication is available at\n  [http://www.springerlink.com/content/071k46u248061x72/]", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DC cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While distributed systems with transfer of processes have become pervasive,\nmethods for reasoning about their behaviour are underdeveloped. In this paper\nwe propose a bisimulation technique for proving behavioural equivalence of such\nsystems modelled in the \\emph{higher-order $\\pi$-calculus with passivation}\n(and restriction). Previous research for this calculus is limited to context\nbisimulations and normal bisimulations which are either impractical or unsound.\nIn contrast, we provide a sound and useful definition of \\emph{environmental\nbisimulations}, with several non-trivial examples. Technically, a central point\nin our bisimulations is the clause for parallel composition, which must account\nfor passivation of the spawned processes in the middle of their execution.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2010 09:32:27 GMT"}, {"version": "v2", "created": "Fri, 6 May 2011 10:37:23 GMT"}], "update_date": "2011-05-09", "authors_parsed": [["Pi\u00e9rard", "Adrien", ""], ["Sumii", "Eijiro", ""]]}, {"id": "1006.5096", "submitter": "EPTCS", "authors": "Dami\\'an Barsotti (Universidad Nacional de C\\'ordoba), Nicol\\'as\n  Wolovick (Universidad Nacional de C\\'ordoba)", "title": "Automatic Probabilistic Program Verification through Random Variable\n  Abstraction", "comments": null, "journal-ref": "EPTCS 28, 2010, pp. 34-47", "doi": "10.4204/EPTCS.28.3", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The weakest pre-expectation calculus has been proved to be a mature theory to\nanalyze quantitative properties of probabilistic and nondeterministic programs.\nWe present an automatic method for proving quantitative linear properties on\nany denumerable state space using iterative backwards fixed point calculation\nin the general framework of abstract interpretation. In order to accomplish\nthis task we present the technique of random variable abstraction (RVA) and we\nalso postulate a sufficient condition to achieve exact fixed point computation\nin the abstract domain. The feasibility of our approach is shown with two\nexamples, one obtaining the expected running time of a probabilistic program,\nand the other the expected gain of a gambling strategy.\n  Our method works on general guarded probabilistic and nondeterministic\ntransition systems instead of plain pGCL programs, allowing us to easily model\na wide range of systems including distributed ones and unstructured programs.\nWe present the operational and weakest precondition semantics for this programs\nand prove its equivalence.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jun 2010 03:03:08 GMT"}], "update_date": "2010-06-29", "authors_parsed": [["Barsotti", "Dami\u00e1n", "", "Universidad Nacional de C\u00f3rdoba"], ["Wolovick", "Nicol\u00e1s", "", "Universidad Nacional de C\u00f3rdoba"]]}, {"id": "1006.5098", "submitter": "EPTCS", "authors": "David Cachera, Arnaud Jobin", "title": "Injecting Abstract Interpretations into Linear Cost Models", "comments": null, "journal-ref": "EPTCS 28, 2010, pp. 64-81", "doi": "10.4204/EPTCS.28.5", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a semantics based framework for analysing the quantitative\nbehaviour of programs with regard to resource usage. We start from an\noperational semantics equipped with costs. The dioid structure of the set of\ncosts allows for defining the quantitative semantics as a linear operator. We\nthen present an abstraction technique inspired from abstract interpretation in\norder to effectively compute global cost information from the program.\nAbstraction has to take two distinct notions of order into account: the order\non costs and the order on states. We show that our abstraction technique\nprovides a correct approximation of the concrete cost computations.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jun 2010 03:03:19 GMT"}], "update_date": "2010-06-29", "authors_parsed": [["Cachera", "David", ""], ["Jobin", "Arnaud", ""]]}, {"id": "1006.5107", "submitter": "EPTCS", "authors": "Alessandra Di Pierro (University of Verona), Gethin Norman (University\n  of Glasgow)", "title": "Proceedings Eighth Workshop on Quantitative Aspects of Programming\n  Languages", "comments": null, "journal-ref": "EPTCS 28, 2010", "doi": "10.4204/EPTCS.28", "report-no": null, "categories": "cs.PL cs.LO cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the proceedings of the Eighth Workshop on Quantitative\nAspects of Programming Languages (QAPL 2010), held in Paphos, Cyprus, on March\n27-28, 2010. QAPL 2010 is a satellite event of the European Joint Conferences\non Theory and Practice of Software (ETAPS 2010).\n  The workshop theme is on quantitative aspects of computation. These aspects\nare related to the use of physical quantities (storage space, time, bandwidth,\netc.) as well as mathematical quantities (e.g. probability and measures for\nreliability, security and trust), and play an important (sometimes essential)\nrole in characterising the behavior and determining the properties of systems.\nSuch quantities are central to the definition of both the model of systems\n(architecture, language design, semantics) and the methodologies and tools for\nthe analysis and verification of the systems properties.\n  The aim of this workshop is to discuss the explicit use of quantitative\ninformation such as time and probabilities either directly in the model or as a\ntool for the analysis of systems.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jun 2010 03:34:52 GMT"}], "update_date": "2010-06-29", "authors_parsed": [["Di Pierro", "Alessandra", "", "University of Verona"], ["Norman", "Gethin", "", "University\n  of Glasgow"]]}, {"id": "1006.5442", "submitter": "Christoph Knabe", "authors": "Christoph Knabe", "title": "Static and Dynamic Quality Assurance by Aspect Oriented Techniques", "comments": "18 pages, 35 TOC items, 38 code snippets, 1 table, 6 references, 21\n  source files with the aspects on accompanying web site", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The overall goal of the described research project was to create applicable\nquality assurance patterns for Java software systems using the aspect-oriented\nprogramming language extension AspectJ 5. We tried to develop aspects to check\nstatic quality criteria as a variable mutator convention and architectural\nlayering rules. We successfully developed aspects for automating the following\ndynamic quality criteria: Parameterized Exception Chaining, Comfortable\nDeclaration of Parameterized Exceptions, Not-Null Checking of Reference\nVariables.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2010 14:53:51 GMT"}], "update_date": "2010-07-06", "authors_parsed": [["Knabe", "Christoph", ""]]}]