[{"id": "1308.0158", "submitter": "Torsten Grust", "authors": "Torsten Grust, Alexander Ulrich", "title": "First-Class Functions for First-Order Database Engines", "comments": "Proceedings of the 14th International Symposium on Database\n  Programming Languages (DBPL 2013), August 30, 2013, Riva del Garda, Trento,\n  Italy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe Query Defunctionalization which enables off-the-shelf first-order\ndatabase engines to process queries over first-class functions. Support for\nfirst-class functions is characterized by the ability to treat functions like\nregular data items that can be constructed at query runtime, passed to or\nreturned from other (higher-order) functions, assigned to variables, and stored\nin persistent data structures. Query defunctionalization is a non-invasive\napproach that transforms such function-centric queries into the data-centric\noperations implemented by common query processors. Experiments with XQuery and\nPL/SQL database systems demonstrate that first-order database engines can\nfaithfully and efficiently support the expressive \"functions as data\" paradigm.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2013 11:39:18 GMT"}], "update_date": "2013-08-02", "authors_parsed": [["Grust", "Torsten", ""], ["Ulrich", "Alexander", ""]]}, {"id": "1308.0219", "submitter": "Kees Middelburg", "authors": "J. A. Bergstra, C. A. Middelburg", "title": "Instruction sequence expressions for the secure hash algorithm SHA-256", "comments": "14 pages; several minor errors corrected; counting error corrected;\n  instruction sequence fault repaired; misunderstanding cleared up; a minor\n  error corrected; 15 pages, presentation improved, a minor error corrected.\n  preliminaries have text overlap with arXiv:1301.3297", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The secure hash function SHA-256 is a function on bit strings. This means\nthat its restriction to the bit strings of any given length can be computed by\na finite instruction sequence that contains only instructions to set and get\nthe content of Boolean registers, forward jump instructions, and a termination\ninstruction. We describe such instruction sequences for the restrictions to bit\nstrings of the different possible lengths by means of uniform terms from an\nalgebraic theory.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2013 14:19:28 GMT"}, {"version": "v2", "created": "Mon, 12 Aug 2013 12:20:41 GMT"}, {"version": "v3", "created": "Thu, 22 Aug 2013 11:40:13 GMT"}, {"version": "v4", "created": "Mon, 16 Sep 2013 11:58:04 GMT"}, {"version": "v5", "created": "Sat, 2 Nov 2013 09:45:55 GMT"}, {"version": "v6", "created": "Tue, 11 Nov 2014 15:40:30 GMT"}, {"version": "v7", "created": "Sat, 18 Nov 2017 11:01:35 GMT"}], "update_date": "2017-11-21", "authors_parsed": [["Bergstra", "J. A.", ""], ["Middelburg", "C. A.", ""]]}, {"id": "1308.0388", "submitter": "EPTCS", "authors": "Luca Cesari (Universit\\`a di Pisa / Universit\\`a degli Studi di\n  Firenze, Italy), Rosario Pugliese (Universit\\`a degli Studi di Firenze,\n  Italy), Francesco Tiezzi (IMT Advanced Studies Lucca, Italy)", "title": "Blind-date Conversation Joining", "comments": "In Proceedings WWV 2013, arXiv:1308.0268", "journal-ref": "EPTCS 123, 2013, pp. 3-18", "doi": "10.4204/EPTCS.123.3", "report-no": null, "categories": "cs.SE cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on a form of joining conversations among multiple parties in\nservice-oriented applications where a client may asynchronously join an\nexisting conversation without need to know in advance any information about it.\nMore specifically, we show how the correlation mechanism provided by\norchestration languages enables a form of conversation joining that is\ncompletely transparent to clients and that we call 'blind-date joining'. We\nprovide an implementation of this strategy by using the standard orchestration\nlanguage WS-BPEL. We then present its formal semantics by resorting to COWS, a\nprocess calculus specifically designed for modelling service-oriented\napplications. We illustrate our approach by means of a simple, but realistic,\ncase study from the online games domain.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2013 01:55:21 GMT"}], "update_date": "2013-08-05", "authors_parsed": [["Cesari", "Luca", "", "Universit\u00e0 di Pisa / Universit\u00e0 degli Studi di\n  Firenze, Italy"], ["Pugliese", "Rosario", "", "Universit\u00e0 degli Studi di Firenze,\n  Italy"], ["Tiezzi", "Francesco", "", "IMT Advanced Studies Lucca, Italy"]]}, {"id": "1308.0389", "submitter": "EPTCS", "authors": "Gabriel Ciobanu (Romanian Academy, Iasi), Ross Horne (Romanian\n  Academy, Iasi), Vladimiro Sassone (University of Southampton)", "title": "Local Type Checking for Linked Data Consumers", "comments": "In Proceedings WWV 2013, arXiv:1308.0268", "journal-ref": "EPTCS 123, 2013, pp. 19-33", "doi": "10.4204/EPTCS.123.4", "report-no": null, "categories": "cs.PL cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Web of Linked Data is the cumulation of over a decade of work by the Web\nstandards community in their effort to make data more Web-like. We provide an\nintroduction to the Web of Linked Data from the perspective of a Web developer\nthat would like to build an application using Linked Data. We identify a\nweakness in the development stack as being a lack of domain specific scripting\nlanguages for designing background processes that consume Linked Data. To\naddress this weakness, we design a scripting language with a simple but\nappropriate type system. In our proposed architecture some data is consumed\nfrom sources outside of the control of the system and some data is held\nlocally. Stronger type assumptions can be made about the local data than\nexternal data, hence our type system mixes static and dynamic typing.\nThroughout, we relate our work to the W3C recommendations that drive Linked\nData, so our syntax is accessible to Web developers.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2013 01:55:30 GMT"}], "update_date": "2013-08-05", "authors_parsed": [["Ciobanu", "Gabriel", "", "Romanian Academy, Iasi"], ["Horne", "Ross", "", "Romanian\n  Academy, Iasi"], ["Sassone", "Vladimiro", "", "University of Southampton"]]}, {"id": "1308.0390", "submitter": "EPTCS", "authors": "Ivan Lanese (Focus Team, University of Bologna/INRIA, Italy), Fabrizio\n  Montesi (IT University of Copenhagen, Denmark), Gianluigi Zavattaro (Focus\n  Team, University of Bologna/INRIA, Italy)", "title": "Amending Choreographies", "comments": "In Proceedings WWV 2013, arXiv:1308.0268", "journal-ref": "EPTCS 123, 2013, pp. 34-48", "doi": "10.4204/EPTCS.123.5", "report-no": null, "categories": "cs.PL cs.DC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Choreographies are global descriptions of system behaviors, from which the\nlocal behavior of each endpoint entity can be obtained automatically through\nprojection. To guarantee that its projection is correct, i.e. it has the same\nbehaviors of the original choreography, a choreography usually has to respect\nsome coherency conditions. This restricts the set of choreographies that can be\nprojected.\n  In this paper, we present a transformation for amending choreographies that\ndo not respect common syntactic conditions for projection correctness.\nSpecifically, our transformation automatically reduces the amount of\nconcurrency, and it infers and adds hidden communications that make the\nresulting choreography respect the desired conditions, while preserving its\nbehavior.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2013 01:55:37 GMT"}], "update_date": "2013-08-05", "authors_parsed": [["Lanese", "Ivan", "", "Focus Team, University of Bologna/INRIA, Italy"], ["Montesi", "Fabrizio", "", "IT University of Copenhagen, Denmark"], ["Zavattaro", "Gianluigi", "", "Focus\n  Team, University of Bologna/INRIA, Italy"]]}, {"id": "1308.0514", "submitter": "Stefanie Scherzinger", "authors": "Stefanie Scherzinger and Meike Klettke and Uta St\\\"orl", "title": "Managing Schema Evolution in NoSQL Data Stores", "comments": "Proceedings of the 14th International Symposium on Database\n  Programming Languages (DBPL 2013), August 30, 2013, Riva del Garda, Trento,\n  Italy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  NoSQL data stores are commonly schema-less, providing no means for globally\ndefining or managing the schema. While this offers great flexibility in early\nstages of application development, developers soon can experience the heavy\nburden of dealing with increasingly heterogeneous data. This paper targets\nschema evolution for NoSQL data stores, the complex task of adapting and\nchanging the implicit structure of the data stored. We discuss the\nrecommendations of the developer community on handling schema changes, and\nintroduce a simple, declarative schema evolution language. With our language,\nsoftware developers and architects can systematically manage the evolution of\ntheir production data and perform typical schema maintenance tasks. We further\nprovide a holistic NoSQL database programming language to define the semantics\nof our schema evolution language. Our solution does not require any\nmodifications to the NoSQL data store, treating the data store as a black box.\nThus, we want to address application developers that use NoSQL systems\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2013 14:34:14 GMT"}], "update_date": "2013-08-05", "authors_parsed": [["Scherzinger", "Stefanie", ""], ["Klettke", "Meike", ""], ["St\u00f6rl", "Uta", ""]]}, {"id": "1308.0689", "submitter": "Johannes Borgstr", "authors": "Johannes Borgstr\\\"om (Uppsala University, Uppsala, Sweden), Andrew D\n  Gordon (Microsoft Research, Cambridge, UK), Michael Greenberg (University of\n  Pennsylvania, Philadelphia, PA, USA), James Margetson (Microsoft Research,\n  Cambridge, UK), Jurgen Van Gael (Microsoft FUSE Labs, Cambridge, UK)", "title": "Measure Transformer Semantics for Bayesian Machine Learning", "comments": "An abridged version of this paper appears in the proceedings of the\n  20th European Symposium on Programming (ESOP'11), part of ETAPS 2011", "journal-ref": "Logical Methods in Computer Science, Volume 9, Issue 3 (September\n  9, 2013) lmcs:815", "doi": "10.2168/LMCS-9(3:11)2013", "report-no": null, "categories": "cs.LO cs.AI cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Bayesian approach to machine learning amounts to computing posterior\ndistributions of random variables from a probabilistic model of how the\nvariables are related (that is, a prior distribution) and a set of observations\nof variables. There is a trend in machine learning towards expressing Bayesian\nmodels as probabilistic programs. As a foundation for this kind of programming,\nwe propose a core functional calculus with primitives for sampling prior\ndistributions and observing variables. We define measure-transformer\ncombinators inspired by theorems in measure theory, and use these to give a\nrigorous semantics to our core calculus. The original features of our semantics\ninclude its support for discrete, continuous, and hybrid measures, and, in\nparticular, for observations of zero-probability events. We compile our core\nlanguage to a small imperative language that is processed by an existing\ninference engine for factor graphs, which are data structures that enable many\nefficient inference algorithms. This allows efficient approximate inference of\nposterior marginal distributions, treating thousands of observations per second\nfor large instances of realistic models.\n", "versions": [{"version": "v1", "created": "Sat, 3 Aug 2013 12:28:23 GMT"}, {"version": "v2", "created": "Fri, 6 Sep 2013 11:45:21 GMT"}, {"version": "v3", "created": "Fri, 20 Sep 2013 18:48:34 GMT"}, {"version": "v4", "created": "Mon, 23 Sep 2013 08:01:06 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Borgstr\u00f6m", "Johannes", "", "Uppsala University, Uppsala, Sweden"], ["Gordon", "Andrew D", "", "Microsoft Research, Cambridge, UK"], ["Greenberg", "Michael", "", "University of\n  Pennsylvania, Philadelphia, PA, USA"], ["Margetson", "James", "", "Microsoft Research,\n  Cambridge, UK"], ["Van Gael", "Jurgen", "", "Microsoft FUSE Labs, Cambridge, UK"]]}, {"id": "1308.0698", "submitter": "Meisam Booshehri", "authors": "Meisam Booshehri, Abbas Malekpour, Peter Luksch", "title": "An Improving Method for Loop Unrolling", "comments": "4 pages, International Journal of Computer Science and Information\n  Security", "journal-ref": "International Journal of Computer Science and Information\n  Security, Vol. 11, No. 5, pp. 73-76 , 2013", "doi": null, "report-no": null, "categories": "cs.PL cs.OS", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  In this paper we review main ideas mentioned in several other papers which\ntalk about optimization techniques used by compilers. Here we focus on loop\nunrolling technique and its effect on power consumption, energy usage and also\nits impact on program speed up by achieving ILP (Instruction-level\nparallelism). Concentrating on superscalar processors, we discuss the idea of\ngeneralized loop unrolling presented by J.C. Hang and T. Leng and then we\npresent a new method to traverse a linked list to get a better result of loop\nunrolling in that case. After that we mention the results of some experiments\ncarried out on a Pentium 4 processor (as an instance of super scalar\narchitecture). Furthermore, the results of some other experiments on\nsupercomputer (the Alliat FX/2800 System) containing superscalar node\nprocessors would be mentioned. These experiments show that loop unrolling has a\nslight measurable effect on energy usage as well as power consumption. But it\ncould be an effective way for program speed up.\n", "versions": [{"version": "v1", "created": "Sat, 3 Aug 2013 14:09:23 GMT"}], "update_date": "2013-08-13", "authors_parsed": [["Booshehri", "Meisam", ""], ["Malekpour", "Abbas", ""], ["Luksch", "Peter", ""]]}, {"id": "1308.0729", "submitter": "Michael Shulman", "authors": "The Univalent Foundations Program", "title": "Homotopy Type Theory: Univalent Foundations of Mathematics", "comments": "465 pages. arXiv v1: first-edition-257-g5561b73, formatted for online\n  reading. The most recent version, copies formatted for printing, and bound\n  copies, are available at http://homotopytypetheory.org/book/", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.PL math.AT math.CT", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Homotopy type theory is a new branch of mathematics, based on a recently\ndiscovered connection between homotopy theory and type theory, which brings new\nideas into the very foundation of mathematics. On the one hand, Voevodsky's\nsubtle and beautiful \"univalence axiom\" implies that isomorphic structures can\nbe identified. On the other hand, \"higher inductive types\" provide direct,\nlogical descriptions of some of the basic spaces and constructions of homotopy\ntheory. Both are impossible to capture directly in classical set-theoretic\nfoundations, but when combined in homotopy type theory, they permit an entirely\nnew kind of \"logic of homotopy types\". This suggests a new conception of\nfoundations of mathematics, with intrinsic homotopical content, an \"invariant\"\nconception of the objects of mathematics -- and convenient machine\nimplementations, which can serve as a practical aid to the working\nmathematician. This book is intended as a first systematic exposition of the\nbasics of the resulting \"Univalent Foundations\" program, and a collection of\nexamples of this new style of reasoning -- but without requiring the reader to\nknow or learn any formal logic, or to use any computer proof assistant.\n", "versions": [{"version": "v1", "created": "Sat, 3 Aug 2013 18:35:45 GMT"}], "update_date": "2013-08-06", "authors_parsed": [["Program", "The Univalent Foundations", ""]]}, {"id": "1308.1034", "submitter": "Clemens Grabmayer", "authors": "Clemens Grabmayer and Jan Rochel", "title": "Term Graph Representations for Cyclic Lambda-Terms", "comments": "35 pages. report extending proceedings article on arXiv:1302.6338\n  (changes with respect to version v2: added section 8, modified Proposition\n  2.4, added Remark 2.5, added Corollary 7.11, modified figures in the\n  conclusion)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study various representations for cyclic lambda-terms as higher-order or\nas first-order term graphs. We focus on the relation between\n`lambda-higher-order term graphs' (lambda-ho-term-graphs), which are\nfirst-order term graphs endowed with a well-behaved scope function, and their\nrepresentations as `lambda-term-graphs', which are plain first-order term\ngraphs with scope-delimiter vertices that meet certain scoping requirements.\nSpecifically we tackle the question: Which class of first-order term graphs\nadmits a faithful embedding of lambda-ho-term-graphs in the sense that: (i) the\nhomomorphism-based sharing-order on lambda-ho-term-graphs is preserved and\nreflected, and (ii) the image of the embedding corresponds closely to a natural\nclass (of lambda-term-graphs) that is closed under homomorphism?\n  We systematically examine whether a number of classes of lambda-term-graphs\nhave this property, and we find a particular class of lambda-term-graphs that\nsatisfies this criterion. Term graphs of this class are built from application,\nabstraction, variable, and scope-delimiter vertices, and have the\ncharacteristic feature that the latter two kinds of vertices have back-links to\nthe corresponding abstraction.\n  This result puts a handle on the concept of subterm sharing for higher-order\nterm graphs, both theoretically and algorithmically: We obtain an easily\nimplementable method for obtaining the maximally shared form of\nlambda-ho-term-graphs. Also, we open up the possibility to pull back properties\nfrom first-order term graphs to lambda-ho-term-graphs. In fact we prove this\nfor the property of the sharing-order successors of a given term graph to be a\ncomplete lattice with respect to the sharing order.\n  This report extends the paper with the same title\n(http://arxiv.org/abs/1302.6338v1) in the proceedings of the workshop TERMGRAPH\n2013.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2013 13:19:14 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2013 09:58:01 GMT"}, {"version": "v3", "created": "Sat, 2 Nov 2013 15:07:37 GMT"}], "update_date": "2013-11-05", "authors_parsed": [["Grabmayer", "Clemens", ""], ["Rochel", "Jan", ""]]}, {"id": "1308.1246", "submitter": "Keehang Kwon", "authors": "Keehang Kwon and Jeongyoon Seo and Daeseong Kang", "title": "Bounded-Choice Statements for User Interaction in Imperative and\n  Object-Oriented Programming", "comments": "5 pages", "journal-ref": "IEICE transactions on information and systems, vol.E99-D, no.3,\n  2016", "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adding versatile interactions to imperative programming -- C, Java and\nAndroid -- is an essential task. Unfortunately, existing languages provide only\nlimited constructs for user interaction. These constructs are usually in the\nform of $unbounded$ quantification. For example, existing languages can take\nthe keyboard input from the user only via the $read(x)/scan(x)$ construct. Note\nthat the value of $x$ is unbounded in the sense that $x$ can have any value.\nThis construct is thus not useful for applications with bounded inputs. To\nsupport bounded choices, we propose new bounded-choice statements for user\ninteration. Each input device (the keyboard, the mouse, the touch, $...$)\nnaturally requires a new bounded-choice statement. To make things simple,\nhowever, we focus on a bounded-choice statement for keyboard -- kchoose -- to\nallow for more controlled and more guided participation from the user. It is\nstraightforward to adjust our idea to other input devices. We illustrate our\nidea via Java(BI), an extension of the core Java with a new bounded-choice\nstatement for the keyboard.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2013 11:46:02 GMT"}, {"version": "v2", "created": "Mon, 23 Nov 2015 05:47:21 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Kwon", "Keehang", ""], ["Seo", "Jeongyoon", ""], ["Kang", "Daeseong", ""]]}, {"id": "1308.1733", "submitter": "Muthiah Annamalai", "authors": "Muthiah Annamalai", "title": "Invitation to Ezhil: A Tamil Programming Language for Early\n  Computer-Science Education", "comments": "11 pages, 5 insets, 4 figures; accepted to Tamil Internet Conference,\n  2013, TI-2013, Malaysia", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ezhil is a Tamil programming language with support for imperative\nprogramming, with mixed use of Tamil and English identifiers and\nfunction-names. Ezhil programing system is targeted toward the K-12 (junior\nhigh-school) level Tamil speaking students, as an early introduction to\nthinking like a computer-scientist. We believe this 'numeracy' knowledge is\neasily transferred over from a native language (Tamil) to the pervasive English\nlanguage programming systems, in Java, dot-Net, Ruby or Python. Ezhil is an\neffort to improve access to computing in the 21st Century.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2013 01:47:36 GMT"}], "update_date": "2013-08-12", "authors_parsed": [["Annamalai", "Muthiah", ""]]}, {"id": "1308.2055", "submitter": "Remy Haemmerle", "authors": "R\\'emy Haemmerl\\'e and Jose Morales", "title": "Proceedings of the 23rd Workshop on Logic-based methods in Programming\n  Environments (WLPE 2013)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the papers presented at the 23rd Workshop on Logic-based\nMethods in Programming Environments (WLPE 2013), which was held in Istanbul,\nTurkey, on August 24 & 25 2013 as a satellite event of the 29th International\nConference on Logic Programming, (ICLP 2013).\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2013 09:03:57 GMT"}, {"version": "v2", "created": "Wed, 21 Aug 2013 01:05:23 GMT"}, {"version": "v3", "created": "Thu, 22 Aug 2013 06:21:25 GMT"}], "update_date": "2013-08-23", "authors_parsed": [["Haemmerl\u00e9", "R\u00e9my", ""], ["Morales", "Jose", ""]]}, {"id": "1308.2507", "submitter": "Hongseok Yang", "authors": "Alexey Gotsman (IMDEA Software Institute), Hongseok Yang (University\n  of Oxford)", "title": "Linearizability with Ownership Transfer", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 9, Issue 3 (September\n  9, 2013) lmcs:931", "doi": "10.2168/LMCS-9(3:12)2013", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linearizability is a commonly accepted notion of correctness for libraries of\nconcurrent algorithms. Unfortunately, it assumes a complete isolation between a\nlibrary and its client, with interactions limited to passing values of a given\ndata type. This is inappropriate for common programming languages, where\nlibraries and their clients can communicate via the heap, transferring the\nownership of data structures, and can even run in a shared address space\nwithout any memory protection. In this paper, we present the first definition\nof linearizability that lifts this limitation and establish an Abstraction\nTheorem: while proving a property of a client of a concurrent library, we can\nsoundly replace the library by its abstract implementation related to the\noriginal one by our generalisation of linearizability. This allows abstracting\nfrom the details of the library implementation while reasoning about the\nclient. We also prove that linearizability with ownership transfer can be\nderived from the classical one if the library does not access some of data\nstructures transferred to it by the client.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2013 09:59:02 GMT"}, {"version": "v2", "created": "Fri, 6 Sep 2013 11:54:08 GMT"}, {"version": "v3", "created": "Fri, 20 Sep 2013 18:50:21 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Gotsman", "Alexey", "", "IMDEA Software Institute"], ["Yang", "Hongseok", "", "University\n  of Oxford"]]}, {"id": "1308.3156", "submitter": "Kartik Gupta", "authors": "Kartik Gupta and V. Krishna Nandivada", "title": "Lexical State Analyzer", "comments": "16 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lexical states provide a powerful mechanism to scan regular expressions in a\ncontext sensitive manner. At the same time, lexical states also make it hard to\nreason about the correctness of the grammar. We first categorize the related\ncorrectness issues into two classes: errors and warnings, and then present a\ncontext sensitive and a context insensitive analysis to identify errors and\nwarnings in context-free-grammars (CFGs). We also present a comparative study\nof these analyses. A standalone tool (LSA) has also been implemented by us that\ncan identify errors and warnings in JavaCC grammars. The LSA tool outputs a\ngraph that depicts the grammar and the error transitions. It can also generates\ncounter example strings that can be used to establish the errors. We have used\nLSA to analyze a host of open-source JavaCC grammar files to good effect.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2013 15:36:23 GMT"}], "update_date": "2013-08-15", "authors_parsed": [["Gupta", "Kartik", ""], ["Nandivada", "V. Krishna", ""]]}, {"id": "1308.3203", "submitter": "Dino Distefano", "authors": "Dino Distefano and Jeremy Dubreil", "title": "Detecting Data Races on OpenCL Kernels with Symbolic Execution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an automatic analysis technique for checking data races on OpenCL\nkernels. Our method defines symbolic execution techniques based on separation\nlogic with suitable abstractions to automatically detect non-benign racy\nbehaviours on kernel\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2013 18:30:37 GMT"}], "update_date": "2013-08-15", "authors_parsed": [["Distefano", "Dino", ""], ["Dubreil", "Jeremy", ""]]}, {"id": "1308.3472", "submitter": "Andrei Popescu", "authors": "Andrei Popescu", "title": "Security Type Systems as Recursive Predicates", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how security type systems from the literature of language-based\nnoninterference can be represented more directly as predicates defined by\nstructural recursion on the programs. In this context, we show how our uniform\nsyntactic criteria from previous work cover several previous type-system\nsoundness results.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2013 18:36:31 GMT"}], "update_date": "2013-08-16", "authors_parsed": [["Popescu", "Andrei", ""]]}, {"id": "1308.3937", "submitter": "Remy Haemmerle", "authors": "Michael Codish, Yoav Fekete, Amit Metodi", "title": "Compiling Finite Domain Constraints to SAT with BEE: the Director's Cut", "comments": "Part of WLPE 2013 proceedings (arXiv:1308.2055)", "journal-ref": null, "doi": null, "report-no": "WLPE/2013/1", "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  BEE is a compiler which facilitates solving finite domain constraints by\nencoding them to CNF and applying an underlying SAT solver. In BEE constraints\nare modeled as Boolean functions which propagate information about equalities\nbetween Boolean literals. This information is then applied to simplify the CNF\nencoding of the constraints. We term this process equi-propagation. A key\nfactor is that considering only a small fragment of a constraint model at one\ntime enables to apply stronger, and even complete reasoning to detect\nequivalent literals in that fragment. Once detected, equivalences propagate to\nsimplify the entire constraint model and facilitate further reasoning on other\nfragments. BEE is described in several recent papers. In this paper, after a\nquick review of BEE, we elaborate on two undocumented details of the\nimplementation: the hybrid encoding of cardinality constraints and complete\nequi-propagation. We thendescribe on-going work aimed to extend BEE to consider\nbinary representation of numbers.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2013 07:15:16 GMT"}], "update_date": "2013-08-20", "authors_parsed": [["Codish", "Michael", ""], ["Fekete", "Yoav", ""], ["Metodi", "Amit", ""]]}, {"id": "1308.3938", "submitter": "Remy Haemmerle", "authors": "Spyros Hadjichristodoulou, Donald E. Porter, David S. Warren", "title": "Efficiently Retrieving Function Dependencies in the Linux Kernel Using\n  XSB", "comments": "Part of WLPE 2013 proceedings (arXiv:1308.2055)", "journal-ref": null, "doi": null, "report-no": "WLPE/2013/3", "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we investigate XSB-Prolog as a static analysis engine for data\nrepresented by medium-sized graphs. We use XSB-Prolog to automatically identify\nfunction dependencies in the Linux Kernel---queries that are difficult to\nimplement efficiently in a commodity database and that developers often have to\nidentify manually. This project illustrates that Prolog systems are ideal for\nbuilding tools for use in other disciplines that require sophisticated\ninferences, because Prolog is both declarative and can efficiently implement\ncomplex problem specifications through tabling and indexing.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2013 07:15:23 GMT"}], "update_date": "2013-08-20", "authors_parsed": [["Hadjichristodoulou", "Spyros", ""], ["Porter", "Donald E.", ""], ["Warren", "David S.", ""]]}, {"id": "1308.3939", "submitter": "Remy Haemmerle", "authors": "Dragan Ivanovi\\'c", "title": "Implementing Constraint Handling Rules as a Domain-Specific Language\n  Embedded in Java", "comments": "Part of WLPE 2013 proceedings (arXiv:1308.2055)", "journal-ref": null, "doi": null, "report-no": "WLPE/2013/4", "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Programming languages and techniques based on logic and constraints, such as\nthe Constraint Handling Rules (CHR), can support many common programming tasks\nthat can be expressed in the form of a search for feasible or optimal\nsolutions. Developing new constraint solvers using CHR is especially\ninteresting in configuration management for large scale, distributed and\ndynamic cloud applications, where dynamic configuration and component selection\nis an integral part of the programming environment. Writing CHR-style\nconstraint solvers in a domain-specific language which is a subset of Java --\ninstead of using a separate language layer -- solves many integration,\ndevelopment cycle disruption, testing and debugging problems that discourage or\nmake difficult the adoption of the CHR-based approach in the mainstream\nprogramming environments. Besides, the prototype implementation exposes a\nwell-defined API that supports transactional store behavior, safe termination,\nand debugging via event notifications.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2013 07:15:27 GMT"}], "update_date": "2013-08-20", "authors_parsed": [["Ivanovi\u0107", "Dragan", ""]]}, {"id": "1308.3940", "submitter": "Remy Haemmerle", "authors": "Alejandro Serrano, Pedro L\\'opez-Garc\\'ia, Manuel Hermenegildo", "title": "Towards an Abstract Domain for Resource Analysis of Logic Programs Using\n  Sized Types", "comments": "Part of WLPE 2013 proceedings (arXiv:1308.2055)", "journal-ref": null, "doi": null, "report-no": "WLPE/2013/5", "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel general resource analysis for logic programs based on\nsized types.Sized types are representations that incorporate structural (shape)\ninformation and allow expressing both lower and upper bounds on the size of a\nset of terms and their subterms at any position and depth. They also allow\nrelating the sizes of terms and subterms occurring at different argument\npositions in logic predicates. Using these sized types, the resource analysis\ncan infer both lower and upper bounds on the resources used by all the\nprocedures in a program as functions on input term (and subterm) sizes,\novercoming limitations of existing analyses and enhancing their precision. Our\nnew resource analysis has been developed within the abstract interpretation\nframework, as an extension of the sized types abstract domain, and has been\nintegrated into the Ciao preprocessor, CiaoPP. The abstract domain operations\nare integrated with the setting up and solving of recurrence equations for\nboth, inferring size and resource usage functions. We show that the analysis is\nan improvement over the previous resource analysis present in CiaoPP and\ncompares well in power to state of the art systems.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2013 07:15:30 GMT"}], "update_date": "2013-08-20", "authors_parsed": [["Serrano", "Alejandro", ""], ["L\u00f3pez-Garc\u00eda", "Pedro", ""], ["Hermenegildo", "Manuel", ""]]}, {"id": "1308.3941", "submitter": "Remy Haemmerle", "authors": "Jan Wielemaker, Michael Hendricks", "title": "Why It's Nice to be Quoted: Quasiquoting for Prolog", "comments": "Part of WLPE 2013 proceedings (arXiv:1308.2055)", "journal-ref": null, "doi": null, "report-no": "WLPE/2013/7", "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prolog's support for dynamic programming, meta programming and text\nprocessing using context free grammars make the language highly suitable for\ndefining domain specific languages (DSL) as well as analysing, refactoring or\ngenerating expression states in other (programming) languages. Well known DSLs\nare the DCG (Definite Clause Grammar) notation and constraint languages such as\nCHR. These extensions use Prolog operator declarations and the {...} notation\nto realise a good syntax. When external languages, such as HTML, SQL or\nJavaScript enter the picture, operators no longer satisfy for embedding\nsnippets of these languages into a Prolog source file. In addition, Prolog has\npoor support for quoting long text fragments.\n  Haskell introduced quasi quotationsto resolve this problem. In this paper we\n`ported' the Haskell mechanism for quasi quoting to Prolog. We show that this\ncan be done cleanly and that quasi quoting can solve the above mentioned\nproblems.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2013 07:15:38 GMT"}], "update_date": "2013-08-20", "authors_parsed": [["Wielemaker", "Jan", ""], ["Hendricks", "Michael", ""]]}, {"id": "1308.4125", "submitter": "Remy Haemmerle", "authors": "Carl Andersen, Brett Benyo, Miguel Calejo, Mike Dean, Paul Fodor,\n  Benjamin N. Grosof, Michael Kifer, Senlin Liang, Terrance Swift", "title": "Understanding Rulelog Computations in Silk", "comments": "Part of WLPE 2013 proceedings (arXiv:1308.2055)", "journal-ref": null, "doi": null, "report-no": "WLPE/2013/6", "categories": "cs.SE cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rulelog is a knowledge representation and reasoning language based on logic\nprogramming under the well-founded semantics. It is an extension of the\nlanguage of Flora-2 and so supports inheritance and other object-oriented\nfeatures, as well as the higher-order syntax of Hilog. However, Rulelog rules\nmay also contain quantifiers and may be contra-positional. In addition, these\nrules are evaluated in the presence of defeasibility mechanisms that include\nrule cancellation, rule priorities, and other aspects. Rulelog programs are\nsometimes developed by loosely coordinated teams of knowledge engineers (KEs)\nwho are not necessarily programmers. This requires not only declarative\ndebugging support, but also support for profiling to help KEs understand the\noverall structure of a computation, including its termination properties. The\ndesign of debugging and profiling tools is made more challenging because\nRulelog programs undergo a series of transformations into normal programs, so\nthat there is a cognitive distance between how rules are specified and how they\nare executed.\n  In this paper, we describe the debugging and profiling environment for\nRulelog implemented in the integrated development environment of the Silk\nsystem. Our approach includes an interface to justification graphs, which treat\nwhy-not and defeasibility as well as provenance of the rules supporting\nanswers. It also includes tools for trace-based analysis of computations to\npermit understanding of erroneous non-termination and of general performance\nissues. For semantically correct cases of the non-terminating behavior, Silk\noffers a different approach, which addresses the problem in a formally sound\nmanner by leveraging a form of bounded rationality called restraint.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2013 07:15:34 GMT"}], "update_date": "2013-08-21", "authors_parsed": [["Andersen", "Carl", ""], ["Benyo", "Brett", ""], ["Calejo", "Miguel", ""], ["Dean", "Mike", ""], ["Fodor", "Paul", ""], ["Grosof", "Benjamin N.", ""], ["Kifer", "Michael", ""], ["Liang", "Senlin", ""], ["Swift", "Terrance", ""]]}, {"id": "1308.4452", "submitter": "Keehang Kwon", "authors": "Keehang Kwon", "title": "A New Statement for Selection and Exception Handling in Imperative\n  Languages", "comments": "8 pages. We add the notion of negative exception handling", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diverse selection statements -- if-then-else, switch and try-catch -- are\ncommonly used in modern programming languages. To make things simple, we\npropose a unifying statement for selection. This statement is of the form\nseqor(G_1,...,G_n) where each $G_i$ is a statement. It has a a simple\nsemantics: sequentially choose the first successful statement $G_i$ and then\nproceeds with executing $G_i$. Examples will be provided for this statement.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2013 00:13:32 GMT"}, {"version": "v2", "created": "Sun, 7 Jun 2015 12:00:03 GMT"}, {"version": "v3", "created": "Mon, 24 Aug 2015 04:59:23 GMT"}, {"version": "v4", "created": "Fri, 11 Jan 2019 06:51:07 GMT"}], "update_date": "2019-01-14", "authors_parsed": [["Kwon", "Keehang", ""]]}, {"id": "1308.4815", "submitter": "Clinton Goss Ph.D.", "authors": "Clinton F. Goss", "title": "Machine Code Optimization - Improving Executable Object Code", "comments": "Technical Report #246, Courant Institute of Mathematical Sciences,\n  New York University. Initially published June 1986; Revised August 22, 2013.\n  41 pages, 9 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  This dissertation explores classes of compiler optimization techniques that\nare applicable late in the compilation process, after all executable code for a\nprogram has been linked. I concentrate on techniques which, for various\nreasons, cannot be applied earlier in the compilation process. In addition to a\ntheoretical treatment of this class of optimization techniques, this\ndissertation reports on an implementation of these techniques in a production\nenvironment. I describe the details of the implementation which allows these\ntechniques to be re-targeted easily and report on improvements gained when\noptimizing production software.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2013 10:14:43 GMT"}, {"version": "v2", "created": "Fri, 23 Aug 2013 09:02:41 GMT"}], "update_date": "2013-08-26", "authors_parsed": [["Goss", "Clinton F.", ""]]}, {"id": "1308.5896", "submitter": "EPTCS", "authors": "David Baelde (LSV, ENS Cachan), Arnaud Carayol (CNRS, Universit\\'e\n  Paris-Est, Marne-la-Vall\\'ee)", "title": "Proceedings Workshop on Fixed Points in Computer Science", "comments": null, "journal-ref": "EPTCS 126, 2013", "doi": "10.4204/EPTCS.126", "report-no": null, "categories": "cs.LO cs.FL cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the proceedings of the Ninth Workshop on Fixed Points in\nComputer Science which took place on the September 1st, 2013 in Torino, Italy\nas a CSL-affiliated workshop. Past workshops have been held in Brno (1998,\nMFCS/CSL workshop), Paris (2000, LC workshop), Florence (2001, PLI workshop),\nCopenhagen (2002, LICS (FLoC) workshop), Warsaw (2003, ETAPS workshop), Coimbra\n(2009, CSL workshop), Brno (2010, MFCS-CSL workshop), Tallinn (2012, CSL\nworkshop). Fixed points play a fundamental role in several areas of computer\nscience. They are used to justify (co)recursive definitions and associated\nreasoning techniques. The construction and properties of fixed points have been\ninvestigated in many different settings such as: design and implementation of\nprogramming languages, logics, verification, databases. The aim of this\nworkshop is to provide a forum for researchers to present their results to\nthose members of the computer science and logic communities who study or apply\nthe theory of fixed points.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2013 15:25:01 GMT"}], "update_date": "2013-08-28", "authors_parsed": [["Baelde", "David", "", "LSV, ENS Cachan"], ["Carayol", "Arnaud", "", "CNRS, Universit\u00e9\n  Paris-Est, Marne-la-Vall\u00e9e"]]}, {"id": "1308.6096", "submitter": "Clinton Goss Ph.D.", "authors": "Robert B. K. Dewar, Martin Charles Golumbic, and Clinton F. Goss", "title": "Micro Spitbol", "comments": "Initially published October 1979; Revised August 28, 2013. 8 pages, 3\n  figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  A compact version of MACRO SPITBOL, a compiler/ interpreter for a variant of\nSNOBOL4, has been developed for use on microcomputer systems. The techniques\nfor producing an implementation are largely automatic in order to preserve the\nintegrity and portability of the SPITBOL system. These techniques are discussed\nalong with a description of an initial implementation on a 65K byte\nminicomputer. An interesting theoretical problem which arises when using\nprocedures which compact the interpretive object code is also analyzed.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2013 08:59:41 GMT"}], "update_date": "2013-08-29", "authors_parsed": [["Dewar", "Robert B. K.", ""], ["Golumbic", "Martin Charles", ""], ["Goss", "Clinton F.", ""]]}]