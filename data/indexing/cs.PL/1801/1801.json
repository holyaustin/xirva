[{"id": "1801.00285", "submitter": "Thorsten Wissmann", "authors": "Paula Severi", "title": "A Light Modality for Recursion", "comments": "32 pages 1 figure in pdf format", "journal-ref": "Logical Methods in Computer Science, Volume 15, Issue 1 (February\n  5, 2019) lmcs:5166", "doi": "10.23638/LMCS-15(1:8)2019", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We investigate the interplay between a modality for controlling the behaviour\nof recursive functional programs on infinite structures which are completely\nsilent in the syntax. The latter means that programs do not contain \"marks\"\nshowing the application of the introduction and elimination rules for the\nmodality. This shifts the burden of controlling recursion from the programmer\nto the compiler. To do this, we introduce a typed lambda calculus a la Curry\nwith a silent modality and guarded recursive types. The typing discipline\nguarantees normalisation and can be transformed into an algorithm which infers\nthe type of a program.\n", "versions": [{"version": "v1", "created": "Sun, 31 Dec 2017 14:02:33 GMT"}, {"version": "v2", "created": "Sun, 25 Feb 2018 16:16:44 GMT"}, {"version": "v3", "created": "Wed, 2 May 2018 10:41:17 GMT"}, {"version": "v4", "created": "Mon, 23 Jul 2018 19:54:35 GMT"}, {"version": "v5", "created": "Sat, 2 Feb 2019 13:57:14 GMT"}], "update_date": "2019-04-29", "authors_parsed": [["Severi", "Paula", ""]]}, {"id": "1801.00471", "submitter": "Brandon Bohrer", "authors": "Brandon Bohrer and Karl Crary", "title": "TWAM: A Certifying Abstract Machine for Logic Programs", "comments": "41 pages, under submission to ACM Transactions on Computational Logic", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Type-preserving (or typed) compilation uses typing derivations to certify\ncorrectness properties of compilation. We have designed and implemented a\ntype-preserving compiler for a simply-typed dialect of Prolog we call T-Prolog.\nThe crux of our approach is a new certifying abstract machine which we call the\nTyped Warren Abstract Machine (TWAM). The TWAM has a dependent type system\nstrong enough to specify the semantics of a logic program in the logical\nframework LF. We present a soundness metatheorem which constitutes a partial\ncorrectness guarantee: well-typed programs implement the logic program\nspecified by their type. This metatheorem justifies our design and\nimplementation of a certifying compiler from T-Prolog to TWAM.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jan 2018 16:46:28 GMT"}], "update_date": "2018-01-03", "authors_parsed": [["Bohrer", "Brandon", ""], ["Crary", "Karl", ""]]}, {"id": "1801.00687", "submitter": "Ilya Sergey", "authors": "Ilya Sergey, Amrit Kumar, Aquinas Hobor", "title": "Scilla: a Smart Contract Intermediate-Level LAnguage", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper outlines key design principles of Scilla---an intermediate-level\nlanguage for verified smart contracts.\n  Scilla provides a clean separation between the communication aspect of smart\ncontracts on a blockchain, allowing for the rich interaction patterns, and a\nprogramming component, which enjoys principled semantics and is amenable to\nformal verification. Scilla is not meant to be a high-level programming\nlanguage, and we are going to use it as a translation target for high-level\nlanguages, such as Solidity, for performing program analysis and verification,\nbefore further compilation to an executable bytecode.\n  We describe the automata-based model of Scilla, present its programming\ncomponent and show how contract definitions in terms of automata streamline the\nprocess of mechanised verification of their safety and temporal properties.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jan 2018 15:31:24 GMT"}], "update_date": "2018-01-03", "authors_parsed": [["Sergey", "Ilya", ""], ["Kumar", "Amrit", ""], ["Hobor", "Aquinas", ""]]}, {"id": "1801.01579", "submitter": "Karl Crary", "authors": "Karl Crary", "title": "Hygienic Source-Code Generation Using Functors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing source-code-generating tools such as Lex and Yacc suffer from\npractical inconveniences because they use disembodied code to implement\nactions. To prevent this problem, such tools could generate closed functors\nthat are then instantiated by the programmer with appropriate action code. This\nresults in all code being type checked in its appropriate context, and it\nassists the type checker in localizing errors correctly. We have implemented a\nlexer generator and parser generator based on this technique for Standard ML,\nOCaml, and Haskell.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jan 2018 23:15:28 GMT"}], "update_date": "2018-01-08", "authors_parsed": [["Crary", "Karl", ""]]}, {"id": "1801.01896", "submitter": "Van Chan Ngo", "authors": "Van Chan Ngo, Mario Dehesa-Azuara, Matthew Fredrikson, Jan Hoffmann", "title": "Verifying and Synthesizing Constant-Resource Implementations with Types", "comments": "30, IEEE S&P 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel type system for verifying that programs correctly\nimplement constant-resource behavior. Our type system extends recent work on\nautomatic amortized resource analysis (AARA), a set of techniques that\nautomatically derive provable upper bounds on the resource consumption of\nprograms. We devise new techniques that build on the potential method to\nachieve compositionality, precision, and automation.\n  A strict global requirement that a program always maintains constant resource\nusage is too restrictive for most practical applications. It is sufficient to\nrequire that the program's resource behavior remain constant with respect to an\nattacker who is only allowed to observe part of the program's state and\nbehavior. To account for this, our type system incorporates information flow\ntracking into its resource analysis. This allows our system to certify programs\nthat need to violate the constant-time requirement in certain cases, as long as\ndoing so does not leak confidential information to attackers. We formalize this\nguarantee by defining a new notion of resource-aware noninterference, and prove\nthat our system enforces it.\n  Finally, we show how our type inference algorithm can be used to synthesize a\nconstant-time implementation from one that cannot be verified as secure,\neffectively repairing insecure programs automatically. We also show how a\nsecond novel AARA system that computes lower bounds on resource usage can be\nused to derive quantitative bounds on the amount of information that a program\nleaks through its resource use. We implemented each of these systems in\nResource Aware ML, and show that it can be applied to verify constant-time\nbehavior in a number of applications including encryption and decryption\nroutines, database queries, and other resource-aware functionality.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jan 2018 19:10:44 GMT"}], "update_date": "2018-01-09", "authors_parsed": [["Ngo", "Van Chan", ""], ["Dehesa-Azuara", "Mario", ""], ["Fredrikson", "Matthew", ""], ["Hoffmann", "Jan", ""]]}, {"id": "1801.02216", "submitter": "Oleg Lobachev", "authors": "Martin Braun, Oleg Lobachev, Phil Trinder", "title": "Arrows for Parallel Computation", "comments": "43 pages, 31 main figures, 3 tables, to be submitted to JFP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Arrows are a general interface for computation and an alternative to Monads\nfor API design. In contrast to Monad-based parallelism, we explore the use of\nArrows for specifying generalised parallelism. Specifically, we define an\nArrow-based language and implement it using multiple parallel Haskells.\n  As each parallel computation is an Arrow, such parallel Arrows (PArrows) can\nbe readily composed and transformed as such. To allow for more sophisticated\ncommunication schemes between computation nodes in distributed systems, we\nutilise the concept of Futures to wrap direct communication.\n  To show that PArrows have similar expressive power as existing parallel\nlanguages, we implement several algorithmic skeletons and four benchmarks.\nBenchmarks show that our framework does not induce any notable performance\noverhead. We conclude that Arrows have considerable potential for composing\nparallel programs and for producing programs that can execute on multiple\nparallel language implementations.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jan 2018 17:14:47 GMT"}], "update_date": "2018-01-09", "authors_parsed": [["Braun", "Martin", ""], ["Lobachev", "Oleg", ""], ["Trinder", "Phil", ""]]}, {"id": "1801.02571", "submitter": "Abel Nieto", "authors": "Abel Nieto", "title": "Tamarin: Concolic Disequivalence for MIPS", "comments": "Technical Report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given two MIPS programs, when are they equivalent? At first glance, this is\ntricky to define, because of the unstructured nature of assembly code. We\npropose the use of alternating concolic execution to detect whether two\nprograms are disequivalent. We have implemented our approach in a tool called\nTamarin, which includes a MIPS emulator instrumented to record symbolic traces,\nas well as a concolic execution engine that integrates with the Z3 solver. We\nshow that Tamarin is able to reason about program disequivalence in a number of\nscenarios, without any a-priori knowledge about the MIPS programs under\nconsideration.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jan 2018 17:26:35 GMT"}], "update_date": "2018-01-09", "authors_parsed": [["Nieto", "Abel", ""]]}, {"id": "1801.03367", "submitter": "Amir Kafshdar Goharshady", "authors": "Krishnendu Chatterjee, Amir Kafshdar Goharshady, Yaron Velner", "title": "Quantitative Analysis of Smart Contracts", "comments": "ESOP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smart contracts are computer programs that are executed by a network of\nmutually distrusting agents, without the need of an external trusted authority.\nSmart contracts handle and transfer assets of considerable value (in the form\nof crypto-currency like Bitcoin). Hence, it is crucial that their\nimplementation is bug-free. We identify the utility (or expected payoff) of\ninteracting with such smart contracts as the basic and canonical quantitative\nproperty for such contracts. We present a framework for such quantitative\nanalysis of smart contracts. Such a formal framework poses new and novel\nresearch challenges in programming languages, as it requires modeling of\ngame-theoretic aspects to analyze incentives for deviation from honest behavior\nand modeling utilities which are not specified as standard temporal properties\nsuch as safety and termination. While game-theoretic incentives have been\nanalyzed in the security community, their analysis has been restricted to the\nvery special case of stateless games. However, to analyze smart contracts,\nstateful analysis is required as it must account for the different program\nstates of the protocol. Our main contributions are as follows: we present (i)~a\nsimplified programming language for smart contracts; (ii)~an automatic\ntranslation of the programs to state-based games; (iii)~an\nabstraction-refinement approach to solve such games; and (iv)~experimental\nresults on real-world-inspired smart contracts.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jan 2018 13:31:32 GMT"}, {"version": "v2", "created": "Thu, 15 Feb 2018 10:22:55 GMT"}, {"version": "v3", "created": "Sun, 17 Jun 2018 16:58:50 GMT"}], "update_date": "2018-06-19", "authors_parsed": [["Chatterjee", "Krishnendu", ""], ["Goharshady", "Amir Kafshdar", ""], ["Velner", "Yaron", ""]]}, {"id": "1801.03763", "submitter": "Ioannis Christou Ph.D.", "authors": "Ioannis T. Christou, Sofoklis Efremidis", "title": "To Pool or Not To Pool? Revisiting an Old Pattern", "comments": "14 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the well-known object-pool design pattern in Java. In the last\ndecade, the pattern has attracted a lot of criticism regarding its validity\nwhen used for light-weight objects that are only meant to hold memory rather\nthan any other resources (database connections, sockets etc.) and in fact,\ncommon opinion holds that is an anti-pattern in such cases. Nevertheless, we\nshow through several experiments in different systems that the use of this\npattern for extremely short-lived and light-weight memory objects can in fact\nsignificantly reduce the response time of high-performance multi-threaded\napplications, especially in memory-constrained environments. In certain\nmulti-threaded applications where high performance is a requirement and/or\nmemory constraints exist, we recommend therefore that the object pool pattern\nbe given consideration and tested for possible run-time as well as memory\nfootprint improvements.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jan 2018 17:00:58 GMT"}], "update_date": "2018-01-15", "authors_parsed": [["Christou", "Ioannis T.", ""], ["Efremidis", "Sofoklis", ""]]}, {"id": "1801.03967", "submitter": "Andreas Humenberger", "authors": "Andreas Humenberger, Maximilian Jaroschek, Laura Kov\\'acs", "title": "Invariant Generation for Multi-Path Loops with Polynomial Assignments", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-319-73721-8_11", "report-no": null, "categories": "cs.PL cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Program analysis requires the generation of program properties expressing\nconditions to hold at intermediate program locations. When it comes to programs\nwith loops, these properties are typically expressed as loop invariants. In\nthis paper we study a class of multi-path program loops with numeric variables,\nin particular nested loops with conditionals, where assignments to program\nvariables are polynomial expressions over program variables. We call this class\nof loops extended P-solvable and introduce an algorithm for generating all\npolynomial invariants of such loops. By an iterative procedure employing\nGr\\\"obner basis computation, our approach computes the polynomial ideal of the\npolynomial invariants of each program path and combines these ideals\nsequentially until a fixed point is reached. This fixed point represents the\npolynomial ideal of all polynomial invariants of the given extended P-solvable\nloop. We prove termination of our method and show that the maximal number of\niterations for reaching the fixed point depends linearly on the number of\nprogram variables and the number of inner loops. In particular, for a loop with\nm program variables and r conditional branches we prove an upper bound of m*r\niterations. We implemented our approach in the Aligator software package.\nFurthermore, we evaluated it on 18 programs with polynomial arithmetic and\ncompared it to existing methods in invariant generation. The results show the\nefficiency of our approach.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jan 2018 19:55:51 GMT"}], "update_date": "2018-01-15", "authors_parsed": [["Humenberger", "Andreas", ""], ["Jaroschek", "Maximilian", ""], ["Kov\u00e1cs", "Laura", ""]]}, {"id": "1801.04032", "submitter": "Shelly Grossman", "authors": "Shelly Grossman, Ittai Abraham, Guy Golan-Gueta, Yan Michalevsky, Noam\n  Rinetzky, Mooly Sagiv, and Yoni Zohar", "title": "Online Detection of Effectively Callback Free Objects with Applications\n  to Smart Contracts", "comments": "31 pages. Technical Report for the paper presented in POPL'18 with\n  the same title", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Callbacks are essential in many programming environments, but drastically\ncomplicate program understanding and reasoning because they allow to mutate\nobject's local states by external objects in unexpected fashions, thus breaking\nmodularity. The famous DAO bug in the cryptocurrency framework Ethereum,\nemployed callbacks to steal $150M. We define the notion of Effectively Callback\nFree (ECF) objects in order to allow callbacks without preventing modular\nreasoning.\n  An object is ECF in a given execution trace if there exists an equivalent\nexecution trace without callbacks to this object. An object is ECF if it is ECF\nin every possible execution trace. We study the decidability of dynamically\nchecking ECF in a given execution trace and statically checking if an object is\nECF. We also show that dynamically checking ECF in Ethereum is feasible and can\nbe done online. By running the history of all execution traces in Ethereum, we\nwere able to verify that virtually all existing contracts, excluding the DAO or\ncontracts with similar known vulnerabilities, are ECF. Finally, we show that\nECF, whether it is verified dynamically or statically, enables modular\nreasoning about objects with encapsulated state.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jan 2018 01:33:42 GMT"}], "update_date": "2018-01-15", "authors_parsed": [["Grossman", "Shelly", ""], ["Abraham", "Ittai", ""], ["Golan-Gueta", "Guy", ""], ["Michalevsky", "Yan", ""], ["Rinetzky", "Noam", ""], ["Sagiv", "Mooly", ""], ["Zohar", "Yoni", ""]]}, {"id": "1801.04167", "submitter": "Luca Padovani", "authors": "Ugo de'Liguoro and Luca Padovani", "title": "Mailbox Types for Unordered Interactions", "comments": "working draft", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a type system for reasoning on protocol conformance and deadlock\nfreedom in networks of processes that communicate through unordered mailboxes.\nWe model these networks in the mailbox calculus, a mild extension of the\nasynchronous {\\pi}-calculus with first-class mailboxes and selective input. The\ncalculus subsumes the actor model and allows us to analyze networks with\ndynamic topologies and varying number of processes possibly mixing different\nconcurrency abstractions. Well-typed processes are deadlock free and never fail\nbecause of unexpected messages. For a non-trivial class of them, junk freedom\nis also guaranteed. We illustrate the expressiveness of the calculus and of the\ntype system by encoding instances of non-uniform, concurrent objects, binary\nsessions extended with joins and forks, and some known actor benchmarks.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jan 2018 13:59:38 GMT"}], "update_date": "2018-01-15", "authors_parsed": [["de'Liguoro", "Ugo", ""], ["Padovani", "Luca", ""]]}, {"id": "1801.04405", "submitter": "Amir Ashouri", "authors": "Amir H. Ashouri, William Killian, John Cavazos, Gianluca Palermo and\n  Cristina Silvano", "title": "A Survey on Compiler Autotuning using Machine Learning", "comments": "version 5.0 (updated on September 2018)- Preprint Version For our\n  Accepted Journal @ ACM CSUR 2018 (42 pages) - This survey will be updated\n  quarterly here (Send me your new published papers to be added in the\n  subsequent version) History: Received November 2016; Revised August 2017;\n  Revised February 2018; Accepted March 2018-", "journal-ref": null, "doi": "10.1145/3197978", "report-no": null, "categories": "cs.PL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since the mid-1990s, researchers have been trying to use machine-learning\nbased approaches to solve a number of different compiler optimization problems.\nThese techniques primarily enhance the quality of the obtained results and,\nmore importantly, make it feasible to tackle two main compiler optimization\nproblems: optimization selection (choosing which optimizations to apply) and\nphase-ordering (choosing the order of applying optimizations). The compiler\noptimization space continues to grow due to the advancement of applications,\nincreasing number of compiler optimizations, and new target architectures.\nGeneric optimization passes in compilers cannot fully leverage newly introduced\noptimizations and, therefore, cannot keep up with the pace of increasing\noptions. This survey summarizes and classifies the recent advances in using\nmachine learning for the compiler optimization field, particularly on the two\nmajor problems of (1) selecting the best optimizations and (2) the\nphase-ordering of optimizations. The survey highlights the approaches taken so\nfar, the obtained results, the fine-grain classification among different\napproaches and finally, the influential papers of the field.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jan 2018 09:41:57 GMT"}, {"version": "v2", "created": "Tue, 13 Mar 2018 04:35:32 GMT"}, {"version": "v3", "created": "Thu, 22 Mar 2018 01:03:50 GMT"}, {"version": "v4", "created": "Wed, 16 May 2018 04:48:00 GMT"}, {"version": "v5", "created": "Mon, 3 Sep 2018 20:42:21 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Ashouri", "Amir H.", ""], ["Killian", "William", ""], ["Cavazos", "John", ""], ["Palermo", "Gianluca", ""], ["Silvano", "Cristina", ""]]}, {"id": "1801.04618", "submitter": "Adrien Guatto", "authors": "Adrien Guatto, Sam Westrick, Ram Raghunathan, Umut Acar, Matthew Fluet", "title": "Hierarchical Memory Management for Mutable State", "comments": "15 pages, 14 figures, PPoPP 2018", "journal-ref": null, "doi": "10.1145/3178487.3178494", "report-no": null, "categories": "cs.PL cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that modern functional programming languages are naturally\namenable to parallel programming. Achieving efficient parallelism using\nfunctional languages, however, remains difficult. Perhaps the most important\nreason for this is their lack of support for efficient in-place updates, i.e.,\nmutation, which is important for the implementation of both parallel algorithms\nand the run-time system services (e.g., schedulers and synchronization\nprimitives) used to execute them.\n  In this paper, we propose techniques for efficient mutation in parallel\nfunctional languages. To this end, we couple the memory manager with the thread\nscheduler to make reading and updating data allocated by nested threads\nefficient. We describe the key algorithms behind our technique, implement them\nin the MLton Standard ML compiler, and present an empirical evaluation. Our\nexperiments show that the approach performs well, significantly improving\nefficiency over existing functional language implementations.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jan 2018 22:25:44 GMT"}, {"version": "v2", "created": "Sun, 18 Feb 2018 11:00:48 GMT"}], "update_date": "2018-02-20", "authors_parsed": [["Guatto", "Adrien", ""], ["Westrick", "Sam", ""], ["Raghunathan", "Ram", ""], ["Acar", "Umut", ""], ["Fluet", "Matthew", ""]]}, {"id": "1801.04992", "submitter": "Johannes Reich", "authors": "Johannes Reich", "title": "Data", "comments": "Improved version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The contribution of this article is a data concept that is essentially based\non the two concepts of information and computable functionality. In short, data\nis viewed as typed information. A data type is defined as a pair of a set of\ndistinguishable characters (an alphabet) and a set of operations (computable\nfunctions) that operate on this alphabet as domain. Two different ways of\nsubtyping in the sense of Liskov and Wing are described, one for restriction\nand one for extension of existing types. They lead to two different partial\norders on types. It is argued that the proposed data concept matches the\nconcept of characteristics (Merkmale) of the automation industry.\n", "versions": [{"version": "v1", "created": "Sat, 23 Dec 2017 09:28:31 GMT"}, {"version": "v2", "created": "Thu, 7 Jun 2018 18:06:32 GMT"}], "update_date": "2018-06-11", "authors_parsed": [["Reich", "Johannes", ""]]}, {"id": "1801.05052", "submitter": "Ale\\v{s} Bizjak", "authors": "Lorenzo Bettini, Viviana Bono, Mariangiola Dezani-Ciancaglini, Paola\n  Giannini, Betti Venneri", "title": "Java & Lambda: a Featherweight Story", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 14, Issue 3 (September\n  5, 2018) lmcs:4803", "doi": "10.23638/LMCS-14(3:17)2018", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present FJ&$\\lambda$, a new core calculus that extends Featherweight Java\n(FJ) with interfaces, supporting multiple inheritance in a restricted form,\n$\\lambda$-expressions, and intersection types. Our main goal is to formalise\nhow lambdas and intersection types are grafted on Java 8, by studying their\nproperties in a formal setting. We show how intersection types play a\nsignificant role in several cases, in particular in the typecast of a\n$\\lambda$-expression and in the typing of conditional expressions. We also\nembody interface \\emph{default methods} in FJ&$\\lambda$, since they increase\nthe dynamism of $\\lambda$-expressions, by allowing these methods to be called\non $\\lambda$-expressions.\n  The crucial point in Java 8 and in our calculus is that $\\lambda$-expressions\ncan have various types according to the context requirements (target types):\nindeed, Java code does not compile when $\\lambda$-expressions come without\ntarget types. In particular, in the operational semantics we must record target\ntypes by decorating $\\lambda$-expressions, otherwise they would be lost in the\nruntime expressions.\n  We prove the subject reduction property and progress for the resulting\ncalculus, and we give a type inference algorithm that returns the type of a\ngiven program if it is well typed. The design of FJ&$\\lambda$ has been driven\nby the aim of making it a subset of Java 8, while preserving the elegance and\ncompactness of FJ. Indeed, FJ&$\\lambda$ programs are typed and behave the same\nas Java programs.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jan 2018 22:31:54 GMT"}, {"version": "v2", "created": "Mon, 21 May 2018 11:23:05 GMT"}, {"version": "v3", "created": "Thu, 19 Jul 2018 20:12:25 GMT"}, {"version": "v4", "created": "Mon, 3 Sep 2018 07:17:23 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Bettini", "Lorenzo", ""], ["Bono", "Viviana", ""], ["Dezani-Ciancaglini", "Mariangiola", ""], ["Giannini", "Paola", ""], ["Venneri", "Betti", ""]]}, {"id": "1801.05909", "submitter": "Nirmal Prajapati", "authors": "Nirmal Prajapati", "title": "Scheduling and Tiling Reductions on Realistic Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computations, where the number of results is much smaller than the input data\nand are produced through some sort of accumulation, are called Reductions.\nReductions appear in many scientific applications. Usually, reductions admit an\nassociative and commutative binary operator over accumulation. Reductions are\ntherefore highly parallel. Given unbounded fan-in, one can execute a reduction\nin constant/linear time provided that the data is available. However, due to\nthe fact that real machines have bounded fan-in, accumulations cannot be\nperformed in one time step and have to be broken into parts. Thus, a (partial)\nserialization of reductions becomes necessary. This makes scheduling reductions\na difficult and interesting problem.\n  There have been a number of research works in the context of scheduling\nreductions. We focus on the scheduling techniques presented in Gupta et al.,\nidentify a potential issue in their scheduling algorithm and provide a\nsolution. In addition, we demonstrate how these scheduling techniques can be\nextended to \"tile\" reductions and briefly survey other studies that address the\nproblem of scheduling reductions.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jan 2018 02:22:57 GMT"}], "update_date": "2018-01-19", "authors_parsed": [["Prajapati", "Nirmal", ""]]}, {"id": "1801.06144", "submitter": "Erick Lavoie", "authors": "Erick Lavoie and Laurie Hendren", "title": "A Formalization for Specifying and Implementing Correct Pull-Stream\n  Modules", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Pull-stream is a JavaScript demand-driven functional design pattern based on\ncallback functions that enables the creation and easy composition of\nindependent modules that are used to create streaming applications. It is used\nin popular open source projects and the community around it has created over a\nhundred compatible modules. While the description of the pull-stream design\npattern may seem simple, it does exhibit complicated termination cases. Despite\nthe popularity and large uptake of the pull-stream design pattern, there was no\nexisting formal specification that could help programmers reason about the\ncorrectness of their implementations.\n  Thus, the main contribution of this paper is to provide a formalization for\nspecifying and implementing correct pull-stream modules based on the following:\n(1) we show the pull-stream design pattern is a form of declarative concurrent\nprogramming; (2) we present an event-based protocol language that supports our\nformalization, independently of JavaScript; (3) we provide the first precise\nand explicit definition of the expected sequences of events that happen at the\ninterface of two modules, which we call the pull-stream protocol; (4) we\nspecify reference modules that exhibit the full range of behaviors of the\npull-stream protocol; (5) we validate our definitions against the community\nexpectations by testing the existing core pull-stream modules against them and\nidentify unspecified behaviors in existing modules.\n  Our approach helps to better understand the pull-stream protocol, to ensure\ninteroperability of community modules, and to concisely and precisely specify\nnew pull-stream abstractions in papers and documentation.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jan 2018 17:48:52 GMT"}], "update_date": "2018-01-19", "authors_parsed": [["Lavoie", "Erick", ""], ["Hendren", "Laurie", ""]]}, {"id": "1801.06793", "submitter": "Moez AbdelGawad", "authors": "Moez AbdelGawad and Robert Cartwright", "title": "NOOP: A Domain-Theoretic Model of Nominally-Typed OOP", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The majority of industrial-strength object-oriented (OO) software is written\nusing nominally-typed OO programming languages. Extant domain-theoretic models\nof OOP developed to analyze OO type systems miss, however, a crucial feature of\nthese mainstream OO languages: nominality. This paper presents the construction\nof NOOP as the first domain-theoretic model of OOP that includes full\nclass/type names information found in nominally-typed OOP. Inclusion of nominal\ninformation in objects of NOOP and asserting that type inheritance in\nstatically-typed OO programming languages is an inherently nominal notion allow\nreadily proving that type inheritance and subtyping are completely identified\nin these languages. This conclusion is in full agreement with intuitions of\ndevelopers and language designers of these OO languages, and contrary to the\nbelief that \"inheritance is not subtyping,\" which came from assuming\nnon-nominal (a.k.a., structural) models of OOP.\n  To motivate the construction of NOOP, this paper briefly presents the\nbenefits of nominal-typing to mainstream OO developers and OO language\ndesigners, as compared to structural-typing. After presenting NOOP, the paper\nfurther briefly compares NOOP to the most widely known domain-theoretic models\nof OOP. Leveraging the development of NOOP, the comparisons presented in this\npaper provide clear, brief and precise technical and mathematical accounts for\nthe relation between nominal and structural OO type systems. NOOP, thus,\nprovides a firmer semantic foundation for analyzing and progressing\nnominally-typed OO programming languages.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jan 2018 09:17:31 GMT"}], "update_date": "2018-01-23", "authors_parsed": [["AbdelGawad", "Moez", ""], ["Cartwright", "Robert", ""]]}, {"id": "1801.07647", "submitter": "Eugen Z\\u{a}linescu", "authors": "Serdar Erbatur and Martin Hofmann and Eugen Zalinescu", "title": "Enforcing Programming Guidelines with Region Types and Effects", "comments": "long version of APLAS'17 paper", "journal-ref": null, "doi": "10.1007/978-3-319-71237-6_5", "report-no": null, "categories": "cs.PL cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present in this paper a new type and effect system for Java which can be\nused to ensure adherence to guidelines for secure web programming. The system\nis based on the region and effect system by Beringer, Grabowski, and Hofmann.\nIt improves upon it by being parametrized over an arbitrary guideline supplied\nin the form of a finite monoid or automaton and a type annotation or mockup\ncode for external methods. Furthermore, we add a powerful type inference based\non precise interprocedural analysis and provide an implementation in the Soot\nframework which has been tested on a number of benchmarks including large parts\nof the Stanford SecuriBench.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jan 2018 16:38:18 GMT"}], "update_date": "2018-01-24", "authors_parsed": [["Erbatur", "Serdar", ""], ["Hofmann", "Martin", ""], ["Zalinescu", "Eugen", ""]]}, {"id": "1801.08107", "submitter": "Hugo Torres Vieira", "authors": "Marco Carbone (1), Fabrizio Montesi (2), Hugo Torres Vieira (3) ((1)\n  IT University of Copenhagen, (2) University of Southern Denmark, (3) IMT\n  School for Advanced Studies Lucca)", "title": "Choreographies for Reactive Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modular programming is a cornerstone in software development, as it allows to\nbuild complex systems from the assembly of simpler components, and support\nreusability and substitution principles. In a distributed setting, component\nassembly is supported by communication that is often required to follow a\nprescribed protocol of interaction. In this paper, we present a language for\nthe modular development of distributed systems, where the assembly of\ncomponents is supported by a choreography that specifies the communication\nprotocol. Our language allows to separate component behaviour, given in terms\nof reactive data ports, and choreographies, specified as first class entities.\nThis allows us to consider reusability and substitution principles for both\ncomponents and choreographies. We show how our model can be compiled into a\nmore operational perspective in a provably-correct way, and we present a typing\ndiscipline that addresses communication safety and progress of systems, where a\nnotion of substitutability naturally arises.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jan 2018 18:13:06 GMT"}], "update_date": "2018-01-25", "authors_parsed": [["Carbone", "Marco", ""], ["Montesi", "Fabrizio", ""], ["Vieira", "Hugo Torres", ""]]}, {"id": "1801.08114", "submitter": "Bernardo Toninho", "authors": "Bernardo Toninho and Nobuko Yoshida", "title": "Depending on Session-Typed Processes", "comments": "Extended version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work proposes a dependent type theory that combines functions and\nsession-typed processes (with value dependencies) through a contextual monad,\ninternalising typed processes in a dependently-typed lambda-calculus. The\nproposed framework, by allowing session processes to depend on functions and\nvice-versa, enables us to specify and statically verify protocols where the\nchoice of the next communication action can depend on specific values of\nreceived data. Moreover, the type theoretic nature of the framework endows us\nwith the ability to internally describe and prove predicates on process\nbehaviours. Our main results are type soundness of the framework, and a\nfaithful embedding of the functional layer of the calculus within the\nsession-typed layer, showcasing the expressiveness of dependent session types.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jan 2018 18:30:22 GMT"}], "update_date": "2018-01-25", "authors_parsed": [["Toninho", "Bernardo", ""], ["Yoshida", "Nobuko", ""]]}, {"id": "1801.08350", "submitter": "Thorsten Wissmann", "authors": "Emmanuel Hainry and Romain P\\'echoux", "title": "Theory of higher order interpretations and application to Basic Feasible\n  Functions", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 16, Issue 4 (December\n  14, 2020) lmcs:6973", "doi": "10.23638/LMCS-16(4:14)2020", "report-no": null, "categories": "cs.LO cs.CC cs.PL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Interpretation methods and their restrictions to polynomials have been deeply\nused to control the termination and complexity of first-order term rewrite\nsystems. This paper extends interpretation methods to a pure higher order\nfunctional language. We develop a theory of higher order functions that is\nwell-suited for the complexity analysis of this programming language. The\ninterpretation domain is a complete lattice and, consequently, we express\nprogram interpretation in terms of a least fixpoint. As an application, by\nbounding interpretations by higher order polynomials, we characterize Basic\nFeasible Functions at any order.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jan 2018 11:11:10 GMT"}, {"version": "v2", "created": "Wed, 4 Sep 2019 10:08:28 GMT"}, {"version": "v3", "created": "Tue, 27 Oct 2020 14:07:28 GMT"}, {"version": "v4", "created": "Fri, 11 Dec 2020 16:09:10 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Hainry", "Emmanuel", ""], ["P\u00e9choux", "Romain", ""]]}, {"id": "1801.08441", "submitter": "Moez AbdelGawad", "authors": "Moez A. AbdelGawad", "title": "Finitary-based Domain Theory in Coq: An Early Report", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In domain theory every finite computable object can be represented by a\nsingle mathematical object instead of a set of objects, using the notion of\nfinitary-basis. In this article we report on our effort to formalize domain\ntheory in Coq in terms of finitary-basis.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jan 2018 11:13:59 GMT"}], "update_date": "2018-01-26", "authors_parsed": [["AbdelGawad", "Moez A.", ""]]}, {"id": "1801.08450", "submitter": "Thorsten Wissmann", "authors": "Ian A. Mason and Carolyn L. Talcott", "title": "Reasoning about effects: from lists to cyber-physical agents", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 15, Issue 2 (April 30,\n  2019) lmcs:5411", "doi": "10.23638/LMCS-15(2:8)2019", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Theories for reasoning about programs with effects initially focused on basic\nmanipulation of lists and other mutable data. The next challenge was to\nconsider higher-order programming, adding functions as first class objects to\nmutable data. Reasoning about actors added the challenge of dealing with\ndistributed open systems of entities interacting asynchronously. The advent of\ncyber-physical agents introduces the need to consider uncertainty, faults,\nphysical as well as logical effects. In addition cyber-physical agents have\nsensors and actuators giving rise to a much richer class of effects with\nbroader scope: think of self-driving cars, autonomous drones, or smart medical\ndevices.\n  This paper gives a retrospective on reasoning about effects highlighting key\nprinciples and techniques and closing with challenges for future work.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jan 2018 17:35:32 GMT"}, {"version": "v2", "created": "Wed, 13 Jun 2018 11:16:34 GMT"}, {"version": "v3", "created": "Fri, 26 Oct 2018 18:22:20 GMT"}, {"version": "v4", "created": "Mon, 29 Apr 2019 16:52:44 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Mason", "Ian A.", ""], ["Talcott", "Carolyn L.", ""]]}, {"id": "1801.08766", "submitter": "Alexander Weigl", "authors": "Bernhard Beckert and Timo Bingmann and Moritz Kiefer and Peter Sanders\n  and Mattias Ulbrich and Alexander Weigl", "title": "Relational Equivalence Proofs Between Imperative and MapReduce\n  Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MapReduce frameworks are widely used for the implementation of distributed\nalgorithms. However, translating imperative algorithms into these frameworks\nrequires significant structural changes to the algorithm. As the costs of\nrunning faulty algorithms at scale can be severe, it is highly desirable to\nverify the correctness of the translation, i.e., to prove that the MapReduce\nversion is equivalent to the imperative original. We present a novel approach\nfor proving equivalence between imperative and MapReduce algorithms based on\npartitioning the equivalence proof into a sequence of equivalence proofs\nbetween intermediate programs with smaller differences. Our approach is based\non the insight that two kinds of sub-proofs are required: (1) uniform\ntransformations changing the controlflow structure that are mostly independent\nof the particular context in which they are applied; and (2) context-dependent\ntransformations that are not uniform but that preserve the overall structure\nand can be proved correct using coupling invariants. We demonstrate the\nfeasibility of our approach by evaluating it on two prototypical algorithms\ncommonly used as examples in MapReduce frameworks: k-means and PageRank. To\ncarry out the proofs, we use the interactive theorem prover Coq with partial\nproof automation. The results show that our approach and its prototypical\nimplementation based on Coq enables equivalence proofs of non-trivial\nalgorithms and could be automated to a large degree.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jan 2018 11:44:15 GMT"}], "update_date": "2018-02-07", "authors_parsed": [["Beckert", "Bernhard", ""], ["Bingmann", "Timo", ""], ["Kiefer", "Moritz", ""], ["Sanders", "Peter", ""], ["Ulbrich", "Mattias", ""], ["Weigl", "Alexander", ""]]}, {"id": "1801.08771", "submitter": "Norman Rink", "authors": "Norman A. Rink", "title": "Modeling of languages for tensor manipulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerical applications and, more recently, machine learning applications rely\non high-dimensional data that is typically organized into multi-dimensional\ntensors. Many existing frameworks, libraries, and domain-specific languages\nsupport the development of efficient code for manipulating tensors and tensor\nexpressions. However, such frameworks and languages that are used in practice\noften lack formal specifications. The present report formally defines a model\nlanguage for expressing tensor operations. The model language is simple and yet\ngeneral enough so that it captures the fundamental tensor operations common to\nmost existing languages and frameworks. It is shown that the given formal\nsemantics are sensible, in the sense that well-typed programs in the model\nlanguage execute correctly, without error. Moreover, an alternative\nimplementation of the model language is formally defined. The alternative\nimplementation introduces padding into the storage of tensors, which may\nbenefit performance on modern hardware platforms. Based on their formal\ndefinitions, the original implementation of the model language and the\nimplementation with padding are proven equivalent. Finally, some possible\nextensions of the presented model language for tensor manipulation are\ndiscussed.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jan 2018 11:56:54 GMT"}], "update_date": "2018-01-29", "authors_parsed": [["Rink", "Norman A.", ""]]}, {"id": "1801.09189", "submitter": "Uday Khedker", "authors": "Pritam M. Gharat, Uday P. Khedker, Alan Mycroft", "title": "Generalized Points-to Graphs: A New Abstraction of Memory in the\n  Presence of Pointers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Flow- and context-sensitive points-to analysis is difficult to scale; for\ntop-down approaches, the problem centers on repeated analysis of the same\nprocedure; for bottom-up approaches, the abstractions used to represent\nprocedure summaries have not scaled while preserving precision.\n  We propose a novel abstraction called the Generalized Points-to Graph (GPG)\nwhich views points-to relations as memory updates and generalizes them using\nthe counts of indirection levels leaving the unknown pointees implicit. This\nallows us to construct GPGs as compact representations of bottom-up procedure\nsummaries in terms of memory updates and control flow between them. Their\ncompactness is ensured by the following optimizations: strength reduction\nreduces the indirection levels, redundancy elimination removes redundant memory\nupdates and minimizes control flow (without over-approximating data dependence\nbetween memory updates), and call inlining enhances the opportunities of these\noptimizations. We devise novel operations and data flow analyses for these\noptimizations.\n  Our quest for scalability of points-to analysis leads to the following\ninsight: The real killer of scalability in program analysis is not the amount\nof data but the amount of control flow that it may be subjected to in search of\nprecision. The effectiveness of GPGs lies in the fact that they discard as much\ncontrol flow as possible without losing precision (i.e., by preserving data\ndependence without over-approximation). This is the reason why the GPGs are\nvery small even for main procedures that contain the effect of the entire\nprogram. This allows our implementation to scale to 158kLoC for C programs.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jan 2018 06:51:18 GMT"}], "update_date": "2018-01-30", "authors_parsed": [["Gharat", "Pritam M.", ""], ["Khedker", "Uday P.", ""], ["Mycroft", "Alan", ""]]}, {"id": "1801.09373", "submitter": "M.Zubair Malik", "authors": "Muhammad Zubair Malik, Muhammad Nawaz, Nimrah Mustafa, Junaid Haroon\n  Siddiqui", "title": "Search Based Code Generation for Machine Learning Programs", "comments": "Search Based Software Engineering, Generating Machine Learning Code,\n  Partial Evaluation, Futamura Projection, Sketching", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning (ML) has revamped every domain of life as it provides\npowerful tools to build complex systems that learn and improve from experience\nand data. Our key insight is that to solve a machine learning problem, data\nscientists do not invent a new algorithm each time, but evaluate a range of\nexisting models with different configurations and select the best one. This\ntask is laborious, error-prone, and drains a large chunk of project budget and\ntime. In this paper we present a novel framework inspired by programming by\nSketching and Partial Evaluation to minimize human intervention in developing\nML solutions. We templatize machine learning algorithms to expose configuration\nchoices as holes to be searched. We share code and computation between\ndifferent algorithms, and only partially evaluate configuration space of\nalgorithms based on information gained from initial algorithm evaluations. We\nalso employ hierarchical and heuristic based pruning to reduce the search\nspace. Our initial findings indicate that our approach can generate highly\naccurate ML models. Interviews with data scientists show that they feel our\nframework can eliminate sources of common errors and significantly reduce\ndevelopment time.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jan 2018 06:28:47 GMT"}, {"version": "v2", "created": "Tue, 6 Feb 2018 09:55:12 GMT"}], "update_date": "2018-02-07", "authors_parsed": [["Malik", "Muhammad Zubair", ""], ["Nawaz", "Muhammad", ""], ["Mustafa", "Nimrah", ""], ["Siddiqui", "Junaid Haroon", ""]]}, {"id": "1801.09802", "submitter": "Maaz Bin Safeer Ahmad", "authors": "Maaz Bin Safeer Ahmad and Alvin Cheung", "title": "Automatically Leveraging MapReduce Frameworks for Data-Intensive\n  Applications", "comments": "12 pages, additional 4 pages of references and appendix", "journal-ref": "SIGMOD '18 Proceedings of the 2018 International Conference on\n  Management of Data, Pages 1205-1220", "doi": "10.1145/3183713.3196891", "report-no": null, "categories": "cs.DB cs.DC cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MapReduce is a popular programming paradigm for developing large-scale,\ndata-intensive computation. Many frameworks that implement this paradigm have\nrecently been developed. To leverage these frameworks, however, developers must\nbecome familiar with their APIs and rewrite existing code. Casper is a new tool\nthat automatically translates sequential Java programs into the MapReduce\nparadigm. Casper identifies potential code fragments to rewrite and translates\nthem in two steps: (1) Casper uses program synthesis to search for a program\nsummary (i.e., a functional specification) of each code fragment. The summary\nis expressed using a high-level intermediate language resembling the MapReduce\nparadigm and verified to be semantically equivalent to the original using a\ntheorem prover. (2) Casper generates executable code from the summary, using\neither the Hadoop, Spark, or Flink API. We evaluated Casper by automatically\nconverting real-world, sequential Java benchmarks to MapReduce. The resulting\nbenchmarks perform up to 48.2x faster compared to the original.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jan 2018 00:02:57 GMT"}, {"version": "v2", "created": "Tue, 19 Jun 2018 05:01:08 GMT"}], "update_date": "2018-06-20", "authors_parsed": [["Ahmad", "Maaz Bin Safeer", ""], ["Cheung", "Alvin", ""]]}, {"id": "1801.10140", "submitter": "Cristian Mattarei", "authors": "Cristian Mattarei, Clark Barrett, Shu-yu Guo, Bradley Nelson, Ben\n  Smith, JF Bastien", "title": "EMME: a formal tool for ECMAScript Memory Model Evaluation", "comments": "16 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nearly all web-based interfaces are written in JavaScript. Given its\nprevalence, the support for high performance JavaScript code is crucial. The\nECMA Technical Committee 39 (TC39) has recently extended the ECMAScript\nlanguage (i.e., JavaScript) to support shared memory accesses between different\nthreads. The extension is given in terms of a natural language memory model\nspecification. In this paper we describe a formal approach for validating both\nthe memory model and its implementations in various JavaScript engines. We\nfirst introduce a formal version of the memory model and report results on\nchecking the model for consistency and other properties. We then introduce our\ntool, EMME, built on top of the Alloy analyzer, which leverages the model to\ngenerate all possible valid executions of a given JavaScript program. Finally,\nwe report results using EMME together with small test programs to analyze\nindustrial JavaScript engines. We show that EMME can find bugs as well as\nmissed opportunities for optimization.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jan 2018 18:46:58 GMT"}, {"version": "v2", "created": "Tue, 17 Apr 2018 06:22:11 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Mattarei", "Cristian", ""], ["Barrett", "Clark", ""], ["Guo", "Shu-yu", ""], ["Nelson", "Bradley", ""], ["Smith", "Ben", ""], ["Bastien", "JF", ""]]}, {"id": "1801.10467", "submitter": "Rahul Gupta", "authors": "Rahul Gupta, Aditya Kanade, Shirish Shevade", "title": "Deep Reinforcement Learning for Programming Language Correction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Novice programmers often struggle with the formal syntax of programming\nlanguages. To assist them, we design a novel programming language correction\nframework amenable to reinforcement learning. The framework allows an agent to\nmimic human actions for text navigation and editing. We demonstrate that the\nagent can be trained through self-exploration directly from the raw input, that\nis, program text itself, without any knowledge of the formal syntax of the\nprogramming language. We leverage expert demonstrations for one tenth of the\ntraining data to accelerate training. The proposed technique is evaluated on\n6975 erroneous C programs with typographic errors, written by students during\nan introductory programming course. Our technique fixes 14% more programs and\n29% more compiler error messages relative to those fixed by a state-of-the-art\ntool, DeepFix, which uses a fully supervised neural machine translation\napproach.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jan 2018 14:48:41 GMT"}], "update_date": "2018-02-01", "authors_parsed": [["Gupta", "Rahul", ""], ["Kanade", "Aditya", ""], ["Shevade", "Shirish", ""]]}, {"id": "1801.10490", "submitter": "Alessandro Warth", "authors": "Tony Garnock-Jones, Mahdi Eslamimehr, Alessandro Warth", "title": "Recognising and Generating Terms using Derivatives of Parsing Expression\n  Grammars", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Grammar-based sentence generation has been thoroughly explored for\nContext-Free Grammars (CFGs), but remains unsolved for recognition-based\napproaches such as Parsing Expression Grammars (PEGs). Lacking tool support,\nlanguage designers using PEGs have difficulty predicting the behaviour of their\nparsers. In this paper, we extend the idea of derivatives, originally\nformulated for regular expressions, to PEGs. We then present a novel technique\nfor sentence generation based on derivatives, applicable to any grammatical\nformalism for which the derivative can be defined--now including PEGs. Finally,\nwe propose applying derivatives more generally to other problems facing\nlanguage designers and implementers.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jan 2018 15:28:30 GMT"}], "update_date": "2018-02-01", "authors_parsed": [["Garnock-Jones", "Tony", ""], ["Eslamimehr", "Mahdi", ""], ["Warth", "Alessandro", ""]]}, {"id": "1801.10519", "submitter": "Andr\\'es Ezequiel Viso", "authors": "Delia Kesner and Alejandro R\\'ios and Andr\\'es Viso", "title": "Call-by-Need, Neededness and All That", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-319-89366-2_13", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that call-by-need is observationally equivalent to weak-head needed\nreduction. The proof of this result uses a semantical argument based on a\n(non-idempotent) intersection type system called $\\mathcal{V}$. Interestingly,\nsystem $\\mathcal{V}$ also allows to syntactically identify all the weak-head\nneeded redexes of a term.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jan 2018 16:03:32 GMT"}, {"version": "v2", "created": "Tue, 8 Sep 2020 13:09:59 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Kesner", "Delia", ""], ["R\u00edos", "Alejandro", ""], ["Viso", "Andr\u00e9s", ""]]}]