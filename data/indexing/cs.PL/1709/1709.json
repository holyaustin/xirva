[{"id": "1709.00049", "submitter": "EPTCS", "authors": "Kirstin Peters, Simone Tini", "title": "Proceedings Combined 24th International Workshop on Expressiveness in\n  Concurrency and 14th Workshop on Structural Operational Semantics", "comments": null, "journal-ref": "EPTCS 255, 2017", "doi": "10.4204/EPTCS.255", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the proceedings of the Combined 24th International\nWorkshop on Expressiveness in Concurrency and the 14th Workshop on Structural\nOperational Semantics (EXPRESS/SOS 2017) which was held on 04 September 2017 in\nBerlin, Germany, as an affiliated workshop of CONCUR 2017, the 28th\nInternational Conference on Concurrency Theory. The EXPRESS workshops aim at\nbringing together researchers interested in the expressiveness of various\nformal systems and semantic notions, particularly in the field of concurrency.\nTheir focus has traditionally been on the comparison between programming\nconcepts (such as concurrent, functional, imperative, logic and object-oriented\nprogramming) and between mathematical models of computation (such as process\nalgebras, Petri nets, event structures, modal logics, and rewrite systems) on\nthe basis of their relative expressive power. The EXPRESS workshop series has\nrun successfully since 1994 and over the years this focus has become broadly\nconstrued. The SOS workshops aim at being a forum for researchers, students and\npractitioners interested in new developments, and directions for future\ninvestigation, in the field of structural operational semantics. One of the\nspecific goals of the SOS workshop series is to establish synergies between the\nconcurrency and programming language communities working on the theory and\npractice of SOS. Since 2012, the EXPRESS and SOS communities have organized an\nannual combined EXPRESS/SOS workshop on the expressiveness of mathematical\nmodels of computation and the formal semantics of systems and programming\nconcepts.\n", "versions": [{"version": "v1", "created": "Thu, 31 Aug 2017 19:32:45 GMT"}], "update_date": "2017-09-04", "authors_parsed": [["Peters", "Kirstin", ""], ["Tini", "Simone", ""]]}, {"id": "1709.00828", "submitter": "EPTCS", "authors": "James Hoey (University of Leicester), Irek Ulidowski (University of\n  Leicester), Shoji Yuen (Nagoya University)", "title": "Reversing Imperative Parallel Programs", "comments": "In Proceedings EXPRESS/SOS 2017, arXiv:1709.00049", "journal-ref": "EPTCS 255, 2017, pp. 51-66", "doi": "10.4204/EPTCS.255.4", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an approach and a subsequent extension for reversing imperative\nprograms. Firstly, we produce both an augmented version and a corresponding\ninverted version of the original program. Augmentation saves reversal\ninformation into an auxiliary data store, maintaining segregation between this\nand the program state, while never altering the data store in any other way\nthan that of the original program. Inversion uses this information to revert\nthe final program state to the state as it was before execution. We prove that\naugmentation and inversion work as intended, and illustrate our approach with\nseveral examples. We also suggest a modification to our first approach to\nsupport non-communicating parallelism. Execution interleaving introduces a\nnumber of challenges, each of which our extended approach considers. We define\nannotation and redefine inversion to use a sequence of statement identifiers,\nmaking the interleaving order deterministic in reverse.\n", "versions": [{"version": "v1", "created": "Mon, 4 Sep 2017 06:28:33 GMT"}], "update_date": "2017-09-05", "authors_parsed": [["Hoey", "James", "", "University of Leicester"], ["Ulidowski", "Irek", "", "University of\n  Leicester"], ["Yuen", "Shoji", "", "Nagoya University"]]}, {"id": "1709.00833", "submitter": "Ludovic Courtes", "authors": "Ludovic Court\\`es", "title": "Code Staging in GNU Guix", "comments": "16th ACM SIGPLAN International Conference on Generative Programming:\n  Concepts and Experiences (GPCE'17), Oct 2017, Vancouver, Canada", "journal-ref": null, "doi": "10.1145/3136040.3136045", "report-no": null, "categories": "cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  GNU Guix is a \" functional \" package manager that builds upon earlier work on\nNix. Guix implements high-level abstractions such as packages and operating\nsystem services as domain-specic languages (DSLs) embedded in Scheme. It also\nimplements build actions and operating system orchestration in Scheme. This\nleads to a multi-tier programming environment where embedded code snippets are\nstaged for eventual execution. This paper presents G-expressions or \" gexps \",\nthe staging mechanism we devised for Guix. We explain our journey from\ntraditional Lisp S-expressions to G-expressions, which augment the former with\ncontextual information and ensure hygienic code staging. We discuss the\nimplementation of gexps and report on our experience using them in a variety of\noperating system use cases-from package build processes to system services.\nGexps provide a novel way to cover many aspects of OS connguration in a single,\nmulti-tier language, while facilitating code reuse and code sharing .\n", "versions": [{"version": "v1", "created": "Mon, 4 Sep 2017 06:34:07 GMT"}], "update_date": "2017-09-05", "authors_parsed": [["Court\u00e8s", "Ludovic", ""]]}, {"id": "1709.00964", "submitter": "Hassan Ait-Kaci", "authors": "Hassan A\\\"it-Kaci, Gabriella Pasi", "title": "Lattice Operations on Terms over Similar Signatures", "comments": "Pre-proceedings paper presented at the 27th International Symposium\n  on Logic-Based Program Synthesis and Transformation (LOPSTR 2017), Namur,\n  Belgium, 10-12 October 2017 (arXiv:1708.07854)", "journal-ref": null, "doi": null, "report-no": "LOPSTR/2017/9", "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unification and generalization are operations on two terms computing\nrespectively their greatest lower bound and least upper bound when the terms\nare quasi-ordered by subsumption up to variable renaming (i.e., $t_1\\preceq\nt_2$ iff $t_1 = t_2\\sigma$ for some variable substitution $\\sigma$). When term\nsignatures are such that distinct functor symbols may be related with a fuzzy\nequivalence (called a similarity), these operations can be formally extended to\ntolerate mismatches on functor names and/or arity or argument order. We\nreformulate and extend previous work with a declarative approach defining\nunification and generalization as sets of axioms and rules forming a complete\nconstraint-normalization proof system. These include the Reynolds-Plotkin\nterm-generalization procedures, Maria Sessa's \"weak\" unification with partially\nfuzzy signatures and its corresponding generalization, as well as novel\nextensions of such operations to fully fuzzy signatures (i.e., similar functors\nwith possibly different arities). One advantage of this approach is that it\nrequires no modification of the conventional data structures for terms and\nsubstitutions. This and the fact that these declarative specifications are\nefficiently executable conditional Horn-clauses offers great practical\npotential for fuzzy information-handling applications.\n", "versions": [{"version": "v1", "created": "Mon, 4 Sep 2017 13:57:25 GMT"}, {"version": "v2", "created": "Mon, 25 Sep 2017 12:14:14 GMT"}, {"version": "v3", "created": "Fri, 13 Oct 2017 10:15:08 GMT"}, {"version": "v4", "created": "Tue, 17 Oct 2017 06:23:12 GMT"}], "update_date": "2017-10-18", "authors_parsed": [["A\u00eft-Kaci", "Hassan", ""], ["Pasi", "Gabriella", ""]]}, {"id": "1709.01304", "submitter": "Stefan Wagner", "authors": "Stefan Wagner and Florian Deissenboeck", "title": "Abstractness, specificity, and complexity in software design", "comments": "8 pages, 3 figures", "journal-ref": "Proceedings of the 2nd International Workshop on The Role of\n  Abstraction in Software Engineering (ROA '08), pages 35-42, ACM, 2008", "doi": "10.1145/1370164.1370173", "report-no": null, "categories": "cs.SE cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Abstraction is one of the fundamental concepts of software design.\nConsequently, the determination of an appropriate abstraction level for the\nmultitude of artefacts that form a software system is an integral part of\nsoftware engineering. However, the very nature of abstraction in software\ndesign and particularly its interrelation with equally important concepts like\ncomplexity, specificity or genericity are not fully understood today. As a step\ntowards a better understanding of the trade-offs involved, this paper proposes\na distinction of abstraction into two types that have different effects on the\nspecificity and the complexity of artefacts. We discuss the roles of the two\ntypes of abstraction in software design and explain the interrelations between\nabstractness, specificity, and complexity. Furthermore, we illustrate the\nbenefit of the proposed distinction with multiple examples and describe\nconsequences of our findings for software design activities.\n", "versions": [{"version": "v1", "created": "Tue, 5 Sep 2017 09:38:06 GMT"}], "update_date": "2017-09-06", "authors_parsed": [["Wagner", "Stefan", ""], ["Deissenboeck", "Florian", ""]]}, {"id": "1709.01588", "submitter": "Martin Sulzmann", "authors": "Martin Sulzmann and Kai Stadtm\\\"uller", "title": "Trace-Based Run-time Analysis of Message-Passing Go Programs", "comments": "HVC'17 published version + appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the task of analyzing message-passing programs by observing their\nrun-time behavior.\n  We introduce a purely library-based instrumentation method to trace\ncommunication events during execution. A model of the dependencies among events\ncan be constructed to identify potential bugs. Compared to the vector clock\nmethod, our approach is much simpler and has in general a significant lower\nrun-time overhead.\n  A further advantage is that we also trace events that could not commit. Thus,\nwe can infer alternative communications. This provides the user with additional\ninformation to identify potential bugs.\n  We have fully implemented our approach in the Go programming language and\nprovide a number of examples to substantiate our claims.\n", "versions": [{"version": "v1", "created": "Tue, 5 Sep 2017 20:43:02 GMT"}, {"version": "v2", "created": "Thu, 7 Sep 2017 06:10:07 GMT"}, {"version": "v3", "created": "Wed, 20 Sep 2017 13:17:10 GMT"}, {"version": "v4", "created": "Tue, 30 Jan 2018 11:03:20 GMT"}], "update_date": "2018-01-31", "authors_parsed": [["Sulzmann", "Martin", ""], ["Stadtm\u00fcller", "Kai", ""]]}, {"id": "1709.02076", "submitter": "Clayton Morrison", "authors": "Donya Quick, Clayton T. Morrison", "title": "Composition by Conversation", "comments": "6 pages, 8 figures, accepted to ICMC 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL cs.IR cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Most musical programming languages are developed purely for coding virtual\ninstruments or algorithmic compositions. Although there has been some work in\nthe domain of musical query languages for music information retrieval, there\nhas been little attempt to unify the principles of musical programming and\nquery languages with cognitive and natural language processing models that\nwould facilitate the activity of composition by conversation. We present a\nprototype framework, called MusECI, that merges these domains, permitting\nscore-level algorithmic composition in a text editor while also supporting\nconnectivity to existing natural language processing frameworks.\n", "versions": [{"version": "v1", "created": "Thu, 7 Sep 2017 05:39:00 GMT"}], "update_date": "2017-09-08", "authors_parsed": [["Quick", "Donya", ""], ["Morrison", "Clayton T.", ""]]}, {"id": "1709.02092", "submitter": "EPTCS", "authors": "Aleksandar S. Dimovski (IT University of Copenhagen)", "title": "Probabilistic Analysis Based On Symbolic Game Semantics and Model\n  Counting", "comments": "In Proceedings GandALF 2017, arXiv:1709.01761", "journal-ref": "EPTCS 256, 2017, pp. 1-15", "doi": "10.4204/EPTCS.256.1", "report-no": null, "categories": "cs.PL cs.FL cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic program analysis aims to quantify the probability that a given\nprogram satisfies a required property. It has many potential applications, from\nprogram understanding and debugging to computing program reliability, compiler\noptimizations and quantitative information flow analysis for security. In these\nsituations, it is usually more relevant to quantify the probability of\nsatisfying/violating a given property than to just assess the possibility of\nsuch events to occur.\n  In this work, we introduce an approach for probabilistic analysis of open\nprograms (i.e. programs with undefined identifiers) based on game semantics and\nmodel counting. We use a symbolic representation of algorithmic game semantics\nto collect the symbolic constraints on the input data (context) that lead to\nthe occurrence of the target events (e.g. satisfaction/violation of a given\nproperty). The constraints are then analyzed to quantify how likely is an input\nto satisfy them. We use model counting techniques to count the number of\nsolutions (from a bounded integer domain) that satisfy given constraints. These\ncounts are then used to assign probabilities to program executions and to\nassess the probability for the target event to occur at the desired level of\nconfidence. Finally, we present the results of applying our approach to several\ninteresting examples and illustrate the benefits they may offer.\n", "versions": [{"version": "v1", "created": "Thu, 7 Sep 2017 06:53:49 GMT"}], "update_date": "2017-09-08", "authors_parsed": [["Dimovski", "Aleksandar S.", "", "IT University of Copenhagen"]]}, {"id": "1709.02346", "submitter": "Ian Cassar", "authors": "Ian Cassar", "title": "Towards Runtime Adaptation of Actor Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this dissertation we focus on providing effective adaptations that can be\nlocalised and applied to specific concurrent actors, thereby only causing a\ntemporary disruption to the parts of the system requiring mitigation, while\nleaving the rest of the system intact. We make the application of localised\nadaptations efficient through incremental synchronisation, whereby the\nspecifier can strategically suspend specific parts of the system, whenever this\nis strictly required for ensuring that adaptations are effectively applied. We\nalso study static analysis techniques to determine whether the specified\nincremental synchronisation is in some sense adequate for local adaptations to\nbe carried out.\n  We thus identify a number of generic adaptations that can be applied to any\nactor system, regardless of its design and the code that it executes. We\nimplement the identified adaptations as an extension of an existing Runtime\nVerification tool for actor-systems, thereby creating a RA framework for\nmonitoring and mitigating actor systems. In parallel to our implementation we\nalso develop a formal model of our RA framework that further serves to guide\nour implementation. This model also enables us to better understand the subtle\nerrors that erroneously specified adaptation scripts may introduce. We thus\ndevelop a static type system for detecting and rejecting erroneous adaptation\nscripts prior to deployment, thereby providing the specifier with assistance\nfor writing valid scripts. Although the static typesystem analyses scripts with\nrespect to certain assumptions, we do not assume that the monitored system\nabides by these assumptions. We therefore augment our RA framework with dynamic\nchecks for halting monitoring whenever the system deviates from our assumption.\nBased on this dynamically checked model of our RA framework, we prove type\nsoundness for our static type system.\n", "versions": [{"version": "v1", "created": "Thu, 31 Aug 2017 13:01:13 GMT"}], "update_date": "2017-09-08", "authors_parsed": [["Cassar", "Ian", ""]]}, {"id": "1709.02610", "submitter": "Nachshon Cohen", "authors": "Nachshon Cohen, Michal Friedman, James R. Larus", "title": "Efficient Logging in Non-Volatile Memory by Exploiting Coherency\n  Protocols", "comments": null, "journal-ref": null, "doi": "10.1145/3133891", "report-no": null, "categories": "cs.DC cs.DB cs.PL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Non-volatile memory (NVM) technologies such as PCM, ReRAM and STT-RAM allow\nprocessors to directly write values to persistent storage at speeds that are\nsignificantly faster than previous durable media such as hard drives or SSDs.\nMany applications of NVM are constructed on a logging subsystem, which enables\noperations to appear to execute atomically and facilitates recovery from\nfailures. Writes to NVM, however, pass through a processor's memory system,\nwhich can delay and reorder them and can impair the correctness and cost of\nlogging algorithms.\n  Reordering arises because of out-of-order execution in a CPU and the\ninter-processor cache coherence protocol. By carefully considering the\nproperties of these reorderings, this paper develops a logging protocol that\nrequires only one round trip to non-volatile memory while avoiding expensive\ncomputations. We show how to extend the logging protocol to building a\npersistent set (hash map) that also requires only a single round trip to\nnon-volatile memory for insertion, updating, or deletion.\n", "versions": [{"version": "v1", "created": "Fri, 8 Sep 2017 09:35:29 GMT"}], "update_date": "2017-09-11", "authors_parsed": [["Cohen", "Nachshon", ""], ["Friedman", "Michal", ""], ["Larus", "James R.", ""]]}, {"id": "1709.03245", "submitter": "Fatemeh Ghassemi", "authors": "Rosa Abbasi, Fatemeh Ghassemi, Ramtin Khosravi", "title": "Verification of Asynchronous Systems with an Unspecified Component", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO cs.PL", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Component-based systems evolve as a new component is added or an existing one\nis replaced by a newer version. Hence, it is appealing to assure the new system\nstill preserves its safety properties. However, instead of inspecting the new\nsystem as a whole, which may result in a large state space, it is beneficial to\nreuse the verification results by inspecting the newly added component in\nisolation. To this aim, we study the problem of model checking component-based\nasynchronously communicating systems in the presence of an unspecified\ncomponent against safety properties. Our solution is based on assume-guarantee\nreasoning, adopted for asynchronous environments, which generates the weakest\nassumption. If the newly added component conforms to the assumption, then the\nwhole system still satisfies the property. To make the approach efficient and\nconvergent, we produce an overapproximated interface of the missing component\nand by its composition with the rest of the system components, we achieve an\noverapproximated specification of the system, from which we remove those traces\nof the system that violate the property and generate an assumption for the\nmissing component.\n  We have implemented our approach on two case studies. Furthermore, we\ncompared our results with the state of the art direct approach. Our resulting\nassumptions are smaller in size and achieved faster.\n", "versions": [{"version": "v1", "created": "Mon, 11 Sep 2017 05:26:43 GMT"}], "update_date": "2017-09-14", "authors_parsed": [["Abbasi", "Rosa", ""], ["Ghassemi", "Fatemeh", ""], ["Khosravi", "Ramtin", ""]]}, {"id": "1709.03404", "submitter": "Oskar Schirmer", "authors": "Felix Winkelmann, Oskar Schirmer", "title": "A Domain-specific Language for High-reliability Software used in the\n  JUICE SWI Instrument - The hO Language Manual", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  hO is a custom restricted dialect of Oberon, developed at the Max-Planck\nInstitute for Solar System Research in G\\\"ottingen and used in the SWI flight\nsoftware for the JUICE mission. hO is applied to reduce the possibility of\nsyntactically valid but incorrect code, provide better means of statically\nanalyzing source code, is more readable than C and gives syntactic support for\nthe software architecture used in the SWI instrument software. By using a\nhigher-level, application-specific notation a whole range of possible errors is\neliminated and source code size is reduced, while making the code itself easier\nto understand, review and analyze.\n", "versions": [{"version": "v1", "created": "Mon, 11 Sep 2017 14:27:33 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["Winkelmann", "Felix", ""], ["Schirmer", "Oskar", ""]]}, {"id": "1709.03652", "submitter": "Gustavo Betarte", "authors": "Gustavo Betarte, Juan Campo, Felipe Gorostiaga and Carlos Luna", "title": "A certified reference validation mechanism for the permission model of\n  Android", "comments": "Pre-proceedings paper presented at the 27th International Symposium\n  on Logic-Based Program Synthesis and Transformation (LOPSTR 2017), Namur,\n  Belgium, 10-12 October 2017 (arXiv:1708.07854)", "journal-ref": null, "doi": null, "report-no": "LOPSTR/2017/11", "categories": "cs.PL cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Android embodies security mechanisms at both OS and application level. In\nthis platform application security is built primarily upon a system of\npermissions which specify restrictions on the operations a particular process\ncan perform. The critical role of these security mechanisms makes them a prime\ntarget for (formal) verification. We present an idealized model of a reference\nmonitor of the novel mechanisms of Android 6 (and further), where it is\npossible to grant permissions at run time. Using the programming language of\nthe proof-assistant Coq we have developed a functional implementation of the\nreference validation mechanism and certified its correctness with respect to\nthe specified reference monitor. Several properties concerning the permission\nmodel of Android 6 and its security mechanisms have been formally formulated\nand proved. Applying the program extraction mechanism provided by Coq we have\nalso derived a certified Haskell prototype of the reference validation\nmechanism.\n", "versions": [{"version": "v1", "created": "Tue, 12 Sep 2017 02:00:51 GMT"}], "update_date": "2017-09-13", "authors_parsed": [["Betarte", "Gustavo", ""], ["Campo", "Juan", ""], ["Gorostiaga", "Felipe", ""], ["Luna", "Carlos", ""]]}, {"id": "1709.04037", "submitter": "Petr Novotn\\'y", "authors": "Sheshansh Agrawal, Krishnendu Chatterjee, Petr Novotn\\'y", "title": "Lexicographic Ranking Supermartingales: An Efficient Approach to\n  Termination of Probabilistic Programs", "comments": "Preliminary version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic programs extend classical imperative programs with real-valued\nrandom variables and random branching. The most basic liveness property for\nsuch programs is the termination property. The qualitative (aka almost-sure)\ntermination problem given a probabilistic program asks whether the program\nterminates with probability 1. While ranking functions provide a sound and\ncomplete method for non-probabilistic programs, the extension of them to\nprobabilistic programs is achieved via ranking supermartingales (RSMs). While\ndeep theoretical results have been established about RSMs, their application to\nprobabilistic programs with nondeterminism has been limited only to academic\nexamples. For non-probabilistic programs, lexicographic ranking functions\nprovide a compositional and practical approach for termination analysis of\nreal-world programs. In this work we introduce lexicographic RSMs and show that\nthey present a sound method for almost-sure termination of probabilistic\nprograms with nondeterminism. We show that lexicographic RSMs provide a tool\nfor compositional reasoning about almost sure termination, and for\nprobabilistic programs with linear arithmetic they can be synthesized\nefficiently (in polynomial time). We also show that with additional\nrestrictions even asymptotic bounds on expected termination time can be\nobtained through lexicographic RSMs. Finally, we present experimental results\non abstractions of real-world programs to demonstrate the effectiveness of our\napproach.\n", "versions": [{"version": "v1", "created": "Tue, 12 Sep 2017 19:35:47 GMT"}], "update_date": "2017-09-14", "authors_parsed": [["Agrawal", "Sheshansh", ""], ["Chatterjee", "Krishnendu", ""], ["Novotn\u00fd", "Petr", ""]]}, {"id": "1709.04152", "submitter": "Cosimo Laneve", "authors": "Abel Garcia, Cosimo Laneve", "title": "Deadlock detection of Java Bytecode", "comments": "Pre-proceedings paper presented at the 27th International Symposium\n  on Logic-Based Program Synthesis and Transformation (LOPSTR 2017), Namur,\n  Belgium, 10-12 October 2017 (arXiv:1708.07854)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a technique for deadlock detection of Java programs. The\ntechnique uses typing rules for extracting infinite-state abstract models of\nthe dependencies among the components of the Java intermediate language -- the\nJava bytecode. Models are subsequently analysed by means of an extension of a\nsolver that we have defined for detecting deadlocks in process calculi. Our\ntechnique is complemented by a prototype verifier that also covers most of the\nJava features.\n", "versions": [{"version": "v1", "created": "Wed, 13 Sep 2017 06:36:33 GMT"}], "update_date": "2017-09-14", "authors_parsed": [["Garcia", "Abel", ""], ["Laneve", "Cosimo", ""]]}, {"id": "1709.04199", "submitter": "EPTCS", "authors": "Ekaterina Komendantskaya (Heriot-Watt University), John Power\n  (University of Bath)", "title": "Proceedings of the First Workshop on Coalgebra, Horn Clause Logic\n  Programming and Types", "comments": null, "journal-ref": "EPTCS 258, 2017", "doi": "10.4204/EPTCS.258", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Workshop on Coalgebra, Horn Clause Logic Programming and Types was held\non the 28-29 November 2016 in Edinburgh. The workshop marked the end of the\nEPSRC Grant Coalgebraic Logic Programming for Type Inference, by E.\nKomendantskaya, Heriot-Watt University and J. Power, University of Bath, UK.\n", "versions": [{"version": "v1", "created": "Wed, 13 Sep 2017 09:07:50 GMT"}], "update_date": "2017-09-14", "authors_parsed": [["Komendantskaya", "Ekaterina", "", "Heriot-Watt University"], ["Power", "John", "", "University of Bath"]]}, {"id": "1709.04255", "submitter": "Miguel Isabel", "authors": "Elvira Albert, Miguel G\\'omez-Zamalloa and Miguel Isabel", "title": "On the Generation of Initial Contexts for Effective Deadlock Detection", "comments": "Pre-proceedings paper presented at the 27th International Symposium\n  on Logic-Based Program Synthesis and Transformation (LOPSTR 2017), Namur,\n  Belgium, 10-12 October 2017 (arXiv:1708.07854)", "journal-ref": null, "doi": null, "report-no": "LOPSTR/2017/15", "categories": "cs.PL cs.DC cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been recently proposed that testing based on symbolic execution can be\nused in conjunction with static deadlock analysis to define a deadlock\ndetection framework that: (i) can show deadlock presence, in that case a\nconcrete test-case and trace are obtained, and (ii) can also prove deadlock\nfreedom. Such symbolic execution starts from an initial distributed context,\ni.e., a set of locations and their initial tasks. Considering all possibilities\nresults in a combinatorial explosion on the different distributed contexts that\nmust be considered. This paper proposes a technique to effectively generate\ninitial contexts that can lead to deadlock, using the possible conflicting task\ninteractions identified by static analysis, discarding other distributed\ncontexts that cannot lead to deadlock. The proposed technique has been\nintegrated in the above-mentioned deadlock detection framework hence enabling\nit to analyze systems without the need of any user supplied initial context.\n", "versions": [{"version": "v1", "created": "Wed, 13 Sep 2017 11:16:10 GMT"}], "update_date": "2017-09-14", "authors_parsed": [["Albert", "Elvira", ""], ["G\u00f3mez-Zamalloa", "Miguel", ""], ["Isabel", "Miguel", ""]]}, {"id": "1709.04302", "submitter": "Paul Tarau", "authors": "Olivier Bodini and Paul Tarau", "title": "On Uniquely Closable and Uniquely Typable Skeletons of Lambda Terms", "comments": "Pre-proceedings paper presented at the 27th International Symposium\n  on Logic-Based Program Synthesis and Transformation (LOPSTR 2017), Namur,\n  Belgium, 10-12 October 2017 (arXiv:1708.07854)", "journal-ref": null, "doi": null, "report-no": "LOPSTR/2017/10", "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uniquely closable skeletons of lambda terms are Motzkin-trees that\npredetermine the unique closed lambda term that can be obtained by labeling\ntheir leaves with de Bruijn indices. Likewise, uniquely typable skeletons of\nclosed lambda terms predetermine the unique simply-typed lambda term that can\nbe obtained by labeling their leaves with de Bruijn indices.\n  We derive, through a sequence of logic program transformations, efficient\ncode for their combinatorial generation and study their statistical properties.\n  As a result, we obtain context-free grammars describing closable and uniquely\nclosable skeletons of lambda terms, opening the door for their in-depth study\nwith tools from analytic combinatorics.\n  Our empirical study of the more difficult case of (uniquely) typable terms\nreveals some interesting open problems about their density and asymptotic\nbehavior.\n  As a connection between the two classes of terms, we also show that uniquely\ntypable closed lambda term skeletons of size $3n+1$ are in a bijection with\nbinary trees of size $n$.\n", "versions": [{"version": "v1", "created": "Wed, 13 Sep 2017 12:57:20 GMT"}], "update_date": "2017-09-14", "authors_parsed": [["Bodini", "Olivier", ""], ["Tarau", "Paul", ""]]}, {"id": "1709.04382", "submitter": "David Monniaux", "authors": "David Monniaux (VERIMAG - IMAG)", "title": "On the decidability of the existence of polyhedral invariants in\n  transition systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated program verification often proceeds by exhibiting inductive\ninvariants entailing the desired properties.For numerical properties, a\nclassical class of invariants is convex polyhedra: solution sets of system of\nlinear (in)equalities.Forty years of research on convex polyhedral invariants\nhave focused, on the one hand, on identifying \"easier\" subclasses, on the other\nhand on heuristics for finding general convex polyhedra.These heuristics are\nhowever not guaranteed to find polyhedral inductive invariants when they\nexist.To our best knowledge, the existence of polyhedral inductive invariants\nhas never been proved to be undecidable.In this article, we show that the\nexistence of convex polyhedral invariants is undecidable, even if there is only\none control state in addition to the \"bad\" one.The question is still open if\none is not allowed any nonlinear constraint.\n", "versions": [{"version": "v1", "created": "Wed, 13 Sep 2017 15:28:57 GMT"}, {"version": "v2", "created": "Tue, 15 May 2018 08:31:56 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Monniaux", "David", "", "VERIMAG - IMAG"]]}, {"id": "1709.04421", "submitter": "Gerg\\\"o Barany", "authors": "Gerg\\\"o Barany", "title": "Liveness-Driven Random Program Generation", "comments": "Pre-proceedings paper presented at the 27th International Symposium\n  on Logic-Based Program Synthesis and Transformation (LOPSTR 2017), Namur,\n  Belgium, 10-12 October 2017 (arXiv:1708.07854)", "journal-ref": null, "doi": null, "report-no": "LOPSTR/2017/6", "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Randomly generated programs are popular for testing compilers and program\nanalysis tools, with hundreds of bugs in real-world C compilers found by random\ntesting. However, existing random program generators may generate large amounts\nof dead code (computations whose result is never used). This leaves relatively\nlittle code to exercise a target compiler's more complex optimizations.\n  To address this shortcoming, we introduce liveness-driven random program\ngeneration. In this approach the random program is constructed bottom-up,\nguided by a simultaneous structural data-flow analysis to ensure that the\ngenerator never generates dead code.\n  The algorithm is implemented as a plugin for the Frama-C framework. We\nevaluate it in comparison to Csmith, the standard random C program generator.\nOur tool generates programs that compile to more machine code with a more\ncomplex instruction mix.\n", "versions": [{"version": "v1", "created": "Wed, 13 Sep 2017 17:06:10 GMT"}], "update_date": "2017-09-14", "authors_parsed": [["Barany", "Gerg\u00f6", ""]]}, {"id": "1709.04497", "submitter": "Julien Signoles", "authors": "Michele Alberti and Julien Signoles", "title": "Context Generation from Formal Specifications for C Analysis Tools", "comments": "Pre-proceedings paper presented at the 27th International Symposium\n  on Logic-Based Program Synthesis and Transformation (LOPSTR 2017), Namur,\n  Belgium, 10-12 October 2017 (arXiv:1708.07854)", "journal-ref": null, "doi": null, "report-no": "LOPSTR/2017/14", "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analysis tools like abstract interpreters, symbolic execution tools and\ntesting tools usually require a proper context to give useful results when\nanalyzing a particular function. Such a context initializes the function\nparameters and global variables to comply with function requirements. However\nit may be error-prone to write it by hand: the handwritten context might\ncontain bugs or not match the intended specification. A more robust approach is\nto specify the context in a dedicated specification language, and hold the\nanalysis tools to support it properly. This may mean to put significant\ndevelopment efforts for enhancing the tools, something that is often not\nfeasible if ever possible.\n  This paper presents a way to systematically generate such a context from a\nformal specification of a C function. This is applied to a subset of the ACSL\nspecification language in order to generate suitable contexts for the abstract\ninterpretation-based value analysis plug-ins of Frama-C, a framework for\nanalysis of code written in C. The idea here presented has been implemented in\na new Frama-C plug-in which is currently in use in an operational industrial\nsetting.\n", "versions": [{"version": "v1", "created": "Tue, 5 Sep 2017 08:38:25 GMT"}], "update_date": "2017-09-15", "authors_parsed": [["Alberti", "Michele", ""], ["Signoles", "Julien", ""]]}, {"id": "1709.04619", "submitter": "Keehang Kwon", "authors": "Keehang Kwon", "title": "Extending Functional Languages with High-Level Exception Handling", "comments": "3 pages. We discuss the notion of exception handling and its dual in\n  functional languages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend functional languages with high-level exception handling. To be\nspecific, we allow sequential-disjunction expressions of the form $E_0\n\\bigtriangledown E_1$ where $E_0, E_1$ are expressions. These expressions have\nthe following intended semantics: sequentially $choose$ the first successful\n$E_i$ and evaluate $E_i$ where $i$ = 0 or 1. These expressions thus allow us to\nspecify an expression $E_0$ with the failure-handling (exception handling)\nroutine, i.e., expression $E_1$. We also discuss the class of\nsequential-conjunction function declarations which is a dual of the former.\n", "versions": [{"version": "v1", "created": "Thu, 14 Sep 2017 05:39:55 GMT"}, {"version": "v2", "created": "Wed, 26 Dec 2018 09:02:39 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Kwon", "Keehang", ""]]}, {"id": "1709.04714", "submitter": "EPTCS", "authors": "Bashar Igried (Dept. of Computer Science, Swansea University), Anton\n  Setzer (Dept. of Computer Science, Swansea University)", "title": "Trace and Stable Failures Semantics for CSP-Agda", "comments": "In Proceedings CoALP-Ty'16, arXiv:1709.04199", "journal-ref": "EPTCS 258, 2017, pp. 36-51", "doi": "10.4204/EPTCS.258.3", "report-no": null, "categories": "cs.PL cs.DC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  CSP-Agda is a library, which formalises the process algebra CSP in the\ninteractive theorem prover Agda using coinductive data types. In CSP-Agda, CSP\nprocesses are in monadic form, which sup- ports a modular development of\nprocesses. In this paper, we implement two main models of CSP, trace and stable\nfailures semantics, in CSP-Agda, and define the corresponding refinement and\nequal- ity relations. Because of the monadic setting, some adjustments need to\nbe made. As an example, we prove commutativity of the external choice operator\nw.r.t. the trace semantics in CSP-Agda, and that refinement w.r.t. stable\nfailures semantics is a partial order. All proofs and definitions have been\ntype checked in Agda. Further proofs of algebraic laws will be available in the\nCSP-Agda repository.\n", "versions": [{"version": "v1", "created": "Thu, 14 Sep 2017 11:35:47 GMT"}], "update_date": "2017-09-15", "authors_parsed": [["Igried", "Bashar", "", "Dept. of Computer Science, Swansea University"], ["Setzer", "Anton", "", "Dept. of Computer Science, Swansea University"]]}, {"id": "1709.04816", "submitter": "Michael Hanus", "authors": "Michael Hanus", "title": "Combining Static and Dynamic Contract Checking for Curry", "comments": "Pre-proceedings paper presented at the 27th International Symposium\n  on Logic-Based Program Synthesis and Transformation (LOPSTR 2017), Namur,\n  Belgium, 10-12 October 2017 (arXiv:1708.07854)", "journal-ref": null, "doi": null, "report-no": "Report number: LOPSTR/2017/21", "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Static type systems are usually not sufficient to express all requirements on\nfunction calls. Hence, contracts with pre- and postconditions can be used to\nexpress more complex constraints on operations. Contracts can be checked at run\ntime to ensure that operations are only invoked with reasonable arguments and\nreturn intended results. Although such dynamic contract checking provides more\nreliable program execution, it requires execution time and could lead to\nprogram crashes that might be detected with more advanced methods at compile\ntime. To improve this situation for declarative languages, we present an\napproach to combine static and dynamic contract checking for the functional\nlogic language Curry. Based on a formal model of contract checking for\nfunctional logic programming, we propose an automatic method to verify\ncontracts at compile time. If a contract is successfully verified, dynamic\nchecking of it can be omitted. This method decreases execution time without\ndegrading reliable program execution. In the best case, when all contracts are\nstatically verified, it provides trust in the software since crashes due to\ncontract violations cannot occur during program execution.\n", "versions": [{"version": "v1", "created": "Thu, 14 Sep 2017 14:35:50 GMT"}], "update_date": "2017-09-15", "authors_parsed": [["Hanus", "Michael", ""]]}, {"id": "1709.04901", "submitter": "EPTCS", "authors": "Davide Ancona (DIBRIS, University of Genova), Francesco Dagnino\n  (DIBRIS, University of Genova), Elena Zucca (DIBRIS, University of Genova)", "title": "Extending Coinductive Logic Programming with Co-Facts", "comments": "In Proceedings CoALP-Ty'16, arXiv:1709.04199", "journal-ref": "EPTCS 258, 2017, pp. 1-18", "doi": "10.4204/EPTCS.258.1", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a generalized logic programming paradigm where programs,\nconsisting of facts and rules with the usual syntax, can be enriched by\nco-facts, which syntactically resemble facts but have a special meaning. As in\ncoinductive logic programming, interpretations are subsets of the complete\nHerbrand basis, including infinite terms. However, the intended meaning\n(declarative semantics) of a program is a fixed point which is not necessarily\nthe least, nor the greatest one, but is determined by co-facts. In this way, it\nis possible to express predicates on non well-founded structures, such as\ninfinite lists and graphs, for which the coinductive interpretation would be\nnot precise enough. Moreover, this paradigm nicely subsumes standard\n(inductive) and coinductive logic programming, since both can be expressed by a\nparticular choice of co-facts, hence inductive and coinductive predicates can\ncoexist in the same program. We illustrate the paradigm by examples, and\nprovide declarative and operational semantics, proving the correctness of the\nlatter. Finally, we describe a prototype meta-interpreter.\n", "versions": [{"version": "v1", "created": "Thu, 14 Sep 2017 17:45:35 GMT"}], "update_date": "2017-09-26", "authors_parsed": [["Ancona", "Davide", "", "DIBRIS, University of Genova"], ["Dagnino", "Francesco", "", "DIBRIS, University of Genova"], ["Zucca", "Elena", "", "DIBRIS, University of Genova"]]}, {"id": "1709.04902", "submitter": "EPTCS", "authors": "Luca Franceschini (University of Genoa, Italy), Davide Ancona\n  (University of Genoa, Italy), Ekaterina Komendantskaya (Heriot-Watt\n  University, Edinburgh, UK)", "title": "Structural Resolution for Abstract Compilation of Object-Oriented\n  Languages", "comments": "In Proceedings CoALP-Ty'16, arXiv:1709.04199", "journal-ref": "EPTCS 258, 2017, pp. 19-35", "doi": "10.4204/EPTCS.258.2", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose abstract compilation for precise static type analysis of\nobject-oriented languages based on coinductive logic programming. Source code\nis translated to a logic program, then type-checking and inference problems\namount to queries to be solved with respect to the resulting logic program. We\nexploit a coinductive semantics to deal with infinite terms and proofs produced\nby recursive types and methods. Thanks to the recent notion of structural\nresolution for coinductive logic programming, we are able to infer very precise\ntype information, including a class of irrational recursive types causing\nnon-termination for previously considered coinductive semantics. We also show\nhow to transform logic programs to make them satisfy the preconditions for the\noperational semantics of structural resolution, and we prove this step does not\naffect the semantics of the logic program.\n", "versions": [{"version": "v1", "created": "Thu, 14 Sep 2017 17:45:51 GMT"}], "update_date": "2017-09-15", "authors_parsed": [["Franceschini", "Luca", "", "University of Genoa, Italy"], ["Ancona", "Davide", "", "University of Genoa, Italy"], ["Komendantskaya", "Ekaterina", "", "Heriot-Watt\n  University, Edinburgh, UK"]]}, {"id": "1709.04991", "submitter": "Adrian Sampson", "authors": "Alex Renda, Harrison Goldstein, Sarah Bird, Chris Quirk and Adrian\n  Sampson", "title": "Abstractions for AI-Based User Interfaces and Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Novel user interfaces based on artificial intelligence, such as\nnatural-language agents, present new categories of engineering challenges.\nThese systems need to cope with uncertainty and ambiguity, interface with\nmachine learning algorithms, and compose information from multiple users to\nmake decisions. We propose to treat these challenges as language-design\nproblems. We describe three programming language abstractions for three core\nproblems in intelligent system design. First, hypothetical worlds support\nnondeterministic search over spaces of alternative actions. Second, a feature\ntype system abstracts the interaction between applications and learning\nalgorithms. Finally, constructs for collaborative execution extend hypothetical\nworlds across multiple machines while controlling access to private data. We\nenvision these features as first steps toward a complete language for\nimplementing AI-based interfaces and applications.\n", "versions": [{"version": "v1", "created": "Thu, 14 Sep 2017 21:53:01 GMT"}], "update_date": "2017-09-18", "authors_parsed": [["Renda", "Alex", ""], ["Goldstein", "Harrison", ""], ["Bird", "Sarah", ""], ["Quirk", "Chris", ""], ["Sampson", "Adrian", ""]]}, {"id": "1709.05045", "submitter": "Stephen Skeirik", "authors": "Stephen Skeirik, Andrei Stefanescu, Jos\\'e Meseguer", "title": "A Constructor-Based Reachability Logic for Rewrite Theories", "comments": "Pre-proceedings paper presented at the 27th International Symposium\n  on Logic-Based Program Synthesis and Transformation (LOPSTR 2017), Namur,\n  Belgium, 10-12 October 2017 (arXiv:1708.07854)", "journal-ref": null, "doi": null, "report-no": "Report number: LOPSTR/2017/2", "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reachability logic has been applied to $\\mathbb{K}$ rewrite-rule-based\nlanguage definitions as a language-generic logic of programs. To be able to\nverify not just code but also distributed system designs, a new\nrewrite-theory-generic reachability logic is presented and proved sound for a\nwide class of rewrite theories. The logic's automation is increased by means of\nconstructor-based semantic unification, matching, and satisfiability\nprocedures. New methods for proving invariants of possibly never terminating\ndistributed systems are developed, and experiments with a prototype\nimplementation illustrating the new proof methods are presented.\n", "versions": [{"version": "v1", "created": "Fri, 15 Sep 2017 03:37:46 GMT"}], "update_date": "2017-09-18", "authors_parsed": [["Skeirik", "Stephen", ""], ["Stefanescu", "Andrei", ""], ["Meseguer", "Jos\u00e9", ""]]}, {"id": "1709.05095", "submitter": "Salvador Lucas", "authors": "Salvador Lucas", "title": "A Semantic Approach to the Analysis of Rewriting-Based Systems", "comments": "Pre-proceedings paper presented at the 27th International Symposium\n  on Logic-Based Program Synthesis and Transformation (LOPSTR 2017), Namur,\n  Belgium, 10-12 October 2017 (arXiv:1708.07854)", "journal-ref": null, "doi": null, "report-no": "LOPSTR/2017/19", "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Properties expressed as the provability of a first-order sentence can be\ndisproved by just finding a model of the negation of the sentence. This fact,\nhowever, is meaningful in restricted cases only, depending on the shape of the\nsentence and the class of systems at stake. In this paper we show that a number\nof interesting properties of rewriting-based systems can be investigated in\nthis way, including infeasibility and non-joinability of critical pairs in\n(conditional) rewriting, non-loopingness of conditional rewrite systems, or the\nsecure access to protected pages of a web site modeled as an order-sorted\nrewrite theory. Interestingly, this uniform, semantic approach succeeds when\nspecific techniques developed to deal with the aforementioned problems fail.\n", "versions": [{"version": "v1", "created": "Fri, 15 Sep 2017 08:15:35 GMT"}], "update_date": "2017-09-18", "authors_parsed": [["Lucas", "Salvador", ""]]}, {"id": "1709.05123", "submitter": "Henning Christiansen", "authors": "Maja H. Kirkeby, Henning Christiansen", "title": "Confluence and Convergence in Probabilistically Terminating Reduction\n  Systems", "comments": "Pre-proceedings paper presented at the 27th International Symposium\n  on Logic-Based Program Synthesis and Transformation (LOPSTR 2017), Namur,\n  Belgium, 10-12 October 2017 (arXiv:1708.07854)", "journal-ref": null, "doi": null, "report-no": "LOPSTR/2017/13", "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convergence of an abstract reduction system (ARS) is the property that any\nderivation from an initial state will end in the same final state, a.k.a.\nnormal form. We generalize this for probabilistic ARS as almost-sure\nconvergence, meaning that the normal form is reached with probability one, even\nif diverging derivations may exist. We show and exemplify properties that can\nbe used for proving almost-sure convergence of probabilistic ARS, generalizing\nknown results from ARS.\n", "versions": [{"version": "v1", "created": "Fri, 15 Sep 2017 09:30:48 GMT"}, {"version": "v2", "created": "Tue, 3 Oct 2017 07:24:14 GMT"}], "update_date": "2017-10-04", "authors_parsed": [["Kirkeby", "Maja H.", ""], ["Christiansen", "Henning", ""]]}, {"id": "1709.05203", "submitter": "Ra\\'ul Guti\\'errez", "authors": "Ra\\'ul Guti\\'errez and Jos\\'e Meseguer", "title": "Variant-Based Decidable Satisfiability in Initial Algebras with\n  Predicates", "comments": "Pre-proceedings paper presented at the 27th International Symposium\n  on Logic-Based Program Synthesis and Transformation (LOPSTR 2017), Namur,\n  Belgium, 10-12 October 2017 (arXiv:1708.07854)", "journal-ref": null, "doi": null, "report-no": "LOPSTR/2017/4", "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision procedures can be either theory-specific, e.g., Presburger\narithmetic, or theory-generic, applying to an infinite number of user-definable\ntheories. Variant satisfiability is a theory-generic procedure for\nquantifier-free satisfiability in the initial algebra of an order-sorted\nequational theory $({\\Sigma},E \\cup B)$ under two conditions: (i) $E \\cup B$\nhas the finite variant property and $B$ has a finitary unification algorithm;\nand (ii) $({\\Sigma},E \\cup B)$ protects a constructor subtheory\n$({\\Omega},E_{\\Omega} \\cup B_{\\Omega})$ that is OS-compact. These conditions\napply to many user-definable theories, but have a main limitation: they apply\nwell to data structures, but often do not hold for user-definable predicates on\nsuch data structures. We present a theory-generic satisfiability decision\nprocedure, and a prototype implementation, extending variant-based\nsatisfiability to initial algebras with user-definable predicates under fairly\ngeneral conditions.\n", "versions": [{"version": "v1", "created": "Fri, 15 Sep 2017 13:44:15 GMT"}], "update_date": "2017-09-18", "authors_parsed": [["Guti\u00e9rrez", "Ra\u00fal", ""], ["Meseguer", "Jos\u00e9", ""]]}, {"id": "1709.05291", "submitter": "Salvador Tamarit", "authors": "David Insa, Sergio P\\'erez, Josep Silva and Salvador Tamarit", "title": "Erlang Code Evolution Control", "comments": "Pre-proceedings paper presented at the 27th International Symposium\n  on Logic-Based Program Synthesis and Transformation (LOPSTR 2017), Namur,\n  Belgium, 10-12 October 2017 (arXiv:1708.07854)", "journal-ref": null, "doi": null, "report-no": "LOPSTR/2017/26", "categories": "cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the software lifecycle, a program can evolve several times for\ndifferent reasons such as the optimisation of a bottle-neck, the refactoring of\nan obscure function, etc. These code changes often involve several functions or\nmodules, so it can be difficult to know whether the correct behaviour of the\nprevious releases has been preserved in the new release. Most developers rely\non a previously defined test suite to check this behaviour preservation. We\npropose here an alternative approach to automatically obtain a test suite that\nspecifically focusses on comparing the old and new versions of the code. Our\ntest case generation is directed by a sophisticated combination of several\nalready existing tools such as TypEr, CutEr, and PropEr; and other ideas such\nas allowing the programmer to chose an expression of interest that must\npreserve the behaviour, or the recording of the sequences of values to which\nthis expression is evaluated. All the presented work has been implemented in an\nopen-source tool that is publicly available on GitHub.\n", "versions": [{"version": "v1", "created": "Fri, 15 Sep 2017 16:19:40 GMT"}], "update_date": "2017-09-18", "authors_parsed": [["Insa", "David", ""], ["P\u00e9rez", "Sergio", ""], ["Silva", "Josep", ""], ["Tamarit", "Salvador", ""]]}, {"id": "1709.05361", "submitter": "Justin Hsu", "authors": "Aws Albarghouthi, Justin Hsu", "title": "Synthesizing Coupling Proofs of Differential Privacy", "comments": null, "journal-ref": null, "doi": "10.1145/3158146", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential privacy has emerged as a promising probabilistic formulation of\nprivacy, generating intense interest within academia and industry. We present a\npush-button, automated technique for verifying $\\varepsilon$-differential\nprivacy of sophisticated randomized algorithms. We make several conceptual,\nalgorithmic, and practical contributions: (i) Inspired by the recent advances\non approximate couplings and randomness alignment, we present a new proof\ntechnique called coupling strategies, which casts differential privacy proofs\nas a winning strategy in a game where we have finite privacy resources to\nexpend. (ii) To discover a winning strategy, we present a constraint-based\nformulation of the problem as a set of Horn modulo couplings (HMC) constraints,\na novel combination of first-order Horn clauses and probabilistic constraints.\n(iii) We present a technique for solving HMC constraints by transforming\nprobabilistic constraints into logical constraints with uninterpreted\nfunctions. (iv) Finally, we implement our technique in the FairSquare verifier\nand provide the first automated privacy proofs for a number of challenging\nalgorithms from the differential privacy literature, including Report Noisy\nMax, the Exponential Mechanism, and the Sparse Vector Mechanism.\n", "versions": [{"version": "v1", "created": "Fri, 15 Sep 2017 18:22:14 GMT"}, {"version": "v2", "created": "Wed, 8 Nov 2017 20:29:44 GMT"}], "update_date": "2017-11-10", "authors_parsed": [["Albarghouthi", "Aws", ""], ["Hsu", "Justin", ""]]}, {"id": "1709.05376", "submitter": "Christiane Engels", "authors": "Christiane Engels, Andreas Behrend and Stefan Brass", "title": "A Rule-Based Approach to Analyzing Database Schema Objects with Datalog", "comments": "Pre-proceedings paper presented at the 27th International Symposium\n  on Logic-Based Program Synthesis and Transformation (LOPSTR 2017), Namur,\n  Belgium, 10-12 October 2017 (arXiv:1708.07854)", "journal-ref": null, "doi": null, "report-no": "LOPSTR/2017/18", "categories": "cs.PL cs.DB cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Database schema elements such as tables, views, triggers and functions are\ntypically defined with many interrelationships. In order to support database\nusers in understanding a given schema, a rule-based approach for analyzing the\nrespective dependencies is proposed using Datalog expressions. We show that\nmany interesting properties of schema elements can be systematically determined\nthis way. The expressiveness of the proposed analysis is exemplarily shown with\nthe problem of computing induced functional dependencies for derived relations.\nThe propagation of functional dependencies plays an important role in data\nintegration and query optimization but represents an undecidable problem in\ngeneral. And yet, our rule-based analysis covers all relational operators as\nwell as linear recursive expressions in a systematic way showing the depth of\nanalysis possible by our proposal. The analysis of functional dependencies is\nwell-integrated in a uniform approach to analyzing dependencies between schema\nelements in general.\n", "versions": [{"version": "v1", "created": "Fri, 15 Sep 2017 19:23:30 GMT"}], "update_date": "2017-09-19", "authors_parsed": [["Engels", "Christiane", ""], ["Behrend", "Andreas", ""], ["Brass", "Stefan", ""]]}, {"id": "1709.05384", "submitter": "Mauricio Ayala-Rincon", "authors": "Mauricio Ayala-Rinc\\'on, Washington de Carvalho-Segundo, Maribel\n  Fern\\'andez, Daniele Nantes-Sobrinho", "title": "Nominal C-Unification", "comments": "Pre-proceedings paper presented at the 27th International Symposium\n  on Logic-Based Program Synthesis and Transformation (LOPSTR 2017), Namur,\n  Belgium, 10-12 October 2017 (arXiv:1708.07854)", "journal-ref": null, "doi": null, "report-no": "LOPSTR/2017/22", "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nominal unification is an extension of first-order unification that takes\ninto account the \\alpha-equivalence relation generated by binding operators,\nfollowing the nominal approach. We propose a sound and complete procedure for\nnominal unification with commutative operators, or nominal C-unification for\nshort, which has been formalised in Coq. The procedure transforms nominal\nC-unification problems into simpler (finite families) of fixpoint problems,\nwhose solutions can be generated by algebraic techniques on combinatorics of\npermutations.\n", "versions": [{"version": "v1", "created": "Fri, 15 Sep 2017 20:09:44 GMT"}], "update_date": "2017-09-19", "authors_parsed": [["Ayala-Rinc\u00f3n", "Mauricio", ""], ["de Carvalho-Segundo", "Washington", ""], ["Fern\u00e1ndez", "Maribel", ""], ["Nantes-Sobrinho", "Daniele", ""]]}, {"id": "1709.06182", "submitter": "Miltiadis Allamanis", "authors": "Miltiadis Allamanis, Earl T. Barr, Premkumar Devanbu, Charles Sutton", "title": "A Survey of Machine Learning for Big Code and Naturalness", "comments": "Website accompanying this survey paper can be found at\n  https://ml4code.github.io", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research at the intersection of machine learning, programming languages, and\nsoftware engineering has recently taken important steps in proposing learnable\nprobabilistic models of source code that exploit code's abundance of patterns.\nIn this article, we survey this work. We contrast programming languages against\nnatural languages and discuss how these similarities and differences drive the\ndesign of probabilistic models. We present a taxonomy based on the underlying\ndesign principles of each model and use it to navigate the literature. Then, we\nreview how researchers have adapted these models to application areas and\ndiscuss cross-cutting and application-specific challenges and opportunities.\n", "versions": [{"version": "v1", "created": "Mon, 18 Sep 2017 22:03:51 GMT"}, {"version": "v2", "created": "Sat, 5 May 2018 02:38:45 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Allamanis", "Miltiadis", ""], ["Barr", "Earl T.", ""], ["Devanbu", "Premkumar", ""], ["Sutton", "Charles", ""]]}, {"id": "1709.06897", "submitter": "Irina Asavoae", "authors": "Irina Mariuca Asavoae, Mihail Asavoae and Adrian Riesco", "title": "Context-Updates Analysis and Refinement in Chisel", "comments": "Pre-proceedings paper presented at the 27th International Symposium\n  on Logic-Based Program Synthesis and Transformation (LOPSTR 2017), Namur,\n  Belgium, 10-12 October 2017 (arXiv:1708.07854)", "journal-ref": null, "doi": null, "report-no": "LOPSTR/2017/30", "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the context-updates synthesis component of Chisel--a tool\nthat synthesizes a program slicer directly from a given algebraic specification\nof a programming language operational semantics. (By context-updates we\nunderstand programming language constructs such as goto instructions or\nfunction calls.) The context-updates synthesis follows two directions: an\noverapproximating phase that extracts a set of potential context-update\nconstructs and an underapproximating phase that refines the results of the\nfirst step by testing the behaviour of the context-updates constructs produced\nat the previous phase. We use two experimental semantics that cover two types\nof language paradigms: high-level imperative and low-level assembly languages\nand we conduct the tests on standard benchmarks used in avionics.\n", "versions": [{"version": "v1", "created": "Wed, 20 Sep 2017 14:22:50 GMT"}], "update_date": "2017-09-21", "authors_parsed": [["Asavoae", "Irina Mariuca", ""], ["Asavoae", "Mihail", ""], ["Riesco", "Adrian", ""]]}, {"id": "1709.07139", "submitter": "Anthony Widjaja Lin", "authors": "Yu-Fang Chen, Chih-Duo Hong, Anthony W. Lin, and Philipp Ruemmer", "title": "Learning to Prove Safety over Parameterised Concurrent Systems (Full\n  Version)", "comments": "Full version of FMCAD'17 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the classic problem of proving safety over parameterised\nconcurrent systems, i.e., an infinite family of finite-state concurrent systems\nthat are represented by some finite (symbolic) means. An example of such an\ninfinite family is a dining philosopher protocol with any number n of processes\n(n being the parameter that defines the infinite family). Regular model\nchecking is a well-known generic framework for modelling parameterised\nconcurrent systems, where an infinite set of configurations (resp. transitions)\nis represented by a regular set (resp. regular transducer). Although verifying\nsafety properties in the regular model checking framework is undecidable in\ngeneral, many sophisticated semi-algorithms have been developed in the past\nfifteen years that can successfully prove safety in many practical instances.\nIn this paper, we propose a simple solution to synthesise regular inductive\ninvariants that makes use of Angluin's classic L* algorithm (and its variants).\nWe provide a termination guarantee when the set of configurations reachable\nfrom a given set of initial configurations is regular. We have tested L*\nalgorithm on standard (as well as new) examples in regular model checking\nincluding the dining philosopher protocol, the dining cryptographer protocol,\nand several mutual exclusion protocols (e.g. Bakery, Burns, Szymanski, and\nGerman). Our experiments show that, despite the simplicity of our solution, it\ncan perform at least as well as existing semi-algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 21 Sep 2017 02:56:39 GMT"}, {"version": "v2", "created": "Tue, 3 Oct 2017 02:45:47 GMT"}], "update_date": "2017-10-04", "authors_parsed": [["Chen", "Yu-Fang", ""], ["Hong", "Chih-Duo", ""], ["Lin", "Anthony W.", ""], ["Ruemmer", "Philipp", ""]]}, {"id": "1709.07741", "submitter": "Germ\\'an Andr\\'es Delbianco", "authors": "Aleksandar Nanevski, Anindya Banerjee, Germ\\'an Andr\\'es Delbianco", "title": "Subjective Simulation as a Notion of Morphism for Composing Concurrent\n  Resources", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.DC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent approaches to verifying programs in separation logics for concurrency\nhave used state transition systems (STSs) to specify the atomic operations of\nprograms. A key challenge in the setting has been to compose such STSs into\nlarger ones, while enabling programs specified under one STS to be linked to a\nlarger one, without reverification. This paper develops a notion of morphism\nbetween two STSs which permits such lifting. The morphisms are a constructive\nform of simulation between the STSs, and lead to a general and concise proof\nsystem. We illustrate the concept and its generality on several disparate\nexamples, including staged construction of a readers/writers lock and its\nproof, and of proofs about quiescence when concurrent programs are executed\nwithout external interference.\n", "versions": [{"version": "v1", "created": "Fri, 22 Sep 2017 13:35:58 GMT"}], "update_date": "2017-09-25", "authors_parsed": [["Nanevski", "Aleksandar", ""], ["Banerjee", "Anindya", ""], ["Delbianco", "Germ\u00e1n Andr\u00e9s", ""]]}, {"id": "1709.08016", "submitter": "Amey Karkare", "authors": "Prasanna Kumar K., Amitabha Sanyal, Amey Karkare", "title": "An Incremental Slicing Method for Functional Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several applications of slicing require a program to be sliced with respect\nto more than one slicing criterion. Program specialization, parallelization and\ncohesion measurement are examples of such applications. These applications can\nbenefit from an incremental static slicing method in which a significant extent\nof the computations for slicing with respect to one criterion could be reused\nfor another. In this paper, we consider the problem of incremental slicing of\nfunctional programs. We first present a non-incremental version of the slicing\nalgorithm which does a polyvariant analysis 1 of functions. Since polyvariant\nanalyses tend to be costly, we compute a compact context-independent summary of\neach function and then use this summary at the call sites of the function. The\nconstruction of the function summary is non-trivial and helps in the\ndevelopment of the incremental version. The incremental method, on the other\nhand, consists of a one-time pre-computation step that uses the non-incremental\nversion to slice the program with respect to a fixed default slicing criterion\nand processes the results further to a canonical form. Presented with an actual\nslicing criterion, the incremental step involves a low-cost computation that\nuses the results of the pre-computation to obtain the slice. We have\nimplemented a prototype of the slicer for a pure subset of Scheme, with pairs\nand lists as the only algebraic data types. Our experiments show that the\nincremental step of the slicer runs orders of magnitude faster than the\nnon-incremental version. We have also proved the correctness of our incremental\nalgorithm with respect to the non-incremental version.\n", "versions": [{"version": "v1", "created": "Sat, 23 Sep 2017 07:55:10 GMT"}], "update_date": "2017-09-26", "authors_parsed": [["K.", "Prasanna Kumar", ""], ["Sanyal", "Amitabha", ""], ["Karkare", "Amey", ""]]}, {"id": "1709.08056", "submitter": "Moez AbdelGawad", "authors": "Moez A. AbdelGawad", "title": "Novel Uses of Category Theory in Modeling OOP", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An outline and summary of four new potential applications of category theory\nto OOP research are presented. These include (1) the use of operads to model\nJava subtyping, (2) the use of Yoneda's lemma and representable functors in the\nmodeling of generic types in generic nominally-typed OOP, (3) using a\ncombination of category presentations and cartesian closed categories to model\nstructurally-typed OOP, and (4) the use of adjoint functors to model Java\nerasure.\n", "versions": [{"version": "v1", "created": "Sat, 23 Sep 2017 14:10:29 GMT"}, {"version": "v2", "created": "Wed, 27 Sep 2017 10:41:26 GMT"}, {"version": "v3", "created": "Mon, 25 Dec 2017 19:42:11 GMT"}, {"version": "v4", "created": "Fri, 29 Dec 2017 17:46:21 GMT"}], "update_date": "2018-01-01", "authors_parsed": [["AbdelGawad", "Moez A.", ""]]}, {"id": "1709.08193", "submitter": "Keehang Kwon", "authors": "Keehang Kwon", "title": "Anonymous Variables in Imperative Languages", "comments": "5 pages, We describe some usage of blind universal/existential\n  quantifiers in imperative languages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we bring anonymous variables into imperative languages.\nAnonymous variables represent don't-care values and have proven useful in logic\nprogramming. To bring the same level of benefits into imperative languages, we\ndescribe an extension to C wth anonymous variables.\n", "versions": [{"version": "v1", "created": "Sun, 24 Sep 2017 13:04:34 GMT"}], "update_date": "2017-09-26", "authors_parsed": [["Kwon", "Keehang", ""]]}, {"id": "1709.09369", "submitter": "Giuseppe Lipari", "authors": "Cl\\'ement Ballabriga, Julien Forget, Giuseppe Lipari", "title": "Symbolic Computation of the Worst-Case Execution Time of a Program", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parametric Worst-case execution time (WCET) analysis of a sequential program\nproduces a formula that represents the worst-case execution time of the\nprogram, where parameters of the formula are user-defined parameters of the\nprogram (as loop bounds, values of inputs or internal variables, etc).\n  In this paper we propose a novel methodology to compute the parametric WCET\nof a program. Unlike other algorithms in the literature, our method is not\nbased on Integer Linear Programming (ILP). Instead, we follow an approach based\non the notion of symbolic computation of WCET formulae. After explaining our\nmethodology and proving its correctness, we present a set of experiments to\ncompare our method against the state of the art. We show that our approach\ndominates other parametric analyses, and produces results that are very close\nto those produced by non-parametric ILP-based approaches, while keeping very\ngood computing time.\n", "versions": [{"version": "v1", "created": "Wed, 27 Sep 2017 07:40:57 GMT"}], "update_date": "2017-10-09", "authors_parsed": [["Ballabriga", "Cl\u00e9ment", ""], ["Forget", "Julien", ""], ["Lipari", "Giuseppe", ""]]}, {"id": "1709.09623", "submitter": "Hongxu Chen", "authors": "Hongxu Chen, Alwen Tiu, Zhiwu Xu, Yang Liu", "title": "A Permission-Dependent Type System for Secure Information Flow Analysis", "comments": "48 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel type system for enforcing secure information flow in an\nimperative language. Our work is motivated by the problem of statically\nchecking potential information leakage in Android applications. To this end, we\ndesign a lightweight type system featuring Android permission model, where the\npermissions are statically assigned to applications and are used to enforce\naccess control in the applications. We take inspiration from a type system by\nBanerjee and Naumann (BN) to allow security types to be dependent on the\npermissions of the applications. A novel feature of our type system is a typing\nrule for conditional branching induced by permission testing, which introduces\na merging operator on security types, allowing more precise security policies\nto be enforced. The soundness of our type system is proved with respect to a\nnotion of noninterference. In addition, a type inference algorithm is presented\nfor the underlying security type system, by reducing the inference problem to a\nconstraint solving problem in the lattice of security types.\n", "versions": [{"version": "v1", "created": "Wed, 27 Sep 2017 16:55:25 GMT"}], "update_date": "2017-09-28", "authors_parsed": [["Chen", "Hongxu", ""], ["Tiu", "Alwen", ""], ["Xu", "Zhiwu", ""], ["Liu", "Yang", ""]]}, {"id": "1709.10008", "submitter": "Valentin Touzeau", "authors": "Claire Maiza (VERIMAG - IMAG), Valentin Touzeau (VERIMAG - IMAG),\n  Claire Ma\u00a8{\\i}za, David Monniaux (VERIMAG - IMAG), Jan Reineke", "title": "Ascertaining Uncertainty for Efficient Exact Cache Analysis", "comments": null, "journal-ref": "Rupak Majumdar; Viktor Kuncak. Computer Aided Verification - 29th\n  International Conference, Jul 2017, Heidelberg, France. Springer, 10427 (2),\n  pp.20 - 40, 2017, Lecture notes in computer science.\n  http://cavconference.org/2017/", "doi": "10.1007/978-3-319-63390-9_2", "report-no": null, "categories": "cs.PL cs.AR cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Static cache analysis characterizes a program's cache behavior by determining\nin a sound but approximate manner which memory accesses result in cache hits\nand which result in cache misses. Such information is valuable in optimizing\ncompilers, worst-case execution time analysis, and side-channel attack\nquantification and mitigation.Cache analysis is usually performed as a\ncombination of `must' and `may' abstract interpretations, classifying\ninstructions as either `always hit', `always miss', or `unknown'. Instructions\nclassified as `unknown' might result in a hit or a miss depending on program\ninputs or the initial cache state. It is equally possible that they do in fact\nalways hit or always miss, but the cache analysis is too coarse to see it.Our\napproach to eliminate this uncertainty consists in (i) a novel abstract\ninterpretation able to ascertain that a particular instruction may definitely\ncause a hit and a miss on different paths, and (ii) an exact analysis, removing\nall remaining uncertainty, based on model checking, using\nabstract-interpretation results to prune down the model for scalability.We\nevaluated our approach on a variety of examples; it notably improves precision\nupon classical abstract interpretation at reasonable cost.\n", "versions": [{"version": "v1", "created": "Thu, 28 Sep 2017 15:05:54 GMT"}, {"version": "v2", "created": "Thu, 20 Dec 2018 08:38:34 GMT"}], "update_date": "2019-04-25", "authors_parsed": [["Maiza", "Claire", "", "VERIMAG - IMAG"], ["Touzeau", "Valentin", "", "VERIMAG - IMAG"], ["Ma\u00a8\u0131za", "Claire", "", "VERIMAG - IMAG"], ["Monniaux", "David", "", "VERIMAG - IMAG"], ["Reineke", "Jan", ""]]}, {"id": "1709.10077", "submitter": "Chao Wang", "authors": "Markus Kusano and Chao Wang", "title": "Thread-Modular Static Analysis for Relaxed Memory Models", "comments": "revised version of the ESEC/FSE 2017 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a memory-model-aware static program analysis method for accurately\nanalyzing the behavior of concurrent software running on processors with weak\nconsistency models such as x86-TSO, SPARC-PSO, and SPARC-RMO. At the center of\nour method is a unified framework for deciding the feasibility of inter-thread\ninterferences to avoid propagating spurious data flows during static analysis\nand thus boost the performance of the static analyzer. We formulate the\nchecking of interference feasibility as a set of Datalog rules which are both\nefficiently solvable and general enough to capture a range of hardware-level\nmemory models. Compared to existing techniques, our method can significantly\nreduce the number of bogus alarms as well as unsound proofs. We implemented the\nmethod and evaluated it on a large set of multithreaded C programs. Our\nexperiments showthe method significantly outperforms state-of-the-art\ntechniques in terms of accuracy with only moderate run-time overhead.\n", "versions": [{"version": "v1", "created": "Thu, 28 Sep 2017 17:41:03 GMT"}], "update_date": "2017-09-29", "authors_parsed": [["Kusano", "Markus", ""], ["Wang", "Chao", ""]]}, {"id": "1709.10078", "submitter": "Chao Wang", "authors": "Chungha Sung, Markus Kusano, Chao Wang", "title": "Modular Verification of Interrupt-Driven Software", "comments": "preprint of the ASE 2017 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interrupts have been widely used in safety-critical computer systems to\nhandle outside stimuli and interact with the hardware, but reasoning about\ninterrupt-driven software remains a difficult task. Although a number of static\nverification techniques have been proposed for interrupt-driven software, they\noften rely on constructing a monolithic verification model. Furthermore, they\ndo not precisely capture the complete execution semantics of interrupts such as\nnested invocations of interrupt handlers. To overcome these limitations, we\npropose an abstract interpretation framework for static verification of\ninterrupt-driven software that first analyzes each interrupt handler in\nisolation as if it were a sequential program, and then propagates the result to\nother interrupt handlers. This iterative process continues until results from\nall interrupt handlers reach a fixed point. Since our method never constructs\nthe global model, it avoids the up-front blowup in model construction that\nhampers existing, non-modular, verification techniques. We have evaluated our\nmethod on 35 interrupt-driven applications with a total of 22,541 lines of\ncode. Our results show the method is able to quickly and more accurately\nanalyze the behavior of interrupts.\n", "versions": [{"version": "v1", "created": "Thu, 28 Sep 2017 17:41:44 GMT"}], "update_date": "2017-09-29", "authors_parsed": [["Sung", "Chungha", ""], ["Kusano", "Markus", ""], ["Wang", "Chao", ""]]}, {"id": "1709.10116", "submitter": "Chao Wang", "authors": "Markus Kusano and Chao Wang", "title": "Flow-Sensitive Composition of Thread-Modular Abstract Interpretation", "comments": "revised version of the FSE 2016 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a constraint-based flow-sensitive static analysis for concurrent\nprograms by iteratively composing thread-modular abstract interpreters via the\nuse of a system of lightweight constraints. Our method is compositional in that\nit first applies sequential abstract interpreters to individual threads and\nthen composes their results. It is flow-sensitive in that the causality\nordering of interferences (flow of data from global writes to reads) is modeled\nby a system of constraints. These interference constraints are lightweight\nsince they only refer to the execution order of program statements as opposed\nto their numerical properties: they can be decided efficiently using an\noff-the-shelf Datalog engine. Our new method has the advantage of being more\naccurate than existing, flow-insensitive, static analyzers while remaining\nscalable and providing the expected soundness and termination guarantees even\nfor programs with unbounded data. We implemented our method and evaluated it on\na large number of benchmarks, demonstrating its effectiveness at increasing the\naccuracy of thread-modular abstract interpretation.\n", "versions": [{"version": "v1", "created": "Thu, 28 Sep 2017 18:03:16 GMT"}], "update_date": "2017-10-02", "authors_parsed": [["Kusano", "Markus", ""], ["Wang", "Chao", ""]]}]