[{"id": "1906.00046", "submitter": "Li-Yao Xia", "authors": "Li-yao Xia, Yannick Zakowski, Paul He, Chung-Kil Hur, Gregory Malecha,\n  Benjamin C. Pierce, Steve Zdancewic", "title": "Interaction Trees: Representing Recursive and Impure Programs in Coq", "comments": "28 pages, 4 pages references, published at POPL 2020", "journal-ref": null, "doi": "10.1145/3371119", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \"Interaction trees\" (ITrees) are a general-purpose data structure for\nrepresenting the behaviors of recursive programs that interact with their\nenvironments. A coinductive variant of \"free monads,\" ITrees are built out of\nuninterpreted events and their continuations. They support compositional\nconstruction of interpreters from \"event handlers\", which give meaning to\nevents by defining their semantics as monadic actions. ITrees are expressive\nenough to represent impure and potentially nonterminating, mutually recursive\ncomputations, while admitting a rich equational theory of equivalence up to\nweak bisimulation. In contrast to other approaches such as relationally\nspecified operational semantics, ITrees are executable via code extraction,\nmaking them suitable for debugging, testing, and implementing software\nartifacts that are amenable to formal verification.\n  We have implemented ITrees and their associated theory as a Coq library,\nmechanizing classic domain- and category-theoretic results about program\nsemantics, iteration, monadic structures, and equational reasoning. Although\nthe internals of the library rely heavily on coinductive proofs, the interface\nhides these details so that clients can use and reason about ITrees without\nexplicit use of Coq's coinduction tactics.\n  To showcase the utility of our theory, we prove the termination-sensitive\ncorrectness of a compiler from a simple imperative source language to an\nassembly-like target whose meanings are given in an ITree-based denotational\nsemantics. Unlike previous results using operational techniques, our\nbisimulation proof follows straightforwardly by structural induction and\nelementary rewriting via an equational theory of combinators for control-flow\ngraphs.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 19:47:40 GMT"}, {"version": "v2", "created": "Thu, 14 Nov 2019 21:24:25 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Xia", "Li-yao", ""], ["Zakowski", "Yannick", ""], ["He", "Paul", ""], ["Hur", "Chung-Kil", ""], ["Malecha", "Gregory", ""], ["Pierce", "Benjamin C.", ""], ["Zdancewic", "Steve", ""]]}, {"id": "1906.00367", "submitter": "Bruce Belson", "authors": "Bruce Belson (1), Jason Holdsworth (1), Wei Xiang (1), Bronson\n  Philippa (1) ((1) College of Science & Engineering, James Cook University)", "title": "A Survey of Asynchronous Programming Using Coroutines in the Internet of\n  Things and Embedded Systems", "comments": "22 pages, 8 figures, to be published in ACM Transactions on Embedded\n  Computing Systems (TECS)", "journal-ref": "ACM Trans. Embed. Comput. Syst. 18, 3, Article 21 (June 2019)", "doi": "10.1145/3319618", "report-no": null, "categories": "cs.SE cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many Internet of Things and embedded projects are event-driven, and therefore\nrequire asynchronous and concurrent programming. Current proposals for C++20\nsuggest that coroutines will have native language support. It is timely to\nsurvey the current use of coroutines in embedded systems development. This\npaper investigates existing research which uses or describes coroutines on\nresource-constrained platforms. The existing research is analysed with regard\nto: software platform, hardware platform and capacity; use cases and intended\nbenefits; and the application programming interface design used for coroutines.\nA systematic mapping study was performed, to select studies published between\n2007 and 2018 which contained original research into the application of\ncoroutines on resource-constrained platforms. An initial set of 566 candidate\npapers were reduced to only 35 after filters were applied, revealing the\nfollowing taxonomy. The C & C++ programming languages were used by 22 studies\nout of 35. As regards hardware, 16 studies used 8- or 16-bit processors while\n13 used 32-bit processors. The four most common use cases were concurrency (17\npapers), network communication (15), sensor readings (9) and data flow (7). The\nleading intended benefits were code style and simplicity (12 papers),\nscheduling (9) and efficiency (8). A wide variety of techniques have been used\nto implement coroutines, including native macros, additional tool chain steps,\nnew language features and non-portable assembly language. We conclude that\nthere is widespread demand for coroutines on resource-constrained devices. Our\nfindings suggest that there is significant demand for a formalised, stable,\nwell-supported implementation of coroutines in C++, designed with consideration\nof the special needs of resource-constrained devices, and further that such an\nimplementation would bring benefits specific to such devices.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jun 2019 09:10:01 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Belson", "Bruce", "", "College of Science & Engineering, James Cook University"], ["Holdsworth", "Jason", "", "College of Science & Engineering, James Cook University"], ["Xiang", "Wei", "", "College of Science & Engineering, James Cook University"], ["Philippa", "Bronson", "", "College of Science & Engineering, James Cook University"]]}, {"id": "1906.00715", "submitter": "Kamellia Reshadi", "authors": "Thorsten Ehlers, Florin Manea, Dirk Nowotka, Kamellia Reshadi", "title": "On Modelling the Avoidability of Patterns as CSP", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solving avoidability problems in the area of string combinatorics often\nrequires, in an initial step, the construction, via a computer program, of a\nvery long word that does not contain any word that matches a given pattern. It\nis well known that this is a computationally hard task. Despite being rather\nstraightforward that, ultimately, all such tasks can be formalized as\nconstraints satisfaction problems, no unified approach to solving them was\nproposed so far, and very diverse ad-hoc methods were used. We aim to fill this\ngap: we show how several relevant avoidability problems can be modelled, and\nconsequently solved, in an uniform way as constraint satisfaction problems,\nusing the framework of MiniZinc. The main advantage of this approach is that\none is now required only to formulate the avoidability problem in the MiniZinc\nlanguage, and then the actual search for a solution does not have to be\nimplemented ad-hoc, being instead carried out by a standard CSP-solver.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 11:32:34 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Ehlers", "Thorsten", ""], ["Manea", "Florin", ""], ["Nowotka", "Dirk", ""], ["Reshadi", "Kamellia", ""]]}, {"id": "1906.01128", "submitter": "Millad Ghane", "authors": "Millad Ghane, Sunita Chandrasekaran, Margaret S. Cheung", "title": "Assessing Performance Implications of Deep Copy Operations via\n  Microbenchmarking", "comments": "11 pages, 7 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As scientific frameworks become sophisticated, so do their data structures.\nCurrent data structures are no longer simple in design and they have been\nprogressively complicated. The typical trend in designing data structures in\nscientific applications are basically nested data structures: pointing to a\ndata structure within another one. Managing nested data structures on a modern\nheterogeneous system requires tremendous effort due to the separate memory\nspace design.\n  In this paper, we will discuss the implications of deep copy on data\ntransfers on current heterogeneous. Then, we will discuss the two options that\nare currently available to perform the memory copy operations on complex\nstructures and will introduce pointerchain directive that we proposed.\nAfterwards, we will introduce a set of extensive benchmarks to compare the\navailable approaches. Our goal is to make our proposed benchmarks a basis to\nexamine the efficiency of upcoming approaches that address the challenge of\ndeep copy operations.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 23:44:02 GMT"}, {"version": "v2", "created": "Tue, 11 Jun 2019 21:52:30 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Ghane", "Millad", ""], ["Chandrasekaran", "Sunita", ""], ["Cheung", "Margaret S.", ""]]}, {"id": "1906.01519", "submitter": "Fabio Zanasi", "authors": "Filippo Bonchi, Robin Piedeleu, Pawel Sobocinski, and Fabio Zanasi", "title": "Bialgebraic Semantics for String Diagrams", "comments": "Accepted for publications in the proceedings of the 30th\n  International Conference on Concurrency Theory (CONCUR 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Turi and Plotkin's bialgebraic semantics is an abstract approach to\nspecifying the operational semantics of a system, by means of a distributive\nlaw between its syntax (encoded as a monad) and its dynamics (an endofunctor).\nThis setup is instrumental in showing that a semantic specification (a\ncoalgebra) satisfies desirable properties: in particular, that it is\ncompositional.\n  In this work, we use the bialgebraic approach to derive well-behaved\nstructural operational semantics of string diagrams, a graphical syntax that is\nincreasingly used in the study of interacting systems across different\ndisciplines. Our analysis relies on representing the two-dimensional operations\nunderlying string diagrams in various categories as a monad, and their\nbialgebraic semantics in terms of a distributive law over that monad.\n  As a proof of concept, we provide bialgebraic compositional semantics for a\nversatile string diagrammatic language which has been used to model both signal\nflow graphs (control theory) and Petri nets (concurrency theory). Moreover, our\napproach reveals a correspondence between two different interpretations of the\nFrobenius equations on string diagrams and two synchronisation mechanisms for\nprocesses, \\`a la Hoare and \\`a la Milner.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 15:31:35 GMT"}, {"version": "v2", "created": "Tue, 2 Jul 2019 09:25:16 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Bonchi", "Filippo", ""], ["Piedeleu", "Robin", ""], ["Sobocinski", "Pawel", ""], ["Zanasi", "Fabio", ""]]}, {"id": "1906.01706", "submitter": "Jakub Kuderski", "authors": "Jakub Kuderski, Jorge A. Navas, Arie Gurfinkel", "title": "Unification-based Pointer Analysis without Oversharing", "comments": "9 pages, typos fixed, accepted to FMCAD'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pointer analysis is indispensable for effectively verifying heap-manipulating\nprograms. Even though it has been studied extensively, there are no publicly\navailable pointer analyses that are moderately precise while scalable to large\nreal-world programs. In this paper, we show that existing context-sensitive\nunification-based pointer analyses suffer from the problem of oversharing --\npropagating too many abstract objects across the analysis of different\nprocedures, which prevents them from scaling to large programs. We present a\nnew pointer analysis for LLVM, called TeaDsa, without such an oversharing. We\nshow how to further improve precision and speed of TeaDsa with extra contextual\ninformation, such as flow-sensitivity at call- and return-sites, and type\ninformation about memory accesses. We evaluate TeaDsa on the verification\nproblem of detecting unsafe memory accesses and compare it against two\nstate-of-the-art pointer analyses: SVF and SeaDsa. We show that TeaDsa is one\norder of magnitude faster than either SVF or SeaDsa, strictly more precise than\nSeaDsa, and, surprisingly, sometimes more precise than SVF.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 20:03:47 GMT"}, {"version": "v2", "created": "Fri, 16 Aug 2019 13:58:39 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Kuderski", "Jakub", ""], ["Navas", "Jorge A.", ""], ["Gurfinkel", "Arie", ""]]}, {"id": "1906.03028", "submitter": "Maria I. Gorinova", "authors": "Maria I. Gorinova, Dave Moore, Matthew D. Hoffman", "title": "Automatic Reparameterisation of Probabilistic Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Probabilistic programming has emerged as a powerful paradigm in statistics,\napplied science, and machine learning: by decoupling modelling from inference,\nit promises to allow modellers to directly reason about the processes\ngenerating data. However, the performance of inference algorithms can be\ndramatically affected by the parameterisation used to express a model,\nrequiring users to transform their programs in non-intuitive ways. We argue for\nautomating these transformations, and demonstrate that mechanisms available in\nrecent modeling frameworks can implement non-centring and related\nreparameterisations. This enables new inference algorithms, and we propose two:\na simple approach using interleaved sampling and a novel variational\nformulation that searches over a continuous space of parameterisations. We show\nthat these approaches enable robust inference across a range of models, and can\nyield more efficient samplers than the best fixed parameterisation.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 11:56:42 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Gorinova", "Maria I.", ""], ["Moore", "Dave", ""], ["Hoffman", "Matthew D.", ""]]}, {"id": "1906.03836", "submitter": "Jorge A. P\\'erez", "authors": "Alen Arslanagi\\'c, Jorge A. P\\'erez, and Erik Voogd", "title": "Minimal Session Types (Extended Version)", "comments": "Extended version of an ECOOP 2019 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Session types are a type-based approach to the verification of\nmessage-passing programs. They have been much studied as type systems for the\npi-calculus and for languages such as Java. A session type specifies what and\nwhen should be exchanged through a channel. Central to session-typed languages\nare constructs in types and processes that specify sequencing in protocols.\nHere we study minimal session types, session types without sequencing. This is\narguably the simplest form of session types. By relying on a core process\ncalculus with sessions and higher-order concurrency (abstraction passing), we\nprove that every process typable with usual (non minimal) session types can be\ncompiled down into a process typed with minimal session types. This means that\nhaving sequencing constructs in both processes and session types is redundant;\nonly sequentiality in processes is indispensable, as it can precisely codify\nsequentiality in types. Our developments draw inspiration from work by Parrow\non behavior-preserving decompositions of untyped processes. By casting Parrow's\nresults in the realm of typed processes, our results reveal a conceptually\nsimple formulation of session types and a principled avenue to the integration\nof session types into languages without sequencing in types.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 08:20:56 GMT"}, {"version": "v2", "created": "Wed, 12 Jun 2019 13:30:34 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Arslanagi\u0107", "Alen", ""], ["P\u00e9rez", "Jorge A.", ""], ["Voogd", "Erik", ""]]}, {"id": "1906.03937", "submitter": "Moez AbdelGawad", "authors": "Moez A. AbdelGawad", "title": "Java Generics: An Order-Theoretic Approach (Detailed Outline)", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generics have been added to Java so as to increase the expressiveness of its\ntype system. Generics in Java, however, include some features---such as Java\nwildcards, $F$-bounded generics, and Java erasure---that have been hard to\nanalyze and reason about so far, reflecting the fact that the mathematical\nmodeling of generics in Java and other similar nominally-typed object-oriented\nprogramming (OOP) languages is a challenge. As a result, the type systems of\nmainstream nominally-typed OOP languages, which are built based on current\nmodels of generics, are overly complex, which hinders the progress of these\ntype systems.\n  In this paper we present a detailed outline of a new approach to modeling\nJava generics that uses concepts and tools from order theory, and we report on\nour progress in developing this approach. Fundamentally, we use the nominal\nsubclassing relation (as a partial order) together with some standard and novel\norder-theoretic tools to construct the generic nominal subtyping relation (as a\npartial order) and the containment relation between generic type arguments (a\nthird partial order). We further analyze the relation between these three\nordering relations---which lie at the heart of mainstream generic OO type\nsystems---using order theoretic tools, and accordingly we explore extensions of\nOO type systems suggested by such analysis. In our approach we also make use of\nsome concepts and tools from category theory. We believe a combined\norder-theoretic and category-theoretic approach to modeling generics holds the\nkeys to overcoming much of the adversity found when analyzing features of\ngeneric OO type systems.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 11:58:36 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["AbdelGawad", "Moez A.", ""]]}, {"id": "1906.03957", "submitter": "Martin Hirzel", "authors": "Martin Hirzel, Kiran Kate, Avraham Shinnar, Subhrajit Roy, Parikshit\n  Ram", "title": "Type-Driven Automated Learning with Lale", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine-learning automation tools, ranging from humble grid-search to\nhyperopt, auto-sklearn, and TPOT, help explore large search spaces of possible\npipelines. Unfortunately, each of these tools has a different syntax for\nspecifying its search space, leading to lack of portability, missed relevant\npoints, and spurious points that are inconsistent with error checks and\ndocumentation of the searchable base components. This paper proposes using\ntypes (such as enum, float, or dictionary) both for checking the correctness\nof, and for automatically searching over, hyperparameters and pipeline\nconfigurations. Using types for both of these purposes guarantees consistency.\nWe present Lale, an embedded language that resembles scikit learn but provides\nbetter automation, correctness checks, and portability. Lale extends the reach\nof existing automation tools across data modalities (tables, text, images,\ntime-series) and programming languages (Python, Java, R). Thus, data scientists\ncan leverage automation while remaining in control of their work.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 20:33:51 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Hirzel", "Martin", ""], ["Kate", "Kiran", ""], ["Shinnar", "Avraham", ""], ["Roy", "Subhrajit", ""], ["Ram", "Parikshit", ""]]}, {"id": "1906.03969", "submitter": "Antonio Flores Montoya", "authors": "Antonio Flores-Montoya and Eric Schulte", "title": "Datalog Disassembly", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Disassembly is fundamental to binary analysis and rewriting. We present a\nnovel disassembly technique that takes a stripped binary and produces\nreassembleable assembly code. The resulting assembly code has accurate symbolic\ninformation, providing cross-references for analysis and to enable adjustment\nof code and data pointers to accommodate rewriting. Our technique features\nmultiple static analyses and heuristics in a combined Datalog implementation.\nWe argue that Datalog's inference process is particularly well suited for\ndisassembly and the required analyses. Our implementation and experiments\nsupport this claim. We have implemented our approach into an open-source tool\ncalled Ddisasm. In extensive experiments in which we rewrite thousands of x64\nbinaries we find Ddisasm is both faster and more accurate than the current\nstate-of-the-art binary reassembling tool, Ramblr.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 12:54:36 GMT"}, {"version": "v2", "created": "Wed, 12 Jun 2019 11:01:44 GMT"}, {"version": "v3", "created": "Wed, 20 Nov 2019 15:52:25 GMT"}, {"version": "v4", "created": "Thu, 21 Nov 2019 14:33:19 GMT"}, {"version": "v5", "created": "Wed, 26 Feb 2020 15:57:32 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Flores-Montoya", "Antonio", ""], ["Schulte", "Eric", ""]]}, {"id": "1906.03970", "submitter": "Duanyang Jing", "authors": "Duanyang Jing", "title": "A scheme for dynamically integrating C library functions into a\n  $\\lambda$Prolog implementation", "comments": "report for Master's project", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Teyjus system realizes the higher-order logic programming\nlanguage$\\lambda$Prolog by compiling programs into bytecode for an abstract\nmachine and executing this translated form using a simulator for the machine.\nTeyjus supports a number of builtin relations that are realized through C code.\nIn the current scheme, these relations are realized by including the C programs\nthat implement them within the simulator and tailoring the compiler to produce\ninstructions to invoke such code. There are two drawbacks to such an approach.\nFirst, the entire collection of library functions must be included within the\nsystem, thereby leading to a larger than necessary memory footprint. Second,\nenhancing the collection of built-in predicates requires changing parts of the\nsimulator and compiler, a task whose accomplishment requires specific knowledge\nof these two subsystems. This project addresses these problems in three steps.\nFirst, the code for the builtin functions is moved from the simulator into a\nlibrary from where relevant parts, determined by information in the bytecode\nfile, are linked into the runtime system at load time. Second, information is\nassociated with each library function about how it can be invoked from a\n$\\lambda$Prolog program and where the C code for it is to be found. Finally,\nthe compiler is modified to use the preceding information to include relevant\nlinking instructions in the bytecode file and to translate invocations to\nbuiltin relations into a special instruction that calls the dynamically linked\ncode. More generally, these ideas are capable of supporting an interface in\n$\\lambda$Prolog to \"foreign functions\" implemented in C, a possibility that is\nalso discussed.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 19:32:26 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Jing", "Duanyang", ""]]}, {"id": "1906.03982", "submitter": "Mohammad Khayatian", "authors": "Bob Iannucci, Aviral Shrivastava, Mohammad Khayatian", "title": "TickTalk -- Timing API for Dynamically Federated Cyber-Physical Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although timing and synchronization of a dynamically-changing set of elements\nand their related power considerations are essential to many cyber-physical\nsystems (CPS), they are absent from today's programming languages, forcing\nprogrammers to handle these matters outside of the language and on a\ncase-by-case basis. This paper proposes a framework for adding time-related\nconcepts to languages. Complementing prior work in this area, this paper\ndevelops the notion of dynamically federated islands of variable-precision\nsynchronization and coordinated entities through synergistic activities at the\nlanguage, system, network, and device levels. At the language level, we explore\nconstructs that capture key timing and synchronization concepts and, at the\nsystem level, we propose a flexible intermediate language that represents both\nprogram logic and timing constraints together with run-time mechanisms. At the\nnetwork level, we argue for architectural extensions that permit the network to\nact as a combined computing, communication, storage, and synchronization\nplatform and at the device level, we explore architectural concepts that can\nlead to greater interoperability, easy establishment of timing constraints, and\nmore power-efficient designs.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 19:42:04 GMT"}, {"version": "v2", "created": "Wed, 12 Jun 2019 17:07:06 GMT"}, {"version": "v3", "created": "Tue, 18 Jun 2019 20:55:00 GMT"}, {"version": "v4", "created": "Fri, 25 Sep 2020 00:42:52 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Iannucci", "Bob", ""], ["Shrivastava", "Aviral", ""], ["Khayatian", "Mohammad", ""]]}, {"id": "1906.04011", "submitter": "Roy Freedman", "authors": "Roy S. Freedman", "title": "Visual Backpropagation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how a declarative functional programming specification of\nbackpropagation yields a visual and transparent implementation within\nspreadsheets. We call our method Visual Backpropagation. This backpropagation\nimplementation exploits array worksheet formulas, manual calculation, and has a\nsequential order of computation similar to the processing of a systolic array.\nThe implementation uses no hidden macros nor user-defined functions; there are\nno loops, assignment statements, or links to any procedural programs written in\nconventional languages. As an illustration, we compare a Visual Backpropagation\nsolution to a Tensorflow (Python) solution on a standard regression problem.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 18:15:24 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Freedman", "Roy S.", ""]]}, {"id": "1906.04604", "submitter": "Maxwell Nye", "authors": "Kevin Ellis, Maxwell Nye, Yewen Pu, Felix Sosa, Josh Tenenbaum,\n  Armando Solar-Lezama", "title": "Write, Execute, Assess: Program Synthesis with a REPL", "comments": "The first four authors contributed equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.AI cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a neural program synthesis approach integrating components which\nwrite, execute, and assess code to navigate the search space of possible\nprograms. We equip the search process with an interpreter or a\nread-eval-print-loop (REPL), which immediately executes partially written\nprograms, exposing their semantics. The REPL addresses a basic challenge of\nprogram synthesis: tiny changes in syntax can lead to huge changes in\nsemantics. We train a pair of models, a policy that proposes the new piece of\ncode to write, and a value function that assesses the prospects of the code\nwritten so-far. At test time we can combine these models with a Sequential\nMonte Carlo algorithm. We apply our approach to two domains: synthesizing text\nediting programs and inferring 2D and 3D graphics programs.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2019 23:12:40 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Ellis", "Kevin", ""], ["Nye", "Maxwell", ""], ["Pu", "Yewen", ""], ["Sosa", "Felix", ""], ["Tenenbaum", "Josh", ""], ["Solar-Lezama", "Armando", ""]]}, {"id": "1906.04765", "submitter": "W{\\l}odzimierz Drabent", "authors": "W{\\l}odzimierz Drabent", "title": "The Prolog debugger and declarative programming", "comments": "15 pages. This version: a reference added to a companion report with\n  examples", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Logic programming is a declarative programming paradigm. Programming language\nProlog makes logic programming possible, at least to a substantial extent.\nHowever the Prolog debugger works solely in terms of the operational semantics.\nSo it is incompatible with declarative programming. This report discusses this\nissue and tries to find how the debugger may be used from the declarative point\nof view. The results are rather not encouraging.\n  Also, the box model of Byrd, used by the debugger, is explained in terms of\nSLD-resolution.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 18:32:15 GMT"}, {"version": "v2", "created": "Thu, 2 Jan 2020 01:08:36 GMT"}, {"version": "v3", "created": "Mon, 17 Feb 2020 16:30:50 GMT"}, {"version": "v4", "created": "Thu, 5 Mar 2020 19:07:37 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Drabent", "W\u0142odzimierz", ""]]}, {"id": "1906.04830", "submitter": "\\'Eric Tanter", "authors": "Raimil Cruz, \\'Eric Tanter", "title": "Polymorphic Relaxed Noninterference", "comments": "update affiliation/funding", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Information-flow security typing statically preserves confidentiality by\nenforcing noninterference. To address the practical need of selective and\nflexible declassification of confidential information, several approaches have\ndeveloped a notion of relaxed noninterference, where security labels are either\nfunctions or types. The labels-as-types approach to relaxed noninterference\nsupports expressive declassification policies, including recursive ones, via a\nsimple subtyping-based ordering, and provides a local, modular reasoning\nprinciple. In this work, we extend this expressive declassification approach in\norder to support polymorphic declassification. First, we identify the need for\nbounded polymorphism through concrete examples. We then formalize polymorphic\nrelaxed noninterference in a typed object-oriented calculus, using a\nstep-indexed logical relation to prove that all well-typed terms are secure.\nFinally, we address the case of primitive types, which requires a form of\nad-hoc polymorphism. Therefore, this work addresses practical hurdles to\nproviding controlled and expressive declassification for the construction of\ninformation-flow secure systems.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 21:29:44 GMT"}, {"version": "v2", "created": "Mon, 14 Oct 2019 10:15:08 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Cruz", "Raimil", ""], ["Tanter", "\u00c9ric", ""]]}, {"id": "1906.04908", "submitter": "Sumith Kulal", "authors": "Sumith Kulal, Panupong Pasupat, Kartik Chandra, Mina Lee, Oded Padon,\n  Alex Aiken, Percy Liang", "title": "SPoC: Search-based Pseudocode to Code", "comments": "Under submission to NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the task of mapping pseudocode to long programs that are\nfunctionally correct. Given test cases as a mechanism to validate programs, we\nsearch over the space of possible translations of the pseudocode to find a\nprogram that passes the validation. However, without proper credit assignment\nto localize the sources of program failures, it is difficult to guide search\ntoward more promising programs. We propose to perform credit assignment based\non signals from compilation errors, which constitute 88.7% of program failures.\nConcretely, we treat the translation of each pseudocode line as a discrete\nportion of the program, and whenever a synthesized program fails to compile, an\nerror localization method tries to identify the portion of the program\nresponsible for the failure. We then focus search over alternative translations\nof the pseudocode for those portions. For evaluation, we collected the SPoC\ndataset (Search-based Pseudocode to Code) containing 18,356 programs with\nhuman-authored pseudocode and test cases. Under a budget of 100 program\ncompilations, performing search improves the synthesis success rate over using\nthe top-one translation of the pseudocode from 25.6% to 44.7%.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 03:13:18 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Kulal", "Sumith", ""], ["Pasupat", "Panupong", ""], ["Chandra", "Kartik", ""], ["Lee", "Mina", ""], ["Padon", "Oded", ""], ["Aiken", "Alex", ""], ["Liang", "Percy", ""]]}, {"id": "1906.04924", "submitter": "Shawn Meier", "authors": "Shawn Meier, Sergio Mover, and Bor-Yuh Evan Chang", "title": "Lifestate: Event-Driven Protocols and Callback Control Flow (Extended\n  Version)", "comments": "26 pages, 11 figures, ECOOP 2019", "journal-ref": null, "doi": "10.4230/LIPIcs.ECOOP.2019.4", "report-no": null, "categories": "cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developing interactive applications (apps) against event-driven software\nframeworks such as Android is notoriously difficult. To create apps that behave\nas expected, developers must follow complex and often implicit asynchronous\nprogramming protocols. Such protocols intertwine the proper registering of\ncallbacks to receive control from the framework with appropriate\napplication-programming interface (API) calls that in turn affect the set of\npossible future callbacks. An app violates the protocol when, for example, it\ncalls a particular API method in a state of the framework where such a call is\ninvalid. What makes automated reasoning hard in this domain is largely what\nmakes programming apps against such frameworks hard: the specification of the\nprotocol is unclear, and the control flow is complex, asynchronous, and\nhigher-order. In this paper, we tackle the problem of specifying and modeling\nevent-driven application-programming protocols. In particular, we formalize a\ncore meta-model that captures the dialogue between event-driven frameworks and\napplication callbacks. Based on this meta-model, we define a language called\nlifestate that permits precise and formal descriptions of\napplication-programming protocols and the callback control flow imposed by the\nevent-driven framework. Lifestate unifies modeling what app callbacks can\nexpect of the framework with specifying rules the app must respect when calling\ninto the framework. In this way, we effectively combine lifecycle constraints\nand typestate rules. To evaluate the effectiveness of lifestate modeling, we\nprovide a dynamic verification algorithm that takes as input a trace of\nexecution of an app and a lifestate protocol specification to either produce a\ntrace witnessing a protocol violation or a proof that no such trace is\nrealizable.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 03:36:11 GMT"}, {"version": "v2", "created": "Thu, 13 Jun 2019 01:40:21 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Meier", "Shawn", ""], ["Mover", "Sergio", ""], ["Chang", "Bor-Yuh Evan", ""]]}, {"id": "1906.04925", "submitter": "Moez AbdelGawad", "authors": "Moez A. AbdelGawad", "title": "Using Category Theory in Modeling Generics in OOP (Outline)", "comments": "3 pages (excluding references and an appendix). arXiv admin note:\n  text overlap with arXiv:1906.03937", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling generics in object-oriented programming languages such as Java and\nC# is a challenge. Recently we proposed a new order-theoretic approach to\nmodeling generics. Given the strong relation between order theory and category\ntheory, in this extended abstract we present how also some tools from category\ntheory, such as adjunctions, monads and operads, are used in our approach to\nmodeling generics.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 07:40:55 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["AbdelGawad", "Moez A.", ""]]}, {"id": "1906.04984", "submitter": "Pablo Gordillo", "authors": "Elvira Albert, Jes\\'us Correas, Pablo Gordillo, Guillermo\n  Rom\\'an-D\\'iez and Albert Rubio", "title": "SAFEVM: A Safety Verifier for Ethereum Smart Contracts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ethereum smart contracts are public, immutable and distributed and, as such,\nthey are prone to vulnerabilities sourcing from programming mistakes of\ndevelopers. This paper presents SAFEVM, a verification tool for Ethereum smart\ncontracts that makes use of state-of-the-art verification engines for C\nprograms. SAFEVM takes as input an Ethereum smart contract (provided either in\nSolidity source code, or in compiled EVM bytecode), optionally with assert and\nrequire verification annotations, and produces in the output a report with the\nverification results. Besides general safety annotations, SAFEVM handles the\nverification of array accesses: it automatically generates SV-COMP verification\nassertions such that C verification engines can prove safety of array accesses.\nOur experimental evaluation has been undertaken on all contracts pulled from\netherscan.io (more than 24,000) by using as back-end verifiers CPAchecker,\nSeaHorn and VeryMax.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 07:49:06 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Albert", "Elvira", ""], ["Correas", "Jes\u00fas", ""], ["Gordillo", "Pablo", ""], ["Rom\u00e1n-D\u00edez", "Guillermo", ""], ["Rubio", "Albert", ""]]}, {"id": "1906.05092", "submitter": "Yuka Takahashi", "authors": "Yuka Takahashi (1), Oksana Shadura (2), Vassil Vassilev (3) ((1)\n  University of Tokyo, (2) University of Nebraska-Lincoln, (3) Princeton\n  University)", "title": "Migrating large codebases to C++ Modules", "comments": "To be appear in 19th International Workshop on Advanced Computing and\n  Analysis Techniques in Physics Research", "journal-ref": null, "doi": "10.1088/1742-6596/1525/1/012051", "report-no": null, "categories": "cs.SE cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ROOT has several features which interact with libraries and require implicit\nheader inclusion. This can be triggered by reading or writing data on disk, or\nuser actions at the prompt. Often, the headers are immutable, and reparsing is\nredundant. C++ Modules are designed to minimize the reparsing of the same\nheader content by providing an efficient on-disk representation of C++ Code.\nROOT has released a C++ Modules-aware technology preview which intends to\nbecome the default for the next release.\n  In this paper, we will summarize our experience with migrating C++ Modules to\nLHC experiment's software code bases. We outline the challenges in C++ Modules\nmigration of the CMS software, including the integration of C++ Modules support\nin CMS build system. We also evaluate the performance benefits that experiments\nare expected to achieve.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 12:42:42 GMT"}, {"version": "v2", "created": "Thu, 22 Aug 2019 18:54:31 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Takahashi", "Yuka", ""], ["Shadura", "Oksana", ""], ["Vassilev", "Vassil", ""]]}, {"id": "1906.05170", "submitter": "Graham Campbell", "authors": "Graham Campbell", "title": "Efficient Graph Rewriting", "comments": "BSc Thesis, Department of Computer Science, University of York, 54\n  pages, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC cs.PL cs.SC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Graph transformation is the rule-based modification of graphs, and is a\ndiscipline dating back to the 1970s. The declarative nature of graph rewriting\nrules comes at a cost. In general, to match the left-hand graph of a fixed rule\nwithin a host graph requires polynomial time. To improve matching performance,\nD\\\"orr proposed to equip rules and host graphs with distinguished root nodes.\nThis model was implemented by Plump and Bak, but unfortunately, is not\ninvertible. We address this problem by defining rootedness using a partial\nfunction onto a two-point set rather than pointing graphs with root nodes. We\nshow a new result that the graph class of trees can be recognised by a rooted\nGT system in linear time, given an input graph of bounded degree. Finally, we\ndefine a new notion of confluence modulo garbage and non-garbage critical\npairs, showing it is sufficient to require strong joinability of only the\nnon-garbage critical pairs to establish confluence modulo garbage.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 15:50:57 GMT"}, {"version": "v2", "created": "Fri, 1 Jan 2021 11:46:20 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Campbell", "Graham", ""]]}, {"id": "1906.05704", "submitter": "Eduard Kamburjan", "authors": "Eduard Kamburjan, Stefan Mitsch, Martina Kettenbach, and Reiner\n  H\\\"ahnle", "title": "Modeling and Verifying Cyber-Physical Systems with Hybrid Active Objects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LO cs.PL cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Formal modeling of cyber-physical systems (CPS) is hard, because they pose\nthe double challenge of combined discrete-continuous dynamics and concurrent\nbehavior. Existing formal specification and verification languages for CPS are\ndesigned on top of their underlying proof search technology. They lack\nhigh-level structuring elements. In addition, they are not efficiently\nexecutable. This makes formal CPS models hard to understand and to validate,\nhence impairs their usability. Instead, we suggest to model CPS in an Active\nObjects (AO) language designed for concise, intuitive modeling of concurrent\nsystems. To this end, we extend the AO language ABS and its runtime environment\nwith Hybrid Active Objects (HAO). CPS models and requirements formalized in HAO\nmust follow certain communication patterns that permit automatic translation\ninto differential dynamic logic, a sequential hybrid program logic.\nVerification is achieved by discharging the resulting formulas with the theorem\nprover KeYmaera X. We demonstrate the practicality of our approach with case\nstudies.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 14:01:16 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Kamburjan", "Eduard", ""], ["Mitsch", "Stefan", ""], ["Kettenbach", "Martina", ""], ["H\u00e4hnle", "Reiner", ""]]}, {"id": "1906.06469", "submitter": "Joseph Eremondi", "authors": "Joseph Eremondi, \\'Eric Tanter, Ronald Garcia", "title": "Approximate Normalization for Gradual Dependent Types", "comments": null, "journal-ref": "Proc. ACM Program. Lang. 3, ICFP, Article 88 (July 2019), 30 pages", "doi": "10.1145/3341692", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dependent types help programmers write highly reliable code. However, this\nreliability comes at a cost: it can be challenging to write new prototypes in\n(or migrate old code to) dependently-typed programming languages. Gradual\ntyping makes static type disciplines more flexible, so an appropriate notion of\ngradual dependent types could fruitfully lower this cost. However, dependent\ntypes raise unique challenges for gradual typing. Dependent typechecking\ninvolves the execution of program code, but gradually-typed code can signal\nruntime type errors or diverge. These runtime errors threaten the soundness\nguarantees that make dependent types so attractive, while divergence spoils the\ntype-driven programming experience.\n  This paper presents GDTL, a gradual dependently-typed language that\nemphasizes pragmatic dependently-typed programming. GDTL fully embeds both an\nuntyped and dependently-typed language, and allows for smooth transitions\nbetween the two. In addition to gradual types we introduce gradual terms ,\nwhich allow the user to be imprecise in type indices and to omit proof terms;\nruntime checks ensure type safety . To account for nontermination and failure,\nwe distinguish between compile-time normalization and run-time execution:\ncompile-time normalization is approximate but total, while runtime execution is\nexact , but may fail or diverge. We prove that GDTL has decidable typechecking\nand satisfies all the expected properties of gradual languages. In particular,\nGDTL satisfies the static and dynamic gradual guarantees: reducing type\nprecision preserves typedness, and altering type precision does not change\nprogram behavior outside of dynamic type failures. To prove these properties,\nwe were led to establish a novel normalization gradual guarantee that captures\nthe monotonicity of approximate normalization with respect to imprecision.\n", "versions": [{"version": "v1", "created": "Sat, 15 Jun 2019 04:49:58 GMT"}, {"version": "v2", "created": "Wed, 21 Aug 2019 15:29:22 GMT"}, {"version": "v3", "created": "Thu, 22 Aug 2019 11:07:44 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Eremondi", "Joseph", ""], ["Tanter", "\u00c9ric", ""], ["Garcia", "Ronald", ""]]}, {"id": "1906.07181", "submitter": "Zhan Shi", "authors": "Zhan Shi, Kevin Swersky, Daniel Tarlow, Parthasarathy Ranganathan,\n  Milad Hashemi", "title": "Learning Execution through Neural Code Fusion", "comments": "14 pages,7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the performance of computer systems stagnates due to the end of Moore's\nLaw, there is a need for new models that can understand and optimize the\nexecution of general purpose code. While there is a growing body of work on\nusing Graph Neural Networks (GNNs) to learn representations of source code,\nthese representations do not understand how code dynamically executes. In this\nwork, we propose a new approach to use GNNs to learn fused representations of\ngeneral source code and its execution. Our approach defines a multi-task GNN\nover low-level representations of source code and program state (i.e., assembly\ncode and dynamic memory states), converting complex source code constructs and\ncomplex data structures into a simpler, more uniform format. We show that this\nleads to improved performance over similar methods that do not use execution\nand it opens the door to applying GNN models to new tasks that would not be\nfeasible from static code alone. As an illustration of this, we apply the new\nmodel to challenging dynamic tasks (branch prediction and prefetching) from the\nSPEC CPU benchmark suite, outperforming the state-of-the-art by 26% and 45%\nrespectively. Moreover, we use the learned fused graph embeddings to\ndemonstrate transfer learning with high performance on an indirectly related\ntask (algorithm classification).\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 20:05:48 GMT"}, {"version": "v2", "created": "Wed, 11 Mar 2020 03:11:50 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Shi", "Zhan", ""], ["Swersky", "Kevin", ""], ["Tarlow", "Daniel", ""], ["Ranganathan", "Parthasarathy", ""], ["Hashemi", "Milad", ""]]}, {"id": "1906.07223", "submitter": "Eric Campbell", "authors": "Matthias Eichholz, Eric Campbell, Nate Foster, Guido Salvaneschi, Mira\n  Mezini", "title": "How to Avoid Making a Billion-Dollar Mistake: Type-Safe Data Plane\n  Programming with SafeP4", "comments": "This version is the companion technical report for submission to\n  ECOOP 2019. 26 Pages + 2 Reference pages + 10 pages of Appendices; 26 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The P4 programming language offers high-level, declarative abstractions that\nbring the flexibility of software to the domain of networking. Unfortunately,\nthe main abstraction used to represent packet data in P4, namely header types,\nlacks basic safety guarantees. Over the last few years, experience with an\nincreasing number of programs has shown the risks of the unsafe approach, which\noften leads to subtle software bugs.\n  This paper proposes SafeP4, a domain-specific language for programmable data\nplanes in which all packet data is guaranteed to have a well-defined meaning\nand satisfy essential safety guarantees. We equip SafeP4 with a formal\nsemantics and a static type system that statically guarantees header\nvalidity---a common source of safety bugs according to our analysis of\nreal-world P4 programs. Statically ensuring header validity is challenging\nbecause the set of valid headers can be modified at runtime, making it a\ndynamic program property. Our type system achieves static safety by using a\nform of path-sensitive reasoning that tracks dynamic information from\nconditional statements, routing tables, and the control plane. Our evaluation\nshows that SafeP4's type system can effectively eliminate common failures in\nmany real-world programs.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 18:59:33 GMT"}, {"version": "v2", "created": "Mon, 24 Jun 2019 13:47:59 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Eichholz", "Matthias", ""], ["Campbell", "Eric", ""], ["Foster", "Nate", ""], ["Salvaneschi", "Guido", ""], ["Mezini", "Mira", ""]]}, {"id": "1906.07629", "submitter": "Fabrizio Romano Genovese PhD", "authors": "Statebox Team: Fabrizio Genovese, Jelle Herold", "title": "The Mathematical Specification of the Statebox Language", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.DC math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This document defines the mathematical backbone of the Statebox programming\nlanguage. In the simplest way possible, Statebox can be seen as a clever way to\ntie together different theoretical structures to maximize their benefits and\nlimit their downsides. Since consistency and correctness are central requisites\nfor our language, it became clear from the beginning that such tying could not\nbe achieved by just hacking together different pieces of code representing\nimplementations of the structures we wanted to leverage: Rigorous mathematics\nis employed to ensure both conceptual consistency of the language and\nreliability of the code itself. The mathematics presented here is what guided\nthe implementation process, and we deemed very useful to release it to the\npublic to help people wanting to audit our work to better understand the code\nitself.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 15:04:33 GMT"}, {"version": "v2", "created": "Wed, 26 Jun 2019 14:26:53 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Statebox Team", "", ""], ["Genovese", "Fabrizio", ""], ["Herold", "Jelle", ""]]}, {"id": "1906.08911", "submitter": "Vivek Kale PhD", "authors": "Vivek Kale, Christian Iwainsky, Michael Klemm, Jonas H. Muller\n  Korndorfer and Florina M. Ciorba", "title": "Toward a Standard Interface for User-Defined Scheduling in OpenMP", "comments": "16 pages with references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CL cs.PF cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parallel loops are an important part of OpenMP programs. Efficient scheduling\nof parallel loops can improve performance of the programs. The current OpenMP\nspecification only offers three options for loop scheduling, which are\ninsufficient in certain instances. Given the large number of other possible\nscheduling strategies, it is infeasible to standardize each one. A more viable\napproach is to extend the OpenMP standard to allow for users to define loop\nscheduling strategies. The approach will enable standard-compliant\napplication-specific scheduling. This work analyzes the principal components\nrequired by user-defined scheduling and proposes two competing interfaces as\ncandidates for the OpenMP standard. We conceptually compare the two proposed\ninterfaces with respect to the three host languages of OpenMP, i.e., C, C++,\nand Fortran. These interfaces serve the OpenMP community as a basis for\ndiscussion and prototype implementation for user-defined scheduling.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 01:47:32 GMT"}, {"version": "v2", "created": "Mon, 8 Jul 2019 20:29:35 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Kale", "Vivek", ""], ["Iwainsky", "Christian", ""], ["Klemm", "Michael", ""], ["Korndorfer", "Jonas H. Muller", ""], ["Ciorba", "Florina M.", ""]]}, {"id": "1906.09370", "submitter": "Andr\\'es Ezequiel Viso", "authors": "Eduardo Bonelli and Delia Kesner and Andr\\'es Viso", "title": "Strong Bisimulation for Control Operators", "comments": null, "journal-ref": null, "doi": "10.4230/LIPIcs.CSL.2020.4", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of this paper is to identify programs with control operators\nwhose reduction semantics are in exact correspondence. This is achieved by\nintroducing a relation $\\simeq$, defined over a revised presentation of\nParigot's $\\lambda\\mu$-calculus we dub $\\Lambda M$. Our result builds on two\nfundamental ingredients: (1) factorization of $\\lambda\\mu$-reduction into\nmultiplicative and exponential steps by means of explicit term operators of\n$\\Lambda M$, and (2) translation of $\\Lambda M$-terms into Laurent's polarized\nproof-nets (PPN) such that cut-elimination in PPN simulates our calculus. Our\nproposed relation $\\simeq$ is shown to characterize structural equivalence in\nPPN. Most notably, $\\simeq$ is shown to be a strong bisimulation with respect\nto reduction in $\\Lambda M$, i.e. two $\\simeq$-equivalent terms have the exact\nsame reduction semantics, a result which fails for Regnier's\n$\\sigma$-equivalence in $\\lambda$-calculus as well as for Laurent's\n$\\sigma$-equivalence in $\\lambda\\mu$.\n", "versions": [{"version": "v1", "created": "Sat, 22 Jun 2019 02:35:39 GMT"}, {"version": "v2", "created": "Wed, 16 Oct 2019 15:11:34 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Bonelli", "Eduardo", ""], ["Kesner", "Delia", ""], ["Viso", "Andr\u00e9s", ""]]}, {"id": "1906.09503", "submitter": "Vladimir Zamdzhiev", "authors": "Bert Lindenhovius and Michael Mislove and Vladimir Zamdzhiev", "title": "LNL-FPC: The Linear/Non-linear Fixpoint Calculus", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 17, Issue 2 (April 22,\n  2021) lmcs:7390", "doi": null, "report-no": null, "categories": "cs.PL cs.LO math.CT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We describe a type system with mixed linear and non-linear recursive types\ncalled LNL-FPC (the linear/non-linear fixpoint calculus). The type system\nsupports linear typing, which enhances the safety properties of programs, but\nalso supports non-linear typing as well, which makes the type system more\nconvenient for programming. Just as in FPC, we show that LNL-FPC supports\ntype-level recursion, which in turn induces term-level recursion. We also\nprovide sound and computationally adequate categorical models for LNL-FPC that\ndescribe the categorical structure of the substructural operations of\nIntuitionistic Linear Logic at all non-linear types, including the recursive\nones. In order to do so, we describe a new technique for solving recursive\ndomain equations within cartesian categories by constructing the solutions over\npre-embeddings. The type system also enjoys implicit weakening and contraction\nrules that we are able to model by identifying the canonical comonoid structure\nof all non-linear types. We also show that the requirements of our abstract\nmodel are reasonable by constructing a large class of concrete models that have\nfound applications not only in classical functional programming, but also in\nemerging programming paradigms that incorporate linear types, such as quantum\nprogramming and circuit description programming languages.\n", "versions": [{"version": "v1", "created": "Sat, 22 Jun 2019 20:50:27 GMT"}, {"version": "v2", "created": "Wed, 21 Aug 2019 14:30:24 GMT"}, {"version": "v3", "created": "Mon, 25 May 2020 23:21:45 GMT"}, {"version": "v4", "created": "Wed, 17 Mar 2021 20:37:57 GMT"}, {"version": "v5", "created": "Tue, 23 Mar 2021 15:07:34 GMT"}, {"version": "v6", "created": "Wed, 21 Apr 2021 06:44:05 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Lindenhovius", "Bert", ""], ["Mislove", "Michael", ""], ["Zamdzhiev", "Vladimir", ""]]}, {"id": "1906.09702", "submitter": "Matthias Noack", "authors": "Matthias Noack", "title": "Heterogeneous Active Messages (HAM) -- Implementing Lightweight Remote\n  Procedure Calls in C++", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present HAM (Heterogeneous Active Messages), a C++-only active messaging\nsolution for heterogeneous distributed systems.Combined with a communication\nprotocol, HAM can be used as a generic Remote Procedure Call (RPC) mechanism.\nIt has been used in HAM-Offload to implement a low-overhead offloading\nframework for inter- and intra-node offloading between different architectures\nincluding accelerators like the Intel Xeon Phi x100 series and the NEC\nSX-Aurora TSUBASA Vector Engine. HAM uses template meta-programming to\nimplicitly generate active message types and their corresponding handler\nfunctions. Heterogeneity is enabled by providing an efficient address\ntranslation mechanism between the individual handler code addresses of\nprocesses running different binaries on different architectures, as well a\nhooks to inject serialisation and deserialisation code on a per-type basis.\nImplementing such a solution in modern C++ sheds some light on the shortcomings\nand grey areas of the C++ standard when it comes to distributed and\nheterogeneous environments.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 03:23:42 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Noack", "Matthias", ""]]}, {"id": "1906.09709", "submitter": "Jeremy Siek", "authors": "Jeremy G. Siek", "title": "Transitivity of Subtyping for Intersection Types", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The subtyping rules for intersection types traditionally employ a\ntransitivity rule (Barendregt et al. 1983), which means that subtyping does not\nsatisfy the subformula property, making it more difficult to use in filter\nmodels for compiler verification. Laurent develops a sequent-style subtyping\nsystem, without transitivity, and proves transitivity via a sequence of six\nlemmas that culminate in cut-elimination (2018). This article develops a\nsubtyping system in regular style that omits transitivity and provides a direct\nproof of transitivity, significantly reducing the length of the proof,\nexchanging the six lemmas for just one. Inspired by Laurent's system, the rule\nfor function types is essentially the $\\beta$-soundness property. The new\nsystem satisfies the \"subformula conjunction property\": every type occurring in\nthe derivation of $A <: B$ is a subformula of $A$ or $B$, or an intersection of\nsuch subformulas. The article proves that the new subtyping system is\nequivalent to that of Barendregt, Coppo, and Dezani-Ciancaglini.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 03:41:50 GMT"}, {"version": "v2", "created": "Fri, 15 May 2020 21:38:44 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Siek", "Jeremy G.", ""]]}, {"id": "1906.10204", "submitter": "Yurii Kostyukov", "authors": "Yurii Kostyukov, Konstantin Batoev, Dmitry Mordvinov, Michael\n  Kostitsyn, Aleksandr Misonizhnik", "title": "Automatic verification of heap-manipulating programs", "comments": "44 pages, in Russian; to be published in Trudy ISP RAN/Proc. ISP RAS,\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Theoretical foundations of compositional reasoning about heaps in imperative\nprogramming languages are investigated. We introduce a novel concept of\ncompositional symbolic memory and its relevant properties. We utilize these\nformal foundations to build up a compositional algorithm that generates\ngeneralized heaps, terms of symbolic heap calculus, which characterize\narbitrary cyclic code segments. All states inferred by this calculus precisely\ncorrespond to reachable states of the original program. We establish the\ncorrespondence between inference in this calculus and execution of pure\nsecond-order functional programs.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 19:57:46 GMT"}, {"version": "v2", "created": "Wed, 26 Jun 2019 07:11:51 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Kostyukov", "Yurii", ""], ["Batoev", "Konstantin", ""], ["Mordvinov", "Dmitry", ""], ["Kostitsyn", "Michael", ""], ["Misonizhnik", "Aleksandr", ""]]}, {"id": "1906.10502", "submitter": "Hossein Hajipour", "authors": "Hossein Hajipour, Apratim Bhattacharya, Mario Fritz", "title": "SampleFix: Learning to Correct Programs by Sampling Diverse Fixes", "comments": "13 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG cs.PL stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Automatic program correction is an active topic of research, which holds the\npotential of dramatically improving productivity of programmers during the\nsoftware development process and correctness of software in general. Recent\nadvances in machine learning, deep learning and NLP have rekindled the hope to\neventually fully automate the process of repairing programs. A key challenge is\nambiguity, as multiple codes -- or fixes -- can implement the same\nfunctionality. In addition, datasets by nature fail to capture the variance\nintroduced by such ambiguities. Therefore, we propose a deep generative model\nto automatically correct programming errors by learning a distribution of\npotential fixes. Our model is formulated as a deep conditional variational\nautoencoder that samples diverse fixes for the given erroneous programs. In\norder to account for ambiguity and inherent lack of representative datasets, we\npropose a novel regularizer to encourage the model to generate diverse fixes.\nOur evaluations on common programming errors show for the first time the\ngeneration of diverse fixes and strong improvements over the state-of-the-art\napproaches by fixing up to 65% of the mistakes.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 13:28:51 GMT"}, {"version": "v2", "created": "Mon, 9 Sep 2019 14:11:19 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Hajipour", "Hossein", ""], ["Bhattacharya", "Apratim", ""], ["Fritz", "Mario", ""]]}, {"id": "1906.10719", "submitter": "Thorsten Wissmann", "authors": "Thomas Powell", "title": "A unifying framework for continuity and complexity in higher types", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 16, Issue 3 (September\n  9, 2020) lmcs:6769", "doi": "10.23638/LMCS-16(3:17)2020", "report-no": null, "categories": "cs.LO cs.PL math.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We set up a parametrised monadic translation for a class of call-by-value\nfunctional languages, and prove a corresponding soundness theorem. We then\npresent a series of concrete instantiations of our translation, demonstrating\nthat a number of fundamental notions concerning higher-order computation,\nincluding termination, continuity and complexity, can all be subsumed into our\nframework. Our main goal is to provide a unifying scheme which brings together\nseveral concepts which are often treated separately in the literature. However,\nas a by-product, we also obtain (i) a method for extracting moduli of\ncontinuity for closed functionals of type\n$(\\mathbb{N}\\to\\mathbb{N})\\to\\mathbb{N}$ definable in (extensions of) System T,\nand (ii) a characterisation of the time complexity of bar recursion.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 18:39:38 GMT"}, {"version": "v2", "created": "Wed, 4 Sep 2019 14:26:36 GMT"}, {"version": "v3", "created": "Mon, 17 Aug 2020 14:58:16 GMT"}, {"version": "v4", "created": "Tue, 8 Sep 2020 08:39:54 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Powell", "Thomas", ""]]}, {"id": "1906.10757", "submitter": "EPTCS", "authors": "Peter Achten (Radboud University), Heather Miller (Carnegie Mellon\n  University)", "title": "Proceedings Seventh International Workshop on Trends in Functional\n  Programming in Education", "comments": null, "journal-ref": "EPTCS 295, 2019", "doi": "10.4204/EPTCS.295", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Seventh International Workshop on Trends in Functional Programming in\nEducation, TFPIE 2018, was held on 14th of June 2018 at Chalmers University in\nGothenburg, Sweden, and was co-located with TFP, the Symposium on Trends in\nFunctional Programming. The goal of TFPIE is to gather researchers, professors,\nteachers, and all professionals interested in functional programming in\neducation. This includes the teaching of functional programming, but also the\napplication of functional programming as a tool for teaching other topics, e.g.\ncomputational concepts, complexity, logic and reasoning, and even disciplines,\ne.g. philosophy or music. TFPIE is the heir of previous events, like Functional\nand Declarative Programming in Education (FDPE), to which it owes a great deal\nand from which it has borrowed experience and ideas. We were delighted to\nwelcome Julien Tournay, Data Engineer at Spotify, Stockholm, Sweden who gave a\nkeynote lecture about the role of functional programming and Scala in\nparticular at Spotify.\n", "versions": [{"version": "v1", "created": "Sat, 8 Jun 2019 12:39:54 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Achten", "Peter", "", "Radboud University"], ["Miller", "Heather", "", "Carnegie Mellon\n  University"]]}, {"id": "1906.10811", "submitter": "Vincenzo Pandolfo", "authors": "Vincenzo Pandolfo", "title": "Investigating the OPS intermediate representation to target GPUs in the\n  Devito DSL", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Devito DSL is a code generation tool for the solution of partial\ndifferential equations using the finite difference method specifically aimed at\nseismic inversion problems.\n  In this work we investigate the integration of OPS, an API to generate highly\noptimized code for applications running on structured meshes targeting various\nplatforms, within Devito as a mean of bringing it to the GPU realm by providing\nan implementation of a OPS backend in Devito, obtaining considerable speed ups\ncompared to the core Devito backend.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 02:11:08 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Pandolfo", "Vincenzo", ""]]}, {"id": "1906.10816", "submitter": "Oleksandr Polozov", "authors": "Richard Shin, Miltiadis Allamanis, Marc Brockschmidt, Oleksandr\n  Polozov", "title": "Program Synthesis and Semantic Parsing with Learned Code Idioms", "comments": "33rd Conference on Neural Information Processing Systems (NeurIPS)\n  2019. 13 pages total, 9 pages of main text", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Program synthesis of general-purpose source code from natural language\nspecifications is challenging due to the need to reason about high-level\npatterns in the target program and low-level implementation details at the same\ntime. In this work, we present PATOIS, a system that allows a neural program\nsynthesizer to explicitly interleave high-level and low-level reasoning at\nevery generation step. It accomplishes this by automatically mining common code\nidioms from a given corpus, incorporating them into the underlying language for\nneural synthesis, and training a tree-based neural synthesizer to use these\nidioms during code generation. We evaluate PATOIS on two complex semantic\nparsing datasets and show that using learned code idioms improves the\nsynthesizer's accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 02:28:10 GMT"}, {"version": "v2", "created": "Tue, 23 Jul 2019 21:58:59 GMT"}, {"version": "v3", "created": "Thu, 5 Sep 2019 01:28:05 GMT"}, {"version": "v4", "created": "Tue, 5 Nov 2019 02:44:38 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Shin", "Richard", ""], ["Allamanis", "Miltiadis", ""], ["Brockschmidt", "Marc", ""], ["Polozov", "Oleksandr", ""]]}, {"id": "1906.11197", "submitter": "Moez AbdelGawad", "authors": "Moez A. AbdelGawad", "title": "Java Generics: An Order-Theoretic Approach (Abridged Outline)", "comments": "5 pages excluding references. An abridged version of arXiv:1906.03937", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The mathematical modeling of generics in Java and other similar\nnominally-typed object-oriented programming languages is a challenge. In this\nshort paper we present the outline of a novel order-theoretic approach to\nmodeling generics, in which we also elementarily use some concepts and tools\nfrom category theory. We believe a combined order-theoretic and\ncategory-theoretic approach to modeling generics holds the keys to overcoming\nmuch of the adversity found when analyzing features of generic OO type systems.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 07:04:44 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["AbdelGawad", "Moez A.", ""]]}, {"id": "1906.11199", "submitter": "David Tolpin", "authors": "David Tolpin", "title": "Deployable probabilistic programming", "comments": "15 pages, to appear in SLPASH Onward! 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose design guidelines for a probabilistic programming facility\nsuitable for deployment as a part of a production software system. As a\nreference implementation, we introduce Infergo, a probabilistic programming\nfacility for Go, a modern programming language of choice for server-side\nsoftware development. We argue that a similar probabilistic programming\nfacility can be added to most modern general-purpose programming languages.\n  Probabilistic programming enables automatic tuning of program parameters and\nalgorithmic decision making through probabilistic inference based on the data.\nTo facilitate addition of probabilistic programming capabilities to other\nprogramming languages, we share implementation choices and techniques employed\nin development of Infergo. We illustrate applicability of Infergo to various\nuse cases on case studies, and evaluate Infergo's performance on several\nbenchmarks, comparing Infergo to dedicated inference-centric probabilistic\nprogramming frameworks.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 15:17:02 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Tolpin", "David", ""]]}, {"id": "1906.11421", "submitter": "EPTCS", "authors": "Marco T. Moraz\\'an (Seton Hall University), Josephine A. Des Rosiers\n  (Seton Hall University)", "title": "FSM Error Messages", "comments": "In Proceedings TFPIE 2018, arXiv:1906.10757", "journal-ref": "EPTCS 295, 2019, pp. 1-16", "doi": "10.4204/EPTCS.295.1", "report-no": null, "categories": "cs.FL cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer Science students, in general, find Automata Theory difficult and\nmostly unrelated to their area of study. To mitigate these perceptions, FSM, a\nlibrary to program state machines and grammars, was developed to bring\nprogramming to the Automata Theory classroom. The results of the library's\nmaiden voyage at Seton Hall University had a positive impact on students, but\nthe students found the library difficult to use due to the error messages\ngenerated. These messages were generated by the host language meaning that\nstudents needed to be familiar with the library's implementation to make sense\nof them. This article presents the design of and results obtained from using an\nerror-messaging system tailor-made for FSM. The effectiveness of the library\nwas measured by both a control group study and a survey. The results strongly\nsuggest that the error-messaging system has had a positive impact on students'\nattitude towards automata theory, towards programming in FSM, and towards FSM\nerror messages. The consequence has been a marked improvement on students'\nability to implement algorithms developed as part of constructive proofs by\nmaking the debugging of FSM programs easier.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 03:32:37 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Moraz\u00e1n", "Marco T.", "", "Seton Hall University"], ["Rosiers", "Josephine A. Des", "", "Seton Hall University"]]}, {"id": "1906.11422", "submitter": "EPTCS", "authors": "Tsukino Furukawa (Ochanomizu University), Youyou Cong (Ochanomizu\n  University), Kenichi Asai (Ochanomizu University)", "title": "Stepping OCaml", "comments": "In Proceedings TFPIE 2018, arXiv:1906.10757", "journal-ref": "EPTCS 295, 2019, pp. 17-34", "doi": "10.4204/EPTCS.295.2", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Steppers, which display all the reduction steps of a given program, are a\nnovice-friendly tool for understanding program behavior. Unfortunately,\nsteppers are not as popular as they ought to be; indeed, the tool is only\navailable in the pedagogical languages of the DrRacket programming environment.\n  We present a stepper for a practical fragment of OCaml. Similarly to the\nDrRacket stepper, we keep track of evaluation contexts in order to reconstruct\nthe whole program at each reduction step. The difference is that we support\neffectful constructs, such as exception handling and printing primitives,\nallowing the stepper to assist a wider range of users. In this paper, we\ndescribe the implementation of the stepper, share the feedback from our\nstudents, and show an attempt at assessing the educational impact of our\nstepper.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 03:32:58 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Furukawa", "Tsukino", "", "Ochanomizu University"], ["Cong", "Youyou", "", "Ochanomizu\n  University"], ["Asai", "Kenichi", "", "Ochanomizu University"]]}, {"id": "1906.11423", "submitter": "EPTCS", "authors": "Marco T. Moraz\\'an (Seton Hall University)", "title": "Vector Programming Using Generative Recursion", "comments": "In Proceedings TFPIE 2018, arXiv:1906.10757. arXiv admin note: text\n  overlap with arXiv:1805.05124", "journal-ref": "EPTCS 295, 2019, pp. 35-51", "doi": "10.4204/EPTCS.295.3", "report-no": null, "categories": "cs.DS cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vector programming is an important topic in many Introduction to Computer\nScience courses. Despite the importance of vectors, learning vector programming\nis a source of frustration for many students. Much of the frustration is rooted\nin discovering the source of bugs that are manifested as out-of-bounds\nindexing. The problem is that such bugs are, sometimes, rooted in incorrectly\ncomputing an index. Other times, however, these errors are rooted in mistaken\nreasoning about how to correctly process a vector. Unfortunately, either way,\nall too often beginners are left adrift to resolve indexing errors on their\nown. This article extends the work done on vector programming using vector\nintervals and structural recursion to using generative recursion. As for\nproblems solved using structural recursion, vector intervals provide beginners\nwith a useful framework for designing code that properly indexes vectors. This\narticle presents the methodology and concrete examples that others may use to\nbuild their own CS1 modules involving vector programming using any programming\nlanguage.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 03:33:23 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Moraz\u00e1n", "Marco T.", "", "Seton Hall University"]]}, {"id": "1906.11425", "submitter": "EPTCS", "authors": "Per Lindgren (Lule{\\aa} University of Technology), Marcus Lindner\n  (Lule{\\aa} University of Technology), Nils Fitinghoff (Lule{\\aa} University\n  of Technology)", "title": "Introducing Certified Compilation in Education by a Functional Language\n  Approach", "comments": "In Proceedings TFPIE 2018, arXiv:1906.10757", "journal-ref": "EPTCS 295, 2019, pp. 65-78", "doi": "10.4204/EPTCS.295.5", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classes on compiler technology are commonly found in Computer Science\ncurricula, covering aspects of parsing, semantic analysis, intermediate\ntransformations and target code generation. This paper reports on introducing\ncertified compilation techniques through a functional language approach in an\nintroductory course on Compiler Construction. Targeting students with little or\nno experience in formal methods, the proof process is highly automated using\nthe Why3 framework. Underlying logic, semantic modelling and proofs are\nintroduced along with exercises and assignments leading up to a formally\nverified compiler for a simplistic imperative language.\n  This paper covers the motivation, course design, tool selection, and teaching\nmethods, together with evaluations and suggested improvements from the\nperspectives of both students and teachers.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 03:33:54 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Lindgren", "Per", "", "Lule\u00e5 University of Technology"], ["Lindner", "Marcus", "", "Lule\u00e5 University of Technology"], ["Fitinghoff", "Nils", "", "Lule\u00e5 University\n  of Technology"]]}, {"id": "1906.11450", "submitter": "EPTCS", "authors": "Boldizs\\'ar N\\'emeth (E\\\"otv\\\"os Lor\\'and University), Eunjong Choi\n  (Nara Institute of Science and Technology), Erina Makihara (Nara Institute of\n  Science and Technology), Hajimu Iida (Nara Institute of Science and\n  Technology)", "title": "Investigating Compilation Errors of Students Learning Haskell", "comments": "In Proceedings TFPIE 2018, arXiv:1906.10757", "journal-ref": "EPTCS 295, 2019, pp. 52-64", "doi": "10.4204/EPTCS.295.4", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While functional programming is an efficient way to express complex software,\nfunctional programming languages have a steep learning curve. Haskell can be\nchallenging to learn for students who were only introduced to imperative\nprogramming. It is important to look for methods and tools that may reduce the\ndifficulty of learning functional programming. Finding methods to help students\nrequires understanding the errors that students make while learning Haskell.\n  There are several previous studies revealing data about Haskell compiler\nerrors, but they do not focus on the analysis of the compiler errors or they\nonly study a certain kind of compiler errors.\n  This study investigates compilation errors of novice Haskell students and\nmake suggestions on how their learning efficiency can be improved. Unlike\nprevious studies we focus on uncovering the root problems with the student\nsolutions by analysing samples of their submissions.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 06:23:20 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["N\u00e9meth", "Boldizs\u00e1r", "", "E\u00f6tv\u00f6s Lor\u00e1nd University"], ["Choi", "Eunjong", "", "Nara Institute of Science and Technology"], ["Makihara", "Erina", "", "Nara Institute of\n  Science and Technology"], ["Iida", "Hajimu", "", "Nara Institute of Science and\n  Technology"]]}, {"id": "1906.11606", "submitter": "Gregor Nitsche", "authors": "Gregor Nitsche", "title": "Structural Contracts -- Contracts for Type Construction & Dependent\n  Types to Ensure Consistency of Extra-Functional Reasoning", "comments": "4 pages, 2 figures, research abstract, submitted for acceptance at\n  the Doctoral Symposium of 3. World Congress on Formal Methods (FM'19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Targeting to use contract-based design for the specification and refinement\nof extra-functional properties, this research abstract suggests to use type\nconstraints and dependent types to ensure correct and consistent top-down\ndecomposition of contracts with respect to a specifiable type constructor. For\nthis, we summarize the composition problem and give a short draft of our\napproach, called Structural Contracts.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 12:03:22 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Nitsche", "Gregor", ""]]}, {"id": "1906.11929", "submitter": "Wei He", "authors": "Wei He", "title": "Invariant Detection with Program Verification Tools", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compilers can specialize programs having invariants for performance\nimprovement. Detecting program invariants that span large and complex code,\nhowever, is difficult for compilers. Traditional compilers do not perform very\nexpensive analysis and thus only identify limited invariants, which limits the\npotential of subsequent optimizations. We would like to address the invariant\ndetection problem via more sophisticated analyses using program verification\ntools. In this paper, we reveal pitfalls of choosing program verification tools\nfor invariant detection, identify challenges of modeling program behavior using\none of these tools---CVC4, and propose some ideas about how to address the\nchallenges.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 19:37:49 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["He", "Wei", ""]]}, {"id": "1906.12029", "submitter": "Cheng Fu", "authors": "Cheng Fu, Huili Chen, Haolan Liu, Xinyun Chen, Yuandong Tian, Farinaz\n  Koushanfar, Jishen Zhao", "title": "A Neural-based Program Decompiler", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reverse engineering of binary executables is a critical problem in the\ncomputer security domain. On the one hand, malicious parties may recover\ninterpretable source codes from the software products to gain commercial\nadvantages. On the other hand, binary decompilation can be leveraged for code\nvulnerability analysis and malware detection. However, efficient binary\ndecompilation is challenging. Conventional decompilers have the following major\nlimitations: (i) they are only applicable to specific source-target language\npair, hence incurs undesired development cost for new language tasks; (ii)\ntheir output high-level code cannot effectively preserve the correct\nfunctionality of the input binary; (iii) their output program does not capture\nthe semantics of the input and the reversed program is hard to interpret. To\naddress the above problems, we propose Coda, the first end-to-end neural-based\nframework for code decompilation. Coda decomposes the decompilation task into\ntwo key phases: First, Coda employs an instruction type-aware encoder and a\ntree decoder for generating an abstract syntax tree (AST) with attention\nfeeding during the code sketch generation stage. Second, Coda then updates the\ncode sketch using an iterative error correction machine guided by an ensembled\nneural error predictor. By finding a good approximate candidate and then fixing\nit towards perfect, Coda achieves superior performance compared to baseline\napproaches. We assess Coda's performance with extensive experiments on various\nbenchmarks. Evaluation results show that Coda achieves an average of 82\\%\nprogram recovery accuracy on unseen binary samples, where the state-of-the-art\ndecompilers yield 0\\% accuracy. Furthermore, Coda outperforms the\nsequence-to-sequence model with attention by a margin of 70\\% program accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 03:29:38 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Fu", "Cheng", ""], ["Chen", "Huili", ""], ["Liu", "Haolan", ""], ["Chen", "Xinyun", ""], ["Tian", "Yuandong", ""], ["Koushanfar", "Farinaz", ""], ["Zhao", "Jishen", ""]]}, {"id": "1906.12066", "submitter": "Pengfei Su", "authors": "Pengfei Su, Qingsen Wang, Milind Chabbi, Xu Liu", "title": "Pinpointing Performance Inefficiencies in Java", "comments": "This is a full-version of our ESEC/FSE'2019 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many performance inefficiencies such as inappropriate choice of algorithms or\ndata structures, developers' inattention to performance, and missed compiler\noptimizations show up as wasteful memory operations. Wasteful memory operations\nare those that produce/consume data to/from memory that may have been avoided.\nWe present, JXPerf, a lightweight performance analysis tool for pinpointing\nwasteful memory operations in Java programs. Traditional byte-code\ninstrumentation for such analysis (1) introduces prohibitive overheads and (2)\nmisses inefficiencies in machine code generation. JXPerf overcomes both of\nthese problems. JXPerf uses hardware performance monitoring units to sample\nmemory locations accessed by a program and uses hardware debug registers to\nmonitor subsequent accesses to the same memory. The result is a lightweight\nmeasurement at machine-code level with attribution of inefficiencies to their\nprovenance: machine and source code within full calling contexts. JXPerf\nintroduces only 7% runtime overhead and 7% memory overhead making it useful in\nproduction. Guided by JXPerf, we optimize several Java applications by\nimproving code generation and choosing superior data structures and algorithms,\nwhich yield significant speedups.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 07:25:24 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Su", "Pengfei", ""], ["Wang", "Qingsen", ""], ["Chabbi", "Milind", ""], ["Liu", "Xu", ""]]}, {"id": "1906.12095", "submitter": "Antoine Amarilli", "authors": "Sidi Mohamed Beillahi, Ahmed Bouajjani, and Constantin Enea", "title": "Robustness Against Transactional Causal Consistency", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 17, Issue 1 (February\n  3, 2021) lmcs:7149", "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Distributed storage systems and databases are widely used by various types of\napplications. Transactional access to these storage systems is an important\nabstraction allowing application programmers to consider blocks of actions\n(i.e., transactions) as executing atomically. For performance reasons, the\nconsistency models implemented by modern databases are weaker than the standard\nserializability model, which corresponds to the atomicity abstraction of\ntransactions executing over a sequentially consistent memory. Causal\nconsistency for instance is one such model that is widely used in practice.\n  In this paper, we investigate application-specific relationships between\nseveral variations of causal consistency and we address the issue of verifying\nautomatically if a given transactional program is robust against causal\nconsistency, i.e., all its behaviors when executed over an arbitrary causally\nconsistent database are serializable. We show that programs without write-write\nraces have the same set of behaviors under all these variations, and we show\nthat checking robustness is polynomial time reducible to a state reachability\nproblem in transactional programs over a sequentially consistent shared memory.\nA surprising corollary of the latter result is that causal consistency\nvariations which admit incomparable sets of behaviors admit comparable sets of\nrobust programs. This reduction also opens the door to leveraging existing\nmethods and tools for the verification of concurrent programs (assuming\nsequential consistency) for reasoning about programs running over causally\nconsistent databases. Furthermore, it allows to establish that the problem of\nchecking robustness is decidable when the programs executed at different sites\nare finite-state.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 08:44:47 GMT"}, {"version": "v2", "created": "Thu, 19 Dec 2019 06:23:33 GMT"}, {"version": "v3", "created": "Mon, 16 Nov 2020 14:39:25 GMT"}, {"version": "v4", "created": "Wed, 13 Jan 2021 13:44:31 GMT"}, {"version": "v5", "created": "Tue, 2 Feb 2021 18:47:09 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Beillahi", "Sidi Mohamed", ""], ["Bouajjani", "Ahmed", ""], ["Enea", "Constantin", ""]]}, {"id": "1906.12098", "submitter": "Andr\\'es Goens", "authors": "Sebastian Ertel and Justus Adam and Norman A. Rink and Andr\\'es Goens\n  and Jeronimo Castrillon", "title": "Category-Theoretic Foundations of \"STCLang: State Thread Composition as\n  a Foundation for Monadic Dataflow Parallelism\"", "comments": "11 Pages, Supplementary to article published in the Haskell'19\n  Symposium", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This manuscript gives a category-theoretic foundation to the composition of\nState Threads as a Foundation for Monadic Dataflow Parallelism. It serves as a\nsupplementary formalization of the concepts introduced in the Article \"STCLang:\nState Thread Composition as a Foundation for Monadic Dataflow Parallelism\", as\npublished in Proceedings of the 12th ACM SIGPLAN International Symposium on\nHaskell (Haskell'19).\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 08:54:55 GMT"}, {"version": "v2", "created": "Fri, 9 Aug 2019 12:55:26 GMT"}], "update_date": "2019-08-12", "authors_parsed": [["Ertel", "Sebastian", ""], ["Adam", "Justus", ""], ["Rink", "Norman A.", ""], ["Goens", "Andr\u00e9s", ""], ["Castrillon", "Jeronimo", ""]]}, {"id": "1906.12242", "submitter": "Koen Pauwels", "authors": "Koen Pauwels, Georgios Karachalias, Michiel Derhaeg and Tom Schrijvers", "title": "Bidirectional Type Class Instances (Extended Version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  GADTs were introduced in Haskell's eco-system more than a decade ago, but\ntheir interaction with several mainstream features such as type classes and\nfunctional dependencies has a lot of room for improvement. More specifically,\nfor some GADTs it can be surprisingly difficult to provide an instance for even\nthe simplest of type classes.\n  In this paper we identify the source of this shortcoming and address it by\nintroducing a conservative extension to Haskell's type classes: Bidirectional\nType Class Instances. In essence, under our interpretation class instances\ncorrespond to logical bi-implications, in contrast to their traditional\nunidirectional interpretation.\n  We present a fully-fledged design of bidirectional instances, covering the\nspecification of typing and elaboration into System FC, as well as an algorithm\nfor type inference and elaboration. We provide a proof-of-concept\nimplementation of our algorithm, and revisit the meta-theory of type classes in\nthe presence of our extension.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 14:35:28 GMT"}, {"version": "v2", "created": "Mon, 1 Jul 2019 08:50:14 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Pauwels", "Koen", ""], ["Karachalias", "Georgios", ""], ["Derhaeg", "Michiel", ""], ["Schrijvers", "Tom", ""]]}]