[{"id": "1402.0087", "submitter": "Reza Ebrahimi Atani", "authors": "Mehran Alidoost Nia, Reza Ebrahimi Atani", "title": "A novel datatype architecture support for programming languages", "comments": "This paper is accepted and published in International journal of\n  Programming Languages and applications", "journal-ref": "International journal of Programming Languages and applications\n  Vol. 4 No.1 2014", "doi": "10.5121/ijpla", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In programmers point of view, Datatypes in programming language level have a\nsimple description but inside hardware, huge machine codes are responsible to\ndescribe type features. Datatype architecture design is a novel approach to\nmatch programming features along with hardware design. In this paper a novel\nData type-Based Code Reducer (TYPELINE) architecture is proposed and\nimplemented according to significant data types (SDT) of programming languages.\nTYPELINE uses TEUs for processing various SDT operations. This architecture\ndesign leads to reducing the number of machine codes, and increases execution\nspeed, and also improves some parallelism level. This is because this\narchitecture supports some operation for the execution of Abstract Data Types\nin parallel. Also it ensures to maintain data type features and entire\napplication level specifications using the proposed type conversion unit. This\nframework includes compiler level identifying execution modes and memory\nmanagement unit for decreasing object read/write in heap memory by ISA support.\nThis energy-efficient architecture is completely compatible with object\noriented programming languages and in combination mode it can process complex\nC++ data structures with respect to parallel TYPELINE architecture support.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2014 14:07:59 GMT"}], "update_date": "2014-04-17", "authors_parsed": [["Nia", "Mehran Alidoost", ""], ["Atani", "Reza Ebrahimi", ""]]}, {"id": "1402.0671", "submitter": "Roshan Ragel", "authors": "Rajitha Navarathna, Swarnalatha Radhakrishnan and Roshan Ragel", "title": "Loop Unrolling in Multi-pipeline ASIP Design", "comments": "6 pages", "journal-ref": "Navarathna, H. M R D B; Radhakrishnan, S.; Ragel, R.G., \"Loop\n  unrolling in multi-pipeline ASIP design,\" Industrial and Information Systems\n  (ICIIS), 2009 International Conference on , pp.306-311, 28-31 Dec. 2009", "doi": "10.1109/ICIINFS.2009.5429845", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Application Specific Instruction-set Processor (ASIP) is one of the popular\nprocessor design techniques for embedded systems which allows customizability\nin processor design without overly hindering design flexibility. Multi-pipeline\nASIPs were proposed to improve the performance of such systems by compromising\nbetween speed and processor area. One of the problems in the multi-pipeline\ndesign is the limited inherent instruction level parallelism (ILP) available in\napplications. The ILP of application programs can be improved via a compiler\noptimization technique known as loop unrolling. In this paper, we present how\nloop unrolling effects the performance of multi-pipeline ASIPs. The\nimprovements in performance average around 15% for a number of benchmark\napplications with the maximum improvement of around 30%. In addition, we\nanalyzed the variable of performance against loop unrolling factor, which is\nthe amount of unrolling we perform.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2014 09:36:34 GMT"}], "update_date": "2014-02-05", "authors_parsed": [["Navarathna", "Rajitha", ""], ["Radhakrishnan", "Swarnalatha", ""], ["Ragel", "Roshan", ""]]}, {"id": "1402.1287", "submitter": "Brijender Kahanwal Dr.", "authors": "Brijender Kahanwal", "title": "Towards High Performance Computing (Hpc) Through Parallel Programming\n  Paradigms and Their Principles", "comments": "11 pages, 2 figures. International Journal of Programming Languages\n  and Applications (IJPLA) 2014", "journal-ref": null, "doi": "10.5121/ijpla.2014.4104", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, we are to find out solutions to huge computing problems very\nrapidly. It brings the idea of parallel computing in which several machines or\nprocessors work cooperatively for computational tasks. In the past decades,\nthere are a lot of variations in perceiving the importance of parallelism in\ncomputing machines. And it is observed that the parallel computing is a\nsuperior solution to many of the computing limitations like speed and density;\nnon-recurring and high cost; and power consumption and heat dissipation etc.\nThe commercial multiprocessors have emerged with lower prices than the\nmainframe machines and supercomputers machines. In this article the high\nperformance computing (HPC) through parallel programming paradigms (PPPs) are\ndiscussed with their constructs and design approaches.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2014 09:34:01 GMT"}], "update_date": "2014-02-07", "authors_parsed": [["Kahanwal", "Brijender", ""]]}, {"id": "1402.1699", "submitter": "Mauro Jaskelioff", "authors": "Mauro Jaskelioff and Russell O'Connor", "title": "A Representation Theorem for Second-Order Functionals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representation theorems relate seemingly complex objects to concrete, more\ntractable ones.\n  In this paper, we take advantage of the abstraction power of category theory\nand provide a general representation theorem for a wide class of second-order\nfunctionals which are polymorphic over a class of functors. Types polymorphic\nover a class of functors are easily representable in languages such as Haskell,\nbut are difficult to analyse and reason about. The concrete representation\nprovided by the theorem is easier to analyse, but it might not be as convenient\nto implement. Therefore, depending on the task at hand, the change of\nrepresentation may prove valuable in one direction or the other.\n  We showcase the usefulness of the representation theorem with a range of\nexamples. Concretely, we show how the representation theorem can be used to\nshow that traversable functors are finitary containers, how parameterised\ncoalgebras relate to very well-behaved lenses, and how algebraic effects might\nbe implemented in a functional language.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2014 17:21:14 GMT"}, {"version": "v2", "created": "Wed, 4 Feb 2015 16:32:31 GMT"}], "update_date": "2015-02-05", "authors_parsed": [["Jaskelioff", "Mauro", ""], ["O'Connor", "Russell", ""]]}, {"id": "1402.1922", "submitter": "Georg Moser", "authors": "Martin Hofmann and Georg Moser", "title": "Amortised Resource Analysis and Typed Polynomial Interpretations\n  (extended version)", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  We introduce a novel resource analysis for typed term rewrite systems based\non a potential-based type system. This type system gives rise to polynomial\nbounds on the innermost runtime complexity. We relate the thus obtained\namortised resource analysis to polynomial interpretations and obtain the\nperhaps surprising result that whenever a rewrite system R can be well-typed,\nthen there exists a polynomial interpretation that orients R. For this we\nadequately adapt the standard notion of polynomial interpretations to the typed\nsetting.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2014 07:08:04 GMT"}, {"version": "v2", "created": "Fri, 14 Mar 2014 11:39:15 GMT"}], "update_date": "2014-03-17", "authors_parsed": [["Hofmann", "Martin", ""], ["Moser", "Georg", ""]]}, {"id": "1402.2949", "submitter": "Aaron Karper", "authors": "Aaron Karper", "title": "A Programming Language Oriented Approach to Computability", "comments": "Bachelor thesis at the University of Bern, supervised by Professor\n  Dr. Thomas Strahm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  The field of computability and complexity was, where computer science sprung\nfrom. Turing, Church, and Kleene all developed formalisms that demonstrated\nwhat they held \"intuitively computable\". The times change however and today's\n(aspiring) computer scientists are less proficient in building automata or\ncomposing functions and are much more native to the world of programming\nlanguages. This article will try to introduce typical concepts of computability\ntheory and complexity in a form more fitted for a modern developer. It is\nmostly based on \\cite{jones}, but takes input from other sources to provide\nexamples, additional information, etc.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2014 21:35:37 GMT"}], "update_date": "2014-02-13", "authors_parsed": [["Karper", "Aaron", ""]]}, {"id": "1402.3690", "submitter": "Jonathan Heras", "authors": "J\\'onathan Heras and Ekaterina Komendantskaya and Martin Schmidt", "title": "(Co)recursion in Logic Programming: Lazy vs Eager", "comments": "To appear in Theory and Practice of Logic Programming (TPLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  CoAlgebraic Logic Programming (CoALP) is a dialect of Logic Programming\ndesigned to bring a more precise compile-time and run-time analysis of\ntermination and productivity for recursive and corecursive functions in Logic\nProgramming. Its second goal is to introduce guarded lazy (co)recursion akin to\nfunctional theorem provers into logic programming. In this paper, we explain\nlazy features of CoALP, and compare them with the loop-analysis and eager\nexecution in Coinductive Logic Programming (CoLP). We conclude by outlining the\nfuture directions in developing the guarded (co)recursion in logic programming.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2014 13:28:34 GMT"}, {"version": "v2", "created": "Thu, 15 May 2014 21:25:25 GMT"}, {"version": "v3", "created": "Mon, 19 May 2014 08:07:40 GMT"}, {"version": "v4", "created": "Tue, 20 May 2014 07:46:48 GMT"}], "update_date": "2014-05-21", "authors_parsed": [["Heras", "J\u00f3nathan", ""], ["Komendantskaya", "Ekaterina", ""], ["Schmidt", "Martin", ""]]}, {"id": "1402.4043", "submitter": "James Riely", "authors": "Radha Jagadeesan and James Riely", "title": "Between Linearizability and Quiescent Consistency: Quantitative\n  Quiescent Consistency", "comments": "Short version in ICALP 2014. http://icalp2014.itu.dk/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linearizability is the de facto correctness criterion for concurrent data\nstructures. Unfortunately, linearizability imposes a performance penalty which\nscales linearly in the number of contending threads. Quiescent consistency is\nan alternative criterion which guarantees that a concurrent data structure\nbehaves correctly when accessed sequentially. Yet quiescent consistency says\nvery little about executions that have any contention.\n  We define quantitative quiescent consistency (QQC), a relaxation of\nlinearizability where the degree of relaxation is proportional to the degree of\ncontention. When quiescent, no relaxation is allowed, and therefore QQC refines\nquiescent consistency, unlike other proposed relaxations of linearizability. We\nshow that high performance counters and stacks designed to satisfy quiescent\nconsistency continue to satisfy QQC. The precise assumptions under which QQC\nholds provides fresh insight on these structures. To demonstrate the robustness\nof QQC, we provide three natural characterizations and prove compositionality.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2014 15:58:49 GMT"}, {"version": "v2", "created": "Wed, 16 Apr 2014 20:53:25 GMT"}, {"version": "v3", "created": "Sat, 26 Apr 2014 17:09:09 GMT"}], "update_date": "2014-04-29", "authors_parsed": [["Jagadeesan", "Radha", ""], ["Riely", "James", ""]]}, {"id": "1402.4467", "submitter": "Krysta Svore", "authors": "Dave Wecker and Krysta M. Svore", "title": "LIQUi|>: A Software Design Architecture and Domain-Specific Language for\n  Quantum Computing", "comments": "14 pages, 12 figures, comments welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.ET cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Languages, compilers, and computer-aided design tools will be essential for\nscalable quantum computing, which promises an exponential leap in our ability\nto execute complex tasks. LIQUi|> is a modular software architecture designed\nto control quantum hardware. It enables easy programming, compilation, and\nsimulation of quantum algorithms and circuits, and is independent of a specific\nquantum architecture. LIQUi|> contains an embedded, domain-specific language\ndesigned for programming quantum algorithms, with F# as the host language. It\nalso allows the extraction of a circuit data structure that can be used for\noptimization, rendering, or translation. The circuit can also be exported to\nexternal hardware and software environments. Two different simulation\nenvironments are available to the user which allow a trade-off between number\nof qubits and class of operations. LIQUi|> has been implemented on a wide range\nof runtimes as back-ends with a single user front-end. We describe the\nsignificant components of the design architecture and how to express any given\nquantum algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2014 20:46:01 GMT"}], "update_date": "2014-02-20", "authors_parsed": [["Wecker", "Dave", ""], ["Svore", "Krysta M.", ""]]}, {"id": "1402.4843", "submitter": "Aleksandar Perisic", "authors": "Aleksandar Perisic", "title": "Exercise: +-1 bug and center of an array problem", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A problem that is constantly cropping up in designing even the simplest\nalgorithm or a program is dealing with +-1 bug when we calculate positions\nwithin an array, very noticeably while splitting it in half. This bug is often\nfound in buffer overflow type of bugs. While designing one complicated\nalgorithm, we needed various ways of splitting an array, and we found lack of\ngeneral guidance for this apparently minor problem. We present an exercise that\ntracks the cause of the problem and leads to the solution. This problem looks\ntrivial because it seems obvious or insignificant, however treating it without\noutmost precision can lead to subtle bugs, unbalanced solution, not transparent\nexpressions for various languages. Basically, the exercise is about dealing\nwith <= < as well as n/2, n/2-1, (n+1)/2, n-1 and similar expressions when they\nare rounded down to the nearest integer and used to define a range.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2014 22:50:29 GMT"}, {"version": "v2", "created": "Sun, 2 Mar 2014 12:51:39 GMT"}, {"version": "v3", "created": "Wed, 5 Mar 2014 12:33:13 GMT"}, {"version": "v4", "created": "Wed, 12 Mar 2014 07:59:05 GMT"}, {"version": "v5", "created": "Fri, 21 Mar 2014 08:44:07 GMT"}], "update_date": "2014-03-24", "authors_parsed": [["Perisic", "Aleksandar", ""]]}, {"id": "1402.5172", "submitter": "Mingsheng Ying", "authors": "Mingsheng Ying, Nengkun Yu and Yuan Feng", "title": "Alternation in Quantum Programming: From Superposition of Data to\n  Superposition of Programs", "comments": "arXiv admin note: substantial text overlap with arXiv:1209.4379", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extract a novel quantum programming paradigm - superposition of programs -\nfrom the design idea of a popular class of quantum algorithms, namely quantum\nwalk-based algorithms. The generality of this paradigm is guaranteed by the\nuniversality of quantum walks as a computational model. A new quantum\nprogramming language QGCL is then proposed to support the paradigm of\nsuperposition of programs. This language can be seen as a quantum extension of\nDijkstra's GCL (Guarded Command Language). Surprisingly, alternation in GCL\nsplits into two different notions in the quantum setting: classical alternation\n(of quantum programs) and quantum alternation, with the latter being introduced\nin QGCL for the first time. Quantum alternation is the key program construct\nfor realizing the paradigm of superposition of programs.\n  The denotational semantics of QGCL are defined by introducing a new\nmathematical tool called the guarded composition of operator-valued functions.\nThen the weakest precondition semantics of QGCL can straightforwardly derived.\nAnother very useful program construct in realizing the quantum programming\nparadigm of superposition of programs, called quantum choice, can be easily\ndefined in terms of quantum alternation. The relation between quantum choices\nand probabilistic choices is clarified through defining the notion of local\nvariables. We derive a family of algebraic laws for QGCL programs that can be\nused in program verification, transformations and compilation. The expressive\npower of QGCL is illustrated by several examples where various variants and\ngeneralizations of quantum walks are conveniently expressed using quantum\nalternation and quantum choice. We believe that quantum programming with\nquantum alternation and choice will play an important role in further\nexploiting the power of quantum computing.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2014 23:35:58 GMT"}], "update_date": "2014-02-24", "authors_parsed": [["Ying", "Mingsheng", ""], ["Yu", "Nengkun", ""], ["Feng", "Yuan", ""]]}, {"id": "1402.5647", "submitter": "Mohamed El-Zawawy Dr.", "authors": "Mohamed A. El-Zawawy, Eisa A. Aleisa", "title": "A new model for Context-Oriented Programs", "comments": "9 pages, 6 figures", "journal-ref": "Mohamed A. El-Zawawy, Eisa A. Aleisa. A new model for\n  Context-Oriented Programs. Life Science Journal, 2013, 10(2), pp: 2515-2523", "doi": null, "report-no": null, "categories": "cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Context-oriented programming (COP) is a new technique for programming that\nallows changing the context in which commands execute as a program executes.\nCompared to object-oriented programming (aspect-oriented programming), COP is\nmore flexible (modular and structured). This paper presents a precise\nsyntax-directed operational semantics for context-oriented programming with\nlayers, as realized by COP languages like ContextJ* and ContextL. Our language\nmodel is built on Java enriched with layer concepts and activation and\ndeactivation of layer scopes. The paper also presents a static type system that\nguarantees that typed programs do not get stuck. Using the means of the\nproposed semantics, the mathematical correctness of the type system is\npresented in the paper.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2014 18:19:23 GMT"}], "update_date": "2014-02-25", "authors_parsed": [["El-Zawawy", "Mohamed A.", ""], ["Aleisa", "Eisa A.", ""]]}, {"id": "1402.5745", "submitter": "Mohamed El-Zawawy Dr.", "authors": "Mohamed A. El-Zawawy", "title": "Distributed Data and Programs Slicing", "comments": "9 pages, 8 figures", "journal-ref": "Life Science Journal, 2013, 10(4), pp. 1361--1369", "doi": null, "report-no": null, "categories": "cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new technique for data slicing of distributed programs\nrunning on a hierarchy of machines. Data slicing can be realized as a program\ntransformation that partitions heaps of machines in a hierarchy into\nindependent regions. Inside each region of each machine, pointers preserve the\noriginal pointer structures in the original heap hierarchy. Each heap component\nof the base type (e.g., the integer type) goes only to a region of one of the\nheaps. The proposed technique has the shape of a system of inference rules. In\naddition, this paper presents a simply structure type system to decide type\nsoundness of distributed programs. Using this type system, a mathematical proof\nthat the proposed slicing technique preserves typing properties is outlined in\nthis paper as well.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2014 08:23:34 GMT"}], "update_date": "2014-02-25", "authors_parsed": [["El-Zawawy", "Mohamed A.", ""]]}]