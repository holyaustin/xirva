[{"id": "1109.0323", "submitter": "EPTCS", "authors": "Olivier Danvy, Chung-chieh Shan", "title": "Proceedings IFIP Working Conference on Domain-Specific Languages", "comments": "This volume is dedicated to the memory of Anne-Fran\\c{c}oise Le Meur\n  (1972--2011)", "journal-ref": "EPTCS 66, 2011", "doi": "10.4204/EPTCS.66", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume is the proceedings of the second IFIP Working Conference on\nDomain-Specific Languages (DSL 2011). It contains 2 abstracts of invited\npresentations, 7 peer-reviewed articles selected by the program committee from\n14 submissions, and 6 lecture notes for the distilled tutorials that we\nsolicited.\n", "versions": [{"version": "v1", "created": "Thu, 1 Sep 2011 22:59:50 GMT"}], "update_date": "2011-09-05", "authors_parsed": [["Danvy", "Olivier", ""], ["Shan", "Chung-chieh", ""]]}, {"id": "1109.0638", "submitter": "Masanobu Umeda", "authors": "Masanobu Umeda, Ryoto Naruse, Hiroaki Sone, Keiichi Katamine", "title": "Translating Nondeterministic Functional Language based on Attribute\n  Grammars into Java", "comments": "13 pages, 8 figures, 2 tables, 19th International Conference on\n  Applications of Declarative Programming and Knowledge Management (INAP2011)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge-based systems are suitable for realizing advanced functions that\nrequire domain-specific expert knowledge, while knowledge representation\nlanguages and their supporting environments are essential for realizing such\nsystems. Although Prolog is useful and effective in realizing such a supporting\nenvironment, the language interoperability with other implementation languages,\nsuch as Java, is often an important issue in practical application development.\nThis paper describes the techniques for translating a knowledge representation\nlanguage that is a nondeterministic functional language based on attribute\ngrammars into Java. The translation is based on binarization and the techniques\nproposed for Prolog to Java translation although the semantics are different\nfrom those of Prolog. A continuation unit is introduced to handle continuation\nefficiently, while the variable and register management on backtracking is\nsimplified by using the single and unidirectional assignment features of\nvariables. An experimental translator written in the language itself\nsuccessfully generates Java code, while experimental results show that the\ngenerated code is over 25 times faster than that of Prolog Cafe for\nnondeterministic programs, and over 2 times faster for deterministic programs.\nThe generated code is also over 2 times faster than B-Prolog for\nnondeterministic programs.\n", "versions": [{"version": "v1", "created": "Sat, 3 Sep 2011 16:54:11 GMT"}], "update_date": "2011-09-06", "authors_parsed": [["Umeda", "Masanobu", ""], ["Naruse", "Ryoto", ""], ["Sone", "Hiroaki", ""], ["Katamine", "Keiichi", ""]]}, {"id": "1109.0774", "submitter": "EPTCS", "authors": "Tim Bauer (Oregon State University), Martin Erwig (Oregon State\n  University), Alan Fern (Oregon State University), Jervis Pinto (Oregon State\n  University)", "title": "Adaptation-Based Programming in Haskell", "comments": "In Proceedings DSL 2011, arXiv:1109.0323", "journal-ref": "EPTCS 66, 2011, pp. 1-23", "doi": "10.4204/EPTCS.66.1", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an embedded DSL to support adaptation-based programming (ABP) in\nHaskell. ABP is an abstract model for defining adaptive values, called\nadaptives, which adapt in response to some associated feedback. We show how our\ndesign choices in Haskell motivate higher-level combinators and constructs and\nhelp us derive more complicated compositional adaptives.\n  We also show an important specialization of ABP is in support of\nreinforcement learning constructs, which optimize adaptive values based on a\nprogrammer-specified objective function. This permits ABP users to easily\ndefine adaptive values that express uncertainty anywhere in their programs.\nOver repeated executions, these adaptive values adjust to more efficient ones\nand enable the user's programs to self optimize.\n  The design of our DSL depends significantly on the use of type classes. We\nwill illustrate, along with presenting our DSL, how the use of type classes can\nsupport the gradual evolution of DSLs.\n", "versions": [{"version": "v1", "created": "Mon, 5 Sep 2011 01:56:05 GMT"}], "update_date": "2011-09-06", "authors_parsed": [["Bauer", "Tim", "", "Oregon State University"], ["Erwig", "Martin", "", "Oregon State\n  University"], ["Fern", "Alan", "", "Oregon State University"], ["Pinto", "Jervis", "", "Oregon State\n  University"]]}, {"id": "1109.0775", "submitter": "EPTCS", "authors": "Azer Bestavros (Boston University), Assaf Kfoury (Boston University)", "title": "A Domain-Specific Language for Incremental and Modular Design of\n  Large-Scale Verifiably-Safe Flow Networks (Preliminary Report)", "comments": "In Proceedings DSL 2011, arXiv:1109.0323", "journal-ref": "EPTCS 66, 2011, pp. 24-47", "doi": "10.4204/EPTCS.66.2", "report-no": null, "categories": "cs.PL cs.DC cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define a domain-specific language (DSL) to inductively assemble flow\nnetworks from small networks or modules to produce arbitrarily large ones, with\ninterchangeable functionally-equivalent parts. Our small networks or modules\nare \"small\" only as the building blocks in this inductive definition (there is\nno limit on their size). Associated with our DSL is a type theory, a system of\nformal annotations to express desirable properties of flow networks together\nwith rules that enforce them as invariants across their interfaces, i.e, the\nrules guarantee the properties are preserved as we build larger networks from\nsmaller ones. A prerequisite for a type theory is a formal semantics, i.e, a\nrigorous definition of the entities that qualify as feasible flows through the\nnetworks, possibly restricted to satisfy additional efficiency or safety\nrequirements. This can be carried out in one of two ways, as a denotational\nsemantics or as an operational (or reduction) semantics; we choose the first in\npreference to the second, partly to avoid exponential-growth rewriting in the\noperational approach. We set up a typing system and prove its soundness for our\nDSL.\n", "versions": [{"version": "v1", "created": "Mon, 5 Sep 2011 01:56:15 GMT"}], "update_date": "2011-09-06", "authors_parsed": [["Bestavros", "Azer", "", "Boston University"], ["Kfoury", "Assaf", "", "Boston University"]]}, {"id": "1109.0776", "submitter": "EPTCS", "authors": "Lucas Beyak, Jacques Carette (McMaster University)", "title": "SAGA: A DSL for Story Management", "comments": "In Proceedings DSL 2011, arXiv:1109.0323", "journal-ref": "EPTCS 66, 2011, pp. 48-67", "doi": "10.4204/EPTCS.66.3", "report-no": null, "categories": "cs.PL cs.MM cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Video game development is currently a very labour-intensive endeavour.\nFurthermore it involves multi-disciplinary teams of artistic content creators\nand programmers, whose typical working patterns are not easily meshed. SAGA is\nour first effort at augmenting the productivity of such teams.\n  Already convinced of the benefits of DSLs, we set out to analyze the domains\npresent in games in order to find out which would be most amenable to the DSL\napproach. Based on previous work, we thus sought those sub-parts that already\nhad a partially established vocabulary and at the same time could be well\nmodeled using classical computer science structures. We settled on the 'story'\naspect of video games as the best candidate domain, which can be modeled using\nstate transition systems.\n  As we are working with a specific company as the ultimate customer for this\nwork, an additional requirement was that our DSL should produce code that can\nbe used within a pre-existing framework. We developed a full system (SAGA)\ncomprised of a parser for a human-friendly language for 'story events', an\ninternal representation of design patterns for implementing object-oriented\nstate-transitions systems, an instantiator for these patterns for a specific\n'story', and three renderers (for C++, C# and Java) for the instantiated\nabstract code.\n", "versions": [{"version": "v1", "created": "Mon, 5 Sep 2011 01:56:19 GMT"}], "update_date": "2011-09-06", "authors_parsed": [["Beyak", "Lucas", "", "McMaster University"], ["Carette", "Jacques", "", "McMaster University"]]}, {"id": "1109.0777", "submitter": "EPTCS", "authors": "Dominic Orchard (Computer Laboratory, University of Cambridge), Alan\n  Mycroft (Computer Laboratory, University of Cambridge)", "title": "Efficient and Correct Stencil Computation via Pattern Matching and\n  Static Typing", "comments": "In Proceedings DSL 2011, arXiv:1109.0323", "journal-ref": "EPTCS 66, 2011, pp. 68-92", "doi": "10.4204/EPTCS.66.4", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stencil computations, involving operations over the elements of an array, are\na common programming pattern in scientific computing, games, and image\nprocessing. As a programming pattern, stencil computations are highly regular\nand amenable to optimisation and parallelisation. However, general-purpose\nlanguages obscure this regular pattern from the compiler, and even the\nprogrammer, preventing optimisation and obfuscating (in)correctness. This paper\nfurthers our work on the Ypnos domain-specific language for stencil\ncomputations embedded in Haskell. Ypnos allows declarative, abstract\nspecification of stencil computations, exposing the structure of a problem to\nthe compiler and to the programmer via specialised syntax. In this paper we\nshow the decidable safety guarantee that well-formed, well-typed Ypnos programs\ncannot index outside of array boundaries. Thus indexing in Ypnos is safe and\nrun-time bounds checking can be eliminated. Program information is encoded as\ntypes, using the advanced type-system features of the Glasgow Haskell Compiler,\nwith the safe-indexing invariant enforced at compile time via type checking.\n", "versions": [{"version": "v1", "created": "Mon, 5 Sep 2011 01:56:26 GMT"}], "update_date": "2011-09-06", "authors_parsed": [["Orchard", "Dominic", "", "Computer Laboratory, University of Cambridge"], ["Mycroft", "Alan", "", "Computer Laboratory, University of Cambridge"]]}, {"id": "1109.0778", "submitter": "EPTCS", "authors": "Tiark Rompf (EPFL), Arvind K. Sujeeth (Stanford University),\n  HyoukJoong Lee (Stanford University), Kevin J. Brown (Stanford University),\n  Hassan Chafi (Stanford University), Martin Odersky (EPFL), Kunle Olukotun\n  (Stanford University)", "title": "Building-Blocks for Performance Oriented DSLs", "comments": "In Proceedings DSL 2011, arXiv:1109.0323", "journal-ref": "EPTCS 66, 2011, pp. 93-117", "doi": "10.4204/EPTCS.66.5", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain-specific languages raise the level of abstraction in software\ndevelopment. While it is evident that programmers can more easily reason about\nvery high-level programs, the same holds for compilers only if the compiler has\nan accurate model of the application domain and the underlying target platform.\nSince mapping high-level, general-purpose languages to modern, heterogeneous\nhardware is becoming increasingly difficult, DSLs are an attractive way to\ncapitalize on improved hardware performance, precisely by making the compiler\nreason on a higher level. Implementing efficient DSL compilers is a daunting\ntask however, and support for building performance-oriented DSLs is urgently\nneeded. To this end, we present the Delite Framework, an extensible toolkit\nthat drastically simplifies building embedded DSLs and compiling DSL programs\nfor execution on heterogeneous hardware. We discuss several building blocks in\nsome detail and present experimental results for the OptiML machine-learning\nDSL implemented on top of Delite.\n", "versions": [{"version": "v1", "created": "Mon, 5 Sep 2011 01:56:34 GMT"}], "update_date": "2011-09-06", "authors_parsed": [["Rompf", "Tiark", "", "EPFL"], ["Sujeeth", "Arvind K.", "", "Stanford University"], ["Lee", "HyoukJoong", "", "Stanford University"], ["Brown", "Kevin J.", "", "Stanford University"], ["Chafi", "Hassan", "", "Stanford University"], ["Odersky", "Martin", "", "EPFL"], ["Olukotun", "Kunle", "", "Stanford University"]]}, {"id": "1109.0779", "submitter": "EPTCS", "authors": "Basile Starynkevitch (CEA, LIST)", "title": "MELT - a Translated Domain Specific Language Embedded in the GCC\n  Compiler", "comments": "In Proceedings DSL 2011, arXiv:1109.0323", "journal-ref": "EPTCS 66, 2011, pp. 118-142", "doi": "10.4204/EPTCS.66.6", "report-no": null, "categories": "cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The GCC free compiler is a very large software, compiling source in several\nlanguages for many targets on various systems. It can be extended by plugins,\nwhich may take advantage of its power to provide extra specific functionality\n(warnings, optimizations, source refactoring or navigation) by processing\nvarious GCC internal representations (Gimple, Tree, ...). Writing plugins in C\nis a complex and time-consuming task, but customizing GCC by using an existing\nscripting language inside is impractical. We describe MELT, a specific\nLisp-like DSL which fits well into existing GCC technology and offers\nhigh-level features (functional, object or reflexive programming, pattern\nmatching). MELT is translated to C fitted for GCC internals and provides\nvarious features to facilitate this. This work shows that even huge, legacy,\nsoftware can be a posteriori extended by specifically tailored and translated\nhigh-level DSLs.\n", "versions": [{"version": "v1", "created": "Mon, 5 Sep 2011 01:56:40 GMT"}], "update_date": "2011-09-06", "authors_parsed": [["Starynkevitch", "Basile", "", "CEA, LIST"]]}, {"id": "1109.0780", "submitter": "EPTCS", "authors": "Eric Walkingshaw (Oregon State University), Martin Erwig (Oregon State\n  University)", "title": "A DSEL for Studying and Explaining Causation", "comments": "In Proceedings DSL 2011, arXiv:1109.0323", "journal-ref": "EPTCS 66, 2011, pp. 143-167", "doi": "10.4204/EPTCS.66.7", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a domain-specific embedded language (DSEL) in Haskell that\nsupports the philosophical study and practical explanation of causation. The\nlanguage provides constructs for modeling situations comprised of events and\nfunctions for reliably determining the complex causal relationships that emerge\nbetween these events. It enables the creation of visual explanations of these\ncausal relationships and a means to systematically generate alternative,\nrelated scenarios, along with corresponding outcomes and causes. The DSEL is\nbased on neuron diagrams, a visual notation that is well established in\npractice and has been successfully employed for causation explanation and\nresearch. In addition to its immediate applicability by users of neuron\ndiagrams, the DSEL is extensible, allowing causation experts to extend the\nnotation to introduce special-purpose causation constructs. The DSEL also\nextends the notation of neuron diagrams to operate over non-boolean values,\nimproving its expressiveness and offering new possibilities for causation\nresearch and its applications.\n", "versions": [{"version": "v1", "created": "Mon, 5 Sep 2011 01:56:47 GMT"}], "update_date": "2011-09-06", "authors_parsed": [["Walkingshaw", "Eric", "", "Oregon State University"], ["Erwig", "Martin", "", "Oregon State\n  University"]]}, {"id": "1109.0781", "submitter": "EPTCS", "authors": "William R. Cook (University of Texas at Austin), Ralf L\\\"ammel\n  (University of Koblenz-Landau)", "title": "Tutorial on Online Partial Evaluation", "comments": "In Proceedings DSL 2011, arXiv:1109.0323", "journal-ref": "EPTCS 66, 2011, pp. 168-180", "doi": "10.4204/EPTCS.66.8", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is a short tutorial introduction to online partial evaluation. We\nshow how to write a simple online partial evaluator for a simple, pure,\nfirst-order, functional programming language. In particular, we show that the\npartial evaluator can be derived as a variation on a compositionally defined\ninterpreter. We demonstrate the use of the resulting partial evaluator for\nprogram optimization in the context of model-driven development.\n", "versions": [{"version": "v1", "created": "Mon, 5 Sep 2011 01:56:53 GMT"}], "update_date": "2011-09-06", "authors_parsed": [["Cook", "William R.", "", "University of Texas at Austin"], ["L\u00e4mmel", "Ralf", "", "University of Koblenz-Landau"]]}, {"id": "1109.0782", "submitter": "Jeremy Gibbons Jeremy Gibbons", "authors": "Jeremy Gibbons (University of Oxford)", "title": "Maximum Segment Sum, Monadically (distilled tutorial, with solutions)", "comments": "Revision of the article in Proceedings DSL 2011, EPTCS 66,\n  arXiv:1109.0323, to provide solutions to the exercises", "journal-ref": "EPTCS 66, 2011, pp. 181-194", "doi": "10.4204/EPTCS.66.9", "report-no": null, "categories": "cs.DS cs.DM cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The maximum segment sum problem is to compute, given a list of integers, the\nlargest of the sums of the contiguous segments of that list. This problem\nspecification maps directly onto a cubic-time algorithm; however, there is a\nvery elegant linear-time solution too. The problem is a classic exercise in the\nmathematics of program construction, illustrating important principles such as\ncalculational development, pointfree reasoning, algebraic structure, and\ndatatype-genericity. Here, we take a sideways look at the datatype-generic\nversion of the problem in terms of monadic functional programming, instead of\nthe traditional relational approach; the presentation is tutorial in style, and\nleavened with exercises for the reader.\n", "versions": [{"version": "v1", "created": "Mon, 5 Sep 2011 01:57:00 GMT"}, {"version": "v2", "created": "Fri, 18 Nov 2011 15:37:23 GMT"}], "update_date": "2011-11-21", "authors_parsed": [["Gibbons", "Jeremy", "", "University of Oxford"]]}, {"id": "1109.0783", "submitter": "EPTCS", "authors": "Jerzy Karczmarczuk (University of Caen, France)", "title": "Specific \"scientific\" data structures, and their processing", "comments": "In Proceedings DSL 2011, arXiv:1109.0323", "journal-ref": "EPTCS 66, 2011, pp. 195-209", "doi": "10.4204/EPTCS.66.10", "report-no": null, "categories": "cs.DS cs.MS cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Programming physicists use, as all programmers, arrays, lists, tuples,\nrecords, etc., and this requires some change in their thought patterns while\nconverting their formulae into some code, since the \"data structures\" operated\nupon, while elaborating some theory and its consequences, are rather: power\nseries and Pad\\'e approximants, differential forms and other instances of\ndifferential algebras, functionals (for the variational calculus), trajectories\n(solutions of differential equations), Young diagrams and Feynman graphs, etc.\nSuch data is often used in a [semi-]numerical setting, not necessarily\n\"symbolic\", appropriate for the computer algebra packages. Modules adapted to\nsuch data may be \"just libraries\", but often they become specific, embedded\nsub-languages, typically mapped into object-oriented frameworks, with\noverloaded mathematical operations. Here we present a functional approach to\nthis philosophy. We show how the usage of Haskell datatypes and - fundamental\nfor our tutorial - the application of lazy evaluation makes it possible to\noperate upon such data (in particular: the \"infinite\" sequences) in a natural\nand comfortable manner.\n", "versions": [{"version": "v1", "created": "Mon, 5 Sep 2011 01:57:07 GMT"}], "update_date": "2011-09-06", "authors_parsed": [["Karczmarczuk", "Jerzy", "", "University of Caen, France"]]}, {"id": "1109.0784", "submitter": "EPTCS", "authors": "Oleg Kiselyov", "title": "Implementing Explicit and Finding Implicit Sharing in Embedded DSLs", "comments": "In Proceedings DSL 2011, arXiv:1109.0323", "journal-ref": "EPTCS 66, 2011, pp. 210-225", "doi": "10.4204/EPTCS.66.11", "report-no": null, "categories": "cs.PL cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aliasing, or sharing, is prominent in many domains, denoting that two\ndifferently-named objects are in fact identical: a change in one object (memory\ncell, circuit terminal, disk block) is instantly reflected in the other.\nLanguages for modelling such domains should let the programmer explicitly\ndefine the sharing among objects or expressions. A DSL compiler may find other\nidentical expressions and share them, implicitly. Such common subexpression\nelimination is crucial to the efficient implementation of DSLs. Sharing is\ntricky in embedded DSL, since host aliasing may correspond to copying of the\nunderlying objects rather than their sharing.\n  This tutorial summarizes discussions of implementing sharing in Haskell DSLs\nfor automotive embedded systems and hardware description languages. The\ntechnique has since been used in a Haskell SAT solver and the DSL for music\nsynthesis. We demonstrate the embedding in pure Haskell of a simple DSL with a\nlanguage form for explicit sharing. The DSL also has implicit sharing,\nimplemented via hash-consing. Explicit sharing greatly speeds up hash-consing.\nThe seemingly imperative nature of hash-consing is hidden beneath a simple\ncombinator language. The overall implementation remains pure functional and\neasy to reason about.\n", "versions": [{"version": "v1", "created": "Mon, 5 Sep 2011 01:57:14 GMT"}], "update_date": "2011-09-06", "authors_parsed": [["Kiselyov", "Oleg", ""]]}, {"id": "1109.0785", "submitter": "EPTCS", "authors": "Keiko Nakata (Institute of Cybernetics at Tallinn University of\n  Technology)", "title": "Resumption-based big-step and small-step interpreters for While with\n  interactive I/O", "comments": "In Proceedings DSL 2011, arXiv:1109.0323", "journal-ref": "EPTCS 66, 2011, pp. 226-235", "doi": "10.4204/EPTCS.66.12", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this tutorial, we program big-step and small-step total interpreters for\nthe While language extended with input and output primitives. While is a simple\nimperative language consisting of skip, assignment, sequence, conditional and\nloop. We first develop trace-based interpreters for While. Traces are\npotentially infinite nonempty sequences of states. The interpreters assign\ntraces to While programs: for us, traces are denotations of While programs. The\ntrace is finite if the program is terminating and infinite if the program is\nnon-terminating. However, we cannot decide (i.e., write a program to\ndetermine), for any given program, whether its trace is finite or infinite,\nwhich amounts to deciding the halting problem. We then extend While with\ninteractive input/output primitives. Accordingly, we extend the interpreters by\ngeneralizing traces to resumptions.\n  The tutorial is based on our previous work with T. Uustalu on reasoning about\ninteractive programs in the setting of constructive type theory.\n", "versions": [{"version": "v1", "created": "Mon, 5 Sep 2011 01:57:20 GMT"}], "update_date": "2011-09-06", "authors_parsed": [["Nakata", "Keiko", "", "Institute of Cybernetics at Tallinn University of\n  Technology"]]}, {"id": "1109.0786", "submitter": "EPTCS", "authors": "Walid Taha (Halmstad University), Veronica Gaspes (Halmstad\n  University), Rex Page (University of Oklahoma)", "title": "Accurate Programming: Thinking about programs in terms of properties", "comments": "In Proceedings DSL 2011, arXiv:1109.0323", "journal-ref": "EPTCS 66, 2011, pp. 236-260", "doi": "10.4204/EPTCS.66.13", "report-no": null, "categories": "cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate programming is a practical approach to producing high quality\nprograms. It combines ideas from test-automation, test-driven development,\nagile programming, and other state of the art software development methods. In\naddition to building on approaches that have proven effective in practice, it\nemphasizes concepts that help programmers sharpen their understanding of both\nthe problems they are solving and the solutions they come up with. This is\nachieved by encouraging programmers to think about programs in terms of\nproperties.\n", "versions": [{"version": "v1", "created": "Mon, 5 Sep 2011 01:57:27 GMT"}], "update_date": "2011-09-06", "authors_parsed": [["Taha", "Walid", "", "Halmstad University"], ["Gaspes", "Veronica", "", "Halmstad\n  University"], ["Page", "Rex", "", "University of Oklahoma"]]}, {"id": "1109.1420", "submitter": "Paul Bone", "authors": "Paul Bone, Zoltan Somogyi and Peter Schachte", "title": "Estimating the overlap between dependent computations for automatic\n  parallelization", "comments": null, "journal-ref": "Theory and Practice of Logic Programming, 27th Int'l. Conference\n  on Logic Programming (ICLP'11) Special Issue, volume 11, issue 4-5, pages\n  575-587. July 2011", "doi": null, "report-no": null, "categories": "cs.PL cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Researchers working on the automatic parallelization of programs have long\nknown that too much parallelism can be even worse for performance than too\nlittle, because spawning a task to be run on another CPU incurs overheads.\nAutoparallelizing compilers have therefore long tried to use granularity\nanalysis to ensure that they only spawn off computations whose cost will\nprobably exceed the spawn-off cost by a comfortable margin. However, this is\nnot enough to yield good results, because data dependencies may \\emph{also}\nlimit the usefulness of running computations in parallel. If one computation\nblocks almost immediately and can resume only after another has completed its\nwork, then the cost of parallelization again exceeds the benefit.\n  We present a set of algorithms for recognizing places in a program where it\nis worthwhile to execute two or more computations in parallel that pay\nattention to the second of these issues as well as the first. Our system uses\nprofiling information to compute the times at which a procedure call consumes\nthe values of its input arguments and the times at which it produces the values\nof its output arguments. Given two calls that may be executed in parallel, our\nsystem uses the times of production and consumption of the variables they share\nto determine how much their executions would overlap if they were run in\nparallel, and therefore whether executing them in parallel is a good idea or\nnot.\n  We have implemented this technique for Mercury in the form of a tool that\nuses profiling data to generate recommendations about what to parallelize, for\nthe Mercury compiler to apply on the next compilation of the program. We\npresent preliminary results that show that this technique can yield useful\nparallelization speedups, while requiring nothing more from the programmer than\nrepresentative input data for the profiling run.\n", "versions": [{"version": "v1", "created": "Wed, 7 Sep 2011 11:19:55 GMT"}], "update_date": "2011-09-08", "authors_parsed": [["Bone", "Paul", ""], ["Somogyi", "Zoltan", ""], ["Schachte", "Peter", ""]]}, {"id": "1109.1421", "submitter": "Paul Bone", "authors": "Paul Bone and Zoltan Somogyi", "title": "Profiling parallel Mercury programs with ThreadScope", "comments": "21st Workshop on Logic-based methods in Programming Environments.\n  Lexington, Kentucky, July 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The behavior of parallel programs is even harder to understand than the\nbehavior of sequential programs. Parallel programs may suffer from any of the\nperformance problems affecting sequential programs, as well as from several\nproblems unique to parallel systems. Many of these problems are quite hard (or\neven practically impossible) to diagnose without help from specialized tools.\nWe present a proposal for a tool for profiling the parallel execution of\nMercury programs, a proposal whose implementation we have already started. This\ntool is an adaptation and extension of the ThreadScope profiler that was first\nbuilt to help programmers visualize the execution of parallel Haskell programs.\n", "versions": [{"version": "v1", "created": "Wed, 7 Sep 2011 11:20:46 GMT"}], "update_date": "2011-09-08", "authors_parsed": [["Bone", "Paul", ""], ["Somogyi", "Zoltan", ""]]}, {"id": "1109.1587", "submitter": "Laura Titolo", "authors": "Marco Comini and Laura Titolo and Alicia Villanueva", "title": "Abstract Diagnosis for Timed Concurrent Constraint programs", "comments": "16 pages", "journal-ref": "Theory and Practice of Logic Programming 2011, 11(4-5): 487-502\n  (2011)", "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Timed Concurrent Constraint Language (tccp in short) is a concurrent\nlogic language based on the simple but powerful concurrent constraint paradigm\nof Saraswat. In this paradigm, the notion of store-as-value is replaced by the\nnotion of store-as-constraint, which introduces some differences w.r.t. other\napproaches to concurrency. In this paper, we provide a general framework for\nthe debugging of tccp programs. To this end, we first present a new compact,\nbottom-up semantics for the language that is well suited for debugging and\nverification purposes in the context of reactive systems. We also provide an\nabstract semantics that allows us to effectively implement debugging algorithms\nbased on abstract interpretation. Given a tccp program and a behavior\nspecification, our debugging approach automatically detects whether the program\nsatisfies the specification. This differs from other semiautomatic approaches\nto debugging and avoids the need to provide symptoms in advance. We show the\nefficacy of our approach by introducing two illustrative examples. We choose a\nspecific abstract domain and show how we can detect that a program is\nerroneous.\n", "versions": [{"version": "v1", "created": "Wed, 7 Sep 2011 22:02:45 GMT"}], "update_date": "2011-09-09", "authors_parsed": [["Comini", "Marco", ""], ["Titolo", "Laura", ""], ["Villanueva", "Alicia", ""]]}, {"id": "1109.1774", "submitter": "Ozgur Akgun", "authors": "Ozgur Akgun, Alan M. Frisch, Brahim Hnich, Chris Jefferson, Ian Miguel", "title": "Conjure Revisited: Towards Automated Constraint Modelling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automating the constraint modelling process is one of the key challenges\nfacing the constraints field, and one of the principal obstacles preventing\nwidespread adoption of constraint solving. This paper focuses on the\nrefinement-based approach to automated modelling, where a user specifies a\nproblem in an abstract constraint specification language and it is then\nautomatically refined into a constraint model. In particular, we revisit the\nConjure system that first appeared in prototype form in 2005 and present a new\nimplementation with a much greater coverage of the specification language\nEssence.\n", "versions": [{"version": "v1", "created": "Thu, 8 Sep 2011 17:09:00 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Akgun", "Ozgur", ""], ["Frisch", "Alan M.", ""], ["Hnich", "Brahim", ""], ["Jefferson", "Chris", ""], ["Miguel", "Ian", ""]]}, {"id": "1109.1905", "submitter": "David Monniaux", "authors": "David Monniaux (VERIMAG - IMAG), Martin Bodin (VERIMAG - IMAG, DI)", "title": "Modular Abstractions of Reactive Nodes using Disjunctive Invariants", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We wish to abstract nodes in a reactive programming language, such as Lustre,\ninto nodes with a simpler control structure, with a bound on the number of\ncontrol states. In order to do so, we compute disjunctive invariants in\npredicate abstraction, with a bounded number of disjuncts, then we abstract the\nnode, each disjunct representing an abstract state. The computation of the\ndisjunctive invariant is performed by a form of quantifier elimination\nexpressed using SMT-solving. The same method can also be used to obtain\ndisjunctive loop invariants.\n", "versions": [{"version": "v1", "created": "Fri, 9 Sep 2011 06:38:06 GMT"}], "update_date": "2011-09-12", "authors_parsed": [["Monniaux", "David", "", "VERIMAG - IMAG"], ["Bodin", "Martin", "", "VERIMAG - IMAG, DI"]]}, {"id": "1109.2015", "submitter": "Michael Leuschel", "authors": "Stefan Hallerstede and Michael Leuschel", "title": "Constraint-Based Deadlock Checking of High-Level Specifications", "comments": null, "journal-ref": "Theory and Practice of Logic Programming 11(4--5): 767--782, 2011", "doi": null, "report-no": null, "categories": "cs.LO cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Establishing the absence of deadlocks is important in many applications of\nformal methods. The use of model checking for finding deadlocks in formal\nmodels is often limited. In this paper we propose a constraint-based approach\nto finding deadlocks employing the ProB constraint solver. We present the\ngeneral technique, as well as various improvements that had to be performed on\nProB's Prolog kernel, such as reification of membership and arithmetic\nconstraints. This work was guided by an industrial case study, where a team\nfrom Bosch was modeling a cruise control system. Within this case study, ProB\nwas able to quickly find counter examples to very large deadlock-freedom\nconstraints. In the paper, we also present other successful applications of\nthis new technique. Experiments using SAT and SMT solvers on these constraints\nwere thus far unsuccessful.\n", "versions": [{"version": "v1", "created": "Fri, 9 Sep 2011 14:03:41 GMT"}], "update_date": "2011-09-12", "authors_parsed": [["Hallerstede", "Stefan", ""], ["Leuschel", "Michael", ""]]}, {"id": "1109.2222", "submitter": "Lars Wortel", "authors": "Lars Wortel", "title": "Side Effects in Steering Fragments", "comments": "Master's thesis - Master of Logic - University of Amsterdam", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this thesis I will give a formal definition of side effects. I will do so\nby modifying a system for modelling program instructions and program states,\nQuantified Dynamic Logic, to a system called DLAf (for Dynamic Logic with\nAssignments as Formulas), which in contrast to QDL allows assignments in\nformulas and makes use of short-circuit evaluation. I will show the underlying\nlogic in those formulas to be a variant of short-circuit logic called\nrepetition-proof short-circuit logic.\n  Using DLAf I will define the actual and the expected evaluation of a single\ninstruction. The side effects are then defined to be the difference between the\ntwo. I will give rules for composing those side effects in single instructions,\nthus scaling up our definition of side effects to a definition of side effects\nin deterministic \\dlaf-programs. Using this definition I will give a\nclassification of side effects, introducing as most important class that of\nmarginal side effects. Finally, I will show how to use our system for\ncalculating the side effects in a real system such as Program Algebra (PGA).\n", "versions": [{"version": "v1", "created": "Sat, 10 Sep 2011 13:24:08 GMT"}], "update_date": "2011-09-13", "authors_parsed": [["Wortel", "Lars", ""]]}, {"id": "1109.2247", "submitter": "Robert Kent", "authors": "Robert E. Kent", "title": "The Standard Aspect of Dialectical Logic", "comments": "An abstracted version of this paper, entitled \"Dialectical Program\n  Semantics\", was accepted for presentation at the 1st International Conference\n  on Algebraic Methodology and Software Technology (AMAST'89), University of\n  Iowa, Iowa City, Iowa, 1989", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialectical logic is the logic of dialectical processes. The goal of\ndialectical logic is to introduce dynamic notions into logical computational\nsystems. The fundamental notions of proposition and truth-value in standard\nlogic are subsumed by the notions of process and flow in dialectical logic.\nDialectical logic has a standard aspect, which can be defined in terms of the\n\"local cartesian closure\" of subtypes. The standard aspect of dialectical logic\nprovides a natural program semantics which incorporates Hoare's\nprecondition/postcondition semantics and extends the standard Kripke semantics\nof dynamic logic. The goal of the standard aspect of dialectical logic is to\nunify the logic of small-scale and large-scale programming.\n", "versions": [{"version": "v1", "created": "Sat, 10 Sep 2011 18:23:07 GMT"}], "update_date": "2011-09-13", "authors_parsed": [["Kent", "Robert E.", ""]]}, {"id": "1109.2405", "submitter": "David Monniaux", "authors": "David Monniaux (VERIMAG - IMAG), Julien Le Guen (VERIMAG - IMAG, ST\n  Microelectronics)", "title": "Stratified Static Analysis Based on Variable Dependencies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In static analysis by abstract interpretation, one often uses widening\noperators in order to enforce convergence within finite time to an inductive\ninvariant. Certain widening operators, including the classical one over finite\npolyhedra, exhibit an unintuitive behavior: analyzing the program over a subset\nof its variables may lead a more precise result than analyzing the original\nprogram! In this article, we present simple workarounds for such behavior.\n", "versions": [{"version": "v1", "created": "Mon, 12 Sep 2011 08:48:00 GMT"}], "update_date": "2011-09-13", "authors_parsed": [["Monniaux", "David", "", "VERIMAG - IMAG"], ["Guen", "Julien Le", "", "VERIMAG - IMAG, ST\n  Microelectronics"]]}, {"id": "1109.2434", "submitter": "Kim Bauters", "authors": "Kim Bauters and Jeroen Janssen and Steven Schockaert and Dirk Vermeir\n  and Martine De Cock", "title": "Expressiveness of Communication in Answer Set Programming", "comments": "35 pages. This article has been accepted for publication in Theory\n  and Practice of Logic Programming, Copyright Cambridge University Press", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Answer set programming (ASP) is a form of declarative programming that allows\nto succinctly formulate and efficiently solve complex problems. An intuitive\nextension of this formalism is communicating ASP, in which multiple ASP\nprograms collaborate to solve the problem at hand. However, the expressiveness\nof communicating ASP has not been thoroughly studied. In this paper, we present\na systematic study of the additional expressiveness offered by allowing ASP\nprograms to communicate. First, we consider a simple form of communication\nwhere programs are only allowed to ask questions to each other. For the most\npart, we deliberately only consider simple programs, i.e. programs for which\ncomputing the answer sets is in P. We find that the problem of deciding whether\na literal is in some answer set of a communicating ASP program using simple\ncommunication is NP-hard. In other words: we move up a step in the polynomial\nhierarchy due to the ability of these simple ASP programs to communicate and\ncollaborate. Second, we modify the communication mechanism to also allow us to\nfocus on a sequence of communicating programs, where each program in the\nsequence may successively remove some of the remaining models. This mimics a\nnetwork of leaders, where the first leader has the first say and may remove\nmodels that he or she finds unsatisfactory. Using this particular communication\nmechanism allows us to capture the entire polynomial hierarchy. This means, in\nparticular, that communicating ASP could be used to solve problems that are\nabove the second level of the polynomial hierarchy, such as some forms of\nabductive reasoning as well as PSPACE-complete problems such as STRIPS\nplanning.\n", "versions": [{"version": "v1", "created": "Mon, 12 Sep 2011 11:48:38 GMT"}], "update_date": "2011-09-13", "authors_parsed": [["Bauters", "Kim", ""], ["Janssen", "Jeroen", ""], ["Schockaert", "Steven", ""], ["Vermeir", "Dirk", ""], ["De Cock", "Martine", ""]]}, {"id": "1109.2548", "submitter": "Jael Kriener", "authors": "Jael Kriener and Andy King", "title": "RedAlert: Determinacy Inference for Prolog", "comments": "Theory and Practice of Logic Programming, 2011, 27th Int'l.\n  Conference on Logic Programming (ICLP'11) Special Issue, volume 11, issue 4-5", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper revisits the problem of determinacy inference addressing the\nproblem of how to uniformly handle cut. To this end a new semantics is\nintroduced for cut, which is abstracted to systematically derive a backward\nanalysis that derives conditions sufficient for a goal to succeed at most once.\nThe method is conceptionally simpler and easier to implement than existing\ntechniques, whilst improving the latter's handling of cut. Formal arguments\nsubstantiate correctness and experimental work, and a tool called 'RedAlert'\ndemonstrates the method's generality and applicability.\n", "versions": [{"version": "v1", "created": "Mon, 12 Sep 2011 17:49:01 GMT"}], "update_date": "2011-09-13", "authors_parsed": [["Kriener", "Jael", ""], ["King", "Andy", ""]]}, {"id": "1109.2807", "submitter": "Damien Cassou", "authors": "Damien Cassou (INRIA Bordeaux - Sud-Ouest, LaBRI), Emilie Balland\n  (INRIA Bordeaux - Sud-Ouest), Charles Consel (INRIA Bordeaux - Sud-Ouest,\n  ENSEIRB), Julia Lawall (DIKU, LIP6)", "title": "Leveraging Software Architectures to Guide and Verify the Development of\n  Sense/Compute/Control Applications", "comments": null, "journal-ref": "ICSE'11: Proceedings of the 33rd International Conference on\n  Software Engineering (2011) 431-440", "doi": null, "report-no": null, "categories": "cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A software architecture describes the structure of a computing system by\nspecifying software components and their interactions. Mapping a software\narchitecture to an implementation is a well known challenge. A key element of\nthis mapping is the architecture's description of the data and control-flow\ninteractions between components. The characterization of these interactions can\nbe rather abstract or very concrete, providing more or less implementation\nguidance, programming support, and static verification. In this paper, we\nexplore one point in the design space between abstract and concrete component\ninteraction specifications. We introduce a notion of behavioral contract that\nexpresses the set of allowed interactions between components, describing both\ndata and control-flow constraints. This declaration is part of the architecture\ndescription, allows generation of extensive programming support, and enables\nvarious verifications. We instantiate our approach in an architecture\ndescription language for the domain of Sense/Compute/Control applications, and\ndescribe associated compilation and verification strategies.\n", "versions": [{"version": "v1", "created": "Tue, 13 Sep 2011 14:50:11 GMT"}], "update_date": "2011-09-14", "authors_parsed": [["Cassou", "Damien", "", "INRIA Bordeaux - Sud-Ouest, LaBRI"], ["Balland", "Emilie", "", "INRIA Bordeaux - Sud-Ouest"], ["Consel", "Charles", "", "INRIA Bordeaux - Sud-Ouest,\n  ENSEIRB"], ["Lawall", "Julia", "", "DIKU, LIP6"]]}, {"id": "1109.3256", "submitter": "Dean Voets", "authors": "Dean Voets, Danny De Schreye", "title": "Non-termination Analysis of Logic Programs with Integer arithmetics", "comments": "15 pages, 2 figures, journal TPLP (special issue on the international\n  conference of logic programming)", "journal-ref": "TPLP, 2011, volume 11, number 4-5, pages 521 --536", "doi": "10.1017/S1471068411000159", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past years, analyzers have been introduced to detect classes of\nnon-terminating queries for definite logic programs. Although these\nnon-termination analyzers have shown to be rather precise, their applicability\non real-life Prolog programs is limited because most Prolog programs use\nnon-logical features. As a first step towards the analysis of Prolog programs,\nthis paper presents a non-termination condition for Logic Programs containing\ninteger arithmetics. The analyzer is based on our non-termination analyzer\npresented at ICLP 2009. The analysis starts from a class of queries and infers\na subclass of non-terminating ones. In a first phase, we ignore the outcome\n(success or failure) of the arithmetic operations, assuming success of all\narithmetic calls. In a second phase, we characterize successful arithmetic\ncalls as a constraint problem, the solution of which determines the\nnon-terminating queries.\n", "versions": [{"version": "v1", "created": "Thu, 15 Sep 2011 03:58:37 GMT"}], "update_date": "2011-09-16", "authors_parsed": [["Voets", "Dean", ""], ["De Schreye", "Danny", ""]]}, {"id": "1109.3989", "submitter": "J\\\"org P\\\"uhrer", "authors": "Johannes Oetsch and J\\\"org P\\\"uhrer and Hans Tompits", "title": "The SeaLion has Landed: An IDE for Answer-Set Programming---Preliminary\n  Report", "comments": "Proceedings of the 19th International Conference on Applications of\n  Declarative Programming and Knowledge Management (INAP 2011) and 25th\n  Workshop on Logic Programming (WLP 2011)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report about the current state and designated features of the tool\nSeaLion, aimed to serve as an integrated development environment (IDE) for\nanswer-set programming (ASP). A main goal of SeaLion is to provide a\nuser-friendly environment for supporting a developer to write, evaluate, debug,\nand test answer-set programs. To this end, new support techniques have to be\ndeveloped that suit the requirements of the answer-set semantics and meet the\nconstraints of practical applicability. In this respect, SeaLion benefits from\nthe research results of a project on methods and methodologies for answer-set\nprogram development in whose context SeaLion is realised. Currently, the tool\nprovides source-code editors for the languages of Gringo and DLV that offer\nsyntax highlighting, syntax checking, and a visual program outline. Further\nimplemented features are support for external solvers and visualisation as well\nas visual editing of answer sets. SeaLion comes as a plugin of the popular\nEclipse platform and provides itself interfaces for future extensions of the\nIDE.\n", "versions": [{"version": "v1", "created": "Mon, 19 Sep 2011 10:24:28 GMT"}, {"version": "v2", "created": "Tue, 11 Oct 2011 10:03:44 GMT"}], "update_date": "2011-10-12", "authors_parsed": [["Oetsch", "Johannes", ""], ["P\u00fchrer", "J\u00f6rg", ""], ["Tompits", "Hans", ""]]}, {"id": "1109.4048", "submitter": "Shinji Kono Dr.", "authors": "Shinji Kono and Kento Yogi", "title": "Implementing Continuation based language in GCC", "comments": "Continuation Festa 2008 Tokyo", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  We have implemented C like Continuation based programming language.\nContinuation based C, CbC was implemented using micro-C on various\narchitecture, and we have tried several CbC programming experiments. Here we\nreport new implementation of CbC compiler based on GCC 4.2.3. Since it contains\nfull C capability, we can use CbC and C in a mixture.\n", "versions": [{"version": "v1", "created": "Mon, 19 Sep 2011 14:51:27 GMT"}], "update_date": "2011-09-20", "authors_parsed": [["Kono", "Shinji", ""], ["Yogi", "Kento", ""]]}, {"id": "1109.4095", "submitter": "J\\\"org P\\\"uhrer", "authors": "Christian Kloim\\\"ullner, Johannes Oetsch, J\\\"org P\\\"uhrer, and Hans\n  Tompits", "title": "Kara: A System for Visualising and Visual Editing of Interpretations for\n  Answer-Set Programs", "comments": "Proceedings of the 19th International Conference on Applications of\n  Declarative Programming and Knowledge Management (INAP 2011) and 25th\n  Workshop on Logic Programming (WLP 2011)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.GR cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In answer-set programming (ASP), the solutions of a problem are encoded in\ndedicated models, called answer sets, of a logical theory. These answer sets\nare computed from the program that represents the theory by means of an ASP\nsolver and returned to the user as sets of ground first-order literals. As this\ntype of representation is often cumbersome for the user to interpret, tools\nlike ASPVIZ and IDPDraw were developed that allow for visualising answer sets.\nThe tool Kara, introduced in this paper, follows these approaches, using ASP\nitself as a language for defining visualisations of interpretations. Unlike\nexisting tools that position graphic primitives according to static coordinates\nonly, Kara allows for more high-level specifications, supporting graph\nstructures, grids, and relative positioning of graphical elements. Moreover,\ngeneralising the functionality of previous tools, Kara provides modifiable\nvisualisations such that interpretations can be manipulated by graphically\nediting their visualisations. This is realised by resorting to abductive\nreasoning techniques. Kara is part of SeaLion, a forthcoming integrated\ndevelopment environment (IDE) for ASP.\n", "versions": [{"version": "v1", "created": "Mon, 19 Sep 2011 17:09:21 GMT"}, {"version": "v2", "created": "Tue, 11 Oct 2011 10:03:57 GMT"}], "update_date": "2011-10-12", "authors_parsed": [["Kloim\u00fcllner", "Christian", ""], ["Oetsch", "Johannes", ""], ["P\u00fchrer", "J\u00f6rg", ""], ["Tompits", "Hans", ""]]}, {"id": "1109.4240", "submitter": "Stefan Plantikow", "authors": "Stefan Plantikow", "title": "Actor Continuation Passing: Efficient and Extensible Request Routing for\n  Event-Driven Architectures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.DC cs.SE", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  The logic for handling of application requests to a staged, event-driven\narchitecture is often distributed over different portions of the source code.\nThis complicates changing and understanding the flow of events in the system.\nThe article presents an approach that extracts request handling logic from\nregular stage functionality into a set of request scripts. These scripts are\nexecuted step-wise by sending continuations that encapsulate their request's\ncurrent execution state to stages for local processing and optional forwarding\nof follow-up continuations. A new internal domain specific language (DSL) that\naims to simplify writing of request scripts is described along with its\nimplementation for the scala actors library. Evaluation results indicate that\nrequest handling with actor continuations performs about equally or better\ncompared to using separate stages for request handling logic for scripts of at\nleast 3 sequential steps.\n", "versions": [{"version": "v1", "created": "Tue, 20 Sep 2011 08:55:10 GMT"}], "update_date": "2011-09-21", "authors_parsed": [["Plantikow", "Stefan", ""]]}, {"id": "1109.4467", "submitter": "David Van Horn", "authors": "David Van Horn and Matthew Might", "title": "Pushdown Abstractions of JavaScript", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We design a family of program analyses for JavaScript that make no\napproximation in matching calls with returns, exceptions with handlers, and\nbreaks with labels. We do so by starting from an established reduction\nsemantics for JavaScript and systematically deriving its intensional abstract\ninterpretation. Our first step is to transform the semantics into an equivalent\nlow-level abstract machine: the JavaScript Abstract Machine (JAM). We then give\nan infinite-state yet decidable pushdown machine whose stack precisely models\nthe structure of the concrete program stack. The precise model of stack\nstructure in turn confers precise control-flow analysis even in the presence of\ncontrol effects, such as exceptions and finally blocks. We give pushdown\ngeneralizations of traditional forms of analysis such as k-CFA, and prove the\npushdown framework for abstract interpretation is sound and computable.\n", "versions": [{"version": "v1", "created": "Wed, 21 Sep 2011 03:26:53 GMT"}, {"version": "v2", "created": "Tue, 20 Dec 2011 10:30:48 GMT"}], "update_date": "2011-12-21", "authors_parsed": [["Van Horn", "David", ""], ["Might", "Matthew", ""]]}, {"id": "1109.5267", "submitter": "Naoki Kobayashi", "authors": "Naoki Kobayashi (Graduate School of Information Sciences, Tohoku\n  University), C.-H. Luke Ong (Oxford University Computing Laboratory)", "title": "Complexity of Model Checking Recursion Schemes for Fragments of the\n  Modal Mu-Calculus", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 7, Issue 4 (January\n  18, 2012) lmcs:1211", "doi": "10.2168/LMCS-7(4:9)2011", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ong has shown that the modal mu-calculus model checking problem\n(equivalently, the alternating parity tree automaton (APT) acceptance problem)\nof possibly-infinite ranked trees generated by order-n recursion schemes is\nn-EXPTIME complete. We consider two subclasses of APT and investigate the\ncomplexity of the respective acceptance problems. The main results are that,\nfor APT with a single priority, the problem is still n-EXPTIME complete;\nwhereas, for APT with a disjunctive transition function, the problem is\n(n-1)-EXPTIME complete. This study was motivated by Kobayashi's recent work\nshowing that the resource usage verification of functional programs can be\nreduced to the model checking of recursion schemes. As an application, we show\nthat the resource usage verification problem is (n-1)-EXPTIME complete.\n", "versions": [{"version": "v1", "created": "Sat, 24 Sep 2011 14:05:50 GMT"}, {"version": "v2", "created": "Tue, 20 Dec 2011 18:20:48 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Kobayashi", "Naoki", "", "Graduate School of Information Sciences, Tohoku\n  University"], ["Ong", "C. -H. Luke", "", "Oxford University Computing Laboratory"]]}, {"id": "1109.5416", "submitter": "M. H. van Emden", "authors": "M. H. van Emden", "title": "Matrix Code", "comments": "39 pages, 19 figures; extensions and minor corrections", "journal-ref": null, "doi": null, "report-no": "DCS-341-IR", "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix Code gives imperative programming a mathematical semantics and\nheuristic power comparable in quality to functional and logic programming. A\nprogram in Matrix Code is developed incrementally from a specification in\npre/post-condition form. The computations of a code matrix are characterized by\npowers of the matrix when it is interpreted as a transformation in a space of\nvectors of logical conditions. Correctness of a code matrix is expressed in\nterms of a fixpoint of the transformation. The abstract machine for Matrix Code\nis the dual-state machine, which we present as a variant of the classical\nfinite-state machine.\n", "versions": [{"version": "v1", "created": "Sun, 25 Sep 2011 23:31:15 GMT"}, {"version": "v2", "created": "Wed, 12 Oct 2011 00:21:50 GMT"}, {"version": "v3", "created": "Thu, 17 Nov 2011 19:49:50 GMT"}, {"version": "v4", "created": "Mon, 11 Jun 2012 01:42:49 GMT"}, {"version": "v5", "created": "Tue, 17 Jul 2012 00:09:57 GMT"}, {"version": "v6", "created": "Mon, 25 Feb 2013 05:37:09 GMT"}], "update_date": "2013-02-26", "authors_parsed": [["van Emden", "M. H.", ""]]}, {"id": "1109.6112", "submitter": "Carmen Gervet", "authors": "Islam Abdelraouf, Slim Abdennadher, Carmen Gervet", "title": "A Visual Entity-Relationship Model for Constraint-Based University\n  Timetabling", "comments": "12 pages, 7 figures, INAP 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  University timetabling (UTT) is a complex problem due to its combinatorial\nnature but also the type of constraints involved. The holy grail of\n(constraint) programming: \"the user states the problem the program solves it\"\nremains a challenge since solution quality is tightly coupled with deriving\n\"effective models\", best handled by technology experts. In this paper, focusing\non the field of university timetabling, we introduce a visual graphic\ncommunication tool that lets the user specify her problem in an abstract\nmanner, using a visual entity-relationship model. The entities are nodes of\nmainly two types: resource nodes (lecturers, assistants, student groups) and\nevents nodes (lectures, lab sessions, tutorials). The links between the nodes\nsignify a desired relationship between them. The visual modeling abstraction\nfocuses on the nature of the entities and their relationships and abstracts\nfrom an actual constraint model.\n", "versions": [{"version": "v1", "created": "Wed, 28 Sep 2011 06:52:22 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Abdelraouf", "Islam", ""], ["Abdennadher", "Slim", ""], ["Gervet", "Carmen", ""]]}, {"id": "1109.6926", "submitter": "Dirk Beyer", "authors": "Dirk Beyer and Thomas A. Henzinger and M. Erkan Keremoglu and Philipp\n  Wendler", "title": "Conditional Model Checking", "comments": "14 pages, 8 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": "Technical Report, Number MIP-1107, University of Passau, Germany", "categories": "cs.SE cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software model checking, as an undecidable problem, has three possible\noutcomes: (1) the program satisfies the specification, (2) the program does not\nsatisfy the specification, and (3) the model checker fails. The third outcome\nusually manifests itself in a space-out, time-out, or one component of the\nverification tool giving up; in all of these failing cases, significant\ncomputation is performed by the verification tool before the failure, but no\nresult is reported. We propose to reformulate the model-checking problem as\nfollows, in order to have the verification tool report a summary of the\nperformed work even in case of failure: given a program and a specification,\nthe model checker returns a condition P ---usually a state predicate--- such\nthat the program satisfies the specification under the condition P ---that is,\nas long as the program does not leave states in which P is satisfied. We are of\ncourse interested in model checkers that return conditions P that are as weak\nas possible. Instead of outcome (1), the model checker will return P = true;\ninstead of (2), the condition P will return the part of the state space that\nsatisfies the specification; and in case (3), the condition P can summarize the\nwork that has been performed by the model checker before space-out, time-out,\nor giving up. If complete verification is necessary, then a different\nverification method or tool may be used to focus on the states that violate the\ncondition. We give such conditions as input to a conditional model checker,\nsuch that the verification problem is restricted to the part of the state space\nthat satisfies the condition. Our experiments show that repeated application of\nconditional model checkers, using different conditions, can significantly\nimprove the verification results, state-space coverage, and performance.\n", "versions": [{"version": "v1", "created": "Fri, 30 Sep 2011 18:55:34 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Beyer", "Dirk", ""], ["Henzinger", "Thomas A.", ""], ["Keremoglu", "M. Erkan", ""], ["Wendler", "Philipp", ""]]}]