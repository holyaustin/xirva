[{"id": "1808.00064", "submitter": "Shoaib Akram", "authors": "Shoaib Akram, Jennifer B. Sartor, Kathryn S. McKinley, Lieven Eeckhout", "title": "Emulating Hybrid Memory on NUMA Hardware", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-volatile memory (NVM) has the potential to disrupt the boundary between\nmemory and storage, including the abstractions that manage this boundary.\nResearchers comparing the speed, durability, and abstractions of hybrid systems\nwith DRAM, NVM, and disk to traditional systems typically use simulation, which\nmakes it easy to evaluate different hardware technologies and parameters.\nUnfortunately, simulation is extremely slow, limiting the number of\napplications and dataset sizes in the evaluation. Simulation typically\nprecludes realistic multiprogram workloads and considering runtime and\noperating system design alternatives. Good methodology embraces a variety of\ntechniques for validation, expanding the experimental scope, and uncovering new\ninsights. This paper introduces an emulation platform for hybrid memory that\nuses commodity NUMA servers. Emulation complements simulation well, offering\nspeed and accuracy for realistic workloads, and richer software\nexperimentation. We use a thread-local socket to emulate DRAM and the remote\nsocket to emulate NVM. We use standard C library routines to allocate heap\nmemory in the DRAM or NVM socket for use with explicit memory management or\ngarbage collection. We evaluate the emulator using various configurations of\nwrite-rationing garbage collectors that improve NVM lifetimes by limiting\nwrites to NVM, and use 15 applications from three benchmark suites with various\ndatasets and workload configurations. We show emulation enhances simulation\nresults. The two systems confirm most trends, such as NVM write and read rates\nof different software configurations, increasing our confidence for predicting\nfuture system effects. Emulation adds novel insights, such as the non-linear\neffects of multi-program workloads on write rates.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jul 2018 20:35:01 GMT"}], "update_date": "2018-08-02", "authors_parsed": [["Akram", "Shoaib", ""], ["Sartor", "Jennifer B.", ""], ["McKinley", "Kathryn S.", ""], ["Eeckhout", "Lieven", ""]]}, {"id": "1808.00077", "submitter": "Hanwen Wu", "authors": "Hanwen Wu, Hongwei Xi", "title": "Multiparty Dependent Session Types (Extended Abstract)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Programs are more distributed and concurrent today than ever before, and\nstructural communications are at the core. Constructing and debugging such\nprograms are hard due to the lack of formal specification/verification of\nconcurrency. This work formalizes the first multiparty dependent session types\nas an expressive and practical type discipline for enforcing communication\nprotocols. The type system is formulated in the setting of multi-threaded\n$\\lambda$-calculus with inspirations from multirole logic, a generalization of\nclassical logic we discovered earlier. We prove its soundness by a novel\ntechnique called deadlock-freeness reducibility. The soundness of the type\nsystem implies communication fidelity and absence of deadlock.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jul 2018 21:19:50 GMT"}], "update_date": "2018-08-02", "authors_parsed": [["Wu", "Hanwen", ""], ["Xi", "Hongwei", ""]]}, {"id": "1808.00185", "submitter": "Umang Mathur", "authors": "Umang Mathur, Dileep Kini, Mahesh Viswanathan", "title": "What Happens - After the First Race? Enhancing the Predictive Power of\n  Happens - Before Based Dynamic Race Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic race detection is the problem of determining if an observed program\nexecution reveals the presence of a data race in a program. The classical\napproach to solving this problem is to detect if there is a pair of conflicting\nmemory accesses that are unordered by Lamport's happens-before (HB) relation.\nHB based race detection is known to not report false positives, i.e., it is\nsound. However, the soundness guarantee of HB only promises that the first pair\nof unordered, conflicting events is a schedulable data race. That is, there can\nbe pairs of HB-unordered conflicting data accesses that are not schedulable\nraces because there is no reordering of the events of the execution, where the\nevents in race can be executed immediately after each other. We introduce a new\npartial order, called schedulable happens-before (SHB) that exactly\ncharacterizes the pairs of schedulable data races --- every pair of conflicting\ndata accesses that are identified by SHB can be scheduled, and every HB-race\nthat can be scheduled is identified by SHB. Thus, the SHB partial order is\ntruly sound. We present a linear time, vector clock algorithm to detect\nschedulable races using SHB. Our experiments demonstrate the value of our\nalgorithm for dynamic race detection --- SHB incurs only little performance\noverhead and can scale to executions from real-world software applications\nwithout compromising soundness.\n", "versions": [{"version": "v1", "created": "Wed, 1 Aug 2018 06:29:17 GMT"}], "update_date": "2018-08-02", "authors_parsed": [["Mathur", "Umang", ""], ["Kini", "Dileep", ""], ["Viswanathan", "Mahesh", ""]]}, {"id": "1808.00225", "submitter": "Matteo Busi", "authors": "Matteo Busi and Pierpaolo Degano and Letterio Galletta", "title": "Using Standard Typing Algorithms Incrementally", "comments": "corrected and updated; experimental results added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern languages are equipped with static type checking/inference that helps\nprogrammers to keep a clean programming style and to reduce errors. However,\nthe ever-growing size of programs and their continuous evolution require\nbuilding fast and efficient analysers. A promising solution is incrementality,\nso one only re-types those parts of the program that are new, rather than the\nentire codebase. We propose an algorithmic schema driving the definition of an\nincremental typing algorithm that exploits the existing, standard ones with no\nchanges. Ours is a grey-box approach, meaning that just the shape of the input,\nthat of the results and some domain-specific knowledge are needed to\ninstantiate our schema. Here, we present the foundations of our approach and we\nshow it at work to derive three different incremental typing algorithms. The\nfirst two implement type checking and inference for a functional language. The\nlast one type-checks an imperative language to detect information flow and\nnon-interference. We assessed our proposal on a prototypical implementation of\nan incremental type checker. Our experiments show that using the type checker\nincrementally is (almost) always rewarding.\n", "versions": [{"version": "v1", "created": "Wed, 1 Aug 2018 08:44:00 GMT"}, {"version": "v2", "created": "Tue, 27 Nov 2018 14:57:49 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Busi", "Matteo", ""], ["Degano", "Pierpaolo", ""], ["Galletta", "Letterio", ""]]}, {"id": "1808.00486", "submitter": "Wilmer Ricciotti", "authors": "Wilmer Ricciotti and James Cheney", "title": "Explicit Auditing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Calculus of Audited Units (CAU) is a typed lambda calculus resulting from\na computational interpretation of Artemov's Justification Logic under the\nCurry-Howard isomorphism; it extends the simply typed lambda calculus by\nproviding audited types, inhabited by expressions carrying a trail of their\npast computation history. Unlike most other auditing techniques, CAU allows the\ninspection of trails at runtime as a first-class operation, with applications\nin security, debugging, and transparency of scientific computation.\n  An efficient implementation of CAU is challenging: not only do the sizes of\ntrails grow rapidly, but they also need to be normalized after every beta\nreduction. In this paper, we study how to reduce terms more efficiently in an\nuntyped variant of CAU by means of explicit substitutions and explicit auditing\noperations, finally deriving a call-by-value abstract machine.\n", "versions": [{"version": "v1", "created": "Wed, 1 Aug 2018 18:03:02 GMT"}], "update_date": "2018-08-03", "authors_parsed": [["Ricciotti", "Wilmer", ""], ["Cheney", "James", ""]]}, {"id": "1808.00843", "submitter": "Tuan Phong Ngo", "authors": "Parosh Aziz Abdulla and Mohamed Faouzi Atig and Bengt Jonsson and Tuan\n  Phong Ngo", "title": "Optimal Stateless Model Checking under the Release-Acquire Semantics", "comments": "Accepted paper in OOPSLA'18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a framework for the efficient application of stateless model\nchecking (SMC) to concurrent programs running under the Release-Acquire (RA)\nfragment of the C/C++11 memory model. Our approach is based on exploring the\npossible program orders, which define the order in which instructions of a\nthread are executed, and read-from relations, which specify how reads obtain\ntheir values from writes. This is in contrast to previous approaches, which\nalso explore the possible coherence orders, i.e., orderings between conflicting\nwrites. Since unexpected test results such as program crashes or assertion\nviolations depend only on the read-from relation, we avoid a potentially\nsignificant source of redundancy. Our framework is based on a novel technique\nfor determining whether a particular read-from relation is feasible under the\nRA semantics. We define an SMC algorithm which is provably optimal in the sense\nthat it explores each program order and read-from relation exactly once. This\noptimality result is strictly stronger than previous analogous optimality\nresults, which also take coherence order into account. We have implemented our\nframework in the tool Tracer. Experiments show that Tracer can be significantly\nfaster than state-of-the-art tools that can handle the RA semantics.\n", "versions": [{"version": "v1", "created": "Thu, 2 Aug 2018 14:55:27 GMT"}, {"version": "v2", "created": "Mon, 10 Sep 2018 21:26:47 GMT"}], "update_date": "2018-09-12", "authors_parsed": [["Abdulla", "Parosh Aziz", ""], ["Atig", "Mohamed Faouzi", ""], ["Jonsson", "Bengt", ""], ["Ngo", "Tuan Phong", ""]]}, {"id": "1808.01232", "submitter": "Nassim Seghir", "authors": "Mohamed Nassim Seghir", "title": "Data-Flow Guided Slicing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a flow-insensitive analysis that prunes out portions of code which\nare irrelevant to a specified set of data-flow paths. Our approach is fast and\nscalable, in addition to being able to generate a certificate as an audit for\nthe computed result. We have implemented our technique in a tool called DSlicer\nand applied it to a set of 10600 real-world Android applications. Results are\nconclusive, we found out that the program code can be significantly reduced by\n36% on average with respect to a specified set of data leak paths.\n", "versions": [{"version": "v1", "created": "Fri, 3 Aug 2018 15:43:08 GMT"}], "update_date": "2018-08-06", "authors_parsed": [["Seghir", "Mohamed Nassim", ""]]}, {"id": "1808.01246", "submitter": "Nassim Seghir", "authors": "Mohamed Nassim Seghir", "title": "Certificate Enhanced Data-Flow Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Proof-carrying-code was proposed as a solution to ensure a trust relationship\nbetween two parties: a (heavyweight) analyzer and a (lightweight) checker. The\nanalyzer verifies the conformance of a given application to a specified\nproperty and generates a certificate attesting the validity of the analysis\nresult. It suffices then for the checker just to test the consistency of the\nproof instead of constructing it. We set out to study the applicability of this\ntechnique in the context of data- flow analysis. In particular, we want to know\nif there is a significant performance difference between the analyzer and the\nchecker. Therefore, we developed a tool, called DCert, implementing an\ninter-procedural context and flow-sensitive data-flow analyzer and checker for\nAndroid. Applying our tool to real-world large applications, we found out that\nchecking can be up to 8 times faster than verification. This important gain in\ntime suggests a potential for equipping applications on app stores with\ncertificates that can be checked on mobile devices which are limited in\ncomputation and storage resources. We describe our implementation and report on\nexperimental results.\n", "versions": [{"version": "v1", "created": "Fri, 3 Aug 2018 16:09:04 GMT"}], "update_date": "2018-08-06", "authors_parsed": [["Seghir", "Mohamed Nassim", ""]]}, {"id": "1808.01344", "submitter": "Amir Shaikhha", "authors": "Amir Shaikhha, Vojin Jovanovic, Christoph Koch", "title": "A Compiler-Compiler for DSL Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a framework to generate compilers for embedded\ndomain-specific languages (EDSLs). This framework provides facilities to\nautomatically generate the boilerplate code required for building DSL compilers\non top of extensible optimizing compilers. We evaluate the practicality of our\nframework by demonstrating several use-cases successfully built with it.\n", "versions": [{"version": "v1", "created": "Fri, 3 Aug 2018 20:22:53 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Shaikhha", "Amir", ""], ["Jovanovic", "Vojin", ""], ["Koch", "Christoph", ""]]}, {"id": "1808.01348", "submitter": "Conrad Watt", "authors": "Conrad Watt, John Renner, Natalie Popescu, Sunjay Cauligi, Deian\n  Stefan", "title": "CT-Wasm: Type-Driven Secure Cryptography for the Web Ecosystem", "comments": "29 pages, 9 figures", "journal-ref": null, "doi": "10.1145/3290390", "report-no": null, "categories": "cs.CR cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A significant amount of both client and server-side cryptography is\nimplemented in JavaScript. Despite widespread concerns about its security, no\nother language has been able to match the convenience that comes from its\nubiquitous support on the \"web ecosystem\" - the wide variety of technologies\nthat collectively underpins the modern World Wide Web. With the new\nintroduction of the WebAssembly bytecode language (Wasm) into the web\necosystem, we have a unique opportunity to advance a principled alternative to\nexisting JavaScript cryptography use cases which does not compromise this\nconvenience.\n  We present Constant-Time WebAssembly (CT-Wasm), a type-driven strict\nextension to WebAssembly which facilitates the verifiably secure implementation\nof cryptographic algorithms. CT-Wasm's type system ensures that code written in\nCT-Wasm is both information flow secure and resistant to timing side channel\nattacks; like base Wasm, these guarantees are verifiable in linear time.\nBuilding on an existing Wasm mechanization, we mechanize the full CT-Wasm\nspecification, prove soundness of the extended type system, implement a\nverified type checker, and give several proofs of the language's security\nproperties.\n  We provide two implementations of CT-Wasm: an OCaml reference interpreter and\na native implementation for Node.js and Chromium that extends Google's V8\nengine. We also implement a CT-Wasm to Wasm rewrite tool that allows developers\nto reap the benefits of CT-Wasm's type system today, while developing\ncryptographic algorithms for base Wasm environments. We evaluate the language,\nour implementations, and supporting tools by porting several cryptographic\nprimitives - Salsa20, SHA-256, and TEA - and the full TweetNaCl library. We\nfind that CT-Wasm is fast, expressive, and generates code that we\nexperimentally measure to be constant-time.\n", "versions": [{"version": "v1", "created": "Fri, 3 Aug 2018 20:39:10 GMT"}, {"version": "v2", "created": "Tue, 6 Nov 2018 02:16:50 GMT"}, {"version": "v3", "created": "Thu, 8 Nov 2018 10:39:39 GMT"}, {"version": "v4", "created": "Sun, 18 Nov 2018 16:44:34 GMT"}, {"version": "v5", "created": "Mon, 17 Dec 2018 17:44:10 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Watt", "Conrad", ""], ["Renner", "John", ""], ["Popescu", "Natalie", ""], ["Cauligi", "Sunjay", ""], ["Stefan", "Deian", ""]]}, {"id": "1808.01400", "submitter": "Uri Alon", "authors": "Uri Alon, Shaked Brody, Omer Levy, Eran Yahav", "title": "code2seq: Generating Sequences from Structured Representations of Code", "comments": "Accepted to ICLR'2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to generate natural language sequences from source code snippets\nhas a variety of applications such as code summarization, documentation, and\nretrieval. Sequence-to-sequence (seq2seq) models, adopted from neural machine\ntranslation (NMT), have achieved state-of-the-art performance on these tasks by\ntreating source code as a sequence of tokens. We present ${\\rm {\\scriptsize\nCODE2SEQ}}$: an alternative approach that leverages the syntactic structure of\nprogramming languages to better encode source code. Our model represents a code\nsnippet as the set of compositional paths in its abstract syntax tree (AST) and\nuses attention to select the relevant paths while decoding. We demonstrate the\neffectiveness of our approach for two tasks, two programming languages, and\nfour datasets of up to $16$M examples. Our model significantly outperforms\nprevious models that were specifically designed for programming languages, as\nwell as state-of-the-art NMT models. An interactive online demo of our model is\navailable at http://code2seq.org. Our code, data and trained models are\navailable at http://github.com/tech-srl/code2seq.\n", "versions": [{"version": "v1", "created": "Sat, 4 Aug 2018 01:26:07 GMT"}, {"version": "v2", "created": "Wed, 10 Oct 2018 19:15:15 GMT"}, {"version": "v3", "created": "Fri, 4 Jan 2019 22:20:49 GMT"}, {"version": "v4", "created": "Fri, 25 Jan 2019 21:54:12 GMT"}, {"version": "v5", "created": "Wed, 6 Feb 2019 08:27:31 GMT"}, {"version": "v6", "created": "Thu, 21 Feb 2019 14:12:56 GMT"}], "update_date": "2019-02-22", "authors_parsed": [["Alon", "Uri", ""], ["Brody", "Shaked", ""], ["Levy", "Omer", ""], ["Yahav", "Eran", ""]]}, {"id": "1808.02010", "submitter": "Colin Gordon", "authors": "Colin S. Gordon", "title": "Polymorphic Iterable Sequential Effect Systems", "comments": "Extended journal version of ECOOP 2017 paper (preprint at\n  arXiv:1705.02264) generalizing the iteration operator for behavioral effect\n  systems, strengthening existence results, strengthening proof, and adding to\n  examples and comparison to related work (more details in paper). Final author\n  version", "journal-ref": "ACM Transactions on Programming Languages and Systems (TOPLAS),\n  2021", "doi": "10.1145/3450272", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effect systems are lightweight extensions to type systems that can verify a\nwide range of important properties with modest developer burden. But our\ngeneral understanding of effect systems is limited primarily to systems where\nthe order of effects is irrelevant. Understanding such systems in terms of a\nsemilattice of effects grounds understanding of the essential issues, and\nprovides guidance when designing new effect systems. By contrast, sequential\neffect systems -- where the order of effects is important -- lack an\nestablished algebraic structure on effects.\n  We present an abstract polymorphic effect system parameterized by an effect\nquantale -- an algebraic structure with well-defined properties that can model\nthe effects of a range of existing sequential effect systems. We define effect\nquantales, derive useful properties, and show how they cleanly model a variety\nof known sequential effect systems.\n  We show that for most effect quantales, there is an induced notion of\niterating a sequential effect; that for systems we consider the derived\niteration agrees with the manually designed iteration operators in prior work;\nand that this induced notion of iteration is as precise as possible when\ndefined. We also position effect quantales with respect to work on categorical\nsemantics for sequential effect systems, clarifying the distinctions between\nthese systems and our own in the course of giving a thorough survey of these\nframeworks. Our derived iteration construct should generalize to these semantic\nstructures, addressing limitations of that work. Finally, we consider the\nrelationship between sequential effects and Kleene Algebras, where the latter\nmay be used as instances of the former.\n", "versions": [{"version": "v1", "created": "Mon, 6 Aug 2018 17:57:13 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 16:37:43 GMT"}, {"version": "v3", "created": "Wed, 28 Aug 2019 16:53:54 GMT"}, {"version": "v4", "created": "Wed, 29 Apr 2020 19:13:56 GMT"}, {"version": "v5", "created": "Fri, 2 Oct 2020 18:04:40 GMT"}, {"version": "v6", "created": "Thu, 15 Jul 2021 15:26:55 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Gordon", "Colin S.", ""]]}, {"id": "1808.02101", "submitter": "David Van Horn", "authors": "Phuc C. Nguyen, Thomas Gilray, Sam Tobin-Hochstadt, David Van Horn", "title": "Size-Change Termination as a Contract", "comments": null, "journal-ref": "Proceedings of the 40th ACM SIGPLAN Conference on Programming\n  Language Design and Implementation (PLDI '19), June 22-26, 2019, Phoenix, AZ,\n  USA", "doi": "10.1145/3314221.3314643", "report-no": null, "categories": "cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Termination is an important but undecidable program property, which has led\nto a large body of work on static methods for conservatively predicting or\nenforcing termination. One such method is the size-change termination approach\nof Lee, Jones, and Ben-Amram, which operates in two phases: (1) abstract\nprograms into \"size-change graphs,\" and (2) check these graphs for the\nsize-change property: the existence of paths that lead to infinite decreasing\nsequences.\n  We transpose these two phases with an operational semantics that accounts for\nthe run-time enforcement of the size-change property, postponing (or entirely\navoiding) program abstraction. This choice has two key consequences: (1)\nsize-change termination can be checked at run-time and (2) termination can be\nrephrased as a safety property analyzed using existing methods for systematic\nabstraction.\n  We formulate run-time size-change checks as contracts in the style of Findler\nand Felleisen. The result compliments existing contracts that enforce partial\ncorrectness specifications to obtain contracts for total correctness. Our\napproach combines the robustness of the size-change principle for termination\nwith the precise information available at run-time. It has tunable overhead and\ncan check for nontermination without the conservativeness necessary in static\nchecking. To obtain a sound and computable termination analysis, we apply\nexisting abstract interpretation techniques directly to the operational\nsemantics, avoiding the need for custom abstractions for termination. The\nresulting analyzer is competitive with with existing, purpose-built analyzers.\n", "versions": [{"version": "v1", "created": "Mon, 6 Aug 2018 20:41:56 GMT"}, {"version": "v2", "created": "Thu, 25 Apr 2019 20:41:32 GMT"}], "update_date": "2019-04-29", "authors_parsed": [["Nguyen", "Phuc C.", ""], ["Gilray", "Thomas", ""], ["Tobin-Hochstadt", "Sam", ""], ["Van Horn", "David", ""]]}, {"id": "1808.02103", "submitter": "Nassim Seghir", "authors": "Mohamed Nassim Seghir", "title": "DCert: Find the Leak in Your Pocket", "comments": "arXiv admin note: substantial text overlap with arXiv:1808.01246", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CR cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Static data-flow analysis has proven its effectiveness in assessing security\nof applications. One major challenge it faces is scalability to large software.\nThis issue is even exacerbated when additional limitations on computing and\nstorage resources are imposed, as is the case for mobile devices. In such cases\nthe analysis is performed on a conventional computer. This poses two problems.\nFirst, a man-in-the-middle attack can tamper with an analyzed application. So\nonce on the mobile device, what guarantees that the actual version is not\ncorrupt. Second, the analysis itself might be broken leading to an erroneous\nresult. As a solution, we present DCert a tool for checking and certifying\ndata-flow properties that consists of two components: a (heavy- weight)\nanalyzer and a (lightweight) checker. The analyzer is deployed on a\nconventional computer. It verifies the conformance of a given application to a\nspecified policy and generates a certificate attesting the validity of the\nanalysis result. It suffices then for the checker, on a mobile device, to\nperform a linear pass in the application size to validate or refute the\ncertificate as well as the policy. This allows us to separate the verification\nand the checking process while ensuring a trust relationship between them via\nthe certificate. We describe DCert and report on experimental results obtained\nfor real-world applications.\n", "versions": [{"version": "v1", "created": "Fri, 3 Aug 2018 16:59:04 GMT"}], "update_date": "2018-08-08", "authors_parsed": [["Seghir", "Mohamed Nassim", ""]]}, {"id": "1808.02943", "submitter": "Thorsten Wissmann", "authors": "Francesco Dagnino", "title": "Coaxioms: flexible coinductive definitions by inference systems", "comments": "This is a corrected version of the paper (arXiv:1808.02943v4)\n  published originally on 12 March 2019", "journal-ref": "Logical Methods in Computer Science, Volume 15, Issue 1 (February\n  20, 2020) lmcs:5277", "doi": "10.23638/LMCS-15(1:26)2019", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce a generalized notion of inference system to support more\nflexible interpretations of recursive definitions. Besides axioms and inference\nrules with the usual meaning, we allow also coaxioms, which are, intuitively,\naxioms which can only be applied \"at infinite depth\" in a proof tree. Coaxioms\nallow us to interpret recursive definitions as fixed points which are not\nnecessarily the least, nor the greatest one, whose existence is guaranteed by a\nsmooth extension of classical results. This notion nicely subsumes standard\ninference systems and their inductive and coinductive interpretation, thus\nallowing formal reasoning in cases where the inductive and coinductive\ninterpretation do not provide the intended meaning, but are rather mixed\ntogether.\n", "versions": [{"version": "v1", "created": "Wed, 8 Aug 2018 21:15:11 GMT"}, {"version": "v2", "created": "Wed, 28 Nov 2018 16:08:42 GMT"}, {"version": "v3", "created": "Wed, 30 Jan 2019 14:16:17 GMT"}, {"version": "v4", "created": "Mon, 11 Mar 2019 17:36:37 GMT"}, {"version": "v5", "created": "Wed, 19 Feb 2020 13:36:53 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Dagnino", "Francesco", ""]]}, {"id": "1808.02998", "submitter": "Benno Stein", "authors": "Benno Stein, Lazaro Clapp, Manu Sridharan, Bor-Yuh Evan Chang", "title": "Safe Stream-Based Programming with Refinement Types", "comments": null, "journal-ref": "Proceedings of the 2018 33rd ACM/IEEE International Conference on\n  Automated Software Engineering", "doi": "10.1145/3238147.3238174", "report-no": null, "categories": "cs.SE cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In stream-based programming, data sources are abstracted as a stream of\nvalues that can be manipulated via callback functions. Stream-based programming\nis exploding in popularity, as it provides a powerful and expressive paradigm\nfor handling asynchronous data sources in interactive software. However,\nhigh-level stream abstractions can also make it difficult for developers to\nreason about control- and data-flow relationships in their programs. This is\nparticularly impactful when asynchronous stream-based code interacts with\nthread-limited features such as UI frameworks that restrict UI access to a\nsingle thread, since the threading behavior of streaming constructs is often\nnon-intuitive and insufficiently documented.\n  In this paper, we present a type-based approach that can statically prove the\nthread-safety of UI accesses in stream-based software. Our key insight is that\nthe fluent APIs of stream-processing frameworks enable the tracking of threads\nvia type-refinement, making it possible to reason automatically about what\nthread a piece of code runs on -- a difficult problem in general.\n  We implement the system as an annotation-based Java typechecker for Android\nprograms built upon the popular ReactiveX framework and evaluate its efficacy\nby annotating and analyzing 8 open-source apps, where we find 33 instances of\nunsafe UI access while incurring an annotation burden of only one annotation\nper 186 source lines of code. We also report on our experience applying the\ntypechecker to two much larger apps from the Uber Technologies Inc. codebase,\nwhere it currently runs on every code change and blocks changes that introduce\npotential threading bugs.\n", "versions": [{"version": "v1", "created": "Thu, 9 Aug 2018 02:19:16 GMT"}], "update_date": "2018-08-10", "authors_parsed": [["Stein", "Benno", ""], ["Clapp", "Lazaro", ""], ["Sridharan", "Manu", ""], ["Chang", "Bor-Yuh Evan", ""]]}, {"id": "1808.03370", "submitter": "Jiahao Chen", "authors": "Jeff Bezanson and Jake Bolewski and Jiahao Chen", "title": "Fast Flexible Function Dispatch in Julia", "comments": "15 pages, repository at https://github.com/jiahao/julia-type-system", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.CL cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Technical computing is a challenging application area for programming\nlanguages to address. This is evinced by the unusually large number of\nspecialized languages in the area (e.g. MATLAB, R), and the complexity of\ncommon software stacks, often involving multiple languages and custom code\ngenerators. We believe this is ultimately due to key characteristics of the\ndomain: highly complex operators, a need for extensive code specialization for\nperformance, and a desire for permissive high-level programming styles allowing\nproductive experimentation. The Julia language attempts to provide a more\neffective structure for this kind of programming by allowing programmers to\nexpress complex polymorphic behaviors using dynamic multiple dispatch over\nparametric types. The forms of extension and reuse permitted by this paradigm\nhave proven valuable for technical computing. We report on how this approach\nhas allowed domain experts to express useful abstractions while simultaneously\nproviding a natural path to better performance for high-level technical code.\n", "versions": [{"version": "v1", "created": "Thu, 9 Aug 2018 23:09:16 GMT"}], "update_date": "2018-08-13", "authors_parsed": [["Bezanson", "Jeff", ""], ["Bolewski", "Jake", ""], ["Chen", "Jiahao", ""]]}, {"id": "1808.03576", "submitter": "Mat\\'u\\v{s} Sul\\'ir", "authors": "Mat\\'u\\v{s} Sul\\'ir, Milan Nos\\'a\\v{l}, Jaroslav Porub\\\"an", "title": "Recording Concerns in Source Code Using Annotations", "comments": null, "journal-ref": "Computer Languages, Systems and Structures (COMLAN), Vol. 46,\n  2016, pp. 44-65, Elsevier", "doi": "10.1016/j.cl.2016.07.003", "report-no": null, "categories": "cs.SE cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A concern can be characterized as a developer's intent behind a piece of\ncode, often not explicitly captured in it. We discuss a technique of recording\nconcerns using source code annotations (concern annotations). Using two studies\nand two controlled experiments, we seek to answer the following 3 research\nquestions: 1) Do programmers' mental models overlap? 2) How do developers use\nshared concern annotations when they are available? 3) Does using annotations\ncreated by others improve program comprehension and maintenance correctness,\ntime and confidence? The first study shows that developers' mental models,\nrecorded using concern annotations, overlap and thus can be shared. The second\nstudy shows that shared concern annotations can be used during program\ncomprehension for the following purposes: hypotheses confirmation, feature\nlocation, obtaining new knowledge, finding relationships and maintenance notes.\nThe first controlled experiment with students showed that the presence of\nannotations significantly reduced program comprehension and maintenance time by\n34%. The second controlled experiment was a differentiated replication of the\nfirst one, focused on industrial developers. It showed a 33% significant\nimprovement in correctness. We conclude that concern annotations are a viable\nway to share developers' thoughts.\n", "versions": [{"version": "v1", "created": "Fri, 10 Aug 2018 15:05:06 GMT"}], "update_date": "2018-08-13", "authors_parsed": [["Sul\u00edr", "Mat\u00fa\u0161", ""], ["Nos\u00e1\u013e", "Milan", ""], ["Porub\u00e4n", "Jaroslav", ""]]}, {"id": "1808.03916", "submitter": "Jiahao Chen", "authors": "Jiahao Chen", "title": "Linguistic Relativity and Programming Languages", "comments": "10 pages, repo at\n  https://github.com/jiahao/statistical-computing-linguistics, Published in\n  Proceedings of the 2016 Joint Statistical Meetings, Chicago, IL, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.MS stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of programming languages can wax and wane across the decades. We\nexamine the split-apply- combine pattern that is common in statistical\ncomputing, and consider how its invocation or implementation in languages like\nMATLAB and APL differ from R/dplyr. The differences in spelling illustrate how\nthe concept of linguistic relativity applies to programming languages in ways\nthat are analogous to human languages. Finally, we discuss how Julia, by being\na high performance yet general purpose dynamic language, allows its users to\nexpress different abstractions to suit individual preferences.\n", "versions": [{"version": "v1", "created": "Sun, 12 Aug 2018 09:38:34 GMT"}], "update_date": "2018-08-16", "authors_parsed": [["Chen", "Jiahao", ""]]}, {"id": "1808.04006", "submitter": "William J. Bowman", "authors": "William J. Bowman and Amal Ahmed", "title": "Typed Closure Conversion for the Calculus of Constructions", "comments": null, "journal-ref": null, "doi": "10.1145/3192366.3192372", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dependently typed languages such as Coq are used to specify and verify the\nfull functional correctness of source programs. Type-preserving compilation can\nbe used to preserve these specifications and proofs of correctness through\ncompilation into the generated target-language programs. Unfortunately,\ntype-preserving compilation of dependent types is hard. In essence, the problem\nis that dependent type systems are designed around high-level compositional\nabstractions to decide type checking, but compilation interferes with the\ntype-system rules for reasoning about run-time terms.\n  We develop a type-preserving closure-conversion translation from the Calculus\nof Constructions (CC) with strong dependent pairs ($\\Sigma$ types)---a subset\nof the core language of Coq---to a type-safe, dependently typed compiler\nintermediate language named CC-CC. The central challenge in this work is how to\ntranslate the source type-system rules for reasoning about functions into\ntarget type-system rules for reasoning about closures. To justify these rules,\nwe prove soundness of CC-CC by giving a model in CC. In addition to type\npreservation, we prove correctness of separate compilation.\n", "versions": [{"version": "v1", "created": "Sun, 12 Aug 2018 22:10:28 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Bowman", "William J.", ""], ["Ahmed", "Amal", ""]]}, {"id": "1808.04176", "submitter": "Angelos Charalambidis", "authors": "Antonis Troumpoukis, Angelos Charalambidis", "title": "Predicate Specialization for Definitional Higher-order Logic Programs", "comments": "Pre-proceedings paper presented at the 28th International Symposium\n  on Logic-Based Program Synthesis and Transformation (LOPSTR 2018), Frankfurt\n  am Main, Germany, 4-6 September 2018 (arXiv:1808.03326)", "journal-ref": null, "doi": null, "report-no": "LOPSTR/2018/11", "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Higher-order logic programming is an interesting extension of traditional\nlogic programming that allows predicates to appear as arguments and variables\nto be used where predicates typically occur. Higher-order characteristics are\nindeed desirable but on the other hand they are also usually more expensive to\nsupport. In this paper we propose a program specialization technique based on\npartial evaluation that can be applied to a modest but useful class of\nhigher-order logic programs and can transform them into first-order programs\nwithout introducing additional data structures. The resulting first-order\nprograms can be executed by conventional logic programming interpreters and\nbenefit from other optimizations that might be available. We provide an\nimplementation and experimental results that suggest the efficiency of the\ntransformation.\n", "versions": [{"version": "v1", "created": "Mon, 13 Aug 2018 12:38:48 GMT"}, {"version": "v2", "created": "Sat, 1 Dec 2018 20:42:46 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Troumpoukis", "Antonis", ""], ["Charalambidis", "Angelos", ""]]}, {"id": "1808.04190", "submitter": "Luigi Liquori", "authors": "Ciaffaglione Alberto, Di Gianantonio Pietro, Honsell Furio, Liquori\n  Luigi", "title": "A prototype-based approach to object reclassification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate, in the context of functional prototype-based lan- guages, a\ncalculus of objects which might extend themselves upon receiving a message, a\ncapability referred to by Cardelli as a self-inflicted operation. We present a\nsound type system for this calculus which guarantees that evaluating a\nwell-typed expression will never yield a message-not-found runtime error. The\nresulting calculus is an attempt towards the definition of a language combining\nthe safety advantage of static type checking with the flexibility normally\nfound in dynamically typed languages.\n", "versions": [{"version": "v1", "created": "Mon, 13 Aug 2018 13:13:14 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Alberto", "Ciaffaglione", ""], ["Pietro", "Di Gianantonio", ""], ["Furio", "Honsell", ""], ["Luigi", "Liquori", ""]]}, {"id": "1808.04264", "submitter": "Kees Middelburg", "authors": "J. A. Bergstra, C. A. Middelburg", "title": "A short introduction to program algebra with instructions for Boolean\n  registers", "comments": "21 pages, this paper is to a large extent a compilation of material\n  from several earlier publications; 23 pages, presentation improved and\n  section on uses for the theory added. arXiv admin note: text overlap with\n  arXiv:1702.03511", "journal-ref": "Computer Science Journal of Moldova, 26(3):199--232, 2018", "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A parameterized algebraic theory of instruction sequences, objects that\nrepresent the behaviours produced by instruction sequences under execution, and\nobjects that represent the behaviours exhibited by the components of the\nexecution environment of instruction sequences is the basis of a line of\nresearch in which issues relating to a wide variety of subjects from computer\nscience have been rigorously investigated thinking in terms of instruction\nsequences. In various papers that belong to this line of research, use is made\nof an instantiation of this theory in which the basic instructions are\ninstructions to read out and alter the content of Boolean registers and the\ncomponents of the execution environment are Boolean registers. In this paper,\nwe give a simplified presentation of the most general such instantiated theory.\n", "versions": [{"version": "v1", "created": "Mon, 13 Aug 2018 14:24:35 GMT"}, {"version": "v2", "created": "Sun, 2 Sep 2018 09:01:55 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Bergstra", "J. A.", ""], ["Middelburg", "C. A.", ""]]}, {"id": "1808.04289", "submitter": "Laura Titolo", "authors": "Laura Titolo and Cesar A. Mu\\~noz and Marco A. Feliu and Mariano M.\n  Moscato", "title": "Eliminating Unstable Tests in Floating-Point Programs", "comments": "Pre-proceedings paper presented at the 28th International Symposium\n  on Logic-Based Program Synthesis and Transformation (LOPSTR 2018), Frankfurt\n  am Main, Germany, 4-6 September 2018 (arXiv:1808.03326)", "journal-ref": null, "doi": null, "report-no": "LOPSTR/2018/1", "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Round-off errors arising from the difference between real numbers and their\nfloating-point representation cause the control flow of conditional\nfloating-point statements to deviate from the ideal flow of the real-number\ncomputation. This problem, which is called test instability, may result in a\nsignificant difference between the computation of a floating-point program and\nthe expected output in real arithmetic. In this paper, a formally proven\nprogram transformation is proposed to detect and correct the effects of\nunstable tests. The output of this transformation is a floating-point program\nthat is guaranteed to return either the result of the original floating-point\nprogram when it can be assured that both its real and its floating-point flows\nagree or a warning when these flows may diverge. The proposed approach is\nillustrated with the transformation of the core computation of a polygon\ncontainment algorithm developed at NASA that is used in a geofencing system for\nunmanned aircraft systems.\n", "versions": [{"version": "v1", "created": "Mon, 13 Aug 2018 15:25:12 GMT"}, {"version": "v2", "created": "Sat, 1 Dec 2018 04:10:44 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Titolo", "Laura", ""], ["Mu\u00f1oz", "Cesar A.", ""], ["Feliu", "Marco A.", ""], ["Moscato", "Mariano M.", ""]]}, {"id": "1808.04706", "submitter": "Fei Zuo", "authors": "Fei Zuo, Xiaopeng Li, Patrick Young, Lannan Luo, Qiang Zeng, Zhexin\n  Zhang", "title": "Neural Machine Translation Inspired Binary Code Similarity Comparison\n  beyond Function Pairs", "comments": "Accepted by Network and Distributed Systems Security (NDSS) Symposium\n  2019", "journal-ref": null, "doi": "10.14722/ndss.2019.23492", "report-no": null, "categories": "cs.SE cs.CL cs.CR cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Binary code analysis allows analyzing binary code without having access to\nthe corresponding source code. A binary, after disassembly, is expressed in an\nassembly language. This inspires us to approach binary analysis by leveraging\nideas and techniques from Natural Language Processing (NLP), a rich area\nfocused on processing text of various natural languages. We notice that binary\ncode analysis and NLP share a lot of analogical topics, such as semantics\nextraction, summarization, and classification. This work utilizes these ideas\nto address two important code similarity comparison problems. (I) Given a pair\nof basic blocks for different instruction set architectures (ISAs), determining\nwhether their semantics is similar or not; and (II) given a piece of code of\ninterest, determining if it is contained in another piece of assembly code for\na different ISA. The solutions to these two problems have many applications,\nsuch as cross-architecture vulnerability discovery and code plagiarism\ndetection. We implement a prototype system INNEREYE and perform a comprehensive\nevaluation. A comparison between our approach and existing approaches to\nProblem I shows that our system outperforms them in terms of accuracy,\nefficiency and scalability. And the case studies utilizing the system\ndemonstrate that our solution to Problem II is effective. Moreover, this\nresearch showcases how to apply ideas and techniques from NLP to large-scale\nbinary code analysis.\n", "versions": [{"version": "v1", "created": "Wed, 8 Aug 2018 22:26:08 GMT"}, {"version": "v2", "created": "Sun, 16 Dec 2018 21:50:13 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Zuo", "Fei", ""], ["Li", "Xiaopeng", ""], ["Young", "Patrick", ""], ["Luo", "Lannan", ""], ["Zeng", "Qiang", ""], ["Zhang", "Zhexin", ""]]}, {"id": "1808.05065", "submitter": "Etienne Payet", "authors": "Etienne Payet", "title": "Guided Unfoldings for Finding Loops in Standard Term Rewriting", "comments": "Pre-proceedings paper presented at the 28th International Symposium\n  on Logic-Based Program Synthesis and Transformation (LOPSTR 2018), Frankfurt\n  am Main, Germany, 4-6 September 2018 (arXiv:1808.03326)", "journal-ref": null, "doi": null, "report-no": "LOPSTR/2018/19", "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we reconsider the unfolding-based technique that we have\nintroduced previously for detecting loops in standard term rewriting. We\nimprove it by guiding the unfolding process, using distinguished positions in\nthe rewrite rules. This results in a depth-first computation of the unfoldings,\nwhereas the original technique was breadth-first. We have implemented this new\napproach in our tool NTI and compared it to the previous one on a bunch of\nrewrite systems. The results we get are promising (better times, more\nsuccessful proofs).\n", "versions": [{"version": "v1", "created": "Wed, 15 Aug 2018 13:13:37 GMT"}, {"version": "v2", "created": "Thu, 8 Nov 2018 06:45:55 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Payet", "Etienne", ""]]}, {"id": "1808.05088", "submitter": "Marco Carbone", "authors": "Marco Carbone, Luis Cruz-Filipe, Fabrizio Montesi, Agata Murawska", "title": "Multiparty Classical Choreographies", "comments": "Post-proceedings paper presented at the 28th International Symposium\n  on Logic-Based Program Synthesis and Transformation (LOPSTR 2018), Frankfurt\n  am Main, Germany, 4-6 September 2018 (arXiv:1808.03326) The paper was\n  improved and extended (+2 pages). Now more details are provided on the work", "journal-ref": null, "doi": null, "report-no": "LOPSTR/2018/24", "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Multiparty Classical Choreographies (MCC), a language model where\nglobal descriptions of communicating systems (choreographies) implement typed\nmultiparty sessions. Typing is achieved by generalising classical linear logic\nto judgements that explicitly record parallelism by means of hypersequents. Our\napproach unifies different lines of work on choreographies and processes with\nmultiparty sessions, as well as their connection to linear logic. Thus, results\ndeveloped in one context are carried over to the others. Key novelties of MCC\ninclude support for server invocation in choreographies, as well as\nlogic-driven compilation of choreographies with replicated processes.\n", "versions": [{"version": "v1", "created": "Wed, 15 Aug 2018 14:11:41 GMT"}, {"version": "v2", "created": "Sun, 30 Sep 2018 06:09:12 GMT"}, {"version": "v3", "created": "Sun, 2 Dec 2018 10:04:57 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Carbone", "Marco", ""], ["Cruz-Filipe", "Luis", ""], ["Montesi", "Fabrizio", ""], ["Murawska", "Agata", ""]]}, {"id": "1808.05097", "submitter": "Angel Cuenca-Ortega", "authors": "Mar\\'ia Alpuente and Angel Cuenca-Ortega and Santiago Escobar and\n  Jos\\'e Meseguer", "title": "Homeomorphic Embedding modulo Combinations of Associativity and\n  Commutativity Axioms", "comments": "Pre-proceedings paper presented at the 28th International Symposium\n  on Logic-Based Program Synthesis and Transformation (LOPSTR 2018), Frankfurt\n  am Main, Germany, 4-6 September 2018", "journal-ref": null, "doi": null, "report-no": "LOPSTR/2018/8", "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Homeomorphic Embedding relation has been amply used for defining\ntermination criteria of symbolic methods for program analysis, transformation,\nand verification. However, homeomorphic embedding has never been investigated\nin the context of order-sorted rewrite theories that support symbolic execution\nmethods modulo equational axioms. This paper generalizes the symbolic\nhomeomorphic embedding relation to order-sorted rewrite theories that may\ncontain various combinations of associativity and/or commutativity axioms for\ndifferent binary operators. We systematically measure the performance of\nincreasingly efficient formulations of the homeomorphic embedding relation\nmodulo associativity and commutativity axioms. From our experimental results,\nwe conclude that our most efficient version indeed pays off in practice.\n", "versions": [{"version": "v1", "created": "Wed, 15 Aug 2018 14:30:12 GMT"}, {"version": "v2", "created": "Wed, 28 Nov 2018 15:34:26 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Alpuente", "Mar\u00eda", ""], ["Cuenca-Ortega", "Angel", ""], ["Escobar", "Santiago", ""], ["Meseguer", "Jos\u00e9", ""]]}, {"id": "1808.05197", "submitter": "Isabel Garcia-Contreras", "authors": "Isabel Garcia-Contreras, Jose F. Morales, Manuel V. Hermenegildo", "title": "Multivariant Assertion-based Guidance in Abstract Interpretation", "comments": "Pre-proceedings paper presented at the 28th International Symposium\n  on Logic-Based Program Synthesis and Transformation (LOPSTR 2018), Frankfurt\n  am Main, Germany, 4-6 September 2018 (arXiv:1808.03326)", "journal-ref": null, "doi": null, "report-no": "LOPSTR/2018/29", "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approximations during program analysis are a necessary evil, as they ensure\nessential properties, such as soundness and termination of the analysis, but\nthey also imply not always producing useful results. Automatic techniques have\nbeen studied to prevent precision loss, typically at the expense of larger\nresource consumption. In both cases (i.e., when analysis produces inaccurate\nresults and when resource consumption is too high), it is necessary to have\nsome means for users to provide information to guide analysis and thus improve\nprecision and/or performance. We present techniques for supporting within an\nabstract interpretation framework a rich set of assertions that can deal with\nmultivariance/context-sensitivity, and can handle different run-time semantics\nfor those assertions that cannot be discharged at compile time. We show how the\nproposed approach can be applied to both improving precision and accelerating\nanalysis. We also provide some formal results on the effects of such assertions\non the analysis results.\n", "versions": [{"version": "v1", "created": "Wed, 15 Aug 2018 17:44:16 GMT"}, {"version": "v2", "created": "Sun, 2 Dec 2018 20:24:09 GMT"}, {"version": "v3", "created": "Mon, 17 Dec 2018 17:16:53 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Garcia-Contreras", "Isabel", ""], ["Morales", "Jose F.", ""], ["Hermenegildo", "Manuel V.", ""]]}, {"id": "1808.05360", "submitter": "Vincent Nys", "authors": "Vincent Nys and Danny De Schreye", "title": "Compiling Control as Offline Partial Deduction", "comments": "Pre-proceedings paper presented at the 28th International Symposium\n  on Logic-Based Program Synthesis and Transformation (LOPSTR 2018), Frankfurt\n  am Main, Germany, 4-6 September 2018 (arXiv:1808.03326)", "journal-ref": null, "doi": null, "report-no": "LOPSTR/2018/7", "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new approach to a technique known as compiling control, whose\naim is to compile away special mechanisms for non-standard atom selection in\nlogic programs. It has previously been conjectured that compiling control could\nbe implemented as an instance of the first Futamura projection, in which an\ninterpreter is specialized for an input program. However, the exact nature of\nsuch an interpreter and of the required technique for specialization were never\nspecified. In this work, we propose a Prolog meta-interpreter which applies the\ndesired non-standard selection rule and which is amenable to specialization\nusing offline partial deduction. After the initial analysis phase of compiling\ncontrol, we collect annotations to specialize the interpreter using the Logen\nsystem for offline partial deduction. We also show that the result of the\nspecialization is equivalent to the program obtained using the traditional\napproach to compiling control. In this way, we simplify the synthesis step.\n", "versions": [{"version": "v1", "created": "Thu, 16 Aug 2018 07:09:58 GMT"}, {"version": "v2", "created": "Fri, 30 Nov 2018 17:22:12 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Nys", "Vincent", ""], ["De Schreye", "Danny", ""]]}, {"id": "1808.05490", "submitter": "Petros Papapanagiotou", "authors": "Petros Papapanagiotou and Jacques Fleuriot", "title": "A Pragmatic, Scalable Approach to Correct-by-construction Process\n  Composition Using Classical Linear Logic Inference", "comments": "Post-proceedings paper presented at the 28th International Symposium\n  on Logic-Based Program Synthesis and Transformation (LOPSTR 2018), Frankfurt\n  am Main, Germany, 4-6 September 2018 (arXiv:1808.03326). arXiv admin note:\n  substantial text overlap with arXiv:1803.02613", "journal-ref": null, "doi": null, "report-no": "LOPSTR/2018/13", "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The need for rigorous process composition is encountered in many situations\npertaining to the development and analysis of complex systems. We discuss the\nuse of Classical Linear Logic (CLL) for correct-by-construction resource-based\nprocess composition, with guaranteed deadlock freedom, systematic resource\naccounting, and concurrent execution. We introduce algorithms to automate the\nnecessary inference steps for binary compositions of processes in parallel,\nconditionally, and in sequence. We combine decision procedures and heuristics\nto achieve intuitive and practically useful compositions in an applied setting.\n", "versions": [{"version": "v1", "created": "Wed, 15 Aug 2018 16:24:38 GMT"}, {"version": "v2", "created": "Mon, 3 Dec 2018 10:02:57 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Papapanagiotou", "Petros", ""], ["Fleuriot", "Jacques", ""]]}, {"id": "1808.05789", "submitter": "Moa Johansson", "authors": "Andreas Arvidsson, Moa Johansson, Robin Touche", "title": "Proving Type Class Laws for Haskell", "comments": "Presented at the Symposium for Trends in Functional Programming, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Type classes in Haskell are used to implement ad-hoc polymorphism, i.e. a way\nto ensure both to the programmer and the compiler that a set of functions are\ndefined for a specific data type. All instances of such type classes are\nexpected to behave in a certain way and satisfy laws associated with the\nrespective class. These are however typically just stated in comments and as\nsuch, there is no real way to enforce that they hold. In this paper we describe\na system which allows the user to write down type class laws which are then\nautomatically instantiated and sent to an inductive theorem prover when\ndeclaring a new instance of a type class.\n", "versions": [{"version": "v1", "created": "Fri, 17 Aug 2018 08:19:37 GMT"}], "update_date": "2018-08-20", "authors_parsed": [["Arvidsson", "Andreas", ""], ["Johansson", "Moa", ""], ["Touche", "Robin", ""]]}, {"id": "1808.06052", "submitter": "Moez AbdelGawad", "authors": "Moez A. AbdelGawad", "title": "Doubly F-Bounded Generics", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we suggest how f-bounded generics in nominally-typed OOP can be\nextended to the more general notion we call `doubly f-bounded generics' and we\nsuggest how doubly f-bounded generics can be reasoned about. We also (attempt\nto) prove, using a coinductive argument, that our reasoning method is\nmathematically sound.\n", "versions": [{"version": "v1", "created": "Sat, 18 Aug 2018 07:19:08 GMT"}, {"version": "v2", "created": "Mon, 27 Aug 2018 13:36:10 GMT"}, {"version": "v3", "created": "Thu, 30 Aug 2018 10:50:33 GMT"}, {"version": "v4", "created": "Thu, 6 Sep 2018 14:01:42 GMT"}, {"version": "v5", "created": "Fri, 7 Sep 2018 02:54:21 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["AbdelGawad", "Moez A.", ""]]}, {"id": "1808.06292", "submitter": "Wolfgang Slany", "authors": "Kirshan Kumar Luhana, Matthias Mueller, Christian Schindler, Wolfgang\n  Slany, Bernadette Spieler", "title": "Rock bottom, the world, the sky: Catrobat, an extremely large-scale and\n  long-term visual coding project relying purely on smartphones", "comments": "Constructionism 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Most of the 700 million teenagers everywhere in the world already have their\nown smartphones, but comparatively few of them have access to PCs, laptops,\nOLPCs, Chromebooks, or tablets. The free open source non-profit project\nCatrobat allows users to create and publish their own apps using only their\nsmartphones. Initiated in 2010, with first public versions of our free apps\nsince 2014 and 47 releases of the main coding app as of July 2018, Catrobat\ncurrently has more than 700,000 users from 180 countries, is available in 50+\nlanguages, and has been developed so far by almost 1,000 volunteers from around\nthe world (\"the world\"). Catrobat is strongly inspired by Scratch and indeed\nallows to import most Scratch projects, thus giving access to more than 30\nmillion projects on our users' phones as of July 2018. Our apps are very\nintuitive (\"rock bottom\"), have many accessibility settings, e.g., for kids\nwith visual or cognitive impairments, and there are tons of constructionist\ntutorials and courses in many languages. We also have created a plethora of\nextensions, e.g., for various educational robots, including Lego Mindstorms and\nflying Parrot quadcopters (\"the sky\"), as well as for controlling arbitrary\nexternal devices through Arduino or Raspberry Pi boards, going up to the\nstratosphere and even beyond to interplanetary space (\"the sky\"). A\nTurtleStitch extension allowing to code one's own embroidery patterns for\nclothes is currently being developed. Catrobat among others intensely focuses\non including female teenagers. While a dedicated version for schools is being\ndeveloped, our apps are meant to be primarily used outside of class rooms,\nanywhere and in particular outdoors (\"rock bottom\", \"the world\"). Catrobat is\ndiscovered by our users through various app stores such as Google Play and via\nsocial media channels such as YouTube as well as via our presence on Code.org.\n", "versions": [{"version": "v1", "created": "Mon, 20 Aug 2018 03:05:39 GMT"}], "update_date": "2018-08-21", "authors_parsed": [["Luhana", "Kirshan Kumar", ""], ["Mueller", "Matthias", ""], ["Schindler", "Christian", ""], ["Slany", "Wolfgang", ""], ["Spieler", "Bernadette", ""]]}, {"id": "1808.06348", "submitter": "Nachshon Cohen", "authors": "Nachshon Cohen", "title": "Every Data Structure Deserves Lock-Free Memory Reclamation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Memory-management support for lock-free data structures is well known to be a\ntough problem. Recent work has successfully reduced the overhead of such\nschemes. However, applying memory-management support to a data structure\nremains complex and, in many cases, requires redesigning the data structure. In\nthis paper, we present the first lock-free memory-management scheme that is\napplicable to general (arbitrary) lock-free data structures and that can be\napplied automatically via a compiler plug-in. In addition to the simplicity of\nincorporating to data structures, this scheme provides low overhead and does\nnot rely on the lock freedom of any OS services.\n", "versions": [{"version": "v1", "created": "Mon, 20 Aug 2018 08:48:48 GMT"}], "update_date": "2018-08-21", "authors_parsed": [["Cohen", "Nachshon", ""]]}, {"id": "1808.07401", "submitter": "Michael Hanus", "authors": "Sergio Antoy, Michael Hanus, Finn Teegen", "title": "Synthesizing Set Functions", "comments": "17 pages, Accepted for presentation in WFLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Set functions are a feature of functional logic programming to encapsulate\nall results of a non-deterministic computation in a single data structure.\nGiven a function $f$ of a functional logic program written in Curry, we\ndescribe a technique to synthesize the definition of the set function of $f$.\nThe definition produced by our technique is based on standard Curry constructs.\nOur approach is interesting for three reasons. It allows reasoning about set\nfunctions, it offers an implementation of set functions which can be added to\nany Curry system, and it has the potential of changing our thinking about the\nimplementation of non-determinism, a notoriously difficult problem.\n", "versions": [{"version": "v1", "created": "Wed, 22 Aug 2018 15:13:56 GMT"}], "update_date": "2018-08-23", "authors_parsed": [["Antoy", "Sergio", ""], ["Hanus", "Michael", ""], ["Teegen", "Finn", ""]]}, {"id": "1808.07725", "submitter": "Philipp K\\\"orner", "authors": "Alexandros Efremidis, Joshua Schmidt, Sebastian Krings, Philipp\n  K\\\"orner", "title": "Measuring Coverage of Prolog Programs Using Mutation Testing", "comments": "16 pages, Accepted for presentation in WFLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Testing is an important aspect in professional software development, both to\navoid and identify bugs as well as to increase maintainability. However,\nincreasing the number of tests beyond a reasonable amount hinders development\nprogress. To decide on the completeness of a test suite, many approaches to\nassert test coverage have been suggested. Yet, frameworks for logic programs\nremain scarce.\n  In this paper, we introduce a framework for Prolog programs measuring test\ncoverage using mutations. We elaborate the main ideas of mutation testing and\ntransfer them to logic programs. To do so, we discuss the usefulness of\ndifferent mutations in the context of Prolog and empirically evaluate them in a\nnew mutation testing framework on different examples.\n", "versions": [{"version": "v1", "created": "Thu, 23 Aug 2018 12:47:52 GMT"}], "update_date": "2018-08-24", "authors_parsed": [["Efremidis", "Alexandros", ""], ["Schmidt", "Joshua", ""], ["Krings", "Sebastian", ""], ["K\u00f6rner", "Philipp", ""]]}, {"id": "1808.07770", "submitter": "Ingmar Dasseville", "authors": "Ingmar Dasseville, Marc Denecker", "title": "Transpiling Programmable Computable Functions to Answer Set Programs", "comments": "15 pages, Accepted for presentation in WFLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Programming Computable Functions (PCF) is a simplified programming language\nwhich provides the theoretical basis of modern functional programming\nlanguages. Answer set programming (ASP) is a programming paradigm focused on\nsolving search problems. In this paper we provide a translation from PCF to\nASP. Using this translation it becomes possible to specify search problems\nusing PCF.\n", "versions": [{"version": "v1", "created": "Thu, 23 Aug 2018 14:07:39 GMT"}], "update_date": "2018-08-24", "authors_parsed": [["Dasseville", "Ingmar", ""], ["Denecker", "Marc", ""]]}, {"id": "1808.07771", "submitter": "Ingmar Dasseville", "authors": "Ingmar Dasseville, Gerda Janssens", "title": "FMS: Functional Programming as a Modelling Language", "comments": "16 pages, Accepted for presentation in WFLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce the Functional Modelling System (FMS). The system\nintroduces the Functional Modelling Language (FML), which is a modelling\nlanguage for NP-complete search problems based on concepts of functional\nprogramming. Internally, we translate FML specifications to an Answer Set\nProgram to obtain models. We give a general overview of the new FML language,\nand how this language is handled in the system. We give a step-by-step\nwalkthrough of the system, pointing out what features are in place, and what\nimprovements are still possible.\n", "versions": [{"version": "v1", "created": "Thu, 23 Aug 2018 14:10:39 GMT"}], "update_date": "2018-08-24", "authors_parsed": [["Dasseville", "Ingmar", ""], ["Janssens", "Gerda", ""]]}, {"id": "1808.07788", "submitter": "Daniel Gall", "authors": "Thom Fr\\\"uhwirth and Daniel Gall", "title": "Exploring Parallel Execution Strategies for Constraint Handling Rules -\n  Work-in-Progress Report", "comments": "16 pages, Accepted for presentation in WFLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constraint Handling Rules (CHR) is a declarative rule-based formalism and\nlanguage. Concurrency is inherent as rules can be applied to subsets of\nconstraints in parallel. Parallel implementations of CHR, be it in software, be\nit in hardware, use different execution strategies for parallel execution of\nCHR programs depending on the implementation language.\n  In this report, our goal is to analyze parallel execution of CHR programs\nfrom a more general conceptual perspective. We want to experimentally see what\nis possible when CHR programs are automatically parallelized. For this purpose,\na sequential simulation of parallel CHR execution is used to systematically\nencode different parallel execution strategies. In exhaustive experiments on\nsome typical examples from the literature, parallel and sequential execution\ncan be compared to each other. The number of processors can be bounded or\nunbounded for a more theoretical analysis. As a result, some preliminary but\nindicative observations on the influence of the execution strategy can be made\nfor the different problem classes and in general.\n", "versions": [{"version": "v1", "created": "Thu, 23 Aug 2018 14:57:47 GMT"}], "update_date": "2018-08-24", "authors_parsed": [["Fr\u00fchwirth", "Thom", ""], ["Gall", "Daniel", ""]]}, {"id": "1808.07826", "submitter": "Matthew Hammer", "authors": "Matthew A. Hammer, Jana Dunfield, Kyle Headley, Monal Narasimhamurthy,\n  Dimitrios J. Economou", "title": "Fungi: Typed incremental computation with names", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Incremental computations attempt to exploit input similarities over time,\nreusing work that is unaffected by input changes. To maximize this reuse in a\ngeneral-purpose programming setting, programmers need a mechanism to identify\ndynamic allocations (of data and subcomputations) that correspond over time. We\npresent Fungi, a typed functional language for incremental computation with\nnames. Unlike prior general-purpose languages for incremental computing,\nFungi's notion of names is formal, general, and statically verifiable. Fungi's\ntype-and-effect system permits the programmer to encode (program-specific)\nlocal invariants about names, and to use these invariants to establish global\nuniqueness for their composed programs, the property of using names correctly.\nWe prove that well-typed Fungi programs respect global uniqueness. We derive a\nbidirectional version of the type and effect system, and we have implemented a\nprototype of Fungi in Rust. We apply Fungi to a library of incremental\ncollections, showing that it is expressive in practice.\n", "versions": [{"version": "v1", "created": "Mon, 20 Aug 2018 15:55:24 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Hammer", "Matthew A.", ""], ["Dunfield", "Jana", ""], ["Headley", "Kyle", ""], ["Narasimhamurthy", "Monal", ""], ["Economou", "Dimitrios J.", ""]]}, {"id": "1808.07827", "submitter": "EPTCS", "authors": "Vincenzo Arceri (University of Verona, Department of Computer Science,\n  Verona, Italy), Isabella Mastroeni (University of Verona, Department of\n  Computer Science, Verona, Italy)", "title": "Static Program Analysis for String Manipulation Languages", "comments": "In Proceedings VPT 2019, arXiv:1908.06723", "journal-ref": "EPTCS 299, 2019, pp. 19-33", "doi": "10.4204/EPTCS.299.5", "report-no": null, "categories": "cs.PL cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, dynamic languages, such as JavaScript or Python, have been\nincreasingly used in a wide range of fields and applications. Their tricky and\nmisunderstood behaviors pose a hard challenge for static analysis of these\nprogramming languages. A key aspect of any dynamic language program is the\nmultiple usage of strings, since they can be implicitly converted to another\ntype value, transformed by string-to-code primitives or used to access an\nobject-property. Unfortunately, string analyses for dynamic languages still\nlack precision and do not take into account some important string features.\nMoreover, string obfuscation is very popular in the context of dynamic language\nmalicious code, for example, to hide code information inside strings and then\nto dynamically transform strings into executable code. In this scenario, more\nprecise string analyses become a necessity. This paper is placed in the context\nof static string analysis by abstract interpretation and proposes a new\nsemantics for string analysis, placing a first step for handling dynamic\nlanguages string features.\n", "versions": [{"version": "v1", "created": "Fri, 17 Aug 2018 22:21:07 GMT"}, {"version": "v2", "created": "Tue, 20 Aug 2019 06:35:39 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Arceri", "Vincenzo", "", "University of Verona, Department of Computer Science,\n  Verona, Italy"], ["Mastroeni", "Isabella", "", "University of Verona, Department of\n  Computer Science, Verona, Italy"]]}, {"id": "1808.07832", "submitter": "Devangi Parikh", "authors": "Devangi N. Parikh, Margaret E. Myers, Richard Vuduc, Robert A. van de\n  Geijn", "title": "A Simple Methodology for Computing Families of Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": "FLAME Working Note #87, The University of Texas at Austin,\n  Department of Computer Science, Technical Report TR-18-06", "categories": "cs.PL cs.LO cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discovering \"good\" algorithms for an operation is often considered an art\nbest left to experts. What if there is a simple methodology, an algorithm, for\nsystematically deriving a family of algorithms as well as their cost analyses,\nso that the best algorithm can be chosen? We discuss such an approach for\nderiving loop-based algorithms. The example used to illustrate this\nmethodology, evaluation of a polynomial, is itself simple yet the best\nalgorithm that results is surprising to a non-expert: Horner's rule. We finish\nby discussing recent advances that make this approach highly practical for the\ndomain of high-performance linear algebra software libraries.\n", "versions": [{"version": "v1", "created": "Mon, 20 Aug 2018 23:17:06 GMT"}], "update_date": "2018-08-24", "authors_parsed": [["Parikh", "Devangi N.", ""], ["Myers", "Margaret E.", ""], ["Vuduc", "Richard", ""], ["van de Geijn", "Robert A.", ""]]}, {"id": "1808.07921", "submitter": "Ankush Desai", "authors": "Ankush Desai and Shromona Ghosh and Sanjit A. Seshia and Natarajan\n  Shankar and Ashish Tiwari", "title": "SOTER: A Runtime Assurance Framework for Programming Safe Robotics\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.PL cs.SE cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent drive towards achieving greater autonomy and intelligence in\nrobotics has led to high levels of complexity. Autonomous robots increasingly\ndepend on third party off-the-shelf components and complex machine-learning\ntechniques. This trend makes it challenging to provide strong design-time\ncertification of correct operation.\n  To address these challenges, we present SOTER, a robotics programming\nframework with two key components: (1) a programming language for implementing\nand testing high-level reactive robotics software and (2) an integrated runtime\nassurance (RTA) system that helps enable the use of uncertified components,\nwhile still providing safety guarantees. SOTER provides language primitives to\ndeclaratively construct a RTA module consisting of an advanced,\nhigh-performance controller (uncertified), a safe, lower-performance controller\n(certified), and the desired safety specification. The framework provides a\nformal guarantee that a well-formed RTA module always satisfies the safety\nspecification, without completely sacrificing performance by using higher\nperformance uncertified components whenever safe. SOTER allows the complex\nrobotics software stack to be constructed as a composition of RTA modules,\nwhere each uncertified component is protected using a RTA module.\n  To demonstrate the efficacy of our framework, we consider a real-world\ncase-study of building a safe drone surveillance system. Our experiments both\nin simulation and on actual drones show that the SOTER-enabled RTA ensures the\nsafety of the system, including when untrusted third-party components have bugs\nor deviate from the desired behavior.\n", "versions": [{"version": "v1", "created": "Thu, 23 Aug 2018 19:49:53 GMT"}, {"version": "v2", "created": "Mon, 11 Feb 2019 23:26:09 GMT"}, {"version": "v3", "created": "Fri, 19 Apr 2019 19:02:53 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Desai", "Ankush", ""], ["Ghosh", "Shromona", ""], ["Seshia", "Sanjit A.", ""], ["Shankar", "Natarajan", ""], ["Tiwari", "Ashish", ""]]}, {"id": "1808.07937", "submitter": "Salvador Tamarit", "authors": "Lars-{\\AA}ke Fredlund, Julio Mari\\~no, Sergio P\\'erez, and Salvador\n  Tamarit", "title": "Runtime verification in Erlang by using contracts", "comments": "19 pages, Accepted for presentation in WFLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  During its lifetime, a program suffers several changes that seek to improve\nor to augment some parts of its functionality. However, these modifications\nusually also introduce errors that affect the already-working code. There are\nseveral approaches and tools that help to spot and find the source of these\nerrors. However, most of these errors could be avoided beforehand by using some\nof the knowledge that the programmers had when they were writing the code. This\nis the idea behind the design-by-contract approach, where users can define\ncontracts that can be checked during runtime. In this paper, we apply the\nprinciples of this approach to Erlang, enabling, in this way, a runtime\nverification system in this language. We define two types of contracts. One of\nthem can be used in any Erlang program, while the second type is intended to be\nused only in concurrent programs. We provide the details of the implementation\nof both types of contracts. Moreover, we provide an extensive explanation of\neach contract as well as examples of their usage. All the ideas presented in\nthis paper have been implemented in a contract-based runtime verification\nsystem named EDBC. Its source code is available at GitHub as an open-source and\nfree project.\n", "versions": [{"version": "v1", "created": "Thu, 23 Aug 2018 20:31:57 GMT"}, {"version": "v2", "created": "Mon, 27 Aug 2018 10:20:47 GMT"}, {"version": "v3", "created": "Tue, 5 Feb 2019 17:24:36 GMT"}], "update_date": "2019-02-06", "authors_parsed": [["Fredlund", "Lars-\u00c5ke", ""], ["Mari\u00f1o", "Julio", ""], ["P\u00e9rez", "Sergio", ""], ["Tamarit", "Salvador", ""]]}, {"id": "1808.07938", "submitter": "Salvador Tamarit", "authors": "Sergio P\\'erez and Salvador Tamarit", "title": "Enhancing POI testing approach through the use of additional information", "comments": "29 pages, Accepted for presentation in WFLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, a new approach to perform regression testing has been defined: the\npoint of interest (POI) testing. A POI, in this context, is any expression of a\nprogram. The approach receives as input a set of relations between POIs from a\nversion of a program and POIs from another version, and also a sequence of\ninput functions, i.e. test cases. Then, a program instrumentation, an input\ntest case generation and different comparison functions are used to obtain the\nfinal report which indicates whether the alternative version of the program\nbehaves as expected, e.g. it produces the same values or it uses less\nCPU/memory. In this paper, we explain how we can improve the POI testing\napproach through the use of common stack traces and a more sophisticated\ntracing for calls. These enhancements of the approach allow users to identify\nerrors earlier and easier. Additionally, they enable new comparison modes and\nnew categories of reported unexpected behaviours.\n", "versions": [{"version": "v1", "created": "Thu, 23 Aug 2018 20:32:45 GMT"}], "update_date": "2018-08-27", "authors_parsed": [["P\u00e9rez", "Sergio", ""], ["Tamarit", "Salvador", ""]]}, {"id": "1808.07990", "submitter": "Sergio Antoy", "authors": "Sergio Antoy and Steven Libby", "title": "Making Bubbling Practical", "comments": "14 pages, Accepted for presentation in WFLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bubbling is a run-time graph transformation studied for the execution of\nnon-deterministic steps in functional logic computations. This transformation\nhas been proven correct, but as currently formulated it requires information\nabout the entire context of a step, even when the step affects only a handful\nof nodes. Therefore, despite some advantages, it does not appear to be\ncompetitive with approaches that require only localized information, such as\nbacktracking and pull-tabbing. We propose a novel algorithm that executes\nbubbling steps accessing only local information. To this aim, we define graphs\nthat have an additional attribute, a dominator of each node, and we maintain\nthis attribute when a rewrite and/or bubbling step is executed. When a bubbling\nstep is executed, the dominator is available at no cost, and only local\ninformation is accessed. Our work makes bubbling practical, and theoretically\ncompetitive, for implementing non-determinism in functional logic computations.\n", "versions": [{"version": "v1", "created": "Fri, 24 Aug 2018 03:06:57 GMT"}], "update_date": "2018-08-27", "authors_parsed": [["Antoy", "Sergio", ""], ["Libby", "Steven", ""]]}, {"id": "1808.08042", "submitter": "Fabrizio Riguzzi PhD", "authors": "Jan Wielemaker, Fabrizio Riguzzi, Bob Kowalski, Torbj\\\"orn Lager,\n  Fariba Sadri, Miguel Calejo", "title": "Using SWISH to realise interactive web based tutorials for logic based\n  languages", "comments": null, "journal-ref": "Jan Wielemaker et al. Using SWISH to realise interactive web based\n  tutorials for logic based languages. Theory and Practice of Logic\n  Programming, 19(2):229--261, 2019", "doi": "10.1017/S1471068418000522", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Programming environments have evolved from purely text based to using\ngraphical user interfaces, and now we see a move towards web based interfaces,\nsuch as Jupyter. Web based interfaces allow for the creation of interactive\ndocuments that consist of text and programs, as well as their output. The\noutput can be rendered using web technology as, e.g., text, tables, charts or\ngraphs. This approach is particularly suitable for capturing data analysis\nworkflows and creating interactive educational material. This article describes\nSWISH, a web front-end for Prolog that consists of a web server implemented in\nSWI-Prolog and a client web application written in JavaScript. SWISH provides a\nweb server where multiple users can manipulate and run the same material, and\nit can be adapted to support Prolog extensions. In this paper we describe the\narchitecture of SWISH, and describe two case studies of extensions of Prolog,\nnamely Probabilistic Logic Programming (PLP) and Logic Production System (LPS),\nwhich have used SWISH to provide tutorial sites.\n", "versions": [{"version": "v1", "created": "Fri, 24 Aug 2018 08:14:29 GMT"}, {"version": "v2", "created": "Thu, 30 Jan 2020 11:59:17 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Wielemaker", "Jan", ""], ["Riguzzi", "Fabrizio", ""], ["Kowalski", "Bob", ""], ["Lager", "Torbj\u00f6rn", ""], ["Sadri", "Fariba", ""], ["Calejo", "Miguel", ""]]}, {"id": "1808.08071", "submitter": "EPTCS", "authors": "Jorge A. P\\'erez (University of Groningen, The Netherlands), Simone\n  Tini (University of Insubria, Italy)", "title": "Proceedings Combined 25th International Workshop on Expressiveness in\n  Concurrency and 15th Workshop on Structural Operational Semantics", "comments": null, "journal-ref": "EPTCS 276, 2018", "doi": "10.4204/EPTCS.276", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the proceedings of the Combined 25th International\nWorkshop on Expressiveness in Concurrency and the 15th Workshop on Structural\nOperational Semantics (EXPRESS/SOS 2018), which was held on September 3, 2018,\nin Beijing, China, as an affiliated workshop of CONCUR 2018, the 29th\nInternational Conference on Concurrency Theory. The EXPRESS workshops aim at\nbringing together researchers interested in the expressiveness of various\nformal systems and semantic notions, particularly in the field of concurrency.\nTheir focus has traditionally been on the comparison between programming\nconcepts (such as concurrent, functional, imperative, logic and object-oriented\nprogramming) and between mathematical models of computation (such as process\nalgebras, Petri nets, event structures, modal logics, and rewrite systems) on\nthe basis of their relative expressive power. The SOS workshops aim at being a\nforum for researchers, students and practitioners interested in new\ndevelopments, and directions for future investigation, in the field of\nstructural operational semantics. One of the specific goals of the SOS workshop\nseries is to establish synergies between the concurrency and programming\nlanguage communities working on the theory and practice of SOS. Since 2012, the\nEXPRESS and SOS communities have organized an annual combined EXPRESS/SOS\nworkshop on the expressiveness of mathematical models of computation and the\nformal semantics of systems and programming concepts.\n", "versions": [{"version": "v1", "created": "Fri, 24 Aug 2018 10:08:05 GMT"}], "update_date": "2018-08-27", "authors_parsed": [["P\u00e9rez", "Jorge A.", "", "University of Groningen, The Netherlands"], ["Tini", "Simone", "", "University of Insubria, Italy"]]}, {"id": "1808.08094", "submitter": "Maja Hanne Kirkeby", "authors": "Henning Christiansen and Maja Kirkeby", "title": "Towards a constraint solver for proving confluence with invariant and\n  equivalence of realistic CHR programs", "comments": "17 pages, Accepted for presentation in WFLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Confluence of a nondeterministic program ensures a functional input-output\nrelation, freeing the programmer from considering the actual scheduling\nstrategy, and allowing optimized and perhaps parallel implementations. The more\ngeneral property of confluence modulo equivalence ensures that equivalent\ninputs are related to equivalent outputs, that need not be identical.\nConfluence under invariants is also considered. Constraint Handling Rules (CHR)\nis an important example of a rewrite based logic programming language, and we\naim at a mechanizable method for proving confluence modulo equivalence of\nterminating programs. While earlier approaches to confluence for CHR programs\nconcern an idealized logic subset, we refer to a semantics compatible with\nstandard Prolog-based implementations. We specify a meta-level constraint\nlanguage in which invariants and equivalences can be expressed and manipulated,\nextending our previous theoretical results towards a practical implementation.\n", "versions": [{"version": "v1", "created": "Fri, 24 Aug 2018 11:26:40 GMT"}, {"version": "v2", "created": "Thu, 13 Sep 2018 10:32:56 GMT"}], "update_date": "2018-09-14", "authors_parsed": [["Christiansen", "Henning", ""], ["Kirkeby", "Maja", ""]]}, {"id": "1808.08143", "submitter": "Gregor Ulm", "authors": "Gregor Ulm, Emil Gustavsson, Mats Jirstrand", "title": "Functional Federated Learning in Erlang (ffl-erl)", "comments": "16 pages, accepted for publication in the WFLP 2018 conference\n  proceedings; final post-print", "journal-ref": "In: Silva J. (eds) Functional and Constraint Logic Programming.\n  WFLP 2018. Lecture Notes in Computer Science, vol 11285. Springer, Cham\n  (2019)", "doi": "10.1007/978-3-030-16202-3_10", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The functional programming language Erlang is well-suited for concurrent and\ndistributed applications. Numerical computing, however, is not seen as one of\nits strengths. The recent introduction of Federated Learning, a concept\naccording to which client devices are leveraged for decentralized machine\nlearning tasks, while a central server updates and distributes a global model,\nprovided the motivation for exploring how well Erlang is suited to that\nproblem. We present ffl-erl, a framework for Federated Learning, written in\nErlang, and explore how well it performs in two scenarios: one in which the\nentire system has been written in Erlang, and another in which Erlang is\nrelegated to coordinating client processes that rely on performing numerical\ncomputations in the programming language C. There is a concurrent as well as a\ndistributed implementation of each case. Erlang incurs a performance penalty,\nbut for certain use cases this may not be detrimental, considering the\ntrade-off between conciseness of the language and speed of development (Erlang)\nversus performance (C). Thus, Erlang may be a viable alternative to C for some\npractical machine learning tasks.\n", "versions": [{"version": "v1", "created": "Fri, 24 Aug 2018 14:03:52 GMT"}, {"version": "v2", "created": "Fri, 16 Nov 2018 13:53:26 GMT"}, {"version": "v3", "created": "Fri, 15 Mar 2019 10:42:06 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Ulm", "Gregor", ""], ["Gustavsson", "Emil", ""], ["Jirstrand", "Mats", ""]]}, {"id": "1808.08185", "submitter": "Jan C. Dagef\\\"orde", "authors": "Jan C. Dagef\\\"orde", "title": "Reference Type Logic Variables in Constraint-logic Object-oriented\n  Programming", "comments": "12 pages, Accepted for presentation in WFLP 2018", "journal-ref": "Functional and Constraint Logic Programming - Springer LNCS 11285\n  (2019) 131-144", "doi": "10.1007/978-3-030-16202-3_8", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constraint-logic object-oriented programming, for example using Muli,\nfacilitates the integrated development of business software that occasionally\ninvolves finding solutions to constraint-logic problems. The availability of\nobject-oriented features calls for the option to use objects as logic variables\nas well, as opposed to being limited to primitive type logic variables. The\npresent work contributes a concept for reference type logic variables in\nconstraint-logic object-oriented programming that takes arbitrary class\nhierarchies of programs written in object-oriented languages into account. The\nconcept discusses interactions between constraint-logic object-oriented\nprograms and reference type logic variables, particularly invocations on and\naccess to logic variables, type operations, and equality. Furthermore, it\nproposes approaches as to how these interactions can be handled by a\ncorresponding execution environment.\n", "versions": [{"version": "v1", "created": "Fri, 24 Aug 2018 15:54:00 GMT"}, {"version": "v2", "created": "Fri, 1 Mar 2019 10:30:43 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Dagef\u00f6rde", "Jan C.", ""]]}, {"id": "1808.08329", "submitter": "Johannes Waldmann", "authors": "Johannes Waldmann", "title": "When You Should Use Lists in Haskell (Mostly, You Should Not)", "comments": "10 pages, Accepted for presentation in WFLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We comment on the over-use of lists in functional programming. With this\nrespect, we review history of Haskell and some of its libraries, and hint at\ncurrent developments.\n", "versions": [{"version": "v1", "created": "Fri, 24 Aug 2018 22:41:46 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Waldmann", "Johannes", ""]]}, {"id": "1808.08330", "submitter": "Paventhan Vivekanandan", "authors": "Paventhan Vivekanandan", "title": "Code Generation for Higher Inductive Types", "comments": "16 pages, Accepted for presentation in WFLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Higher inductive types are inductive types that include nontrivial\nhigher-dimensional structure, represented as identifications that are not\nreflexivity. While work proceeds on type theories with a computational\ninterpretation of univalence and higher inductive types, it is convenient to\nencode these structures in more traditional type theories with mature\nimplementations. However, these encodings involve a great deal of error-prone\nadditional syntax. We present a library that uses Agda's metaprogramming\nfacilities to automate this process, allowing higher inductive types to be\nspecified with minimal additional syntax.\n", "versions": [{"version": "v1", "created": "Fri, 24 Aug 2018 22:46:13 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Vivekanandan", "Paventhan", ""]]}, {"id": "1808.08511", "submitter": "Zheng Yang", "authors": "Zheng Yang, Hang Lei", "title": "Optimization of Executable Formal Interpreters developed in Higher-order\n  Theorem Proving Systems", "comments": "20 pages, 14 figures, 9 tables", "journal-ref": "IEEE Access, 2018", "doi": "10.1109/ACCESS.2018.2880692", "report-no": "vol. 6, pp. 70331-70348", "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent publications, we presented a novel formal symbolic process virtual\nmachine (FSPVM) framework that combined higher-order theorem proving and\nsymbolic execution for verifying the reliability and security of smart\ncontracts developed in the Ethereum blockchain system without suffering the\nstandard issues surrounding reusability, consistency, and automation. A\nspecific FSPVM, denoted as FSPVM-E, was developed in Coq based on a general,\nextensible, and reusable formal memory (GERM) framework, an extensible and\nuniversal formal intermediate programming language, denoted as Lolisa, which is\na large subset of the Solidity programming language that uses generalized\nalgebraic datatypes, and a corresponding formally verified interpreter for\nLolisa, denoted as FEther, which serves as a crucial component of FSPVM-E.\nHowever, our past work has demonstrated that the execution efficiency of the\nstandard development of FEther is extremely low. As a result, FSPVM-E fails to\nachieve its expected verification effect. The present work addresses this issue\nby first identifying three root causes of the low execution efficiency of\nformal interpreters. We then build abstract models of these causes, and present\nrespective optimization schemes for rectifying the identified conditions.\nFinally, we apply these optimization schemes to FEther, and demonstrate that\nits execution efficiency has been improved significantly.\n", "versions": [{"version": "v1", "created": "Sun, 26 Aug 2018 06:41:41 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Yang", "Zheng", ""], ["Lei", "Hang", ""]]}, {"id": "1808.08648", "submitter": "EPTCS", "authors": "Jens Aagaard (Department of Computer Science, Aalborg University),\n  Hans H\\\"uttel (Department of Computer Science, Aalborg University), Mathias\n  Jakobsen (Department of Computer Science, Aalborg University), Mikkel\n  Kettunen (Department of Computer Science, Aalborg University)", "title": "Context-Free Session Types for Applied Pi-Calculus", "comments": "In Proceedings EXPRESS/SOS 2018, arXiv:1808.08071", "journal-ref": "EPTCS 276, 2018, pp. 3-18", "doi": "10.4204/EPTCS.276.3", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a binary session type system using context-free session types to a\nversion of the applied pi-calculus of Abadi et. al. where only base terms,\nconstants and channels can be sent. Session types resemble process terms from\nBPA and we use a version of bisimulation equivalence to characterize type\nequivalence. We present a quotiented type system defined on type equivalence\nclasses for which type equivalence is built into the type system. Both type\nsystems satisfy general soundness properties; this is established by an appeal\nto a generic session type system for psi-calculi.\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2018 01:18:46 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Aagaard", "Jens", "", "Department of Computer Science, Aalborg University"], ["H\u00fcttel", "Hans", "", "Department of Computer Science, Aalborg University"], ["Jakobsen", "Mathias", "", "Department of Computer Science, Aalborg University"], ["Kettunen", "Mikkel", "", "Department of Computer Science, Aalborg University"]]}, {"id": "1808.08651", "submitter": "EPTCS", "authors": "James Hoey (University of Leicester), Irek Ulidowski (University of\n  Leicester), Shoji Yuen (Nagoya University)", "title": "Reversing Parallel Programs with Blocks and Procedures", "comments": "In Proceedings EXPRESS/SOS 2018, arXiv:1808.08071", "journal-ref": "EPTCS 276, 2018, pp. 69-86", "doi": "10.4204/EPTCS.276.7", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how to reverse a while language extended with blocks, local\nvariables, procedures and the interleaving parallel composition. Annotation is\ndefined along with a set of operational semantics capable of storing necessary\nreversal information, and identifiers are introduced to capture the\ninterleaving order of an execution. Inversion is defined with a set of\noperational semantics that use saved information to undo an execution. We prove\nthat annotation does not alter the behaviour of the original program, and that\ninversion correctly restores the initial program state.\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2018 01:20:00 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Hoey", "James", "", "University of Leicester"], ["Ulidowski", "Irek", "", "University of\n  Leicester"], ["Yuen", "Shoji", "", "Nagoya University"]]}, {"id": "1808.08989", "submitter": "Maurice Chandoo", "authors": "Maurice Chandoo", "title": "A Systematic Approach to Programming", "comments": "30 pages + 10 pages appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how to systematically implement an algorithm in any imperative or\nfunctional programming language. The method is based on the premise that it is\neasy to write down how an algorithm proceeds on a concrete input. This\ninformation---which we call execution trace---is used as a starting point to\nderive the desired program. In contrast to test-driven development the program\nis directly constructed from the test cases instead of written separately. The\nprogram's operations, control flow and predicates guiding the control flow are\nworked out separately, which saves the programmer from having to think about\nthem simultaneously. We demonstrate the method for two examples and discuss its\nutility. Additionally, we provide a formal framework to compare it with other\napproaches.\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2018 18:47:41 GMT"}, {"version": "v2", "created": "Thu, 25 Apr 2019 12:59:59 GMT"}, {"version": "v3", "created": "Sun, 26 Apr 2020 13:34:49 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Chandoo", "Maurice", ""]]}, {"id": "1808.09234", "submitter": "Jan De Muijnck-Hughes", "authors": "Jan de Muijnck-Hughes", "title": "A Short Note on Collecting Dependently Typed Values", "comments": "A short paper illustrating minor semi-unpublished work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Within dependently typed languages, such as Idris, types can depend on\nvalues. This dependency, however, can limit the collection of items in standard\ncontainers: all elements must have the same type, and as such their types must\ncontain the same values. We present two dependently typed data structures for\ncollecting dependent types: \\texttt{DList} and \\texttt{PList}. Use of these new\ndata structures allow for the creation of single succinct inductive ADT whose\nconstructions were previously verbose and split across many data structures.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 11:45:33 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["de Muijnck-Hughes", "Jan", ""]]}, {"id": "1808.09870", "submitter": "Ruth Hoffmann", "authors": "Ruth Hoffmann, \\\"Ozg\\\"ur Akg\\\"un, Susmit Sarkar", "title": "Memory Consistency Models using Constraints", "comments": null, "journal-ref": "ModRef 2018, The 17th workshop on Constraint Modelling and\n  Reformulation, 2018", "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Memory consistency models (MCMs) are at the heart of concurrent programming.\nThey represent the behaviour of concurrent programs at the chip level. To test\nthese models small program snippets called litmus test are generated, which\nshow allowed or forbidden behaviour of different MCMs. This paper is showcasing\nthe use of constraint programming to automate the generation and testing of\nlitmus tests for memory consistency models. We produce a few exemplary case\nstudies for two MCMs, namely Sequential Consistency and Total Store Order.\nThese studies demonstrate the flexibility of constrains programming in this\ncontext and lay foundation to the direct verification of MCMs against the\nsoftware facing cache coherence protocols.\n", "versions": [{"version": "v1", "created": "Wed, 29 Aug 2018 15:04:58 GMT"}], "update_date": "2018-08-30", "authors_parsed": [["Hoffmann", "Ruth", ""], ["Akg\u00fcn", "\u00d6zg\u00fcr", ""], ["Sarkar", "Susmit", ""]]}, {"id": "1808.10363", "submitter": "Mat\\'u\\v{s} Sul\\'ir", "authors": "Mat\\'u\\v{s} Sul\\'ir, Jaroslav Porub\\\"an, Ondrej Zori\\v{c}\\'ak", "title": "IDE-Independent Program Comprehension Tools via Source File Overwriting", "comments": null, "journal-ref": "2017 IEEE 14th International Scientific Conference on Informatics,\n  IEEE, 2017, pp. 372-376", "doi": "10.1109/INFORMATICS.2017.8327277", "report-no": null, "categories": "cs.SE cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditionally, we have two possibilities to design tools for program\ncomprehension and analysis. The first option is to create a standalone program,\nindependent of any source code editor. This way, the act of source code editing\nis separated from the act of viewing the code analysis results. The second\noption is to create a plugin for a specific IDE (integrated development\nenvironment) - in this case, a separate version must be created for each IDE.\nWe propose an approach where information about source code elements is written\ndirectly into source files as annotations or special comments. Before\ncommitting to a version control system, the annotations are removed from the\nsource code to avoid code pollution. We briefly evaluate the approach and\ndelineate its limitations.\n", "versions": [{"version": "v1", "created": "Thu, 30 Aug 2018 15:45:52 GMT"}], "update_date": "2018-08-31", "authors_parsed": [["Sul\u00edr", "Mat\u00fa\u0161", ""], ["Porub\u00e4n", "Jaroslav", ""], ["Zori\u010d\u00e1k", "Ondrej", ""]]}, {"id": "1808.10603", "submitter": "Satoshi Egi", "authors": "Satoshi Egi and Yuichi Nishiwaki", "title": "Non-linear Pattern Matching with Backtracking for Non-free Data Types", "comments": null, "journal-ref": "Asian Symposium on Programming Languages and Systems. Springer.\n  2018", "doi": "10.1007/978-3-030-02768-1_1", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-free data types are data types whose data have no canonical forms. For\nexample, multisets are non-free data types because the multiset $\\{a,b,b\\}$ has\ntwo other equivalent but literally different forms $\\{b,a,b\\}$ and $\\{b,b,a\\}$.\nPattern matching is known to provide a handy tool set to treat such data types.\nAlthough many studies on pattern matching and implementations for practical\nprogramming languages have been proposed so far, we observe that none of these\nstudies satisfy all the criteria of practical pattern matching, which are as\nfollows: i) efficiency of the backtracking algorithm for non-linear patterns,\nii) extensibility of matching process, and iii) polymorphism in patterns.\n  This paper aims to design a new pattern-matching-oriented programming\nlanguage that satisfies all the above three criteria. The proposed language\nfeatures clean Scheme-like syntax and efficient and extensible pattern matching\nsemantics. This programming language is especially useful for the processing of\ncomplex non-free data types that not only include multisets and sets but also\ngraphs and symbolic mathematical expressions. We discuss the importance of our\ncriteria of practical pattern matching and how our language design naturally\narises from the criteria. The proposed language has been already implemented\nand open-sourced as the Egison programming language.\n", "versions": [{"version": "v1", "created": "Fri, 31 Aug 2018 06:08:55 GMT"}, {"version": "v2", "created": "Mon, 27 May 2019 05:17:59 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Egi", "Satoshi", ""], ["Nishiwaki", "Yuichi", ""]]}, {"id": "1808.10652", "submitter": "Daniel Lehmann", "authors": "Daniel Lehmann, Michael Pradel", "title": "Wasabi: A Framework for Dynamically Analyzing WebAssembly", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  WebAssembly is the new low-level language for the web and has now been\nimplemented in all major browsers since over a year. To ensure the security,\nperformance, and correctness of future web applications, there is a strong need\nfor dynamic analysis tools for WebAssembly. Unfortunately, building such tools\nfrom scratch requires knowledge of low-level details of the language, and\nperhaps even its runtime environment. This paper presents Wasabi, the first\ngeneral-purpose framework for dynamically analyzing WebAssembly. Wasabi\nprovides an easy-to-use, high-level API that allows implementing heavyweight\ndynamic analyses that can monitor all low-level behavior. The approach is based\non binary instrumentation, which inserts calls to analysis functions written in\nJavaScript into a WebAssembly binary. Wasabi addresses several unique\nchallenges not present for other binary instrumentation tools, such as the\nproblem of tracing type-polymorphic instructions with analysis functions that\nhave a fixed type, which we address through an on-demand monomorphization of\nanalysis calls. To control the overhead imposed by an analysis, Wasabi\nselectively instruments only those instructions relevant for the analysis. Our\nevaluation on compute-intensive benchmarks and real-world applications shows\nthat Wasabi (i) faithfully preserves the original program behavior, (ii)\nimposes an overhead that is reasonable for heavyweight dynamic analysis\n(depending on the program and the analyzed instructions, between 1.02x and\n163x), and (iii) makes it straightforward to implement various dynamic\nanalyses, including instruction counting, call graph extraction, memory access\ntracing, and taint analysis.\n", "versions": [{"version": "v1", "created": "Fri, 31 Aug 2018 09:53:52 GMT"}], "update_date": "2018-09-03", "authors_parsed": [["Lehmann", "Daniel", ""], ["Pradel", "Michael", ""]]}, {"id": "1808.10717", "submitter": "Malte Schmitz", "authors": "Lukas Convent and Sebastian Hungerecker and Martin Leucker and Torben\n  Scheffel and Malte Schmitz and Daniel Thoma", "title": "TeSSLa: Temporal Stream-based Specification Language", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Runtime verification is concerned with monitoring program traces. In\nparticular, stream runtime verification (SRV) takes the program trace as input\nstreams and incrementally derives output streams. SRV can check logical\nproperties and compute temporal metrics and statistics from the trace. We\npresent TeSSLa, a temporal stream-based specification language for SRV. TeSSLa\nsupports timestamped events natively and is hence suitable for streams that are\nboth sparse and fine-grained, which often occur in practice. We prove results\non TeSSLa's expressiveness and compare different TeSSLa fragments to (timed)\nautomata, thereby inheriting various decidability results. Finally, we present\na monitor implementation and prove its correctness.\n", "versions": [{"version": "v1", "created": "Fri, 31 Aug 2018 12:59:50 GMT"}], "update_date": "2018-09-03", "authors_parsed": [["Convent", "Lukas", ""], ["Hungerecker", "Sebastian", ""], ["Leucker", "Martin", ""], ["Scheffel", "Torben", ""], ["Schmitz", "Malte", ""], ["Thoma", "Daniel", ""]]}]