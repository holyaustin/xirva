[{"id": "1512.01438", "submitter": "EPTCS", "authors": "Oleg Kiselyov (Tohoku University, Japan), Jacques Garrigue (Nagoya\n  University, Japan)", "title": "Proceedings ML Family/OCaml Users and Developers workshops", "comments": null, "journal-ref": "EPTCS 198, 2015", "doi": "10.4204/EPTCS.198", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume collects the extended versions of selected papers originally\npresented at the two ACM SIGPLAN workshops: ML Family Workshop 2014 and OCaml\n2014. Both were affiliated with ICFP 2014 and took place on two consecutive\ndays, on September 4 and 5, 2014 in Gothenburg, Sweden.\n  The ML Family workshop aims to recognize the entire extended family of ML and\nML-like languages: languages that are Higher-order, Typed, Inferred, and\nStrict. It provides the forum to discuss common issues, both practical\n(compilation techniques, implementations of concurrency and parallelism,\nprogramming for the Web) and theoretical (fancy types, module systems,\nmetaprogramming). The scope of the workshop includes all aspects of the design,\nsemantics, theory, application, implementation, and teaching of the members of\nthe ML family.\n  The OCaml workshop is more specifically targeted at the OCaml community, with\nan emphasis on new proposals and tools aiming to improve OCaml, its\nenvironment, and the functioning of the community. As such, it is interested in\nworks on the type system, language extensions, compiler and optimizations,\napplications, tools, and experience reports of exciting uses.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2015 01:00:15 GMT"}], "update_date": "2015-12-07", "authors_parsed": [["Kiselyov", "Oleg", "", "Tohoku University, Japan"], ["Garrigue", "Jacques", "", "Nagoya\n  University, Japan"]]}, {"id": "1512.01690", "submitter": "Dmitri Soshnikov", "authors": "Dmitri Soshnikov", "title": "Using Functional Programming for Development of Distributed, Cloud and\n  Web Applications in F#", "comments": "Presented at CEE-SECR 2011, Moscow, Russia, see\n  http://2011.secr.ru/lang/en-en/talks/using-functional-programming-and-f", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we argue that modern functional programming languages - in\nparticular, FSharp on the .NET platform - are well suited for the development\nof distributed, web and cloud applications on the Internet. We emphasize that\nFSharp can be successfully used in a range of scenarios - starting from simple\nASP.NET web applications, and including cloud data processing tasks and\ndata-driven web applications. In particular, we show how some of the FSharp\nfeatures (eg. quotations) can be effectively used to develop a distributed web\nsystem using single code-base, and describe the commercial WebSharper project\nby Intellifactory for building distributed client-server web applications, as\nwell as research library that uses Windows Azure for parametric sweep\ncomputational tasks.\n", "versions": [{"version": "v1", "created": "Sat, 5 Dec 2015 17:50:21 GMT"}], "update_date": "2015-12-08", "authors_parsed": [["Soshnikov", "Dmitri", ""]]}, {"id": "1512.01837", "submitter": "Jonathan Sterling", "authors": "Jonathan Sterling", "title": "Type Theory and its Meaning Explanations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  At the heart of intuitionistic type theory lies an intuitive semantics called\nthe \"meaning explanations\"; crucially, when meaning explanations are taken as\ndefinitive for type theory, the core notion is no longer \"proof\" but\n\"verification\". We'll explore how type theories of this sort arise naturally as\nenrichments of logical theories with further judgements, and contrast this with\nmodern proof-theoretic type theories which interpret the judgements and proofs\nof logics, not their propositions and verifications.\n", "versions": [{"version": "v1", "created": "Sun, 6 Dec 2015 21:29:30 GMT"}, {"version": "v2", "created": "Thu, 14 Jul 2016 23:46:26 GMT"}], "update_date": "2016-07-18", "authors_parsed": [["Sterling", "Jonathan", ""]]}, {"id": "1512.01895", "submitter": "EPTCS", "authors": "Leo White, Fr\\'ed\\'eric Bour, Jeremy Yallop", "title": "Modular implicits", "comments": "In Proceedings ML/OCaml 2014, arXiv:1512.01438", "journal-ref": "EPTCS 198, 2015, pp. 22-63", "doi": "10.4204/EPTCS.198.2", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present modular implicits, an extension to the OCaml language for ad-hoc\npolymorphism inspired by Scala implicits and modular type classes. Modular\nimplicits are based on type-directed implicit module parameters, and elaborate\nstraightforwardly into OCaml's first-class functors. Basing the design on\nOCaml's modules leads to a system that naturally supports many features from\nother languages with systematic ad-hoc overloading, including inheritance,\ninstance constraints, constructor classes and associated types.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2015 03:16:36 GMT"}], "update_date": "2015-12-08", "authors_parsed": [["White", "Leo", ""], ["Bour", "Fr\u00e9d\u00e9ric", ""], ["Yallop", "Jeremy", ""]]}, {"id": "1512.01896", "submitter": "EPTCS", "authors": "Tomas Petricek (University of Cambridge), Don Syme (Microsoft\n  Research), Zach Bray (Type Inferred Ltd)", "title": "In the Age of Web: Typed Functional-First Programming Revisited", "comments": "In Proceedings ML/OCaml 2014, arXiv:1512.01438", "journal-ref": "EPTCS 198, 2015, pp. 64-79", "doi": "10.4204/EPTCS.198.3", "report-no": null, "categories": "cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most programming languages were designed before the age of web. This matters\nbecause the web changes many assumptions that typed functional language\ndesigners take for granted. For example, programs do not run in a closed world,\nbut must instead interact with (changing and likely unreliable) services and\ndata sources, communication is often asynchronous or event-driven, and programs\nneed to interoperate with untyped environments.\n  In this paper, we present how the F# language and libraries face the\nchallenges posed by the web. Technically, this comprises using type providers\nfor integration with external information sources and for integration with\nuntyped programming environments, using lightweight meta-programming for\ntargeting JavaScript and computation expressions for writing asynchronous code.\n  In this inquiry, the holistic perspective is more important than each of the\nfeatures in isolation. We use a practical case study as a starting point and\nlook at how F# language and libraries approach the challenges posed by the web.\nThe specific lessons learned are perhaps less interesting than our attempt to\nuncover hidden assumptions that no longer hold in the age of web.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2015 03:17:05 GMT"}], "update_date": "2015-12-08", "authors_parsed": [["Petricek", "Tomas", "", "University of Cambridge"], ["Syme", "Don", "", "Microsoft\n  Research"], ["Bray", "Zach", "", "Type Inferred Ltd"]]}, {"id": "1512.01897", "submitter": "EPTCS", "authors": "Arthur Chargu\\'eraud", "title": "Improving Type Error Messages in OCaml", "comments": "In Proceedings ML/OCaml 2014, arXiv:1512.01438", "journal-ref": "EPTCS 198, 2015, pp. 80-97", "doi": "10.4204/EPTCS.198.4", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cryptic type error messages are a major obstacle to learning OCaml or other\nML-based languages. In many cases, error messages cannot be interpreted without\na sufficiently-precise model of the type inference algorithm. The problem of\nimproving type error messages in ML has received quite a bit of attention over\nthe past two decades, and many different strategies have been considered. The\nchallenge is not only to produce error messages that are both sufficiently\nconcise and systematically useful to the programmer, but also to handle a\nfull-blown programming language and to cope with large-sized programs\nefficiently.\n  In this work, we present a modification to the traditional ML type inference\nalgorithm implemented in OCaml that, by significantly reducing the\nleft-to-right bias, allows us to report error messages that are more helpful to\nthe programmer. Our algorithm remains fully predictable and continues to\nproduce fairly concise error messages that always help making some progress\ntowards fixing the code. We implemented our approach as a patch to the OCaml\ncompiler in just a few hundred lines of code. We believe that this patch should\nbenefit not just to beginners, but also to experienced programs developing\nlarge-scale OCaml programs.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2015 03:17:30 GMT"}], "update_date": "2015-12-08", "authors_parsed": [["Chargu\u00e9raud", "Arthur", ""]]}, {"id": "1512.01898", "submitter": "EPTCS", "authors": "Akinori Abe, Eijiro Sumii", "title": "A Simple and Practical Linear Algebra Library Interface with Static Size\n  Checking", "comments": "In Proceedings ML/OCaml 2014, arXiv:1512.01438", "journal-ref": "EPTCS 198, 2015, pp. 1-21", "doi": "10.4204/EPTCS.198.1", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear algebra is a major field of numerical computation and is widely\napplied. Most linear algebra libraries (in most programming languages) do not\nstatically guarantee consistency of the dimensions of vectors and matrices,\ncausing runtime errors. While advanced type systems--specifically, dependent\ntypes on natural numbers--can ensure consistency among the sizes of collections\nsuch as lists and arrays, such type systems generally require non-trivial\nchanges to existing languages and application programs, or tricky type-level\nprogramming.\n  We have developed a linear algebra library interface that verifies the\nconsistency (with respect to dimensions) of matrix operations by means of\ngenerative phantom types, implemented via fairly standard ML types and module\nsystem. To evaluate its usability, we ported to it a practical machine learning\nlibrary from a traditional linear algebra library. We found that most of the\nchanges required for the porting could be made mechanically, and changes that\nneeded human thought are minor.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2015 03:17:50 GMT"}], "update_date": "2015-12-08", "authors_parsed": [["Abe", "Akinori", ""], ["Sumii", "Eijiro", ""]]}, {"id": "1512.02215", "submitter": "EPTCS", "authors": "Alexei Lisitsa (The University of Liverpool), Andrei P. Nemytykh\n  (Program Systems Institute of Russian Academy of Sciences), Alberto\n  Pettorossi (University of Roma Tor Vergata)", "title": "Proceedings of the Third International Workshop on Verification and\n  Program Transformation", "comments": null, "journal-ref": "EPTCS 199, 2015", "doi": "10.4204/EPTCS.199", "report-no": null, "categories": "cs.LO cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the papers selected among those which were presented at\nthe 3rd International Workshop on Verification and Program Transformation (VPT\n2015) held in London, UK, on April 11th, 2015. Previous editions of the\nWorkshop were held at Saint-Petersburg (Russia) in 2013, and Vienna (Austria)\nin 2014.\n  Those papers show that methods and tools developed in the field of program\ntransformation such as partial evaluation and fold/unfold transformations, and\nsupercompilation, can be applied in the verification of software systems. They\nalso show how some program verification methods, such as model checking\ntechniques, abstract interpretation, SAT and SMT solving, and automated theorem\nproving, can be used to enhance program transformation techniques, thereby\nmaking these techniques more powerful and useful in practice.\n", "versions": [{"version": "v1", "created": "Sun, 6 Dec 2015 00:30:58 GMT"}], "update_date": "2015-12-09", "authors_parsed": [["Lisitsa", "Alexei", "", "The University of Liverpool"], ["Nemytykh", "Andrei P.", "", "Program Systems Institute of Russian Academy of Sciences"], ["Pettorossi", "Alberto", "", "University of Roma Tor Vergata"]]}, {"id": "1512.02995", "submitter": "Anton Salikhmetov", "authors": "Anton Salikhmetov", "title": "A token-passing net implementation of optimal reduction with embedded\n  read-back", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a new interaction net implementation of optimal\nreduction for pure untyped lambda calculus. Unlike others, our implementation\nallows to reach normal form regardless of interaction net reduction strategy\nusing the approach of so-called token-passing nets. Another new feature is the\nread-back mechanism also implemented without leaving the formalism of\ninteraction nets.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2015 19:01:32 GMT"}, {"version": "v2", "created": "Mon, 14 Dec 2015 05:15:14 GMT"}], "update_date": "2015-12-15", "authors_parsed": [["Salikhmetov", "Anton", ""]]}, {"id": "1512.03207", "submitter": "Carl Friedrich Bolz", "authors": "Carl Friedrich Bolz, Darya Kurilova, Laurence Tratt", "title": "Making an Embedded DBMS JIT-friendly", "comments": "24 pages, 18 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.DB", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  While database management systems (DBMSs) are highly optimized, interactions\nacross the boundary between the programming language (PL) and the DBMS are\ncostly, even for in-process embedded DBMSs. In this paper, we show that\nprograms that interact with the popular embedded DBMS SQLite can be\nsignificantly optimized - by a factor of 3.4 in our benchmarks - by inlining\nacross the PL / DBMS boundary. We achieved this speed-up by replacing parts of\nSQLite's C interpreter with RPython code and composing the resulting\nmeta-tracing virtual machine (VM) - called SQPyte - with the PyPy VM. SQPyte\ndoes not compromise stand-alone SQL performance and is 2.2% faster than SQLite\non the widely used TPC-H benchmark suite.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2015 10:57:56 GMT"}, {"version": "v2", "created": "Tue, 10 May 2016 15:35:58 GMT"}, {"version": "v3", "created": "Fri, 27 May 2016 09:03:22 GMT"}, {"version": "v4", "created": "Mon, 20 Jun 2016 05:35:28 GMT"}], "update_date": "2016-06-21", "authors_parsed": [["Bolz", "Carl Friedrich", ""], ["Kurilova", "Darya", ""], ["Tratt", "Laurence", ""]]}, {"id": "1512.03859", "submitter": "EPTCS", "authors": "Alexei P. Lisitsa (Department of Computer Science, The University of\n  Liverpool), Andrei P. Nemytykh (Program Systems Institute, Russian Academy of\n  Sciences)", "title": "Finite Countermodel Based Verification for Program Transformation (A\n  Case Study)", "comments": "In Proceedings VPT 2015, arXiv:1512.02215", "journal-ref": "EPTCS 199, 2015, pp. 15-32", "doi": "10.4204/EPTCS.199.2", "report-no": null, "categories": "cs.SE cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Both automatic program verification and program transformation are based on\nprogram analysis. In the past decade a number of approaches using various\nautomatic general-purpose program transformation techniques (partial deduction,\nspecialization, supercompilation) for verification of unreachability properties\nof computing systems were introduced and demonstrated. On the other hand, the\nsemantics based unfold-fold program transformation methods pose themselves\ndiverse kinds of reachability tasks and try to solve them, aiming at improving\nthe semantics tree of the program being transformed. That means some\ngeneral-purpose verification methods may be used for strengthening program\ntransformation techniques. This paper considers the question how finite\ncountermodels for safety verification method might be used in Turchin's\nsupercompilation method. We extract a number of supercompilation sub-algorithms\ntrying to solve reachability problems and demonstrate use of an external\ncountermodel finder for solving some of the problems.\n", "versions": [{"version": "v1", "created": "Sat, 12 Dec 2015 01:59:00 GMT"}], "update_date": "2015-12-15", "authors_parsed": [["Lisitsa", "Alexei P.", "", "Department of Computer Science, The University of\n  Liverpool"], ["Nemytykh", "Andrei P.", "", "Program Systems Institute, Russian Academy of\n  Sciences"]]}, {"id": "1512.03860", "submitter": "EPTCS", "authors": "Geoff Hamilton (School of Computing, Dublin City University)", "title": "Verifying Temporal Properties of Reactive Systems by Transformation", "comments": "In Proceedings VPT 2015, arXiv:1512.02215. This work was supported,\n  in part, by Science Foundation Ireland grant 10/CE/I1855 to Lero - the Irish\n  Software Engineering Research Centre (www.lero.ie), and by the School of\n  Computing, Dublin City University", "journal-ref": "EPTCS 199, 2015, pp. 33-49", "doi": "10.4204/EPTCS.199.3", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how program transformation techniques can be used for the\nverification of both safety and liveness properties of reactive systems. In\nparticular, we show how the program transformation technique distillation can\nbe used to transform reactive systems specified in a functional language into a\nsimplified form that can subsequently be analysed to verify temporal properties\nof the systems. Example systems which are intended to model mutual exclusion\nare analysed using these techniques with respect to both safety (mutual\nexclusion) and liveness (non-starvation), with the errors they contain being\ncorrectly identified.\n", "versions": [{"version": "v1", "created": "Sat, 12 Dec 2015 01:59:09 GMT"}], "update_date": "2015-12-15", "authors_parsed": [["Hamilton", "Geoff", "", "School of Computing, Dublin City University"]]}, {"id": "1512.03861", "submitter": "EPTCS", "authors": "Martin Lester (Department of Computer Science, University of Oxford)", "title": "Control Flow Analysis for SF Combinator Calculus", "comments": "In Proceedings VPT 2015, arXiv:1512.02215", "journal-ref": "EPTCS 199, 2015, pp. 51-67", "doi": "10.4204/EPTCS.199.4", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Programs that transform other programs often require access to the internal\nstructure of the program to be transformed. This is at odds with the usual\nextensional view of functional programming, as embodied by the lambda calculus\nand SK combinator calculus. The recently-developed SF combinator calculus\noffers an alternative, intensional model of computation that may serve as a\nfoundation for developing principled languages in which to express intensional\ncomputation, including program transformation. Until now there have been no\nstatic analyses for reasoning about or verifying programs written in\nSF-calculus. We take the first step towards remedying this by developing a\nformulation of the popular control flow analysis 0CFA for SK-calculus and\nextending it to support SF-calculus. We prove its correctness and demonstrate\nthat the analysis is invariant under the usual translation from SK-calculus\ninto SF-calculus.\n", "versions": [{"version": "v1", "created": "Sat, 12 Dec 2015 01:59:18 GMT"}], "update_date": "2015-12-15", "authors_parsed": [["Lester", "Martin", "", "Department of Computer Science, University of Oxford"]]}, {"id": "1512.04013", "submitter": "Andrew Santosa", "authors": "Andrew E. Santosa", "title": "Comparing Weakest Precondition and Weakest Liberal Precondition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we investigate the relationships between the classical\nnotions of weakest precondition and weakest liberal precondition, and provide\nseveral results, namely that in general, weakest liberal precondition is\nneither stronger nor weaker than weakest precondition, however, given a\ndeterministic and terminating sequential while program and a postcondition,\nthey are equivalent. Hence, in such situation, it does not matter which\ndefinition is used.\n", "versions": [{"version": "v1", "created": "Sun, 13 Dec 2015 07:32:01 GMT"}], "update_date": "2015-12-15", "authors_parsed": [["Santosa", "Andrew E.", ""]]}, {"id": "1512.06178", "submitter": "EPTCS", "authors": "Marisa Navarro (UPV/EHU)", "title": "Proceedings XV Jornadas sobre Programaci\\'on y Lenguajes", "comments": null, "journal-ref": "EPTCS 200, 2015", "doi": "10.4204/EPTCS.200", "report-no": null, "categories": "cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains a selection of the papers presented at the XV Jornadas\nsobre Programaci\\'on y Lenguajes (PROLE 2015), held at Santander, Spain, during\nSeptember 15th-17th, 2015. Previous editions of the workshop were held in\nC\\'adiz (2014), Madrid (2013), Almer\\'ia (2012), A Coru\\~na (2011), Val\\`encia\n(2010), San Sebasti\\'an (2009), Gij\\'on (2008), Zaragoza (2007), Sitges (2006),\nGranada (2005), M\\'alaga (2004), Alicante (2003), El Escorial (2002), and\nAlmagro (2001). Programming languages provide a conceptual framework which is\nnecessary for the development, analysis, optimization and understanding of\nprograms and programming tasks. The aim of the PROLE series of conferences\n(PROLE stems from PROgramaci\\'on y LEnguajes) is to serve as a meeting point\nfor Spanish research groups which develop their work in the area of programming\nand programming languages. The organization of this series of events aims at\nfostering the exchange of ideas, experiences and results among these groups.\nPromoting further collaboration is also one of its main goals.\n", "versions": [{"version": "v1", "created": "Sat, 19 Dec 2015 02:15:49 GMT"}], "update_date": "2015-12-22", "authors_parsed": [["Navarro", "Marisa", "", "UPV/EHU"]]}, {"id": "1512.06941", "submitter": "EPTCS", "authors": "Mar\\'ia Alpuente (DSIC-UPV), Daniel Pardo (DSIC-UPV), Alicia\n  Villanueva (DSIC-UPV)", "title": "Automatic Inference of Specifications in the K Framework", "comments": "In Proceedings PROLE 2015, arXiv:1512.06178", "journal-ref": "EPTCS 200, 2015, pp. 1-17", "doi": "10.4204/EPTCS.200.1", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite its many unquestionable benefits, formal specifications are not\nwidely used in industrial software development. In order to reduce the time and\neffort required to write formal specifications, in this paper we propose a\ntechnique for automatically discovering specifications from real code. The\nproposed methodology relies on the symbolic execution capabilities recently\nprovided by the K framework that we exploit to automatically infer formal\nspecifications from programs that are written in a non-trivial fragment of C,\ncalled KernelC. Roughly speaking, our symbolic analysis of KernelC programs\nexplains the execution of a (modifier) function by using other (observer)\nroutines in the program. We implemented our technique in the automated tool\nKindspec 2.0, which generates axioms that describe the precise input/output\nbehavior of C routines that handle pointer-based structures (i.e., result\nvalues and state change). We describe the implementation of our system and\ndiscuss the differences w.r.t. our previous work on inferring specifications\nfrom C code.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2015 03:16:11 GMT"}], "update_date": "2015-12-23", "authors_parsed": [["Alpuente", "Mar\u00eda", "", "DSIC-UPV"], ["Pardo", "Daniel", "", "DSIC-UPV"], ["Villanueva", "Alicia", "", "DSIC-UPV"]]}, {"id": "1512.06942", "submitter": "EPTCS", "authors": "Salvador Lucas (DSIC, Universitat Polit\\`ecnica de Val\\`encia, Spain)", "title": "Termination of canonical context-sensitive rewriting and productivity of\n  rewrite systems", "comments": "In Proceedings PROLE 2015, arXiv:1512.06178", "journal-ref": "EPTCS 200, 2015, pp. 18-31", "doi": "10.4204/EPTCS.200.2", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Termination of programs, i.e., the absence of infinite computations, ensures\nthe existence of normal forms for all initial expressions, thus providing an\nessential ingredient for the definition of a normalization semantics for\nfunctional programs. In lazy functional languages, though, infinite data\nstructures are often delivered as the outcome of computations. For instance,\nthe list of all prime numbers can be returned as a neverending stream of\nnumerical expressions or data structures. If such streams are allowed,\nrequiring termination is hopeless. In this setting, the notion of productivity\ncan be used to provide an account of computations with infinite data\nstructures, as it \"captures the idea of computability, of progress of\ninfinite-list programs\" (B.A. Sijtsma, On the Productivity of Recursive List\nDefinitions, ACM Transactions on Programming Languages and Systems\n11(4):633-649, 1989). However, in the realm of Term Rewriting Systems, which\ncan be seen as (first-order, untyped, unconditional) functional programs,\ntermination of Context-Sensitive Rewriting (CSR) has been showed equivalent to\nproductivity of rewrite systems through appropriate transformations. In this\nway, tools for proving termination of CSR can be used to prove productivity. In\nterm rewriting, CSR is the restriction of rewriting that arises when reductions\nare allowed on selected arguments of function symbols only. In this paper we\nshow that well-known results about the computational power of CSR are useful to\nbetter understand the existing connections between productivity of rewrite\nsystems and termination of CSR, and also to obtain more powerful techniques to\nprove productivity of rewrite systems.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2015 03:16:22 GMT"}], "update_date": "2015-12-23", "authors_parsed": [["Lucas", "Salvador", "", "DSIC, Universitat Polit\u00e8cnica de Val\u00e8ncia, Spain"]]}, {"id": "1512.06943", "submitter": "EPTCS", "authors": "Salvador Lucas (DSIC, Universitat Polit\\`ecnica de Val\\`encia, Spain)", "title": "Synthesis of models for order-sorted first-order theories using linear\n  algebra and constraint solving", "comments": "In Proceedings PROLE 2015, arXiv:1512.06178", "journal-ref": "EPTCS 200, 2015, pp. 32-47", "doi": "10.4204/EPTCS.200.3", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent developments in termination analysis for declarative programs\nemphasize the use of appropriate models for the logical theory representing the\nprogram at stake as a generic approach to prove termination of declarative\nprograms. In this setting, Order-Sorted First-Order Logic provides a powerful\nframework to represent declarative programs. It also provides a target logic to\nobtain models for other logics via transformations. We investigate the\nautomatic generation of numerical models for order-sorted first-order logics\nand its use in program analysis, in particular in termination analysis of\ndeclarative programs. We use convex domains to give domains to the different\nsorts of an order-sorted signature; we interpret the ranked symbols of sorted\nsignatures by means of appropriately adapted convex matrix interpretations.\nSuch numerical interpretations permit the use of existing algorithms and tools\nfrom linear algebra and arithmetic constraint solving to synthesize the models.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2015 03:16:34 GMT"}], "update_date": "2015-12-23", "authors_parsed": [["Lucas", "Salvador", "", "DSIC, Universitat Polit\u00e8cnica de Val\u00e8ncia, Spain"]]}, {"id": "1512.06947", "submitter": "EPTCS", "authors": "Jos\\'e Proen\\c{c}a, Massimo Tivoli", "title": "Proceedings 14th International Workshop on Foundations of Coordination\n  Languages and Self-Adaptive Systems", "comments": null, "journal-ref": "EPTCS 201, 2015", "doi": "10.4204/EPTCS.201", "report-no": null, "categories": "cs.DC cs.LO cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the proceedings of FOCLASA 2015, the 14th International\nWorkshop on the Foundations of Coordination Languages and Self-Adaptive\nSystems. FOCLASA 2015 was held in Madrid, Spain, on September 5, 2015 as a\nsatellite event of CONCUR 2015, the 26th International Conference on\nConcurrency Theory.\n  Modern software systems are distributed, concurrent, mobile, and often\ninvolve composition of heterogeneous components and stand-alone services.\nService coordination and self-adaptation constitute the core characteristics of\ndistributed and service-oriented systems. Coordination languages and formal\napproaches to modelling and reasoning about self-adaptive behaviour help to\nsimplify the development of complex distributed service-based systems, enable\nfunctional correctness proofs, automated synthesis of correct-by-construction\nsystems, and improve reusability and maintainability of such systems. The goal\nof the FOCLASA workshop is to put together researchers and practitioners of the\naforementioned fields, to share and identify common problems, and to devise\ngeneral solutions in the context of coordination languages and self-adaptive\nsystems.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2015 03:30:13 GMT"}], "update_date": "2015-12-23", "authors_parsed": [["Proen\u00e7a", "Jos\u00e9", ""], ["Tivoli", "Massimo", ""]]}, {"id": "1512.07067", "submitter": "Brodu Etienne", "authors": "Etienne Brodu (DICE), St\\'ephane Fr\\'enot (DICE), Fr\\'ed\\'eric Obl\\'e", "title": "Transforming Javascript Event-Loop Into a Pipeline", "comments": null, "journal-ref": "Symposium on Applied Computing, Apr 2016, Pisa, Italy. 2016,\n  http://www.acm.org/conferences/sac/sac2016/", "doi": "10.1145/2851613.2851745", "report-no": null, "categories": "cs.PL cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of a real-time web application often starts with a\nfeature-driven approach allowing to quickly react to users feedbacks. However,\nthis approach poorly scales in performance. Yet, the user-base can increase by\nan order of magnitude in a matter of hours. This first approach is unable to\ndeal with the highest connections spikes. It leads the development team to\nshift to a scalable approach often linked to new development paradigm such as\ndataflow programming. This shift of technology is disruptive and\ncontinuity-threatening. To avoid it, we propose to abstract the feature-driven\ndevelopment into a more scalable high-level language. Indeed, reasoning on this\nhigh-level language allows to dynamically cope with user-base size evolutions.\nWe propose a compilation approach that transforms a Javascript, single-threaded\nreal-time web application into a network of small independent parts\ncommunicating by message streams. We named these parts fluxions, by contraction\nbetween a flow (flux in french) and a function. The independence of these parts\nallows their execution to be parallel, and to organize an application on\nseveral processors to cope with its load, in a similar way network routers do\nwith IP traffic. We test this approach by applying the compiler to a real web\napplication. We transform this application to parallelize the execution of an\nindependent part and present the result.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2015 13:01:48 GMT"}], "update_date": "2015-12-23", "authors_parsed": [["Brodu", "Etienne", "", "DICE"], ["Fr\u00e9not", "St\u00e9phane", "", "DICE"], ["Obl\u00e9", "Fr\u00e9d\u00e9ric", ""]]}, {"id": "1512.07681", "submitter": "EPTCS", "authors": "Andrea Canciani (Dipartimento di Informatica, Universit\\`a di Pisa,\n  Pisa, Italy), Pierpaolo Degano (Dipartimento di Informatica, Universit\\`a di\n  Pisa, Pisa, Italy), Gian-Luigi Ferrari (Dipartimento di Informatica,\n  Universit\\`a di Pisa, Pisa, Italy), Letterio Galletta (Dipartimento di\n  Informatica, Universit\\`a di Pisa, Pisa, Italy)", "title": "A Context-Oriented Extension of F#", "comments": "In Proceedings FOCLASA 2015, arXiv:1512.06947", "journal-ref": "EPTCS 201, 2015, pp. 18-32", "doi": "10.4204/EPTCS.201.2", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Context-Oriented programming languages provide us with primitive constructs\nto adapt program behaviour depending on the evolution of their operational\nenvironment, namely the context. In previous work we proposed ML_CoDa, a\ncontext-oriented language with two-components: a declarative constituent for\nprogramming the context and a functional one for computing. This paper\ndescribes the implementation of ML_CoDa as an extension of F#.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2015 01:39:47 GMT"}], "update_date": "2015-12-25", "authors_parsed": [["Canciani", "Andrea", "", "Dipartimento di Informatica, Universit\u00e0 di Pisa,\n  Pisa, Italy"], ["Degano", "Pierpaolo", "", "Dipartimento di Informatica, Universit\u00e0 di\n  Pisa, Pisa, Italy"], ["Ferrari", "Gian-Luigi", "", "Dipartimento di Informatica,\n  Universit\u00e0 di Pisa, Pisa, Italy"], ["Galletta", "Letterio", "", "Dipartimento di\n  Informatica, Universit\u00e0 di Pisa, Pisa, Italy"]]}, {"id": "1512.08990", "submitter": "Marcin Szymczak", "authors": "Johannes Borgstr\\\"om and Ugo Dal Lago and Andrew D. Gordon and Marcin\n  Szymczak", "title": "A Lambda-Calculus Foundation for Universal Probabilistic Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We develop the operational semantics of an untyped probabilistic\nlambda-calculus with continuous distributions, as a foundation for universal\nprobabilistic programming languages such as Church, Anglican, and Venture. Our\nfirst contribution is to adapt the classic operational semantics of\nlambda-calculus to a continuous setting via creating a measure space on terms\nand defining step-indexed approximations. We prove equivalence of big-step and\nsmall-step formulations of this distribution-based semantics. To move closer to\ninference techniques, we also define the sampling-based semantics of a term as\na function from a trace of random samples to a value. We show that the\ndistribution induced by integrating over all traces equals the\ndistribution-based semantics. Our second contribution is to formalize the\nimplementation technique of trace Markov chain Monte Carlo (MCMC) for our\ncalculus and to show its correctness. A key step is defining sufficient\nconditions for the distribution induced by trace MCMC to converge to the\ndistribution-based semantics. To the best of our knowledge, this is the first\nrigorous correctness proof for trace MCMC for a higher-order functional\nlanguage.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2015 16:15:30 GMT"}, {"version": "v2", "created": "Mon, 18 Apr 2016 15:24:48 GMT"}, {"version": "v3", "created": "Fri, 22 Apr 2016 11:32:59 GMT"}, {"version": "v4", "created": "Thu, 19 May 2016 10:01:54 GMT"}, {"version": "v5", "created": "Mon, 23 Jan 2017 10:14:36 GMT"}], "update_date": "2017-01-24", "authors_parsed": [["Borgstr\u00f6m", "Johannes", ""], ["Lago", "Ugo Dal", ""], ["Gordon", "Andrew D.", ""], ["Szymczak", "Marcin", ""]]}, {"id": "1512.09369", "submitter": "Pedro Lopez-Garcia", "authors": "Pedro Lopez-Garcia and Remy Haemmerle and Maximiliano Klemen and Umer\n  Liqat and Manuel V. Hermenegildo", "title": "Towards Energy Consumption Verification via Static Analysis", "comments": "Presented at HIP3ES, 2015 (arXiv: 1501.03064)", "journal-ref": null, "doi": null, "report-no": "HIP3ES/2015/04", "categories": "cs.PL cs.DC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we leverage an existing general framework for resource usage\nverification and specialize it for verifying energy consumption specifications\nof embedded programs. Such specifications can include both lower and upper\nbounds on energy usage, and they can express intervals within which energy\nusage is to be certified to be within such bounds. The bounds of the intervals\ncan be given in general as functions on input data sizes. Our verification\nsystem can prove whether such energy usage specifications are met or not. It\ncan also infer the particular conditions under which the specifications hold.\nTo this end, these conditions are also expressed as intervals of functions of\ninput data sizes, such that a given specification can be proved for some\nintervals but disproved for others. The specifications themselves can also\ninclude preconditions expressing intervals for input data sizes. We report on a\nprototype implementation of our approach within the CiaoPP system for the XC\nlanguage and XS1-L architecture, and illustrate with an example how embedded\nsoftware developers can use this tool, and in particular for determining values\nfor program parameters that ensure meeting a given energy budget while\nminimizing the loss in quality of service.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2015 20:57:50 GMT"}], "update_date": "2016-01-01", "authors_parsed": [["Lopez-Garcia", "Pedro", ""], ["Haemmerle", "Remy", ""], ["Klemen", "Maximiliano", ""], ["Liqat", "Umer", ""], ["Hermenegildo", "Manuel V.", ""]]}]