[{"id": "1703.00053", "submitter": "Catalin Hritcu", "authors": "Jonathan Protzenko, Jean-Karim Zinzindohou\\'e, Aseem Rastogi, Tahina\n  Ramananandro, Peng Wang, Santiago Zanella-B\\'eguelin, Antoine\n  Delignat-Lavaud, Catalin Hritcu, Karthikeyan Bhargavan, C\\'edric Fournet and\n  Nikhil Swamy", "title": "Verified Low-Level Programming Embedded in F*", "comments": "extended version of ICFP final camera ready version; only\n  Acknowledgements differ from 30 Aug 2017 version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present Low*, a language for low-level programming and verification, and\nits application to high-assurance optimized cryptographic libraries. Low* is a\nshallow embedding of a small, sequential, well-behaved subset of C in F*, a\ndependently-typed variant of ML aimed at program verification. Departing from\nML, Low* does not involve any garbage collection or implicit heap allocation;\ninstead, it has a structured memory model \\`a la CompCert, and it provides the\ncontrol required for writing efficient low-level security-critical code.\n  By virtue of typing, any Low* program is memory safe. In addition, the\nprogrammer can make full use of the verification power of F* to write\nhigh-level specifications and verify the functional correctness of Low* code\nusing a combination of SMT automation and sophisticated manual proofs. At\nextraction time, specifications and proofs are erased, and the remaining code\nenjoys a predictable translation to C. We prove that this translation preserves\nsemantics and side-channel resistance.\n  We provide a new compiler back-end from Low* to C and, to evaluate our\napproach, we implement and verify various cryptographic algorithms,\nconstructions, and tools for a total of about 28,000 lines of code,\nspecification and proof. We show that our Low* code delivers performance\ncompetitive with existing (unverified) C cryptographic libraries, suggesting\nour approach may be applicable to larger-scale low-level software.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2017 20:53:33 GMT"}, {"version": "v2", "created": "Thu, 2 Mar 2017 09:00:51 GMT"}, {"version": "v3", "created": "Sat, 24 Jun 2017 10:28:26 GMT"}, {"version": "v4", "created": "Tue, 27 Jun 2017 18:41:01 GMT"}, {"version": "v5", "created": "Wed, 30 Aug 2017 06:25:59 GMT"}, {"version": "v6", "created": "Tue, 11 Dec 2018 12:56:19 GMT"}], "update_date": "2018-12-12", "authors_parsed": [["Protzenko", "Jonathan", ""], ["Zinzindohou\u00e9", "Jean-Karim", ""], ["Rastogi", "Aseem", ""], ["Ramananandro", "Tahina", ""], ["Wang", "Peng", ""], ["Zanella-B\u00e9guelin", "Santiago", ""], ["Delignat-Lavaud", "Antoine", ""], ["Hritcu", "Catalin", ""], ["Bhargavan", "Karthikeyan", ""], ["Fournet", "C\u00e9dric", ""], ["Swamy", "Nikhil", ""]]}, {"id": "1703.00055", "submitter": "Catalin Hritcu", "authors": "Niklas Grimm, Kenji Maillard, C\\'edric Fournet, Catalin Hritcu, Matteo\n  Maffei, Jonathan Protzenko, Tahina Ramananandro, Aseem Rastogi, Nikhil Swamy,\n  Santiago Zanella-B\\'eguelin", "title": "A Monadic Framework for Relational Verification: Applied to Information\n  Security, Program Equivalence, and Optimizations", "comments": "CPP'18 extended version with the missing ERC acknowledgement", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Relational properties describe multiple runs of one or more programs. They\ncharacterize many useful notions of security, program refinement, and\nequivalence for programs with diverse computational effects, and they have\nreceived much attention in the recent literature. Rather than developing\nseparate tools for special classes of effects and relational properties, we\nadvocate using a general purpose proof assistant as a unifying framework for\nthe relational verification of effectful programs. The essence of our approach\nis to model effectful computations using monads and to prove relational\nproperties on their monadic representations, making the most of existing\nsupport for reasoning about pure programs.\n  We apply this method in F* and evaluate it by encoding a variety of\nrelational program analyses, including information flow control, program\nequivalence and refinement at higher order, correctness of program\noptimizations and game-based cryptographic security. By relying on SMT-based\nautomation, unary weakest preconditions, user-defined effects, and monadic\nreification, we show that, compared to unary properties, verifying relational\nproperties requires little additional effort from the F* programmer.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2017 21:04:50 GMT"}, {"version": "v2", "created": "Thu, 2 Mar 2017 19:29:14 GMT"}, {"version": "v3", "created": "Sat, 8 Jul 2017 16:47:18 GMT"}, {"version": "v4", "created": "Thu, 13 Jul 2017 15:00:38 GMT"}, {"version": "v5", "created": "Thu, 12 Oct 2017 14:53:34 GMT"}, {"version": "v6", "created": "Mon, 27 Nov 2017 14:15:55 GMT"}, {"version": "v7", "created": "Sat, 12 Oct 2019 10:56:42 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Grimm", "Niklas", ""], ["Maillard", "Kenji", ""], ["Fournet", "C\u00e9dric", ""], ["Hritcu", "Catalin", ""], ["Maffei", "Matteo", ""], ["Protzenko", "Jonathan", ""], ["Ramananandro", "Tahina", ""], ["Rastogi", "Aseem", ""], ["Swamy", "Nikhil", ""], ["Zanella-B\u00e9guelin", "Santiago", ""]]}, {"id": "1703.00659", "submitter": "Marco Carbone", "authors": "Mario Bravetti and Marco Carbone and Gianluigi Zavattaro", "title": "On the Boundary between Decidability and Undecidability of Asynchronous\n  Session Subtyping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Session types are behavioural types for guaranteeing that concurrent programs\nare free from basic communication errors. Recent work has shown that\nasynchronous session subtyping is undecidable. However, since session types\nhave become popular in mainstream programming languages in which asynchronous\ncommunication is the norm rather than the exception, it is crucial to detect\nsignificant decidable subtyping relations. Previous work considered extremely\nrestrictive fragments in which limitations were imposed to the size of\ncommunication buffer (at most 1) or to the possibility to express multiple\nchoices (disallowing them completely in one of the compared types). In this\nwork, for the first time, we show decidability of a fragment that does not\nimpose any limitation on communication buffers and allows both the compared\ntypes to include multiple choices for either input or output, thus yielding a\nfragment which is more significant from an applicability viewpoint. In general,\nwe study the boundary between decidability and undecidability by considering\nseveral fragments of subtyping. Notably, we show that subtyping remains\nundecidable even if restricted to not using output covariance and input\ncontravariance.\n", "versions": [{"version": "v1", "created": "Thu, 2 Mar 2017 08:14:33 GMT"}, {"version": "v2", "created": "Fri, 9 Feb 2018 09:41:17 GMT"}, {"version": "v3", "created": "Mon, 12 Feb 2018 09:28:35 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Bravetti", "Mario", ""], ["Carbone", "Marco", ""], ["Zavattaro", "Gianluigi", ""]]}, {"id": "1703.01192", "submitter": "Breck Yunits", "authors": "Breck Yunits", "title": "Tree Notation: an antifragile program notation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents Tree Notation, a new simple, universal syntax. Language\ndesigners can invent new programming languages, called Tree Languages, on top\nof Tree Notation. Tree Languages have a number of advantages over traditional\nprogramming languages.\n  We include a Visual Abstract to succinctly display the problem and discovery.\nThen we describe the problem--the BNF to abstract syntax tree (AST) parse\nstep--and introduce the novel solution we discovered: a new family of 2D\nprogramming languages that are written directly as geometric trees.\n", "versions": [{"version": "v1", "created": "Fri, 3 Mar 2017 14:53:18 GMT"}, {"version": "v2", "created": "Mon, 12 Jun 2017 14:07:34 GMT"}, {"version": "v3", "created": "Tue, 13 Jun 2017 00:54:46 GMT"}, {"version": "v4", "created": "Fri, 16 Jun 2017 05:34:35 GMT"}, {"version": "v5", "created": "Tue, 20 Jun 2017 04:54:04 GMT"}, {"version": "v6", "created": "Wed, 21 Jun 2017 10:15:19 GMT"}, {"version": "v7", "created": "Mon, 23 Oct 2017 18:24:52 GMT"}], "update_date": "2017-10-25", "authors_parsed": [["Yunits", "Breck", ""]]}, {"id": "1703.01288", "submitter": "G. A. Kavvos", "authors": "G. A. Kavvos", "title": "Intensionality, Intensional Recursion, and the G\\\"odel-L\\\"ob axiom", "comments": "Presented at IMLA 2017. Revised version following post-conference\n  review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of a necessity modality in a typed $\\lambda$-calculus can be used to\nseparate it into two regions. These can be thought of as intensional vs.\nextensional data: data in the first region, the modal one, are available as\ncode, and their description can be examined. In contrast, data in the second\nregion are only available as values up to ordinary equality. This allows us to\nadd non-functional operations at modal types whilst maintaining consistency. In\nthis setting, the G\\\"odel-L\\\"ob axiom acquires a novel constructive reading: it\naffords the programmer the possibility of a very strong kind of recursion which\nenables them to write programs that have access to their own code. This is a\ntype of computational reflection that is strongly reminiscent of Kleene's\nSecond Recursion Theorem.\n", "versions": [{"version": "v1", "created": "Fri, 3 Mar 2017 18:54:38 GMT"}, {"version": "v2", "created": "Sat, 13 Jun 2020 13:13:08 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Kavvos", "G. A.", ""]]}, {"id": "1703.01690", "submitter": "Marco Tulio Valente", "authors": "Leonardo Humberto Silva, Marco Tulio Valente, Alexandre Bergel", "title": "Refactoring Legacy JavaScript Code to Use Classes: The Good, The Bad and\n  The Ugly", "comments": "Paper accepted at 16th International Conference on Software Reuse\n  (ICSR), 2017; 16 pages", "journal-ref": null, "doi": "10.1007/978-3-319-56856-0_11", "report-no": null, "categories": "cs.SE cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  JavaScript systems are becoming increasingly complex and large. To tackle the\nchallenges involved in implementing these systems, the language is evolving to\ninclude several constructions for programming- in-the-large. For example,\nalthough the language is prototype-based, the latest JavaScript standard, named\nECMAScript 6 (ES6), provides native support for implementing classes. Even\nthough most modern web browsers support ES6, only a very few applications use\nthe class syntax. In this paper, we analyze the process of migrating structures\nthat emulate classes in legacy JavaScript code to adopt the new syntax for\nclasses introduced by ES6. We apply a set of migration rules on eight legacy\nJavaScript systems. In our study, we document: (a) cases that are\nstraightforward to migrate (the good parts); (b) cases that require manual and\nad-hoc migration (the bad parts); and (c) cases that cannot be migrated due to\nlimitations and restrictions of ES6 (the ugly parts). Six out of eight systems\n(75%) contain instances of bad and/or ugly cases. We also collect the\nperceptions of JavaScript developers about migrating their code to use the new\nsyntax for classes.\n", "versions": [{"version": "v1", "created": "Sun, 5 Mar 2017 23:19:01 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Silva", "Leonardo Humberto", ""], ["Valente", "Marco Tulio", ""], ["Bergel", "Alexandre", ""]]}, {"id": "1703.02312", "submitter": "Ahmad Salim Al-Sibahi", "authors": "Ahmad Salim Al-Sibahi", "title": "The Formal Semantics of Rascal Light", "comments": "Revision: Minor fixes to proofs and rules", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Rascal is a high-level transformation language that aims to simplify software\nlanguage engineering tasks like defining program syntax, analyzing and\ntransforming programs, and performing code generation. The language provides\nseveral features including built-in collections (lists, sets, maps), algebraic\ndata-types, powerful pattern matching operations with backtracking, and\nhigh-level traversals supporting multiple strategies. Interaction between\ndifferent language features can be difficult to comprehend, since most features\nare semantically rich. The report provides a well-defined formal semantics for\na large subset of Rascal, called Rascal Light, suitable for developing formal\ntechniques, e.g., type systems and static analyses. Additionally, the report\nstates and proofs a series of interesting properties of the semantics,\nincluding purity of backtracking, strong typing, partial progress and the\nexistence of a terminating subset.\n", "versions": [{"version": "v1", "created": "Tue, 7 Mar 2017 10:22:07 GMT"}, {"version": "v2", "created": "Mon, 19 Jun 2017 09:46:13 GMT"}, {"version": "v3", "created": "Mon, 23 Oct 2017 10:12:17 GMT"}, {"version": "v4", "created": "Tue, 6 Feb 2018 11:28:18 GMT"}], "update_date": "2018-02-07", "authors_parsed": [["Al-Sibahi", "Ahmad Salim", ""]]}, {"id": "1703.02394", "submitter": "Petr Ro\\v{c}kai", "authors": "Vladim\\'ir \\v{S}till and Petr Ro\\v{c}kai and Ji\\v{r}\\'i Barnat", "title": "Using Off-the-Shelf Exception Support Components in C++ Verification", "comments": null, "journal-ref": null, "doi": "10.1109/QRS.2017.15", "report-no": null, "categories": "cs.SE cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important step toward adoption of formal methods in software development\nis support for mainstream programming languages. Unfortunately, these languages\nare often rather complex and come with substantial standard libraries. However,\nby choosing a suitable intermediate language, most of the complexity can be\ndelegated to existing execution-oriented (as opposed to verification-oriented)\ncompiler frontends and standard library implementations. In this paper, we\ndescribe how support for C++ exceptions can take advantage of the same\nprinciple. Our work is based on DiVM, an LLVM-derived, verification-friendly\nintermediate language.\n  Our implementation consists of 2 parts: an implementation of the `libunwind`\nplatform API which is linked to the program under test and consists of 9 C\nfunctions. The other part is a preprocessor for LLVM bitcode which prepares\nexception-related metadata and replaces associated special-purpose LLVM\ninstructions.\n", "versions": [{"version": "v1", "created": "Tue, 7 Mar 2017 14:16:07 GMT"}, {"version": "v2", "created": "Thu, 31 May 2018 11:57:33 GMT"}], "update_date": "2018-06-01", "authors_parsed": [["\u0160till", "Vladim\u00edr", ""], ["Ro\u010dkai", "Petr", ""], ["Barnat", "Ji\u0159\u00ed", ""]]}, {"id": "1703.02873", "submitter": "Pansy Arafa", "authors": "Pansy Arafa, Hany Kashif, and Sebastian Fischmeister", "title": "Redundancy Suppression In Time-Aware Dynamic Binary Instrumentation", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.PF cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software tracing techniques are well-established and used by instrumentation\ntools to extract run-time information for program analysis and debugging.\nDynamic binary instrumentation as one tool instruments program binaries to\nextract information. Unfortunately, instrumentation causes perturbation that is\nunacceptable for time-sensitive applications. Consequently we developed DIME*,\na tool for dynamic binary instrumentation that considers timing constraints.\nDIME* uses Pin and a rate-based server approach to extract information only as\nlong as user-specified constraints are maintained. Due to the large amount of\nredundancies in program traces, DIME* reduces the instrumentation overhead by\none to three orders of magnitude compared to native Pin while extracting up to\n99% of the information. We instrument VLC and PostgreSQL to demonstrate the\nusability of DIME*.\n", "versions": [{"version": "v1", "created": "Tue, 7 Mar 2017 14:40:58 GMT"}], "update_date": "2017-03-09", "authors_parsed": [["Arafa", "Pansy", ""], ["Kashif", "Hany", ""], ["Fischmeister", "Sebastian", ""]]}, {"id": "1703.03539", "submitter": "Oleksandr Polozov", "authors": "Vu Le, Daniel Perelman, Oleksandr Polozov, Mohammad Raza, Abhishek\n  Udupa, Sumit Gulwani", "title": "Interactive Program Synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Program synthesis from incomplete specifications (e.g. input-output examples)\nhas gained popularity and found real-world applications, primarily due to its\nease-of-use. Since this technology is often used in an interactive setting,\nefficiency and correctness are often the key user expectations from a system\nbased on such technologies. Ensuring efficiency is challenging since the highly\ncombinatorial nature of program synthesis algorithms does not fit in a 1-2\nsecond response expectation of a user-facing system. Meeting correctness\nexpectations is also difficult, given that the specifications provided are\nincomplete, and that the users of such systems are typically non-programmers.\n  In this paper, we describe how interactivity can be leveraged to develop\nefficient synthesis algorithms, as well as to decrease the cognitive burden\nthat a user endures trying to ensure that the system produces the desired\nprogram. We build a formal model of user interaction along three dimensions:\nincremental algorithm, step-based problem formulation, and feedback-based\nintent refinement. We then illustrate the effectiveness of each of these forms\nof interactivity with respect to synthesis performance and correctness on a set\nof real-world case studies.\n", "versions": [{"version": "v1", "created": "Fri, 10 Mar 2017 04:05:04 GMT"}], "update_date": "2017-03-13", "authors_parsed": [["Le", "Vu", ""], ["Perelman", "Daniel", ""], ["Polozov", "Oleksandr", ""], ["Raza", "Mohammad", ""], ["Udupa", "Abhishek", ""], ["Gulwani", "Sumit", ""]]}, {"id": "1703.05042", "submitter": "Alejandro Aguirre", "authors": "Alejandro Aguirre, Gilles Barthe, Marco Gaboardi, Deepak Garg,\n  Pierre-Yves Strub", "title": "A Relational Logic for Higher-Order Programs", "comments": "Submitted to ICFP 2017", "journal-ref": "J. Funct. Prog. 29 (2019) e16", "doi": "10.1017/S0956796819000145", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relational program verification is a variant of program verification where\none can reason about two programs and as a special case about two executions of\na single program on different inputs. Relational program verification can be\nused for reasoning about a broad range of properties, including equivalence and\nrefinement, and specialized notions such as continuity, information flow\nsecurity or relative cost. In a higher-order setting, relational program\nverification can be achieved using relational refinement type systems, a form\nof refinement types where assertions have a relational interpretation.\nRelational refinement type systems excel at relating structurally equivalent\nterms but provide limited support for relating terms with very different\nstructures.\n  We present a logic, called Relational Higher Order Logic (RHOL), for proving\nrelational properties of a simply typed $\\lambda$-calculus with inductive types\nand recursive definitions. RHOL retains the type-directed flavour of relational\nrefinement type systems but achieves greater expressivity through rules which\nsimultaneously reason about the two terms as well as rules which only\ncontemplate one of the two terms. We show that RHOL has strong foundations, by\nproving an equivalence with higher-order logic (HOL), and leverage this\nequivalence to derive key meta-theoretical properties: subject reduction,\nadmissibility of a transitivity rule and set-theoretical soundness. Moreover,\nwe define sound embeddings for several existing relational type systems such as\nrelational refinement types and type systems for dependency analysis and\nrelative cost, and we verify examples that were out of reach of prior work.\n", "versions": [{"version": "v1", "created": "Wed, 15 Mar 2017 09:32:27 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Aguirre", "Alejandro", ""], ["Barthe", "Gilles", ""], ["Gaboardi", "Marco", ""], ["Garg", "Deepak", ""], ["Strub", "Pierre-Yves", ""]]}, {"id": "1703.05185", "submitter": "Manuel Mazzara", "authors": "Manuel Mazzara", "title": "Designing a pi-based Programming Language in the .NET framework: CLR\n  interoperability from the Programmer's point of view", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interoperability is the ability of a programming language to work with\nsystems based on different languages and paradigms. These days, many widely\nused high-level language impementations provide access to external\nfunctionalities. In this paper, we present some ideas on CLR interoperability\nfocusing on the kind of constructs desirable by a programmer to this regard.\n", "versions": [{"version": "v1", "created": "Wed, 15 Mar 2017 14:40:21 GMT"}], "update_date": "2017-03-16", "authors_parsed": [["Mazzara", "Manuel", ""]]}, {"id": "1703.05186", "submitter": "Manuel Mazzara", "authors": "Evgenii Akentev, Alexander Tchitchigin, Larisa Safina, Manuel Mazzara", "title": "Verified type checker for Jolie programming language", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Jolie is a service-oriented programming language which comes with the formal\nspecification of its type system. However, there is no tool to ensure that\nprograms in Jolie are well-typed. In this paper we provide the results of\nbuilding a type checker for Jolie as a part of its syntax and semantics formal\nmodel. We express the type checker as a program with dependent types in Agda\nproof assistant which helps to ascertain that the type checker is correct.\n", "versions": [{"version": "v1", "created": "Wed, 15 Mar 2017 14:42:26 GMT"}, {"version": "v2", "created": "Thu, 23 Mar 2017 06:57:15 GMT"}], "update_date": "2017-03-24", "authors_parsed": [["Akentev", "Evgenii", ""], ["Tchitchigin", "Alexander", ""], ["Safina", "Larisa", ""], ["Mazzara", "Manuel", ""]]}, {"id": "1703.05227", "submitter": "Phil Scott", "authors": "Phil Scott, Steven Obua, Jacques Fleuriot", "title": "Compiling Purely Functional Structured Programs", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a marriage of functional and structured imperative programming\nthat embeds in pure lambda calculus. We describe how we implement the core of\nthis language in a monadic DSL which is structurally equivalent to our intended\nsource language and which, when evaluated, generates pure lambda terms in\ncontinuation-passing-style.\n", "versions": [{"version": "v1", "created": "Wed, 15 Mar 2017 16:07:38 GMT"}, {"version": "v2", "created": "Thu, 16 Mar 2017 08:09:52 GMT"}], "update_date": "2017-03-17", "authors_parsed": [["Scott", "Phil", ""], ["Obua", "Steven", ""], ["Fleuriot", "Jacques", ""]]}, {"id": "1703.05410", "submitter": "Matthew Hammer", "authors": "Chris Martens, Matthew A. Hammer", "title": "Languages of Play: Towards semantic foundations for game interfaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Formal models of games help us account for and predict behavior, leading to\nmore robust and innovative designs. While the games research community has\nproposed many formalisms for both the \"game half\" (game models, game\ndescription languages) and the \"human half\" (player modeling) of a game\nexperience, little attention has been paid to the interface between the two,\nparticularly where it concerns the player expressing her intent toward the\ngame. We describe an analytical and computational toolbox based on programming\nlanguage theory to examine the phenomenon sitting between control schemes and\ngame rules, which we identify as a distinct player intent language for each\ngame.\n", "versions": [{"version": "v1", "created": "Wed, 15 Mar 2017 22:44:07 GMT"}], "update_date": "2017-03-17", "authors_parsed": [["Martens", "Chris", ""], ["Hammer", "Matthew A.", ""]]}, {"id": "1703.05615", "submitter": "Stephan Brandauer", "authors": "Stephan Brandauer, Tobias Wrigstad", "title": "Spencer: Interactive Heap Analysis for the Masses", "comments": "MSR 2017 -- 14th International Conference on Mining Software\n  Repositories", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Programming language-design and run-time-implementation require detailed\nknowledge about the programs that users want to implement. Acquiring this\nknowledge is hard, and there is little tool support to effectively estimate\nwhether a proposed tradeoff actually makes sense in the context of real world\napplications.\n  Ideally, knowledge about behaviour of \"typical\" programs is 1) easily\nobtainable, 2) easily reproducible, and 3) easily sharable. We present Spencer,\na web service and API framework for dynamic analysis of a continuously growing\nset of traces of standard program corpora. Users do not obtain traces on their\nown, but can instead send queries to the web service that will be executed on a\nset of program traces. Queries are built in terms of a set of query combinators\nthat present a high level interface for working with trace data. Since the\nframework is high level, and there is a hosted collection of recorded traces,\nqueries are easy to implement. Since the data sets are shared by the research\ncommunity, results are reproducible. Since the actual queries run on one (or\nmany) servers that provide analysis as a service, obtaining results is possible\non commodity hardware.\n  Data in Spencer is meant to be obtained once, and analysed often, making the\noverhead of data collection mostly irrelevant. This allows Spencer to collect\nmore data than traditional tracing tools can afford within their performance\nbudget. Results in Spencer are cached, making complicated analyses that build\non cached primitive queries speedy.\n", "versions": [{"version": "v1", "created": "Thu, 16 Mar 2017 13:37:05 GMT"}, {"version": "v2", "created": "Fri, 31 Mar 2017 07:41:46 GMT"}], "update_date": "2017-04-03", "authors_parsed": [["Brandauer", "Stephan", ""], ["Wrigstad", "Tobias", ""]]}, {"id": "1703.05698", "submitter": "Vijayaraghavan Murali", "authors": "Vijayaraghavan Murali, Letao Qi, Swarat Chaudhuri, Chris Jermaine", "title": "Neural Sketch Learning for Conditional Program Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of generating source code in a strongly typed, Java-like\nprogramming language, given a label (for example a set of API calls or types)\ncarrying a small amount of information about the code that is desired. The\ngenerated programs are expected to respect a \"realistic\" relationship between\nprograms and labels, as exemplified by a corpus of labeled programs available\nduring training.\n  Two challenges in such conditional program generation are that the generated\nprograms must satisfy a rich set of syntactic and semantic constraints, and\nthat source code contains many low-level features that impede learning. We\naddress these problems by training a neural generator not on code but on\nprogram sketches, or models of program syntax that abstract out names and\noperations that do not generalize across programs. During generation, we infer\na posterior distribution over sketches, then concretize samples from this\ndistribution into type-safe programs using combinatorial techniques. We\nimplement our ideas in a system for generating API-heavy Java code, and show\nthat it can often predict the entire body of a method given just a few API\ncalls or data types that appear in the method.\n", "versions": [{"version": "v1", "created": "Thu, 16 Mar 2017 16:23:30 GMT"}, {"version": "v2", "created": "Tue, 21 Mar 2017 18:29:10 GMT"}, {"version": "v3", "created": "Mon, 17 Jul 2017 02:29:37 GMT"}, {"version": "v4", "created": "Mon, 15 Jan 2018 18:31:54 GMT"}, {"version": "v5", "created": "Thu, 12 Apr 2018 19:09:05 GMT"}], "update_date": "2018-04-16", "authors_parsed": [["Murali", "Vijayaraghavan", ""], ["Qi", "Letao", ""], ["Chaudhuri", "Swarat", ""], ["Jermaine", "Chris", ""]]}, {"id": "1703.06368", "submitter": "Alexander J. Summers", "authors": "Alexander J. Summers and Peter M\\\"uller", "title": "Automating Deductive Verification for Weak-Memory Programs", "comments": "Extended version of TACAS 2018 publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Writing correct programs for weak memory models such as the C11 memory model\nis challenging because of the weak consistency guarantees these models provide.\nThe first program logics for the verification of such programs have recently\nbeen proposed, but their usage has been limited thus far to manual proofs.\nAutomating proofs in these logics via first-order solvers is non-trivial, due\nto reasoning features such as higher-order assertions, modalities and rich\npermission resources. In this paper, we provide the first implementation of a\nweak memory program logic using existing deductive verification tools. We\ntackle three recent program logics: Relaxed Separation Logic and two forms of\nFenced Separation Logic, and show how these can be encoded using the Viper\nverification infrastructure. In doing so, we illustrate several novel encoding\ntechniques which could be employed for other logics. Our work is implemented,\nand has been evaluated on examples from existing papers as well as the Facebook\nopen-source Folly library.\n", "versions": [{"version": "v1", "created": "Sat, 18 Mar 2017 23:51:15 GMT"}, {"version": "v2", "created": "Mon, 19 Feb 2018 18:46:30 GMT"}], "update_date": "2018-02-20", "authors_parsed": [["Summers", "Alexander J.", ""], ["M\u00fcller", "Peter", ""]]}, {"id": "1703.06391", "submitter": "Hongwei Xi", "authors": "Hongwei Xi and Hanwen Wu", "title": "Multirole Logic (Extended Abstract)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.DC cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We identify multirole logic as a new form of logic in which\nconjunction/disjunction is interpreted as an ultrafilter on the power set of\nsome underlying set (of roles) and the notion of negation is generalized to\nendomorphisms on this underlying set. We formalize both multirole logic (MRL)\nand linear multirole logic (LMRL) as natural generalizations of classical logic\n(CL) and classical linear logic (CLL), respectively, and also present a\nfilter-based interpretation for intuitionism in multirole logic. Among various\nmeta-properties established for MRL and LMRL, we obtain one named multiparty\ncut-elimination stating that every cut involving one or more sequents (as a\ngeneralization of a (binary) cut involving exactly two sequents) can be\neliminated, thus extending the celebrated result of cut-elimination by Gentzen.\n", "versions": [{"version": "v1", "created": "Sun, 19 Mar 2017 04:47:19 GMT"}], "update_date": "2017-03-21", "authors_parsed": [["Xi", "Hongwei", ""], ["Wu", "Hanwen", ""]]}, {"id": "1703.06576", "submitter": "EPTCS", "authors": "Bugra M. Yildiz, Arend Rensink, Christoph Bockisch, Mehmet Aksit", "title": "A Model-Derivation Framework for Software Analysis", "comments": "In Proceedings MARS 2017, arXiv:1703.05812", "journal-ref": "EPTCS 244, 2017, pp. 217-229", "doi": "10.4204/EPTCS.244.9", "report-no": null, "categories": "cs.SE cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-based verification allows to express behavioral correctness conditions\nlike the validity of execution states, boundaries of variables or timing at a\nhigh level of abstraction and affirm that they are satisfied by a software\nsystem. However, this requires expressive models which are difficult and\ncumbersome to create and maintain by hand. This paper presents a framework that\nautomatically derives behavioral models from real-sized Java programs. Our\nframework builds on the EMF/ECore technology and provides a tool that creates\nan initial model from Java bytecode, as well as a series of transformations\nthat simplify the model and eventually output a timed-automata model that can\nbe processed by a model checker such as UPPAAL. The framework has the following\nproperties: (1) consistency of models with software, (2) extensibility of the\nmodel derivation process, (3) scalability and (4) expressiveness of models. We\nreport several case studies to validate how our framework satisfies these\nproperties.\n", "versions": [{"version": "v1", "created": "Mon, 20 Mar 2017 02:49:18 GMT"}], "update_date": "2017-03-21", "authors_parsed": [["Yildiz", "Bugra M.", ""], ["Rensink", "Arend", ""], ["Bockisch", "Christoph", ""], ["Aksit", "Mehmet", ""]]}, {"id": "1703.06577", "submitter": "EPTCS", "authors": "Hubert Garavel, Wendelin Serwe", "title": "The Unheralded Value of the Multiway Rendezvous: Illustration with the\n  Production Cell Benchmark", "comments": "In Proceedings MARS 2017, arXiv:1703.05812", "journal-ref": "EPTCS 244, 2017, pp. 230-270", "doi": "10.4204/EPTCS.244.10", "report-no": null, "categories": "cs.PL cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The multiway rendezvous introduced in Theoretical CSP is a powerful paradigm\nto achieve synchronization and communication among a group of (possibly more\nthan two) processes. We illustrate the advantages of this paradigm on the\nproduction cell benchmark, a model of a real metal processing plant, for which\nwe propose a compositional software controller, which is written in LNT and\nLOTOS, and makes intensive use of the multiway rendezvous.\n", "versions": [{"version": "v1", "created": "Mon, 20 Mar 2017 02:49:31 GMT"}], "update_date": "2017-03-21", "authors_parsed": [["Garavel", "Hubert", ""], ["Serwe", "Wendelin", ""]]}, {"id": "1703.06822", "submitter": "Kees Middelburg", "authors": "J. A. Bergstra, C. A. Middelburg", "title": "Process algebra with strategic interleaving", "comments": "19 pages, this version is a revision of the published version", "journal-ref": "Theory of Computing Systems, 63(3):488--505, 2019", "doi": "10.1007/s00224-018-9873-2", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In process algebras such as ACP (Algebra of Communicating Processes),\nparallel processes are considered to be interleaved in an arbitrary way. In the\ncase of multi-threading as found in contemporary programming languages,\nparallel processes are actually interleaved according to some interleaving\nstrategy. An interleaving strategy is what is called a process-scheduling\npolicy in the field of operating systems. In many systems, for instance\nhardware/software systems, we have to do with both parallel processes that may\nbest be considered to be interleaved in an arbitrary way and parallel processes\nthat may best be considered to be interleaved according to some interleaving\nstrategy. Therefore, we extend ACP in this paper with the latter form of\ninterleaving. The established properties of the extension concerned include an\nelimination property, a conservative extension property, and a unique expansion\nproperty.\n", "versions": [{"version": "v1", "created": "Mon, 20 Mar 2017 16:15:17 GMT"}, {"version": "v2", "created": "Mon, 19 Feb 2018 11:05:48 GMT"}, {"version": "v3", "created": "Tue, 21 Apr 2020 12:39:01 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Bergstra", "J. A.", ""], ["Middelburg", "C. A.", ""]]}, {"id": "1703.07547", "submitter": "Samir Genaim", "authors": "Amir M. Ben-Amram and Samir Genaim", "title": "On Multiphase-Linear Ranking Functions", "comments": "typos corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiphase ranking functions ($\\mathit{M{\\Phi}RFs}$) were proposed as a means\nto prove the termination of a loop in which the computation progresses through\na number of \"phases\", and the progress of each phase is described by a\ndifferent linear ranking function. Our work provides new insights regarding\nsuch functions for loops described by a conjunction of linear constraints\n(single-path loops). We provide a complete polynomial-time solution to the\nproblem of existence and of synthesis of $\\mathit{M{\\Phi}RF}$ of bounded depth\n(number of phases), when variables range over rational or real numbers; a\ncomplete solution for the (harder) case that variables are integer, with a\nmatching lower-bound proof, showing that the problem is coNP-complete; and a\nnew theorem which bounds the number of iterations for loops with\n$\\mathit{M{\\Phi}RFs}$. Surprisingly, the bound is linear, even when the\nvariables involved change in non-linear way. We also consider a type of\nlexicographic ranking functions, $\\mathit{LLRFs}$, more expressive than types\nof lexicographic functions for which complete solutions have been given so far.\nWe prove that for the above type of loops, lexicographic functions can be\nreduced to $\\mathit{M{\\Phi}RFs}$, and thus the questions of complexity of\ndetection and synthesis, and of resulting iteration bounds, are also answered\nfor this class.\n", "versions": [{"version": "v1", "created": "Wed, 22 Mar 2017 07:24:15 GMT"}, {"version": "v2", "created": "Thu, 23 Mar 2017 16:19:32 GMT"}], "update_date": "2017-03-24", "authors_parsed": [["Ben-Amram", "Amir M.", ""], ["Genaim", "Samir", ""]]}, {"id": "1703.07638", "submitter": "Shaul Zevin", "authors": "Shaul Zevin, Catherine Holzem", "title": "Machine Learning Based Source Code Classification Using Syntax Oriented\n  Features", "comments": "13 pages, 4 tables, 4 examples", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As of today the programming language of the vast majority of the published\nsource code is manually specified or programmatically assigned based on the\nsole file extension. In this paper we show that the source code programming\nlanguage identification task can be fully automated using machine learning\ntechniques. We first define the criteria that a production-level automatic\nprogramming language identification solution should meet. Our criteria include\naccuracy, programming language coverage, extensibility and performance. We then\ndescribe our approach: How training files are preprocessed for extracting\nfeatures that mimic grammar productions, and then how these extracted grammar\nproductions are used for the training and testing of our classifier. We achieve\na 99 percent accuracy rate while classifying 29 of the most popular programming\nlanguages with a Maximum Entropy classifier.\n", "versions": [{"version": "v1", "created": "Sat, 4 Mar 2017 10:44:40 GMT"}], "update_date": "2017-03-23", "authors_parsed": [["Zevin", "Shaul", ""], ["Holzem", "Catherine", ""]]}, {"id": "1703.07682", "submitter": "Benjamin Lucien Kaminski", "authors": "Benjamin Lucien Kaminski, Joost-Pieter Katoen", "title": "A Weakest Pre-Expectation Semantics for Mixed-Sign Expectations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a weakest-precondition-style calculus for reasoning about the\nexpected values (pre-expectations) of \\emph{mixed-sign unbounded} random\nvariables after execution of a probabilistic program. The semantics of a\nwhile-loop is well-defined as the limit of iteratively applying a functional to\na zero-element just as in the traditional weakest pre-expectation calculus,\neven though a standard least fixed point argument is not applicable in this\ncontext. A striking feature of our semantics is that it is always well-defined,\neven if the expected values do not exist. We show that the calculus is sound,\nallows for compositional reasoning, and present an invariant-based approach for\nreasoning about pre-expectations of loops.\n", "versions": [{"version": "v1", "created": "Wed, 22 Mar 2017 14:42:11 GMT"}, {"version": "v2", "created": "Tue, 18 Apr 2017 13:18:32 GMT"}], "update_date": "2017-04-19", "authors_parsed": [["Kaminski", "Benjamin Lucien", ""], ["Katoen", "Joost-Pieter", ""]]}, {"id": "1703.08113", "submitter": "Artur Boronat", "authors": "Artur Boronat", "title": "Well-Behaved Model Transformations with Model Subtyping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In model-driven engineering, models abstract the relevant features of\nsoftware artefacts and model transformations act on them automating complex\ntasks of the development process. It is, thus, crucially important to provide\npragmatic, reliable methods to verify that model transformations guarantee the\ncorrectness of generated models in order to ensure the quality of the final end\nproduct. In this paper, we build on an object-oriented algebraic encoding of\nmetamodels and models as defined in the standard Meta-Object Facility and in\ntools, such as the Eclipse Modeling Framework, to specify a domain-specific\nlanguage for representing the action part of model transformations. We\nintroduce the big-step operational structural semantics of this language and\nits type system, which includes a notion of polymorphic model subtyping,\nshowing that well-typed model transformations are well behaved. That is, that\nmetamodel-conformant model transformations never go wrong.\n", "versions": [{"version": "v1", "created": "Thu, 23 Mar 2017 15:42:14 GMT"}], "update_date": "2017-03-24", "authors_parsed": [["Boronat", "Artur", ""]]}, {"id": "1703.08219", "submitter": "Tiark Rompf", "authors": "Gr\\'egory M. Essertel, Ruby Y. Tahboub, James M. Decker, Kevin J.\n  Brown, Kunle Olukotun, Tiark Rompf", "title": "Flare: Native Compilation for Heterogeneous Workloads in Apache Spark", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DC cs.PF cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The need for modern data analytics to combine relational, procedural, and\nmap-reduce-style functional processing is widely recognized. State-of-the-art\nsystems like Spark have added SQL front-ends and relational query optimization,\nwhich promise an increase in expressiveness and performance. But how good are\nthese extensions at extracting high performance from modern hardware platforms?\n  While Spark has made impressive progress, we show that for relational\nworkloads, there is still a significant gap compared with best-of-breed query\nengines. And when stepping outside of the relational world, query optimization\ntechniques are ineffective if large parts of a computation have to be treated\nas user-defined functions (UDFs).\n  We present Flare: a new back-end for Spark that brings performance closer to\nthe best SQL engines, without giving up the added expressiveness of Spark. We\ndemonstrate order of magnitude speedups both for relational workloads such as\nTPC-H, as well as for a range of machine learning kernels that combine\nrelational and iterative functional processing.\n  Flare achieves these results through (1) compilation to native code, (2)\nreplacing parts of the Spark runtime system, and (3) extending the scope of\noptimization and code generation to large classes of UDFs.\n", "versions": [{"version": "v1", "created": "Thu, 23 Mar 2017 20:04:55 GMT"}], "update_date": "2017-03-27", "authors_parsed": [["Essertel", "Gr\u00e9gory M.", ""], ["Tahboub", "Ruby Y.", ""], ["Decker", "James M.", ""], ["Brown", "Kevin J.", ""], ["Olukotun", "Kunle", ""], ["Rompf", "Tiark", ""]]}, {"id": "1703.08683", "submitter": "Hongwei Xi", "authors": "Hongwei Xi", "title": "Applied Type System: An Approach to Practical Programming with\n  Theorem-Proving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The framework Pure Type System (PTS) offers a simple and general approach to\ndesigning and formalizing type systems. However, in the presence of dependent\ntypes, there often exist certain acute problems that make it difficult for PTS\nto directly accommodate many common realistic programming features such as\ngeneral recursion, recursive types, effects (e.g., exceptions, references,\ninput/output), etc. In this paper, Applied Type System (ATS) is presented as a\nframework for designing and formalizing type systems in support of practical\nprogramming with advanced types (including dependent types). In particular, it\nis demonstrated that ATS can readily accommodate a paradigm referred to as\nprogramming with theorem-proving (PwTP) in which programs and proofs are\nconstructed in a syntactically intertwined manner, yielding a practical\napproach to internalizing constraint-solving needed during type-checking. The\nkey salient feature of ATS lies in a complete separation between statics, where\ntypes are formed and reasoned about, and dynamics, where programs are\nconstructed and evaluated. With this separation, it is no longer possible for a\nprogram to occur in a type as is otherwise allowed in PTS. The paper contains\nnot only a formal development of ATS but also some examples taken from\nats-lang.org, a programming language with a type system rooted in ATS, in\nsupport of employing ATS as a framework to formulate advanced type systems for\npractical programming.\n", "versions": [{"version": "v1", "created": "Sat, 25 Mar 2017 12:33:11 GMT"}], "update_date": "2017-03-28", "authors_parsed": [["Xi", "Hongwei", ""]]}, {"id": "1703.08694", "submitter": "Matthew Hammer", "authors": "Cyrus Omar, Ian Voysey, Michael Hilton, Joshua Sunshine, Claire Le\n  Goues, Jonathan Aldrich, Matthew A. Hammer", "title": "Toward Semantic Foundations for Program Editors", "comments": "The 2nd Summit on Advances in Programming Languages (SNAPL 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Programming language definitions assign formal meaning to complete programs.\nProgrammers, however, spend a substantial amount of time interacting with\nincomplete programs -- programs with holes, type inconsistencies and binding\ninconsistencies -- using tools like program editors and live programming\nenvironments (which interleave editing and evaluation). Semanticists have done\ncomparatively little to formally characterize (1) the static and dynamic\nsemantics of incomplete programs; (2) the actions available to programmers as\nthey edit and inspect incomplete programs; and (3) the behavior of editor\nservices that suggest likely edit actions to the programmer based on semantic\ninformation extracted from the incomplete program being edited, and from\nprograms that the system has encountered in the past. As such, each tool\ndesigner has largely been left to develop their own ad hoc heuristics.\n  This paper serves as a vision statement for a research program that seeks to\ndevelop these \"missing\" semantic foundations. Our hope is that these\ncontributions, which will take the form of a series of simple formal calculi\nequipped with a tractable metatheory, will guide the design of a variety of\ncurrent and future interactive programming tools, much as various lambda\ncalculi have guided modern language designs. Our own research will apply these\nprinciples in the design of Hazel, an experimental live lab notebook\nprogramming environment designed for data science tasks. We plan to co-design\nthe Hazel language with the editor so that we can explore concepts such as\nedit-time semantic conflict resolution mechanisms and mechanisms that allow\nlibrary providers to install library-specific editor services.\n", "versions": [{"version": "v1", "created": "Sat, 25 Mar 2017 13:39:51 GMT"}], "update_date": "2017-03-28", "authors_parsed": [["Omar", "Cyrus", ""], ["Voysey", "Ian", ""], ["Hilton", "Michael", ""], ["Sunshine", "Joshua", ""], ["Goues", "Claire Le", ""], ["Aldrich", "Jonathan", ""], ["Hammer", "Matthew A.", ""]]}, {"id": "1703.09988", "submitter": "Marco Patrignani", "authors": "Dominique Devriese, Marco Patrignani, Frank Piessens, Steven Keuchel", "title": "Modular, Fully-abstract Compilation by Approximate Back-translation", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 13, Issue 4 (October\n  25, 2017) lmcs:4011", "doi": "10.23638/LMCS-13(4:2)2017", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A compiler is fully-abstract if the compilation from source language programs\nto target language programs reflects and preserves behavioural equivalence.\nSuch compilers have important security benefits, as they limit the power of an\nattacker interacting with the program in the target language to that of an\nattacker interacting with the program in the source language. Proving compiler\nfull-abstraction is, however, rather complicated. A common proof technique is\nbased on the back-translation of target-level program contexts to\nbehaviourally-equivalent source-level contexts. However, constructing such a\nback- translation is problematic when the source language is not strong enough\nto embed an encoding of the target language. For instance, when compiling from\nSTLC to ULC, the lack of recursive types in the former prevents such a\nback-translation.\n  We propose a general and elegant solution for this problem. The key insight\nis that it suffices to construct an approximate back-translation. The\napproximation is only accurate up to a certain number of steps and conservative\nbeyond that, in the sense that the context generated by the back-translation\nmay diverge when the original would not, but not vice versa. Based on this\ninsight, we describe a general technique for proving compiler full-abstraction\nand demonstrate it on a compiler from STLC to ULC. The proof uses asymmetric\ncross-language logical relations and makes innovative use of step-indexing to\nexpress the relation between a context and its approximate back-translation.\nThe proof extends easily to common compiler patterns such as modular\ncompilation and it, to the best of our knowledge, it is the first compiler full\nabstraction proof to have been fully mechanised in Coq. We believe this proof\ntechnique can scale to challenging settings and enable simpler, more scalable\nproofs of compiler full-abstraction.\n", "versions": [{"version": "v1", "created": "Wed, 29 Mar 2017 11:58:42 GMT"}, {"version": "v2", "created": "Wed, 11 Oct 2017 08:50:41 GMT"}, {"version": "v3", "created": "Thu, 19 Oct 2017 14:21:42 GMT"}, {"version": "v4", "created": "Tue, 24 Oct 2017 12:11:51 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Devriese", "Dominique", ""], ["Patrignani", "Marco", ""], ["Piessens", "Frank", ""], ["Keuchel", "Steven", ""]]}, {"id": "1703.10027", "submitter": "Dan Ghica", "authors": "Koko Muroya and Dan R. Ghica", "title": "The Dynamic Geometry of Interaction Machine: A Call-by-need Graph\n  Rewriter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Girard's Geometry of Interaction (GoI), a semantics designed for linear logic\nproofs, has been also successfully applied to programming language semantics.\nOne way is to use abstract machines that pass a token on a fixed graph along a\npath indicated by the GoI. These token-passing abstract machines are space\nefficient, because they handle duplicated computation by repeating the same\nmoves of a token on the fixed graph. Although they can be adapted to obtain\nsound models with regard to the equational theories of various evaluation\nstrategies for the lambda calculus, it can be at the expense of significant\ntime costs. In this paper we show a token-passing abstract machine that can\nimplement evaluation strategies for the lambda calculus, with certified time\nefficiency. Our abstract machine, called the Dynamic GoI Machine (DGoIM),\nrewrites the graph to avoid replicating computation, using the token to find\nthe redexes. The flexibility of interleaving token transitions and graph\nrewriting allows the DGoIM to balance the trade-off of space and time costs.\nThis paper shows that the DGoIM can implement call-by-need evaluation for the\nlambda calculus by using a strategy of interleaving token passing with as much\ngraph rewriting as possible. Our quantitative analysis confirms that the DGoIM\nwith this strategy of interleaving the two kinds of possible operations on\ngraphs can be classified as \"efficient\" following Accattoli's taxonomy of\nabstract machines.\n", "versions": [{"version": "v1", "created": "Wed, 29 Mar 2017 13:29:11 GMT"}], "update_date": "2017-03-30", "authors_parsed": [["Muroya", "Koko", ""], ["Ghica", "Dan R.", ""]]}, {"id": "1703.10179", "submitter": "Dorothea Jansen", "authors": "Dorothea Jansen", "title": "\\\"Uber die Pr\\\"azision interprozeduraler Analysen", "comments": "Diploma thesis; german", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we examine two approaches to interprocedural data-flow analysis\nof Sharir and Pnueli in terms of precision: the functional and the call-string\napproach. In doing so, not only the theoretical best, but all solutions are\nregarded which occur when using abstract interpretation or widening\nadditionally. It turns out that the solutions of both approaches coincide. This\nproperty is preserved when using abstract interpretation; in the case of\nwidening, a comparison of the results is not always possible.\n", "versions": [{"version": "v1", "created": "Wed, 29 Mar 2017 18:06:56 GMT"}], "update_date": "2017-03-31", "authors_parsed": [["Jansen", "Dorothea", ""]]}, {"id": "1703.10242", "submitter": "James Ross", "authors": "David Richie, James Ross", "title": "I CAN HAS SUPERCOMPUTER? A Novel Approach to Teaching Parallel and\n  Distributed Computing Concepts Using a Meme-Based Programming Language", "comments": "7 pages, 2 figures, example code, accepted for publication at the 7th\n  NSF/TCPP Workshop on Parallel and Distributed Computing Education (EduPar-17)\n  workshop in conjunction with the 31st IEEE International Parallel &\n  Distributed Processing Symposium (IPDPS 17)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel approach is presented to teach the parallel and distributed computing\nconcepts of synchronization and remote memory access. The single program\nmultiple data (SPMD) partitioned global address space (PGAS) model presented in\nthis paper uses a procedural programming language appealing to undergraduate\nstudents. We propose that the amusing nature of the approach may engender\ncreativity and interest using these concepts later in more sober environments.\nSpecifically, we implement parallel extensions to LOLCODE within a\nsource-to-source compiler sufficient for the development of parallel and\ndistributed algorithms normally implemented using conventional high-performance\ncomputing languages and APIs.\n", "versions": [{"version": "v1", "created": "Wed, 29 Mar 2017 20:42:28 GMT"}], "update_date": "2017-03-31", "authors_parsed": [["Richie", "David", ""], ["Ross", "James", ""]]}, {"id": "1703.10247", "submitter": "Dan Ghica", "authors": "Dan R. Ghica, Achim Jung and Aliaume Lopez", "title": "Diagrammatic Semantics for Digital Circuits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a general diagrammatic theory of digital circuits, based on\nconnections between monoidal categories and graph rewriting. The main\nachievement of the paper is conceptual, filling a foundational gap in reasoning\nsyntactically and symbolically about a large class of digital circuits\n(discrete values, discrete delays, feedback). This complements the dominant\napproach to circuit modelling, which relies on simulation. The main advantage\nof our symbolic approach is the enabling of automated reasoning about abstract\ncircuits, with a potentially interesting new application to partial evaluation\nof digital circuits. Relative to the recent interest and activity in\ncategorical and diagrammatic methods, our work makes several new contributions.\nThe most important is establishing that categories of digital circuits are\nCartesian and admit, in the presence of feedback expressive iteration axioms.\nThe second is producing a general yet simple graph-rewrite framework for\nreasoning about such categories in which the rewrite rules are computationally\nefficient, opening the way for practical applications.\n", "versions": [{"version": "v1", "created": "Wed, 29 Mar 2017 21:24:07 GMT"}], "update_date": "2017-03-31", "authors_parsed": [["Ghica", "Dan R.", ""], ["Jung", "Achim", ""], ["Lopez", "Aliaume", ""]]}, {"id": "1703.10331", "submitter": "Matthias Keil", "authors": "Matthias Keil, Peter Thiemann", "title": "Static Contract Simplification", "comments": "Technical Report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contracts and contract monitoring are a powerful mechanism for specifying\nproperties and guaranteeing them at run time. However, run time monitoring of\ncontracts imposes a significant overhead. The execution time is impacted by the\ninsertion of contract checks as well as by the introduction of proxy objects\nthat perform delayed contract checks on demand.\n  Static contract simplification attacks this issue using program\ntransformation. It applies compile-time transformations to programs with\ncontracts to reduce the overall run time while preserving the original\nbehavior. Our key technique is to statically propagate contracts through the\nprogram and to evaluate and merge contracts where possible. The goal is to\nobtain residual contracts that are collectively cheaper to check at run time.\nWe distinguish different levels of preservation of behavior, which impose\ndifferent limitations on the admissible transformations: Strong blame\npreservation, where the transformation is a behavioral equivalence, and weak\nblame preservation, where the transformed program is equivalent up to the\nparticular violation reported. Our transformations never increase the overall\nnumber of contract checks.\n", "versions": [{"version": "v1", "created": "Thu, 30 Mar 2017 06:53:13 GMT"}], "update_date": "2017-03-31", "authors_parsed": [["Keil", "Matthias", ""], ["Thiemann", "Peter", ""]]}, {"id": "1703.10354", "submitter": "Stefan Wagner", "authors": "Erica Janke, Philipp Brune, Stefan Wagner", "title": "Does Outside-In Teaching Improve the Learning of Object-Oriented\n  Programming?", "comments": "10 pages, 7 figures", "journal-ref": "Proc. 37h International Conference on Software Engineering\n  (ICSE'15). IEEE, 2015", "doi": "10.1109/ICSE.2015.173", "report-no": null, "categories": "cs.SE cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Object-oriented programming (OOP) is widely used in the software industry and\nuniversity introductory courses today. Following the structure of most\ntextbooks, such courses frequently are organised starting with the concepts of\nimperative and structured programming and only later introducing OOP. An\nalternative approach is to begin directly with OOP following the Outside-In\nteaching method as proposed by Meyer. Empirical results for the effects of\nOutside-In teaching on students and lecturers are sparse, however. We describe\nthe conceptual design and empirical evaluation of two OOP introductory courses\nfrom different universities based on Outside-In teaching. The evaluation\nresults are compared to those from a third course serving as the control group,\nwhich was taught OOP the \"traditional\" way. We evaluate the initial motivation\nand knowledge of the participants and the learning outcomes. In addition, we\nanalyse results of the end-term exams and qualitatively analyse the results of\ninterviews with the lecturers and tutors. Regarding the learning outcomes, the\nresults show no signif- icant differences between the Outside-In and the\n\"traditional\" teaching method. In general, students found it harder to solve\nand implement algorithmic problems than to understand object oriented (OO)\nconcepts. Students taught OOP by the Outside-In method, however, were less\nafraid that they would not pass the exam at the end of term and understood the\nOO paradigm more quickly. Therefore, the Outside-In method is no silver bullet\nfor teaching OOP regarding the learning outcomes but has positive effects on\nmotivation and interest.\n", "versions": [{"version": "v1", "created": "Thu, 30 Mar 2017 08:31:18 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Janke", "Erica", ""], ["Brune", "Philipp", ""], ["Wagner", "Stefan", ""]]}, {"id": "1703.10857", "submitter": "Matthew Pickering", "authors": "Matthew Pickering (University of Bristol, United Kingdom), Jeremy\n  Gibbons (University of Oxford, United Kingdom), Nicolas Wu (University of\n  Bristol, United Kingdom)", "title": "Profunctor Optics: Modular Data Accessors", "comments": null, "journal-ref": "The Art, Science, and Engineering of Programming, 2017, Vol. 1,\n  Issue 2, Article 7", "doi": "10.22152/programming-journal.org/2017/1/7", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  CONTEXT: Data accessors allow one to read and write components of a data\nstructure, such as the fields of a record, the variants of a union, or the\nelements of a container. These data accessors are collectively known as optics;\nthey are fundamental to programs that manipulate complex data. INQUIRY:\nIndividual data accessors for simple data structures are easy to write, for\nexample as pairs of \"getter\" and \"setter\" methods. However, it is not obvious\nhow to combine data accessors, in such a way that data accessors for a compound\ndata structure are composed out of smaller data accessors for the parts of that\nstructure. Generally, one has to write a sequence of statements or declarations\nthat navigate step by step through the data structure, accessing one level at a\ntime - which is to say, data accessors are traditionally not first-class\ncitizens, combinable in their own right. APPROACH: We present a framework for\nmodular data access, in which individual data accessors for simple data\nstructures may be freely combined to obtain more complex data accessors for\ncompound data structures. Data accessors become first-class citizens. The\nframework is based around the notion of profunctors, a flexible generalization\nof functions. KNOWLEDGE: The language features required are higher-order\nfunctions (\"lambdas\" or \"closures\"), parametrized types (\"generics\" or\n\"abstract types\"), and some mechanism for separating interfaces from\nimplementations (\"abstract classes\" or \"modules\"). We use Haskell as a vehicle\nin which to present our constructions, but languages such as Java, C#, or Scala\nthat provide the necessary features should work just as well. GROUNDING: We\nprovide implementations of all our constructions, in the form of a literate\nprogram: the manuscript file for the paper is also the source code for the\nprogram, and the extracted code is available separately for evaluation. We also\nprove the essential properties demonstrating that our profunctor-based\nrepresentations are precisely equivalent to the more familiar concrete\nrepresentations. IMPORTANCE: Our results should pave the way to simpler ways of\nwriting programs that access the components of compound data structures.\n", "versions": [{"version": "v1", "created": "Fri, 31 Mar 2017 11:45:17 GMT"}], "update_date": "2017-04-03", "authors_parsed": [["Pickering", "Matthew", "", "University of Bristol, United Kingdom"], ["Gibbons", "Jeremy", "", "University of Oxford, United Kingdom"], ["Wu", "Nicolas", "", "University of\n  Bristol, United Kingdom"]]}, {"id": "1703.10858", "submitter": "Arik Hadas", "authors": "Arik Hadas (Open University of Israel, Israel), David H Lorenz (Open\n  University of Israel, Israel)", "title": "Language Oriented Modularity: From Theory to Practice", "comments": null, "journal-ref": "The Art, Science, and Engineering of Programming, 2017, Vol. 1,\n  Issue 2, Article 10", "doi": "10.22152/programming-journal.org/2017/1/10", "report-no": null, "categories": "cs.SE cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language-oriented modularity (LOM) is a methodology that complements\nlanguage-oriented programming (LOP) in providing on-demand language abstraction\nsolutions during software development. It involves the implementation and\nimmediate utilization of domain-specific languages (DSLs) that are also\naspect-oriented (DSALs). However, while DSL development is affordable thanks to\nmodern language workbenches, DSAL development lacks similar tool support.\nConsequently, LOM is often impractical and underutilized. The challenge we\naddress is making the complexity of DSAL implementation comparable to that of\nDSLs and the effectiveness of programming with DSALs comparable to that of\ngeneral-purpose aspect languages (GPALs). Today, despite being essentially both\ndomain-specific and aspect-oriented, DSALs seem to be second-class. Aspect\ndevelopment tools (e.g., AJDT) do not work on DSAL code. DSL development tools\nlike language workbenches (e.g., Spoofax) neither deal with the backend weaving\nnor handle the composition of DSALs. DSAL composition frameworks (e.g.,\nAwesome) do not provide frontend development tools. DSAL code transformation\napproaches (e.g., XAspects) do not preserve the semantics of DSAL programs in\nthe presence of other aspect languages. We extend AspectJ with a small set of\nannotations and interfaces that allows DSAL designers to define a\nsemantic-preserving transformation to AspectJ and interface with AspectJ tools.\nOur transformation approach enables the use of standard language workbench to\nimplement DSALs and use of standard aspect development tools to program with\nthose DSALs. As a result, DSALs regain first-class status with respect to both\nDSLs and aspect languages. This, on the one hand, lowers the cost of developing\nDSALs to the level of DSLs and, on the other hand, raises the effectiveness of\nusing a DSAL to the level of a GPAL. Consequently, LOM becomes cost-effective\ncompared to the LOP baseline. We modified the ajc compiler to support our\napproach. Using two different language workbenches (Spoofax and Xtext) we then\nimplemented several DSALs. AspectJ was supported out-of-the-box. We implemented\nCool to demonstrate that the non-trivial composition of AspectJ and Cool can be\naccommodated using our approach. We applied LOM to crosscutting concerns in two\nopen source projects (oVirt and muCommander), implementing in the process\napplication-specific DSALs, thus providing a sense of the decrease in the cost\nof developing composable DSALs and the increase in the effectiveness of\nprogramming with them. Crosscutting concerns remain a problem in modern\nreal-world projects (e.g., as observed in oVirt). DSALs are often the right\ntool for addressing these concerns. Our work makes LOM practical, thus\nfacilitating use of DSAL solutions in the software development process.\n", "versions": [{"version": "v1", "created": "Fri, 31 Mar 2017 11:45:38 GMT"}], "update_date": "2017-04-03", "authors_parsed": [["Hadas", "Arik", "", "Open University of Israel, Israel"], ["Lorenz", "David H", "", "Open\n  University of Israel, Israel"]]}, {"id": "1703.10859", "submitter": "Stefan Ramson", "authors": "Stefan Ramson (Hasso Plattner Institute, Germany), Robert Hirschfeld\n  (Hasso Plattner Institute, Germany)", "title": "Active Expressions: Basic Building Blocks for Reactive Programming", "comments": null, "journal-ref": "The Art, Science, and Engineering of Programming, 2017, Vol. 1,\n  Issue 2, Article 12", "doi": "10.22152/programming-journal.org/2017/1/12", "report-no": null, "categories": "cs.SE cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern software development without reactive programming is hard to imagine.\nReactive programming favors a wide class of contemporary software systems that\nrespond to user input, network messages, and other events. While reactive\nprogramming is an active field of research, the implementation of reactive\nconcepts remains challenging. In particular, change detection represents a hard\nbut inevitable necessity when implementing reactive concepts. Typically, change\ndetection mechanisms are not intended for reuse but are tightly coupled to the\nparticular change resolution mechanism. As a result, developers often have to\nre-implement similar abstractions. A reusable primitive for change detection is\nstill missing. To find a suitable primitive, we identify commonalities in\nexisting reactive concepts. We discover a class of reactive concepts,\nstate-based reactive concepts. All state-based reactive concepts share a common\nchange detection mechanism: they detect changes in the evaluation result of an\nexpression. On the basis of the identified common change detection mechanism,\nwe propose active expressions as a reusable primitive. By abstracting the\ntedious implementation details of change detection, active expressions can ease\nthe implementation of reactive programming concepts. We evaluate the design of\nactive expressions by re-implementing a number of existing state-based reactive\nconcepts using them. The resulting implementations highlight the expressiveness\nof active expressions. Active expressions enable the separation of essential\nfrom non-essential parts when reasoning about reactive programming concepts. By\nusing active expressions as a primitive for change detection, developers of\nreactive language constructs and runtime support can now focus on the design of\nhow application programmers should be able to react to change. Ultimately, we\nwould like active expressions to encourage experiments with novel reactive\nprogramming concepts and with that to yield a wider variety of them to explore.\n", "versions": [{"version": "v1", "created": "Fri, 31 Mar 2017 11:46:09 GMT"}], "update_date": "2017-04-03", "authors_parsed": [["Ramson", "Stefan", "", "Hasso Plattner Institute, Germany"], ["Hirschfeld", "Robert", "", "Hasso Plattner Institute, Germany"]]}, {"id": "1703.10860", "submitter": "Simon Thompson", "authors": "Simon Thompson (University of Kent, United Kingdom), Huiqing Li\n  (University of Kent, United Kingdom), Andreas Schumacher (Ericsson AB,\n  Sweden)", "title": "The pragmatics of clone detection and elimination", "comments": null, "journal-ref": "The Art, Science, and Engineering of Programming, 2017, Vol. 1,\n  Issue 2, Article 8", "doi": "10.22152/programming-journal.org/2017/1/8", "report-no": null, "categories": "cs.SE cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The occurrence of similar code, or `code clones', can make program code\ndifficult to read, modify and maintain. This paper describes industrial case\nstudies of clone detection and elimination using a refactoring and clone\ndetection tool. We discuss how the studies have informed the design of the\ntool; more importantly, we use the studies to illustrate the complex set of\ndecisions that have to be taken when performing clone elimination in practice.\nThe case studies were performed in collaboration with engineers from Ericsson\nAB, and used the refactoring tool Wrangler for Erlang. However, the conclusions\nwe draw are largely language-independent, and set out the pragmatics of clone\ndetection and elimination in real-world projects as well as design principles\nfor clone detection decision-support tools.\n", "versions": [{"version": "v1", "created": "Fri, 31 Mar 2017 11:46:26 GMT"}], "update_date": "2017-04-03", "authors_parsed": [["Thompson", "Simon", "", "University of Kent, United Kingdom"], ["Li", "Huiqing", "", "University of Kent, United Kingdom"], ["Schumacher", "Andreas", "", "Ericsson AB,\n  Sweden"]]}, {"id": "1703.10861", "submitter": "Kazuhiro Ichikawa", "authors": "Kazuhiro Ichikawa (The University of Tokyo, Japan), Shigeru Chiba (The\n  University of Tokyo, Japan)", "title": "User-Defined Operators Including Name Binding for New Language\n  Constructs", "comments": null, "journal-ref": "The Art, Science, and Engineering of Programming, 2017, Vol. 1,\n  Issue 2, Article 15", "doi": "10.22152/programming-journal.org/2017/1/15", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  User-defined syntax extensions are useful to implement an embedded domain\nspecific language (EDSL) with good code-readability. They allow EDSL authors to\ndefine domain-natural notation, which is often different from the host language\nsyntax. Nowadays, there are several research works of powerful user-defined\nsyntax extensions. One promising approach uses user-defined operators. A\nuser-defined operator is a function with user-defined syntax. It can be\nregarded as a syntax extension implemented without macros. An advantage of\nuser-defined operators is that an operator can be statically typed. The\ncompiler can find type errors in the definition of an operator before the\noperator is used. In addition, the compiler can resolve syntactic ambiguities\nby using static types. However, user-defined operators are difficult to\nimplement language constructs involving static name binding. Name binding is\nassociation between names and values (or memory locations). Our inquiry is\nwhether we can design a system for user-defined operators involving a new\ncustom name binding. This paper proposes a module system for user-defined\noperators named a dsl class. A dsl class is similar to a normal class in Java\nbut it contains operators instead of methods. We use operators for implementing\ncustom name binding. For example, we use a nullary operator for emulating a\nvariable name. An instance of a dsl class, called a dsl object, reifies an\nenvironment that expresses name binding. Programmers can control a scope of\ninstance operators by specifying where the dsl object is active. We extend the\nhost type system so that it can express the activation of a dsl object. In our\nsystem, a bound name is propagated through a type parameter to a dsl object.\nThis enables us to implement user-defined language constructs involving static\nname binding. A contribution of this paper is that we reveal we can integrate a\nsystem for managing names and their scopes with a module and type system of an\nobject-oriented language like Java. This allows us to implement a proposed\nsystem by adopting eager disambiguation based on expected types so that the\ncompilation time will be acceptable. Eager disambiguation, which prunes out\nsemantically invalid abstract parsing trees (ASTs) while a parser is running,\nis needed because the parser may generate a huge number of potentially valid\nASTs for the same source code. We have implemented ProteaJ2, which is a\nprogramming language based on Java and it supports our proposal. We describe a\nparsing method that adopts eager disambiguation for fast parsing and discuss\nits time complexity. To show the practicality of our proposal, we have\nconducted two micro benchmarks to see the performance of our compiler. We also\nshow several use cases of dsl classes for demonstrating dsl classes can express\nvarious language constructs. Our ultimate goal is to let programmers add any\nkind of new language construct to a host language. To do this, programmers\nshould be able to define new syntax, name binding, and type system within the\nhost language. This paper shows programmers can define the former two: their\nown syntax and name binding.\n", "versions": [{"version": "v1", "created": "Fri, 31 Mar 2017 11:46:39 GMT"}], "update_date": "2017-04-03", "authors_parsed": [["Ichikawa", "Kazuhiro", "", "The University of Tokyo, Japan"], ["Chiba", "Shigeru", "", "The\n  University of Tokyo, Japan"]]}, {"id": "1703.10862", "submitter": "Patrick Rein", "authors": "Toni Mattis (Hasso Plattner Institute, Germany), Patrick Rein (Hasso\n  Plattner Institute, Germany), Robert Hirschfeld (Hasso Plattner Institute,\n  Germany)", "title": "Edit Transactions: Dynamically Scoped Change Sets for Controlled Updates\n  in Live Programming", "comments": null, "journal-ref": "The Art, Science, and Engineering of Programming, 2017, Vol. 1,\n  Issue 2, Article 13", "doi": "10.22152/programming-journal.org/2017/1/13", "report-no": null, "categories": "cs.SE cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Live programming environments enable programmers to edit a running program\nand obtain immediate feedback on each individual change. The liveness quality\nis valued by programmers to help work in small steps and continuously add or\ncorrect small functionality while maintaining the impression of a direct\nconnection between each edit and its manifestation at run-time. Such immediacy\nmay conflict with the desire to perform a combined set of intermediate steps,\nsuch as a refactoring, without immediately taking effect after each individual\nedit. This becomes important when an incomplete sequence of small-scale changes\ncan easily break the running program. State-of-the-art solutions focus on\nretroactive recovery mechanisms, such as debugging or version control. In\ncontrast, we propose a proactive approach: Multiple individual changes to the\nprogram are collected in an Edit Transaction, which can be made effective if\ndeemed complete. Upon activation, the combined steps become visible together.\nEdit Transactions are capable of dynamic scoping, allowing a set of changes to\nbe tested in isolation before being extended to the running application. This\nenables a live programming workflow with full control over change granularity,\nimmediate feedback on tests, delayed effect on the running application, and\ncoarse-grained undos. We present an implementation of Edit Transactions along\nwith Edit-Transaction-aware tools in Squeak/Smalltalk. We asses this\nimplementation by conducting a case study with and without the new tool\nsupport, comparing programming activities, errors, and detours for implementing\nnew functionality in a running simulation. We conclude that workflows using\nEdit Transactions have the potential to increase confidence in a change, reduce\npotential for run-time errors, and eventually make live programming more\npredictable and engaging.\n", "versions": [{"version": "v1", "created": "Fri, 31 Mar 2017 11:46:52 GMT"}, {"version": "v2", "created": "Mon, 3 Apr 2017 21:39:46 GMT"}], "update_date": "2017-04-05", "authors_parsed": [["Mattis", "Toni", "", "Hasso Plattner Institute, Germany"], ["Rein", "Patrick", "", "Hasso\n  Plattner Institute, Germany"], ["Hirschfeld", "Robert", "", "Hasso Plattner Institute,\n  Germany"]]}, {"id": "1703.10863", "submitter": "Tomas Petricek", "authors": "Tomas Petricek (Alan Turing Institute, United Kingdom)", "title": "Miscomputation in software: Learning to live with errors", "comments": null, "journal-ref": "The Art, Science, and Engineering of Programming, 2017, Vol. 1,\n  Issue 2, Article 14", "doi": "10.22152/programming-journal.org/2017/1/14", "report-no": null, "categories": "cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer programs do not always work as expected. In fact, ominous warnings\nabout the desperate state of the software industry continue to be released with\nalmost ritualistic regularity. In this paper, we look at the 60 years history\nof programming and at the different practical methods that software community\ndeveloped to live with programming errors. We do so by observing a class of\nstudents discussing different approaches to programming errors. While learning\nabout the different methods for dealing with errors, we uncover basic\nassumptions that proponents of different paradigms follow. We learn about the\nmathematical attempt to eliminate errors through formal methods, scientific\nmethod based on testing, a way of building reliable systems through engineering\nmethods, as well as an artistic approach to live coding that accepts errors as\na creative inspiration. This way, we can explore the differences and\nsimilarities among the different paradigms. By inviting proponents of different\nmethods into a single discussion, we hope to open potential for new thinking\nabout errors. When should we use which of the approaches? And what can software\ndevelopment learn from mathematics, science, engineering and art? When\nprogramming or studying programming, we are often enclosed in small communities\nand we take our basic assumptions for granted. Through the discussion in this\npaper, we attempt to map the large and rich space of programming ideas and\nprovide reference points for exploring, perhaps foreign, ideas that can\nchallenge some of our assumptions.\n", "versions": [{"version": "v1", "created": "Fri, 31 Mar 2017 11:47:06 GMT"}], "update_date": "2017-04-03", "authors_parsed": [["Petricek", "Tomas", "", "Alan Turing Institute, United Kingdom"]]}, {"id": "1703.10864", "submitter": "Kapil Arya", "authors": "Kapil Arya (Northeastern University, USA), Tyler Denniston (MIT, USA),\n  Ariel Rabkin (Cloudera, USA), Gene Cooperman (Northeastern University, USA)", "title": "Transition Watchpoints: Teaching Old Debuggers New Tricks", "comments": "arXiv admin note: text overlap with arXiv:1212.5204", "journal-ref": "The Art, Science, and Engineering of Programming, 2017, Vol. 1,\n  Issue 2, Article 16", "doi": "10.22152/programming-journal.org/2017/1/16", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reversible debuggers and process replay have been developed at least since\n1970. This vision enables one to execute backwards in time under a debugger.\nTwo important problems in practice are that, first, current reversible\ndebuggers are slow when reversing over long time periods, and, second, after\nbuilding one reversible debugger, it is difficult to transfer that achievement\nto a new programming environment. The user observes a bug when arriving at an\nerror. Searching backwards for the corresponding fault may require many reverse\nsteps. Ultimately, the user prefers to write an expression that will transition\nto false upon arriving at the fault. The solution is an expression-transition\nwatchpoint facility based on top of snapshots and record/replay.\nExpression-transition watch- points are implemented as binary search through\nthe timeline of a program execution, while using the snapshots as landmarks\nwithin that timeline. This allows for debugging of subtle bugs that appear only\nafter minutes or more of program execution. When a bug occurs within seconds of\nprogram startup, repeated debugging sessions suffice. Reversible debugging is\npreferred for bugs seen only after minutes. This architecture allows for an\nefficient and easy-to-write snapshot-based reversibe debugger on top of a\nconventional debugger. The validity of this approach was tested by developing\nfour personalities (for GDB, MATLAB, Perl, and Python), with each personality\ntypically requiring just 100 lines of code.\n", "versions": [{"version": "v1", "created": "Fri, 31 Mar 2017 11:47:28 GMT"}], "update_date": "2017-04-03", "authors_parsed": [["Arya", "Kapil", "", "Northeastern University, USA"], ["Denniston", "Tyler", "", "MIT, USA"], ["Rabkin", "Ariel", "", "Cloudera, USA"], ["Cooperman", "Gene", "", "Northeastern University, USA"]]}, {"id": "1703.10873", "submitter": "Walter Cazzola", "authors": "Walter Cazzola (Universit\\`a degli Studi di Milano, Italy), Albert\n  Shaqiri (Universit\\`a degli Studi di Milano, Italy)", "title": "Open Programming Language Interpreters", "comments": null, "journal-ref": "The Art, Science, and Engineering of Programming, 2017, Vol. 1,\n  Issue 2, Article 5", "doi": "10.22152/programming-journal.org/2017/1/5", "report-no": null, "categories": "cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Context: This paper presents the concept of open programming language\ninterpreters and the implementation of a framework-level metaobject protocol\n(MOP) to support them. Inquiry: We address the problem of dynamic interpreter\nadaptation to tailor the interpreter's behavior on the task to be solved and to\nintroduce new features to fulfill unforeseen requirements. Many languages\nprovide a MOP that to some degree supports reflection. However, MOPs are\ntypically language-specific, their reflective functionality is often\nrestricted, and the adaptation and application logic are often mixed which\nhardens the understanding and maintenance of the source code. Our system\novercomes these limitations. Approach: We designed and implemented a system to\nsupport open programming language interpreters. The prototype implementation is\nintegrated in the Neverlang framework. The system exposes the structure,\nbehavior and the runtime state of any Neverlang-based interpreter with the\nability to modify it. Knowledge: Our system provides a complete control over\ninterpreter's structure, behavior and its runtime state. The approach is\napplicable to every Neverlang-based interpreter. Adaptation code can\npotentially be reused across different language implementations. Grounding:\nHaving a prototype implementation we focused on feasibility evaluation. The\npaper shows that our approach well addresses problems commonly found in the\nresearch literature. We have a demonstrative video and examples that illustrate\nour approach on dynamic software adaptation, aspect-oriented programming,\ndebugging and context-aware interpreters. Importance: To our knowledge, our\npaper presents the first reflective approach targeting a general framework for\nlanguage development. Our system provides full reflective support for free to\nany Neverlang-based interpreter. We are not aware of any prior application of\nopen implementations to programming language interpreters in the sense defined\nin this paper. Rather than substituting other approaches, we believe our system\ncan be used as a complementary technique in situations where other approaches\npresent serious limitations.\n", "versions": [{"version": "v1", "created": "Fri, 31 Mar 2017 12:09:27 GMT"}], "update_date": "2017-04-03", "authors_parsed": [["Cazzola", "Walter", "", "Universit\u00e0 degli Studi di Milano, Italy"], ["Shaqiri", "Albert", "", "Universit\u00e0 degli Studi di Milano, Italy"]]}, {"id": "1703.10882", "submitter": "Nicole Vavrov\\'a", "authors": "Nicole Vavrov\\'a (Universiteit van Amsterdam, Netherlands), Vadim\n  Zaytsev (Raincode Labs, Belgium)", "title": "Does Python Smell Like Java? Tool Support for Design Defect Discovery in\n  Python", "comments": null, "journal-ref": "The Art, Science, and Engineering of Programming, 2017, Vol. 1,\n  Issue 2, Article 11", "doi": "10.22152/programming-journal.org/2017/1/11", "report-no": null, "categories": "cs.SE cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The context of this work is specification, detection and ultimately removal\nof detectable harmful patterns in source code that are associated with defects\nin design and implementation of software. In particular, we investigate five\ncode smells and four antipatterns previously defined in papers and books. Our\ninquiry is about detecting those in source code written in Python programming\nlanguage, which is substantially different from all prior research, most of\nwhich concerns Java or C-like languages. Our approach was that of software\nengineers: we have processed existing research literature on the topic,\nextracted both the abstract definitions of nine design defects and their\nconcrete implementation specifications, implemented them all in a tool we have\nprogrammed and let it loose on a huge test set obtained from open source code\nfrom thousands of GitHub projects. When it comes to knowledge, we have found\nthat more than twice as many methods in Python can be considered too long\n(statistically extremely longer than their neighbours within the same project)\nthan in Java, but long parameter lists are seven times less likely to be found\nin Python code than in Java code. We have also found that Functional\nDecomposition, the way it was defined for Java, is not found in the Python code\nat all, and Spaghetti Code and God Classes are extremely rare there as well.\nThe grounding and the confidence in these results comes from the fact that we\nhave performed our experiments on 32'058'823 lines of Python code, which is by\nfar the largest test set for a freely available Python parser. We have also\ndesigned the experiment in such a way that it aligned with prior research on\ndesign defect detection in Java in order to ease the comparison if we treat our\nown actions as a replication. Thus, the importance of the work is both in the\nunique open Python grammar of highest quality, tested on millions of lines of\ncode, and in the design defect detection tool which works on something else\nthan Java.\n", "versions": [{"version": "v1", "created": "Fri, 31 Mar 2017 12:47:50 GMT"}], "update_date": "2017-04-03", "authors_parsed": [["Vavrov\u00e1", "Nicole", "", "Universiteit van Amsterdam, Netherlands"], ["Zaytsev", "Vadim", "", "Raincode Labs, Belgium"]]}, {"id": "1703.10895", "submitter": "Sebastian Erdweg", "authors": "Sebastian Erdweg (TU Delft, Netherlands), Klaus Ostermann (University\n  of T\\\"ubingen, Germany)", "title": "A Module-System Discipline for Model-Driven Software Development", "comments": null, "journal-ref": "The Art, Science, and Engineering of Programming, 2017, Vol. 1,\n  Issue 2, Article 9", "doi": "10.22152/programming-journal.org/2017/1/9", "report-no": null, "categories": "cs.SE cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-driven development is a pragmatic approach to software development that\nembraces domain-specific languages (DSLs), where models correspond to DSL\nprograms. A distinguishing feature of model-driven development is that clients\nof a model can select from an open set of alternative semantics of the model by\napplying different model transformation. However, in existing model-driven\nframeworks, dependencies between models, model transformations, and generated\ncode artifacts are either implicit or globally declared in build scripts, which\nimpedes modular reasoning, separate compilation, and programmability in\ngeneral. We propose the design of a new module system that incorporates models\nand model transformations as modules. A programmer can apply transformations in\nimport statements, thus declaring a dependency on generated code artifacts. Our\ndesign enables modular reasoning and separate compilation by preventing hidden\ndependencies, and it supports mixing modeling artifacts with conventional code\nartifacts as well as higher-order transformations. We have formalized our\ndesign and the aforementioned properties and have validated it by an\nimplementation and case studies that show that our module system successfully\nintegrates model-driven development into conventional programming languages.\n", "versions": [{"version": "v1", "created": "Fri, 31 Mar 2017 13:54:32 GMT"}], "update_date": "2017-04-03", "authors_parsed": [["Erdweg", "Sebastian", "", "TU Delft, Netherlands"], ["Ostermann", "Klaus", "", "University\n  of T\u00fcbingen, Germany"]]}, {"id": "1703.10959", "submitter": "Thom Fruehwirth", "authors": "Thom Fruehwirth", "title": "Parallelism, Concurrency and Distribution in Constraint Handling Rules:\n  A Survey", "comments": "Under consideration in Theory and Practice of Logic Programming\n  (TPLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constraint Handling Rules is an effective concurrent declarative programming\nlanguage and a versatile computational logic formalism. CHR programs consist of\nguarded reactive rules that transform multisets of constraints. One of the main\nfeatures of CHR is its inherent concurrency. Intuitively, rules can be applied\nto parts of a multiset in parallel. In this comprehensive survey, we give an\noverview of concurrent and parallel as well as distributed CHR semantics,\nstandard and more exotic, that have been proposed over the years at various\nlevels of refinement. These semantics range from the abstract to the concrete.\nThey are related by formal soundness results. Their correctness is established\nas correspondence between parallel and sequential computations. We present\ncommon concise sample CHR programs that have been widely used in experiments\nand benchmarks. We review parallel CHR implementations in software and\nhardware. The experimental results obtained show a consistent parallel speedup.\nMost implementations are available online. The CHR formalism can also be used\nto implement and reason with models for concurrency. To this end, the Software\nTransaction Model, the Actor Model, Colored Petri Nets and the Join-Calculus\nhave been faithfully encoded in CHR. Under consideration in Theory and Practice\nof Logic Programming (TPLP).\n", "versions": [{"version": "v1", "created": "Fri, 31 Mar 2017 15:51:51 GMT"}, {"version": "v2", "created": "Mon, 3 Apr 2017 11:53:11 GMT"}, {"version": "v3", "created": "Fri, 22 Dec 2017 12:59:30 GMT"}, {"version": "v4", "created": "Fri, 6 Apr 2018 15:41:19 GMT"}], "update_date": "2018-04-09", "authors_parsed": [["Fruehwirth", "Thom", ""]]}, {"id": "1703.10994", "submitter": "Abhishek Kr Singh", "authors": "Abhishek Kr Singh and Raja Natrajan", "title": "An Outline of Separation Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Separation Logic is an effective Program Logic for proving programs that\ninvolve pointers. Reasoning with pointers becomes difficult especially when\nthere is aliasing arising due to several pointers to a given cell location. In\nthis paper, we try to explore the problems with aliasing through some simple\nexamples and introduce the notion of separating conjunction as a tool to deal\nwith it. We introduce Separation Logic as an extension of the standard Hoare\nLogic with the help pf a programming language that has four pointer\nmanipulating commands. These commands perform the usual heap operations such as\nlookup, update, allocation and deallocation. The new set of assertions and\naxioms of Separation Logic is presented in a semi-formal style. Examples are\ngiven to illustrate the unique features of the new assertions and axioms.\nFinally the paper concludes with the proofs of some real programs using the\naxioms of Separation Logic.\n", "versions": [{"version": "v1", "created": "Fri, 31 Mar 2017 17:32:17 GMT"}], "update_date": "2017-04-07", "authors_parsed": [["Singh", "Abhishek Kr", ""], ["Natrajan", "Raja", ""]]}]