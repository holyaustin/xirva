[{"id": "1608.00089", "submitter": "Dana Drachsler-Cohen", "authors": "Dana Drachsler-Cohen, Martin Vechev, and Eran Yahav", "title": "Optimal Learning of Specifications from Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental challenge in synthesis from examples is designing a learning\nalgorithm that poses the minimal number of questions to an end user while\nguaranteeing that the target hypothesis is discovered. Such guarantees are\npractically important because they ensure that end users will not be\noverburdened with unnecessary questions.\n  We present SPEX -- a learning algorithm that addresses the above challenge.\nSPEX considers the hypothesis space of formulas over first-order predicates and\nlearns the correct hypothesis by only asking the user simple membership queries\nfor concrete examples. Thus, SPEX is directly applicable to any learning\nproblem that fits its hypothesis space and uses membership queries.\n  SPEX works by iteratively eliminating candidate hypotheses from the space\nuntil converging to the target hypothesis. The main idea is to use the\nimplication order between hypotheses to guarantee that in each step the\nquestion presented to the user obtains maximal pruning of the space. This\nproblem is particularly challenging when predicates are potentially correlated.\n  To show that SPEX is practically useful, we expressed two rather different\napplications domains in its framework: learning programs for the domain of\ntechnical analysts (stock trading) and learning data structure specifications.\nThe experimental results show that SPEX's optimality guarantee is effective: it\ndrastically reduces the number of questions posed to the user while\nsuccessfully learning the exact hypothesis.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jul 2016 08:12:32 GMT"}], "update_date": "2016-08-02", "authors_parsed": [["Drachsler-Cohen", "Dana", ""], ["Vechev", "Martin", ""], ["Yahav", "Eran", ""]]}, {"id": "1608.00099", "submitter": "Oliver Serang", "authors": "Florian Heyl, Oliver Serang", "title": "TRIOT: Faster tensor manipulation in C++11", "comments": null, "journal-ref": "The Art, Science, and Engineering of Programming, 2017, Vol. 1,\n  Issue 2, Article 6", "doi": "10.22152/programming-journal.org/2017/1/6", "report-no": null, "categories": "cs.MS cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  [abridged] Context: Multidimensional arrays are used by many different\nalgorithms. As such, indexing and broadcasting complex operations over\nmultidimensional arrays are ubiquitous tasks and can be performance limiting.\nInquiry: Simultaneously indexing two or more multidimensional arrays with\ndifferent shapes (e.g., copying data from one tensor to another larger, zero\npadded tensor in anticipation of a convolution) is difficult to do efficiently:\nHard-coded nested for loops in C, Fortran, and Go cannot be applied when the\ndimension of a tensor is unknown at compile time. Likewise, boost::multi_array\ncannot be used unless the dimensions of the array are known at compile time,\nand the style of implementation restricts the user from using the index tuple\ninside a vectorized operation (as would be required to compute an expected\nvalue of a multidimensional distribution). On the other hand, iteration methods\nthat do not require the dimensionality or shape to be known at compile time\n(e.g., incrementing and applying carry operations to index tuples or remapping\ninteger indices in the flat array), can be substantially slower than hard-coded\nnested for loops. ... Importance: Manipulation of multidimensional arrays is a\ncommon task in software, especially in high performance numerical methods. This\npaper proposes a novel way to leverage template recursion to iterate over and\napply operations to multidimensional arrays, and then demonstrates the superior\nperformance and flexibility of operations that can be achieved using this new\napproach.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jul 2016 10:40:29 GMT"}, {"version": "v2", "created": "Fri, 31 Mar 2017 22:40:34 GMT"}], "update_date": "2017-04-04", "authors_parsed": [["Heyl", "Florian", ""], ["Serang", "Oliver", ""]]}, {"id": "1608.00571", "submitter": "Daniel Sorin", "authors": "Blake A. Hechtman, Andrew D. Hilton, and Daniel J. Sorin", "title": "TREES: A CPU/GPU Task-Parallel Runtime with Explicit Epoch\n  Synchronization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.OS cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We have developed a task-parallel runtime system, called TREES, that is\ndesigned for high performance on CPU/GPU platforms. On platforms with multiple\nCPUs, Cilk's \"work-first\" principle underlies how task-parallel applications\ncan achieve performance, but work-first is a poor fit for GPUs. We build upon\nwork-first to create the \"work-together\" principle that addresses the specific\nstrengths and weaknesses of GPUs. The work-together principle extends\nwork-first by stating that (a) the overhead on the critical path should be paid\nby the entire system at once and (b) work overheads should be paid\nco-operatively. We have implemented the TREES runtime in OpenCL, and we\nexperimentally evaluate TREES applications on a CPU/GPU platform.\n", "versions": [{"version": "v1", "created": "Mon, 1 Aug 2016 15:33:14 GMT"}], "update_date": "2016-08-03", "authors_parsed": [["Hechtman", "Blake A.", ""], ["Hilton", "Andrew D.", ""], ["Sorin", "Daniel J.", ""]]}, {"id": "1608.00730", "submitter": "Carmine Dodaro", "authors": "Carmine Dodaro, Philip Gasteiger, Nicola Leone, Benjamin Musitsch,\n  Francesco Ricca, Kostyantyn Shchekotykhin", "title": "Combining Answer Set Programming and Domain Heuristics for Solving Hard\n  Industrial Problems (Application Paper)", "comments": "Paper presented at the 32nd International Conference on Logic\n  Programming (ICLP 2016), New York City, USA, 16-21 October 2016, 15 pages,\n  LaTeX, 3 PDF figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Answer Set Programming (ASP) is a popular logic programming paradigm that has\nbeen applied for solving a variety of complex problems. Among the most\nchallenging real-world applications of ASP are two industrial problems defined\nby Siemens: the Partner Units Problem (PUP) and the Combined Configuration\nProblem (CCP). The hardest instances of PUP and CCP are out of reach for\nstate-of-the-art ASP solvers. Experiments show that the performance of ASP\nsolvers could be significantly improved by embedding domain-specific\nheuristics, but a proper effective integration of such criteria in\noff-the-shelf ASP implementations is not obvious. In this paper the combination\nof ASP and domain-specific heuristics is studied with the goal of effectively\nsolving real-world problem instances of PUP and CCP. As a byproduct of this\nactivity, the ASP solver WASP was extended with an interface that eases\nembedding new external heuristics in the solver. The evaluation shows that our\ndomain-heuristic-driven ASP solver finds solutions for all the real-world\ninstances of PUP and CCP ever provided by Siemens. This paper is under\nconsideration for acceptance in TPLP.\n", "versions": [{"version": "v1", "created": "Tue, 2 Aug 2016 08:36:08 GMT"}], "update_date": "2016-08-03", "authors_parsed": [["Dodaro", "Carmine", ""], ["Gasteiger", "Philip", ""], ["Leone", "Nicola", ""], ["Musitsch", "Benjamin", ""], ["Ricca", "Francesco", ""], ["Shchekotykhin", "Kostyantyn", ""]]}, {"id": "1608.00787", "submitter": "Alexander Vandenbroucke", "authors": "Alexander Vandenbroucke, Maciej Pir\\'og, Benoit Desouter and Tom\n  Schrijvers", "title": "Tabling with Sound Answer Subsumption", "comments": "Paper presented at the 32nd International Conference on Logic\n  Programming (ICLP 2016), New York City, USA, 16-21 October 2016, 15 pages,\n  LaTeX, 0 PDF figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tabling is a powerful resolution mechanism for logic programs that captures\ntheir least fixed point semantics more faithfully than plain Prolog. In many\ntabling applications, we are not interested in the set of all answers to a\ngoal, but only require an aggregation of those answers. Several works have\nstudied efficient techniques, such as lattice-based answer subsumption and\nmode-directed tabling, to do so for various forms of aggregation.\n  While much attention has been paid to expressivity and efficient\nimplementation of the different approaches, soundness has not been considered.\nThis paper shows that the different implementations indeed fail to produce\nleast fixed points for some programs. As a remedy, we provide a formal\nframework that generalises the existing approaches and we establish a soundness\ncriterion that explains for which programs the approach is sound.\n  This article is under consideration for acceptance in TPLP.\n", "versions": [{"version": "v1", "created": "Tue, 2 Aug 2016 12:23:16 GMT"}], "update_date": "2016-08-03", "authors_parsed": [["Vandenbroucke", "Alexander", ""], ["Pir\u00f3g", "Maciej", ""], ["Desouter", "Benoit", ""], ["Schrijvers", "Tom", ""]]}, {"id": "1608.00816", "submitter": "Amr Hany Saleh", "authors": "Amr Hany Saleh and Tom Schrijvers", "title": "Efficient Algebraic Effect Handlers for Prolog", "comments": "Paper presented at the 32nd International Conference on Logic\n  Programming (ICLP 2016), New York City, USA, 16-21 October 2016, LaTex, 14\n  pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has provided delimited control for Prolog to dynamically\nmanipulate the program control-flow, and to implement a wide range of\ncontrol-flow and dataflow effects on top of. Unfortunately, delimited control\nis a rather primitive language feature that is not easy to use.\n  As a remedy, this work introduces algebraic effect handlers for Prolog, as a\nhigh-level and structured way of defining new side-effects in a modular\nfashion. We illustrate the expressive power of the feature and provide an\nimplementation by means of elaboration into the delimited control primitives.\n  The latter add a non-negligible performance overhead when used extensively.\nTo address this issue, we present an optimised compilation approach that\ncombines partial evaluation with dedicated rewrite rules. The rewrite rules are\ndriven by a lightweight effect inference that analyses what effect operations\nmay be called by a goal. We illustrate the effectiveness of this approach on a\nrange of benchmarks. This article is under consideration for acceptance in\nTPLP.\n", "versions": [{"version": "v1", "created": "Tue, 2 Aug 2016 13:38:00 GMT"}], "update_date": "2016-08-03", "authors_parsed": [["Saleh", "Amr Hany", ""], ["Schrijvers", "Tom", ""]]}, {"id": "1608.00989", "submitter": "Jan Wielemaker", "authors": "Jan Wielemaker and Keri Harris", "title": "Lock-free atom garbage collection for multithreaded Prolog", "comments": "Paper presented at the 32nd International Conference on Logic\n  Programming (ICLP 2016), New York City, USA, 16-21 October 2016, 14 pages,\n  LaTeX, 4 PDF figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The runtime system of dynamic languages such as Prolog or Lisp and their\nderivatives contain a symbol table, in Prolog often called the atom table. A\nsimple dynamically resizing hash-table used to be an adequate way to implement\nthis table. As Prolog becomes fashionable for 24x7 server processes we need to\ndeal with atom garbage collection and concurrent access to the atom table.\nClassical lock-based implementations to ensure consistency of the atom table\nscale poorly and a stop-the-world approach to implement atom garbage collection\nquickly becomes a bottle-neck, making Prolog unsuitable for soft real-time\napplications. In this article we describe a novel implementation for the atom\ntable using lock-free techniques where the atom-table remains accessible even\nduring atom garbage collection. Relying only on CAS (Compare And Swap) and not\non external libraries, the implementation is straightforward and portable.\n  Under consideration for acceptance in TPLP.\n", "versions": [{"version": "v1", "created": "Tue, 2 Aug 2016 20:11:56 GMT"}], "update_date": "2016-08-04", "authors_parsed": [["Wielemaker", "Jan", ""], ["Harris", "Keri", ""]]}, {"id": "1608.01036", "submitter": "Michael J. Steindorfer", "authors": "Michael J. Steindorfer and Jurgen J. Vinju", "title": "Fast and Lean Immutable Multi-Maps on the JVM based on Heterogeneous\n  Hash-Array Mapped Tries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An immutable multi-map is a many-to-many thread-friendly map data structure\nwith expected fast insert and lookup operations. This data structure is used\nfor applications processing graphs or many-to-many relations as applied in\nstatic analysis of object-oriented systems. When processing such big data sets\nthe memory overhead of the data structure encoding itself is a memory usage\nbottleneck. Motivated by reuse and type-safety, libraries for Java, Scala and\nClojure typically implement immutable multi-maps by nesting sets as the values\nwith the keys of a trie map. Like this, based on our measurements the expected\nbyte overhead for a sparse multi-map per stored entry adds up to around 65B,\nwhich renders it unfeasible to compute with effectively on the JVM.\n  In this paper we propose a general framework for Hash-Array Mapped Tries on\nthe JVM which can store type-heterogeneous keys and values: a Heterogeneous\nHash-Array Mapped Trie (HHAMT). Among other applications, this allows for a\nhighly efficient multi-map encoding by (a) not reserving space for empty value\nsets and (b) inlining the values of singleton sets while maintaining a (c)\ntype-safe API.\n  We detail the necessary encoding and optimizations to mitigate the overhead\nof storing and retrieving heterogeneous data in a hash-trie. Furthermore, we\nevaluate HHAMT specifically for the application to multi-maps, comparing them\nto state-of-the-art encodings of multi-maps in Java, Scala and Clojure. We\nisolate key differences using microbenchmarks and validate the resulting\nconclusions on a real world case in static analysis. The new encoding brings\nthe per key-value storage overhead down to 30B: a 2x improvement. With\nadditional inlining of primitive values it reaches a 4x improvement.\n", "versions": [{"version": "v1", "created": "Wed, 3 Aug 2016 00:35:42 GMT"}], "update_date": "2016-08-04", "authors_parsed": [["Steindorfer", "Michael J.", ""], ["Vinju", "Jurgen J.", ""]]}, {"id": "1608.01106", "submitter": "Maja Hanne Kirkeby", "authors": "Maja H. Kirkeby and Mads Rosendahl", "title": "Probabilistic Resource Analysis by Program Transformation", "comments": null, "journal-ref": "Lecture Notes in Computer Science 9964 (2016) 60-80", "doi": "10.1007/978-3-319-46559-3_4", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of a probabilistic resource analysis is to derive a probability\ndistribution of possible resource usage for a program from a probability\ndistribution of its input. We present an automated multi- phase rewriting based\nmethod to analyze programs written in a subset of C. It generates a probability\ndistribution of the resource usage as a possibly uncomputable expression and\nthen transforms it into a closed form expression using over-approximations. We\npresent the technique, outline the implementation and show results from\nexperiments with the system.\n", "versions": [{"version": "v1", "created": "Wed, 3 Aug 2016 08:23:34 GMT"}, {"version": "v2", "created": "Thu, 15 Dec 2016 07:51:56 GMT"}], "update_date": "2016-12-16", "authors_parsed": [["Kirkeby", "Maja H.", ""], ["Rosendahl", "Mads", ""]]}, {"id": "1608.01594", "submitter": "K. Tuncay Tekle", "authors": "K. Tuncay Tekle, Yanhong A. Liu", "title": "Precise Complexity Guarantees for Pointer Analysis via Datalog with\n  Extensions", "comments": "Paper presented at the 32nd International Conference on Logic\n  Programming (ICLP 2016), New York City, USA, 16-21 October 2016, 19 pages,\n  LaTeX", "journal-ref": "Theory and Practice of Logic Programming, Volume 16, Special Issue\n  5-6, September 2016, pp. 916-932", "doi": "10.1017/S1471068416000405", "report-no": null, "categories": "cs.PL cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pointer analysis is a fundamental static program analysis for computing the\nset of objects that an expression can refer to. Decades of research has gone\ninto developing methods of varying precision and efficiency for pointer\nanalysis for programs that use different language features, but determining\nprecisely how efficient a particular method is has been a challenge in itself.\n  For programs that use different language features, we consider methods for\npointer analysis using Datalog and extensions to Datalog. When the rules are in\nDatalog, we present the calculation of precise time complexities from the rules\nusing a new algorithm for decomposing rules for obtaining the best\ncomplexities. When extensions such as function symbols and universal\nquantification are used, we describe algorithms for efficiently implementing\nthe extensions and the complexities of the algorithms.\n  This paper is under consideration for acceptance in TPLP.\n", "versions": [{"version": "v1", "created": "Thu, 4 Aug 2016 16:05:13 GMT"}, {"version": "v2", "created": "Mon, 8 Aug 2016 15:46:20 GMT"}], "update_date": "2019-02-01", "authors_parsed": [["Tekle", "K. Tuncay", ""], ["Liu", "Yanhong A.", ""]]}, {"id": "1608.01654", "submitter": "Mounir Assaf", "authors": "Mounir Assaf, David A. Naumann, Julien Signoles, \\'Eric Totel,\n  Fr\\'ed\\'eric Tronel", "title": "Hypercollecting Semantics and its Application to Static Analysis of\n  Information Flow", "comments": null, "journal-ref": null, "doi": "10.1145/3009837.3009889", "report-no": null, "categories": "cs.PL cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how static analysis for secure information flow can be expressed and\nproved correct entirely within the framework of abstract interpretation. The\nkey idea is to define a Galois connection that directly approximates the\nhyperproperty of interest. To enable use of such Galois connections, we\nintroduce a fixpoint characterisation of hypercollecting semantics, i.e. a \"set\nof set\" transformer. This makes it possible to systematically derive static\nanalyses for hyperproperties entirely within the calculational framework of\nabstract interpretation. We evaluate this technique by deriving example static\nanalyses. For qualitative information flow, we derive a dependence analysis\nsimilar to the logic of Amtoft and Banerjee (SAS'04) and the type system of\nHunt and Sands (POPL'06). For quantitative information flow, we derive a novel\ncardinality analysis that bounds the leakage conveyed by a program instead of\nsimply deciding whether it exists. This encompasses problems that are\nhypersafety but not k-safety. We put the framework to use and introduce\nvariations that achieve precision rivalling the most recent and precise static\nanalyses for information flow.\n", "versions": [{"version": "v1", "created": "Thu, 4 Aug 2016 19:40:42 GMT"}, {"version": "v2", "created": "Mon, 7 Nov 2016 12:50:06 GMT"}], "update_date": "2016-11-08", "authors_parsed": [["Assaf", "Mounir", ""], ["Naumann", "David A.", ""], ["Signoles", "Julien", ""], ["Totel", "\u00c9ric", ""], ["Tronel", "Fr\u00e9d\u00e9ric", ""]]}, {"id": "1608.01723", "submitter": "Osbert Bastani", "authors": "Osbert Bastani, Rahul Sharma, Alex Aiken, Percy Liang", "title": "Synthesizing Program Input Grammars", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an algorithm for synthesizing a context-free grammar encoding the\nlanguage of valid program inputs from a set of input examples and blackbox\naccess to the program. Our algorithm addresses shortcomings of existing grammar\ninference algorithms, which both severely overgeneralize and are prohibitively\nslow. Our implementation, GLADE, leverages the grammar synthesized by our\nalgorithm to fuzz test programs with structured inputs. We show that GLADE\nsubstantially increases the incremental coverage on valid inputs compared to\ntwo baseline fuzzers.\n", "versions": [{"version": "v1", "created": "Fri, 5 Aug 2016 00:13:42 GMT"}, {"version": "v2", "created": "Fri, 16 Jun 2017 10:41:54 GMT"}], "update_date": "2017-06-19", "authors_parsed": [["Bastani", "Osbert", ""], ["Sharma", "Rahul", ""], ["Aiken", "Alex", ""], ["Liang", "Percy", ""]]}, {"id": "1608.02012", "submitter": "Marco Tulio Valente", "authors": "Miguel Ramos, Marco Tulio Valente, Ricardo Terra, Gustavo Santos", "title": "AngularJS in the Wild: A Survey with 460 Developers", "comments": "Accepted at 7th Workshop on Evaluation and Usability of Programming\n  Languages and Tools (PLATEAU)", "journal-ref": null, "doi": "10.1145/3001878.3001881", "report-no": null, "categories": "cs.SE cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To implement modern web applications, a new family of JavaScript frameworks\nhas emerged, using the MVC pattern. Among these frameworks, the most popular\none is AngularJS, which is supported by Google. In spite of its popularity,\nthere is not a clear knowledge on how AngularJS design and features affect the\ndevelopment experience of Web applications. Therefore, this paper reports the\nresults of a survey about AngularJS, including answers from 460 developers. Our\ncontributions include the identification of the most appreciated features of\nAngularJS (e.g., custom interface components, dependency injection, and two-way\ndata binding) and the most problematic aspects of the framework (e.g.,\nperformance and implementation of directives).\n", "versions": [{"version": "v1", "created": "Fri, 5 Aug 2016 20:21:57 GMT"}, {"version": "v2", "created": "Sun, 25 Sep 2016 21:56:34 GMT"}, {"version": "v3", "created": "Tue, 27 Sep 2016 23:47:43 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Ramos", "Miguel", ""], ["Valente", "Marco Tulio", ""], ["Terra", "Ricardo", ""], ["Santos", "Gustavo", ""]]}, {"id": "1608.02534", "submitter": "Pedro Lopez-Garcia", "authors": "Manuel V. Hermenegildo and Pedro Lopez-Garcia", "title": "Pre-proceedings of the 26th International Symposium on Logic-Based\n  Program Synthesis and Transformation (LOPSTR 2016)", "comments": "Papers selected for presentation at LOPSTR 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume constitutes the pre-proceedings of the 26th International\nSymposium on Logic-Based Program Synthesis and Transformation (LOPSTR 2016),\nheld on 6-8th September 2016 in Edinburgh, Scotland UK, and co-located with the\n18th International Symposium on Principles and Practice of Declarative\nProgramming (PPDP 2016) and the 23rd Static Analysis Symposium (SAS 2016).\nAfter discussion at the symposium papers will go through a second round of\nrefereeing and selection for the formal proceedings.\n", "versions": [{"version": "v1", "created": "Mon, 8 Aug 2016 17:57:30 GMT"}, {"version": "v2", "created": "Thu, 1 Sep 2016 15:52:11 GMT"}], "update_date": "2016-09-02", "authors_parsed": [["Hermenegildo", "Manuel V.", ""], ["Lopez-Garcia", "Pedro", ""]]}, {"id": "1608.02565", "submitter": "Isabel Garcia-Contreras", "authors": "Isabel Garcia-Contreras, Jose F. Morales and Manuel V. Hermenegildo", "title": "Semantic Code Browsing", "comments": "Paper presented at the 32nd International Conference on Logic\n  Programming (ICLP 2016), New York City, USA, 16-21 October 2016, 15 pages,\n  LaTeX, 4 PDF figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Programmers currently enjoy access to a very high number of code repositories\nand libraries of ever increasing size. The ensuing potential for reuse is\nhowever hampered by the fact that searching within all this code becomes an\nincreasingly difficult task. Most code search engines are based on syntactic\ntechniques such as signature matching or keyword extraction. However, these\ntechniques are inaccurate (because they basically rely on documentation) and at\nthe same time do not offer very expressive code query languages. We propose a\nnovel approach that focuses on querying for semantic characteristics of code\nobtained automatically from the code itself. Program units are pre-processed\nusing static analysis techniques, based on abstract interpretation, obtaining\nsafe semantic approximations. A novel, assertion-based code query language is\nused to express desired semantic characteristics of the code as partial\nspecifications. Relevant code is found by comparing such partial specifications\nwith the inferred semantics for program elements. Our approach is fully\nautomatic and does not rely on user annotations or documentation. It is more\npowerful and flexible than signature matching because it is parametric on the\nabstract domain and properties, and does not require type definitions. Also, it\nreasons with relations between properties, such as implication and abstraction,\nrather than just equality. It is also more resilient to syntactic code\ndifferences. We describe the approach and report on a prototype implementation\nwithin the Ciao system.\n  Under consideration for acceptance in TPLP.\n", "versions": [{"version": "v1", "created": "Mon, 8 Aug 2016 19:25:10 GMT"}], "update_date": "2016-08-09", "authors_parsed": [["Garcia-Contreras", "Isabel", ""], ["Morales", "Jose F.", ""], ["Hermenegildo", "Manuel V.", ""]]}, {"id": "1608.02692", "submitter": "EPTCS", "authors": "Daniel Gebler, Kirstin Peters", "title": "Proceedings Combined 23rd International Workshop on Expressiveness in\n  Concurrency and 13th Workshop on Structural Operational Semantics", "comments": null, "journal-ref": "EPTCS 222, 2016", "doi": "10.4204/EPTCS.222", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the proceedings of the Combined 23nd International\nWorkshop on Expressiveness in Concurrency and the 13th Workshop on Structural\nOperational Semantics (EXPRESS/SOS 2016) which was held on 22 August 2016 in\nQu\\'ebec City, Canada, as an affiliated workshop of CONCUR 2016, the 27th\nInternational Conference on Concurrency Theory. The EXPRESS workshops aim at\nbringing together researchers interested in the expressiveness of various\nformal systems and semantic notions, particularly in the field of concurrency.\nTheir focus has traditionally been on the comparison between programming\nconcepts (such as concurrent, functional, imperative, logic and object-oriented\nprogramming) and between mathematical models of computation (such as process\nalgebras, Petri nets, event structures, modal logics, and rewrite systems) on\nthe basis of their relative expressive power. The EXPRESS workshop series has\nrun successfully since 1994 and over the years this focus has become broadly\nconstrued. The SOS workshops aim at being a forum for researchers, students and\npractitioners interested in new developments, and directions for future\ninvestigation, in the field of structural operational semantics. One of the\nspecific goals of the SOS workshop series is to establish synergies between the\nconcurrency and programming language communities working on the theory and\npractice of SOS. Since 2012, the EXPRESS and SOS communities have organized an\nannual combined EXPRESS/SOS workshop on the expressiveness of mathematical\nmodels of computation and the formal semantics of systems and programming\nconcepts.\n", "versions": [{"version": "v1", "created": "Tue, 9 Aug 2016 05:24:04 GMT"}], "update_date": "2016-08-10", "authors_parsed": [["Gebler", "Daniel", ""], ["Peters", "Kirstin", ""]]}, {"id": "1608.02780", "submitter": "Pedro Lopez-Garcia", "authors": "Pedro Lopez-Garcia and Maximiliano Klemen and Umer Liqat and Manuel V.\n  Hermenegildo", "title": "A General Framework for Static Profiling of Parametric Resource Usage", "comments": "Paper presented at the 32nd International Conference on Logic\n  Programming (ICLP 2016), New York City, USA, 16-21 October 2016, 22 pages,\n  LaTeX", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional static resource analyses estimate the total resource usage of a\nprogram, without executing it. In this paper we present a novel resource\nanalysis whose aim is instead the static profiling of accumulated cost, i.e.,\nto discover, for selected parts of the program, an estimate or bound of the\nresource usage accumulated in each of those parts. Traditional resource\nanalyses are parametric in the sense that the results can be functions on input\ndata sizes. Our static profiling is also parametric, i.e., our accumulated cost\nestimates are also parameterized by input data sizes. Our proposal is based on\nthe concept of cost centers and a program transformation that allows the static\ninference of functions that return bounds on these accumulated costs depending\non input data sizes, for each cost center of interest. Such information is much\nmore useful to the software developer than the traditional resource usage\nfunctions, as it allows identifying the parts of a program that should be\noptimized, because of their greater impact on the total cost of program\nexecutions. We also report on our implementation of the proposed technique\nusing the CiaoPP program analysis framework, and provide some experimental\nresults. This paper is under consideration for acceptance in TPLP.\n", "versions": [{"version": "v1", "created": "Tue, 9 Aug 2016 12:13:02 GMT"}, {"version": "v2", "created": "Mon, 17 Oct 2016 10:44:20 GMT"}], "update_date": "2016-10-18", "authors_parsed": [["Lopez-Garcia", "Pedro", ""], ["Klemen", "Maximiliano", ""], ["Liqat", "Umer", ""], ["Hermenegildo", "Manuel V.", ""]]}, {"id": "1608.02829", "submitter": "Ravi Chugh", "authors": "Brian Hempel and Ravi Chugh", "title": "Semi-Automated SVG Programming via Direct Manipulation", "comments": "In 29th ACM User Interface Software and Technology Symposium (UIST\n  2016)", "journal-ref": null, "doi": "10.1145/2984511.2984575", "report-no": null, "categories": "cs.HC cs.GR cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Direct manipulation interfaces provide intuitive and interactive features to\na broad range of users, but they often exhibit two limitations: the built-in\nfeatures cannot possibly cover all use cases, and the internal representation\nof the content is not readily exposed. We believe that if direct manipulation\ninterfaces were to (a) use general-purpose programs as the representation\nformat, and (b) expose those programs to the user, then experts could customize\nthese systems in powerful new ways and non-experts could enjoy some of the\nbenefits of programmable systems.\n  In recent work, we presented a prototype SVG editor called Sketch-n-Sketch\nthat offered a step towards this vision. In that system, the user wrote a\nprogram in a general-purpose lambda-calculus to generate a graphic design and\ncould then directly manipulate the output to indirectly change design\nparameters (i.e. constant literals) in the program in real-time during the\nmanipulation. Unfortunately, the burden of programming the desired\nrelationships rested entirely on the user.\n  In this paper, we design and implement new features for Sketch-n-Sketch that\nassist in the programming process itself. Like typical direct manipulation\nsystems, our extended Sketch-n-Sketch now provides GUI-based tools for drawing\nshapes, relating shapes to each other, and grouping shapes together. Unlike\ntypical systems, however, each tool carries out the user's intention by\ntransforming their general-purpose program. This novel, semi-automated\nprogramming workflow allows the user to rapidly create high-level, reusable\nabstractions in the program while at the same time retaining direct\nmanipulation capabilities. In future work, our approach may be extended with\nmore graphic design features or realized for other application domains.\n", "versions": [{"version": "v1", "created": "Tue, 9 Aug 2016 15:17:46 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Hempel", "Brian", ""], ["Chugh", "Ravi", ""]]}, {"id": "1608.02896", "submitter": "Enrique Martin-Martin", "authors": "Elvira Albert, Nikolaos Bezirgiannis, Frank de Boer, Enrique\n  Martin-Martin", "title": "A Formal, Resource Consumption-Preserving Translation of Actors to\n  Haskell", "comments": "Pre-proceedings paper presented at the 26th International Symposium\n  on Logic-Based Program Synthesis and Transformation (LOPSTR 2016), Edinburgh,\n  Scotland UK, 6-8 September 2016 (arXiv:1608.02534)", "journal-ref": null, "doi": null, "report-no": "LOPSTR/2016/35", "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a formal translation of an actor-based language with cooperative\nscheduling to the functional language Haskell. The translation is proven\ncorrect with respect to a formal semantics of the source language and a\nhigh-level operational semantics of the target, i.e. a subset of Haskell. The\nmain correctness theorem is expressed in terms of a simulation relation between\nthe operational semantics of actor programs and their translation. This allows\nus to then prove that the resource consumption is preserved over this\ntranslation, as we establish an equivalence of the cost of the original and\nHaskell-translated execution traces.\n", "versions": [{"version": "v1", "created": "Tue, 9 Aug 2016 18:13:45 GMT"}, {"version": "v2", "created": "Wed, 10 Aug 2016 07:56:38 GMT"}], "update_date": "2016-08-11", "authors_parsed": [["Albert", "Elvira", ""], ["Bezirgiannis", "Nikolaos", ""], ["de Boer", "Frank", ""], ["Martin-Martin", "Enrique", ""]]}, {"id": "1608.03125", "submitter": "EPTCS", "authors": "Eduard Baranov (Ecole polytechnique f\\'ed\\'erale de Lausanne), Simon\n  Bliudze (Ecole polytechnique f\\'ed\\'erale de Lausanne)", "title": "A Note on the Expressiveness of BIP", "comments": "In Proceedings EXPRESS/SOS 2016, arXiv:1608.02692", "journal-ref": "EPTCS 222, 2016, pp. 1-14", "doi": "10.4204/EPTCS.222.1", "report-no": null, "categories": "cs.DC cs.LO cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend our previous algebraic formalisation of the notion of\ncomponent-based framework in order to formally define two forms, strong and\nweak, of the notion of full expressiveness. Our earlier result shows that the\nBIP (Behaviour-Interaction-Priority) framework does not possess the strong full\nexpressiveness. In this paper, we show that BIP has the weak form of this\nnotion and provide results detailing weak and strong full expressiveness for\nclassical BIP and several modifications, obtained by relaxing the constraints\nimposed on priority models.\n", "versions": [{"version": "v1", "created": "Wed, 10 Aug 2016 11:10:33 GMT"}], "update_date": "2016-08-11", "authors_parsed": [["Baranov", "Eduard", "", "Ecole polytechnique f\u00e9d\u00e9rale de Lausanne"], ["Bliudze", "Simon", "", "Ecole polytechnique f\u00e9d\u00e9rale de Lausanne"]]}, {"id": "1608.03127", "submitter": "EPTCS", "authors": "Sanjiva Prasad (Indian Institute of Technology Delhi), Lenore D. Zuck\n  (University of Illinois at Chicago)", "title": "Self-Similarity Breeds Resilience", "comments": "In Proceedings EXPRESS/SOS 2016, arXiv:1608.02692", "journal-ref": "EPTCS 222, 2016, pp. 30-44", "doi": "10.4204/EPTCS.222.3", "report-no": null, "categories": "cs.PL cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-similarity is the property of a system being similar to a part of\nitself. We posit that a special class of behaviourally self-similar systems\nexhibits a degree of resilience to adversarial behaviour. We formalise the\nnotions of system, adversary and resilience in operational terms, based on\ntransition systems and observations. While the general problem of proving\nsystems to be behaviourally self-similar is undecidable, we show, by casting\nthem in the framework of well-structured transition systems, that there is an\ninteresting class of systems for which the problem is decidable. We illustrate\nour prescriptive framework for resilience with some small examples, e.g.,\nsystems robust to failures in a fail-stop model, and those avoiding\nside-channel attacks.\n", "versions": [{"version": "v1", "created": "Wed, 10 Aug 2016 11:10:49 GMT"}], "update_date": "2016-08-11", "authors_parsed": [["Prasad", "Sanjiva", "", "Indian Institute of Technology Delhi"], ["Zuck", "Lenore D.", "", "University of Illinois at Chicago"]]}, {"id": "1608.03128", "submitter": "EPTCS", "authors": "Matias David Lee (Univ. Lyon, ENS de Lyon, CNRS, UCB Lyon 1, LIP,\n  France.), Bas Luttik (Eindhoven University of Technology, The Netherlands.)", "title": "Unique Parallel Decomposition for the Pi-calculus", "comments": "In Proceedings EXPRESS/SOS 2016, arXiv:1608.02692", "journal-ref": "EPTCS 222, 2016, pp. 45-59", "doi": "10.4204/EPTCS.222.4", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A (fragment of a) process algebra satisfies unique parallel decomposition if\nthe definable behaviours admit a unique decomposition into indecomposable\nparallel components. In this paper we prove that finite processes of the\npi-calculus, i.e. processes that perform no infinite executions, satisfy this\nproperty modulo strong bisimilarity and weak bisimilarity. Our results are\nobtained by an application of a general technique for establishing unique\nparallel decomposition using decomposition orders.\n", "versions": [{"version": "v1", "created": "Wed, 10 Aug 2016 11:10:58 GMT"}], "update_date": "2016-08-11", "authors_parsed": [["Lee", "Matias David", "", "Univ. Lyon, ENS de Lyon, CNRS, UCB Lyon 1, LIP,\n  France."], ["Luttik", "Bas", "", "Eindhoven University of Technology, The Netherlands."]]}, {"id": "1608.03131", "submitter": "EPTCS", "authors": "Massimo Bartoletti, Ludovic Henrio, Sophia Knight, Hugo Torres Vieira", "title": "Proceedings 9th Interaction and Concurrency Experience", "comments": null, "journal-ref": "EPTCS 223, 2016", "doi": "10.4204/EPTCS.223", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the proceedings of ICE 2016, the 9th Interaction and\nConcurrency Experience, which was held in Heraklion, Greece on the 8th and 9th\nof June 2016 as a satellite event of DisCoTec 2016. The ICE procedure for paper\nselection allows PC members to interact, anonymously, with authors. During the\nreview phase, each submitted paper is published on a discussion forum whose\naccess is restricted to the authors and to all the PC members not declaring a\nconflict of interest. The PC members post comments and questions that the\nauthors reply to. For the first time, the 2016 edition of ICE included a\nfeature targeting review transparency: reviews of accepted papers were made\npublic on the workshop website and workshop participants in particular were\nable to access them during the workshop. Each paper was reviewed by three PC\nmembers, and altogether nine papers were accepted for publication (the workshop\nalso featured three brief announcements which are not part of this volume). We\nwere proud to host two invited talks, by Alexandra Silva and Uwe Nestmann. The\nabstracts of these two talks are included in this volume together with the\nregular papers.\n", "versions": [{"version": "v1", "created": "Wed, 10 Aug 2016 11:24:02 GMT"}], "update_date": "2016-08-11", "authors_parsed": [["Bartoletti", "Massimo", ""], ["Henrio", "Ludovic", ""], ["Knight", "Sophia", ""], ["Vieira", "Hugo Torres", ""]]}, {"id": "1608.03321", "submitter": "EPTCS", "authors": "Simon Fowler (The University of Edinburgh, Edinburgh, UK)", "title": "An Erlang Implementation of Multiparty Session Actors", "comments": "In Proceedings ICE 2016, arXiv:1608.03131", "journal-ref": "EPTCS 223, 2016, pp. 36-50", "doi": "10.4204/EPTCS.223.3", "report-no": null, "categories": "cs.PL cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By requiring co-ordination to take place using explicit message passing\ninstead of relying on shared memory, actor-based programming languages have\nbeen shown to be effective tools for building reliable and fault-tolerant\ndistributed systems. Although naturally communication-centric, communication\npatterns in actor-based applications remain informally specified, meaning that\nerrors in communication are detected late, if at all.\n  Multiparty session types are a formalism to describe, at a global level, the\ninteractions between multiple communicating entities. This article describes\nthe implementation of a prototype framework for monitoring Erlang/OTP\ngen_server applications against multiparty session types, showing how previous\nwork on multiparty session actors can be adapted to a purely actor-based\nlanguage, and how monitor violations and termination of session participants\ncan be reported in line with the Erlang mantra of \"let it fail\". Finally, the\nframework is used to implement two case studies: an adaptation of a\nfreely-available DNS server, and a chat server.\n", "versions": [{"version": "v1", "created": "Thu, 11 Aug 2016 00:25:48 GMT"}], "update_date": "2016-08-12", "authors_parsed": [["Fowler", "Simon", "", "The University of Edinburgh, Edinburgh, UK"]]}, {"id": "1608.03322", "submitter": "EPTCS", "authors": "Keyvan Azadbakht (Centrum Wiskunde en Informatica), Frank S. de Boer\n  (Centrum Wiskunde en Informatica), Vlad Serbanescu (Centrum Wiskunde en\n  Informatica)", "title": "Multi-Threaded Actors", "comments": "In Proceedings ICE 2016, arXiv:1608.03131", "journal-ref": "EPTCS 223, 2016, pp. 51-66", "doi": "10.4204/EPTCS.223.4", "report-no": null, "categories": "cs.DC cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce a new programming model of multi-threaded actors\nwhich feature the parallel processing of their messages. In this model an actor\nconsists of a group of active objects which share a message queue. We provide a\nformal operational semantics, and a description of a Java-based implementation\nfor the basic programming abstractions describing multi-threaded actors.\nFinally, we evaluate our proposal by means of an example application.\n", "versions": [{"version": "v1", "created": "Thu, 11 Aug 2016 00:25:56 GMT"}], "update_date": "2016-08-12", "authors_parsed": [["Azadbakht", "Keyvan", "", "Centrum Wiskunde en Informatica"], ["de Boer", "Frank S.", "", "Centrum Wiskunde en Informatica"], ["Serbanescu", "Vlad", "", "Centrum Wiskunde en\n  Informatica"]]}, {"id": "1608.03323", "submitter": "EPTCS", "authors": "Roberto Guanciale (KTH Royal Institute of Technology, Sweden), Emilio\n  Tuosto (University of Leicester, UK)", "title": "An Abstract Semantics of the Global View of Choreographies", "comments": "In Proceedings ICE 2016, arXiv:1608.03131", "journal-ref": "EPTCS 223, 2016, pp. 67-82", "doi": "10.4204/EPTCS.223.5", "report-no": null, "categories": "cs.LO cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an abstract semantics of the global view of choreographies. Our\nsemantics is given in terms of pre-orders and can accommodate different lower\nlevel semantics. We discuss the adequacy of our model by considering its\nrelation with communicating machines, that we use to formalise the local view.\nInterestingly, our framework seems to be more expressive than others where\nsemantics of global views have been considered. This will be illustrated by\ndiscussing some interesting examples.\n", "versions": [{"version": "v1", "created": "Thu, 11 Aug 2016 00:26:06 GMT"}], "update_date": "2016-08-12", "authors_parsed": [["Guanciale", "Roberto", "", "KTH Royal Institute of Technology, Sweden"], ["Tuosto", "Emilio", "", "University of Leicester, UK"]]}, {"id": "1608.03325", "submitter": "EPTCS", "authors": "Alexis Bernadet (Dalhousie University, Canada), Ivan Lanese (Focus\n  Team, University of Bologna/INRIA, Italy)", "title": "A Modular Formalization of Reversibility for Concurrent Models and\n  Languages", "comments": "In Proceedings ICE 2016, arXiv:1608.03131", "journal-ref": "EPTCS 223, 2016, pp. 98-112", "doi": "10.4204/EPTCS.223.7", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal-consistent reversibility is the reference notion of reversibility for\nconcurrency. We introduce a modular framework for defining causal-consistent\nreversible extensions of concurrent models and languages. We show how our\nframework can be used to define reversible extensions of formalisms as\ndifferent as CCS and concurrent X-machines. The generality of the approach\nallows for the reuse of theories and techniques in different settings.\n", "versions": [{"version": "v1", "created": "Thu, 11 Aug 2016 00:26:24 GMT"}], "update_date": "2016-08-12", "authors_parsed": [["Bernadet", "Alexis", "", "Dalhousie University, Canada"], ["Lanese", "Ivan", "", "Focus\n  Team, University of Bologna/INRIA, Italy"]]}, {"id": "1608.03327", "submitter": "EPTCS", "authors": "Chiara Bodei (Dipartimento di Informatica, Universit\\`a di Pisa),\n  Pierpaolo Degano (Dipartimento di Informatica, Universit\\`a di Pisa),\n  Gian-Luigi Ferrari (Dipartimento di Informatica, Universit\\`a di Pisa),\n  Letterio Galletta (Dipartimento di Informatica, Universit\\`a di Pisa)", "title": "A Step Towards Checking Security in IoT", "comments": "In Proceedings ICE 2016, arXiv:1608.03131", "journal-ref": "EPTCS 223, 2016, pp. 128-142", "doi": "10.4204/EPTCS.223.9", "report-no": null, "categories": "cs.PL cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet of Things (IoT) is smartifying our everyday life. Our starting\npoint is IoT-LySa, a calculus for describing IoT systems, and its static\nanalysis, which will be presented at Coordination 2016. We extend the mentioned\nproposal in order to begin an investigation about security issues, in\nparticular for the static verification of secrecy and some other security\nproperties.\n", "versions": [{"version": "v1", "created": "Thu, 11 Aug 2016 00:26:43 GMT"}], "update_date": "2016-08-12", "authors_parsed": [["Bodei", "Chiara", "", "Dipartimento di Informatica, Universit\u00e0 di Pisa"], ["Degano", "Pierpaolo", "", "Dipartimento di Informatica, Universit\u00e0 di Pisa"], ["Ferrari", "Gian-Luigi", "", "Dipartimento di Informatica, Universit\u00e0 di Pisa"], ["Galletta", "Letterio", "", "Dipartimento di Informatica, Universit\u00e0 di Pisa"]]}, {"id": "1608.03350", "submitter": "Yutaka Nagashima", "authors": "Yutaka Nagashima and Liam O'Connor", "title": "Close Encounters of the Higher Kind Emulating Constructor Classes in\n  Standard ML", "comments": "Accepted by ACM SIGPLAN Workshop on ML, September 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We implement a library for encoding constructor classes in Standard ML,\nincluding elaboration from minimal definitions, and automatic instantiation of\nsuperclasses.\n", "versions": [{"version": "v1", "created": "Thu, 11 Aug 2016 02:17:09 GMT"}], "update_date": "2016-08-12", "authors_parsed": [["Nagashima", "Yutaka", ""], ["O'Connor", "Liam", ""]]}, {"id": "1608.03355", "submitter": "Robert Smith", "authors": "Robert S. Smith, Michael J. Curtis, William J. Zeng", "title": "A Practical Quantum Instruction Set Architecture", "comments": "15 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.ET cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an abstract machine architecture for classical/quantum\ncomputations---including compilation---along with a quantum instruction\nlanguage called Quil for explicitly writing these computations. With this\nformalism, we discuss concrete implementations of the machine and non-trivial\nalgorithms targeting them. The introduction of this machine dovetails with\nongoing development of quantum computing technology, and makes possible\nportable descriptions of recent classical/quantum algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 11 Aug 2016 03:17:57 GMT"}, {"version": "v2", "created": "Fri, 17 Feb 2017 18:44:52 GMT"}], "update_date": "2017-02-20", "authors_parsed": [["Smith", "Robert S.", ""], ["Curtis", "Michael J.", ""], ["Zeng", "William J.", ""]]}, {"id": "1608.03424", "submitter": "Santiago Escobar", "authors": "Maria Alpuente and Angel Cuenca and Santiago Escobar and Jose Meseguer", "title": "Partial Evaluation of Order-sorted Equational Programs modulo Axioms", "comments": "Pre-proceedings paper presented at the 26th International Symposium\n  on Logic-Based Program Synthesis and Transformation (LOPSTR 2016), Edinburgh,\n  Scotland UK, 6-8 September 2016 (arXiv:1608.02534)", "journal-ref": null, "doi": null, "report-no": "LOPSTR/2016/38", "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Partial evaluation (PE) is a powerful and general program optimization\ntechnique with many successful applications. However, it has never been\ninvestigated in the context of expressive rule-based languages like Maude,\nCafeOBJ, OBJ, ASF+SDF, and ELAN, which support: 1) rich type structures with\nsorts, subsorts and overloading; 2) equational rewriting modulo axioms such as\ncommutativity, associativity-commutativity, and\nassociativity-commutativity-identity. In this extended abstract, we illustrate\nthe key concepts by showing how they apply to partial evaluation of expressive\nrule-based programs written in Maude. Our partial evaluation scheme is based on\nan automatic unfolding algorithm that computes term variants and relies on\nequational least general generalization for ensuring global termination. We\ndemonstrate the use of the resulting partial evaluator for program optimization\non several examples where it shows significant speed-ups.\n", "versions": [{"version": "v1", "created": "Thu, 11 Aug 2016 11:51:04 GMT"}], "update_date": "2016-08-12", "authors_parsed": [["Alpuente", "Maria", ""], ["Cuenca", "Angel", ""], ["Escobar", "Santiago", ""], ["Meseguer", "Jose", ""]]}, {"id": "1608.03535", "submitter": "Fernando S\\'aenz-P\\'erez", "authors": "Fernando S\\'aenz-P\\'erez", "title": "Intuitionistic Logic Programming for SQL (Extended Abstract)", "comments": "Pre-proceedings paper presented at the 26th International Symposium\n  on Logic-Based Program Synthesis and Transformation (LOPSTR 2016), Edinburgh,\n  Scotland UK, 6-8 September 2016 (arXiv:1608.02534)", "journal-ref": null, "doi": null, "report-no": "LOPSTR/2016/44", "categories": "cs.PL cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intuitionistic logic programming provides the notion of embedded implication\nin rule bodies, which can be used to reason about a current database modified\nby the antecedent. This can be applied to a system that translates SQL to\nDatalog to solve SQL WITH queries, for which relations are locally defined and\ncan therefore be understood as added to the current database. In addition,\nassumptions in SQL queries as either adding or removing data can be modelled in\nthis way as well, which is an interesting feature for decision-support\nscenarios. This work suggests a way to apply intuitionistic logic programming\nto SQL, and provides a pointer to a working system implementing this idea.\n", "versions": [{"version": "v1", "created": "Thu, 11 Aug 2016 17:01:37 GMT"}, {"version": "v2", "created": "Thu, 22 Sep 2016 17:25:10 GMT"}], "update_date": "2016-09-23", "authors_parsed": [["S\u00e1enz-P\u00e9rez", "Fernando", ""]]}, {"id": "1608.03650", "submitter": "Roberto Amadini", "authors": "Roberto Amadini, Pierre Flener, Justin Pearson, Joseph D. Scott, Peter\n  J. Stuckey, Guido Tack", "title": "MiniZinc with Strings", "comments": "Pre-proceedings paper presented at the 26th International Symposium\n  on Logic-Based Program Synthesis and Transformation (LOPSTR 2016), Edinburgh,\n  Scotland UK, 6-8 September 2016 (arXiv:1608.02534)", "journal-ref": null, "doi": null, "report-no": "LOPSTR/2016/7", "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Strings are extensively used in modern programming languages and constraints\nover strings of unknown length occur in a wide range of real-world applications\nsuch as software analysis and verification, testing, model checking, and web\nsecurity. Nevertheless, practically no CP solver natively supports string\nconstraints. We introduce string variables and a suitable set of string\nconstraints as builtin features of the MiniZinc modelling language.\nFurthermore, we define an interpreter for converting a MiniZinc model with\nstrings into a FlatZinc instance relying on only integer variables. This\nprovides a user-friendly interface for modelling combinatorial problems with\nstrings, and enables both string and non-string solvers to actually solve such\nproblems.\n", "versions": [{"version": "v1", "created": "Fri, 12 Aug 2016 01:17:09 GMT"}], "update_date": "2016-08-15", "authors_parsed": [["Amadini", "Roberto", ""], ["Flener", "Pierre", ""], ["Pearson", "Justin", ""], ["Scott", "Joseph D.", ""], ["Stuckey", "Peter J.", ""], ["Tack", "Guido", ""]]}, {"id": "1608.03771", "submitter": "Manfred Schmidt-Schauss", "authors": "Manfred Schmidt-Schau{\\ss} and Temur Kutsia and Jordi Levy and Mateu\n  Villaret", "title": "Nominal Unification of Higher Order Expressions with Recursive Let", "comments": "Pre-proceedings paper presented at the 26th International Symposium\n  on Logic-Based Program Synthesis and Transformation (LOPSTR 2016), Edinburgh,\n  Scotland UK, 6-8 September 2016 (arXiv:1608.02534)", "journal-ref": null, "doi": null, "report-no": "LOPSTR/2016/34", "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A sound and complete algorithm for nominal unification of higher-order\nexpressions with a recursive let is described, and shown to run in\nnon-deterministic polynomial time. We also explore specializations like nominal\nletrec-matching for plain expressions and for DAGs and determine the complexity\nof corresponding unification problems.\n", "versions": [{"version": "v1", "created": "Fri, 12 Aug 2016 12:21:30 GMT"}], "update_date": "2016-08-15", "authors_parsed": [["Schmidt-Schau\u00df", "Manfred", ""], ["Kutsia", "Temur", ""], ["Levy", "Jordi", ""], ["Villaret", "Mateu", ""]]}, {"id": "1608.03828", "submitter": "Amey Karkare", "authors": "Rajdeep Das, Umair Z. Ahmed, Amey Karkare, Sumit Gulwani", "title": "Prutor: A System for Tutoring CS1 and Collecting Student Programs for\n  Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An introductory programming course (CS1) is an integral part of any\nundergraduate curriculum. Due to large number and diverse programming\nbackground of students, providing timely and personalised feedback to\nindividual students is a challenging task for any CS1 instructor. The help\nprovided by teaching assistants (typically senior students) is not sufficient\nas it suffers from unintentional bias and, most of the time, not quick enough.\n  In this paper, we present Prutor, a tutoring system platform to conduct\nintroductory programming courses. Prutor is a cloud-based web application that\nprovides instant and useful feedback to students while solving programming\nproblems. Prutor stores, at regular intervals, the snapshots of students'\nattempts to solve programming problems. These intermediate versions of the\nstudent programs provide the instructors (and data analysts) a view of the\nstudents' approach to solving programming problems. Since Prutor is accessible\nthrough any standard web browser, students do not need to worry about\ndependencies external to the programming course, viz. Operating Systems,\nEditors, Compilers, Compiler Options, etc.. This enables the students to focus\non solving only the programming problems. Apart from the code snapshots at\nregular intervals, Prutor also collects other valuable data such as the time\ntaken by the students to solve the problems, the number of compile and\nexecution events, and the errors made. We have used this data in developing\nintelligent tools for giving feedback to students, some of which are described\nbriefly in this paper. This system thus serves as a platform for tutoring as\nwell as data collection for researchers.\n", "versions": [{"version": "v1", "created": "Fri, 12 Aug 2016 15:33:54 GMT"}], "update_date": "2017-02-03", "authors_parsed": [["Das", "Rajdeep", ""], ["Ahmed", "Umair Z.", ""], ["Karkare", "Amey", ""], ["Gulwani", "Sumit", ""]]}, {"id": "1608.03912", "submitter": "Paul Tarau", "authors": "Paul Tarau", "title": "A Hiking Trip Through the Orders of Magnitude: Deriving Efficient\n  Generators for Closed Simply-Typed Lambda Terms and Normal Forms", "comments": "Pre-proceedings paper presented at the 26th International Symposium\n  on Logic-Based Program Synthesis and Transformation (LOPSTR 2016), Edinburgh,\n  Scotland UK, 6-8 September 2016 (arXiv:1608.02534)", "journal-ref": null, "doi": null, "report-no": "LOPSTR/2016/16", "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contrary to several other families of lambda terms, no closed formula or\ngenerating function is known and none of the sophisticated techniques devised\nin analytic combinatorics can currently help with counting or generating the\nset of {\\em simply-typed closed lambda terms} of a given size.\n  Moreover, their asymptotic scarcity among the set of closed lambda terms\nmakes counting them via brute force generation and type inference quickly\nintractable, with previous published work showing counts for them only up to\nsize 10.\n  By taking advantage of the synergy between logic variables, unification with\noccurs check and efficient backtracking in today's Prolog systems, we climb 4\norders of magnitude above previously known counts by deriving progressively\nfaster Horn Clause programs that generate and/or count the set of closed\nsimply-typed lambda terms of sizes up to 14. A similar count for {\\em closed\nsimply-typed normal forms} is also derived up to size 14.\n  {\\em {\\bf Keywords:} logic programming transformations, type inference,\ncombinatorics of lambda terms, simply-typed lambda calculus, simply-typed\nnormal forms. }\n", "versions": [{"version": "v1", "created": "Fri, 12 Aug 2016 21:11:33 GMT"}], "update_date": "2016-08-16", "authors_parsed": [["Tarau", "Paul", ""]]}, {"id": "1608.04016", "submitter": "Sergio Antoy", "authors": "Sergio Antoy and Andy Jost", "title": "A New Functional-Logic Compiler for Curry: Sprite", "comments": "Pre-proceedings paper presented at the 26th International Symposium\n  on Logic-Based Program Synthesis and Transformation (LOPSTR 2016), Edinburgh,\n  Scotland UK, 6-8 September 2016 (arXiv:1608.02534)", "journal-ref": null, "doi": null, "report-no": "LOPSTR/2016/17", "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new native code compiler for Curry codenamed Sprite. Sprite is\nbased on the Fair Scheme, a compilation strategy that provides instructions for\ntransforming declarative, non-deterministic programs of a certain class into\nimperative, deterministic code. We outline salient features of Sprite, discuss\nits implementation of Curry programs, and present benchmarking results. Sprite\nis the first-to-date operationally complete implementation of Curry.\nPreliminary results show that ensuring this property does not incur a\nsignificant penalty.\n", "versions": [{"version": "v1", "created": "Sat, 13 Aug 2016 18:41:11 GMT"}], "update_date": "2016-08-16", "authors_parsed": [["Antoy", "Sergio", ""], ["Jost", "Andy", ""]]}, {"id": "1608.04041", "submitter": "Jeremy Kepner", "authors": "Alexander Chen, Alan Edelman, Jeremy Kepner, Vijay Gadepally, Dylan\n  Hutchison", "title": "Julia Implementation of the Dynamic Distributed Dimensional Data Model", "comments": "7 pages, 16 figures, IEEE HPEC 2016", "journal-ref": null, "doi": "10.1109/HPEC.2016.7761626", "report-no": null, "categories": "cs.MS cs.PF cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Julia is a new language for writing data analysis programs that are easy to\nimplement and run at high performance. Similarly, the Dynamic Distributed\nDimensional Data Model (D4M) aims to clarify data analysis operations while\nretaining strong performance. D4M accomplishes these goals through a\ncomposable, unified data model on associative arrays. In this work, we present\nan implementation of D4M in Julia and describe how it enables and facilitates\ndata analysis. Several experiments showcase scalable performance in our new\nJulia version as compared to the original Matlab implementation.\n", "versions": [{"version": "v1", "created": "Sun, 14 Aug 2016 00:58:41 GMT"}], "update_date": "2016-12-13", "authors_parsed": [["Chen", "Alexander", ""], ["Edelman", "Alan", ""], ["Kepner", "Jeremy", ""], ["Gadepally", "Vijay", ""], ["Hutchison", "Dylan", ""]]}, {"id": "1608.04415", "submitter": "Ekaterina Komendantskaya Dr", "authors": "E. Komendantskaya and P. Johann and M. Schmidt", "title": "A Productivity Checker for Logic Programming", "comments": "Pre-proceedings paper presented at the 26th International Symposium\n  on Logic-Based Program Synthesis and Transformation (LOPSTR 2016), Edinburgh,\n  Scotland UK, 6-8 September 2016 (arXiv:1608.02534)", "journal-ref": null, "doi": null, "report-no": "LOPSTR/2016/31", "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated analysis of recursive derivations in logic programming is known to\nbe a hard problem. Both termination and non-termination are undecidable\nproblems in Turing-complete languages. However, some declarative languages\noffer a practical work-around for this problem, by making a clear distinction\nbetween whether a program is meant to be understood inductively or\ncoinductively. For programs meant to be understood inductively, termination\nmust be guaranteed, whereas for programs meant to be understood coinductively,\nproductive non-termination (or \"productivity\") must be ensured. In practice,\nsuch classification helps to better understand and implement some\nnon-terminating computations.\n  Logic programming was one of the first declarative languages to make this\ndistinction: in the 1980's, Lloyd and van Emden's \"computations at infinity\"\ncaptured the big-step operational semantics of derivations that produce\ninfinite terms as answers. In modern terms, computations at infinity describe\n\"global productivity\" of computations in logic programming. Most programming\nlanguages featuring coinduction also provide an observational, or small-step,\nnotion of productivity as a computational counterpart to global productivity.\nThis kind of productivity is ensured by checking that finite initial fragments\nof infinite computations can always be observed to produce finite portions of\ntheir infinite answer terms.\n  In this paper we introduce a notion of observational productivity for logic\nprogramming as an algorithmic approximation of global productivity, give an\neffective procedure for semi-deciding observational productivity, and offer an\nimplemented automated observational productivity checker for logic programs.\n", "versions": [{"version": "v1", "created": "Mon, 15 Aug 2016 21:35:32 GMT"}, {"version": "v2", "created": "Thu, 18 Aug 2016 10:10:17 GMT"}, {"version": "v3", "created": "Fri, 19 Aug 2016 13:54:10 GMT"}], "update_date": "2016-08-22", "authors_parsed": [["Komendantskaya", "E.", ""], ["Johann", "P.", ""], ["Schmidt", "M.", ""]]}, {"id": "1608.04592", "submitter": "J\\\"urgen Koslowski", "authors": "Sung-Shik T.Q. Jongmans (Open University of the Netherlands, Radboud\n  University Nijmegen) and Farhad Arbab (Centrum Wiskunde and Informatica,\n  Leiden University)", "title": "Data optimizations for constraint automata", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 12, Issue 3 (April 27,\n  2017) lmcs:2041", "doi": "10.2168/LMCS-12(3:11)2016", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constraint automata (CA) constitute a coordination model based on finite\nautomata on infinite words. Originally introduced for modeling of coordinators,\nan interesting new application of CAs is implementing coordinators (i.e.,\ncompiling CAs into executable code). Such an approach guarantees\ncorrectness-by-construction and can even yield code that outperforms\nhand-crafted code. The extent to which these two potential advantages\nmaterialize depends on the smartness of CA-compilers and the existence of\nproofs of their correctness.\n  Every transition in a CA is labeled by a \"data constraint\" that specifies an\natomic data-flow between coordinated processes as a first-order formula. At\nrun-time, compiler-generated code must handle data constraints as efficiently\nas possible. In this paper, we present, and prove the correctness of two\noptimization techniques for CA-compilers related to handling of data\nconstraints: a reduction to eliminate redundant variables and a translation\nfrom (declarative) data constraints to (imperative) data commands expressed in\na small sequential language. Through experiments, we show that these\noptimization techniques can have a positive impact on performance of generated\nexecutable code.\n", "versions": [{"version": "v1", "created": "Tue, 16 Aug 2016 13:45:53 GMT"}, {"version": "v2", "created": "Wed, 21 Sep 2016 05:36:23 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Jongmans", "Sung-Shik T. Q.", "", "Open University of the Netherlands, Radboud\n  University Nijmegen"], ["Arbab", "Farhad", "", "Centrum Wiskunde and Informatica,\n  Leiden University"]]}, {"id": "1608.04688", "submitter": "Gines Moreno Dr.", "authors": "Gin\\'es Moreno, Jaime Penabad, and Germ\\'an Vidal", "title": "Tuning Fuzzy Logic Programs with Symbolic Execution", "comments": "Pre-proceedings paper presented at the 26th International Symposium\n  on Logic-Based Program Synthesis and Transformation (LOPSTR 2016), Edinburgh,\n  Scotland UK, 6-8 September 2016 (arXiv:1608.02534)", "journal-ref": null, "doi": null, "report-no": "LOPSTR/2016/15", "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fuzzy logic programming is a growing declarative paradigm aiming to integrate\nfuzzy logic into logic programming. One of the most difficult tasks when\nspecifying a fuzzy logic program is determining the right weights for each\nrule, as well as the most appropriate fuzzy connectives and operators. In this\npaper, we introduce a symbolic extension of fuzzy logic programs in which some\nof these parameters can be left unknown, so that the user can easily see the\nimpact of their possible values. Furthermore, given a number of test cases, the\nmost appropriate values for these parameters can be automatically computed.\n", "versions": [{"version": "v1", "created": "Tue, 16 Aug 2016 17:51:07 GMT"}], "update_date": "2016-08-17", "authors_parsed": [["Moreno", "Gin\u00e9s", ""], ["Penabad", "Jaime", ""], ["Vidal", "Germ\u00e1n", ""]]}, {"id": "1608.04999", "submitter": "James Cheney", "authors": "Weili Fu, Roly Perera, Paul Anderson, and James Cheney", "title": "$\\mu$Puppet: A Declarative Subset of the Puppet Configuration Language", "comments": "Full version of ECOOP 2017 conference paper", "journal-ref": null, "doi": "10.4230/LIPIcs.ECOOP.2017.12", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Puppet is a popular declarative framework for specifying and managing complex\nsystem configurations. The Puppet framework includes a domain-specific language\nwith several advanced features inspired by object-oriented programming,\nincluding user-defined resource types, 'classes' with a form of inheritance,\nand dependency management. Like most real-world languages, the language has\nevolved in an ad hoc fashion, resulting in a design with numerous features,\nsome of which are complex, hard to understand, and difficult to use correctly.\n  We present an operational semantics for $\\mu$Puppet, a representative subset\nof the Puppet language that covers the distinctive features of Puppet, while\nexcluding features that are either deprecated or work-in-progress. Formalising\nthe semantics sheds light on difficult parts of the language, identifies\nopportunities for future improvements, and provides a foundation for future\nanalysis or debugging techniques, such as static typechecking or provenance\ntracking. Our semantics leads straightforwardly to a reference implementation\nin Haskell. We also discuss some of Puppet's idiosyncrasies, particularly its\nhandling of classes and scope, and present an initial corpus of test cases\nsupported by our formal semantics.\n", "versions": [{"version": "v1", "created": "Wed, 17 Aug 2016 15:26:48 GMT"}, {"version": "v2", "created": "Sun, 21 Aug 2016 20:17:32 GMT"}, {"version": "v3", "created": "Thu, 26 Jan 2017 18:06:06 GMT"}, {"version": "v4", "created": "Fri, 26 May 2017 10:13:55 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["Fu", "Weili", ""], ["Perera", "Roly", ""], ["Anderson", "Paul", ""], ["Cheney", "James", ""]]}, {"id": "1608.05233", "submitter": "Frantisek Farka", "authors": "Franti\\v{s}ek Farka, Ekaterina Komendantskaya, and Kevin Hammond", "title": "Coinductive Soundness of Corecursive Type Class Resolution", "comments": "Pre-proceedings paper presented at the 26th International Symposium\n  on Logic-Based Program Synthesis and Transformation (LOPSTR 2016), Edinburgh,\n  Scotland UK, 6-8 September 2016 (arXiv:1608.02534)", "journal-ref": null, "doi": null, "report-no": "LOPSTR/2016/2", "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Horn clauses and first-order resolution are commonly used to implement type\nclasses in Haskell. Several corecursive extensions to type class resolution\nhave recently been proposed, with the goal of allowing (co)recursive dictionary\nconstruction where resolution does not termi- nate. This paper shows, for the\nfirst time, that corecursive type class resolution and its extensions are\ncoinductively sound with respect to the greatest Herbrand models of logic\nprograms and that they are induc- tively unsound with respect to the least\nHerbrand models. We establish incompleteness results for various fragments of\nthe proof system.\n", "versions": [{"version": "v1", "created": "Thu, 18 Aug 2016 10:37:22 GMT"}, {"version": "v2", "created": "Thu, 8 Dec 2016 13:37:20 GMT"}], "update_date": "2016-12-09", "authors_parsed": [["Farka", "Franti\u0161ek", ""], ["Komendantskaya", "Ekaterina", ""], ["Hammond", "Kevin", ""]]}, {"id": "1608.05252", "submitter": "Carlos Olarte", "authors": "Moreno Falaschi, Maurizio Gabbrielli, Carlos Olarte, Catuscia\n  Palamidessi", "title": "Slicing Concurrent Constraint Programs", "comments": "Pre-proceedings paper presented at the 26th International Symposium\n  on Logic-Based Program Synthesis and Transformation (LOPSTR 2016), Edinburgh,\n  Scotland UK, 6-8 September 2016 (arXiv:1608.02534)", "journal-ref": null, "doi": null, "report-no": "LOPSTR/2016/21", "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Concurrent Constraint Programming (CCP) is a declarative model for\nconcurrency where agents interact by telling and asking constraints (pieces of\ninformation) in a shared store. Some previous works have developed\n(approximated) declarative debuggers for CCP languages. However, the task of\ndebugging concurrent programs remains difficult. In this paper we define a\ndynamic slicer for CCP and we show it to be a useful companion tool for the\nexisting debugging techniques. Our technique starts by considering a partial\ncomputation (a trace) that shows the presence of bugs. Often, the quantity of\ninformation in such a trace is overwhelming, and the user gets easily lost,\nsince she cannot focus on the sources of the bugs. Our slicer allows for\nmarking part of the state of the computation and assists the user to eliminate\nmost of the redundant information in order to highlight the errors. We show\nthat this technique can be tailored to timed variants of CCP. We also develop a\nprototypical implementation freely available for making experiments.\n", "versions": [{"version": "v1", "created": "Thu, 18 Aug 2016 13:36:21 GMT"}, {"version": "v2", "created": "Fri, 10 Feb 2017 14:43:44 GMT"}], "update_date": "2017-02-13", "authors_parsed": [["Falaschi", "Moreno", ""], ["Gabbrielli", "Maurizio", ""], ["Olarte", "Carlos", ""], ["Palamidessi", "Catuscia", ""]]}, {"id": "1608.05263", "submitter": "David Tolpin", "authors": "David Tolpin, Jan Willem van de Meent, Hongseok Yang, Frank Wood", "title": "Design and Implementation of Probabilistic Programming Language Anglican", "comments": "IFL 2016 submission, 12 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anglican is a probabilistic programming system designed to interoperate with\nClojure and other JVM languages. We introduce the programming language\nAnglican, outline our design choices, and discuss in depth the implementation\nof the Anglican language and runtime, including macro-based compilation,\nextended CPS-based evaluation model, and functional representations for\nprobabilistic paradigms, such as a distribution, a random process, and an\ninference algorithm.\n  We show that a probabilistic functional language can be implemented\nefficiently and integrated tightly with a conventional functional language with\nonly moderate computational overhead. We also demonstrate how advanced\nprobabilistic modeling concepts are mapped naturally to the functional\nfoundation.\n", "versions": [{"version": "v1", "created": "Thu, 18 Aug 2016 14:00:35 GMT"}, {"version": "v2", "created": "Wed, 30 Nov 2016 11:54:56 GMT"}], "update_date": "2016-12-01", "authors_parsed": [["Tolpin", "David", ""], ["van de Meent", "Jan Willem", ""], ["Yang", "Hongseok", ""], ["Wood", "Frank", ""]]}, {"id": "1608.05368", "submitter": "Anushri Jana", "authors": "Anushri Jana, Uday P. Khedker, Advaita Datar, R Venkatesh, C Niyas", "title": "Scaling Bounded Model Checking By Transforming Programs With Arrays", "comments": "Pre-proceedings paper presented at the 26th International Symposium\n  on Logic-Based Program Synthesis and Transformation (LOPSTR 2016), Edinburgh,\n  Scotland UK, 6-8 September 2016 (arXiv:1608.02534)", "journal-ref": null, "doi": null, "report-no": "LOPSTR/2016/23", "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bounded Model Checking is one the most successful techniques for finding bugs\nin program. However, for programs with loops iterating over large-sized arrays,\nbounded model checkers often exceed the limit of resources available to them.\nWe present a transformation that enables bounded model checkers to verify a\ncertain class of array properties. Our technique transforms an\narray-manipulating program in ANSI-C to an array-free and loop-free program.\nThe transformed program can efficiently be verified by an off-the-shelf bounded\nmodel checker. Though the transformed program is, in general, an abstraction of\nthe original program, we formally characterize the properties for which the\ntransformation is precise. We demonstrate the applicability and usefulness of\nour technique on both industry code as well as academic benchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 17 Aug 2016 17:35:49 GMT"}], "update_date": "2016-08-22", "authors_parsed": [["Jana", "Anushri", ""], ["Khedker", "Uday P.", ""], ["Datar", "Advaita", ""], ["Venkatesh", "R", ""], ["Niyas", "C", ""]]}, {"id": "1608.05440", "submitter": "Manuel Carro", "authors": "Manuel Carro and Andy King (Eds.)", "title": "Papers presented at the 32nd International Conference on Logic\n  Programming (ICLP 2016)", "comments": "To be published at Theory and Practive of Logic Programming", "journal-ref": "Theory and Practice of Logic Programming, Vol. 16, 2016", "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is the list of the full papers accepted for presentation at the 32nd\nInternational Conference on Logic Programming, New York City, USA, October\n18-21, 2016.\n  In addition to the main conference itself, ICLP hosted four pre-conference\nworkshops, the Autumn School on Logic Programing, and a Doctoral Consortium.\n  The final versions of the full papers will be published in a special issue of\nthe journal Theory and Practice of Logic Programming (TPLP). We received eighty\neight abstract submissions, of which twenty seven papers were accepted for\npublication as TPLP rapid communications.\n  Papers deemed of sufficiently high quality to be presented as the conference,\nbut not enough to be appear in TPLP, will be published as Technical\nCommunications in the OASIcs series. Fifteen papers fell into this category.\n", "versions": [{"version": "v1", "created": "Thu, 18 Aug 2016 21:58:34 GMT"}], "update_date": "2016-08-22", "authors_parsed": [["Carro", "Manuel", "", "Eds."], ["King", "Andy", "", "Eds."]]}, {"id": "1608.05521", "submitter": "Germ\\'an Vidal", "authors": "Naoki Nishida and Adri\\'an Palacios and Germ\\'an Vidal", "title": "Towards Reversible Computation in Erlang", "comments": "Pre-proceedings paper presented at the 26th International Symposium\n  on Logic-Based Program Synthesis and Transformation (LOPSTR 2016), Edinburgh,\n  Scotland UK, 6-8 September 2016 (arXiv:1608.02534)", "journal-ref": null, "doi": null, "report-no": "LOPSTR/2016/20", "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a reversible language, any forward computation can be undone by a finite\nsequence of backward steps. Reversible computing has been studied in the\ncontext of different programming languages and formalisms, where it has been\nused for debugging and for enforcing fault-tolerance, among others. In this\npaper, we consider a subset of Erlang, a concurrent language based on the actor\nmodel. We formally introduce a reversible semantics for this language. To the\nbest of our knowledge, this is the first attempt to define a reversible\nsemantics for Erlang.\n", "versions": [{"version": "v1", "created": "Fri, 19 Aug 2016 08:01:25 GMT"}], "update_date": "2016-08-22", "authors_parsed": [["Nishida", "Naoki", ""], ["Palacios", "Adri\u00e1n", ""], ["Vidal", "Germ\u00e1n", ""]]}, {"id": "1608.05617", "submitter": "Michael Hanus", "authors": "Michael Hanus", "title": "CurryCheck: Checking Properties of Curry Programs", "comments": "Pre-proceedings paper presented at the 26th International Symposium\n  on Logic-Based Program Synthesis and Transformation (LOPSTR 2016), Edinburgh,\n  Scotland UK, 6-8 September 2016 (arXiv:1608.02534)", "journal-ref": null, "doi": null, "report-no": "LOPSTR/2016/43", "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present CurryCheck, a tool to automate the testing of programs written in\nthe functional logic programming language Curry. CurryCheck executes unit tests\nas well as property tests which are parameterized over one or more arguments.\nIn the latter case, CurryCheck tests these properties by systematically\nenumerating test cases so that, for smaller finite domains, CurryCheck can\nactually prove properties. Unit tests and properties can be defined in a Curry\nmodule without being exported. Thus, they are also useful to document the\nintended semantics of the source code. Furthermore, CurryCheck also supports\nthe automated checking of specifications and contracts occurring in source\nprograms. Hence, CurryCheck is a useful tool that contributes to the property-\nand specification-based development of reliable and well tested declarative\nprograms.\n", "versions": [{"version": "v1", "created": "Fri, 19 Aug 2016 14:40:02 GMT"}], "update_date": "2016-08-22", "authors_parsed": [["Hanus", "Michael", ""]]}, {"id": "1608.05619", "submitter": "Alicia Villanueva", "authors": "Mar\\'ia Alpuente, Daniel Pardo, Alicia Villanueva", "title": "Symbolic Abstract Contract Synthesis in a Rewriting Framework", "comments": "Pre-proceedings paper presented at the 26th International Symposium\n  on Logic-Based Program Synthesis and Transformation (LOPSTR 2016), Edinburgh,\n  Scotland UK, 6-8 September 2016 (arXiv:1608.02534)", "journal-ref": null, "doi": null, "report-no": "LOPSTR/2016/1", "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an automated technique for inferring software contracts from\nprograms that are written in a non-trivial fragment of C, called KernelC, that\nsupports pointer-based structures and heap manipulation. Starting from the\nsemantic definition of KernelC in the K framework, we enrich the symbolic\nexecution facilities recently provided by K with novel capabilities for\nassertion synthesis that are based on abstract subsumption. Roughly speaking,\nwe define an abstract symbolic technique that explains the execution of a\n(modifier) C function by using other (observer) routines in the same program.\nWe implemented our technique in the automated tool KindSpec 2.0, which\ngenerates logical axioms that express pre- and post-condition assertions by\ndefining the precise input/output behaviour of the C routines.\n", "versions": [{"version": "v1", "created": "Fri, 19 Aug 2016 14:43:25 GMT"}], "update_date": "2016-08-22", "authors_parsed": [["Alpuente", "Mar\u00eda", ""], ["Pardo", "Daniel", ""], ["Villanueva", "Alicia", ""]]}, {"id": "1608.05675", "submitter": "Michael Morak", "authors": "Manuel Bichler, Michael Morak and Stefan Woltran", "title": "lpopt: A Rule Optimization Tool for Answer Set Programming", "comments": "Pre-proceedings paper presented at the 26th International Symposium\n  on Logic-Based Program Synthesis and Transformation (LOPSTR 2016), Edinburgh,\n  Scotland UK, 6-8 September 2016 (arXiv:1608.02534), 14 pages, LaTeX, 2\n  figures", "journal-ref": null, "doi": null, "report-no": "LOPSTR/2016/40", "categories": "cs.LO cs.AI cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art answer set programming (ASP) solvers rely on a program\ncalled a grounder to convert non-ground programs containing variables into\nvariable-free, propositional programs. The size of this grounding depends\nheavily on the size of the non-ground rules, and thus, reducing the size of\nsuch rules is a promising approach to improve solving performance. To this end,\nin this paper we announce lpopt, a tool that decomposes large logic programming\nrules into smaller rules that are easier to handle for current solvers. The\ntool is specifically tailored to handle the standard syntax of the ASP language\n(ASP-Core) and makes it easier for users to write efficient and intuitive ASP\nprograms, which would otherwise often require significant hand-tuning by expert\nASP engineers. It is based on an idea proposed by Morak and Woltran (2012) that\nwe extend significantly in order to handle the full ASP syntax, including\ncomplex constructs like aggregates, weak constraints, and arithmetic\nexpressions. We present the algorithm, the theoretical foundations on how to\ntreat these constructs, as well as an experimental evaluation showing the\nviability of our approach.\n", "versions": [{"version": "v1", "created": "Fri, 19 Aug 2016 17:20:03 GMT"}, {"version": "v2", "created": "Tue, 23 Aug 2016 07:59:54 GMT"}], "update_date": "2016-08-24", "authors_parsed": [["Bichler", "Manuel", ""], ["Morak", "Michael", ""], ["Woltran", "Stefan", ""]]}, {"id": "1608.05676", "submitter": "Bin Fang", "authors": "Bin Fang, Mihaela Sighireanu", "title": "Hierarchical Shape Abstraction for Analysis of Free-List Memory\n  Allocators", "comments": "Pre-proceedings paper presented at the 26th International Symposium\n  on Logic-Based Program Synthesis and Transformation (LOPSTR 2016), Edinburgh,\n  Scotland UK, 6-8 September 2016 (arXiv:1608.02534)", "journal-ref": null, "doi": null, "report-no": "LOPSTR/2016/26", "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a hierarchical abstract domain for the analysis of free-list\nmemory allocators that tracks shape and numerical properties about both the\nheap and the free lists. Our domain is based on Separation Logic extended with\npredicates that capture the pointer arithmetics constraints for the heap-list\nand the shape of the free-list. These predicates are combined using a\nhierarchical composition operator to specify the overlapping of the heap-list\nby the free-list. In addition to expressiveness, this operator leads to a\ncompositional and compact representation of abstract values and simplifies the\nimplementation of the abstract domain. The shape constraints are combined with\nnumerical constraints over integer arrays to track properties about the\nallocation policies (best-fit, first-fit, etc). Such properties are out of the\nscope of the existing analyzers. We implemented this domain and we show its\neffectiveness on several implementations of free-list allocators.\n", "versions": [{"version": "v1", "created": "Fri, 19 Aug 2016 17:20:11 GMT"}], "update_date": "2016-08-22", "authors_parsed": [["Fang", "Bin", ""], ["Sighireanu", "Mihaela", ""]]}, {"id": "1608.05893", "submitter": "Tatsuya Abe", "authors": "Tatsuya Abe, Tomoharu Ugawa, Toshiyuki Maeda, and Kousuke Matsumoto", "title": "Reducing State Explosion for Software Model Checking with Relaxed Memory\n  Consistency Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software model checking suffers from the so-called state explosion problem,\nand relaxed memory consistency models even worsen this situation. What is\nworse, parameterizing model checking by memory consistency models, that is, to\nmake the model checker as flexible as we can supply definitions of memory\nconsistency models as an input, intensifies state explosion. This paper\nexplores specific reasons for state explosion in model checking with multiple\nmemory consistency models, provides some optimizations intended to mitigate the\nproblem, and applies them to McSPIN, a model checker for memory consistency\nmodels that we are developing. The effects of the optimizations and the\nusefulness of McSPIN are demonstrated experimentally by verifying copying\nprotocols of concurrent copying garbage collection algorithms. To the best of\nour knowledge, this is the first model checking of the concurrent copying\nprotocols under relaxed memory consistency models.\n", "versions": [{"version": "v1", "created": "Sun, 21 Aug 2016 04:08:45 GMT"}], "update_date": "2016-08-23", "authors_parsed": [["Abe", "Tatsuya", ""], ["Ugawa", "Tomoharu", ""], ["Maeda", "Toshiyuki", ""], ["Matsumoto", "Kousuke", ""]]}, {"id": "1608.06009", "submitter": "Matthew Hammer", "authors": "Kyle Headley, Matthew A. Hammer", "title": "The Random Access Zipper: Simple, Purely-Functional Sequences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the Random Access Zipper (RAZ), a simple, purely-functional data\nstructure for editable sequences. A RAZ combines the structure of a zipper with\nthat of a tree: like a zipper, edits at the cursor require constant time; by\nleveraging tree structure, relocating the edit cursor in the sequence requires\nlogarithmic time. While existing data structures provide these time bounds,\nnone do so with the same simplicity and brevity of code as the RAZ. The\nsimplicity of the RAZ provides the opportunity for more programmers to extend\nthe structure to their own needs, and we provide some suggestions for how to do\nso.\n", "versions": [{"version": "v1", "created": "Sun, 21 Aug 2016 23:15:40 GMT"}], "update_date": "2016-08-23", "authors_parsed": [["Headley", "Kyle", ""], ["Hammer", "Matthew A.", ""]]}, {"id": "1608.06012", "submitter": "Matthew Hammer", "authors": "Matthew A. Hammer, Bor-Yuh Evan Chang, David Van Horn", "title": "A Vision for Online Verification-Validation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today's programmers face a false choice between creating software that is\nextensible and software that is correct. Specifically, dynamic languages permit\nsoftware that is richly extensible (via dynamic code loading, dynamic object\nextension, and various forms of reflection), and today's programmers exploit\nthis flexibility to \"bring their own language features\" to enrich extensible\nlanguages (e.g., by using common JavaScript libraries). Meanwhile, such\nlibrary-based language extensions generally lack enforcement of their\nabstractions, leading to programming errors that are complex to avoid and\npredict.\n  To offer verification for this extensible world, we propose online\nverification-validation (OVV), which consists of language and VM design that\nenables a \"phaseless\" approach to program analysis, in contrast to the standard\nstatic-dynamic phase distinction. Phaseless analysis freely interposes abstract\ninterpretation with concrete execution, allowing analyses to use dynamic\n(concrete) information to prove universal (abstract) properties about future\nexecution.\n  In this paper, we present a conceptual overview of OVV through a motivating\nexample program that uses a hypothetical database library. We present a generic\nsemantics for OVV, and an extension to this semantics that offers a simple\ngradual type system for the database library primitives. The result of\ninstantiating this gradual type system in an OVV setting is a checker that can\nprogressively type successive continuations of the program until a continuation\nis fully verified. To evaluate the proposed vision of OVV for this example, we\nimplement the VM semantics (in Rust), and show that this design permits\nprogressive typing in this manner.\n", "versions": [{"version": "v1", "created": "Sun, 21 Aug 2016 23:42:54 GMT"}], "update_date": "2016-08-23", "authors_parsed": [["Hammer", "Matthew A.", ""], ["Chang", "Bor-Yuh Evan", ""], ["Van Horn", "David", ""]]}, {"id": "1608.06171", "submitter": "Alcides Fonseca", "authors": "Alcides Fonseca and Raul Barbosa", "title": "MISO: An intermediate language to express parallel and dependable\n  programs", "comments": "Editor: Gilles Tredan. 12th European Dependable Computing Conference\n  (EDCC 2016), September 5-9, 2016, Gothenburg, Sweden. Fast Abstracts\n  Proceedings- EDCC 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One way to write fast programs is to explore the potential parallelism and\ntake advantage of the high number of cores available in microprocessors. This\ncan be achieved by manually specifying which code executes on which thread, by\nusing compiler parallelization hints (such as OpenMP or Cilk), or by using a\nparallel programming language (such as X10, Chapel or Aeminium. Regardless of\nthe approach, all of these programs are compiled to an intermediate lower-level\nlanguage that is sequential, thus preventing the backend compiler from\noptimizing the program and observing its parallel nature. This paper presents\nMISO, an intermediate language that expresses the parallel nature of programs\nand that can be targeted by front-end compilers. The language defines 'cells',\nwhich are composed by a state and a transition function from one state to the\nnext. This language can express both sequential and parallel programs, and\nprovides information for a backend- compiler to generate efficient parallel\nprograms. Moreover, MISO can be used to automatically add redundancy to a\nprogram, by replicating the state or by taking advantage of different processor\ncores, in order to provide fault tolerance for programs running on unreliable\nhardware.\n", "versions": [{"version": "v1", "created": "Mon, 22 Aug 2016 14:09:33 GMT"}], "update_date": "2016-08-23", "authors_parsed": [["Fonseca", "Alcides", ""], ["Barbosa", "Raul", ""]]}, {"id": "1608.06499", "submitter": "Catalin Hritcu", "authors": "Danel Ahman and Catalin Hritcu and Kenji Maillard and Guido Martinez\n  and Gordon Plotkin and Jonathan Protzenko and Aseem Rastogi and Nikhil Swamy", "title": "Dijkstra Monads for Free", "comments": "extended pre-print for POPL 2017 final version with the missing ERC\n  acknowledgement", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Dijkstra monads enable a dependent type theory to be enhanced with support\nfor specifying and verifying effectful code via weakest preconditions. Together\nwith their closely related counterparts, Hoare monads, they provide the basis\non which verification tools like F*, Hoare Type Theory (HTT), and Ynot are\nbuilt.\n  We show that Dijkstra monads can be derived \"for free\" by applying a\ncontinuation-passing style (CPS) translation to the standard monadic\ndefinitions of the underlying computational effects. Automatically deriving\nDijkstra monads in this way provides a correct-by-construction and efficient\nway of reasoning about user-defined effects in dependent type theories.\n  We demonstrate these ideas in EMF*, a new dependently typed calculus,\nvalidating it via both formal proof and a prototype implementation within F*.\nBesides equipping F* with a more uniform and extensible effect system, EMF*\nenables a novel mixture of intrinsic and extrinsic proofs within F*.\n", "versions": [{"version": "v1", "created": "Tue, 23 Aug 2016 13:18:01 GMT"}, {"version": "v2", "created": "Tue, 8 Nov 2016 07:30:18 GMT"}, {"version": "v3", "created": "Sat, 12 Oct 2019 11:16:15 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Ahman", "Danel", ""], ["Hritcu", "Catalin", ""], ["Maillard", "Kenji", ""], ["Martinez", "Guido", ""], ["Plotkin", "Gordon", ""], ["Protzenko", "Jonathan", ""], ["Rastogi", "Aseem", ""], ["Swamy", "Nikhil", ""]]}, {"id": "1608.06583", "submitter": "Patrick Cousot", "authors": "Jade ALglave and Patrick Cousot", "title": "Syntax and analytic semantics of LISA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide the syntax and semantics of the LISA (for \"Litmus Instruction Set\nArchitecture\") language. The parallel assembly language LISA is implemented in\nthe herd7 tool (http://virginia.cs.ucl.ac.uk/herd/) for simulating weak\nconsistency models.\n", "versions": [{"version": "v1", "created": "Tue, 23 Aug 2016 17:17:08 GMT"}], "update_date": "2016-08-24", "authors_parsed": [["ALglave", "Jade", ""], ["Cousot", "Patrick", ""]]}, {"id": "1608.07161", "submitter": "Nicholas Tierney", "authors": "Nicholas Tierney", "title": "A Simple Guide to S3 Methods", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Writing functions in R is an important skill for anyone using R. S3 methods\nallow for functions to be generalised across different classes and are easy to\nimplement. Whilst many R users are be adept at creating their own functions, it\nseems that there is room for many more to take advantage of R's S3 methods.\nThis paper provides a simple and targeted guide to explain what S3 methods are,\nwhy people should them, and how they can do it.\n", "versions": [{"version": "v1", "created": "Tue, 23 Aug 2016 06:51:27 GMT"}], "update_date": "2016-08-26", "authors_parsed": [["Tierney", "Nicholas", ""]]}, {"id": "1608.07206", "submitter": "Jeffrey Murphy", "authors": "Jeffrey Murphy, Bhargav Shivkumar, Lukasz Ziarek", "title": "Embedded SML using the MLton compiler", "comments": "IFL 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this extended abstract we present our current work on leveraging Standard\nML for developing embedded and real-time systems. Specifically we detail our\nexperiences in modifying MLton, a whole program, optimizing compiler for\nStandard ML, for use in such contexts. We focus primarily on the language\nruntime, re-working the threading subsystem and garbage collector, as well as\nnecessary changes for integrating MLton generated programs into a light weight\noperating system kernel. We compare and contrast these changes to our previous\nwork on extending MLton for multicore systems, which focused around acheiving\nscalability.\n", "versions": [{"version": "v1", "created": "Thu, 25 Aug 2016 16:17:29 GMT"}], "update_date": "2016-08-26", "authors_parsed": [["Murphy", "Jeffrey", ""], ["Shivkumar", "Bhargav", ""], ["Ziarek", "Lukasz", ""]]}, {"id": "1608.07261", "submitter": "Colin Gordon", "authors": "Satish Chandra, Colin S. Gordon, Jean-Baptiste Jeannin, Cole\n  Schlesinger, Manu Sridharan, Frank Tip, Youngil Choi", "title": "Type Inference for Static Compilation of JavaScript (Extended Version)", "comments": "Extended version of OOPSLA 2016 paper of the same name", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a type system and inference algorithm for a rich subset of\nJavaScript equipped with objects, structural subtyping, prototype inheritance,\nand first-class methods. The type system supports abstract and recursive\nobjects, and is expressive enough to accommodate several standard benchmarks\nwith only minor workarounds. The invariants enforced by the types enable an\nahead-of-time compiler to carry out optimizations typically beyond the reach of\nstatic compilers for dynamic languages. Unlike previous inference techniques\nfor prototype inheritance, our algorithm uses a combination of lower and upper\nbound propagation to infer types and discover type errors in all code,\nincluding uninvoked functions. The inference is expressed in a simple\nconstraint language, designed to leverage off-the-shelf fixed point solvers. We\nprove soundness for both the type system and inference algorithm. An\nexperimental evaluation showed that the inference is powerful, handling the\naforementioned benchmarks with no manual type annotation, and that the inferred\ntypes enable effective static compilation.\n", "versions": [{"version": "v1", "created": "Thu, 25 Aug 2016 19:26:22 GMT"}, {"version": "v2", "created": "Wed, 12 Oct 2016 00:58:03 GMT"}, {"version": "v3", "created": "Tue, 18 Oct 2016 14:44:14 GMT"}], "update_date": "2016-10-19", "authors_parsed": [["Chandra", "Satish", ""], ["Gordon", "Colin S.", ""], ["Jeannin", "Jean-Baptiste", ""], ["Schlesinger", "Cole", ""], ["Sridharan", "Manu", ""], ["Tip", "Frank", ""], ["Choi", "Youngil", ""]]}, {"id": "1608.07531", "submitter": "Patrick Cousot", "authors": "Jade Alglave, Patrick Cousot, Luc Maranget", "title": "Syntax and semantics of the weak consistency model specification\n  language cat", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide the syntax and semantics of the cat language, a domain specific\nlanguage to describe consistency properties of parallel/distributed programs.\nThe language is implemented in the herd7 too\n(http://diy.inria.fr/doc/herd.html)l.\n", "versions": [{"version": "v1", "created": "Fri, 26 Aug 2016 17:28:06 GMT"}, {"version": "v2", "created": "Tue, 30 Aug 2016 15:32:33 GMT"}], "update_date": "2016-08-31", "authors_parsed": [["Alglave", "Jade", ""], ["Cousot", "Patrick", ""], ["Maranget", "Luc", ""]]}, {"id": "1608.07745", "submitter": "Yuepeng Wang", "authors": "Yuepeng Wang, Yu Feng, Ruben Martins, Arati Kaushik, Isil Dillig,\n  Steven P. Reiss", "title": "Type-Directed Code Reuse using Integer Linear Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many common scenarios, programmers need to implement functionality that is\nalready provided by some third party library. This paper presents a tool called\nHunter that facilitates code reuse by finding relevant methods in large code\nbases and automatically synthesizing any necessary wrapper code. The key\ntechnical idea underlying our approach is to use types to both improve search\nresults and guide synthesis. Specifically, our method computes similarity\nmetrics between types and uses this information to solve an integer linear\nprogramming (ILP) problem in which the objective is to minimize the cost of\nsynthesis. We have implemented Hunter as an Eclipse plug-in and evaluate it by\n(a) comparing it against S6, a state-of-the-art code reuse tool, and (b)\nperforming a user study. Our evaluation shows that Hunter compares favorably\nwith S6 and significantly increases programmer productivity.\n", "versions": [{"version": "v1", "created": "Sat, 27 Aug 2016 22:00:09 GMT"}], "update_date": "2016-08-30", "authors_parsed": [["Wang", "Yuepeng", ""], ["Feng", "Yu", ""], ["Martins", "Ruben", ""], ["Kaushik", "Arati", ""], ["Dillig", "Isil", ""], ["Reiss", "Steven P.", ""]]}, {"id": "1608.08219", "submitter": "Michael Vaughn", "authors": "Loris D'Antoni, Rishabh Singh, Michael Vaughn", "title": "NoFAQ: Synthesizing Command Repairs from Examples", "comments": "15 Pages, 9 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Command-line tools are confusing and hard to use for novice programmers due\nto their cryptic error messages and lack of documentation. Novice users often\nresort to online help-forums for finding corrections to their buggy commands,\nbut have a hard time in searching precisely for posts that are relevant to\ntheir problem and then applying the suggested solutions to their buggy command.\n  We present a tool, NoFAQ, that uses a set of rules to suggest possible fixes\nwhen users write buggy commands that trigger commonly occurring errors. The\nrules are expressed in a language called FixIt and each rule pattern-matches\nagainst the user's buggy command and the corresponding error message, and uses\nthese inputs to produce a possible fixed command. Our main contribution is an\nalgorithm based on lazy VSA for synthesizing FixIt rules from examples of buggy\nand repaired commands. The algorithm allows users to add new rules in NoFAQ\nwithout having to manually encode them. We present the evaluation of NoFAQ on\n92 benchmark problems and show that NoFAQ is able to instantly synthesize rules\nfor 81 benchmark problems in real time using just 2 to 5 input-output examples\nfor each rule.\n", "versions": [{"version": "v1", "created": "Mon, 29 Aug 2016 20:00:02 GMT"}], "update_date": "2016-08-31", "authors_parsed": [["D'Antoni", "Loris", ""], ["Singh", "Rishabh", ""], ["Vaughn", "Michael", ""]]}, {"id": "1608.08330", "submitter": "Martin Sulzmann", "authors": "Kai Stadtm\\\"uller and Martin Sulzmann and Peter Thiemann", "title": "Static Trace-Based Deadlock Analysis for Synchronous Mini-Go", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of static deadlock detection for programs in the Go\nprogramming language which make use of synchronous channel communications. In\nour analysis, regular expressions extended with a fork operator capture the\ncommunication behavior of a program. Starting from a simple criterion that\ncharacterizes traces of deadlock-free programs, we develop automata-based\nmethods to check for deadlock-freedom. The approach is implemented and\nevaluated with a series of examples.\n", "versions": [{"version": "v1", "created": "Tue, 30 Aug 2016 05:18:07 GMT"}, {"version": "v2", "created": "Fri, 2 Sep 2016 08:21:00 GMT"}], "update_date": "2016-09-05", "authors_parsed": [["Stadtm\u00fcller", "Kai", ""], ["Sulzmann", "Martin", ""], ["Thiemann", "Peter", ""]]}, {"id": "1608.08724", "submitter": "Christopher Lin", "authors": "Christopher H. Lin, Mausam, Daniel S. Weld", "title": "A Programming Language With a POMDP Inside", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present POAPS, a novel planning system for defining Partially Observable\nMarkov Decision Processes (POMDPs) that abstracts away from POMDP details for\nthe benefit of non-expert practitioners. POAPS includes an expressive adaptive\nprogramming language based on Lisp that has constructs for choice points that\ncan be dynamically optimized. Non-experts can use our language to write\nadaptive programs that have partially observable components without needing to\nspecify belief/hidden states or reason about probabilities. POAPS is also a\ncompiler that defines and performs the transformation of any program written in\nour language into a POMDP with control knowledge. We demonstrate the generality\nand power of POAPS in the rapidly growing domain of human computation by\ndescribing its expressiveness and simplicity by writing several POAPS programs\nfor common crowdsourcing tasks.\n", "versions": [{"version": "v1", "created": "Wed, 31 Aug 2016 04:25:45 GMT"}], "update_date": "2016-09-01", "authors_parsed": [["Lin", "Christopher H.", ""], ["Mausam", "", ""], ["Weld", "Daniel S.", ""]]}, {"id": "1608.09000", "submitter": "Gustavo Soares", "authors": "Reudismam Rolim, Gustavo Soares, Loris D'Antoni, Oleksandr Polozov,\n  Sumit Gulwani, Rohit Gheyi, Ryo Suzuki, Bjoern Hartmann", "title": "Learning Syntactic Program Transformations from Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  IDEs, such as Visual Studio, automate common transformations, such as Rename\nand Extract Method refactorings. However, extending these catalogs of\ntransformations is complex and time-consuming. A similar phenomenon appears in\nintelligent tutoring systems where instructors have to write cumbersome code\ntransformations that describe \"common faults\" to fix similar student\nsubmissions to programming assignments. We present REFAZER, a technique for\nautomatically generating program transformations. REFAZER builds on the\nobservation that code edits performed by developers can be used as examples for\nlearning transformations. Example edits may share the same structure but\ninvolve different variables and subexpressions, which must be generalized in a\ntransformation at the right level of abstraction. To learn transformations,\nREFAZER leverages state-of-the-art programming-by-example methodology using the\nfollowing key components: (a) a novel domain-specific language (DSL) for\ndescribing program transformations, (b) domain-specific deductive algorithms\nfor synthesizing transformations in the DSL, and (c) functions for ranking the\nsynthesized transformations. We instantiate and evaluate REFAZER in two\ndomains. First, given examples of edits used by students to fix incorrect\nprogramming assignment submissions, we learn transformations that can fix other\nstudents' submissions with similar faults. In our evaluation conducted on 4\nprogramming tasks performed by 720 students, our technique helped to fix\nincorrect submissions for 87% of the students. In the second domain, we use\nrepetitive edits applied by developers to the same project to synthesize a\nprogram transformation that applies these edits to other locations in the code.\nIn our evaluation conducted on 59 scenarios of repetitive edits taken from 3 C#\nopen-source projects, REFAZER learns the intended program transformation in 83%\nof the cases.\n", "versions": [{"version": "v1", "created": "Wed, 31 Aug 2016 19:06:06 GMT"}], "update_date": "2016-09-01", "authors_parsed": [["Rolim", "Reudismam", ""], ["Soares", "Gustavo", ""], ["D'Antoni", "Loris", ""], ["Polozov", "Oleksandr", ""], ["Gulwani", "Sumit", ""], ["Gheyi", "Rohit", ""], ["Suzuki", "Ryo", ""], ["Hartmann", "Bjoern", ""]]}]