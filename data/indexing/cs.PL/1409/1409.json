[{"id": "1409.0393", "submitter": "Catalin Hritcu", "authors": "Catalin Hritcu, Leonidas Lampropoulos, Antal Spector-Zabusky, Arthur\n  Azevedo de Amorim, Maxime D\\'en\\`es, John Hughes, Benjamin C. Pierce,\n  Dimitrios Vytiniotis", "title": "Testing Noninterference, Quickly", "comments": null, "journal-ref": "J. Funct. Prog. 26 (2016) e4", "doi": "10.1017/S0956796816000058", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information-flow control mechanisms are difficult both to design and to prove\ncorrect. To reduce the time wasted on doomed proof attempts due to broken\ndefinitions, we advocate modern random testing techniques for finding\ncounterexamples during the design process. We show how to use QuickCheck, a\nproperty-based random-testing tool, to guide the design of increasingly complex\ninformation-flow abstract machines, leading up to a sophisticated register\nmachine with a novel and highly permissive flow-sensitive dynamic enforcement\nmechanism that is sound in the presence of first-class public labels. We find\nthat both sophisticated strategies for generating well-distributed random\nprograms and readily falsifiable formulations of noninterference properties are\ncritically important for efficient testing. We propose several approaches and\nevaluate their effectiveness on a collection of injected bugs of varying\nsubtlety. We also present an effective technique for shrinking large\ncounterexamples to minimal, easily comprehensible ones. Taken together, our\nbest methods enable us to quickly and automatically generate simple\ncounterexamples for more than 45 bugs. Moreover, we show how testing guides the\ndiscovery of the sophisticated invariants needed for the noninterference proof\nof our most complex machine.\n", "versions": [{"version": "v1", "created": "Mon, 1 Sep 2014 12:53:17 GMT"}, {"version": "v2", "created": "Sat, 25 Jul 2015 22:04:20 GMT"}], "update_date": "2016-04-13", "authors_parsed": [["Hritcu", "Catalin", ""], ["Lampropoulos", "Leonidas", ""], ["Spector-Zabusky", "Antal", ""], ["de Amorim", "Arthur Azevedo", ""], ["D\u00e9n\u00e8s", "Maxime", ""], ["Hughes", "John", ""], ["Pierce", "Benjamin C.", ""], ["Vytiniotis", "Dimitrios", ""]]}, {"id": "1409.0757", "submitter": "Carl Friedrich Bolz", "authors": "Edd Barrett, Carl Friedrich Bolz, Laurence Tratt", "title": "Approaches to Interpreter Composition", "comments": "33 pages, 1 figure, 9 tables", "journal-ref": "Computer Languages, Systems and Structures (COMLAN). Volume 44C,\n  December 2015, Pages 199-217", "doi": "10.1016/j.cl.2015.03.001", "report-no": null, "categories": "cs.PL", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  In this paper, we compose six different Python and Prolog VMs into 4 pairwise\ncompositions: one using C interpreters; one running on the JVM; one using\nmeta-tracing interpreters; and one using a C interpreter and a meta-tracing\ninterpreter. We show that programs that cross the language barrier frequently\nexecute faster in a meta-tracing composition, and that meta-tracing imposes a\nsignificantly lower overhead on composed programs relative to mono-language\nprograms.\n", "versions": [{"version": "v1", "created": "Tue, 2 Sep 2014 15:29:23 GMT"}, {"version": "v2", "created": "Fri, 9 Jan 2015 16:23:32 GMT"}, {"version": "v3", "created": "Tue, 19 May 2015 16:17:07 GMT"}], "update_date": "2017-03-02", "authors_parsed": [["Barrett", "Edd", ""], ["Bolz", "Carl Friedrich", ""], ["Tratt", "Laurence", ""]]}, {"id": "1409.1914", "submitter": "Richard Lethin", "authors": "Nicolas Vasilache, Muthu Baskaran, Tom Henretty, Benoit Meister, M.\n  Harper Langston, Sanket Tavarageri, Richard Lethin", "title": "A Tale of Three Runtimes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This contribution discusses the automatic generation of event-driven,\ntuple-space based programs for task-oriented execution models from a sequential\nC specification. We developed a hierarchical mapping solution using\nauto-parallelizing compiler technology to target three different runtimes\nrelying on event-driven tasks (EDTs). Our solution benefits from the important\nobservation that loop types encode short, transitive relations among EDTs that\nare compact and efficiently evaluated at runtime. In this context, permutable\nloops are of particular importance as they translate immediately into\nconservative point-to-point synchronizations of distance 1. Our solution\ngenerates calls into a runtime-agnostic C++ layer, which we have retargeted to\nIntel's Concurrent Collections (CnC), ETI's SWARM, and the Open Community\nRuntime (OCR). Experience with other runtime systems motivates our introduction\nof support for hierarchical async-finishes in CnC. Experimental data is\nprovided to show the benefit of automatically generated code for EDT-based\nruntimes as well as comparisons across runtimes.\n", "versions": [{"version": "v1", "created": "Fri, 5 Sep 2014 19:58:40 GMT"}], "update_date": "2014-09-08", "authors_parsed": [["Vasilache", "Nicolas", ""], ["Baskaran", "Muthu", ""], ["Henretty", "Tom", ""], ["Meister", "Benoit", ""], ["Langston", "M. Harper", ""], ["Tavarageri", "Sanket", ""], ["Lethin", "Richard", ""]]}, {"id": "1409.2088", "submitter": "Michael Kruse", "authors": "Michael Kruse (LRI, INRIA Saclay - Ile de France)", "title": "Introducing Molly: Distributed Memory Parallelization with LLVM", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Programming for distributed memory machines has always been a tedious task,\nbut necessary because compilers have not been sufficiently able to optimize for\nsuch machines themselves. Molly is an extension to the LLVM compiler toolchain\nthat is able to distribute and reorganize workload and data if the program is\norganized in statically determined loop control-flows. These are represented as\npolyhedral integer-point sets that allow program transformations applied on\nthem. Memory distribution and layout can be declared by the programmer as\nneeded and the necessary asynchronous MPI communication is generated\nautomatically. The primary motivation is to run Lattice QCD simulations on IBM\nBlue Gene/Q supercomputers, but since the implementation is not yet completed,\nthis paper shows the capabilities on Conway's Game of Life.\n", "versions": [{"version": "v1", "created": "Sun, 7 Sep 2014 06:41:30 GMT"}], "update_date": "2014-09-09", "authors_parsed": [["Kruse", "Michael", "", "LRI, INRIA Saclay - Ile de France"]]}, {"id": "1409.2089", "submitter": "Michael Kruse", "authors": "Michael Kruse (LRI, INRIA Saclay - Ile de France)", "title": "Perfrewrite -- Program Complexity Analysis via Source Code\n  Instrumentation", "comments": "ACACES 2012 summer school (2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most program profiling methods output the execution time of one specific\nprogram execution, but not its computational complexity class in terms of the\nbig-O notation. Perfrewrite is a tool based on LLVM's Clang compiler to rewrite\na program such that it tracks semantic information while the program executes\nand uses it to guess memory usage, communication and computational complexity.\nWhile source code instrumentation is a standard technique for profiling, using\nit for deriving formulas is an uncommon approach.\n", "versions": [{"version": "v1", "created": "Sun, 7 Sep 2014 06:42:09 GMT"}], "update_date": "2014-09-09", "authors_parsed": [["Kruse", "Michael", "", "LRI, INRIA Saclay - Ile de France"]]}, {"id": "1409.2294", "submitter": "EPTCS", "authors": "Maurice H. ter Beek (ISTI-CNR, Pisa, Italy), Ant\\'onio Ravara (New\n  University of Lisbon, Portugal)", "title": "Proceedings 10th International Workshop on Automated Specification and\n  Verification of Web Systems", "comments": null, "journal-ref": "EPTCS 163, 2014", "doi": "10.4204/EPTCS.163", "report-no": null, "categories": "cs.LO cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  These proceedings contain the papers presented at the 10th International\nWorkshop on Automated Specification and Verification of Web Systems (WWV 2014),\nwhich was held on 18 July 2014 in Vienna, Austria, as a satellite workshop of\nthe Federated Logic Conference (FLoC 2014), associated to the 7th International\nJoint Conference on Automated Reasoning (IJCAR 2014), as part of the Vienna\nSummer of Logic (VSL 2014).\n  WWV is a yearly workshop that aims at providing an interdisciplinary forum to\nfacilitate the cross-fertilization and the advancement of hybrid methods that\nexploit concepts and tools drawn from rule-based programming, formal methods,\nsoftware engineering and Web-oriented research.\n", "versions": [{"version": "v1", "created": "Mon, 8 Sep 2014 11:23:02 GMT"}], "update_date": "2014-09-09", "authors_parsed": [["ter Beek", "Maurice H.", "", "ISTI-CNR, Pisa, Italy"], ["Ravara", "Ant\u00f3nio", "", "New\n  University of Lisbon, Portugal"]]}, {"id": "1409.2764", "submitter": "Takeshi Tsukada", "authors": "Takeshi Tsukada and C.-H. Luke Ong", "title": "Innocent Strategies are Sheaves over Plays---Deterministic,\n  Non-deterministic and Probabilistic Innocence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although the HO/N games are fully abstract for PCF, the traditional notion of\ninnocence (which underpins these games) is not satisfactory for such language\nfeatures as non-determinism and probabilistic branching, in that there are\nstateless terms that are not innocent. Based on a category of P-visible plays\nwith a notion of embedding as morphisms, we propose a natural generalisation by\nviewing innocent strategies as sheaves over (a site of) plays, echoing a slogan\nof Hirschowitz and Pous. Our approach gives rise to fully complete game models\nin each of the three cases of deterministic, nondeterministic and probabilistic\nbranching. To our knowledge, in the second and third cases, ours are the first\nsuch factorisation-free constructions.\n", "versions": [{"version": "v1", "created": "Tue, 9 Sep 2014 14:56:12 GMT"}], "update_date": "2014-09-10", "authors_parsed": [["Tsukada", "Takeshi", ""], ["Ong", "C. -H. Luke", ""]]}, {"id": "1409.3108", "submitter": "David Van Horn", "authors": "Shuying Liang, Weibin Sun, Matthew Might, Andy Keep, David Van Horn", "title": "Pruning, Pushdown Exception-Flow Analysis", "comments": "14th IEEE International Working Conference on Source Code Analysis\n  and Manipulation", "journal-ref": null, "doi": "10.1109/SCAM.2014.44", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statically reasoning in the presence of exceptions and about the effects of\nexceptions is challenging: exception-flows are mutually determined by\ntraditional control-flow and points-to analyses. We tackle the challenge of\nanalyzing exception-flows from two angles. First, from the angle of pruning\ncontrol-flows (both normal and exceptional), we derive a pushdown framework for\nan object-oriented language with full-featured exceptions. Unlike traditional\nanalyses, it allows precise matching of throwers to catchers. Second, from the\nangle of pruning points-to information, we generalize abstract garbage\ncollection to object-oriented programs and enhance it with liveness analysis.\nWe then seamlessly weave the techniques into enhanced reachability computation,\nyielding highly precise exception-flow analysis, without becoming intractable,\neven for large applications. We evaluate our pruned, pushdown exception-flow\nanalysis, comparing it with an established analysis on large scale standard\nJava benchmarks. The results show that our analysis significantly improves\nanalysis precision over traditional analysis within a reasonable analysis time.\n", "versions": [{"version": "v1", "created": "Wed, 10 Sep 2014 15:10:35 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Liang", "Shuying", ""], ["Sun", "Weibin", ""], ["Might", "Matthew", ""], ["Keep", "Andy", ""], ["Van Horn", "David", ""]]}, {"id": "1409.3144", "submitter": "Duncan Temple Lang", "authors": "Duncan Temple Lang", "title": "Enhancing R with Advanced Compilation Tools and Methods", "comments": "Published in at http://dx.doi.org/10.1214/13-STS462 the Statistical\n  Science (http://www.imstat.org/sts/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2014, Vol. 29, No. 2, 181-200", "doi": "10.1214/13-STS462", "report-no": "IMS-STS-STS462", "categories": "stat.CO cs.MS cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  I describe an approach to compiling common idioms in R code directly to\nnative machine code and illustrate it with several examples. Not only can this\nyield significant performance gains, but it allows us to use new approaches to\ncomputing in R. Importantly, the compilation requires no changes to R itself,\nbut is done entirely via R packages. This allows others to experiment with\ndifferent compilation strategies and even to define new domain-specific\nlanguages within R. We use the Low-Level Virtual Machine (LLVM) compiler\ntoolkit to create the native code and perform sophisticated optimizations on\nthe code. By adopting this widely used software within R, we leverage its\nability to generate code for different platforms such as CPUs and GPUs, and\nwill continue to benefit from its ongoing development. This approach\npotentially allows us to develop high-level R code that is also fast, that can\nbe compiled to work with different data representations and sources, and that\ncould even be run outside of R. The approach aims to both provide a compiler\nfor a limited subset of the R language and also to enable R programmers to\nwrite other compilers. This is another approach to help us write high-level\ndescriptions of what we want to compute, not how.\n", "versions": [{"version": "v1", "created": "Tue, 9 Sep 2014 10:37:20 GMT"}], "update_date": "2014-09-12", "authors_parsed": [["Lang", "Duncan Temple", ""]]}, {"id": "1409.3174", "submitter": "Eytan Bakshy", "authors": "Eytan Bakshy, Dean Eckles, Michael S. Bernstein", "title": "Designing and Deploying Online Field Experiments", "comments": "Proceedings of the 23rd international conference on World wide web,\n  283-292", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.PL cs.SI stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online experiments are widely used to compare specific design alternatives,\nbut they can also be used to produce generalizable knowledge and inform\nstrategic decision making. Doing so often requires sophisticated experimental\ndesigns, iterative refinement, and careful logging and analysis. Few tools\nexist that support these needs. We thus introduce a language for online field\nexperiments called PlanOut. PlanOut separates experimental design from\napplication code, allowing the experimenter to concisely describe experimental\ndesigns, whether common \"A/B tests\" and factorial designs, or more complex\ndesigns involving conditional logic or multiple experimental units. These\nlatter designs are often useful for understanding causal mechanisms involved in\nuser behaviors. We demonstrate how experiments from the literature can be\nimplemented in PlanOut, and describe two large field experiments conducted on\nFacebook with PlanOut. For common scenarios in which experiments are run\niteratively and in parallel, we introduce a namespaced management system that\nencourages sound experimental practice.\n", "versions": [{"version": "v1", "created": "Wed, 10 Sep 2014 18:27:47 GMT"}], "update_date": "2014-09-11", "authors_parsed": [["Bakshy", "Eytan", ""], ["Eckles", "Dean", ""], ["Bernstein", "Michael S.", ""]]}, {"id": "1409.3184", "submitter": "Rachid Rebiha", "authors": "Rachid Rebiha and Arnaldo Vieira Moura and Nadir Matringe", "title": "Characterization of Termination for Linear Loop Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present necessary and sufficient conditions for the termination of linear\nhomogeneous programs. We also develop a complete method to check termination\nfor this class of programs. Our complete characterization of termination for\nsuch programs is based on linear algebraic methods. We reduce the verification\nof the termination problem to checking the orthogonality of a well determined\nvector space and a certain vector, both related to loops in the program.\nMoreover, we provide theoretical results and symbolic computational methods\nguaranteeing the soundness, completeness and numerical stability of the\napproach. Finally, we show that it is enough to interpret variable values over\na specific countable number field, or even over its ring of integers, when one\nwants to check termination over the reals.\n", "versions": [{"version": "v1", "created": "Wed, 10 Sep 2014 18:39:44 GMT"}], "update_date": "2014-09-11", "authors_parsed": [["Rebiha", "Rachid", ""], ["Moura", "Arnaldo Vieira", ""], ["Matringe", "Nadir", ""]]}, {"id": "1409.3313", "submitter": "EPTCS", "authors": "Herman Geuvers (Radboud Universiteit Nijmegen, Technical University\n  Eindhoven), Wouter Geraedts (Radboud Universiteit Nijmegen), Bram Geron\n  (University of Birmingham), Judith van Stegeren (Radboud Universiteit\n  Nijmegen)", "title": "A type system for Continuation Calculus", "comments": "In Proceedings CL&C 2014, arXiv:1409.2593", "journal-ref": "EPTCS 164, 2014, pp. 1-17", "doi": "10.4204/EPTCS.164.1", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuation Calculus (CC), introduced by Geron and Geuvers, is a simple\nfoundational model for functional computation. It is closely related to lambda\ncalculus and term rewriting, but it has no variable binding and no pattern\nmatching. It is Turing complete and evaluation is deterministic. Notions like\n\"call-by-value\" and \"call-by-name\" computation are available by choosing\nappropriate function definitions: e.g. there is a call-by-value and a\ncall-by-name addition function. In the present paper we extend CC with types,\nto be able to define data types in a canonical way, and functions over these\ndata types, defined by iteration. Data type definitions follow the so-called\n\"Scott encoding\" of data, as opposed to the more familiar \"Church encoding\".\nThe iteration scheme comes in two flavors: a call-by-value and a call-by-name\niteration scheme. The call-by-value variant is a double negation variant of\ncall-by-name iteration. The double negation translation allows to move between\ncall-by-name and call-by-value.\n", "versions": [{"version": "v1", "created": "Thu, 11 Sep 2014 03:41:53 GMT"}], "update_date": "2014-09-12", "authors_parsed": [["Geuvers", "Herman", "", "Radboud Universiteit Nijmegen, Technical University\n  Eindhoven"], ["Geraedts", "Wouter", "", "Radboud Universiteit Nijmegen"], ["Geron", "Bram", "", "University of Birmingham"], ["van Stegeren", "Judith", "", "Radboud Universiteit\n  Nijmegen"]]}, {"id": "1409.3531", "submitter": "John M. Chambers", "authors": "John M. Chambers", "title": "Object-Oriented Programming, Functional Programming and R", "comments": "Published in at http://dx.doi.org/10.1214/13-STS452 the Statistical\n  Science (http://www.imstat.org/sts/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2014, Vol. 29, No. 2, 167-180", "doi": "10.1214/13-STS452", "report-no": "IMS-STS-STS452", "categories": "stat.ME cs.PL cs.SE stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper reviews some programming techniques in R that have proved useful,\nparticularly for substantial projects. These include several versions of\nobject-oriented programming, used in a large number of R packages. The review\ntries to clarify the origins and ideas behind the various versions, each of\nwhich is valuable in the appropriate context. R has also been strongly\ninfluenced by the ideas of functional programming and, in particular, by the\ndesire to combine functional with object oriented programming. To clarify how\nthis particular mix of ideas has turned out in the current R language and\nsupporting software, the paper will first review the basic ideas behind\nobject-oriented and functional programming, and then examine the evolution of R\nwith these ideas providing context. Functional programming supports\nwell-defined, defensible software giving reproducible results. Object-oriented\nprogramming is the mechanism par excellence for managing complexity while\nkeeping things simple for the user. The two paradigms have been valuable in\nsupporting major software for fitting models to data and numerous other\nstatistical applications. The paradigms have been adopted, and adapted,\ndistinctively in R. Functional programming motivates much of R but R does not\nenforce the paradigm. Object-oriented programming from a functional perspective\ndiffers from that used in non-functional languages, a distinction that needs to\nbe emphasized to avoid confusion. R initially replicated the S language from\nBell Labs, which in turn was strongly influenced by earlier program libraries.\nAt each stage, new ideas have been added, but the previous software continues\nto show its influence in the design as well. Outlining the evolution will\nfurther clarify why we currently have this somewhat unusual combination of\nideas.\n", "versions": [{"version": "v1", "created": "Tue, 9 Sep 2014 10:34:09 GMT"}], "update_date": "2014-09-12", "authors_parsed": [["Chambers", "John M.", ""]]}, {"id": "1409.3533", "submitter": "EPTCS", "authors": "Asad Ali, Maribel Fern\\'andez", "title": "Static Enforcement of Role-Based Access Control", "comments": "In Proceedings WWV 2014, arXiv:1409.2294", "journal-ref": "EPTCS 163, 2014, pp. 36-50", "doi": "10.4204/EPTCS.163.4", "report-no": null, "categories": "cs.SE cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new static approach to Role-Based Access Control (RBAC) policy\nenforcement. The static approach we advocate includes a new design methodology,\nfor applications involving RBAC, which integrates the security requirements\ninto the system's architecture. We apply this new approach to policies\nrestricting calls to methods in Java applications. We present a language to\nexpress RBAC policies on calls to methods in Java, a set of design patterns\nwhich Java programs must adhere to for the policy to be enforced statically,\nand a description of the checks made by our static verifier for static\nenforcement.\n", "versions": [{"version": "v1", "created": "Tue, 9 Sep 2014 04:12:55 GMT"}], "update_date": "2014-09-12", "authors_parsed": [["Ali", "Asad", ""], ["Fern\u00e1ndez", "Maribel", ""]]}, {"id": "1409.3947", "submitter": "Alexandr Savinov", "authors": "Alexandr Savinov", "title": "Concept-Oriented Programming: References, Classes and Inheritance\n  Revisited", "comments": "13 pages, 6 figures, Full version of the paper published in ICSOFT\n  2012 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main goal of concept-oriented programming (COP) is describing how objects\nare represented and accessed. It makes references (object locations)\nfirst-class elements of the program responsible for many important functions\nwhich are difficult to model via objects. COP rethinks and generalizes such\nprimary notions of object-orientation as class and inheritance by introducing a\nnovel construct, concept, and a new relation, inclusion. An advantage is that\nusing only a few basic notions we are able to describe many general patterns of\nthoughts currently belonging to different programming paradigms: modeling\nobject hierarchies (prototype-based program-ming), precedence of parent methods\nover child methods (inner methods in Beta), modularizing cross-cutting\ncon-cerns (aspect-oriented programming), value-orientation (functional\nprogramming). Since COP remains backward compatible with object-oriented\nprogramming, it can be viewed as a perspective direction for developing a\nsimple and natural unified programming model.\n", "versions": [{"version": "v1", "created": "Sat, 13 Sep 2014 13:10:30 GMT"}], "update_date": "2014-09-16", "authors_parsed": [["Savinov", "Alexandr", ""]]}, {"id": "1409.4078", "submitter": "Boris Burshteyn", "authors": "Boris Burshteyn", "title": "The distributed Language Hello White Paper", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hello is a general-purpose, object-oriented, protocol-agnostic distributed\nprogramming language. This paper explains the ideas that guided design of\nHello. It shows the spirit of Hello using two brief expressive programs and\nprovides a summary of language features. In addition, it explores historical\nparallels between the binary programming of early computers and the distributed\nprogramming of modern networks.\n", "versions": [{"version": "v1", "created": "Sun, 14 Sep 2014 17:26:34 GMT"}], "update_date": "2014-09-16", "authors_parsed": [["Burshteyn", "Boris", ""]]}, {"id": "1409.5022", "submitter": "Cosimo Laneve", "authors": "Frank De Boer (CWI), Mahdi Jaghoori (Leiden University), Cosimo Laneve\n  (University of Bologna), Gianluigi Zavattaro (University of Bologna)", "title": "Decidability Problems for Actor Systems", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 10, Issue 4 (December\n  4, 2014) lmcs:1091", "doi": "10.2168/LMCS-10(4:5)2014", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a nominal actor-based language and study its expressive power.\nWe have identified the presence/absence of fields as a crucial feature: the\ndynamic creation of names in combination with fields gives rise to Turing\ncompleteness. On the other hand, restricting to stateless actors gives rise to\nsystems for which properties such as termination are decidable. This\ndecidability result still holds for actors with states when the number of\nactors is bounded and the state is read-only.\n", "versions": [{"version": "v1", "created": "Wed, 17 Sep 2014 15:13:02 GMT"}, {"version": "v2", "created": "Wed, 3 Dec 2014 14:42:47 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["De Boer", "Frank", "", "CWI"], ["Jaghoori", "Mahdi", "", "Leiden University"], ["Laneve", "Cosimo", "", "University of Bologna"], ["Zavattaro", "Gianluigi", "", "University of Bologna"]]}, {"id": "1409.6825", "submitter": "Mohamad Noureddine A", "authors": "Fadi A. Zaraket and Mohamad Noureddine", "title": "Model Checking Software Programs with First Order Logic Specifications\n  using AIG Solvers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Static verification techniques leverage Boolean formula satisfiability\nsolvers such as SAT and SMT solvers that operate on conjunctive normal form and\nfirst order logic formulae, respectively, to validate programs. They force\nbounds on variable ranges and execution time and translate the program and its\nspecifications into a Boolean formula. They are limited to programs of\nrelatively low complexity for the following reasons. (1) A small increase in\nthe bounds can cause a large increase in the size of the translated formula.\n(2) Boolean satisfiability solvers are restricted to using optimizations that\napply at the level of the formula. Finally, (3) the Boolean formulae often need\nto be regenerated with higher bounds to ensure the correctness of the\ntranslation. We present a method that uses sequential circuits, Boolean\nformulae with memory elements and hierarchical structure, and sequential\ncircuit synthesis and verification frameworks to validate programs. (1)\nSequential circuits are much more succinct than Boolean formulae with no memory\nelements and preserve the high-level structure of the program. (2) Encoding the\nproblem as a sequential circuit enables the use of a number of powerful\nautomated analysis techniques that have no counterparts for other Boolean\nformulae. Our method takes an imperative program with a first order logic\nspecification consisting of a precondition and a postcondition pair, and a\nbound on the program variable ranges, and produces a sequential circuit with a\ndesignated output that is true when the program violates the specification.\n", "versions": [{"version": "v1", "created": "Wed, 24 Sep 2014 04:42:04 GMT"}], "update_date": "2014-09-25", "authors_parsed": [["Zaraket", "Fadi A.", ""], ["Noureddine", "Mohamad", ""]]}, {"id": "1409.6873", "submitter": "Kees Middelburg", "authors": "J. A. Bergstra, C. A. Middelburg", "title": "Probabilistic thread algebra", "comments": "25 pages (arXiv admin note: text overlap with arXiv:1408.2955,\n  arXiv:1402.4950); some simplifications made; substantially revised", "journal-ref": "Scientific Annals of Computer Science 25(2):211--243, 2015", "doi": "10.7561/SACS.2015.2.211", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We add probabilistic features to basic thread algebra and its extensions with\nthread-service interaction and strategic interleaving. Here, threads represent\nthe behaviours produced by instruction sequences under execution and services\nrepresent the behaviours exhibited by the components of execution environments\nof instruction sequences. In a paper concerned with probabilistic instruction\nsequences, we proposed several kinds of probabilistic instructions and gave an\ninformal explanation for each of them. The probabilistic features added to the\nextension of basic thread algebra with thread-service interaction make it\npossible to give a formal explanation in terms of non-probabilistic\ninstructions and probabilistic services. The probabilistic features added to\nthe extensions of basic thread algebra with strategic interleaving make it\npossible to cover strategies corresponding to probabilistic scheduling\nalgorithms.\n", "versions": [{"version": "v1", "created": "Wed, 24 Sep 2014 09:43:39 GMT"}, {"version": "v2", "created": "Fri, 26 Sep 2014 10:54:08 GMT"}, {"version": "v3", "created": "Wed, 22 Jul 2015 10:06:30 GMT"}], "update_date": "2016-02-05", "authors_parsed": [["Bergstra", "J. A.", ""], ["Middelburg", "C. A.", ""]]}, {"id": "1409.7509", "submitter": "Georgiana Caltais", "authors": "Georgiana Caltais", "title": "Expression-based aliasing for OO-languages", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Alias analysis has been an interesting research topic in verification and\noptimization of programs. The undecidability of determining whether two\nexpressions in a program may reference to the same object is the main source of\nthe challenges raised in alias analysis. In this paper we propose an extension\nof a previously introduced alias calculus based on program expressions, to the\nsetting of unbounded program executions s.a. infinite loops and recursive\ncalls. Moreover, we devise a corresponding executable specification in the\nK-framework. An important property of our extension is that, in a\nnon-concurrent setting, the corresponding alias expressions can be\nover-approximated in terms of a notion of regular expressions. This further\nenables us to show that the associated K-machinery implements an algorithm that\nalways stops and provides a sound over-approximation of the \"may aliasing\"\ninformation, where soundness stands for the lack of false negatives. As a case\nstudy, we analyze the integration and further applications of the alias\ncalculus in SCOOP. The latter is an object-oriented programming model for\nconcurrency, recently formalized in Maude; K-definitions can be compiled into\nMaude for execution.\n", "versions": [{"version": "v1", "created": "Fri, 26 Sep 2014 09:19:31 GMT"}, {"version": "v2", "created": "Mon, 20 Oct 2014 07:20:47 GMT"}], "update_date": "2014-10-21", "authors_parsed": [["Caltais", "Georgiana", ""]]}, {"id": "1409.7514", "submitter": "Georgiana Caltais", "authors": "Georgiana Caltais and Bertrand Meyer", "title": "Coffman deadlocks in SCOOP", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we address the deadlock detection problem in the context of\nSCOOP - an OO-programming model for concurrency, recently formalized in Maude.\nWe present the integration of a deadlock detection mechanism on top of the\naforementioned formalization and analyze how an abstract semantics of SCOOP\nbased on a notion of \"may alias expressions\" can contribute to improving the\ndeadlock detection procedure.\n", "versions": [{"version": "v1", "created": "Fri, 26 Sep 2014 09:29:09 GMT"}, {"version": "v2", "created": "Mon, 29 Sep 2014 08:39:07 GMT"}, {"version": "v3", "created": "Mon, 6 Oct 2014 12:18:11 GMT"}], "update_date": "2014-10-07", "authors_parsed": [["Caltais", "Georgiana", ""], ["Meyer", "Bertrand", ""]]}, {"id": "1409.7628", "submitter": "Roberto Casta\\~neda Lozano", "authors": "Roberto Casta\\~neda Lozano and Christian Schulte", "title": "Survey on Combinatorial Register Allocation and Instruction Scheduling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Register allocation (mapping variables to processor registers or memory) and\ninstruction scheduling (reordering instructions to increase instruction-level\nparallelism) are essential tasks for generating efficient assembly code in a\ncompiler. In the last three decades, combinatorial optimization has emerged as\nan alternative to traditional, heuristic algorithms for these two tasks.\nCombinatorial optimization approaches can deliver optimal solutions according\nto a model, can precisely capture trade-offs between conflicting decisions, and\nare more flexible at the expense of increased compilation time.\n  This paper provides an exhaustive literature review and a classification of\ncombinatorial optimization approaches to register allocation and instruction\nscheduling, with a focus on the techniques that are most applied in this\ncontext: integer programming, constraint programming, partitioned Boolean\nquadratic programming, and enumeration. Researchers in compilers and\ncombinatorial optimization can benefit from identifying developments, trends,\nand challenges in the area; compiler practitioners may discern opportunities\nand grasp the potential benefit of applying combinatorial optimization.\n", "versions": [{"version": "v1", "created": "Fri, 26 Sep 2014 16:32:07 GMT"}, {"version": "v2", "created": "Thu, 18 Apr 2019 12:21:19 GMT"}, {"version": "v3", "created": "Fri, 7 Jun 2019 08:19:30 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Lozano", "Roberto Casta\u00f1eda", ""], ["Schulte", "Christian", ""]]}, {"id": "1409.7760", "submitter": "Mathias Payer", "authors": "Mathias Payer and Stephen Crane and Per Larsen and Stefan Brunthaler\n  and Richard Wartell and Michael Franz", "title": "Similarity-based matching meets Malware Diversity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.PL cs.SE cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Similarity metrics, e.g., signatures as used by anti-virus products, are the\ndominant technique to detect if a given binary is malware. The underlying\nassumption of this approach is that all instances of a malware (or even malware\nfamily) will be similar to each other.\n  Software diversification is a probabilistic technique that uses code and data\nrandomization and expressiveness in the target instruction set to generate\nlarge amounts of functionally equivalent but different binaries. Malware\ndiversity builds on software diversity and ensures that any two diversified\ninstances of the same malware have low similarity (according to a set of\nsimilarity metrics). An LLVM-based prototype implementation diversifies both\ncode and data of binaries and our evaluation shows that signatures based on\nsimilarity only match one or few instances in a pool of diversified binaries\ngenerated from the same source code.\n", "versions": [{"version": "v1", "created": "Sat, 27 Sep 2014 04:00:59 GMT"}], "update_date": "2014-09-30", "authors_parsed": [["Payer", "Mathias", ""], ["Crane", "Stephen", ""], ["Larsen", "Per", ""], ["Brunthaler", "Stefan", ""], ["Wartell", "Richard", ""], ["Franz", "Michael", ""]]}, {"id": "1409.7841", "submitter": "Martin Strecker", "authors": "Nadezhda Baklanova and Wilmer Ricciotti and Jan-Georg Smaus and Martin\n  Strecker", "title": "Abstracting an operational semantics to finite automata", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is an apparent similarity between the descriptions of small-step\noperational semantics of imperative programs and the semantics of finite\nautomata, so defining an abstraction mapping from semantics to automata and\nproving a simulation property seems to be easy. This paper aims at identifying\nthe reasons why simple proofs break, among them artifacts in the semantics that\nlead to stuttering steps in the simulation. We then present a semantics based\non the zipper data structure, with a direct interpretation of evaluation as\nnavigation in the syntax tree. The abstraction function is then defined by\nequivalence class construction.\n", "versions": [{"version": "v1", "created": "Sat, 27 Sep 2014 21:05:38 GMT"}], "update_date": "2014-09-30", "authors_parsed": [["Baklanova", "Nadezhda", ""], ["Ricciotti", "Wilmer", ""], ["Smaus", "Jan-Georg", ""], ["Strecker", "Martin", ""]]}]