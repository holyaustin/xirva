[{"id": "1309.0339", "submitter": "Taisuke Sato", "authors": "Taisuke Sato and Philipp Meyer", "title": "Infinite probability computation by cyclic explanation graphs", "comments": "29 pages", "journal-ref": "Theory and Practice of Logic Programming 14 (2014) 909-937", "doi": "10.1017/S1471068413000562", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tabling in logic programming has been used to eliminate redundant computation\nand also to stop infinite loop. In this paper we investigate another\npossibility of tabling, i.e. to compute an infinite sum of probabilities for\nprobabilistic logic programs. Using PRISM, a logic-based probabilistic modeling\nlanguage with a tabling mechanism, we generalize prefix probability computation\nfor probabilistic context free grammars (PCFGs) to probabilistic logic\nprograms. Given a top-goal, we search for all proofs with tabling and obtain an\nexplanation graph which compresses them and may be cyclic. We then convert the\nexplanation graph to a set of linear probability equations and solve them by\nmatrix operation. The solution gives us the probability of the top-goal, which,\nin nature, is an infinite sum of probabilities. Our general approach to prefix\nprobability computation through tabling not only allows to deal with non-PCFGs\nsuch as probabilistic left-corner grammars (PLCGs) but has applications such as\nplan recognition and probabilistic model checking and makes it possible to\ncompute probability for probabilistic models describing cyclic relations. To\nappear in Theory and Practice of Logic Programming (TPLP).\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2013 09:44:28 GMT"}, {"version": "v2", "created": "Tue, 17 Sep 2013 04:36:40 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Sato", "Taisuke", ""], ["Meyer", "Philipp", ""]]}, {"id": "1309.0924", "submitter": "EPTCS", "authors": "Ugo de'Liguoro (Turin University), Alexis Saurin (CNRS, PPS UMR 7126,\n  Univ Paris Diderot)", "title": "Proceedings First Workshop on Control Operators and their Semantics", "comments": null, "journal-ref": "EPTCS 127, 2013", "doi": "10.4204/EPTCS.127", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The focus of the papers presented in this volume is on the interplay between\nsyntax and semantics in case of languages, namely the central question of what\na program means and how it does define the intended procedure. This is a\ncrucial issue especially in the case of control operators, since they are as\npowerful as potentially obscure, and programs that use them are usually more\nerror-prone than purely declarative ones. The included contributions provide\nperspectives on the topic of control operators via operational semantics of\nformal calculi as well as type assignment systems, denotational semantics, game\nsemantics, category theory and logic.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2013 06:32:06 GMT"}], "update_date": "2013-09-05", "authors_parsed": [["de'Liguoro", "Ugo", "", "Turin University"], ["Saurin", "Alexis", "", "CNRS, PPS UMR 7126,\n  Univ Paris Diderot"]]}, {"id": "1309.1251", "submitter": "Keehang Kwon", "authors": "Keehang Kwon", "title": "Pattern Matching via Choice Existential Quantifications in Imperative\n  Languages", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Selection statements -- if-then-else, switch and try-catch -- are commonly\nused in modern imperative programming languages. We propose another selection\nstatement called a {\\it choice existentially quantified statement}. This\nstatement turns out to be quite useful for pattern matching among several\nmerits. Examples will be provided for this statement.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2013 07:45:00 GMT"}], "update_date": "2013-09-06", "authors_parsed": [["Kwon", "Keehang", ""]]}, {"id": "1309.1256", "submitter": "EPTCS", "authors": "Harley Eades (University of Iowa), Aaron Stump (University of Iowa)", "title": "Hereditary Substitution for the \\lambda\\Delta-Calculus", "comments": "In Proceedings COS 2013, arXiv:1309.0924", "journal-ref": "EPTCS 127, 2013, pp. 45-65", "doi": "10.4204/EPTCS.127.4", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hereditary substitution is a form of type-bounded iterated substitution,\nfirst made explicit by Watkins et al. and Adams in order to show normalization\nof proof terms for various constructive logics. This paper is the first to\napply hereditary substitution to show normalization of a type theory\ncorresponding to a non-constructive logic, namely the lambda-Delta calculus as\nformulated by Rehof. We show that there is a non-trivial extension of the\nhereditary substitution function of the simply-typed lambda calculus to one for\nthe lambda-Delta calculus. Then hereditary substitution is used to prove\nnormalization.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2013 08:03:41 GMT"}], "update_date": "2013-09-06", "authors_parsed": [["Eades", "Harley", "", "University of Iowa"], ["Stump", "Aaron", "", "University of Iowa"]]}, {"id": "1309.1257", "submitter": "EPTCS", "authors": "Bram Geron, Herman Geuvers", "title": "Continuation calculus", "comments": "In Proceedings COS 2013, arXiv:1309.0924", "journal-ref": "EPTCS 127, 2013, pp. 66-85", "doi": "10.4204/EPTCS.127.5", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Programs with control are usually modeled using lambda calculus extended with\ncontrol operators. Instead of modifying lambda calculus, we consider a\ndifferent model of computation. We introduce continuation calculus, or CC, a\ndeterministic model of computation that is evaluated using only head reduction,\nand argue that it is suitable for modeling programs with control. It is\ndemonstrated how to define programs, specify them, and prove them correct. This\nis shown in detail by presenting in CC a list multiplication program that\nprematurely returns when it encounters a zero. The correctness proof includes\ntermination of the program. In continuation calculus we can model both\ncall-by-name and call-by-value. In addition, call-by-name functions can be\napplied to call-by-value results, and conversely.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2013 08:03:50 GMT"}], "update_date": "2013-09-06", "authors_parsed": [["Geron", "Bram", ""], ["Geuvers", "Herman", ""]]}, {"id": "1309.1258", "submitter": "EPTCS", "authors": "Yoshihiko Kakutani, Daisuke Kimura", "title": "Induction by Coinduction and Control Operators in Call-by-Name", "comments": "In Proceedings COS 2013, arXiv:1309.0924", "journal-ref": "EPTCS 127, 2013, pp. 101-112", "doi": "10.4204/EPTCS.127.7", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies emulation of induction by coinduction in a call-by-name\nlanguage with control operators. Since it is known that call-by-name\nprogramming languages with control operators cannot have general initial\nalgebras, interaction of induction and control operators is often restricted to\neffect-free functions. We show that some class of such restricted inductive\ntypes can be derived from full coinductive types by the power of control\noperators. As a typical example of our results, the type of natural numbers is\nrepresented by the type of streams. The underlying idea is a counterpart of the\nfact that some coinductive types can be expressed by inductive types in\ncall-by-name pure language without side-effects.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2013 08:04:06 GMT"}], "update_date": "2013-09-06", "authors_parsed": [["Kakutani", "Yoshihiko", ""], ["Kimura", "Daisuke", ""]]}, {"id": "1309.1259", "submitter": "EPTCS", "authors": "James Laird (University of Bath)", "title": "Combining and Relating Control Effects and their Semantics", "comments": "In Proceedings COS 2013, arXiv:1309.0924", "journal-ref": "EPTCS 127, 2013, pp. 113-129", "doi": "10.4204/EPTCS.127.8", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combining local exceptions and first class continuations leads to programs\nwith complex control flow, as well as the possibility of expressing powerful\nconstructs such as resumable exceptions. We describe and compare games models\nfor a programming language which includes these features, as well as\nhigher-order references. They are obtained by contrasting methodologies: by\nannotating sequences of moves with \"control pointers\" indicating where\nexceptions are thrown and caught, and by composing the exceptions and\ncontinuations monads.\n  The former approach allows an explicit representation of control flow in\ngames for exceptions, and hence a straightforward proof of definability (full\nabstraction) by factorization, as well as offering the possibility of a\nsemantic approach to control flow analysis of exception-handling. However,\nestablishing soundness of such a concrete and complex model is a non-trivial\nproblem. It may be resolved by establishing a correspondence with the monad\nsemantics, based on erasing explicit exception moves and replacing them with\ncontrol pointers.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2013 08:04:12 GMT"}], "update_date": "2013-09-06", "authors_parsed": [["Laird", "James", "", "University of Bath"]]}, {"id": "1309.1261", "submitter": "EPTCS", "authors": "Ma{\\l}gorzata Biernacka, Dariusz Biernacki, Sergue\\\"i Lenglet, Marek\n  Materzok", "title": "Proving termination of evaluation for System F with control operators", "comments": "In Proceedings COS 2013, arXiv:1309.0924", "journal-ref": "EPTCS 127, 2013, pp. 15-29", "doi": "10.4204/EPTCS.127.2", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present new proofs of termination of evaluation in reduction semantics\n(i.e., a small-step operational semantics with explicit representation of\nevaluation contexts) for System F with control operators. We introduce a\nmodified version of Girard's proof method based on reducibility candidates,\nwhere the reducibility predicates are defined on values and on evaluation\ncontexts as prescribed by the reduction semantics format. We address both\nabortive control operators (callcc) and delimited-control operators (shift and\nreset) for which we introduce novel polymorphic type systems, and we consider\nboth the call-by-value and call-by-name evaluation strategies.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2013 08:04:31 GMT"}], "update_date": "2013-09-06", "authors_parsed": [["Biernacka", "Ma\u0142gorzata", ""], ["Biernacki", "Dariusz", ""], ["Lenglet", "Sergue\u00ef", ""], ["Materzok", "Marek", ""]]}, {"id": "1309.1307", "submitter": "Piotr Beling", "authors": "Piotr Beling", "title": "C++11 -- idea r-warto\\'sci i przenoszenia", "comments": "7 pages, in Polish", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a review of some new futures introduced to C++ language\nby ISO/IEC 14882:2011 standard (known as C++11). It describes the ideas of\nr-values and move constructors.\n  ----\n  Niniejszy artyku{\\l} jest jednym z serii artyku{\\l}\\'ow w kt\\'orych zawarto\nprzegl{\\ka}d nowych element\\'ow j{\\ke}zyka C++ wprowadzonych przez standard\nISO/IEC 14882:2011, znany pod nazw{\\ka} C++11. W artykule przedstawiono nowe\nmo\\.zliwo\\'sci zwi{\\ka}zane z przekazywaniem parametr\\'ow i pisaniem\nkonstruktor\\'ow. Zawarto w nim dok{\\l}adne om\\'owienie idei r-warto\\'sci i\nprzenoszenia obiekt\\'ow.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2013 10:48:52 GMT"}], "update_date": "2013-09-06", "authors_parsed": [["Beling", "Piotr", ""]]}, {"id": "1309.1334", "submitter": "Alan Schmitt", "authors": "Todd J. Green and Alan Schmitt", "title": "Proceedings of the 14th International Symposium on Database Programming\n  Languages (DBPL 2013), August 30, 2013, Riva del Garda, Trento, Italy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the papers presented at the 14th Symposium on Database\nProgramming Languages (DBPL 2013) held on August 30th, 2013, in Riva del Garda,\nco-located with the 39th International Conference on Very Large Databases (VLDB\n2013). They cover a wide range of topics including the application of\nprogramming language techniques to further the expressiveness of database\nlanguages, schema management, and the practical use of XPath. To complement\nthis technical program, DBPL 2013 featured three invited talks by Serge\nAbiteboul (Inria), J\\'er\\^ome Sim\\'eon (IBM), and Soren Lassen (Facebook).\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2013 12:48:03 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2013 09:48:21 GMT"}], "update_date": "2013-09-11", "authors_parsed": [["Green", "Todd J.", ""], ["Schmitt", "Alan", ""]]}, {"id": "1309.2339", "submitter": "Nestor Catano", "authors": "N\\'estor Cata\\~no, Camilo Rueda, Tim Wahls", "title": "A Machine-Checked Proof for a Translation of Event-B Machines to JML", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a machine-checked soundness proof of a translation of Event-B to\nthe Java Modeling Language (JML). The translation is based on an operator\nEventB2Jml that maps Evnet-B events to JML method specifications, and\ndeterministic and non-deterministic assignments to JML method post-conditions.\nThis translation has previously been implemented as the EventB2Jml tool. We\nadopted a taking our own medicine approach in the formalisation of our proof so\nthat Event-B as well as JML are formalised in Event-B and the proof is\ndischarged with the Rodin platform. Hence, for any Event-B substitution\n(whether an event or an assignment) and for the JML method specification\nobtained by applying EventB2Jml to the substitution, we prove that the\nsemantics of the JML method specification is simulated by the semantics of the\nsubstitution. Therefore, the JML specification obtained as translation from the\nEvent-B substitution is a refinement of the substitution. Our proof includes\ninvariants and the standard Event-B initialising event, but it does not include\nfull machines or Event-B contexts. We assume that the semantics of JML and\nEvent-B operate both on the same initial and final states, and we justify our\nassumption.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2013 22:48:24 GMT"}], "update_date": "2013-09-11", "authors_parsed": [["Cata\u00f1o", "N\u00e9stor", ""], ["Rueda", "Camilo", ""], ["Wahls", "Tim", ""]]}, {"id": "1309.2348", "submitter": "Moez AbdelGawad", "authors": "Moez A. AbdelGawad", "title": "An Overview of Nominal-Typing versus Structural-Typing in OOP", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  NOOP is a mathematical model of nominally-typed OOP that proves the\nidentification of inheritance and subtyping in mainstream nominally-typed OO\nprogramming languages and the validity of this identification. This report\ngives an overview of the main notions in OOP relevant to constructing a\nmathematical model of OOP such as NOOP. The emphasis in this report is on\ndefining nominality, nominal typing and nominal subtyping of mainstream\nnominally-typed OO languages, and on contrasting the three notions with their\ncounterparts in structurally-typed OO languages, i.e., with structurality,\nstructural typing and structural subtyping, respectively. An additional\nappendix demonstrates these notions and other related notions, and the\ndifferences between them, using some simple code examples. A detailed, more\ntechnical comparison between nominal typing and structural typing in OOP is\npresented in other publications.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2013 00:10:04 GMT"}, {"version": "v2", "created": "Sun, 29 Jun 2014 11:08:30 GMT"}, {"version": "v3", "created": "Fri, 29 Dec 2017 17:34:49 GMT"}], "update_date": "2018-01-01", "authors_parsed": [["AbdelGawad", "Moez A.", ""]]}, {"id": "1309.2511", "submitter": "Eva Darulova", "authors": "Eva Darulova, Viktor Kuncak", "title": "On Sound Compilation of Reals", "comments": null, "journal-ref": null, "doi": null, "report-no": "EPFL-REPORT-187498", "categories": "cs.PL", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Writing accurate numerical software is hard because of many sources of\nunavoidable uncertainties, including finite numerical precision of\nimplementations. We present a programming model where the user writes a program\nin a real-valued implementation and specification language that explicitly\nincludes different types of uncertainties. We then present a compilation\nalgorithm that generates a conventional implementation that is guaranteed to\nmeet the desired precision with respect to real numbers. Our verification step\ngenerates verification conditions that treat different uncertainties in a\nunified way and encode reasoning about floating-point roundoff errors into\nreasoning about real numbers. Such verification conditions can be used as a\nstandardized format for verifying the precision and the correctness of\nnumerical programs. Due to their often non-linear nature, precise reasoning\nabout such verification conditions remains difficult. We show that current\nstate-of-the art SMT solvers do not scale well to solving such verification\nconditions. We propose a new procedure that combines exact SMT solving over\nreals with approximate and sound affine and interval arithmetic. We show that\nthis approach overcomes scalability limitations of SMT solvers while providing\nimproved precision over affine and interval arithmetic. Using our initial\nimplementation we show the usefullness and effectiveness of our approach on\nseveral examples, including those containing non-linear computation.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2013 13:53:09 GMT"}], "update_date": "2013-09-11", "authors_parsed": [["Darulova", "Eva", ""], ["Kuncak", "Viktor", ""]]}, {"id": "1309.3128", "submitter": "Ton Chanh Le", "authors": "Ton Chanh Le", "title": "Preliminary Notes on Termination and Non-Termination Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this preliminary note, we will illustrate our ideas on automated\nmechanisms for termination and non-termination reasoning.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2013 12:04:49 GMT"}], "update_date": "2013-09-13", "authors_parsed": [["Le", "Ton Chanh", ""]]}, {"id": "1309.3914", "submitter": "Damien Cassou", "authors": "Damien Cassou (INRIA Lille - Nord Europe, LIFL), St\\'ephane Ducasse\n  (INRIA Lille - Nord Europe), Nicolas Petton (INRIA Lille - Nord Europe)", "title": "SafeJS: Hermetic Sandboxing for JavaScript", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Isolating programs is an important mechanism to support more secure\napplications. Isolating program in dynamic languages such as JavaScript is even\nmore challenging since reflective operations can circumvent simple mechanisms\nthat could protect program parts. In this article we present SafeJS, an\napproach and implementation that offers isolation based on separate sandboxes\nand control of information exchanged between them. In SafeJS, sandboxes based\non web workers do not share any data. Data exchanged between sandboxes is\nsolely based on strings. Using different policies, this infrastructure supports\nthe isolation of the different scripts that usually populate web pages. A\nforeign component cannot modify the main DOM tree in unexpected manner. Our\nSafeJS implementation is currently being used in an industrial setting in the\ncontext of the Resilience FUI 12 project.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2013 11:50:39 GMT"}], "update_date": "2013-09-17", "authors_parsed": [["Cassou", "Damien", "", "INRIA Lille - Nord Europe, LIFL"], ["Ducasse", "St\u00e9phane", "", "INRIA Lille - Nord Europe"], ["Petton", "Nicolas", "", "INRIA Lille - Nord Europe"]]}, {"id": "1309.3919", "submitter": "Serguei Lenglet", "authors": "Dariusz Biernacki, Sergue\\\"i Lenglet (INRIA Nancy - Grand Est / LORIA)", "title": "Environmental Bisimulations for Delimited-Control Operators", "comments": "Long version of the corresponding APLAS13 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a theory of environmental bisimilarity for the delimited-control\noperators {\\it shift} and {\\it reset}. We consider two different notions of\ncontextual equivalence: one that does not require the presence of a top-level\ncontrol delimiter when executing tested terms, and another one, fully\ncompatible with the original CPS semantics of shift and reset, that does. For\neach of them, we develop sound and complete environmental bisimilarities, and\nwe discuss up-to techniques.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2013 11:52:40 GMT"}], "update_date": "2013-09-17", "authors_parsed": [["Biernacki", "Dariusz", "", "INRIA Nancy - Grand Est / LORIA"], ["Lenglet", "Sergue\u00ef", "", "INRIA Nancy - Grand Est / LORIA"]]}, {"id": "1309.4334", "submitter": "Lse Lse", "authors": "Martin Dias (INRIA Lille - Nord Europe), Damien Cassou (INRIA Lille -\n  Nord Europe), St\\'ephane Ducasse (INRIA Lille - Nord Europe)", "title": "Representing Code History with Development Environment Events", "comments": null, "journal-ref": "IWST-2013 - 5th International Workshop on Smalltalk Technologies\n  (2013)", "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern development environments handle information about the intent of the\nprogrammer: for example, they use abstract syntax trees for providing\nhigh-level code manipulation such as refactorings; nevertheless, they do not\nkeep track of this information in a way that would simplify code sharing and\nchange understanding. In most Smalltalk systems, source code modifications are\nimmediately registered in a transaction log often called a ChangeSet. Such\nmechanism has proven reliability, but it has several limitations. In this paper\nwe analyse such limitations and describe scenarios and requirements for\ntracking fine-grained code history with a semantic representation. We present\nEpicea, an early prototype implementation. We want to enrich code sharing with\nextra information from the IDE, which will help understanding the intention of\nthe changes and let a new generation of tools act in consequence.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2013 14:50:22 GMT"}], "update_date": "2013-09-18", "authors_parsed": [["Dias", "Martin", "", "INRIA Lille - Nord Europe"], ["Cassou", "Damien", "", "INRIA Lille -\n  Nord Europe"], ["Ducasse", "St\u00e9phane", "", "INRIA Lille - Nord Europe"]]}, {"id": "1309.4557", "submitter": "EPTCS", "authors": "Anindya Banerjee (IMDEA Software Institute), Olivier Danvy (Aarhus\n  University), Kyung-Goo Doh (Hanyang University), John Hatcliff (Kansas State\n  University)", "title": "Semantics, Abstract Interpretation, and Reasoning about Programs: Essays\n  Dedicated to David A. Schmidt on the Occasion of his Sixtieth Birthday", "comments": null, "journal-ref": "EPTCS 129, 2013", "doi": "10.4204/EPTCS.129", "report-no": null, "categories": "cs.PL cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This Liber Amicorum is a collection of essays ranging from personal memories\nto technical contributions. It is a tribute to Dave Schmidt and his career, and\nwas composed at the occasion of his sixtieth birthday.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2013 07:26:07 GMT"}], "update_date": "2013-09-19", "authors_parsed": [["Banerjee", "Anindya", "", "IMDEA Software Institute"], ["Danvy", "Olivier", "", "Aarhus\n  University"], ["Doh", "Kyung-Goo", "", "Hanyang University"], ["Hatcliff", "John", "", "Kansas State\n  University"]]}, {"id": "1309.5128", "submitter": "EPTCS", "authors": "Neil D. Jones (University of Copenhagen)", "title": "A Swiss Pocket Knife for Computability", "comments": "In Proceedings Festschrift for Dave Schmidt, arXiv:1309.4557", "journal-ref": "EPTCS 129, 2013, pp. 1-17", "doi": "10.4204/EPTCS.129.1", "report-no": null, "categories": "cs.PL cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This research is about operational- and complexity-oriented aspects of\nclassical foundations of computability theory. The approach is to re-examine\nsome classical theorems and constructions, but with new criteria for success\nthat are natural from a programming language perspective.\n  Three cornerstones of computability theory are the S-m-ntheorem; Turing's\n\"universal machine\"; and Kleene's second recursion theorem. In today's\nprogramming language parlance these are respectively partial evaluation,\nself-interpretation, and reflection. In retrospect it is fascinating that\nKleene's 1938 proof is constructive; and in essence builds a self-reproducing\nprogram.\n  Computability theory originated in the 1930s, long before the invention of\ncomputers and programs. Its emphasis was on delimiting the boundaries of\ncomputability. Some milestones include 1936 (Turing), 1938 (Kleene), 1967\n(isomorphism of programming languages), 1985 (partial evaluation), 1989 (theory\nimplementation), 1993 (efficient self-interpretation) and 2006 (term register\nmachines).\n  The \"Swiss pocket knife\" of the title is a programming language that allows\nefficient computer implementation of all three computability cornerstones,\nemphasising the third: Kleene's second recursion theorem. We describe\nexperiments with a tree-based computational model aiming for both fast program\ngeneration and fast execution of the generated programs.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2013 01:43:00 GMT"}], "update_date": "2013-09-23", "authors_parsed": [["Jones", "Neil D.", "", "University of Copenhagen"]]}, {"id": "1309.5130", "submitter": "EPTCS", "authors": "Torben {\\AE}. Mogensen (DIKU, University of Copenhagen, Denmark)", "title": "A Comparison of Well-Quasi Orders on Trees", "comments": "In Proceedings Festschrift for Dave Schmidt, arXiv:1309.4557", "journal-ref": "EPTCS 129, 2013, pp. 30-40", "doi": "10.4204/EPTCS.129.3", "report-no": null, "categories": "cs.PL cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Well-quasi orders such as homeomorphic embedding are commonly used to ensure\ntermination of program analysis and program transformation, in particular\nsupercompilation.\n  We compare eight well-quasi orders on how discriminative they are and their\ncomputational complexity. The studied well-quasi orders comprise two very\nsimple examples, two examples from literature on supercompilation and four new\nproposed by the author.\n  We also discuss combining several well-quasi orders to get well-quasi orders\nof higher discriminative power. This adds 19 more well-quasi orders to the\nlist.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2013 01:43:16 GMT"}], "update_date": "2013-09-23", "authors_parsed": [["Mogensen", "Torben \u00c6.", "", "DIKU, University of Copenhagen, Denmark"]]}, {"id": "1309.5131", "submitter": "EPTCS", "authors": "Isabella Mastroeni (Computer Science Dept., Univ. of Verona)", "title": "Abstract interpretation-based approaches to Security - A Survey on\n  Abstract Non-Interference and its Challenging Applications", "comments": "In Proceedings Festschrift for Dave Schmidt, arXiv:1309.4557", "journal-ref": "EPTCS 129, 2013, pp. 41-65", "doi": "10.4204/EPTCS.129.4", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we provide a survey on the framework of abstract\nnon-interference. In particular, we describe a general formalization of\nabstract non-interference by means of three dimensions (observation, protection\nand semantics) that can be instantiated in order to obtain well known or even\nnew weakened non-interference properties. Then, we show that the notions of\nabstract non-interference introduced in language-based security are instances\nof this more general framework which allows to better understand the different\ncomponents of a non-interference policy. Finally, we consider two challenging\nresearch fields concerning security where abstract non-interference seems a\npromising approach providing new perspectives and new solutions to open\nproblems: Code injection and code obfuscation.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2013 01:43:25 GMT"}], "update_date": "2013-09-23", "authors_parsed": [["Mastroeni", "Isabella", "", "Computer Science Dept., Univ. of Verona"]]}, {"id": "1309.5132", "submitter": "EPTCS", "authors": "Philip Mulry (Colgate University)", "title": "Notions of Monad Strength", "comments": "In Proceedings Festschrift for Dave Schmidt, arXiv:1309.4557", "journal-ref": "EPTCS 129, 2013, pp. 67-83", "doi": "10.4204/EPTCS.129.6", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past two decades the notion of a strong monad has found wide\napplicability in computing. Arising out of a need to interpret products in\ncomputational and semantic settings, different approaches to this concept have\narisen. In this paper we introduce and investigate the connections between\nthese approaches and also relate the results to monad composition. We also\nintroduce new methods for checking and using the required laws associated with\nsuch compositions, as well as provide examples illustrating problems and issues\nthat arise.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2013 01:43:32 GMT"}], "update_date": "2013-09-23", "authors_parsed": [["Mulry", "Philip", "", "Colgate University"]]}, {"id": "1309.5133", "submitter": "EPTCS", "authors": "Mads Rosendahl (Roskilde University)", "title": "Abstract Interpretation as a Programming Language", "comments": "In Proceedings Festschrift for Dave Schmidt, arXiv:1309.4557", "journal-ref": "EPTCS 129, 2013, pp. 84-104", "doi": "10.4204/EPTCS.129.7", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In David Schmidt's PhD work he explored the use of denotational semantics as\na programming language. It was part of an effort to not only treat formal\nsemantics as specifications but also as interpreters and input to compiler\ngenerators. The semantics itself can be seen as a program and one may examine\ndifferent programming styles and ways to represent states.\n  Abstract interpretation is primarily a technique for derivation and\nspecification of program analysis. As with denotational semantics we may also\nview abstract interpretations as programs and examine the implementation. The\nmain focus in this paper is to show that results from higher-order strictness\nanalysis may be used more generally as fixpoint operators for higher-order\nfunctions over lattices and thus provide a technique for immediate\nimplementation of a large class of abstract interpretations. Furthermore, it\nmay be seen as a programming paradigm and be used to write programs in a\ncircular style.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2013 01:43:40 GMT"}], "update_date": "2013-09-23", "authors_parsed": [["Rosendahl", "Mads", "", "Roskilde University"]]}, {"id": "1309.5135", "submitter": "EPTCS", "authors": "J. Launchbury, S. Krstic, T. E. Sauerwein", "title": "Coroutining Folds with Hyperfunctions", "comments": "In Proceedings Festschrift for Dave Schmidt, arXiv:1309.4557. It is a\n  privilege to submit a paper for the Festschrift symposium held to honor Dave\n  Schmidt's lifetime of contributions on the occasion of his 60th birthday.\n  Many years ago, as a fresh PhD student, Dave's excellent book on Denotational\n  Semantics opened my eyes to rich possibilities of building functions over\n  functions (recursively!) and our continued interactions over the years were\n  always insightful. So it seemed appropriate to offer a paper whose\n  foundations rely on the same mathematical models that Dave so ably expounded\n  all those years ago, constructing recursive function spaces in a way that is\n  not possible in traditional set-theoretic models. -- John Launchbury, 2013", "journal-ref": "EPTCS 129, 2013, pp. 121-135", "doi": "10.4204/EPTCS.129.9", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fold functions are a general mechanism for computing over recursive data\nstructures. First-order folds compute results bottom-up. With higher-order\nfolds, computations that inherit attributes from above can also be expressed.\nIn this paper, we explore folds over a form of recursive higher-order function,\ncalled hyperfunctions, and show that hyperfunctions allow fold computations to\ncoroutine across data structures, as well as compute bottom up and top down. We\nuse the compiler technique of foldr-build as an exemplar to show how\nhyperfunctions can be used.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2013 01:43:56 GMT"}], "update_date": "2013-09-23", "authors_parsed": [["Launchbury", "J.", ""], ["Krstic", "S.", ""], ["Sauerwein", "T. E.", ""]]}, {"id": "1309.5137", "submitter": "EPTCS", "authors": "Peter Sestoft (IT University of Copenhagen)", "title": "Online partial evaluation of sheet-defined functions", "comments": "In Proceedings Festschrift for Dave Schmidt, arXiv:1309.4557", "journal-ref": "EPTCS 129, 2013, pp. 136-160", "doi": "10.4204/EPTCS.129.10", "report-no": null, "categories": "cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a spreadsheet implementation, extended with sheet-defined\nfunctions, that allows users to define functions using only standard\nspreadsheet concepts such as cells, formulas and references, requiring no new\nsyntax. This implements an idea proposed by Peyton-Jones and others.\n  As the main contribution of this paper, we then show how to add an online\npartial evaluator for such sheet-defined functions. The result is a\nhigher-order functional language that is dynamically typed, in keeping with\nspreadsheet traditions, and an interactive platform for function definition and\nfunction specialization.\n  We describe an implementation of these ideas, present some performance data\nfrom microbenchmarks, and outline desirable improvements and extensions.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2013 01:44:04 GMT"}], "update_date": "2013-09-23", "authors_parsed": [["Sestoft", "Peter", "", "IT University of Copenhagen"]]}, {"id": "1309.5138", "submitter": "EPTCS", "authors": "Bor-Yuh Evan Chang (University of Colorado Boulder), Xavier Rival\n  (INRIA, ENS, and CNRS)", "title": "Modular Construction of Shape-Numeric Analyzers", "comments": "In Proceedings Festschrift for Dave Schmidt, arXiv:1309.4557", "journal-ref": "EPTCS 129, 2013, pp. 161-185", "doi": "10.4204/EPTCS.129.11", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of static analysis is to infer invariants about programs that are\nprecise enough to establish semantic properties, such as the absence of\nrun-time errors. Broadly speaking, there are two major branches of static\nanalysis for imperative programs. Pointer and shape analyses focus on inferring\nproperties of pointers, dynamically-allocated memory, and recursive data\nstructures, while numeric analyses seek to derive invariants on numeric values.\nAlthough simultaneous inference of shape-numeric invariants is often needed,\nthis case is especially challenging and is not particularly well explored.\nNotably, simultaneous shape-numeric inference raises complex issues in the\ndesign of the static analyzer itself.\n  In this paper, we study the construction of such shape-numeric, static\nanalyzers. We set up an abstract interpretation framework that allows us to\nreason about simultaneous shape-numeric properties by combining shape and\nnumeric abstractions into a modular, expressive abstract domain. Such a modular\nstructure is highly desirable to make its formalization and implementation\neasier to do and get correct. To achieve this, we choose a concrete semantics\nthat can be abstracted step-by-step, while preserving a high level of\nexpressiveness. The structure of abstract operations (i.e., transfer, join, and\ncomparison) follows the structure of this semantics. The advantage of this\nconstruction is to divide the analyzer in modules and functors that implement\nabstractions of distinct features.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2013 01:44:27 GMT"}], "update_date": "2013-09-23", "authors_parsed": [["Chang", "Bor-Yuh Evan", "", "University of Colorado Boulder"], ["Rival", "Xavier", "", "INRIA, ENS, and CNRS"]]}, {"id": "1309.5139", "submitter": "EPTCS", "authors": "Emanuele De Angelis (DEC, University `G. D'Annunzio', Pescara, Italy),\n  Fabio Fioravanti (DEC, University `G. D'Annunzio', Pescara, Italy), Alberto\n  Pettorossi (DICII, University of Rome Tor Vergata, Rome, Italy), Maurizio\n  Proietti (IASI-CNR, Rome, Italy)", "title": "Verification of Imperative Programs by Constraint Logic Program\n  Transformation", "comments": "In Proceedings Festschrift for Dave Schmidt, arXiv:1309.4557", "journal-ref": "EPTCS 129, 2013, pp. 186-210", "doi": "10.4204/EPTCS.129.12", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method for verifying partial correctness properties of\nimperative programs that manipulate integers and arrays by using techniques\nbased on the transformation of constraint logic programs (CLP). We use CLP as a\nmetalanguage for representing imperative programs, their executions, and their\nproperties. First, we encode the correctness of an imperative program, say\nprog, as the negation of a predicate 'incorrect' defined by a CLP program T. By\nconstruction, 'incorrect' holds in the least model of T if and only if the\nexecution of prog from an initial configuration eventually halts in an error\nconfiguration. Then, we apply to program T a sequence of transformations that\npreserve its least model semantics. These transformations are based on\nwell-known transformation rules, such as unfolding and folding, guided by\nsuitable transformation strategies, such as specialization and generalization.\nThe objective of the transformations is to derive a new CLP program TransfT\nwhere the predicate 'incorrect' is defined either by (i) the fact 'incorrect.'\n(and in this case prog is not correct), or by (ii) the empty set of clauses\n(and in this case prog is correct). In the case where we derive a CLP program\nsuch that neither (i) nor (ii) holds, we iterate the transformation. Since the\nproblem is undecidable, this process may not terminate. We show through\nexamples that our method can be applied in a rather systematic way, and is\namenable to automation by transferring to the field of program verification\nmany techniques developed in the field of program transformation.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2013 01:44:29 GMT"}], "update_date": "2013-09-23", "authors_parsed": [["De Angelis", "Emanuele", "", "DEC, University `G. D'Annunzio', Pescara, Italy"], ["Fioravanti", "Fabio", "", "DEC, University `G. D'Annunzio', Pescara, Italy"], ["Pettorossi", "Alberto", "", "DICII, University of Rome Tor Vergata, Rome, Italy"], ["Proietti", "Maurizio", "", "IASI-CNR, Rome, Italy"]]}, {"id": "1309.5141", "submitter": "EPTCS", "authors": "Julien Mercadal, Zo\\'e Drey, Charles Consel", "title": "Denotational Semantics of A User-Oriented, Domain-Specific Language", "comments": "In Proceedings Festschrift for Dave Schmidt, arXiv:1309.4557", "journal-ref": "EPTCS 129, 2013, pp. 229-249", "doi": "10.4204/EPTCS.129.14", "report-no": null, "categories": "cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the formal definition of a domain-specific language,\nnamed Pantagruel, following the methodology proposed by David Schmidt for\nlanguage development. This language is dedicated to programming applications\nthat orchestrate networked entities. It targets developers that are\nprofessionals in such domains as building management and assisted living, and\nwant to leverage networked entities to support daily tasks.\n  Pantagruel has a number of features that address the requirements of the\ndomain of entity orchestration. Furthermore, Pantagruel provides high-level\nconstructs that make it accessible to developers that do not necessarily have\nprogramming skills. It has been used to develop a number of applications by\nnon-programmers.\n  We show how the user-oriented programming concepts of Pantagruel are\nexpressed in the denotational semantics of Pantagruel. This formal definition\nhas been used to derive an interpreter for Pantagruel and to provide a basis to\nreason about Pantagruel programs.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2013 01:44:48 GMT"}], "update_date": "2013-09-23", "authors_parsed": [["Mercadal", "Julien", ""], ["Drey", "Zo\u00e9", ""], ["Consel", "Charles", ""]]}, {"id": "1309.5142", "submitter": "EPTCS", "authors": "Robert Gl\\\"uck (DIKU)", "title": "Simulation of Two-Way Pushdown Automata Revisited", "comments": "In Proceedings Festschrift for Dave Schmidt, arXiv:1309.4557", "journal-ref": "EPTCS 129, 2013, pp. 250-258", "doi": "10.4204/EPTCS.129.15", "report-no": null, "categories": "cs.PL cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The linear-time simulation of 2-way deterministic pushdown automata (2DPDA)\nby the Cook and Jones constructions is revisited. Following the semantics-based\napproach by Jones, an interpreter is given which, when extended with\nrandom-access memory, performs a linear-time simulation of 2DPDA. The recursive\ninterpreter works without the dump list of the original constructions, which\nmakes Cook's insight into linear-time simulation of exponential-time automata\nmore intuitive and the complexity argument clearer. The simulation is then\nextended to 2-way nondeterministic pushdown automata (2NPDA) to provide for a\ncubic-time recognition of context-free languages. The time required to run the\nfinal construction depends on the degree of nondeterminism. The key mechanism\nthat enables the polynomial-time simulations is the sharing of computations by\nmemoization.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2013 01:44:54 GMT"}], "update_date": "2013-09-23", "authors_parsed": [["Gl\u00fcck", "Robert", "", "DIKU"]]}, {"id": "1309.5143", "submitter": "EPTCS", "authors": "Johannes Neubauer (Chair of Programming Systems, TU Dortmund,\n  Germany), Bernhard Steffen (Chair of Programming Systems, TU Dortmund,\n  Germany), Tiziana Margaria (Chair of Service and Software Engineering,\n  Universit\\\"at Potsdam, Germany)", "title": "Higher-Order Process Modeling: Product-Lining, Variability Modeling and\n  Beyond", "comments": "In Proceedings Festschrift for Dave Schmidt, arXiv:1309.4557", "journal-ref": "EPTCS 129, 2013, pp. 259-283", "doi": "10.4204/EPTCS.129.16", "report-no": null, "categories": "cs.SE cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a graphical and dynamic framework for binding and execution of\nbusiness) process models. It is tailored to integrate 1) ad hoc processes\nmodeled graphically, 2) third party services discovered in the (Inter)net, and\n3) (dynamically) synthesized process chains that solve situation-specific\ntasks, with the synthesis taking place not only at design time, but also at\nruntime. Key to our approach is the introduction of type-safe stacked\nsecond-order execution contexts that allow for higher-order process modeling.\nTamed by our underlying strict service-oriented notion of abstraction, this\napproach is tailored also to be used by application experts with little\ntechnical knowledge: users can select, modify, construct and then pass\n(component) processes during process execution as if they were data. We\nillustrate the impact and essence of our framework along a concrete, realistic\n(business) process modeling scenario: the development of Springer's\nbrowser-based Online Conference Service (OCS). The most advanced feature of our\nnew framework allows one to combine online synthesis with the integration of\nthe synthesized process into the running application. This ability leads to a\nparticularly flexible way of implementing self-adaption, and to a particularly\nconcise and powerful way of achieving variability not only at design time, but\nalso at runtime.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2013 01:45:10 GMT"}], "update_date": "2013-09-23", "authors_parsed": [["Neubauer", "Johannes", "", "Chair of Programming Systems, TU Dortmund,\n  Germany"], ["Steffen", "Bernhard", "", "Chair of Programming Systems, TU Dortmund,\n  Germany"], ["Margaria", "Tiziana", "", "Chair of Service and Software Engineering,\n  Universit\u00e4t Potsdam, Germany"]]}, {"id": "1309.5144", "submitter": "EPTCS", "authors": "Anindya Banerjee, David A. Naumann", "title": "A Simple Semantics and Static Analysis for Stack Inspection", "comments": "In Proceedings Festschrift for Dave Schmidt, arXiv:1309.4557", "journal-ref": "EPTCS 129, 2013, pp. 284-308", "doi": "10.4204/EPTCS.129.17", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Java virtual machine and the .NET common language runtime feature an\naccess control mechanism specified operationally in terms of run-time stack\ninspection. We give a denotational semantics in \"eager\" form, and show that it\nis equivalent to the \"lazy\" semantics using stack inspection. We give a static\nanalysis of safety, i.e., the absence of security errors, that is simpler than\nprevious proposals. We identify several program transformations that can be\nused to remove run-time checks. We give complete, detailed proofs for safety of\nthe analysis and for the transformations, exploiting compositionality of the\neager semantics.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2013 01:45:17 GMT"}], "update_date": "2013-09-23", "authors_parsed": [["Banerjee", "Anindya", ""], ["Naumann", "David A.", ""]]}, {"id": "1309.5147", "submitter": "EPTCS", "authors": "Chris Hankin (Imperial College London)", "title": "A short note on Simulation and Abstraction", "comments": "In Proceedings Festschrift for Dave Schmidt, arXiv:1309.4557", "journal-ref": "EPTCS 129, 2013, pp. 337-340", "doi": "10.4204/EPTCS.129.20", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This short note is written in celebration of David Schmidt's sixtieth\nbirthday. He has now been active in the program analysis research community for\nover thirty years and we have enjoyed many interactions with him. His work on\ncharacterising simulations between Kripke structures using Galois connections\nwas particularly influential in our own work on using probabilistic abstract\ninterpretation to study Larsen and Skou's notion of probabilistic bisimulation.\nWe briefly review this work and discuss some recent applications of these ideas\nin a variety of different application areas.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2013 01:45:44 GMT"}], "update_date": "2013-09-23", "authors_parsed": [["Hankin", "Chris", "", "Imperial College London"]]}, {"id": "1309.5148", "submitter": "EPTCS", "authors": "Francesco Logozzo (Microsoft Research, Redmond, USA), Matthieu Martel\n  (Universit\\'e de Perpignan Via Domitia & LIRMM)", "title": "Automatic Repair of Overflowing Expressions with Abstract Interpretation", "comments": "In Proceedings Festschrift for Dave Schmidt, arXiv:1309.4557", "journal-ref": "EPTCS 129, 2013, pp. 341-357", "doi": "10.4204/EPTCS.129.21", "report-no": null, "categories": "cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of synthesizing provably non-overflowing integer\narithmetic expressions or Boolean relations among integer arithmetic\nexpressions. First we use a numerical abstract domain to infer numerical\nproperties among program variables. Then we check if those properties guarantee\nthat a given expression does not overflow. If this is not the case, we\nsynthesize an equivalent, yet not-overflowing expression, or we report that\nsuch an expression does not exists.\n  The synthesis of a non-overflowing expression depends on three, orthogonal\nfactors: the input expression (e.g., is it linear, polynomial,... ?), the\noutput expression (e.g., are case splits allowed?), and the underlying\nnumerical abstract domain - the more precise the abstract domain is, the more\ncorrect expressions can be synthesized.\n  We consider three common cases: (i) linear expressions with integer\ncoefficients and intervals; (ii) Boolean expressions of linear expressions; and\n(iii) linear expressions with templates. In the first case we prove there\nexists a complete and polynomial algorithm to solve the problem. In the second\ncase, we have an incomplete yet polynomial algorithm, whereas in the third we\nhave a complete yet worst-case exponential algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2013 01:45:52 GMT"}], "update_date": "2013-09-23", "authors_parsed": [["Logozzo", "Francesco", "", "Microsoft Research, Redmond, USA"], ["Martel", "Matthieu", "", "Universit\u00e9 de Perpignan Via Domitia & LIRMM"]]}, {"id": "1309.5149", "submitter": "EPTCS", "authors": "Martin Bodin (ENS Lyon and Inria), Thomas Jensen (Inria), Alan Schmitt\n  (Inria)", "title": "Pretty-big-step-semantics-based Certified Abstract Interpretation\n  (Preliminary version)", "comments": "In Proceedings Festschrift for Dave Schmidt, arXiv:1309.4557", "journal-ref": "EPTCS 129, 2013, pp. 360-383", "doi": "10.4204/EPTCS.129.23", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a technique for deriving semantic program analyses from a natural\nsemantics specification of the programming language. The technique is based on\na particular kind of semantics called pretty-big-step semantics. We present a\npretty-big-step semantics of a language with simple objects called O'While and\nspecify a series of instrumentations of the semantics that explicitates the\nflows of values in a program. This leads to a semantics-based dependency\nanalysis, at the core, e.g., of tainting analysis in software security. The\nformalization has been realized with the Coq proof assistant.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2013 01:46:06 GMT"}], "update_date": "2013-09-23", "authors_parsed": [["Bodin", "Martin", "", "ENS Lyon and Inria"], ["Jensen", "Thomas", "", "Inria"], ["Schmitt", "Alan", "", "Inria"]]}, {"id": "1309.5150", "submitter": "EPTCS", "authors": "Benedikt Nordhoff (Westf\\\"alische Wilhelms-Universit\\\"at M\\\"unster,\n  Germany), Markus M\\\"uller-Olm (Westf\\\"alische Wilhelms-Universit\\\"at\n  M\\\"unster, Germany), Peter Lammich (Technische Universit\\\"at M\\\"unchen,\n  Germany)", "title": "Iterable Forward Reachability Analysis of Monitor-DPNs", "comments": "In Proceedings Festschrift for Dave Schmidt, arXiv:1309.4557", "journal-ref": "EPTCS 129, 2013, pp. 384-403", "doi": "10.4204/EPTCS.129.24", "report-no": null, "categories": "cs.LO cs.DC cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a close connection between data-flow analysis and model checking as\nobserved and studied in the nineties by Steffen and Schmidt. This indicates\nthat automata-based analysis techniques developed in the realm of\ninfinite-state model checking can be applied as data-flow analyzers that\ninterpret complex control structures, which motivates the development of such\nanalysis techniques for ever more complex models. One approach proposed by\nEsparza and Knoop is based on computation of predecessor or successor sets for\nsets of automata configurations. Our goal is to adapt and exploit this approach\nfor analysis of multi-threaded Java programs. Specifically, we consider the\nmodel of Monitor-DPNs for concurrent programs. Monitor-DPNs precisely model\nunbounded recursion, dynamic thread creation, and synchronization via\nwell-nested locks with finite abstractions of procedure- and thread-local\nstate. Previous work on this model showed how to compute regular predecessor\nsets of regular configurations and tree-regular successor sets of a fixed\ninitial configuration. By combining and extending different previously\ndeveloped techniques we show how to compute tree-regular successor sets of\ntree-regular sets. Thereby we obtain an iterable, lock-sensitive forward\nreachability analysis. We implemented the analysis for Java programs and\napplied it to information flow control and data race detection.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2013 01:46:11 GMT"}], "update_date": "2013-09-23", "authors_parsed": [["Nordhoff", "Benedikt", "", "Westf\u00e4lische Wilhelms-Universit\u00e4t M\u00fcnster,\n  Germany"], ["M\u00fcller-Olm", "Markus", "", "Westf\u00e4lische Wilhelms-Universit\u00e4t\n  M\u00fcnster, Germany"], ["Lammich", "Peter", "", "Technische Universit\u00e4t M\u00fcnchen,\n  Germany"]]}, {"id": "1309.5152", "submitter": "EPTCS", "authors": "Jooyong Yi (National University of Singapore)", "title": "A Case for Dynamic Reverse-code Generation to Debug Non-deterministic\n  Programs", "comments": "In Proceedings Festschrift for Dave Schmidt, arXiv:1309.4557", "journal-ref": "EPTCS 129, 2013, pp. 419-428", "doi": "10.4204/EPTCS.129.27", "report-no": null, "categories": "cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Backtracking (i.e., reverse execution) helps the user of a debugger to\nnaturally think backwards along the execution path of a program, and thinking\nbackwards makes it easy to locate the origin of a bug. So far backtracking has\nbeen implemented mostly by state saving or by checkpointing. These\nimplementations, however, inherently do not scale. Meanwhile, a more recent\nbacktracking method based on reverse-code generation seems promising because\nexecuting reverse code can restore the previous states of a program without\nstate saving. In the literature, there can be found two methods that generate\nreverse code: (a) static reverse-code generation that pre-generates reverse\ncode through static analysis before starting a debugging session, and (b)\ndynamic reverse-code generation that generates reverse code by applying dynamic\nanalysis on the fly during a debugging session. In particular, we espoused the\nlatter one in our previous work to accommodate non-determinism of a program\ncaused by e.g., multi-threading. To demonstrate the usefulness of our dynamic\nreverse-code generation, this article presents a case study of various\nbacktracking methods including ours. We compare the memory usage of various\nbacktracking methods in a simple but nontrivial example, a bounded-buffer\nprogram. In the case of non-deterministic programs such as this bounded-buffer\nprogram, our dynamic reverse-code generation outperforms the existing\nbacktracking methods in terms of memory efficiency.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2013 01:46:26 GMT"}], "update_date": "2013-09-23", "authors_parsed": [["Yi", "Jooyong", "", "National University of Singapore"]]}, {"id": "1309.5500", "submitter": "Vinayak Naik", "authors": "Judith Bishop, Nikolai Tillmann, Arno Puder, Vinayak Naik", "title": "PRoMoTo 2013 proceedings", "comments": "Published in PRoMoTo'13", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Programming for Mobile and Touch (PRoMoTo'13) was held at the 2013 ACM\nSIGPLAN conference on Systems, Programming, Languages and Applications (SPLASH\n2013), October 2013 in Indianapolis, USA. Submissions for this event were\ninvited in the general area of mobile and touch-oriented programming languages\nand programming environments, and teaching of programming for mobile devices.\nThese are proceedings of the PRoMoTo'13.\n", "versions": [{"version": "v1", "created": "Sat, 21 Sep 2013 16:48:22 GMT"}], "update_date": "2013-09-24", "authors_parsed": [["Bishop", "Judith", ""], ["Tillmann", "Nikolai", ""], ["Puder", "Arno", ""], ["Naik", "Vinayak", ""]]}, {"id": "1309.7584", "submitter": "Luca Breveglieri", "authors": "Luca Breveglieri, Stefano Crespi Reghizzi, Angelo Morzenti", "title": "Parsing methods streamlined", "comments": "64 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper has the goals (1) of unifying top-down parsing with shift-reduce\nparsing to yield a single simple and consistent framework, and (2) of producing\nprovably correct parsing methods, deterministic as well as tabular ones, for\nextended context-free grammars (EBNF) represented as state-transition networks.\nDeparting from the traditional way of presenting as independent algorithms the\ndeterministic bottom-up LR(1), the top-down LL(1) and the general tabular\n(Earley) parsers, we unify them in a coherent minimalist framework. We present\na simple general construction method for EBNF ELR(1) parsers, where the new\ncategory of convergence conflicts is added to the classical shift-reduce and\nreduce-reduce conflicts; we prove its correctness and show two implementations\nby deterministic push-down machines and by vector-stack machines, the latter to\nbe also used for Earley parsers. Then the Beatty's theoretical characterization\nof LL(1) grammars is adapted to derive the extended ELL(1 parsing method, first\nby minimizing the ELR(1) parser and then by simplifying its state information.\nThrough using the same notations in the ELR(1) case, the extended Earley parser\nis obtained. Since all the parsers operate on compatible representations, it is\nfeasible to combine them into mixed mode algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2013 12:23:04 GMT"}], "update_date": "2013-10-01", "authors_parsed": [["Breveglieri", "Luca", ""], ["Reghizzi", "Stefano Crespi", ""], ["Morzenti", "Angelo", ""]]}, {"id": "1309.7685", "submitter": "Amey Karkare", "authors": "Saravana Perumal P and Amey Karkare", "title": "Retargeting GCC: Do We Reinvent the Wheel Every Time?", "comments": "4 pages, accepted at The Second Asia-Pacific Programming Languages\n  and Compilers Workshop (APPLC), Shenzen, China, Feb 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Porting GCC to new architecture requires writing a Machine Description (MD)\nfile that contains mapping from GCC's intermediate form to the target assembly\ncode. Constructing an MD file is a difficult task because it requires the user\nto understand both (a) the internals of GCC, and (b) the intricacies of the\ntarget architecture. Instruction sets of different architectures exhibit\nsignificant amount of semantic similarities across a large class (for example,\nthe instruction sets for RISC architectures) and differ only in syntax.\nTherefore, it is expected that MD files of machines with similar architectures\nshould also have similarities. To confirm our hypothesis, we created\n\"mdcompare\", a tool to (a) extract RTL patterns (machine independent\nabstraction of RTL templates) from MD files of well known architectures and (b)\ncompare the similarity of patterns across architectures. The results are\nencouraging; we found that 28% -- 70% RTL expressions are similar across pairs\nof MD files, the similarity percentage being on the higher side for pairs of\nsimilar architectures.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2013 00:48:02 GMT"}], "update_date": "2013-10-04", "authors_parsed": [["P", "Saravana Perumal", ""], ["Karkare", "Amey", ""]]}]