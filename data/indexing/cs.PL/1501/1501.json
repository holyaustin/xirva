[{"id": "1501.00349", "submitter": "A.Aziz Altowayan", "authors": "A. Aziz Altowayan", "title": "Static Analysis for Biological Systems (BioAmbients)", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, I present a summary on some works that utilized static\nanalysis techniques for understanding biological systems. Control flow\nanalysis, context dependent analysis, and other techniques were employed to\ninvestigate the properties of BioAmbients. In this summary report, I tried to\nintroduce the ideas and explain the techniques used in the subject papers. This\nsummary will highlight the biological concepts of BioAmbients.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jan 2015 06:31:25 GMT"}], "update_date": "2015-01-05", "authors_parsed": [["Altowayan", "A. Aziz", ""]]}, {"id": "1501.00440", "submitter": "Tatjana Petrov", "authors": "Andreea Beica, Calin Guet, Tatjana Petrov", "title": "Efficient reduction of Kappa models by static inspection of the rule-set", "comments": "11 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LO cs.PL q-bio.MN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When designing genetic circuits, the typical primitives used in major\nexisting modelling formalisms are gene interaction graphs, where edges between\ngenes denote either an activation or inhibition relation. However, when\ndesigning experiments, it is important to be precise about the low-level\nmechanistic details as to how each such relation is implemented. The rule-based\nmodelling language Kappa allows to unambiguously specify mechanistic details\nsuch as DNA binding sites, dimerisation of transcription factors, or\nco-operative interactions. However, such a detailed description comes with\ncomplexity and computationally costly execution. We propose a general method\nfor automatically transforming a rule-based program, by eliminating\nintermediate species and adjusting the rate constants accordingly. Our method\nconsists of searching for those interaction patterns known to be amenable to\nequilibrium approximations (e.g. Michaelis-Menten scheme). The reduced model is\nefficiently obtained by static inspection over the rule-set, and it represents\na particular theoretical limit of the original model. The Bhattacharyya\ndistance is proposed as a metric to estimate the reduction error for a given\nobservable. The tool is tested on a detailed rule-based model of a\n$\\lambda$-phage switch, which lists $96$ rules and $16$ agents. The reduced\nmodel has $11$ rules and $5$ agents, and provides a dramatic reduction in\nsimulation time of several orders of magnitude.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jan 2015 17:30:59 GMT"}], "update_date": "2015-01-05", "authors_parsed": [["Beica", "Andreea", ""], ["Guet", "Calin", ""], ["Petrov", "Tatjana", ""]]}, {"id": "1501.00669", "submitter": "Mohamed El-Zawawy Dr.", "authors": "Mohamed A. El-Zawawy", "title": "Asynchronous Programming in a Prioritized Form", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Asynchronous programming has appeared as a programming style that overcomes\nundesired properties of concurrent programming. Typically in asynchronous\nmodels of programming, methods are posted into a post list for latter\nexecution. The order of method executions is serial, but nondeterministic. This\npaper presents a new and simple, yet powerful, model for asynchronous\nprogramming. The proposed model consists of two components; a context-free\ngrammar and an operational semantics. The model is supported by the ability to\nexpress important applications. An advantage of our model over related work is\nthat the model simplifies the way posted methods are assigned priorities.\nAnother advantage is that the operational semantics uses the simple concept of\nsingly linked list to simulate the prioritized process of methods posting and\nexecution. The simplicity and expressiveness make it relatively easy for\nanalysis algorithms to disclose the otherwise un-captured programming bugs in\nasynchronous programs.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jan 2015 12:19:57 GMT"}], "update_date": "2015-01-06", "authors_parsed": [["El-Zawawy", "Mohamed A.", ""]]}, {"id": "1501.00720", "submitter": "Alexandr Savinov", "authors": "Alexandr Savinov", "title": "Concept-oriented programming: from classes to concepts and from\n  inheritance to inclusion", "comments": "12 pages, 2 figures. arXiv admin note: text overlap with\n  arXiv:1409.3947", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the past several decades, programmers have been modeling things in the\nworld with trees using hierarchies of classes and object-oriented programming\n(OOP) languages. In this paper, we describe a novel approach to programming,\ncalled concept-oriented programming (COP), which generalizes classes and\ninheritance by introducing concepts and inclusion, respectively.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jan 2015 21:02:34 GMT"}], "update_date": "2015-01-06", "authors_parsed": [["Savinov", "Alexandr", ""]]}, {"id": "1501.01086", "submitter": "Vasanthakumar Soundararajan", "authors": "Vasanthakumar Soundararajan", "title": "A Novel Design of a Parallel Machine Learnt Generational Garbage\n  Collector", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Generational Garbage collection involves organizing the heap into\ndifferent divisions of memory space in-order to filter long-lived objects from\nshort-lived objects through moving the surviving object of each generation\nGarbage Collection cycle to another memory space updating its age and\nreclaiming space from the dead ones. The problem in this method is that the\nlonger an object is alive during its initial generations the longer the garbage\ncollector will have to deal with it by checking for its reachability from the\nroot and promoting it to other space divisions where as the ultimate goal of\nthe Garbage Collector is to reclaim memory from unreachable objects at a\nminimal time possible. This paper is a proposal of a method where the lifetime\nof every object getting into the heap will be predicted and will be placed in\nheap accordingly for the garbage collector to deal more with reclaiming space\nfrom dead objects and less in promoting the live ones to the higher level.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jan 2015 06:04:45 GMT"}], "update_date": "2015-01-07", "authors_parsed": [["Soundararajan", "Vasanthakumar", ""]]}, {"id": "1501.01588", "submitter": "Nadeem Akhtar", "authors": "Nadeem Akhtar, Anique Akhtar", "title": "KitRobot: A multi-platform graphical programming IDE to program\n  mini-robotic agents", "comments": "9 pages, IISTE - Computer Engineering and Intelligent Systems, ISSN\n  2222-1719 (Paper) ISSN 2222-2863 (Online) Vol.5, No.3, 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.HC cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The analysis, design and development of a graphical programming IDE for\nmini-robotic agents allows novice users to program robotic agents by a\ngraphical drag and drop interface, without knowing the syntax and semantics of\nthe intermediate programming language. Our work started with the definition of\nthe syntax and semantics of the intermediate programming language. The major\nwork is the definition of grammar for this language. The use of a graphical\ndrag and drop interface for programming mini-robots offers a user-friendly\ninterface to novice users. The user can program graphically by drag and drop\nprogram parts without having expertise of the intermediate programming\nlanguage. The IDE is highly flexible as it uses xml technology to store program\nobjects (i.e. loops, conditions) and robot objects (i.e. sensors, actuators).\nUse of xml technology allows making major changes and updating the interface\nwithout modifying the underlying design and programming.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jan 2015 18:54:55 GMT"}], "update_date": "2015-01-08", "authors_parsed": [["Akhtar", "Nadeem", ""], ["Akhtar", "Anique", ""]]}, {"id": "1501.01678", "submitter": "Changwang Zhang", "authors": "Changwang Zhang, Shi Zhou, and Benjamin M. Chain", "title": "LeoTask: a fast, flexible and reliable framework for computational\n  research", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.DC cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  LeoTask is a Java library for computation-intensive and time-consuming\nresearch tasks. It automatically executes tasks in parallel on multiple CPU\ncores on a computing facility. It uses a configuration file to enable automatic\nexploration of parameter space and flexible aggregation of results, and\ntherefore allows researchers to focus on programming the key logic of a\ncomputing task. It also supports reliable recovery from interruptions, dynamic\nand cloneable networks, and integration with the plotting software Gnuplot.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jan 2015 22:33:40 GMT"}], "update_date": "2015-01-09", "authors_parsed": [["Zhang", "Changwang", ""], ["Zhou", "Shi", ""], ["Chain", "Benjamin M.", ""]]}, {"id": "1501.01693", "submitter": "EPTCS", "authors": "Santiago Escobar (Universitat Polit\\'ecnica de Val\\'encia)", "title": "Proceedings XIV Jornadas sobre Programaci\\'on y Lenguajes", "comments": null, "journal-ref": "EPTCS 173, 2015", "doi": "10.4204/EPTCS.173", "report-no": null, "categories": "cs.PL cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains a selection of the papers presented at the XIV Jornadas\nsobre Programaci\\'on y Lenguajes (PROLE 2014), held at C\\'adiz, Spain, during\nSeptember 17th-19th, 2014. Previous editions of the workshop were held in\nMadrid (2013), Almer\\'ia (2012), A Coru\\~na (2011), Val\\'encia (2010), San\nSebasti\\'an (2009), Gij\\'on (2008), Zaragoza (2007), Sitges (2006), Granada\n(2005), M\\'alaga (2004), Alicante (2003), El Escorial (2002), and Almagro\n(2001).\n  Programming languages provide a conceptual framework which is necessary for\nthe development, analysis, optimization and understanding of programs and\nprogramming tasks. The aim of the PROLE series of conferences (PROLE stems from\nthe spanish PROgramaci\\'on y LEnguajes) is to serve as a meeting point for\nspanish research groups which develop their work in the area of programming and\nprogramming languages. The organization of this series of events aims at\nfostering the exchange of ideas, experiences and results among these groups.\nPromoting further collaboration is also one of the main goals of PROLE.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jan 2015 00:15:30 GMT"}], "update_date": "2015-01-09", "authors_parsed": [["Escobar", "Santiago", "", "Universitat Polit\u00e9cnica de Val\u00e9ncia"]]}, {"id": "1501.02030", "submitter": "EPTCS", "authors": "Dami\\'an Adalid (University of M\\'alaga), Mar\\'ia del Mar Gallardo\n  (University of M\\'alaga), Laura Titolo (University of M\\'alaga)", "title": "Modeling Hybrid Systems in the Concurrent Constraint Paradigm", "comments": "In Proceedings PROLE 2014, arXiv:1501.01693", "journal-ref": "EPTCS 173, 2015, pp. 1-15", "doi": "10.4204/EPTCS.173.1", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hybrid systems, which combine discrete and continuous dynamics, require\nquality modeling languages to be either described or analyzed. The Concurrent\nConstraint paradigm (ccp) is an expressive declarative paradigm, characterized\nby the use of a common constraint store to communicate and synchronize\nconcurrent agents. In this paradigm, the information is stated in the form of\nconstraints, in contrast to the variable/value style typical of imperative\nlanguages. Several extensions of ccp have been proposed in order to model\nreactive systems. One of these extensions is the Timed Concurrent Constraint\nLanguage (tccp) that adds to ccp a notion of discrete time and new features to\nmodel time-out and preemption actions. The goal of this paper is to explore the\nexpressive power of tccp to describe hybrid systems. We introduce the language\nHy-tccp as a conservative extension of tccp, by adding a notion of continuous\ntime and new constructs to describe the continuous dynamics of hybrid systems.\nIn this paper, we present the syntax and the operational semantics of Hy-tccp\ntogether with some examples that show the expressive power of our new language.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jan 2015 03:59:25 GMT"}], "update_date": "2015-01-12", "authors_parsed": [["Adalid", "Dami\u00e1n", "", "University of M\u00e1laga"], ["Gallardo", "Mar\u00eda del Mar", "", "University of M\u00e1laga"], ["Titolo", "Laura", "", "University of M\u00e1laga"]]}, {"id": "1501.02033", "submitter": "EPTCS", "authors": "Jes\\'us M. Almendros-Jim\\'enez (Universidad de Almer\\'ia)", "title": "XQOWL: An Extension of XQuery for OWL Querying and Reasoning", "comments": "In Proceedings PROLE 2014, arXiv:1501.01693", "journal-ref": "EPTCS 173, 2015, pp. 41-55", "doi": "10.4204/EPTCS.173.4", "report-no": null, "categories": "cs.PL cs.DB cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the main aims of the so-called Web of Data is to be able to handle\nheterogeneous resources where data can be expressed in either XML or RDF. The\ndesign of programming languages able to handle both XML and RDF data is a key\ntarget in this context. In this paper we present a framework called XQOWL that\nmakes possible to handle XML and RDF/OWL data with XQuery. XQOWL can be\nconsidered as an extension of the XQuery language that connects XQuery with\nSPARQL and OWL reasoners. XQOWL embeds SPARQL queries (via Jena SPARQL engine)\nin XQuery and enables to make calls to OWL reasoners (HermiT, Pellet and\nFaCT++) from XQuery. It permits to combine queries against XML and RDF/OWL\nresources as well as to reason with RDF/OWL data. Therefore input data can be\neither XML or RDF/OWL and output data can be formatted in XML (also using\nRDF/OWL XML serialization).\n", "versions": [{"version": "v1", "created": "Fri, 9 Jan 2015 03:59:54 GMT"}], "update_date": "2015-01-12", "authors_parsed": [["Almendros-Jim\u00e9nez", "Jes\u00fas M.", "", "Universidad de Almer\u00eda"]]}, {"id": "1501.02034", "submitter": "EPTCS", "authors": "Pascual Juli\\'an-Iranzo (Universidad de Castilla-La Mancha), Gin\\'es\n  Moreno (Universidad de Castilla-La Mancha), Jaime Penabad (Universidad de\n  Castilla-La Mancha), Carlos V\\'azquez (Universidad de Castilla-La Mancha)", "title": "A Fuzzy Logic Programming Environment for Managing Similarity and Truth\n  Degrees", "comments": "In Proceedings PROLE 2014, arXiv:1501.01693", "journal-ref": "EPTCS 173, 2015, pp. 71-86", "doi": "10.4204/EPTCS.173.6", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  FASILL (acronym of \"Fuzzy Aggregators and Similarity Into a Logic Language\")\nis a fuzzy logic programming language with implicit/explicit truth degree\nannotations, a great variety of connectives and unification by similarity.\nFASILL integrates and extends features coming from MALP (Multi-Adjoint Logic\nProgramming, a fuzzy logic language with explicitly annotated rules) and\nBousi~Prolog (which uses a weak unification algorithm and is well suited for\nflexible query answering). Hence, it properly manages similarity and truth\ndegrees in a single framework combining the expressive benefits of both\nlanguages. This paper presents the main features and implementations details of\nFASILL. Along the paper we describe its syntax and operational semantics and we\ngive clues of the implementation of the lattice module and the similarity\nmodule, two of the main building blocks of the new programming environment\nwhich enriches the FLOPER system developed in our research group.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jan 2015 04:00:25 GMT"}], "update_date": "2015-01-12", "authors_parsed": [["Juli\u00e1n-Iranzo", "Pascual", "", "Universidad de Castilla-La Mancha"], ["Moreno", "Gin\u00e9s", "", "Universidad de Castilla-La Mancha"], ["Penabad", "Jaime", "", "Universidad de\n  Castilla-La Mancha"], ["V\u00e1zquez", "Carlos", "", "Universidad de Castilla-La Mancha"]]}, {"id": "1501.02035", "submitter": "EPTCS", "authors": "Adri\\'an Riesco (Universidad Complutense de Madrid), Juan\n  Rodr\\'iguez-Hortal\\'a (Lambdoop Solutions)", "title": "Lifting Term Rewriting Derivations in Constructor Systems by Using\n  Generators", "comments": "In Proceedings PROLE 2014, arXiv:1501.01693", "journal-ref": "EPTCS 173, 2015, pp. 87-99", "doi": "10.4204/EPTCS.173.7", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Narrowing is a procedure that was first studied in the context of equational\nE-unification and that has been used in a wide range of applications. The\nclassic completeness result due to Hullot states that any term rewriting\nderivation starting from an instance of an expression can be \"lifted\" to a\nnarrowing derivation, whenever the substitution employed is normalized. In this\npaper we adapt the generator- based extra-variables-elimination transformation\nused in functional-logic programming to overcome that limitation, so we are\nable to lift term rewriting derivations starting from arbitrary instances of\nexpressions. The proposed technique is limited to left-linear constructor\nsystems and to derivations reaching a ground expression. We also present a\nMaude-based implementation of the technique, using natural rewriting for the\non-demand evaluation strategy.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jan 2015 04:00:31 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Riesco", "Adri\u00e1n", "", "Universidad Complutense de Madrid"], ["Rodr\u00edguez-Hortal\u00e1", "Juan", "", "Lambdoop Solutions"]]}, {"id": "1501.02038", "submitter": "EPTCS", "authors": "Fernando Berzal (Universidad de Granada), Francisco J. Cortijo\n  (Universidad de Granada), Juan-Carlos Cubero (Universidad de Granada), Luis\n  Quesada (Universidad de Granada)", "title": "The ModelCC Model-Driven Parser Generator", "comments": "In Proceedings PROLE 2014, arXiv:1501.01693", "journal-ref": "EPTCS 173, 2015, pp. 56-70", "doi": "10.4204/EPTCS.173.5", "report-no": null, "categories": "cs.PL cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Syntax-directed translation tools require the specification of a language by\nmeans of a formal grammar. This grammar must conform to the specific\nrequirements of the parser generator to be used. This grammar is then annotated\nwith semantic actions for the resulting system to perform its desired function.\nIn this paper, we introduce ModelCC, a model-based parser generator that\ndecouples language specification from language processing, avoiding some of the\nproblems caused by grammar-driven parser generators. ModelCC receives a\nconceptual model as input, along with constraints that annotate it. It is then\nable to create a parser for the desired textual syntax and the generated parser\nfully automates the instantiation of the language conceptual model. ModelCC\nalso includes a reference resolution mechanism so that ModelCC is able to\ninstantiate abstract syntax graphs, rather than mere abstract syntax trees.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jan 2015 04:12:34 GMT"}], "update_date": "2015-01-12", "authors_parsed": [["Berzal", "Fernando", "", "Universidad de Granada"], ["Cortijo", "Francisco J.", "", "Universidad de Granada"], ["Cubero", "Juan-Carlos", "", "Universidad de Granada"], ["Quesada", "Luis", "", "Universidad de Granada"]]}, {"id": "1501.02633", "submitter": "Bart van Delft", "authors": "Bart van Delft, Sebastian Hunt, David Sands", "title": "Very Static Enforcement of Dynamic Policies", "comments": "Technical Report of publication under the same name in Principles of\n  Security and Trust (POST) 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Security policies are naturally dynamic. Reflecting this, there has been a\ngrowing interest in studying information-flow properties which change during\nprogram execution, including concepts such as declassification, revocation, and\nrole-change.\n  A static verification of a dynamic information flow policy, from a semantic\nperspective, should only need to concern itself with two things: 1) the\ndependencies between data in a program, and 2) whether those dependencies are\nconsistent with the intended flow policies as they change over time. In this\npaper we provide a formal ground for this intuition. We present a\nstraightforward extension to the principal flow-sensitive type system\nintroduced by Hunt and Sands (POPL '06, ESOP '11) to infer both end-to-end\ndependencies and dependencies at intermediate points in a program. This allows\ntypings to be applied to verification of both static and dynamic policies. Our\nextension preserves the principal type system's distinguishing feature, that\ntype inference is independent of the policy to be enforced: a single, generic\ndependency analysis (typing) can be used to verify many different dynamic\npolicies of a given program, thus achieving a clean separation between (1) and\n(2).\n  We also make contributions to the foundations of dynamic information flow.\nArguably, the most compelling semantic definitions for dynamic security\nconditions in the literature are phrased in the so-called knowledge-based\nstyle. We contribute a new definition of knowledge-based termination\ninsensitive security for dynamic policies. We show that the new definition\navoids anomalies of previous definitions and enjoys a simple and useful\ncharacterisation as a two-run style property.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jan 2015 13:03:28 GMT"}], "update_date": "2015-01-13", "authors_parsed": [["van Delft", "Bart", ""], ["Hunt", "Sebastian", ""], ["Sands", "David", ""]]}, {"id": "1501.02683", "submitter": "Georgel Calin", "authors": "Ahmed Bouajjani, Georgel Calin, Egor Derevenetc, Roland Meyer", "title": "Lazy TSO Reachability", "comments": "accepted to FASE 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of checking state reachability for programs running\nunder Total Store Order (TSO). The problem has been shown to be decidable but\nthe cost is prohibitive, namely non-primitive recursive. We propose here to\ngive up completeness. Our contribution is a new algorithm for TSO reachability:\nit uses the standard SC semantics and introduces the TSO semantics lazily and\nonly where needed. At the heart of our algorithm is an iterative refinement of\nthe program of interest. If the program's goal state is SC-reachable, we are\ndone. If the goal state is not SC-reachable, this may be due to the fact that\nSC under-approximates TSO. We employ a second algorithm that determines TSO\ncomputations which are infeasible under SC, and hence likely to lead to new\nstates. We enrich the program to emulate, under SC, these TSO computations.\nAltogether, this yields an iterative under-approximation that we prove sound\nand complete for bug hunting, i.e., a semi-decision procedure halting for\npositive cases of reachability. We have implemented the procedure as an\nextension to the tool Trencher and compared it to the Memorax and CBMC model\ncheckers.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jan 2015 15:50:07 GMT"}], "update_date": "2015-01-13", "authors_parsed": [["Bouajjani", "Ahmed", ""], ["Calin", "Georgel", ""], ["Derevenetc", "Egor", ""], ["Meyer", "Roland", ""]]}, {"id": "1501.02699", "submitter": "Bj\\\"orn Engelmann", "authors": "Bj\\\"orn Engelmann and Ernst-R\\\"udiger Olderog and Nils Erik Flick", "title": "Closing the Gap -- Formally Verifying Dynamically Typed Programs like\n  Statically Typed Ones Using Hoare Logic -- Extended Version --", "comments": "includes all appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamically typed object-oriented languages enable programmers to write\nelegant, reusable and extensible programs. However, with the current\nmethodology for program verification, the absence of static type information\ncreates significant overhead. Our proposal is two-fold:\n  First, we propose a layer of abstraction hiding the complexity of dynamic\ntyping when provided with sufficient type information. Since this essentially\ncreates the illusion of verifying a statically-typed program, the effort\nrequired is equivalent to the statically-typed case.\n  Second, we show how the required type information can be efficiently derived\nfor all type-safe programs by integrating a type inference algorithm into Hoare\nlogic, yielding a semi-automatic procedure allowing the user to focus on those\ntyping problems really requiring his attention. While applying type inference\nto dynamically typed programs is a well-established method by now, our approach\ncomplements conventional soft typing systems by offering formal proof as a\nthird option besides modifying the program (static typing) and accepting the\npresence of runtime type errors (dynamic typing).\n", "versions": [{"version": "v1", "created": "Mon, 12 Jan 2015 16:30:00 GMT"}], "update_date": "2015-01-13", "authors_parsed": [["Engelmann", "Bj\u00f6rn", ""], ["Olderog", "Ernst-R\u00fcdiger", ""], ["Flick", "Nils Erik", ""]]}, {"id": "1501.02925", "submitter": "Ranald Clouston", "authors": "Ranald Clouston, Ale\\v{s} Bizjak, Hans Bugge Grathwohl, Lars Birkedal", "title": "Programming and Reasoning with Guarded Recursion for Coinductive Types", "comments": "Version of FoSSaCS 2015 paper with appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the guarded lambda-calculus, an extension of the simply typed\nlambda-calculus with guarded recursive and coinductive types. The use of\nguarded recursive types ensures the productivity of well-typed programs.\nGuarded recursive types may be transformed into coinductive types by a\ntype-former inspired by modal logic and Atkey-McBride clock quantification,\nallowing the typing of acausal functions. We give a call-by-name operational\nsemantics for the calculus, and define adequate denotational semantics in the\ntopos of trees. The adequacy proof entails that the evaluation of a program\nalways terminates. We demonstrate the expressiveness of the calculus by showing\nthe definability of solutions to Rutten's behavioural differential equations.\nWe introduce a program logic with L\\\"{o}b induction for reasoning about the\ncontextual equivalence of programs.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jan 2015 09:24:28 GMT"}, {"version": "v2", "created": "Thu, 15 Jan 2015 12:37:21 GMT"}], "update_date": "2015-01-16", "authors_parsed": [["Clouston", "Ranald", ""], ["Bizjak", "Ale\u0161", ""], ["Grathwohl", "Hans Bugge", ""], ["Birkedal", "Lars", ""]]}, {"id": "1501.03458", "submitter": "Luis Quesada", "authors": "Luis Quesada, Fernando Berzal, Juan-Carlos Cubero", "title": "The ModelCC Model-Based Parser Generator", "comments": "arXiv admin note: substantial text overlap with arXiv:1111.3970,\n  arXiv:1501.02038", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Formal languages let us define the textual representation of data with\nprecision. Formal grammars, typically in the form of BNF-like productions,\ndescribe the language syntax, which is then annotated for syntax-directed\ntranslation and completed with semantic actions. When, apart from the textual\nrepresentation of data, an explicit representation of the corresponding data\nstructure is required, the language designer has to devise the mapping between\nthe suitable data model and its proper language specification, and then develop\nthe conversion procedure from the parse tree to the data model instance.\nUnfortunately, whenever the format of the textual representation has to be\nmodified, changes have to propagated throughout the entire language processor\ntool chain. These updates are time-consuming, tedious, and error-prone.\nBesides, in case different applications use the same language, several copies\nof the same language specification have to be maintained. In this paper, we\nintroduce ModelCC, a model-based parser generator that decouples language\nspecification from language processing, hence avoiding many of the problems\ncaused by grammar-driven parsers and parser generators. ModelCC incorporates\nreference resolution within the parsing process. Therefore, instead of\nreturning mere abstract syntax trees, ModelCC is able to obtain abstract syntax\ngraphs from input strings.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jan 2015 15:03:03 GMT"}], "update_date": "2015-01-15", "authors_parsed": [["Quesada", "Luis", ""], ["Berzal", "Fernando", ""], ["Cubero", "Juan-Carlos", ""]]}, {"id": "1501.03839", "submitter": "Arkady Klimov", "authors": "Arkady Klimov", "title": "Yet Another Way of Building Exact Polyhedral Model for Weakly Dynamic\n  Affine Programs", "comments": "8 pages, 11 figures, was submitted to IMPACT-2015 (however was not\n  accepted)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exact polyhedral model (PM) can be built in the general case if the only\ncontrol structures are {\\tt do}-loops and structured {\\tt if}s, and if loop\ncounter bounds, array subscripts and {\\tt if}-conditions are affine expressions\nof enclosing loop counters and possibly some integer constants. In more general\ndynamic control programs, where arbitrary {\\tt if}s and {\\tt while}s are\nallowed, in the general case the usual dataflow analysis can be only fuzzy.\nThis is not a problem when PM is used just for guiding the parallelizing\ntransformations, but is insufficient for transforming source programs to other\ncomputation models (CM) relying on the PM, such as our version of dataflow CM\nor the well-known KPN.\n  The paper presents a novel way of building the exact polyhedral model and an\nextension of the concept of the exact PM, which allowed us to add in a natural\nway all the processing related to the data dependent conditions. Currently, in\nour system, only arbirary {\\tt if}s (not {\\tt while}s) are allowed in input\nprograms. The resulting polyhedral model can be easily put out as an equivalent\nprogram with the dataflow computation semantics.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jan 2015 22:07:16 GMT"}], "update_date": "2015-01-19", "authors_parsed": [["Klimov", "Arkady", ""]]}, {"id": "1501.04100", "submitter": "Aws Albarghouthi", "authors": "Aws Albarghouthi, Josh Berdine, Byron Cook, Zachary Kincaid", "title": "Spatial Interpolants", "comments": "Short version published in ESOP 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Splinter, a new technique for proving properties of\nheap-manipulating programs that marries (1) a new separation logic-based\nanalysis for heap reasoning with (2) an interpolation-based technique for\nrefining heap-shape invariants with data invariants. Splinter is property\ndirected, precise, and produces counterexample traces when a property does not\nhold. Using the novel notion of spatial interpolants modulo theories, Splinter\ncan infer complex invariants over general recursive predicates, e.g., of the\nform all elements in a linked list are even or a binary tree is sorted.\nFurthermore, we treat interpolation as a black box, which gives us the freedom\nto encode data manipulation in any suitable theory for a given program (e.g.,\nbit vectors, arrays, or linear arithmetic), so that our technique immediately\nbenefits from any future advances in SMT solving and interpolation.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jan 2015 17:10:32 GMT"}], "update_date": "2015-01-20", "authors_parsed": [["Albarghouthi", "Aws", ""], ["Berdine", "Josh", ""], ["Cook", "Byron", ""], ["Kincaid", "Zachary", ""]]}, {"id": "1501.04132", "submitter": "Stefan Heule", "authors": "Stefan Heule, Deian Stefan, Edward Z. Yang, John C. Mitchell,\n  Alejandro Russo", "title": "IFC Inside: Retrofitting Languages with Dynamic Information Flow Control\n  (Extended Version)", "comments": "Extended version of POST'15 paper; 31 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many important security problems in JavaScript, such as browser extension\nsecurity, untrusted JavaScript libraries and safe integration of mutually\ndistrustful websites (mash-ups), may be effectively addressed using an\nefficient implementation of information flow control (IFC). Unfortunately\nexisting fine-grained approaches to JavaScript IFC require modifications to the\nlanguage semantics and its engine, a non-goal for browser applications. In this\nwork, we take the ideas of coarse-grained dynamic IFC and provide the\ntheoretical foundation for a language-based approach that can be applied to any\nprogramming language for which external effects can be controlled. We then\napply this formalism to server- and client-side JavaScript, show how it\ngeneralizes to the C programming language, and connect it to the Haskell LIO\nsystem. Our methodology offers design principles for the construction of\ninformation flow control systems when isolation can easily be achieved, as well\nas compositional proofs for optimized concrete implementations of these\nsystems, by relating them to their isolated variants.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jan 2015 23:21:36 GMT"}], "update_date": "2015-01-20", "authors_parsed": [["Heule", "Stefan", ""], ["Stefan", "Deian", ""], ["Yang", "Edward Z.", ""], ["Mitchell", "John C.", ""], ["Russo", "Alejandro", ""]]}, {"id": "1501.04511", "submitter": "Conrad Cotton-Barratt", "authors": "Conrad Cotton-Barratt, David Hopkins, Andrzej S. Murawski, and C.-H.\n  Luke Ong", "title": "Fragments of ML Decidable by Nested Data Class Memory Automata", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The call-by-value language RML may be viewed as a canonical restriction of\nStandard ML to ground-type references, augmented by a \"bad variable\" construct\nin the sense of Reynolds. We consider the fragment of (finitary) RML terms of\norder at most 1 with free variables of order at most 2, and identify two\nsubfragments of this for which we show observational equivalence to be\ndecidable. The first subfragment consists of those terms in which the\nP-pointers in the game semantic representation are determined by the underlying\nsequence of moves. The second subfragment consists of terms in which the\nO-pointers of moves corresponding to free variables in the game semantic\nrepresentation are determined by the underlying moves. These results are shown\nusing a reduction to a form of automata over data words in which the data\nvalues have a tree-structure, reflecting the tree-structure of the threads in\nthe game semantic plays. In addition we show that observational equivalence is\nundecidable at every third- or higher-order type, every second-order type which\ntakes at least two first-order arguments, and every second-order type (of arity\ngreater than one) that has a first-order argument which is not the final\nargument.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jan 2015 15:03:46 GMT"}], "update_date": "2015-01-20", "authors_parsed": [["Cotton-Barratt", "Conrad", ""], ["Hopkins", "David", ""], ["Murawski", "Andrzej S.", ""], ["Ong", "C. -H. Luke", ""]]}, {"id": "1501.04684", "submitter": "Razvan Ranca", "authors": "Razvan Ranca, Zoubin Ghahramani", "title": "Slice Sampling for Probabilistic Programming", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the first, general purpose, slice sampling inference engine for\nprobabilistic programs. This engine is released as part of StocPy, a new\nTuring-Complete probabilistic programming language, available as a Python\nlibrary. We present a transdimensional generalisation of slice sampling which\nis necessary for the inference engine to work on traces with different numbers\nof random variables. We show that StocPy compares favourably to other PPLs in\nterms of flexibility and usability, and that slice sampling can outperform\npreviously introduced inference methods. Our experiments include a logistic\nregression, HMM, and Bayesian Neural Net.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jan 2015 00:24:14 GMT"}], "update_date": "2015-01-21", "authors_parsed": [["Ranca", "Razvan", ""], ["Ghahramani", "Zoubin", ""]]}, {"id": "1501.04725", "submitter": "Siddharth Krishna", "authors": "Siddharth Krishna, Christian Puhrsch, Thomas Wies", "title": "Learning Invariants using Decision Trees", "comments": "15 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of inferring an inductive invariant for verifying program safety\ncan be formulated in terms of binary classification. This is a standard problem\nin machine learning: given a sample of good and bad points, one is asked to\nfind a classifier that generalizes from the sample and separates the two sets.\nHere, the good points are the reachable states of the program, and the bad\npoints are those that reach a safety property violation. Thus, a learned\nclassifier is a candidate invariant. In this paper, we propose a new algorithm\nthat uses decision trees to learn candidate invariants in the form of arbitrary\nBoolean combinations of numerical inequalities. We have used our algorithm to\nverify C programs taken from the literature. The algorithm is able to infer\nsafe invariants for a range of challenging benchmarks and compares favorably to\nother ML-based invariant inference techniques. In particular, it scales well to\nlarge sample sets.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jan 2015 07:20:30 GMT"}], "update_date": "2015-01-21", "authors_parsed": [["Krishna", "Siddharth", ""], ["Puhrsch", "Christian", ""], ["Wies", "Thomas", ""]]}, {"id": "1501.04730", "submitter": "Raghavan Komondoor", "authors": "Raveendra Kumar Medicherla, Raghavan Komondoor, S. Narendran", "title": "Static Analysis of File-Processing Programs using File Format\n  Specifications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Programs that process data that reside in files are widely used in varied\ndomains, such as banking, healthcare, and web-traffic analysis. Precise static\nanalysis of these programs in the context of software verification and\ntransformation tasks is a challenging problem. Our key insight is that static\nanalysis of file-processing programs can be made more useful if knowledge of\nthe input file formats of these programs is made available to the analysis. We\npropose a generic framework that is able to perform any given underlying\nabstract interpretation on the program, while restricting the attention of the\nanalysis to program paths that are potentially feasible when the program's\ninput conforms to the given file format specification. We describe an\nimplementation of our approach, and present empirical results using real and\nrealistic programs that show how our approach enables novel verification and\ntransformation tasks, and also improves the precision of standard analysis\nproblems.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jan 2015 07:53:09 GMT"}, {"version": "v2", "created": "Fri, 3 Apr 2015 09:01:38 GMT"}], "update_date": "2015-04-06", "authors_parsed": [["Medicherla", "Raveendra Kumar", ""], ["Komondoor", "Raghavan", ""], ["Narendran", "S.", ""]]}, {"id": "1501.04789", "submitter": "Charles Grellois", "authors": "Charles Grellois and Paul-Andr\\'e Melli\\`es", "title": "Relational semantics of linear logic and higher-order model-checking", "comments": "24 pages. Submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we develop a new and somewhat unexpected connection between\nhigher-order model-checking and linear logic. Our starting point is the\nobservation that once embedded in the relational semantics of linear logic, the\nChurch encoding of any higher-order recursion scheme (HORS) comes together with\na dual Church encoding of an alternating tree automata (ATA) of the same\nsignature. Moreover, the interaction between the relational interpretations of\nthe HORS and of the ATA identifies the set of accepting states of the tree\nautomaton against the infinite tree generated by the recursion scheme. We show\nhow to extend this result to alternating parity automata (APT) by introducing a\nparametric version of the exponential modality of linear logic, capturing the\nformal properties of colors (or priorities) in higher-order model-checking. We\nshow in particular how to reunderstand in this way the type-theoretic approach\nto higher-order model-checking developed by Kobayashi and Ong. We briefly\nexplain in the end of the paper how his analysis driven by linear logic results\nin a new and purely semantic proof of decidability of the formulas of the\nmonadic second-order logic for higher-order recursion schemes.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jan 2015 12:51:34 GMT"}, {"version": "v2", "created": "Wed, 15 Apr 2015 14:35:28 GMT"}, {"version": "v3", "created": "Fri, 1 May 2015 10:11:26 GMT"}], "update_date": "2016-09-29", "authors_parsed": [["Grellois", "Charles", ""], ["Melli\u00e8s", "Paul-Andr\u00e9", ""]]}, {"id": "1501.05338", "submitter": "Damiano Macedonio Dr.", "authors": "Michael Ernst, Damiano Macedonio, Massimo Merro and Fausto Spoto", "title": "Semantics for Locking Specifications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To prevent concurrency errors, programmers need to obey a locking discipline.\nAnnotations that specify that discipline, such as Java's @GuardedBy, are\nalready widely used. Unfortunately, their semantics is expressed informally and\nis consequently ambiguous. This article highlights such ambiguities and\nformalizes the semantics of @GuardedBy in two alternative ways, building on an\noperational semantics for a small concurrent fragment of a Java-like language.\nIt also identifies when such annotations are actual guarantees against data\nraces. Our work aids in understanding the annotations and supports the\ndevelopment of sound formal tools that verify or infer such annotations.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jan 2015 21:56:06 GMT"}, {"version": "v2", "created": "Sun, 15 Nov 2015 15:34:03 GMT"}], "update_date": "2015-11-17", "authors_parsed": [["Ernst", "Michael", ""], ["Macedonio", "Damiano", ""], ["Merro", "Massimo", ""], ["Spoto", "Fausto", ""]]}, {"id": "1501.05425", "submitter": "Dmitriy Traytel", "authors": "Jasmin Christian Blanchette and Andrei Popescu and Dmitriy Traytel", "title": "Foundational Extensible Corecursion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a formalized framework for defining corecursive functions\nsafely in a total setting, based on corecursion up-to and relational\nparametricity. The end product is a general corecursor that allows corecursive\n(and even recursive) calls under well-behaved operations, including\nconstructors. Corecursive functions that are well behaved can be registered as\nsuch, thereby increasing the corecursor's expressiveness. The metatheory is\nformalized in the Isabelle proof assistant and forms the core of a prototype\ntool. The corecursor is derived from first principles, without requiring new\naxioms or extensions of the logic.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jan 2015 08:45:10 GMT"}], "update_date": "2015-01-23", "authors_parsed": [["Blanchette", "Jasmin Christian", ""], ["Popescu", "Andrei", ""], ["Traytel", "Dmitriy", ""]]}, {"id": "1501.05673", "submitter": "Limin Jia", "authors": "Limin Jia, Shayak Sen, Deepak Garg, and Anupam Datta", "title": "System M: A Program Logic for Code Sandboxing and Identification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Security-sensitive applications that execute untrusted code often check the\ncode's integrity by comparing its syntax to a known good value or sandbox the\ncode to contain its effects. System M is a new program logic for reasoning\nabout such security-sensitive applications. System M extends Hoare Type Theory\n(HTT) to trace safety properties and, additionally, contains two new reasoning\nprinciples. First, its type system internalizes logical equality, facilitating\nreasoning about applications that check code integrity. Second, a confinement\nrule assigns an effect type to a computation based solely on knowledge of the\ncomputation's sandbox. We prove the soundness of system M relative to a\nstep-indexed trace-based semantic model. We illustrate both new reasoning\nprinciples of system M by verifying the main integrity property of the design\nof Memoir, a previously proposed trusted computing system for ensuring state\ncontinuity of isolated security-sensitive applications.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jan 2015 22:22:44 GMT"}], "update_date": "2015-01-26", "authors_parsed": [["Jia", "Limin", ""], ["Sen", "Shayak", ""], ["Garg", "Deepak", ""], ["Datta", "Anupam", ""]]}, {"id": "1501.05691", "submitter": "Kuen-Bang Hou", "authors": "Robert Harper and Kuen-Bang Hou", "title": "A Note on the Uniform Kan Condition in Nominal Cubical Sets", "comments": "25 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.PL math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bezem, Coquand, and Huber have recently given a constructively valid model of\nhigher type theory in a category of nominal cubical sets satisfying a novel\ncondition, called the uniform Kan condition (UKC), which generalizes the\nstandard cubical Kan condition (as considered by, for example, Williamson in\nhis survey of combinatorial homotopy theory) to admit phantom \"additional\"\ndimensions in open boxes. This note, which represents the authors' attempts to\nfill in the details of the UKC, is intended for newcomers to the field who may\nappreciate a more explicit formulation and development of the main ideas. The\ncrux of the exposition is an analogue of the Yoneda Lemma for co-sieves that\nrelates geometric open boxes bijectively to their algebraic counterparts, much\nas its progenitor for representables relates geometric cubes to their algebraic\ncounterparts in a cubical set. This characterization is used to give a\nformulation of uniform Kan fibrations in which uniformity emerges as naturality\nin the additional dimensions.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jan 2015 01:11:11 GMT"}], "update_date": "2015-01-26", "authors_parsed": [["Harper", "Robert", ""], ["Hou", "Kuen-Bang", ""]]}, {"id": "1501.05936", "submitter": "Avinash Malik", "authors": "Avinash Malik and Partha Roop", "title": "A unified framework for modeling and implementation of hybrid systems\n  with synchronous controllers", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel approach to including non-instantaneous discrete\ncontrol transitions in the linear hybrid automaton approach to simulation and\nverification of hybrid control systems. In this paper we study the control of a\ncontinuously evolving analog plant using a controller programmed in a\nsynchronous programming language. We provide extensions to the synchronous\nsubset of the SystemJ programming language for modeling, implementation, and\nverification of such hybrid systems. We provide a sound rewrite semantics that\napproximate the evolution of the continuous variables in the discrete domain\ninspired from the classical supervisory control theory. The resultant discrete\ntime model can be verified using classical model-checking tools. Finally, we\nshow that systems designed using our approach have a higher fidelity than the\nones designed using the hybrid automaton approach.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jan 2015 20:42:56 GMT"}], "update_date": "2015-01-26", "authors_parsed": [["Malik", "Avinash", ""], ["Roop", "Partha", ""]]}, {"id": "1501.06743", "submitter": "Esraa Alwan Hadi", "authors": "Esraa Alwan, John Fitch and Julian Padget", "title": "Enhancing the performance of Decoupled Software Pipeline through\n  Backward Slicing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapidly increasing number of cores available in multicore processors does\nnot necessarily lead directly to a commensurate increase in performance:\nprograms written in conventional languages, such as C, need careful\nrestructuring, preferably automatically, before the benefits can be observed in\nimproved run-times. Even then, much depends upon the intrinsic capacity of the\noriginal program for concurrent execution. The subject of this paper is the\nperformance gains from the combined effect of the complementary techniques of\nthe Decoupled Software Pipeline (DSWP) and (backward) slicing. DSWP extracts\nthreadlevel parallelism from the body of a loop by breaking it into stages\nwhich are then executed pipeline style: in effect cutting across the control\nchain. Slicing, on the other hand, cuts the program along the control chain,\nteasing out finer threads that depend on different variables (or locations).\nparts that depend on different variables. The main contribution of this paper\nis to demonstrate that the application of DSWP, followed by slicing offers\nnotable improvements over DSWP alone, especially when there is a loop-carried\ndependence that prevents the application of the simpler DOALL optimization.\nExperimental results show an improvement of a factor of ?1.6 for DSWP + slicing\nover DSWP alone and a factor of ?2.4 for DSWP + slicing over the original\nsequential code.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jan 2015 11:04:59 GMT"}], "update_date": "2015-01-28", "authors_parsed": [["Alwan", "Esraa", ""], ["Fitch", "John", ""], ["Padget", "Julian", ""]]}, {"id": "1501.06769", "submitter": "Jan-Willem van de Meent", "authors": "Jan-Willem van de Meent and Hongseok Yang and Vikash Mansinghka and\n  Frank Wood", "title": "Particle Gibbs with Ancestor Sampling for Probabilistic Programs", "comments": "9 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Particle Markov chain Monte Carlo techniques rank among current\nstate-of-the-art methods for probabilistic program inference. A drawback of\nthese techniques is that they rely on importance resampling, which results in\ndegenerate particle trajectories and a low effective sample size for variables\nsampled early in a program. We here develop a formalism to adapt ancestor\nresampling, a technique that mitigates particle degeneracy, to the\nprobabilistic programming setting. We present empirical results that\ndemonstrate nontrivial performance gains.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jan 2015 14:16:59 GMT"}, {"version": "v2", "created": "Wed, 28 Jan 2015 18:26:55 GMT"}, {"version": "v3", "created": "Mon, 2 Feb 2015 19:42:52 GMT"}, {"version": "v4", "created": "Wed, 4 Feb 2015 16:12:05 GMT"}, {"version": "v5", "created": "Mon, 9 Feb 2015 23:49:26 GMT"}], "update_date": "2015-02-11", "authors_parsed": [["van de Meent", "Jan-Willem", ""], ["Yang", "Hongseok", ""], ["Mansinghka", "Vikash", ""], ["Wood", "Frank", ""]]}]