[{"id": "1503.00375", "submitter": "M. H. van Emden", "authors": "M. H. van Emden", "title": "The lambda mechanism in lambda calculus and in other calculi", "comments": "9 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A comparison of Landin's form of lambda calculus with Church's shows that,\nindependently of the lambda calculus, there exists a mechanism for converting\nfunctions with arguments indexed by variables to the usual kind of function\nwhere the arguments are indexed numerically. We call this the \"lambda\nmechanism\" and show how it can be used in other calculi. In first-order\npredicate logic it can be used to define new functions and new predicates in\nterms of existing ones. In a purely imperative programming language it can be\nused to provide an Algol-like procedure facility.\n", "versions": [{"version": "v1", "created": "Sun, 1 Mar 2015 23:27:46 GMT"}, {"version": "v2", "created": "Thu, 5 Mar 2015 16:52:35 GMT"}, {"version": "v3", "created": "Sun, 8 Mar 2015 17:02:26 GMT"}, {"version": "v4", "created": "Thu, 28 May 2015 21:32:27 GMT"}], "update_date": "2015-06-01", "authors_parsed": [["van Emden", "M. H.", ""]]}, {"id": "1503.00503", "submitter": "Eugene Panferov", "authors": "Eugene Panferov", "title": "A Next-Generation Data Language Proposal", "comments": "27 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper analyzes the fatal drawback of the relational calculus not\nallowing relations to be domains of relations, and its consequences entrenched\nin SQL. In order to overcome this obstacle we propose \"multitable index\" - an\neasily implementable upgrade to an existing data storage, which enables a\nrevolutionary change in the field of data languages - the demotion of\nrelational calculus and tables. We propose a new data language with \"pragmatic\ntypisation\" where types represent domain knowledge but not memory management.\nThe language handles sets of tuples as first class data objects and supports\nset operation and tuple (de)composition operations as fluently as basic arith.\nAnd it is equally suitable for building-into a general purpose language as well\nas querying a remote DB (thus removing the ubiquitous gap between SQL and\napplication).\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2015 12:52:53 GMT"}, {"version": "v2", "created": "Sun, 22 Mar 2015 20:30:36 GMT"}, {"version": "v3", "created": "Sun, 21 Feb 2021 18:11:54 GMT"}, {"version": "v4", "created": "Fri, 26 Feb 2021 10:48:29 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Panferov", "Eugene", ""]]}, {"id": "1503.00622", "submitter": "Pavel Zaichenkov", "authors": "Pavel Zaichenkov, Olga Tveretina, Alex Shafarenko", "title": "Interface Reconciliation in Kahn Process Networks using CSP and SAT", "comments": "20 pages, 3 figures, accepted to CSPSAT 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new CSP- and SAT-based approach for coordinating interfaces of\ndistributed stream-connected components provided as closed-source services. The\nKahn Process Network (KPN) is taken as a formal model of computation and a\nMessage Definition Language (MDL) is introduced to describe the format of\nmessages communicated between the processes. MDL links input and output\ninterfaces of a node to support flow inheritance and contextualisation. Since\ninterfaces can also be linked by the existence of a data channel between them,\nthe match is generally not only partial but also substantially nonlocal. The\nKPN communication graph thus becomes a graph of interlocked constraints to be\nsatisfied by specific instances of the variables. We present an algorithm that\nsolves the CSP by iterative approximation while generating an adjunct Boolean\nSAT problem on the way. We developed a solver in OCaml as well as tools that\nanalyse the source code of KPN vertices to derive MDL terms and automatically\nmodify the code by propagating type definitions back to the vertices after the\nCSP has been solved. Techniques and approaches are illustrated on a KPN\nimplementing an image processing algorithm as a running example.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2015 17:11:03 GMT"}, {"version": "v2", "created": "Wed, 22 Apr 2015 21:34:28 GMT"}, {"version": "v3", "created": "Tue, 16 Jun 2015 16:49:21 GMT"}, {"version": "v4", "created": "Sun, 12 Jul 2015 19:36:19 GMT"}], "update_date": "2015-07-14", "authors_parsed": [["Zaichenkov", "Pavel", ""], ["Tveretina", "Olga", ""], ["Shafarenko", "Alex", ""]]}, {"id": "1503.00793", "submitter": "Neeraj Kumar", "authors": "Therese Biedl, Sebastian Fischmeister and Neeraj Kumar", "title": "DAG-width of Control Flow Graphs with Applications to Model Checking", "comments": "12 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.LO cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The treewidth of control flow graphs arising from structured programs is\nknown to be at most six. However, as a control flow graph is inherently\ndirected, it makes sense to consider a measure of width for digraphs instead.\nWe use the so-called DAG-width and show that the DAG-width of control flow\ngraphs arising from structured (goto-free) programs is at most three.\nAdditionally, we also give a linear time algorithm to compute the DAG\ndecomposition of these control flow graphs. One consequence of this result is\nthat parity games (and hence the $\\mu$-calculus model checking problem), which\nare known to be tractable on graphs of bounded DAG-width, can be solved\nefficiently in practice on control flow graphs.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2015 01:05:06 GMT"}], "update_date": "2015-03-04", "authors_parsed": [["Biedl", "Therese", ""], ["Fischmeister", "Sebastian", ""], ["Kumar", "Neeraj", ""]]}, {"id": "1503.00883", "submitter": "Kalmer Apinis", "authors": "Gianluca Amato, Francesca Scozzari, Helmut Seidl, Kalmer Apinis, Vesal\n  Vojdani", "title": "Efficiently intertwining widening and narrowing", "comments": "For submission to Science of Computer Programming", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-trivial analysis problems require posets with infinite ascending and\ndescending chains. In order to compute reasonably precise post-fixpoints of the\nresulting systems of equations, Cousot and Cousot have suggested accelerated\nfixpoint iteration by means of widening and narrowing.\n  The strict separation into phases, however, may unnecessarily give up\nprecision that cannot be recovered later, as over-approximated interim results\nhave to be fully propagated through the equation the system. Additionally,\nclassical two-phased approach is not suitable for equation systems with\ninfinitely many unknowns---where demand driven solving must be used.\nConstruction of an intertwined approach must be able to answer when it is safe\nto apply narrowing---or when widening must be applied. In general, this is a\ndifficult problem. In case the right-hand sides of equations are monotonic,\nhowever, we can always apply narrowing whenever we have reached a post-fixpoint\nfor an equation. The assumption of monotonicity, though, is not met in presence\nof widening. It is also not met by equation systems corresponding to\ncontext-sensitive inter-procedural analysis, possibly combining\ncontext-sensitive analysis of local information with flow-insensitive analysis\nof globals.\n  As a remedy, we present a novel operator that combines a given widening\noperator with a given narrowing operator. We present adapted versions of\nround-robin as well as of worklist iteration, local and side-effecting solving\nalgorithms for the combined operator and prove that the resulting solvers\nalways return sound results and are guaranteed to terminate for monotonic\nsystems whenever only finitely many unknowns (constraint variables) are\nencountered. Practical remedies are proposed for termination in the\nnon-monotonic case.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2015 10:35:47 GMT"}], "update_date": "2015-03-04", "authors_parsed": [["Amato", "Gianluca", ""], ["Scozzari", "Francesca", ""], ["Seidl", "Helmut", ""], ["Apinis", "Kalmer", ""], ["Vojdani", "Vesal", ""]]}, {"id": "1503.01398", "submitter": "Konstantinos Fysarakis", "authors": "Konstantinos Fysarakis (1), Damianos Mylonakis (2), Charalampos\n  Manifavas (3) and Ioannis Papaefstathiou (1) ((1) Dept. of Electronic &\n  Computer Engineering, Technical University of Crete, Greece, (2) Dept. of\n  Computer Science, University of Crete, Greece, (3) Dept. of Informatics\n  Engineering, Technological Educational Institute of Crete, Greece)", "title": "Node.DPWS: High performance and scalable Web Services for the IoT", "comments": "12 pages, 1 table, 3 figures, for associated libraries, see\n  https://github.com/danmilon/node-dpws and\n  https://github.com/danmilon/node-ws-discovery. This work has been submitted\n  to the IEEE for possible publication. Copyright may be transferred without\n  notice, after which this version may no longer be accessible", "journal-ref": null, "doi": "10.1109/MS.2015.155", "report-no": null, "categories": "cs.NI cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interconnected computing systems, in various forms, are expected to permeate\nour lives, realizing the vision of the Internet of Things (IoT) and allowing us\nto enjoy novel, enhanced services that promise to improve our everyday lives.\nNevertheless, this new reality also introduces significant challenges in terms\nof performance, scaling, usability and interoperability. Leveraging the\nbenefits of Service Oriented Architectures (SOAs) can help alleviate many of\nthe issues that developers, implementers and end-users have to face in the\ncontext of the IoT. This work presents Node.DPWS, a novel implementation of the\nDevices Profile for Web Services (DPWS) based on the Node.js platform.\nNode.DPWS can be used to deploy lightweight, efficient and scalable Web\nServices over heterogeneous nodes, including devices with limited resources.\nThe performance of the presented work is evaluated on typical embedded devices,\nincluding comparisons with implementations created using alternative DPWS\ntoolkits.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2015 17:52:24 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2015 16:18:47 GMT"}], "update_date": "2016-01-19", "authors_parsed": [["Fysarakis", "Konstantinos", ""], ["Mylonakis", "Damianos", ""], ["Manifavas", "Charalampos", ""], ["Papaefstathiou", "Ioannis", ""]]}, {"id": "1503.01547", "submitter": "Arlen Cox", "authors": "Arlen Cox", "title": "Binary-Decision-Diagrams for Set Abstraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Whether explicit or implicit, sets are a critical part of many pieces of\nsoftware. As a result, it is necessary to develop abstractions of sets for the\npurposes of abstract interpretation, model checking, and deductive\nverification. However, the construction of effective abstractions for sets is\nchallenging because they are a higher-order construct. It is necessary to\nreason about contents of sets as well as relationships between sets. This paper\npresents a new abstraction for sets that is based on binary decision diagrams.\nIt is optimized for precisely and efficiently representing relations between\nsets while still providing limited support for content reasoning.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2015 06:11:25 GMT"}], "update_date": "2015-03-06", "authors_parsed": [["Cox", "Arlen", ""]]}, {"id": "1503.01981", "submitter": "Andr\\'e Platzer", "authors": "Andr\\'e Platzer", "title": "A Uniform Substitution Calculus for Differential Dynamic Logic", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-319-21401-6_32", "report-no": null, "categories": "cs.LO cs.PL math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new proof calculus for differential dynamic logic\n(dL) that is entirely based on uniform substitution, a proof rule that\nsubstitutes a formula for a predicate symbol everywhere. Uniform substitutions\nmake it possible to rely on axioms rather than axiom schemata, substantially\nsimplifying implementations. Instead of nontrivial schema variables and\nsoundness-critical side conditions on the occurrence patterns of variables, the\nresulting calculus adopts only a finite number of ordinary dL formulas as\naxioms. The static semantics of differential dynamic logic is captured\nexclusively in uniform substitutions and bound variable renamings as opposed to\nbeing spread in delicate ways across the prover implementation. In addition to\nsound uniform substitutions, this paper introduces differential forms for\ndifferential dynamic logic that make it possible to internalize differential\ninvariants, differential substitutions, and derivations as first-class axioms\nin dL.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2015 15:05:30 GMT"}, {"version": "v2", "created": "Wed, 25 Mar 2015 15:23:32 GMT"}, {"version": "v3", "created": "Wed, 29 Apr 2015 19:53:19 GMT"}, {"version": "v4", "created": "Fri, 15 May 2015 02:22:37 GMT"}, {"version": "v5", "created": "Thu, 30 Jul 2015 19:18:02 GMT"}], "update_date": "2015-07-31", "authors_parsed": [["Platzer", "Andr\u00e9", ""]]}, {"id": "1503.04377", "submitter": "EPTCS", "authors": "Jakob Rehof (TU-Dortmund)", "title": "Proceedings Seventh Workshop on Intersection Types and Related Systems", "comments": null, "journal-ref": "EPTCS 177, 2015", "doi": "10.4204/EPTCS.177", "report-no": null, "categories": "cs.LO cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains a final and revised selection of papers presented at the\nSeventh Workshop on Intersection Types and Related Systems (ITRS 2014), held in\nVienna (Austria) on July 18th, affiliated with TLCA 2014, Typed Lambda Calculi\nand Applications (held jointly with RTA, Rewriting Techniques and Applications)\nas part of FLoC and the Vienna Summer of Logic (VSL) 2014. Intersection types\nhave been introduced in the late 1970s as a language for describing properties\nof lambda calculus which were not captured by all previous type systems. They\nprovided the first characterisation of strongly normalising lambda terms and\nhave become a powerful syntactic and semantic tool for analysing various\nnormalisation properties as well as lambda models. Over the years the scope of\nresearch on intersection types has broadened. Recently, there have been a\nnumber of breakthroughs in the use of intersection types and similar technology\nfor practical purposes such as program analysis, verification and concurrency,\nand program synthesis. The aim of the ITRS workshop series is to bring together\nresearchers working on both the theory and practical applications of systems\nbased on intersection types and related approaches (e.g., union types,\nrefinement types, behavioral types).\n", "versions": [{"version": "v1", "created": "Sun, 15 Mar 2015 02:58:54 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Rehof", "Jakob", "", "TU-Dortmund"]]}, {"id": "1503.04608", "submitter": "Aleksandar Dimovski", "authors": "Aleksandar S. Dimovski, Claus Brabrand, Andrzej W\\k{a}sowski", "title": "Variability Abstractions: Trading Precision for Speed in Family-Based\n  Analyses (Extended Version)", "comments": "50 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Family-based (lifted) data-flow analysis for Software Product Lines (SPLs) is\ncapable of analyzing all valid products (variants) without generating any of\nthem explicitly. It takes as input only the common code base, which encodes all\nvariants of a SPL, and produces analysis results corresponding to all variants.\nHowever, the computational cost of the lifted analysis still depends inherently\non the number of variants (which is exponential in the number of features, in\nthe worst case). For a large number of features, the lifted analysis may be too\ncostly or even infeasible. In this paper, we introduce variability abstractions\ndefined as Galois connections and use abstract interpretation as a formal\nmethod for the calculational-based derivation of approximate (abstracted)\nlifted analyses of SPL programs, which are sound by construction. Moreover,\ngiven an abstraction we define a syntactic transformation that translates any\nSPL program into an abstracted version of it, such that the analysis of the\nabstracted SPL coincides with the corresponding abstracted analysis of the\noriginal SPL. We implement the transformation in a tool, reconfigurator that\nworks on Object-Oriented Java program families, and evaluate the practicality\nof this approach on three Java SPL benchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2015 11:16:36 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Dimovski", "Aleksandar S.", ""], ["Brabrand", "Claus", ""], ["W\u0105sowski", "Andrzej", ""]]}, {"id": "1503.04906", "submitter": "EPTCS", "authors": "Rick Statman (Carnegie Mellon University)", "title": "A Finite Model Property for Intersection Types", "comments": "In Proceedings ITRS 2014, arXiv:1503.04377", "journal-ref": "EPTCS 177, 2015, pp. 1-9", "doi": "10.4204/EPTCS.177.1", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the relational theory of intersection types known as BCD has the\nfinite model property; that is, BCD is complete for its finite models. Our\nproof uses rewriting techniques which have as an immediate by-product the\npolynomial time decidability of the preorder <= (although this also follows\nfrom the so called beta soundness of BCD).\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2015 03:58:23 GMT"}], "update_date": "2015-03-18", "authors_parsed": [["Statman", "Rick", "", "Carnegie Mellon University"]]}, {"id": "1503.04907", "submitter": "EPTCS", "authors": "Kentaro Kikuchi (RIEC, Tohoku University, Japan)", "title": "Uniform Proofs of Normalisation and Approximation for Intersection Types", "comments": "In Proceedings ITRS 2014, arXiv:1503.04377", "journal-ref": "EPTCS 177, 2015, pp. 10-23", "doi": "10.4204/EPTCS.177.2", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present intersection type systems in the style of sequent calculus,\nmodifying the systems that Valentini introduced to prove normalisation\nproperties without using the reducibility method. Our systems are more natural\nthan Valentini's ones and equivalent to the usual natural deduction style\nsystems. We prove the characterisation theorems of strong and weak\nnormalisation through the proposed systems, and, moreover, the approximation\ntheorem by means of direct inductive arguments. This provides in a uniform way\nproofs of the normalisation and approximation theorems via type systems in\nsequent calculus style.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2015 03:58:35 GMT"}], "update_date": "2015-03-18", "authors_parsed": [["Kikuchi", "Kentaro", "", "RIEC, Tohoku University, Japan"]]}, {"id": "1503.04908", "submitter": "EPTCS", "authors": "M\\'ario Pereira (University of Porto, Department of Computer Science &\n  LIACC), Sandra Alves (University of Porto, Department of Computer Science &\n  LIACC), M\\'ario Florido (University of Porto, Department of Computer Science\n  & LIACC)", "title": "Liquid Intersection Types", "comments": "In Proceedings ITRS 2014, arXiv:1503.04377", "journal-ref": "EPTCS 177, 2015, pp. 24-42", "doi": "10.4204/EPTCS.177.3", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new type system combining refinement types and the\nexpressiveness of intersection type discipline. The use of such features makes\nit possible to derive more precise types than in the original refinement\nsystem. We have been able to prove several interesting properties for our\nsystem (including subject reduction) and developed an inference algorithm,\nwhich we proved to be sound.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2015 03:58:44 GMT"}], "update_date": "2015-03-18", "authors_parsed": [["Pereira", "M\u00e1rio", "", "University of Porto, Department of Computer Science &\n  LIACC"], ["Alves", "Sandra", "", "University of Porto, Department of Computer Science &\n  LIACC"], ["Florido", "M\u00e1rio", "", "University of Porto, Department of Computer Science\n  & LIACC"]]}, {"id": "1503.04911", "submitter": "EPTCS", "authors": "Jan Bessai (Technical University of Dortmund), Boris D\\\"udder\n  (Technical University of Dortmund), Andrej Dudenhefner (Technical University\n  of Dortmund), Tzu-Chun Chen (Technical University of Darmstadt), Ugo\n  de'Liguoro (University of Torino)", "title": "Typing Classes and Mixins with Intersection Types", "comments": "In Proceedings ITRS 2014, arXiv:1503.04377", "journal-ref": "EPTCS 177, 2015, pp. 79-93", "doi": "10.4204/EPTCS.177.7", "report-no": null, "categories": "cs.PL cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study an assignment system of intersection types for a lambda-calculus\nwith records and a record-merge operator, where types are preserved both under\nsubject reduction and expansion. The calculus is expressive enough to naturally\nrepresent mixins as functions over recursively defined classes, whose fixed\npoints, the objects, are recursive records. In spite of the double recursion\nthat is involved in their definition, classes and mixins can be meaningfully\ntyped without resorting to neither recursive nor F-bounded polymorphic types.\n  We then adapt mixin construct and composition to Java and C#, relying solely\non existing features in such a way that the resulting code remains typable in\nthe respective type systems. We exhibit some example code, and study its\ntypings in the intersection type system via interpretation into the\nlambda-calculus with records we have proposed.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2015 03:59:20 GMT"}], "update_date": "2015-03-18", "authors_parsed": [["Bessai", "Jan", "", "Technical University of Dortmund"], ["D\u00fcdder", "Boris", "", "Technical University of Dortmund"], ["Dudenhefner", "Andrej", "", "Technical University\n  of Dortmund"], ["Chen", "Tzu-Chun", "", "Technical University of Darmstadt"], ["de'Liguoro", "Ugo", "", "University of Torino"]]}, {"id": "1503.04913", "submitter": "EPTCS", "authors": "Nils J\\\"ahnig (TU Berlin), Thomas G\\\"othel (TU Berlin), Sabine Glesner\n  (TU Berlin)", "title": "A Denotational Semantics for Communicating Unstructured Code", "comments": "In Proceedings FESCA 2015, arXiv:1503.04378", "journal-ref": "EPTCS 178, 2015, pp. 9-21", "doi": "10.4204/EPTCS.178.2", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important property of programming language semantics is that they should\nbe compositional. However, unstructured low-level code contains goto-like\ncommands making it hard to define a semantics that is compositional. In this\npaper, we follow the ideas of Saabas and Uustalu to structure low-level code.\nThis gives us the possibility to define a compositional denotational semantics\nbased on least fixed points to allow for the use of inductive verification\nmethods. We capture the semantics of communication using finite traces similar\nto the denotations of CSP. In addition, we examine properties of this semantics\nand give an example that demonstrates reasoning about communication and jumps.\nWith this semantics, we lay the foundations for a proof calculus that captures\nboth, the semantics of unstructured low-level code and communication.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2015 03:59:45 GMT"}], "update_date": "2015-03-18", "authors_parsed": [["J\u00e4hnig", "Nils", "", "TU Berlin"], ["G\u00f6thel", "Thomas", "", "TU Berlin"], ["Glesner", "Sabine", "", "TU Berlin"]]}, {"id": "1503.04914", "submitter": "EPTCS", "authors": "Heinz Riener, R\\\"udiger Ehlers, G\\\"orschwin Fey", "title": "Path-Based Program Repair", "comments": "In Proceedings FESCA 2015, arXiv:1503.04378", "journal-ref": "EPTCS 178, 2015, pp. 22-32", "doi": "10.4204/EPTCS.178.3", "report-no": null, "categories": "cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a path-based approach to program repair for imperative programs.\nOur repair framework takes as input a faulty program, a logic specification\nthat is refuted, and a hint where the fault may be located. An iterative\nabstraction refinement loop is then used to repair the program: in each\niteration, the faulty program part is re-synthesized considering a symbolic\ncounterexample, where the control-flow is kept concrete but the data-flow is\nsymbolic. The appeal of the idea is two-fold: 1) the approach lazily considers\ncandidate repairs and 2) the repairs are directly derived from the logic\nspecification. In contrast to prior work, our approach is complete for programs\nwith finitely many control-flow paths, i.e., the program is repaired if and\nonly if it can be repaired at the specified fault location. Initial results for\nsmall programs indicate that the approach is useful for debugging programs in\npractice.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2015 03:59:53 GMT"}], "update_date": "2015-03-18", "authors_parsed": [["Riener", "Heinz", ""], ["Ehlers", "R\u00fcdiger", ""], ["Fey", "G\u00f6rschwin", ""]]}, {"id": "1503.04918", "submitter": "EPTCS", "authors": "Marcin Benke, Viviana Bono, Aleksy Schubert", "title": "Lucretia - intersection type polymorphism for scripting languages", "comments": "In Proceedings ITRS 2014, arXiv:1503.04377", "journal-ref": "EPTCS 177, 2015, pp. 65-78", "doi": "10.4204/EPTCS.177.6", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scripting code may present maintenance problems in the long run. There is,\nthen, the call for methodologies that make it possible to control the\nproperties of programs written in dynamic languages in an automatic fashion. We\nintroduce Lucretia, a core language with an introspection primitive. Lucretia\nis equipped with a (retrofitted) static type system based on local updates of\ntypes that describe the structure of objects being used. In this way, we deal\nwith one of the most dynamic features of scripting languages, that is, the\nruntime modification of object interfaces. Judgements in our systems have a\nHoare-like shape, as they have a precondition and a postcondition part.\nPreconditions describe static approximations of the interfaces of visible\nobjects before a certain expression has been executed and postconditions\ndescribe them after its execution. The field update operation complicates the\nissue of aliasing in the system. We cope with it by introducing intersection\ntypes in method signatures.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2015 04:03:54 GMT"}], "update_date": "2015-03-18", "authors_parsed": [["Benke", "Marcin", ""], ["Bono", "Viviana", ""], ["Schubert", "Aleksy", ""]]}, {"id": "1503.05445", "submitter": "Matt Lewis", "authors": "Cristina David and Daniel Kroening and Matt Lewis", "title": "Danger Invariants", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Static analysers search for overapproximating proofs of safety commonly known\nas safety invariants. Fundamentally, such analysers summarise traces into sets\nof states, thus trading the ability to distinguish traces for computational\ntractability. Conversely, static bug finders (e.g. Bounded Model Checking) give\nevidence for the failure of an assertion in the form of a counterexample, which\ncan be inspected by the user. However, static bug finders fail to scale when\nanalysing programs with bugs that require many iterations of a loop as the\ncomputational effort grows exponentially with the depth of the bug. We propose\na novel approach for finding bugs, which delivers the performance of abstract\ninterpretation together with the concrete precision of BMC. To do this, we\nintroduce the concept of danger invariants -- the dual to safety invariants.\nDanger invariants summarise sets of traces that are guaranteed to reach an\nerror state. This summarisation allows us to find deep bugs without false\nalarms and without explicitly unwinding loops. We present a second-order\nformulation of danger invariants and use the Second-Order SAT solver described\nin previous work to compute danger invariants for intricate programs taken from\nthe literature.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2015 15:13:12 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["David", "Cristina", ""], ["Kroening", "Daniel", ""], ["Lewis", "Matt", ""]]}, {"id": "1503.06061", "submitter": "Jules Hedges", "authors": "Jules Hedges", "title": "The selection monad as a CPS transformation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A computation in the continuation monad returns a final result given a\ncontinuation, ie. it is a function with type $(X \\to R) \\to R$. If we instead\nreturn the intermediate result at $X$ then our computation is called a\nselection function. Selection functions appear in diverse areas of mathematics\nand computer science (especially game theory, proof theory and topology) but\nthe existing literature does not heavily emphasise the fact that the selection\nmonad is a CPS translation. In particular it has so far gone unnoticed that the\nselection monad has a call/cc-like operator with interesting similarities and\ndifferences to the usual call/cc, which we explore experimentally using\nHaskell.\n  Selection functions can be used whenever we find the intermediate result more\ninteresting than the final result. For example a SAT solver computes an\nassignment to a boolean function, and then its continuation decides whether it\nis a satisfying assignment, and we find the assignment itself more interesting\nthan the fact that it is or is not satisfying. In game theory we find the move\nchosen by a player more interesting than the outcome that results from that\nmove. The author and collaborators are developing a theory of games in which\nselection functions are viewed as generalised notions of rationality, used to\nmodel players. By realising that strategic contexts in game theory are examples\nof continuations we can see that classical game theory narrowly misses being in\nCPS, and that a small change of viewpoint yields a theory of games that is\nbetter behaved, and especially more compositional.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2015 13:28:02 GMT"}], "update_date": "2015-03-23", "authors_parsed": [["Hedges", "Jules", ""]]}, {"id": "1503.07073", "submitter": "John Wickerson", "authors": "Mark Batty, Alastair F. Donaldson, and John Wickerson", "title": "Overhauling SC Atomics in C11 and OpenCL", "comments": "Published in the proceedings of the 43rd Annual ACM SIGPLAN-SIGACT\n  Symposium on Principles of Programming Languages (POPL), 2016", "journal-ref": "ACM SIGPLAN Notices - POPL '16. Volume 51, Issue 1, January 2016", "doi": "10.1145/2837614.2837637", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the conceptual simplicity of sequential consistency (SC), the\nsemantics of SC atomic operations and fences in the C11 and OpenCL memory\nmodels is subtle, leading to convoluted prose descriptions that translate to\ncomplex axiomatic formalisations. We conduct an overhaul of SC atomics in C11,\nreducing the associated axioms in both number and complexity. A consequence of\nour simplification is that the SC operations in an execution no longer need to\nbe totally ordered. This relaxation enables, for the first time, efficient and\nexhaustive simulation of litmus tests that use SC atomics. We extend our\nimproved C11 model to obtain the first rigorous memory model formalisation for\nOpenCL (which extends C11 with support for heterogeneous many-core\nprogramming). In the OpenCL setting, we refine the SC axioms still further to\ngive a sensible semantics to SC operations that employ a 'memory scope' to\nrestrict their visibility to specific threads. Our overhaul requires slight\nstrengthenings of both the C11 and the OpenCL memory models, causing some\nbehaviours to become disallowed. We argue that these strengthenings are\nnatural, and that all of the formalised C11 and OpenCL compilation schemes of\nwhich we are aware (Power and x86 CPUs for C11, AMD GPUs for OpenCL) remain\nvalid in our revised models. Using the Herd memory model simulator, we show\nthat our overhaul leads to an exponential improvement in simulation time for\nC11 litmus tests compared with the original model, making exhaustive simulation\ncompetitive, time-wise, with the non-exhaustive CDSChecker tool.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2015 15:23:16 GMT"}, {"version": "v2", "created": "Thu, 30 Jul 2015 09:15:29 GMT"}, {"version": "v3", "created": "Wed, 16 Nov 2016 14:43:28 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Batty", "Mark", ""], ["Donaldson", "Alastair F.", ""], ["Wickerson", "John", ""]]}, {"id": "1503.07659", "submitter": "Andreas Kl\\\"ockner", "authors": "Andreas Kl\\\"ockner", "title": "Loo.py: From Fortran to performance via transformation and substitution\n  rules", "comments": "ARRAY 2015 - 2nd ACM SIGPLAN International Workshop on Libraries,\n  Languages and Compilers for Array Programming (ARRAY 2015)", "journal-ref": null, "doi": "10.1145/2774959.2774969", "report-no": null, "categories": "cs.PL cs.CE cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A large amount of numerically-oriented code is written and is being written\nin legacy languages. Much of this code could, in principle, make good use of\ndata-parallel throughput-oriented computer architectures. Loo.py, a\ntransformation-based programming system targeted at GPUs and general\ndata-parallel architectures, provides a mechanism for user-controlled\ntransformation of array programs. This transformation capability is designed to\nnot just apply to programs written specifically for Loo.py, but also those\nimported from other languages such as Fortran. It eases the trade-off between\nachieving high performance, portability, and programmability by allowing the\nuser to apply a large and growing family of transformations to an input\nprogram. These transformations are expressed in and used from Python and may be\napplied from a variety of settings, including a pragma-like manner from other\nlanguages.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2015 09:40:56 GMT"}, {"version": "v2", "created": "Sat, 16 May 2015 08:14:18 GMT"}], "update_date": "2015-05-19", "authors_parsed": [["Kl\u00f6ckner", "Andreas", ""]]}, {"id": "1503.07792", "submitter": "Jana Dunfield", "authors": "Matthew A. Hammer, Jana Dunfield, Kyle Headley, Nicholas Labich,\n  Jeffrey S. Foster, Michael Hicks, David Van Horn", "title": "Incremental Computation with Names", "comments": "OOPSLA '15, October 25-30, 2015, Pittsburgh, PA, USA", "journal-ref": null, "doi": "10.1145/2814270.2814305", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past thirty years, there has been significant progress in developing\ngeneral-purpose, language-based approaches to incremental computation, which\naims to efficiently update the result of a computation when an input is\nchanged. A key design challenge in such approaches is how to provide efficient\nincremental support for a broad range of programs. In this paper, we argue that\nfirst-class names are a critical linguistic feature for efficient incremental\ncomputation. Names identify computations to be reused across differing runs of\na program, and making them first class gives programmers a high level of\ncontrol over reuse. We demonstrate the benefits of names by presenting NOMINAL\nADAPTON, an ML-like language for incremental computation with names. We\ndescribe how to use NOMINAL ADAPTON to efficiently incrementalize several\nstandard programming patterns -- including maps, folds, and unfolds -- and show\nhow to build efficient, incremental probabilistic trees and tries. Since\nNOMINAL ADAPTON's implementation is subtle, we formalize it as a core calculus\nand prove it is from-scratch consistent, meaning it always produces the same\nanswer as simply re-running the computation. Finally, we demonstrate that\nNOMINAL ADAPTON can provide large speedups over both from-scratch computation\nand ADAPTON, a previous state-of-the-art incremental computation system.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2015 17:13:34 GMT"}, {"version": "v2", "created": "Sun, 29 Mar 2015 21:35:07 GMT"}, {"version": "v3", "created": "Mon, 24 Aug 2015 17:48:20 GMT"}, {"version": "v4", "created": "Wed, 26 Aug 2015 06:20:41 GMT"}, {"version": "v5", "created": "Fri, 9 Oct 2015 11:46:09 GMT"}, {"version": "v6", "created": "Tue, 23 Mar 2021 17:37:21 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Hammer", "Matthew A.", ""], ["Dunfield", "Jana", ""], ["Headley", "Kyle", ""], ["Labich", "Nicholas", ""], ["Foster", "Jeffrey S.", ""], ["Hicks", "Michael", ""], ["Van Horn", "David", ""]]}, {"id": "1503.08476", "submitter": "Vadim Zaytsev", "authors": "Vadim Zaytsev", "title": "Guided Grammar Convergence", "comments": "In Poster Proceedings of 6th Conference on Software Language\n  Engineering (SLE) 2013, http://www.sleconf.org/2013/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.FL cs.PL", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Relating formal grammars is a hard problem that balances between language\nequivalence (which is known to be undecidable) and grammar identity (which is\ntrivial). In this paper, we investigate several milestones between those two\nextremes and propose a methodology for inconsistency management in grammar\nengineering. While conventional grammar convergence is a practical approach\nrelying on human experts to encode differences as transformation steps, guided\ngrammar convergence is a more narrowly applicable technique that infers such\ntransformation steps automatically by normalising the grammars and establishing\na structural equivalence relation between them. This allows us to perform a\ncase study with automatically inferring bidirectional transformations between\n11 grammars (in a broad sense) of the same artificial functional language:\nparser specifications with different combinator libraries, definite clause\ngrammars, concrete syntax definitions, algebraic data types, metamodels, XML\nschemata, object models.\n", "versions": [{"version": "v1", "created": "Sun, 29 Mar 2015 18:40:45 GMT"}], "update_date": "2015-03-31", "authors_parsed": [["Zaytsev", "Vadim", ""]]}, {"id": "1503.08623", "submitter": "Edd Barrett Dr", "authors": "Edd Barrett, Carl Friedrich Bolz, Lukas Diekmann, Laurence Tratt", "title": "Fine-grained Language Composition: A Case Study", "comments": "27 pages, 4 tables, 5 figures", "journal-ref": "European Conference on Object-Oriented Programming (ECOOP). July\n  2016, Pages 3:1--3:27", "doi": "10.4230/LIPIcs.ECOOP.2016.3", "report-no": null, "categories": "cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Although run-time language composition is common, it normally takes the form\nof a crude Foreign Function Interface (FFI). While useful, such compositions\ntend to be coarse-grained and slow. In this paper we introduce a novel\nfine-grained syntactic composition of PHP and Python which allows users to\nembed each language inside the other, including referencing variables across\nlanguages. This composition raises novel design and implementation challenges.\nWe show that good solutions can be found to the design challenges; and that the\nresulting implementation imposes an acceptable performance overhead of, at\nmost, 2.6x.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2015 10:10:18 GMT"}, {"version": "v2", "created": "Wed, 9 Dec 2015 15:36:57 GMT"}, {"version": "v3", "created": "Mon, 11 Jul 2016 11:39:51 GMT"}], "update_date": "2017-03-02", "authors_parsed": [["Barrett", "Edd", ""], ["Bolz", "Carl Friedrich", ""], ["Diekmann", "Lukas", ""], ["Tratt", "Laurence", ""]]}, {"id": "1503.08665", "submitter": "Sigurd Schneider", "authors": "Sigurd Schneider, Gert Smolka, Sebastian Hack", "title": "A Linear First-Order Functional Intermediate Language for Verified\n  Compilers", "comments": "Addressed comments from reviewers (ITP 2015): (1) Added discussion of\n  a paper in related work (2) Added definition of renamed-apart in appendix (3)\n  Formulation changes in a coupe of places", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the linear first-order intermediate language IL for verified\ncompilers. IL is a functional language with calls to a nondeterministic\nenvironment. We give IL terms a second, imperative semantic interpretation and\nobtain a register transfer language. For the imperative interpretation we\nestablish a notion of live variables. Based on live variables, we formulate a\ndecidable property called coherence ensuring that the functional and the\nimperative interpretation of a term coincide. We formulate a register\nassignment algorithm for IL and prove its correctness. The algorithm translates\na functional IL program into an equivalent imperative IL program. Correctness\nfollows from the fact that the algorithm reaches a coherent program after\nconsistently renaming local variables. We prove that the maximal number of live\nvariables in the initial program bounds the number of different variables in\nthe final coherent program. The entire development is formalized in Coq.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2015 13:31:38 GMT"}, {"version": "v2", "created": "Thu, 4 Jun 2015 10:45:52 GMT"}], "update_date": "2015-06-05", "authors_parsed": [["Schneider", "Sigurd", ""], ["Smolka", "Gert", ""], ["Hack", "Sebastian", ""]]}, {"id": "1503.09006", "submitter": "Michael Lippautz", "authors": "Martin Aigner, Christoph M. Kirsch, Michael Lippautz, Ana Sokolova", "title": "Fast, Multicore-Scalable, Low-Fragmentation Memory Allocation through\n  Large Virtual Memory and Global Data Structures", "comments": null, "journal-ref": null, "doi": "10.1145/2814270.2814294", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate that general-purpose memory allocation involving many threads\non many cores can be done with high performance, multicore scalability, and low\nmemory consumption. For this purpose, we have designed and implemented scalloc,\na concurrent allocator that generally performs and scales in our experiments\nbetter than other allocators while using less memory, and is still competitive\notherwise. The main ideas behind the design of scalloc are: uniform treatment\nof small and big objects through so-called virtual spans, efficiently and\neffectively reclaiming free memory through fast and scalable global data\nstructures, and constant-time (modulo synchronization) allocation and\ndeallocation operations that trade off memory reuse and spatial locality\nwithout being subject to false sharing.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2015 11:36:46 GMT"}, {"version": "v2", "created": "Tue, 25 Aug 2015 11:05:23 GMT"}], "update_date": "2015-08-26", "authors_parsed": [["Aigner", "Martin", ""], ["Kirsch", "Christoph M.", ""], ["Lippautz", "Michael", ""], ["Sokolova", "Ana", ""]]}, {"id": "1503.09097", "submitter": "Marco Peressotti", "authors": "Marino Miculan and Marco Peressotti and Andrea Toneguzzo", "title": "Open Transactions on Shared Memory", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-319-19282-6_14", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transactional memory has arisen as a good way for solving many of the issues\nof lock-based programming. However, most implementations admit isolated\ntransactions only, which are not adequate when we have to coordinate\ncommunicating processes. To this end, in this paper we present OCTM, an\nHaskell-like language with open transactions over shared transactional memory:\nprocesses can join transactions at runtime just by accessing to shared\nvariables. Thus a transaction can co-operate with the environment through\nshared variables, but if it is rolled-back, also all its effects on the\nenvironment are retracted. For proving the expressive power of TCCS we give an\nimplementation of TCCS, a CCS-like calculus with open transactions.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2015 15:49:55 GMT"}], "update_date": "2015-05-14", "authors_parsed": [["Miculan", "Marino", ""], ["Peressotti", "Marco", ""], ["Toneguzzo", "Andrea", ""]]}]