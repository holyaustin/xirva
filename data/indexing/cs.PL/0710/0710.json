[{"id": "0710.0528", "submitter": "Francesca Scozzari", "authors": "Gianluca Amato and Francesca Scozzari", "title": "On the interaction between sharing and linearity", "comments": null, "journal-ref": "Theory and Practice of Logic Programming, volume 10, issue 01, pp.\n  49-112, 2010", "doi": "10.1017/S1471068409990160", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the analysis of logic programs, abstract domains for detecting sharing and\nlinearity information are widely used. Devising abstract unification algorithms\nfor such domains has proved to be rather hard. At the moment, the available\nalgorithms are correct but not optimal, i.e., they cannot fully exploit the\ninformation conveyed by the abstract domains. In this paper, we define a new\n(infinite) domain ShLin-w which can be thought of as a general framework from\nwhich other domains can be easily derived by abstraction. ShLin-w makes the\ninteraction between sharing and linearity explicit. We provide a constructive\ncharacterization of the optimal abstract unification operator on ShLin-w and we\nlift it to two well-known abstractions of ShLin-w. Namely, to the classical\nSharing X Lin abstract domain and to the more precise ShLin-2 abstract domain\nby Andy King. In the case of single binding substitutions, we obtain optimal\nabstract unification algorithms for such domains.\n  To appear in Theory and Practice of Logic Programming (TPLP).\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2007 13:29:28 GMT"}, {"version": "v2", "created": "Tue, 28 Jul 2009 09:35:55 GMT"}], "update_date": "2012-10-09", "authors_parsed": [["Amato", "Gianluca", ""], ["Scozzari", "Francesca", ""]]}, {"id": "0710.0824", "submitter": "Norman Danner", "authors": "Norman Danner and James S. Royer", "title": "Two algorithms in search of a type system", "comments": "30 pages. Final version to appear in Theory of Computing Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": null, "abstract": "  The authors' ATR programming formalism is a version of call-by-value PCF\nunder a complexity-theoretically motivated type system. ATR programs run in\ntype-2 polynomial-time and all standard type-2 basic feasible functionals are\nATR-definable (ATR types are confined to levels 0, 1, and 2). A limitation of\nthe original version of ATR is that the only directly expressible recursions\nare tail-recursions. Here we extend ATR so that a broad range of affine\nrecursions are directly expressible. In particular, the revised ATR can fairly\nnaturally express the classic insertion- and selection-sort algorithms, thus\novercoming a sticking point of most prior implicit-complexity-based formalisms.\nThe paper's main work is in refining the original time-complexity semantics for\nATR to show that these new recursion schemes do not lead out of the realm of\nfeasibility.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2007 16:04:59 GMT"}, {"version": "v2", "created": "Fri, 18 Apr 2008 19:17:30 GMT"}], "update_date": "2008-04-18", "authors_parsed": [["Danner", "Norman", ""], ["Royer", "James S.", ""]]}, {"id": "0710.1482", "submitter": "Amey Karkare", "authors": "Amey Karkare, Amitabha Sanyal, Uday Khedker", "title": "Heap Reference Analysis for Functional Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.SE", "license": null, "abstract": "  Current garbage collectors leave a lot of garbage uncollected because they\nconservatively approximate liveness by reachability from program variables. In\nthis paper, we describe a sequence of static analyses that takes as input a\nprogram written in a first-order, eager functional programming language, and\nfinds at each program point the references to objects that are guaranteed not\nto be used in the future. Such references are made null by a transformation\npass. If this makes the object unreachable, it can be collected by the garbage\ncollector. This causes more garbage to be collected, resulting in fewer\ncollections. Additionally, for those garbage collectors which scavenge live\nobjects, it makes each collection faster.\n  The interesting aspects of our method are both in the identification of the\nanalyses required to solve the problem and the way they are carried out. We\nidentify three different analyses -- liveness, sharing and accessibility. In\nliveness and sharing analyses, the function definitions are analyzed\nindependently of the calling context. This is achieved by using a variable to\nrepresent the unknown context of the function being analyzed and setting up\nconstraints expressing the effect of the function with respect to the variable.\nThe solution of the constraints is a summary of the function that is\nparameterized with respect to a calling context and is used to analyze function\ncalls. As a result we achieve context sensitivity at call sites without\nanalyzing the function multiple number of times.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2007 08:43:58 GMT"}], "update_date": "2007-10-09", "authors_parsed": [["Karkare", "Amey", ""], ["Sanyal", "Amitabha", ""], ["Khedker", "Uday", ""]]}, {"id": "0710.2358", "submitter": "Catherine Recanati", "authors": "C. Recanati", "title": "Success and failure of programming environments - report on the design\n  and use of a graphic abstract syntax tree editor", "comments": "This is an old paper (1990) of 29 pages", "journal-ref": null, "doi": null, "report-no": "Esprit project no. 891 (STAPLE), Technical Report no 90/1, Paris,\n  Jan 1990", "categories": "cs.PL cs.HC", "license": null, "abstract": "  The STAPLE project investigated (at the end of the eighties), a persistent\narchitecture for functional programming. Work has been done in two directions:\nthe development of a programming environment for a functional language within a\npersistent system and an experiment on transferring the expertise of functional\nprototyping into industry. This paper is a report on the first activity. The\nfirst section gives a general description of Absynte - the abstract syntax tree\neditor developed within the Project. Following sections make an attempt at\nmeasuring the effectiveness of such an editor and discuss the problems raised\nby structured syntax editing - specially environments based on abstract syntax\ntrees.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2007 23:40:47 GMT"}], "update_date": "2007-10-15", "authors_parsed": [["Recanati", "C.", ""]]}, {"id": "0710.2887", "submitter": "Olivier Zendra", "authors": "Roland Ducournau (LIRMM), Etienne Gagnon, Chandra Krintz (RACE LAB),\n  Philippe Mulet, Jan Vitek (S3L), Olivier Zendra (INRIA Lorraine - LORIA)", "title": "Implementation, Compilation, Optimization of Object-Oriented Languages,\n  Programs and Systems - Report on the Workshop ICOOOLPS'2006 at ECOOP'06", "comments": "The original publication is available at http://www.springerlink.com", "journal-ref": "Object-Oriented Technology. ECOOP 2006 Workshop Reader - ECOOP\n  2006 Workshops, Nantes, France, July 3-7, 2006, Final Reports Springer Berlin\n  / Heidelberg (Ed.) (2007) 1-14", "doi": "10.1007/978-3-540-71774-4_1", "report-no": null, "categories": "cs.PF cs.PL cs.SE", "license": null, "abstract": "  ICOOOLPS'2006 was the first edition of ECOOP-ICOOOLPS workshop. It intended\nto bring researchers and practitioners both from academia and industry\ntogether, with a spirit of openness, to try and identify and begin to address\nthe numerous and very varied issues of optimization. This succeeded, as can be\nseen from the papers, the attendance and the liveliness of the discussions that\ntook place during and after the workshop, not to mention a few new cooperations\nor postdoctoral contracts. The 22 talented people from different groups who\nparticipated were unanimous to appreciate this first edition and recommend that\nICOOOLPS be continued next year. A community is thus beginning to form, and\nshould be reinforced by a second edition next year, with all the improvements\nthis first edition made emerge.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2007 17:53:49 GMT"}], "update_date": "2007-10-16", "authors_parsed": [["Ducournau", "Roland", "", "LIRMM"], ["Gagnon", "Etienne", "", "RACE LAB"], ["Krintz", "Chandra", "", "RACE LAB"], ["Mulet", "Philippe", "", "S3L"], ["Vitek", "Jan", "", "S3L"], ["Zendra", "Olivier", "", "INRIA Lorraine - LORIA"]]}, {"id": "0710.4640", "submitter": "EDA Publishing Association", "authors": "Ilya Issenin, Nikil Dutt", "title": "FORAY-GEN: Automatic Generation of Affine Functions for Memory\n  Optimizations", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.PL", "license": null, "abstract": "  In today's embedded applications a significant portion of energy is spent in\nthe memory subsystem. Several approaches have been proposed to minimize this\nenergy, including the use of scratch pad memories, with many based on static\nanalysis of a program. However, often it is not possible to perform static\nanalysis and optimization of a program's memory access behavior unless the\nprogram is specifically written for this purpose. In this paper we introduce\nthe FORAY model of a program that permits aggressive analysis of the\napplication's memory behavior that further enables such optimizations since it\nconsists of 'for' loops and array accesses which are easily analyzable. We\npresent FORAY-GEN: an automated profile-based approach for extraction of the\nFORAY model from the original program. We also demonstrate how FORAY-GEN\nenhances applicability of other memory subsystem optimization approaches,\nresulting in an average of two times increase in the number of memory\nreferences that can be analyzed by existing static approaches.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 08:11:20 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Issenin", "Ilya", ""], ["Dutt", "Nikil", ""]]}, {"id": "0710.4683", "submitter": "EDA Publishing Association", "authors": "Stephen A. Edwards", "title": "The Challenges of Hardware Synthesis from C-Like Languages", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.PL", "license": null, "abstract": "  MANY TECHNIQUES for synthesizing digital hardware from C-like languages have\nbeen proposed, but none have emerged as successful as Verilog or VHDL for\nregister-transfer-level design. This paper looks at two of the fundamental\nchallenges: concurrency and timing control.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 09:07:39 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Edwards", "Stephen A.", ""]]}, {"id": "0710.4702", "submitter": "EDA Publishing Association", "authors": "Nastaran Baradaran, Pedro C. Diniz", "title": "A Register Allocation Algorithm in the Presence of Scalar Replacement\n  for Fine-Grain Configurable Architectures", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.PL", "license": null, "abstract": "  The aggressive application of scalar replacement to array references\nsubstantially reduces the number of memory operations at the expense of a\npossibly very large number of registers. In this paper we describe a register\nallocation algorithm that assigns registers to scalar replaced array references\nalong the critical paths of a computation, in many cases exploiting the\nopportunity for concurrent memory accesses. Experimental results, for a set of\nimage/signal processing code kernels, reveal that the proposed algorithm leads\nto a substantial reduction of the number of execution cycles for the\ncorresponding hardware implementation on a contemporary\nField-Programmable-Gate-Array (FPGA) when compared to other greedy allocation\nalgorithms, in some cases, using even fewer number of registers.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 09:27:20 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Baradaran", "Nastaran", ""], ["Diniz", "Pedro C.", ""]]}, {"id": "0710.4780", "submitter": "Jesus M. Almendros-Jimenez Dr.", "authors": "J. M. Almendros-Jim\\'enez and A. Becerra-Ter\\'on and F. J.\n  Enciso-Ba\\~nos", "title": "Querying XML Documents in Logic Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.DB", "license": null, "abstract": "  Extensible Markup Language (XML) is a simple, very flexible text format\nderived from SGML. Originally designed to meet the challenges of large-scale\nelectronic publishing, XML is also playing an increasingly important role in\nthe exchange of a wide variety of data on the Web and elsewhere. XPath language\nis the result of an effort to provide address parts of an XML document. In\nsupport of this primary purpose, it becomes in a query language against an XML\ndocument. In this paper we present a proposal for the implementation of the\nXPath language in logic programming. With this aim we will describe the\nrepresentation of XML documents by means of a logic program. Rules and facts\ncan be used for representing the document schema and the XML document itself.\nIn particular, we will present how to index XML documents in logic programs:\nrules are supposed to be stored in main memory, however facts are stored in\nsecondary memory by using two kind of indexes: one for each XML tag, and other\nfor each group of terminal items. In addition, we will study how to query by\nmeans of the XPath language against a logic program representing an XML\ndocument. It evolves the specialization of the logic program with regard to the\nXPath expression. Finally, we will also explain how to combine the indexing and\nthe top-down evaluation of the logic program. To appear in Theory and Practice\nof Logic Programming (TPLP)\"\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 10:45:08 GMT"}], "update_date": "2007-10-26", "authors_parsed": [["Almendros-Jim\u00e9nez", "J. M.", ""], ["Becerra-Ter\u00f3n", "A.", ""], ["Enciso-Ba\u00f1os", "F. J.", ""]]}, {"id": "0710.4807", "submitter": "EDA Publishing Association", "authors": "G. Chen, M. Kandemir, M. Karakoy", "title": "A Constraint Network Based Approach to Memory Layout Optimization", "comments": "Submitted on behalf of EDAA (http://www.edaa.com/)", "journal-ref": "Dans Design, Automation and Test in Europe - DATE'05, Munich :\n  Allemagne (2005)", "doi": null, "report-no": null, "categories": "cs.PL", "license": null, "abstract": "  While loop restructuring based code optimization for array intensive\napplications has been successful in the past, it has several problems such as\nthe requirement of checking dependences (legality issues) and transformation of\nall of the array references within the loop body indiscriminately (while some\nof the references can benefit from the transformation, others may not). As a\nresult, data transformations, i.e., transformations that modify memory layout\nof array data instead of loop structure have been proposed. One of the problems\nassociated with data transformations is the difficulty of selecting a memory\nlayout for an array that is acceptable to the entire program (not just to a\nsingle loop). In this paper, we formulate the problem of determining the memory\nlayouts of arrays as a constraint network, and explore several methods of\nsolution in a systematic way. Our experiments provide strong support in favor\nof employing constraint processing, and point out future research directions.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2007 11:59:01 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Chen", "G.", ""], ["Kandemir", "M.", ""], ["Karakoy", "M.", ""]]}, {"id": "0710.5895", "submitter": "Wim Vanhoof", "authors": "Francois Gobert, Baudouin Le Charlier", "title": "Source-to-source optimizing transformations of Prolog programs based on\n  abstract interpretation", "comments": "Paper presented at the 17th Workshop on Logic-based Methods in\n  Programming Environments (WLPE2007)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO cs.SE", "license": null, "abstract": "  Making a Prolog program more efficient by transforming its source code,\nwithout changing its operational semantics, is not an obvious task. It requires\nthe user to have a clear understanding of how the Prolog compiler works, and in\nparticular, of the effects of impure features like the cut. The way a Prolog\ncode is written - e.g., the order of clauses, the order of literals in a\nclause, the use of cuts or negations - influences its efficiency. Furthermore,\ndifferent optimization techniques may be redundant or conflicting when they are\napplied together, depending on the way a procedure is called - e.g., inserting\ncuts and enabling indexing. We present an optimiser, based on abstract\ninterpretation, that automatically performs safe code transformations of Prolog\nprocedures in the context of some class of input calls. The method is more\neffective if procedures are annotated with additional information about modes,\ntypes, sharing, number of solutions and the like. Thus the approach is similar\nto Mercury. It applies to any Prolog program, however.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2007 15:59:50 GMT"}], "update_date": "2007-11-01", "authors_parsed": [["Gobert", "Francois", ""], ["Charlier", "Baudouin Le", ""]]}]