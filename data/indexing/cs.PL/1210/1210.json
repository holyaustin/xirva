[{"id": "1210.0614", "submitter": "EPTCS", "authors": "Timothy A. S. Davidson (University of Warwick, UK), Simon J. Gay\n  (University of Glasgow, UK), Rajagopal Nagarajan (University of Warwick, UK),\n  Ittoop Vergheese Puthoor (University of Glasgow, UK)", "title": "Analysis of a Quantum Error Correcting Code using Quantum Process\n  Calculus", "comments": "In Proceedings QPL 2011, arXiv:1210.0298", "journal-ref": "EPTCS 95, 2012, pp. 67-80", "doi": "10.4204/EPTCS.95.7", "report-no": null, "categories": "cs.LO cs.PL quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe the use of quantum process calculus to describe and analyze\nquantum communication protocols, following the successful field of formal\nmethods from classical computer science. The key idea is to define two systems,\none modelling a protocol and one expressing a specification, and prove that\nthey are behaviourally equivalent. We summarize the necessary theory in the\nprocess calculus CQP, including the crucial result that equivalence is a\ncongruence, meaning that it is preserved by embedding in any context. We\nillustrate the approach by analyzing two versions of a quantum error correction\nsystem.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2012 00:34:28 GMT"}], "update_date": "2012-10-03", "authors_parsed": [["Davidson", "Timothy A. S.", "", "University of Warwick, UK"], ["Gay", "Simon J.", "", "University of Glasgow, UK"], ["Nagarajan", "Rajagopal", "", "University of Warwick, UK"], ["Puthoor", "Ittoop Vergheese", "", "University of Glasgow, UK"]]}, {"id": "1210.1039", "submitter": "Frederic Le Mouel", "authors": "Julien Ponge (CITI), Fr\\'ed\\'eric Le Mou\\\"el (CITI)", "title": "JooFlux: Hijacking Java 7 InvokeDynamic To Support Live Code\n  Modifications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OS cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Changing functional and non-functional software implementation at runtime is\nuseful and even sometimes critical both in development and production\nenvironments. JooFlux is a JVM agent that allows both the dynamic replacement\nof method implementations and the application of aspect advices. It works by\ndoing bytecode transformation to take advantage of the new invokedynamic\ninstruction added in Java SE 7 to help implementing dynamic languages for the\nJVM. JooFlux can be managed using a JMX agent so as to operate dynamic\nmodifications at runtime, without resorting to a dedicated domain-specific\nlanguage. We compared JooFlux with existing AOP platforms and dynamic\nlanguages. Results demonstrate that JooFlux performances are close to the Java\nones --- with most of the time a marginal overhead, and sometimes a gain ---\nwhere AOP platforms and dynamic languages present significant overheads. This\npaves the way for interesting future evolutions and applications of JooFlux.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2012 09:15:19 GMT"}], "update_date": "2012-10-04", "authors_parsed": [["Ponge", "Julien", "", "CITI"], ["Mou\u00ebl", "Fr\u00e9d\u00e9ric Le", "", "CITI"]]}, {"id": "1210.1157", "submitter": "James Hanlon", "authors": "James Hanlon, Simon J. Hollis and David May", "title": "Scalable data abstractions for distributed parallel computations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to express a program as a hierarchical composition of parts is an\nessential tool in managing the complexity of software and a key abstraction\nthis provides is to separate the representation of data from the computation.\nMany current parallel programming models use a shared memory model to provide\ndata abstraction but this doesn't scale well with large numbers of cores due to\nnon-determinism and access latency. This paper proposes a simple programming\nmodel that allows scalable parallel programs to be expressed with distributed\nrepresentations of data and it provides the programmer with the flexibility to\nemploy shared or distributed styles of data-parallelism where applicable. It is\ncapable of an efficient implementation, and with the provision of a small set\nof primitive capabilities in the hardware, it can be compiled to operate\ndirectly on the hardware, in the same way stack-based allocation operates for\nsubroutines in sequential machines.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2012 15:57:01 GMT"}], "update_date": "2012-10-04", "authors_parsed": [["Hanlon", "James", ""], ["Hollis", "Simon J.", ""], ["May", "David", ""]]}, {"id": "1210.1611", "submitter": "Neng-Fa Zhou", "authors": "Neng-Fa Zhou and Christian Theil Have", "title": "Efficient Tabling of Structured Data with Enhanced Hash-Consing", "comments": "16 pages; TPLP, 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Current tabling systems suffer from an increase in space complexity, time\ncomplexity or both when dealing with sequences due to the use of data\nstructures for tabled subgoals and answers and the need to copy terms into and\nfrom the table area. This symptom can be seen in not only B-Prolog, which uses\nhash tables, but also systems that use tries such as XSB and YAP. In this\npaper, we apply hash-consing to tabling structured data in B-Prolog. While\nhash-consing can reduce the space consumption when sharing is effective, it\ndoes not change the time complexity. We enhance hash-consing with two\ntechniques, called input sharing and hash code memoization, for reducing the\ntime complexity by avoiding computing hash codes for certain terms. The\nimproved system is able to eliminate the extra linear factor in the old system\nfor processing sequences, thus significantly enhancing the scalability of\napplications such as language parsing and bio-sequence analysis applications.\nWe confirm this improvement with experimental results.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2012 23:19:16 GMT"}], "update_date": "2012-10-08", "authors_parsed": [["Zhou", "Neng-Fa", ""], ["Have", "Christian Theil", ""]]}, {"id": "1210.1653", "submitter": "Iliano Cervesato", "authors": "Iliano Cervesato", "title": "An Improved Proof-Theoretic Compilation of Logic Programs", "comments": "To appear in Theory and Practice of Logic Programming", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  In prior work, we showed that logic programming compilation can be given a\nproof-theoretic justification for generic abstract logic programming languages,\nand demonstrated this technique in the case of hereditary Harrop formulas and\ntheir linear variant. Compiled clauses were themselves logic formulas except\nfor the presence of a second-order abstraction over the atomic goals matching\ntheir head. In this paper, we revisit our previous results into a more detailed\nand fully logical justification that does away with this spurious abstraction.\nWe then refine the resulting technique to support well-moded programs\nefficiently.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2012 06:26:26 GMT"}], "update_date": "2012-10-08", "authors_parsed": [["Cervesato", "Iliano", ""]]}, {"id": "1210.1665", "submitter": "Germ\\'an Vidal", "authors": "Germ\\'an Vidal", "title": "Annotation of Logic Programs for Independent AND-Parallelism by Partial\n  Evaluation", "comments": "22 pages, includes an appendix", "journal-ref": "Theory and Practice of Logic Programming, Volume12, Special\n  Issue4-5, 2012, pp 583-600", "doi": "10.1017/S1471068412000191", "report-no": null, "categories": "cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional approaches to automatic AND-parallelization of logic programs\nrely on some static analysis to identify independent goals that can be safely\nand efficiently run in parallel in any possible execution. In this paper, we\npresent a novel technique for generating annotations for independent\nAND-parallelism that is based on partial evaluation. Basically, we augment a\nsimple partial evaluation procedure with (run-time) groundness and variable\nsharing information so that parallel conjunctions are added to the residual\nclauses when the conditions for independence are met. In contrast to previous\napproaches, our partial evaluator is able to transform the source program in\norder to expose more opportunities for parallelism. To the best of our\nknowledge, we present the first approach to a parallelizing partial evaluator.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2012 07:38:35 GMT"}], "update_date": "2012-10-08", "authors_parsed": [["Vidal", "Germ\u00e1n", ""]]}, {"id": "1210.2094", "submitter": "EPTCS", "authors": "Danko Ilik", "title": "Type Directed Partial Evaluation for Level-1 Shift and Reset", "comments": "In Proceedings COS 2013, arXiv:1309.0924", "journal-ref": "EPTCS 127, 2013, pp. 86-100", "doi": "10.4204/EPTCS.127.6", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an implementation in the Coq proof assistant of type directed\npartial evaluation (TDPE) algorithms for call-by-name and call-by-value\nversions of shift and reset delimited control operators, and in presence of\nstrong sum types. We prove that the algorithm transforms well-typed programs to\nones in normal form. These normal forms can not always be arrived at using the\nso far known equational theories. The typing system does not allow answer-type\nmodification for function types and allows delimiters to be set on at most one\natomic type. The semantic domain for evaluation is expressed in Constructive\nType Theory as a dependently typed monadic structure combining Kripke models\nand continuation passing style translations.\n", "versions": [{"version": "v1", "created": "Sun, 7 Oct 2012 18:56:54 GMT"}, {"version": "v2", "created": "Sun, 7 Apr 2013 06:38:59 GMT"}, {"version": "v3", "created": "Tue, 28 May 2013 12:09:56 GMT"}, {"version": "v4", "created": "Thu, 5 Sep 2013 08:03:57 GMT"}], "update_date": "2013-09-06", "authors_parsed": [["Ilik", "Danko", ""]]}, {"id": "1210.2125", "submitter": "Guoxin Su Mr", "authors": "Guoxin Su, Mingsheng Ying, and Chengqi Zhang", "title": "Session Communication and Integration", "comments": "A short version of this paper is submitted for review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The scenario-based specification of a large distributed system is usually\nnaturally decomposed into various modules. The integration of specification\nmodules contrasts to the parallel composition of program components, and\nincludes various ways such as scenario concatenation, choice, and nesting. The\nrecent development of multiparty session types for process calculi provides\nuseful techniques to accommodate the protocol modularisation, by encoding\nfragments of communication protocols in the usage of private channels for a\nclass of agents. In this paper, we extend forgoing session type theories by\nenhancing the session integration mechanism. More specifically, we propose a\nnovel synchronous multiparty session type theory, in which sessions are\nseparated into the communicating and integrating levels. Communicating sessions\nrecord the message-based communications between multiple agents, whilst\nintegrating sessions describe the integration of communicating ones. A\ntwo-level session type system is developed for pi-calculus with syntactic\nprimitives for session establishment, and several key properties of the type\nsystem are studied. Applying the theory to system description, we show that a\nchannel safety property and a session conformance property can be analysed.\nAlso, to improve the utility of the theory, a process slicing method is used to\nhelp identify the violated sessions in the type checking.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2012 01:17:26 GMT"}], "update_date": "2012-10-09", "authors_parsed": [["Su", "Guoxin", ""], ["Ying", "Mingsheng", ""], ["Zhang", "Chengqi", ""]]}, {"id": "1210.2282", "submitter": "Miguel Areias", "authors": "Miguel Areias and Ricardo Rocha", "title": "Towards Multi-Threaded Local Tabling Using a Common Table Space", "comments": "To appear in Theory and Practice of Logic Programming", "journal-ref": "Theory and Practice of Logic Programming, Volume 12, Special Issue\n  4-5, 2012, pp 427-443", "doi": "10.1017/S1471068412000117", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-threading is currently supported by several well-known Prolog systems\nproviding a highly portable solution for applications that can benefit from\nconcurrency. When multi-threading is combined with tabling, we can exploit the\npower of higher procedural control and declarative semantics. However, despite\nthe availability of both threads and tabling in some Prolog systems, the\nimplementation of these two features implies complex ties to each other and to\nthe underlying engine. Until now, XSB was the only Prolog system combining\nmulti-threading with tabling. In XSB, tables may be either private or shared\nbetween threads. While thread-private tables are easier to implement, shared\ntables have all the associated issues of locking, synchronization and potential\ndeadlocks. In this paper, we propose an alternative view to XSB's approach. In\nour proposal, each thread views its tables as private but, at the engine level,\nwe use a common table space where tables are shared among all threads. We\npresent three designs for our common table space approach: No-Sharing (NS)\n(similar to XSB's private tables), Subgoal-Sharing (SS) and Full-Sharing (FS).\nThe primary goal of this work was to reduce the memory usage for the table\nspace but, our experimental results, using the YapTab tabling system with a\nlocal evaluation strategy, show that we can also achieve significant reductions\non running time.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2012 14:00:07 GMT"}, {"version": "v2", "created": "Tue, 9 Oct 2012 22:12:00 GMT"}], "update_date": "2012-10-11", "authors_parsed": [["Areias", "Miguel", ""], ["Rocha", "Ricardo", ""]]}, {"id": "1210.2297", "submitter": "Remy Haemmerle", "authors": "R\\'emy Haemmerl\\'e", "title": "Diagrammatic confluence for Constraint Handling Rules", "comments": null, "journal-ref": "Theory and Practice of Logic Programming, 12(4-5): 737-753, 2012", "doi": "10.1017/S1471068412000270", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Confluence is a fundamental property of Constraint Handling Rules (CHR)\nsince, as in other rewriting formalisms, it guarantees that the computations\nare not dependent on rule application order, and also because it implies the\nlogical consistency of the program declarative view. In this paper we are\nconcerned with proving the confluence of non-terminating CHR programs. For this\npurpose, we derive from van Oostrom's decreasing diagrams method a novel\ncriterion on CHR critical pairs that generalizes all preexisting criteria. We\nsubsequently improve on a result on the modularity of CHR confluence, which\npermits modular combinations of possibly non-terminating confluent programs,\nwithout loss of confluence.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2012 14:34:25 GMT"}, {"version": "v2", "created": "Tue, 9 Oct 2012 12:43:36 GMT"}], "update_date": "2012-10-10", "authors_parsed": [["Haemmerl\u00e9", "R\u00e9my", ""]]}, {"id": "1210.2454", "submitter": "EPTCS", "authors": "Aleksandar S. Dimovski", "title": "Symbolic Representation of Algorithmic Game Semantics", "comments": "In Proceedings GandALF 2012, arXiv:1210.2028", "journal-ref": "EPTCS 96, 2012, pp. 99-112", "doi": "10.4204/EPTCS.96.8", "report-no": null, "categories": "cs.FL cs.GT cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we revisit the regular-language representation of game\nsemantics of second-order recursion free Idealized Algol with infinite data\ntypes. By using symbolic values instead of concrete ones we generalize the\nstandard notion of regular-language and automata representations to that of\ncorresponding symbolic representations. In this way terms with infinite data\ntypes, such as integers, can be expressed as finite symbolic-automata although\nthe standard automata interpretation is infinite. Moreover, significant\nreductions of the state space of game semantics models are obtained. This\nenables efficient verification of terms, which is illustrated with several\nexamples.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2012 00:53:55 GMT"}], "update_date": "2012-10-10", "authors_parsed": [["Dimovski", "Aleksandar S.", ""]]}, {"id": "1210.2864", "submitter": "Remy Haemmerle", "authors": "Jose F. Morales, R\\'emy Haemmerl\\'e, Manuel Carro, and Manuel V.\n  Hermenegildo", "title": "Lightweight compilation of (C)LP to JavaScript", "comments": null, "journal-ref": "Theory and Practice of Logic Programming, 12(4-5): 755-773, 2012", "doi": "10.1017/S1471068412000336", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present and evaluate a compiler from Prolog (and extensions) to JavaScript\nwhich makes it possible to use (constraint) logic programming to develop the\nclient side of web applications while being compliant with current industry\nstandards. Targeting JavaScript makes (C)LP programs executable in virtually\nevery modern computing device with no additional software requirements from the\npoint of view of the user. In turn, the use of a very high-level language\nfacilitates the development of high-quality, complex software. The compiler is\na back end of the Ciao system and supports most of its features, including its\nmodule system and its rich language extension mechanism based on packages. We\npresent an overview of the compilation process and a detailed description of\nthe run-time system, including the support for modular compilation into\nseparate JavaScript code. We demonstrate the maturity of the compiler by\ntesting it with complex code such as a CLP(FD) library written in Prolog with\nattributed variables. Finally, we validate our proposal by measuring the\nperformance of some LP and CLP(FD) benchmarks running on top of major\nJavaScript engines.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2012 10:39:03 GMT"}], "update_date": "2012-10-11", "authors_parsed": [["Morales", "Jose F.", ""], ["Haemmerl\u00e9", "R\u00e9my", ""], ["Carro", "Manuel", ""], ["Hermenegildo", "Manuel V.", ""]]}, {"id": "1210.3593", "submitter": "Ond\\v{r}ej B\\'ilka", "authors": "Ond\\v{r}ej B\\'ilka", "title": "Pattern matching in compilers", "comments": "master thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this thesis we develop tools for effective and flexible pattern matching.\nWe introduce a new pattern matching system called amethyst. Amethyst is not\nonly a generator of parsers of programming languages, but can also serve as an\nalternative to tools for matching regular expressions.\n  Our framework also produces dynamic parsers. Its intended use is in the\ncontext of IDE (accurate syntax highlighting and error detection on the fly).\nAmethyst offers pattern matching of general data structures. This makes it a\nuseful tool for implementing compiler optimizations such as constant folding,\ninstruction scheduling, and dataflow analysis in general.\n  The parsers produced are essentially top-down parsers. Linear time complexity\nis obtained by introducing the novel notion of structured grammars and\nregularized regular expressions. Amethyst uses techniques known from compiler\noptimizations to produce effective parsers.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2012 18:23:56 GMT"}], "update_date": "2012-10-15", "authors_parsed": [["B\u00edlka", "Ond\u0159ej", ""]]}, {"id": "1210.3937", "submitter": "V\\'itor Santos Costa", "authors": "Agostino Dovier, V\\'itor Santos Costa", "title": "Introduction to the 28th International Conference on Logic Programming\n  Special Issue", "comments": null, "journal-ref": "TPLP 12 (4-5): 421-426, 2012", "doi": "10.1017/S1471068412000300", "report-no": null, "categories": "cs.PL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are proud to introduce this special issue of the Journal of Theory and\nPractice of Logic Programming (TPLP), dedicated to the full papers accepted for\nthe 28th International Conference on Logic Programming (ICLP). The ICLP\nmeetings started in Marseille in 1982 and since then constitute the main venue\nfor presenting and discussing work in the area of logic programming.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2012 08:31:38 GMT"}], "update_date": "2012-10-16", "authors_parsed": [["Dovier", "Agostino", ""], ["Costa", "V\u00edtor Santos", ""]]}, {"id": "1210.4263", "submitter": "Gabriel Kerneis", "authors": "Matthieu Boutier (PPS), Gabriel Kerneis (PPS)", "title": "Generating events with style", "comments": "Submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Threads and events are two common abstractions for writing concurrent\nprograms. Because threads are often more convenient, but events more efficient,\nit is natural to want to translate the former into the latter. However, whereas\nthere are many different event-driven styles, existing translators often apply\nad-hoc rules which do not reflect this diversity. We analyse various\ncontrol-flow and data-flow encodings in real-world event-driven code, and we\nobserve that it is possible to generate any of these styles automatically from\nthreaded code, by applying certain carefully chosen classical program\ntransformations. In particular, we implement two of these transformations,\nlambda lifting and environments, in CPC, an extension of the C language for\nwriting concurrent systems. Finally, we find out that, although rarely used in\nreal-world programs because it is tedious to perform manually, lambda lifting\nyields better performance than environments in most of our benchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2012 06:35:59 GMT"}, {"version": "v2", "created": "Wed, 17 Oct 2012 13:38:02 GMT"}], "update_date": "2012-10-18", "authors_parsed": [["Boutier", "Matthieu", "", "PPS"], ["Kerneis", "Gabriel", "", "PPS"]]}, {"id": "1210.4289", "submitter": "Pierre Ganty", "authors": "Pierre Ganty, Radu Iosif, Filip Konecny", "title": "Underapproximation of Procedure Summaries for Integer Programs", "comments": "35 pages, 3 figures (this report supersedes the STTT version which in\n  turn supersedes the TACAS'13 version)", "journal-ref": null, "doi": "10.1007/s10009-016-0420-7", "report-no": null, "categories": "cs.PL cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how to underapproximate the procedure summaries of recursive programs\nover the integers using off-the-shelf analyzers for non-recursive programs. The\nnovelty of our approach is that the non-recursive program we compute may\ncapture unboundedly many behaviors of the original recursive program for which\nstack usage cannot be bounded. Moreover, we identify a class of recursive\nprograms on which our method terminates and returns the precise summary\nrelations without underapproximation. Doing so, we generalize a similar result\nfor non-recursive programs to the recursive case. Finally, we present\nexperimental results of an implementation of our method applied on a number of\nexamples.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2012 08:16:23 GMT"}, {"version": "v2", "created": "Tue, 13 May 2014 08:40:50 GMT"}, {"version": "v3", "created": "Mon, 24 Oct 2016 15:14:53 GMT"}], "update_date": "2016-10-25", "authors_parsed": [["Ganty", "Pierre", ""], ["Iosif", "Radu", ""], ["Konecny", "Filip", ""]]}, {"id": "1210.4992", "submitter": "S\\'ergio Medeiros", "authors": "S\\'ergio Medeiros, Fabio Mascarenhas and Roberto Ierusalimschy", "title": "From Regexes to Parsing Expression Grammars", "comments": null, "journal-ref": null, "doi": "10.1016/j.scico.2012.11.006", "report-no": null, "categories": "cs.FL cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most scripting languages nowadays use regex pattern-matching libraries. These\nregex libraries borrow the syntax of regular expressions, but have an informal\nsemantics that is different from the semantics of regular expressions, removing\nthe commutativity of alternation and adding ad-hoc extensions that cannot be\nexpressed by formalisms for efficient recognition of regular languages, such as\ndeterministic finite automata.\n  Parsing Expression Grammars are a formalism that can describe all\ndeterministic context-free languages and has a simple computational model. In\nthis paper, we present a formalization of regexes via transformation to Parsing\nExpression Grammars. The proposed transformation easily accommodates several of\nthe common regex extensions, giving a formal meaning to them. It also provides\na clear computational model that helps to estimate the efficiency of\nregex-based matchers, and a basis for specifying provably correct optimizations\nfor them.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2012 23:53:30 GMT"}], "update_date": "2014-02-17", "authors_parsed": [["Medeiros", "S\u00e9rgio", ""], ["Mascarenhas", "Fabio", ""], ["Ierusalimschy", "Roberto", ""]]}, {"id": "1210.5307", "submitter": "Gregory Duck", "authors": "Gregory J. Duck", "title": "SMCHR: Satisfiability Modulo Constraint Handling Rules", "comments": "International Conference on Logic Programming 2012", "journal-ref": "Theory and Practice of Logic Programming, 12(4-5):601-618, 2012", "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constraint Handling Rules (CHRs) are a high-level rule-based programming\nlanguage for specification and implementation of constraint solvers. CHR\nmanipulates a global store representing a flat conjunction of constraints. By\ndefault, CHR does not support goals with a more complex propositional structure\nincluding disjunction, negation, etc., or CHR relies on the host system to\nprovide such features. In this paper we introduce Satisfiability Modulo\nConstraint Handling Rules (SMCHR): a tight integration of CHR with a modern\nBoolean Satisfiability (SAT) solver for quantifier-free formulae with an\narbitrary propositional structure. SMCHR is essentially a Satisfiability Modulo\nTheories (SMT) solver where the theory T is implemented in CHR. The execution\nalgorithm of SMCHR is based on lazy clause generation, where a new clause for\nthe SAT solver is generated whenever a rule is applied. We shall also explore\nthe practical aspects of building an SMCHR system, including extending a\n\"built-in\" constraint solver supporting equality with unification and\njustifications.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 03:47:37 GMT"}], "update_date": "2012-10-22", "authors_parsed": [["Duck", "Gregory J.", ""]]}, {"id": "1210.5670", "submitter": "Chitta Baral", "authors": "Chitta Baral, Juraj Dzifcak, Marcos A. Gonzalez and Aaron Gottesman", "title": "Typed Answer Set Programming and Inverse Lambda Algorithms", "comments": "To appear in Theory and Practice of Logic Programming", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our broader goal is to automatically translate English sentences into\nformulas in appropriate knowledge representation languages as a step towards\nunderstanding and thus answering questions with respect to English text. Our\nfocus in this paper is on the language of Answer Set Programming (ASP). Our\napproach to translate sentences to ASP rules is inspired by Montague's use of\nlambda calculus formulas as meaning of words and phrases. With ASP as the\ntarget language the meaning of words and phrases are ASP-lambda formulas. In an\nearlier work we illustrated our approach by manually developing a dictionary of\nwords and their ASP-lambda formulas. However such an approach is not scalable.\nIn this paper our focus is on two algorithms that allow one to construct\nASP-lambda formulas in an inverse manner. In particular the two algorithms take\nas input two lambda-calculus expressions G and H and compute a lambda-calculus\nexpression F such that F with input as G, denoted by F@G, is equal to H; and\nsimilarly G@F = H. We present correctness and complexity results about these\nalgorithms. To do that we develop the notion of typed ASP-lambda calculus\ntheories and their orders and use it in developing the completeness results.\n(To appear in Theory and Practice of Logic Programming.)\n", "versions": [{"version": "v1", "created": "Sun, 21 Oct 2012 00:42:19 GMT"}], "update_date": "2012-10-23", "authors_parsed": [["Baral", "Chitta", ""], ["Dzifcak", "Juraj", ""], ["Gonzalez", "Marcos A.", ""], ["Gottesman", "Aaron", ""]]}, {"id": "1210.5935", "submitter": "Scherer Gabriel", "authors": "Gabriel Scherer (INRIA Rocquencourt), Didier R\\'emy (INRIA\n  Rocquencourt)", "title": "GADT meet Subtyping", "comments": "No. RR-8114 (2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While generalized abstract datatypes (GADT) are now considered\nwell-understood, adding them to a language with a notion of subtyping comes\nwith a few surprises. What does it mean for a GADT parameter to be covariant?\nThe answer turns out to be quite subtle. It involves fine-grained properties of\nthe subtyping relation that raise interesting design questions. We allow\nvariance annotations in GADT definitions, study their soundness, and present a\nsound and complete algorithm to check them. Our work may be applied to\nreal-world ML-like languages with explicit subtyping such as OCaml, or to\nlanguages with general subtyping constraints.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2012 15:36:56 GMT"}], "update_date": "2012-10-23", "authors_parsed": [["Scherer", "Gabriel", "", "INRIA Rocquencourt"], ["R\u00e9my", "Didier", "", "INRIA\n  Rocquencourt"]]}, {"id": "1210.5974", "submitter": "Hector Castillo-Andreu", "authors": "H\\'ector Castillo-Andreu", "title": "An MML-based tool for evaluating the complexity of (stochastic) logic\n  theories", "comments": "MsC Thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Theory evaluation is a key problem in many areas: machine learning,\nscientific discovery, inverse engineering, decision making, software\nengineering, design, human sciences, etc. If we have a set of theories that are\nable to explain the same set of phenomena, we need a criterion to choose which\none is best. There are, of course, many possible criteria. Model simplicity is\none of the most common criteria in theory evaluation. The Minimum Message\nLength (MML) is a solid approach to evaluate theories relative to a given\nevidence or data. Theories can be expressed in specific or general\n(Turing-complete) languages. First-order logic, and logic programming in\nparticular, is a Turing-complete language. Evaluating the simplicity of a\ntheory or program described in a Turing-complete language is much more\ndifficult than just counting the number of lines or bits. It is, in fact, the\nproblem of calculating its Kolmogorov complexity, which is uncomputable. Few\nworks in the literature have been able to present accurate and effective\napproximations for a Turing-complete language. In this work, we present the\nfirst general MML coding scheme for logic programs. With this scheme, we can\nquantify the bits of information required to code (or send) a theory, a set of\ndata or the same data given the theory. As a realization of the above-mentioned\nschemes, we present a software tool which is able to code and evaluate a set of\nalternative (stochastic) theories (programs) against a set of examples. We\nillustrate the application of the tool to a variety of non-probabilistic and\nprobabilistic scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2012 17:20:25 GMT"}, {"version": "v2", "created": "Tue, 23 Oct 2012 17:02:22 GMT"}], "update_date": "2013-01-23", "authors_parsed": [["Castillo-Andreu", "H\u00e9ctor", ""]]}, {"id": "1210.6112", "submitter": "EPTCS", "authors": "James Smith", "title": "The Jasper Framework: Towards a Platform Independent, Formal Treatment\n  of Web Programming", "comments": "In Proceedings WWV 2012, arXiv:1210.5783. Added doi references where\n  possible", "journal-ref": "EPTCS 98, 2012, pp. 31-45", "doi": "10.4204/EPTCS.98.5", "report-no": null, "categories": "cs.SE cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces Jasper, a web programming framework which allows web\napplications to be developed in an essentially platform indepedent manner and\nwhich is also suited to a formal treatment. It outlines Jasper conceptually and\nshows how Jasper is implemented on several commonplace platforms. It also\nintroduces the Jasper Music Store, a web application powered by Jasper and\nimplemented on each of these platforms. And it briefly describes a formal\ntreatment and outlines the tools and languages planned that will allow this\ntreatment to be automated.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2012 02:54:58 GMT"}], "update_date": "2012-12-07", "authors_parsed": [["Smith", "James", ""]]}, {"id": "1210.6114", "submitter": "EPTCS", "authors": "Jonathan Michaux (T\\'el\\'ecom ParisTech), Elie Najm (T\\'el\\'ecom\n  ParisTech), Alessandro Fantechi (Universit\\`a degli Studi di Firenze)", "title": "Adding Sessions to BPEL", "comments": "In Proceedings WWV 2012, arXiv:1210.5783", "journal-ref": "EPTCS 98, 2012, pp. 60-76", "doi": "10.4204/EPTCS.98.7", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By considering an essential subset of the BPEL orchestration language, we\ndefine SeB, a session based style of this subset. We discuss the formal\nsemantics of SeB and we present its main properties. We use a new approach to\naddress the formal semantics, based on a translation into so-called control\ngraphs. Our semantics handles control links and addresses the static semantics\nthat prescribes the valid usage of variables. We also provide the semantics of\ncollections of networked services.\n  Relying on these semantics, we define precisely what is meant by interaction\nsafety, paving the way to the formal analysis of safe interactions between BPEL\nservices.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2012 02:55:15 GMT"}], "update_date": "2012-10-24", "authors_parsed": [["Michaux", "Jonathan", "", "T\u00e9l\u00e9com ParisTech"], ["Najm", "Elie", "", "T\u00e9l\u00e9com\n  ParisTech"], ["Fantechi", "Alessandro", "", "Universit\u00e0 degli Studi di Firenze"]]}, {"id": "1210.6284", "submitter": "Paolo Giosu\\'e Giarrusso", "authors": "Paolo G. Giarrusso, Klaus Ostermann, Michael Eichberg, Ralf Mitschke,\n  Tillmann Rendel, Christian K\\\"astner", "title": "Reify Your Collection Queries for Modularity and Speed!", "comments": "20 pages", "journal-ref": "Proceedings of the 12th annual international conference on\n  Aspect-oriented software development (AOSD '13), 2013. ACM, New York, NY,\n  USA, 1-12", "doi": "10.1145/2451436.2451438", "report-no": null, "categories": "cs.PL cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modularity and efficiency are often contradicting requirements, such that\nprogramers have to trade one for the other. We analyze this dilemma in the\ncontext of programs operating on collections. Performance-critical code using\ncollections need often to be hand-optimized, leading to non-modular, brittle,\nand redundant code. In principle, this dilemma could be avoided by automatic\ncollection-specific optimizations, such as fusion of collection traversals,\nusage of indexing, or reordering of filters. Unfortunately, it is not obvious\nhow to encode such optimizations in terms of ordinary collection APIs, because\nthe program operating on the collections is not reified and hence cannot be\nanalyzed.\n  We propose SQuOpt, the Scala Query Optimizer--a deep embedding of the Scala\ncollections API that allows such analyses and optimizations to be defined and\nexecuted within Scala, without relying on external tools or compiler\nextensions. SQuOpt provides the same \"look and feel\" (syntax and static typing\nguarantees) as the standard collections API. We evaluate SQuOpt by\nre-implementing several code analyses of the Findbugs tool using SQuOpt, show\naverage speedups of 12x with a maximum of 12800x and hence demonstrate that\nSQuOpt can reconcile modularity and efficiency in real-world applications.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2012 16:32:13 GMT"}], "update_date": "2013-12-03", "authors_parsed": [["Giarrusso", "Paolo G.", ""], ["Ostermann", "Klaus", ""], ["Eichberg", "Michael", ""], ["Mitschke", "Ralf", ""], ["Rendel", "Tillmann", ""], ["K\u00e4stner", "Christian", ""]]}, {"id": "1210.6379", "submitter": "Mario Bravetti", "authors": "Mario Bravetti (University of Bologna), Cinzia Di Giusto (INRIA Rhone\n  Alpes), Jorge A Perez (FCT New University of Lisbon), Gianluigi Zavattaro\n  (University of Bologna)", "title": "Adaptable processes", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 8, Issue 4 (November\n  19, 2012) lmcs:982", "doi": "10.2168/LMCS-8(4:13)2012", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the concept of adaptable processes as a way of overcoming the\nlimitations that process calculi have for describing patterns of dynamic\nprocess evolution. Such patterns rely on direct ways of controlling the\nbehavior and location of running processes, and so they are at the heart of the\nadaptation capabilities present in many modern concurrent systems. Adaptable\nprocesses have a location and are sensible to actions of dynamic update at\nruntime; this allows to express a wide range of evolvability patterns for\nconcurrent processes. We introduce a core calculus of adaptable processes and\npropose two verification problems for them: bounded and eventual adaptation.\nWhile the former ensures that the number of consecutive erroneous states that\ncan be traversed during a computation is bound by some given number k, the\nlatter ensures that if the system enters into a state with errors then a state\nwithout errors will be eventually reached. We study the (un)decidability of\nthese two problems in several variants of the calculus, which result from\nconsidering dynamic and static topologies of adaptable processes as well as\ndifferent evolvability patterns. Rather than a specification language, our\ncalculus intends to be a basis for investigating the fundamental properties of\nevolvable processes and for developing richer languages with evolvability\ncapabilities.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2012 21:00:05 GMT"}, {"version": "v2", "created": "Fri, 16 Nov 2012 01:35:49 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Bravetti", "Mario", "", "University of Bologna"], ["Di Giusto", "Cinzia", "", "INRIA Rhone\n  Alpes"], ["Perez", "Jorge A", "", "FCT New University of Lisbon"], ["Zavattaro", "Gianluigi", "", "University of Bologna"]]}, {"id": "1210.6390", "submitter": "Pierre-Evariste Dagand", "authors": "Pierre-Evariste Dagand and Conor McBride", "title": "Elaborating Inductive Definitions", "comments": "32 pages, technical report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an elaboration of inductive definitions down to a universe of\ndatatypes. The universe of datatypes is an internal presentation of strictly\npositive families within type theory. By elaborating an inductive definition --\na syntactic artifact -- to its code -- its semantics -- we obtain an\ninternalized account of inductives inside the type theory itself: we claim that\nreasoning about inductive definitions could be carried in the type theory, not\nin the meta-theory as it is usually the case. Besides, we give a formal\nspecification of that elaboration process. It is therefore amenable to formal\nreasoning too. We prove the soundness of our translation and hint at its\ncorrectness with respect to Coq's Inductive definitions.\n  The practical benefits of this approach are numerous. For the type theorist,\nthis is a small step toward bootstrapping, ie. implementing the inductive\nfragment in the type theory itself. For the programmer, this means better\nsupport for generic programming: we shall present a lightweight deriving\nmechanism, entirely definable by the programmer and therefore not requiring any\nextension to the type theory.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2012 21:47:21 GMT"}, {"version": "v2", "created": "Tue, 30 Oct 2012 22:01:16 GMT"}], "update_date": "2012-11-01", "authors_parsed": [["Dagand", "Pierre-Evariste", ""], ["McBride", "Conor", ""]]}, {"id": "1210.6857", "submitter": "Ugo Dal Lago", "authors": "Ugo Dal Lago and Barbara Petit", "title": "The Geometry of Types (Long Version)", "comments": "27 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that time complexity analysis of higher-order functional programs can\nbe effectively reduced to an arguably simpler (although computationally\nequivalent) verification problem, namely checking first-order inequalities for\nvalidity. This is done by giving an efficient inference algorithm for linear\ndependent types which, given a PCF term, produces in output both a linear\ndependent type and a cost expression for the term, together with a set of proof\nobligations. Actually, the output type judgement is derivable iff all proof\nobligations are valid. This, coupled with the already known relative\ncompleteness of linear dependent types, ensures that no information is lost,\ni.e., that there are no false positives or negatives. Moreover, the procedure\nreflects the difficulty of the original problem: simple PCF terms give rise to\nsets of proof obligations which are easy to solve. The latter can then be put\nin a format suitable for automatic or semi-automatic verification by external\nsolvers. Ongoing experimental evaluation has produced encouraging results,\nwhich are briefly presented in the paper.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2012 14:40:48 GMT"}], "update_date": "2012-10-26", "authors_parsed": [["Lago", "Ugo Dal", ""], ["Petit", "Barbara", ""]]}, {"id": "1210.7774", "submitter": "Mads Kristensen", "authors": "Mads Ruben Burgdorff Kristensen, Simon Andreas Frimann Lund, Troels\n  Blum, Brian Vinter", "title": "cphVB: A System for Automated Runtime Optimization and Parallelization\n  of Vectorized Applications", "comments": null, "journal-ref": "Proceedings of The 11th Python In Science Conference (SciPy 2012)", "doi": null, "report-no": null, "categories": "cs.PL cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern processor architectures, in addition to having still more cores, also\nrequire still more consideration to memory-layout in order to run at full\ncapacity. The usefulness of most languages is deprecating as their\nabstractions, structures or objects are hard to map onto modern processor\narchitectures efficiently.\n  The work in this paper introduces a new abstract machine framework, cphVB,\nthat enables vector oriented high-level programming languages to map onto a\nbroad range of architectures efficiently. The idea is to close the gap between\nhigh-level languages and hardware optimized low-level implementations. By\ntranslating high-level vector operations into an intermediate vector bytecode,\ncphVB enables specialized vector engines to efficiently execute the vector\noperations.\n  The primary success parameters are to maintain a complete abstraction from\nlow-level details and to provide efficient code execution across different,\nmodern, processors. We evaluate the presented design through a setup that\ntargets multi-core CPU architectures. We evaluate the performance of the\nimplementation using Python implementations of well-known algorithms: a jacobi\nsolver, a kNN search, a shallow water simulation and a synthetic stencil\nsimulation. All demonstrate good performance.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2012 12:03:08 GMT"}, {"version": "v2", "created": "Mon, 25 Mar 2013 15:18:56 GMT"}], "update_date": "2013-03-26", "authors_parsed": [["Kristensen", "Mads Ruben Burgdorff", ""], ["Lund", "Simon Andreas Frimann", ""], ["Blum", "Troels", ""], ["Vinter", "Brian", ""]]}]