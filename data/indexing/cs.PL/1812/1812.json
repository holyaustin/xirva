[{"id": "1812.00089", "submitter": "In-Ho Yi", "authors": "In-Ho Yi", "title": "Parametric Denotational Semantics for Extensible Language Definition and\n  Program Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We present a novel approach to construction of a formal semantics for a\nprogramming language. Our approach, using a parametric denotational semantics,\nallows the semantics to be easily extended to support new language features,\nand abstracted to define program analyses. We apply this in analysing a\nduck-typed, reflective, curried dynamic language. The benefits of this approach\ninclude its terseness and modularity, and the ease with which one can gradually\nbuild language features and analyses on top of a previous incarnation of a\nsemantics.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 23:04:37 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Yi", "In-Ho", ""]]}, {"id": "1812.00619", "submitter": "Evgeniy Shishkin", "authors": "Evgeniy Shishkin", "title": "Debugging Smart Contract's Business Logic Using Symbolic Model-Checking", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CR cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smart contracts are a special type of programs running inside a blockchain.\nImmutable and transparent, they provide means to implement fault-tolerant and\ncensorship-resistant services. Unfortunately, its immutability causes a serious\nchallenge of ensuring that a business logic and implementation is correct\nupfront, before publishing in a blockchain. Several big accidents have indeed\nshown that users of this technology need special tools to verify smart contract\ncorrectness. Existing automated checkers are able to detect only well known\nimplementation bugs, leaving the question of business logic correctness far\naside. In this work, we present a symbolic model-checking technique along with\na formal specification method for a subset of Solidity programming language\nthat is able to express both state properties and trace properties; the latter\nconstitutes a weak analogy of temporal properties. We evaluate the proposed\ntechnique on the MiniDAO smart contract, a young brother of notorious TheDAO.\nOur Proof-of-Concept was able to detect a non-trivial error in the business\nlogic of this smart contract in a few seconds.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 09:25:22 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Shishkin", "Evgeniy", ""]]}, {"id": "1812.00992", "submitter": "Irene C\\'ordoba", "authors": "Irene C\\'ordoba, Juan de Lara", "title": "Ann: A domain-specific language for the effective design and validation\n  of Java annotations", "comments": "45 pages, 14 figures, 2016 journal publication. arXiv admin note:\n  text overlap with arXiv:1807.03566", "journal-ref": "Computer Languages, Systems and Structures, 45:164-190, 2016", "doi": "10.1016/j.cl.2016.02.002", "report-no": null, "categories": "cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a new modelling language for the effective design and\nvalidation of Java annotations. Since their inclusion in the 5th edition of\nJava, annotations have grown from a useful tool for the addition of meta-data\nto play a central role in many popular software projects. Usually they are not\nconceived in isolation, but in groups, with dependency and integrity\nconstraints between them. However, the native support provided by Java for\nexpressing this design is very limited.\n  To overcome its deficiencies and make explicit the rich conceptual model\nwhich lies behind a set of annotations, we propose a domain-specific modelling\nlanguage. The proposal has been implemented as an Eclipse plug-in, including an\neditor and an integrated code generator that synthesises annotation processors.\nThe environment also integrates a model finder, able to detect unsatisfiable\nconstraints between different annotations, and to provide examples of correct\nannotation usages for validation. The language has been tested using a real set\nof annotations from the Java Persistence API (JPA). Within this subset we have\nfound enough rich semantics expressible with Ann and omitted nowadays by the\nJava language, which shows the benefits of Ann in a relevant field of\napplication.\n", "versions": [{"version": "v1", "created": "Sun, 2 Dec 2018 15:53:24 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["C\u00f3rdoba", "Irene", ""], ["de Lara", "Juan", ""]]}, {"id": "1812.01069", "submitter": "Sharon Shoham Buchbinder", "authors": "Sharon Shoham", "title": "Undecidability of Inferring Linear Integer Invariants", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the problem of determining the existence of an inductive\ninvariant in the language of quantifier free linear integer arithmetic (QFLIA)\nis undecidable, even for transition systems and safety properties expressed in\nQFLIA.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 20:26:55 GMT"}, {"version": "v2", "created": "Thu, 6 Dec 2018 21:03:30 GMT"}], "update_date": "2018-12-10", "authors_parsed": [["Shoham", "Sharon", ""]]}, {"id": "1812.01099", "submitter": "Polina Lemenkova", "authors": "Polina Lemenkova", "title": "R scripting libraries for comparative analysis of the correlation\n  methods to identify factors affecting Mariana Trench formation", "comments": "8 pages; 11 figures", "journal-ref": "Journal of Marine Technology and Environment 2 (2018) 35-42", "doi": "10.6084/m9.figshare.7434167.v1", "report-no": null, "categories": "physics.geo-ph cs.PL", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Mariana trench is the deepest place on the Earth. It crosses four tectonic\nplates of the Pacific Ocean: Mariana, Caroline, Pacific and Philippine. The\nformation of the trench is caused by the complex interconnection of various\nenvironmental factors. The aim of this study was to describe and characterize\nvarious impact factors affecting formation of the Mariana trench geomorphology\nand continental margin environments using R programming language and\nmathematical algorithms of correlation methods written on R code. To record the\nsystem of geological, tectonic, geographic, oceanological and bathymetric\nfeatures affecting Mariana trench , a combination of statistical methods, GIS\nand R programming codes were applied. The questions answered are as follows:\nwhich factors are the most influencing for the Mariana trench morphology, and\nto what extend do they affect its development? Is sedimental thickness of the\nocean trench basement more important factors for the trench formation comparing\nto the steepness slope angle and aspect degree? Three methods of computing were\ntested: Pearson correlation, Spearman correlation, Kendall correlation,\nnumerical correlogram, correlation matrix and cross-correlatios to analyze\nenvironmental impact factors. The correlogram matrices are computed and\nvisualized by R scripting libraries. Complex usage of programming tools,\nmathematical statistics and geospatial analysis enabled to get a differentiated\nunderstandings of the hadal environments of the Mariana trench. The results\nrevealed following three types of factors having the highest score: geometric\n(tg{\\deg} slope angle), geologic (sedimental thickness) and tectonic structure.\nThe results furthermore indicated that tectonic plates, sedimental thickness of\nthe trench basement and igneous volcanic areas causing earthquakes play the\nmost essential role in the geomorphology of the trench.\n", "versions": [{"version": "v1", "created": "Sun, 18 Nov 2018 05:56:49 GMT"}], "update_date": "2018-12-10", "authors_parsed": [["Lemenkova", "Polina", ""]]}, {"id": "1812.01329", "submitter": "Eunji Jeong", "authors": "Eunji Jeong, Sungwoo Cho, Gyeong-In Yu, Joo Seong Jeong, Dong-Jin\n  Shin, Byung-Gon Chun", "title": "JANUS: Fast and Flexible Deep Learning via Symbolic Graph Execution of\n  Imperative Programs", "comments": "Appeared in NSDI 2019", "journal-ref": "16th USENIX Symposium on Networked Systems Design and\n  Implementation (NSDI 2019)", "doi": null, "report-no": null, "categories": "cs.PL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid evolution of deep neural networks is demanding deep learning (DL)\nframeworks not only to satisfy the requirement of quickly executing large\ncomputations, but also to support straightforward programming models for\nquickly implementing and experimenting with complex network structures.\nHowever, existing frameworks fail to excel in both departments simultaneously,\nleading to diverged efforts for optimizing performance and improving usability.\n  This paper presents JANUS, a system that combines the advantages from both\nsides by transparently converting an imperative DL program written in Python,\nthe de-facto scripting language for DL, into an efficiently executable symbolic\ndataflow graph. JANUS can convert various dynamic features of Python, including\ndynamic control flow, dynamic types, and impure functions, into elements of a\nsymbolic dataflow graph. Experiments demonstrate that JANUS can achieve fast DL\ntraining by exploiting the techniques imposed by symbolic graph-based DL\nframeworks, while maintaining the simple and flexible programmability of\nimperative DL frameworks at the same time.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 10:59:12 GMT"}, {"version": "v2", "created": "Mon, 11 Mar 2019 08:05:55 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Jeong", "Eunji", ""], ["Cho", "Sungwoo", ""], ["Yu", "Gyeong-In", ""], ["Jeong", "Joo Seong", ""], ["Shin", "Dong-Jin", ""], ["Chun", "Byung-Gon", ""]]}, {"id": "1812.02243", "submitter": "Antoine Amarilli", "authors": "Henk P. Barendregt", "title": "Gems of Corrado B\\\"ohm", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 16, Issue 3 (September\n  2, 2020) lmcs:6755", "doi": "10.23638/LMCS-16(3:15)2020", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The main scientific heritage of Corrado B\\\"ohm consists of ideas about\ncomputing, concerning concrete algorithms, as well as models of computability.\nThe following will be presented. 1. A compiler that can compile itself. 2.\nStructured programming, eliminating the 'goto' statement. 3. Functional\nprogramming and an early implementation. 4. Separability in {\\lambda}-calculus.\n5. Compiling combinators without parsing. 6. Self-evaluation in\n{\\lambda}-calculus.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2018 21:56:23 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 12:18:52 GMT"}, {"version": "v3", "created": "Wed, 5 Aug 2020 20:32:59 GMT"}, {"version": "v4", "created": "Thu, 27 Aug 2020 12:02:48 GMT"}, {"version": "v5", "created": "Mon, 31 Aug 2020 18:31:54 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Barendregt", "Henk P.", ""]]}, {"id": "1812.02989", "submitter": "Matthew Hague", "authors": "Matthew Hague and Anthony W. Lin and Chih-Duo Hong", "title": "CSS Minification via Constraint Solving (Technical Report)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Minification is a widely-accepted technique which aims at reducing the size\nof the code transmitted over the web. We study the problem of minifying\nCascading Style Sheets (CSS) --- the de facto language for styling web\ndocuments. Traditionally, CSS minifiers focus on simple syntactic\ntransformations (e.g. shortening colour names). In this paper, we propose a new\nminification method based on merging similar rules in a CSS file.\n  We consider safe transformations of CSS files, which preserve the semantics\nof the CSS file. The semantics of CSS files are sensitive to the ordering of\nrules in the file. To automatically identify a rule merging opportunity that\nbest minimises file size, we reduce the rule-merging problem to a problem on\nCSS-graphs, i.e., node-weighted bipartite graphs with a dependency ordering on\nthe edges, where weights capture the number of characters (e.g. in a selector\nor in a property declaration). Roughly speaking, the corresponding CSS-graph\nproblem concerns minimising the total weight of a sequence of bicliques\n(complete bipartite subgraphs) that covers the CSS-graph and respects the edge\norder.\n  We provide the first full formalisation of CSS3 selectors and reduce\ndependency detection to satisfiability of quantifier-free integer linear\narithmetic, for which highly-optimised SMT-solvers are available. To solve the\nabove NP-hard graph optimisation problem, we show how Max-SAT solvers can be\neffectively employed. We have implemented our algorithms using Max-SAT and\nSMT-solvers as backends, and tested against approximately 70 real-world\nexamples (including the top 20 most popular websites). In our benchmarks, our\ntool yields larger savings than six well-known minifiers (which do not perform\nrule-merging, but support many other optimisations). Our experiments also\nsuggest that better savings can be achieved in combination with one of these\nsix minifiers.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2018 11:54:13 GMT"}], "update_date": "2018-12-12", "authors_parsed": [["Hague", "Matthew", ""], ["Lin", "Anthony W.", ""], ["Hong", "Chih-Duo", ""]]}, {"id": "1812.03571", "submitter": "Ambrose Bonnaire-Sergeant", "authors": "Ambrose Bonnaire-Sergeant, Rowan Davies, Sam Tobin-Hochstadt", "title": "Practical Optional Types for Clojure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Typed Clojure is an optional type system for Clojure, a dynamic language in\nthe Lisp family that targets the JVM. Typed Clojure enables Clojure programmers\nto gain greater confidence in the correctness of their code via static type\nchecking while remaining in the Clojure world, and has acquired significant\nadoption in the Clojure community. Typed Clojure repurposes Typed Racket's\noccurrence typing, an approach to statically reasoning about predicate tests,\nand also includes several new type system features to handle existing Clojure\nidioms. In this paper, we describe Typed Clojure and present these type system\nextensions, focusing on three features widely used in Clojure. First,\nmultimethods provide extensible operations, and their Clojure semantics turns\nout to have a surprising synergy with the underlying occurrence typing\nframework. Second, Java interoperability is central to Clojure's mission but\nintroduces challenges such as ubiquitous null; Typed Clojure handles Java\ninteroperability while ensuring the absence of null-pointer exceptions in typed\nprograms. Third, Clojure programmers idiomatically use immutable dictionaries\nfor data structures; Typed Clojure handles this with multiple forms of\nheterogeneous dictionary types. We provide a formal model of the Typed Clojure\ntype system incorporating these and other features, with a proof of soundness.\nAdditionally, Typed Clojure is now in use by numerous corporations and\ndevelopers working with Clojure, and we present a quantitative analysis on the\nuse of type system features in two substantial code bases.\n", "versions": [{"version": "v1", "created": "Sun, 9 Dec 2018 22:57:04 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Bonnaire-Sergeant", "Ambrose", ""], ["Davies", "Rowan", ""], ["Tobin-Hochstadt", "Sam", ""]]}, {"id": "1812.03624", "submitter": "Amy Felty", "authors": "Mohamed Yousri Mahmoud and Amy P. Felty", "title": "Formalization of Metatheory of the Quipper Quantum Programming Language\n  in a Linear Logic", "comments": "40 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a linear logical framework within the Hybrid system and use it to\nreason about the type system of a quantum lambda calculus. In particular, we\nconsider a practical version of the calculus called Proto-Quipper, which\ncontains the core of Quipper. Quipper is a new quantum programming language\nunder active development and recently has gained much popularity among the\nquantum computing communities. Hybrid is a system that is designed to support\nthe use of higher-order abstract syntax (HOAS) for representing and reasoning\nabout formal systems implemented in the Coq Proof Assistant. In this work, we\nextend the system with a linear specification logic (SL) in order to reason\nabout the linear type system of Quipper. To this end, we formalize the\nsemantics of Proto-Quipper by encoding the typing and evaluation rules in the\nSL, and prove type soundness.\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2018 05:10:13 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Mahmoud", "Mohamed Yousri", ""], ["Felty", "Amy P.", ""]]}, {"id": "1812.03973", "submitter": "Dustin Tran", "authors": "Dustin Tran and Michael W. Dusenberry and Mark van der Wilk and\n  Danijar Hafner", "title": "Bayesian Layers: A Module for Neural Network Uncertainty", "comments": "Code available at https://github.com/tensorflow/tensor2tensor", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe Bayesian Layers, a module designed for fast experimentation with\nneural network uncertainty. It extends neural network libraries with drop-in\nreplacements for common layers. This enables composition via a unified\nabstraction over deterministic and stochastic functions and allows for\nscalability via the underlying system. These layers capture uncertainty over\nweights (Bayesian neural nets), pre-activation units (dropout), activations\n(\"stochastic output layers\"), or the function itself (Gaussian processes). They\ncan also be reversible to propagate uncertainty from input to output. We\ninclude code examples for common architectures such as Bayesian LSTMs, deep\nGPs, and flow-based models. As demonstration, we fit a 5-billion parameter\n\"Bayesian Transformer\" on 512 TPUv2 cores for uncertainty in machine\ntranslation and a Bayesian dynamics model for model-based planning. Finally, we\nshow how Bayesian Layers can be used within the Edward2 probabilistic\nprogramming language for probabilistic programs with stochastic processes.\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2018 18:46:21 GMT"}, {"version": "v2", "created": "Tue, 11 Dec 2018 20:05:54 GMT"}, {"version": "v3", "created": "Tue, 5 Mar 2019 23:11:16 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Tran", "Dustin", ""], ["Dusenberry", "Michael W.", ""], ["van der Wilk", "Mark", ""], ["Hafner", "Danijar", ""]]}, {"id": "1812.03992", "submitter": "Yuka Takahashi", "authors": "Yuka Takahashi (1 and 2), Vassil Vassilev (1), Oksana Shadura (3),\n  Raphael Isemann (2 and 4) ((1) Princeton University (2) CERN (3) University\n  of Nebraska Lincoln (4) Chalmers University of Technology)", "title": "Optimizing Frameworks Performance Using C++ Modules Aware ROOT", "comments": "8 pages, 3 figures, 6 listing, CHEP 2018 - 23rd International\n  Conference on Computing in High Energy and Nuclear Physics", "journal-ref": null, "doi": "10.1051/epjconf/201921402011", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ROOT is a data analysis framework broadly used in and outside of High Energy\nPhysics (HEP). Since HEP software frameworks always strive for performance\nimprovements, ROOT was extended with experimental support of runtime C++\nModules. C++ Modules are designed to improve the performance of C++ code\nparsing. C++ Modules offers a promising way to improve ROOT's runtime\nperformance by saving the C++ header parsing time which happens during ROOT\nruntime. This paper presents the results and challenges of integrating C++\nModules into ROOT.\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2018 12:52:09 GMT"}, {"version": "v2", "created": "Fri, 17 May 2019 06:13:02 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Takahashi", "Yuka", "", "1 and 2"], ["Vassilev", "Vassil", "", "2 and 4"], ["Shadura", "Oksana", "", "2 and 4"], ["Isemann", "Raphael", "", "2 and 4"]]}, {"id": "1812.04077", "submitter": "Michel Kinsy", "authors": "Mihailo Isakov and Michel A. Kinsy", "title": "BRISC-V Emulator: A Standalone, Installation-Free, Browser-Based\n  Teaching Tool", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many computer organization and computer architecture classes have recently\nstarted adopting the RISC-V architecture as an alternative to proprietary RISC\nISAs and architectures. Emulators are a common teaching tool used to introduce\nstudents to writing assembly. We present the BRISC-V (Boston University RISC-V)\nEmulator and teaching tool, a RISC-V emulator inspired by existing RISC and\nCISC emulators. The emulator is a web-based, pure javascript implementation\nmeant to simplify deployment, as it does not require maintaining support for\ndifferent operating systems or any installation. Here we present the workings,\nusage, and extensibility of the BRISC-V emulator.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2018 02:49:49 GMT"}], "update_date": "2018-12-12", "authors_parsed": [["Isakov", "Mihailo", ""], ["Kinsy", "Michel A.", ""]]}, {"id": "1812.04090", "submitter": "Weihao Qu", "authors": "Weihao Qu, Marco Gaboardi and Deepak Garg", "title": "Relational Cost Analysis for Functional-Imperative Programs", "comments": "14 pages", "journal-ref": null, "doi": "10.1145/3341696", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Relational cost analysis aims at formally establishing bounds on the\ndifference in the evaluation costs of two programs. As a particular case, one\ncan also use relational cost analysis to establish bounds on the difference in\nthe evaluation cost of the same program on two different inputs. One way to\nperform relational cost analysis is to use a relational type-and-effect system\nthat supports reasoning about relations between two executions of two programs.\n  Building on this basic idea, we present a type-and-effect system, called\nARel, for reasoning about the relative cost of array-manipulating, higher-order\nfunctional-imperative programs. The key ingredient of our approach is a new\nlightweight type refinement discipline that we use to track relations\n(differences) between two arrays. This discipline combined with Hoare-style\ntriples built into the types allows us to express and establish precise\nrelative costs of several interesting programs which imperatively update their\ndata.\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2018 21:09:47 GMT"}, {"version": "v2", "created": "Tue, 24 Sep 2019 18:24:28 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Qu", "Weihao", ""], ["Gaboardi", "Marco", ""], ["Garg", "Deepak", ""]]}, {"id": "1812.04125", "submitter": "Martin Hirzel", "authors": "Guillaume Baudart, Martin Hirzel, Kiran Kate, Louis Mandel, Avraham\n  Shinnar", "title": "Yaps: Python Frontend to Stan", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stan is a popular probabilistic programming language with a self-contained\nsyntax and semantics that is close to graphical models. Unfortunately, existing\nembeddings of Stan in Python use multi-line strings. That approach forces users\nto switch between two different language styles, with no support for syntax\nhighlighting or simple error reporting within the Stan code. This paper tackles\nthe question of whether Stan could use Python syntax while retaining its\nself-contained semantics. The answer is yes, that can be accomplished by\nreinterpreting the Python syntax. This paper introduces Yaps, a new frontend to\nStan based on reinterpreted Python. We tested Yaps on over a thousand Stan\nmodels and made it available open-source.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 01:24:29 GMT"}], "update_date": "2018-12-12", "authors_parsed": [["Baudart", "Guillaume", ""], ["Hirzel", "Martin", ""], ["Kate", "Kiran", ""], ["Mandel", "Louis", ""], ["Shinnar", "Avraham", ""]]}, {"id": "1812.04562", "submitter": "Alexander Lavin", "authors": "Alexander Lavin", "title": "Doubly Bayesian Optimization", "comments": "conflict of interest", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic programming systems enable users to encode model structure and\nnaturally reason about uncertainties, which can be leveraged towards improved\nBayesian optimization (BO) methods. Here we present a probabilistic program\nembedding of BO that is capable of addressing main issues such as problematic\ndomains (noisy, non-smooth, high-dimensional) and the neglected\ninner-optimization. Not only can we utilize programmable structure to\nincorporate domain knowledge to aid optimization, but dealing with\nuncertainties and implementing advanced BO techniques become trivial, crucial\nfor use in practice (particularly for non-experts). We demonstrate the efficacy\nof the approach on optimization benchmarks and a real-world drug development\nscenario.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2018 17:38:52 GMT"}, {"version": "v2", "created": "Thu, 13 Dec 2018 20:31:47 GMT"}, {"version": "v3", "created": "Fri, 1 Feb 2019 20:07:08 GMT"}, {"version": "v4", "created": "Tue, 5 Feb 2019 01:39:37 GMT"}], "update_date": "2019-02-06", "authors_parsed": [["Lavin", "Alexander", ""]]}, {"id": "1812.04905", "submitter": "Frederic Bour", "authors": "Fr\\'ed\\'eric Bour", "title": "CAMLroot: revisiting the OCaml FFI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The OCaml language comes with a facility for interfacing with C code -- the\nForeign Function Interface or FFI. The primitives for working with the OCaml\nruntime -- and, in particular, with the garbage collector (GC) -- strive for a\nminimal overhead: they avoid unnecessary work and allow for calls to C code to\nbe very cheap. But they are also hard to use properly. Satisfying the GC\ninvariants leads to counter-intuitive C code and there are hardly any safety\nchecks to warn the developer. In this work, we explore two complementary\napproaches to mitigate these issues. First, simply adding an indirection to the\nAPI manipulating OCaml values let us write safer code amenable to optional\nruntime tests that assert proper use of the API. Second, a notion of region for\ntracking lifetimes of OCaml values on C side let us trade some performance for\nsimpler code.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2018 11:37:02 GMT"}, {"version": "v2", "created": "Fri, 26 Apr 2019 13:52:54 GMT"}], "update_date": "2019-04-29", "authors_parsed": [["Bour", "Fr\u00e9d\u00e9ric", ""]]}, {"id": "1812.05067", "submitter": "Weihao Qu", "authors": "Ezgi \\c{C}i\\c{c}ek, Weihao Qu, Gilles Barthe, Marco Gaboardi and\n  Deepak Garg", "title": "Bidirectional Type Checking for Relational Properties", "comments": "14 pages", "journal-ref": null, "doi": "10.1145/3314221.3314603", "report-no": null, "categories": "cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Relational type systems have been designed for several applications including\ninformation flow, differential privacy, and cost analysis. In order to achieve\nthe best results, these systems often use relational refinements and relational\neffects to maximally exploit the similarity in the structure of the two\nprograms being compared. Relational type systems are appealing for relational\nproperties because they deliver simpler and more precise verification than what\ncould be derived from typing the two programs separately. However, relational\ntype systems do not yet achieve the practical appeal of their non-relational\ncounterpart, in part because of the lack of a general foundations for\nimplementing them.\n  In this paper, we take a step in this direction by developing bidirectional\nrelational type checking for systems with relational refinements and effects.\nOur approach achieves the benefits of bidirectional type checking, in a\nrelational setting. In particular, it significantly reduces the need for typing\nannotations through the combination of type checking and type inference. In\norder to highlight the foundational nature of our approach, we develop\nbidirectional versions of several relational type systems which incrementally\ncombine many different components needed for expressive relational analysis.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2018 18:05:45 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["\u00c7i\u00e7ek", "Ezgi", ""], ["Qu", "Weihao", ""], ["Barthe", "Gilles", ""], ["Gaboardi", "Marco", ""], ["Garg", "Deepak", ""]]}, {"id": "1812.05878", "submitter": "Kieran Clenaghan", "authors": "Kieran Clenaghan", "title": "In Praise of Sequence (Co-)Algebra and its implementation in Haskell", "comments": "43 pages. Work commenced when the author was a visitor at the\n  University of York", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.DM cs.PL cs.SC math.HO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What is Sequence Algebra? This is a question that any teacher or student of\nmathematics or computer science can engage with. Sequences are in Calculus,\nCombinatorics, Statistics and Computation. They are foundational, a step up\nfrom number arithmetic. Sequence operations are easy to implement from scratch\n(in Haskell) and afford a wide variety of testing and experimentation. When\nbits and pieces of sequence algebra are pulled together from the literature,\nthere emerges a claim for status as a substantial pre-analysis topic. Here we\nset the stage by bringing together a variety of sequence algebra concepts for\nthe first time in one paper. This provides a novel economical overview,\nintended to invite a broad mathematical audience to cast an eye over the\nsubject. A complete, yet succinct, basic implementation of sequence operations\nis presented, ready to play with. The implementation also serves as a benchmark\nfor introducing Haskell by mathematical example.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2018 12:17:56 GMT"}, {"version": "v2", "created": "Thu, 28 Feb 2019 12:09:31 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Clenaghan", "Kieran", ""]]}, {"id": "1812.06009", "submitter": "Christoph Rauch", "authors": "Antonio Bucciarelli, Delia Kesner, Simona Ronchi Della Rocca", "title": "Solvability = Typability + Inhabitation", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 17, Issue 1 (January\n  29, 2021) lmcs:7141", "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We extend the classical notion of solvability to a lambda-calculus equipped\nwith pattern matching. We prove that solvability can be characterized by means\nof typability and inhabitation in an intersection type system P based on\nnon-idempotent types. We show first that the system P characterizes the set of\nterms having canonical form, i.e. that a term is typable if and only if it\nreduces to a canonical form. But the set of solvable terms is properly\ncontained in the set of canonical forms. Thus, typability alone is not\nsufficient to characterize solvability, in contrast to the case for the\nlambda-calculus. We then prove that typability, together with inhabitation,\nprovides a full characterization of solvability, in the sense that a term is\nsolvable if and only if it is typable and the types of all its arguments are\ninhabited. We complete the picture by providing an algorithm for the\ninhabitation problem of P.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2018 16:27:40 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2020 08:52:00 GMT"}, {"version": "v3", "created": "Mon, 30 Nov 2020 08:16:58 GMT"}, {"version": "v4", "created": "Thu, 28 Jan 2021 13:07:59 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Bucciarelli", "Antonio", ""], ["Kesner", "Delia", ""], ["Della Rocca", "Simona Ronchi", ""]]}, {"id": "1812.06197", "submitter": "Chide Groenouwe", "authors": "Chide Groenouwe, Jesse Nortier, John-Jules Ch. Meyer", "title": "Truly Visual Polymorphic Algebraic Data Structures through\n  Maramafication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a so-called maramafication of an essential part of\nfunctional programming languages such as Haskell or Clean: the construction of\nfully polymorphic well-typed algebraic data structures based on type\ndefinitions with at most one type parameter. As such, this work extends our\nprevious work, in which only a very limited form of polymorphism was present.\nMaramafication means the design of visual 'twins' of existing programming\nconstructs using spatial metaphors rooted in common sense or inborn spatial\nintuition, to achieve self-explanatoriness. This is, among others, useful to\nconsiderably reduce the gap between programmers and non-programmers in the\ncreation of programs, for educational purposes, for inclusion of non-typical\nprogrammers and for invoking enthusiasm among non-programmers.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2018 23:01:24 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Groenouwe", "Chide", ""], ["Nortier", "Jesse", ""], ["Meyer", "John-Jules Ch.", ""]]}, {"id": "1812.07429", "submitter": "Daisuke Yamaguchi", "authors": "Daisuke Yamaguchi and Kimio Kuramitsu", "title": "CPEG: A Typed Tree Construction from Parsing Expression Grammars with\n  Regex-Like Captures", "comments": "Accepted for publication in the proceedings of the 34th ACM/SIGAPP\n  Symposium On Applied Computing (SAC'19)", "journal-ref": null, "doi": "10.1145/3297280.3297433", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  CPEG is an extended parsing expression grammar with regex-like capture\nannotation. Two annotations (capture and left-folding) allow a flexible\nconstruction of syntax trees from arbitrary parsing patterns. More importantly,\nCPEG is designed to guarantee structural constraints of syntax trees for any\ninput strings. This reduces the amount of user code needed to check whether the\nintended elements exist.\n  To represent the structural constraints, we focus on regular expression\ntypes, a variant formalism of tree automata, which have been intensively\nstudied in the context of XML schemas. Regular expression type is inferred from\na given CPEG by the type inference that is formally developed in this paper. We\nprove the soundness and the uniqueness of the type inference. The type\ninference enables a CPEG to serve both as a syntactic specification of the\ninput and a schematic specification of the output.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2018 15:23:47 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Yamaguchi", "Daisuke", ""], ["Kuramitsu", "Kimio", ""]]}, {"id": "1812.07439", "submitter": "Daniel Lund\\'en", "authors": "Daniel Lund\\'en, David Broman, Fredrik Ronquist, Lawrence M. Murray", "title": "Automatic Alignment of Sequential Monte Carlo Inference in Higher-Order\n  Probabilistic Programs", "comments": "19 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic programming is a programming paradigm for expressing flexible\nprobabilistic models. Implementations of probabilistic programming languages\nemploy a variety of inference algorithms, where sequential Monte Carlo methods\nare commonly used. A problem with current state-of-the-art implementations\nusing sequential Monte Carlo inference is the alignment of program\nsynchronization points. We propose a new static analysis approach based on the\n0-CFA algorithm for automatically aligning higher-order probabilistic programs.\nWe evaluate the automatic alignment on a phylogenetic model, showing a\nsignificant decrease in runtime and increase in accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2018 15:42:55 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Lund\u00e9n", "Daniel", ""], ["Broman", "David", ""], ["Ronquist", "Fredrik", ""], ["Murray", "Lawrence M.", ""]]}, {"id": "1812.08073", "submitter": "Jovonni Pharr", "authors": "Jovonni L. Pharr", "title": "Exposing A Customizable, Decentralized Cryptoeconomy as a Data Type", "comments": "working/active paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR cs.GT cs.MA cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Purposely modular, this protocol enables customization of several protocol\nproperties, including the consensus properties implemented, blockchain type,\nthe roots used, and virtual machine opcodes, among others. These modules enable\nimplementing parties to control the behavior of their economy, with a minimal\namount of effort, and no sacrifice in participant cryptoeconomic quality. This\nwork also demonstrates the simplification of the developer experience by\nabstracting away all technological details, except basic CRUD-based operations,\nusing various programming languages. We demonstrate the mechanism design\napproach taken, and formalize a process for deploying populations of blockchain\neconomies at scale. The framework shown includes adequate tooling for\nsimulation, development, deployment, maintenance, and analytic-based decision\nmaking. Lastly, we introduce an expressive programming language for the purpose\nof creating, and interacting with the cryptoeconomy designed by the\nimplementing developer.\n", "versions": [{"version": "v1", "created": "Wed, 19 Dec 2018 16:49:26 GMT"}], "update_date": "2018-12-20", "authors_parsed": [["Pharr", "Jovonni L.", ""]]}, {"id": "1812.08278", "submitter": "Dimitri Racordon", "authors": "Dimitri Racordon", "title": "Coroutines with Higher Order Functions", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coroutines are non-preemptive concurrent subroutines that, unlike preemptive\nthreads, voluntarily transfer control between each others. Introduced in the\n60s before loosing in popularity in the 80s, they have seen a regain of\ninterest in recent years, thanks to how elegantly they can solve numerous\nalgorithmic problems. Unfortunately, some mainstream languages still lack\nsupport for coroutines, hence requiring either the use of non-standard\ninterpreter/compilers, or elaborate hacks in thrid-party libraries. In this\nshort paper, we propose a very simple way to implement coroutine-like\ncomponents on the top of any language that support or can emulate higher order\nfunctions. We accompany our explanations with a handful of examples in\nJavaScript.\n", "versions": [{"version": "v1", "created": "Wed, 19 Dec 2018 22:37:59 GMT"}], "update_date": "2018-12-21", "authors_parsed": [["Racordon", "Dimitri", ""]]}, {"id": "1812.08829", "submitter": "Shuvendu Lahiri", "authors": "Yuepeng Wang, Shuvendu K. Lahiri, Shuo Chen, Rong Pan, Isil Dillig,\n  Cody Born, Immad Naseer", "title": "Formal Specification and Verification of Smart Contracts for Azure\n  Blockchain", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Ensuring correctness of smart contracts is paramount to ensuring trust in\nblockchain-based systems. This paper studies the safety and security of smart\ncontracts in the \\emph{Azure Blockchain Workbench}, an enterprise\nBlockchain-as-a-Service offering from Microsoft. As part of this study, we\nformalize \\emph{semantic conformance} of smart contracts against a state\nmachine model with access-control policy and develop a highly-automated formal\nverifier for Solidity that can produce proofs as well as counterexamples. We\nhave applied our verifier {\\sc VeriSol} to analyze {\\it all} contracts shipped\nwith the Azure Blockchain Workbench, which includes application samples as well\nas a governance contract for Proof of Authority (PoA). We have found previously\nunknown bugs in these published smart contracts. After fixing these bugs, {\\sc\nVeriSol} was able to successfully perform full verification for all of these\ncontracts.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2018 20:24:51 GMT"}, {"version": "v2", "created": "Mon, 29 Apr 2019 17:47:46 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Wang", "Yuepeng", ""], ["Lahiri", "Shuvendu K.", ""], ["Chen", "Shuo", ""], ["Pan", "Rong", ""], ["Dillig", "Isil", ""], ["Born", "Cody", ""], ["Naseer", "Immad", ""]]}, {"id": "1812.09167", "submitter": "Mark Fingerhuth", "authors": "Mark Fingerhuth, Tom\\'a\\v{s} Babej, Peter Wittek", "title": "Open source software in quantum computing", "comments": "22 pages, 4 figures", "journal-ref": "Fingerhuth M, Babej T, Wittek P (2018) Open source software in\n  quantum computing. PLoS ONE 13(12): e0208561", "doi": "10.1371/journal.pone.0208561", "report-no": null, "categories": "quant-ph cs.MS cs.PL", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Open source software is becoming crucial in the design and testing of quantum\nalgorithms. Many of the tools are backed by major commercial vendors with the\ngoal to make it easier to develop quantum software: this mirrors how\nwell-funded open machine learning frameworks enabled the development of complex\nmodels and their execution on equally complex hardware. We review a wide range\nof open source software for quantum computing, covering all stages of the\nquantum toolchain from quantum hardware interfaces through quantum compilers to\nimplementations of quantum algorithms, as well as all quantum computing\nparadigms, including quantum annealing, and discrete and continuous-variable\ngate-model quantum computing. The evaluation of each project covers\ncharacteristics such as documentation, licence, the choice of programming\nlanguage, compliance with norms of software engineering, and the culture of the\nproject. We find that while the diversity of projects is mesmerizing, only a\nfew attract external developers and even many commercially backed frameworks\nhave shortcomings in software engineering. Based on these observations, we\nhighlight the best practices that could foster a more active community around\nquantum computing software that welcomes newcomers to the field, but also\nensures high-quality, well-documented code.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2018 14:56:18 GMT"}], "update_date": "2018-12-24", "authors_parsed": [["Fingerhuth", "Mark", ""], ["Babej", "Tom\u00e1\u0161", ""], ["Wittek", "Peter", ""]]}, {"id": "1812.09411", "submitter": "M. H. van Emden", "authors": "M.H. van Emden", "title": "Correct by construction", "comments": "16 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": "DCS-361-IR", "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix code allows one to discover algorithms and to render them in code that\nis both compilable and is correct by construction. In this way the difficulty\nof verifying existing code is avoided. The method is especially important for\nlogically dense code and when precision programming is called for. The paper\nexplains both these concepts. Logically dense code is explained by means of the\npartition stage of the Quicksort algorithm. Precision programming is explained\nby means of fast exponentiation.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2018 23:26:07 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["van Emden", "M. H.", ""]]}, {"id": "1812.10026", "submitter": "Moez AbdelGawad", "authors": "Moez A. AbdelGawad", "title": "Induction, Coinduction, and Fixed Points: A Concise Comparative Survey", "comments": "13 pages (split article into three articles)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this survey article (which hitherto is an ongoing work-in-progress) we\npresent the formulation of the induction and coinduction principles using the\nlanguage and conventions of each of order theory, set theory, programming\nlanguages' type theory, first-order logic, and category theory, for the purpose\nof examining some of the similarities and, more significantly, the\ndissimilarities between these various mathematical disciplines, and hence shed\nsome light on the precise relation between these disciplines.\n  Towards that end, in this article we discuss plenty of related concepts, such\nas fixed points, pre-fixed points, post-fixed points, inductive sets and types,\ncoinductive sets and types, algebras and coalgebras. We conclude the survey by\nhinting at the possibility of a more abstract and unified treatment that uses\nconcepts from category theory such as monads and comonads.\n", "versions": [{"version": "v1", "created": "Tue, 25 Dec 2018 04:28:54 GMT"}, {"version": "v2", "created": "Mon, 31 Dec 2018 17:23:14 GMT"}, {"version": "v3", "created": "Thu, 17 Jan 2019 13:30:48 GMT"}, {"version": "v4", "created": "Thu, 24 Jan 2019 18:53:17 GMT"}, {"version": "v5", "created": "Mon, 28 Jan 2019 18:10:32 GMT"}, {"version": "v6", "created": "Thu, 7 Feb 2019 18:37:16 GMT"}, {"version": "v7", "created": "Wed, 13 Feb 2019 13:47:52 GMT"}, {"version": "v8", "created": "Mon, 18 Feb 2019 10:16:59 GMT"}, {"version": "v9", "created": "Thu, 28 Feb 2019 04:41:34 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["AbdelGawad", "Moez A.", ""]]}, {"id": "1812.10891", "submitter": "EPTCS", "authors": "Kenichi Asai (Ochanomizu University), Mark Shinwell (Jane Street\n  Europe)", "title": "Proceedings ML Family Workshop / OCaml Users and Developers workshops", "comments": null, "journal-ref": "EPTCS 285, 2018", "doi": "10.4204/EPTCS.285", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the joint post-proceedings of the 2016 edition of the ML\nFamily Workshop and OCaml Users and Developers Workshop, held in Nara, Japan,\nin affiliation with ICFP 2016.\n", "versions": [{"version": "v1", "created": "Fri, 28 Dec 2018 04:40:03 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Asai", "Kenichi", "", "Ochanomizu University"], ["Shinwell", "Mark", "", "Jane Street\n  Europe"]]}, {"id": "1812.11145", "submitter": "Zeeshan Lakhani", "authors": "Zeeshan Lakhani and Heather Miller", "title": "Checking-in on Network Functions", "comments": "ANRW 2019 ~ https://irtf.org/anrw/2019/program.html", "journal-ref": null, "doi": "10.1145/3340301.3341131", "report-no": null, "categories": "cs.NI cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When programming network functions, changes within a packet tend to have\nconsequences---side effects which must be accounted for by network programmers\nor administrators via arbitrary logic and an innate understanding of\ndependencies. Examples of this include updating checksums when a packet's\ncontents has been modified or adjusting a payload length field of a IPv6 header\nif another header is added or updated within a packet. While static-typing\ncaptures interface specifications and how packet contents should behave, it\ndoes not enforce precise invariants around runtime dependencies like the\nexamples above. Instead, during the design phase of network functions,\nprogrammers should be given an easier way to specify checks up front, all\nwithout having to account for and keep track of these consequences at each and\nevery step during the development cycle. In keeping with this view, we present\na unique approach for adding and generating both static checks and dynamic\ncontracts for specifying and checking packet processing operations. We develop\nour technique within an existing framework called NetBricks and demonstrate how\nour approach simplifies and checks common dependent packet and header\nprocessing logic that other systems take for granted, all without adding much\noverhead during development.\n", "versions": [{"version": "v1", "created": "Fri, 28 Dec 2018 18:20:55 GMT"}, {"version": "v2", "created": "Sat, 29 Jun 2019 04:34:04 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Lakhani", "Zeeshan", ""], ["Miller", "Heather", ""]]}, {"id": "1812.11664", "submitter": "EPTCS", "authors": "Oleg Kiselyov (Tohoku University, Japan), KC Sivaramakrishnan\n  (University of Cambridge, UK)", "title": "Eff Directly in OCaml", "comments": "In Proceedings ML/OCAML 2016, arXiv:1812.10891", "journal-ref": "EPTCS 285, 2018, pp. 23-58", "doi": "10.4204/EPTCS.285.2", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The language Eff is an OCaml-like language serving as a prototype\nimplementation of the theory of algebraic effects, intended for experimentation\nwith algebraic effects on a large scale.\n  We present the embedding of Eff into OCaml, using the library of delimited\ncontinuations or the multicore OCaml branch. We demonstrate the correctness of\nthe embedding denotationally, relying on the tagless-final-style\ninterpreter-based denotational semantics, including the novel, direct\ndenotational semantics of multi-prompt delimited control. The embedding is\nsystematic, lightweight, performant and supports even higher-order, 'dynamic'\neffects with their polymorphism. OCaml thus may be regarded as another\nimplementation of Eff, broadening the scope and appeal of that language.\n", "versions": [{"version": "v1", "created": "Mon, 31 Dec 2018 02:09:18 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Kiselyov", "Oleg", "", "Tohoku University, Japan"], ["Sivaramakrishnan", "KC", "", "University of Cambridge, UK"]]}, {"id": "1812.11665", "submitter": "EPTCS", "authors": "Florent Balestrieri (ENSTA-ParisTech), Michel Mauny (Inria Paris)", "title": "Generic Programming in OCaml", "comments": "In Proceedings ML/OCAML 2016, arXiv:1812.10891", "journal-ref": "EPTCS 285, 2018, pp. 59-100", "doi": "10.4204/EPTCS.285.3", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a library for generic programming in OCaml, adapting some\ntechniques borrowed from other functional languages. The library makes use of\nthree recent additions to OCaml: generalised abstract datatypes are essential\nto reflect types, extensible variants allow this reflection to be open for new\nadditions, and extension points provide syntactic sugar and generate boiler\nplate code that simplify the use of the library. The building blocks of the\nlibrary can be used to support many approaches to generic programming through\nthe concept of view. Generic traversals are implemented on top of the library\nand provide powerful combinators to write concise definitions of recursive\nfunctions over complex tree types. Our case study is a type-safe\ndeserialisation function that respects type abstraction.\n", "versions": [{"version": "v1", "created": "Mon, 31 Dec 2018 02:09:43 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Balestrieri", "Florent", "", "ENSTA-ParisTech"], ["Mauny", "Michel", "", "Inria Paris"]]}, {"id": "1812.11668", "submitter": "EPTCS", "authors": "Timothy Bourke (Inria Paris & \\'Ecole normale sup\\'erieure, PSL\n  University), Jun Inoue (National Institute of Advanced Industrial Science and\n  Technology), Marc Pouzet (Sorbonne Universit\\'es, UPMC Univ Paris 06 &\n  \\'Ecole normale sup\\'erieure, PSL University & Inria Paris)", "title": "Sundials/ML: Connecting OCaml to the Sundials Numeric Solvers", "comments": "In Proceedings ML/OCAML 2016, arXiv:1812.10891", "journal-ref": "EPTCS 285, 2018, pp. 101-130", "doi": "10.4204/EPTCS.285.4", "report-no": null, "categories": "cs.PL cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the design and implementation of a comprehensive OCaml\ninterface to the Sundials library of numeric solvers for ordinary differential\nequations, differential algebraic equations, and non-linear equations. The\ninterface provides a convenient and memory-safe alternative to using Sundials\ndirectly from C and facilitates application development by integrating with\nhigher-level language features, like garbage-collected memory management,\nalgebraic data types, and exceptions. Our benchmark results suggest that the\ninterface overhead is acceptable: the standard examples are rarely twice as\nslow in OCaml than in C, and often less than 50% slower. The challenges in\ninterfacing with Sundials are to efficiently and safely share data structures\nbetween OCaml and C, to support multiple implementations of vector operations\nand linear solvers through a common interface, and to manage calls and error\nsignalling to and from OCaml. We explain how we overcame these difficulties\nusing a combination of standard techniques such as phantom types and\npolymorphic variants, and carefully crafted data representations.\n", "versions": [{"version": "v1", "created": "Mon, 31 Dec 2018 02:10:13 GMT"}], "update_date": "2019-01-07", "authors_parsed": [["Bourke", "Timothy", "", "Inria Paris & \u00c9cole normale sup\u00e9rieure, PSL\n  University"], ["Inoue", "Jun", "", "National Institute of Advanced Industrial Science and\n  Technology"], ["Pouzet", "Marc", "", "Sorbonne Universit\u00e9s, UPMC Univ Paris 06 &\n  \u00c9cole normale sup\u00e9rieure, PSL University & Inria Paris"]]}, {"id": "1812.11838", "submitter": "Adri\\'an Riesco", "authors": "Adri\\'an Riesco and Juan Rodr\\'iguez-Hortal\\'a", "title": "Property-based testing for Spark Streaming", "comments": "Under consideration in Theory and Practice of Logic Programming\n  (TPLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stream processing has reached the mainstream in the last years, as a new\ngeneration of open source distributed stream processing systems, designed for\nscaling horizontally on commodity hardware, has brought the capability for\nprocessing high volume and high velocity data streams to companies of all\nsizes. In this work we propose a combination of temporal logic and\nproperty-based testing (PBT) for dealing with the challenges of testing\nprograms that employ this programming model. We formalize our approach in a\ndiscrete time temporal logic for finite words, with some additions to improve\nthe expressiveness of properties, which includes timeouts for temporal\noperators and a binding operator for letters. In particular we focus on testing\nSpark Streaming programs written with the Spark API for the functional language\nScala, using the PBT library ScalaCheck. For that we add temporal logic\noperators to a set of new ScalaCheck generators and properties, as part of our\ntesting library sscheck. Under consideration in Theory and Practice of Logic\nProgramming (TPLP).\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2018 15:10:50 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Riesco", "Adri\u00e1n", ""], ["Rodr\u00edguez-Hortal\u00e1", "Juan", ""]]}, {"id": "1812.11918", "submitter": "Joshua Brul\\'e", "authors": "Joshua Brul\\'e", "title": "Whittemore: An embedded domain specific language for causal programming", "comments": "7 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.AI stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces Whittemore, a language for causal programming. Causal\nprogramming is based on the theory of structural causal models and consists of\ntwo primary operations: identification, which finds formulas that compute\ncausal queries, and estimation, which applies formulas to transform probability\ndistributions to other probability distribution. Causal programming provides\nabstractions to declare models, queries, and distributions with syntax similar\nto standard mathematical notation, and conducts rigorous causal inference,\nwithout requiring detailed knowledge of the underlying algorithms. Examples of\ncausal inference with real data are provided, along with discussion of the\nimplementation and possibilities for future extension.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2018 20:41:20 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Brul\u00e9", "Joshua", ""]]}]