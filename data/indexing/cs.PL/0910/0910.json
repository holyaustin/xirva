[{"id": "0910.0747", "submitter": "Andrew Gacek", "authors": "Andrew Gacek", "title": "A Framework for Specifying, Prototyping, and Reasoning about\n  Computational Systems", "comments": "PhD Thesis submitted September, 2009", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This thesis concerns the development of a framework that facilitates the\ndesign and analysis of formal systems. Specifically, this framework provides a\nspecification language which supports the concise and direct description of\nformal systems, a mechanism for animating the specification language thereby\nproducing prototypes of encoded systems, and a logic for proving properties of\nspecifications and therefore of the systems they encode. A defining\ncharacteristic of the proposed framework is that it is based on two separate\nbut closely intertwined logics: a specification logic that facilitates the\ndescription of computational structure and another logic that exploits the\nspecial characteristics of the specification logic to support reasoning about\nthe computational behavior of systems that are described using it. Both logics\nembody a natural treatment of binding structure by using the lambda-calculus as\na means for representing objects and by incorporating special mechanisms for\nworking with such structure. By using this technique, they lift the treatment\nof binding from the object language into the domain of the relevant meta logic,\nthereby allowing the specification or analysis components to focus on the more\nessential logical aspects of the systems that are encoded. The primary\ncontributions of these thesis are the development of a rich meta-logic called G\nwith capabilities for sophisticated reasoning that includes induction and\nco-induction over high-level specifications of computations and with an\nassociated cut-elimination result; an interactive reasoning system called\nAbella based on G; and several reasoning examples which demonstrate the\nexpressiveness and naturalness of both G and Abella.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2009 12:36:17 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2009 20:06:19 GMT"}], "update_date": "2009-10-06", "authors_parsed": [["Gacek", "Andrew", ""]]}, {"id": "0910.1028", "submitter": "Ernie Cohen", "authors": "Ernie Cohen", "title": "Weak Kleene Algebra is Sound and (Possibly) Complete for Simulation", "comments": "12 pages, 9 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the axioms of Weak Kleene Algebra (WKA) are sound and complete\nfor the theory of regular expressions modulo simulation equivalence, assuming\ntheir completeness for monodic trees (as conjectured by Takai and Furusawa).\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2009 14:45:15 GMT"}], "update_date": "2009-10-07", "authors_parsed": [["Cohen", "Ernie", ""]]}, {"id": "0910.1406", "submitter": "EPTCS", "authors": "Luca Bortolussi (University of Trieste), Alberto Policriti (University\n  of Udine)", "title": "Hybrid Semantics of Stochastic Programs with Dynamic Reconfiguration", "comments": null, "journal-ref": "EPTCS 6, 2009, pp. 63-76", "doi": "10.4204/EPTCS.6.5", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We begin by reviewing a technique to approximate the dynamics of stochastic\nprograms --written in a stochastic process algebra-- by a hybrid system,\nsuitable to capture a mixed discrete/continuous evolution. In a nutshell, the\ndiscrete dynamics is kept stochastic while the continuous evolution is given in\nterms of ODEs, and the overall technique, therefore, naturally associates a\nPiecewise Deterministic Markov Process with a stochastic program. The specific\ncontribution in this work consists in an increase of the flexibility of the\ntranslation scheme, obtained by allowing a dynamic reconfiguration of the\ndegree of discreteness/continuity of the semantics. We also discuss the\nrelationships of this approach with other hybrid simulation strategies for\nbiochemical systems.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2009 06:33:01 GMT"}], "update_date": "2009-10-09", "authors_parsed": [["Bortolussi", "Luca", "", "University of Trieste"], ["Policriti", "Alberto", "", "University\n  of Udine"]]}, {"id": "0910.1410", "submitter": "EPTCS", "authors": "Laurence Loewe, Stuart Moodie, Jane Hillston", "title": "Quantifying the implicit process flow abstraction in SBGN-PD diagrams\n  with Bio-PEPA", "comments": null, "journal-ref": "EPTCS 6, 2009, pp. 93-107", "doi": "10.4204/EPTCS.6.7", "report-no": null, "categories": "cs.PL cs.CE q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a long time biologists have used visual representations of biochemical\nnetworks to gain a quick overview of important structural properties. Recently\nSBGN, the Systems Biology Graphical Notation, has been developed to standardise\nthe way in which such graphical maps are drawn in order to facilitate the\nexchange of information. Its qualitative Process Diagrams (SBGN-PD) are based\non an implicit Process Flow Abstraction (PFA) that can also be used to\nconstruct quantitative representations, which can be used for automated\nanalyses of the system. Here we explicitly describe the PFA that underpins\nSBGN-PD and define attributes for SBGN-PD glyphs that make it possible to\ncapture the quantitative details of a biochemical reaction network. We\nimplemented SBGNtext2BioPEPA, a tool that demonstrates how such quantitative\ndetails can be used to automatically generate working Bio-PEPA code from a\ntextual representation of SBGN-PD that we developed. Bio-PEPA is a process\nalgebra that was designed for implementing quantitative models of concurrent\nbiochemical reaction systems. We use this approach to compute the expected\ndelay between input and output using deterministic and stochastic simulations\nof the MAPK signal transduction cascade. The scheme developed here is general\nand can be easily adapted to other output formalisms.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2009 05:10:21 GMT"}], "update_date": "2009-10-09", "authors_parsed": [["Loewe", "Laurence", ""], ["Moodie", "Stuart", ""], ["Hillston", "Jane", ""]]}, {"id": "0910.2315", "submitter": "Kazuhiro Inaba", "authors": "Kazuhiro Inaba and Sebastian Maneth", "title": "The Complexity of Translation Membership for Macro Tree Transducers", "comments": "9 pages, appeared at International Workshop on Programming Language\n  Techniques for XML (PLAN-X 2009)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Macro tree transducers (mtts) are a useful formal model for XML query and\ntransformation languages. In this paper one of the fundamental decision\nproblems on translations, namely the \"translation membership problem\" is\nstudied for mtts. For a fixed translation, the translation membership problem\nasks whether a given input/output pair is element of the translation. For\ncall-by-name mtts this problem is shown to be NP-complete. The main result is\nthat translation membership for call-by-value mtts is in polynomial time. For\nseveral extensions, such as addition of regular look-ahead or the\ngeneralization to multi-return mtts, it is shown that translation membership\nstill remains in PTIME.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2009 06:38:11 GMT"}], "update_date": "2009-10-14", "authors_parsed": [["Inaba", "Kazuhiro", ""], ["Maneth", "Sebastian", ""]]}, {"id": "0910.2324", "submitter": "Bernhard Scholz", "authors": "Raymes Khoury, Bernd Burgstaller and Bernhard Scholz", "title": "Accelerating the Execution of Matrix Languages on the Cell Broadband\n  Engine Architecture", "comments": "61 pages, 34 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix languages, including MATLAB and Octave, are established standards for\napplications in science and engineering. They provide interactive programming\nenvironments that are easy to use due to their scripting languages with matrix\ndata types. Current implementations of matrix languages do not fully utilise\nhigh-performance, special-purpose chip architectures such as the IBM PowerXCell\nprocessor (Cell), which is currently used in the fastest computer in the world.\n  We present a new framework that extends Octave to harness the computational\npower of the Cell. With this framework the programmer is relieved of the burden\nof introducing explicit notions of parallelism. Instead the programmer uses a\nnew matrix data-type to execute matrix operations in parallel on the\nsynergistic processing elements (SPEs) of the Cell. We employ lazy evaluation\nsemantics for our new matrix data-type to obtain execution traces of matrix\noperations. Traces are converted to data dependence graphs; operations in the\ndata dependence graph are lowered (split into sub-matrices), scheduled and\nexecuted on the SPEs. Thereby we exploit (1) data parallelism, (2) instruction\nlevel parallelism, (3) pipeline parallelism and (4) task parallelism of matrix\nlanguage programs. We conducted extensive experiments to show the validity of\nour approach. Our Cell-based implementation achieves speedups of up to a factor\nof 12 over code run on recent Intel Core2 Quad processors.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2009 08:54:18 GMT"}, {"version": "v2", "created": "Sat, 14 Nov 2009 23:55:21 GMT"}], "update_date": "2009-11-15", "authors_parsed": [["Khoury", "Raymes", ""], ["Burgstaller", "Bernd", ""], ["Scholz", "Bernhard", ""]]}, {"id": "0910.2654", "submitter": "Wonseok Chae", "authors": "Wonseok Chae", "title": "Type Safe Extensible Programming", "comments": "PhD Thesis submitted October, 2009", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software products evolve over time. Sometimes they evolve by adding new\nfeatures, and sometimes by either fixing bugs or replacing outdated\nimplementations with new ones. When software engineers fail to anticipate such\nevolution during development, they will eventually be forced to re-architect or\nre-build from scratch. Therefore, it has been common practice to prepare for\nchanges so that software products are extensible over their lifetimes. However,\nmaking software extensible is challenging because it is difficult to anticipate\nsuccessive changes and to provide adequate abstraction mechanisms over\npotential changes. Such extensibility mechanisms, furthermore, should not\ncompromise any existing functionality during extension. Software engineers\nwould benefit from a tool that provides a way to add extensions in a reliable\nway. It is natural to expect programming languages to serve this role.\nExtensible programming is one effort to address these issues.\n  In this thesis, we present type safe extensible programming using the MLPolyR\nlanguage. MLPolyR is an ML-like functional language whose type system provides\ntype-safe extensibility mechanisms at several levels. After presenting the\nlanguage, we will show how these extensibility mechanisms can be put to good\nuse in the context of product line engineering. Product line engineering is an\nemerging software engineering paradigm that aims to manage variations, which\noriginate from successive changes in software.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2009 16:08:29 GMT"}], "update_date": "2009-10-15", "authors_parsed": [["Chae", "Wonseok", ""]]}, {"id": "0910.3321", "submitter": "Miguel Vilaca", "authors": "Ian Mackie, Jorge Sousa Pinto and Miguel Vilaca", "title": "Iterators, Recursors and Interaction Nets", "comments": "ISBN: 978-972-9348-18-1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method for encoding iterators (and recursion operators in\ngeneral) using interaction nets (INs). There are two main applications for\nthis: the method can be used to obtain a visual nota- tion for functional\nprograms; and it can be used to extend the existing translations of the\nlambda-calculus into INs to languages with recursive types.\n", "versions": [{"version": "v1", "created": "Sat, 17 Oct 2009 18:52:53 GMT"}], "update_date": "2009-10-20", "authors_parsed": [["Mackie", "Ian", ""], ["Pinto", "Jorge Sousa", ""], ["Vilaca", "Miguel", ""]]}, {"id": "0910.4033", "submitter": "EPTCS", "authors": "Han Chen (School of Electronic Engineering and Computer Science, Queen\n  Mary University of London), Pasquale Malacaria (School of Electronic\n  Engineering and Computer Science, Queen Mary University of London)", "title": "Studying Maximum Information Leakage Using Karush-Kuhn-Tucker Conditions", "comments": null, "journal-ref": "EPTCS 7, 2009, pp. 1-15", "doi": "10.4204/EPTCS.7.1", "report-no": null, "categories": "cs.CR cs.IT cs.LO cs.PL math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When studying the information leakage in programs or protocols, a natural\nquestion arises: \"what is the worst case scenario?\". This problem of\nidentifying the maximal leakage can be seen as a channel capacity problem in\nthe information theoretical sense. In this paper, by combining two powerful\ntheories: Information Theory and Karush-Kuhn-Tucker conditions, we demonstrate\na very general solution to the channel capacity problem. Examples are given to\nshow how our solution can be applied to practical contexts of programs and\nanonymity protocols, and how this solution generalizes previous approaches to\nthis problem.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2009 10:04:45 GMT"}], "update_date": "2009-10-22", "authors_parsed": [["Chen", "Han", "", "School of Electronic Engineering and Computer Science, Queen\n  Mary University of London"], ["Malacaria", "Pasquale", "", "School of Electronic\n  Engineering and Computer Science, Queen Mary University of London"]]}, {"id": "0910.4044", "submitter": "EPTCS", "authors": "Jun Pang (University of Luxembourg), Chenyi Zhang (University of\n  Luxembourg)", "title": "How to Work with Honest but Curious Judges? (Preliminary Report)", "comments": null, "journal-ref": "EPTCS 7, 2009, pp. 31-45", "doi": "10.4204/EPTCS.7.3", "report-no": null, "categories": "cs.CR cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The three-judges protocol, recently advocated by Mclver and Morgan as an\nexample of stepwise refinement of security protocols, studies how to securely\ncompute the majority function to reach a final verdict without revealing each\nindividual judge's decision. We extend their protocol in two different ways for\nan arbitrary number of 2n+1 judges. The first generalisation is inherently\ncentralised, in the sense that it requires a judge as a leader who collects\ninformation from others, computes the majority function, and announces the\nfinal result. A different approach can be obtained by slightly modifying the\nwell-known dining cryptographers protocol, however it reveals the number of\nvotes rather than the final verdict. We define a notion of conditional\nanonymity in order to analyse these two solutions. Both of them have been\nchecked in the model checker MCMAS.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2009 10:53:36 GMT"}], "update_date": "2009-10-22", "authors_parsed": [["Pang", "Jun", "", "University of Luxembourg"], ["Zhang", "Chenyi", "", "University of\n  Luxembourg"]]}, {"id": "0910.4053", "submitter": "EPTCS", "authors": "Qurat ul Ain Nizamani (Department of Computer Science, University of\n  Leicester, UK), Emilio Tuosto (Department of Computer Science, University of\n  Leicester, UK)", "title": "Heuristic Methods for Security Protocols", "comments": null, "journal-ref": "EPTCS 7, 2009, pp. 61-75", "doi": "10.4204/EPTCS.7.5", "report-no": null, "categories": "cs.CR cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model checking is an automatic verification technique to verify hardware and\nsoftware systems. However it suffers from state-space explosion problem. In\nthis paper we address this problem in the context of cryptographic protocols by\nproposing a security property-dependent heuristic. The heuristic weights the\nstate space by exploiting the security formulae; the weights may then be used\nto explore the state space when searching for attacks.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2009 13:30:10 GMT"}], "update_date": "2009-10-22", "authors_parsed": [["Nizamani", "Qurat ul Ain", "", "Department of Computer Science, University of\n  Leicester, UK"], ["Tuosto", "Emilio", "", "Department of Computer Science, University of\n  Leicester, UK"]]}, {"id": "0910.4056", "submitter": "EPTCS", "authors": "Filippo Del Tedesco (Chalmers University of Technology, Gothenburg,\n  Sweden), David Sands (Chalmers University of Technology, Gothenburg, Sweden)", "title": "A User Model for Information Erasure", "comments": null, "journal-ref": "EPTCS 7, 2009, pp. 16-30", "doi": "10.4204/EPTCS.7.2", "report-no": null, "categories": "cs.CR cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hunt and Sands (ESOP'08) studied a notion of information erasure for systems\nwhich receive secrets intended for limited-time use. Erasure demands that once\na secret has fulfilled its purpose the subsequent behaviour of the system\nshould reveal no information about the erased data. In this paper we address a\nshortcoming in that work: for erasure to be possible the user who provides data\nmust also play his part, but previously that role was only specified\ninformally. Here we provide a formal model of the user and a collection of\nrequirements called erasure friendliness. We prove that an erasure-friendly\nuser can be composed with an erasing system (in the sense of Hunt and Sands) to\nobtain a combined system which is jointly erasing in an appropriate sense. In\ndoing so we identify stronger requirements on the user than those informally\ndescribed in the previous work.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2009 13:23:59 GMT"}], "update_date": "2009-10-22", "authors_parsed": [["Del Tedesco", "Filippo", "", "Chalmers University of Technology, Gothenburg,\n  Sweden"], ["Sands", "David", "", "Chalmers University of Technology, Gothenburg, Sweden"]]}, {"id": "0910.4081", "submitter": "Jakob Grue Simonsen Dr", "authors": "Jeroen Ketema, Jakob Grue Simonsen", "title": "Infinitary Combinatory Reduction Systems: Confluence", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 5, Issue 4 (December\n  20, 2009) lmcs:840", "doi": "10.2168/LMCS-5(4:3)2009", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study confluence in the setting of higher-order infinitary rewriting, in\nparticular for infinitary Combinatory Reduction Systems (iCRSs). We prove that\nfully-extended, orthogonal iCRSs are confluent modulo identification of\nhypercollapsing subterms. As a corollary, we obtain that fully-extended,\northogonal iCRSs have the normal form property and the unique normal form\nproperty (with respect to reduction). We also show that, unlike the case in\nfirst-order infinitary rewriting, almost non-collapsing iCRSs are not\nnecessarily confluent.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2009 13:15:22 GMT"}, {"version": "v2", "created": "Sun, 20 Dec 2009 16:29:37 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Ketema", "Jeroen", ""], ["Simonsen", "Jakob Grue", ""]]}, {"id": "0910.4342", "submitter": "Steve Kremer", "authors": "Joshua D. Guttman (The MITRE Corporation and Worcester Polytechnic\n  Institute)", "title": "Fair Exchange in Strand Spaces", "comments": null, "journal-ref": "EPTCS 7, 2009, pp. 46-60", "doi": "10.4204/EPTCS.7.4", "report-no": null, "categories": "cs.CR cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many cryptographic protocols are intended to coordinate state changes among\nprincipals. Exchange protocols coordinate delivery of new values to the\nparticipants, e.g. additions to the set of values they possess. An exchange\nprotocol is fair if it ensures that delivery of new values is balanced: If one\nparticipant obtains a new possession via the protocol, then all other\nparticipants will, too. Fair exchange requires progress assumptions, unlike\nsome other protocol properties. The strand space model is a framework for\ndesign and verification of cryptographic protocols. A strand is a local\nbehavior of a single principal in a single session of a protocol. A bundle is a\npartially ordered global execution built from protocol strands and adversary\nactivities. The strand space model needs two additions for fair exchange\nprotocols. First, we regard the state as a multiset of facts, and we allow\nstrands to cause changes in this state via multiset rewriting. Second, progress\nassumptions stipulate that some channels are resilient-and guaranteed to\ndeliver messages-and some principals are assumed not to stop at certain\ncritical steps. This method leads to proofs of correctness that cleanly\nseparate protocol properties, such as authentication and confidentiality, from\ninvariants governing state evolution. G. Wang's recent fair exchange protocol\nillustrates the approach.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2009 17:13:44 GMT"}], "update_date": "2009-10-23", "authors_parsed": [["Guttman", "Joshua D.", "", "The MITRE Corporation and Worcester Polytechnic\n  Institute"]]}, {"id": "0910.4420", "submitter": "EPTCS", "authors": "Michele Boreale, Steve Kremer", "title": "Proceedings 7th International Workshop on Security Issues in Concurrency", "comments": null, "journal-ref": "EPTCS 7, 2009", "doi": "10.4204/EPTCS.7", "report-no": null, "categories": "cs.CR cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the proceedings of the 7th Workshop on Security Issues\nin Concurrency (SecCo'09). The workshop was held in Bologna, Italy on September\n5th 2009, as a satellite workshop of CONCUR'09. The aim of the SecCo workshop\nseries is to cover the gap between the security and the concurrency\ncommunities. More precisely, the workshop promotes the exchange of ideas,\ntrying to focus on common interests and stimulating discussions on central\nresearch questions. In particular, we called for papers dealing with security\nissues (such as authentication, integrity, privacy, confidentiality, access\ncontrol, denial of service, service availability, safety aspects, fault\ntolerance, trust, language-based security, probabilistic and information\ntheoretic models) in emerging fields like web services, mobile ad-hoc networks,\nagent-based infrastructures, peer-to-peer systems, context-aware computing,\nglobal/ubiquitous/pervasive computing.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2009 02:08:49 GMT"}], "update_date": "2009-10-26", "authors_parsed": [["Boreale", "Michele", ""], ["Kremer", "Steve", ""]]}, {"id": "0910.4748", "submitter": "Francesco Ranzato", "authors": "Roberto Giacobazzi and Francesco Ranzato", "title": "Correctness Kernels of Abstract Interpretations", "comments": "An extended abstract of this paper appeared in Proceedings of the\n  37th International Colloquium on Automata, Languages, and Programming (ICALP\n  '10), Bordeaux, France. LNCS vol. 6199, pages 211-222, Springer, 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In abstract interpretation-based static analysis, approximation is encoded by\nabstract domains. They provide systematic guidelines for designing abstract\nsemantic functions that approximate some concrete system behaviors under\nanalysis. It may happen that an abstract domain contains redundant information\nfor the specific purpose of approximating a given concrete semantic function.\nThis paper introduces the notion of correctness kernel of abstract\ninterpretations, a methodology for simplifying abstract domains, i.e. removing\nabstract values from them, in a maximal way while retaining exactly the same\napproximate behavior of the system under analysis. We show that in abstract\nmodel checking correctness kernels provide a simplification paradigm of the\nabstract state space that is guided by examples, meaning that this\nsimplification preserves spuriousness of examples (i.e., abstract paths). In\nparticular, we show how correctness kernels can be integrated with the\nwell-known CEGAR (CounterExample-Guided Abstraction Refinement) methodology.\n", "versions": [{"version": "v1", "created": "Sun, 25 Oct 2009 15:05:07 GMT"}, {"version": "v2", "created": "Wed, 22 Jun 2011 13:21:28 GMT"}, {"version": "v3", "created": "Fri, 19 Apr 2013 08:29:03 GMT"}], "update_date": "2013-04-22", "authors_parsed": [["Giacobazzi", "Roberto", ""], ["Ranzato", "Francesco", ""]]}, {"id": "0910.5564", "submitter": "Kees Middelburg", "authors": "J. A. Bergstra, C. A. Middelburg", "title": "Instruction sequence processing operators", "comments": "37 pages; missing equations in table 3 added; combined with\n  arXiv:0911.1851 [cs.PL] and arXiv:0911.5018 [cs.LO]; introduction and\n  concluding remarks rewritten; remarks and examples added; minor error in\n  proof of theorem 4 corrected", "journal-ref": "Acta Informatica, 49(3):139--172, 2012", "doi": "10.1007/s00236-012-0154-2", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Instruction sequence is a key concept in practice, but it has as yet not come\nprominently into the picture in theoretical circles. This paper concerns\ninstruction sequences, the behaviours produced by them under execution, the\ninteraction between these behaviours and components of the execution\nenvironment, and two issues relating to computability theory. Positioning\nTuring's result regarding the undecidability of the halting problem as a result\nabout programs rather than machines, and taking instruction sequences as\nprograms, we analyse the autosolvability requirement that a program of a\ncertain kind must solve the halting problem for all programs of that kind. We\npresent novel results concerning this autosolvability requirement. The analysis\nis streamlined by using the notion of a functional unit, which is an abstract\nstate-based model of a machine. In the case where the behaviours exhibited by a\ncomponent of an execution environment can be viewed as the behaviours of a\nmachine in its different states, the behaviours concerned are completely\ndetermined by a functional unit. The above-mentioned analysis involves\nfunctional units whose possible states represent the possible contents of the\ntapes of Turing machines with a particular tape alphabet. We also investigate\nfunctional units whose possible states are the natural numbers. This\ninvestigation yields a novel computability result, viz. the existence of a\nuniversal computable functional unit for natural numbers.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2009 07:41:27 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2009 08:01:30 GMT"}, {"version": "v3", "created": "Sun, 17 Oct 2010 20:17:01 GMT"}, {"version": "v4", "created": "Mon, 26 Dec 2011 13:43:37 GMT"}, {"version": "v5", "created": "Wed, 7 Mar 2012 08:40:16 GMT"}], "update_date": "2012-05-07", "authors_parsed": [["Bergstra", "J. A.", ""], ["Middelburg", "C. A.", ""]]}, {"id": "0910.5833", "submitter": "Jean-Loup Carr\\'e", "authors": "Jean-Loup Carre and Charles Hymans", "title": "From Single-thread to Multithreaded: An Efficient Static Analysis\n  Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A great variety of static analyses that compute safety properties of\nsingle-thread programs have now been developed. This paper presents a\nsystematic method to extend a class of such static analyses, so that they\nhandle programs with multiple POSIX-style threads. Starting from a pragmatic\noperational semantics, we build a denotational semantics that expresses\nreasoning a la assume-guarantee. The final algorithm is then derived by\nabstract interpretation. It analyses each thread in turn, propagating\ninterferences between threads, in addition to other semantic information. The\ncombinatorial explosion, ensued from the explicit consideration of all\ninterleavings, is thus avoided. The worst case complexity is only increased by\na factor n compared to the single-thread case, where n is the number of\ninstructions in the program. We have implemented prototype tools, demonstrating\nthe practicality of the approach.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2009 10:27:23 GMT"}], "update_date": "2009-11-02", "authors_parsed": [["Carre", "Jean-Loup", ""], ["Hymans", "Charles", ""]]}]