[{"id": "1302.0126", "submitter": "Nicos Angelopoulos", "authors": "Nicos Angelopoulos and Roberto Bagnara", "title": "Proceedings of the 12th International Colloquium on Implementation of\n  Constraint and LOgic Programming Systems", "comments": "1 invited talk, 9 papers and 1 panel discussion", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the papers presented at CICLOPS'12: 12th International\nColloquium on Implementation of Constraint and LOgic Programming Systems held\non Tueseday September 4th, 2012 in Budapest.\n  The program included 1 invited talk, 9 technical presentations and a panel\ndiscussion on Prolog open standards (open.pl). Each programme paper was\nreviewed by 3 reviewers.\n  CICLOPS'12 continues a tradition of successful workshops on Implementations\nof Logic Programming Systems, previously held in Budapest (1993) and Ithaca\n(1994), the Compulog Net workshops on Parallelism and Implementation\nTechnologies held in Madrid (1993 and 1994), Utrecht (1995) and Bonn (1996),\nthe Workshop on Parallelism and Implementation Technology for (Constraint)\nLogic Programming Languages held in Port Jefferson (1997), Manchester (1998),\nLas Cruces (1999), and London (2000), and more recently the Colloquium on\nImplementation of Constraint and LOgic Programming Systems in Paphos (2001),\nCopenhagen (2002), Mumbai (2003), Saint Malo (2004), Sitges (2005), Seattle\n(2006), Porto (2007), Udine (2008), Pasadena (2009), Edinburgh (2010) -\ntogether with WLPE, Lexington (2011).\n  We would like to thank all the authors, Tom Schrijvers for his invited talk,\nthe programme committee members, and the ICLP 2012 organisers. We would like to\nalso thank arXiv.org for providing permanent hosting.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2013 10:20:15 GMT"}], "update_date": "2013-02-04", "authors_parsed": [["Angelopoulos", "Nicos", ""], ["Bagnara", "Roberto", ""]]}, {"id": "1302.1737", "submitter": "Damien Pous", "authors": "Damien Pous (LIP)", "title": "Kleene Algebra with Tests and Coq Tools for While Programs", "comments": "16+3 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.MS cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a Coq library about Kleene algebra with tests, including a proof\nof their completeness over the appropriate notion of languages, a decision\nprocedure for their equational theory, and tools for exploiting hypotheses of a\nparticular shape in such a theory. Kleene algebra with tests make it possible\nto represent if-then-else statements and while loops in most imperative\nprogramming languages. They were actually introduced by Kozen as an alternative\nto propositional Hoare logic. We show how to exploit the corresponding Coq\ntools in the context of program verification by proving equivalences of while\nprograms, correctness of some standard compiler optimisations, Hoare rules for\npartial correctness, and a particularly challenging equivalence of flowchart\nschemes.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2013 13:15:45 GMT"}], "update_date": "2013-02-08", "authors_parsed": [["Pous", "Damien", "", "LIP"]]}, {"id": "1302.2273", "submitter": "Pranav Garg", "authors": "Pranav Garg, Christof Loding, P. Madhusudan, Daniel Neider", "title": "Learning Universally Quantified Invariants of Linear Data Structures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.FL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new automaton model, called quantified data automata over words,\nthat can model quantified invariants over linear data structures, and build\npoly-time active learning algorithms for them, where the learner is allowed to\nquery the teacher with membership and equivalence queries. In order to express\ninvariants in decidable logics, we invent a decidable subclass of QDAs, called\nelastic QDAs, and prove that every QDA has a unique\nminimally-over-approximating elastic QDA. We then give an application of these\ntheoretically sound and efficient active learning algorithms in a passive\nlearning framework and show that we can efficiently learn quantified linear\ndata structure invariants from samples obtained from dynamic runs for a large\nclass of programs.\n", "versions": [{"version": "v1", "created": "Sat, 9 Feb 2013 21:41:03 GMT"}], "update_date": "2013-02-12", "authors_parsed": [["Garg", "Pranav", ""], ["Loding", "Christof", ""], ["Madhusudan", "P.", ""], ["Neider", "Daniel", ""]]}, {"id": "1302.2692", "submitter": "David Van Horn", "authors": "Shuying Liang, Matthew Might, Thomas Gilray, David Van Horn", "title": "Pushdown Exception-Flow Analysis of Object-Oriented Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statically reasoning in the presence of and about exceptions is challenging:\nexceptions worsen the well-known mutual recursion between data-flow and\ncontrol-flow analysis. The recent development of pushdown control-flow analysis\nfor the {\\lambda}-calculus hints at a way to improve analysis of exceptions: a\npushdown stack can precisely match catches to throws in the same way it matches\nreturns to calls. This work generalizes pushdown control-flow analysis to\nobject-oriented programs and to exceptions. Pushdown analysis of exceptions\nimproves precision over the next best analysis, Bravenboer and Smaragdakis's\nDoop, by orders of magnitude. By then generalizing abstract garbage collection\nto object-oriented programs, we reduce analysis time by half over pure pushdown\nanalysis. We evaluate our implementation for Dalvik bytecode on standard\nbenchmarks as well as several Android applications.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2013 03:29:55 GMT"}], "update_date": "2013-02-13", "authors_parsed": [["Liang", "Shuying", ""], ["Might", "Matthew", ""], ["Gilray", "Thomas", ""], ["Van Horn", "David", ""]]}, {"id": "1302.2757", "submitter": "Daniel Cederman", "authors": "Daniel Cederman and Anders Gidenstam and Phuong Ha and H{\\aa}kan\n  Sundell and Marina Papatriantafilou and Philippas Tsigas", "title": "Lock-free Concurrent Data Structures", "comments": "To appear in \"Programming Multi-core and Many-core Computing\n  Systems\", eds. S. Pllana and F. Xhafa, Wiley Series on Parallel and\n  Distributed Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Concurrent data structures are the data sharing side of parallel programming.\nData structures give the means to the program to store data, but also provide\noperations to the program to access and manipulate these data. These operations\nare implemented through algorithms that have to be efficient. In the sequential\nsetting, data structures are crucially important for the performance of the\nrespective computation. In the parallel programming setting, their importance\nbecomes more crucial because of the increased use of data and resource sharing\nfor utilizing parallelism.\n  The first and main goal of this chapter is to provide a sufficient background\nand intuition to help the interested reader to navigate in the complex research\narea of lock-free data structures. The second goal is to offer the programmer\nfamiliarity to the subject that will allow her to use truly concurrent methods.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2013 11:08:26 GMT"}], "update_date": "2013-02-13", "authors_parsed": [["Cederman", "Daniel", ""], ["Gidenstam", "Anders", ""], ["Ha", "Phuong", ""], ["Sundell", "H\u00e5kan", ""], ["Papatriantafilou", "Marina", ""], ["Tsigas", "Philippas", ""]]}, {"id": "1302.2837", "submitter": "Sebastian Nanz", "authors": "Sebastian Nanz, Scott West, Kaue Soares da Silveira, Bertrand Meyer", "title": "Benchmarking Usability and Performance of Multicore Languages", "comments": null, "journal-ref": "Proceedings of the 7th ACM-IEEE International Symposium Empirical\n  Software Engineering and Measurement (ESEM'13), pages 183-192. IEEE, 2013", "doi": "10.1109/ESEM.2013.10", "report-no": null, "categories": "cs.DC cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developers face a wide choice of programming languages and libraries\nsupporting multicore computing. Ever more diverse paradigms for expressing\nparallelism and synchronization become available while their influence on\nusability and performance remains largely unclear. This paper describes an\nexperiment comparing four markedly different approaches to parallel\nprogramming: Chapel, Cilk, Go, and Threading Building Blocks (TBB). Each\nlanguage is used to implement sequential and parallel versions of six benchmark\nprograms. The implementations are then reviewed by notable experts in the\nlanguage, thereby obtaining reference versions for each language and benchmark.\nThe resulting pool of 96 implementations is used to compare the languages with\nrespect to source code size, coding time, execution time, and speedup. The\nexperiment uncovers strengths and weaknesses in all approaches, facilitating an\ninformed selection of a language under a particular set of requirements. The\nexpert review step furthermore highlights the importance of expert knowledge\nwhen using modern parallel programming approaches.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2013 16:08:12 GMT"}, {"version": "v2", "created": "Thu, 23 Oct 2014 10:42:56 GMT"}], "update_date": "2014-10-24", "authors_parsed": [["Nanz", "Sebastian", ""], ["West", "Scott", ""], ["da Silveira", "Kaue Soares", ""], ["Meyer", "Bertrand", ""]]}, {"id": "1302.3178", "submitter": "Martin Lester", "authors": "Martin Lester, Luke Ong, Max Schaefer", "title": "Information Flow Analysis for a Dynamically Typed Functional Language\n  with Staged Metaprogramming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Web applications written in JavaScript are regularly used for dealing with\nsensitive or personal data. Consequently, reasoning about their security\nproperties has become an important problem, which is made very difficult by the\nhighly dynamic nature of the language, particularly its support for runtime\ncode generation. As a first step towards dealing with this, we propose to\ninvestigate security analyses for languages with more principled forms of\ndynamic code generation. To this end, we present a static information flow\nanalysis for a dynamically typed functional language with prototype-based\ninheritance and staged metaprogramming. We prove its soundness, implement it\nand test it on various examples designed to show its relevance to proving\nsecurity properties, such as noninterference, in JavaScript. To our knowledge,\nthis is the first fully static information flow analysis for a language with\nstaged metaprogramming, and the first formal soundness proof of a CFA-based\ninformation flow analysis for a functional programming language.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2013 18:09:05 GMT"}], "update_date": "2013-02-14", "authors_parsed": [["Lester", "Martin", ""], ["Ong", "Luke", ""], ["Schaefer", "Max", ""]]}, {"id": "1302.4796", "submitter": "Asankhaya Sharma", "authors": "Asankhaya Sharma", "title": "End to End Verification and Validation with SPIN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the last several years the tools used for model checking have become\nmore efficient and usable. This has enabled users to apply model checking to\nindustrial-scale problems, however the task of validating the implementation of\nthe model is usually much harder. In this paper we present an approach to do\nend to end verification and validation of a real time system using the SPIN\nmodel checker. Taking the example of the cardiac pacemaker system proposed in\nthe SQRL Pacemaker Formal Methods Challenge we demonstrate our framework by\nbuilding a formal model for the cardiac pacemaker in SPIN, checking for\ndesirable temporal properties of the model (expressed as LTL formulas),\ngenerating C code from the model (by refinement of PROMELA) and validating the\ngenerated implementation (using SPIN). We argue that a state of the art model\nchecking tool like SPIN can be used to do formal specification as well as\nvalidation of the implementation. To evaluate our approach we show that our\npacemaker model is expressive enough to derive consistent operating modes and\nthat the refinement rules preserve LTL properties.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 02:53:43 GMT"}], "update_date": "2013-02-21", "authors_parsed": [["Sharma", "Asankhaya", ""]]}, {"id": "1302.4798", "submitter": "Asankhaya Sharma", "authors": "Asankhaya Sharma", "title": "An Empirical Study of Path Feasibility Queries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a comparative study of path feasibility queries\ngenerated during path exploration based software engineering methods. Symbolic\nexecution based methods are gaining importance in different aspects of software\nengineering e.g. proving properties about programs, test case generation,\ncomparing different executions of programs. These methods use SMT solvers to\ncheck the satisfiability of path feasibility queries written as a formula in\nthe supported theories. We study the performance of solving such path\nfeasibility queries using SMT solvers for real world programs. Our path\ncondition formulas are generated in a theory of quantifier free bit vectors\nwith arrays (QF_ABV). We show that among the different SMT solvers, STP is\nbetter than Z3 by an order of magnitude for such kind of queries. As an\napplication we design a new program analysis (Change Value Analysis) based on\nour study which exploits undefined behaviors in programs. We have implemented\nour analysis in LLVM and tested it with the benchmark of SIR programs. It\nreduces the time taken for solving path feasibility queries by 48%. The study\ncan serve as guidance to practitioners using path feasibility queries to create\nscalable software engineering methods based on symbolic execution.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 02:59:49 GMT"}], "update_date": "2013-02-21", "authors_parsed": [["Sharma", "Asankhaya", ""]]}, {"id": "1302.5133", "submitter": "Mohammed El-Dosuky", "authors": "A. S. Tolba, M. Z. Rashad, M. A. El-Dosuky", "title": "Q#, a quantum computation package for the .NET platform", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.MS cs.PL quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum computing is a promising approach of computation that is based on\nequations from Quantum Mechanics. A simulator for quantum algorithms must be\ncapable of performing heavy mathematical matrix transforms. The design of the\nsimulator itself takes one of three forms: Quantum Turing Machine, Network\nModel or circuit model of connected gates or, Quantum Programming Language,\nyet, some simulators are hybrid. We studied previous simulators and then we\nadopt features from three simulators of different implementation languages,\ndifferent paradigms, and for different platforms. They are Quantum Computing\nLanguage (QCL), QUASI, and Quantum Optics Toolbox for Matlab 5. Our simulator\nfor quantum algorithms takes the form of a package or a programming library for\nQuantum computing, with a case study showing the ability of using it in the\ncircuit model. The .NET is a promising platform for computing. VB.NET is an\neasy, high productive programming language with the full power and\nfunctionality provided by the .NET framework. It is highly readable, writeable,\nand flexible language, compared to another language such as C#.NET in many\naspects. We adopted VB.NET although its shortage in built-in mathematical\ncomplex and matrix operations, compared to Matlab. For implementation, we first\nbuilt a mathematical core of matrix operations. Then, we built a quantum core\nwhich contains: basic qubits and register operations, basic 1D, 2D, and 3D\nquantum gates, and multi-view visualization of the quantum state, then a window\nfor demos to show you how to use and get the most of the package.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 21:37:43 GMT"}], "update_date": "2013-02-25", "authors_parsed": [["Tolba", "A. S.", ""], ["Rashad", "M. Z.", ""], ["El-Dosuky", "M. A.", ""]]}, {"id": "1302.5175", "submitter": "EPTCS", "authors": "Jan Olaf Blech (fortiss GmbH)", "title": "Towards a Framework for Behavioral Specifications of OSGi Components", "comments": "In Proceedings FESCA 2013, arXiv:1302.4780", "journal-ref": "EPTCS 108, 2013, pp. 79-93", "doi": "10.4204/EPTCS.108.6", "report-no": null, "categories": "cs.SE cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present work on behavioral specifications of OSGi components. Our\nbehavioral specifications are based on finite automata like formalisms.\nBehavioral specifications can be used to find appropriate components to\ninteract with, detect incompatibilities between communication protocols of\ncomponents and potential problems resulting from the interplay of\nnon-deterministic component specifications. These operations can be carried out\nduring development and at runtime of a system. Furthermore, we describe work\ncarried out using the Eclipse based implementation of our framework.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2013 04:00:37 GMT"}], "update_date": "2013-02-22", "authors_parsed": [["Blech", "Jan Olaf", "", "fortiss GmbH"]]}, {"id": "1302.5521", "submitter": "Ulrik Schultz", "authors": "Mikael Moghadam and David Johan Christensen and David Brandt and Ulrik\n  Pagh Schultz", "title": "Towards Python-based Domain-specific Languages for Self-reconfigurable\n  Modular Robotics Research", "comments": "Presented at DSLRob 2011 (arXiv:1212.3308)", "journal-ref": null, "doi": null, "report-no": "DSLRob/2011/04", "categories": "cs.RO cs.OS cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores the role of operating system and high-level languages in\nthe development of software and domain-specific languages (DSLs) for\nself-reconfigurable robotics. We review some of the current trends in\nself-reconfigurable robotics and describe the development of a software system\nfor ATRON II which utilizes Linux and Python to significantly improve software\nabstraction and portability while providing some basic features which could\nprove useful when using Python, either stand-alone or via a DSL, on a\nself-reconfigurable robot system. These features include transparent socket\ncommunication, module identification, easy software transfer and reliable\nmodule-to-module communication. The end result is a software platform for\nmodular robots that where appropriate builds on existing work in operating\nsystems, virtual machines, middleware and high-level languages.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2013 09:01:24 GMT"}], "update_date": "2013-02-25", "authors_parsed": [["Moghadam", "Mikael", ""], ["Christensen", "David Johan", ""], ["Brandt", "David", ""], ["Schultz", "Ulrik Pagh", ""]]}, {"id": "1302.5586", "submitter": "Riyadh Baghdadi", "authors": "Riyadh Baghdadi, Albert Cohen, Serge Guelton, Sven Verdoolaege, Jun\n  Inoue, Tobias Grosser, Georgia Kouveli, Alexey Kravets, Anton Lokhmotov,\n  Cedric Nugteren, Fraser Waters, Alastair F. Donaldson", "title": "PENCIL: Towards a Platform-Neutral Compute Intermediate Language for\n  DSLs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We motivate the design and implementation of a platform-neutral compute\nintermediate language (PENCIL) for productive and performance-portable\naccelerator programming.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2013 13:43:12 GMT"}], "update_date": "2013-02-25", "authors_parsed": [["Baghdadi", "Riyadh", ""], ["Cohen", "Albert", ""], ["Guelton", "Serge", ""], ["Verdoolaege", "Sven", ""], ["Inoue", "Jun", ""], ["Grosser", "Tobias", ""], ["Kouveli", "Georgia", ""], ["Kravets", "Alexey", ""], ["Lokhmotov", "Anton", ""], ["Nugteren", "Cedric", ""], ["Waters", "Fraser", ""], ["Donaldson", "Alastair F.", ""]]}, {"id": "1302.5765", "submitter": "Daisuke Kimura", "authors": "Daisuke Kimura (National Institute of Informatics), Makoto Tatsuta\n  (National Institute of Informatics)", "title": "Call-by-Value and Call-by-Name Dual Calculi with Inductive and\n  Coinductive Types", "comments": "The conference version of this paper has appeared in RTA 2009", "journal-ref": "Logical Methods in Computer Science, Volume 9, Issue 1 (March 29,\n  2013) lmcs:1055", "doi": "10.2168/LMCS-9(1:14)2013", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper extends the dual calculus with inductive types and coinductive\ntypes. The paper first introduces a non-deterministic dual calculus with\ninductive and coinductive types. Besides the same duality of the original dual\ncalculus, it has the duality of inductive and coinductive types, that is, the\nduality of terms and coterms for inductive and coinductive types, and the\nduality of their reduction rules. Its strong normalization is also proved,\nwhich is shown by translating it into a second-order dual calculus. The strong\nnormalization of the second-order dual calculus is proved by translating it\ninto the second-order symmetric lambda calculus. This paper then introduces a\ncall-by-value system and a call-by-name system of the dual calculus with\ninductive and coinductive types, and shows the duality of call-by-value and\ncall-by-name, their Church-Rosser properties, and their strong normalization.\nTheir strong normalization is proved by translating them into the\nnon-deterministic dual calculus with inductive and coinductive types.\n", "versions": [{"version": "v1", "created": "Sat, 23 Feb 2013 06:01:19 GMT"}, {"version": "v2", "created": "Wed, 27 Mar 2013 20:27:50 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Kimura", "Daisuke", "", "National Institute of Informatics"], ["Tatsuta", "Makoto", "", "National Institute of Informatics"]]}, {"id": "1302.5798", "submitter": "EPTCS", "authors": "Simon Gay, Paul Kelly", "title": "Proceedings Fifth Workshop on Programming Language Approaches to\n  Concurrency- and Communication-cEntric Software", "comments": null, "journal-ref": "EPTCS 109, 2013", "doi": "10.4204/EPTCS.109", "report-no": null, "categories": "cs.PL cs.DC cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  PLACES 2012 (full title: Programming Language Approaches to Concurrency- and\nCommunication-Centric Software) is the fifth edition of the PLACES workshop\nseries. After the first PLACES, which was affiliated to DisCoTec in 2008, the\nworkshop has been part of ETAPS every year since 2009 and is now an established\npart of the ETAPS satellite events. PLACES 2012 was held on 31st March in\nTallinn, Estonia.\n  The workshop series was started in order to promote the application of novel\nprogramming language ideas to the increasingly important problem of developing\nsoftware for systems in which concurrency and communication are intrinsic\naspects. This includes software for both multi-core systems and large-scale\ndistributed and/or service-oriented systems. The scope of PLACES includes new\nprogramming language features, whole new programming language designs, new type\nsystems, new semantic approaches, new program analysis techniques, and new\nimplementation mechanisms.\n  This year's call for papers attracted 17 submissions, from which the\nprogramme committee selected 10 papers for presentation at the workshop. After\nthe workshop, all of the authors were invited to produce revised versions of\ntheir papers for inclusion in the EPTCS proceedings. The authors of six papers\naccepted the invitation, and those papers constitute the present volume.\n", "versions": [{"version": "v1", "created": "Sat, 23 Feb 2013 13:44:36 GMT"}], "update_date": "2013-02-26", "authors_parsed": [["Gay", "Simon", ""], ["Kelly", "Paul", ""]]}, {"id": "1302.6325", "submitter": "Nabizath Saleena", "authors": "Saleena Nabeezath and Vineeth Paleri", "title": "A Note on \"A polynomial-time algorithm for global value numbering\"", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Global Value Numbering(GVN) is a popular method for detecting redundant\ncomputations. A polynomial time algorithm for GVN is presented by Gulwani and\nNecula(2006). Here we present two limitations of this GVN algorithm due to\nwhich detection of certain kinds of redundancies can not be done using this\nalgorithm. The first one is concerning the use of this algorithm in detecting\nsome instances of the classical global common subexpressions, and the second is\nconcerning its use in the detection of some redundancies that a local value\nnumbering algorithm will detect. We suggest improvements that enable the\nalgorithm to detect these kinds of redundancies as well.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2013 06:34:42 GMT"}, {"version": "v2", "created": "Wed, 27 Feb 2013 06:54:04 GMT"}, {"version": "v3", "created": "Fri, 8 Mar 2013 04:21:36 GMT"}, {"version": "v4", "created": "Mon, 13 May 2013 06:51:13 GMT"}, {"version": "v5", "created": "Fri, 6 Apr 2018 09:15:06 GMT"}], "update_date": "2018-04-09", "authors_parsed": [["Nabeezath", "Saleena", ""], ["Paleri", "Vineeth", ""]]}, {"id": "1302.6328", "submitter": "EPTCS", "authors": "Yu David Liu (SUNY Binghamton)", "title": "Variant-Frequency Semantics for Green Futures", "comments": "In Proceedings PLACES 2012, arXiv:1302.5798", "journal-ref": "EPTCS 109, 2013, pp. 1-6", "doi": "10.4204/EPTCS.109.1", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes an operational semantics for futures, with the primary\ntarget on energy efficiency. The work in progress is built around an insight\nthat different threads can coordinate by running at different \"paces,\" so that\nthe time for synchronization and the resulting wasteful energy consumption can\nbe reduced. We exploit several inherent characteristics of futures to determine\nhow the paces of involving threads can be coordinated. The semantics is\ninspired by recent advances in computer architectures, where the frequencies of\nCPU cores can be adjusted dynamically. The work is a first-step toward a\ndirection where variant frequencies are directly modeled as an essential\nsemantic feature in concurrent programming languages.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2013 06:48:39 GMT"}], "update_date": "2013-02-27", "authors_parsed": [["Liu", "Yu David", "", "SUNY Binghamton"]]}, {"id": "1302.6329", "submitter": "EPTCS", "authors": "Peter Calvert (University of Cambridge Computer Laboratory), Alan\n  Mycroft (University of Cambridge Computer Laboratory)", "title": "Mapping the Join Calculus to Heterogeneous Hardware", "comments": "In Proceedings PLACES 2012, arXiv:1302.5798", "journal-ref": "EPTCS 109, 2013, pp. 7-12", "doi": "10.4204/EPTCS.109.2", "report-no": null, "categories": "cs.DC cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As modern architectures introduce additional heterogeneity and parallelism,\nwe look for ways to deal with this that do not involve specialising software to\nevery platform. In this paper, we take the Join Calculus, an elegant model for\nconcurrent computation, and show how it can be mapped to an architecture by a\nCartesian-product-style construction, thereby making use of the calculus'\ninherent non-determinism to encode placement choices. This unifies the concepts\nof placement and scheduling into a single task.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2013 06:48:47 GMT"}], "update_date": "2013-02-27", "authors_parsed": [["Calvert", "Peter", "", "University of Cambridge Computer Laboratory"], ["Mycroft", "Alan", "", "University of Cambridge Computer Laboratory"]]}, {"id": "1302.6331", "submitter": "EPTCS", "authors": "Marco Carbone (IT University of Copenhagen), Fabrizio Montesi (IT\n  University of Copenhagen)", "title": "Merging Multiparty Protocols in Multiparty Choreographies", "comments": "In Proceedings PLACES 2012, arXiv:1302.5798", "journal-ref": "EPTCS 109, 2013, pp. 21-27", "doi": "10.4204/EPTCS.109.4", "report-no": null, "categories": "cs.PL cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Choreography-based programming is a powerful paradigm for defining\ncommunication-based systems from a global viewpoint. A choreography can be\nchecked against multiparty protocol specifications, given as behavioural types,\nthat may be instantiated indefinitely at runtime. Each protocol instance is\nstarted with a synchronisation among the involved peers.\n  We analyse a simple transformation from a choreography with a possibly\nunbounded number of protocol instantiations to a choreography instantiating a\nsingle protocol, which is the merge of the original ones. This gives an\neffective methodology for obtaining new protocols by composing existing ones.\nMoreover, by removing all synchronisations required for starting protocol\ninstances, our transformation reduces the number of communications and\nresources needed to execute a choreography.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2013 06:49:03 GMT"}], "update_date": "2013-02-27", "authors_parsed": [["Carbone", "Marco", "", "IT University of Copenhagen"], ["Montesi", "Fabrizio", "", "IT\n  University of Copenhagen"]]}, {"id": "1302.6332", "submitter": "EPTCS", "authors": "Pierpaolo Degano (Dipartimento di Informatica - Universit\\`a di Pisa),\n  Gian-Luigi Ferrari (Dipartimento di Informatica - Universit\\`a di Pisa),\n  Letterio Galletta (Dipartimento di Informatica - Universit\\`a di Pisa),\n  Gianluca Mezzetti (Dipartimento di Informatica - Universit\\`a di Pisa)", "title": "Typing Context-Dependent Behavioural Variation", "comments": "In Proceedings PLACES 2012, arXiv:1302.5798", "journal-ref": "EPTCS 109, 2013, pp. 28-33", "doi": "10.4204/EPTCS.109.5", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Context Oriented Programming (COP) concerns the ability of programs to adapt\nto changes in their running environment. A number of programming languages\nendowed with COP constructs and features have been developed. However, some\nfoundational issues remain unclear. This paper proposes adopting static\nanalysis techniques to reason on and predict how programs adapt their\nbehaviour. We introduce a core functional language, ContextML, equipped with\nCOP primitives for manipulating contexts and for programming behavioural\nvariations. In particular, we specify the dispatching mechanism, used to select\nthe program fragments to be executed in the current active context. Besides the\ndynamic semantics we present an annotated type system. It guarantees that the\nwell-typed programs adapt to any context, i.e. the dispatching mechanism always\nsucceeds at run-time.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2013 06:49:09 GMT"}], "update_date": "2013-02-27", "authors_parsed": [["Degano", "Pierpaolo", "", "Dipartimento di Informatica - Universit\u00e0 di Pisa"], ["Ferrari", "Gian-Luigi", "", "Dipartimento di Informatica - Universit\u00e0 di Pisa"], ["Galletta", "Letterio", "", "Dipartimento di Informatica - Universit\u00e0 di Pisa"], ["Mezzetti", "Gianluca", "", "Dipartimento di Informatica - Universit\u00e0 di Pisa"]]}, {"id": "1302.6333", "submitter": "EPTCS", "authors": "Sung-Shik T.Q. Jongmans, Farhad Arbab", "title": "Modularizing and Specifying Protocols among Threads", "comments": "In Proceedings PLACES 2012, arXiv:1302.5798", "journal-ref": "EPTCS 109, 2013, pp. 34-45", "doi": "10.4204/EPTCS.109.6", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We identify three problems with current techniques for implementing protocols\namong threads, which complicate and impair the scalability of multicore\nsoftware development: implementing synchronization, implementing coordination,\nand modularizing protocols. To mend these deficiencies, we argue for the use of\ndomain-specific languages (DSL) based on existing models of concurrency. To\ndemonstrate the feasibility of this proposal, we explain how to use the model\nof concurrency Reo as a high-level protocol DSL, which offers appropriate\nabstractions and a natural separation of protocols and computations. We\ndescribe a Reo-to-Java compiler and illustrate its use through examples.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2013 06:49:18 GMT"}], "update_date": "2013-02-27", "authors_parsed": [["Jongmans", "Sung-Shik T. Q.", ""], ["Arbab", "Farhad", ""]]}, {"id": "1302.6335", "submitter": "EPTCS", "authors": "Patrick Bahr (Department of Computer Science, University of\n  Copenhagen)", "title": "Convergence in Infinitary Term Graph Rewriting Systems is Simple\n  (Extended Abstract)", "comments": "In Proceedings TERMGRAPH 2013, arXiv:1302.5997", "journal-ref": "EPTCS 110, 2013, pp. 17-28", "doi": "10.4204/EPTCS.110.4", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this extended abstract, we present a simple approach to convergence on\nterm graphs that allows us to unify term graph rewriting and infinitary term\nrewriting. This approach is based on a partial order and a metric on term\ngraphs. These structures arise as straightforward generalisations of the\ncorresponding structures used in infinitary term rewriting. We compare our\nsimple approach to a more complicated approach that we developed earlier and\nshow that this new approach is superior in many ways. The only unfavourable\nproperty that we were able to identify, viz. failure of full correspondence\nbetween weak metric and partial order convergence, is rectified by adopting a\nstrong convergence discipline.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2013 06:50:15 GMT"}], "update_date": "2013-02-27", "authors_parsed": [["Bahr", "Patrick", "", "Department of Computer Science, University of\n  Copenhagen"]]}, {"id": "1302.6337", "submitter": "EPTCS", "authors": "Beniamino Accattoli (Carnegie Mellon University)", "title": "Evaluating functions as processes", "comments": "In Proceedings TERMGRAPH 2013, arXiv:1302.5997", "journal-ref": "EPTCS 110, 2013, pp. 41-55", "doi": "10.4204/EPTCS.110.6", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A famous result by Milner is that the lambda-calculus can be simulated inside\nthe pi-calculus. This simulation, however, holds only modulo strong\nbisimilarity on processes, i.e. there is a slight mismatch between\nbeta-reduction and how it is simulated in the pi-calculus. The idea is that\nevaluating a lambda-term in the pi-calculus is like running an\nenvironment-based abstract machine, rather than applying ordinary\nbeta-reduction. In this paper we show that such an abstract-machine evaluation\ncorresponds to linear weak head reduction, a strategy arising from the\nrepresentation of lambda-terms as linear logic proof nets, and that the\nrelation between the two is as tight as it can be. The study is also smoothly\nrephrased in the call-by-value case, introducing a call-by-value analogous of\nlinear weak head reduction.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2013 06:50:30 GMT"}], "update_date": "2013-02-27", "authors_parsed": [["Accattoli", "Beniamino", "", "Carnegie Mellon University"]]}, {"id": "1302.6338", "submitter": "EPTCS", "authors": "Clemens Grabmayer (Department of Philosophy, Utrecht University, The\n  Netherlands), Jan Rochel (Department of Computing Sciences, Utrecht\n  University, The Netherlands)", "title": "Term Graph Representations for Cyclic Lambda-Terms", "comments": "In Proceedings TERMGRAPH 2013, arXiv:1302.5997", "journal-ref": "EPTCS 110, 2013, pp. 56-73", "doi": "10.4204/EPTCS.110.7", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study various representations for cyclic lambda-terms as higher-order or\nas first-order term graphs. We focus on the relation between\n'lambda-higher-order term graphs' (lambda-ho-term-graphs), which are\nfirst-order term graphs endowed with a well-behaved scope function, and their\nrepresentations as 'lambda-term-graphs', which are plain first-order term\ngraphs with scope-delimiter vertices that meet certain scoping requirements.\nSpecifically we tackle the question: Which class of first-order term graphs\nadmits a faithful embedding of lambda-ho-term-graphs in the sense that (i) the\nhomomorphism-based sharing-order on lambda-ho-term-graphs is preserved and\nreflected, and (ii) the image of the embedding corresponds closely to a natural\nclass (of lambda-term-graphs) that is closed under homomorphism?\n  We systematically examine whether a number of classes of lambda-term-graphs\nhave this property, and we find a particular class of lambda-term-graphs that\nsatisfies this criterion. Term graphs of this class are built from application,\nabstraction, variable, and scope-delimiter vertices, and have the\ncharacteristic feature that the latter two kinds of vertices have back-links to\nthe corresponding abstraction.\n  This result puts a handle on the concept of subterm sharing for higher-order\nterm graphs, both theoretically and algorithmically: We obtain an easily\nimplementable method for obtaining the maximally shared form of\nlambda-ho-term-graphs. Furthermore, we open up the possibility to pull back\nproperties from first-order term graphs to lambda-ho-term-graphs, properties\nsuch as the complete lattice structure of bisimulation equivalence classes with\nrespect to the sharing order.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2013 06:50:38 GMT"}], "update_date": "2013-02-27", "authors_parsed": [["Grabmayer", "Clemens", "", "Department of Philosophy, Utrecht University, The\n  Netherlands"], ["Rochel", "Jan", "", "Department of Computing Sciences, Utrecht\n  University, The Netherlands"]]}, {"id": "1302.6339", "submitter": "EPTCS", "authors": "Maribel Fern\\'andez, Ian Mackie, Matthew Walker", "title": "Bigraphical Nets", "comments": "In Proceedings TERMGRAPH 2013, arXiv:1302.5997", "journal-ref": "EPTCS 110, 2013, pp. 74-81", "doi": "10.4204/EPTCS.110.8", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interaction nets are a graphical model of computation, which has been used to\ndefine efficient evaluators for functional calculi, and specifically lambda\ncalculi with patterns. However, the flat structure of interaction nets forces\npattern matching and functional behaviour to be encoded at the same level,\nlosing some potential parallelism. In this paper, we introduce bigraphical\nnets, or binets for short, as a generalisation of interaction nets using ideas\nfrom bigraphs and port graphs, and we present a formal notation and operational\nsemantics for binets. We illustrate their expressive power by examples of\napplications.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2013 06:50:45 GMT"}], "update_date": "2013-02-27", "authors_parsed": [["Fern\u00e1ndez", "Maribel", ""], ["Mackie", "Ian", ""], ["Walker", "Matthew", ""]]}]