[{"id": "0906.0049", "submitter": "Serguei Mokhov", "authors": "Serguei A. Mokhov, Joey Paquet, and Mourad Debbabi", "title": "Towards Automated Deduction in Blackmail Case Analysis with Forensic\n  Lucid", "comments": "11 pages, 7 figures; related to arXiv:0904.3789 and arXiv:0905.2449", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CR cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work-in-progress focuses on the refinement of application of the\nintensional logic to cyberforensic analysis and its benefits are compared with\nthe finite-state automata approach. This work extends the use of the scientific\nintensional programming paradigm onto modeling and implementation of a\ncyberforensics investigation process with the backtrace of event\nreconstruction, modeling the evidence as multidimensional hierarchical\ncontexts, and proving or disproving the claims with it in the intensional\nmanner of evaluation. This is a practical, context-aware improvement over the\nfinite state automata (FSA) approach we have seen in the related works. As a\nbase implementation language model we use in this approach is a new dialect of\nthe Lucid programming language, that we call Forensic Lucid and in this paper\nwe focus on defining hierarchical contexts based on the intensional logic for\nthe evaluation of cyberforensic expressions.\n", "versions": [{"version": "v1", "created": "Sat, 30 May 2009 02:04:15 GMT"}], "update_date": "2009-06-02", "authors_parsed": [["Mokhov", "Serguei A.", ""], ["Paquet", "Joey", ""], ["Debbabi", "Mourad", ""]]}, {"id": "0906.1350", "submitter": "Jan Schwinghammer", "authors": "Catalin Hritcu and Jan Schwinghammer", "title": "A Step-indexed Semantics of Imperative Objects", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 5, Issue 4 (December\n  18, 2009) lmcs:744", "doi": "10.2168/LMCS-5(4:2)2009", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Step-indexed semantic interpretations of types were proposed as an\nalternative to purely syntactic proofs of type safety using subject reduction.\nThe types are interpreted as sets of values indexed by the number of\ncomputation steps for which these values are guaranteed to behave like proper\nelements of the type. Building on work by Ahmed, Appel and others, we introduce\na step-indexed semantics for the imperative object calculus of Abadi and\nCardelli. Providing a semantic account of this calculus using more\n`traditional', domain-theoretic approaches has proved challenging due to the\ncombination of dynamically allocated objects, higher-order store, and an\nexpressive type system. Here we show that, using step-indexing, one can\ninterpret a rich type discipline with object types, subtyping, recursive and\nbounded quantified types in the presence of state.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jun 2009 11:42:45 GMT"}, {"version": "v2", "created": "Fri, 18 Dec 2009 14:58:00 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Hritcu", "Catalin", ""], ["Schwinghammer", "Jan", ""]]}, {"id": "0906.1777", "submitter": "Andrey Breslav", "authors": "Andrey Breslav", "title": "Creating Textual Language Dialects Using Aspect-like Techniques", "comments": "extended abstract for GTTSE'09", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Here we present a work aimed on efficiently creating textual language\ndialects and supporting tools for them (e.g. compiler front-ends, IDE support,\npretty-printers, etc.). A dialect is a language which may be described with a\n(relatively small) set of changes to some other language (a parent language).\nFor example we can consider SQL dialects used in DB-management systems.\n  We propose to use aspects for grammars to define different features of the\nanguage and to transform grammars. A dialect is created by defining a\nsyntactical spect which modifies the parent language. This technique is not\ndependent on any particular language design, AST structure or parsing\ntechnology and provides a uniform way for creating dialects, which extend or\nrestrict languages.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2009 16:30:01 GMT"}], "update_date": "2009-06-10", "authors_parsed": [["Breslav", "Andrey", ""]]}, {"id": "0906.2727", "submitter": "Pietro Di Gianantonio", "authors": "Pietro Di Gianantonio, Furio Honsell and Marina Lenisa", "title": "RPO, Second-order Contexts, and Lambda-calculus", "comments": "35 pages, published in Logical Methods in Computer Science", "journal-ref": "Logical Methods in Computer Science, Volume 5, Issue 3 (August 6,\n  2009) lmcs:1120", "doi": "10.2168/LMCS-5(3:6)2009", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  First, we extend Leifer-Milner RPO theory, by giving general conditions to\nobtain IPO labelled transition systems (and bisimilarities) with a reduced set\nof transitions, and possibly finitely branching. Moreover, we study the weak\nvariant of Leifer-Milner theory, by giving general conditions under which the\nweak bisimilarity is a congruence. Then, we apply such extended RPO technique\nto the lambda-calculus, endowed with lazy and call by value reduction\nstrategies.\n  We show that, contrary to process calculi, one can deal directly with the\nlambda-calculus syntax and apply Leifer-Milner technique to a category of\ncontexts, provided that we work in the framework of weak bisimilarities.\n  However, even in the case of the transition system with minimal contexts, the\nresulting bisimilarity is infinitely branching, due to the fact that, in\nstandard context categories, parametric rules such as the beta-rule can be\nrepresented only by infinitely many ground rules.\n  To overcome this problem, we introduce the general notion of second-order\ncontext category. We show that, by carrying out the RPO construction in this\nsetting, the lazy observational equivalence can be captured as a weak\nbisimilarity equivalence on a finitely branching transition system. This result\nis achieved by considering an encoding of lambda-calculus in Combinatory Logic.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2009 15:44:56 GMT"}, {"version": "v2", "created": "Thu, 6 Aug 2009 08:18:28 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Di Gianantonio", "Pietro", ""], ["Honsell", "Furio", ""], ["Lenisa", "Marina", ""]]}, {"id": "0906.3083", "submitter": "Kees Middelburg", "authors": "J. A. Bergstra, C. A. Middelburg", "title": "Instruction sequence notations with probabilistic instructions", "comments": "15 pages, revised because arxiv:1409.6873v1 [cs.LO] has come out", "journal-ref": null, "doi": null, "report-no": "PRG0906", "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper concerns instruction sequences that contain probabilistic\ninstructions, i.e. instructions that are themselves probabilistic by nature. We\npropose several kinds of probabilistic instructions, provide an informal\noperational meaning for each of them, and discuss related work. On purpose, we\nrefrain from providing an ad hoc formal meaning for the proposed kinds of\ninstructions. We also discuss the approach of projection semantics, which was\nintroduced in earlier work on instruction sequences, in the light of\nprobabilistic instruction sequences.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2009 07:03:17 GMT"}, {"version": "v2", "created": "Wed, 1 Oct 2014 14:26:01 GMT"}], "update_date": "2014-10-02", "authors_parsed": [["Bergstra", "J. A.", ""], ["Middelburg", "C. A.", ""]]}, {"id": "0906.3423", "submitter": "David Lorenz", "authors": "Atzmon Hen-Tov, David H. Lorenz, and Lior Schachter", "title": "ModelTalk: A Framework for Developing Domain Specific Executable Models", "comments": null, "journal-ref": "Proc. 8th Ann. OOPSLA Workshop on Domain-Specific Modeling\n  (DSM08), Nashville, Tennessee, USA, October 19-20, 2008", "doi": null, "report-no": null, "categories": "cs.SE cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developing and maintaining complex, large-scale, product line of highly\ncustomized software systems is difficult and costly. Part of the difficulty is\ndue to the need to communicate business knowledge between domain experts and\napplication programmers. Domain specific model driven development (MDD)\naddresses this difficulty by providing domain experts and developers with\ndomain specific abstractions for communicating designs. Most MDD\nimplementations take a generative approach. In contrast, we adopt an\ninterpretive approach to domain specific model driven development. We present a\nframework, named ModelTalk, that integrates MDD, dependency injection and\nmeta-modeling to form an interpretive, domain specific modeling framework. The\nframework is complemented by tool support that provides developers with the\nsame advanced level of usability for modeling as they are accustomed to in\nprogramming environments. ModelTalk is used in a commercial setting for\ndeveloping a product line of Telco grade business support systems (BSS).\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2009 12:13:38 GMT"}], "update_date": "2009-06-19", "authors_parsed": [["Hen-Tov", "Atzmon", ""], ["Lorenz", "David H.", ""], ["Schachter", "Lior", ""]]}, {"id": "0906.3772", "submitter": "R Doomun", "authors": "Baolong Liu, Joan Lu, Jim Yip", "title": "XML Data Integrity Based on Concatenated Hash Function", "comments": "10 pages, International Journal of Computer Science and Information\n  Security (IJCSIS)", "journal-ref": "IJCSIS, May 2009, Vol. 1", "doi": null, "report-no": null, "categories": "cs.SE cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data integrity is the fundamental for data authentication. A major problem\nfor XML data authentication is that signed XML data can be copied to another\ndocument but still keep signature valid. This is caused by XML data integrity\nprotecting. Through investigation, the paper discovered that besides data\ncontent integrity, XML data integrity should also protect element location\ninformation, and context referential integrity under fine-grained security\nsituation. The aim of this paper is to propose a model for XML data integrity\nconsidering XML data features. The paper presents an XML data integrity model\nnamed as CSR (content integrity, structure integrity, context referential\nintegrity) based on a concatenated hash function. XML data content integrity is\nensured using an iterative hash process, structure integrity is protected by\nhashing an absolute path string from root node, and context referential\nintegrity is ensured by protecting context-related elements. Presented XML data\nintegrity model can satisfy integrity requirements under situation of\nfine-grained security, and compatible with XML signature. Through evaluation,\nthe integrity model presented has a higher efficiency on digest\nvalue-generation than the Merkle hash tree-based integrity model for XML data.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jun 2009 03:10:16 GMT"}], "update_date": "2009-06-23", "authors_parsed": [["Liu", "Baolong", ""], ["Lu", "Joan", ""], ["Yip", "Jim", ""]]}, {"id": "0906.3815", "submitter": "Wlodzimierz Drabent", "authors": "W. Drabent, J. Maluszynski", "title": "Hybrid Rules with Well-Founded Semantics", "comments": null, "journal-ref": "Knowledge and Information Systems, 25:137-168, 2010", "doi": "10.1007/s10115-010-0300-5", "report-no": null, "categories": "cs.LO cs.AI cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A general framework is proposed for integration of rules and external first\norder theories. It is based on the well-founded semantics of normal logic\nprograms and inspired by ideas of Constraint Logic Programming (CLP) and\nconstructive negation for logic programs. Hybrid rules are normal clauses\nextended with constraints in the bodies; constraints are certain formulae in\nthe language of the external theory. A hybrid program is a pair of a set of\nhybrid rules and an external theory. Instances of the framework are obtained by\nspecifying the class of external theories, and the class of constraints. An\nexample instance is integration of (non-disjunctive) Datalog with ontologies\nformalized as description logics.\n  The paper defines a declarative semantics of hybrid programs and a\ngoal-driven formal operational semantics. The latter can be seen as a\ngeneralization of SLS-resolution. It provides a basis for hybrid\nimplementations combining Prolog with constraint solvers. Soundness of the\noperational semantics is proven. Sufficient conditions for decidability of the\ndeclarative semantics, and for completeness of the operational semantics are\ngiven.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jun 2009 16:09:24 GMT"}], "update_date": "2010-12-08", "authors_parsed": [["Drabent", "W.", ""], ["Maluszynski", "J.", ""]]}, {"id": "0906.3911", "submitter": "Serguei Mokhov", "authors": "Serguei A. Mokhov and Joey Paquet", "title": "Using the General Intensional Programming System (GIPSY) for Evaluation\n  of Higher-Order Intensional Logic (HOIL) Expressions", "comments": "14 pages; 8 figures", "journal-ref": null, "doi": "10.1109/SERA.2010.23", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The General Intensional Programming System (GIPSY) has been built around the\nLucid family of intensional programming languages that rely on the higher-order\nintensional logic (HOIL) to provide context-oriented multidimensional reasoning\nof intensional expressions. HOIL combines functional programming with various\nintensional logics to allow explicit context expressions to be evaluated as\nfirst-class values that can be passed as parameters to functions and return as\nresults with an appropriate set of operators defined on contexts. GIPSY's\nframeworks are implemented in Java as a collection of replaceable components\nfor the compilers of various Lucid dialects and the demand-driven eductive\nevaluation engine that can run distributively. GIPSY provides support for\nhybrid programming models that couple intensional and imperative languages for\na variety of needs. Explicit context expressions limit the scope of evaluation\nof math expressions (effectively a Lucid program is a mathematics or physics\nexpression constrained by the context) in tensor physics, regular math in\nmultiple dimensions, etc., and for cyberforensic reasoning as one of the\nuse-cases of interest. Thus, GIPSY is a support testbed for HOIL-based\nlanguages some of which enable such reasoning, as in formal cyberforensic case\nanalysis with event reconstruction. In this paper we discuss the GIPSY\narchitecture, its evaluation engine and example use-cases.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2009 03:05:48 GMT"}], "update_date": "2010-07-09", "authors_parsed": [["Mokhov", "Serguei A.", ""], ["Paquet", "Joey", ""]]}, {"id": "0906.3919", "submitter": "Serguei Mokhov", "authors": "Serguei A. Mokhov and Joey Paquet", "title": "A Type System Theory for Higher-Order Intensional Logic Support for\n  Variable Bindings in Hybrid Intensional-Imperative Programs in GIPSY", "comments": "12 pages, 1 table; 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a type system for a platform called the General Intensional\nProgramming System (GIPSY), designed to support intensional programming\nlanguages built upon intensional logic and their imperative counter-parts for\nthe intensional execution model. In GIPSY, the type system glues the static and\ndynamic typing between intensional and imperative languages in its compiler and\nrun-time environments to support the intensional evaluation of expressions\nwritten in various dialects of the intensional programming language Lucid. The\nintensionality makes expressions to explicitly take into the account a\nmultidimensional context of evaluation with the context being a first-class\nvalue that serves a number of applications that need the notion of context to\nproceed. We describe and discuss the properties of such a type system and the\nrelated type theory as well as particularities of the semantics, design and\nimplementation of the GIPSY type system.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2009 05:27:49 GMT"}], "update_date": "2009-12-21", "authors_parsed": [["Mokhov", "Serguei A.", ""], ["Paquet", "Joey", ""]]}, {"id": "0906.3920", "submitter": "EPTCS", "authors": "Claudio Guidi, Fabrizio Montesi", "title": "Reasoning About a Service-oriented Programming Paradigm", "comments": null, "journal-ref": "EPTCS 2, 2009, pp. 67-81", "doi": "10.4204/EPTCS.2.6", "report-no": null, "categories": "cs.PL cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is about a new way for programming distributed applications: the\nservice-oriented one. It is a concept paper based upon our experience in\ndeveloping a theory and a language for programming services. Both the\ntheoretical formalization and the language interpreter showed us the evidence\nthat a new programming paradigm exists. In this paper we illustrate the basic\nfeatures it is characterized by.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2009 05:49:12 GMT"}], "update_date": "2009-06-23", "authors_parsed": [["Guidi", "Claudio", ""], ["Montesi", "Fabrizio", ""]]}, {"id": "0906.3926", "submitter": "EPTCS", "authors": "Stefano Bistarelli, Francesco Santini", "title": "Soft Constraints for Quality Aspects in Service Oriented Architectures", "comments": null, "journal-ref": "EPTCS 2, 2009, pp. 51-65", "doi": "10.4204/EPTCS.2.5", "report-no": null, "categories": "cs.AI cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the use of Soft Constraints as a natural way to model Service\nOriented Architecture. In the framework, constraints are used to model\ncomponents and connectors and constraint aggregation is used to represent their\ninteractions. The \"quality of a service\" is measured and considered when\nperforming queries to service providers. Some examples consist in the levels of\ncost, performance and availability required by clients. In our framework, the\nQoS scores are represented by the softness level of the constraint and the\nmeasure of complex (web) services is computed by combining the levels of the\ncomponents.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2009 06:37:02 GMT"}], "update_date": "2009-06-23", "authors_parsed": [["Bistarelli", "Stefano", ""], ["Santini", "Francesco", ""]]}, {"id": "0906.4474", "submitter": "Jon Sneyers", "authors": "Jon Sneyers, Peter Van Weert, Tom Schrijvers, Leslie De Koninck", "title": "As time goes by: Constraint Handling Rules - A survey of CHR research\n  from 1998 to 2007", "comments": "49 pages. To appear in Theory and Practice of Logic Programming", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constraint Handling Rules (CHR) is a high-level programming language based on\nmulti-headed multiset rewrite rules. Originally designed for writing\nuser-defined constraint solvers, it is now recognized as an elegant general\npurpose language. CHR-related research has surged during the decade following\nthe previous survey by Fruehwirth. Covering more than 180 publications, this\nnew survey provides an overview of recent results in a wide range of research\nareas, from semantics and analysis to systems, extensions and applications.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2009 13:54:41 GMT"}, {"version": "v2", "created": "Thu, 25 Jun 2009 13:17:41 GMT"}], "update_date": "2009-06-25", "authors_parsed": [["Sneyers", "Jon", ""], ["Van Weert", "Peter", ""], ["Schrijvers", "Tom", ""], ["De Koninck", "Leslie", ""]]}, {"id": "0906.4837", "submitter": "Serguei Mokhov", "authors": "Bin Han, Serguei A. Mokhov, and Joey Paquet", "title": "Advances in the Design and Implementation of a Multi-Tier Architecture\n  in the GIPSY Environment", "comments": "11 pages, 3 figures", "journal-ref": null, "doi": "10.1109/SERA.2010.40", "report-no": null, "categories": "cs.SE cs.DC cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present advances in the software engineering design and implementation of\nthe multi-tier run-time system for the General Intensional Programming System\n(GIPSY) by further unifying the distributed technologies used to implement the\nDemand Migration Framework (DMF) in order to streamline distributed execution\nof hybrid intensional-imperative programs using Java.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2009 04:08:05 GMT"}], "update_date": "2010-07-09", "authors_parsed": [["Han", "Bin", ""], ["Mokhov", "Serguei A.", ""], ["Paquet", "Joey", ""]]}, {"id": "0906.5181", "submitter": "Serguei Mokhov", "authors": "Serguei A. Mokhov, Joey Paquet, and Mourad Debbabi", "title": "Reasoning About a Simulated Printer Case Investigation with Forensic\n  Lucid", "comments": "18 pages, 3 figures, 7 listings, TOC, index; this article closely\n  relates to arXiv:0906.0049 and arXiv:0904.3789 but to remain stand-alone\n  repeats some of the background and introductory content; abstract presented\n  at HSC'09 and the full updated paper at ICDF2C'11. This is an updated/edited\n  version after ICDF2C proceedings with more references and corrections", "journal-ref": "S. A. Mokhov, J. Paquet, and M. Debbabi. Reasoning about a\n  simulated printer case investigation with Forensic Lucid. In P. Gladyshev and\n  M. K. Rogers, editors, Proceedings of ICDF2C'11, number 0088 in LNICST, pp.\n  282-296. Springer, 2012", "doi": "10.1007/978-3-642-35515-8_23", "report-no": null, "categories": "cs.LO cs.CR cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we model the ACME (a fictitious company name) \"printer case\nincident\" and make its specification in Forensic Lucid, a Lucid- and\nintensional-logic-based programming language for cyberforensic analysis and\nevent reconstruction specification. The printer case involves a dispute between\ntwo parties that was previously solved using the finite-state automata (FSA)\napproach, and is now re-done in a more usable way in Forensic Lucid. Our\nsimulation is based on the said case modeling by encoding concepts like\nevidence and the related witness accounts as an evidential statement context in\na Forensic Lucid program, which is an input to the transition function that\nmodels the possible deductions in the case. We then invoke the transition\nfunction (actually its reverse) with the evidential statement context to see if\nthe evidence we encoded agrees with one's claims and then attempt to\nreconstruct the sequence of events that may explain the claim or disprove it.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2009 00:06:22 GMT"}, {"version": "v2", "created": "Thu, 26 Apr 2012 09:41:26 GMT"}], "update_date": "2013-09-17", "authors_parsed": [["Mokhov", "Serguei A.", ""], ["Paquet", "Joey", ""], ["Debbabi", "Mourad", ""]]}, {"id": "0906.5446", "submitter": "Tom Hirschowitz", "authors": "Daniel Hirschkoff (LIP), Aur\\'elien Pardon (LIP), Tom Hirschowitz\n  (LAMA), Samuel Hym (LIFL), Damien Pous (INRIA Rh\\^one-Alpes / LIG Laboratoire\n  d'Informatique de Grenoble)", "title": "Encapsulation and Dynamic Modularity in the Pi-Calculus", "comments": null, "journal-ref": "PLACES 2008, Oslo : Norv\\`ege (2008)", "doi": "10.1016/j.entcs.2009.06.005", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a process calculus featuring high level constructs for\ncomponent-oriented programming in a distributed setting. We propose an\nextension of the higher-order pi-calculus intended to capture several important\nmechanisms related to component-based programming, such as dynamic update,\nreconfiguration and code migration. In this paper, we are primarily concerned\nwith the possibility to build a distributed implementation of our calculus.\nAccordingly, we define a low-level calculus, that describes how the high-level\nconstructs are implemented, as well as details of the data structures\nmanipulated at runtime. We also discuss current and future directions of\nresearch in relation to our analysis of component-based programming.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2009 09:16:03 GMT"}], "update_date": "2009-09-04", "authors_parsed": [["Hirschkoff", "Daniel", "", "LIP"], ["Pardon", "Aur\u00e9lien", "", "LIP"], ["Hirschowitz", "Tom", "", "LAMA"], ["Hym", "Samuel", "", "LIFL"], ["Pous", "Damien", "", "INRIA Rh\u00f4ne-Alpes / LIG Laboratoire\n  d'Informatique de Grenoble"]]}, {"id": "0906.5488", "submitter": "Rasmus M{\\o}gelberg", "authors": "Rasmus Ejlers M{\\o}gelberg, Alex Simpson", "title": "Relational Parametricity for Computational Effects", "comments": "31 pages, appears in Logical Methods in Computer Science", "journal-ref": "Logical Methods in Computer Science, Volume 5, Issue 3 (August 9,\n  2009) lmcs:1113", "doi": "10.2168/LMCS-5(3:7)2009", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  According to Strachey, a polymorphic program is parametric if it applies a\nuniform algorithm independently of the type instantiations at which it is\napplied. The notion of relational parametricity, introduced by Reynolds, is one\npossible mathematical formulation of this idea. Relational parametricity\nprovides a powerful tool for establishing data abstraction properties, proving\nequivalences of datatypes, and establishing equalities of programs. Such\nproperties have been well studied in a pure functional setting. Many programs,\nhowever, exhibit computational effects, and are not accounted for by the\nstandard theory of relational parametricity. In this paper, we develop a\nfoundational framework for extending the notion of relational parametricity to\nprogramming languages with effects.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2009 11:47:58 GMT"}, {"version": "v2", "created": "Sun, 9 Aug 2009 19:09:56 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["M\u00f8gelberg", "Rasmus Ejlers", ""], ["Simpson", "Alex", ""]]}]