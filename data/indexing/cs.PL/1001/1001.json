[{"id": "1001.0143", "submitter": "Gheorghe Stefanescu", "authors": "Alexandru Sofronia and Alexandru Popa and Gheorghe Stefanescu", "title": "Undecidability Results for Finite Interactive Systems", "comments": null, "journal-ref": "Romanian Journal of Information Science and Technology, Volume 12\n  (2009), pp. 265-279", "doi": null, "report-no": null, "categories": "cs.FL cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new approach to the design of massively parallel and interactive\nprogramming languages has been recently proposed using rv-systems (interactive\nsystems with registers and voices) and Agapia programming. In this paper we\npresent a few theoretical results on FISs (finite interactive systems), the\nunderlying mechanism used for specifying control and interaction in these\nsystems. First, we give a proof for the undecidability of the emptiness problem\nfor FISs, by reduction to the Post Correspondence Problem. Next, we use the\nconstruction in this proof to get other undecidability results, e.g., for the\naccessibility of a transition in a FIS, or for the finiteness of the language\nrecognized by a FIS. Finally, we present a simple proof of the equivalence\nbetween FISs and tile systems, making explicit that they precisely capture\nrecognizable two-dimensional languages.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2009 15:19:39 GMT"}], "update_date": "2010-01-05", "authors_parsed": [["Sofronia", "Alexandru", ""], ["Popa", "Alexandru", ""], ["Stefanescu", "Gheorghe", ""]]}, {"id": "1001.0641", "submitter": "Pierre Clairambault", "authors": "Pierre Clairambault (PPS)", "title": "Least and greatest fixpoints in game semantics", "comments": null, "journal-ref": "Foundations of Software Science and Computational Structures, York\n  : United Kingdom (2009)", "doi": "10.1007/978-3-642-00596-1_3", "report-no": null, "categories": "cs.LO cs.GT cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how solutions to many recursive arena equations can be computed in a\nnatural way by allowing loops in arenas. We then equip arenas with winning\nfunctions and total winning strategies. We present two natural winning\nconditions compatible with the loop construction which respectively provide\ninitial algebras and terminal coalgebras for a large class of continuous\nfunctors. Finally, we introduce an intuitionistic sequent calculus, extended\nwith syntactic constructions for least and greatest fixed points, and prove it\nhas a sound and (in a certain weak sense) complete interpretation in our game\nmodel.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2010 07:31:37 GMT"}], "update_date": "2010-01-06", "authors_parsed": [["Clairambault", "Pierre", "", "PPS"]]}, {"id": "1001.1022", "submitter": "Emil Vassev Dr.", "authors": "Emil Vassev", "title": "LXG Compiler - Design and Implementation", "comments": "37 pages, 2 figures, grammar in BNF", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  LXG is a simple Pascal-like language. It is a functional programming language\ndeveloped for studying compiler design and implementation. The language\nsupports procedure and variable declarations, but no classes. This paper\nreports the design and implementation of an LXG compiler. Test results are\npresented as well.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2010 04:18:02 GMT"}], "update_date": "2010-01-08", "authors_parsed": [["Vassev", "Emil", ""]]}, {"id": "1001.1043", "submitter": "Shang Yun", "authors": "Ruqian Lu, Lixing Li, Yun Shang, Xiaoyu Li", "title": "Process Algebra as Abstract Data Types", "comments": "74pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduced an algebraic semantics for process algebra in\nform of abstract data types. For that purpose, we developed a particular type\nof algebra, the seed algebra, which describes exactly the behavior of a process\nwithin a labeled transition system. We have shown the possibility of\ncharacterizing the bisimulation of two processes with the isomorphism of their\ncorresponding seed algebras. We pointed out that the traditional concept of\nisomorphism of algebra does not apply here, because there is even no one-one\ncorrespondence between the elements of two seed algebras. The lack of this\none-one correspondence comes from the non-deterministic choice of transitions\nof a process. We introduce a technique of hidden operations to mask unwanted\ndetails of elements of a seed algebra, which only reflect non-determinism or\nother implicit control mechanism of process transition. Elements of a seed\nalgebra are considered as indistinguishable if they show the same behavior\nafter these unwanted details are masked. Each class of indistinguishable\nelements is called a non-hidden closure. We proved that bisimulation of two\nprocesses is equivalent to isomorphism of non-hidden closures of two seed\nalgebras representing these two processes. We call this kind of isomorphism a\ndeep isomorphism. We get different models of seed algebra by specifying\ndifferent axiom systems for the same signature. Each model corresponds to a\ndifferent kind of bisimulation. By proving the relations between these models\nwe also established relations between 10 different bisimulations, which form a\nacyclic directed graph.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2010 09:58:04 GMT"}], "update_date": "2010-01-08", "authors_parsed": [["Lu", "Ruqian", ""], ["Li", "Lixing", ""], ["Shang", "Yun", ""], ["Li", "Xiaoyu", ""]]}, {"id": "1001.1610", "submitter": "Bertrand Meyer", "authors": "Bertrand Meyer", "title": "Steps towards a theory and calculus of aliasing", "comments": "Revision of original JOT paper. To appear in IJSI (International\n  Journal of Software and Informatics) in 2011. The original title was: The\n  theory and calculus of aliasing", "journal-ref": "International Journal of Software and Informaticsspecial issue\n  (Festschrift in honor of Manfred Broy), Chinese Academy of Sciences, 2011,\n  pages 77-116", "doi": null, "report-no": "ISSN 1673-7288", "categories": "cs.SE cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A theory, graphical notation, mathematical calculus and implementation for\nfinding whether two given expressions can, at execution time, denote references\nattached to the same object. Intended as the basis for a comprehensive solution\nto the \"frame problem\" and as a complement to, or even a replacement for,\nseparation logic, shape analysis, ownership types and dynamic frames.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jan 2010 09:24:02 GMT"}, {"version": "v2", "created": "Tue, 12 Jan 2010 07:35:39 GMT"}, {"version": "v3", "created": "Wed, 13 Jan 2010 09:34:04 GMT"}, {"version": "v4", "created": "Thu, 14 Jan 2010 05:38:08 GMT"}, {"version": "v5", "created": "Fri, 15 Jan 2010 06:26:29 GMT"}, {"version": "v6", "created": "Mon, 18 Jan 2010 01:54:32 GMT"}, {"version": "v7", "created": "Thu, 21 Jan 2010 01:54:01 GMT"}, {"version": "v8", "created": "Sun, 3 Apr 2011 13:18:07 GMT"}, {"version": "v9", "created": "Sun, 10 Apr 2011 14:00:02 GMT"}], "update_date": "2013-08-06", "authors_parsed": [["Meyer", "Bertrand", ""]]}, {"id": "1001.1902", "submitter": "Volker Weinberg", "authors": "Iris Christadler and Volker Weinberg", "title": "RapidMind: Portability across Architectures and its Limitations", "comments": "12 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, hybrid architectures using accelerators like GPGPUs or the Cell\nprocessor have gained much interest in the HPC community. The RapidMind\nMulti-Core Development Platform is a programming environment that allows\ngenerating code which is able to seamlessly run on hardware accelerators like\nGPUs or the Cell processor and multicore CPUs both from AMD and Intel. This\npaper describes the ports of three mathematical kernels to RapidMind which are\nchosen as synthetic benchmarks and representatives of scientific codes.\nPerformance of these kernels has been measured on various RapidMind backends\n(cuda, cell and x86) and compared to other hardware-specific implementations\n(using CUDA, Cell SDK and Intel MKL). The results give an insight in the degree\nof portability of RapidMind code and code performance across different\narchitectures.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2010 18:11:23 GMT"}, {"version": "v2", "created": "Fri, 19 Feb 2010 16:55:00 GMT"}], "update_date": "2010-02-19", "authors_parsed": [["Christadler", "Iris", ""], ["Weinberg", "Volker", ""]]}, {"id": "1001.2188", "submitter": "Pierre Deransart", "authors": "Pierre Deransart (INRIA Rocquencourt), Rafael Oliveira (CIN)", "title": "Towards a Generic Framework to Generate Explanatory Traces of Constraint\n  Solving and Rule-Based Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": "RR-7165", "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this report, we show how to use the Simple Fluent Calculus (SFC) to\nspecify generic tracers, i.e. tracers which produce a generic trace. A generic\ntrace is a trace which can be produced by different implementations of a\nsoftware component and used independently from the traced component. This\napproach is used to define a method for extending a java based CHRor platform\ncalled CHROME (Constraint Handling Rule Online Model-driven Engine) with an\nextensible generic tracer. The method includes a tracer specification in SFC, a\nmethodology to extend it, and the way to integrate it with CHROME, resulting in\nthe platform CHROME-REF (for Reasoning Explanation Facilities), which is a\nconstraint solving and rule based reasoning engine with explanatory traces.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2010 14:54:54 GMT"}], "update_date": "2010-01-14", "authors_parsed": [["Deransart", "Pierre", "", "INRIA Rocquencourt"], ["Oliveira", "Rafael", "", "CIN"]]}, {"id": "1001.2817", "submitter": "Andrey Breslav", "authors": "Andrey Breslav", "title": "Grammatical Aspects for Language Descriptions", "comments": "Submitted to LDTA, 15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the purposes of tool development, computer languages are usually\ndescribed using context-free grammars with annotations such as semantic actions\nor pretty-printing instructions.\n  These descriptions are processed by generators which automatically build\nsoftware, e.g., parsers, pretty-printers and editing support.\n  In many cases the annotations make grammars unreadable, and when generating\ncode for several tools supporting the same language, one usually needs to\nduplicate the grammar in order to provide different annotations for different\ngenerators.\n  We present an approach to describing languages which improves readability of\ngrammars and reduces the duplication. To achieve this we use Aspect-Oriented\nProgramming principles. This approach has been implemented in an open-source\ntool named Grammatic. We show how it can be used to generate pretty-printers\nand syntax highlighters.\n", "versions": [{"version": "v1", "created": "Sat, 16 Jan 2010 11:35:59 GMT"}], "update_date": "2010-01-19", "authors_parsed": [["Breslav", "Andrey", ""]]}, {"id": "1001.3368", "submitter": "Sandra Alves", "authors": "Sandra Alves (1), Maribel Fern\\'andez (2), M\\'ario Florido (1) and Ian\n  Mackie (3) ((1) University of Porto, (2) King's College London, (3) \\'Ecole\n  Polytechnique)", "title": "Linear Recursion", "comments": "28 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define two extensions of the typed linear lambda-calculus that yield\nminimal Turing-complete systems. The extensions are based on unbounded\nrecursion in one case, and bounded recursion with minimisation in the other. We\nshow that both approaches are compatible with linearity and typeability\nconstraints. Both extensions of the typed linear lambda-calculus are minimal,\nin the sense that taking out any of the components breaks the universality of\nthe system. We discuss implementation techniques that exploit the linearity of\nthe calculi. Finally, we apply the results to languages with fixpoint\noperators: we give a compilation of the programming language PCF into a linear\nlambda-calculus with linear unbounded recursion.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jan 2010 17:38:25 GMT"}, {"version": "v2", "created": "Thu, 14 Oct 2010 16:08:38 GMT"}, {"version": "v3", "created": "Fri, 14 Jan 2011 11:16:08 GMT"}, {"version": "v4", "created": "Fri, 25 Nov 2016 15:11:40 GMT"}], "update_date": "2016-11-28", "authors_parsed": [["Alves", "Sandra", ""], ["Fern\u00e1ndez", "Maribel", ""], ["Florido", "M\u00e1rio", ""], ["Mackie", "Ian", ""]]}, {"id": "1001.3604", "submitter": "Sven Apel", "authors": "Sven Apel, Christian Kaestner, Armin Groesslinger, Christian Lengauer", "title": "Type-Safe Feature-Oriented Product Lines", "comments": "Technical Report of the University of Passau, Germany", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A feature-oriented product line is a family of programs that share a common\nset of features. A feature implements a stakeholder's requirement, represents a\ndesign decision and configuration option and, when added to a program, involves\nthe introduction of new structures, such as classes and methods, and the\nrefinement of existing ones, such as extending methods. With feature-oriented\ndecomposition, programs can be generated, solely on the basis of a user's\nselection of features, by the composition of the corresponding feature code. A\nkey challenge of feature-oriented product line engineering is how to guarantee\nthe correctness of an entire feature-oriented product line, i.e., of all of the\nmember programs generated from different combinations of features. As the\nnumber of valid feature combinations grows progressively with the number of\nfeatures, it is not feasible to check all individual programs. The only\nfeasible approach is to have a type system check the entire code base of the\nfeature-oriented product line. We have developed such a type system on the\nbasis of a formal model of a feature-oriented Java-like language. We\ndemonstrate that the type system ensures that every valid program of a\nfeature-oriented product line is well-typed and that the type system is\ncomplete.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jan 2010 14:44:46 GMT"}], "update_date": "2010-01-21", "authors_parsed": [["Apel", "Sven", ""], ["Kaestner", "Christian", ""], ["Groesslinger", "Armin", ""], ["Lengauer", "Christian", ""]]}, {"id": "1001.4381", "submitter": "EPTCS", "authors": "Hans Zantema (TU Eindhoven), Matthias Raffelsieper (TU Eindhoven)", "title": "Stream Productivity by Outermost Termination", "comments": null, "journal-ref": "EPTCS 15, 2010, pp. 83-95", "doi": "10.4204/EPTCS.15.7", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Streams are infinite sequences over a given data type. A stream specification\nis a set of equations intended to define a stream. A core property is\nproductivity: unfolding the equations produces the intended stream in the\nlimit. In this paper we show that productivity is equivalent to termination\nwith respect to the balanced outermost strategy of a TRS obtained by adding an\nadditional rule. For specifications not involving branching symbols\nbalancedness is obtained for free, by which tools for proving outermost\ntermination can be used to prove productivity fully automatically.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2010 14:20:12 GMT"}], "update_date": "2010-01-26", "authors_parsed": [["Zantema", "Hans", "", "TU Eindhoven"], ["Raffelsieper", "Matthias", "", "TU Eindhoven"]]}, {"id": "1001.4427", "submitter": "EPTCS", "authors": "Tony Bourdier (INRIA Nancy Grand-Est), Horatiu Cirstea (INRIA Nancy\n  Grand-Est), Daniel Dougherty (Worcester Polytechnic Institute), H\\'el\\`ene\n  Kirchner (INRIA Bordeaux Sud-Ouest)", "title": "Extensional and Intensional Strategies", "comments": null, "journal-ref": "EPTCS 15, 2010, pp. 1-19", "doi": "10.4204/EPTCS.15.1", "report-no": null, "categories": "cs.GT cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is a contribution to the theoretical foundations of strategies. We\nfirst present a general definition of abstract strategies which is extensional\nin the sense that a strategy is defined explicitly as a set of derivations of\nan abstract reduction system. We then move to a more intensional definition\nsupporting the abstract view but more operational in the sense that it\ndescribes a means for determining such a set. We characterize the class of\nextensional strategies that can be defined intensionally. We also give some\nhints towards a logical characterization of intensional strategies and propose\na few challenging perspectives.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2010 13:52:00 GMT"}], "update_date": "2010-01-26", "authors_parsed": [["Bourdier", "Tony", "", "INRIA Nancy Grand-Est"], ["Cirstea", "Horatiu", "", "INRIA Nancy\n  Grand-Est"], ["Dougherty", "Daniel", "", "Worcester Polytechnic Institute"], ["Kirchner", "H\u00e9l\u00e8ne", "", "INRIA Bordeaux Sud-Ouest"]]}, {"id": "1001.4434", "submitter": "EPTCS", "authors": "Besik Dundua (RISC, JKU Linz), Temur Kutsia (RISC, JKU Linz), Mircea\n  Marin (University of Tsukuba)", "title": "Strategies in PRholog", "comments": null, "journal-ref": "EPTCS 15, 2010, pp. 32-43", "doi": "10.4204/EPTCS.15.3", "report-no": null, "categories": "cs.PL cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  PRholog is an experimental extension of logic programming with strategic\nconditional transformation rules, combining Prolog with Rholog calculus. The\nrules perform nondeterministic transformations on hedges. Queries may have\nseveral results that can be explored on backtracking. Strategies provide a\ncontrol on rule applications in a declarative way. With strategy combinators,\nthe user can construct more complex strategies from simpler ones. Matching with\nfour different kinds of variables provides a flexible mechanism of selecting\n(sub)terms during execution. We give an overview on programming with strategies\nin PRholog and demonstrate how rewriting strategies can be expressed.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2010 14:06:29 GMT"}], "update_date": "2010-01-26", "authors_parsed": [["Dundua", "Besik", "", "RISC, JKU Linz"], ["Kutsia", "Temur", "", "RISC, JKU Linz"], ["Marin", "Mircea", "", "University of Tsukuba"]]}, {"id": "1001.4438", "submitter": "EPTCS", "authors": "Daniel Ventura (Universidade de Brasilia), Mauricio Ayala-Rinc\\'on\n  (Universidade de Brasilia), Fairouz Kamareddine (Heriot-Watt University,\n  Edinburgh)", "title": "Principal Typings in a Restricted Intersection Type System for Beta\n  Normal Forms with De Bruijn Indices", "comments": null, "journal-ref": "EPTCS 15, 2010, pp. 69-82", "doi": "10.4204/EPTCS.15.6", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The lambda-calculus with de Bruijn indices assembles each alpha-class of\nlambda-terms in a unique term, using indices instead of variable names.\nIntersection types provide finitary type polymorphism and can characterise\nnormalisable lambda-terms through the property that a term is normalisable if\nand only if it is typeable. To be closer to computations and to simplify the\nformalisation of the atomic operations involved in beta-contractions, several\ncalculi of explicit substitution were developed mostly with de Bruijn indices.\nVersions of explicit substitutions calculi without types and with simple type\nsystems are well investigated in contrast to versions with more elaborate type\nsystems such as intersection types. In previous work, we introduced a de Bruijn\nversion of the lambda-calculus with an intersection type system and proved that\nit preserves subject reduction, a basic property of type systems. In this paper\na version with de Bruijn indices of an intersection type system originally\nintroduced to characterise principal typings for beta-normal forms is\npresented. We present the characterisation in this new system and the\ncorresponding versions for the type inference and the reconstruction of normal\nforms from principal typings algorithms. We briefly discuss the failure of the\nsubject reduction property and some possible solutions for it.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2010 14:17:36 GMT"}], "update_date": "2010-01-26", "authors_parsed": [["Ventura", "Daniel", "", "Universidade de Brasilia"], ["Ayala-Rinc\u00f3n", "Mauricio", "", "Universidade de Brasilia"], ["Kamareddine", "Fairouz", "", "Heriot-Watt University,\n  Edinburgh"]]}, {"id": "1001.4573", "submitter": "EPTCS", "authors": "Maribel Fern\\'andez (King's College London)", "title": "Proceedings Ninth International Workshop on Reduction Strategies in\n  Rewriting and Programming", "comments": null, "journal-ref": "EPTCS 15, 2010", "doi": "10.4204/EPTCS.15", "report-no": null, "categories": "cs.PL cs.LO cs.SC cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains selected papers presented at the 9th International\nWorkshop on Reduction Strategies in Rewriting and Programming, WRS2009, which\nwas held in Brasilia on the 28th June 2009, associated to RTA 2009 (the 20th\nInternational Conference on Rewriting Techniques and Applications) at RDP, the\nFederated Conference on Rewriting, Deduction and Programming. Reduction\nstrategies define which (sub)expression(s) should be selected for evaluation\nand which rule(s) should be applied. These choices affect fundamental\nproperties of reductions, such as completeness, laziness and efficiency in\ngeneral. The WRS workshops promote research and collaboration in the area of\nreduction strategies and their applications in specification and programming,\ntheorem proving, software engineering, etc.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2010 01:05:09 GMT"}], "update_date": "2010-01-27", "authors_parsed": [["Fern\u00e1ndez", "Maribel", "", "King's College London"]]}, {"id": "1001.4901", "submitter": "Benjamin Nguyen Ph.D.", "authors": "Ivan Bedini, Georges Gardarin, Benjamin Nguyen", "title": "Deriving Ontologies from XML Schema", "comments": null, "journal-ref": "Entrepots de Donnees et Analyse en Ligne (EDA) Conference, Invited\n  Paper, 2008", "doi": null, "report-no": null, "categories": "cs.PL cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a method and a tool for deriving a skeleton of an\nontology from XML schema files. We first recall what an is ontology and its\nrelationships with XML schemas. Next, we focus on ontology building methodology\nand associated tool requirements. Then, we introduce Janus, a tool for building\nan ontology from various XML schemas in a given domain. We summarize the main\nfeatures of Janus and illustrate its functionalities through a simple example.\nFinally, we compare our approach to other existing ontology building tools.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2010 10:44:26 GMT"}], "update_date": "2010-01-28", "authors_parsed": [["Bedini", "Ivan", ""], ["Gardarin", "Georges", ""], ["Nguyen", "Benjamin", ""]]}]