[{"id": "1505.00017", "submitter": "Chester Holtz", "authors": "Tyler Hannan, Chester Holtz, Jonathan Liao", "title": "Comparative Analysis of Classic Garbage-Collection Algorithms for a\n  Lisp-like Language", "comments": "14 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we demonstrate the effectiveness of Cheney's Copy Algorithm\nfor a Lisp-like system and experimentally show the infeasability of developing\nan optimal garbage collector for general use. We summarize and compare several\ngarbage-collection algorithms including Cheney's Algorithm, the canonical Mark\nand Sweep Algorithm, and Knuth's Classical Lisp 2 Algorithm. We implement and\nanalyze these three algorithms in the context of a custom MicroLisp\nenvironment. We conclude and present the core considerations behind the\ndevelopment of a garbage collector---specifically for Lisp---and make an\nattempt to investigate these issues in depth. We also discuss experimental\nresults that imply the effectiveness of Cheney's algorithm over Mark-Sweep for\nLisp-like languages.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2015 20:16:47 GMT"}], "update_date": "2015-05-04", "authors_parsed": [["Hannan", "Tyler", ""], ["Holtz", "Chester", ""], ["Liao", "Jonathan", ""]]}, {"id": "1505.02298", "submitter": "Alexander Bakst", "authors": "Alexander Bakst and Ranjit Jhala", "title": "Predicate Abstraction for Linked Data Structures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Alias Refinement Types (ART), a new approach to the verification\nof correctness properties of linked data structures. While there are many\ntechniques for checking that a heap-manipulating program adheres to its\nspecification, they often require that the programmer annotate the behavior of\neach procedure, for example, in the form of loop invariants and pre- and\npost-conditions. Predicate abstraction would be an attractive abstract domain\nfor performing invariant inference, existing techniques are not able to reason\nabout the heap with enough precision to verify functional properties of data\nstructure manipulating programs. In this paper, we propose a technique that\nlifts predicate abstraction to the heap by factoring the analysis of data\nstructures into two orthogonal components: (1) Alias Types, which reason about\nthe physical shape of heap structures, and (2) Refinement Types, which use\nsimple predicates from an SMT decidable theory to capture the logical or\nsemantic properties of the structures. We prove ART sound by translating types\ninto separation logic assertions, thus translating typing derivations in ART\ninto separation logic proofs. We evaluate ART by implementing a tool that\nperforms type inference for an imperative language, and empirically show, using\na suite of data-structure benchmarks, that ART requires only 21% of the\nannotations needed by other state-of-the-art verification techniques.\n", "versions": [{"version": "v1", "created": "Sat, 9 May 2015 17:52:27 GMT"}, {"version": "v2", "created": "Sat, 31 Oct 2015 19:06:16 GMT"}], "update_date": "2015-11-03", "authors_parsed": [["Bakst", "Alexander", ""], ["Jhala", "Ranjit", ""]]}, {"id": "1505.02579", "submitter": "James Cheney", "authors": "Faris Abou-Saleh and James Cheney and Jeremy Gibbons and James McKinna\n  and Perdita Stevens", "title": "Notions of bidirectional computation and entangled state monads", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-319-19797-5_9", "report-no": null, "categories": "cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bidirectional transformations (bx) support principled consistency maintenance\nbetween data sources. Each data source corresponds to one perspective on a\ncomposite system, manifested by operations to 'get' and 'set' a view of the\nwhole from that particular perspective. Bx are important in a wide range of\nsettings, including databases, interactive applications, and model-driven\ndevelopment. We show that bx are naturally modelled in terms of mutable state;\nin particular, the 'set' operations are stateful functions. This leads\nnaturally to considering bx that exploit other computational effects too, such\nas I/O, nondeterminism, and failure, all largely ignored in the bx literature\nto date. We present a semantic foundation for symmetric bidirectional\ntransformations with effects. We build on the mature theory of monadic\nencapsulation of effects in functional programming, develop the equational\ntheory and important combinators for effectful bx, and provide a prototype\nimplementation in Haskell along with several illustrative examples.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2015 12:11:08 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["Abou-Saleh", "Faris", ""], ["Cheney", "James", ""], ["Gibbons", "Jeremy", ""], ["McKinna", "James", ""], ["Stevens", "Perdita", ""]]}, {"id": "1505.02642", "submitter": "Hamid Ebadi", "authors": "Hamid Ebadi, David Sands", "title": "Featherweight PINQ", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differentially private mechanisms enjoy a variety of composition properties.\nLeveraging these, McSherry introduced PINQ (SIGMOD 2009), a system empowering\nnon-experts to construct new differentially private analyses. PINQ is an\nLINQ-like API which provides automatic privacy guarantees for all programs\nwhich use it to mediate sensitive data manipulation. In this work we introduce\nfeatherweight PINQ, a formal model capturing the essence of PINQ. We prove that\nany program interacting with featherweight PINQ's API is differentially\nprivate.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2015 14:40:29 GMT"}], "update_date": "2015-05-12", "authors_parsed": [["Ebadi", "Hamid", ""], ["Sands", "David", ""]]}, {"id": "1505.02878", "submitter": "Hiroshi Unno", "authors": "Kodai Hashimoto and Hiroshi Unno", "title": "Refinement Type Inference via Horn Constraint Optimization", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel method for inferring refinement types of higher-order\nfunctional programs. The main advantage of the proposed method is that it can\ninfer maximally preferred (i.e., Pareto optimal) refinement types with respect\nto a user-specified preference order. The flexible optimization of refinement\ntypes enabled by the proposed method paves the way for interesting\napplications, such as inferring most-general characterization of inputs for\nwhich a given program satisfies (or violates) a given safety (or termination)\nproperty. Our method reduces such a type optimization problem to a Horn\nconstraint optimization problem by using a new refinement type system that can\nflexibly reason about non-determinism in programs. Our method then solves the\nconstraint optimization problem by repeatedly improving a current solution\nuntil convergence via template-based invariant generation. We have implemented\na prototype inference system based on our method, and obtained promising\nresults in preliminary experiments.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2015 05:38:53 GMT"}, {"version": "v2", "created": "Sat, 16 May 2015 13:04:03 GMT"}], "update_date": "2015-05-19", "authors_parsed": [["Hashimoto", "Kodai", ""], ["Unno", "Hiroshi", ""]]}, {"id": "1505.02951", "submitter": "Jo\\~ao Louren\\c{c}o", "authors": "Diogo G. Sousa and Ricardo J. Dias and Carla Ferreira and Jo\\~ao M.\n  Louren\\c{c}o", "title": "Preventing Atomicity Violations with Contracts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software developers are expected to protect concurrent accesses to shared\nregions of memory with some mutual exclusion primitive that ensures atomicity\nproperties to a sequence of program statements. This approach prevents data\nraces but may fail to provide all necessary correctness properties.The\ncomposition of correlated atomic operations without further synchronization may\ncause atomicity violations. Atomic violations may be avoided by grouping the\ncorrelated atomic regions in a single larger atomic scope. Concurrent programs\nare particularly prone to atomicity violations when they use services provided\nby third party packages or modules, since the programmer may fail to identify\nwhich services are correlated. In this paper we propose to use contracts for\nconcurrency, where the developer of a module writes a set of contract terms\nthat specify which methods are correlated and must be executed in the same\natomic scope. These contracts are then used to verify the correctness of the\nmain program with respect to the usage of the module(s). If a contract is well\ndefined and complete, and the main program respects it, then the program is\nsafe from atomicity violations with respect to that module. We also propose a\nstatic analysis based methodology to verify contracts for concurrency that we\napplied to some real-world software packages. The bug we found in Tomcat 6.0\nwas immediately acknowledged and corrected by its development team.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2015 10:47:29 GMT"}], "update_date": "2015-05-13", "authors_parsed": [["Sousa", "Diogo G.", ""], ["Dias", "Ricardo J.", ""], ["Ferreira", "Carla", ""], ["Louren\u00e7o", "Jo\u00e3o M.", ""]]}, {"id": "1505.04533", "submitter": "Thorsten Tarrach", "authors": "Pavol \\v{C}ern\\'y, Edmund M. Clarke, Thomas A. Henzinger, Arjun\n  Radhakrishna, Leonid Ryzhyk, Roopsha Samanta, Thorsten Tarrach", "title": "From Non-preemptive to Preemptive Scheduling using Synchronization\n  Synthesis", "comments": "Liss is published as open-source at\n  https://github.com/thorstent/Liss, Computer Aided Verification 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a computer-aided programming approach to concurrency. The approach\nallows programmers to program assuming a friendly, non-preemptive scheduler,\nand our synthesis procedure inserts synchronization to ensure that the final\nprogram works even with a preemptive scheduler. The correctness specification\nis implicit, inferred from the non-preemptive behavior. Let us consider\nsequences of calls that the program makes to an external interface. The\nspecification requires that any such sequence produced under a preemptive\nscheduler should be included in the set of such sequences produced under a\nnon-preemptive scheduler. The solution is based on a finitary abstraction, an\nalgorithm for bounded language inclusion modulo an independence relation, and\nrules for inserting synchronization. We apply the approach to device-driver\nprogramming, where the driver threads call the software interface of the device\nand the API provided by the operating system. Our experiments demonstrate that\nour synthesis method is precise and efficient, and, since it does not require\nexplicit specifications, is more practical than the conventional approach based\non user-provided assertions.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2015 07:25:17 GMT"}], "update_date": "2015-05-19", "authors_parsed": [["\u010cern\u00fd", "Pavol", ""], ["Clarke", "Edmund M.", ""], ["Henzinger", "Thomas A.", ""], ["Radhakrishna", "Arjun", ""], ["Ryzhyk", "Leonid", ""], ["Samanta", "Roopsha", ""], ["Tarrach", "Thorsten", ""]]}, {"id": "1505.05265", "submitter": "Claudio Corrodi", "authors": "Claudio Corrodi", "title": "Modelling and Verifying an Object-Oriented Concurrency Model in GROOVE", "comments": "124 pages, Master's Thesis at ETH Z\\\"urich", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SCOOP is a programming model and language that allows concurrent programming\nat a high level of abstraction. Several approaches to verifying SCOOP programs\nhave been proposed in the past, but none of them operate directly on the source\ncode without modifications or annotations.\n  We propose a fully automatic approach to verifying (a subset of) SCOOP\nprograms by translation to graph-based models. First, we present a graph\ntransformation based semantics for SCOOP. We present an implementation of the\nmodel in the state-of-the-art model checker GROOVE, which can be used to\nsimulate programs and verify concurrency and consistency properties, such as\nthe impossibility of deadlocks occurring or the absence of postcondition\nviolations. Second, we present a translation tool that operates on SCOOP\nprogram code and generates input for the model. We evaluate our approach by\ninspecting a number of programs in the form of case studies.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2015 07:33:14 GMT"}], "update_date": "2015-05-21", "authors_parsed": [["Corrodi", "Claudio", ""]]}, {"id": "1505.05868", "submitter": "Arjun Radhakrishna", "authors": "Rajeev Alur, Pavol Cerny, Arjun Radhakrishna", "title": "Synthesis through Unification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a specification and a set of candidate programs (program space), the\nprogram synthesis problem is to find a candidate program that satisfies the\nspecification. We present the synthesis through unification (STUN) approach,\nwhich is an extension of the counter-example guided inductive synthesis (CEGIS)\napproach. In CEGIS, the synthesizer maintains a subset S of inputs and a\ncandidate program Prog that is correct for S. The synthesizer repeatedly checks\nif there exists a counter-example input c such that the execution of Prog is\nincorrect on c. If so, the synthesizer enlarges S to include c, and picks a\nprogram from the program space that is correct for the new set S.\n  The STUN approach extends CEGIS with the idea that given a program Prog that\nis correct for a subset of inputs, the synthesizer can try to find a program\nProg' that is correct for the rest of the inputs. If Prog and Prog' can be\nunified into a program in the program space, then a solution has been found. We\npresent a generic synthesis procedure based on the STUN approach and specialize\nit for three different domains by providing the appropriate unification\noperators. We implemented these specializations in prototype tools, and we show\nthat our tools often per- forms significantly better on standard benchmarks\nthan a tool based on a pure CEGIS approach.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2015 19:58:46 GMT"}], "update_date": "2015-05-22", "authors_parsed": [["Alur", "Rajeev", ""], ["Cerny", "Pavol", ""], ["Radhakrishna", "Arjun", ""]]}, {"id": "1505.06003", "submitter": "Julien Ponge", "authors": "Julien Ponge (CITI), Fr\\'ed\\'eric Le Mou\\\"el (CITI), Nicolas Stouls\n  (CITI), Yannick Loiseau (LIMOS)", "title": "Opportunities for a Truffle-based Golo Interpreter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Golo is a simple dynamically-typed language for the Java Virtual Machine.\nInitially implemented as a ahead-of-time compiler to JVM bytecode, it leverages\ninvokedy-namic and JSR 292 method handles to implement a reasonably efficient\nruntime. Truffle is emerging as a framework for building interpreters for JVM\nlanguages with self-specializing AST nodes. Combined with the Graal compiler,\nTruffle offers a simple path towards writing efficient interpreters while\nkeeping the engineering efforts balanced. The Golo project is interested in\nexperimenting with a Truffle interpreter in the future, as it would provides\ninteresting comparison elements between invokedynamic versus Truffle for\nbuilding a language runtime.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2015 09:29:05 GMT"}], "update_date": "2015-05-25", "authors_parsed": [["Ponge", "Julien", "", "CITI"], ["Mou\u00ebl", "Fr\u00e9d\u00e9ric Le", "", "CITI"], ["Stouls", "Nicolas", "", "CITI"], ["Loiseau", "Yannick", "", "LIMOS"]]}, {"id": "1505.06299", "submitter": "Matthieu Perrin", "authors": "Matthieu Perrin, Claude Jard, Achour Mostefaoui", "title": "Tracking Causal Dependencies in Web Services Orchestrations Defined in\n  ORC", "comments": "NETYS - 3rd International Conference on NETwork sYStems, May 2015,\n  Agadir, Morocco. 2015, Proceedings of the third international conference on\n  network systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article shows how the operational semantics of a language like ORC can\nbe instrumented so that the execution of a program produces information on the\ncausal dependencies between events. The concurrent semantics we obtain is based\non asymmetric labeled event structures. The approach is illustrated using a Web\nservice orchestration instance and the detection of race conditions.\n", "versions": [{"version": "v1", "created": "Sat, 23 May 2015 10:03:49 GMT"}], "update_date": "2015-05-26", "authors_parsed": [["Perrin", "Matthieu", ""], ["Jard", "Claude", ""], ["Mostefaoui", "Achour", ""]]}, {"id": "1505.07162", "submitter": "EPTCS", "authors": "Sergio Antoy, Jacob Johannsen, Steven Libby", "title": "Needed Computations Shortcutting Needed Steps", "comments": "In Proceedings TERMGRAPH 2014, arXiv:1505.06818", "journal-ref": "EPTCS 183, 2015, pp. 18-32", "doi": "10.4204/EPTCS.183.2", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define a compilation scheme for a constructor-based, strongly-sequential,\ngraph rewriting system which shortcuts some needed steps. The object code is\nanother constructor-based graph rewriting system. This system is normalizing\nfor the original system when using an innermost strategy. Consequently, the\nobject code can be easily implemented by eager functions in a variety of\nprogramming languages. We modify this object code in a way that avoids total or\npartial construction of the contracta of some needed steps of a computation.\nWhen computing normal forms in this way, both memory consumption and execution\ntime are reduced compared to ordinary rewriting computations in the original\nsystem.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2015 00:47:50 GMT"}], "update_date": "2015-05-28", "authors_parsed": [["Antoy", "Sergio", ""], ["Johannsen", "Jacob", ""], ["Libby", "Steven", ""]]}, {"id": "1505.07164", "submitter": "EPTCS", "authors": "Abubakar Hassan (Theory and Practice of Software Ltd), Ian Mackie\n  (LIX, Ecole Polytechnique), Shinya Sato (University of Sussex)", "title": "An Implementation Model for Interaction Nets", "comments": "In Proceedings TERMGRAPH 2014, arXiv:1505.06818", "journal-ref": "EPTCS 183, 2015, pp. 66-80", "doi": "10.4204/EPTCS.183.5", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To study implementations and optimisations of interaction net systems we\npropose a calculus to allow us to reason about nets, a concrete data-structure\nthat is in close correspondence with the calculus, and a low-level language to\ncreate and manipulate this data structure. These work together so that we can\ndescribe the compilation process for interaction nets, reason about the\nbehaviours of the implementation, and study the efficiency and properties.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2015 00:48:30 GMT"}], "update_date": "2015-05-28", "authors_parsed": [["Hassan", "Abubakar", "", "Theory and Practice of Software Ltd"], ["Mackie", "Ian", "", "LIX, Ecole Polytechnique"], ["Sato", "Shinya", "", "University of Sussex"]]}, {"id": "1505.07368", "submitter": "Dominik Charousset", "authors": "Dominik Charousset and Raphael Hiesgen and Thomas C. Schmidt", "title": "Revisiting Actor Programming in C++", "comments": "33 pages", "journal-ref": "Elsevier Computer Languages, Systems and Structures 45, pp.\n  105--131, 2016", "doi": "10.1016/j.cl.2016.01.002", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The actor model of computation has gained significant popularity over the\nlast decade. Its high level of abstraction makes it appealing for concurrent\napplications in parallel and distributed systems. However, designing a\nreal-world actor framework that subsumes full scalability, strong reliability,\nand high resource efficiency requires many conceptual and algorithmic additives\nto the original model.\n  In this paper, we report on designing and building CAF, the \"C++ Actor\nFramework\". CAF targets at providing a concurrent and distributed native\nenvironment for scaling up to very large, high-performance applications, and\nequally well down to small constrained systems. We present the key\nspecifications and design concepts---in particular a message-transparent\narchitecture, type-safe message interfaces, and pattern matching\nfacilities---that make native actors a viable approach for many robust,\nelastic, and highly distributed developments. We demonstrate the feasibility of\nCAF in three scenarios: first for elastic, upscaling environments, second for\nincluding heterogeneous hardware like GPGPUs, and third for distributed runtime\nsystems. Extensive performance evaluations indicate ideal runtime behaviour for\nup to 64 cores at very low memory footprint, or in the presence of GPUs. In\nthese tests, CAF continuously outperforms the competing actor environments\nErlang, Charm++, SalsaLite, Scala, ActorFoundry, and even the OpenMPI.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2015 15:16:57 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Charousset", "Dominik", ""], ["Hiesgen", "Raphael", ""], ["Schmidt", "Thomas C.", ""]]}, {"id": "1505.07375", "submitter": "Hong-Yi Dai", "authors": "Hong-Yi Dai", "title": "The Mysteries of Lisp -- I: The Way to S-expression Lisp", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Despite its old age, Lisp remains mysterious to many of its admirers. The\nmysteries on one hand fascinate the language, on the other hand also obscure\nit. Following Stoyan but paying attention to what he has neglected or omitted,\nin this first essay of a series intended to unravel these mysteries, we trace\nthe development of Lisp back to its origin, revealing how the language has\nevolved into its nowadays look and feel. The insights thus gained will not only\nenhance existent understanding of the language but also inspires further\nimprovement of it.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2015 04:16:50 GMT"}], "update_date": "2015-05-28", "authors_parsed": [["Dai", "Hong-Yi", ""]]}, {"id": "1505.07383", "submitter": "Lars Bergstrom", "authors": "Brian Anderson and Lars Bergstrom and David Herman and Josh Matthews\n  and Keegan McAllister and Manish Goregaokar and Jack Moffitt and Simon Sapin", "title": "Experience Report: Developing the Servo Web Browser Engine using Rust", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  All modern web browsers - Internet Explorer, Firefox, Chrome, Opera, and\nSafari - have a core rendering engine written in C++. This language choice was\nmade because it affords the systems programmer complete control of the\nunderlying hardware features and memory in use, and it provides a transparent\ncompilation model.\n  Servo is a project started at Mozilla Research to build a new web browser\nengine that preserves the capabilities of these other browser engines but also\nboth takes advantage of the recent trends in parallel hardware and is more\nmemory-safe. We use a new language, Rust, that provides us a similar level of\ncontrol of the underlying system to C++ but which builds on many concepts\nfamiliar to the functional programming community, forming a novelty - a useful,\nsafe systems programming language.\n  In this paper, we show how a language with an affine type system, regions,\nand many syntactic features familiar to functional language programmers can be\nsuccessfully used to build state-of-the-art systems software. We also outline\nseveral pitfalls encountered along the way and describe some potential areas\nfor future research.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2015 18:49:02 GMT"}], "update_date": "2015-05-28", "authors_parsed": [["Anderson", "Brian", ""], ["Bergstrom", "Lars", ""], ["Herman", "David", ""], ["Matthews", "Josh", ""], ["McAllister", "Keegan", ""], ["Goregaokar", "Manish", ""], ["Moffitt", "Jack", ""], ["Sapin", "Simon", ""]]}, {"id": "1505.07716", "submitter": "Johannes Doerfert", "authors": "Johannes Doerfert, Kevin Streit, Sebastian Hack and Zino Benaissa", "title": "Polly's Polyhedral Scheduling in the Presence of Reductions", "comments": "Presented at the IMPACT15 workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The polyhedral model provides a powerful mathematical abstraction to enable\neffective optimization of loop nests with respect to a given optimization goal,\ne.g., exploiting parallelism. Unexploited reduction properties are a frequent\nreason for polyhedral optimizers to assume parallelism prohibiting dependences.\nTo our knowledge, no polyhedral loop optimizer available in any production\ncompiler provides support for reductions. In this paper, we show that\nleveraging the parallelism of reductions can lead to a significant performance\nincrease. We give a precise, dependence based, definition of reductions and\ndiscuss ways to extend polyhedral optimization to exploit the associativity and\ncommutativity of reduction computations. We have implemented a\nreduction-enabled scheduling approach in the Polly polyhedral optimizer and\nevaluate it on the standard Polybench 3.2 benchmark suite. We were able to\ndetect and model all 52 arithmetic reductions and achieve speedups up to\n2.21$\\times$ on a quad core machine by exploiting the multidimensional\nreduction in the BiCG benchmark.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2015 15:05:46 GMT"}], "update_date": "2015-05-29", "authors_parsed": [["Doerfert", "Johannes", ""], ["Streit", "Kevin", ""], ["Hack", "Sebastian", ""], ["Benaissa", "Zino", ""]]}]