[{"id": "1107.0064", "submitter": "EPTCS", "authors": "Jeroen van den Bos (CWI), Mark Hills (CWI), Paul Klint (CWI), Tijs van\n  der Storm (CWI), Jurgen J. Vinju (CWI)", "title": "Rascal: From Algebraic Specification to Meta-Programming", "comments": "In Proceedings AMMSE 2011, arXiv:1106.5962", "journal-ref": "EPTCS 56, 2011, pp. 15-32", "doi": "10.4204/EPTCS.56.2", "report-no": null, "categories": "cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algebraic specification has a long tradition in bridging the gap between\nspecification and programming by making specifications executable. Building on\nextensive experience in designing, implementing and using specification\nformalisms that are based on algebraic specification and term rewriting (namely\nAsf and Asf+Sdf), we are now focusing on using the best concepts from algebraic\nspecification and integrating these into a new programming language: Rascal.\nThis language is easy to learn by non-experts but is also scalable to very\nlarge meta-programming applications.\n  We explain the algebraic roots of Rascal and its main application areas:\nsoftware analysis, software transformation, and design and implementation of\ndomain-specific languages. Some example applications in the domain of\nModel-Driven Engineering (MDE) are described to illustrate this.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jun 2011 21:44:38 GMT"}], "update_date": "2011-07-04", "authors_parsed": [["Bos", "Jeroen van den", "", "CWI"], ["Hills", "Mark", "", "CWI"], ["Klint", "Paul", "", "CWI"], ["van der Storm", "Tijs", "", "CWI"], ["Vinju", "Jurgen J.", "", "CWI"]]}, {"id": "1107.0350", "submitter": "David Insa", "authors": "David Insa, Josep Silva", "title": "Optimal Divide and Query (extended version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithmic debugging is a semi-automatic debugging technique that allows the\nprogrammer to precisely identify the location of bugs without the need to\ninspect the source code. The technique has been successfully adapted to all\nparadigms and mature implementations have been released for languages such as\nHaskell, Prolog or Java. During three decades, the algorithm introduced by\nShapiro and later improved by Hirunkitti has been thought optimal. In this\npaper we first show that this algorithm is not optimal, and moreover, in some\nsituations it is unable to find all possible solutions, thus it is incomplete.\nThen, we present a new version of the algorithm that is proven optimal, and we\nintroduce some equations that allow the algorithm to identify all optimal\nsolutions.\n", "versions": [{"version": "v1", "created": "Sat, 2 Jul 2011 01:35:07 GMT"}, {"version": "v2", "created": "Fri, 22 Jul 2011 15:09:51 GMT"}, {"version": "v3", "created": "Tue, 26 Jul 2011 14:08:07 GMT"}], "update_date": "2011-07-27", "authors_parsed": [["Insa", "David", ""], ["Silva", "Josep", ""]]}, {"id": "1107.0666", "submitter": "Patrick Bahr", "authors": "Patrick Bahr", "title": "Infinitary Term Graph Rewriting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Term graph rewriting provides a formalism for implementing term rewriting in\nan efficient manner by avoiding duplication. Infinitary term rewriting has been\nintroduced to study infinite term reduction sequences. Such infinite reductions\ncan be used to reason about lazy evaluation. In this paper, we combine term\ngraph rewriting and infinitary term rewriting thereby addressing both\ncomponents of lazy evaluation: non-strictness and sharing. Moreover, we show\nhow our theoretical underpinnings, based on a metric space and a complete\nsemilattice, provides a unified framework for both term rewriting and term\ngraph rewriting. This makes it possible to study the correspondences between\nthese two worlds. As an example, we show how the soundness of term graph\nrewriting w.r.t. term rewriting can be extended to the infinitary setting.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jul 2011 15:48:50 GMT"}], "update_date": "2011-07-05", "authors_parsed": [["Bahr", "Patrick", ""]]}, {"id": "1107.0746", "submitter": "EPTCS", "authors": "Mieke Massink (CNR-ISTI, Pisa, Italy), Gethin Norman (University of\n  Glasgow, UK)", "title": "Proceedings Ninth Workshop on Quantitative Aspects of Programming\n  Languages", "comments": null, "journal-ref": "EPTCS 57, 2011", "doi": "10.4204/EPTCS.57", "report-no": null, "categories": "cs.PL cs.LO cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the proceedings of the Ninth Workshop on Quantitative\nAspects of Programming Languages (QAPL 2011), held in Saarbrucken, Germany,\nApril 1--3, 2011. QAPL 2011 is a satellite event of the European Joint\nConferences on Theory and Practice of Software (ETAPS 2011).\n  The workshop theme is on quantitative aspects of computation. These aspects\nare related to the use of physical quantities (storage space, time, bandwidth,\netc.) as well as mathematical quantities (e.g. probability and measures for\nreliability, security and trust), and play an important (sometimes essential)\nrole in characterising the behavior and determining the properties of systems.\nSuch quantities are central to the definition of both the model of systems\n(architecture, language design, semantics) and the methodologies and tools for\nthe analysis and verification of the systems properties. The aim of this\nworkshop is to discuss the explicit use of quantitative information such as\ntime and probabilities either directly in the model or as a tool for the\nanalysis of systems.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jul 2011 21:44:01 GMT"}], "update_date": "2011-07-06", "authors_parsed": [["Massink", "Mieke", "", "CNR-ISTI, Pisa, Italy"], ["Norman", "Gethin", "", "University of\n  Glasgow, UK"]]}, {"id": "1107.0940", "submitter": "Serguei Mokhov", "authors": "Joey Paquet and Serguei A. Mokhov", "title": "Furthering Baseline Core Lucid Standard Specification in the Context of\n  the History of Lucid, Intensional Programming, and Context-Aware Computing", "comments": "46 pages, 3 figures, 1 table, 1 listing; a running draft and a\n  collection of references on the subject; v4 primarily updates some references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work is multifold. We review the historical literature on the Lucid\nprogramming language, its dialects, intensional logic, intensional programming,\nthe implementing systems, and context-oriented and context-aware computing and\nso on that provide a contextual framework for the converging Core Lucid\nstandard programming model. We are designing a standard specification of a\nbaseline Lucid virtual machine for generic execution of Lucid programs. The\nresulting Core Lucid language would inherit the properties of generalization\nattempts of GIPL (1999-2013) and TransLucid (2008-2013) for all future and\nrecent Lucid implementing systems to follow. We also maintain this work across\nlocal research group in order to foster deeper collaboration, maintain a list\nof recent and historical bibliography and a reference manual and reading list\nfor students. We form a (for now informal) SIGLUCID group to keep track of this\nstandard and historical records with eventual long-term goal through iterative\nrevisions for this work to become a book or an encyclopedia of the referenced\ntopics, and perhaps, an RFC. We first begin small with this initial set of\nnotes.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jul 2011 18:49:26 GMT"}, {"version": "v2", "created": "Fri, 5 Jul 2013 18:53:05 GMT"}, {"version": "v3", "created": "Fri, 26 Jul 2013 13:35:35 GMT"}, {"version": "v4", "created": "Mon, 21 Oct 2013 19:32:15 GMT"}], "update_date": "2013-10-22", "authors_parsed": [["Paquet", "Joey", ""], ["Mokhov", "Serguei A.", ""]]}, {"id": "1107.1203", "submitter": "EPTCS", "authors": "Daniel Seidel, Janis Voigtl\\\"ander", "title": "Improvements for Free", "comments": "In Proceedings QAPL 2011, arXiv:1107.0746", "journal-ref": "EPTCS 57, 2011, pp. 89-103", "doi": "10.4204/EPTCS.57.7", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \"Theorems for Free!\" (Wadler, FPCA 1989) is a slogan for a technique that\nallows to derive statements about functions just from their types. So far, the\nstatements considered have always had a purely extensional flavor: statements\nrelating the value semantics of program expressions, but not statements\nrelating their runtime (or other) cost. Here we study an extension of the\ntechnique that allows precisely statements of the latter flavor, by deriving\nquantitative theorems for free. After developing the theory, we walk through a\nnumber of example derivations. Probably none of the statements derived in those\nsimple examples will be particularly surprising to most readers, but what is\nmaybe surprising, and at the very least novel, is that there is a general\ntechnique for obtaining such results on a quantitative level in a principled\nway. Moreover, there is good potential to bring that technique to bear on more\ncomplex examples as well. We turn our attention to short-cut fusion (Gill et\nal., FPCA 1993) in particular.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jul 2011 17:55:03 GMT"}], "update_date": "2011-07-07", "authors_parsed": [["Seidel", "Daniel", ""], ["Voigtl\u00e4nder", "Janis", ""]]}, {"id": "1107.1398", "submitter": "Jan Obdr\\v{z}\\'alek", "authors": "Jan Obdrzalek and Marek Trtik", "title": "Efficient Loop Navigation for Symbolic Execution", "comments": "This is the full version of the extended abstract to appear in ATVA\n  2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Symbolic execution is a successful and very popular technique used in\nsoftware verification and testing. A key limitation of symbolic execution is in\ndealing with code containing loops. The problem is that even a single loop can\ngenerate a huge number of different symbolic execution paths, corresponding to\ndifferent number of loop iterations and taking various paths through the loop.\n  We introduce a technique which, given a start location above some loops and a\ntarget location anywhere below these loops, returns a feasible path between\nthese two locations, if such a path exists. The technique infers a collection\nof constraint systems from the program and uses them to steer the symbolic\nexecution towards the target. On reaching a loop it iteratively solves the\nappropriate constraint system to find out which path through this loop to take,\nor, alternatively, whether to continue below the loop. To construct the\nconstraint systems we express the values of variables modified in a loop as\nfunctions of the number of times a given path through the loop was executed.\n  We have built a prototype implementation of our technique and compared it to\nstate-of-the-art symbolic execution tools on simple programs with loops. The\nresults show significant improvements in the running time. We found instances\nwhere our algorithm finished in seconds, whereas the other tools did not finish\nwithin an hour. Our approach also shows very good results in the case when the\ntarget location is not reachable by any feasible path.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jul 2011 14:13:14 GMT"}], "update_date": "2011-07-08", "authors_parsed": [["Obdrzalek", "Jan", ""], ["Trtik", "Marek", ""]]}, {"id": "1107.1999", "submitter": "Bertrand Meyer", "authors": "Bertrand Meyer", "title": "Towards a Calculus of Object Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Verifying properties of object-oriented software requires a method for\nhandling references in a simple and intuitive way, closely related to how O-O\nprogrammers reason about their programs. The method presented here, a Calculus\nof Object Programs, combines four components: compositional logic, a framework\nfor describing program semantics and proving program properties; negative\nvariables to address the specifics of O-O programming, in particular qualified\ncalls; the alias calculus, which determines whether reference expressions can\never have the same value; and the calculus of object structures, a\nspecification technique for the structures that arise during the execution of\nan object-oriented program. The article illustrates the Calculus by proving the\nstandard algorithm for reversing a linked list.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jul 2011 11:18:21 GMT"}, {"version": "v2", "created": "Sun, 17 Jul 2011 07:37:24 GMT"}], "update_date": "2011-07-19", "authors_parsed": [["Meyer", "Bertrand", ""]]}, {"id": "1107.2003", "submitter": "Qi Guo", "authors": "Qi Guo, Yunji Chen, Tianshi chen, and Ling Li", "title": "Efficient Deterministic Replay Using Complete Race Detection", "comments": "18 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data races can significantly affect the executions of multi-threaded\nprograms. Hence, one has to recur the results of data races to\ndeterministically replay a multi-threaded program. However, data races are\nconcealed in enormous number of memory operations in a program. Due to the\ndifficulty of accurately identifying data races, previous multi-threaded\ndeterministic record/replay schemes for commodity multi-processor system give\nup to record data races directly. Consequently, they either record all shared\nmemory operations, which brings remarkable slowdown to the production run, or\nrecord the synchronization only, which introduces significant efforts to\nreplay.\n  Inspired by the advances in data race detection, we propose an efficient\nsoftware-only deterministic replay scheme for commodity multi-processor\nsystems, which is named RacX. The key insight of RacX is as follows: although\nit is NP-hard to accurately identify the existence of data races between a pair\nof memory operations, we can find out all potential data races in a\nmulti-threaded program, in which the false positives can be reduced to a small\namount with our automatic false positive reduction techniques. As a result,\nRacX can efficiently monitor all potential data races to deterministically\nreplay a multi-threaded program.\n  To evaluate RacX, we have carried out experiments over a number of well-known\nmulti-threaded programs from SPLASH-2 benchmark suite and large-scale\ncommercial programs. RacX can precisely recur production runs of these programs\nwith value determinism. Averagely, RacX causes only about 1.21%, 1.89%, 2.20%,\nand 8.41% slowdown to the original run during recording (for 2-, 4-, 8- and\n16-thread programs, respectively). The soundness, efficiency, scalability, and\nportability of RacX well demonstrate its superiority.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jul 2011 11:51:06 GMT"}, {"version": "v2", "created": "Tue, 12 Jul 2011 08:46:58 GMT"}], "update_date": "2011-07-13", "authors_parsed": [["Guo", "Qi", ""], ["Chen", "Yunji", ""], ["chen", "Tianshi", ""], ["Li", "Ling", ""]]}, {"id": "1107.2157", "submitter": "Matthew Sottile", "authors": "Matthew J. Sottile and Craig E Rasmussen and Wayne N. Weseloh and\n  Robert W. Robey and Daniel Quinlan and Jeffrey Overbey", "title": "ForOpenCL: Transformations Exploiting Array Syntax in Fortran for\n  Accelerator Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emerging GPU architectures for high performance computing are well suited to\na data-parallel programming model. This paper presents preliminary work\nexamining a programming methodology that provides Fortran programmers with\naccess to these emerging systems. We use array constructs in Fortran to show\nhow this infrequently exploited, standardized language feature is easily\ntransformed to lower-level accelerator code. The transformations in ForOpenCL\nare based on a simple mapping from Fortran to OpenCL. We demonstrate, using a\nstencil code solving the shallow-water fluid equations, that the performance of\nthe ForOpenCL compiler-generated transformations is comparable with that of\nhand-optimized OpenCL code.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jul 2011 22:07:32 GMT"}], "update_date": "2011-07-13", "authors_parsed": [["Sottile", "Matthew J.", ""], ["Rasmussen", "Craig E", ""], ["Weseloh", "Wayne N.", ""], ["Robey", "Robert W.", ""], ["Quinlan", "Daniel", ""], ["Overbey", "Jeffrey", ""]]}, {"id": "1107.2437", "submitter": "Ignacio Vega-Paez M en C", "authors": "Harold V. McIntosh", "title": "A CONVERT compiler of REC for PDP-8", "comments": "This paper is seminal formal definition for REC language was\n  published in \"Acta Mexicana de Ciencia y Tecnolog\\'ia\" of IPN, Jan-April\n  1968. REC is a programming language of extremely simple structure and what it\n  was proved that the well publicized inconvenience of programming without a\n  goto was a myth in Sixties endings", "journal-ref": "Acta Mexicana de Ciencia y Tecnologia of IPN, Vol. II, No. 1, pp\n  33-43, Jan-April 1968, Mexico, D.F", "doi": null, "report-no": "IBP-Memo 2011-07", "categories": "cs.PL", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  REC (REGULAR EXPRESSION COMPILER) is a programming language of simple\nstructure developed originally for the PDP-8 computer of the Digital Equipment,\nCorporation, but readily adaptable to any other general purpose computer. It\nhas been used extensively in teaching Algebra and Numerical Analysis in the\nEscuela Superior de F\\'isica y Matem\\'aticas of the Instituto Polit\\'ecnico\nNacional. Moreover, the fact that the same control language, REC, is equally\napplicable and equally efficient over the whole range of computer facilities\navailable to the students gives a very welcome coherence to the entire teaching\nprogram, including the course of Mathematical Logic which is devoted to the\ntheoretical aspects of such matters.\n  REC; derives its appeal from the fact that computers can be regarded\nreasonably well as Turing Machines. The REC notation is simply a manner of\nwriting regular expression, somewhat more amenable to programming the Turing\nMachine which they control. If one does not wish to think so strictly in terms\nof Turing Machines, REC expressions still provide a means of defining the flow\nof control in a program which is quite convenient for many applications.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jul 2011 23:43:18 GMT"}], "update_date": "2011-07-15", "authors_parsed": [["McIntosh", "Harold V.", ""]]}, {"id": "1107.3193", "submitter": "Chengpu Wang", "authors": "Chengpu Wang", "title": "Type Expressiveness and Its Application in Separation of Behavior\n  Programming and Data Management Programming", "comments": "13 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new behavior descriptive entity type called spec is proposed, which\ncombines the traditional interface with test rules and test cases, to\ncompletely specify the desired behavior of each method, and to enforce the\nbehavior-wise correctness of all compiled units. Using spec, a new programming\nparadigm is proposed, which allows the separation programming space into 1) a\nbehavior domain to aggregate all behavior programming in the format of specs,\n2) a object domain to bind each concrete spec to its data representation in a\nparticular address space, and 3) a realization domain to connect the behavior\ndomain and the object domain. Such separation guarantees the strictness of\nbehavior satisfaction at compile time, while allows flexibility of dynamical\nbinding of actual implementation at runtime. A new convention call type\nexpressiveness to allow data exchange between different programming languages\nand between different software environments is also proposed.\n", "versions": [{"version": "v1", "created": "Sat, 16 Jul 2011 03:03:10 GMT"}, {"version": "v10", "created": "Wed, 20 Aug 2014 04:36:19 GMT"}, {"version": "v2", "created": "Thu, 21 Jul 2011 10:57:53 GMT"}, {"version": "v3", "created": "Wed, 27 Jul 2011 11:12:39 GMT"}, {"version": "v4", "created": "Wed, 10 Aug 2011 01:44:52 GMT"}, {"version": "v5", "created": "Tue, 27 Sep 2011 02:10:59 GMT"}, {"version": "v6", "created": "Thu, 13 Oct 2011 01:01:00 GMT"}, {"version": "v7", "created": "Fri, 18 Nov 2011 16:09:51 GMT"}, {"version": "v8", "created": "Sat, 3 Dec 2011 05:57:19 GMT"}, {"version": "v9", "created": "Tue, 19 Aug 2014 03:54:50 GMT"}], "update_date": "2014-08-21", "authors_parsed": [["Wang", "Chengpu", ""]]}, {"id": "1107.3539", "submitter": "David Van Horn", "authors": "David Van Horn and Matthew Might", "title": "Systematic Abstraction of Abstract Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a derivational approach to abstract interpretation that yields\nnovel and transparently sound static analyses when applied to well-established\nabstract machines for higher-order and imperative programming languages. To\ndemonstrate the technique and support our claim, we transform the CEK machine\nof Felleisen and Friedman, a lazy variant of Krivine's machine, and the\nstack-inspecting CM machine of Clements and Felleisen into abstract\ninterpretations of themselves. The resulting analyses bound temporal ordering\nof program events; predict return-flow and stack-inspection behavior; and\napproximate the flow and evaluation of by-need parameters. For all of these\nmachines, we find that a series of well-known concrete machine refactorings,\nplus a technique of store-allocated continuations, leads to machines that\nabstract into static analyses simply by bounding their stores. We demonstrate\nthat the technique scales up uniformly to allow static analysis of realistic\nlanguage features, including tail calls, conditionals, side effects,\nexceptions, first-class continuations, and even garbage collection. In order to\nclose the gap between formalism and implementation, we provide translations of\nthe mathematics as running Haskell code for the initial development of our\nmethod.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jul 2011 19:44:11 GMT"}], "update_date": "2011-07-19", "authors_parsed": [["Van Horn", "David", ""], ["Might", "Matthew", ""]]}, {"id": "1107.4422", "submitter": "G. Ramalingam", "authors": "Jyotirmoy Deshmukh (University of Texas at Austin), G. Ramalingam\n  (Microsoft Research India), Venkatesh-Prasad Ranganath (Microsoft Research\n  India), Kapil Vaswani (Microsoft Research India)", "title": "Logical Concurrency Control from Sequential Proofs", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 7, Issue 3 (September\n  2, 2011) lmcs:986", "doi": "10.2168/LMCS-7(3:10)2011", "report-no": null, "categories": "cs.PL cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are interested in identifying and enforcing the isolation requirements of\na concurrent program, i.e., concurrency control that ensures that the program\nmeets its specification. The thesis of this paper is that this can be done\nsystematically starting from a sequential proof, i.e., a proof of correctness\nof the program in the absence of concurrent interleavings. We illustrate our\nthesis by presenting a solution to the problem of making a sequential library\nthread-safe for concurrent clients. We consider a sequential library annotated\nwith assertions along with a proof that these assertions hold in a sequential\nexecution. We show how we can use the proof to derive concurrency control that\nensures that any execution of the library methods, when invoked by concurrent\nclients, satisfies the same assertions. We also present an extension to\nguarantee that the library methods are linearizable or atomic.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jul 2011 06:10:34 GMT"}, {"version": "v2", "created": "Thu, 1 Sep 2011 07:24:16 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Deshmukh", "Jyotirmoy", "", "University of Texas at Austin"], ["Ramalingam", "G.", "", "Microsoft Research India"], ["Ranganath", "Venkatesh-Prasad", "", "Microsoft Research\n  India"], ["Vaswani", "Kapil", "", "Microsoft Research India"]]}, {"id": "1107.4478", "submitter": "Ugo Dal Lago", "authors": "Ugo Dal Lago and Paolo Di Giamberardino", "title": "Soft Session Types (Long Version)", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how systems of sessions types can enforce interactions to be bounded\nfor all typable processes. The type system we propose is based on Lafont's soft\nlinear logic and is strongly inspired by recent works about session types as\nintuitionistic linear logic formulas. Our main result is the existence, for\nevery typable process, of a polynomial bound on the length of any reduction\nsequence starting from it and on the size of any of its reducts.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jul 2011 10:57:08 GMT"}, {"version": "v2", "created": "Mon, 29 Aug 2011 14:38:27 GMT"}, {"version": "v3", "created": "Tue, 3 Jan 2012 09:20:22 GMT"}], "update_date": "2012-01-04", "authors_parsed": [["Lago", "Ugo Dal", ""], ["Di Giamberardino", "Paolo", ""]]}, {"id": "1107.4724", "submitter": "Pablo Chico de Guzman Huerta", "authors": "Pablo Chico de Guzm\\'an, Amadeo Casas, Manuel Carro and Manuel V.\n  Hermenegildo", "title": "Parallel Backtracking with Answer Memoing for Independent\n  And-Parallelism", "comments": "19 pages, 15 figures, uses tlp style", "journal-ref": "Theory and Practice of Logic Programming (2011) volume 11, issue\n  4-5, pages 555-574", "doi": null, "report-no": null, "categories": "cs.PL cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Goal-level Independent and-parallelism (IAP) is exploited by scheduling for\nsimultaneous execution two or more goals which will not interfere with each\nother at run time. This can be done safely even if such goals can produce\nmultiple answers. The most successful IAP implementations to date have used\nrecomputation of answers and sequentially ordered backtracking. While in\nprinciple simplifying the implementation, recomputation can be very inefficient\nif the granularity of the parallel goals is large enough and they produce\nseveral answers, while sequentially ordered backtracking limits parallelism.\nAnd, despite the expected simplification, the implementation of the classic\nschemes has proved to involve complex engineering, with the consequent\ndifficulty for system maintenance and extension, while still frequently running\ninto the well-known trapped goal and garbage slot problems. This work presents\nan alternative parallel backtracking model for IAP and its implementation. The\nmodel features parallel out-of-order (i.e., non-chronological) backtracking and\nrelies on answer memoization to reuse and combine answers. We show that this\napproach can bring significant performance advantages. Also, it can bring some\nsimplification to the important engineering task involved in implementing the\nbacktracking mechanism of previous approaches.\n", "versions": [{"version": "v1", "created": "Sun, 24 Jul 2011 06:28:05 GMT"}], "update_date": "2011-07-26", "authors_parsed": [["de Guzm\u00e1n", "Pablo Chico", ""], ["Casas", "Amadeo", ""], ["Carro", "Manuel", ""], ["Hermenegildo", "Manuel V.", ""]]}, {"id": "1107.4747", "submitter": "Fabrizio Riguzzi PhD", "authors": "Fabrizio Riguzzi and Terrance Swift", "title": "The PITA System: Tabling and Answer Subsumption for Reasoning under\n  Uncertainty", "comments": null, "journal-ref": "Theory and Practice of Logic Programming, 27th International\n  Conference on Logic Programming (ICLP'11) Special Issue, 11(4-5), 433-449,\n  2011", "doi": "10.1017/S147106841100010X", "report-no": null, "categories": "cs.AI cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real world domains require the representation of a measure of\nuncertainty. The most common such representation is probability, and the\ncombination of probability with logic programs has given rise to the field of\nProbabilistic Logic Programming (PLP), leading to languages such as the\nIndependent Choice Logic, Logic Programs with Annotated Disjunctions (LPADs),\nProblog, PRISM and others. These languages share a similar distribution\nsemantics, and methods have been devised to translate programs between these\nlanguages. The complexity of computing the probability of queries to these\ngeneral PLP programs is very high due to the need to combine the probabilities\nof explanations that may not be exclusive. As one alternative, the PRISM system\nreduces the complexity of query answering by restricting the form of programs\nit can evaluate. As an entirely different alternative, Possibilistic Logic\nPrograms adopt a simpler metric of uncertainty than probability. Each of these\napproaches -- general PLP, restricted PLP, and Possibilistic Logic Programming\n-- can be useful in different domains depending on the form of uncertainty to\nbe represented, on the form of programs needed to model problems, and on the\nscale of the problems to be solved. In this paper, we show how the PITA system,\nwhich originally supported the general PLP language of LPADs, can also\nefficiently support restricted PLP and Possibilistic Logic Programs. PITA\nrelies on tabling with answer subsumption and consists of a transformation\nalong with an API for library functions that interface with answer subsumption.\n", "versions": [{"version": "v1", "created": "Sun, 24 Jul 2011 11:22:41 GMT"}], "update_date": "2011-07-26", "authors_parsed": [["Riguzzi", "Fabrizio", ""], ["Swift", "Terrance", ""]]}, {"id": "1107.4751", "submitter": "Benedikt Ahrens", "authors": "Benedikt Ahrens (University of Nice Sophia-Antipolis)", "title": "Extended Initiality for Typed Abstract Syntax", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 8, Issue 2 (April 6,\n  2012) lmcs:1193", "doi": "10.2168/LMCS-8(2:1)2012", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Initial Semantics aims at interpreting the syntax associated to a signature\nas the initial object of some category of 'models', yielding induction and\nrecursion principles for abstract syntax. Zsid\\'o proves an initiality result\nfor simply-typed syntax: given a signature S, the abstract syntax associated to\nS constitutes the initial object in a category of models of S in monads.\nHowever, the iteration principle her theorem provides only accounts for\ntranslations between two languages over a fixed set of object types. We\ngeneralize Zsid\\'o's notion of model such that object types may vary, yielding\na larger category, while preserving initiality of the syntax therein. Thus we\nobtain an extended initiality theorem for typed abstract syntax, in which\ntranslations between terms over different types can be specified via the\nassociated category-theoretic iteration operator as an initial morphism. Our\ndefinitions ensure that translations specified via initiality are type-safe,\ni.e. compatible with the typing in the source and target language in the\nobvious sense. Our main example is given via the propositions-as-types\nparadigm: we specify propositions and inference rules of classical and\nintuitionistic propositional logics through their respective typed signatures.\nAfterwards we use the category--theoretic iteration operator to specify a\ndouble negation translation from the former to the latter. A second example is\ngiven by the signature of PCF. For this particular case, we formalize the\ntheorem in the proof assistant Coq. Afterwards we specify, via the\ncategory-theoretic iteration operator, translations from PCF to the untyped\nlambda calculus.\n", "versions": [{"version": "v1", "created": "Sun, 24 Jul 2011 12:32:49 GMT"}, {"version": "v2", "created": "Wed, 28 Mar 2012 15:38:05 GMT"}, {"version": "v3", "created": "Thu, 5 Apr 2012 07:04:45 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Ahrens", "Benedikt", "", "University of Nice Sophia-Antipolis"]]}, {"id": "1107.5252", "submitter": "Benedikt Ahrens", "authors": "Benedikt Ahrens", "title": "Modules over relative monads for syntax and semantics", "comments": "v2: - Abstract and Introduction completely rewritten - Addition of\n  examples and remarks in Secs. 1 and 2 - Sec 3 now describes the\n  implementation in proof assistant Coq of the main theorem v3: - final version\n  for publication in MSCS", "journal-ref": "Math. Struct. Comp. Sci. 26 (2016) 3-37", "doi": "10.1017/S0960129514000103", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give an algebraic characterization of the syntax and semantics of a class\nof languages with variable binding.\n  We introduce a notion of 2-signature: such a signature specifies not only the\nterms of a language, but also reduction rules on those terms. To any\n2-signature $S$ we associate a category of \"models\" of $S$. This category has\nan initial object, which integrates the terms freely generated by $S$, and\nwhich is equipped with reductions according to the inequations given in $S$. We\ncall this initial object the language generated by $S$. Models of a\n2--signature are built from relative monads and modules over such monads.\nThrough the use of monads, the models---and in particular, the initial\nmodel---come equipped with a substitution operation that is compatible with\nreduction in a suitable sense.\n  The initiality theorem is formalized in the proof assistant Coq, yielding a\nmachinery which, when fed with a 2-signature, provides the associated\nprogramming language with reduction relation and certified substitution.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jul 2011 16:06:20 GMT"}, {"version": "v2", "created": "Sun, 6 Nov 2011 23:42:30 GMT"}, {"version": "v3", "created": "Tue, 19 Nov 2013 01:03:24 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Ahrens", "Benedikt", ""]]}, {"id": "1107.5408", "submitter": "Ant\\'onio Porto", "authors": "Ant\\'onio Porto", "title": "A structured alternative to Prolog with simple compositional semantics", "comments": "27th Int'l. Conference on Logic Programming (ICLP'11) Special Issue,\n  2011", "journal-ref": "Theory and Practice of Logic Programming 11(4-5), 611-627, 2011", "doi": "10.1017/S1471068411000202", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prolog's very useful expressive power is not captured by traditional logic\nprogramming semantics, due mainly to the cut and goal and clause order. Several\nalternative semantics have been put forward, exposing operational details of\nthe computation state. We propose instead to redesign Prolog around structured\nalternatives to the cut and clauses, keeping the expressive power and\ncomputation model but with a compositional denotational semantics over much\nsimpler states-just variable bindings. This considerably eases reasoning about\nprograms, by programmers and tools such as a partial evaluator, with safe\nunfolding of calls through predicate definitions. An if-then-else across\nclauses replaces most uses of the cut, but the cut's full power is achieved by\nan until construct. Disjunction, conjunction and until, along with unification,\nare the primitive goal types with a compositional semantics yielding sequences\nof variable-binding solutions. This extends to programs via the usual technique\nof a least fixpoint construction. A simple interpreter for Prolog in the\nalternative language, and a definition of until in Prolog, establish the\nidentical expressive power of the two languages. Many useful control constructs\nare derivable from the primitives, and the semantic framework illuminates the\ndiscussion of alternative ones. The formalisation rests on a term language with\nvariable abstraction as in the {\\lambda}-calculus. A clause is an abstraction\non the call arguments, a continuation, and the local variables. It can be\ninclusive or exclusive, expressing a local case bound to a continuation by\neither a disjunction or an if-then-else. Clauses are open definitions, composed\n(and closed) with simple functional application ({\\beta}-reduction). This paves\nthe way for a simple account of flexible module composition mechanisms. Cube, a\nconcrete language with the exposed principles, has been implemented.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jul 2011 08:24:34 GMT"}], "update_date": "2011-07-28", "authors_parsed": [["Porto", "Ant\u00f3nio", ""]]}, {"id": "1107.5556", "submitter": "Flavio Cruz", "authors": "Flavio Cruz and Ricardo Rocha", "title": "Efficient Instance Retrieval of Subgoals for Subsumptive Tabled\n  Evaluation of Logic Programs", "comments": "Theory and Practice of Logic Programming, 27th Int'l. Conference on\n  Logic Programming (ICLP 2011) Special Issue, volume 11, issue 4-5", "journal-ref": "Theory and Practice of Logic Programming, Volume 11, Special Issue\n  4-5, July 2011, pp 697-712 Published Cambridge University Press 2011", "doi": "10.1017/S1471068411000251", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tabled evaluation is an implementation technique that solves some problems of\ntraditional Prolog systems in dealing with recursion and redundant\ncomputations. Most tabling engines determine if a tabled subgoal will produce\nor consume answers by using variant checks. A more refined method, named call\nsubsumption, considers that a subgoal A will consume from a subgoal B if A is\nsubsumed by (an instance of) B, thus allowing greater answer reuse. We recently\ndeveloped an extension, called Retroactive Call Subsumption, that improves upon\ncall subsumption by supporting bidirectional sharing of answers between\nsubsumed/subsuming subgoals. In this paper, we present both an algorithm and an\nextension to the table space data structures to efficiently implement instance\nretrieval of subgoals for subsumptive tabled evaluation of logic programs.\nExperiments results using the YapTab tabling system show that our\nimplementation performs quite well on some complex benchmarks and is robust\nenough to handle a large number of subgoals without performance degradation.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jul 2011 18:31:13 GMT"}], "update_date": "2011-07-29", "authors_parsed": [["Cruz", "Flavio", ""], ["Rocha", "Ricardo", ""]]}, {"id": "1107.5594", "submitter": "Aslan Askarov", "authors": "Aslan Askarov (Cornell University), Andrew Myers (Cornell University)", "title": "Attacker Control and Impact for Confidentiality and Integrity", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 7, Issue 3 (September\n  26, 2011) lmcs:987", "doi": "10.2168/LMCS-7(3:17)2011", "report-no": null, "categories": "cs.PL cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language-based information flow methods offer a principled way to enforce\nstrong security properties, but enforcing noninterference is too inflexible for\nrealistic applications. Security-typed languages have therefore introduced\ndeclassification mechanisms for relaxing confidentiality policies, and\nendorsement mechanisms for relaxing integrity policies. However, a continuing\nchallenge has been to define what security is guaranteed when such mechanisms\nare used. This paper presents a new semantic framework for expressing security\npolicies for declassification and endorsement in a language-based setting. The\nkey insight is that security can be characterized in terms of the influence\nthat declassification and endorsement allow to the attacker. The new framework\nintroduces two notions of security to describe the influence of the attacker.\nAttacker control defines what the attacker is able to learn from observable\neffects of this code; attacker impact captures the attacker's influence on\ntrusted locations. This approach yields novel security conditions for checked\nendorsements and robust integrity. The framework is flexible enough to recover\nand to improve on the previously introduced notions of robustness and qualified\nrobustness. Further, the new security conditions can be soundly enforced by a\nsecurity type system. The applicability and enforcement of the new policies is\nillustrated through various examples, including data sanitization and\nauthentication.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jul 2011 21:19:34 GMT"}, {"version": "v2", "created": "Fri, 23 Sep 2011 13:40:07 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Askarov", "Aslan", "", "Cornell University"], ["Myers", "Andrew", "", "Cornell University"]]}]