[{"id": "1612.00277", "submitter": "Jacques-Henri Jourdan", "authors": "Jacques-Henri Jourdan (MPI Software systems, GALLIUM)", "title": "Sparsity Preserving Algorithms for Octagons", "comments": "in Isabella Mastroeni. Numerical and symbolic abstract domains, Sep\n  2016, Edinburgh, United Kingdom. Elsevier, Numerical and symbolic abstract\n  domains, pp.14, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.DS cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Known algorithms for manipulating octagons do not preserve their sparsity,\nleading typically to quadratic or cubic time and space complexities even if no\nrelation among variables is known when they are all bounded. In this paper, we\npresent new algorithms, which use and return octagons represented as weakly\nclosed difference bound matrices, preserve the sparsity of their input and have\nbetter performance in the case their inputs are sparse. We prove that these\nalgorithms are as precise as the known ones.\n", "versions": [{"version": "v1", "created": "Thu, 1 Dec 2016 14:44:20 GMT"}], "update_date": "2016-12-02", "authors_parsed": [["Jourdan", "Jacques-Henri", "", "MPI Software systems, GALLIUM"]]}, {"id": "1612.00666", "submitter": "Christian Johansen", "authors": "Christian Johansen and Olaf Owe", "title": "Dynamic Structural Operational Semantics", "comments": "36 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We introduce Dynamic SOS as a framework for describing semantics of\nprogramming languages that include dynamic software upgrades, for upgrading\nsoftware code during run-time. Dynamic SOS (DSOS) is built on top of the\nModular SOS of P. Mosses, with an underlying category theory formalization. The\nidea of Dynamic SOS is to bring out the essential differences between dynamic\nupgrade constructs and program execution constructs. The important feature of\nModular SOS (MSOS) that we exploit in DSOS is the sharp separation of the\nprogram execution code from the additional (data) structures needed at\nrun-time. In DSOS we aim to achieve the same modularity and decoupling for\ndynamic software upgrades. This is partly motivated by the long term goal of\nhaving machine-checkable proofs for general results like type safety.\n  We exemplify Dynamic SOS on two languages supporting dynamic software\nupgrades, namely the C-like Proteus, which supports updating of variables,\nfunctions, records, or types at specific program points, and Creol, which\nsupports dynamic class upgrades in the setting of concurrent objects. Existing\ntype analyses for software upgrades can be done on top of DSOS too, as we\nillustrate for Proteus.\n  As a side result we define of a general encapsulating construction on Modular\nSOS useful in situations where a form of encapsulation of the execution is\nneeded. We use encapsulation in the Creol setting of concurrent object-oriented\nprogramming with active objects and asynchronous method calls.\n", "versions": [{"version": "v1", "created": "Fri, 2 Dec 2016 12:56:10 GMT"}, {"version": "v2", "created": "Fri, 20 Jul 2018 18:20:33 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Johansen", "Christian", ""], ["Owe", "Olaf", ""]]}, {"id": "1612.00669", "submitter": "Matthias Keil", "authors": "Matthias Keil, Peter Thiemann", "title": "Transaction-based Sandboxing for JavaScript", "comments": "Technical Report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Today's JavaScript applications are composed of scripts from different\norigins that are loaded at run time. As not all of these origins are equally\ntrusted, the execution of these scripts should be isolated from one another.\nHowever, some scripts must access the application state and some may be allowed\nto change it, while preserving the confidentiality and integrity constraints of\nthe application.\n  This paper presents design and implementation of DecentJS, a\nlanguage-embedded sandbox for full JavaScript. It enables scripts to run in a\nconfigurable degree of isolation with fine-grained access control. It provides\na transactional scope in which effects are logged for review by the access\ncontrol policy. After inspection of the log, effects can be committed to the\napplication state or rolled back.\n  The implementation relies on JavaScript proxies to guarantee full\ninterposition for the full language and for all code, including dynamically\nloaded scripts and code injected via eval. Its only restriction is that scripts\nmust be compliant with JavaScript's strict mode.\n", "versions": [{"version": "v1", "created": "Fri, 2 Dec 2016 13:11:41 GMT"}, {"version": "v2", "created": "Tue, 17 Jan 2017 14:00:55 GMT"}], "update_date": "2017-01-18", "authors_parsed": [["Keil", "Matthias", ""], ["Thiemann", "Peter", ""]]}, {"id": "1612.00670", "submitter": "Johannes Emerich", "authors": "Johannes Emerich", "title": "How Are Programs Found? Speculating About Language Ergonomics With\n  Curry-Howard", "comments": null, "journal-ref": "Proceedings of the 2016 ACM International Symposium on New Ideas,\n  New Paradigms, and Reflections on Programming and Software (Onward! 2016).\n  ACM, New York, NY, USA, 212-223", "doi": "10.1145/2986012.2986030", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Functional languages with strong static type systems have beneficial\nproperties to help ensure program correctness and reliability. Surprisingly,\ntheir practical significance in applications is low relative to other languages\nlacking in those dimensions. In this paper, the programs-as-proofs analogy is\ntaken seriously to gain speculative insights by analysis of creation habits in\nthe proof-centric discipline of mathematics. Viewed in light of this analogy, a\nsampling of mathematicians' attitudes towards formal proof suggests that the\ncrucial role of intuition and experimentation in programming tasks may be under\nappreciated, hinting at a possible explanation of the challenges rigorously\ndisciplined languages face in practical applications.\n", "versions": [{"version": "v1", "created": "Fri, 2 Dec 2016 13:18:58 GMT"}], "update_date": "2016-12-05", "authors_parsed": [["Emerich", "Johannes", ""]]}, {"id": "1612.00693", "submitter": "Ralph Matthes", "authors": "Benedikt Ahrens and Ralph Matthes and Anders M\\\"ortberg", "title": "From signatures to monads in UniMath", "comments": "30 pages", "journal-ref": "J Autom Reasoning (2019) Vol 63, 285-318", "doi": "10.1007/s10817-018-9474-4", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The term UniMath refers both to a formal system for mathematics, as well as a\ncomputer-checked library of mathematics formalized in that system. The UniMath\nsystem is a core dependent type theory, augmented by the univalence axiom. The\nsystem is kept as small as possible in order to ease verification of it - in\nparticular, general inductive types are not part of the system.\n  In this work, we partially remedy the lack of inductive types by constructing\nsome datatypes and their associated induction principles from other type\nconstructors. This involves a formalization of a category-theoretic result on\nthe construction of initial algebras, as well as a mechanism to conveniently\nuse the datatypes obtained. We also connect this construction to a previous\nformalization of substitution for languages with variable binding. Altogether,\nwe construct a framework that allows us to concisely specify, via a simple\nnotion of binding signature, a language with variable binding. From such a\nspecification we obtain the datatype of terms of that language, equipped with a\ncertified monadic substitution operation and a suitable recursion scheme. Using\nthis we formalize the untyped lambda calculus and the raw syntax of\nMartin-L\\\"of type theory.\n", "versions": [{"version": "v1", "created": "Fri, 2 Dec 2016 14:40:57 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Ahrens", "Benedikt", ""], ["Matthes", "Ralph", ""], ["M\u00f6rtberg", "Anders", ""]]}, {"id": "1612.01325", "submitter": "Piotr Danilewski", "authors": "Piotr Danilewski (1 and 2 and 3) and Philipp Slusallek (1 and 2 and 4)\n  ((1) Saarland University, Germany, (2) Intel Visual Computing Institute,\n  Germany, (3) Theoretical Computer Science, Jagiellonian University, Poland,\n  (4) Deutsches Forschungszentrum f\\\"ur K\\\"unstliche Intelligenz, Germany)", "title": "Building Code with Dynamic Staging", "comments": "11 pages, 2 figures, 14 listings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When creating a new domain-specific language (DSL) it is common to embed it\nas a part of a flexible host language, rather than creating it entirely from\nscratch. The semantics of an embedded DSL (EDSL) is either given directly as a\nset of functions (shallow embedding), or an AST is constructed that is later\nprocessed (deep embedding). Typically, the deep embedding is used when the EDSL\nspecifies domain-specific optimizations (DSO) in a form of AST transformations.\n  In this paper we show that deep embedding is not necessary to specify most\noptimizations. We define language semantics as action functions that are\nexecuted during parsing. These actions build incrementally a new, arbitrary\ncomplex program function.\n  The EDSL designer is able to specify many aspects of the semantics as a\nrunnable code, such as variable scoping rules, custom type checking, arbitrary\ncontrol flow structures, or DSO. A sufficiently powerful staging mechanism\nhelps assembling the code from different actions, as well as evaluate the\nsemantics in arbitrarily many stages. In the end, we obtain code that is as\nefficient as one written by hand.\n  We never create any object representation of the code. No external traversing\nalgorithm is used to process the code. All program fragments are functions with\ntheir entire semantics embedded within the function bodies. This approach\nallows reusing the code between EDSL and the host language, as well as\ncombining actions of many different EDSLs.\n", "versions": [{"version": "v1", "created": "Mon, 5 Dec 2016 12:20:32 GMT"}], "update_date": "2016-12-06", "authors_parsed": [["Danilewski", "Piotr", "", "1 and 2 and 3"], ["Slusallek", "Philipp", "", "1 and 2 and 4"]]}, {"id": "1612.01637", "submitter": "EPTCS", "authors": "Paolo Bottoni (Sapienza University), Andrew Fish (University of\n  Brighton), Francesco Parisi Presicce (Sapienza University)", "title": "Type Annotation for Adaptive Systems", "comments": "In Proceedings GaM 2016, arXiv:1612.01053", "journal-ref": "EPTCS 231, 2016, pp. 1-15", "doi": "10.4204/EPTCS.231.1", "report-no": null, "categories": "cs.SE cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce type annotations as a flexible typing mechanism for graph\nsystems and discuss their advantages with respect to classical typing based on\ngraph morphisms. In this approach the type system is incorporated with the\ngraph and elements can adapt to changes in context by changing their type\nannotations. We discuss some case studies in which this mechanism is relevant.\n", "versions": [{"version": "v1", "created": "Tue, 6 Dec 2016 02:36:04 GMT"}], "update_date": "2016-12-07", "authors_parsed": [["Bottoni", "Paolo", "", "Sapienza University"], ["Fish", "Andrew", "", "University of\n  Brighton"], ["Presicce", "Francesco Parisi", "", "Sapienza University"]]}, {"id": "1612.02547", "submitter": "Hiun Kim", "authors": "Hiun Kim", "title": "Self-composable Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many variability management techniques rely on sophisticated language\nextension or tools to support it. While this can provide dedicated syntax and\noperational mechanism but it struggling practical adaptation for the cost of\nadapting new technology as part of development process. We present\nSelf-composable Programming, a language-driven, composition-based variability\nimplementation which takes an object-oriented approach to modeling and\ncomposing behaviors in software. Self-composable Programming introduces\nhierarchical relationship of behavior by providing concepts of abstract\nfunction, which modularise commonalities, and specific function which inherits\nfrom abstract function and be apply refinement to contain variabilities to\nfulfill desired functionality. Various object-oriented techniques can\napplicable in the refinement process including explicit method-based, and\nimplicit traits-based refinement. In order to evaluate the potential\nindependence of behavior from the object by applying object-orientation to\nfunction, we compare it to Aspect-oriented Programming both conceptually and\nempirically.\n", "versions": [{"version": "v1", "created": "Thu, 8 Dec 2016 07:02:49 GMT"}, {"version": "v2", "created": "Wed, 1 Mar 2017 13:01:07 GMT"}], "update_date": "2017-03-03", "authors_parsed": [["Kim", "Hiun", ""]]}, {"id": "1612.03488", "submitter": "Piotr Danilewski", "authors": "Piotr Danilewski (1 and 2 and 3), Philipp Slusallek (1 and 2 and 4)\n  ((1) Saarland University, Germany, (2) Intel Visual Computing Institute,\n  Germany, (3) Theoretical Computer Science, Jagiellonian University, Poland,\n  (4) Deutsches Forschungszentrum f\\\"ur K\\\"unstliche Intelligenz, Germany)", "title": "ManyDSL: A Host for Many Languages", "comments": "14 pages, 11 code listings, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain-specific languages are becoming increasingly important. Almost every\napplication touches multiple domains. But how to define, use, and combine\nmultiple DSLs within the same application?\n  The most common approach is to split the project along the domain boundaries\ninto multiple pieces and files. Each file is then compiled separately.\nAlternatively, multiple languages can be embedded in a flexible host language:\nwithin the same syntax a new domain semantic is provided. In this paper we\nfollow a less explored route of metamorphic languages. These languages are able\nto modify their own syntax and semantics on the fly, thus becoming a more\nflexible host for DSLs.\n  Our language allows for dynamic creation of grammars and switching languages\nwhere needed. We achieve this through a novel concept of Syntax-Directed\nExecution. A language grammar includes semantic actions that are pieces of\nfunctional code executed immediately during parsing. By avoiding additional\nintermediate representation, connecting actions from different languages and\ndomains is greatly simplified. Still, actions can generate highly specialized\ncode though lambda encapsulation and Dynamic Staging.\n", "versions": [{"version": "v1", "created": "Sun, 11 Dec 2016 21:58:17 GMT"}], "update_date": "2016-12-13", "authors_parsed": [["Danilewski", "Piotr", "", "1 and 2 and 3"], ["Slusallek", "Philipp", "", "1 and 2 and 4"]]}, {"id": "1612.03813", "submitter": "Daniel Kulesz", "authors": "Daniel Kulesz and Verena K\\\"afer and Stefan Wagner", "title": "Spreadsheet Guardian: An Approach to Protecting Semantic Correctness\n  throughout the Evolution of Spreadsheets", "comments": "30 pages, 15 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spreadsheets are powerful tools which play a business-critical role in many\norganizations. However, many bad decisions taken due to faulty spreadsheets\nshow that these tools need serious quality assurance. Furthermore, while\ncollaboration on spreadsheets for maintenance tasks is common, there has been\nalmost no support for ensuring that the spreadsheets remain correct during this\nprocess.\n  We have developed an approach named Spreadsheet Guardian which separates the\nspecification of spreadsheet test rules from their execution. By automatically\nexecuting user-defined test rules, our approach is able to detect semantic\nfaults. It also protects all collaborating spreadsheet users from introducing\nfaults during maintenance, even if only few end-users specify test rules. To\nevaluate Spreadsheet Guardian, we implemented a representative testing\ntechnique as an add-in for Microsoft Excel.\n  We evaluated the testing technique in two empirical evaluations with 29\nend-users and 42 computer science students. The results indicate that the\ntechnique is easy to learn and to apply. Furthermore, after finishing\nmaintenance, participants with spreadsheets \"protected\" by the technique are\nmore realistic about the correctness of their spreadsheets than participants\nwho employ only \"classic\", non-interactive test rules based on static analysis\ntechniques. Hence, we believe Spreadsheet Guardian can be of use for\nbusiness-critical spreadsheets.\n", "versions": [{"version": "v1", "created": "Wed, 30 Nov 2016 21:31:22 GMT"}, {"version": "v2", "created": "Thu, 19 Jan 2017 13:00:06 GMT"}, {"version": "v3", "created": "Thu, 30 Nov 2017 17:07:59 GMT"}], "update_date": "2017-12-01", "authors_parsed": [["Kulesz", "Daniel", ""], ["K\u00e4fer", "Verena", ""], ["Wagner", "Stefan", ""]]}, {"id": "1612.04610", "submitter": "Doaitse Swierstra", "authors": "S. Doaitse Swierstra and Marcos Viera and Atze Dijkstra", "title": "A Lazy Language Needs a Lazy Type System: Introducing Polymorphic\n  Contexts", "comments": null, "journal-ref": null, "doi": null, "report-no": "UU-CS-2016-012", "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most type systems that support polymorphic functions are based on a version\nof System-F. We argue that this limits useful programming paradigms for\nlanguages with lazy evaluation. We motivate an extension of System-F\nalleviating this limitation.\n  First, using a sequence of examples, we show that for lazily evaluated\nlanguages current type systems may force one to write a program in an unnatural\nway; we in particular argue that in such languages the relationship between\npolymorphic and existential types can be made more systematic by allowing to\npass back (part of) an existential result of a function call as an argument to\nthe the function call that produced that value.\n  After presenting our extension to System-F we show how we can implement the\nstrict-state thread monad $\\mathrm{ST}$ by using a returned existential type in\nspecialising the polymorphic function which returns that type. Currently this\nmonad is built-in into the runtime system of GHC and as such has become part of\nthe language.\n  Our proposed language extension, i.e. the introduction of polymorphic\ncontexts, reverses the relationship between the context of a function call and\nthe called function with respect to where it is decided with which type to\ninstantiate a type variable.\n", "versions": [{"version": "v1", "created": "Wed, 14 Dec 2016 12:46:19 GMT"}], "update_date": "2016-12-15", "authors_parsed": [["Swierstra", "S. Doaitse", ""], ["Viera", "Marcos", ""], ["Dijkstra", "Atze", ""]]}, {"id": "1612.04983", "submitter": "EPTCS", "authors": "Dirk Beyer (LMU Munich, Germany), Karlheinz Friedberger (University of\n  Passau, Germany)", "title": "A Light-Weight Approach for Verifying Multi-Threaded Programs with\n  CPAchecker", "comments": "In Proceedings MEMICS 2016, arXiv:1612.04037", "journal-ref": "EPTCS 233, 2016, pp. 61-71", "doi": "10.4204/EPTCS.233.6", "report-no": null, "categories": "cs.LO cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Verifying multi-threaded programs is becoming more and more important,\nbecause of the strong trend to increase the number of processing units per CPU\nsocket. We introduce a new configurable program analysis for verifying\nmulti-threaded programs with a bounded number of threads. We present a simple\nand yet efficient implementation as component of the existing\nprogram-verification framework CPAchecker. While CPAchecker is already\ncompetitive on a large benchmark set of sequential verification tasks, our\nextension enhances the overall applicability of the framework. Our\nimplementation of handling multiple threads is orthogonal to the abstract\ndomain of the data-flow analysis, and thus, can be combined with several\nexisting analyses in CPAchecker, like value analysis, interval analysis, and\nBDD analysis. The new analysis is modular and can be used, for example, to\nverify reachability properties as well as to detect deadlocks in the program.\nThis paper includes an evaluation of the benefit of some optimization steps\n(e.g., changing the iteration order of the reachability algorithm or applying\npartial-order reduction) as well as the comparison with other state-of-the-art\ntools for verifying multi-threaded programs.\n", "versions": [{"version": "v1", "created": "Thu, 15 Dec 2016 08:50:32 GMT"}], "update_date": "2016-12-23", "authors_parsed": [["Beyer", "Dirk", "", "LMU Munich, Germany"], ["Friedberger", "Karlheinz", "", "University of\n  Passau, Germany"]]}, {"id": "1612.06633", "submitter": "J. Garrett Morris", "authors": "J. Garrett Morris", "title": "The Best of Both Worlds: Linear Functional Programming without\n  Compromise", "comments": "Extended version", "journal-ref": null, "doi": "10.1145/2951913.2951925", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a linear functional calculus with both the safety guarantees\nexpressible with linear types and the rich language of combinators and\ncomposition provided by functional programming. Unlike previous combinations of\nlinear typing and functional programming, we compromise neither the linear side\n(for example, our linear values are first-class citizens of the language) nor\nthe functional side (for example, we do not require duplicate definitions of\ncompositions for linear and unrestricted functions). To do so, we must\ngeneralize abstraction and application to encompass both linear and\nunrestricted functions. We capture the typing of the generalized constructs\nwith a novel use of qualified types. Our system maintains the metatheoretic\nproperties of the theory of qualified types, including principal types and\ndecidable type inference. Finally, we give a formal basis for our claims of\nexpressiveness, by showing that evaluation respects linearity, and that our\nlanguage is a conservative extension of existing functional calculi.\n", "versions": [{"version": "v1", "created": "Tue, 20 Dec 2016 12:40:45 GMT"}, {"version": "v2", "created": "Thu, 16 Mar 2017 16:53:47 GMT"}], "update_date": "2017-03-17", "authors_parsed": [["Morris", "J. Garrett", ""]]}, {"id": "1612.06668", "submitter": "Aggelos Biboudis", "authors": "Oleg Kiselyov, Aggelos Biboudis, Nick Palladinos, Yannis Smaragdakis", "title": "Stream Fusion, to Completeness", "comments": null, "journal-ref": null, "doi": "10.1145/3009837.3009880", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stream processing is mainstream (again): Widely-used stream libraries are now\navailable for virtually all modern OO and functional languages, from Java to C#\nto Scala to OCaml to Haskell. Yet expressivity and performance are still\nlacking. For instance, the popular, well-optimized Java 8 streams do not\nsupport the zip operator and are still an order of magnitude slower than\nhand-written loops. We present the first approach that represents the full\ngenerality of stream processing and eliminates overheads, via the use of\nstaging. It is based on an unusually rich semantic model of stream interaction.\nWe support any combination of zipping, nesting (or flat-mapping), sub-ranging,\nfiltering, mapping-of finite or infinite streams. Our model captures\nidiosyncrasies that a programmer uses in optimizing stream pipelines, such as\nrate differences and the choice of a \"for\" vs. \"while\" loops. Our approach\ndelivers hand-written-like code, but automatically. It explicitly avoids the\nreliance on black-box optimizers and sufficiently-smart compilers, offering\nhighest, guaranteed and portable performance. Our approach relies on high-level\nconcepts that are then readily mapped into an implementation. Accordingly, we\nhave two distinct implementations: an OCaml stream library, staged via\nMetaOCaml, and a Scala library for the JVM, staged via LMS. In both cases, we\nderive libraries richer and simultaneously many tens of times faster than past\nwork. We greatly exceed in performance the standard stream libraries available\nin Java, Scala and OCaml, including the well-optimized Java 8 streams.\n", "versions": [{"version": "v1", "created": "Tue, 20 Dec 2016 14:06:34 GMT"}], "update_date": "2016-12-21", "authors_parsed": [["Kiselyov", "Oleg", ""], ["Biboudis", "Aggelos", ""], ["Palladinos", "Nick", ""], ["Smaragdakis", "Yannis", ""]]}, {"id": "1612.06740", "submitter": "Pierre Vial", "authors": "Pierre Vial", "title": "All the {\\lambda}-Terms are Meaningful for the Infinitary Relational\n  Model", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Infinite types and formulas are known to have really curious and unsound\nbehaviors. For instance, they allow to type {\\Omega}, the auto- autoapplication\nand they thus do not ensure any form of normalization/productivity. Moreover,\nin most infinitary frameworks, it is not difficult to define a type R that can\nbe assigned to every {\\lambda}-term. However, these observations do not say\nmuch about what coinductive (i.e. infinitary) type grammars are able to\nprovide: it is for instance very difficult to know what types (besides R) can\nbe assigned to a given term in this setting. We begin with a discussion on the\nexpressivity of different forms of infinite types. Then, using the\nresource-awareness of sequential intersection types (system S) and tracking, we\nprove that infinite types are able to characterize the order (arity) of every\n{\\lambda}-terms and that, in the infinitary extension of the relational model,\nevery term has a \"meaning\" i.e. a non-empty denotation. From the technical\npoint of view, we must deal with the total lack of productivity guarantee for\ntypable terms: we do so by importing methods inspired by first order model\ntheory.\n", "versions": [{"version": "v1", "created": "Tue, 20 Dec 2016 16:32:56 GMT"}, {"version": "v2", "created": "Sat, 20 Jan 2018 22:14:48 GMT"}], "update_date": "2018-01-23", "authors_parsed": [["Vial", "Pierre", ""]]}, {"id": "1612.06749", "submitter": "Oskar Schirmer", "authors": "Oskar Schirmer", "title": "GuStL - An Experimental Guarded States Language", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Programming a parallel computing system that consists of several thousands or\neven up to a million message passing processing units may ask for a language\nthat supports waiting for and sending messages over hardware channels. As\nprograms are looked upon as state machines, the language provides syntax to\nimplement a main event driven loop. The language presented herewith surely will\nnot serve as a generic programming language for any arbitrary task. Its main\npurpose is to allow for a prototypical implementation of a dynamic software\nsystem as a proof of concept.\n", "versions": [{"version": "v1", "created": "Tue, 20 Dec 2016 16:50:21 GMT"}, {"version": "v2", "created": "Tue, 10 Jul 2018 09:31:29 GMT"}], "update_date": "2018-07-11", "authors_parsed": [["Schirmer", "Oskar", ""]]}, {"id": "1612.07586", "submitter": "Nassim Seghir", "authors": "Mohamed Nassim Seghir, David Aspinall", "title": "DroidGen: Constraint-based and Data-Driven Policy Generation for Android", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present DroidGen a tool for automatic anti-malware policy inference.\nDroidGen employs a data-driven approach: it uses a training set of malware and\nbenign applications and makes call to a constraint solver to generate a policy\nunder which a maximum of malware is excluded and a maximum of benign\napplications is allowed. Preliminary results are encouraging. We are able to\nautomatically generate a policy which filters out 91% of the tested Android\nmalware. Moreover, compared to black-box machine learning classifiers, our\nmethod has the advantage of generating policies in a declarative readable\nformat. We illustrate our approach, describe its implementation and report on\nthe preliminary results.\n", "versions": [{"version": "v1", "created": "Thu, 22 Dec 2016 13:07:20 GMT"}], "update_date": "2016-12-23", "authors_parsed": [["Seghir", "Mohamed Nassim", ""], ["Aspinall", "David", ""]]}, {"id": "1612.08091", "submitter": "Damian S. Steiger", "authors": "Damian S. Steiger, Thomas H\\\"aner, Matthias Troyer", "title": "ProjectQ: An Open Source Software Framework for Quantum Computing", "comments": "Version accepted by Quantum", "journal-ref": "Quantum 2, 49 (2018)", "doi": "10.22331/q-2018-01-31-49", "report-no": null, "categories": "quant-ph cs.ET cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce ProjectQ, an open source software effort for quantum computing.\nThe first release features a compiler framework capable of targeting various\ntypes of hardware, a high-performance simulator with emulation capabilities,\nand compiler plug-ins for circuit drawing and resource estimation. We introduce\nour Python-embedded domain-specific language, present the features, and provide\nexample implementations for quantum algorithms. The framework allows testing of\nquantum algorithms through simulation and enables running them on actual\nquantum hardware using a back-end connecting to the IBM Quantum Experience\ncloud service. Through extension mechanisms, users can provide back-ends to\nfurther quantum hardware, and scientists working on quantum compilation can\nprovide plug-ins for additional compilation, optimization, gate synthesis, and\nlayout strategies.\n", "versions": [{"version": "v1", "created": "Fri, 23 Dec 2016 21:00:03 GMT"}, {"version": "v2", "created": "Mon, 29 Jan 2018 19:27:09 GMT"}], "update_date": "2018-02-01", "authors_parsed": [["Steiger", "Damian S.", ""], ["H\u00e4ner", "Thomas", ""], ["Troyer", "Matthias", ""]]}, {"id": "1612.08199", "submitter": "J. Garrett Morris", "authors": "J. Garrett Morris", "title": "A Simple Semantics for Haskell Overloading", "comments": "Originally presented at Haskell 2014", "journal-ref": null, "doi": "10.1145/2633357.2633364", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As originally proposed, type classes provide overloading and ad-hoc\ndefinition, but can still be understood (and implemented) in terms of strictly\nparametric calculi. This is not true of subsequent extensions of type classes.\nFunctional dependencies and equality constraints allow the satisfiability of\npredicates to refine typing; this means that the interpretations of equivalent\nqualified types may not be interconvertible. Overlapping instances and instance\nchains allow predicates to be satisfied without determining the implementations\nof their associated class methods, introducing truly non-parametric behavior.\nWe propose a new approach to the semantics of type classes, interpreting\npolymorphic expressions by the behavior of each of their ground instances, but\nwithout requiring that those behaviors be parametrically determined. We argue\nthat this approach both matches the intuitive meanings of qualified types and\naccurately models the behavior of programs\n", "versions": [{"version": "v1", "created": "Sat, 24 Dec 2016 16:14:50 GMT"}], "update_date": "2016-12-28", "authors_parsed": [["Morris", "J. Garrett", ""]]}, {"id": "1612.08203", "submitter": "J. Garrett Morris", "authors": "J. Garrett Morris", "title": "Variations on Variants", "comments": "Originally presented at Haskell 2014", "journal-ref": null, "doi": "10.1145/2804302.2804320", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extensible variants improve the modularity and expressiveness of programming\nlanguages: they allow program functionality to be decomposed into independent\nblocks, and allow seamless extension of existing code with both new cases of\nexisting data types and new operations over those data types.\n  This paper considers three approaches to providing extensible variants in\nHaskell. Row typing is a long understood mechanism for typing extensible\nrecords and variants, but its adoption would require extension of Haskell's\ncore type system. Alternatively, we might hope to encode extensible variants in\nterms of existing mechanisms, such as type classes. We describe an encoding of\nextensible variants using instance chains, a proposed extension of the class\nsystem. Unlike many previous encodings of extensible variants, ours does not\nrequire the definition of a new type class for each function that consumes\nvariants. Finally, we translate our encoding to use closed type families, an\nexisting feature of GHC. Doing so demonstrates the interpretation of instances\nchains and functional dependencies in closed type families.\n  One concern with encodings like ours is how completely they match the encoded\nsystem. We compare the expressiveness of our encodings with each other and with\nsystems based on row types. We find that, while equivalent terms are typable in\neach system, both encodings require explicit type annotations to resolve\nambiguities in typing not present in row type systems, and the type family\nimplementation retains more constraints in principal types than does the\ninstance chain implementation. We propose a general mechanism to guide the\ninstantiation of ambiguous type variables, show that it eliminates the need for\ntype annotations in our encodings, and discuss conditions under which it\npreserves coherence.\n", "versions": [{"version": "v1", "created": "Sat, 24 Dec 2016 16:30:07 GMT"}], "update_date": "2016-12-28", "authors_parsed": [["Morris", "J. Garrett", ""]]}, {"id": "1612.09394", "submitter": "Kwonsoo Chae", "authors": "Kwonsoo Chae and Hakjoo Oh and Kihong Heo and Hongseok Yang", "title": "Automatically generating features for learning program analysis\n  heuristics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a technique for automatically generating features for data-driven\nprogram analyses. Recently data-driven approaches for building a program\nanalysis have been proposed, which mine existing codebases and automatically\nlearn heuristics for finding a cost-effective abstraction for a given analysis\ntask. Such approaches reduce the burden of the analysis designers, but they do\nnot remove it completely; they still leave the highly nontrivial task of\ndesigning so called features to the hands of the designers. Our technique\nautomates this feature design process. The idea is to use programs as features\nafter reducing and abstracting them. Our technique goes through selected\nprogram-query pairs in codebases, and it reduces and abstracts the program in\neach pair to a few lines of code, while ensuring that the analysis behaves\nsimilarly for the original and the new programs with respect to the query. Each\nreduced program serves as a boolean feature for program-query pairs. This\nfeature evaluates to true for a given program-query pair when (as a program) it\nis included in the program part of the pair. We have implemented our approach\nfor three real-world program analyses. Our experimental evaluation shows that\nthese analyses with automatically-generated features perform comparably to\nthose with manually crafted features.\n", "versions": [{"version": "v1", "created": "Fri, 30 Dec 2016 05:55:56 GMT"}], "update_date": "2017-01-02", "authors_parsed": [["Chae", "Kwonsoo", ""], ["Oh", "Hakjoo", ""], ["Heo", "Kihong", ""], ["Yang", "Hongseok", ""]]}]