[{"id": "1611.00271", "submitter": "Ashish Sureka", "authors": "Divya Kundra and Ashish Sureka", "title": "Application of Case-Based Teaching and Learning in Compiler Design\n  Course", "comments": "Extended version of our short paper accepted in T4E 2016 (The Eighth\n  IEEE International Conference on Technology for Education)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compiler design is a course that discusses ideas used in construction of\nprogramming language compilers. Students learn how a program written in high\nlevel programming language and designed for humans understanding is\nsystematically converted into low level assembly language understood by\nmachines. We propose and implement a Case-based and Project-based Learning\nenvironment for teaching important Compiler design concepts (CPLC) to B.Tech\nthird year students of a Delhi University (India) college. A case is a text\nthat describes a real-life situation providing information but not solution.\nPrevious research shows that case-based teaching helps students to apply the\nprinciples discussed in the class for solving complex practical problems. We\ndivide one main project into sub-projects to give to students in order to\nenhance their practical experience of designing a compiler. To measure the\neffectiveness of case-based discussions, students complete a survey on their\nperceptions of benefits of case-based learning. The survey is analyzed using\nfrequency distribution and chi square test of association. The results of the\nsurvey show that case-based teaching of compiler concepts does enhance students\nskills of learning, critical thinking, engagement, communication skills and\nteam work.\n", "versions": [{"version": "v1", "created": "Tue, 1 Nov 2016 15:25:39 GMT"}], "update_date": "2016-11-02", "authors_parsed": [["Kundra", "Divya", ""], ["Sureka", "Ashish", ""]]}, {"id": "1611.00467", "submitter": "Ruijie Fang", "authors": "Ruijie Fang and Siqi Liu", "title": "A Performance Survey on Stack-based and Register-based Virtual Machines", "comments": "Short paper for evaluating performance differences between a\n  stack-based and a register-based virtual machine", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Virtual machines have been widely adapted for high-level programming language\nimplementations and for providing a degree of platform neutrality. As the\noverall use and adaptation of virtual machines grow, the overall performance of\nvirtual machines has become a widely-discussed topic. In this paper, we present\na survey on the performance differences of the two most widely adapted types of\nvirtual machines - the stack-based virtual machine and the register-based\nvirtual machine - using various benchmark programs. Additionally, we adopted a\nnew approach of measuring performance by measuring the overall dispatch time,\namount of dispatches, fetch time, and execution time while running benchmarks\non custom-implemented, lightweight virtual machines. Finally, we present two\nlightweight, custom-designed, Turing-equivalent virtual machines that are\nspecifically designed in benchmarking virtual machine performance - the\n\"Conceptum\" stack-based virtual machine, and the \"Inertia\" register-based\nvirtual machine. Our result showed that while on average the register machine\nspends 20.39% less time in executing benchmarks than the stack machine, the\nstack-based virtual machine is still faster than the virtual machine regarding\nthe instruction fetch time.\n", "versions": [{"version": "v1", "created": "Wed, 2 Nov 2016 04:37:13 GMT"}], "update_date": "2016-11-03", "authors_parsed": [["Fang", "Ruijie", ""], ["Liu", "Siqi", ""]]}, {"id": "1611.00602", "submitter": "Ruslan Shevchenko", "authors": "Ruslan Shevchenko", "title": "Scala-gopher: CSP-style programming techniques with idiomatic Scala", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cala-gopher is a library-level Scala implementation of communication sequence\nprocess constructs: channels, selectors (similar to analogical constructs in\nLimbo or Go) transputers (similar to Occam proc) and a set of high-level\noperations on top of akka and SIP-22 async. The framework integrates CSP-style\nprogramming into standard Scala concurrency environment via idiomatic API. This\nallows usage of communication patterns, well known in Go world, but not easy\nexpressable in mainstream scala concurrency frameworks, along with algebraic\napproach for composing computation builders. Besides, we want to discuss\ncurrent implementation issues and future directions in the context of evolving\nof compiler and libraries ecosystem.\n", "versions": [{"version": "v1", "created": "Wed, 2 Nov 2016 13:38:36 GMT"}], "update_date": "2016-11-03", "authors_parsed": [["Shevchenko", "Ruslan", ""]]}, {"id": "1611.00692", "submitter": "Ankush Das", "authors": "Jan Hoffmann, Ankush Das and Shu-Chun Weng", "title": "Towards Automatic Resource Bound Analysis for OCaml", "comments": "74 pages, technical report, short version accepted at POPL 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents a resource analysis system for OCaml programs. This\nsystem automatically derives worst-case resource bounds for higher-order\npolymorphic programs with user-defined inductive types. The technique is\nparametric in the resource and can derive bounds for time, memory allocations\nand energy usage. The derived bounds are multivariate resource polynomials\nwhich are functions of different size parameters that depend on the standard\nOCaml types. Bound inference is fully automatic and reduced to a linear\noptimization problem that is passed to an off-the-shelf LP solver. Technically,\nthe analysis system is based on a novel multivariate automatic amortized\nresource analysis (AARA). It builds on existing work on linear AARA for\nhigher-order programs with user-defined inductive types and on multivariate\nAARA for first-order programs with built-in lists and binary trees. For the\nfirst time, it is possible to automatically derive polynomial bounds for\nhigher-order functions and polynomial bounds that depend on user-defined\ninductive types. Moreover, the analysis handles programs with side effects and\neven outperforms the linear bound inference of previous systems. At the same\ntime, it preserves the expressivity and efficiency of existing AARA techniques.\nThe practicality of the analysis system is demonstrated with an implementation\nand integration with Inria's OCaml compiler. The implementation is used to\nautomatically derive resource bounds for 411 functions and 6018 lines of code\nderived from OCaml libraries, the CompCert compiler, and implementations of\ntextbook algorithms. In a case study, the system infers bounds on the number of\nqueries that are sent by OCaml programs to DynamoDB, a commercial NoSQL cloud\ndatabase service.\n", "versions": [{"version": "v1", "created": "Wed, 2 Nov 2016 17:36:19 GMT"}], "update_date": "2016-11-03", "authors_parsed": [["Hoffmann", "Jan", ""], ["Das", "Ankush", ""], ["Weng", "Shu-Chun", ""]]}, {"id": "1611.00860", "submitter": "Maria Kotsifakou", "authors": "Prakalp Srivastava, Maria Kotsifakou, Vikram Adve (University of\n  Illinois at Urbana Champaign)", "title": "HPVM: A Portable Virtual Instruction Set for Heterogeneous Parallel\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a programming abstraction for heterogeneous parallel hardware,\ndesigned to capture a wide range of popular parallel hardware, including GPUs,\nvector instruction sets and multicore CPUs. Our abstraction, which we call\nHPVM, is a hierarchical dataflow graph with shared memory and vector\ninstructions. We use HPVM to define both a virtual instruction set (ISA) and\nalso a compiler intermediate representation (IR). The virtual ISA aims to\nachieve both functional portability and performance portability across\nheterogeneous systems, while the compiler IR aims to enable effective code\ngeneration and optimization for such systems.\n  HPVM effectively supports all forms of parallelism used to achieve\ncomputational speedups (as opposed to concurrency), including task parallelism,\ncoarse-grain data parallelism, fine-grain data parallelism, and pipelined\nparallelism. HPVM also enables flexible scheduling and tiling: different nodes\nin the dataflow graph can be mapped flexibly to different combinations of\ncompute units, and the graph hierarchy expresses memory tiling, essential for\nachieving high performance on GPU and CPU targets.\n", "versions": [{"version": "v1", "created": "Thu, 3 Nov 2016 01:53:20 GMT"}], "update_date": "2016-11-04", "authors_parsed": [["Srivastava", "Prakalp", "", "University of\n  Illinois at Urbana Champaign"], ["Kotsifakou", "Maria", "", "University of\n  Illinois at Urbana Champaign"], ["Adve", "Vikram", "", "University of\n  Illinois at Urbana Champaign"]]}, {"id": "1611.01063", "submitter": "Petr Novotn\\'y", "authors": "Krishnendu Chatterjee, Petr Novotn\\'y, {\\DJ}or{\\dj}e \\v{Z}ikeli\\'c", "title": "Stochastic Invariants for Probabilistic Termination", "comments": "Full version of a paper published at POPL 2017. 20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Termination is one of the basic liveness properties, and we study the\ntermination problem for probabilistic programs with real-valued variables.\nPrevious works focused on the qualitative problem that asks whether an input\nprogram terminates with probability~1 (almost-sure termination). A powerful\napproach for this qualitative problem is the notion of ranking supermartingales\nwith respect to a given set of invariants. The quantitative problem\n(probabilistic termination) asks for bounds on the termination probability. A\nfundamental and conceptual drawback of the existing approaches to address\nprobabilistic termination is that even though the supermartingales consider the\nprobabilistic behavior of the programs, the invariants are obtained completely\nignoring the probabilistic aspect.\n  In this work we address the probabilistic termination problem for\nlinear-arithmetic probabilistic programs with nondeterminism. We define the\nnotion of {\\em stochastic invariants}, which are constraints along with a\nprobability bound that the constraints hold. We introduce a concept of {\\em\nrepulsing supermartingales}. First, we show that repulsing supermartingales can\nbe used to obtain bounds on the probability of the stochastic invariants.\nSecond, we show the effectiveness of repulsing supermartingales in the\nfollowing three ways: (1)~With a combination of ranking and repulsing\nsupermartingales we can compute lower bounds on the probability of termination;\n(2)~repulsing supermartingales provide witnesses for refutation of almost-sure\ntermination; and (3)~with a combination of ranking and repulsing\nsupermartingales we can establish persistence properties of probabilistic\nprograms.\n  We also present results on related computational problems and an experimental\nevaluation of our approach on academic examples.\n", "versions": [{"version": "v1", "created": "Thu, 3 Nov 2016 15:28:36 GMT"}, {"version": "v2", "created": "Wed, 16 Nov 2016 14:20:04 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Chatterjee", "Krishnendu", ""], ["Novotn\u00fd", "Petr", ""], ["\u017dikeli\u0107", "\u0110or\u0111e", ""]]}, {"id": "1611.01507", "submitter": "Yatin Manerkar", "authors": "Yatin A. Manerkar, Caroline Trippel, Daniel Lustig, Michael Pellauer,\n  Margaret Martonosi", "title": "Counterexamples and Proof Loophole for the C/C++ to POWER and ARMv7\n  Trailing-Sync Compiler Mappings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The C and C++ high-level languages provide programmers with atomic operations\nfor writing high-performance concurrent code. At the assembly language level, C\nand C++ atomics get mapped down to individual instructions or combinations of\ninstructions by compilers, depending on the ordering guarantees and\nsynchronization instructions provided by the underlying architecture. These\ncompiler mappings must uphold the ordering guarantees provided by C/C++ atomics\nor the compiled program will not behave according to the C/C++ memory model. In\nthis paper we discuss two counterexamples to the well-known trailing-sync\ncompiler mappings for the Power and ARMv7 architectures that were previously\nthought to be proven correct. In addition to the counterexamples, we discuss\nthe loophole in the proof of the mappings that allowed the incorrect mappings\nto be proven correct. We also discuss the current state of compilers and\narchitectures in relation to the bug.\n", "versions": [{"version": "v1", "created": "Fri, 4 Nov 2016 19:52:35 GMT"}, {"version": "v2", "created": "Thu, 17 Nov 2016 03:42:46 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Manerkar", "Yatin A.", ""], ["Trippel", "Caroline", ""], ["Lustig", "Daniel", ""], ["Pellauer", "Michael", ""], ["Martonosi", "Margaret", ""]]}, {"id": "1611.01667", "submitter": "Christian Schuessler", "authors": "Christian Schuessler and Roland Gruber", "title": "A Traversable Fixed Size Small Object Allocator in C++", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  At the allocation and deallocation of small objects with fixed size, the\nstandard allocator of the runtime system has commonly a worse time performance\ncompared to allocators adapted for a special application field. We propose a\nmemory allocator, originally developed for mesh primitives but also usable for\nany other small equally sized objects. For a large amount of objects it leads\nto better results than allocating data with the C ++new instruction and behaves\nnowhere worse. The proposed synchronization approach for this allocator behaves\nlock-free in practical scenarios without using machine instructions, such as\ncompare-and-swap. A traversal structure is integrated requiring less memory\nthan using containers such as STL-vectors or lists, but with comparable time\nperformance.\n", "versions": [{"version": "v1", "created": "Sat, 5 Nov 2016 16:33:02 GMT"}, {"version": "v2", "created": "Tue, 8 Nov 2016 20:10:27 GMT"}], "update_date": "2016-11-09", "authors_parsed": [["Schuessler", "Christian", ""], ["Gruber", "Roland", ""]]}, {"id": "1611.01752", "submitter": "Pavol Bielik", "authors": "Pavol Bielik, Veselin Raychev, Martin Vechev", "title": "Learning a Static Analyzer from Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To be practically useful, modern static analyzers must precisely model the\neffect of both, statements in the programming language as well as frameworks\nused by the program under analysis. While important, manually addressing these\nchallenges is difficult for at least two reasons: (i) the effects on the\noverall analysis can be non-trivial, and (ii) as the size and complexity of\nmodern libraries increase, so is the number of cases the analysis must handle.\n  In this paper we present a new, automated approach for creating static\nanalyzers: instead of manually providing the various inference rules of the\nanalyzer, the key idea is to learn these rules from a dataset of programs. Our\nmethod consists of two ingredients: (i) a synthesis algorithm capable of\nlearning a candidate analyzer from a given dataset, and (ii) a counter-example\nguided learning procedure which generates new programs beyond those in the\ninitial dataset, critical for discovering corner cases and ensuring the learned\nanalysis generalizes to unseen programs.\n  We implemented and instantiated our approach to the task of learning\nJavaScript static analysis rules for a subset of points-to analysis and for\nallocation sites analysis. These are challenging yet important problems that\nhave received significant research attention. We show that our approach is\neffective: our system automatically discovered practical and useful inference\nrules for many cases that are tricky to manually identify and are missed by\nstate-of-the-art, manually tuned analyzers.\n", "versions": [{"version": "v1", "created": "Sun, 6 Nov 2016 10:35:56 GMT"}, {"version": "v2", "created": "Sun, 25 Jun 2017 16:32:21 GMT"}], "update_date": "2017-06-27", "authors_parsed": [["Bielik", "Pavol", ""], ["Raychev", "Veselin", ""], ["Vechev", "Martin", ""]]}, {"id": "1611.01855", "submitter": "Rishabh Singh", "authors": "Emilio Parisotto, Abdel-rahman Mohamed, Rishabh Singh, Lihong Li,\n  Dengyong Zhou, Pushmeet Kohli", "title": "Neuro-Symbolic Program Synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have seen the proposal of a number of neural architectures for\nthe problem of Program Induction. Given a set of input-output examples, these\narchitectures are able to learn mappings that generalize to new test inputs.\nWhile achieving impressive results, these approaches have a number of important\nlimitations: (a) they are computationally expensive and hard to train, (b) a\nmodel has to be trained for each task (program) separately, and (c) it is hard\nto interpret or verify the correctness of the learnt mapping (as it is defined\nby a neural network). In this paper, we propose a novel technique,\nNeuro-Symbolic Program Synthesis, to overcome the above-mentioned problems.\nOnce trained, our approach can automatically construct computer programs in a\ndomain-specific language that are consistent with a set of input-output\nexamples provided at test time. Our method is based on two novel neural\nmodules. The first module, called the cross correlation I/O network, given a\nset of input-output examples, produces a continuous representation of the set\nof I/O examples. The second module, the Recursive-Reverse-Recursive Neural\nNetwork (R3NN), given the continuous representation of the examples,\nsynthesizes a program by incrementally expanding partial programs. We\ndemonstrate the effectiveness of our approach by applying it to the rich and\ncomplex domain of regular expression based string transformations. Experiments\nshow that the R3NN model is not only able to construct programs from new\ninput-output examples, but it is also able to construct new programs for tasks\nthat it had never observed before during training.\n", "versions": [{"version": "v1", "created": "Sun, 6 Nov 2016 22:23:56 GMT"}], "update_date": "2016-11-08", "authors_parsed": [["Parisotto", "Emilio", ""], ["Mohamed", "Abdel-rahman", ""], ["Singh", "Rishabh", ""], ["Li", "Lihong", ""], ["Zhou", "Dengyong", ""], ["Kohli", "Pushmeet", ""]]}, {"id": "1611.01988", "submitter": "Marc Brockschmidt", "authors": "John K. Feser, Marc Brockschmidt, Alexander L. Gaunt, Daniel Tarlow", "title": "Differentiable Functional Program Interpreters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Programming by Example (PBE) is the task of inducing computer programs from\ninput-output examples. It can be seen as a type of machine learning where the\nhypothesis space is the set of legal programs in some programming language.\nRecent work on differentiable interpreters relaxes the discrete space of\nprograms into a continuous space so that search over programs can be performed\nusing gradient-based optimization. While conceptually powerful, so far\ndifferentiable interpreter-based program synthesis has only been capable of\nsolving very simple problems. In this work, we study modeling choices that\narise when constructing a differentiable programming language and their impact\non the success of synthesis. The main motivation for the modeling choices comes\nfrom functional programming: we study the effect of memory allocation schemes,\nimmutable data, type systems, and built-in control-flow structures. Empirically\nwe show that incorporating functional programming ideas into differentiable\nprogramming languages allows us to learn much more complex programs than is\npossible with existing differentiable languages.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2016 11:09:19 GMT"}, {"version": "v2", "created": "Thu, 2 Mar 2017 13:26:11 GMT"}], "update_date": "2017-03-03", "authors_parsed": [["Feser", "John K.", ""], ["Brockschmidt", "Marc", ""], ["Gaunt", "Alexander L.", ""], ["Tarlow", "Daniel", ""]]}, {"id": "1611.02392", "submitter": "Jana Dunfield", "authors": "Khurram A. Jafery and Jana Dunfield", "title": "Sums of Uncertainty: Refinements Go Gradual", "comments": "14 pages + appendix with proofs, to appear at POPL 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A long-standing shortcoming of statically typed functional languages is that\ntype checking does not rule out pattern-matching failures (run-time match\nexceptions). Refinement types distinguish different values of datatypes; if a\nprogram annotated with refinements passes type checking, pattern-matching\nfailures become impossible. Unfortunately, refinement is a monolithic property\nof a type, exacerbating the difficulty of adding refinement types to nontrivial\nprograms.\n  Gradual typing has explored how to incrementally move between static typing\nand dynamic typing. We develop a type system of gradual sums that combines\nrefinement with imprecision. Then, we develop a bidirectional version of the\ntype system, which rules out excessive imprecision, and give a type-directed\ntranslation to a target language with explicit casts. We prove that the static\nsublanguage cannot have match failures, that a well-typed program remains\nwell-typed if its type annotations are made less precise, and that making\nannotations less precise causes target programs to fail later. Several of these\nresults correspond to criteria for gradual typing given by Siek et al. (2015).\n", "versions": [{"version": "v1", "created": "Tue, 8 Nov 2016 05:18:52 GMT"}, {"version": "v2", "created": "Sat, 19 Sep 2020 22:34:17 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Jafery", "Khurram A.", ""], ["Dunfield", "Jana", ""]]}, {"id": "1611.02528", "submitter": "Tayssir Touili Touili", "authors": "Fu Song and Tayssir Touili", "title": "LTL Model-Checking for Dynamic Pushdown Networks Communicating via Locks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Dynamic Pushdown Network (DPN) is a set of pushdown systems (PDSs) where\neach process can dynamically create new instances of PDSs. DPNs are a natural\nmodel of multi-threaded programs with (possibly recursive) procedure calls and\nthread creation. Extending DPNs with locks allows processes to synchronize with\neach other. Thus, DPNs with locks are a well adapted formalism to model\nmulti-threaded programs that synchronize via locks. Therefore, it is important\nto have model-checking algorithms for DPNs with locks. We consider in this work\nmodel-checking for DPNs with locks against single-indexed LTL properties of the\nform V fi s.t. fi is a LTL formula interpreted over the PDS i. We consider the\nmodel-checking problems w.r.t. simple valuations (i.e, whether a configuration\nsatisfies an atomic proposition depends only on its control location and held\nlocks) and w.r.t. regular valuations (i.e., the set of the configurations\nsatisfying an atomic proposition is a regular set of configurations). We show\nthat these model-checking problems are decidable.\n", "versions": [{"version": "v1", "created": "Tue, 11 Oct 2016 11:29:46 GMT"}], "update_date": "2016-11-09", "authors_parsed": [["Song", "Fu", ""], ["Touili", "Tayssir", ""]]}, {"id": "1611.02537", "submitter": "Ahmed El-Hassany", "authors": "Ahmed El-Hassany, Petar Tsankov, Laurent Vanbever, Martin Vechev", "title": "Network-wide Configuration Synthesis", "comments": "24 Pages, short version published in CAV 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer networks are hard to manage. Given a set of high-level requirements\n(e.g., reachability, security), operators have to manually figure out the\nindividual configuration of potentially hundreds of devices running complex\ndistributed protocols so that they, collectively, compute a compatible\nforwarding state. Not surprisingly, operators often make mistakes which lead to\ndowntimes. To address this problem, we present a novel synthesis approach that\nautomatically computes correct network configurations that comply with the\noperator's requirements. We capture the behavior of existing routers along with\nthe distributed protocols they run in stratified Datalog. Our key insight is to\nreduce the problem of finding correct input configurations to the task of\nsynthesizing inputs for a stratified Datalog program. To solve this synthesis\ntask, we introduce a new algorithm that synthesizes inputs for stratified\nDatalog programs. This algorithm is applicable beyond the domain of networks.\nWe leverage our synthesis algorithm to construct the first network-wide\nconfiguration synthesis system, called SyNET, that support multiple interacting\nrouting protocols (OSPF and BGP) and static routes. We show that our system is\npractical and can infer correct input configurations, in a reasonable amount\ntime, for networks of realistic size (> 50 routers) that forward packets for\nmultiple traffic classes.\n", "versions": [{"version": "v1", "created": "Tue, 8 Nov 2016 14:47:41 GMT"}, {"version": "v2", "created": "Tue, 30 May 2017 10:26:24 GMT"}], "update_date": "2017-05-31", "authors_parsed": [["El-Hassany", "Ahmed", ""], ["Tsankov", "Petar", ""], ["Vanbever", "Laurent", ""], ["Vechev", "Martin", ""]]}, {"id": "1611.02823", "submitter": "Saurabh Hukerikar", "authors": "Saurabh Hukerikar and Christian Engelmann", "title": "Language Support for Reliable Memory Regions", "comments": "The 29th International Workshop on Languages and Compilers for\n  Parallel Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The path to exascale computational capabilities in high-performance computing\n(HPC) systems is challenged by the inadequacy of present software technologies\nto adapt to the rapid evolution of architectures of supercomputing systems. The\nconstraints of power have driven system designs to include increasingly\nheterogeneous architectures and diverse memory technologies and interfaces.\nFuture systems are also expected to experience an increased rate of errors,\nsuch that the applications will no longer be able to assume correct behavior of\nthe underlying machine. To enable the scientific community to succeed in\nscaling their applications, and to harness the capabilities of exascale\nsystems, we need software strategies that provide mechanisms for explicit\nmanagement of resilience to errors in the system, in addition to locality of\nreference in the complex memory hierarchies of future HPC systems.\n  In prior work, we introduced the concept of explicitly reliable memory\nregions, called havens. Memory management using havens supports reliability\nmanagement through a region-based approach to memory allocations. Havens enable\nthe creation of robust memory regions, whose resilient behavior is guaranteed\nby software-based protection schemes. In this paper, we propose language\nsupport for havens through type annotations that make the structure of a\nprogram's havens more explicit and convenient for HPC programmers to use. We\ndescribe how the extended haven-based memory management model is implemented,\nand demonstrate the use of the language-based annotations to affect the\nresiliency of a conjugate gradient solver application.\n", "versions": [{"version": "v1", "created": "Wed, 9 Nov 2016 05:49:52 GMT"}, {"version": "v2", "created": "Wed, 23 Nov 2016 05:49:25 GMT"}], "update_date": "2016-11-24", "authors_parsed": [["Hukerikar", "Saurabh", ""], ["Engelmann", "Christian", ""]]}, {"id": "1611.03410", "submitter": "Barak Pearlmutter", "authors": "Jeffrey Mark Siskind and Barak A. Pearlmutter", "title": "Binomial Checkpointing for Arbitrary Programs with No User Annotation", "comments": "Extended abstract presented at the AD 2016 Conference, Sep 2016,\n  Oxford UK", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LG cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Heretofore, automatic checkpointing at procedure-call boundaries, to reduce\nthe space complexity of reverse mode, has been provided by systems like\nTapenade. However, binomial checkpointing, or treeverse, has only been provided\nin Automatic Differentiation (AD) systems in special cases, e.g., through\nuser-provided pragmas on DO loops in Tapenade, or as the nested taping\nmechanism in adol-c for time integration processes, which requires that user\ncode be refactored. We present a framework for applying binomial checkpointing\nto arbitrary code with no special annotation or refactoring required. This is\naccomplished by applying binomial checkpointing directly to a program trace.\nThis trace is produced by a general-purpose checkpointing mechanism that is\northogonal to AD.\n", "versions": [{"version": "v1", "created": "Thu, 10 Nov 2016 17:29:24 GMT"}], "update_date": "2016-11-11", "authors_parsed": [["Siskind", "Jeffrey Mark", ""], ["Pearlmutter", "Barak A.", ""]]}, {"id": "1611.03416", "submitter": "Barak Pearlmutter", "authors": "Jeffrey Mark Siskind and Barak A. Pearlmutter", "title": "Efficient Implementation of a Higher-Order Language with Built-In AD", "comments": "Extended abstract presented at the AD 2016 Conference, Sep 2016,\n  Oxford UK", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that Automatic Differentiation (AD) operators can be provided in a\ndynamic language without sacrificing numeric performance. To achieve this,\ngeneral forward and reverse AD functions are added to a simple high-level\ndynamic language, and support for them is included in an aggressive optimizing\ncompiler. Novel technical mechanisms are discussed, which have the ability to\nmigrate the AD transformations from run-time to compile-time. The resulting\nsystem, although only a research prototype, exhibits startlingly good\nperformance. In fact, despite the potential inefficiencies entailed by support\nof a functional-programming language and a first-class AD operator, performance\nis competitive with the fastest available preprocessor-based Fortran AD\nsystems. On benchmarks involving nested use of the AD operators, it can even\ndramatically exceed their performance.\n", "versions": [{"version": "v1", "created": "Thu, 10 Nov 2016 17:40:53 GMT"}], "update_date": "2016-11-11", "authors_parsed": [["Siskind", "Jeffrey Mark", ""], ["Pearlmutter", "Barak A.", ""]]}, {"id": "1611.03429", "submitter": "Barak Pearlmutter", "authors": "Robert Kelly and Barak A. Pearlmutter and Jeffrey Mark Siskind", "title": "Evolving the Incremental {\\lambda} Calculus into a Model of Forward\n  Automatic Differentiation (AD)", "comments": "Extended abstract presented at the AD 2016 Conference, Sep 2016,\n  Oxford UK", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Formal transformations somehow resembling the usual derivative are\nsurprisingly common in computer science, with two notable examples being\nderivatives of regular expressions and derivatives of types. A newcomer to this\nlist is the incremental $\\lambda$-calculus, or ILC, a \"theory of changes\" that\ndeploys a formal apparatus allowing the automatic generation of efficient\nupdate functions which perform incremental computation. The ILC is not only\ndefined, but given a formal machine-understandable definition---accompanied by\nmechanically verifiable proofs of various properties, including in particular\ncorrectness of various sorts. Here, we show how the ILC can be mutated into\npropagating tangents, thus serving as a model of Forward Accumulation Mode\nAutomatic Differentiation. This mutation is done in several steps. These steps\ncan also be applied to the proofs, resulting in machine-checked proofs of the\ncorrectness of this model of forward AD.\n", "versions": [{"version": "v1", "created": "Thu, 10 Nov 2016 18:06:43 GMT"}], "update_date": "2016-11-11", "authors_parsed": [["Kelly", "Robert", ""], ["Pearlmutter", "Barak A.", ""], ["Siskind", "Jeffrey Mark", ""]]}, {"id": "1611.05026", "submitter": "Mario Bravetti", "authors": "Mario Bravetti, Marco Carbone and Gianluigi Zavattaro", "title": "Undecidability of Asynchronous Session Subtyping", "comments": "36 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Session types are used to describe communication protocols in distributed\nsystems and, as usual in type theories, session subtyping characterizes\nsubstitutability of the communicating processes. We investigate the\n(un)decidability of subtyping for session types in asynchronously communicating\nsystems. We first devise a core undecidable subtyping relation that is obtained\nby imposing limitations on the structure of types. Then, as a consequence of\nthis initial undecidability result, we show that (differently from what stated\nor conjectured in the literature) the three notions of asynchronous subtyping\ndefined so far for session types are all undecidable. Namely, we consider the\nasynchronous session subtyping by Mostrous and Yoshida for binary sessions, the\nrelation by Chen et al. for binary sessions under the assumption that every\nmessage emitted is eventually consumed, and the one by Mostrous et al. for\nmultiparty session types. Finally, by showing that two fragments of the core\nsubtyping relation are decidable, we evince that further restrictions on the\nstructure of types make our core subtyping relation decidable.\n", "versions": [{"version": "v1", "created": "Tue, 15 Nov 2016 20:52:17 GMT"}, {"version": "v2", "created": "Thu, 22 Dec 2016 15:20:29 GMT"}, {"version": "v3", "created": "Wed, 19 Jul 2017 12:41:53 GMT"}], "update_date": "2017-07-20", "authors_parsed": [["Bravetti", "Mario", ""], ["Carbone", "Marco", ""], ["Zavattaro", "Gianluigi", ""]]}, {"id": "1611.05105", "submitter": "Matteo Cimini", "authors": "Matteo Cimini, Dale Miller, and Jeremy G. Siek", "title": "Well-Typed Languages are Sound", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Type soundness is an important property of modern programming languages. In\nthis paper we explore the idea that \"well-typed languages are sound\": the idea\nthat the appropriate typing discipline over language specifications guarantees\nthat the language is type sound. We instantiate this idea for a certain class\nof languages defined using small step operational semantics by ensuring the\nprogress and preservation theorems. Our first contribution is a syntactic\ndiscipline for organizing and restricting language specifications so that they\nautomatically satisfy the progress theorem. This discipline is not novel but\nmakes explicit the way expert language designers have been organizing a certain\nclass of languages for long time. We give a formal account of this discipline\nby representing language specifications as (higher-order) logic programs and by\ngiving a meta type system over that collection of formulas. Our second\ncontribution is a methodology and meta type system for guaranteeing that\nlanguages satisfy the preservation theorem. Ultimately, we proved that language\nspecifications that conform to our meta type systems are guaranteed to be type\nsound. We have implemented these ideas in the TypeSoundnessCertifier, a tool\nthat takes language specifications in the form of logic programs and type\nchecks them according to our meta type systems. For those languages that pass\nour type checker, our tool automatically produces a proof of type soundness\nthat can be machine-checked by the Abella proof assistant. For those languages\nthat fail our type checker, the tool pinpoints the design mistakes that hinder\ntype soundness. We have applied the TypeSoundnessCertifier to a large number of\nprogramming languages, including those with recursive types, polymorphism,\nletrec, exceptions, lists and other common types and operators.\n", "versions": [{"version": "v1", "created": "Wed, 16 Nov 2016 00:56:59 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Cimini", "Matteo", ""], ["Miller", "Dale", ""], ["Siek", "Jeremy G.", ""]]}, {"id": "1611.05651", "submitter": "Hugo Andres Lopez", "authors": "Hugo A. L\\'opez, Flemming Nielson, Hanne Riis Nielson", "title": "A Theory of Available-by-Design Communicating Systems", "comments": "Extended version of paper entitled \"Enforcing Availability in\n  Failure-Aware Communicating Systems\", presented at FORTE 2016. 30 pages\n  (original paper) + 19 pages of appendixes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Choreographic programming is a programming-language design approach that\ndrives error-safe protocol development in distributed systems. Starting from a\nglobal specification (choreography) one can generate distributed\nimplementations. The advantages of this top-down approach lie in the\ncorrectness-by-design principle, where implementations (endpoints) generated\nfrom a choreography behave according to the strict control flow described in\nthe choreography, and do not deadlock. Motivated by challenging scenarios in\nCyber-Physical Systems (CPS), we study how choreographic programming can cater\nfor dynamic infrastructures where not all endpoints are always available. We\nintroduce the Global Quality Calculus ($GC_q$), a variant of choreographic\nprogramming for the description of communication systems where some of the\ncomponents involved in a communication might fail. GCq features novel operators\nfor multiparty, partial and collective communications. This paper studies the\nnature of failure-aware communication: First, we introduce $GC_q$ syntax,\nsemantics and examples of its use. The interplay between failures and\ncollective communications in a choreography can lead to choreographies that\ncannot progress due to absence of resources. In our second contribution, we\nprovide a type system that ensures that choreographies can be realized despite\nchanging availability conditions. A specification in $GC_q$ guides the\nimplementation of distributed endpoints when paired with global (session)\ntypes. Our third contribution provides an endpoint-projection based methodology\nfor the generation of failure-aware distributed processes. We show the\ncorrectness of the projection, and that well-typed choreographies with\navailability considerations enjoy progress.\n", "versions": [{"version": "v1", "created": "Thu, 17 Nov 2016 12:19:57 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["L\u00f3pez", "Hugo A.", ""], ["Nielson", "Flemming", ""], ["Nielson", "Hanne Riis", ""]]}, {"id": "1611.05980", "submitter": "Santosh Nagarakatte", "authors": "David Menendez and Santosh Nagarakatte", "title": "Precondition Inference for Peephole Optimizations in LLVM", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": "Rutgers CS Technical Report: DCS-TR-727", "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Peephole optimizations are a common source of compiler bugs. Compiler\ndevelopers typically transform an incorrect peephole optimization into a valid\none by strengthening the precondition. This process is challenging and tedious.\nThis paper proposes ALIVE-INFER, a data-driven approach that infers\npreconditions for peephole optimizations expressed in Alive. ALIVE-INFER\ngenerates positive and negative examples for an optimization, enumerates\npredicates on-demand, and learns a set of predicates that separate the positive\nand negative examples. ALIVE-INFER repeats this process until it finds a\nprecondition that ensures the validity of the optimization. ALIVE-INFER reports\nboth a weakest precondition and a set of succinct partial preconditions to the\ndeveloper. Our prototype generates preconditions that are weaker than LLVM's\npreconditions for 73 optimizations in the Alive suite. We also demonstrate the\napplicability of this technique to generalize 54 optimization patterns\ngenerated by Souper, an LLVM~IR--based superoptimizer.\n", "versions": [{"version": "v1", "created": "Fri, 18 Nov 2016 05:21:00 GMT"}, {"version": "v2", "created": "Wed, 1 Feb 2017 00:45:58 GMT"}, {"version": "v3", "created": "Sat, 25 Mar 2017 01:58:45 GMT"}], "update_date": "2017-03-28", "authors_parsed": [["Menendez", "David", ""], ["Nagarakatte", "Santosh", ""]]}, {"id": "1611.06276", "submitter": "Simon Fowler", "authors": "Simon Fowler and Sam Lindley and Philip Wadler", "title": "Mixing Metaphors: Actors as Channels and Channels as Actors (Extended\n  Version)", "comments": "Extended version of paper appearing at ECOOP'17", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Channel- and actor-based programming languages are both used in practice, but\nthe two are often confused. Languages such as Go provide anonymous processes\nwhich communicate using buffers or rendezvous points---known as\nchannels---while languages such as Erlang provide addressable processes---known\nas actors---each with a single incoming message queue. The lack of a common\nrepresentation makes it difficult to reason about translations that exist in\nthe folklore. We define a calculus $\\lambda_{\\textrm{ch}}$ for typed\nasynchronous channels, and a calculus $\\lambda_{\\textrm{act}}$ for typed\nactors. We define translations from $\\lambda_{\\textrm{act}}$ into\n$\\lambda_{\\textrm{ch}}$ and $\\lambda_{\\textrm{ch}}$ into\n$\\lambda_{\\textrm{act}}$ and prove that both are type- and\nsemantics-preserving. We show that our approach accounts for synchronisation\nand selective receive in actor systems and discuss future extensions to support\nguarded choice and behavioural types.\n", "versions": [{"version": "v1", "created": "Fri, 18 Nov 2016 23:32:34 GMT"}, {"version": "v2", "created": "Tue, 22 Nov 2016 14:57:48 GMT"}, {"version": "v3", "created": "Wed, 10 May 2017 13:37:13 GMT"}], "update_date": "2017-05-11", "authors_parsed": [["Fowler", "Simon", ""], ["Lindley", "Sam", ""], ["Wadler", "Philip", ""]]}, {"id": "1611.07502", "submitter": "Yu Feng", "authors": "Yu Feng, Ruben Martins, Jacob Van Geffen, Isil Dillig, Swarat\n  Chaudhuri", "title": "Component-based Synthesis of Table Consolidation and Transformation\n  Tasks from Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an example-driven synthesis technique for automating a\nlarge class of data preparation tasks that arise in data science. Given a set\nof input tables and an out- put table, our approach synthesizes a table\ntransformation program that performs the desired task. Our approach is not\nrestricted to a fixed set of DSL constructs and can synthesize programs from an\narbitrary set of components, including higher-order combinators. At a\nhigh-level, our approach performs type-directed enumerative search over partial\npro- grams but incorporates two key innovations that allow it to scale: First,\nour technique can utilize any first-order specification of the components and\nuses SMT-based deduction to reject partial programs. Second, our algorithm uses\npartial evaluation to increase the power of deduction and drive enumerative\nsearch. We have evaluated our synthesis algorithm on dozens of data preparation\ntasks obtained from on-line forums, and we show that our approach can\nautomatically solve a large class of problems encountered by R users.\n", "versions": [{"version": "v1", "created": "Tue, 22 Nov 2016 20:31:18 GMT"}], "update_date": "2016-11-23", "authors_parsed": [["Feng", "Yu", ""], ["Martins", "Ruben", ""], ["Van Geffen", "Jacob", ""], ["Dillig", "Isil", ""], ["Chaudhuri", "Swarat", ""]]}, {"id": "1611.07610", "submitter": "Marianna Rapoport", "authors": "Marianna Rapoport and Ond\\v{r}ej Lhot\\'ak", "title": "Mutable WadlerFest DOT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Dependent Object Types (DOT) calculus aims to model the essence of Scala,\nwith a focus on abstract type members, path-dependent types, and subtyping.\nOther Scala features could be defined by translation to DOT. Mutation is a\nfundamental feature of Scala currently missing in DOT. Mutation in DOT is\nneeded not only to model effectful computation and mutation in Scala programs,\nbut even to precisely specify how Scala initializes immutable variables and\nfields (vals). We present an extension to DOT that adds typed mutable reference\ncells. We have proven the extension sound with a mechanized proof in Coq. We\npresent the key features of our extended calculus and its soundness proof, and\ndiscuss the challenges that we encountered in our search for a sound design and\nthe alternative solutions that we considered.\n", "versions": [{"version": "v1", "created": "Wed, 23 Nov 2016 02:37:51 GMT"}], "update_date": "2016-11-24", "authors_parsed": [["Rapoport", "Marianna", ""], ["Lhot\u00e1k", "Ond\u0159ej", ""]]}, {"id": "1611.07620", "submitter": "EPTCS", "authors": "Sarah Chasins (UC Berkeley), Julie L. Newcomb (University of\n  Washington)", "title": "Using SyGuS to Synthesize Reactive Motion Plans", "comments": "In Proceedings SYNT 2016, arXiv:1611.07178", "journal-ref": "EPTCS 229, 2016, pp. 3-20", "doi": "10.4204/EPTCS.229.3", "report-no": null, "categories": "cs.PL cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approach for synthesizing reactive robot motion plans, based on\ncompilation to Syntax-Guided Synthesis (SyGuS) specifications. Our method\nreduces the motion planning problem to the problem of synthesizing a function\nthat can choose the next robot action in response to the current state of the\nsystem. This technique offers reactivity not by generating new motion plans\nthroughout deployment, but by synthesizing a single program that causes the\nrobot to reach its target from any system state that is consistent with the\nsystem model. This approach allows our tool to handle environments with\nadversarial obstacles. This work represents the first use of the SyGuS\nformalism to solve robot motion planning problems. We investigate whether using\nSyGuS for a bounded two-player reachability game is practical at this point in\ntime.\n", "versions": [{"version": "v1", "created": "Wed, 23 Nov 2016 03:16:09 GMT"}], "update_date": "2016-11-24", "authors_parsed": [["Chasins", "Sarah", "", "UC Berkeley"], ["Newcomb", "Julie L.", "", "University of\n  Washington"]]}, {"id": "1611.07623", "submitter": "EPTCS", "authors": "Maaz Bin Safeer Ahmad, Alvin Cheung", "title": "Leveraging Parallel Data Processing Frameworks with Verified Lifting", "comments": "In Proceedings SYNT 2016, arXiv:1611.07178", "journal-ref": "EPTCS 229, 2016, pp. 67-83", "doi": "10.4204/EPTCS.229.7", "report-no": null, "categories": "cs.PL cs.DB cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many parallel data frameworks have been proposed in recent years that let\nsequential programs access parallel processing. To capitalize on the benefits\nof such frameworks, existing code must often be rewritten to the\ndomain-specific languages that each framework supports. This rewriting-tedious\nand error-prone-also requires developers to choose the framework that best\noptimizes performance given a specific workload.\n  This paper describes Casper, a novel compiler that automatically retargets\nsequential Java code for execution on Hadoop, a parallel data processing\nframework that implements the MapReduce paradigm. Given a sequential code\nfragment, Casper uses verified lifting to infer a high-level summary expressed\nin our program specification language that is then compiled for execution on\nHadoop. We demonstrate that Casper automatically translates Java benchmarks\ninto Hadoop. The translated results execute on average 3.3x faster than the\nsequential implementations and scale better, as well, to larger datasets.\n", "versions": [{"version": "v1", "created": "Wed, 23 Nov 2016 03:16:38 GMT"}], "update_date": "2016-11-24", "authors_parsed": [["Ahmad", "Maaz Bin Safeer", ""], ["Cheung", "Alvin", ""]]}, {"id": "1611.07624", "submitter": "EPTCS", "authors": "Leonid Ryzhyk (Samsung Research America), Adam Walker (NICTA and UNSW)", "title": "Developing a Practical Reactive Synthesis Tool: Experience and Lessons\n  Learned", "comments": "In Proceedings SYNT 2016, arXiv:1611.07178", "journal-ref": "EPTCS 229, 2016, pp. 84-99", "doi": "10.4204/EPTCS.229.8", "report-no": null, "categories": "cs.SE cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We summarise our experience developing and using Termite, the first reactive\nsynthesis tool intended for use by software development practitioners. We\nidentify the main barriers to making reactive synthesis accessible to software\ndevelopers and describe the key features of Termite designed to overcome these\nbarriers, including an imperative C-like specification language, an interactive\nsource-level debugger, and a user-guided code generator. Based on our\nexperience applying Termite to synthesising real-world reactive software, we\nidentify several caveats of the practical use of the reactive synthesis\ntechnology. We hope that these findings will help define the agenda for future\nresearch on practical reactive synthesis.\n", "versions": [{"version": "v1", "created": "Wed, 23 Nov 2016 03:16:46 GMT"}], "update_date": "2016-11-24", "authors_parsed": [["Ryzhyk", "Leonid", "", "Samsung Research America"], ["Walker", "Adam", "", "NICTA and UNSW"]]}, {"id": "1611.07629", "submitter": "EPTCS", "authors": "Grigory Fedyukovich (UW), Rastislav Bod\\'ik (UW)", "title": "Approaching Symbolic Parallelization by Synthesis of Recurrence\n  Decompositions", "comments": "In Proceedings SYNT 2016, arXiv:1611.07178", "journal-ref": "EPTCS 229, 2016, pp. 55-66", "doi": "10.4204/EPTCS.229.6", "report-no": null, "categories": "cs.PL cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present GraSSP, a novel approach to perform automated parallelization\nrelying on recent advances in formal verification and synthesis. GraSSP\naugments an existing sequential program with an additional functionality to\ndecompose data dependencies in loop iterations, to compute partial results, and\nto compose them together. We show that for some classes of the sequential\nprefix sum problems, such parallelization can be performed efficiently.\n", "versions": [{"version": "v1", "created": "Wed, 23 Nov 2016 03:28:09 GMT"}], "update_date": "2016-11-24", "authors_parsed": [["Fedyukovich", "Grigory", "", "UW"], ["Bod\u00edk", "Rastislav", "", "UW"]]}, {"id": "1611.07862", "submitter": "Emery Berger", "authors": "Bobby Powers, John Vilk, Emery D. Berger", "title": "Browsix: Bridging the Gap Between Unix and the Browser", "comments": "Final version published at\n  https://dl.acm.org/citation.cfm?doid=3037697.3037727", "journal-ref": "ASPLOS 2017", "doi": "10.1145/3037697.3037727", "report-no": null, "categories": "cs.OS cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applications written to run on conventional operating systems typically\ndepend on OS abstractions like processes, pipes, signals, sockets, and a shared\nfile system. Porting these applications to the web currently requires extensive\nrewriting or hosting significant portions of code server-side because browsers\npresent a nontraditional runtime environment that lacks OS functionality.\n  This paper presents Browsix, a framework that bridges the considerable gap\nbetween conventional operating systems and the browser, enabling unmodified\nprograms expecting a Unix-like environment to run directly in the browser.\nBrowsix comprises two core parts: (1) a JavaScript-only system that makes core\nUnix features (including pipes, concurrent processes, signals, sockets, and a\nshared file system) available to web applications; and (2) extended JavaScript\nruntimes for C, C++, Go, and Node.js that support running programs written in\nthese languages as processes in the browser. Browsix supports running a POSIX\nshell, making it straightforward to connect applications together via pipes.\n  We illustrate Browsix's capabilities via case studies that demonstrate how it\neases porting legacy applications to the browser and enables new functionality.\nWe demonstrate a Browsix-enabled LaTeX editor that operates by executing\nunmodified versions of pdfLaTeX and BibTeX. This browser-only LaTeX editor can\nrender documents in seconds, making it fast enough to be practical. We further\ndemonstrate how Browsix lets us port a client-server application to run\nentirely in the browser for disconnected operation. Creating these applications\nrequired less than 50 lines of glue code and no code modifications,\ndemonstrating how easily Browsix can be used to build sophisticated web\napplications from existing parts without modification.\n", "versions": [{"version": "v1", "created": "Wed, 23 Nov 2016 16:23:40 GMT"}, {"version": "v2", "created": "Mon, 29 Apr 2019 04:32:16 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Powers", "Bobby", ""], ["Vilk", "John", ""], ["Berger", "Emery D.", ""]]}, {"id": "1611.08004", "submitter": "Stefan Wagner", "authors": "Jan-Peter Ostberg and Stefan Wagner", "title": "At Ease with Your Warnings: The Principles of the Salutogenesis Model\n  Applied to Automatic Static Analysis", "comments": "5 pages, 4 figures", "journal-ref": "Proc. 23rd International Conference on Software Analysis,\n  Evolution, and Reengineering (SANER). IEEE, 2016", "doi": "10.1109/SANER.2016.63", "report-no": null, "categories": "cs.SE cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The results of an automatic static analysis run can be overwhelming,\nespecially for beginners. The overflow of information and the resulting need\nfor many decisions is mentally tiring and can cause stress symptoms. There are\nseveral models in health care which are designed to fight stress. One of these\nis the salutogenesis model created by Aaron Antonovsky. In this paper, we will\npresent an idea on how to transfer this model into a triage and recommendation\nmodel for static analysis tools and give an example of how this can be\nimplemented in FindBugs, a static analysis tool for Java.\n", "versions": [{"version": "v1", "created": "Wed, 23 Nov 2016 21:25:17 GMT"}], "update_date": "2016-11-28", "authors_parsed": [["Ostberg", "Jan-Peter", ""], ["Wagner", "Stefan", ""]]}, {"id": "1611.08005", "submitter": "Stefan Wagner", "authors": "Stefan Wagner and Asim Abdulkhaleq and Kamer Kaya and Alexander Paar", "title": "On the Relationship of Inconsistent Software Clones and Faults: An\n  Empirical Study", "comments": "11 pages, 0 figures", "journal-ref": "Proc. 23rd International Conference on Software Analysis,\n  Evolution, and Reengineering (SANER). IEEE, 2016", "doi": "10.1109/SANER.2016.94", "report-no": null, "categories": "cs.SE cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: Code cloning - copying and reusing pieces of source code - is a\ncommon phenomenon in software development in practice. There have been several\nempirical studies on the effects of cloning, but there are contradictory\nresults regarding the connection of cloning and faults. Objective: Our aim is\nto clarify the relationship between code clones and faults. In particular, we\nfocus on inconsistent (or type-3) clones in this work. Method: We conducted a\ncase study with TWT GmbH where we detected the code clones in three Java\nsystems, set them into relation to information from issue tracking and version\ncontrol and interviewed three key developers. Results: Of the type-3 clones, 17\n% contain faults. Developers modified most of the type-3 clones simultaneously\nand thereby fixed half of the faults in type-3 clones consistently. Type-2\nclones with faults all evolved to fixed type-3 clones. Clone length is only\nweakly correlated with faultiness. Conclusion: There are indications that the\ndevelopers in two cases have been aware of clones. It might be a reason for the\nweak relationship between type-3 clones and faults. Hence, it seems important\nto keep developers aware of clones, potentially with new tool support. Future\nstudies need to investigate if the rate of faults in type-3 clones justifies\nusing them as cues in defect detection.\n", "versions": [{"version": "v1", "created": "Wed, 23 Nov 2016 21:25:36 GMT"}], "update_date": "2016-11-28", "authors_parsed": [["Wagner", "Stefan", ""], ["Abdulkhaleq", "Asim", ""], ["Kaya", "Kamer", ""], ["Paar", "Alexander", ""]]}, {"id": "1611.08651", "submitter": "EPTCS", "authors": "Johan Jeuring (Utrecht University and Open University, The\n  Netherlands), Jay McCarthy (University of Massachusetts Lowell)", "title": "Proceedings of the 4th and 5th International Workshop on Trends in\n  Functional Programming in Education", "comments": null, "journal-ref": "EPTCS 230, 2016", "doi": "10.4204/EPTCS.230", "report-no": null, "categories": "cs.PL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the proceedings of the Fourth and Fifth International\nWorkshops on Trends in Functional Programming in Education, TFPIE 2015 and\nTFPIE 2016, which were held on June 2, 2015 in Sophia-Antipolis, France, and on\nJune 7, 2016 at the University of Maryland College Park in the USA,\nrespectively.\n", "versions": [{"version": "v1", "created": "Sat, 26 Nov 2016 02:45:35 GMT"}], "update_date": "2016-11-29", "authors_parsed": [["Jeuring", "Johan", "", "Utrecht University and Open University, The\n  Netherlands"], ["McCarthy", "Jay", "", "University of Massachusetts Lowell"]]}, {"id": "1611.08888", "submitter": "Hanwen Wu", "authors": "Hongwei Xi, Hanwen Wu", "title": "Propositions in Linear Multirole Logic as Multiparty Session Types", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We identify multirole logic as a new form of logic and formalize linear\nmultirole logic (LMRL) as a natural generalization of classical linear logic\n(CLL). Among various meta-properties established for LMRL, we obtain one named\nmulti-cut elimination stating that every cut between three (or more) sequents\n(as a generalization of a cut between two sequents) can be eliminated, thus\nextending the celebrated result of cut-elimination by Gentzen. We also present\na variant of $\\pi$-calculus for multiparty sessions that demonstrates a tight\ncorrespondence between process communication in this variant and multi-cut\nelimination in LMRL, thus extending some recent results by Caires and Pfenning\n(2010) and Wadler (2012), among others, along a similar line of work.\n", "versions": [{"version": "v1", "created": "Sun, 27 Nov 2016 19:06:42 GMT"}], "update_date": "2016-11-29", "authors_parsed": [["Xi", "Hongwei", ""], ["Wu", "Hanwen", ""]]}, {"id": "1611.09067", "submitter": "J\\\"urgen Koslowski", "authors": "Mila Dalla Preda, Maurizio Gabbrielli, Saverio Giallorenzo, Ivan\n  Lanese, Jacopo Mauro", "title": "Dynamic Choreographies: Theory And Implementation", "comments": "arXiv admin note: text overlap with arXiv:1407.0970", "journal-ref": "Logical Methods in Computer Science, Volume 13, Issue 2 (April 10,\n  2017) lmcs:3263", "doi": "10.23638/LMCS-13(2:1)2017", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Programming distributed applications free from communication deadlocks and\nrace conditions is complex. Preserving these properties when applications are\nupdated at runtime is even harder. We present a choreographic approach for\nprogramming updatable, distributed applications. We define a choreography\nlanguage, called Dynamic Interaction-Oriented Choreography (AIOC), that allows\nthe programmer to specify, from a global viewpoint, which parts of the\napplication can be updated. At runtime, these parts may be replaced by new AIOC\nfragments from outside the application. AIOC programs are compiled, generating\ncode for each participant in a process-level language called Dynamic\nProcess-Oriented Choreographies (APOC). We prove that APOC distributed\napplications generated from AIOC specifications are deadlock free and race free\nand that these properties hold also after any runtime update. We instantiate\nthe theoretical model above into a programming framework called Adaptable\nInteraction-Oriented Choreographies in Jolie (AIOCJ) that comprises an\nintegrated development environment, a compiler from an extension of AIOCs to\ndistributed Jolie programs, and a runtime environment to support their\nexecution.\n", "versions": [{"version": "v1", "created": "Mon, 28 Nov 2016 11:04:47 GMT"}, {"version": "v2", "created": "Thu, 1 Dec 2016 15:31:49 GMT"}, {"version": "v3", "created": "Thu, 6 Apr 2017 11:37:43 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Preda", "Mila Dalla", ""], ["Gabbrielli", "Maurizio", ""], ["Giallorenzo", "Saverio", ""], ["Lanese", "Ivan", ""], ["Mauro", "Jacopo", ""]]}, {"id": "1611.09259", "submitter": "Craig McLaughlin", "authors": "Sam Lindley and Conor McBride and Craig McLaughlin", "title": "Do be do be do", "comments": "15 pages, 6 figures, fixing typos and an error in the pattern\n  matching elaboration algorithm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the design and implementation of Frank, a strict functional\nprogramming language with a bidirectional effect type system designed from the\nground up around a novel variant of Plotkin and Pretnar's effect handler\nabstraction.\n  Effect handlers provide an abstraction for modular effectful programming: a\nhandler acts as an interpreter for a collection of commands whose interfaces\nare statically tracked by the type system. However, Frank eliminates the need\nfor an additional effect handling construct by generalising the basic mechanism\nof functional abstraction itself. A function is simply the special case of a\nFrank operator that interprets no commands. Moreover, Frank's operators can be\nmultihandlers which simultaneously interpret commands from several sources at\nonce, without disturbing the direct style of functional programming with\nvalues.\n  Effect typing in Frank employs a novel form of effect polymorphism which\navoid mentioning effect variables in source code. This is achieved by\npropagating an ambient ability inwards, rather than accumulating unions of\npotential effects outwards.\n  We introduce Frank by example, and then give a formal account of the Frank\ntype system and its semantics. We introduce Core Frank by elaborating Frank\noperators into functions, case expressions, and unary handlers, and then give a\nsound small-step operational semantics for Core Frank.\n  Programming with effects and handlers is in its infancy. We contribute an\nexploration of future possibilities, particularly in combination with other\nforms of rich type system.\n", "versions": [{"version": "v1", "created": "Mon, 28 Nov 2016 17:44:19 GMT"}, {"version": "v2", "created": "Tue, 3 Oct 2017 17:27:42 GMT"}], "update_date": "2017-10-04", "authors_parsed": [["Lindley", "Sam", ""], ["McBride", "Conor", ""], ["McLaughlin", "Craig", ""]]}, {"id": "1611.09470", "submitter": "EPTCS", "authors": "J. Boender (School of Science and Technology Middlesex University,\n  London), E. Currie (School of Science and Technology Middlesex University,\n  London), M. Loomes (School of Science and Technology Middlesex University,\n  London), G. Primiero (School of Science and Technology Middlesex University,\n  London), F. Raimondi (School of Science and Technology Middlesex University,\n  London)", "title": "Teaching Functional Patterns through Robotic Applications", "comments": "In Proceedings TFPIE 2015/6, arXiv:1611.08651", "journal-ref": "EPTCS 230, 2016, pp. 17-29", "doi": "10.4204/EPTCS.230.2", "report-no": null, "categories": "cs.CY cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present our approach to teaching functional programming to First Year\nComputer Science students at Middlesex University through projects in robotics.\nA holistic approach is taken to the curriculum, emphasising the connections\nbetween different subject areas. A key part of the students' learning is\nthrough practical projects that draw upon and integrate the taught material. To\nsupport these, we developed the Middlesex Robotic plaTfOrm (MIRTO), an\nopen-source platform built using Raspberry Pi, Arduino, HUB-ee wheels and\nrunning Racket (a LISP dialect). In this paper we present the motivations for\nour choices and explain how a number of concepts of functional programming may\nbe employed when programming robotic applications. We present some students'\nwork with robotics projects: we consider the use of robotics projects to have\nbeen a success, both for their value in reinforcing students' understanding of\nprogramming concepts and for their value in motivating the students.\n", "versions": [{"version": "v1", "created": "Tue, 29 Nov 2016 03:39:20 GMT"}], "update_date": "2016-11-30", "authors_parsed": [["Boender", "J.", "", "School of Science and Technology Middlesex University,\n  London"], ["Currie", "E.", "", "School of Science and Technology Middlesex University,\n  London"], ["Loomes", "M.", "", "School of Science and Technology Middlesex University,\n  London"], ["Primiero", "G.", "", "School of Science and Technology Middlesex University,\n  London"], ["Raimondi", "F.", "", "School of Science and Technology Middlesex University,\n  London"]]}, {"id": "1611.09471", "submitter": "EPTCS", "authors": "Scott N. Walck (Lebanon Valley College, Annville, Pennsylvania, USA)", "title": "Learn Quantum Mechanics with Haskell", "comments": "In Proceedings TFPIE 2015/6, arXiv:1611.08651", "journal-ref": "EPTCS 230, 2016, pp. 31-46", "doi": "10.4204/EPTCS.230.3", "report-no": null, "categories": "cs.PL quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To learn quantum mechanics, one must become adept in the use of various\nmathematical structures that make up the theory; one must also become familiar\nwith some basic laboratory experiments that the theory is designed to explain.\nThe laboratory ideas are naturally expressed in one language, and the\ntheoretical ideas in another. We present a method for learning quantum\nmechanics that begins with a laboratory language for the description and\nsimulation of simple but essential laboratory experiments, so that students can\ngain some intuition about the phenomena that a theory of quantum mechanics\nneeds to explain. Then, in parallel with the introduction of the mathematical\nframework on which quantum mechanics is based, we introduce a calculational\nlanguage for describing important mathematical objects and operations, allowing\nstudents to do calculations in quantum mechanics, including calculations that\ncannot be done by hand. Finally, we ask students to use the calculational\nlanguage to implement a simplified version of the laboratory language, bringing\ntogether the theoretical and laboratory ideas.\n", "versions": [{"version": "v1", "created": "Tue, 29 Nov 2016 03:39:28 GMT"}], "update_date": "2016-11-30", "authors_parsed": [["Walck", "Scott N.", "", "Lebanon Valley College, Annville, Pennsylvania, USA"]]}, {"id": "1611.09472", "submitter": "EPTCS", "authors": "Victor Winter (University of Nebraska-Omaha), Betty Love (University\n  of Nebraska-Omaha), Cindy Corritore (Creighton University)", "title": "The Bricklayer Ecosystem - Art, Math, and Code", "comments": "In Proceedings TFPIE 2015/6, arXiv:1611.08651", "journal-ref": "EPTCS 230, 2016, pp. 47-61", "doi": "10.4204/EPTCS.230.4", "report-no": null, "categories": "cs.PL cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the Bricklayer Ecosystem - a freely-available online\neducational ecosystem created for people of all ages and coding backgrounds.\nBricklayer is designed in accordance with a \"low-threshold infinite ceiling\"\nphilosophy and has been successfully used to teach coding to primary school\nstudents, middle school students, university freshmen, and in-service secondary\nmath teachers. Bricklayer programs are written in the functional programming\nlanguage SML and, when executed, create 2D and 3D artifacts. These artifacts\ncan be viewed using a variety of third-party tools such as LEGO Digital\nDesigner (LDD), LDraw, Minecraft clients, Brickr, as well as STereoLithography\nviewers.\n", "versions": [{"version": "v1", "created": "Tue, 29 Nov 2016 03:39:56 GMT"}], "update_date": "2016-11-30", "authors_parsed": [["Winter", "Victor", "", "University of Nebraska-Omaha"], ["Love", "Betty", "", "University\n  of Nebraska-Omaha"], ["Corritore", "Cindy", "", "Creighton University"]]}, {"id": "1611.09473", "submitter": "EPTCS", "authors": "Prabhakar Ragde (University of Waterloo)", "title": "Proust: A Nano Proof Assistant", "comments": "In Proceedings TFPIE 2015/6, arXiv:1611.08651", "journal-ref": "EPTCS 230, 2016, pp. 63-75", "doi": "10.4204/EPTCS.230.5", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Proust is a small Racket program offering rudimentary interactive assistance\nin the development of verified proofs for propositional and predicate logic. It\nis constructed in stages, some of which are done by students before using it to\ncomplete proof exercises, and in parallel with the study of its theoretical\nunderpinnings, including elements of Martin-Lof type theory. The goal is\ntwofold: to demystify some of the machinery behind full-featured proof\nassistants such as Coq and Agda, and to better integrate the study of formal\nlogic with other core elements of an undergraduate computer science curriculum.\n", "versions": [{"version": "v1", "created": "Tue, 29 Nov 2016 03:40:04 GMT"}], "update_date": "2016-11-30", "authors_parsed": [["Ragde", "Prabhakar", "", "University of Waterloo"]]}, {"id": "1611.09475", "submitter": "EPTCS", "authors": "Cezar Ionescu (Chalmers University of Technology), Patrik Jansson\n  (Chalmers University of Technology)", "title": "Domain-Specific Languages of Mathematics: Presenting Mathematical\n  Analysis Using Functional Programming", "comments": "In Proceedings TFPIE 2015/6, arXiv:1611.08651", "journal-ref": "EPTCS 230, 2016, pp. 1-15", "doi": "10.4204/EPTCS.230.1", "report-no": null, "categories": "cs.CY cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the approach underlying a course on \"Domain-Specific Languages of\nMathematics\", currently being developed at Chalmers in response to difficulties\nfaced by third-year students in learning and applying classical mathematics\n(mainly real and complex analysis). The main idea is to encourage the students\nto approach mathematical domains from a functional programming perspective: to\nidentify the main functions and types involved and, when necessary, to\nintroduce new abstractions; to give calculational proofs; to pay attention to\nthe syntax of the mathematical expressions; and, finally, to organise the\nresulting functions and types in domain-specific languages.\n", "versions": [{"version": "v1", "created": "Tue, 29 Nov 2016 03:42:04 GMT"}], "update_date": "2016-11-30", "authors_parsed": [["Ionescu", "Cezar", "", "Chalmers University of Technology"], ["Jansson", "Patrik", "", "Chalmers University of Technology"]]}, {"id": "1611.09606", "submitter": "Sigurd Schneider", "authors": "Sigurd Schneider, Gert Smolka, Sebastian Hack", "title": "An Inductive Proof Method for Simulation-based Compiler Correctness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study induction on the program structure as a proof method for\nbisimulation-based compiler correctness. We consider a first-order language\nwith mutually recursive function definitions, system calls, and an environment\nsemantics. The proof method relies on a generalization of compatibility of\nfunction definition with the bisimulation. We use the inductive method to show\ncorrectness of a form of dead code elimination. This is an interesting case\nstudy because the transformation removes function, variable, and parameter\ndefinitions from the program. While such transformations require modification\nof the simulation in a coinductive proof, the inductive method deals with them\nnaturally. All our results are formalized in Coq.\n", "versions": [{"version": "v1", "created": "Tue, 29 Nov 2016 12:47:15 GMT"}], "update_date": "2016-11-30", "authors_parsed": [["Schneider", "Sigurd", ""], ["Smolka", "Gert", ""], ["Hack", "Sebastian", ""]]}, {"id": "1611.09626", "submitter": "Christoph Rauch", "authors": "Andr\\'es Aristiz\\'abal, Dariusz Biernacki, Sergue\\\"i Lenglet, Piotr\n  Polesiuk", "title": "Environmental Bisimulations for Delimited-Control Operators with Dynamic\n  Prompt Generation", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 13, Issue 3 (September\n  19, 2017) lmcs:3942", "doi": "10.23638/LMCS-13(3:27)2017", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present sound and complete environmental bisimilarities for a variant of\nDybvig et al.'s calculus of multi-prompted delimited-control operators with\ndynamic prompt generation. The reasoning principles that we obtain generalize\nand advance the existing techniques for establishing program equivalence in\ncalculi with single-prompted delimited control. The basic theory that we\ndevelop is presented using Madiot et al.'s framework that allows for smooth\nintegration and composition of up-to techniques facilitating bisimulation\nproofs. We also generalize the framework in order to express environmental\nbisimulations that support equivalence proofs of evaluation contexts\nrepresenting continuations. This change leads to a novel and powerful up-to\ntechnique enhancing bisimulation proofs in the presence of control operators.\n", "versions": [{"version": "v1", "created": "Tue, 29 Nov 2016 13:39:44 GMT"}, {"version": "v2", "created": "Fri, 28 Apr 2017 09:31:30 GMT"}, {"version": "v3", "created": "Wed, 30 Aug 2017 08:30:28 GMT"}, {"version": "v4", "created": "Thu, 31 Aug 2017 09:37:48 GMT"}, {"version": "v5", "created": "Mon, 18 Sep 2017 12:35:33 GMT"}], "update_date": "2017-10-11", "authors_parsed": [["Aristiz\u00e1bal", "Andr\u00e9s", ""], ["Biernacki", "Dariusz", ""], ["Lenglet", "Sergue\u00ef", ""], ["Polesiuk", "Piotr", ""]]}, {"id": "1611.09633", "submitter": "Christoph Rauch", "authors": "Dmitriy Traytel", "title": "Formal Languages, Formally and Coinductively", "comments": "Extended version of homonymous FSCD 2016 paper", "journal-ref": "Logical Methods in Computer Science, Volume 13, Issue 3 (September\n  19, 2017) lmcs:3943", "doi": "10.23638/LMCS-13(3:28)2017", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditionally, formal languages are defined as sets of words. More recently,\nthe alternative coalgebraic or coinductive representation as infinite tries,\ni.e., prefix trees branching over the alphabet, has been used to obtain compact\nand elegant proofs of classic results in language theory. In this article, we\nstudy this representation in the Isabelle proof assistant. We define regular\noperations on infinite tries and prove the axioms of Kleene algebra for those\noperations. Thereby, we exercise corecursion and coinduction and confirm the\ncoinductive view being profitable in formalizations, as it improves over the\nset-of-words view with respect to proof automation.\n", "versions": [{"version": "v1", "created": "Tue, 29 Nov 2016 13:56:39 GMT"}, {"version": "v2", "created": "Sat, 13 May 2017 22:58:31 GMT"}, {"version": "v3", "created": "Mon, 18 Sep 2017 12:53:01 GMT"}], "update_date": "2017-10-11", "authors_parsed": [["Traytel", "Dmitriy", ""]]}, {"id": "1611.09906", "submitter": "Saverio Perugini", "authors": "Brandon M. Williams and Saverio Perugini", "title": "Revisiting the Futamura Projections: A Diagrammatic Approach", "comments": "20 pages, 11 figures, 3 tables; pre-print of published version in\n  Theoretical and Applied Informatics", "journal-ref": "B.M. Williams & Perugini, S. (2016) Revisiting the Futamura\n  Projections: A diagrammatic approach. Theoretical and Applied Informatics,\n  28(4), 15-32", "doi": "10.20904/284015", "report-no": null, "categories": "cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advent of language implementation tools such as PyPy and Truffle/Graal\nhave reinvigorated and broadened interest in topics related to automatic\ncompiler generation and optimization. Given this broader interest, we revisit\nthe Futamura Projections using a novel diagram scheme. Through these diagrams\nwe emphasize the recurring patterns in the Futamura Projections while\naddressing their complexity and abstract nature. We anticipate that this\napproach will improve the accessibility of the Futamura Projections and help\nfoster analysis of those new tools through the lens of partial evaluation.\n", "versions": [{"version": "v1", "created": "Tue, 29 Nov 2016 21:56:34 GMT"}, {"version": "v2", "created": "Wed, 29 Mar 2017 00:00:13 GMT"}, {"version": "v3", "created": "Tue, 20 Mar 2018 22:38:16 GMT"}], "update_date": "2018-03-22", "authors_parsed": [["Williams", "Brandon M.", ""], ["Perugini", "Saverio", ""]]}]