[{"id": "1507.00385", "submitter": "Ranjit Jhala", "authors": "Niki Vazou, Alexander Bakst, Ranjit Jhala", "title": "Bounded Refinement Types", "comments": "14 pages, International Conference on Functional Programming, ICFP\n  2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a notion of bounded quantification for refinement types and show\nhow it expands the expressiveness of refinement typing by using it to develop\ntyped combinators for: (1) relational algebra and safe database access, (2)\nFloyd-Hoare logic within a state transformer monad equipped with combinators\nfor branching and looping, and (3) using the above to implement a refined IO\nmonad that tracks capabilities and resource usage. This leap in expressiveness\ncomes via a translation to \"ghost\" functions, which lets us retain the\nautomated and decidable SMT based checking and inference that makes refinement\ntyping effective in practice.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2015 22:14:45 GMT"}], "update_date": "2015-07-03", "authors_parsed": [["Vazou", "Niki", ""], ["Bakst", "Alexander", ""], ["Jhala", "Ranjit", ""]]}, {"id": "1507.00723", "submitter": "Bertrand Meyer", "authors": "Bertrand Meyer", "title": "Theory of Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A general theory of programs, programming and programming languages built up\nfrom a few concepts of elementary set theory. Derives, as theorems, properties\ntreated as axioms by classic approaches to programming. Covers sequential and\nconcurrent computation.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2015 12:34:20 GMT"}, {"version": "v2", "created": "Mon, 6 Jul 2015 16:10:04 GMT"}, {"version": "v3", "created": "Mon, 7 Dec 2015 16:26:15 GMT"}], "update_date": "2015-12-08", "authors_parsed": [["Meyer", "Bertrand", ""]]}, {"id": "1507.00980", "submitter": "C\\'esar Rodr\\'iguez", "authors": "C\\'esar Rodr\\'iguez, Marcelo Sousa, Subodh Sharma, Daniel Kroening", "title": "Unfolding-based Partial Order Reduction", "comments": "Long version of a paper with the same title appeared on the\n  proceedings of CONCUR 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Partial order reduction (POR) and net unfoldings are two alternative methods\nto tackle state-space explosion caused by concurrency. In this paper, we\npropose the combination of both approaches in an effort to combine their\nstrengths. We first define, for an abstract execution model, unfolding\nsemantics parameterized over an arbitrary independence relation. Based on it,\nour main contribution is a novel stateless POR algorithm that explores at most\none execution per Mazurkiewicz trace, and in general, can explore exponentially\nfewer, thus achieving a form of super-optimality. Furthermore, our\nunfolding-based POR copes with non-terminating executions and incorporates\nstate-caching. Over benchmarks with busy-waits, among others, our experiments\nshow a dramatic reduction in the number of executions when compared to a\nstate-of-the-art DPOR.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jul 2015 18:23:13 GMT"}], "update_date": "2015-07-06", "authors_parsed": [["Rodr\u00edguez", "C\u00e9sar", ""], ["Sousa", "Marcelo", ""], ["Sharma", "Subodh", ""], ["Kroening", "Daniel", ""]]}, {"id": "1507.00996", "submitter": "Jan-Willem van de Meent", "authors": "Frank Wood, Jan Willem van de Meent, Vikash Mansinghka", "title": "A New Approach to Probabilistic Programming Inference", "comments": "Updated version of the 2014 AISTATS paper (to reflect changes in new\n  language syntax). 10 pages, 3 figures. Proceedings of the Seventeenth\n  International Conference on Artificial Intelligence and Statistics, JMLR\n  Workshop and Conference Proceedings, Vol 33, 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce and demonstrate a new approach to inference in expressive\nprobabilistic programming languages based on particle Markov chain Monte Carlo.\nOur approach is simple to implement and easy to parallelize. It applies to\nTuring-complete probabilistic programming languages and supports accurate\ninference in models that make use of complex control flow, including stochastic\nrecursion. It also includes primitives from Bayesian nonparametric statistics.\nOur experiments show that this approach can be more efficient than previously\nintroduced single-site Metropolis-Hastings methods.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jul 2015 19:52:58 GMT"}, {"version": "v2", "created": "Thu, 9 Jul 2015 10:31:26 GMT"}], "update_date": "2015-07-10", "authors_parsed": [["Wood", "Frank", ""], ["van de Meent", "Jan Willem", ""], ["Mansinghka", "Vikash", ""]]}, {"id": "1507.01423", "submitter": "Francesco Ranzato", "authors": "Francesco Ranzato", "title": "Abstract Interpretation of Supermodular Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supermodular games find significant applications in a variety of models,\nespecially in operations research and economic applications of noncooperative\ngame theory, and feature pure strategy Nash equilibria characterized as fixed\npoints of multivalued functions on complete lattices. Pure strategy Nash\nequilibria of supermodular games are here approximated by resorting to the\ntheory of abstract interpretation, a well established and known framework used\nfor designing static analyses of programming languages. This is obtained by\nextending the theory of abstract interpretation in order to handle\napproximations of multivalued functions and by providing some methods for\nabstracting supermodular games, in order to obtain approximate Nash equilibria\nwhich are shown to be correct within the abstract interpretation framework.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2015 12:47:52 GMT"}], "update_date": "2015-07-07", "authors_parsed": [["Ranzato", "Francesco", ""]]}, {"id": "1507.01451", "submitter": "Peter Sch\\\"uller", "authors": "Thomas Eiter, Michael Fink, Giovambattista Ianni, Thomas Krennwallner,\n  Christoph Redl, Peter Sch\\\"uller", "title": "A model building framework for Answer Set Programming with external\n  computations", "comments": "57 pages, 9 figures, 3 tables, 6 algorithms, to appear in Theory and\n  Practice of Logic Programming (accepted in June 2015)", "journal-ref": "Theory and Practice of Logic Programming 16 (2016) 418-464", "doi": "10.1017/S1471068415000113", "report-no": null, "categories": "cs.AI cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As software systems are getting increasingly connected, there is a need for\nequipping nonmonotonic logic programs with access to external sources that are\npossibly remote and may contain information in heterogeneous formats. To cater\nfor this need, HEX programs were designed as a generalization of answer set\nprograms with an API style interface that allows to access arbitrary external\nsources, providing great flexibility. Efficient evaluation of such programs\nhowever is challenging, and it requires to interleave external computation and\nmodel building; to decide when to switch between these tasks is difficult, and\nexisting approaches have limited scalability in many real-world application\nscenarios. We present a new approach for the evaluation of logic programs with\nexternal source access, which is based on a configurable framework for dividing\nthe non-ground program into possibly overlapping smaller parts called\nevaluation units. The latter will be processed by interleaving external\nevaluation and model building using an evaluation graph and a model graph,\nrespectively, and by combining intermediate results. Experiments with our\nprototype implementation show a significant improvement compared to previous\napproaches. While designed for HEX-programs, the new evaluation approach may be\ndeployed to related rule-based formalisms as well.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2015 13:31:39 GMT"}, {"version": "v2", "created": "Sat, 11 Jul 2015 22:20:15 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Eiter", "Thomas", ""], ["Fink", "Michael", ""], ["Ianni", "Giovambattista", ""], ["Krennwallner", "Thomas", ""], ["Redl", "Christoph", ""], ["Sch\u00fcller", "Peter", ""]]}, {"id": "1507.01656", "submitter": "Steve Versteeg", "authors": "Steve Versteeg", "title": "Languages for Mobile Agents", "comments": "Honours Thesis. Department of Computer Science and Sofware\n  Engineering, University of Melbourne. 1997", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile agents represent a new model for network computing. Many different\nlanguages have been used to implement mobile agents. The characteristics that\nmake a language useful for writing mobile agents are: (1) their support of\nagent migration, (2) their support for agent-to-agent communication, (3) how\nthey allow agents to interact with local resources, (4) security mechanisms,\n(5) execution efficiency, (6) language implementation across multiple\nplatforms, and (7) the language's ease of programming of the tasks mobile\nagents perform.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2015 01:47:31 GMT"}], "update_date": "2015-07-08", "authors_parsed": [["Versteeg", "Steve", ""]]}, {"id": "1507.01708", "submitter": "Carlo Sartiani", "authors": "Dario Colazzo, Carlo Sartiani", "title": "Typing Regular Path Query Languages for Data Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regular path query languages for data graphs are essentially \\emph{untyped}.\nThe lack of type information greatly limits the optimization opportunities for\nquery engines and makes application development more complex. In this paper we\ndiscuss a simple, yet expressive, schema language for edge-labelled data\ngraphs. This schema language is, then, used to define a query type inference\napproach with good precision properties.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2015 08:43:59 GMT"}], "update_date": "2015-07-08", "authors_parsed": [["Colazzo", "Dario", ""], ["Sartiani", "Carlo", ""]]}, {"id": "1507.01902", "submitter": "Ali JavadiAbhari", "authors": "Ali JavadiAbhari, Shruti Patil, Daniel Kudrow, Jeff Heckey, Alexey\n  Lvov, Frederic T. Chong, Margaret Martonosi", "title": "ScaffCC: Scalable Compilation and Analysis of Quantum Programs", "comments": "Journal of Parallel Computing (PARCO)", "journal-ref": "Parallel Comput. 45, C (June 2015), 2-17", "doi": "10.1016/j.parco.2014.12.001", "report-no": null, "categories": "quant-ph cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present ScaffCC, a scalable compilation and analysis framework based on\nLLVM, which can be used for compiling quantum computing applications at the\nlogical level. Drawing upon mature compiler technologies, we discuss\nsimilarities and differences between compilation of classical and quantum\nprograms, and adapt our methods to optimizing the compilation time and output\nfor the quantum case. Our work also integrates a reversible-logic synthesis\ntool in the compiler to facilitate coding of quantum circuits. Lastly, we\npresent some useful quantum program analysis scenarios and discuss their\nimplications, specifically with an elaborate discussion of timing analysis for\ncritical path estimation. Our work focuses on bridging the gap between\nhigh-level quantum algorithm specifi- cations and low-level physical\nimplementations, while providing good scalability to larger and more\ninteresting problems\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2015 18:00:50 GMT"}], "update_date": "2015-07-08", "authors_parsed": [["JavadiAbhari", "Ali", ""], ["Patil", "Shruti", ""], ["Kudrow", "Daniel", ""], ["Heckey", "Jeff", ""], ["Lvov", "Alexey", ""], ["Chong", "Frederic T.", ""], ["Martonosi", "Margaret", ""]]}, {"id": "1507.02437", "submitter": "Maxime Chevalier-Boisvert", "authors": "Maxime Chevalier-Boisvert and Marc Feeley", "title": "Extending Basic Block Versioning with Typed Object Shapes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Typical JavaScript (JS) programs feature a large number of object property\naccesses. Hence, fast property reads and writes are crucial for good\nperformance. Unfortunately, many (often redundant) dynamic checks are implied\nin each property access and the semantic complexity of JS makes it difficult to\noptimize away these tests through program analysis. We introduce two techniques\nto effectively eliminate a large proportion of dynamic checks related to object\nproperty accesses.\n  Typed shapes enable code specialization based on object property types\nwithout potentially complex and expensive analyses. Shape propagation allows\nthe elimination of redundant shape checks in inline caches. These two\ntechniques combine particularly well with Basic Block Versioning (BBV), but\nshould be easily adaptable to tracing Just-In-Time (JIT) compilers and method\nJITs with type feedback.\n  To assess the effectiveness of the techniques presented, we have implemented\nthem in Higgs, a type-specializing JIT compiler for JS. The techniques are\ncompared to a baseline using polymorphic Inline Caches (PICs), as well as\ncommercial JS implementations. Empirical results show that across the 26\nbenchmarks tested, these techniques eliminate on average 48% of type tests,\nreduce code size by 17% and reduce execution time by 25%. On several\nbenchmarks, Higgs performs better than current production JS virtual machines\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2015 09:58:44 GMT"}], "update_date": "2015-07-10", "authors_parsed": [["Chevalier-Boisvert", "Maxime", ""], ["Feeley", "Marc", ""]]}, {"id": "1507.02988", "submitter": "Ravi Chugh", "authors": "Ravi Chugh, Brian Hempel, Mitchell Spradlin, Jacob Albers", "title": "Programmatic and Direct Manipulation, Together at Last", "comments": "PLDI 2016 Paper + Supplementary Appendices", "journal-ref": null, "doi": "10.1145/2908080.2908103", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Direct manipulation interfaces and programmatic systems have distinct and\ncomplementary strengths. The former provide intuitive, immediate visual\nfeedback and enable rapid prototyping, whereas the latter enable complex,\nreusable abstractions. Unfortunately, existing systems typically force users\ninto just one of these two interaction modes.\n  We present a system called Sketch-n-Sketch that integrates programmatic and\ndirect manipulation for the particular domain of Scalable Vector Graphics\n(SVG). In Sketch-n-Sketch, the user writes a program to generate an output SVG\ncanvas. Then the user may directly manipulate the canvas while the system\nimmediately infers a program update in order to match the changes to the\noutput, a workflow we call live synchronization. To achieve this, we propose\n(i) a technique called trace-based program synthesis that takes program\nexecution history into account in order to constrain the search space and (ii)\nheuristics for dealing with ambiguities. Based on our experience with examples\nspanning 2,000 lines of code and from the results of a preliminary user study,\nwe believe that Sketch-n-Sketch provides a novel workflow that can augment\ntraditional programming systems. Our approach may serve as the basis for live\nsynchronization in other application domains, as well as a starting point for\nyet more ambitious ways of combining programmatic and direct manipulation.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2015 18:55:56 GMT"}, {"version": "v2", "created": "Fri, 20 Nov 2015 22:51:03 GMT"}, {"version": "v3", "created": "Mon, 18 Apr 2016 18:56:50 GMT"}], "update_date": "2016-04-19", "authors_parsed": [["Chugh", "Ravi", ""], ["Hempel", "Brian", ""], ["Spradlin", "Mitchell", ""], ["Albers", "Jacob", ""]]}, {"id": "1507.03137", "submitter": "David Van Horn", "authors": "Thomas Gilray, Steven Lyde, Michael D. Adams, Matthew Might, David Van\n  Horn", "title": "Pushdown Control-Flow Analysis for Free", "comments": "in Proceedings of the 43rd Annual ACM SIGPLAN-SIGACT Symposium on\n  Principles of Programming Languages, 2016", "journal-ref": null, "doi": "10.1145/2837614.2837631", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional control-flow analysis (CFA) for higher-order languages, whether\nimplemented by constraint-solving or abstract interpretation, introduces\nspurious connections between callers and callees. Two distinct invocations of a\nfunction will necessarily pollute one another's return-flow. Recently, three\ndistinct approaches have been published which provide perfect call-stack\nprecision in a computable manner: CFA2, PDCFA, and AAC. Unfortunately, CFA2 and\nPDCFA are difficult to implement and require significant engineering effort.\nFurthermore, all three are computationally expensive; for a monovariant\nanalysis, CFA2 is in $O(2^n)$, PDCFA is in $O(n^6)$, and AAC is in $O(n^9 log\nn)$.\n  In this paper, we describe a new technique that builds on these but is both\nstraightforward to implement and computationally inexpensive. The crucial\ninsight is an unusual state-dependent allocation strategy for the addresses of\ncontinuation. Our technique imposes only a constant-factor overhead on the\nunderlying analysis and, with monovariance, costs only O(n3) in the worst case.\n  This paper presents the intuitions behind this development, a proof of the\nprecision of this analysis, and benchmarks demonstrating its efficacy.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jul 2015 18:37:48 GMT"}, {"version": "v2", "created": "Mon, 21 Mar 2016 22:32:20 GMT"}], "update_date": "2016-03-23", "authors_parsed": [["Gilray", "Thomas", ""], ["Lyde", "Steven", ""], ["Adams", "Michael D.", ""], ["Might", "Matthew", ""], ["Van Horn", "David", ""]]}, {"id": "1507.03513", "submitter": "Jean Yang", "authors": "Jean Yang, Travis Hance, Thomas H. Austin, Armando Solar-Lezama,\n  Cormac Flanagan, Stephen Chong", "title": "Precise, Dynamic Information Flow for Database-Backed Applications", "comments": null, "journal-ref": null, "doi": "10.1145/2908080.2908098", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approach for dynamic information flow control across the\napplication and database. Our approach reduces the amount of policy code\nrequired, yields formal guarantees across the application and database, works\nwith existing relational database implementations, and scales for realistic\napplications. In this paper, we present a programming model that factors out\ninformation flow policies from application code and database queries, a dynamic\nsemantics for the underlying {\\lambda}^JDB core language, and proofs of\ntermination-insensitive non-interference and policy compliance for the\nsemantics. We implement these ideas in Jacqueline, a Python web framework, and\ndemonstrate feasibility through three application case studies: a course\nmanager, a health record system, and a conference management system used to run\nan academic workshop. We show that in comparison to traditional applications\nwith hand-coded policy checks, Jacqueline applications have 1) a smaller\ntrusted computing base, 2) fewer lines of policy code, and 2) reasonable, often\nnegligible, additional overheads.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2015 16:26:09 GMT"}, {"version": "v2", "created": "Sat, 21 Nov 2015 17:21:09 GMT"}, {"version": "v3", "created": "Wed, 25 Nov 2015 00:31:26 GMT"}, {"version": "v4", "created": "Fri, 15 Apr 2016 03:42:46 GMT"}, {"version": "v5", "created": "Sat, 23 Apr 2016 22:49:26 GMT"}], "update_date": "2016-04-26", "authors_parsed": [["Yang", "Jean", ""], ["Hance", "Travis", ""], ["Austin", "Thomas H.", ""], ["Solar-Lezama", "Armando", ""], ["Flanagan", "Cormac", ""], ["Chong", "Stephen", ""]]}, {"id": "1507.03559", "submitter": "David Van Horn", "authors": "David Darais, David Van Horn", "title": "Mechanically Verified Calculational Abstract Interpretation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Calculational abstract interpretation, long advocated by Cousot, is a\ntechnique for deriving correct-by-construction abstract interpreters from the\nformal semantics of programming languages.\n  This paper addresses the problem of deriving correct-by-verified-construction\nabstract interpreters with the use of a proof assistant. We identify several\ntechnical challenges to overcome with the aim of supporting verified\ncalculational abstract interpretation that is faithful to existing\npencil-and-paper proofs, supports calculation with Galois connections\ngenerally, and enables the extraction of verified static analyzers from these\nproofs. To meet these challenges, we develop a theory of Galois connections in\nmonadic style that include a specification effect. Effectful calculations may\nreason classically, while pure calculations have extractable computational\ncontent. Moving between the worlds of specification and implementation is\nenabled by our metatheory.\n  To validate our approach, we give the first mechanically verified proof of\ncorrectness for Cousot's \"Calculational design of a generic abstract\ninterpreter.\" Our proof \"by calculus\" closely follows the original\npaper-and-pencil proof and supports the extraction of a verified static\nanalyzer.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2015 19:23:25 GMT"}], "update_date": "2015-07-14", "authors_parsed": [["Darais", "David", ""], ["Van Horn", "David", ""]]}, {"id": "1507.03577", "submitter": "Jinseong Jeon", "authors": "Jinseong Jeon and Xiaokang Qiu and Jeffrey S. Foster and Armando\n  Solar-Lezama", "title": "JSKETCH: Sketching for Java", "comments": "This research was supported in part by NSF CCF-1139021, CCF- 1139056,\n  CCF-1161775, and the partnership between UMIACS and the Laboratory for\n  Telecommunication Sciences", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sketch-based synthesis, epitomized by the SKETCH tool, lets developers\nsynthesize software starting from a partial program, also called a sketch or\ntemplate. This paper presents JSKETCH, a tool that brings sketch-based\nsynthesis to Java. JSKETCH's input is a partial Java program that may include\nholes, which are unknown constants, expression generators, which range over\nsets of expressions, and class generators, which are partial classes. JSKETCH\nthen translates the synthesis problem into a SKETCH problem; this translation\nis complex because SKETCH is not object-oriented. Finally, JSKETCH synthesizes\nan executable Java program by interpreting the output of SKETCH.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2015 05:02:53 GMT"}], "update_date": "2015-07-15", "authors_parsed": [["Jeon", "Jinseong", ""], ["Qiu", "Xiaokang", ""], ["Foster", "Jeffrey S.", ""], ["Solar-Lezama", "Armando", ""]]}, {"id": "1507.03634", "submitter": "J\\\"urgen Koslowski", "authors": "Michael Shulman (University of San Diego)", "title": "Idempotents in intensional type theory", "comments": "24 pages. v2: final version, to appear in LMCS", "journal-ref": "Logical Methods in Computer Science, Volume 12, Issue 3 (April 27,\n  2017) lmcs:2027", "doi": "10.2168/LMCS-12(3:9)2016", "report-no": null, "categories": "math.LO cs.PL math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study idempotents in intensional Martin-L\\\"of type theory, and in\nparticular the question of when and whether they split. We show that in the\npresence of propositional truncation and Voevodsky's univalence axiom, there\nexist idempotents that do not split; thus in plain MLTT not all idempotents can\nbe proven to split. On the other hand, assuming only function extensionality,\nan idempotent can be split if and only if its witness of idempotency satisfies\none extra coherence condition. Both proofs are inspired by parallel results of\nLurie in higher category theory, showing that ideas from higher category theory\nand homotopy theory can have applications even in ordinary MLTT.\n  Finally, we show that although the witness of idempotency can be recovered\nfrom a splitting, the one extra coherence condition cannot in general; and we\nconstruct \"the type of fully coherent idempotents\", by splitting an idempotent\non the type of partially coherent ones. Our results have been formally verified\nin the proof assistant Coq.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2015 21:59:32 GMT"}, {"version": "v2", "created": "Tue, 16 Aug 2016 19:05:22 GMT"}, {"version": "v3", "created": "Mon, 12 Sep 2016 19:12:04 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Shulman", "Michael", "", "University of San Diego"]]}, {"id": "1507.04817", "submitter": "David Van Horn", "authors": "Phuc C. Nguyen and Sam Tobin-Hochstadt and David Van Horn", "title": "Higher-order symbolic execution for contract verification and refutation", "comments": "This paper unifies and expands upon the work presented in the papers\n  \"Soft contract verification\" [arXiv:1307.6239], and \"Relatively complete\n  counterexamples for higher-order programs\" [arXiv:1411.3967]. It also\n  subsumes the work in the paper \"Higher-order symbolic execution via\n  contracts\" [arXiv:1103.1362]", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new approach to automated reasoning about higher-order programs\nby endowing symbolic execution with a notion of higher-order, symbolic values.\nOur approach is sound and relatively complete with respect to a first-order\nsolver for base type values. Therefore, it can form the basis of automated\nverification and bug-finding tools for higher-order programs.\n  To validate our approach, we use it to develop and evaluate a system for\nverifying and refuting behavioral software contracts of components in a\nfunctional language, which we call soft contract verification. In doing so, we\ndiscover a mutually beneficial relation between behavioral contracts and\nhigher-order symbolic execution.\n  Our system uses higher-order symbolic execution, leveraging contracts as a\nsource of symbolic values including unknown behavioral values, and employs an\nupdatable heap of contract invariants to reason about flow-sensitive facts.\nWhenever a contract is refuted, it reports a concrete counterexample\nreproducing the error, which may involve solving for an unknown function. The\napproach is able to analyze first-class contracts, recursive data structures,\nunknown functions, and control-flow-sensitive refinements of values, which are\nall idiomatic in dynamic languages. It makes effective use of an off-the-shelf\nsolver to decide problems without heavy encodings. The approach is competitive\nwith a wide range of existing tools---including type systems, flow analyzers,\nand model checkers---on their own benchmarks. We have built a tool which\nanalyzes programs written in Racket, and report on its effectiveness in\nverifying and refuting contracts.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2015 02:21:05 GMT"}, {"version": "v2", "created": "Sat, 13 Feb 2016 18:33:34 GMT"}, {"version": "v3", "created": "Sun, 20 Mar 2016 14:12:06 GMT"}], "update_date": "2016-03-22", "authors_parsed": [["Nguyen", "Phuc C.", ""], ["Tobin-Hochstadt", "Sam", ""], ["Van Horn", "David", ""]]}, {"id": "1507.04943", "submitter": "Andr\\'e Platzer", "authors": "Andr\\'e Platzer", "title": "Differential Hybrid Games", "comments": null, "journal-ref": "ACM Transactions on Computational Logic 18(3), pages 19:1-19:44,\n  2017", "doi": "10.1145/3091123", "report-no": "CMU-CS-14-102", "categories": "cs.LO cs.GT cs.PL math.DS math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article introduces differential hybrid games, which combine differential\ngames with hybrid games. In both kinds of games, two players interact with\ncontinuous dynamics. The difference is that hybrid games also provide all the\nfeatures of hybrid systems and discrete games, but only deterministic\ndifferential equations. Differential games, instead, provide differential\nequations with continuous-time game input by both players, but not the luxury\nof hybrid games, such as mode switches and discrete-time or alternating\nadversarial interaction. This article augments differential game logic with\nmodalities for the combined dynamics of differential hybrid games. It shows how\nhybrid games subsume differential games and introduces differential game\ninvariants and differential game variants for proving properties of\ndifferential games inductively.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2015 12:20:01 GMT"}, {"version": "v2", "created": "Fri, 8 Jul 2016 12:42:59 GMT"}, {"version": "v3", "created": "Fri, 24 Feb 2017 03:08:33 GMT"}], "update_date": "2017-08-17", "authors_parsed": [["Platzer", "Andr\u00e9", ""]]}, {"id": "1507.05454", "submitter": "Germ\\'an Vidal", "authors": "Fred Mesnard, \\'Etienne Payet, Germ\\'an Vidal", "title": "Concolic Testing in Logic Programming", "comments": "To appear in Theory and Practice of Logic Programming (TPLP),\n  Proceedings of ICLP 2015", "journal-ref": "Theory and Practice of Logic Programming 15 (2015) 711-725", "doi": "10.1017/S1471068415000332", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software testing is one of the most popular validation techniques in the\nsoftware industry. Surprisingly, we can only find a few approaches to testing\nin the context of logic programming. In this paper, we introduce a systematic\napproach for dynamic testing that combines both concrete and symbolic\nexecution. Our approach is fully automatic and guarantees full path coverage\nwhen it terminates. We prove some basic properties of our technique and\nillustrate its practical usefulness through a prototype implementation.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2015 11:41:49 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Mesnard", "Fred", ""], ["Payet", "\u00c9tienne", ""], ["Vidal", "Germ\u00e1n", ""]]}, {"id": "1507.05527", "submitter": "Jeevana Priya Inala", "authors": "Jeevana Priya Inala, Nadia Polikarpova, Xiaokang Qiu, Benjamin S.\n  Lerner, Armando Solar-Lezama", "title": "Synthesis of Recursive ADT Transformations from Reusable Templates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has proposed a promising approach to improving scalability of\nprogram synthesis by allowing the user to supply a syntactic template that\nconstrains the space of potential programs. Unfortunately, creating templates\noften requires nontrivial effort from the user, which impedes the usability of\nthe synthesizer. We present a solution to this problem in the context of\nrecursive transformations on algebraic data-types. Our approach relies on\npolymorphic synthesis constructs: a small but powerful extension to the\nlanguage of syntactic templates, which makes it possible to define a program\nspace in a concise and highly reusable manner, while at the same time retains\nthe scalability benefits of conventional templates. This approach enables\nend-users to reuse predefined templates from a library for a wide variety of\nproblems with little effort. The paper also describes a novel optimization that\nfurther improves the performance and scalability of the system. We evaluated\nthe approach on a set of benchmarks that most notably includes desugaring\nfunctions for lambda calculus, which force the synthesizer to discover Church\nencodings for pairs and boolean operations.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2015 15:09:58 GMT"}, {"version": "v2", "created": "Mon, 24 Oct 2016 14:55:48 GMT"}, {"version": "v3", "created": "Sun, 16 Apr 2017 06:39:33 GMT"}], "update_date": "2017-04-18", "authors_parsed": [["Inala", "Jeevana Priya", ""], ["Polikarpova", "Nadia", ""], ["Qiu", "Xiaokang", ""], ["Lerner", "Benjamin S.", ""], ["Solar-Lezama", "Armando", ""]]}, {"id": "1507.05612", "submitter": "Daniel Neider", "authors": "Christof L\\\"oding and P. Madhusudan and Daniel Neider", "title": "Abstract Learning Frameworks for Synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop abstract learning frameworks (ALFs) for synthesis that embody the\nprinciples of CEGIS (counter-example based inductive synthesis) strategies that\nhave become widely applicable in recent years. Our framework defines a general\nabstract framework of iterative learning, based on a hypothesis space that\ncaptures the synthesized objects, a sample space that forms the space on which\ninduction is performed, and a concept space that abstractly defines the\nsemantics of the learning process. We show that a variety of synthesis\nalgorithms in current literature can be embedded in this general framework.\nWhile studying these embeddings, we also generalize some of the synthesis\nproblems these instances are of, resulting in new ways of looking at synthesis\nproblems using learning. We also investigate convergence issues for the general\nframework, and exhibit three recipes for convergence in finite time. The first\ntwo recipes generalize current techniques for convergence used by existing\nsynthesis engines. The third technique is a more involved technique of which we\nknow of no existing instantiation, and we instantiate it to concrete synthesis\nproblems.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2015 17:19:11 GMT"}, {"version": "v2", "created": "Fri, 20 May 2016 17:29:34 GMT"}], "update_date": "2016-05-23", "authors_parsed": [["L\u00f6ding", "Christof", ""], ["Madhusudan", "P.", ""], ["Neider", "Daniel", ""]]}, {"id": "1507.05762", "submitter": "Peter Schachte", "authors": "Graeme Gange, Jorge A. Navas, Peter Schachte, Harald Sondergaard,\n  Peter J. Stuckey", "title": "Horn Clauses as an Intermediate Representation for Program Analysis and\n  Transformation", "comments": "To Appear in Theory and Practice of Logic Programming (TPLP),\n  Proceedings of ICLP 2015", "journal-ref": "Theory and Practice of Logic Programming 15 (2015) 526-542", "doi": "10.1017/S1471068415000204", "report-no": null, "categories": "cs.PL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Many recent analyses for conventional imperative programs begin by\ntransforming programs into logic programs, capitalising on existing LP analyses\nand simple LP semantics. We propose using logic programs as an intermediate\nprogram representation throughout the compilation process. With restrictions\nensuring determinism and single-modedness, a logic program can easily be\ntransformed to machine language or other low-level language, while maintaining\nthe simple semantics that makes it suitable as a language for program analysis\nand transformation. We present a simple LP language that enforces determinism\nand single-modedness, and show that it makes a convenient program\nrepresentation for analysis and transformation.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2015 09:39:11 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Gange", "Graeme", ""], ["Navas", "Jorge A.", ""], ["Schachte", "Peter", ""], ["Sondergaard", "Harald", ""], ["Stuckey", "Peter J.", ""]]}, {"id": "1507.05877", "submitter": "Emanuele De Angelis", "authors": "Emanuele De Angelis (1), Fabio Fioravanti (1), Alberto Pettorossi (2),\n  Maurizio Proietti (3) ((1) DEC, University G. d'Annunzio, Pescara, Italy, (2)\n  DICII, Universita' di Roma Tor Vergata, Roma, Italy, (3) CNR-IASI, Roma,\n  Italy)", "title": "Proving Correctness of Imperative Programs by Linearizing Constrained\n  Horn Clauses", "comments": "To appear in Theory and Practice of Logic Programming (TPLP),\n  Proceedings of ICLP 2015", "journal-ref": "Theory and Practice of Logic Programming 15 (2015) 635-650", "doi": "10.1017/S1471068415000289", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method for verifying the correctness of imperative programs\nwhich is based on the automated transformation of their specifications. Given a\nprogram prog, we consider a partial correctness specification of the form\n$\\{\\varphi\\}$ prog $\\{\\psi\\}$, where the assertions $\\varphi$ and $\\psi$ are\npredicates defined by a set Spec of possibly recursive Horn clauses with linear\narithmetic (LA) constraints in their premise (also called constrained Horn\nclauses). The verification method consists in constructing a set PC of\nconstrained Horn clauses whose satisfiability implies that $\\{\\varphi\\}$ prog\n$\\{\\psi\\}$ is valid. We highlight some limitations of state-of-the-art\nconstrained Horn clause solving methods, here called LA-solving methods, which\nprove the satisfiability of the clauses by looking for linear arithmetic\ninterpretations of the predicates. In particular, we prove that there exist\nsome specifications that cannot be proved valid by any of those LA-solving\nmethods. These specifications require the proof of satisfiability of a set PC\nof constrained Horn clauses that contain nonlinear clauses (that is, clauses\nwith more than one atom in their premise). Then, we present a transformation,\ncalled linearization, that converts PC into a set of linear clauses (that is,\nclauses with at most one atom in their premise). We show that several\nspecifications that could not be proved valid by LA-solving methods, can be\nproved valid after linearization. We also present a strategy for performing\nlinearization in an automatic way and we report on some experimental results\nobtained by using a preliminary implementation of our method.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2015 15:40:25 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["De Angelis", "Emanuele", ""], ["Fioravanti", "Fabio", ""], ["Pettorossi", "Alberto", ""], ["Proietti", "Maurizio", ""]]}, {"id": "1507.05946", "submitter": "Carlo Pinciroli", "authors": "Carlo Pinciroli, Adam Lee-Brown and Giovanni Beltrame", "title": "Buzz: An Extensible Programming Language for Self-Organizing\n  Heterogeneous Robot Swarms", "comments": "12 pages, 4 figures, submitted to IEEE Transactions on Robotics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.MA cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Buzz, a novel programming language for heterogeneous robot swarms.\nBuzz advocates a compositional approach, offering primitives to define swarm\nbehaviors both from the perspective of the single robot and of the overall\nswarm. Single-robot primitives include robot-specific instructions and\nmanipulation of neighborhood data. Swarm-based primitives allow for the dynamic\nmanagement of robot teams, and for sharing information globally across the\nswarm. Self-organization stems from the completely decentralized mechanisms\nupon which the Buzz run-time platform is based. The language can be extended to\nadd new primitives (thus supporting heterogeneous robot swarms), and its\nrun-time platform is designed to be laid on top of other frameworks, such as\nRobot Operating System. We showcase the capabilities of Buzz by providing code\nexamples, and analyze scalability and robustness of the run-time platform\nthrough realistic simulated experiments with representative swarm algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2015 19:16:30 GMT"}, {"version": "v2", "created": "Wed, 29 Jul 2015 05:09:45 GMT"}, {"version": "v3", "created": "Sat, 1 Aug 2015 18:44:54 GMT"}], "update_date": "2015-08-04", "authors_parsed": [["Pinciroli", "Carlo", ""], ["Lee-Brown", "Adam", ""], ["Beltrame", "Giovanni", ""]]}, {"id": "1507.05956", "submitter": "Thomas Lynch", "authors": "Thomas W. Lynch", "title": "Towards a Better Understanding of CAR, CDR, CADR and the Others", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the IBM 704 architecture and the genesis of the names\nfor CAR, and CDR, which, as it turns out, probably don't quite make sense. The\npaper suggests that this may not be all bad, as the names lend themselves to\ncompounding. Indeed that the compound function names , such as CADR, or even\nCADADR, etc. may be read as little access programs.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2015 14:24:28 GMT"}, {"version": "v2", "created": "Thu, 23 Jul 2015 09:59:33 GMT"}, {"version": "v3", "created": "Fri, 27 Nov 2015 12:33:25 GMT"}, {"version": "v4", "created": "Mon, 7 Dec 2015 06:31:09 GMT"}, {"version": "v5", "created": "Wed, 6 Apr 2016 15:52:45 GMT"}, {"version": "v6", "created": "Thu, 7 Apr 2016 04:48:00 GMT"}], "update_date": "2016-04-08", "authors_parsed": [["Lynch", "Thomas W.", ""]]}, {"id": "1507.05986", "submitter": "Nataliia Stulova", "authors": "Nataliia Stulova, Jos\\'e F. Morales and Manuel V. Hermenegildo", "title": "Practical Run-time Checking via Unobtrusive Property Caching", "comments": "30 pages, 1 table, 170 figures; added appendix with plots; To appear\n  in Theory and Practice of Logic Programming (TPLP), Proceedings of ICLP 2015", "journal-ref": "Theory and Practice of Logic Programming 15 (2015) 726-741", "doi": "10.1017/S1471068415000344", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of annotations, referred to as assertions or contracts, to describe\nprogram properties for which run-time tests are to be generated, has become\nfrequent in dynamic programing languages. However, the frameworks proposed to\nsupport such run-time testing generally incur high time and/or space overheads\nover standard program execution. We present an approach for reducing this\noverhead that is based on the use of memoization to cache intermediate results\nof check evaluation, avoiding repeated checking of previously verified\nproperties. Compared to approaches that reduce checking frequency, our proposal\nhas the advantage of being exhaustive (i.e., all tests are checked at all\npoints) while still being much more efficient than standard run-time checking.\nCompared to the limited previous work on memoization, it performs the task\nwithout requiring modifications to data structure representation or checking\ncode. While the approach is general and system-independent, we present it for\nconcreteness in the context of the Ciao run-time checking framework, which\nallows us to provide an operational semantics with checks and caching. We also\nreport on a prototype implementation and provide some experimental results that\nsupport that using a relatively small cache leads to significant decreases in\nrun-time checking overhead.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2015 21:07:24 GMT"}, {"version": "v2", "created": "Thu, 23 Jul 2015 09:54:01 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Stulova", "Nataliia", ""], ["Morales", "Jos\u00e9 F.", ""], ["Hermenegildo", "Manuel V.", ""]]}, {"id": "1507.06189", "submitter": "Pablo Buiras", "authors": "Pablo Buiras, Deian Stefan, Alejandro Russo", "title": "On Dynamic Flow-Sensitive Floating-Label Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Flow-sensitive analysis for information-flow control (IFC) allows data\nstructures to have mutable security labels, i.e., labels that can change over\nthe course of the computation. This feature is often used to boost the\npermissiveness of the IFC monitor, by rejecting fewer runs of programs, and to\nreduce the burden of explicit label annotations. However, adding flow-sensitive\nconstructs (e.g., references or files) to a dynamic IFC system is subtle and\nmay also introduce high-bandwidth covert channels. In this work, we extend\nLIO---a language-based floating-label system---with flow-sensitive references.\nThe key insight to safely manipulating the label of a reference is to not only\nconsider the label on the data stored in the reference, i.e., the reference\nlabel, but also the label on the reference label itself. Taking this into\nconsideration, we provide an upgrade primitive that can be used to change the\nlabel of a reference in a safe manner. We additionally provide a mechanism for\nautomatic upgrades to eliminate the burden of determining when a reference\nshould be upgraded. This approach naturally extends to a concurrent setting,\nwhich has not been previously considered by dynamic flow-sensitive systems. For\nboth our sequential and concurrent calculi we prove non-interference by\nembedding the flow-sensitive system into the original, flow-insensitive LIO\ncalculus---a surprising result on its own.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jul 2015 13:59:34 GMT"}], "update_date": "2015-07-23", "authors_parsed": [["Buiras", "Pablo", ""], ["Stefan", "Deian", ""], ["Russo", "Alejandro", ""]]}, {"id": "1507.06576", "submitter": "Amelia  Harrison", "authors": "Martin Gebser, Amelia Harrison, Roland Kaminski, Vladimir Lifschitz,\n  and Torsten Schaub", "title": "Abstract Gringo", "comments": null, "journal-ref": "Theory and Practice of Logic Programming 15 (2015) 449-463", "doi": "10.1017/S1471068415000150", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper defines the syntax and semantics of the input language of the ASP\ngrounder GRINGO. The definition covers several constructs that were not\ndiscussed in earlier work on the semantics of that language, including\nintervals, pools, division of integers, aggregates with non-numeric values, and\nlparse-style aggregate expressions. The definition is abstract in the sense\nthat it disregards some details related to representing programs by strings of\nASCII characters. It serves as a specification for GRINGO from Version 4.5 on.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2015 17:26:57 GMT"}, {"version": "v2", "created": "Wed, 14 Feb 2018 21:18:28 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Gebser", "Martin", ""], ["Harrison", "Amelia", ""], ["Kaminski", "Roland", ""], ["Lifschitz", "Vladimir", ""], ["Schaub", "Torsten", ""]]}, {"id": "1507.06852", "submitter": "Maximiliano Cristia", "authors": "Maximiliano Cristia, Gianfranco Rossi and Claudia Frydman", "title": "Adding Partial Functions to Constraint Logic Programming with Sets", "comments": null, "journal-ref": "Theory and Practice of Logic Programming 15 (2015) 651-665", "doi": "10.1017/S1471068415000290", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Partial functions are common abstractions in formal specification notations\nsuch as Z, B and Alloy. Conversely, executable programming languages usually\nprovide little or no support for them. In this paper we propose to add partial\nfunctions as a primitive feature to a Constraint Logic Programming (CLP)\nlanguage, namely {log}. Although partial functions could be programmed on top\nof {log}, providing them as first-class citizens adds valuable flexibility and\ngenerality to the form of set-theoretic formulas that the language can safely\ndeal with. In particular, the paper shows how the {log} constraint solver is\nnaturally extended in order to accommodate for the new primitive constraints\ndealing with partial functions. Efficiency of the new version is empirically\nassessed by running a number of non-trivial set-theoretical goals involving\npartial functions, obtained from specifications written in Z.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2015 14:18:59 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Cristia", "Maximiliano", ""], ["Rossi", "Gianfranco", ""], ["Frydman", "Claudia", ""]]}, {"id": "1507.06944", "submitter": "Paul Tarau", "authors": "Paul Tarau", "title": "A Logic Programming Playground for Lambda Terms, Combinators, Types and\n  Tree-based Arithmetic Computations", "comments": "70 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With sound unification, Definite Clause Grammars and compact expression of\ncombinatorial generation algorithms, logic programming is shown to conveniently\nhost a declarative playground where interesting properties and behaviors emerge\nfrom the interaction of heterogenous but deeply connected computational\nobjects.\n  Compact combinatorial generation algorithms are given for several families of\nlambda terms, including open, closed, simply typed and linear terms as well as\ntype inference and normal order reduction algorithms. We describe a\nProlog-based combined lambda term generator and type-inferrer for closed\nwell-typed terms of a given size, in de Bruijn notation.\n  We introduce a compressed de Bruijn representation of lambda terms and define\nits bijections to standard representations. Our compressed terms facilitate\nderivation of size-proportionate ranking and unranking algorithms of lambda\nterms and their inferred simple types.\n  The S and K combinator expressions form a well-known Turing-complete subset\nof the lambda calculus. We specify evaluation, type inference and combinatorial\ngeneration algorithms for SK-combinator trees. In the process, we unravel\nproperties shedding new light on interesting aspects of their structure and\ndistribution.\n  A uniform representation, as binary trees with empty leaves, is given to\nexpressions built with Rosser's X-combinator, natural numbers, lambda terms and\nsimple types. Using this shared representation, ranking/unranking algorithm of\nlambda terms to tree-based natural numbers are described.\n  Our algorithms, expressed as an incrementally developed literate Prolog\nprogram, implement a declarative playground for exploration of representations,\nencodings and computations with uniformly represented lambda terms, types,\ncombinators and tree-based arithmetic.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2015 18:20:20 GMT"}], "update_date": "2015-07-27", "authors_parsed": [["Tarau", "Paul", ""]]}, {"id": "1507.06988", "submitter": "Luiz Capretz Dr.", "authors": "Lihua Wang, Luz Fernando Capretz", "title": "A Binary Data Stream Scripting Language", "comments": null, "journal-ref": "Transactions on Information Science and Applications,\n  3(2):291-298, 2006", "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Any file is fundamentally a binary data stream. A practical solution was\nachieved to interpret binary data stream. A new scripting language named Data\nFormat Scripting Language (DFSL) was developed to describe the physical layout\nof the data in a structural, more intelligible way. On the basis of the\nsolution, a generic software application was implemented; it parses various\nbinary data streams according to their respective DFSL scripts and generates\nhuman-readable result and XML document for data sharing. Our solution helps\neliminate the error-prone low-level programming, especially in the hardware\ndevices or network protocol development/debugging processes.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2015 18:26:21 GMT"}], "update_date": "2015-07-28", "authors_parsed": [["Wang", "Lihua", ""], ["Capretz", "Luz Fernando", ""]]}, {"id": "1507.07049", "submitter": "Jedidiah McClurg", "authors": "Jedidiah McClurg, Hossein Hojjat, Nate Foster, Pavol Cerny", "title": "Event-Driven Network Programming", "comments": null, "journal-ref": null, "doi": "10.1145/2908080.2908097", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software-defined networking (SDN) programs must simultaneously describe\nstatic forwarding behavior and dynamic updates in response to events.\nEvent-driven updates are critical to get right, but difficult to implement\ncorrectly due to the high degree of concurrency in networks. Existing SDN\nplatforms offer weak guarantees that can break application invariants, leading\nto problems such as dropped packets, degraded performance, security violations,\netc. This paper introduces EVENT-DRIVEN CONSISTENT UPDATES that are guaranteed\nto preserve well-defined behaviors when transitioning between configurations in\nresponse to events. We propose NETWORK EVENT STRUCTURES (NESs) to model\nconstraints on updates, such as which events can be enabled simultaneously and\ncausal dependencies between events. We define an extension of the NetKAT\nlanguage with mutable state, give semantics to stateful programs using NESs,\nand discuss provably-correct strategies for implementing NESs in SDNs. Finally,\nwe evaluate our approach empirically, demonstrating that it gives well-defined\nconsistency guarantees while avoiding expensive synchronization and packet\nbuffering.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jul 2015 01:12:57 GMT"}, {"version": "v2", "created": "Wed, 25 Nov 2015 02:21:46 GMT"}, {"version": "v3", "created": "Sat, 16 Apr 2016 03:57:02 GMT"}], "update_date": "2016-04-19", "authors_parsed": [["McClurg", "Jedidiah", ""], ["Hojjat", "Hossein", ""], ["Foster", "Nate", ""], ["Cerny", "Pavol", ""]]}, {"id": "1507.07264", "submitter": "Shayan Najd", "authors": "Shayan Najd, Sam Lindley, Josef Svenningsson, Philip Wadler", "title": "Everything old is new again: Quoted Domain Specific Languages", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a new approach to domain specific languages (DSLs), called Quoted\nDSLs (QDSLs), that resurrects two old ideas: quotation, from McCarthy's Lisp of\n1960, and the subformula property, from Gentzen's natural deduction of 1935.\nQuoted terms allow the DSL to share the syntax and type system of the host\nlanguage. Normalising quoted terms ensures the subformula property, which\nguarantees that one can use higher-order types in the source while guaranteeing\nfirst-order types in the target, and enables using types to guide fusion. We\ntest our ideas by re-implementing Feldspar, which was originally implemented as\nan Embedded DSL (EDSL), as a QDSL; and we compare the QDSL and EDSL variants.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jul 2015 23:11:16 GMT"}, {"version": "v2", "created": "Tue, 4 Aug 2015 09:27:36 GMT"}], "update_date": "2015-08-05", "authors_parsed": [["Najd", "Shayan", ""], ["Lindley", "Sam", ""], ["Svenningsson", "Josef", ""], ["Wadler", "Philip", ""]]}, {"id": "1507.07597", "submitter": "EPTCS", "authors": "Iliano Cervesato, Kaustuv Chaudhuri", "title": "Proceedings Tenth International Workshop on Logical Frameworks and Meta\n  Languages: Theory and Practice", "comments": null, "journal-ref": "EPTCS 185, 2015", "doi": "10.4204/EPTCS.185", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume constitutes the proceedings of LFMTP 2015, the Tenth\nInternational Workshop on Logical Frameworks and Meta-Languages: Theory and\nPractice, held on August 1st, 2015 in Berlin, Germany. The workshop was a\none-day satellite event of CADE-25, the 25th International Conference on\nAutomated Deduction. Logical frameworks and meta-languages form a common\nsubstrate for representing, implementing, and reasoning about a wide variety of\ndeductive systems of interest in logic and computer science. Their design and\nimplementation and their use in reasoning tasks ranging from the correctness of\nsoftware to the properties of formal computational systems have been the focus\nof considerable research over the last two decades. This workshop brought\ntogether designers, implementors, and practitioners to discuss various aspects\nimpinging on the structure and utility of logical frameworks, including the\ntreatment of variable binding, inductive and co-inductive reasoning techniques\nand the expressiveness and lucidity of the reasoning process.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2015 22:45:43 GMT"}], "update_date": "2015-07-29", "authors_parsed": [["Cervesato", "Iliano", ""], ["Chaudhuri", "Kaustuv", ""]]}, {"id": "1507.07719", "submitter": "Silvia Crafa", "authors": "Silvia Crafa", "title": "The role of concurrency in an evolutionary view of programming\n  abstractions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we examine how concurrency has been embodied in mainstream\nprogramming languages. In particular, we rely on the evolutionary talking\nborrowed from biology to discuss major historical landmarks and crucial\nconcepts that shaped the development of programming languages. We examine the\ngeneral development process, occasionally deepening into some language, trying\nto uncover evolutionary lineages related to specific programming traits. We\nmainly focus on concurrency, discussing the different abstraction levels\ninvolved in present-day concurrent programming and emphasizing the fact that\nthey correspond to different levels of explanation. We then comment on the role\nof theoretical research on the quest for suitable programming abstractions,\nrecalling the importance of changing the working framework and the way of\nlooking every so often. This paper is not meant to be a survey of modern\nmainstream programming languages: it would be very incomplete in that sense. It\naims instead at pointing out a number of remarks and connect them under an\nevolutionary perspective, in order to grasp a unifying, but not simplistic,\nview of the programming languages development process.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2015 10:44:58 GMT"}], "update_date": "2015-07-29", "authors_parsed": [["Crafa", "Silvia", ""]]}, {"id": "1507.08052", "submitter": "EPTCS", "authors": "Amy Felty (University of Ottawa), Alberto Momigliano (Universita degli\n  Studi di Milano), Brigitte Pientka (McGill University)", "title": "An Open Challenge Problem Repository for Systems Supporting Binders", "comments": "In Proceedings LFMTP 2015, arXiv:1507.07597", "journal-ref": "EPTCS 185, 2015, pp. 18-32", "doi": "10.4204/EPTCS.185.2", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A variety of logical frameworks support the use of higher-order abstract\nsyntax in representing formal systems; however, each system has its own set of\nbenchmarks. Even worse, general proof assistants that provide special libraries\nfor dealing with binders offer a very limited evaluation of such libraries, and\nthe examples given often do not exercise and stress-test key aspects that arise\nin the presence of binders. In this paper we design an open repository ORBI\n(Open challenge problem Repository for systems supporting reasoning with\nBInders). We believe the field of reasoning about languages with binders has\nmatured, and a common set of benchmarks provides an important basis for\nevaluation and qualitative comparison of different systems and libraries that\nsupport binders, and it will help to advance the field.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2015 08:20:55 GMT"}], "update_date": "2015-07-30", "authors_parsed": [["Felty", "Amy", "", "University of Ottawa"], ["Momigliano", "Alberto", "", "Universita degli\n  Studi di Milano"], ["Pientka", "Brigitte", "", "McGill University"]]}, {"id": "1507.08053", "submitter": "EPTCS", "authors": "Andrew Cave (McGill University), Brigitte Pientka (McGill University)", "title": "A Case Study on Logical Relations using Contextual Types", "comments": "In Proceedings LFMTP 2015, arXiv:1507.07597", "journal-ref": "EPTCS 185, 2015, pp. 33-45", "doi": "10.4204/EPTCS.185.3", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Proofs by logical relations play a key role to establish rich properties such\nas normalization or contextual equivalence. They are also challenging to\nmechanize. In this paper, we describe the completeness proof of algorithmic\nequality for simply typed lambda-terms by Crary where we reason about logically\nequivalent terms in the proof environment Beluga. There are three key aspects\nwe rely upon: 1) we encode lambda-terms together with their operational\nsemantics and algorithmic equality using higher-order abstract syntax 2) we\ndirectly encode the corresponding logical equivalence of well-typed\nlambda-terms using recursive types and higher-order functions 3) we exploit\nBeluga's support for contexts and the equational theory of simultaneous\nsubstitutions. This leads to a direct and compact mechanization, demonstrating\nBeluga's strength at formalizing logical relations proofs.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2015 08:21:05 GMT"}], "update_date": "2015-07-30", "authors_parsed": [["Cave", "Andrew", "", "McGill University"], ["Pientka", "Brigitte", "", "McGill University"]]}, {"id": "1507.08087", "submitter": "Marko Van Dooren", "authors": "Benoit Desouter, Tom Schrijvers, Marko van Dooren", "title": "Tabling as a Library with Delimited Control", "comments": "15 pages. To appear in Theory and Practice of Logic Programming\n  (TPLP), Proceedings of ICLP 2015", "journal-ref": "Theory and Practice of Logic Programming 15 (2015) 419-433", "doi": "10.1017/S1471068415000137", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tabling is probably the most widely studied extension of Prolog. But despite\nits importance and practicality, tabling is not implemented by most Prolog\nsystems. Existing approaches require substantial changes to the Prolog engine,\nwhich is an investment out of reach of most systems. To enable more widespread\nadoption, we present a new implementation of tabling in under 600 lines of\nProlog code. Our lightweight approach relies on delimited control and provides\nreasonable performance.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2015 10:01:22 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Desouter", "Benoit", ""], ["Schrijvers", "Tom", ""], ["van Dooren", "Marko", ""]]}, {"id": "1507.08093", "submitter": "Shrawan Kumar", "authors": "Shrawan Kumar", "title": "Property irrelevant predicates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although slicing removes code which has no bearing on property checking.\nHowever even after that, our study has found that there are predicates in\nprogram which have no bearing on property validation, although slicing could\nnot eliminate them. We have cope up with a criteria to identify such predicates\nand then give a process to leverage them in scale up of property checking.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2015 10:24:33 GMT"}], "update_date": "2015-08-03", "authors_parsed": [["Kumar", "Shrawan", ""]]}, {"id": "1507.08398", "submitter": "Frederic Le Mouel", "authors": "Baptiste Maingret (CITI), Fr\\'ed\\'eric Le Mou\\\"el (CITI), Julien Ponge\n  (CITI), Nicolas Stouls (CITI), Jian Cao (CSE), Yannick Loiseau (LIMOS)", "title": "Towards a Decoupled Context-Oriented Programming Language for the\n  Internet of Things", "comments": null, "journal-ref": "ACM. 7th International Workshop on Context-Oriented Programming\n  (COP'2015) in conjunction with the European Conference on Object-Oriented\n  Programming (ECOOP'2015), Jul 2015, Prague, Czech Republic. pp.6, 2015", "doi": "10.1145/2786545.2786552", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Easily programming behaviors is one major issue of a large and reconfigurable\ndeployment in the Internet of Things. Such kind of devices often requires to\nexternalize part of their behavior such as the sensing, the data aggregation or\nthe code offloading. Most existing context-oriented programming languages\nintegrate in the same class or close layers the whole behavior. We propose to\nabstract and separate the context tracking from the decision process, and to\nuse event-based handlers to interconnect them. We keep a very easy declarative\nand non-layered programming model. We illustrate by defining an extension to\nGolo-a JVM-based dynamic language.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jul 2015 06:54:25 GMT"}], "update_date": "2015-07-31", "authors_parsed": [["Maingret", "Baptiste", "", "CITI"], ["Mou\u00ebl", "Fr\u00e9d\u00e9ric Le", "", "CITI"], ["Ponge", "Julien", "", "CITI"], ["Stouls", "Nicolas", "", "CITI"], ["Cao", "Jian", "", "CSE"], ["Loiseau", "Yannick", "", "LIMOS"]]}, {"id": "1507.08610", "submitter": "Kimio Kuramitsu", "authors": "Kimio Kuramitsu", "title": "Fast, Flexible, and Declarative Construction of Abstract Syntax Trees\n  with PEGs", "comments": "To appear in Journal of Information Processing (2015)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address a declarative construction of abstract syntax trees with Parsing\nExpression Grammars. AST operators (constructor, connector, and tagging) are\nnewly defined to specify flexible AST constructions. A new challenge coming\nwith PEGs is the consistency management of ASTs in backtracking and packrat\nparsing. We make the transaction AST machine in order to perform AST operations\nin the context of the speculative parsing of PEGs. All the consistency control\nis automated by the analysis of AST operators. The proposed approach is\nimplemented in the Nez parser, written in Java. The performance study shows\nthat the transactional AST machine requires 25\\% approximately more time in\nCSV, XML, and C grammars.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jul 2015 18:15:02 GMT"}], "update_date": "2015-07-31", "authors_parsed": [["Kuramitsu", "Kimio", ""]]}]