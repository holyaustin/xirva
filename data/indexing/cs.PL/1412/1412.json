[{"id": "1412.0625", "submitter": "Peter Selinger", "authors": "Jonathan M. Smith, Neil J. Ross, Peter Selinger, and Beno\\^it Valiron", "title": "Quipper: Concrete Resource Estimation in Quantum Algorithms", "comments": "Extended abstract for a talk given at QAPL 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.ET quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the rich literature on quantum algorithms, there is a surprisingly\nsmall amount of coverage of their concrete logical design and implementation.\nMost resource estimation is done at the level of complexity analysis, but\nactual concrete numbers (of quantum gates, qubits, etc.) can differ by orders\nof magnitude. The line of work we present here is a formal framework to write,\nand reason about, quantum algorithms. Specifically, we designed a language,\nQuipper, with scalability in mind, and we are able to report actual resource\ncounts for seven non-trivial algorithms found in the quantum computer science\nliterature.\n", "versions": [{"version": "v1", "created": "Mon, 1 Dec 2014 20:20:04 GMT"}], "update_date": "2014-12-02", "authors_parsed": [["Smith", "Jonathan M.", ""], ["Ross", "Neil J.", ""], ["Selinger", "Peter", ""], ["Valiron", "Beno\u00eet", ""]]}, {"id": "1412.0961", "submitter": "Stephan Merz", "authors": "Jingshu Chen (INRIA Nancy - Grand Est / LORIA), Marie Duflot (INRIA\n  Nancy - Grand Est / LORIA), Stephan Merz (INRIA Nancy - Grand Est / LORIA)", "title": "Analyzing Conflict Freedom For Multi-threaded Programs With Time\n  Annotations", "comments": "http://journal.ub.tu-berlin.de/eceasst/article/view/978", "journal-ref": "Electronic Communications of the EASST, 2014, Automated\n  Verification of Critical Systems 2014, 70, pp.14", "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Avoiding access conflicts is a major challenge in the design of\nmulti-threaded programs. In the context of real-time systems, the absence of\nconflicts can be guaranteed by ensuring that no two potentially conflicting\naccesses are ever scheduled concurrently.In this paper, we analyze programs\nthat carry time annotations specifying the time for executing each statement.\nWe propose a technique for verifying that a multi-threaded program with time\nannotations is free of access conflicts. In particular, we generate constraints\nthat reflect the possible schedules for executing the program and the required\nproperties. We then invoke an SMT solver in order to verify that no execution\ngives rise to concurrent conflicting accesses. Otherwise, we obtain a trace\nthat exhibits the access conflict.\n", "versions": [{"version": "v1", "created": "Sun, 30 Nov 2014 07:22:03 GMT"}], "update_date": "2014-12-03", "authors_parsed": [["Chen", "Jingshu", "", "INRIA Nancy - Grand Est / LORIA"], ["Duflot", "Marie", "", "INRIA\n  Nancy - Grand Est / LORIA"], ["Merz", "Stephan", "", "INRIA Nancy - Grand Est / LORIA"]]}, {"id": "1412.0981", "submitter": "Sergey Vostokin", "authors": "Sergey Vostokin", "title": "Templet: a Markup Language for Concurrent Programming", "comments": "13 pages", "journal-ref": null, "doi": "10.18287/1613-0073-2016-1638-460-468", "report-no": null, "categories": "cs.PL cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a new approach to the description of a network of\ninteracting processes in a traditional programming language. Special\nprogramming languages or extensions to sequential languages are usually\ndesigned to express the semantics of concurrent execution. Using libraries in\nC++, Java, C#, and other languages is more practical way of concurrent\nprogramming. However, this method leads to an increase in workload of a manual\ncoding. Besides, stock compilers can not detect semantic errors related to the\nprogramming model in such libraries. The new markup language and a special\ntechnique of automatic programming based on the marked code can solve these\nproblems. The article provides a detailed specification of the markup language\nwithout discussing its implementation details. The language is used for\nprogramming of current and prospective multi-core and many-core systems.\n", "versions": [{"version": "v1", "created": "Tue, 2 Dec 2014 17:06:28 GMT"}], "update_date": "2017-02-17", "authors_parsed": [["Vostokin", "Sergey", ""]]}, {"id": "1412.1127", "submitter": "Ahmad Lashgar", "authors": "Ahmad Lashgar and Alireza Majidi and Amirali Baniasadi", "title": "IPMACC: Open Source OpenACC to CUDA/OpenCL Translator", "comments": "14 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce IPMACC, a framework for translating OpenACC\napplications to CUDA or OpenCL. IPMACC is composed of set of translators\ntranslating OpenACC for C applications to CUDA or OpenCL. The framework uses\nthe system compiler (e.g. nvcc) for generating final accelerator's binary. The\nframework can be used for extending the OpenACC API, executing OpenACC\napplications, or obtaining CUDA or OpenCL code which is equivalent to OpenACC\ncode. We verify correctness of our framework under several benchmarks included\nfrom Rodinia Benchmark Suit and CUDA SDK. We also compare the performance of\nCUDA version of the benchmarks to OpenACC version which is compiled by our\nframework. By comparing CUDA and OpenACC versions, we discuss the limitations\nof OpenACC in achieving a performance near to highly-optimized CUDA version.\n", "versions": [{"version": "v1", "created": "Tue, 2 Dec 2014 22:49:14 GMT"}], "update_date": "2014-12-04", "authors_parsed": [["Lashgar", "Ahmad", ""], ["Majidi", "Alireza", ""], ["Baniasadi", "Amirali", ""]]}, {"id": "1412.1221", "submitter": "Keehang Kwon", "authors": "Daeseong Kang and Keehang Kwon and Zulkarnine Mahmud", "title": "Sequential Operations in LogicWeb", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequential tasks cannot be effectively handled in logic programming based on\nclassical logic or linear logic. This limitation can be addressed by using a\nfragment of Japaridze'sSequential tasks cannot be effectively handled in logic\nprogramming based on classical logic or linear logic. This limitation can be\naddressed by using a fragment of Japaridze's computability logic. We propose\n\\seqweb, an extension to LogicWeb with sequential goal formulas. SeqWeb extends\nthe LogicWeb by allowing goals of the form $G\\seqand G$ and $G\\seqor G$ where\n$G$ is a goal. These goals allow us to specify both sequential-conjunctive and\nsequential-disjunctive tasks. computability logic. We propose \\seqweb, an\nextension to LogicWeb with sequential goal formulas. SeqWeb extends the\nLogicWeb by allowing goals of the form $G\\seqand G$ and $G\\seqor G$ where $G$\nis a goal. These goals allow us to specify both sequential-conjunctive and\nsequential-disjunctive tasks.\n", "versions": [{"version": "v1", "created": "Wed, 3 Dec 2014 07:54:13 GMT"}], "update_date": "2014-12-04", "authors_parsed": [["Kang", "Daeseong", ""], ["Kwon", "Keehang", ""], ["Mahmud", "Zulkarnine", ""]]}, {"id": "1412.1393", "submitter": "Marco  Antoniotti", "authors": "Marco Antoniotti", "title": "CLAZY: Lazy Calling for Common Lisp", "comments": "A version of this note was presented at the 1st European Lisp\n  Symposium 2008, Bordeaux, France", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This document contains a description of a Common Lisp extension that allows a\nprogrammer to write functional programs that use \"normal order\" evaluation, as\nin \"non-strict\" languages like Haskell. The extension is relatively\nstraightforward, and it appears to be the first one such that is integrated in\nthe overall Common Lisp framework.\n", "versions": [{"version": "v1", "created": "Wed, 3 Dec 2014 16:34:11 GMT"}], "update_date": "2014-12-04", "authors_parsed": [["Antoniotti", "Marco", ""]]}, {"id": "1412.1961", "submitter": "Ludwig N\\\"agele M.Sc.", "authors": "Benjamin Schwartz, Ludwig N\\\"agele, Andreas Angerer, and Bruce A.\n  MacDonald", "title": "Towards a graphical language for quadrotor missions", "comments": "Presented at DSLRob 2014 (arXiv:cs/1411.7148)", "journal-ref": null, "doi": null, "report-no": "DSLRob/2014/02", "categories": "cs.RO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an approach for defining Unmanned Aerial Vehicle (UAV)\nmissions on a high level. Current methods for UAV mission specification are\nevaluated and their deficiencies are analyzed. From these findings, a new\ngraphical specification language for UAV missions is proposed, which is\ntargeted towards typical UAV users from various domains rather than computer\nscience experts. The research is ongoing, but a first prototype is presented.\n", "versions": [{"version": "v1", "created": "Fri, 5 Dec 2014 11:39:04 GMT"}], "update_date": "2014-12-08", "authors_parsed": [["Schwartz", "Benjamin", ""], ["N\u00e4gele", "Ludwig", ""], ["Angerer", "Andreas", ""], ["MacDonald", "Bruce A.", ""]]}, {"id": "1412.2221", "submitter": "Dan Olteanu", "authors": "Vince Barany and Balder ten Cate and Benny Kimelfeld and Dan Olteanu\n  and Zografoula Vagena", "title": "Declarative Statistical Modeling with Datalog", "comments": "14 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Formalisms for specifying statistical models, such as\nprobabilistic-programming languages, typically consist of two components: a\nspecification of a stochastic process (the prior), and a specification of\nobservations that restrict the probability space to a conditional subspace (the\nposterior). Use cases of such formalisms include the development of algorithms\nin machine learning and artificial intelligence. We propose and investigate a\ndeclarative framework for specifying statistical models on top of a database,\nthrough an appropriate extension of Datalog. By virtue of extending Datalog,\nour framework offers a natural integration with the database, and has a robust\ndeclarative semantics. Our Datalog extension provides convenient mechanisms to\ninclude numerical probability functions; in particular, conclusions of rules\nmay contain values drawn from such functions. The semantics of a program is a\nprobability distribution over the possible outcomes of the input database with\nrespect to the program; these outcomes are minimal solutions with respect to a\nrelated program with existentially quantified variables in conclusions.\nObservations are naturally incorporated by means of integrity constraints over\nthe extensional and intensional relations. We focus on programs that use\ndiscrete numerical distributions, but even then the space of possible outcomes\nmay be uncountable (as a solution can be infinite). We define a probability\nmeasure over possible outcomes by applying the known concept of cylinder sets\nto a probabilistic chase procedure. We show that the resulting semantics is\nrobust under different chases. We also identify conditions guaranteeing that\nall possible outcomes are finite (and then the probability space is discrete).\nWe argue that the framework we propose retains the purely declarative nature of\nDatalog, and allows for natural specifications of statistical models.\n", "versions": [{"version": "v1", "created": "Sat, 6 Dec 2014 11:04:14 GMT"}, {"version": "v2", "created": "Mon, 5 Jan 2015 19:49:24 GMT"}], "update_date": "2015-01-06", "authors_parsed": [["Barany", "Vince", ""], ["Cate", "Balder ten", ""], ["Kimelfeld", "Benny", ""], ["Olteanu", "Dan", ""], ["Vagena", "Zografoula", ""]]}, {"id": "1412.2304", "submitter": "Sergii Dymchenko", "authors": "Sergii Dymchenko and Mariia Mykhailova", "title": "Declaratively solving tricky Google Code Jam problems with Prolog-based\n  ECLiPSe CLP system", "comments": "6 pages. This is a full version of a paper accepted at SAC 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we demonstrate several examples of solving challenging\nalgorithmic problems from the Google Code Jam programming contest with the\nProlog-based ECLiPSe system using declarative techniques like constraint logic\nprogramming and linear (integer) programming. These problems were designed to\nbe solved by inventing clever algorithms and efficiently implementing them in a\nconventional imperative programming language, but we present relatively simple\ndeclarative programs in ECLiPSe that are fast enough to find answers within the\ntime limit imposed by the contest rules. We claim that declarative programming\nwith ECLiPSe is better suited for solving certain common kinds of programming\nproblems offered in Google Code Jam than imperative programming. We show this\nby comparing the mental steps required to come up with both kinds of solutions.\n", "versions": [{"version": "v1", "created": "Sun, 7 Dec 2014 02:24:21 GMT"}, {"version": "v2", "created": "Sun, 14 Dec 2014 23:22:07 GMT"}], "update_date": "2014-12-16", "authors_parsed": [["Dymchenko", "Sergii", ""], ["Mykhailova", "Mariia", ""]]}, {"id": "1412.3136", "submitter": "Isaac Sheff", "authors": "Isaac C. Sheff, Robbert van Renesse, Andrew C. Myers", "title": "Distributed Protocols and Heterogeneous Trust: Technical Report", "comments": "This is the technical report of a submission for EuroSys 2015. 26\n  Pages 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR cs.DB cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The robustness of distributed systems is usually phrased in terms of the\nnumber of failures of certain types that they can withstand. However, these\nfailure models are too crude to describe the different kinds of trust and\nexpectations of participants in the modern world of complex, integrated systems\nextending across different owners, networks, and administrative domains. Modern\nsystems often exist in an environment of heterogeneous trust, in which\ndifferent participants may have different opinions about the trustworthiness of\nother nodes, and a single participant may consider other nodes to differ in\ntheir trustworthiness. We explore how to construct distributed protocols that\nmeet the requirements of all participants, even in heterogeneous trust\nenvironments. The key to our approach is using lattice-based information flow\nto analyse and prove protocol properties. To demonstrate this approach, we show\nhow two earlier distributed algorithms can be generalized to work in the\npresence of heterogeneous trust: first, Heterogeneous Fast Consensus, an\nadaptation of the earlier Bosco Fast Consensus protocol; and second, Nysiad, an\nalgorithm for converting crash-tolerant protocols to be Byzantine-tolerant.\nThrough simulations, we show that customizing a protocol to a heterogeneous\ntrust configuration yields performance improvements over the conventional\nprotocol designed for homogeneous trust.\n", "versions": [{"version": "v1", "created": "Tue, 9 Dec 2014 22:09:48 GMT"}], "update_date": "2014-12-11", "authors_parsed": [["Sheff", "Isaac C.", ""], ["van Renesse", "Robbert", ""], ["Myers", "Andrew C.", ""]]}, {"id": "1412.3480", "submitter": "M. H. van Emden", "authors": "M.H. van Emden", "title": "Logic programming beyond Prolog", "comments": "19 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": "DCS-355-IR", "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A logic program is an executable specification. For example, merge sort in\npure Prolog is a logical formula, yet shows creditable performance on long\nlinked lists. But such executable specifications are a compromise: the logic is\ndistorted by algorithmic considerations, yet only indirectly executable via an\nabstract machine. This paper introduces relational programming, a method that\nsolves the difficulty with logic programming by a separation of concerns. It\nrequires three texts: (1) the axioms, a logical formula that specifies the\nproblem and is not compromised by algorithmic considerations, (2) the theorem,\na logical formula that expresses the idea of the algorithm and follows from the\naxioms, and (3) the code, a transcription of the theorem to a procedural\nlanguage. Correctness of the code relies on the logical relationship of the\ntheorem with the axioms and relies on an accurate transcription of the theorem\nto the procedural language. Sorting is an example where relational programming\nhas the advantage of a higher degree of abstractness: the data to be sorted can\nbe any data type in C++ (the procedural language we use in our examples) that\nsatisfies the axioms of linear order, while the pure-Prolog version is limited\nto data structures in the form of linked cells. We show another advantage of\nrelational programs: they have a model-theoretic and fixpoint semantics\nequivalent to each other and analogous to those of pure Prolog programs.\n", "versions": [{"version": "v1", "created": "Wed, 10 Dec 2014 21:45:04 GMT"}, {"version": "v2", "created": "Tue, 23 Dec 2014 04:27:31 GMT"}, {"version": "v3", "created": "Sat, 26 Sep 2015 01:43:26 GMT"}], "update_date": "2015-09-29", "authors_parsed": [["van Emden", "M. H.", ""]]}, {"id": "1412.3588", "submitter": "Muhammad Taimoor Khan", "authors": "Muhammad Taimoor Khan, Dimitrios Serpanos, Howard Shrobe", "title": "On the Formal Semantics of the Cognitive Middleware AWDRAT", "comments": "Technical report (submitted) to CSAIL, MIT, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of this work is two fold: on one hand we want to formalize the\nbehavior of critical components of the self generating and adapting cognitive\nmiddleware AWDRAT such that the formalism not only helps to understand the\nsemantics and technical details of the middleware but also opens an opportunity\nto extend the middleware to support other complex application domains of\ncybersecurity; on the other hand, the formalism serves as a pre-requisite for\nour proof of the behavioral correctness of the critical components to ensure\nthe safety of the middleware itself. However, here we focus only on the core\nand critical component of the middleware, i.e. Execution Monitor which is a\npart of the module \"Architectural Differencer\" of AWDRAT. The role of the\nexecution monitor is to identify inconsistencies between runtime observations\nof the target system and predictions of the System Architectural Model.\nTherefore, to achieve this goal, we first define the formal (denotational)\nsemantics of the observations (runtime events) and predictions (executable\nspecifications as of System Architectural Model); then based on the\naforementioned formal semantices, we formalize the behavior of the \"Execution\nMonitor\" of the middleware.\n", "versions": [{"version": "v1", "created": "Thu, 11 Dec 2014 09:57:28 GMT"}, {"version": "v2", "created": "Sun, 14 Dec 2014 14:37:46 GMT"}], "update_date": "2014-12-16", "authors_parsed": [["Khan", "Muhammad Taimoor", ""], ["Serpanos", "Dimitrios", ""], ["Shrobe", "Howard", ""]]}, {"id": "1412.3729", "submitter": "Etienne Payet", "authors": "Etienne Payet and Fred Mesnard", "title": "Non-termination of Dalvik bytecode via compilation to CLP", "comments": "5 pages, presented at the 13th International Workshop on Termination\n  (WST) 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  We present a set of rules for compiling a Dalvik bytecode program into a\nlogic program with array constraints. Non-termination of the resulting program\nentails that of the original one, hence the techniques we have presented before\nfor proving non-termination of constraint logic programs can be used for\nproving non-termination of Dalvik programs.\n", "versions": [{"version": "v1", "created": "Wed, 10 Dec 2014 12:20:13 GMT"}], "update_date": "2014-12-12", "authors_parsed": [["Payet", "Etienne", ""], ["Mesnard", "Fred", ""]]}, {"id": "1412.4053", "submitter": "Neil Toronto", "authors": "Neil Toronto and Jay McCarthy and David Van Horn", "title": "Running Probabilistic Programs Backwards", "comments": "26 pages, ESOP 2015 (to appear)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many probabilistic programming languages allow programs to be run under\nconstraints in order to carry out Bayesian inference. Running programs under\nconstraints could enable other uses such as rare event simulation and\nprobabilistic verification---except that all such probabilistic languages are\nnecessarily limited because they are defined or implemented in terms of an\nimpoverished theory of probability. Measure-theoretic probability provides a\nmore general foundation, but its generality makes finding computational content\ndifficult.\n  We develop a measure-theoretic semantics for a first-order probabilistic\nlanguage with recursion, which interprets programs as functions that compute\npreimages. Preimage functions are generally uncomputable, so we derive an\nabstract semantics. We implement the abstract semantics and use the\nimplementation to carry out Bayesian inference, stochastic ray tracing (a rare\nevent simulation), and probabilistic verification of floating-point error\nbounds.\n", "versions": [{"version": "v1", "created": "Fri, 12 Dec 2014 16:59:14 GMT"}, {"version": "v2", "created": "Fri, 16 Jan 2015 15:30:58 GMT"}], "update_date": "2015-01-19", "authors_parsed": [["Toronto", "Neil", ""], ["McCarthy", "Jay", ""], ["Van Horn", "David", ""]]}, {"id": "1412.4184", "submitter": "Burak Ekici", "authors": "Kostadin Kratchanov and Emilia Golemanova and Tzanko Golemanov and\n  Tuncay Ercan and Burak Ekici", "title": "Procedural and Non-Procedural Implementation of Search Strategies in\n  Control Network Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This report presents the general picture of how Control Network Programming\ncan be effectively used for implementing various search strategies, both blind\nand informed. An interesting possibility is non - procedural solutions that can\nbe developed for most local search algorithms. A generic solution is described\nfor procedural implementations.\n", "versions": [{"version": "v1", "created": "Sat, 13 Dec 2014 02:39:20 GMT"}], "update_date": "2014-12-16", "authors_parsed": [["Kratchanov", "Kostadin", ""], ["Golemanova", "Emilia", ""], ["Golemanov", "Tzanko", ""], ["Ercan", "Tuncay", ""], ["Ekici", "Burak", ""]]}, {"id": "1412.4395", "submitter": "Rachel Gauci", "authors": "Rachel Gauci", "title": "Dafny: Statically Verifying Functional Correctness", "comments": "12 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This report presents the Dafny language and verifier, with a focus on\ndescribing the main features of the language, including pre- and\npostconditions, assertions, loop invariants, termination metrics, quantifiers,\npredicates and frames. Examples of Dafny code are provided to illustrate the\nuse of each feature, and an overview of how Dafny translates programming code\ninto a mathematical proof of functional verification is presented. The report\nalso includes references to useful resources on Dafny, with mentions of related\nworks in the domain of specification languages.\n", "versions": [{"version": "v1", "created": "Sun, 14 Dec 2014 19:04:47 GMT"}], "update_date": "2014-12-16", "authors_parsed": [["Gauci", "Rachel", ""]]}, {"id": "1412.4480", "submitter": "Long Zheng", "authors": "Long Zheng, Xiaofei Liao, Bingsheng He, Song Wu, Hai Jin", "title": "On Performance Debugging of Unnecessary Lock Contentions on Multicore\n  Processors: A Replay-based Approach", "comments": "18 pages, 19 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Locks have been widely used as an effective synchronization mechanism among\nprocesses and threads. However, we observe that a large number of false\ninter-thread dependencies (i.e., unnecessary lock contentions) exist during the\nprogram execution on multicore processors, thereby incurring significant\nperformance overhead. This paper presents a performance debugging framework,\nPERFPLAY, to facilitate a comprehensive and in-depth understanding of the\nperformance impact of unnecessary lock contentions. The core technique of our\ndebugging framework is trace replay. Specifically, PERFPLAY records the program\nexecution trace, on the basis of which the unnecessary lock contentions can be\nidentified through trace analysis. We then propose a novel technique of trace\ntransformation to transform these identified unnecessary lock contentions in\nthe original trace into the correct pattern as a new trace free of unnecessary\nlock contentions. Through replaying both traces, PERFPLAY can quantify the\nperformance impact of unnecessary lock contentions. To demonstrate the\neffectiveness of our debugging framework, we study five real-world programs and\nPARSEC benchmarks. Our experimental results demonstrate the significant\nperformance overhead of unnecessary lock contentions, and the effectiveness of\nPERFPLAY in identifying the performance critical unnecessary lock contentions\nin real applications.\n", "versions": [{"version": "v1", "created": "Mon, 15 Dec 2014 07:22:40 GMT"}, {"version": "v2", "created": "Tue, 21 Apr 2015 09:28:21 GMT"}], "update_date": "2015-04-22", "authors_parsed": [["Zheng", "Long", ""], ["Liao", "Xiaofei", ""], ["He", "Bingsheng", ""], ["Wu", "Song", ""], ["Jin", "Hai", ""]]}, {"id": "1412.4550", "submitter": "Laura Titolo", "authors": "Damian Adalid and Maria del Mar Gallardo and Laura Titolo", "title": "Modeling Hybrid Systems in Hy-tccp", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Concurrent,reactive and hybrid systems require quality modeling languages to\nbe described and analyzed. The Timed Concurrent Constraint Language (tccp) was\nintroduced as a simple but powerful model for reactive systems. In this paper,\nwe present hybrid tccp (hy-tccp), an extension of tccp over continuous time\nwhich includes new con- structs to model the continuous dynamics of hybrid\nsystems.\n", "versions": [{"version": "v1", "created": "Mon, 15 Dec 2014 11:32:54 GMT"}], "update_date": "2014-12-16", "authors_parsed": [["Adalid", "Damian", ""], ["Gallardo", "Maria del Mar", ""], ["Titolo", "Laura", ""]]}, {"id": "1412.4629", "submitter": "Pablo Estef\\'o", "authors": "Pablo Estef\\'o, Miguel Campusano, Luc Fabresse, Johan Fabry, Jannik\n  Laval, and Noury Bouraqad", "title": "Towards Live Programming in ROS with PhaROS and LRP", "comments": "Presented at DSLRob 2014 (arXiv:cs/1411.7148)", "journal-ref": null, "doi": null, "report-no": "DSLRob/2014/06", "categories": "cs.PL cs.RO", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  In traditional robot behavior programming, the\nedit-compile-simulate-deploy-run cycle creates a large mental disconnect\nbetween program creation and eventual robot behavior. This significantly slows\ndown behavior development because there is no immediate mental connection\nbetween the program and the resulting behavior. With live programming the\ndevelopment cycle is made extremely tight, realizing such an immediate\nconnection. In our work on programming of ROS robots in a more dynamic fashion\nthrough PhaROS, we have experimented with the use of the Live Robot Programming\nlanguage. This has given rise to a number of requirements for such live\nprogramming of robots. In this text we introduce these requirements and\nillustrate them using an example robot behavior.\n", "versions": [{"version": "v1", "created": "Mon, 15 Dec 2014 15:11:23 GMT"}], "update_date": "2014-12-16", "authors_parsed": [["Estef\u00f3", "Pablo", ""], ["Campusano", "Miguel", ""], ["Fabresse", "Luc", ""], ["Fabry", "Johan", ""], ["Laval", "Jannik", ""], ["Bouraqad", "Noury", ""]]}, {"id": "1412.4738", "submitter": "EPTCS", "authors": "James Caldwell (University of Wyoming), Philip H\\\"olzenspies\n  (University of Twente), Peter Achten (Radboud University Nijmegen)", "title": "Proceedings 3rd International Workshop on Trends in Functional\n  Programming in Education", "comments": null, "journal-ref": "EPTCS 170, 2014", "doi": "10.4204/EPTCS.170", "report-no": null, "categories": "cs.CY cs.DS cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of TFPIE is to gather researchers, professors, teachers, and all\nprofessionals interested in functional programming in education. This includes\nthe teaching of functional programming, but also the application of functional\nprogramming as a tool for teaching other topics. The post-workshop review\nprocess received 13 submissions, which were vetted by the program committee,\nassuming scientific journal standards of publication. The six articles in this\nvolume were selected for publication as the result of this process.\n", "versions": [{"version": "v1", "created": "Fri, 12 Dec 2014 00:47:22 GMT"}], "update_date": "2014-12-16", "authors_parsed": [["Caldwell", "James", "", "University of Wyoming"], ["H\u00f6lzenspies", "Philip", "", "University of Twente"], ["Achten", "Peter", "", "Radboud University Nijmegen"]]}, {"id": "1412.4877", "submitter": "EPTCS", "authors": "Yuki Ishii (Ochanomizu University, Tokyo, Japan), Kenichi Asai\n  (Ochanomizu University, Tokyo, Japan)", "title": "Report on a User Test and Extension of a Type Debugger for Novice\n  Programmers", "comments": "In Proceedings TFPIE 2014, arXiv:1412.4738", "journal-ref": "EPTCS 170, 2014, pp. 1-18", "doi": "10.4204/EPTCS.170.1", "report-no": null, "categories": "cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A type debugger interactively detects the expressions that cause type errors.\nIt asks users whether they intend the types of identifiers to be those that the\ncompiler inferred. However, it seems that novice programmers often get in\ntrouble when they think about how to fix type errors by reading the messages\ngiven by the type debugger. In this paper, we analyze the user tests of a type\ndebugger and report problems of the current type debugger. We then extend the\ntype debugger to address these problems. Specifically, we introduce\nexpression-specific error messages and language levels. Finally, we show type\nerrors that we think are difficult to explain to novice programmers. The\nsubjects of the user tests were 40 novice students belonging to the department\nof information science at Ochanomizu University.\n", "versions": [{"version": "v1", "created": "Tue, 16 Dec 2014 05:13:29 GMT"}], "update_date": "2014-12-17", "authors_parsed": [["Ishii", "Yuki", "", "Ochanomizu University, Tokyo, Japan"], ["Asai", "Kenichi", "", "Ochanomizu University, Tokyo, Japan"]]}, {"id": "1412.4879", "submitter": "EPTCS", "authors": "Tim Olmer (Open University of the Netherlands), Bastiaan Heeren (Open\n  University of the Netherlands), Johan Jeuring (Universiteit Utrecht and Open\n  University of the Netherlands)", "title": "Evaluating Haskell expressions in a tutoring environment", "comments": "In Proceedings TFPIE 2014, arXiv:1412.4738", "journal-ref": "EPTCS 170, 2014, pp. 50-66", "doi": "10.4204/EPTCS.170.4", "report-no": null, "categories": "cs.CY cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A number of introductory textbooks for Haskell use calculations right from\nthe start to give the reader insight into the evaluation of expressions and the\nbehavior of functional programs. Many programming concepts that are important\nin the functional programming paradigm, such as recursion, higher-order\nfunctions, pattern-matching, and lazy evaluation, can be partially explained by\nshowing a stepwise computation. A student gets a better understanding of these\nconcepts if she performs these evaluation steps herself. Tool support for\nexperimenting with the evaluation of Haskell expressions is currently lacking.\nIn this paper we present a prototype implementation of a stepwise evaluator for\nHaskell expressions that supports multiple evaluation strategies, specifically\ntargeted at education. Besides performing evaluation steps the tool also\ndiagnoses steps that are submitted by a student, and provides feedback.\nInstructors can add or change function definitions without knowledge of the\ntool's internal implementation. We discuss some preliminary results of a small\nsurvey about the tool.\n", "versions": [{"version": "v1", "created": "Tue, 16 Dec 2014 05:14:19 GMT"}], "update_date": "2014-12-17", "authors_parsed": [["Olmer", "Tim", "", "Open University of the Netherlands"], ["Heeren", "Bastiaan", "", "Open\n  University of the Netherlands"], ["Jeuring", "Johan", "", "Universiteit Utrecht and Open\n  University of the Netherlands"]]}, {"id": "1412.4880", "submitter": "EPTCS", "authors": "Scott N. Walck (Lebanon Valley College, Annville, Pennsylvania, USA)", "title": "Learn Physics by Programming in Haskell", "comments": "In Proceedings TFPIE 2014, arXiv:1412.4738", "journal-ref": "EPTCS 170, 2014, pp. 67-77", "doi": "10.4204/EPTCS.170.5", "report-no": null, "categories": "cs.CY cs.PL physics.ed-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a method for deepening a student's understanding of basic physics\nby asking the student to express physical ideas in a functional programming\nlanguage. The method is implemented in a second-year course in computational\nphysics at Lebanon Valley College. We argue that the structure of Newtonian\nmechanics is clarified by its expression in a language (Haskell) that supports\nhigher-order functions, types, and type classes. In electromagnetic theory, the\ntype signatures of functions that calculate electric and magnetic fields\nclearly express the functional dependency on the charge and current\ndistributions that produce the fields. Many of the ideas in basic physics are\nwell-captured by a type or a function.\n", "versions": [{"version": "v1", "created": "Tue, 16 Dec 2014 05:14:30 GMT"}], "update_date": "2014-12-17", "authors_parsed": [["Walck", "Scott N.", "", "Lebanon Valley College, Annville, Pennsylvania, USA"]]}, {"id": "1412.4881", "submitter": "EPTCS", "authors": "Victor Winter (University of Nebraska at Omaha, USA)", "title": "Bricklayer: An Authentic Introduction to the Functional Programming\n  Language SML", "comments": "In Proceedings TFPIE 2014, arXiv:1412.4738", "journal-ref": "EPTCS 170, 2014, pp. 33-49", "doi": "10.4204/EPTCS.170.3", "report-no": null, "categories": "cs.CY cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Functional programming languages are seen by many as instrumental to\neffectively utilizing the computational power of multi-core platforms. As a\nresult, there is growing interest to introduce functional programming and\nfunctional thinking as early as possible within the computer science\ncurriculum. Bricklayer is an API, written in SML, that provides a set of\nabstractions for creating LEGO artifacts which can be viewed using LEGO Digital\nDesigner. The goal of Bricklayer is to create a problem space (i.e., a set of\nLEGO artifacts) that is accessible and engaging to programmers (especially\nnovice programmers) while providing an authentic introduction to the functional\nprogramming language SML.\n", "versions": [{"version": "v1", "created": "Tue, 16 Dec 2014 05:14:31 GMT"}], "update_date": "2014-12-17", "authors_parsed": [["Winter", "Victor", "", "University of Nebraska at Omaha, USA"]]}, {"id": "1412.4882", "submitter": "EPTCS", "authors": "Prabhakar Ragde (University of Waterloo, Waterloo, Ontario, Canada)", "title": "Simple Balanced Binary Search Trees", "comments": "In Proceedings TFPIE 2014, arXiv:1412.4738", "journal-ref": "EPTCS 170, 2014, pp. 78-87", "doi": "10.4204/EPTCS.170.6", "report-no": null, "categories": "cs.PL cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient implementations of sets and maps (dictionaries) are important in\ncomputer science, and balanced binary search trees are the basis of the best\npractical implementations. Pedagogically, however, they are often quite\ncomplicated, especially with respect to deletion. I present complete code (with\njustification and analysis not previously available in the literature) for a\npurely-functional implementation based on AA trees, which is the simplest\ntreatment of the subject of which I am aware.\n", "versions": [{"version": "v1", "created": "Tue, 16 Dec 2014 05:14:44 GMT"}], "update_date": "2014-12-17", "authors_parsed": [["Ragde", "Prabhakar", "", "University of Waterloo, Waterloo, Ontario, Canada"]]}, {"id": "1412.5143", "submitter": "Matthew Hague", "authors": "Matthew Hague, Anthony Widjaja Lin, Luke Ong", "title": "Detecting Redundant CSS Rules in HTML5 Applications: A Tree-Rewriting\n  Approach", "comments": "50 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DB cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  HTML5 applications normally have a large set of CSS (Cascading Style Sheets)\nrules for data display. Each CSS rule consists of a node selector (given in an\nXPath-like query language) and a declaration block (assigning values to\nselected nodes' display attributes). As web applications evolve, maintaining\nCSS files can easily become problematic. Some CSS rules will be replaced by new\nones, but these obsolete (hence redundant) CSS rules often remain in the\napplications. Not only does this \"bloat\" the applications, but it also\nsignificantly increases web browsers' processing time. Most works on detecting\nredundant CSS rules in HTML5 applications do not consider the dynamic behaviors\nof HTML5 (specified in JavaScript); in fact, the only proposed method that\ntakes these into account is dynamic analysis (a.k.a. testing), which cannot\nsoundly prove redundancy of CSS rules. In this paper, we introduce an\nabstraction of HTML5 applications based on monotonic tree-rewriting and study\nits \"redundancy problem\". We establish the precise complexity of the problem\nand various subproblems of practical importance (ranging from P to EXP). In\nparticular, our algorithm relies on an efficient reduction to an analysis of\nsymbolic pushdown systems (for which highly optimised solvers are available),\nwhich yields a fast method for checking redundancy in practice. We implemented\nour algorithm and demonstrated its efficacy in detecting redundant CSS rules in\nHTML5 applications.\n", "versions": [{"version": "v1", "created": "Mon, 15 Dec 2014 14:22:03 GMT"}, {"version": "v2", "created": "Tue, 21 Jul 2015 02:30:30 GMT"}, {"version": "v3", "created": "Tue, 4 Aug 2015 12:24:10 GMT"}, {"version": "v4", "created": "Tue, 18 Aug 2015 13:25:58 GMT"}], "update_date": "2015-08-19", "authors_parsed": [["Hague", "Matthew", ""], ["Lin", "Anthony Widjaja", ""], ["Ong", "Luke", ""]]}, {"id": "1412.5150", "submitter": "Christos Antonopouos", "authors": "Vassilis Vassiliadis, Konstantinos Parasyris, Charalambos Chalios,\n  Christos D. Antonopoulos, Spyros Lalis, Nikolaos Bellas, Hans Vandierendonck,\n  Dimitrios S. Nikolopoulos", "title": "A Programming Model and Runtime System for Significance-Aware\n  Energy-Efficient Computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reducing energy consumption is one of the key challenges in computing\ntechnology. One factor that contributes to high energy consumption is that all\nparts of the program are considered equally significant for the accuracy of the\nend-result. However, in many cases, parts of computations can be performed in\nan approximate way, or even dropped, without affecting the quality of the final\noutput to a significant degree.\n  In this paper, we introduce a task-based programming model and runtime system\nthat exploit this observation to trade off the quality of program outputs for\nincreased energy-efficiency. This is done in a structured and flexible way,\nallowing for easy exploitation of different execution points in the\nquality/energy space, without code modifications and without adversely\naffecting application performance. The programmer specifies the significance of\ntasks, and optionally provides approximations for them. Moreover, she provides\nhints to the runtime on the percentage of tasks that should be executed\naccurately in order to reach the target quality of results. The runtime system\ncan apply a number of different policies to decide whether it will execute each\nindividual less-significant task in its accurate form, or in its approximate\nversion. Policies differ in terms of their runtime overhead but also the degree\nto which they manage to execute tasks according to the programmer's\nspecification.\n  The results from experiments performed on top of an Intel-based\nmulticore/multiprocessor platform show that, depending on the runtime policy\nused, our system can achieve an energy reduction of up to 83% compared with a\nfully accurate execution and up to 35% compared with an approximate version\nemploying loop perforation. At the same time, our approach always results in\ngraceful quality degradation.\n", "versions": [{"version": "v1", "created": "Mon, 15 Dec 2014 17:46:42 GMT"}], "update_date": "2014-12-17", "authors_parsed": [["Vassiliadis", "Vassilis", ""], ["Parasyris", "Konstantinos", ""], ["Chalios", "Charalambos", ""], ["Antonopoulos", "Christos D.", ""], ["Lalis", "Spyros", ""], ["Bellas", "Nikolaos", ""], ["Vandierendonck", "Hans", ""], ["Nikolopoulos", "Dimitrios S.", ""]]}, {"id": "1412.5400", "submitter": "Uday Khedker", "authors": "Uday P. Khedker", "title": "Buffer Overflow Analysis for C", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Buffer overflow detection and mitigation for C programs has been an important\nconcern for a long time. This paper defines a string buffer overflow analysis\nfor C programs. The key ideas of our formulation are (a) separating buffers\nfrom the pointers that point to them, (b) modelling buffers in terms of sizes\nand sets of positions of null characters, and (c) defining stateless functions\nto compute the sets of null positions and mappings between buffers and\npointers.\n  This exercise has been carried out to test the feasibility of describing such\nan analysis in terms of lattice valued functions and relations to facilitate\nautomatic construction of an analyser without the user having to write\nC/C++/Java code. This is facilitated by devising stateless formulations because\nstateful formulations combine features through side effects in states raising a\nnatural requirement of C/C++/Java code to be written to describe them. Given\nthe above motivation, the focus of this paper is not to build good static\napproximations for buffer overflow analysis but to show how given static\napproximations could be formalized in terms of stateless formulations so that\nthey become amenable to automatic construction of analysers.\n", "versions": [{"version": "v1", "created": "Wed, 17 Dec 2014 14:12:12 GMT"}, {"version": "v2", "created": "Thu, 18 Dec 2014 17:02:14 GMT"}, {"version": "v3", "created": "Sun, 21 Dec 2014 05:52:11 GMT"}, {"version": "v4", "created": "Sun, 28 Dec 2014 17:24:28 GMT"}], "update_date": "2014-12-30", "authors_parsed": [["Khedker", "Uday P.", ""]]}, {"id": "1412.5867", "submitter": "Lidia Dobrescu", "authors": "Lidia Dobrescu", "title": "Replacing ANSI C with other modern programming languages", "comments": "IEEE International Symposium on Fundamentals of Electrical\n  Engineering 2014, ISFEE 2014, Bucharest", "journal-ref": null, "doi": "10.1109/ISFEE.2014.7050621", "report-no": null, "categories": "cs.CY cs.PL", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Replacing ANSI C language with other modern programming languages such as\nPython or Java may be an actual debate topic in technical universities.\nResearchers whose primary interests are not in programming area seem to prefer\nmodern and higher level languages. Keeping standard language ANSI C as a\nprimary tool for engineers and for microcontrollers programming, robotics and\ndata acquisition courses is another strong different opinion trend. Function\noriented versus object oriented languages may be another highlighted topic in\nactual debates.\n", "versions": [{"version": "v1", "created": "Thu, 18 Dec 2014 14:21:00 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Dobrescu", "Lidia", ""]]}, {"id": "1412.6579", "submitter": "Tarmo Uustalu", "authors": "Keiko Nakata (Institute of Cybernetics), Tarmo Uustalu (Institute of\n  Cybernetics)", "title": "A Hoare logic for the coinductive trace-based big-step semantics of\n  While", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 11, Issue 1 (February\n  11, 2015) lmcs:692", "doi": "10.2168/LMCS-11(1:1)2015", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In search for a foundational framework for reasoning about observable\nbehavior of programs that may not terminate, we have previously devised a\ntrace-based big-step semantics for While. In this semantics, both traces and\nevaluation (relating initial states of program runs to traces they produce) are\ndefined coinductively. On terminating runs, this semantics agrees with the\nstandard inductive state-based semantics. Here we present a Hoare logic\ncounterpart of our coinductive trace-based semantics and prove it sound and\ncomplete. Our logic subsumes the standard partial-correctness state-based Hoare\nlogic as well as the total-correctness variation: they are embeddable. In the\nconverse direction, projections can be constructed: a derivation of a Hoare\ntriple in our trace-based logic can be translated into a derivation in the\nstate-based logic of a translated, weaker Hoare triple. Since we work with a\nconstructive underlying logic, the range of program properties we can reason\nabout has a fine structure; in particular, we can distinguish between\ntermination and nondivergence, e.g., unbounded classically total search fails\nto be terminating, but is nonetheless nondivergent. Our meta-theory is entirely\nconstructive as well, and we have formalized it in Coq.\n", "versions": [{"version": "v1", "created": "Sat, 20 Dec 2014 02:00:11 GMT"}, {"version": "v2", "created": "Sun, 8 Feb 2015 11:06:59 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Nakata", "Keiko", "", "Institute of Cybernetics"], ["Uustalu", "Tarmo", "", "Institute of\n  Cybernetics"]]}, {"id": "1412.6765", "submitter": "Nassim Halli", "authors": "Nassim A. Halli, Henri-Pierre Charles and Jean-Fran\\c{c}ois Mehaut", "title": "Performance comparison between Java and JNI for optimal implementation\n  of computational micro-kernels", "comments": "Part of ADAPT Workshop proceedings, 2015 (arXiv:1412.2347)", "journal-ref": null, "doi": null, "report-no": "ADAPT/2015/06", "categories": "cs.PF cs.DC cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  General purpose CPUs used in high performance computing (HPC) support a\nvector instruction set and an out-of-order engine dedicated to increase the\ninstruction level parallelism. Hence, related optimizations are currently\ncritical to improve the performance of applications requiring numerical\ncomputation. Moreover, the use of a Java run-time environment such as the\nHotSpot Java Virtual Machine (JVM) in high performance computing is a promising\nalternative. It benefits from its programming flexibility, productivity and the\nperformance is ensured by the Just-In-Time (JIT) compiler. Though, the JIT\ncompiler suffers from two main drawbacks. First, the JIT is a black box for\ndevelopers. We have no control over the generated code nor any feedback from\nits optimization phases like vectorization. Secondly, the time constraint\nnarrows down the degree of optimization compared to static compilers like GCC\nor LLVM. So, it is compelling to use statically compiled code since it benefits\nfrom additional optimization reducing performance bottlenecks. Java enables to\ncall native code from dynamic libraries through the Java Native Interface\n(JNI). Nevertheless, JNI methods are not inlined and require an additional cost\nto be invoked compared to Java ones. Therefore, to benefit from better static\noptimization, this call overhead must be leveraged by the amount of computation\nperformed at each JNI invocation. In this paper we tackle this problem and we\npropose to do this analysis for a set of micro-kernels. Our goal is to select\nthe most efficient implementation considering the amount of computation defined\nby the calling context. We also investigate the impact on performance of\nseveral different optimization schemes which are vectorization, out-of-order\noptimization, data alignment, method inlining and the use of native memory for\nJNI methods.\n", "versions": [{"version": "v1", "created": "Sun, 21 Dec 2014 11:26:39 GMT"}], "update_date": "2014-12-23", "authors_parsed": [["Halli", "Nassim A.", ""], ["Charles", "Henri-Pierre", ""], ["Mehaut", "Jean-Fran\u00e7ois", ""]]}, {"id": "1412.6787", "submitter": "Kees Middelburg", "authors": "J. A. Bergstra, C. A. Middelburg", "title": "Instruction sequence size complexity of parity", "comments": "12 pages, the preliminaries are largely the same as the preliminaries\n  in arXiv:1312.1812 [cs.PL] and some earlier papers; 13 pages, minor errors\n  corrected; 13 pages, presentation improved; 14 pages, remarks about related\n  work added; 14 pages, presentation improved", "journal-ref": "Fundamenta Informaticae, 149(3):297--309, 2016", "doi": "10.3233/FI-2016-1450", "report-no": null, "categories": "cs.CC cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Each Boolean function can be computed by a single-pass instruction sequence\nthat contains only instructions to set and get the content of Boolean\nregisters, forward jump instructions, and a termination instruction. Auxiliary\nBoolean registers are not necessary for this. In the current paper, we show\nthat, in the case of the parity functions, shorter instruction sequences are\npossible with the use of an auxiliary Boolean register in the presence of\ninstructions to complement the content of auxiliary Boolean registers. This\nresult supports, in a setting where programs are instruction sequences acting\non Boolean registers, a basic intuition behind the storage of auxiliary data,\nnamely the intuition that this makes possible a reduction of the size of a\nprogram.\n", "versions": [{"version": "v1", "created": "Sun, 21 Dec 2014 14:29:29 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2015 07:44:17 GMT"}, {"version": "v3", "created": "Sat, 28 May 2016 09:38:30 GMT"}, {"version": "v4", "created": "Thu, 30 Jun 2016 08:29:13 GMT"}, {"version": "v5", "created": "Fri, 15 Jul 2016 09:44:32 GMT"}], "update_date": "2016-12-30", "authors_parsed": [["Bergstra", "J. A.", ""], ["Middelburg", "C. A.", ""]]}, {"id": "1412.7148", "submitter": "Tarmo Uustalu", "authors": "Thosten Altenkirch (University of Nottingham), James Chapman\n  (Institute of Cybernetics), Tarmo Uustalu (Institute of Cybernetics)", "title": "Monads need not be endofunctors", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 11, Issue 1 (March 6,\n  2015) lmcs:928", "doi": "10.2168/LMCS-11(1:3)2015", "report-no": null, "categories": "cs.PL cs.LO math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a generalization of monads, called relative monads, allowing for\nunderlying functors between different categories. Examples include\nfinite-dimensional vector spaces, untyped and typed lambda-calculus syntax and\nindexed containers. We show that the Kleisli and Eilenberg-Moore constructions\ncarry over to relative monads and are related to relative adjunctions. Under\nreasonable assumptions, relative monads are monoids in the functor category\nconcerned and extend to monads, giving rise to a coreflection between relative\nmonads and monads. Arrows are also an instance of relative monads.\n", "versions": [{"version": "v1", "created": "Mon, 22 Dec 2014 20:53:17 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2015 21:10:14 GMT"}], "update_date": "2015-09-14", "authors_parsed": [["Altenkirch", "Thosten", "", "University of Nottingham"], ["Chapman", "James", "", "Institute of Cybernetics"], ["Uustalu", "Tarmo", "", "Institute of Cybernetics"]]}, {"id": "1412.7664", "submitter": "Roshan Ragel", "authors": "M.G.G.C.R. Salgado and R. G. Ragel", "title": "Register Spilling for Specific Application Domains in Application\n  Specific Instruction-set Processors", "comments": "The 7th International Conference on Information and Automation for\n  Sustainability (ICIAfS) 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An Application Specific Instruction set Processor (ASIP) is an important\ncomponent in designing embedded systems. One of the problems in designing an\ninstruction set for such processors is determining the number of registers is\nneeded in the processor that will optimize the computational time and the cost.\nThe performance of a processor may fall short due to register spilling, which\nis caused by the lack of available registers in a processor. In the design\nperspective, it will result in processors with great performance and low power\nconsumption if we can avoid register spilling by deciding a value for the\nnumber of registers needed in an ASIP. However, as of now, it has not clearly\nbeen recognized how the number of registers changes with different application\ndomains. In this paper, we evaluated whether different application domains have\nany significant effect on register spilling and therefore the performance of a\nprocessor so that we could use different number of registers when building\nASIPs for different application domains rather than using a constant set of\nregisters. Such utilization of registers will result in processors with high\nperformance, low cost and low power consumption.\n", "versions": [{"version": "v1", "created": "Wed, 24 Dec 2014 14:15:19 GMT"}], "update_date": "2014-12-25", "authors_parsed": [["Salgado", "M. G. G. C. R.", ""], ["Ragel", "R. G.", ""]]}, {"id": "1412.8102", "submitter": "EPTCS", "authors": "Bob Coecke (University of Oxford), Ichiro Hasuo (The University of\n  Tokyo), Prakash Panangaden (McGill University)", "title": "Proceedings of the 11th workshop on Quantum Physics and Logic", "comments": null, "journal-ref": "EPTCS 172, 2014", "doi": "10.4204/EPTCS.172", "report-no": null, "categories": "cs.LO cs.CL cs.PL quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the proceedings of the 11th International Workshop on\nQuantum Physics and Logic (QPL 2014), which was held from the 4th to the 6th of\nJune, 2014, at Kyoto University, Japan.\n  The goal of the QPL workshop series is to bring together researchers working\non mathematical foundations of quantum physics, quantum computing and\nspatio-temporal causal structures, and in particular those that use logical\ntools, ordered algebraic and category-theoretic structures, formal languages,\nsemantic methods and other computer science methods for the study of physical\nbehavior in general. Over the past few years, there has been growing activity\nin these foundational approaches, together with a renewed interest in the\nfoundations of quantum theory, which complement the more mainstream research in\nquantum computation. Earlier workshops in this series, with the same acronym\nunder the name \"Quantum Programming Languages\", were held in Ottawa (2003),\nTurku (2004), Chicago (2005), and Oxford (2006). The first QPL under the new\nname Quantum Physics and Logic was held in Reykjavik (2008), followed by Oxford\n(2009 and 2010), Nijmegen (2011), Brussels (2012) and Barcelona (2013).\n", "versions": [{"version": "v1", "created": "Sun, 28 Dec 2014 03:54:16 GMT"}], "update_date": "2014-12-30", "authors_parsed": [["Coecke", "Bob", "", "University of Oxford"], ["Hasuo", "Ichiro", "", "The University of\n  Tokyo"], ["Panangaden", "Prakash", "", "McGill University"]]}, {"id": "1412.8120", "submitter": "Amlan Kusum", "authors": "Amlan Kusum, Iulian Neamtiu and Rajiv Gupta", "title": "Adapting Graph Application Performance via Alternate Data Structure\n  Representation", "comments": "Part of ADAPT Workshop proceedings, 2015 (arXiv:1412.2347)", "journal-ref": null, "doi": null, "report-no": "ADAPT/2015/03", "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph processing is used extensively in areas from social networking mining\nto web indexing. We demonstrate that the performance and dependability of such\napplications critically hinges on the graph data structure used, because a\nfixed, compile-time choice of data structure can lead to poor performance or\napplications unable to complete. To address this problem, we introduce an\napproach that helps programmers transform regular, off-the-shelf graph\napplications into adaptive, more dependable applications where adaptations are\nperformed via runtime selection from alternate data structure representations.\nUsing our approach, applications dynamically adapt to the input graph's\ncharacteristics and changes in available memory so they continue to run when\nfaced with adverse conditions such as low memory. Experiments with graph\nalgorithms on real-world (e.g., Wikipedia metadata, Gnutella topology) and\nsynthetic graph datasets show that our adaptive applications run to completion\nwith lower execution time and/or memory utilization in comparison to their\nnon-adaptive versions.\n", "versions": [{"version": "v1", "created": "Sun, 28 Dec 2014 06:49:23 GMT"}], "update_date": "2014-12-30", "authors_parsed": [["Kusum", "Amlan", ""], ["Neamtiu", "Iulian", ""], ["Gupta", "Rajiv", ""]]}, {"id": "1412.8461", "submitter": "Yanhong Annie Liu", "authors": "Yanhong A. Liu and Scott D. Stoller and Bo Lin", "title": "From Clarity to Efficiency for Distributed Algorithms", "comments": null, "journal-ref": "ACM Transactions on Programming Languages and Systems (TOPLAS)\n  Volume 39 Issue 3, July 2017 Article No. 12", "doi": "10.1145/2994595", "report-no": null, "categories": "cs.PL cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article describes a very high-level language for clear description of\ndistributed algorithms and optimizations necessary for generating efficient\nimplementations. The language supports high-level control flows where complex\nsynchronization conditions can be expressed using high-level queries,\nespecially logic quantifications, over message history sequences.\nUnfortunately, the programs would be extremely inefficient, including consuming\nunbounded memory, if executed straightforwardly.\n  We present new optimizations that automatically transform complex\nsynchronization conditions into incremental updates of necessary auxiliary\nvalues as messages are sent and received. The core of the optimizations is the\nfirst general method for efficient implementation of logic quantifications. We\nhave developed an operational semantics of the language, implemented a\nprototype of the compiler and the optimizations, and successfully used the\nlanguage and implementation on a variety of important distributed algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 29 Dec 2014 20:52:34 GMT"}, {"version": "v2", "created": "Sun, 4 Jan 2015 21:25:03 GMT"}, {"version": "v3", "created": "Wed, 6 Jan 2016 21:09:01 GMT"}, {"version": "v4", "created": "Sun, 12 Mar 2017 02:34:40 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Liu", "Yanhong A.", ""], ["Stoller", "Scott D.", ""], ["Lin", "Bo", ""]]}, {"id": "1412.8639", "submitter": "Kyle Pullicino", "authors": "Kyle Pullicino", "title": "Jif: Language-based Information-flow Security in Java", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  In this report, we examine Jif, a Java extension which augments the language\nwith features related to security. Jif adds support for security labels to\nJava's type system such that the developer can specify confidentiality and\nintegrity policies to the various variables used in their program. We list the\nmain features of Jif and discuss the information flow problem that Jif helps to\nsolve. We see how the information flow problem occurs in real-world systems by\nlooking at two examples: Civitas, a ballot/voting system where voters do not\nnecessarily trust voting agents, and SIF, a web application container\nimplemented using Jif. Finally, we implement a small program that simulates\ninformation flow in a booking system containing sensitive data and discuss the\nusefulness of Jif based on this program.\n", "versions": [{"version": "v1", "created": "Tue, 30 Dec 2014 14:23:13 GMT"}], "update_date": "2014-12-31", "authors_parsed": [["Pullicino", "Kyle", ""]]}, {"id": "1412.8739", "submitter": "Wlodzimierz Drabent", "authors": "W{\\l}odzimierz Drabent", "title": "Correctness and completeness of logic programs", "comments": "29 pages, 2 figures; with editorial modifications, small corrections\n  and extensions. arXiv admin note: text overlap with arXiv:1411.3015. Overlaps\n  explained in \"Related Work\" (p. 21)", "journal-ref": "ACM Transactions on Computational Logic, 17, 3, Article 18 (May\n  2016)", "doi": "10.1145/2898434", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss proving correctness and completeness of definite clause logic\nprograms. We propose a method for proving completeness, while for proving\ncorrectness we employ a method which should be well known but is often\nneglected. Also, we show how to prove completeness and correctness in the\npresence of SLD-tree pruning, and point out that approximate specifications\nsimplify specifications and proofs.\n  We compare the proof methods to declarative diagnosis (algorithmic\ndebugging), showing that approximate specifications eliminate a major drawback\nof the latter. We argue that our proof methods reflect natural declarative\nthinking about programs, and that they can be used, formally or informally, in\nevery-day programming.\n", "versions": [{"version": "v1", "created": "Tue, 30 Dec 2014 19:24:45 GMT"}, {"version": "v2", "created": "Sun, 17 May 2015 09:38:24 GMT"}], "update_date": "2017-01-31", "authors_parsed": [["Drabent", "W\u0142odzimierz", ""]]}]