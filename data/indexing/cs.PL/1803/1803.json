[{"id": "1803.00403", "submitter": "Zheng Yang", "authors": "Zheng Yang, Hang Lei", "title": "A general formal memory framework in Coq for verifying the properties of\n  programs based on higher-order logic theorem proving with increased\n  automation, consistency, and reusability", "comments": "27 pages, 28 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, a number of lightweight programs have been deployed in\ncritical domains, such as in smart contracts based on blockchain technology.\nTherefore, the security and reliability of such programs should be guaranteed\nby the most credible technology. Higher-order logic theorem proving is one of\nthe most reliable technologies for verifying the properties of programs.\nHowever, programs may be developed by different high-level programming\nlanguages, and a general, extensible, and reusable formal memory (GERM)\nframework that can simultaneously support different formal verification\nspecifications, particularly at the code level, is presently unavailable for\nverifying the properties of programs. Therefore, the present work proposes a\nGERM framework to fill this gap. The framework simulates physical memory\nhardware structure, including a low-level formal memory space, and provides a\nset of simple, nonintrusive application programming interfaces and assistant\ntools using Coq that can support different formal verification specifications\nsimultaneously. The proposed GERM framework is independent and customizable,\nand was verified entirely in Coq. We also present an extension of Curry-Howard\nisomorphism, denoted as execution-verification isomorphism (EVI), which\ncombines symbolic execution and theorem proving for increasing the degree of\nautomation in higher-order logic theorem proving assistant tools. We also\nimplement a toy functional programming language in a generalized algebraic\ndatatypes style and a formal interpreter in Coq based on the GERM framework.\nThese implementations are then employed to demonstrate the application of EVI\nto a simple code segment.\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 02:45:34 GMT"}, {"version": "v2", "created": "Sun, 4 Mar 2018 02:19:28 GMT"}, {"version": "v3", "created": "Tue, 27 Mar 2018 05:46:03 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Yang", "Zheng", ""], ["Lei", "Hang", ""]]}, {"id": "1803.00419", "submitter": "R. Baghdadi", "authors": "Riyadh Baghdadi, Jessica Ray, Malek Ben Romdhane, Emanuele Del Sozzo,\n  Patricia Suriana, Shoaib Kamil, Saman Amarasinghe", "title": "Technical Report about Tiramisu: a Three-Layered Abstraction for Hiding\n  Hardware Complexity from DSL Compilers", "comments": "This is a duplicate for 1804.10694. This version of the paper is\n  outdated and should be deleted and only 1804.10694 should be kept. Future\n  versions of the paper will replace 1804.10694 (as second, third version, ...)\n  but now we want to remove duplicates", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-performance DSL developers work hard to take advantage of modern\nhardware. The DSL compilers have to build their own complex middle-ends before\nthey can target a common back-end such as LLVM, which only handles single\ninstruction streams with SIMD instructions. We introduce Tiramisu, a common\nmiddle-end that can generate efficient code for modern processors and\naccelerators such as multicores, GPUs, FPGAs and distributed clusters. Tiramisu\nintroduces a novel three-level IR that separates the algorithm, how that\nalgorithm is executed, and where intermediate data are stored. This separation\nsimplifies optimization and makes targeting multiple hardware architectures\nfrom the same algorithm easier. As a result, DSL compilers can be made\nconsiderably less complex with no loss of performance while immediately\ntargeting multiple hardware or hardware combinations such as distributed nodes\nwith both CPUs and GPUs. We evaluated Tiramisu by creating a new middle-end for\nthe Halide and Julia compilers. We show that Tiramisu extends Halide and Julia\nwith many new capabilities including the ability to: express new algorithms\n(such as recurrent filters and non-rectangular iteration spaces), perform new\ncomplex loop nest transformations (such as wavefront parallelization, loop\nshifting and loop fusion) and generate efficient code for more architectures\n(such as combinations of distributed clusters, multicores, GPUs and FPGAs).\nFinally, we demonstrate that Tiramisu can generate very efficient code that\nmatches the highly optimized Intel MKL gemm (generalized matrix multiplication)\nimplementation, we also show speedups reaching 4X in Halide and 16X in Julia\ndue to optimizations enabled by Tiramisu.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 17:05:22 GMT"}, {"version": "v2", "created": "Wed, 7 Mar 2018 13:48:28 GMT"}, {"version": "v3", "created": "Mon, 28 May 2018 19:49:55 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Baghdadi", "Riyadh", ""], ["Ray", "Jessica", ""], ["Romdhane", "Malek Ben", ""], ["Del Sozzo", "Emanuele", ""], ["Suriana", "Patricia", ""], ["Kamil", "Shoaib", ""], ["Amarasinghe", "Saman", ""]]}, {"id": "1803.00427", "submitter": "Christoph Rauch", "authors": "Koko Muroya, Dan R. Ghica", "title": "The Dynamic Geometry of Interaction Machine: A Token-Guided Graph\n  Rewriter", "comments": "arXiv admin note: text overlap with arXiv:1802.06495", "journal-ref": "Logical Methods in Computer Science, Volume 15, Issue 4 (October\n  30, 2019) lmcs:5882", "doi": "10.23638/LMCS-15(4:7)2019", "report-no": null, "categories": "cs.LO cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In implementing evaluation strategies of the lambda-calculus, both\ncorrectness and efficiency of implementation are valid concerns. While the\nnotion of correctness is determined by the evaluation strategy, regarding\nefficiency there is a larger design space that can be explored, in particular\nthe trade-off between space versus time efficiency. Aiming at a unified\nframework that would enable the study of this trade-off, we introduce an\nabstract machine, inspired by Girard's Geometry of Interaction (GoI), a machine\ncombining token passing and graph rewriting. We show soundness and completeness\nof our abstract machine, called the \\emph{Dynamic GoI Machine} (DGoIM), with\nrespect to three evaluations: call-by-need, left-to-right call-by-value, and\nright-to-left call-by-value. Analysing time cost of its execution classifies\nthe machine as ``efficient'' in Accattoli's taxonomy of abstract machines.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 17:12:49 GMT"}, {"version": "v2", "created": "Sun, 10 Mar 2019 23:07:25 GMT"}, {"version": "v3", "created": "Tue, 29 Oct 2019 15:33:58 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Muroya", "Koko", ""], ["Ghica", "Dan R.", ""]]}, {"id": "1803.00652", "submitter": "Martin Roetteler", "authors": "Krysta M. Svore, Alan Geller, Matthias Troyer, John Azariah,\n  Christopher Granade, Bettina Heim, Vadym Kliuchnikov, Mariia Mykhailova,\n  Andres Paz, Martin Roetteler", "title": "Q#: Enabling scalable quantum computing and development with a\n  high-level domain-specific language", "comments": "11 pages, no figures, REVTeX", "journal-ref": "In: Proceedings of the Real World Domain Specific Languages\n  Workshop (RWDSL 2018)", "doi": "10.1145/3183895.3183901", "report-no": null, "categories": "quant-ph cs.ET cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum computing exploits quantum phenomena such as superposition and\nentanglement to realize a form of parallelism that is not available to\ntraditional computing. It offers the potential of significant computational\nspeed-ups in quantum chemistry, materials science, cryptography, and machine\nlearning. The dominant approach to programming quantum computers is to provide\nan existing high-level language with libraries that allow for the expression of\nquantum programs. This approach can permit computations that are meaningless in\na quantum context; prohibits succinct expression of interaction between\nclassical and quantum logic; and does not provide important constructs that are\nrequired for quantum programming. We present Q#, a quantum-focused\ndomain-specific language explicitly designed to correctly, clearly and\ncompletely express quantum algorithms. Q# provides a type system, a tightly\nconstrained environment to safely interleave classical and quantum\ncomputations; specialized syntax, symbolic code manipulation to automatically\ngenerate correct transformations of quantum operations, and powerful functional\nconstructs which aid composition.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 22:49:20 GMT"}], "update_date": "2018-03-05", "authors_parsed": [["Svore", "Krysta M.", ""], ["Geller", "Alan", ""], ["Troyer", "Matthias", ""], ["Azariah", "John", ""], ["Granade", "Christopher", ""], ["Heim", "Bettina", ""], ["Kliuchnikov", "Vadym", ""], ["Mykhailova", "Mariia", ""], ["Paz", "Andres", ""], ["Roetteler", "Martin", ""]]}, {"id": "1803.00699", "submitter": "EPTCS", "authors": "Robert Rand (University of Pennsylvania), Jennifer Paykin (University\n  of Pennsylvania), Steve Zdancewic (University of Pennsylvania)", "title": "QWIRE Practice: Formal Verification of Quantum Circuits in Coq", "comments": "In Proceedings QPL 2017, arXiv:1802.09737", "journal-ref": "EPTCS 266, 2018, pp. 119-132", "doi": "10.4204/EPTCS.266.8", "report-no": null, "categories": "cs.LO cs.ET cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe an embedding of the QWIRE quantum circuit language in the Coq\nproof assistant. This allows programmers to write quantum circuits using\nhigh-level abstractions and to prove properties of those circuits using Coq's\ntheorem proving features. The implementation uses higher-order abstract syntax\nto represent variable binding and provides a type-checking algorithm for linear\nwire types, ensuring that quantum circuits are well-formed. We formalize a\ndenotational semantics that interprets QWIRE circuits as superoperators on\ndensity matrices, and prove the correctness of some simple quantum programs.\n", "versions": [{"version": "v1", "created": "Fri, 2 Mar 2018 03:46:53 GMT"}], "update_date": "2018-03-05", "authors_parsed": [["Rand", "Robert", "", "University of Pennsylvania"], ["Paykin", "Jennifer", "", "University\n  of Pennsylvania"], ["Zdancewic", "Steve", "", "University of Pennsylvania"]]}, {"id": "1803.02473", "submitter": "Denis Firsov", "authors": "Denis Firsov, Richard Blair and Aaron Stump", "title": "Efficient Mendler-Style Lambda-Encodings in Cedille", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is common to model inductive datatypes as least fixed points of functors.\nWe show that within the Cedille type theory we can relax functoriality\nconstraints and generically derive an induction principle for Mendler-style\nlambda-encoded inductive datatypes, which arise as least fixed points of\ncovariant schemes where the morphism lifting is defined only on identities.\nAdditionally, we implement a destructor for these lambda-encodings that runs in\nconstant-time. As a result, we can define lambda-encoded natural numbers with\nan induction principle and a constant-time predecessor function so that the\nnormal form of a numeral requires only linear space. The paper also includes\nseveral more advanced examples.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 23:36:04 GMT"}], "update_date": "2018-03-08", "authors_parsed": [["Firsov", "Denis", ""], ["Blair", "Richard", ""], ["Stump", "Aaron", ""]]}, {"id": "1803.02796", "submitter": "Guillaume Munch-Maccagnoni", "authors": "Guillaume Munch-Maccagnoni", "title": "Resource Polymorphism", "comments": "62 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a resource-management model for ML-style programming languages,\ndesigned to be compatible with the OCaml philosophy and runtime model. This is\na proposal to extend the OCaml language with destructors, move semantics, and\nresource polymorphism, to improve its safety, efficiency, interoperability, and\nexpressiveness. It builds on the ownership-and-borrowing models of systems\nprogramming languages (Cyclone, C++11, Rust) and on linear types in functional\nprogramming (Linear Lisp, Clean, Alms). It continues a synthesis of resources\nfrom systems programming and resources in linear logic initiated by Baker.\n  It is a combination of many known and some new ideas. On the novel side, it\nhighlights the good mathematical structure of Stroustrup's \"Resource\nacquisition is initialisation\" (RAII) idiom for resource management based on\ndestructors, a notion sometimes confused with finalizers, and builds on it a\nnotion of resource polymorphism, inspired by polarisation in proof theory, that\nmixes C++'s RAII and a tracing garbage collector (GC).\n  The proposal targets a new spot in the design space, with an automatic and\npredictable resource-management model, at the same time based on lightweight\nand expressive language abstractions. It is backwards-compatible: current code\nis expected to run with the same performance, the new abstractions fully\ncombine with the current ones, and it supports a resource-polymorphic extension\nof libraries. It does so with only a few additions to the runtime, and it\nintegrates with the current GC implementation. It is also compatible with the\nupcoming multicore extension, and suggests that the Rust model for eliminating\ndata-races applies.\n  Interesting questions arise for a safe and practical type system, many of\nwhich have already been thoroughly investigated in the languages and prototypes\nCyclone, Rust, and Alms.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2018 18:05:39 GMT"}], "update_date": "2018-03-08", "authors_parsed": [["Munch-Maccagnoni", "Guillaume", ""]]}, {"id": "1803.02976", "submitter": "Sohei Ito", "authors": "Sohei Ito", "title": "Semantical Equivalence of the Control Flow Graph and the Program\n  Dependence Graph", "comments": "30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The program dependence graph (PDG) represents data and control dependence\nbetween statements in a program. This paper presents an operational semantics\nof program dependence graphs. Since PDGs exclude artificial order of statements\nthat resides in sequential programs, executions of PDGs are not unique.\nHowever, we identified a class of PDGs that have unique final states of\nexecutions, called deterministic PDGs. We prove that the operational semantics\nof control flow graphs is equivalent to that of deterministic PDGs. The class\nof deterministic PDGs properly include PDGs obtained from well-structured\nprograms. Thus, our operational semantics of PDGs is more general than that of\nPDGs for well-structured programs, which are already established in literature.\n", "versions": [{"version": "v1", "created": "Thu, 8 Mar 2018 05:56:53 GMT"}], "update_date": "2018-03-09", "authors_parsed": [["Ito", "Sohei", ""]]}, {"id": "1803.04451", "submitter": "Pedro Lopez-Garcia", "authors": "Pedro Lopez-Garcia, Luthfi Darmawan, Maximiliano Klemen, Umer Liqat,\n  Francisco Bueno, Manuel V. Hermenegildo", "title": "Interval-based Resource Usage Verification by Translation into Horn\n  Clauses and an Application to Energy Consumption", "comments": "Under consideration for publication in Theory and Practice of Logic\n  Programming (TPLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many applications require conformance with specifications that constrain the\nuse of resources, such as execution time, energy, bandwidth, etc. We have\npresented a configurable framework for static resource usage verification where\nspecifications can include lower and upper bound, data size-dependent resource\nusage functions. To statically check such specifications, our framework infers\nthe same type of resource usage functions, which safely approximate the actual\nresource usage of the program, and compares them against the specification. We\nreview how this framework supports several languages and compilation output\nformats by translating them to an intermediate representation based on Horn\nclauses and using the configurability of the framework to describe the resource\nsemantics of the input language. We provide a more detailed formalization and\nextend the framework so that both resource usage specification and\nanalysis/verification output can include preconditions expressing intervals for\nthe input data sizes for which assertions are applicable, proved, or disproved.\nMost importantly, we also extend the classes of functions that can be checked.\nWe provide results from an implementation within the Ciao/CiaoPP framework, and\nreport on a tool built by instantiating this framework for the verification of\nenergy consumption specifications for imperative/embedded programs. This paper\nis under consideration for publication in Theory and Practice of Logic\nProgramming (TPLP).\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 18:43:37 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Lopez-Garcia", "Pedro", ""], ["Darmawan", "Luthfi", ""], ["Klemen", "Maximiliano", ""], ["Liqat", "Umer", ""], ["Bueno", "Francisco", ""], ["Hermenegildo", "Manuel V.", ""]]}, {"id": "1803.04870", "submitter": "Benjamin Delaware", "authors": "Benjamin Delaware, Sorawit Suriyakarn, Cl\\'ement Pit--Claudel,\n  Qianchuan Ye, Adam Chlipala", "title": "Narcissus: Deriving Correct-By-Construction Decoders and Encoders from\n  Binary Formats", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is a neat result from functional programming that libraries of parser\ncombinators can support rapid construction of decoders for quite a range of\nformats. With a little more work, the same combinator program can denote both a\ndecoder and an encoder. Unfortunately, the real world is full of gnarly\nformats, as with the packet formats that make up the standard Internet protocol\nstack. Most past parser-combinator approaches cannot handle these formats, and\nthe few exceptions require redundancy -- one part of the natural grammar needs\nto be hand-translated into hints in multiple parts of a parser program. We show\nhow to recover very natural and nonredundant format specifications, covering\nall popular network packet formats and generating both decoders and encoders\nautomatically. The catch is that we use the Coq proof assistant to derive both\nkinds of artifacts using tactics, automatically, in a way that guarantees that\nthey form inverses of each other. We used our approach to reimplement packet\nprocessing for a full Internet protocol stack, inserting our replacement into\nthe OCaml-based MirageOS unikernel, resulting in minimal performance\ndegradation.\n", "versions": [{"version": "v1", "created": "Tue, 13 Mar 2018 15:11:01 GMT"}, {"version": "v2", "created": "Wed, 28 Nov 2018 17:45:26 GMT"}, {"version": "v3", "created": "Wed, 10 Apr 2019 14:39:28 GMT"}], "update_date": "2019-04-11", "authors_parsed": [["Delaware", "Benjamin", ""], ["Suriyakarn", "Sorawit", ""], ["Pit--Claudel", "Cl\u00e9ment", ""], ["Ye", "Qianchuan", ""], ["Chlipala", "Adam", ""]]}, {"id": "1803.05535", "submitter": "Justin Hsu", "authors": "Gilles Barthe and Thomas Espitau and Marco Gaboardi and Benjamin\n  Gr\\'egoire and Justin Hsu and Pierre-Yves Strub", "title": "An Assertion-Based Program Logic for Probabilistic Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research on deductive verification of probabilistic programs has considered\nexpectation-based logics, where pre- and post-conditions are real-valued\nfunctions on states, and assertion-based logics, where pre- and post-conditions\nare boolean predicates on state distributions. Both approaches have developed\nover nearly four decades, but they have different standings today.\nExpectation-based systems have managed to formalize many sophisticated case\nstudies, while assertion-based systems today have more limited expressivity and\nhave targeted simpler examples.\n  We present Ellora, a sound and relatively complete assertion-based program\nlogic, and demonstrate its expressivity by verifying several classical examples\nof randomized algorithms using an implementation in the EasyCrypt proof\nassistant. Ellora features new proof rules for loops and adversarial code, and\nsupports richer assertions than existing program logics. We also show that\nEllora allows convenient reasoning about complex probabilistic concepts by\ndeveloping a new program logic for probabilistic independence and distribution\nlaw, and then smoothly embedding it into Ellora. Our work demonstrates that the\nassertion-based approach is not fundamentally limited and suggests that some\nnotions are potentially easier to reason about in assertion-based systems.\n", "versions": [{"version": "v1", "created": "Wed, 14 Mar 2018 23:11:20 GMT"}], "update_date": "2018-03-16", "authors_parsed": [["Barthe", "Gilles", ""], ["Espitau", "Thomas", ""], ["Gaboardi", "Marco", ""], ["Gr\u00e9goire", "Benjamin", ""], ["Hsu", "Justin", ""], ["Strub", "Pierre-Yves", ""]]}, {"id": "1803.05838", "submitter": "Paola Giannini", "authors": "Paola Giannini, Tim Richter, Marco Servetto, Elena Zucca", "title": "Tracing sharing in an imperative pure calculus (Extended Version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a type and effect system, for an imperative object calculus,\nwhich infers \"sharing\" possibly introduced by the evaluation of an expression,\nrepresented as an equivalence relation among its free variables. This direct\nrepresentation of sharing effects at the syntactic level allows us to express\nin a natural way, and to generalize, widely-used notions in literature, notably\n\"uniqueness\" and \"borrowing\". Moreover, the calculus is \"pure\" in the sense\nthat reduction is defined on language terms only, since they directly encode\nstore. The advantage of this non-standard execution model with respect to a\nbehaviourally equivalent standard model using a global auxiliary structure is\nthat reachability relations among references are partly encoded by scoping.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2018 16:16:35 GMT"}, {"version": "v2", "created": "Sat, 30 Jun 2018 08:08:01 GMT"}, {"version": "v3", "created": "Wed, 1 Aug 2018 22:07:31 GMT"}], "update_date": "2018-08-03", "authors_parsed": [["Giannini", "Paola", ""], ["Richter", "Tim", ""], ["Servetto", "Marco", ""], ["Zucca", "Elena", ""]]}, {"id": "1803.06300", "submitter": "Hengbiao Yu", "authors": "Hengbiao Yu, Zhenbang Chen, Xianjin Fu, Ji Wang, Zhendong Su, Jun Sun,\n  Chun Huang, and Wei Dong", "title": "Combining Symbolic Execution and Model Checking to Verify MPI Programs", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Message passing is the standard paradigm of programming in high-performance\ncomputing. However, verifying Message Passing Interface (MPI) programs is\nchallenging, due to the complex program features (such as non-determinism and\nnon-blocking operations). In this work, we present MPI symbolic verifier\n(MPI-SV), the first symbolic execution based tool for automatically verifying\nMPI programs with non-blocking operations. MPI-SV combines symbolic execution\nand model checking in a synergistic way to tackle the challenges in MPI program\nverification. The synergy improves the scalability and enlarges the scope of\nverifiable properties. We have implemented MPI-SV (footnote:\nhttps://mpi-sv.github.io) and evaluated it with 111 real-world MPI verification\ntasks. The pure symbolic execution-based technique successfully verifies 61 out\nof the 111 tasks (55\\%) within one hour, while in comparison, MPI-SV verifies\n100 tasks (90\\%). On average, compared with pure symbolic execution, MPI-SV\nachieves 19x speedups on verifying the satisfaction of the critical property\nand 5x speedups on finding violations.\n", "versions": [{"version": "v1", "created": "Fri, 16 Mar 2018 16:33:35 GMT"}, {"version": "v2", "created": "Fri, 17 Jan 2020 03:50:40 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Yu", "Hengbiao", ""], ["Chen", "Zhenbang", ""], ["Fu", "Xianjin", ""], ["Wang", "Ji", ""], ["Su", "Zhendong", ""], ["Sun", "Jun", ""], ["Huang", "Chun", ""], ["Dong", "Wei", ""]]}, {"id": "1803.06328", "submitter": "Tom Rainforth", "authors": "Tom Rainforth", "title": "Nesting Probabilistic Programs", "comments": "Published at UAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.PL stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formalize the notion of nesting probabilistic programming queries and\ninvestigate the resulting statistical implications. We demonstrate that while\nquery nesting allows the definition of models which could not otherwise be\nexpressed, such as those involving agents reasoning about other agents,\nexisting systems take approaches which lead to inconsistent estimates. We show\nhow to correct this by delineating possible ways one might want to nest queries\nand asserting the respective conditions required for convergence. We further\nintroduce a new online nested Monte Carlo estimator that makes it substantially\neasier to ensure these conditions are met, thereby providing a simple framework\nfor designing statistically correct inference engines. We prove the correctness\nof this online estimator and show that, when using the recommended setup, its\nasymptotic variance is always better than that of the equivalent fixed\nestimator, while its bias is always within a factor of two.\n", "versions": [{"version": "v1", "created": "Fri, 16 Mar 2018 17:30:35 GMT"}, {"version": "v2", "created": "Sat, 28 Jul 2018 14:48:32 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Rainforth", "Tom", ""]]}, {"id": "1803.06547", "submitter": "Catalin Hritcu", "authors": "Guido Mart\\'inez, Danel Ahman, Victor Dumitrescu, Nick Giannarakis,\n  Chris Hawblitzel, Catalin Hritcu, Monal Narasimhamurthy, Zoe Paraskevopoulou,\n  Cl\\'ement Pit-Claudel, Jonathan Protzenko, Tahina Ramananandro, Aseem\n  Rastogi, Nikhil Swamy", "title": "Meta-F*: Proof Automation with SMT, Tactics, and Metaprograms", "comments": "Full version of ESOP'19 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce Meta-F*, a tactics and metaprogramming framework for the F*\nprogram verifier. The main novelty of Meta-F* is allowing the use of tactics\nand metaprogramming to discharge assertions not solvable by SMT, or to just\nsimplify them into well-behaved SMT fragments. Plus, Meta-F* can be used to\ngenerate verified code automatically.\n  Meta-F* is implemented as an F* effect, which, given the powerful effect\nsystem of F*, heavily increases code reuse and even enables the lightweight\nverification of metaprograms. Metaprograms can be either interpreted, or\ncompiled to efficient native code that can be dynamically loaded into the F*\ntype-checker and can interoperate with interpreted code. Evaluation on\nrealistic case studies shows that Meta-F* provides substantial gains in proof\ndevelopment, efficiency, and robustness.\n", "versions": [{"version": "v1", "created": "Sat, 17 Mar 2018 18:08:13 GMT"}, {"version": "v2", "created": "Thu, 12 Jul 2018 15:04:19 GMT"}, {"version": "v3", "created": "Sat, 17 Nov 2018 20:50:50 GMT"}, {"version": "v4", "created": "Thu, 7 Mar 2019 13:25:38 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Mart\u00ednez", "Guido", ""], ["Ahman", "Danel", ""], ["Dumitrescu", "Victor", ""], ["Giannarakis", "Nick", ""], ["Hawblitzel", "Chris", ""], ["Hritcu", "Catalin", ""], ["Narasimhamurthy", "Monal", ""], ["Paraskevopoulou", "Zoe", ""], ["Pit-Claudel", "Cl\u00e9ment", ""], ["Protzenko", "Jonathan", ""], ["Ramananandro", "Tahina", ""], ["Rastogi", "Aseem", ""], ["Swamy", "Nikhil", ""]]}, {"id": "1803.06960", "submitter": "Joachim Breitner", "authors": "Joachim Breitner and Antal Spector-Zabusky and Yao Li and Christine\n  Rizkallah and John Wiegley and Stephanie Weirich", "title": "Ready, Set, Verify! Applying hs-to-coq to real-world Haskell code", "comments": "30 pages, submitted to ICFP'18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Good tools can bring mechanical verification to programs written in\nmainstream functional languages. We use hs-to-coq to translate significant\nportions of Haskell's containers library into Coq, and verify it against\nspecifications that we derive from a variety of sources including type class\nlaws, the library's test suite, and interfaces from Coq's standard library. Our\nwork shows that it is feasible to verify mature, widely-used, highly optimized,\nand unmodified Haskell code. We also learn more about the theory of\nweight-balanced trees, extend hs-to-coq to handle partiality, and -- since we\nfound no bugs -- attest to the superb quality of well-tested functional code.\n", "versions": [{"version": "v1", "created": "Mon, 19 Mar 2018 14:42:25 GMT"}, {"version": "v2", "created": "Tue, 20 Mar 2018 03:15:09 GMT"}], "update_date": "2018-03-21", "authors_parsed": [["Breitner", "Joachim", ""], ["Spector-Zabusky", "Antal", ""], ["Li", "Yao", ""], ["Rizkallah", "Christine", ""], ["Wiegley", "John", ""], ["Weirich", "Stephanie", ""]]}, {"id": "1803.07130", "submitter": "Joachim Breitner", "authors": "Joachim Breitner", "title": "A promise checked is a promise kept: Inspection Testing", "comments": "15 pages. Submitted to Haskell'18. Includes an additional appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Occasionally, developers need to ensure that the compiler treats their code\nin a specific way that is only visible by inspecting intermediate or final\ncompilation artifacts. This is particularly common with carefully crafted\ncompositional libraries, where certain usage patterns are expected to trigger\nan intricate sequence of compiler optimizations -- stream fusion is a\nwell-known example.\n  The developer of such a library has to manually inspect build artifacts and\ncheck for the expected properties. Because this is too tedious to do often, it\nwill likely go unnoticed if the property is broken by a change to the library\ncode, its dependencies or the compiler. The lack of automation has led to\nreleased versions of such libraries breaking their documented promises.\n  This indicates that there is an unrecognized need for a new testing paradigm,\ninspection testing, where the programmer declaratively describes non-functional\nproperties of an compilation artifact and the compiler checks these properties.\nWe define inspection testing abstractly, implement it in the context of Haskell\nand show that it increases the quality of such libraries.\n", "versions": [{"version": "v1", "created": "Mon, 19 Mar 2018 19:29:47 GMT"}, {"version": "v2", "created": "Sun, 3 Jun 2018 10:22:49 GMT"}], "update_date": "2018-06-05", "authors_parsed": [["Breitner", "Joachim", ""]]}, {"id": "1803.07244", "submitter": "Justin Gottschlich", "authors": "Justin Gottschlich, Armando Solar-Lezama, Nesime Tatbul, Michael\n  Carbin, Martin Rinard, Regina Barzilay, Saman Amarasinghe, Joshua B\n  Tenenbaum, Tim Mattson", "title": "The Three Pillars of Machine Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this position paper, we describe our vision of the future of machine\nprogramming through a categorical examination of three pillars of research.\nThose pillars are: (i) intention, (ii) invention, and(iii) adaptation.\nIntention emphasizes advancements in the human-to-computer and\ncomputer-to-machine-learning interfaces. Invention emphasizes the creation or\nrefinement of algorithms or core hardware and software building blocks through\nmachine learning (ML). Adaptation emphasizes advances in the use of ML-based\nconstructs to autonomously evolve software.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2018 03:51:29 GMT"}, {"version": "v2", "created": "Tue, 8 May 2018 22:48:14 GMT"}, {"version": "v3", "created": "Sat, 26 Jun 2021 16:11:04 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Gottschlich", "Justin", ""], ["Solar-Lezama", "Armando", ""], ["Tatbul", "Nesime", ""], ["Carbin", "Michael", ""], ["Rinard", "Martin", ""], ["Barzilay", "Regina", ""], ["Amarasinghe", "Saman", ""], ["Tenenbaum", "Joshua B", ""], ["Mattson", "Tim", ""]]}, {"id": "1803.07522", "submitter": "Qinheping Hu", "authors": "Qinheping Hu, Isaac Evavold, Roopsha Samanta, Rishabh Singh, Loris\n  D'Antoni", "title": "Program Repair via Direct State Manipulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of program repair is to automatically fix programs to meet a\nspecification. We propose a new specification mechanism, direct manipulation,\nin which the programmer can visualize the trace of a buggy program on a failing\ninput and convey the intended program behavior by manipulating variable values\nat some location. The repair problem is to find a program that, on the same\ninput, reaches the location identified by the programmer with variable values\nequal to the manipulated ones. Since a single program execution under-specifies\nthe overall program behavior, we augment our repair problem with quantitative\nobjectives to find the program that agrees with the specification and is\nclosest to the original one with respect to some distance. We formalize the\nrepair problem, build a program repair tool JDial based on the Sketch\nsynthesizer, and show the effectiveness of JDial on representative buggy\nbenchmarks from introductory programming assignments.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2018 16:59:06 GMT"}], "update_date": "2018-03-21", "authors_parsed": [["Hu", "Qinheping", ""], ["Evavold", "Isaac", ""], ["Samanta", "Roopsha", ""], ["Singh", "Rishabh", ""], ["D'Antoni", "Loris", ""]]}, {"id": "1803.08150", "submitter": "Larry Diehl", "authors": "Larry Diehl, Denis Firsov, and Aaron Stump", "title": "Generic Zero-Cost Reuse for Dependent Types", "comments": "Additional section on Generic Relational Reuse", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dependently typed languages are well known for having a problem with code\nreuse. Traditional non-indexed algebraic datatypes (e.g. lists) appear\nalongside a plethora of indexed variations (e.g. vectors). Functions are often\nrewritten for both non-indexed and indexed versions of essentially the same\ndatatype, which is a source of code duplication.\n  We work in a Curry-style dependent type theory, where the same untyped term\nmay be classified as both the non-indexed and indexed versions of a datatype.\nMany solutions have been proposed for the problem of dependently typed reuse,\nbut we exploit Curry-style type theory in our solution to not only reuse data\nand programs, but do so at zero-cost (without a runtime penalty). Our work is\nan exercise in dependently typed generic programming, and internalizes the\nprocess of zero-cost reuse as the identity function in a Curry-style theory.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 22:02:43 GMT"}, {"version": "v2", "created": "Fri, 23 Mar 2018 00:43:31 GMT"}, {"version": "v3", "created": "Mon, 9 Jul 2018 19:43:01 GMT"}], "update_date": "2018-07-11", "authors_parsed": [["Diehl", "Larry", ""], ["Firsov", "Denis", ""], ["Stump", "Aaron", ""]]}, {"id": "1803.08668", "submitter": "EPTCS", "authors": "John P. Gallagher, Rob van Glabbeek, Wendelin Serwe", "title": "Proceedings Third Workshop on Models for Formal Analysis of Real Systems\n  and Sixth International Workshop on Verification and Program Transformation", "comments": null, "journal-ref": "EPTCS 268, 2018", "doi": "10.4204/EPTCS.268", "report-no": null, "categories": "cs.LO cs.FL cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the joint proceedings of MARS 2018, the third workshop\non Models for Formal Analysis of Real Systems, and VPT 2018, the sixth\ninternational workshop on Verification and Program Transformation, held\ntogether on April 20, 2018 in Thessaloniki, Greece, as part of ETAPS 2018, the\nEuropean Joint Conferences on Theory and Practice of Software.\n  MARS emphasises modelling over verification. It aims at discussing the\nlessons learned from making formal methods for the verification and analysis of\nrealistic systems. Examples are:\n  (1) Which formalism is chosen, and why?\n  (2) Which abstractions have to be made and why?\n  (3) How are important characteristics of the system modelled?\n  (4) Were there any complications while modelling the system?\n  (5) Which measures were taken to guarantee the accuracy of the model?\n  We invited papers that present full models of real systems, which may lay the\nbasis for future comparison and analysis. An aim of the workshop is to present\ndifferent modelling approaches and discuss pros and cons for each of them.\nAlternative formal descriptions of the systems presented at this workshop are\nencouraged, which should foster the development of improved specification\nformalisms.\n  VPT aims to provide a forum where people from the areas of program\ntransformation and program verification can fruitfully exchange ideas and gain\na deeper understanding of the interactions between those two fields. These\ninteractions have been beneficial in both directions. On the one hand, methods\nand tools developed in the field of program transformation, such as partial\ndeduction, partial evaluation, fold/unfold transformations, and\nsupercompilation, are applied with success to verification, in particular to\nthe verification of infinite state and parameterized systems. On the other\nhand, methods developed in program verification, such as model checking,\nabstract interpretation, SAT and SMT solving, and automated theorem proving,\nare used to enhance program transformation techniques, thereby making these\ntechniques more powerful and useful in practice.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 06:30:11 GMT"}], "update_date": "2018-03-26", "authors_parsed": [["Gallagher", "John P.", ""], ["van Glabbeek", "Rob", ""], ["Serwe", "Wendelin", ""]]}, {"id": "1803.09099", "submitter": "Chris Martens", "authors": "Chris Martens, Eric Butler, and Joseph C. Osborn", "title": "A Resourceful Reframing of Behavior Trees", "comments": "17 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designers of autonomous agents, whether in physical or virtual environments,\nneed to express nondeterminisim, failure, and parallelism in behaviors, as well\nas accounting for synchronous coordination between agents. Behavior Trees are a\nsemi-formalism deployed widely for this purpose in the games industry, but with\nchallenges to scalability, reasoning, and reuse of common sub-behaviors.\n  We present an alternative formulation of behavior trees through a language\ndesign perspective, giving a formal operational semantics, type system, and\ncorresponding implementation. We express specifications for atomic behaviors as\nlinear logic formulas describing how they transform the environment, and our\ntype system uses linear sequent calculus to derive a compositional type\nassignment to behavior tree expressions. These types expose the conditions\nrequired for behaviors to succeed and allow abstraction over parameters to\nbehaviors, enabling the development of behavior \"building blocks\" amenable to\ncompositional reasoning and reuse.\n", "versions": [{"version": "v1", "created": "Sat, 24 Mar 2018 12:28:04 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Martens", "Chris", ""], ["Butler", "Eric", ""], ["Osborn", "Joseph C.", ""]]}, {"id": "1803.09473", "submitter": "Uri Alon", "authors": "Uri Alon, Meital Zilberstein, Omer Levy, Eran Yahav", "title": "code2vec: Learning Distributed Representations of Code", "comments": "Accepted in POPL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a neural model for representing snippets of code as continuous\ndistributed vectors (\"code embeddings\"). The main idea is to represent a code\nsnippet as a single fixed-length $\\textit{code vector}$, which can be used to\npredict semantic properties of the snippet. This is performed by decomposing\ncode to a collection of paths in its abstract syntax tree, and learning the\natomic representation of each path $\\textit{simultaneously}$ with learning how\nto aggregate a set of them. We demonstrate the effectiveness of our approach by\nusing it to predict a method's name from the vector representation of its body.\nWe evaluate our approach by training a model on a dataset of 14M methods. We\nshow that code vectors trained on this dataset can predict method names from\nfiles that were completely unobserved during training. Furthermore, we show\nthat our model learns useful method name vectors that capture semantic\nsimilarities, combinations, and analogies. Comparing previous techniques over\nthe same data set, our approach obtains a relative improvement of over 75%,\nbeing the first to successfully predict method names based on a large,\ncross-project, corpus. Our trained model, visualizations and vector\nsimilarities are available as an interactive online demo at\nhttp://code2vec.org. The code, data, and trained models are available at\nhttps://github.com/tech-srl/code2vec.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 09:05:30 GMT"}, {"version": "v2", "created": "Wed, 28 Mar 2018 11:57:57 GMT"}, {"version": "v3", "created": "Sun, 22 Apr 2018 10:00:14 GMT"}, {"version": "v4", "created": "Mon, 29 Oct 2018 09:38:16 GMT"}, {"version": "v5", "created": "Tue, 30 Oct 2018 09:45:07 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Alon", "Uri", ""], ["Zilberstein", "Meital", ""], ["Levy", "Omer", ""], ["Yahav", "Eran", ""]]}, {"id": "1803.09544", "submitter": "Uri Alon", "authors": "Uri Alon, Meital Zilberstein, Omer Levy, Eran Yahav", "title": "A General Path-Based Representation for Predicting Program Properties", "comments": "to appear in PLDI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting program properties such as names or expression types has a wide\nrange of applications. It can ease the task of programming and increase\nprogrammer productivity. A major challenge when learning from programs is\n$\\textit{how to represent programs in a way that facilitates effective\nlearning}$.\n  We present a $\\textit{general path-based representation}$ for learning from\nprograms. Our representation is purely syntactic and extracted automatically.\nThe main idea is to represent a program using paths in its abstract syntax tree\n(AST). This allows a learning model to leverage the structured nature of code\nrather than treating it as a flat sequence of tokens.\n  We show that this representation is general and can: (i) cover different\nprediction tasks, (ii) drive different learning algorithms (for both generative\nand discriminative models), and (iii) work across different programming\nlanguages.\n  We evaluate our approach on the tasks of predicting variable names, method\nnames, and full types. We use our representation to drive both CRF-based and\nword2vec-based learning, for programs of four languages: JavaScript, Java,\nPython and C\\#. Our evaluation shows that our approach obtains better results\nthan task-specific handcrafted representations across different tasks and\nprogramming languages.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 12:30:21 GMT"}, {"version": "v2", "created": "Wed, 28 Mar 2018 11:09:32 GMT"}, {"version": "v3", "created": "Sun, 22 Apr 2018 07:48:46 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Alon", "Uri", ""], ["Zilberstein", "Meital", ""], ["Levy", "Omer", ""], ["Yahav", "Eran", ""]]}, {"id": "1803.09885", "submitter": "Zheng Yang", "authors": "Zheng Yang, Hang Lei", "title": "Lolisa: Formal syntax and semantics for a subset of the solidity\n  programming language in Mathematical Tool Coq", "comments": "15 pages,14 figures. arXiv admin note: text overlap with\n  arXiv:0901.3619 by other authors", "journal-ref": "Mathematical Problems in Engineering 2020 (2020) 6191537", "doi": "10.1155/2020/6191537", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents the formal syntax and semantics for a large subset of\nthe Solidity programming language developed for the Etheruem blockchain\nplatform based on our resent work about developing a general, extensible, and\nreusable formal memory (GERM) framework and an extension of Curry-Howard\nisomorphism, denoted as execution-verification isomorphism (EVI). This subset\nis denoted as Lolisa, which, to our knowledge, is the first mechanized and\nvalidated formal syntax and semantics developed for Solidity. The formal syntax\nof Lolisa adopts a stronger static type system than Solidity for enhanced type\nsafety. In addition, Lolisa not only includes nearly all the syntax components\nof Solidity, such as mapping, modifier, contract, and address types, but it\nalso contains general-purpose programming language features, such as multiple\nreturn values, pointer arithmetic, struct, and field access. Therefore, the\ninherent compatibility of Lolisa allows Solidity programs to be directly\ntranslated into Lolisa with a line-by-line correspondence without rebuilding or\nabstracting, and, in addition, the inherent generality of Lolisa allows it to\nbe extended to express other programming languages as well. To this end, we\nalso present a preliminary scheme for extending Lolisa to other languages\nsystematically.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 03:55:36 GMT"}, {"version": "v2", "created": "Sun, 1 Apr 2018 13:50:24 GMT"}, {"version": "v3", "created": "Mon, 4 Jan 2021 12:08:14 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Yang", "Zheng", ""], ["Lei", "Hang", ""]]}, {"id": "1803.10067", "submitter": "Bernd Burgstaller", "authors": "Johann Blieberger and Bernd Burgstaller", "title": "Safe Non-blocking Synchronization in Ada 202x", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The mutual-exclusion property of locks stands in the way to scalability of\nparallel programs on many-core architectures. Locks do not allow progress\nguarantees, because a task may fail inside a critical section and keep holding\na lock that blocks other tasks from accessing shared data. With non-blocking\nsynchronization, the drawbacks of locks are avoided by synchronizing access to\nshared data by atomic read-modify-write operations. To incorporate non-blocking\nsynchronization in Ada~202x, programmers must be able to reason about the\nbehavior and performance of tasks in the absence of protected objects and\nrendezvous. We therefore extend Ada's memory model by synchronized types, which\nsupport the expression of memory ordering operations at a sufficient level of\ndetail. To mitigate the complexity associated with non-blocking\nsynchronization, we propose concurrent objects as a novel high-level language\nconstruct. Entities of a concurrent object execute in parallel, due to a\nfine-grained, optimistic synchronization mechanism. Synchronization is framed\nby the semantics of concurrent entry execution. The programmer is only required\nto label shared data accesses in the code of concurrent entries. Labels\nconstitute memory-ordering operations expressed through attributes. To the best\nof our knowledge, this is the first approach to provide a non-blocking\nsynchronization construct as a first-class citizen of a high-level programming\nlanguage. We illustrate the use of concurrent objects by several examples.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 13:31:19 GMT"}, {"version": "v2", "created": "Mon, 18 Jun 2018 22:20:12 GMT"}], "update_date": "2018-06-20", "authors_parsed": [["Blieberger", "Johann", ""], ["Burgstaller", "Bernd", ""]]}, {"id": "1803.10195", "submitter": "Tomas Petricek", "authors": "Tomas Petricek (The Alan Turing Institute, United Kingdom)", "title": "What we talk about when we talk about monads", "comments": null, "journal-ref": "The Art, Science, and Engineering of Programming, 2018, Vol. 2,\n  Issue 3, Article 12", "doi": "10.22152/programming-journal.org/2018/2/12", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer science provides an in-depth understanding of technical aspects of\nprogramming concepts, but if we want to understand how programming concepts\nevolve, how programmers think and talk about them and how they are used in\npractice, we need to consider a broader perspective that includes historical,\nphilosophical and cognitive aspects. In this paper, we develop such broader\nunderstanding of monads, a programming concept that has an infamous formal\ndefinition, syntactic support in several programming languages and a reputation\nfor being elegant and powerful, but also intimidating and difficult to grasp.\nThis paper is not a monad tutorial. It will not tell you what a monad is.\nInstead, it helps you understand how computer scientists and programmers talk\nabout monads and why they do so. To answer these questions, we review the\nhistory of monads in the context of programming and study the development\nthrough the perspectives of philosophy of science, philosophy of mathematics\nand cognitive sciences. More generally, we present a framework for\nunderstanding programming concepts that considers them at three levels: formal,\nmetaphorical and implementation. We base such observations on established\nresults about the scientific method and mathematical entities -- cognitive\nsciences suggest that the metaphors used when thinking about monads are more\nimportant than widely accepted, while philosophy of science explains how the\nresearch paradigm from which monads originate influences and restricts their\nuse. Finally, we provide evidence for why a broader philosophical, sociological\nlook at programming concepts should be of interest for programmers. It lets us\nunderstand programming concepts better and, fundamentally, choose more\nappropriate abstractions as illustrated in number of case studies that conclude\nthe paper.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 17:35:50 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Petricek", "Tomas", "", "The Alan Turing Institute, United Kingdom"]]}, {"id": "1803.10197", "submitter": "Gabri\\\"el Konat", "authors": "Gabri\\\"el Konat, Michael J. Steindorfer, Sebastian Erdweg, Eelco\n  Visser (Delft University of Technology, Netherlands)", "title": "PIE: A Domain-Specific Language for Interactive Software Development\n  Pipelines", "comments": null, "journal-ref": "The Art, Science, and Engineering of Programming, 2018, Vol. 2,\n  Issue 3, Article 9", "doi": "10.22152/programming-journal.org/2018/2/9", "report-no": null, "categories": "cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Context. Software development pipelines are used for automating essential\nparts of software engineering processes, such as build automation and\ncontinuous integration testing. In particular, interactive pipelines, which\nprocess events in a live environment such as an IDE, require timely results for\nlow-latency feedback, and persistence to retain low-latency feedback between\nrestarts.\n  Inquiry. Developing an incrementalized and persistent version of a pipeline\nis one way to reduce feedback latency, but requires dependency tracking, cache\ninvalidation, and other complicated techniques. Therefore, interactivity\ncomplicates pipeline development if timeliness and persistence become\nresponsibilities of the pipeline programmer, rather than being supported by the\nunderlying system.\n  Approach. We develop Pipelines for Interactive Environments (PIE), a\nDomain-Specific Language (DSL), API, and runtime for developing interactive\nsoftware development pipelines, where ease of development is a focus.\n  Knowledge. PIE provides a straightforward programming model that enables\ndirect and concise expression of pipelines without boilerplate, reducing the\ndevelopment and maintenance effort of pipelines. Compiled pipeline programs can\nbe embedded into interactive environments such as code editors and IDEs,\nenabling timely feedback at a low cost.\n  Grounding. Compared to the state of the art, PIE reduces the code required to\nexpress an interactive pipeline by a factor of 6 in a case study on\nsyntax-aware editors. Furthermore, we evaluate PIE in two case studies of\ncomplex interactive software development scenarios, demonstrating that PIE can\nhandle complex interactive pipelines in a straightforward and concise way.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 17:36:16 GMT"}, {"version": "v2", "created": "Thu, 19 Apr 2018 12:56:40 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Konat", "Gabri\u00ebl", "", "Delft University of Technology, Netherlands"], ["Steindorfer", "Michael J.", "", "Delft University of Technology, Netherlands"], ["Erdweg", "Sebastian", "", "Delft University of Technology, Netherlands"], ["Visser", "Eelco", "", "Delft University of Technology, Netherlands"]]}, {"id": "1803.10198", "submitter": "Raffi Khatchadourian", "authors": "Raffi Khatchadourian (City University of New York, United States),\n  Hidehiko Masuhara (The University of Tokyo, Japan)", "title": "Proactive Empirical Assessment of New Language Feature Adoption via\n  Automated Refactoring: The Case of Java 8 Default Methods", "comments": null, "journal-ref": "The Art, Science, and Engineering of Programming, 2018, Vol. 2,\n  Issue 3, Article 6", "doi": "10.22152/programming-journal.org/2018/2/6", "report-no": null, "categories": "cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Programming languages and platforms improve over time, sometimes resulting in\nnew language features that offer many benefits. However, despite these\nbenefits, developers may not always be willing to adopt them in their projects\nfor various reasons. In this paper, we describe an empirical study where we\nassess the adoption of a particular new language feature. Studying how\ndevelopers use (or do not use) new language features is important in\nprogramming language research and engineering because it gives designers\ninsight into the usability of the language to create meaning programs in that\nlanguage. This knowledge, in turn, can drive future innovations in the area.\nHere, we explore Java 8 default methods, which allow interfaces to contain\n(instance) method implementations.\n  Default methods can ease interface evolution, make certain ubiquitous design\npatterns redundant, and improve both modularity and maintainability. A focus of\nthis work is to discover, through a scientific approach and a novel technique,\nsituations where developers found these constructs useful and where they did\nnot, and the reasons for each. Although several studies center around assessing\nnew language features, to the best of our knowledge, this kind of construct has\nnot been previously considered.\n  Despite their benefits, we found that developers did not adopt default\nmethods in all situations. Our study consisted of submitting pull requests\nintroducing the language feature to 19 real-world, open source Java projects\nwithout altering original program semantics. This novel assessment technique is\nproactive in that the adoption was driven by an automatic refactoring approach\nrather than waiting for developers to discover and integrate the feature\nthemselves. In this way, we set forth best practices and patterns of using the\nlanguage feature effectively earlier rather than later and are able to possibly\nguide (near) future language evolution. We foresee this technique to be useful\nin assessing other new language features, design patterns, and other\nprogramming idioms.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 17:36:32 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Khatchadourian", "Raffi", "", "City University of New York, United States"], ["Masuhara", "Hidehiko", "", "The University of Tokyo, Japan"]]}, {"id": "1803.10199", "submitter": "Tetsuo Kamina", "authors": "Tetsuo Kamina (Ritsumeikan University, Japan), Tomoyuki Aotani (The\n  University of Tokyo, Japan)", "title": "Harmonizing Signals and Events with a Lightweight Extension to Java", "comments": null, "journal-ref": "The Art, Science, and Engineering of Programming, 2018, Vol. 2,\n  Issue 3, Article 5", "doi": "10.22152/programming-journal.org/2018/2/5", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current demands for seamless connections with the surrounding environment\nmake software more reactive. For example, such demands are evident in systems\nconsisting of the Internet of Things. Such systems include a set of reactive\nvalues that are periodically updated in response to external or internal events\nto form a dataflow in the sense that such updates are propagated to other\nreactive values. Two effective approaches for realizing such reactive values\nhave been proposed: the event mechanisms in event-based programming and the\nsignals in functional-reactive programming. These two approaches are now\nbecoming mixed in several languages such as Flapjax and REScala, which makes\nthese languages notably expressive for modularizing the implementation of\nreactive software. For example, REScala provides a rich API that consists of\nfunctions converting events to signals and vice versa.\n  In this paper, we explore another, simpler approach in the design space of\nreactive programming languages: the event mechanism is harmonized with signals,\nresulting in a simplified programming interface that is mostly based on\nsignals. Based on this approach, we realize SignalJ, a simple extension of Java\nwith events and signals. Our notable findings are (1) an event can be\nrepresented as an update of a signal and (2) such an effectful signal can be\nrepresented using annotations instead of introducing types and constructors for\nsignals to further simplify the language.\n  Another contribution of this paper is the formal model of SignalJ. As both\nmechanisms of events and signals may interfere with each other, this mixing\nsometimes results in surprising behavior. For example, the functional behavior\nof signals is affected by the imperative features of events. Thus,\nunderstanding the formal model of this mixing is actually important. The core\ncalculus, Featherweight SignalJ (FSJ), was developed as an extension of\nFeatherweight Java, and proofs are provided to ensure the soundness of FSJ.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 17:36:46 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Kamina", "Tetsuo", "", "Ritsumeikan University, Japan"], ["Aotani", "Tomoyuki", "", "The\n  University of Tokyo, Japan"]]}, {"id": "1803.10200", "submitter": "Fabio Niephaus", "authors": "Fabio Niephaus (Hasso Plattner Institute, University of Potsdam,\n  Germany, Germany), Tim Felgentreff (Hasso Plattner Institute, University of\n  Potsdam, Germany, Oracle Labs Potsdam, Germany, Germany), Tobias Pape (Hasso\n  Plattner Institute, University of Potsdam, Germany, Germany), Robert\n  Hirschfeld (Hasso Plattner Institute, University of Potsdam, Germany,\n  Germany), Marcel Taeumel (Hasso Plattner Institute, University of Potsdam,\n  Germany, Germany)", "title": "Live Multi-language Development and Runtime Environments", "comments": null, "journal-ref": "The Art, Science, and Engineering of Programming, 2018, Vol. 2,\n  Issue 3, Article 8", "doi": "10.22152/programming-journal.org/2018/2/8", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Context: Software development tools should work and behave consistently\nacross different programming languages, so that developers do not have to\nfamiliarize themselves with new tooling for new languages. Also, being able to\ncombine multiple programming languages in a program increases reusability, as\ndevelopers do not have to recreate software frameworks and libraries in the\nlanguage they develop in and can reuse existing software instead.\n  Inquiry: However, developers often have a broad choice of tools, some of\nwhich are designed for only one specific programming language. Various\nIntegrated Development Environments have support for multiple languages, but\nare usually unable to provide a consistent programming experience due to\ndifferent language-specific runtime features. With regard to language\nintegrations, common mechanisms usually use abstraction layers, such as the\noperating system or a network connection, which are often boundaries for tools\nand hence negatively affect the programming experience.\n  Approach: In this paper, we present a novel approach for tool reuse that aims\nto improve the experience with regard to working with multiple high-level\ndynamic, object-oriented programming languages. As part of this, we build a\nmulti-language virtual execution environment and reuse Smalltalk's live\nprogramming tools for other languages.\n  Knowledge: An important part of our approach is to retrofit and align runtime\ncapabilities for different languages as it is a requirement for providing\nconsistent tools. Furthermore, it provides convenient means to reuse and even\nmix software libraries and frameworks written in different languages without\nbreaking tool support.\n  Grounding: The prototype system Squimera is an implementation of our approach\nand demonstrates that it is possible to reuse both development tools from a\nlive programming system to improve the development experience as well as\nsoftware artifacts from different languages to increase productivity.\n  Importance: In the domain of polyglot programming systems, most research has\nfocused on the integration of different languages and corresponding performance\noptimizations. Our work, on the other hand, focuses on tooling and the overall\nprogramming experience.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 17:37:01 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Niephaus", "Fabio", "", "Hasso Plattner Institute, University of Potsdam,\n  Germany, Germany"], ["Felgentreff", "Tim", "", "Hasso Plattner Institute, University of\n  Potsdam, Germany, Oracle Labs Potsdam, Germany, Germany"], ["Pape", "Tobias", "", "Hasso\n  Plattner Institute, University of Potsdam, Germany, Germany"], ["Hirschfeld", "Robert", "", "Hasso Plattner Institute, University of Potsdam, Germany,\n  Germany"], ["Taeumel", "Marcel", "", "Hasso Plattner Institute, University of Potsdam,\n  Germany, Germany"]]}, {"id": "1803.10201", "submitter": "Michael Van De Vanter", "authors": "Michael Van De Vanter (Oracle Labs, United States), Chris Seaton\n  (Oracle Labs, United Kingdom), Michael Haupt (self, Germany), Christian Humer\n  (Oracle Labs, Switzerland), Thomas W\\\"urthinger (Oracle Labs, Switzerland)", "title": "Fast, Flexible, Polyglot Instrumentation Support for Debuggers and other\n  Tools", "comments": null, "journal-ref": "The Art, Science, and Engineering of Programming, 2018, Vol. 2,\n  Issue 3, Article 14", "doi": "10.22152/programming-journal.org/2018/2/14", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Context: Software development tools that interact with running programs such\nas debuggers, profilers, and dynamic analysis frameworks are presumed to demand\ndifficult tradeoffs among implementation complexity (cost), functionality,\nusability, and performance. Among the many consequences, tools are often\ndelivered late (if ever), have limited functionality, require non-standard\nconfigurations, and impose serious performance costs on running programs.\n  Inquiry: Can flexible tool support become a practical, first class, intrinsic\nrequirement for a modern highperformance programming language implementation\nframework?\n  Approach: We extended the Truffle Language Implementation Framework, which\ntogether with the GraalVM execution environment makes possible very high\nperformance language implementations. Truffle's new Instrumentation Framework\nis language-agnostic and designed to derive high performance from the same\ntechnologies as do language implementations. Truffle Instrumentation includes:\n(1) low overhead capture of execution events by dynamically adding \"wrapper\"\nnodes to executing ASTs; (2) extensions to the Language Implementation\nFramework that allow per-language specialization, primarily for visual display\nof values and names, among others; and (3) versatile APIs and support services\nfor implementing many kinds of tools without VM modification.\n  Knowledge: It is now possible for a client in a production environment to\ninsert (dynamically, with thread safety) an instrumentation probe that captures\nand reports abstractly specified execution events. A probe in fully optimized\ncode imposes very low overhead until actually used to access (or modify)\nexecution state. Event capture has enabled construction of numerous GraalVM\nservices and tools that work for all implemented languages, either singly or in\ncombination. Instrumentation has also proved valuable for implementing some\ntraditionally tricky language features, as well as some GraalVM services such\nas placing bounds on resources consumed by running programs.\n  Grounding: Tools for debugging (via multiple clients), profiling, statement\ncounting, dynamic analysis, and others are now part of GraalVM or are in active\ndevelopment. Third parties have also used Truffle Instrumentation for\ninnovative tool implementations.\n  Importance: Experience with Truffle Instrumentation validates the notion that\naddressing developer tools support as a forethought can change expectations\nabout the availability of practical, efficient tools for high-performance\nlanguages. Tool development becomes a natural part of language implementation,\nrequiring little additional effort and offering the advantage of early and\ncontinuous availability.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 17:37:18 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Van De Vanter", "Michael", "", "Oracle Labs, United States"], ["Seaton", "Chris", "", "Oracle Labs, United Kingdom"], ["Haupt", "Michael", "", "self, Germany"], ["Humer", "Christian", "", "Oracle Labs, Switzerland"], ["W\u00fcrthinger", "Thomas", "", "Oracle Labs, Switzerland"]]}, {"id": "1803.10202", "submitter": "Jan Stolarek", "authors": "Jan Stolarek (The University of Edinburgh, United Kingdom), James\n  Cheney (The University of Edinburgh, United Kingdom)", "title": "Language-integrated provenance in Haskell", "comments": null, "journal-ref": "The Art, Science, and Engineering of Programming, 2018, Vol. 2,\n  Issue 3, Article 11", "doi": "10.22152/programming-journal.org/2018/2/11", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scientific progress increasingly depends on data management, particularly to\nclean and curate data so that it can be systematically analyzed and reused. A\nwealth of techniques for managing and curating data (and its provenance) have\nbeen proposed, largely in the database community. In particular, a number of\ninfluential papers have proposed collecting provenance information explaining\nwhere a piece of data was copied from, or what other records were used to\nderive it. Most of these techniques, however, exist only as research prototypes\nand are not available in mainstream database systems. This means scientists\nmust either implement such techniques themselves or (all too often) go without.\n  This is essentially a code reuse problem: provenance techniques currently\ncannot be implemented reusably, only as ad hoc, usually unmaintained extensions\nto standard databases. An alternative, relatively unexplored approach is to\nsupport such techniques at a higher abstraction level, using metaprogramming or\nreflection techniques. Can advanced programming techniques make it easier to\ntransfer provenance research results into practice?\n  We build on a recent approach called language-integrated provenance, which\nextends language-integrated query techniques with source-to-source query\ntranslations that record provenance. In previous work, a proof of concept was\ndeveloped in a research programming language called Links, which supports\nsophisticated Web and database programming. In this paper, we show how to adapt\nthis approach to work in Haskell building on top of the Database-Supported\nHaskell (DSH) library.\n  Even though it seemed clear in principle that Haskell's rich programming\nfeatures ought to be sufficient, implementing language-integrated provenance in\nHaskell required overcoming a number of technical challenges due to\ninteractions between these capabilities. Our implementation serves as a proof\nof concept showing how this combination of metaprogramming features can, for\nthe first time, make data provenance facilities available to programmers as a\nlibrary in a widely-used, general-purpose language.\n  In our work we were successful in implementing forms of provenance known as\nwhere-provenance and lineage. We have tested our implementation using a simple\ndatabase and query set and established that the resulting queries are executed\ncorrectly on the database. Our implementation is publicly available on GitHub.\n  Our work makes provenance tracking available to users of DSH at little cost.\nAlthough Haskell is not widely used for scientific database development, our\nwork suggests which languages features are necessary to support provenance as\nlibrary. We also highlight how combining Haskell's advanced type programming\nfeatures can lead to unexpected complications, which may motivate further\nresearch into type system expressiveness.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 17:38:00 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Stolarek", "Jan", "", "The University of Edinburgh, United Kingdom"], ["Cheney", "James", "", "The University of Edinburgh, United Kingdom"]]}, {"id": "1803.10215", "submitter": "Lu\\'is Eduardo de Souza Amorim", "authors": "Lu\\'is Eduardo de Souza Amorim (Delft University of Technology,\n  Netherlands), Michael J. Steindorfer (Delft University of Technology,\n  Netherlands), Eelco Visser (Delft University of Technology, Netherlands)", "title": "Towards Zero-Overhead Disambiguation of Deep Priority Conflicts", "comments": null, "journal-ref": "The Art, Science, and Engineering of Programming, 2018, Vol. 2,\n  Issue 3, Article 13", "doi": "10.22152/programming-journal.org/2018/2/13", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  **Context** Context-free grammars are widely used for language prototyping\nand implementation. They allow formalizing the syntax of domain-specific or\ngeneral-purpose programming languages concisely and declaratively. However, the\nnatural and concise way of writing a context-free grammar is often ambiguous.\nTherefore, grammar formalisms support extensions in the form of *declarative\ndisambiguation rules* to specify operator precedence and associativity, solving\nambiguities that are caused by the subset of the grammar that corresponds to\nexpressions.\n  **Inquiry** Implementing support for declarative disambiguation within a\nparser typically comes with one or more of the following limitations in\npractice: a lack of parsing performance, or a lack of modularity (i.e.,\ndisallowing the composition of grammar fragments of potentially different\nlanguages). The latter subject is generally addressed by scannerless\ngeneralized parsers. We aim to equip scannerless generalized parsers with novel\ndisambiguation methods that are inherently performant, without compromising the\nconcerns of modularity and language composition.\n  **Approach** In this paper, we present a novel low-overhead implementation\ntechnique for disambiguating deep associativity and priority conflicts in\nscannerless generalized parsers with lightweight data-dependency.\n  **Knowledge** Ambiguities with respect to operator precedence and\nassociativity arise from combining the various operators of a language. While\n*shallow conflicts* can be resolved efficiently by one-level tree patterns,\n*deep conflicts* require more elaborate techniques, because they can occur\narbitrarily nested in a tree. Current state-of-the-art approaches to solving\ndeep priority conflicts come with a severe performance overhead.\n  **Grounding** We evaluated our new approach against state-of-the-art\ndeclarative disambiguation mechanisms. By parsing a corpus of popular\nopen-source repositories written in Java and OCaml, we found that our approach\nyields speedups of up to 1.73x over a grammar rewriting technique when parsing\nprograms with deep priority conflicts--with a modest overhead of 1-2 % when\nparsing programs without deep conflicts.\n  **Importance** A recent empirical study shows that deep priority conflicts\nare indeed wide-spread in real-world programs. The study shows that in a corpus\nof popular OCaml projects on Github, up to 17 % of the source files contain\ndeep priority conflicts. However, there is no solution in the literature that\naddresses efficient disambiguation of deep priority conflicts, with support for\nmodular and composable syntax definitions.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 17:55:46 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Amorim", "Lu\u00eds Eduardo de Souza", "", "Delft University of Technology,\n  Netherlands"], ["Steindorfer", "Michael J.", "", "Delft University of Technology,\n  Netherlands"], ["Visser", "Eelco", "", "Delft University of Technology, Netherlands"]]}, {"id": "1803.10322", "submitter": "EPTCS", "authors": "Hubert Garavel, Lina Marsso", "title": "Comparative Study of Eight Formal Specifications of the Message\n  Authenticator Algorithm", "comments": "In Proceedings MARS/VPT 2018, arXiv:1803.08668", "journal-ref": "EPTCS 268, 2018, pp. 41-87", "doi": "10.4204/EPTCS.268.2", "report-no": null, "categories": "cs.PL cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Message Authenticator Algorithm (MAA) is one of the first cryptographic\nfunctions for computing a Message Authentication Code. Between 1987 and 2001,\nthe MAA was adopted in international standards (ISO 8730 and ISO 8731-2) to\nensure the authenticity and integrity of banking transactions. In 1990 and\n1991, three formal, yet non-executable, specifications of the MAA (in VDM, Z,\nand LOTOS) were developed at NPL. Since then, five formal executable\nspecifications of the MAA (in LOTOS, LNT, and term rewrite systems) have been\ndesigned at INRIA Grenoble. This article provides an overview of the MAA and\ncompares its formal specifications with respect to common-sense criteria, such\nas conciseness, readability, and efficiency of code generation.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 20:58:44 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Garavel", "Hubert", ""], ["Marsso", "Lina", ""]]}, {"id": "1803.10327", "submitter": "EPTCS", "authors": "Robert Gl\\\"uck (DIKU, Dept. of Computer Science, University of\n  Copenhagen)", "title": "An Experiment in Ping-Pong Protocol Verification by Nondeterministic\n  Pushdown Automata", "comments": "In Proceedings MARS/VPT 2018, arXiv:1803.08668", "journal-ref": "EPTCS 268, 2018, pp. 169-184", "doi": "10.4204/EPTCS.268.6", "report-no": null, "categories": "cs.PL cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An experiment is described that confirms the security of a well-studied class\nof cryptographic protocols (Dolev-Yao intruder model) can be verified by\ntwo-way nondeterministic pushdown automata (2NPDA). A nondeterministic pushdown\nprogram checks whether the intersection of a regular language (the protocol to\nverify) and a given Dyck language containing all canceling words is empty. If\nit is not, an intruder can reveal secret messages sent between trusted users.\nThe verification is guaranteed to terminate in cubic time at most on a\n2NPDA-simulator. The interpretive approach used in this experiment simplifies\nthe verification, by separating the nondeterministic pushdown logic and program\ncontrol, and makes it more predictable. We describe the interpretive approach\nand the known transformational solutions, and show they share interesting\nfeatures. Also noteworthy is how abstract results from automata theory can\nsolve practical problems by programming language means.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 21:00:27 GMT"}], "update_date": "2018-04-02", "authors_parsed": [["Gl\u00fcck", "Robert", "", "DIKU, Dept. of Computer Science, University of\n  Copenhagen"]]}, {"id": "1803.10328", "submitter": "EPTCS", "authors": "Bernhard Beckert (Karlsruhe Institute of Technology), Timo Bingmann\n  (Karlsruhe Institute of Technology), Moritz Kiefer (Karlsruhe Institute of\n  Technology), Peter Sanders (Karlsruhe Institute of Technology), Mattias\n  Ulbrich (Karlsruhe Institute of Technology), Alexander Weigl (Karlsruhe\n  Institute of Technology)", "title": "Proving Equivalence Between Imperative and MapReduce Implementations\n  Using Program Transformations", "comments": "In Proceedings MARS/VPT 2018, arXiv:1803.08668", "journal-ref": "EPTCS 268, 2018, pp. 185-199", "doi": "10.4204/EPTCS.268.7", "report-no": null, "categories": "cs.PL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed programs are often formulated in popular functional frameworks\nlike MapReduce, Spark and Thrill, but writing efficient algorithms for such\nframeworks is usually a non-trivial task. As the costs of running faulty\nalgorithms at scale can be severe, it is highly desirable to verify their\ncorrectness.\n  We propose to employ existing imperative reference implementations as\nspecifications for MapReduce implementations. To this end, we present a novel\nverification approach in which equivalence between an imperative and a\nMapReduce implementation is established by a series of program transformations.\n  In this paper, we present how the equivalence framework can be used to prove\nequivalence between an imperative implementation of the PageRank algorithm and\nits MapReduce variant. The eight individual transformation steps are\nindividually presented and explained.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 21:00:46 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Beckert", "Bernhard", "", "Karlsruhe Institute of Technology"], ["Bingmann", "Timo", "", "Karlsruhe Institute of Technology"], ["Kiefer", "Moritz", "", "Karlsruhe Institute of\n  Technology"], ["Sanders", "Peter", "", "Karlsruhe Institute of Technology"], ["Ulbrich", "Mattias", "", "Karlsruhe Institute of Technology"], ["Weigl", "Alexander", "", "Karlsruhe\n  Institute of Technology"]]}, {"id": "1803.10383", "submitter": "Mark Santolucito", "authors": "Bernd Finkbeiner, Felix Klein, Ruzica Piskac, Mark Santolucito", "title": "Vehicle Platooning Simulations with Functional Reactive Programming", "comments": "SCAV@CPSWeek 2017", "journal-ref": null, "doi": "10.1145/3055378.3055385", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Functional languages have provided major benefits to the verification\ncommunity. Although features such as purity, a strong type system, and\ncomputational abstractions can help guide programmers away from costly errors,\nthese can present challenges when used in a reactive system. Functional\nReactive Programming is a paradigm that allows users the benefits of functional\nlanguages and an easy interface to a reactive environment. We present a tool\nfor building autonomous vehicle controllers in FRP using Haskell.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 02:04:43 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Finkbeiner", "Bernd", ""], ["Klein", "Felix", ""], ["Piskac", "Ruzica", ""], ["Santolucito", "Mark", ""]]}, {"id": "1803.10670", "submitter": "Luca Padovani", "authors": "Luca Padovani (Universit\\`a di Torino, Italy)", "title": "Deadlock-Free Typestate-Oriented Programming", "comments": null, "journal-ref": "The Art, Science, and Engineering of Programming, 2018, Vol. 2,\n  Issue 3, Article 15", "doi": "10.22152/programming-journal.org/2018/2/15", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Context. TypeState-Oriented Programming (TSOP) is a paradigm intended to help\ndevelopers in the implementation and use of mutable objects whose public\ninterface depends on their private state. Under this paradigm, well-typed\nprograms are guaranteed to conform with the protocol of the objects they use.\n  Inquiry. Previous works have investigated TSOP for both sequential and\nconcurrent objects. However, an important difference between the two settings\nstill remains. In a sequential setting, a well-typed program either progresses\nindefinitely or terminates eventually. In a concurrent setting, protocol\nconformance is no longer enough to avoid deadlocks, a situation in which the\nexecution of the program halts because two or more objects are involved in\nmutual dependencies that prevent any further progress.\n  Approach. In this work, we put forward a refinement of TSOP for concurrent\nobjects guaranteeing that well-typed programs not only conform with the\nprotocol of the objects they use, but are also deadlock free. The key\ningredients of the type system are behavioral types, used to specify and\nenforce object protocols, and dependency relations, used to represent abstract\ndescriptions of the dependencies between objects and detect circularities that\nmight cause deadlocks.\n  Knowledge. The proposed approach stands out for two features. First, the\napproach is fully compositional and therefore scalable: the objects of a large\nprogram can be type checked in isolation; deadlock freedom of an object\ncomposition solely depends on the types of the objects being composed; any\nmodification/refactoring of an object that does not affect its public interface\ndoes not affect other objects either. Second, we provide the first deadlock\nanalysis technique for join patterns, a high-level concurrency abstraction with\nwhich programmers can express complex synchronizations in a succinct and\ndeclarative form.\n  Grounding. We detail the proposed typing discipline for a core programming\nlanguage blending concurrent objects, asynchronous message passing and join\npatterns. We prove that the type system is sound and give non-trivial examples\nof programs that can be successfully analyzed. A Haskell implementation of the\ntype system that demonstrates the feasibility of the approach is publicly\navailable.\n  Importance. The static analysis technique described in this work can be used\nto certify programs written in a core language for concurrent TSOP with proven\ncorrectness guarantees. This is an essential first step towards the integration\nand application of the technique in a real-world developer toolchain, making\nprogramming of such systems more productive and less frustrating.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 15:10:38 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Padovani", "Luca", "", "Universit\u00e0 di Torino, Italy"]]}, {"id": "1803.10831", "submitter": "Anthony Anjorin", "authors": "Anthony Anjorin (Paderborn University, Germany), Enes Yigitbas\n  (Paderborn University, Germany), Erhan Leblebici (TU Darmstadt, Germany),\n  Andy Sch\\\"urr (TU Darmstadt, Germany), Marius Lauder (Continental Automotive\n  GmbH, Germany, Germany), Martin Witte (Siemens AG, Germany)", "title": "Description Languages for Consistency Management Scenarios Based on\n  Examples from the Industry Automation Domain", "comments": null, "journal-ref": "The Art, Science, and Engineering of Programming, 2018, Vol. 2,\n  Issue 3, Article 7", "doi": "10.22152/programming-journal.org/2018/2/7", "report-no": null, "categories": "cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To cope with the increasing complexity of developing and maintaining modern\n(software) systems, multiple abstractions (models) of the same system can be\nestablished and used to allow different domain experts to collaborate and\ncontribute their respective expertise. This divide-and-conquer, model-based\napproach requires, however, support for a concurrent engineering process, i.e.,\nproviding a means of checking, restoring, and ensuring the consistency of all\ninvolved and concurrently maintained models. The task of providing such support\nis often referred to as consistency management.\n  Although there exist various approaches to consistency management and\nnumerous (industrial) case studies described in the literature on bidirectional\ntransformations (bx), there is currently no uniform description of diverse but\nrelated industrial applications of model synchronisation and other forms of\nconsistency management. This makes it challenging to detect similarities and\ndifferences related to requirements, constraints, applied techniques and tools.\nIt is thus difficult to compare and transfer knowledge gained from (successful)\nprojects to other bx approaches or even other bx tools for the same general\napproach.\n  In this paper, therefore, we propose a description language for envisioned\nscenarios in the problem domain of consistency management, as well as a\ncomplementary description language for solution strategies in terms of method\nfragments and method patterns in the solution domain of Model-Driven\nEngineering (MDE). Our work is inspired by previous research in the bx and MDE\ncommunities, and is also based on our collective experience from over ten years\nof investigating a series of application scenarios in the industry automation\nsection together with Siemens AG as an industrial partner. [Abridged due to\narXiv]\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 19:57:59 GMT"}], "update_date": "2018-03-30", "authors_parsed": [["Anjorin", "Anthony", "", "Paderborn University, Germany"], ["Yigitbas", "Enes", "", "Paderborn University, Germany"], ["Leblebici", "Erhan", "", "TU Darmstadt, Germany"], ["Sch\u00fcrr", "Andy", "", "TU Darmstadt, Germany"], ["Lauder", "Marius", "", "Continental Automotive\n  GmbH, Germany, Germany"], ["Witte", "Martin", "", "Siemens AG, Germany"]]}, {"id": "1803.11179", "submitter": "Benjamin Andreassen Bj{\\o}rnseth", "authors": "Benjamin Andreassen Bj{\\o}rnseth, Jan Christian Meyer, Lasse Natvig", "title": "Proof-of-Concept Examples of Performance-Transparent Programming Models", "comments": "Companion report to short-paper \"Make Software Harder\", to be\n  presented at Computing Frontiers 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine-specific optimizations command the machine to behave in a specific\nway. As current programming models largely leave machine details unexposed,\nthey cannot accommodate direct encoding of such commands. In previous work we\nhave proposed the design of performance-transparent programming models to\nfacilitate this use-case; this report contains proof-of-concept examples of\nsuch programming models. We demonstrate how programming model abstractions may\nreveal the memory footprint, vector unit utilization and data reuse of an\napplication, with prediction accuracy ranging from 0 to 25 \\%.\n", "versions": [{"version": "v1", "created": "Thu, 29 Mar 2018 17:51:18 GMT"}], "update_date": "2018-03-30", "authors_parsed": [["Bj\u00f8rnseth", "Benjamin Andreassen", ""], ["Meyer", "Jan Christian", ""], ["Natvig", "Lasse", ""]]}, {"id": "1803.11229", "submitter": "Bas van den Heuvel", "authors": "Bas van den Heuvel", "title": "The process of purely event-driven programs", "comments": "Supervisors: Dr. A. Ponse and Dr. ir. B. Diertens; 15 pages, 3\n  figures in appendix; Updated most process descriptions to the style of PSF.\n  Also fixed some design errors that came to light during testing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LO", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Using process algebra, this paper describes the formalisation of the\nprocess/semantics behind the purely event-driven programming language.\n", "versions": [{"version": "v1", "created": "Thu, 29 Mar 2018 19:30:49 GMT"}, {"version": "v2", "created": "Fri, 24 Aug 2018 19:34:30 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Heuvel", "Bas van den", ""]]}]