[{"id": "1905.00199", "submitter": "Tuly Hazbar", "authors": "Tuly Hazbar, Shitij Kumar and Ferat Sahin", "title": "Cyber-Physical Testbed for Human-Robot Collaborative Task Planning and\n  Execution", "comments": "(Draft V1)Submitted to Systems Man and Cybernetics SMC 2019 Corrected\n  typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a cyber-physical testbed created to enable a\nhuman-robot team to perform a shared task in a shared workspace. The testbed is\nsuitable for the implementation of a tabletop manipulation task, a common\nhuman-robot collaboration scenario. The testbed integrates elements that exist\nin the physical and virtual world. In this work, we report the insights we\ngathered throughout our exploration in understanding and implementing task\nplanning and execution for human-robot team.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 06:32:10 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 21:54:50 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Hazbar", "Tuly", ""], ["Kumar", "Shitij", ""], ["Sahin", "Ferat", ""]]}, {"id": "1905.00200", "submitter": "Alvaro Estandia", "authors": "Alvaro Estandia, Maximilian Schiffer, Federico Rossi, Justin Luke,\n  Emre Can Kara, Ram Rajagopal, Marco Pavone", "title": "On the Interaction between Autonomous Mobility on Demand Systems and\n  Power Distribution Networks -- An Optimal Power Flow Approach", "comments": "Version accepted by IEEE TCNS. Numerical results are unchanged.\n  However, much of the text was rewritten and the figures were redone to\n  improve clarity", "journal-ref": null, "doi": "10.1109/TCNS.2021.3059225", "report-no": null, "categories": "eess.SY cs.MA cs.RO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In future transportation systems, the charging behavior of electric\nAutonomous Mobility on Demand (AMoD) fleets, i.e., fleets of electric\nself-driving cars that service on-demand trip requests, will likely challenge\npower distribution networks (PDNs), causing overloads or voltage drops. In this\npaper, we show that these challenges can be significantly attenuated if the\nPDNs' operational constraints and exogenous loads (e.g., from homes or\nbusinesses) are accounted for when operating an electric AMoD fleet. We focus\non a system-level perspective, assuming full coordination between the AMoD and\nthe PDN operators. From this single entity perspective, we assess potential\ncoordination benefits. Specifically, we extend previous results on an\noptimization-based modeling approach for electric AMoD systems to jointly\ncontrol an electric AMoD fleet and a series of PDNs, and analyze the benefit of\ncoordination under load balancing constraints. For a case study of Orange\nCounty, CA, we show that the coordination between the electric AMoD fleet and\nthe PDNs eliminates 99% of the overloads and 50% of the voltage drops that the\nelectric AMoD fleet would cause in an uncoordinated setting. Our results show\nthat coordinating electric AMoD and PDNs can help maintain the reliability of\nPDNs under added electric AMoD charging load, thus significantly mitigating or\ndeferring the need for PDN capacity upgrades.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 06:43:05 GMT"}, {"version": "v2", "created": "Tue, 2 Feb 2021 04:47:23 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Estandia", "Alvaro", ""], ["Schiffer", "Maximilian", ""], ["Rossi", "Federico", ""], ["Luke", "Justin", ""], ["Kara", "Emre Can", ""], ["Rajagopal", "Ram", ""], ["Pavone", "Marco", ""]]}, {"id": "1905.00500", "submitter": "Marijan Vukosavljev", "authors": "Marijan Vukosavljev, Angela P. Schoellig, and Mireille E. Broucke", "title": "Hierarchically Consistent Motion Primitives for Quadrotor Coordination", "comments": "8 pages, 6 figures, video: http://tiny.cc/hier-moprim; submitted to\n  Conference on Decision and Control 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a hierarchical framework for motion planning of a large collection\nof agents. The proposed framework starts from low level motion primitives over\na gridded workspace and provides a set of rules for constructing higher level\nmotion primitives. Our hierarchical approach is highly scalable and robust\nmaking it an ideal tool for planning for multi-agent systems. Results are\ndemonstrated experimentally on a collection of quadrotors that must navigate a\ncluttered environment while maintaining a formation.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 21:16:55 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Vukosavljev", "Marijan", ""], ["Schoellig", "Angela P.", ""], ["Broucke", "Mireille E.", ""]]}, {"id": "1905.00629", "submitter": "Reshef Meir", "authors": "Reshef Meir, Ofra Amir, Omer Ben-Porat, Tsviel Ben-Shabat, Gal\n  Cohensius, Lirong Xia", "title": "General-Domain Truth Discovery via Average Proximity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Truth discovery is a general name for a broad range of statistical methods\naimed to extract the correct answers to questions, based on multiple answers\ncoming from noisy sources. For example, workers in a crowdsourcing platform. In\nthis paper, we suggest a simple heuristic for estimating workers' competence\nusing average proximity to other workers. We prove that this estimates well the\nactual competence level and enables separating high and low quality workers in\na wide spectrum of domains and statistical models.\n  We then design a simple proximity-based truth discovery algorithm (\\PTD) that\nweighs workers according to their average proximity. The answers for questions\nmay be of different forms such as real-valued, categorical, rankings, or other\ncomplex labels, and \\PTD can be combined with any existing aggregation function\nor voting rule to improve their accuracy.\n  We demonstrate through an extensive empirical study on real and synthetic\ndata that \\PTD and its iterative variants outperform other heuristics and\nstate-of-the-art truth discovery methods in the above domains.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 09:13:08 GMT"}, {"version": "v2", "created": "Thu, 20 Aug 2020 13:49:17 GMT"}, {"version": "v3", "created": "Mon, 15 Feb 2021 11:31:16 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Meir", "Reshef", ""], ["Amir", "Ofra", ""], ["Ben-Porat", "Omer", ""], ["Ben-Shabat", "Tsviel", ""], ["Cohensius", "Gal", ""], ["Xia", "Lirong", ""]]}, {"id": "1905.00719", "submitter": "Rongpeng Li", "authors": "Rongpeng Li, Zhifeng Zhao, Xing Xu, Fei Ni, and Honggang Zhang", "title": "Internet of Intelligence: The Collective Advantage for Advancing\n  Communications and Intelligence", "comments": "6 figures; accepted by IEEE Wireless Commun with the title \"The\n  Collective Advantage for Advancing Communications and Intelligence\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA cs.NI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The fifth-generation cellular networks (5G) has boosted the unprecedented\nconvergence between the information world and physical world. On the other\nhand, empowered with the enormous amount of data and information, artificial\nintelligence (AI) has been universally applied and pervasive AI is believed to\nbe an integral part of the six-generation cellular networks (6G). Consequently,\nbenefiting from the advancement in communication technology and AI, we boldly\nargue that the conditions for collective intelligence (CI) will be mature in\nthe 6G era and CI will emerge among the widely connected beings and things.\nAfterwards, we highlight the potential huge impact of CI on both communications\nand intelligence. In particular, we introduce a regular language (i.e., the\ninformation economy metalanguage) supporting the future collective\ncommunications to augment human intelligence and explain its potential\napplications in naming Internet information and pushing information centric\nnetworks forward. Meanwhile, we propose a stigmergy-based federated collective\nintelligence and demonstrate its achievement in a simulated scenario where the\nagents collectively work together to form a pattern through simple indirect\ncommunications. In a word, CI could advance both communications and\nintelligence.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 09:09:56 GMT"}, {"version": "v2", "created": "Sun, 5 May 2019 01:37:31 GMT"}, {"version": "v3", "created": "Thu, 9 May 2019 02:18:12 GMT"}, {"version": "v4", "created": "Sun, 12 May 2019 00:09:37 GMT"}, {"version": "v5", "created": "Thu, 10 Oct 2019 02:56:50 GMT"}, {"version": "v6", "created": "Thu, 16 Apr 2020 14:06:33 GMT"}, {"version": "v7", "created": "Sat, 18 Apr 2020 08:25:18 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Li", "Rongpeng", ""], ["Zhao", "Zhifeng", ""], ["Xu", "Xing", ""], ["Ni", "Fei", ""], ["Zhang", "Honggang", ""]]}, {"id": "1905.00810", "submitter": "Riccardo De Masellis", "authors": "Riccardo De Masellis and Valentin Goranko", "title": "Logic-based Specification and Verification of Homogeneous Dynamic\n  Multi-agent Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a logic-based framework for formal specification and algorithmic\nverification of homogeneous and dynamic concurrent multi-agent transition\nsystems (HDMAS). Homogeneity means that all agents have the same available\nactions at any given state and the actions have the same effects regardless of\nwhich agents perform them. The state transitions are therefore determined only\nby the vector of numbers of agents performing each action and are specified\nsymbolically, by means of conditions on these numbers definable in Presburger\narithmetic. The agents are divided into controllable (by the system\nsupervisor/controller) and uncontrollable, representing the environment or\nadversary. Dynamicity means that the numbers of controllable and uncontrollable\nagents may vary throughout the system evolution, possibly at every transition.\n  As a language for formal specification we use a suitably extended version of\nAlternating-time Temporal Logic (ATL), where one can specify properties of the\ntype \"a coalition of (at least) $n$ controllable agents can ensure against (at\nmost) $m$ uncontrollable agents that any possible evolution of the system\nsatisfies a given objective $\\varphi$\", where $\\varphi$ is specified again as a\nformula of that language and each of $n$ and $m$ is either a fixed number or a\nvariable that can be quantified over.\n  We provide formal semantics to our logic $\\mathcal{L}_{HDMAS}$ and define\nnormal form of its formulae. We then prove that every formula in\n$\\mathcal{L}_{HDMAS}$ is equivalent in the finite to one in a normal form and\ndevelop an algorithm for global model checking of formulae in normal form in\nfinite HDMAS models, which invokes model checking truth of Presburger formulae.\nWe establish worst case complexity estimates for the model checking algorithm\nand illustrate it on a running example.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 15:32:17 GMT"}, {"version": "v2", "created": "Tue, 15 Oct 2019 15:39:14 GMT"}, {"version": "v3", "created": "Fri, 21 Feb 2020 13:49:06 GMT"}, {"version": "v4", "created": "Thu, 19 Mar 2020 19:19:00 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["De Masellis", "Riccardo", ""], ["Goranko", "Valentin", ""]]}, {"id": "1905.00961", "submitter": "Fred Batty", "authors": "Fred Batty, Dmitry Kamenetsky", "title": "An Elo-based rating system for TopCoder SRM", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an Elo-based rating system for programming contests. We justify a\ndefinition of performance using the logarithm of a player's rank. We apply the\ndefinition to rating TopCoder SRM. We improve the accuracy, guided by\nexperimental results. We compare results with SRM ratings.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 02:01:40 GMT"}, {"version": "v2", "created": "Tue, 7 May 2019 14:15:00 GMT"}, {"version": "v3", "created": "Mon, 13 May 2019 15:18:37 GMT"}, {"version": "v4", "created": "Sun, 26 May 2019 17:10:41 GMT"}, {"version": "v5", "created": "Mon, 10 Feb 2020 16:22:55 GMT"}, {"version": "v6", "created": "Mon, 2 Mar 2020 09:25:35 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Batty", "Fred", ""], ["Kamenetsky", "Dmitry", ""]]}, {"id": "1905.00988", "submitter": "Liting Sun", "authors": "Liting Sun, Wei Zhan, Ching-Yao Chan and Masayoshi Tomizuka", "title": "Behavior Planning of Autonomous Cars with Social Perception", "comments": "To be appear on the 2019 IEEE Intelligent Vehicles Symposium (IV2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous cars have to navigate in dynamic environment which can be full of\nuncertainties. The uncertainties can come either from sensor limitations such\nas occlusions and limited sensor range, or from probabilistic prediction of\nother road participants, or from unknown social behavior in a new area. To\nsafely and efficiently drive in the presence of these uncertainties, the\ndecision-making and planning modules of autonomous cars should intelligently\nutilize all available information and appropriately tackle the uncertainties so\nthat proper driving strategies can be generated. In this paper, we propose a\nsocial perception scheme which treats all road participants as distributed\nsensors in a sensor network. By observing the individual behaviors as well as\nthe group behaviors, uncertainties of the three types can be updated uniformly\nin a belief space. The updated beliefs from the social perception are then\nexplicitly incorporated into a probabilistic planning framework based on Model\nPredictive Control (MPC). The cost function of the MPC is learned via inverse\nreinforcement learning (IRL). Such an integrated probabilistic planning module\nwith socially enhanced perception enables the autonomous vehicles to generate\nbehaviors which are defensive but not overly conservative, and socially\ncompatible. The effectiveness of the proposed framework is verified in\nsimulation on an representative scenario with sensor occlusions.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 22:45:26 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["Sun", "Liting", ""], ["Zhan", "Wei", ""], ["Chan", "Ching-Yao", ""], ["Tomizuka", "Masayoshi", ""]]}, {"id": "1905.01026", "submitter": "Shitij Kumar", "authors": "Celal Savur, Shitij Kumar, Sarthak Arora, Tuly Hazbar and Ferat Sahin", "title": "HRC-SoS: Human Robot Collaboration Experimentation Platform as System of\n  Systems", "comments": "(Accepted in SOSE 2019)", "journal-ref": null, "doi": "10.1109/SYSOSE.2019.8753881", "report-no": null, "categories": "cs.RO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an experimentation platform for human robot collaboration\nas a system of systems as well as proposes a conceptual framework describing\nthe aspects of Human Robot Collaboration. These aspects are Awareness,\nIntelligence and Compliance of the system. Based on this framework case studies\ndescribing experiment setups performed using this platform are discussed. Each\nexperiment highlights the use of the subsystems such as the digital twin,\nmotion capture system, human-physiological monitoring system, data collection\nsystem and robot control and interface systems. A highlight of this paper\nshowcases a subsystem with the ability to monitor human physiological feedback\nduring a human robot collaboration task.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 03:22:13 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Savur", "Celal", ""], ["Kumar", "Shitij", ""], ["Arora", "Sarthak", ""], ["Hazbar", "Tuly", ""], ["Sahin", "Ferat", ""]]}, {"id": "1905.01028", "submitter": "Qignrui Zhang", "authors": "Qingrui Zhang and Hugh H.T. Liu", "title": "Robust Cooperative Formation Control of Fixed-Wing Unmanned Aerial\n  Vehicles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust cooperative formation control is investigated in this paper for\nfixed-wing unmanned aerial vehicles in close formation flight to save energy. A\nnovel cooperative control method is developed. The concept of virtual structure\nis employed to resolve the difficulty in designing virtual leaders for a large\nnumber of UAVs in formation flight. To improve the transient performance,\ndesired trajectories are passed through a group of cooperative filters to\ngenerate smooth reference signals, namely the states of the virtual leaders.\nModel uncertainties due to aerodynamic couplings among UAVs are estimated and\ncompensated using uncertainty and disturbance observers. The entire design,\ntherefore, contains three major components: cooperative filters for motion\nplanning, baseline cooperative control, and uncertainty and disturbance\nobservation. The proposed formation controller could at least secure ultimate\nbounded control performance for formation tracking. If certain conditions are\nsatisfied, asymptotic formation tracking control could be obtained. Major\ncontributions of this paper lie in two aspects: 1) the difficulty in designing\nvirtual leaders is resolved in terms of the virtual structure concept; 2) a\nrobust cooperative controller is proposed for close formation flight of a large\nnumber of UAVs suffering from aerodynamic couplings in between. The efficiency\nof the proposed design will be demonstrated using numerical simulations of five\nUAVs in close formation flight.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 03:42:50 GMT"}, {"version": "v2", "created": "Mon, 6 May 2019 19:24:49 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Zhang", "Qingrui", ""], ["Liu", "Hugh H. T.", ""]]}, {"id": "1905.01140", "submitter": "Muhammad Umar Javed", "authors": "Muhammad U. Javed, Zaid Bin Tariq, Usama Muneeb, Ijaz Haider Naqvi", "title": "Multi-level Dynamic Optimization of Intelligent LEACH with Cost\n  Effective Deep Belief Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Energy utilization is a key attribute for energy constrained wireless sensor\nnetworks (WSN) that directly impacts the life time of the network. LEACH (and\nits variants) are considered to be the most common energy efficient routing\nprotocols for WSN. In this paper, we propose an optimized modification of LEACH\nthat makes use of multi-hop communication, dynamic cluster boundaries and\nenergy conservation in routing to maximize lifetime of a network. We propose a\nmulti-level approach to maximize our gains with regards to energy conservation\ni.e., i) Dynamic programming based intra-cluster optimization technique has\nbeen proposed ii) Ant Colony Optimization is used for energy efficient cluster\nhead connection with sink node and iii) Voronoi Tessellation are employed for\nefficient coverage planning i.e., dynamic formation of cluster boundaries. In\norder to accommodate a more flexible adhoc network, hybrid (reactive and\nproactive) event monitoring based on Deep Belief Network has been integrated in\ndistributed nodes to improve the latency of the system. The results show that\nthe proposed scheme significantly outperforms the current state of the art with\nregards to network lifetime and throughput.\n", "versions": [{"version": "v1", "created": "Fri, 12 Apr 2019 20:50:33 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["Javed", "Muhammad U.", ""], ["Tariq", "Zaid Bin", ""], ["Muneeb", "Usama", ""], ["Naqvi", "Ijaz Haider", ""]]}, {"id": "1905.01150", "submitter": "Can Zhao", "authors": "Yadong Xing, Can Zhao, ZhiHeng Li, Yi Zhang, Li Li, Fei-Yue Wang, Xiao\n  Wang, Yujing Wang, Yuelong Su, Dongpu Cao", "title": "A Right-of-Way Based Strategy to Implement Safe and Efficient Driving at\n  Non-Signalized Intersections for Automated Vehicles", "comments": "6 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-signalized intersection is a typical and common scenario for connected\nand automated vehicles (CAVs). How to balance safety and efficiency remains\ndifficult for researchers. To improve the original Responsibility Sensitive\nSafety (RSS) driving strategy on the non-signalized intersection, we propose a\nnew strategy in this paper, based on right-of-way assignment (RWA). The\nperformances of RSS strategy, cooperative driving strategy, and RWA based\nstrategy are tested and compared. Testing results indicate that our strategy\nyields better traffic efficiency than RSS strategy, but not satisfying as the\ncooperative driving strategy due to the limited range of communication and the\nlack of long-term planning. However, our new strategy requires much fewer\ncommunication costs among vehicles.\n", "versions": [{"version": "v1", "created": "Mon, 22 Apr 2019 05:11:20 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["Xing", "Yadong", ""], ["Zhao", "Can", ""], ["Li", "ZhiHeng", ""], ["Zhang", "Yi", ""], ["Li", "Li", ""], ["Wang", "Fei-Yue", ""], ["Wang", "Xiao", ""], ["Wang", "Yujing", ""], ["Su", "Yuelong", ""], ["Cao", "Dongpu", ""]]}, {"id": "1905.01303", "submitter": "Marc Brittain", "authors": "Marc Brittain, Peng Wei", "title": "Autonomous Air Traffic Controller: A Deep Multi-Agent Reinforcement\n  Learning Approach", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Air traffic control is a real-time safety-critical decision making process in\nhighly dynamic and stochastic environments. In today's aviation practice, a\nhuman air traffic controller monitors and directs many aircraft flying through\nits designated airspace sector. With the fast growing air traffic complexity in\ntraditional (commercial airliners) and low-altitude (drones and eVTOL aircraft)\nairspace, an autonomous air traffic control system is needed to accommodate\nhigh density air traffic and ensure safe separation between aircraft. We\npropose a deep multi-agent reinforcement learning framework that is able to\nidentify and resolve conflicts between aircraft in a high-density, stochastic,\nand dynamic en-route sector with multiple intersections and merging points. The\nproposed framework utilizes an actor-critic model, A2C that incorporates the\nloss function from Proximal Policy Optimization (PPO) to help stabilize the\nlearning process. In addition we use a centralized learning, decentralized\nexecution scheme where one neural network is learned and shared by all agents\nin the environment. We show that our framework is both scalable and efficient\nfor large number of incoming aircraft to achieve extremely high traffic\nthroughput with safety guarantee. We evaluate our model via extensive\nsimulations in the BlueSky environment. Results show that our framework is able\nto resolve 99.97% and 100% of all conflicts both at intersections and merging\npoints, respectively, in extreme high-density air traffic scenarios.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 21:03:27 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Brittain", "Marc", ""], ["Wei", "Peng", ""]]}, {"id": "1905.01357", "submitter": "Ercument Ilhan", "authors": "Erc\\\"ument \\.Ilhan, Jeremy Gow, Diego Perez-Liebana", "title": "Teaching on a Budget in Multi-Agent Deep Reinforcement Learning", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Reinforcement Learning (RL) algorithms can solve complex sequential\ndecision tasks successfully. However, they have a major drawback of having poor\nsample efficiency which can often be tackled by knowledge reuse. In Multi-Agent\nReinforcement Learning (MARL) this drawback becomes worse, but at the same\ntime, a new set of opportunities to leverage knowledge are also presented\nthrough agent interactions. One promising approach among these is peer-to-peer\naction advising through a teacher-student framework. Despite being introduced\nfor single-agent RL originally, recent studies show that it can also be applied\nto multi-agent scenarios with promising empirical results. However, studies in\nthis line of research are currently very limited. In this paper, we propose\nheuristics-based action advising techniques in cooperative decentralised MARL,\nusing a nonlinear function approximation based task-level policy. By adopting\nRandom Network Distillation technique, we devise a measurement for agents to\nassess their knowledge in any given state and be able to initiate the\nteacher-student dynamics with no prior role assumptions. Experimental results\nin a gridworld environment show that such an approach may indeed be useful and\nneeds to be further investigated.\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2019 04:22:09 GMT"}, {"version": "v2", "created": "Tue, 28 May 2019 23:08:07 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["\u0130lhan", "Erc\u00fcment", ""], ["Gow", "Jeremy", ""], ["Perez-Liebana", "Diego", ""]]}, {"id": "1905.01358", "submitter": "Sumanta Kumar Das Dr", "authors": "Sumanta Kumar Das and Sumant Mukherjee", "title": "Agent based decision making for Integrated Air Defense system", "comments": "8 pages,9 figure,2 tables", "journal-ref": "Journal of Battlefield Technology, 2011,vol 14,no 1", "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents algorithms of decision making agents for an integrated\nair defense (IAD) system. The advantage of using agent based over conventional\ndecision making system is its ability to automatically detect and track targets\nand if required allocate weapons to neutralize threat in an integrated mode.\nSuch approach is particularly useful for futuristic network centric warfare.\nTwo agents are presented here that perform the basic decisions making tasks of\ncommand and control (C2) like detection and action against jamming, threat\nassessment and weapons allocation, etc. The belief-desire-intension (BDI)\narchitectures stay behind the building blocks of these agents. These agents\ndecide their actions by meta level plan reasoning process. The proposed agent\nbased IAD system runs without any manual inputs, and represents a state of art\nmodel for C2 autonomy.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2019 11:16:34 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Das", "Sumanta Kumar", ""], ["Mukherjee", "Sumant", ""]]}, {"id": "1905.01360", "submitter": "Pablo Hernandez-Leal", "authors": "Chao Gao, Pablo Hernandez-Leal, Bilal Kartal and Matthew E. Taylor", "title": "Skynet: A Top Deep RL Agent in the Inaugural Pommerman Team Competition", "comments": "4th Multidisciplinary Conference on Reinforcement Learning and\n  Decision Making", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Pommerman Team Environment is a recently proposed benchmark which\ninvolves a multi-agent domain with challenges such as partial observability,\ndecentralized execution (without communication), and very sparse and delayed\nrewards. The inaugural Pommerman Team Competition held at NeurIPS 2018 hosted\n25 participants who submitted a team of 2 agents. Our submission\nnn_team_skynet955_skynet955 won 2nd place of the \"learning agents'' category.\nOur team is composed of 2 neural networks trained with state of the art deep\nreinforcement learning algorithms and makes use of concepts like reward\nshaping, curriculum learning, and an automatic reasoning module for action\npruning. Here, we describe these elements and additionally we present a\ncollection of open-sourced agents that can be used for training and testing in\nthe Pommerman environment. Code available at:\nhttps://github.com/BorealisAI/pommerman-baseline\n", "versions": [{"version": "v1", "created": "Sat, 20 Apr 2019 18:30:58 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Gao", "Chao", ""], ["Hernandez-Leal", "Pablo", ""], ["Kartal", "Bilal", ""], ["Taylor", "Matthew E.", ""]]}, {"id": "1905.01361", "submitter": "Abolghasem Daeichian", "authors": "Abolghasem Daeichian and Amir Haghani", "title": "Fuzzy Q-Learning Based Multi-Agent System for Intelligent Traffic\n  Control by a Game Theory Approach", "comments": "10 pages, 10 figures", "journal-ref": "Arabian Journal for Science and Engineering (2017): 1-7", "doi": "10.1007/s13369-017-3018-9", "report-no": null, "categories": "cs.MA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a multi-agent approach to adjust traffic lights based\non traffic situation in order to reduce average delay time. In the traffic\nmodel, lights of each intersection are controlled by an autonomous agent. Since\ndecision of each agent affects neighbor agents, this approach creates a\nclassical non-stationary environment. Thus, each agent not only needs to learn\nfrom the past experience but also has to consider decision of neighbors to\novercome dynamic changes of the traffic network. Fuzzy Q-learning and Game\ntheory are employed to make policy based on previous experiences and decision\nof neighbor agents. Simulation results illustrate the advantage of the proposed\nmethod over fixed time, fuzzy, Q-learning and fuzzy Q-learning control methods.\n", "versions": [{"version": "v1", "created": "Tue, 23 Apr 2019 14:20:44 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Daeichian", "Abolghasem", ""], ["Haghani", "Amir", ""]]}, {"id": "1905.01365", "submitter": "Carole Adam", "authors": "Julius Ba\\~ngate, Julie Dugdale (LIG Laboratoire d'Informatique de\n  Grenoble), Elise Beck (IV), Carole Adam (LIG, LIG Laboratoire d'Informatique\n  de Grenoble)", "title": "A multi-agent system approach in evaluating human spatio-temporal\n  vulnerability to seismic risk using social attachment", "comments": null, "journal-ref": "Risk Analysis and Hazard Mitigation, Jun 2018, Sevilla, Spain", "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social attachment theory states that individuals seek the proximity of\nattachment figures (e.g. family members, friends, colleagues, familiar places\nor objects) when faced with threat. During disasters, this means that family\nmembers may seek each other before evacuating, gather personal property before\nheading to familiar exits and places, or follow groups/crowds, etc. This\nhard-wired human tendency should be considered in the assessment of risk and\nthe creation of disaster management plans. Doing so may result in more\nrealistic evacuation procedures and may minimise the number of casualties and\ninjuries. In this context, a dynamic spatio-temporal analysis of seismic risk\nis presented using SOLACE, a multi-agent model of pedestrian behaviour based on\nsocial attachment theory implemented using the Belief-Desire-Intention\napproach. The model focuses on the influence of human, social, physical and\ntemporal factors on successful evacuation. Human factors considered include\nperception and mobility defined by age. Social factors are defined by\nattachment bonds, social groups, population distribution, and cultural norms.\nPhysical factors refer to the location of the epicentre of the earthquake,\nspatial distribution/layout and attributes of environmental objects such as\nbuildings, roads, barriers (cars), placement of safe areas, evacuation routes,\nand the resulting debris/damage from the earthquake. Experiments tested the\ninfluence of time of the day, presence of disabled persons and earthquake\nintensity. Initial results show that factors that influence arrivals in safe\nareas include (a) human factors (age, disability, speed), (b) pre-evacuation\nbehaviours, (c) perception distance (social attachment, time of day), (d)\nsocial interaction during evacuation, and (e) physical and spatial aspects,\nsuch as limitations imposed by debris (damage), and the distance to safe areas.\nTo validate the results, scenarios will be designed with stakeholders, who will\nalso take part in the definition of a serious game. The recommendation of this\nresearch is that both social and physical aspects should be considered when\ndefining vulnerability in the analysis of risk.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 13:12:13 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Ba\u00f1gate", "Julius", "", "LIG Laboratoire d'Informatique de\n  Grenoble"], ["Dugdale", "Julie", "", "LIG Laboratoire d'Informatique de\n  Grenoble"], ["Beck", "Elise", "", "IV"], ["Adam", "Carole", "", "LIG, LIG Laboratoire d'Informatique\n  de Grenoble"]]}, {"id": "1905.01882", "submitter": "Alexandros A. Voudouris", "authors": "Aris Filos-Ratsikas, Evi Micha, Alexandros A. Voudouris", "title": "The distortion of distributed voting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Voting can abstractly model any decision-making scenario and as such it has\nbeen extensively studied over the decades. Recently, the related literature has\nfocused on quantifying the impact of utilizing only limited information in the\nvoting process on the societal welfare for the outcome, by bounding the\ndistortion of voting rules. Even though there has been significant progress\ntowards this goal, all previous works have so far neglected the fact that in\nmany scenarios (like presidential elections) voting is actually a distributed\nprocedure. In this paper, we consider a setting in which the voters are\npartitioned into disjoint districts and vote locally therein to elect local\nwinning alternatives using a voting rule; the final outcome is then chosen from\nthe set of these alternatives. We prove tight bounds on the distortion of\nwell-known voting rules for such distributed elections both from a worst-case\nperspective as well as from a best-case one. Our results indicate that the\npartition of voters into districts leads to considerably higher distortion, a\nphenomenon which we also experimentally showcase using real-world data.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 08:42:46 GMT"}, {"version": "v2", "created": "Mon, 6 Jan 2020 10:48:20 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Filos-Ratsikas", "Aris", ""], ["Micha", "Evi", ""], ["Voudouris", "Alexandros A.", ""]]}, {"id": "1905.01990", "submitter": "Won-Yong Shin", "authors": "Cong Tran, Jang-Young Kim, Won-Yong Shin, Sang-Wook Kim", "title": "Clustering-Based Collaborative Filtering Using an Incentivized/Penalized\n  User Model", "comments": "12 pages, 4 figures, 6 tables, To appear in the IEEE Access", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG cs.MA cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Giving or recommending appropriate content based on the quality of experience\nis the most important and challenging issue in recommender systems. As\ncollaborative filtering (CF) is one of the most prominent and popular\ntechniques used for recommender systems, we propose a new clustering-based CF\n(CBCF) method using an incentivized/penalized user (IPU) model only with\nratings given by users, which is thus easy to implement. We aim to design such\na simple clustering-based approach with no further prior information while\nimproving the recommendation accuracy. To be precise, the purpose of CBCF with\nthe IPU model is to improve recommendation performance such as precision,\nrecall, and $F_1$ score by carefully exploiting different preferences among\nusers. Specifically, we formulate a constrained optimization problem, in which\nwe aim to maximize the recall (or equivalently $F_1$ score) for a given\nprecision. To this end, users are divided into several clusters based on the\nactual rating data and Pearson correlation coefficient. Afterwards, we give\neach item an incentive/penalty according to the preference tendency by users\nwithin the same cluster. Our experimental results show a significant\nperformance improvement over the baseline CF scheme without clustering in terms\nof recall or $F_1$ score for a given precision.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 06:47:36 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Tran", "Cong", ""], ["Kim", "Jang-Young", ""], ["Shin", "Won-Yong", ""], ["Kim", "Sang-Wook", ""]]}, {"id": "1905.02648", "submitter": "Sai Vemprala", "authors": "Sai Vemprala and Srikanth Saripalli", "title": "Collaborative Localization for Micro Aerial Vehicles", "comments": "Supplementary video at https://www.youtube.com/watch?v=LvaTOWuTOPo", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a framework for performing collaborative\nlocalization for groups of micro aerial vehicles (MAV) that use vision based\nsensing. The vehicles are each assumed to be equipped with a forward-facing\nmonocular camera, and to be capable of communicating with each other. This\ncollaborative localization approach is developed as a decentralized algorithm\nand built in a distributed fashion where individual and relative pose\nestimation techniques are combined for the group to localize against\nsurrounding environments. The MAVs initially detect and match salient features\nbetween each other to create a sparse reconstruction of the observed\nenvironment, which acts as a global map. Once a map is available, each MAV\nperforms feature detection and tracking with a robust outlier rejection process\nto estimate its own pose in 6 degrees of freedom. Occasionally, one or more\nMAVs can be tasked to compute poses for another MAV through relative\nmeasurements, which is achieved by exploiting multiple view geometry concepts.\nThese relative measurements are then fused with individual measurements in a\nconsistent fashion. We present the results of the algorithm on image data from\nMAV flights both in simulation and real life, and discuss the advantages of\ncollaborative localization in improving pose estimation accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 15:45:44 GMT"}, {"version": "v2", "created": "Mon, 11 May 2020 00:08:50 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Vemprala", "Sai", ""], ["Saripalli", "Srikanth", ""]]}, {"id": "1905.02907", "submitter": "Diddigi Raghuram Bharadwaj", "authors": "Raghuram Bharadwaj Diddigi, Sai Koti Reddy Danda, Prabuchandran K.J.,\n  Shalabh Bhatnagar", "title": "Actor-Critic Algorithms for Constrained Multi-agent Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In cooperative stochastic games multiple agents work towards learning joint\noptimal actions in an unknown environment to achieve a common goal. In many\nreal-world applications, however, constraints are often imposed on the actions\nthat can be jointly taken by the agents. In such scenarios the agents aim to\nlearn joint actions to achieve a common goal (minimizing a specified cost\nfunction) while meeting the given constraints (specified via certain penalty\nfunctions). In this paper, we consider the relaxation of the constrained\noptimization problem by constructing the Lagrangian of the cost and penalty\nfunctions. We propose a nested actor-critic solution approach to solve this\nrelaxed problem. In this approach, an actor-critic scheme is employed to\nimprove the policy for a given Lagrange parameter update on a faster timescale\nas in the classical actor-critic architecture. A meta actor-critic scheme using\nthis faster timescale policy updates is then employed to improve the Lagrange\nparameters on the slower timescale. Utilizing the proposed nested actor-critic\nschemes, we develop three Nested Actor-Critic (N-AC) algorithms. Through\nexperiments on constrained cooperative tasks, we show the effectiveness of the\nproposed algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 04:48:08 GMT"}, {"version": "v2", "created": "Sun, 12 Jul 2020 08:39:31 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Diddigi", "Raghuram Bharadwaj", ""], ["Danda", "Sai Koti Reddy", ""], ["J.", "Prabuchandran K.", ""], ["Bhatnagar", "Shalabh", ""]]}, {"id": "1905.03468", "submitter": "Mengmou Li", "authors": "Mengmou Li, Graziano Chesi, Yiguang Hong", "title": "Input-Feedforward-Passivity-Based Distributed Optimization Over Jointly\n  Connected Balanced Digraphs", "comments": "15 pages, 9 figures, accepted by IEEE Transactions on Automatic\n  Control", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a distributed optimization problem is investigated via input\nfeedforward passivity. First, an input-feedforward-passivity-based\ncontinuous-time distributed algorithm is proposed. It is shown that the error\nsystem of the proposed algorithm can be decomposed into a group of individual\ninput feedforward passive (IFP) systems that interact with each other using\noutput feedback information. Based on this IFP framework, convergence\nconditions of a suitable coupling gain are derived over weight-balanced and\nuniformly jointly strongly connected (UJSC) topologies. It is also shown that\nthe IFP-based algorithm converges exponentially when the topology is strongly\nconnected. Second, a novel distributed derivative feedback algorithm is\nproposed based on the passivation of IFP systems. While most works on directed\ntopologies require knowledge of eigenvalues of the graph Laplacian, the\nderivative feedback algorithm is fully distributed, namely, it is robust\nagainst randomly changing weight-balanced digraphs with any positive coupling\ngain and without knowing any global information. Finally, numerical examples\nare presented to illustrate the proposed distributed algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 07:18:31 GMT"}, {"version": "v2", "created": "Sun, 10 Nov 2019 08:40:29 GMT"}, {"version": "v3", "created": "Thu, 1 Oct 2020 06:20:14 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Li", "Mengmou", ""], ["Chesi", "Graziano", ""], ["Hong", "Yiguang", ""]]}, {"id": "1905.04006", "submitter": "Roee Mordechai Francos", "authors": "Roee M. Francos, Alfred M. Bruckstein", "title": "Search for Smart Evaders with Sweeping Agents", "comments": null, "journal-ref": null, "doi": "10.1017/S0263574721000291", "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suppose that in a given planar circular region, there are some smart mobile\nevaders and we would like to find them using sweeping agents. We assume that\nthe sweeping agents are in a line formation whose total length is 2r. We\npropose procedures for designing a sweeping process that ensures the successful\ncompletion of the task, thereby deriving conditions on the sweeping velocity of\nthe linear formation and its path. Successful completion of the task means that\nevaders with a given limit on their velocity cannot escape the sweeping agents.\nA simpler task for the sweeping formation is the confinement of the evaders to\ntheir initial domain. The feasibility of completing these tasks depends on\ngeometric and dynamic constraints that impose a lower bound on the velocity\nthat the sweeper line formation must have. This critical velocity is derived to\nensure the satisfaction of the confinement task. Increasing the velocity above\nthe lower bound enables the agents to complete the search task as well. We\npresent results on the total search time as a function of the sweeping velocity\nof the formation given the initial conditions on the size of the search region\nand the maximal velocity of the evaders.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 08:25:15 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 22:02:06 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Francos", "Roee M.", ""], ["Bruckstein", "Alfred M.", ""]]}, {"id": "1905.04077", "submitter": "Carsten Hahn", "authors": "Carsten Hahn, Thomy Phan, Thomas Gabor, Lenz Belzner, Claudia\n  Linnhoff-Popien", "title": "Emergent Escape-based Flocking Behavior using Multi-Agent Reinforcement\n  Learning", "comments": "Accepted at ALIFE 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In nature, flocking or swarm behavior is observed in many species as it has\nbeneficial properties like reducing the probability of being caught by a\npredator. In this paper, we propose SELFish (Swarm Emergent Learning Fish), an\napproach with multiple autonomous agents which can freely move in a continuous\nspace with the objective to avoid being caught by a present predator. The\npredator has the property that it might get distracted by multiple possible\npreys in its vicinity. We show that this property in interaction with\nself-interested agents which are trained with reinforcement learning to solely\nsurvive as long as possible leads to flocking behavior similar to Boids, a\ncommon simulation for flocking behavior. Furthermore we present interesting\ninsights in the swarming behavior and in the process of agents being caught in\nour modeled environment.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 11:30:20 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Hahn", "Carsten", ""], ["Phan", "Thomy", ""], ["Gabor", "Thomas", ""], ["Belzner", "Lenz", ""], ["Linnhoff-Popien", "Claudia", ""]]}, {"id": "1905.04083", "submitter": "Yuankai Wu", "authors": "Yuankai Wu, Huachun Tan, Zhuxi Jiang, Bin Ran", "title": "ES-CTC: A Deep Neuroevolution Model for Cooperative Intelligent Freeway\n  Traffic Control", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cooperative intelligent freeway traffic control is an important application\nin intelligent transportation systems, which is expected to improve the\nmobility of freeway networks. In this paper, we propose a deep neuroevolution\nmodel, called ES-CTC, to achieve a cooperative control scheme of ramp metering,\ndifferential variable speed limits and lane change control agents for improving\nfreeway traffic. In this model, the graph convolutional networks are used to\nlearn more meaningful spatial pattern from traffic sensors, a knowledge sharing\nlayer is designed for communication between different agents. The proposed\nneural networks structure allows different agents share knowledge with each\nother and execute action asynchronously. In order to address the delayed reward\nand action asynchronism issues, the evolutionary strategy is utilized to train\nthe agents under stochastic traffic demands. The experimental results on a\nsimulated freeway section indicate that ES-CTC is a viable approach and\noutperforms several existing methods\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 11:48:27 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Wu", "Yuankai", ""], ["Tan", "Huachun", ""], ["Jiang", "Zhuxi", ""], ["Ran", "Bin", ""]]}, {"id": "1905.04121", "submitter": "Nikolas Kantas", "authors": "Nikolas Kantas, Panos Parpas, Grigorios A. Pavliotis", "title": "The sharp, the flat and the shallow: Can weakly interacting agents learn\n  to escape bad minima?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An open problem in machine learning is whether flat minima generalize better\nand how to compute such minima efficiently. This is a very challenging problem.\nAs a first step towards understanding this question we formalize it as an\noptimization problem with weakly interacting agents. We review appropriate\nbackground material from the theory of stochastic processes and provide\ninsights that are relevant to practitioners. We propose an algorithmic\nframework for an extended stochastic gradient Langevin dynamics and illustrate\nits potential. The paper is written as a tutorial, and presents an alternative\nuse of multi-agent learning. Our primary focus is on the design of algorithms\nfor machine learning applications; however the underlying mathematical\nframework is suitable for the understanding of large scale systems of agent\nbased models that are popular in the social sciences, economics and finance.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 12:37:51 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Kantas", "Nikolas", ""], ["Parpas", "Panos", ""], ["Pavliotis", "Grigorios A.", ""]]}, {"id": "1905.04205", "submitter": "Sven Tomforde", "authors": "Stefan Rudolph, Sven Tomforde, J\\\"org H\\\"ahner", "title": "On the Detection of Mutual Influences and Their Consideration in\n  Reinforcement Learning Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-adaptation has been proposed as a mechanism to counter complexity in\ncontrol problems of technical systems. A major driver behind self-adaptation is\nthe idea to transfer traditional design-time decisions to runtime and into the\nresponsibility of systems themselves. In order to deal with unforeseen events\nand conditions, systems need creativity -- typically realized by means of\nmachine learning capabilities. Such learning mechanisms are based on different\nsources of knowledge. Feedback from the environment used for reinforcement\npurposes is probably the most prominent one within the self-adapting and\nself-organizing (SASO) systems community. However, the impact of other\n(sub-)systems on the success of the individual system's learning performance\nhas mostly been neglected in this context. In this article, we propose a novel\nmethodology to identify effects of actions performed by other systems in a\nshared environment on the utility achievement of an autonomous system. Consider\nsmart cameras (SC) as illustrating example: For goals such as 3D reconstruction\nof objects, the most promising configuration of one SC in terms of\npan/tilt/zoom parameters depends largely on the configuration of other SCs in\nthe vicinity. Since such mutual influences cannot be pre-defined for dynamic\nsystems, they have to be learned at runtime. Furthermore, they have to be taken\ninto consideration when self-improving the own configuration decisions based on\na feedback loop concept, e.g., known from the SASO domain or the Autonomic and\nOrganic Computing initiatives. We define a methodology to detect such\ninfluences at runtime, present an approach to consider this information in a\nreinforcement learning technique, and analyze the behavior in artificial as\nwell as real-world SASO system settings.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 15:04:48 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Rudolph", "Stefan", ""], ["Tomforde", "Sven", ""], ["H\u00e4hner", "J\u00f6rg", ""]]}, {"id": "1905.04232", "submitter": "Patrik Christen", "authors": "Patrik Christen and Olivier Del Fabbro", "title": "Automatic Programming of Cellular Automata and Artificial Neural\n  Networks Guided by Philosophy", "comments": "12 pages, 1 figure", "journal-ref": "Rolf Dornberger, editor, New Trends in Business Information\n  Systems and Technology: Digital Innovation and Digital Business\n  Transformation, pages 131-146. Springer, Cham, 2020", "doi": "10.1007/978-3-030-48332-6", "report-no": null, "categories": "cs.AI cs.LG cs.MA cs.NE cs.PL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Many computer models such as cellular automata and artificial neural networks\nhave been developed and successfully applied. However, in some cases, these\nmodels might be restrictive on the possible solutions or their solutions might\nbe difficult to interpret. To overcome this problem, we outline a new approach,\nthe so-called allagmatic method, that automatically programs and executes\nmodels with as little limitations as possible while maintaining human\ninterpretability. Earlier we described a metamodel and its building blocks\naccording to the philosophical concepts of structure (spatial dimension) and\noperation (temporal dimension). They are entity, milieu, and update function\nthat together abstractly describe cellular automata, artificial neural\nnetworks, and possibly any kind of computer model. By automatically combining\nthese building blocks in an evolutionary computation, interpretability might be\nincreased by the relationship to the metamodel, and models might be translated\ninto more interpretable models via the metamodel. We propose generic and\nobject-oriented programming to implement the entities and their milieus as\ndynamic and generic arrays and the update function as a method. We show two\nexperiments where a simple cellular automaton and an artificial neural network\nare automatically programmed, compiled, and executed. A target state is\nsuccessfully evolved and learned in the cellular automaton and artificial\nneural network, respectively. We conclude that the allagmatic method can create\nand execute cellular automaton and artificial neural network models in an\nautomated manner with the guidance of philosophy.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 16:00:09 GMT"}, {"version": "v2", "created": "Wed, 26 Jun 2019 14:03:51 GMT"}, {"version": "v3", "created": "Wed, 24 Jul 2019 10:06:41 GMT"}, {"version": "v4", "created": "Wed, 20 Nov 2019 08:47:05 GMT"}, {"version": "v5", "created": "Sun, 3 May 2020 21:05:20 GMT"}, {"version": "v6", "created": "Mon, 31 Aug 2020 21:45:47 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Christen", "Patrik", ""], ["Del Fabbro", "Olivier", ""]]}, {"id": "1905.04433", "submitter": "Manxi Wu", "authors": "Manxi Wu, and Saurabh Amin", "title": "Learning an Unknown Network State in Routing Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study learning dynamics induced by myopic travelers who repeatedly play a\nrouting game on a transportation network with an unknown state. The state\nimpacts cost functions of one or more edges of the network. In each stage,\ntravelers choose their routes according to Wardrop equilibrium based on public\nbelief of the state. This belief is broadcast by an information system that\nobserves the edge loads and realized costs on the used edges, and performs a\nBayesian update to the prior stage's belief. We show that the sequence of\npublic beliefs and edge load vectors generated by the repeated play converge\nalmost surely. In any rest point, travelers have no incentive to deviate from\nthe chosen routes and accurately learn the true costs on the used edges.\nHowever, the costs on edges that are not used may not be accurately learned.\nThus, learning can be incomplete in that the edge load vectors at rest point\nand complete information equilibrium can be different. We present some\nconditions for complete learning and illustrate situations when such an outcome\nis not guaranteed.\n", "versions": [{"version": "v1", "created": "Sat, 11 May 2019 03:04:22 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Wu", "Manxi", ""], ["Amin", "Saurabh", ""]]}, {"id": "1905.04532", "submitter": "James Bailey", "authors": "James P. Bailey, Georgios Piliouras", "title": "Fast and Furious Learning in Zero-Sum Games: Vanishing Regret with\n  Non-Vanishing Step Sizes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show for the first time, to our knowledge, that it is possible to\nreconcile in online learning in zero-sum games two seemingly contradictory\nobjectives: vanishing time-average regret and non-vanishing step sizes. This\nphenomenon, that we coin ``fast and furious\" learning in games, sets a new\nbenchmark about what is possible both in max-min optimization as well as in\nmulti-agent systems. Our analysis does not depend on introducing a carefully\ntailored dynamic. Instead we focus on the most well studied online dynamic,\ngradient descent. Similarly, we focus on the simplest textbook class of games,\ntwo-agent two-strategy zero-sum games, such as Matching Pennies. Even for this\nsimplest of benchmarks the best known bound for total regret, prior to our\nwork, was the trivial one of $O(T)$, which is immediately applicable even to a\nnon-learning agent. Based on a tight understanding of the geometry of the\nnon-equilibrating trajectories in the dual space we prove a regret bound of\n$\\Theta(\\sqrt{T})$ matching the well known optimal bound for adaptive step\nsizes in the online setting. This guarantee holds for all fixed step-sizes\nwithout having to know the time horizon in advance and adapt the fixed\nstep-size accordingly. As a corollary, we establish that even with fixed\nlearning rates the time-average of mixed strategies, utilities converge to\ntheir exact Nash equilibrium values.\n", "versions": [{"version": "v1", "created": "Sat, 11 May 2019 14:34:24 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Bailey", "James P.", ""], ["Piliouras", "Georgios", ""]]}, {"id": "1905.04835", "submitter": "Hossein K. Mousavi", "authors": "Hossein K. Mousavi, Mohammadreza Nazari, Martin Tak\\'a\\v{c}, Nader\n  Motee", "title": "Multi-Agent Image Classification via Reinforcement Learning", "comments": "Preprint of the paper to be published in IROS'19 proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.MA cs.RO cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate a classification problem using multiple mobile agents capable\nof collecting (partial) pose-dependent observations of an unknown environment.\nThe objective is to classify an image over a finite time horizon. We propose a\nnetwork architecture on how agents should form a local belief, take local\nactions, and extract relevant features from their raw partial observations.\nAgents are allowed to exchange information with their neighboring agents to\nupdate their own beliefs. It is shown how reinforcement learning techniques can\nbe utilized to achieve decentralized implementation of the classification\nproblem by running a decentralized consensus protocol. Our experimental results\non the MNIST handwritten digit dataset demonstrates the effectiveness of our\nproposed framework.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 02:24:19 GMT"}, {"version": "v2", "created": "Tue, 6 Aug 2019 17:16:22 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Mousavi", "Hossein K.", ""], ["Nazari", "Mohammadreza", ""], ["Tak\u00e1\u010d", "Martin", ""], ["Motee", "Nader", ""]]}, {"id": "1905.04840", "submitter": "Michael Crosscombe", "authors": "Michael Crosscombe, Jonathan Lawry, Palina Bartashevich", "title": "Evidence Propagation and Consensus Formation in Noisy Environments", "comments": "13th international conference on Scalable Uncertainty Management", "journal-ref": null, "doi": "10.1007/978-3-030-35514-2", "report-no": null, "categories": "cs.MA cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the effectiveness of consensus formation in multi-agent systems\nwhere there is both belief updating based on direct evidence and also belief\ncombination between agents. In particular, we consider the scenario in which a\npopulation of agents collaborate on the best-of-n problem where the aim is to\nreach a consensus about which is the best (alternatively, true) state from\namongst a set of states, each with a different quality value (or level of\nevidence). Agents' beliefs are represented within Dempster-Shafer theory by\nmass functions and we investigate the macro-level properties of four well-known\nbelief combination operators for this multi-agent consensus formation problem:\nDempster's rule, Yager's rule, Dubois & Prade's operator and the averaging\noperator. The convergence properties of the operators are considered and\nsimulation experiments are conducted for different evidence rates and noise\nlevels. Results show that a combination of updating on direct evidence and\nbelief combination between agents results in better consensus to the best state\nthan does evidence updating alone. We also find that in this framework the\noperators are robust to noise. Broadly, Yager's rule is shown to be the better\noperator under various parameter values, i.e. convergence to the best state,\nrobustness to noise, and scalability.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 02:57:59 GMT"}, {"version": "v2", "created": "Mon, 20 Jan 2020 15:04:30 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Crosscombe", "Michael", ""], ["Lawry", "Jonathan", ""], ["Bartashevich", "Palina", ""]]}, {"id": "1905.04859", "submitter": "Keisuke Fujii", "authors": "Keisuke Fujii, Naoya Takeishi, Motokazu Hojo, Yuki Inaba and Yoshinobu\n  Kawahara", "title": "Physically-interpretable classification of biological network dynamics\n  for complex collective motions", "comments": "42 pages with 7 figures and 3 tables. The latest version is published\n  in Scientific Reports, 2020", "journal-ref": "Scientific Reports, 10, 3005, 2020", "doi": null, "report-no": null, "categories": "cs.MA cs.LG cs.SI math.DS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Understanding biological network dynamics is a fundamental issue in various\nscientific and engineering fields. Network theory is capable of revealing the\nrelationship between elements and their propagation; however, for complex\ncollective motions, the network properties often transiently and complexly\nchange. A fundamental question addressed here pertains to the classification of\ncollective motion network based on physically-interpretable dynamical\nproperties. Here we apply a data-driven spectral analysis called graph dynamic\nmode decomposition, which obtains the dynamical properties for collective\nmotion classification. Using a ballgame as an example, we classified the\nstrategic collective motions in different global behaviours and discovered\nthat, in addition to the physical properties, the contextual node information\nwas critical for classification. Furthermore, we discovered the label-specific\nstronger spectra in the relationship among the nearest agents, providing\nphysical and semantic interpretations. Our approach contributes to the\nunderstanding of principles of biological complex network dynamics from the\nperspective of nonlinear dynamical systems.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 04:54:59 GMT"}, {"version": "v2", "created": "Sat, 13 Jun 2020 23:04:14 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Fujii", "Keisuke", ""], ["Takeishi", "Naoya", ""], ["Hojo", "Motokazu", ""], ["Inaba", "Yuki", ""], ["Kawahara", "Yoshinobu", ""]]}, {"id": "1905.04910", "submitter": "Warut Suksompong", "authors": "Xiaohui Bei, Xinhang Lu, Pasin Manurangsi, Warut Suksompong", "title": "The Price of Fairness for Indivisible Goods", "comments": "A preliminary version appears in the 28th International Joint\n  Conference on Artificial Intelligence (IJCAI), 2019", "journal-ref": null, "doi": "10.1007/s00224-021-10039-8", "report-no": null, "categories": "cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the efficiency of fair allocations of indivisible goods using\nthe well-studied price of fairness concept. Previous work has focused on\nclassical fairness notions such as envy-freeness, proportionality, and\nequitability. However, these notions cannot always be satisfied for indivisible\ngoods, leading to certain instances being ignored in the analysis. In this\npaper, we focus instead on notions with guaranteed existence, including\nenvy-freeness up to one good (EF1), balancedness, maximum Nash welfare (MNW),\nand leximin. We also introduce the concept of strong price of fairness, which\ncaptures the efficiency loss in the worst fair allocation as opposed to that in\nthe best fair allocation as in the price of fairness. We mostly provide tight\nor asymptotically tight bounds on the worst-case efficiency loss for\nallocations satisfying these notions, for both the price of fairness and the\nstrong price of fairness.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 08:43:26 GMT"}, {"version": "v2", "created": "Thu, 25 Mar 2021 01:14:30 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Bei", "Xiaohui", ""], ["Lu", "Xinhang", ""], ["Manurangsi", "Pasin", ""], ["Suksompong", "Warut", ""]]}, {"id": "1905.04926", "submitter": "David Balduzzi", "authors": "Alistair Letcher and David Balduzzi and Sebastien Racaniere and James\n  Martens and Jakob Foerster and Karl Tuyls and Thore Graepel", "title": "Differentiable Game Mechanics", "comments": "JMLR 2019, journal version of arXiv:1802.05642", "journal-ref": "Journal of Machine Learning Research (JMLR), v20 (84) 1-40, 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.GT cs.MA cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning is built on the foundational guarantee that gradient descent on\nan objective function converges to local minima. Unfortunately, this guarantee\nfails in settings, such as generative adversarial nets, that exhibit multiple\ninteracting losses. The behavior of gradient-based methods in games is not well\nunderstood -- and is becoming increasingly important as adversarial and\nmulti-objective architectures proliferate. In this paper, we develop new tools\nto understand and control the dynamics in n-player differentiable games.\n  The key result is to decompose the game Jacobian into two components. The\nfirst, symmetric component, is related to potential games, which reduce to\ngradient descent on an implicit function. The second, antisymmetric component,\nrelates to Hamiltonian games, a new class of games that obey a conservation law\nakin to conservation laws in classical mechanical systems. The decomposition\nmotivates Symplectic Gradient Adjustment (SGA), a new algorithm for finding\nstable fixed points in differentiable games. Basic experiments show SGA is\ncompetitive with recently proposed algorithms for finding stable fixed points\nin GANs -- while at the same time being applicable to, and having guarantees\nin, much more general cases.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 09:21:08 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Letcher", "Alistair", ""], ["Balduzzi", "David", ""], ["Racaniere", "Sebastien", ""], ["Martens", "James", ""], ["Foerster", "Jakob", ""], ["Tuyls", "Karl", ""], ["Graepel", "Thore", ""]]}, {"id": "1905.04964", "submitter": "Theodor Cimpeanu", "authors": "Theodor Cimpeanu, The Anh Han, Francisco C. Santos", "title": "Exogenous Rewards for Promoting Cooperation in Scale-Free Networks", "comments": "8 pages, 5 figures, to appear in the Proceedings of the Artifical\n  Life Conference 2019, 29 July - 2 August 2019, Newcastle, England", "journal-ref": null, "doi": "10.1162/isal_a_00181", "report-no": null, "categories": "cs.GT cs.MA cs.SI econ.TH physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The design of mechanisms that encourage pro-social behaviours in populations\nof self-regarding agents is recognised as a major theoretical challenge within\nseveral areas of social, life and engineering sciences. When interference from\nexternal parties is considered, several heuristics have been identified as\ncapable of engineering a desired collective behaviour at a minimal cost.\nHowever, these studies neglect the diverse nature of contexts and social\nstructures that characterise real-world populations. Here we analyse the impact\nof diversity by means of scale-free interaction networks with high and low\nlevels of clustering, and test various interference mechanisms using\nsimulations of agents facing a cooperative dilemma. Our results show that\ninterference on scale-free networks is not trivial and that distinct levels of\nclustering react differently to each interference mechanism. As such, we argue\nthat no tailored response fits all scale-free networks and present which\nmechanisms are more efficient at fostering cooperation in both types of\nnetworks. Finally, we discuss the pitfalls of considering reckless interference\nmechanisms.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 10:57:38 GMT"}, {"version": "v2", "created": "Fri, 17 May 2019 17:32:22 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Cimpeanu", "Theodor", ""], ["Han", "The Anh", ""], ["Santos", "Francisco C.", ""]]}, {"id": "1905.05217", "submitter": "Huichu Zhang", "authors": "Huichu Zhang, Siyuan Feng, Chang Liu, Yaoyao Ding, Yichen Zhu, Zihan\n  Zhou, Weinan Zhang, Yong Yu, Haiming Jin, Zhenhui Li", "title": "CityFlow: A Multi-Agent Reinforcement Learning Environment for Large\n  Scale City Traffic Scenario", "comments": "WWW 2019 Demo Paper", "journal-ref": null, "doi": "10.1145/3308558.3314139", "report-no": null, "categories": "cs.MA cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traffic signal control is an emerging application scenario for reinforcement\nlearning. Besides being as an important problem that affects people's daily\nlife in commuting, traffic signal control poses its unique challenges for\nreinforcement learning in terms of adapting to dynamic traffic environment and\ncoordinating thousands of agents including vehicles and pedestrians. A key\nfactor in the success of modern reinforcement learning relies on a good\nsimulator to generate a large number of data samples for learning. The most\ncommonly used open-source traffic simulator SUMO is, however, not scalable to\nlarge road network and large traffic flow, which hinders the study of\nreinforcement learning on traffic scenarios. This motivates us to create a new\ntraffic simulator CityFlow with fundamentally optimized data structures and\nefficient algorithms. CityFlow can support flexible definitions for road\nnetwork and traffic flow based on synthetic and real-world data. It also\nprovides user-friendly interface for reinforcement learning. Most importantly,\nCityFlow is more than twenty times faster than SUMO and is capable of\nsupporting city-wide traffic simulation with an interactive render for\nmonitoring. Besides traffic signal control, CityFlow could serve as the base\nfor other transportation studies and can create new possibilities to test\nmachine learning methods in the intelligent transportation domain.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 18:07:41 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Zhang", "Huichu", ""], ["Feng", "Siyuan", ""], ["Liu", "Chang", ""], ["Ding", "Yaoyao", ""], ["Zhu", "Yichen", ""], ["Zhou", "Zihan", ""], ["Zhang", "Weinan", ""], ["Yu", "Yong", ""], ["Jin", "Haiming", ""], ["Li", "Zhenhui", ""]]}, {"id": "1905.05408", "submitter": "Kyunghwan Son", "authors": "Kyunghwan Son, Daewoo Kim, Wan Ju Kang, David Earl Hostallero, Yung Yi", "title": "QTRAN: Learning to Factorize with Transformation for Cooperative\n  Multi-Agent Reinforcement Learning", "comments": "18 pages; Accepted to ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore value-based solutions for multi-agent reinforcement learning\n(MARL) tasks in the centralized training with decentralized execution (CTDE)\nregime popularized recently. However, VDN and QMIX are representative examples\nthat use the idea of factorization of the joint action-value function into\nindividual ones for decentralized execution. VDN and QMIX address only a\nfraction of factorizable MARL tasks due to their structural constraint in\nfactorization such as additivity and monotonicity. In this paper, we propose a\nnew factorization method for MARL, QTRAN, which is free from such structural\nconstraints and takes on a new approach to transforming the original joint\naction-value function into an easily factorizable one, with the same optimal\nactions. QTRAN guarantees more general factorization than VDN or QMIX, thus\ncovering a much wider class of MARL tasks than does previous methods. Our\nexperiments for the tasks of multi-domain Gaussian-squeeze and modified\npredator-prey demonstrate QTRAN's superior performance with especially larger\nmargins in games whose payoffs penalize non-cooperative behavior more\naggressively.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 06:29:51 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Son", "Kyunghwan", ""], ["Kim", "Daewoo", ""], ["Kang", "Wan Ju", ""], ["Hostallero", "David Earl", ""], ["Yi", "Yung", ""]]}, {"id": "1905.05717", "submitter": "Hua Wei", "authors": "Hua Wei, Nan Xu, Huichu Zhang, Guanjie Zheng, Xinshi Zang, Chacha\n  Chen, Weinan Zhang, Yanmin Zhu, Kai Xu, Zhenhui Li", "title": "CoLight: Learning Network-level Cooperation for Traffic Signal Control", "comments": "10 pages. Proceedings of the 28th ACM International on Conference on\n  Information and Knowledge Management. ACM, 2018", "journal-ref": null, "doi": "10.1145/3357384.3357902", "report-no": null, "categories": "cs.MA cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cooperation among the traffic signals enables vehicles to move through\nintersections more quickly. Conventional transportation approaches implement\ncooperation by pre-calculating the offsets between two intersections. Such\npre-calculated offsets are not suitable for dynamic traffic environments. To\nenable cooperation of traffic signals, in this paper, we propose a model,\nCoLight, which uses graph attentional networks to facilitate communication.\nSpecifically, for a target intersection in a network, CoLight can not only\nincorporate the temporal and spatial influences of neighboring intersections to\nthe target intersection, but also build up index-free modeling of neighboring\nintersections. To the best of our knowledge, we are the first to use graph\nattentional networks in the setting of reinforcement learning for traffic\nsignal control and to conduct experiments on the large-scale road network with\nhundreds of traffic signals. In experiments, we demonstrate that by learning\nthe communication, the proposed model can achieve superior performance against\nthe state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sat, 11 May 2019 17:26:11 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2019 09:17:57 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Wei", "Hua", ""], ["Xu", "Nan", ""], ["Zhang", "Huichu", ""], ["Zheng", "Guanjie", ""], ["Zang", "Xinshi", ""], ["Chen", "Chacha", ""], ["Zhang", "Weinan", ""], ["Zhu", "Yanmin", ""], ["Xu", "Kai", ""], ["Li", "Zhenhui", ""]]}, {"id": "1905.06449", "submitter": "Nathaniel Tucker", "authors": "Nathaniel Tucker, Bryce Ferguson, Mahnoosh Alizadeh", "title": "An Online Pricing Mechanism for Electric Vehicle Parking Assignment and\n  Charge Scheduling", "comments": "6 pages, 2 figures. To Appear, ACC 2019, Philadelphia, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we design a pricing framework for online electric vehicle (EV)\nparking assignment and charge scheduling. Here, users with electric vehicles\nwant to park and charge at electric-vehicle-supply-equipment (EVSEs) at\ndifferent locations and arrive/depart throughout the day. The goal is to assign\nand schedule users to the available EVSEs while maximizing user utility and\nminimizing operational costs. Our formulation can accommodate multiple\nlocations, limited resources, operational costs, as well as variable arrival\npatterns. With this formulation, the parking facility management can optimize\nfor behind-the-meter solar integration and reduce costs due to procuring\nelectricity from the grid. We use an online pricing mechanism to approximate\nthe EVSE reservation problem's solution and we analyze the performance compared\nto the offline solution. Our numerical simulation validates the performance of\nthe EVSE reservation system in a downtown area with multiple parking locations\nequipped with EVSEs.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 21:54:55 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Tucker", "Nathaniel", ""], ["Ferguson", "Bryce", ""], ["Alizadeh", "Mahnoosh", ""]]}, {"id": "1905.06716", "submitter": "Julie Dugdale", "authors": "Antoine Flepp, Julie Dugdale, Fabrice Bourge, Tiphaine Marie-Cardot", "title": "A Method to Discover Digital Collaborative Conversations in Business\n  Collaborations", "comments": null, "journal-ref": "10th International Joint Conference on Knowledge Discovery,\n  Knowledge Engineering and Knowledge Management, May 2018, Seville, Spain", "doi": null, "report-no": null, "categories": "cs.HC cs.CY cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many companies have a suite of digital tools, such as Enterprise Social\nNetworks, conferencing and document sharing software, and email, to facilitate\ncollaboration among employees. During, or at the end of a collaboration,\ndocuments are often produced. People who were not involved in the initial\ncollaboration often have difficulties understanding parts of its content\nbecause they are lacking the overall context. We argue there is valuable\ncontextual and collaborative knowledge contained in these tools (content and\nuse) that can be used to understand the document. Our goal is to rebuild the\nconversations that took place over a messaging service and their links with a\ndigital conferencing tool during document production. The novelty in our\napproach is to combine several conversation-threading methods to identify\ninteresting links between distinct conversations. Specifically we combine\nheader-field information with social, temporal and semantic proximities. Our\nfindings suggest the messaging service and conferencing tool are used in a\ncomplementary way. The primary results confirm that combining different\nconversation threading approaches is efficient to detect and construct\nconversation threads from distinct digital conversations concerning the same\ndocument.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 12:21:47 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Flepp", "Antoine", ""], ["Dugdale", "Julie", ""], ["Bourge", "Fabrice", ""], ["Marie-Cardot", "Tiphaine", ""]]}, {"id": "1905.06853", "submitter": "Tin Leelavimolsilp", "authors": "Tin Leelavimolsilp, Long Tran-Thanh, Sebastian Stein, Viet Hung Nguyen", "title": "Selfish Mining in Proof-of-Work Blockchain with Multiple Miners: An\n  Empirical Evaluation", "comments": "Accepted in PRIMA2019", "journal-ref": null, "doi": "10.1007/978-3-030-33792-6_14", "report-no": null, "categories": "cs.CR cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Proof-of-Work blockchain, despite its numerous benefits, is still not an\nentirely secure technology due to the existence of Selfish Mining (SM)\nstrategies that can disrupt the system and its mining economy. While the effect\nof SM has been studied mostly in a two-miners scenario, it has not been\ninvestigated in a more practical context where there are multiple malicious\nminers individually performing SM.\n  To fill this gap, we carry out an empirical study that separately accounts\nfor different numbers of SM miners (who always perform SM) and strategic miners\n(who choose either SM or Nakamoto's mining protocol depending on which\nmaximises their individual mining reward).\n  Our result shows that SM is generally more effective as the number of SM\nminers increases, however its effectiveness does not vary in the presence of a\nlarge number of strategic miners. Under specific mining power distributions, we\nalso demonstrate that multiple miners can perform SM and simultaneously gain\nhigher mining rewards than they should. Surprisingly, we also show that the\nmore strategic miners there are, the more robust the systems become. Since\nblockchain miners should naturally be seen as self-interested strategic miners,\nour findings encourage blockchain system developers and engineers to attract as\nmany miners as possible to prevent SM and similar behaviour.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 13:35:15 GMT"}, {"version": "v2", "created": "Sun, 6 Oct 2019 14:04:53 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Leelavimolsilp", "Tin", ""], ["Tran-Thanh", "Long", ""], ["Stein", "Sebastian", ""], ["Nguyen", "Viet Hung", ""]]}, {"id": "1905.07696", "submitter": "Guido Governatori", "authors": "Guido Governatori and Antonino Rotolo", "title": "Is Free Choice Permission Admissible in Classical Deontic Logic?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we explore how, and if, free choice permission (FCP) can be\naccepted when we consider deontic conflicts between certain types of\npermissions and obligations. As is well known, FCP can license, under some\nminimal conditions, the derivation of an indefinite number of permissions. We\ndiscuss this and other drawbacks and present six Hilbert-style classical\ndeontic systems admitting a guarded version of FCP. The systems that we present\nare not too weak from the inferential viewpoint, as far as permission is\nconcerned, and do not commit to weakening any specific logic for obligations.\n", "versions": [{"version": "v1", "created": "Sun, 19 May 2019 07:15:10 GMT"}, {"version": "v2", "created": "Mon, 10 Jun 2019 14:46:08 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Governatori", "Guido", ""], ["Rotolo", "Antonino", ""]]}, {"id": "1905.08036", "submitter": "Anton Kolonin Dr.", "authors": "Anton Kolonin, Ben Goertzel, Cassio Pennachin, Deborah Duong, Matt\n  Ikle, Nejc Znidar and Marco Argentieri", "title": "A Reputation System for Multi-Agent Marketplaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an exploration of a reputation system based on explicit ratings\nweighted by the values of corresponding financial transactions from the\nperspective of its ability to grant \"security\" to market participants by\nprotecting them from scam and \"equity\" in terms of having real qualities of the\nparticipants correctly assessed. We present a simulation modeling approach\nbased on the selected reputation system and discuss the results of the\nsimulation.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 03:44:56 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Kolonin", "Anton", ""], ["Goertzel", "Ben", ""], ["Pennachin", "Cassio", ""], ["Duong", "Deborah", ""], ["Ikle", "Matt", ""], ["Znidar", "Nejc", ""], ["Argentieri", "Marco", ""]]}, {"id": "1905.08041", "submitter": "Rui Portocarrero Sarmento MSc", "authors": "Rui Portocarrero Sarmento", "title": "Inventory Management - A Case Study with NetLogo", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-Agent Systems (MAS) have been applied to several areas or tasks ranging\nfrom energy networks controlling to robot soccer teams. MAS are the ideal\nsolution when they provide decision support in situations where human decision\nand actions are not feasible to operate the system in control and in real-time.\nThus, we present a case study that is related to dynamic simulation of an\nautomatic inventory management system. We provide two types of agents, the\nclients, and the seller agents. Through a system of communication, the agents\nexchange messages to fulfill their inventory needs. The client agents trade\nproducts in quantities according to their needs and rely on seller agents if\nother clients in the retailer chain cannot provide the needed items.\nAdditionally, it is expected that the trading between a client and the sellers\nis done through a reverted type of auction. This case study MAS uses BDI and\nFIPA-ACL in its implementation resulting in a clear simulation of the system.\nWe expect to provide a comparison between two distinct situations. One with\nonly external transactions with providers, and a situation where both internal\nand external transactions are allowed.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 09:33:03 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Sarmento", "Rui Portocarrero", ""]]}, {"id": "1905.08085", "submitter": "Jianyi Wang", "authors": "Yuhang Song, Andrzej Wojcicki, Thomas Lukasiewicz, Jianyi Wang, Abi\n  Aryan, Zhenghua Xu, Mai Xu, Zihan Ding, Lianlong Wu", "title": "Arena: A General Evaluation Platform and Building Toolkit for\n  Multi-Agent Intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning agents that are not only capable of taking tests, but also\ninnovating is becoming a hot topic in AI. One of the most promising paths\ntowards this vision is multi-agent learning, where agents act as the\nenvironment for each other, and improving each agent means proposing new\nproblems for others. However, existing evaluation platforms are either not\ncompatible with multi-agent settings, or limited to a specific game. That is,\nthere is not yet a general evaluation platform for research on multi-agent\nintelligence. To this end, we introduce Arena, a general evaluation platform\nfor multi-agent intelligence with 35 games of diverse logics and\nrepresentations. Furthermore, multi-agent intelligence is still at the stage\nwhere many problems remain unexplored. Therefore, we provide a building toolkit\nfor researchers to easily invent and build novel multi-agent problems from the\nprovided game set based on a GUI-configurable social tree and five basic\nmulti-agent reward schemes. Finally, we provide Python implementations of five\nstate-of-the-art deep multi-agent reinforcement learning baselines. Along with\nthe baseline implementations, we release a set of 100 best agents/teams that we\ncan train with different training schemes for each game, as the base for\nevaluating agents with population performance. As such, the research community\ncan perform comparisons under a stable and uniform standard. All the\nimplementations and accompanied tutorials have been open-sourced for the\ncommunity at https://sites.google.com/view/arena-unity/.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 14:27:25 GMT"}, {"version": "v2", "created": "Fri, 24 May 2019 01:46:20 GMT"}, {"version": "v3", "created": "Thu, 30 May 2019 03:41:14 GMT"}, {"version": "v4", "created": "Sat, 8 Jun 2019 15:16:08 GMT"}, {"version": "v5", "created": "Thu, 28 Nov 2019 03:39:46 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Song", "Yuhang", ""], ["Wojcicki", "Andrzej", ""], ["Lukasiewicz", "Thomas", ""], ["Wang", "Jianyi", ""], ["Aryan", "Abi", ""], ["Xu", "Zhenghua", ""], ["Xu", "Mai", ""], ["Ding", "Zihan", ""], ["Wu", "Lianlong", ""]]}, {"id": "1905.08087", "submitter": "Zheng Tian Mr", "authors": "Zheng Tian, Ying Wen, Zhichen Gong, Faiz Punakkath, Shihao Zou, Jun\n  Wang", "title": "A Regularized Opponent Model with Maximum Entropy Objective", "comments": "Accepted to International Joint Conference on Artificial Intelligence\n  (IJCA2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a single-agent setting, reinforcement learning (RL) tasks can be cast into\nan inference problem by introducing a binary random variable o, which stands\nfor the \"optimality\". In this paper, we redefine the binary random variable o\nin multi-agent setting and formalize multi-agent reinforcement learning (MARL)\nas probabilistic inference. We derive a variational lower bound of the\nlikelihood of achieving the optimality and name it as Regularized Opponent\nModel with Maximum Entropy Objective (ROMMEO). From ROMMEO, we present a novel\nperspective on opponent modeling and show how it can improve the performance of\ntraining agents theoretically and empirically in cooperative games. To optimize\nROMMEO, we first introduce a tabular Q-iteration method ROMMEO-Q with proof of\nconvergence. We extend the exact algorithm to complex environments by proposing\nan approximate version, ROMMEO-AC. We evaluate these two algorithms on the\nchallenging iterated matrix game and differential game respectively and show\nthat they can outperform strong MARL baselines.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 12:30:59 GMT"}, {"version": "v2", "created": "Mon, 19 Aug 2019 12:26:07 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Tian", "Zheng", ""], ["Wen", "Ying", ""], ["Gong", "Zhichen", ""], ["Punakkath", "Faiz", ""], ["Zou", "Shihao", ""], ["Wang", "Jun", ""]]}, {"id": "1905.08355", "submitter": "Kashif Zia Dr.", "authors": "Kashif Zia, Alois Ferscha, Dari Trendafilov", "title": "Importance of Coordination and Cultural Diversity for an Efficient and\n  Flexible Manufacturing System", "comments": "4 pages, The Eleventh International Conference on Advanced Cognitive\n  Technologies and Applications, May 05, 2019 to May 09, 2019 - Venice, Italy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Manufacturing systems of the future need to have flexible resources and\nflexible routing to produce extremely personalized products, even of lot size\nequal to one. In this paper, we have proposed a framework, which is designed to\nachieve this goal. Towards this, we have integrated an established cultural\nevolution model to achieve desired flexibility of resources and acceptable\nrouting time. Promising results are evidenced through a simple proof-of-concept\nsimulation.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 21:28:36 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Zia", "Kashif", ""], ["Ferscha", "Alois", ""], ["Trendafilov", "Dari", ""]]}, {"id": "1905.08645", "submitter": "Nicolas Loizou", "authors": "Nicolas Loizou and Peter Richt\\'arik", "title": "Revisiting Randomized Gossip Algorithms: General Framework, Convergence\n  Rates and Novel Block and Accelerated Protocols", "comments": "44 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DC cs.LG cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we present a new framework for the analysis and design of\nrandomized gossip algorithms for solving the average consensus problem. We show\nhow classical randomized iterative methods for solving linear systems can be\ninterpreted as gossip algorithms when applied to special systems encoding the\nunderlying network and explain in detail their decentralized nature. Our\ngeneral framework recovers a comprehensive array of well-known gossip\nalgorithms as special cases, including the pairwise randomized gossip algorithm\nand path averaging gossip, and allows for the development of provably faster\nvariants. The flexibility of the new approach enables the design of a number of\nnew specific gossip methods. For instance, we propose and analyze novel block\nand the first provably accelerated randomized gossip protocols, and dual\nrandomized gossip algorithms.\n  From a numerical analysis viewpoint, our work is the first that explores in\ndepth the decentralized nature of randomized iterative methods for linear\nsystems and proposes them as methods for solving the average consensus problem.\n  We evaluate the performance of the proposed gossip protocols by performing\nextensive experimental testing on typical wireless network topologies.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 14:36:59 GMT"}, {"version": "v2", "created": "Mon, 3 Jun 2019 16:41:08 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Loizou", "Nicolas", ""], ["Richt\u00e1rik", "Peter", ""]]}, {"id": "1905.08750", "submitter": "Roula Nassif", "authors": "Roula Nassif and Stefan Vlaski and Ali H. Sayed", "title": "Adaptation and learning over networks under subspace constraints -- Part\n  I: Stability Analysis", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2020.2970336", "report-no": null, "categories": "cs.MA eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers optimization problems over networks where agents have\nindividual objectives to meet, or individual parameter vectors to estimate,\nsubject to subspace constraints that require the objectives across the network\nto lie in low-dimensional subspaces. This constrained formulation includes\nconsensus optimization as a special case, and allows for more general task\nrelatedness models such as smoothness. While such formulations can be solved\nvia projected gradient descent, the resulting algorithm is not distributed.\nStarting from the centralized solution, we propose an iterative and distributed\nimplementation of the projection step, which runs in parallel with the\nstochastic gradient descent update. We establish in this Part I of the work\nthat, for small step-sizes $\\mu$, the proposed distributed adaptive strategy\nleads to small estimation errors on the order of $\\mu$. We examine in the\naccompanying Part II [2] the steady-state performance. The results will reveal\nexplicitly the influence of the gradient noise, data characteristics, and\nsubspace constraints, on the network performance. The results will also show\nthat in the small step-size regime, the iterates generated by the distributed\nalgorithm achieve the centralized steady-state performance.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 16:59:16 GMT"}, {"version": "v2", "created": "Sat, 1 Jun 2019 10:05:01 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Nassif", "Roula", ""], ["Vlaski", "Stefan", ""], ["Sayed", "Ali H.", ""]]}, {"id": "1905.09065", "submitter": "Johannes M\\\"uller", "authors": "Johannes M\\\"uller, Tobias Meuser, Ralf Steinmetz, and Michael Buchholz", "title": "A Trust Management and Misbehaviour Detection Mechanism for Multi-Agent\n  Systems and its Application to Intelligent Transportation Systems", "comments": "7 pages, accepted on 15th IEEE International Conference on Control\n  and Automation (IEEE ICCA 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cooperative information shared among a multi-agent system (MAS) can be useful\nto agents to efficiently fulfill their missions. Relying on wrong information,\nhowever, can have severe consequences. While classical approaches only consider\nmeasurement uncertainty, reliability information on the incoming data can be\nuseful for decision making. In this work, a subjective logic based mechanism is\nproposed that amends reliability information to the data shared among the MAS.\n  If multiple agents report the same event, their information is fused. In\norder to maintain high reliability, the mechanism detects and isolates\nmisbehaving agents. Therefore, an attacker model is specified that includes\nfaulty as well as malicious agents. The mechanism is applied to Intelligent\nTransportation Systems (ITS) and it is shown in simulation that the approach\nscales well with the size of the MAS and that it is able to efficiently\ndetected and isolated misbehaving agents.\n  Keywords: Multi-agent systems, Fault Detection, Sensor/data fusion, Control\nApplications\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 10:57:06 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["M\u00fcller", "Johannes", ""], ["Meuser", "Tobias", ""], ["Steinmetz", "Ralf", ""], ["Buchholz", "Michael", ""]]}, {"id": "1905.09177", "submitter": "Ulysse L\\'echine", "authors": "Ulysse L\\'echine and S\\'ebastien Tixeuil", "title": "Asynchronous Scattering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of scattering a swarm of mobile\noblivious robots in a continuous space. We consider the fully asynchronous\nsetting where robots may base their computation on past observations, or may be\nobserved by other robots while moving.\n  It turns out that asynchronous scattering is solvable in the most general\ncase when both vision (the ability to see others robots positions) and weak\nlocal multiplicity detection are available. In the case of a bidimensional\nEuclidean space, ASYNC scattering is also solvable with blind robots if moves\nare rigid. Our approach is constructive and modular, as we present a proof\ntechnique for probabilistic robot protocols that is of independent interest and\ncan be reused for other purposes.\n  On the negative side, we show that when robots are both blind and have no\nmultiplicity detection, the problem is unsolvable, and when only one of those\nis available, the problem remains unsolvable on the line.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 14:53:39 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["L\u00e9chine", "Ulysse", ""], ["Tixeuil", "S\u00e9bastien", ""]]}, {"id": "1905.09795", "submitter": "Kashif Zia Dr.", "authors": "Kashif Zia, Dinesh Kumar Saini, Arshad Muhammad, Alois Ferscha", "title": "Nature-Inspired Computational Model of Population Desegregation under\n  Group Leaders Influence", "comments": "12 pages", "journal-ref": "IEEE Transactions on Computational Social Systems 5(2), 2018", "doi": "10.1109/TCSS.2018.2818324", "report-no": null, "categories": "cs.MA cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an agent-based model of population desegregation and\nprovides a thorough analysis of the social behavior leading to it, namely, the\ncontact hypothesis. Based on the parameters of frequency and intensity of\ninfluence of group leaders on the population, the proposed model is constituted\nby two layers: 1) a physical layer of the population that is influenced by and\n2) a virtual layer of group leaders. The model of negotiation and survival of\ngroup leaders are governed by the nature-inspired evolutionary process of queen\nants, also known as Foundress Dilemma. The motivation of using a virtual\ngrouping concept (instead of taking a subset of population as the group\nleaders) is to stay focused on finding the conditions leading individuals in a\nsociety tolerating a significantly diversified (desegregated) neighborhood,\nrather than, indulging into complex details, which would be more relevant to\nstudies targeting the evolution of societal group and leaders. A geographic\ninformation system-driven simulation is performed, which reveals that: 1)\ndesegregation is directly proportional to the frequency of group leaders'\ncontact with the population and 2) mostly, it remains ineffective with an\nincrease in the intensity of group leaders' contact with the population. The\nmechanism of group selection (the conflict resolution model resolving the\nFoundress Dilemma) reveals an exciting result concerning negative influence of\ncooperative group leaders. Most of the time, desegregation decreases with\nincrease in cooperative leaders (the leaders enforcing desegregation) when\ncompared with fierce leaders (the leaders enforcing segregation).\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 17:38:20 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Zia", "Kashif", ""], ["Saini", "Dinesh Kumar", ""], ["Muhammad", "Arshad", ""], ["Ferscha", "Alois", ""]]}, {"id": "1905.09988", "submitter": "Souma Chowdhury", "authors": "Payam Ghassemi and Souma Chowdhury", "title": "Decentralized Informative Path Planning with Exploration-Exploitation\n  Balance for Swarm Robotic Search", "comments": "Accepted for presentation in (and publication in the proceedings of)\n  The ASME 2019 International Design Engineering Technical Conferences &\n  Computers and Information in Engineering Conference (IDETC/CIE 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Swarm robotic search is concerned with searching targets in unknown\nenvironments (e.g., for search and rescue or hazard localization), using a\nlarge number of collaborating simple mobile robots. In such applications,\ndecentralized swarm systems are touted for their task/coverage scalability,\ntime efficiency, and fault tolerance. To guide the behavior of such swarm\nsystems, two broad classes of approaches are available, namely nature-inspired\nswarm heuristics and multi-robotic search methods. However, simultaneously\noffering computationally-efficient scalability and fundamental insights into\nthe exhibited behavior (instead of a black-box behavior model), remains\nchallenging under either of these two class of approaches. In this paper, we\ndevelop an important extension of the batch Bayesian search method for\napplication to embodied swarm systems, searching in a physical 2D space. Key\ncontributions lie in: 1) designing an acquisition function that not only\nbalances exploration and exploitation across the swarm, but also allows\nmodeling knowledge extraction over trajectories; and 2) developing its\ndistributed implementation to allow asynchronous task inference and path\nplanning by the swarm robots. The resulting collective informative path\nplanning approach is tested on target search case studies of varying\ncomplexity, where the target produces a spatially varying (measurable) signal.\nSignificantly superior performance, in terms of mission completion efficiency,\nis observed compared to exhaustive search and random walk baselines, along with\nfavorable performance scalability with increasing swarm size.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 01:27:12 GMT"}, {"version": "v2", "created": "Fri, 31 May 2019 02:08:19 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Ghassemi", "Payam", ""], ["Chowdhury", "Souma", ""]]}, {"id": "1905.10149", "submitter": "Keisuke Okumura", "authors": "Keisuke Okumura, Yasumasa Tamura, Xavier D\\'efago", "title": "winPIBT: Extended Prioritized Algorithm for Iterative Multi-agent Path\n  Finding", "comments": "9 pages, 7 figures, preprint, to be presented at IJCAI-20 MAPF\n  workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.DC cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of Multi-agent Path Finding (MAPF) consists in providing agents\nwith efficient paths while preventing collisions. Numerous solvers have been\ndeveloped so far since MAPF is critical for practical applications such as\nautomated warehouses. The recently-proposed Priority Inheritance with\nBacktracking (PIBT) is a promising decoupled method that solves MAPF\niteratively with flexible priorities. The method is aimed to be decentralized\nand has a very low computational cost, but it is shortsighted in the sense that\nit plans only one step ahead, thus occasionally resulting in inefficient\nplannings. This work proposes a generalization of PIBT, called windowed PIBT\n(winPIBT), that introduces a configurable time window. winPIBT allows agents to\nplan paths anticipating multiple steps ahead. We prove that, similarly to PIBT,\nall agents reach their own destinations in finite time as long as the\nenvironment is a graph with adequate properties, e.g., biconnected.\nExperimental results over various scenarios confirm that winPIBT mitigates\nlivelock situations occurring in PIBT, and usually plans more efficient paths\ngiven adequate window size.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 11:12:25 GMT"}, {"version": "v2", "created": "Fri, 14 Jun 2019 01:25:00 GMT"}, {"version": "v3", "created": "Sat, 7 Sep 2019 04:49:36 GMT"}, {"version": "v4", "created": "Sat, 26 Sep 2020 09:38:54 GMT"}, {"version": "v5", "created": "Mon, 14 Dec 2020 05:19:36 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Okumura", "Keisuke", ""], ["Tamura", "Yasumasa", ""], ["D\u00e9fago", "Xavier", ""]]}, {"id": "1905.10490", "submitter": "Cleber Amaral Mr.", "authors": "Cleber Jorge Amaral, S\\'ergio Pereira Bernardes, Mateus\n  Concei\\c{c}\\~ao, Jomi Fred H\\\"ubner, Luis Pedro Arenhart Lampert, Ot\\'avio\n  Arruda Matoso, Maicon Rafael Zatelli", "title": "Finding new routes for integrating Multi-Agent Systems using Apache\n  Camel", "comments": "12 pages, 5 figures", "journal-ref": "Presented on Wesaac 2019 (Workshop-School on Agents, Environments,\n  and Applications) - https://gsigma.ufsc.br/wesaac2019/", "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In Multi-Agent Systems (MAS) there are two main models of interaction: among\nagents, and between agents and the environment. Although there are studies\nconsidering these models, there is no practical tool to afford the interaction\nwith external entities with both models. This paper presents a proposal for\nsuch a tool based on the Apache Camel framework by designing two new\ncomponents, namely camel-jason and camel-artifact. By means of these\ncomponents, an external entity is modelled according to its nature, i.e.,\nwhether it is autonomous or non-autonomous, interacting with the MAS\nrespectively as an agent or an artifact. It models coherently external entities\nwhereas Camel provides interoperability with several communication protocols.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 00:26:39 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Amaral", "Cleber Jorge", ""], ["Bernardes", "S\u00e9rgio Pereira", ""], ["Concei\u00e7\u00e3o", "Mateus", ""], ["H\u00fcbner", "Jomi Fred", ""], ["Lampert", "Luis Pedro Arenhart", ""], ["Matoso", "Ot\u00e1vio Arruda", ""], ["Zatelli", "Maicon Rafael", ""]]}, {"id": "1905.10878", "submitter": "Andr\\'e C. R. Martins", "authors": "Andre C. R. Martins", "title": "Discrete Opinion Dynamics with M choices", "comments": "19 pages, 16 figures", "journal-ref": null, "doi": "10.1140/epjb/e2019-100298-3", "report-no": null, "categories": "physics.soc-ph cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Here, I study how to obtain an opinion dynamics model for the case where\nthere are $M$ possible discrete choices and there is need to model how strong\neach agent choice is. The new model is obtained as an extension of the\nContinuous Opinions and Discrete Actions (CODA) model. Technical difficulties\nwith the choice of proper variables for a simple model are solved. For the\nsymmetrical case, a dimensionless model is found. However, when analyzing the\nresults, a change of variables seems to be required for ease of interpretation.\nExtremism is observed here as well, generated by the local reinforcement of\nopinions inside domains of agents with the same choice.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 21:08:16 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Martins", "Andre C. R.", ""]]}, {"id": "1905.10922", "submitter": "Anthony Young", "authors": "Anthony P. Young, David Kohan Marzagao and Josh Murphy", "title": "Applying Abstract Argumentation Theory to Cooperative Game Theory", "comments": "15 pages, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We apply ideas from abstract argumentation theory to study cooperative game\ntheory. Building on Dung's results in his seminal paper, we further the\ncorrespondence between Dung's four argumentation semantics and solution\nconcepts in cooperative game theory by showing that complete extensions (the\ngrounded extension) correspond to Roth's subsolutions (respectively, the\nsupercore). We then investigate the relationship between well-founded\nargumentation frameworks and convex games, where in each case the semantics\n(respectively, solution concepts) coincide; we prove that three-player convex\ngames do not in general have well-founded argumentation frameworks.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 16:40:16 GMT"}, {"version": "v2", "created": "Wed, 2 Oct 2019 21:43:01 GMT"}, {"version": "v3", "created": "Fri, 3 Jan 2020 09:42:12 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Young", "Anthony P.", ""], ["Marzagao", "David Kohan", ""], ["Murphy", "Josh", ""]]}, {"id": "1905.11353", "submitter": "Jiarui Jin", "authors": "Jiarui Jin, Ming Zhou, Weinan Zhang, Minne Li, Zilong Guo, Zhiwei Qin,\n  Yan Jiao, Xiaocheng Tang, Chenxi Wang, Jun Wang, Guobin Wu, Jieping Ye", "title": "CoRide: Joint Order Dispatching and Fleet Management for Multi-Scale\n  Ride-Hailing Platforms", "comments": "CIKM 2019", "journal-ref": null, "doi": "10.1145/3357384.3357978", "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How to optimally dispatch orders to vehicles and how to tradeoff between\nimmediate and future returns are fundamental questions for a typical\nride-hailing platform. We model ride-hailing as a large-scale parallel ranking\nproblem and study the joint decision-making task of order dispatching and fleet\nmanagement in online ride-hailing platforms. This task brings unique challenges\nin the following four aspects. First, to facilitate a huge number of vehicles\nto act and learn efficiently and robustly, we treat each region cell as an\nagent and build a multi-agent reinforcement learning framework. Second, to\ncoordinate the agents from different regions to achieve long-term benefits, we\nleverage the geographical hierarchy of the region grids to perform hierarchical\nreinforcement learning. Third, to deal with the heterogeneous and variant\naction space for joint order dispatching and fleet management, we design the\naction as the ranking weight vector to rank and select the specific order or\nthe fleet management destination in a unified formulation. Fourth, to achieve\nthe multi-scale ride-hailing platform, we conduct the decision-making process\nin a hierarchical way where a multi-head attention mechanism is utilized to\nincorporate the impacts of neighbor agents and capture the key agent in each\nscale. The whole novel framework is named as CoRide. Extensive experiments\nbased on multiple cities real-world data as well as analytic synthetic data\ndemonstrate that CoRide provides superior performance in terms of platform\nrevenue and user experience in the task of city-wide hybrid order dispatching\nand fleet management over strong baselines.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 17:31:52 GMT"}, {"version": "v2", "created": "Fri, 30 Aug 2019 08:38:44 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Jin", "Jiarui", ""], ["Zhou", "Ming", ""], ["Zhang", "Weinan", ""], ["Li", "Minne", ""], ["Guo", "Zilong", ""], ["Qin", "Zhiwei", ""], ["Jiao", "Yan", ""], ["Tang", "Xiaocheng", ""], ["Wang", "Chenxi", ""], ["Wang", "Jun", ""], ["Wu", "Guobin", ""], ["Ye", "Jieping", ""]]}, {"id": "1905.11764", "submitter": "Paul Kr\\\"oger", "authors": "Werner Damm, Martin Fr\\\"anzle, Willem Hagemann, Paul Kr\\\"oger, Astrid\n  Rakow", "title": "Justification Based Reasoning in Dynamic Conflict Resolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study conflict situations that dynamically arise in traffic scenarios,\nwhere different agents try to achieve their set of goals and have to decide on\nwhat to do based on their local perception. We distinguish several types of\nconflicts for this setting. In order to enable modelling of conflict situations\nand the reasons for conflicts, we present a logical framework that adopts\nconcepts from epistemic and modal logic, justification and temporal logic.\nUsing this framework, we illustrate how conflicts can be identified and how we\nderive a chain of justifications leading to this conflict. We discuss how\nconflict resolution can be done when a vehicle has local, incomplete\ninformation, vehicle to vehicle communication (V2V) and partially ordered\ngoals.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 12:19:47 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Damm", "Werner", ""], ["Fr\u00e4nzle", "Martin", ""], ["Hagemann", "Willem", ""], ["Kr\u00f6ger", "Paul", ""], ["Rakow", "Astrid", ""]]}, {"id": "1905.11828", "submitter": "Chen Dingding", "authors": "Yanchen Deng and Ziyu Chen and Dingding Chen and Wenxin Zhang and\n  Xingqiong Jiang", "title": "AsymDPOP: Complete Inference for Asymmetric Distributed Constraint\n  Optimization Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Asymmetric distributed constraint optimization problems (ADCOPs) are an\nemerging model for coordinating agents with personal preferences. However, the\nexisting inference-based complete algorithms which use local eliminations\ncannot be applied to ADCOPs, as the parent agents are required to transfer\ntheir private functions to their children. Rather than disclosing private\nfunctions explicitly to facilitate local eliminations, we solve the problem by\nenforcing delayed eliminations and propose AsymDPOP, the first inference-based\ncomplete algorithm for ADCOPs. To solve the severe scalability problems\nincurred by delayed eliminations, we propose to reduce the memory consumption\nby propagating a set of smaller utility tables instead of a joint utility\ntable, and to reduce the computation efforts by sequential optimizations\ninstead of joint optimizations. The empirical evaluation indicates that\nAsymDPOP significantly outperforms the state-of-the-arts, as well as the\nvanilla DPOP with PEAV formulation.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 14:07:01 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 08:32:31 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Deng", "Yanchen", ""], ["Chen", "Ziyu", ""], ["Chen", "Dingding", ""], ["Zhang", "Wenxin", ""], ["Jiang", "Xingqiong", ""]]}, {"id": "1905.11838", "submitter": "Palash Dey", "authors": "Palash Dey, Neeldhara Misra, Swaprava Nath, and Garima Shakya", "title": "A Parameterized Perspective on Protecting Elections", "comments": "To appear in IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.CY cs.DS cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the parameterized complexity of the optimal defense and optimal\nattack problems in voting. In both the problems, the input is a set of voter\ngroups (every voter group is a set of votes) and two integers $k_a$ and $k_d$\ncorresponding to respectively the number of voter groups the attacker can\nattack and the number of voter groups the defender can defend. A voter group\ngets removed from the election if it is attacked but not defended. In the\noptimal defense problem, we want to know if it is possible for the defender to\ncommit to a strategy of defending at most $k_d$ voter groups such that, no\nmatter which $k_a$ voter groups the attacker attacks, the outcome of the\nelection does not change. In the optimal attack problem, we want to know if it\nis possible for the attacker to commit to a strategy of attacking $k_a$ voter\ngroups such that, no matter which $k_d$ voter groups the defender defends, the\noutcome of the election is always different from the original (without any\nattack) one.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 14:20:33 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Dey", "Palash", ""], ["Misra", "Neeldhara", ""], ["Nath", "Swaprava", ""], ["Shakya", "Garima", ""]]}, {"id": "1905.11871", "submitter": "Diane Bouchacourt", "authors": "Diane Bouchacourt and Marco Baroni", "title": "Miss Tools and Mr Fruit: Emergent communication in agents learning about\n  object affordances", "comments": "Association for Computational Linguistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research studies communication emergence in communities of deep\nnetwork agents assigned a joint task, hoping to gain insights on human language\nevolution. We propose here a new task capturing crucial aspects of the human\nenvironment, such as natural object affordances, and of human conversation,\nsuch as full symmetry among the participants. By conducting a thorough\npragmatic and semantic analysis of the emergent protocol, we show that the\nagents solve the shared task through genuine bilateral, referential\ncommunication. However, the agents develop multiple idiolects, which makes us\nconclude that full symmetry is not a sufficient condition for a common language\nto emerge.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 15:10:30 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Bouchacourt", "Diane", ""], ["Baroni", "Marco", ""]]}, {"id": "1905.12083", "submitter": "Maroua Nouiri", "authors": "Maroua Nouiri, Damien Trentesaux, Abdelghani Bekrar", "title": "EasySched: a multi-agent architecture for the predictive and reactive\n  scheduling of Industry 4.0 production systems based on the available\n  renewable energy", "comments": "In French. G{\\'e}nie industriel et productique, Maria DI MASCOLO,\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Industry 4.0 is concerned with sustainable development constraints. In this\ncontext, we propose a multi-agent architecture, named EasySched, aiming at\nelaborating predictive and reactive scheduling as the result of a coordination\nbetween systems producing goods and systems producing renewable energy. The\nvalidation of this architecture is original, and was conducted in a completely\nand physically distributed way, using networked embedded systems. This\nvalidation was done on a series of instances inspired by the literature. The\nresults showed that EasySched succeeds in adapting the production of goods\naccording to the available renewable energy\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 09:36:29 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Nouiri", "Maroua", ""], ["Trentesaux", "Damien", ""], ["Bekrar", "Abdelghani", ""]]}, {"id": "1905.12104", "submitter": "Nicholas Mattei", "authors": "Jaelle Scheuerman, Jason L. Harman, Nicholas Mattei, and K. Brent\n  Venable", "title": "Heuristics in Multi-Winner Approval Voting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.MA econ.GN q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many real world situations, collective decisions are made using voting.\nMoreover, scenarios such as committee or board elections require voting rules\nthat return multiple winners. In multi-winner approval voting (AV), an agent\nmay vote for as many candidates as they wish. Winners are chosen by tallying up\nthe votes and choosing the top-$k$ candidates receiving the most votes. An\nagent may manipulate the vote to achieve a better outcome by voting in a way\nthat does not reflect their true preferences. In complex and uncertain\nsituations, agents may use heuristics to strategize, instead of incurring the\nadditional effort required to compute the manipulation which most favors them.\nIn this paper, we examine voting behavior in multi-winner approval voting\nscenarios with complete information. We show that people generally manipulate\ntheir vote to obtain a better outcome, but often do not identify the optimal\nmanipulation. Instead, voters tend to prioritize the candidates with the\nhighest utilities. Using simulations, we demonstrate the effectiveness of these\nheuristics in situations where agents only have access to partial information.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 21:44:07 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 16:27:24 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Scheuerman", "Jaelle", ""], ["Harman", "Jason L.", ""], ["Mattei", "Nicholas", ""], ["Venable", "K. Brent", ""]]}, {"id": "1905.12127", "submitter": "Shariq Iqbal", "authors": "Shariq Iqbal and Fei Sha", "title": "Coordinated Exploration via Intrinsic Rewards for Multi-Agent\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solving tasks with sparse rewards is one of the most important challenges in\nreinforcement learning. In the single-agent setting, this challenge is\naddressed by introducing intrinsic rewards that motivate agents to explore\nunseen regions of their state spaces; however, applying these techniques\nnaively to the multi-agent setting results in agents exploring independently,\nwithout any coordination among themselves. Exploration in cooperative\nmulti-agent settings can be accelerated and improved if agents coordinate their\nexploration. In this paper we introduce a framework for designing intrinsic\nrewards which consider what other agents have explored such that the agents can\ncoordinate. Then, we develop an approach for learning how to dynamically select\nbetween several exploration modalities to maximize extrinsic rewards.\nConcretely, we formulate the approach as a hierarchical policy where a\nhigh-level controller selects among sets of policies trained on diverse\nintrinsic rewards and the low-level controllers learn the action policies of\nall agents under these specific rewards. We demonstrate the effectiveness of\nthe proposed approach in cooperative domains with sparse rewards where\nstate-of-the-art methods fail and challenging multi-stage tasks that\nnecessitate changing modes of coordination.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 23:01:02 GMT"}, {"version": "v2", "created": "Fri, 5 Jun 2020 02:08:26 GMT"}, {"version": "v3", "created": "Sat, 22 May 2021 20:19:01 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Iqbal", "Shariq", ""], ["Sha", "Fei", ""]]}, {"id": "1905.12160", "submitter": "Reza Vosooghi", "authors": "Reza Vosooghi (LGI, IRT SystemX), Jakob Puchinger (LGI), Joschka\n  Bischoff, Marija Jankovic (LGI), Anthony Vouillon", "title": "Shared Autonomous Electric Vehicle Service Performance: Assessing the\n  Impact of Charging Infrastructure and Battery Capacity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shared autonomous vehicles (SAVs) are the next major evolution in urban\nmobility. This technology has attracted much interest of car manufacturers\naiming at playing a role as transportation network companies (TNCs) in order to\ngain benefits per kilometer and per ride. The majority of future SAVs will most\nprobably be electric. It is therefore important to understand how limited\nvehicle range and the configuration of charging infrastructure will affect the\nperformance of shared autonomous electric vehicle (SAEV) services. We aim to\nexplore the impacts of charging station placement, charging type (rapid\ncharging, battery swapping) as well as vehicle range onto service efficiency\nand customer experience in terms of service availability and response time. We\nperform an agent-based simulation of SAEVs across the Rouen Normandie\nmetropolitan area in France. The simulation process features impact assessment\nby considering dynamic demand responsive to the network and traffic. Research\nresults suggest that the performance of SAEVs is strongly correlated to the\ncharging infrastructure. Importantly, faster charging infrastructure and\noptimized placement of charging locations in order to minimize distances\nbetween demand hubs and charging stations result in a higher performance.\nFurther analysis indicates the importance of dispersing charging stations\nacross the service area and how this affects service effectiveness. The results\nalso underline that SAEV battery capacity has to be carefully selected to avoid\nthe overlaps between demand and charging peak times. Finally, the simulation\nresults show that by providing battery swapping infrastructure the performance\nindicators of SAEV service are significantly improved.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 12:19:51 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Vosooghi", "Reza", "", "LGI, IRT SystemX"], ["Puchinger", "Jakob", "", "LGI"], ["Bischoff", "Joschka", "", "LGI"], ["Jankovic", "Marija", "", "LGI"], ["Vouillon", "Anthony", ""]]}, {"id": "1905.12191", "submitter": "Shalabh Gupta", "authors": "Junnan Song and Shalabh Gupta", "title": "CARE: Cooperative Autonomy for Resilience and Efficiency of Robot Teams\n  for Complete Coverage of Unknown Environments under Robot Failures", "comments": null, "journal-ref": "Autonomous Robots, volume 44, 2020", "doi": "10.1007/s10514-019-09870-3", "report-no": null, "categories": "cs.RO cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of Multi-robot Coverage Path Planning (MCPP)\nfor unknown environments in the presence of robot failures. Unexpected robot\nfailures can seriously degrade the performance of a robot team and in extreme\ncases jeopardize the overall operation. Therefore, this paper presents a\ndistributed algorithm, called Cooperative Autonomy for Resilience and\nEfficiency (CARE), which not only provides resilience to the robot team against\nfailures of individual robots, but also improves the overall efficiency of\noperation via event-driven replanning. The algorithm uses distributed Discrete\nEvent Supervisors (DESs), which trigger games between a set of feasible players\nin the event of a robot failure or idling, to make collaborative decisions for\ntask reallocations. The game-theoretic structure is built using Potential\nGames, where the utility of each player is aligned with a shared objective\nfunction for all players. The algorithm has been validated in various complex\nscenarios on a high-fidelity robotic simulator, and the results demonstrate\nthat the team achieves complete coverage under failures, reduced coverage time,\nand faster target discovery as compared to three alternative methods.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 03:08:20 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Song", "Junnan", ""], ["Gupta", "Shalabh", ""]]}, {"id": "1905.12204", "submitter": "Hyunwook Kang", "authors": "Hyunwook Kang, Aydar Mynbay, James R. Morrison, Jinkyoo Park", "title": "Learning scalable and transferable multi-robot/machine sequential\n  assignment planning via graph embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can the success of reinforcement learning methods for simple combinatorial\noptimization problems be extended to multi-robot sequential assignment\nplanning? In addition to the challenge of achieving near-optimal performance in\nlarge problems, transferability to an unseen number of robots and tasks is\nanother key challenge for real-world applications. In this paper, we suggest a\nmethod that achieves the first success in both challenges for robot/machine\nscheduling problems.\n  Our method comprises of three components. First, we show a robot scheduling\nproblem can be expressed as a random probabilistic graphical model (PGM). We\ndevelop a mean-field inference method for random PGM and use it for Q-function\ninference. Second, we show that transferability can be achieved by carefully\ndesigning two-step sequential encoding of problem state. Third, we resolve the\ncomputational scalability issue of fitted Q-iteration by suggesting a heuristic\nauction-based Q-iteration fitting method enabled by transferability we\nachieved.\n  We apply our method to discrete-time, discrete space problems (Multi-Robot\nReward Collection (MRRC)) and scalably achieve 97% optimality with\ntransferability. This optimality is maintained under stochastic contexts. By\nextending our method to continuous time, continuous space formulation, we claim\nto be the first learning-based method with scalable performance among\nmulti-machine scheduling problems; our method scalability achieves comparable\nperformance to popular metaheuristics in Identical parallel machine scheduling\n(IPMS) problems.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 04:02:41 GMT"}, {"version": "v2", "created": "Sat, 1 Jun 2019 16:51:06 GMT"}, {"version": "v3", "created": "Mon, 30 Sep 2019 18:44:13 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Kang", "Hyunwook", ""], ["Mynbay", "Aydar", ""], ["Morrison", "James R.", ""], ["Park", "Jinkyoo", ""]]}, {"id": "1905.12267", "submitter": "Reza Vosooghi", "authors": "Reza Vosooghi (LGI, IRT SystemX), Joseph Kamel (IRT SystemX), Jakob\n  Puchinger (LGI, IRT SystemX), Vincent Leblond (IRT SystemX), Marija Jankovic\n  (LGI)", "title": "Robo-Taxi service fleet sizing: assessing the impact of user trust and\n  willingness-to-use", "comments": "Transportation, Springer Verlag, 2019", "journal-ref": null, "doi": "10.1007/s11116-019-10013-x", "report-no": null, "categories": "cs.MA cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The first commercial fleets of Robo-Taxis will be on the road soon. Today\nimportant efforts are made to anticipate future Robo-Taxi services. Fleet size\nis one of the key parameters considered in the planning phase of service design\nand configuration. Based on multi-agent approaches, the fleet size can be\nexplored using dynamic demand response simulations. Time and cost are the most\ncommon variables considered in such simulation approaches. However, personal\ntaste variation can affect the demand and consequently the required fleet size.\nIn this paper, we explore the impact of user trust and willingness-to-use on\nthe Robo-Taxi fleet size. This research is based upon simulating the\ntransportation system of the Rouen-Normandie metropolitan area in France using\nMATSim, a multi-agent activity-based simulator. A local survey is made in order\nto explore the variation of user trust and their willingness-to-use future\nRobo-Taxis according to the sociodemographic attributes. Integrating survey\ndata in the model shows the significant importance of traveler trust and\nwillingness-to-use varying the Robo-Taxi use and the required fleet size.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 08:22:05 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Vosooghi", "Reza", "", "LGI, IRT SystemX"], ["Kamel", "Joseph", "", "IRT SystemX"], ["Puchinger", "Jakob", "", "LGI, IRT SystemX"], ["Leblond", "Vincent", "", "IRT SystemX"], ["Jankovic", "Marija", "", "LGI"]]}, {"id": "1905.12561", "submitter": "Rahma Chaabouni", "authors": "Rahma Chaabouni, Eugene Kharitonov, Emmanuel Dupoux and Marco Baroni", "title": "Anti-efficient encoding in emergent communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite renewed interest in emergent language simulations with neural\nnetworks, little is known about the basic properties of the induced code, and\nhow they compare to human language. One fundamental characteristic of the\nlatter, known as Zipf's Law of Abbreviation (ZLA), is that more frequent words\nare efficiently associated to shorter strings. We study whether the same\npattern emerges when two neural networks, a \"speaker\" and a \"listener\", are\ntrained to play a signaling game. Surprisingly, we find that networks develop\nan \\emph{anti-efficient} encoding scheme, in which the most frequent inputs are\nassociated to the longest messages, and messages in general are skewed towards\nthe maximum length threshold. This anti-efficient code appears easier to\ndiscriminate for the listener, and, unlike in human communication, the speaker\ndoes not impose a contrasting least-effort pressure towards brevity. Indeed,\nwhen the cost function includes a penalty for longer messages, the resulting\nmessage distribution starts respecting ZLA. Our analysis stresses the\nimportance of studying the basic features of emergent communication in a highly\ncontrolled setup, to ensure the latter will not strand too far from human\nlanguage. Moreover, we present a concrete illustration of how different\nfunctional pressures can lead to successful communication codes that lack basic\nproperties of human language, thus highlighting the role such pressures play in\nthe latter.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 16:14:24 GMT"}, {"version": "v2", "created": "Mon, 3 Jun 2019 16:46:47 GMT"}, {"version": "v3", "created": "Thu, 13 Jun 2019 16:58:54 GMT"}, {"version": "v4", "created": "Tue, 15 Oct 2019 11:56:14 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Chaabouni", "Rahma", ""], ["Kharitonov", "Eugene", ""], ["Dupoux", "Emmanuel", ""], ["Baroni", "Marco", ""]]}, {"id": "1905.12564", "submitter": "Gabriele Farina", "authors": "Gabriele Farina, Chun Kai Ling, Fei Fang, Tuomas Sandholm", "title": "Correlation in Extensive-Form Games: Saddle-Point Formulation and\n  Benchmarks", "comments": "Full version of NeurIPS 2019 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While Nash equilibrium in extensive-form games is well understood, very\nlittle is known about the properties of extensive-form correlated equilibrium\n(EFCE), both from a behavioral and from a computational point of view. In this\nsetting, the strategic behavior of players is complemented by an external\ndevice that privately recommends moves to agents as the game progresses;\nplayers are free to deviate at any time, but will then not receive future\nrecommendations. Our contributions are threefold. First, we show that an EFCE\ncan be formulated as the solution to a bilinear saddle-point problem. To\nshowcase how this novel formulation can inspire new algorithms to compute\nEFCEs, we propose a simple subgradient descent method which exploits this\nformulation and structural properties of EFCEs. Our method has better\nscalability than the prior approach based on linear programming. Second, we\npropose two benchmark games, which we hope will serve as the basis for future\nevaluation of EFCE solvers. These games were chosen so as to cover two natural\napplication domains for EFCE: conflict resolution via a mediator, and\nbargaining and negotiation. Third, we document the qualitative behavior of EFCE\nin our proposed games. We show that the social-welfare-maximizing equilibria in\nthese games are highly nontrivial and exhibit surprisingly subtle sequential\nbehavior that so far has not received attention in the literature.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 16:15:31 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 05:17:47 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Farina", "Gabriele", ""], ["Ling", "Chun Kai", ""], ["Fang", "Fei", ""], ["Sandholm", "Tuomas", ""]]}, {"id": "1905.12630", "submitter": "Oscar J. Romero", "authors": "Oscar J. Romero", "title": "Cognitively-inspired Agent-based Service Composition for Mobile &\n  Pervasive Computing", "comments": "This paper will appear on AIMS'19 (International Conference on\n  Artificial Intelligence and Mobile Services) on June 25", "journal-ref": "Artificial Intelligence and Mobile Services AIMS 2019", "doi": "10.1007/978-3-030-23367-9_8", "report-no": null, "categories": "cs.SE cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic service composition in mobile and pervasive computing faces many\nchallenges due to the complex and highly dynamic nature of the environment.\nCommon approaches consider service composition as a decision problem whose\nsolution is usually addressed from optimization perspectives which are not\nfeasible in practice due to the intractability of the problem, limited\ncomputational resources of smart devices, service host's mobility, and time\nconstraints to tailor composition plans. Thus, our main contribution is the\ndevelopment of a cognitively-inspired agent-based service composition model\nfocused on bounded rationality rather than optimality, which allows the system\nto compensate for limited resources by selectively filtering out continuous\nstreams of data. Our approach exhibits features such as distributedness,\nmodularity, emergent global functionality, and robustness, which endow it with\ncapabilities to perform decentralized service composition by orchestrating\nmanifold service providers and conflicting goals from multiple users. The\nevaluation of our approach shows promising results when compared against\nstate-of-the-art service composition models.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 20:19:15 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Romero", "Oscar J.", ""]]}, {"id": "1905.12890", "submitter": "Vahid Yazdanpanah", "authors": "Vahid Yazdanpanah, Devrim Murat Yazan, Jos van Hillegersberg, Mehdi\n  Dastani", "title": "An Introduction to Engineering Multiagent Industrial Symbiosis Systems:\n  Potentials and Challenges", "comments": "10 pages; In Pre-proceedings of the 7th International Workshop on\n  Engineering Multi-Agent Systems (EMAS 2019), 13th-14th May 2019, Montreal,\n  Canada; Editors: Rafael H. Bordini, Louise A. Dennis, Yves Lesp\\'erance", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiagent Systems (MAS) research reached a maturity to be confidently\napplied to real-life complex problems. Successful application of MAS methods\nfor behavior modeling, strategic reasoning, and decentralized governance,\nencouraged us to focus on applicability of MAS techniques in a class of\nindustrial systems and to elaborate on potentials and challenges for method\nintegration/contextualization. We direct attention towards a form of industrial\npractices called Industrial Symbiosis Systems (ISS) as a highly dynamic domain\nof application for MAS techniques. In ISS, firms aim to reduce their material\nand energy footprint by circulating reusable resources among the members. To\nenable systematic reasoning about ISS behavior and support firms' (as well as\nISS designers') decisions, we see the opportunity for marrying industrial\nengineering with engineering multiagent systems. This enables introducing (1)\nrepresentation frameworks to reason about dynamics of ISS, (2) operational\nsemantics to develop computational models for ISS, and (3) coordination\nmechanisms to enforce desirable ISS behaviors. We argue for applicability and\nexpressiveness of resource-bounded formalisms and norm-aware mechanisms for the\ndesign and deployment of ISS practices. In this proposal, we elaborate on\ndifferent dimensions of ISS, present a methodological foundation for ISS\ndevelopment, and finally discuss open problems.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 07:27:34 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Yazdanpanah", "Vahid", ""], ["Yazan", "Devrim Murat", ""], ["van Hillegersberg", "Jos", ""], ["Dastani", "Mehdi", ""]]}, {"id": "1905.13191", "submitter": "Duncan Rheingans-Yoo", "authors": "Duncan Rheingans-Yoo, Scott Duke Kominers, Hongyao Ma, David C. Parkes", "title": "Ridesharing with Driver Location Preferences", "comments": "12 pages, 11 figures, IJCAI '19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study revenue-optimal pricing and driver compensation in ridesharing\nplatforms when drivers have heterogeneous preferences over locations. If a\nplatform ignores drivers' location preferences, it may make inefficient trip\ndispatches; moreover, drivers may strategize so as to route towards their\npreferred locations. In a model with stationary and continuous demand and\nsupply, we present a mechanism that incentivizes drivers to both (i) report\ntheir location preferences truthfully and (ii) always provide service. In\nsettings with unconstrained driver supply or symmetric demand patterns, our\nmechanism achieves (full-information) first-best revenue. Under supply\nconstraints and unbalanced demand, we show via simulation that our mechanism\nimproves over existing mechanisms and has performance close to the first-best.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 17:21:37 GMT"}, {"version": "v2", "created": "Tue, 13 Aug 2019 13:06:20 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Rheingans-Yoo", "Duncan", ""], ["Kominers", "Scott Duke", ""], ["Ma", "Hongyao", ""], ["Parkes", "David C.", ""]]}, {"id": "1905.13225", "submitter": "Ismael Tito Freire Gonz\\'alez", "authors": "Ismael T. Freire, Xerxes D. Arsiwalla, Jordi-Ysard Puigb\\`o, Paul\n  Verschure", "title": "Modeling Theory of Mind in Multi-Agent Games Using Adaptive Feedback\n  Control", "comments": "30 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major challenge in cognitive science and AI has been to understand how\nautonomous agents might acquire and predict behavioral and mental states of\nother agents in the course of complex social interactions. How does such an\nagent model the goals, beliefs, and actions of other agents it interacts with?\nWhat are the computational principles to model a Theory of Mind (ToM)? Deep\nlearning approaches to address these questions fall short of a better\nunderstanding of the problem. In part, this is due to the black-box nature of\ndeep networks, wherein computational mechanisms of ToM are not readily\nrevealed. Here, we consider alternative hypotheses seeking to model how the\nbrain might realize a ToM. In particular, we propose embodied and situated\nagent models based on distributed adaptive control theory to predict actions of\nother agents in five different game theoretic tasks (Harmony Game, Hawk-Dove,\nStag-Hunt, Prisoner's Dilemma and Battle of the Exes). Our multi-layer control\nmodels implement top-down predictions from adaptive to reactive layers of\ncontrol and bottom-up error feedback from reactive to adaptive layers. We test\ncooperative and competitive strategies among seven different agent models\n(cooperative, greedy, tit-for-tat, reinforcement-based, rational, predictive\nand other's-model agents). We show that, compared to pure reinforcement-based\nstrategies, probabilistic learning agents modeled on rational, predictive and\nother's-model phenotypes perform better in game-theoretic metrics across tasks.\nOur autonomous multi-agent models capture systems-level processes underlying a\nToM and highlight architectural principles of ToM from a control-theoretic\nperspective.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 18:26:26 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Freire", "Ismael T.", ""], ["Arsiwalla", "Xerxes D.", ""], ["Puigb\u00f2", "Jordi-Ysard", ""], ["Verschure", "Paul", ""]]}, {"id": "1905.13275", "submitter": "Khoi Hoang", "authors": "Khoi D. Hoang, William Yeoh, Makoto Yokoo, Zinovi Rabinovich", "title": "New Algorithms for Functional Distributed Constraint Optimization\n  Problems", "comments": null, "journal-ref": "Proceedings of the 19th International Conference on Autonomous\n  Agents and MultiAgent Systems, 2020", "doi": "10.5555/3398761.3398823", "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Distributed Constraint Optimization Problem (DCOP) formulation is a\npowerful tool to model multi-agent coordination problems that are distributed\nby nature. The formulation is suitable for problems where variables are\ndiscrete and constraint utilities are represented in tabular form. However,\nmany real-world applications have variables that are continuous and tabular\nforms thus cannot accurately represent constraint utilities. To overcome this\nlimitation, researchers have proposed the Functional DCOP (F-DCOP) model, which\nare DCOPs with continuous variables. But existing approaches usually come with\nsome restrictions on the form of constraint utilities and are without quality\nguarantees. Therefore, in this paper, we (i) propose exact algorithms to solve\na specific subclass of F-DCOPs; (ii) propose approximation methods with quality\nguarantees to solve general F-DCOPs; and (iii) empirically show that our\nalgorithms outperform existing state-of-the-art F-DCOP algorithms on randomly\ngenerated instances when given the same communication limitations.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 19:45:06 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Hoang", "Khoi D.", ""], ["Yeoh", "William", ""], ["Yokoo", "Makoto", ""], ["Rabinovich", "Zinovi", ""]]}, {"id": "1905.13380", "submitter": "Kinzang Chhogyal", "authors": "Kinzang Chhogyal, Abhaya Nayak, Aditya Ghose, Hoa Khanh Dam", "title": "A Value-based Trust Assessment Model for Multi-agent Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An agent's assessment of its trust in another agent is commonly taken to be a\nmeasure of the reliability/predictability of the latter's actions. It is based\non the trustor's past observations of the behaviour of the trustee and requires\nno knowledge of the inner-workings of the trustee. However, in situations that\nare new or unfamiliar, past observations are of little help in assessing trust.\nIn such cases, knowledge about the trustee can help. A particular type of\nknowledge is that of values - things that are important to the trustor and the\ntrustee. In this paper, based on the premise that the more values two agents\nshare, the more they should trust one another, we propose a simple approach to\ntrust assessment between agents based on values, taking into account if agents\ntrust cautiously or boldly, and if they depend on others in carrying out a\ntask.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 02:08:20 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Chhogyal", "Kinzang", ""], ["Nayak", "Abhaya", ""], ["Ghose", "Aditya", ""], ["Dam", "Hoa Khanh", ""]]}, {"id": "1905.13428", "submitter": "Matthew A. Wright", "authors": "Matthew A. Wright and Roberto Horowitz", "title": "Attentional Policies for Cross-Context Multi-Agent Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many potential applications of reinforcement learning in the real world\ninvolve interacting with other agents whose numbers vary over time. We propose\nnew neural policy architectures for these multi-agent problems. In contrast to\nother methods of training an individual, discrete policy for each agent and\nthen enforcing cooperation through some additional inter-policy mechanism, we\nfollow the spirit of recent work on the power of relational inductive biases in\ndeep networks by learning multi-agent relationships at the policy level via an\nattentional architecture. In our method, all agents share the same policy, but\nindependently apply it in their own context to aggregate the other agents'\nstate information when selecting their next action. The structure of our\narchitectures allow them to be applied on environments with varying numbers of\nagents. We demonstrate our architecture on a benchmark multi-agent autonomous\nvehicle coordination problem, obtaining superior results to a full-knowledge,\nfully-centralized reference solution, and significantly outperforming it when\nscaling to large numbers of agents.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 06:02:52 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Wright", "Matthew A.", ""], ["Horowitz", "Roberto", ""]]}]