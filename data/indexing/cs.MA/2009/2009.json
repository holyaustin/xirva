[{"id": "2009.00161", "submitter": "Dinh Hoa Nguyen", "authors": "Dinh Hoa Nguyen", "title": "Optimal Solution Analysis and Decentralized Mechanisms for Peer-to-Peer\n  Energy Markets", "comments": "Accepted for publication in IEEE Transactions on Power Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the optimal clearing problem for prosumers in peer-to-peer\n(P2P) energy markets. It is proved that if no trade weights are enforced and\nthe communication structure between successfully traded peers is connected,\nthen the optimal clearing price and total traded powers in P2P market are the\nsame with that in the pool-based market. However, if such communication\nstructure is unconnected, then the P2P market is clustered into smaller P2P\nmarkets. If the trade weights are imposed, then the derived P2P market\nsolutions can be significantly changed. Next, a novel decentralized\noptimization approach is proposed to derive a trading mechanism for P2P\nmarkets, based on the alternating direction method of multipliers (ADMM) which\nnaturally fits into the bidirectional trading in P2P energy systems and\nconverges reasonably fast. Analytical formulas of variable updates reveal\ninsightful relations for each pair of prosumers on their individually traded\nprices and powers with their total traded powers. Further, based on those\nformulas, decentralized learning schemes for tuning parameters of prosumers\ncost functions are proposed to attain successful trading with total traded\npower amount as desired. Case studies on a synthetic system and the IEEE\nEuropean Low Voltage Test Feeder are then carried out to verify the proposed\napproaches.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 01:00:49 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Nguyen", "Dinh Hoa", ""]]}, {"id": "2009.00288", "submitter": "Qin Yang", "authors": "Qin Yang and Ramviyas Parasuraman", "title": "Needs-driven Heterogeneous Multi-Robot Cooperation in Rescue Missions", "comments": "This is the final version accepted by the 2020 International\n  Symposium on Safety, Security and Rescue Robotics (SSRR 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on the teaming aspects and the role of heterogeneity in a\nmulti-robot system applied to robot-aided urban search and rescue (USAR)\nmissions. We propose a needs-driven multi-robot cooperation mechanism\nrepresented through a Behavior Tree structure and evaluate the system's\nperformance in terms of the group utility and energy cost to achieve the rescue\nmission in a limited time. From the theoretical analysis, we prove that the\nneeds-driven cooperation in a heterogeneous robot system enables higher group\nutility than a homogeneous robot system. We also perform simulation experiments\nto verify the proposed needs-driven collaboration and show that the\nheterogeneous multi-robot cooperation can achieve better performance and\nincrease system robustness by reducing uncertainty in task execution. Finally,\nwe discuss the application to human-robot teaming.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 08:37:36 GMT"}, {"version": "v2", "created": "Sun, 25 Oct 2020 15:15:08 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Yang", "Qin", ""], ["Parasuraman", "Ramviyas", ""]]}, {"id": "2009.00519", "submitter": "Andrew Collins", "authors": "Daniele Vernon-Bido, Andrew J. Collins", "title": "Finding Core Members of Cooperative Games using Agent-Based Modeling", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI econ.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Agent-based modeling (ABM) is a powerful paradigm to gain insight into social\nphenomena. One area that ABM has rarely been applied is coalition formation.\nTraditionally, coalition formation is modeled using cooperative game theory. In\nthis paper, a heuristic algorithm is developed that can be embedded into an ABM\nto allow the agents to find coalition. The resultant coalition structures are\ncomparable to those found by cooperative game theory solution approaches,\nspecifically, the core. A heuristic approach is required due to the\ncomputational complexity of finding a cooperative game theory solution which\nlimits its application to about only a score of agents. The ABM paradigm\nprovides a platform in which simple rules and interactions between agents can\nproduce a macro-level effect without the large computational requirements. As\nsuch, it can be an effective means for approximating cooperative game solutions\nfor large numbers of agents. Our heuristic algorithm combines agent-based\nmodeling and cooperative game theory to help find agent partitions that are\nmembers of a games' core solution. The accuracy of our heuristic algorithm can\nbe determined by comparing its outcomes to the actual core solutions. This\ncomparison achieved by developing an experiment that uses a specific example of\na cooperative game called the glove game. The glove game is a type of exchange\neconomy game. Finding the traditional cooperative game theory solutions is\ncomputationally intensive for large numbers of players because each possible\npartition must be compared to each possible coalition to determine the core\nset; hence our experiment only considers games of up to nine players. The\nresults indicate that our heuristic approach achieves a core solution over 90%\nof the time for the games considered in our experiment.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 17:38:43 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Vernon-Bido", "Daniele", ""], ["Collins", "Andrew J.", ""]]}, {"id": "2009.00588", "submitter": "Logan Beaver", "authors": "Logan E. Beaver, Michael Dorothy, Christopher Kroninger, Andreas A.\n  Malikopoulos", "title": "Energy-Optimal Motion Planning for Agents: Barycentric Motion and\n  Collision Avoidance Constraints", "comments": "6 pages, no figures", "journal-ref": "2021 American Control Conference (ACC), pp 1037-1042", "doi": null, "report-no": null, "categories": "math.OC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As robotic swarm systems emerge, it is increasingly important to provide\nstrong guarantees on energy consumption and safety to maximize system\nperformance. One approach to achieve these guarantees is through\nconstraint-driven control, where agents seek to minimize energy consumption\nsubject to a set of safety and task constraints. In this paper, we provide a\nsufficient and necessary condition for an energy-minimizing agent with\nintegrator dynamics to have a continuous control input at the transition\nbetween unconstrained and constrained trajectories. In addition, we present and\nanalyze barycentric motion and collision avoidance constraints to be used in\nconstraint-driven control of swarms.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 17:23:56 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Beaver", "Logan E.", ""], ["Dorothy", "Michael", ""], ["Kroninger", "Christopher", ""], ["Malikopoulos", "Andreas A.", ""]]}, {"id": "2009.00669", "submitter": "Hans Riess", "authors": "Hans Riess, Yiannis Kantaros, George Pappas, Robert Ghrist", "title": "A Temporal Logic-Based Hierarchical Network Connectivity Controller", "comments": "8 pages, 1 algorithm, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.MA cs.SY math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider networks of static sensors with integrated sensing\nand communication capabilities. The goal of the sensors is to propagate their\ncollected information to every other agent in the network and possibly a human\noperator. Such a task requires constant communication among all agents which\nmay result in collisions and congestion in wireless communication. To mitigate\nthis issue, we impose locally non-interfering connectivity constraints that\nmust be respected by every agent. We show that these constraints along with the\nrequirement of propagating information in the network can be captured by a\nLinear Temporal Logic (LTL) framework. Existing temporal logic control\nsynthesis algorithms can be used to design correct-by-construction\ncommunication schedules that satisfy the considered LTL formula. Nevertheless,\nsuch approaches are centralized and scale poorly with the size of the network.\nWe propose a hierarchical LTL-based algorithm that designs communication\nschedules that determine which agents should communicate while maximizing\nnetwork usage. We show that the proposed algorithm is complete and demonstrate\nits efficiency and scalability through analysis and numerical experiments.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 19:19:48 GMT"}, {"version": "v2", "created": "Tue, 16 Mar 2021 19:49:30 GMT"}, {"version": "v3", "created": "Sun, 25 Apr 2021 15:51:55 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Riess", "Hans", ""], ["Kantaros", "Yiannis", ""], ["Pappas", "George", ""], ["Ghrist", "Robert", ""]]}, {"id": "2009.00862", "submitter": "Kooktae Lee", "authors": "Rabiul Hasan Kabir, Kooktae Lee", "title": "Efficient Multi-Robot Exploration with Energy Constraint based on\n  Optimal Transport Theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.MA cs.RO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses an Optimal Transport (OT)-based efficient multi-robot\nexploration problem, considering the energy constraints of a multi-robot\nsystem. The efficiency in this problem implies how a team of robots (agents)\ncovers a given domain, reflecting a priority of areas of interest represented\nby a density distribution, rather than simply following a preset of uniform\npatterns. To achieve an efficient multi-robot exploration, the optimal\ntransport theory that quantifies a distance between two density distributions\nis employed as a tool, which also serves as a means of performance measure. The\nenergy constraints for the multi-robot system is then incorporated into the\nOT-based multi-robot exploration scheme.\n  The proposed scheme is decoupled from robot dynamics, broadening the\napplicability of the multi-robot exploration plan to heterogeneous robot\nplatforms. Not only the centralized but also decentralized algorithms are\nprovided to cope with more realistic scenarios such as communication range\nlimits between agents. To measure the exploration efficiency, the upper bound\nof the performance is developed for both the centralized and decentralized\ncases based on the optimal transport theory, which is computationally tractable\nas well as efficient. The proposed multi-robot exploration scheme is also\napplicable to a time-varying distribution, where the spatio-temporal evolution\nof the given reference distribution is desired. To validate the proposed\nmethod, multiple simulation results are provided.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 07:23:21 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Kabir", "Rabiul Hasan", ""], ["Lee", "Kooktae", ""]]}, {"id": "2009.01455", "submitter": "Wei Su", "authors": "Wei Su, Xueqiao Wang, Ge Chen, Kai Shen", "title": "Quasi-synchronization of bounded confidence opinion dynamics with\n  stochastic asynchronous rule", "comments": "This paper is a full version of the one which has been accepted for\n  publication by the journal SCIS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.SI math.OC nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently the theory of noise-induced synchronization of Hegselmann-Krause\n(HK) dynamics has been well developed. As a typical opinion dynamics of bounded\nconfidence, the HK model obeys a synchronous updating rule, i.e., \\emph{all}\nagents check and update their opinions at each time point. However, whether\nasynchronous bounded confidence models, including the famous Deffuant-Weisbuch\n(DW) model, can be synchronized by noise have not been theoretically proved. In\nthis paper, we propose a generalized bounded confidence model which possesses a\nstochastic asynchronous rule. The model takes the DW model and the HK model as\nspecial cases and can significantly generalize the bounded confidence models to\npractical application. We discover that the asynchronous model possesses a\ndifferent noise-based synchronization behavior compared to the synchronous HK\nmodel. Generally, the HK dynamics can achieve quasi-synchronization\n\\emph{almost surely} under the drive of noise. For the asynchronous dynamics,\nwe prove that the model can achieve quasi-synchronization \\emph{in mean}, which\nis a new type of quasi-synchronization weaker than the \"almost surely\" sense.\nThe results unify the theory of noise-induced synchronization of bounded\nconfidence opinion dynamics and hence proves the noise-induced synchronization\nof DW model theoretically for the first time. Moreover, the results provide a\ntheoretical foundation for developing noise-based control strategy of more\ncomplex social opinion systems with stochastic asynchronous rules.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 05:21:55 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Su", "Wei", ""], ["Wang", "Xueqiao", ""], ["Chen", "Ge", ""], ["Shen", "Kai", ""]]}, {"id": "2009.01490", "submitter": "Qiang Chen", "authors": "Qiang Chen, Yu Zhao, Guanghui Wen, Guoqing Shi and Xinghuo Yu", "title": "Fixed-Time Cooperative Tracking Control for Double-Integrator\n  Multi-Agent Systems: A Time-Based Generator Approach", "comments": "11 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, both the fixed-time distributed consensus tracking and the\nfixed-time distributed average tracking problems for double-integrator-type\nmulti-agent systems with bounded input disturbances are studied, respectively.\nFirstly, a new practical robust fixed-time sliding mode control method based on\nthe time-based generator is proposed. Secondly, a fixed-time distributed\nconsensus tracking observer for double-integrator-type multi-agent systems is\ndesigned to estimate the state disagreements between the leader and the\nfollowers under undirected and directed communication, respectively. Thirdly, a\nfixed-time distributed average tracking observer for double-integrator-type\nmulti-agent systems is designed to measure the average value of reference\nsignals under undirected communication. Note that both the observers for the\ndistributed consensus tracking and the distributed average tracking are devised\nbased on time-based generators and can be extended to that of high-order\nmulti-agent systems trivially. Furthermore, by combing the fixed-time sliding\nmode control with the fixed-time observers, the fixed-time controllers are\ndesigned to solve the distributed consensus tracking and the distributed\naverage tracking problems. Finally, a few numerical simulations are shown to\nverify the results.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 07:08:04 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Chen", "Qiang", ""], ["Zhao", "Yu", ""], ["Wen", "Guanghui", ""], ["Shi", "Guoqing", ""], ["Yu", "Xinghuo", ""]]}, {"id": "2009.01502", "submitter": "Pengyuan Zhou", "authors": "Pengyuan Zhou, Xianfu Chen, Zhi Liu, Tristan Braud, Pan Hui, Jussi\n  Kangasharju", "title": "DRLE: Decentralized Reinforcement Learning at the Edge for Traffic Light\n  Control in the IoV", "comments": "Accepted by IEEE Transactions on Intelligent Transportation Systems", "journal-ref": null, "doi": "10.1109/TITS.2020.3035841", "report-no": null, "categories": "cs.MA cs.DC cs.LG cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The Internet of Vehicles (IoV) enables real-time data exchange among vehicles\nand roadside units and thus provides a promising solution to alleviate traffic\njams in the urban area. Meanwhile, better traffic management via efficient\ntraffic light control can benefit the IoV as well by enabling a better\ncommunication environment and decreasing the network load. As such, IoV and\nefficient traffic light control can formulate a virtuous cycle. Edge computing,\nan emerging technology to provide low-latency computation capabilities at the\nedge of the network, can further improve the performance of this cycle.\nHowever, while the collected information is valuable, an efficient solution for\nbetter utilization and faster feedback has yet to be developed for\nedge-empowered IoV. To this end, we propose a Decentralized Reinforcement\nLearning at the Edge for traffic light control in the IoV (DRLE). DRLE exploits\nthe ubiquity of the IoV to accelerate the collection of traffic data and its\ninterpretation towards alleviating congestion and providing better traffic\nlight control. DRLE operates within the coverage of the edge servers and uses\naggregated data from neighboring edge servers to provide city-scale traffic\nlight control. DRLE decomposes the highly complex problem of large area\ncontrol. into a decentralized multi-agent problem. We prove its global optima\nwith concrete mathematical reasoning. The proposed decentralized reinforcement\nlearning algorithm running at each edge node adapts the traffic lights in real\ntime. We conduct extensive evaluations and demonstrate the superiority of this\napproach over several state-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 08:09:04 GMT"}, {"version": "v2", "created": "Tue, 5 Jan 2021 10:03:08 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Zhou", "Pengyuan", ""], ["Chen", "Xianfu", ""], ["Liu", "Zhi", ""], ["Braud", "Tristan", ""], ["Hui", "Pan", ""], ["Kangasharju", "Jussi", ""]]}, {"id": "2009.01625", "submitter": "Saaduddin Mahmud", "authors": "Saaduddin Mahmud, Md. Mosaddek Khan, Nicholas R. Jennings", "title": "On Population-Based Algorithms for Distributed Constraint Optimization\n  Problems", "comments": "7 Figures. arXiv admin note: text overlap with arXiv:1909.06254,\n  arXiv:2002.12001", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed Constraint Optimization Problems (DCOPs) are a widely studied\nclass of optimization problems in which interaction between a set of\ncooperative agents are modeled as a set of constraints. DCOPs are NP-hard and\nsignificant effort has been devoted to developing methods for finding\nincomplete solutions. In this paper, we study an emerging class of such\nincomplete algorithms that are broadly termed as population-based algorithms.\nThe main characteristic of these algorithms is that they maintain a population\nof candidate solutions of a given problem and use this population to cover a\nlarge area of the search space and to avoid local-optima. In recent years, this\nclass of algorithms has gained significant attention due to their ability to\nproduce high-quality incomplete solutions. With the primary goal of further\nimproving the quality of solutions compared to the state-of-the-art incomplete\nDCOP algorithms, we present two new population-based algorithms in this paper.\nOur first approach, Anytime Evolutionary DCOP or AED, exploits evolutionary\noptimization meta-heuristics to solve DCOPs. We also present a novel anytime\nupdate mechanism that gives AED its anytime property. While in our second\ncontribution, we show that population-based approaches can be combined with\nlocal search approaches. Specifically, we develop an algorithm called DPSA\nbased on the Simulated Annealing meta-heuristic. We empirically evaluate these\ntwo algorithms to illustrate their respective effectiveness in different\nsettings against the state-of-the-art incomplete DCOP algorithms including all\nexisting population-based algorithms in a wide variety of benchmarks. Our\nevaluation shows AED and DPSA markedly outperform the state-of-the-art and\nproduce up to 75% improved solutions.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 06:39:30 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Mahmud", "Saaduddin", ""], ["Khan", "Md. Mosaddek", ""], ["Jennings", "Nicholas R.", ""]]}, {"id": "2009.01921", "submitter": "Suyun Bae", "authors": "Suyun Bae, Federico Rossi, Joshua Vander Hook, Scott Davidoff, and\n  Kwan-Liu Ma", "title": "A Visual Analytics Approach to Debugging Cooperative, Autonomous\n  Multi-Robot Systems' Worldviews", "comments": "To appear in IEEE Conference on Visual Analytics Science and\n  Technology (VAST) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous multi-robot systems, where a team of robots shares information to\nperform tasks that are beyond an individual robot's abilities, hold great\npromise for a number of applications, such as planetary exploration missions.\nEach robot in a multi-robot system that uses the shared-world coordination\nparadigm autonomously schedules which robot should perform a given task, and\nwhen, using its worldview--the robot's internal representation of its belief\nabout both its own state, and other robots' states. A key problem for operators\nis that robots' worldviews can fall out of sync (often due to weak\ncommunication links), leading to desynchronization of the robots' scheduling\ndecisions and inconsistent emergent behavior (e.g., tasks not performed, or\nperformed by multiple robots). Operators face the time-consuming and difficult\ntask of making sense of the robots' scheduling decisions, detecting\nde-synchronizations, and pinpointing the cause by comparing every robot's\nworldview. To address these challenges, we introduce MOSAIC Viewer, a visual\nanalytics system that helps operators (i) make sense of the robots' schedules\nand (ii) detect and conduct a root cause analysis of the robots' desynchronized\nworldviews. Over a year-long partnership with roboticists at the NASA Jet\nPropulsion Laboratory, we conduct a formative study to identify the necessary\nsystem design requirements and a qualitative evaluation with 12 roboticists. We\nfind that MOSAIC Viewer is faster- and easier-to-use than the users' current\napproaches, and it allows them to stitch low-level details to formulate a\nhigh-level understanding of the robots' schedules and detect and pinpoint the\ncause of the desynchronized worldviews.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 21:01:02 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Bae", "Suyun", ""], ["Rossi", "Federico", ""], ["Hook", "Joshua Vander", ""], ["Davidoff", "Scott", ""], ["Ma", "Kwan-Liu", ""]]}, {"id": "2009.02158", "submitter": "Andreas Schadschneider", "authors": "Stefan Bittihn, Andreas Schadschneider", "title": "Braess' paradox in the age of traffic information", "comments": "37 pages, 15 figures", "journal-ref": "J. Stat. Mech. (2021) 033401", "doi": "10.1088/1742-5468/abdeae", "report-no": null, "categories": "physics.soc-ph cs.MA nlin.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Braess paradox describes the counterintuitive situation that the addition\nof new roads to road networks can lead to higher travel times for all network\nusers. Recently we could show that user optima leading to the paradox exist in\nnetworks of microscopic transport models. We derived phase diagrams for two\nkinds of route choice strategies that were externally tuned and applied by all\nnetwork users. Here we address the question whether these user optima are still\nrealized if intelligent route choice decisions are made based upon two kinds of\ntraffic information. We find that the paradox still can occur if the drivers 1)\nmake informed decisions based on their own past experiences or 2) use traffic\ninformation similar to that provided by modern navigation apps. This indicates\nthat modern traffic information systems are not able to resolve Braess'\nparadox.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 12:44:17 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Bittihn", "Stefan", ""], ["Schadschneider", "Andreas", ""]]}, {"id": "2009.02166", "submitter": "Cornelis Jan Van Leeuwen", "authors": "Cornelis Jan van Leeuwen, Joost Stam, Arun Subramanian, Koen Kok", "title": "Collaboratively Optimizing Power Scheduling and Mitigating Congestion\n  using Local Pricing in a Receding Horizon Market", "comments": "10 pages, 9 figures, 2 tables, 1 algorithm in pseudocode", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A distributed, hierarchical, market based approach is introduced to solve the\neconomic dispatch problem. The approach requires only a minimal amount of\ninformation to be shared between a central market operator and the end-users.\nPrice signals from the market operator are sent down to end-user device agents,\nwhich in turn respond with power schedules. Intermediate congestion agents make\nsure that local power constraints are satisfied and any potential congestion is\navoided by adding local pricing differences. Our results show that in 20% of\nthe evaluated scenarios the solutions are identical to the global optimum when\nperfect knowledge is available. In the other 80% the results are not\nsignificantly worse, while providing a higher level of scalability and\nincreasing the consumer's privacy.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 13:04:50 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["van Leeuwen", "Cornelis Jan", ""], ["Stam", "Joost", ""], ["Subramanian", "Arun", ""], ["Kok", "Koen", ""]]}, {"id": "2009.02240", "submitter": "Cornelis Jan Van Leeuwen", "authors": "Cornelis Jan van Leeuwen and Przemyz{\\l}aw Pawe{\\l}czak", "title": "Hybrid DCOP Solvers: Boosting Performance of Local Search Algorithms", "comments": "16 pages, 6 figures, 2 tables, 2 algorithms with pseudocode.\n  Presented at the International Workshop on Optimization in Multiagent Systems\n  (OptMAS-18), during the AAMAS conference 2018 in Stockholm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel method for expediting both symmetric and asymmetric\nDistributed Constraint Optimization Problem (DCOP) solvers. The core idea is\nbased on initializing DCOP solvers with greedy fast non-iterative DCOP solvers.\nThis is contrary to existing methods where initialization is always achieved\nusing a random value assignment. We empirically show that changing the starting\nconditions of existing DCOP solvers not only reduces the algorithm convergence\ntime by up to 50\\%, but also reduces the communication overhead and leads to a\nbetter solution quality. We show that this effect is due to structural\nimprovements in the variable assignment, which is caused by the spreading\npattern of DCOP algorithm activation.) /Subject (Hybrid DCOPs)\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 15:17:24 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["van Leeuwen", "Cornelis Jan", ""], ["Pawe\u0142czak", "Przemyz\u0142aw", ""]]}, {"id": "2009.02542", "submitter": "Taufik Abrao PhD", "authors": "Jos\\'e Carlos Marinello, Taufik Abr\\~ao, Abolfazl Amiri, Elisabeth de\n  Carvalho, Petar Popovski", "title": "Antenna Selection for Improving Energy Efficiency in XL-MIMO Systems", "comments": "24 pages, 7 figures, 1 table and 22 references", "journal-ref": null, "doi": null, "report-no": "VT-2020-01622.R1", "categories": "eess.SP cs.LG cs.MA cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the recently proposed extra-large scale massive multiple-input\nmultiple-output (XL-MIMO) systems, with some hundreds of antennas serving a\nsmaller number of users. Since the array length is of the same order as the\ndistance to the users, the long-term fading coefficients of a given user vary\nwith the different antennas at the base station (BS). Thus, the signal\ntransmitted by some antennas might reach the user with much more power than\nthat transmitted by some others. From a green perspective, it is not effective\nto simultaneously activate hundreds or even thousands of antennas, since the\npower-hungry radio frequency (RF) chains of the active antennas increase\nsignificantly the total energy consumption. Besides, a larger number of\nselected antennas increases the power required by linear processing, such as\nprecoding matrix computation, and short-term channel estimation. In this paper,\nwe propose four antenna selection (AS) approaches to be deployed in XL-MIMO\nsystems aiming at maximizing the total energy efficiency (EE). Besides,\nemploying some simplifying assumptions, we derive a closed-form analytical\nexpression for the EE of the XL-MIMO system, and propose a straightforward\niterative method to determine the optimal number of selected antennas able to\nmaximize it. The proposed AS schemes are based solely on long-term fading\nparameters, thus, the selected antennas set remains valid for a relatively\nlarge time/frequency intervals. Comparing the results, we find that the\ngenetic-algorithm based AS scheme usually achieves the best EE performance,\nalthough our proposed highest normalized received power AS scheme also achieves\nvery promising EE performance in a simple and straightforward way.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 14:43:21 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Marinello", "Jos\u00e9 Carlos", ""], ["Abr\u00e3o", "Taufik", ""], ["Amiri", "Abolfazl", ""], ["de Carvalho", "Elisabeth", ""], ["Popovski", "Petar", ""]]}, {"id": "2009.02690", "submitter": "Nimrod Talmon", "authors": "Piotr Skowron, Arkadii Slinko, Stanis{\\l}aw Szufa, Nimrod Talmon", "title": "Participatory Budgeting with Cumulative Votes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In participatory budgeting we are given a set of projects---each with a cost,\nan available budget, and a set of voters who in some form express their\npreferences over the projects. The goal is to select---based on voter\npreferences---a subset of projects whose total cost does not exceed the budget.\nWe propose several aggregation methods based on the idea of cumulative votes,\ne.g., for the setting when each voter is given one coin and she specifies how\nthis coin should be split among the projects. We compare our aggregation\nmethods based on (1) axiomatic properties, and (2) computer simulations. We\nidentify one method, Minimal Transfers over Costs, that demonstrates\nparticularly desirable behavior. In particular, it significantly improves on\nexisting methods, satisfies a strong notion of proportionality, and, thus, is\npromising to be used in practice.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 09:46:14 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Skowron", "Piotr", ""], ["Slinko", "Arkadii", ""], ["Szufa", "Stanis\u0142aw", ""], ["Talmon", "Nimrod", ""]]}, {"id": "2009.02714", "submitter": "Anton V. Proskurnikov", "authors": "Anton V. Proskurnikov, Guiseppe Calafiore", "title": "New Results on Delay Robustness of Consensus Algorithms", "comments": "An extended version of a conference paper to be presented on IEEE\n  Conference on Decision and Control 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.MA cs.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consensus of autonomous agents is a benchmark problem in cooperative control.\nIn this paper, we consider standard continuous-time averaging consensus\npolicies (or Laplacian flows) over time-varying graphs and focus on robustness\nof consensus against communication delays. Such a robustness has been proved\nunder the assumption of uniform quasi-strong connectivity of the graph. It is\nknown, however, that the uniform connectivity is not necessary for consensus.\nFor instance, in the case of undirected graph and undelayed communication\nconsensus requires a much weaker condition of integral connectivity. In this\npaper, we show that the latter results remain valid in presence of unknown but\nbounded communication delays, furthermore, the condition of undirected graph\ncan be substantially relaxed and replaced by the conditions of\nnon-instantaneous type-symmetry. Furthermore, consensus can be proved for any\nfeasible solution of the delay differential inequalities associated to the\nconsensus algorithm. Such inequalities naturally arise in problems of\ncontainment control, distributed optimization and models of social dynamics.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 11:40:16 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Proskurnikov", "Anton V.", ""], ["Calafiore", "Guiseppe", ""]]}, {"id": "2009.02762", "submitter": "Yue Yang", "authors": "Yue Yang, Wencang Bao, Mohsen Ramezani, Zhe Xu", "title": "Real-time and Large-scale Fleet Allocation of Autonomous Taxis: A Case\n  Study in New York Manhattan Island", "comments": "Double-check the formulas", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, autonomous taxis become a highly promising transportation mode,\nwhich helps relieve traffic congestion and avoid road accidents. However, it\nhinders the wide implementation of this service that traditional models fail to\nefficiently allocate the available fleet to deal with the imbalance of supply\n(autonomous taxis) and demand (trips), the poor cooperation of taxis, hardly\nsatisfied resource constraints, and on-line platform's requirements. To figure\nout such urgent problems from a global and more farsighted view, we employ a\nConstrained Multi-agent Markov Decision Processes (CMMDP) to model fleet\nallocation decisions, which can be easily split into sub-problems formulated as\na 'Dynamic assignment problem' combining both immediate rewards and future\ngains. We also leverage a Column Generation algorithm to guarantee the\nefficiency and optimality in a large scale. Through extensive experiments, the\nproposed approach not only achieves remarkable improvements over the\nstate-of-the-art benchmarks in terms of the individual's efficiency (arriving\nat 12.40%, 6.54% rise of income and utilization, respectively) and the\nplatform's profit (reaching 4.59% promotion) but also reveals a time-varying\nfleet adjustment policy to minimize the operation cost of the platform.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 16:00:15 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 01:46:34 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Yang", "Yue", ""], ["Bao", "Wencang", ""], ["Ramezani", "Mohsen", ""], ["Xu", "Zhe", ""]]}, {"id": "2009.02970", "submitter": "Charles Monnoyer de Galland de Carni\\`eres", "authors": "Charles Monnoyer de Galland, Samuel Martin and Julien M. Hendrickx", "title": "Open Multi-Agent Systems with Variable Size: the Case of Gossiping", "comments": "13 pages, 12 figures, submitted to IEEE Transactions on Automatic\n  Control (ITAC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider open multi-agent systems, which are systems subject to frequent\narrivals and departures of agents while the process studied takes place. We\nstudy the behavior of all-to-all pairwise gossip interactions in such open\nsystems. Arrivals and departures of agents imply that the composition and size\nof the system evolve with time, and in particular prevent convergence. We\ndescribe the expected behavior of the system by showing that the evolution of\nscale-independent quantities can be characterized exactly by a fixed size\nlinear dynamical system. We apply this approach to characterize the evolution\nof the two first moments (and thus also of the variance) for open systems of\nboth fixed and variable size. Our approach is based on the continuous time\nmodelling of random asynchronous events, namely gossip steps, arrivals,\ndepartures, and replacements.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 09:30:56 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["de Galland", "Charles Monnoyer", ""], ["Martin", "Samuel", ""], ["Hendrickx", "Julien M.", ""]]}, {"id": "2009.02979", "submitter": "Matthew Harrison-Trainor", "authors": "Matthew Harrison-Trainor", "title": "An Analysis of Random Elections with Large Numbers of Voters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.TH cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In an election in which each voter ranks all of the candidates, we consider\nthe head-to-head results between each pair of candidates and form a labeled\ndirected graph, called the margin graph, which contains the margin of victory\nof each candidate over each of the other candidates. A central issue in\ndeveloping voting methods is that there can be cycles in this graph, where\ncandidate $\\mathsf{A}$ defeats candidate $\\mathsf{B}$, $\\mathsf{B}$ defeats\n$\\mathsf{C}$, and $\\mathsf{C}$ defeats $\\mathsf{A}$. In this paper we apply the\ncentral limit theorem, graph homology, and linear algebra to analyze how likely\nsuch situations are to occur for large numbers of voters. There is a large\nliterature on analyzing the probability of having a majority winner; our\nanalysis is more fine-grained. The result of our analysis is that in elections\nwith the number of voters going to infinity, margin graphs that are more cyclic\nin a certain precise sense are less likely to occur.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 09:46:34 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Harrison-Trainor", "Matthew", ""]]}, {"id": "2009.02997", "submitter": "Filippo Bistaffa", "authors": "Filippo Bistaffa, Juan A. Rodr\\'iguez-Aguilar, Jes\\'us Cerquides", "title": "Predicting Requests in Large-Scale Online P2P Ridesharing", "comments": "Presented at the 1st International Workshop on Optimization and\n  Learning in Multiagent Systems (OptLearnMAS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Peer-to-peer ridesharing (P2P-RS) enables people to arrange one-time rides\nwith their own private cars, without the involvement of professional drivers.\nIt is a prominent collective intelligence application producing significant\nbenefits both for individuals (reduced costs) and for the entire community\n(reduced pollution and traffic), as we showed in a recent publication where we\nproposed an online approximate solution algorithm for large-scale P2P-RS. In\nthis paper we tackle the fundamental question of assessing the benefit of\npredicting ridesharing requests in the context of P2P-RS optimisation. Results\non a public real-world show that, by employing a perfect predictor, the total\nreward can be improved by 5.27% with a forecast horizon of 1 minute. On the\nother hand, a vanilla long short-term memory neural network cannot improve upon\na baseline predictor that simply replicates the previous day's requests, whilst\nachieving an almost-double accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 10:27:24 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Bistaffa", "Filippo", ""], ["Rodr\u00edguez-Aguilar", "Juan A.", ""], ["Cerquides", "Jes\u00fas", ""]]}, {"id": "2009.03168", "submitter": "Ankit Sharma", "authors": "Ankit Sharma, Shreyash Arya, Shashee Kumari and Arnab Chatterjee", "title": "Effect of lockdown interventions to control the COVID-19 epidemic in\n  India", "comments": "21 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.MA q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The pandemic caused by the novel Coronavirus SARS-CoV2 has been responsible\nfor life threatening health complications, and extreme pressure on healthcare\nsystems. While preventive and definite curative medical interventions are yet\nto arrive, Non-Pharmaceutical Interventions (NPIs) like physical isolation,\nquarantine and drastic social measures imposed by governing agencies are\neffective in arresting the spread of infections in a population. In densely\npopulated countries like India, lockdown interventions are partially effective\ndue to social and administrative complexities. Using detailed demographic data,\nwe present an agent based model to imitate the behavior of the population and\nits mobility features, even under intervention. We demonstrate the\neffectiveness of contact tracing policies and how our model efficiently relates\nto empirical findings on testing efficiency. We also present various lockdown\nintervention strategies for mitigation - using the bare number of infections,\nthe effective reproduction rate, as well as using reinforcement learning. Our\nanalysis can help assess the socio-economic consequences of such interventions,\nand provide useful ideas and insights to policy makers for better decision\nmaking.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 15:36:34 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Sharma", "Ankit", ""], ["Arya", "Shreyash", ""], ["Kumari", "Shashee", ""], ["Chatterjee", "Arnab", ""]]}, {"id": "2009.03775", "submitter": "Wicak Ananduta", "authors": "Wicak Ananduta, Carlos Ocampo-Martinez, and Angelia Nedi\\'c", "title": "Accelerated Multi-Agent Optimization Method over Stochastic Networks", "comments": "to appear at the 59th Conference on Decision and Control", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a distributed method to solve a multi-agent optimization problem\nwith strongly convex cost function and equality coupling constraints. The\nmethod is based on Nesterov's accelerated gradient approach and works over\nstochastically time-varying communication networks. We consider the standard\nassumptions of Nesterov's method and show that the sequence of the expected\ndual values converge toward the optimal value with the rate of\n$\\mathcal{O}(1/k^2)$. Furthermore, we provide a simulation study of solving an\noptimal power flow problem with a well-known benchmark case.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 14:07:38 GMT"}, {"version": "v2", "created": "Wed, 16 Dec 2020 10:16:57 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Ananduta", "Wicak", ""], ["Ocampo-Martinez", "Carlos", ""], ["Nedi\u0107", "Angelia", ""]]}, {"id": "2009.03934", "submitter": "George Sidiropoulos", "authors": "George Sidiropoulos, Chairi Kiourt, Lefteris Moussiades", "title": "Metis: Multi-Agent Based Crisis Simulation System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advent of the computational technologies (Graphics Processing Units\n- GPUs) and Machine Learning, the research domain of crowd simulation for\ncrisis management has flourished. Along with the new techniques and\nmethodologies that have been proposed all those years, aiming to increase the\nrealism of crowd simulation, several crisis simulation systems/tools have been\ndeveloped, but most of them focus on special cases without providing users the\nability to adapt them based on their needs. Towards these directions, in this\npaper, we introduce a novel multi-agent-based crisis simulation system for\nindoor cases. The main advantage of the system is its ease of use feature,\nfocusing on non-expert users (users with little to no programming skills) that\ncan exploit its capabilities a, adapt the entire environment based on their\nneeds (Case studies) and set up building evacuation planning experiments with\nsome of the most popular Reinforcement Learning algorithms. Simply put, the\nsystem's features focus on dynamic environment design and crisis management,\ninterconnection with popular Reinforcement Learning libraries, agents with\ndifferent characteristics (behaviors), fire propagation parameterization,\nrealistic physics based on popular game engine, GPU-accelerated agents training\nand simulation end conditions. A case study exploiting a popular reinforcement\nlearning algorithm, for training of the agents, presents the dynamics and the\ncapabilities of the proposed systems and the paper is concluded with the\nhighlights of the system and some future directions.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 18:22:27 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Sidiropoulos", "George", ""], ["Kiourt", "Chairi", ""], ["Moussiades", "Lefteris", ""]]}, {"id": "2009.04197", "submitter": "Jian Hu", "authors": "Jian Hu, Seth Austin Harding, Haibin Wu, Siyue Hu, Shih-wei Liao", "title": "QR-MIX: Distributional Value Function Factorisation for Cooperative\n  Multi-Agent Reinforcement Learning", "comments": "There are some experimental errors and experimental unfairness in\n  this paper that will seriously affect the later studies", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Cooperative Multi-Agent Reinforcement Learning (MARL) and under the\nsetting of Centralized Training with Decentralized Execution (CTDE), agents\nobserve and interact with their environment locally and independently. With\nlocal observation and random sampling, the randomness in rewards and\nobservations leads to randomness in long-term returns. Existing methods such as\nValue Decomposition Network (VDN) and QMIX estimate the value of long-term\nreturns as a scalar that does not contain the information of randomness. Our\nproposed model QR-MIX introduces quantile regression, modeling joint\nstate-action values as a distribution, combining QMIX with Implicit Quantile\nNetwork (IQN). However, the monotonicity in QMIX limits the expression of joint\nstate-action value distribution and may lead to incorrect estimation results in\nnon-monotonic cases. Therefore, we proposed a flexible loss function to\napproximate the monotonicity found in QMIX. Our model is not only more tolerant\nof the randomness of returns, but also more tolerant of the randomness of\nmonotonic constraints. The experimental results demonstrate that QR-MIX\noutperforms the previous state-of-the-art method QMIX in the StarCraft\nMulti-Agent Challenge (SMAC) environment.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 10:28:44 GMT"}, {"version": "v2", "created": "Tue, 15 Sep 2020 06:19:53 GMT"}, {"version": "v3", "created": "Mon, 28 Sep 2020 13:19:11 GMT"}, {"version": "v4", "created": "Thu, 15 Oct 2020 08:10:48 GMT"}, {"version": "v5", "created": "Tue, 23 Feb 2021 12:37:48 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Hu", "Jian", ""], ["Harding", "Seth Austin", ""], ["Wu", "Haibin", ""], ["Hu", "Siyue", ""], ["Liao", "Shih-wei", ""]]}, {"id": "2009.04327", "submitter": "Iain Barclay", "authors": "Iain Barclay, Maria Freytsis, Sherri Bucher, Swapna Radha, Alun Preece\n  and Ian Taylor", "title": "Towards a Modelling Framework for Self-Sovereign Identity Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-sovereign Identity promises to give users control of their own data, and\nhas the potential to foster advancements in terms of personal data privacy.\nSelf-sovereign concepts can also be applied to other entities, such as datasets\nand devices. Systems adopting this paradigm will be decentralised, with\nmessages passing between multiple actors, both human and representing other\nentities, in order to issue and request credentials necessary to meet\nindividual and collective goals. Such systems are complex, and build upon\nsocial and technical interactions and behaviours. Modelling self-sovereign\nidentity systems seeks to provide stakeholders and software architects with\ntools to enable them to communicate effectively, and lead to effective and\nwell-regarded system designs and implementations. This paper draws upon\nresearch from Actor-based Modelling to guide a way forward in modelling\nself-sovereign systems, and reports early success in utilising the iStar 2.0\nframework to provide a representation of a birth registration case study.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 14:32:28 GMT"}, {"version": "v2", "created": "Thu, 10 Sep 2020 09:12:29 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Barclay", "Iain", ""], ["Freytsis", "Maria", ""], ["Bucher", "Sherri", ""], ["Radha", "Swapna", ""], ["Preece", "Alun", ""], ["Taylor", "Ian", ""]]}, {"id": "2009.04593", "submitter": "Siddharth Mayya", "authors": "Siddharth Mayya, Diego S. D'antonio, David Salda\\~na, Vijay Kumar", "title": "Resilient Task Allocation in Heterogeneous Multi-Robot Systems", "comments": "A modified version has been submitted to IEEE Robotics and Automation\n  Letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.RO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  For a multi-robot system equipped with heterogeneous capabilities, this paper\npresents a mechanism to allocate robots to tasks in a resilient manner when\nanomalous environmental conditions such as weather events or adversarial\nattacks affect the performance of robots within the tasks. Our primary\nobjective is to ensure that each task is assigned the requisite level of\nresources, measured as the aggregated capabilities of the robots allocated to\nthe task. By keeping track of task performance deviations under external\nperturbations, our framework quantifies the extent to which robot capabilities\n(e.g., visual sensing or aerial mobility) are affected by environmental\nconditions. This enables an optimization-based framework to flexibly reallocate\nrobots to tasks based on the most degraded capabilities within each task. In\nthe face of resource limitations and adverse environmental conditions, our\nalgorithm minimally relaxes the resource constraints corresponding to some\ntasks, thus exhibiting a graceful degradation of performance. Simulated\nexperiments in a multi-robot coverage and target tracking scenario demonstrate\nthe efficacy of the proposed approach.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 22:42:46 GMT"}, {"version": "v2", "created": "Thu, 7 Jan 2021 17:37:38 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Mayya", "Siddharth", ""], ["D'antonio", "Diego S.", ""], ["Salda\u00f1a", "David", ""], ["Kumar", "Vijay", ""]]}, {"id": "2009.04655", "submitter": "Chiao Hsieh", "authors": "Chiao Hsieh (1), Hussein Sibai (1), Hebron Taylor (1), Yifeng Ni (1),\n  Sayan Mitra (1) ((1) University of Illinois at Urbana-Champaign)", "title": "SkyTrakx: A Toolkit for Simulation and Verification of Unmanned\n  Air-Traffic Management Systems (Extended Version)", "comments": "11 pages, 11 figures; This is the extended version of the paper with\n  the same title accepted by the 24th IEEE International Conference on\n  Intelligent Transportation (ITSC 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The key concept for safe and efficient traffic management for Unmanned\nAircraft Systems (UAS) is the notion of operation volume (OV). An OV is a\n4-dimensional block of airspace and time, which can express an aircraft's\nintent, and can be used for planning, de-confliction, and traffic management.\nWhile there are several high-level simulators for UAS Traffic Management (UTM),\nwe are lacking a framework for creating, manipulating, and reasoning about OVs\nfor heterogeneous air vehicles. In this paper, we address this and present\nSkyTrakx -- a software toolkit for simulation and verification of UTM scenarios\nbased on OVs. First, we illustrate a use case of SkyTrakx by presenting a\nspecific air traffic coordination protocol. This protocol communicates OVs\nbetween participating aircraft and an airspace manager for traffic routing. We\nshow how existing formal verification tools, Dafny and Dione, can assist in\nautomatically checking key properties of the protocol. Second, we show how the\nOVs can be computed for heterogeneous air vehicles like quadcopters and\nfixed-wing aircraft using another verification technique, namely reachability\nanalysis. Finally, we show that SkyTrakx can be used to simulate complex\nscenarios involving heterogeneous vehicles, for testing and performance\nevaluation in terms of workload and response delays analysis. Our experiments\ndelineate the trade-off between performance and workload across different\nstrategies for generating OVs.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 03:52:49 GMT"}, {"version": "v2", "created": "Fri, 18 Dec 2020 18:10:37 GMT"}, {"version": "v3", "created": "Sun, 11 Jul 2021 18:13:16 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Hsieh", "Chiao", "", "University of Illinois at Urbana-Champaign"], ["Sibai", "Hussein", "", "University of Illinois at Urbana-Champaign"], ["Taylor", "Hebron", "", "University of Illinois at Urbana-Champaign"], ["Ni", "Yifeng", "", "University of Illinois at Urbana-Champaign"], ["Mitra", "Sayan", "", "University of Illinois at Urbana-Champaign"]]}, {"id": "2009.04801", "submitter": "Marco Karrer", "authors": "Marco Karrer and Margarita Chli", "title": "Distributed Variable-Baseline Stereo SLAM from two UAVs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  VIO has been widely used and researched to control and aid the automation of\nnavigation of robots especially in the absence of absolute position\nmeasurements, such as GPS. However, when observable landmarks in the scene lie\nfar away from the robot's sensor suite, as it is the case at high altitude\nflights, the fidelity of estimates and the observability of the metric scale\ndegrades greatly for these methods. Aiming to tackle this issue, in this\narticle, we employ two UAVs equipped with one monocular camera and one IMU\neach, to exploit their view overlap and relative distance measurements between\nthem using UWB modules onboard to enable collaborative VIO. In particular, we\npropose a novel, distributed fusion scheme enabling the formation of a virtual\nstereo camera rig with adjustable baseline from the two UAVs. In order to\ncontrol the \\gls{uav} agents autonomously, we propose a decentralized\ncollaborative estimation scheme, where each agent hold its own local map,\nachieving an average pose estimation latency of 11ms, while ensuring\nconsistency of the agents' estimates via consensus based optimization.\nFollowing a thorough evaluation on photorealistic simulations, we demonstrate\nthe effectiveness of the approach at high altitude flights of up to 160m, going\nsignificantly beyond the capabilities of state-of-the-art VIO methods. Finally,\nwe show the advantage of actively adjusting the baseline on-the-fly over a\nfixed, target baseline, reducing the error in our experiments by a factor of\ntwo.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 12:16:10 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Karrer", "Marco", ""], ["Chli", "Margarita", ""]]}, {"id": "2009.04981", "submitter": "Mattia Bianchi", "authors": "Mattia Bianchi and Sergio Grammatico", "title": "Nash equilibrium seeking under partial-decision information over\n  directed communication networks", "comments": "To appear in the 59th Conference on Decision and Control (CDC 2020)", "journal-ref": null, "doi": "10.1109/CDC42340.2020.9304267", "report-no": null, "categories": "math.OC cs.DC cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the Nash equilibrium problem in a partial-decision information\nscenario. Specifically, each agent can only receive information from some\nneighbors via a communication network, while its cost function depends on the\nstrategies of possibly all agents. In particular, while the existing methods\nassume undirected or balanced communication, in this paper we allow for\nnon-balanced, directed graphs. We propose a fully-distributed pseudo-gradient\nscheme, which is guaranteed to converge with linear rate to a Nash equilibrium,\nunder strong monotonicity and Lipschitz continuity of the game mapping. Our\nalgorithm requires global knowledge of the communication structure, namely of\nthe Perron-Frobenius eigenvector of the adjacency matrix and of a certain\nconstant related to the graph connectivity. Therefore, we adapt the procedure\nto setups where the network is not known in advance, by computing the\neigenvector online and by means of vanishing step sizes.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 16:44:04 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Bianchi", "Mattia", ""], ["Grammatico", "Sergio", ""]]}, {"id": "2009.05208", "submitter": "S. Rasoul Etesami", "authors": "S. Rasoul Etesami", "title": "Consensus under Network Interruption and Effective Resistance\n  Interdiction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.CC cs.MA cs.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of network robustness under consensus dynamics. We first\nshow that the consensus interdiction problem (CIP), in which the goal is to\nmaximize the convergence time of consensus dynamics subject to removing limited\nnetwork edges, can be cast as an effective resistance interdiction problem\n(ERIP). We then show that ERIP is strongly NP-hard, even for bipartite graphs\nof diameter three with fixed source/sink edges. We establish the same hardness\nresult for the CIP, hence correcting some claims in the existing literature. We\nthen show that both ERIP and CIP do not admit a polynomial-time approximation\nscheme, and moreover, they cannot be approximated up to a (nearly) polynomial\nfactor assuming exponential time hypothesis. Finally, using a quadratic program\nformulation, we devise a polynomial-time $n^4$-approximation algorithm for ERIP\nthat only depends on the number of nodes $n$ and is independent of the size of\nedge resistances. We also develop an iterative heuristic approximation\nalgorithm to find a local optimum for the CIP.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 02:40:57 GMT"}, {"version": "v2", "created": "Fri, 9 Oct 2020 03:52:56 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Etesami", "S. Rasoul", ""]]}, {"id": "2009.05282", "submitter": "Sahbi Sidhom", "authors": "Pedro Barrios, Davy Monticolo (ENSGSI), Sahbi Sidhom (KIWI)", "title": "Results of multi-agent system and ontology to manage ideas and represent\n  knowledge in a challenge of creativity", "comments": null, "journal-ref": "International Multi-Conference OCTA'2019 on Organization of\n  Knowledge and Advanced Technologies, University of Tunis (Tunisia) &\n  International scholarly society ISKO Maghreb, Feb 2020, Tunis (ALECSO),\n  Tunisia. pp.6-17", "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article is about an intelligent system to support ideas management as a\nresult of a multi-agent system used in a distributed system with heterogeneous\ninformation as ideas and knowledge, after the results about an ontology to\ndescribe the meaning of these ideas. The intelligent system assists\nparticipants of the creativity workshop to manage their ideas and consequently\nproposing an ontology dedicated to ideas. During the creative workshop many\ncreative activities and collaborative creative methods are used by roles\nimmersed in this creativity workshop event where they share knowledge. The\ncollaboration of these roles is physically distant, their interactions might be\nsynchrony or asynchrony, and the information of the ideas are heterogeneous, so\nwe can say that the process is distributed. Those ideas are writing in natural\nlanguage by participants which have a role and the ideas are heterogeneous\nsince some of them are described by schema, text or scenario of use. This paper\npresents first, our MAS and second our Ontology design.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 08:31:30 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Barrios", "Pedro", "", "ENSGSI"], ["Monticolo", "Davy", "", "ENSGSI"], ["Sidhom", "Sahbi", "", "KIWI"]]}, {"id": "2009.05445", "submitter": "Julien Hendrickx", "authors": "Julien M. Hendrickx and Michael G. Rabbat", "title": "Stability of Decentralized Gradient Descent in Open Multi-Agent Systems", "comments": "8 pages, 2 figures, 3 pdf files for the figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of decentralized gradient descent (DGD) is to minimize a sum of $n$\nfunctions held by interconnected agents. We study the stability of DGD in open\ncontexts where agents can join or leave the system, resulting each time in the\naddition or the removal of their function from the global objective. Assuming\nall functions are smooth, strongly convex, and their minimizers all lie in a\ngiven ball, we characterize the sensitivity of the global minimizer of the sum\nof these functions to the removal or addition of a new function and provide\nbounds in $ O\\left(\\min \\left(\\kappa^{0.5},\n\\kappa/n^{0.5},\\kappa^{1.5}/n\\right)\\right)$ where $\\kappa$ is the condition\nnumber. We also show that the states of all agents can be eventually bounded\nindependently of the sequence of arrivals and departures. The magnitude of the\nbound scales with the importance of the interconnection, which also determines\nthe accuracy of the final solution in the absence of arrival and departure,\nexposing thus a potential trade-off between accuracy and sensitivity. Our\nanalysis relies on the formulation of DGD as gradient descent on an auxiliary\nfunction. The tightness of our results is analyzed using the PESTO Toolbox.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 13:48:09 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Hendrickx", "Julien M.", ""], ["Rabbat", "Michael G.", ""]]}, {"id": "2009.05528", "submitter": "Juste Raimbault", "authors": "Juste Raimbault, Natalia Zdanowska and Elsa Arcaute", "title": "Modeling growth of urban firm networks", "comments": "19 pages, 9 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emergence of interconnected urban networks is a crucial feature of\nglobalisation processes. Understanding the drivers behind the growth of such\nnetworks - in particular urban firm networks -, is essential for the economic\nresilience of urban systems. We introduce in this paper a generative network\nmodel for firm networks at the urban area level including several complementary\nprocesses: the economic size of urban areas at origin and destination,\nindustrial sector proximity between firms, the strength of links from the past,\nas well as the geographical and socio-cultural distance. An empirical network\nanalysis on European firm ownership data confirms the relevance of each of\nthese factors. We then simulate network growth for synthetic systems of cities,\nunveiling stylized facts such as a transition from a local to a global regime\nor a maximal integration achieved at an intermediate interaction range. We\ncalibrate the model on the European network, outperforming statistical models\nand showing a strong role of path-dependency. Potential applications of the\nmodel include the study of mitigation policies to deal with exogenous shocks\nsuch as economic crisis or potential lockdowns of countries, which we\nillustrate with an application on stylized scenarios.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 17:04:31 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Raimbault", "Juste", ""], ["Zdanowska", "Natalia", ""], ["Arcaute", "Elsa", ""]]}, {"id": "2009.05837", "submitter": "Usman Khan", "authors": "Ran Xin, Shi Pu, Angelia Nedi\\'c, and Usman A. Khan", "title": "A general framework for decentralized optimization with first-order\n  methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA cs.SY eess.SY math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decentralized optimization to minimize a finite sum of functions over a\nnetwork of nodes has been a significant focus within control and signal\nprocessing research due to its natural relevance to optimal control and signal\nestimation problems. More recently, the emergence of sophisticated computing\nand large-scale data science needs have led to a resurgence of activity in this\narea. In this article, we discuss decentralized first-order gradient methods,\nwhich have found tremendous success in control, signal processing, and machine\nlearning problems, where such methods, due to their simplicity, serve as the\nfirst method of choice for many complex inference and training tasks. In\nparticular, we provide a general framework of decentralized first-order methods\nthat is applicable to undirected and directed communication networks alike, and\nshow that much of the existing work on optimization and consensus can be\nrelated explicitly to this framework. We further extend the discussion to\ndecentralized stochastic first-order methods that rely on stochastic gradients\nat each node and describe how local variance reduction schemes, previously\nshown to have promise in the centralized settings, are able to improve the\nperformance of decentralized methods when combined with what is known as\ngradient tracking. We motivate and demonstrate the effectiveness of the\ncorresponding methods in the context of machine learning and signal processing\nproblems that arise in decentralized environments.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 17:52:10 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Xin", "Ran", ""], ["Pu", "Shi", ""], ["Nedi\u0107", "Angelia", ""], ["Khan", "Usman A.", ""]]}, {"id": "2009.05940", "submitter": "Takuma Yoneda", "authors": "Takuma Yoneda, Matthew R. Walter, Jason Naradowsky", "title": "Pow-Wow: A Dataset and Study on Collaborative Communication in Pommerman", "comments": "Accepted at LaReL workshop at ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multi-agent learning, agents must coordinate with each other in order to\nsucceed. For humans, this coordination is typically accomplished through the\nuse of language. In this work we perform a controlled study of human language\nuse in a competitive team-based game, and search for useful lessons for\nstructuring communication protocol between autonomous agents. We construct\nPow-Wow, a new dataset for studying situated goal-directed human communication.\nUsing the Pommerman game environment, we enlisted teams of humans to play\nagainst teams of AI agents, recording their observations, actions, and\ncommunications. We analyze the types of communications which result in\neffective game strategies, annotate them accordingly, and present corpus-level\nstatistical analysis of how trends in communications affect game outcomes.\nBased on this analysis, we design a communication policy for learning agents,\nand show that agents which utilize communication achieve higher win-rates\nagainst baseline systems than those which do not.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 07:11:37 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Yoneda", "Takuma", ""], ["Walter", "Matthew R.", ""], ["Naradowsky", "Jason", ""]]}, {"id": "2009.06021", "submitter": "Chang Liu", "authors": "Chang Liu, Zhihao Liao, and Silvia Ferrari", "title": "Rumor-robust Decentralized Gaussian Process Learning, Fusion, and\n  Planning for Modeling Multiple Moving Targets", "comments": "8 pages, 3 figures, accepted to 59th IEEE Conference on Decision and\n  Control (CDC), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.MA cs.RO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a decentralized Gaussian Process (GP) learning, fusion,\nand planning (RESIN) formalism for mobile sensor networks to actively learn\ntarget motion models. RESIN is characterized by both computational and\ncommunication efficiency, and the robustness to rumor propagation in sensor\nnetworks. By using the weighted exponential product rule and the Chernoff\ninformation, a rumor-robust decentralized GP fusion approach is developed to\ngenerate a globally consistent target trajectory prediction from local GP\nmodels. A decentralized information-driven path planning approach is then\nproposed for mobile sensors to generate informative sensing paths. A novel,\nconstant-sized information sharing strategy is developed for path coordination\nbetween sensors, and an analytical objective function is derived that\nsignificantly reduces the computational complexity of the path planning. The\neffectiveness of RESIN is demonstrated in various numerical simulations.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 15:21:55 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Liu", "Chang", ""], ["Liao", "Zhihao", ""], ["Ferrari", "Silvia", ""]]}, {"id": "2009.06117", "submitter": "Kiran Vodrahalli", "authors": "Christos Papadimitriou, Kiran Vodrahalli, Mihalis Yannakakis", "title": "The Platform Design Problem", "comments": "updated with more results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CC cs.LG cs.MA econ.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  On-line firms deploy suites of software platforms, where each platform is\ndesigned to interact with users during a certain activity, such as browsing,\nchatting, socializing, emailing, driving, etc. The economic and incentive\nstructure of this exchange, as well as its algorithmic nature, have not been\nexplored to our knowledge. We model this interaction as a Stackelberg game\nbetween a Designer and one or more Agents. We model an Agent as a Markov chain\nwhose states are activities; we assume that the Agent's utility is a linear\nfunction of the steady-state distribution of this chain. The Designer may\ndesign a platform for each of these activities/states; if a platform is adopted\nby the Agent, the transition probabilities of the Markov chain are affected,\nand so is the objective of the Agent. The Designer's utility is a linear\nfunction of the steady state probabilities of the accessible states minus the\ndevelopment cost of the platforms. The underlying optimization problem of the\nAgent -- how to choose the states for which to adopt the platform -- is an MDP.\nIf this MDP has a simple yet plausible structure (the transition probabilities\nfrom one state to another only depend on the target state and the recurrent\nprobability of the current state) the Agent's problem can be solved by a greedy\nalgorithm. The Designer's optimization problem (designing a custom suite for\nthe Agent so as to optimize, through the Agent's optimum reaction, the\nDesigner's revenue), is NP-hard to approximate within any finite ratio;\nhowever, the special case, while still NP-hard, has an FPTAS. These results\ngeneralize from a single Agent to a distribution of Agents with finite support,\nas well as to the setting where the Designer must find the best response to the\nexisting strategies of other Designers. We discuss other implications of our\nresults and directions of future research.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 23:53:19 GMT"}, {"version": "v2", "created": "Tue, 13 Jul 2021 02:14:44 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Papadimitriou", "Christos", ""], ["Vodrahalli", "Kiran", ""], ["Yannakakis", "Mihalis", ""]]}, {"id": "2009.06224", "submitter": "Yuanyuan Shi", "authors": "Yuanyuan Shi, Baosen Zhang", "title": "Multi-Agent Reinforcement Learning in Cournot Games", "comments": "IEEE Conference on Decision and Control (CDC), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.GT cs.LG cs.MA cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we study the interaction of strategic agents in continuous\naction Cournot games with limited information feedback. Cournot game is the\nessential market model for many socio-economic systems where agents learn and\ncompete without the full knowledge of the system or each other. We consider the\ndynamics of the policy gradient algorithm, which is a widely adopted continuous\ncontrol reinforcement learning algorithm, in concave Cournot games. We prove\nthe convergence of policy gradient dynamics to the Nash equilibrium when the\nprice function is linear or the number of agents is two. This is the first\nresult (to the best of our knowledge) on the convergence property of learning\nalgorithms with continuous action spaces that do not fall in the no-regret\nclass.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 06:53:21 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Shi", "Yuanyuan", ""], ["Zhang", "Baosen", ""]]}, {"id": "2009.06227", "submitter": "Pierre-Alexandre Murena", "authors": "Mustafa Mert Celikok, Pierre-Alexandre Murena, Samuel Kaski", "title": "Teaching to Learn: Sequential Teaching of Agents with Inner States", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In sequential machine teaching, a teacher's objective is to provide the\noptimal sequence of inputs to sequential learners in order to guide them\ntowards the best model. In this paper we extend this setting from current\nstatic one-data-set analyses to learners which change their learning algorithm\nor latent state to improve during learning, and to generalize to new datasets.\nWe introduce a multi-agent formulation in which learners' inner state may\nchange with the teaching interaction, which affects the learning performance in\nfuture tasks. In order to teach such learners, we propose an optimal control\napproach that takes the future performance of the learner after teaching into\naccount. This provides tools for modelling learners having inner states, and\nmachine teaching of meta-learning algorithms. Furthermore, we distinguish\nmanipulative teaching, which can be done by effectively hiding data and also\nused for indoctrination, from more general education which aims to help the\nlearner become better at generalization and learning in new datasets in the\nabsence of a teacher.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 07:03:15 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Celikok", "Mustafa Mert", ""], ["Murena", "Pierre-Alexandre", ""], ["Kaski", "Samuel", ""]]}, {"id": "2009.06425", "submitter": "Ghalib Tahir", "authors": "Nauman Khalid, Ghalib Ahmed Tahir, Peter Bloodsworth", "title": "Persistent And Scalable JADE: A Cloud based InMemory Multi-agent\n  Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multi-agent systems are often limited in terms of persistenceand scalability.\nThis issue is more prevalent for applications inwhich agent states changes\nfrequently. This makes the existingmethods less usable as they increase the\nagent's complexityand are less scalable. This research study has presented\nanovel in-memory agent persistence framework. Two prototypeshave been\nimplemented, one using the proposed solution andthe other using an established\nagent persistency environment.Experimental results confirm that the proposed\nframework ismore scalable than existing approaches whilst providing asimilar\nlevel of persistency. These findings will help futurereal-time multiagent\nsystems to become scalable and persistentin a dynamic cloud environment.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 13:22:37 GMT"}, {"version": "v2", "created": "Wed, 16 Sep 2020 23:50:02 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Khalid", "Nauman", ""], ["Tahir", "Ghalib Ahmed", ""], ["Bloodsworth", "Peter", ""]]}, {"id": "2009.06797", "submitter": "Antonio Ginart", "authors": "Antonio Ginart, Eva Zhang, Yongchan Kwon, James Zou", "title": "Competing AI: How does competition feedback affect machine learning?", "comments": "Accepted to AISTATS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This papers studies how competition affects machine learning (ML) predictors.\nAs ML becomes more ubiquitous, it is often deployed by companies to compete\nover customers. For example, digital platforms like Yelp use ML to predict user\npreference and make recommendations. A service that is more often queried by\nusers, perhaps because it more accurately anticipates user preferences, is also\nmore likely to obtain additional user data (e.g. in the form of a Yelp review).\nThus, competing predictors cause feedback loops whereby a predictor's\nperformance impacts what training data it receives and biases its predictions\nover time. We introduce a flexible model of competing ML predictors that\nenables both rapid experimentation and theoretical tractability. We show with\nempirical and mathematical analysis that competition causes predictors to\nspecialize for specific sub-populations at the cost of worse performance over\nthe general population. We further analyze the impact of predictor\nspecialization on the overall prediction quality experienced by users. We show\nthat having too few or too many competing predictors in a market can hurt the\noverall prediction quality. Our theory is complemented by experiments on\nseveral real datasets using popular learning algorithms, such as neural\nnetworks and nearest neighbor methods.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 00:13:32 GMT"}, {"version": "v2", "created": "Fri, 2 Oct 2020 06:12:49 GMT"}, {"version": "v3", "created": "Thu, 22 Oct 2020 05:01:12 GMT"}, {"version": "v4", "created": "Thu, 25 Mar 2021 04:04:22 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Ginart", "Antonio", ""], ["Zhang", "Eva", ""], ["Kwon", "Yongchan", ""], ["Zou", "James", ""]]}, {"id": "2009.06894", "submitter": "Hiroyasu Inoue Dr.", "authors": "Hiroyasu Inoue, Yohsuke Murase, Yasuyuki Todo", "title": "Do economic effects of the anti-COVID-19 lockdowns in different regions\n  interact through supply chains?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.MA econ.GN q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To prevent the spread of COVID-19, many cities, states, and countries have\n`locked down', restricting economic activities in non-essential sectors. Such\nlockdowns have substantially shrunk production in most countries. This study\nexamines how the economic effects of lockdowns in different regions interact\nthrough supply chains, a network of firms for production, simulating an\nagent-based model of production on supply-chain data for 1.6 million firms in\nJapan. We further investigate how the complex network structure affects the\ninteractions of lockdowns, emphasising the role of upstreamness and loops by\ndecomposing supply-chain flows into potential and circular flow components. We\nfind that a region's upstreamness, intensity of loops, and supplier\nsubstitutability in supply chains with other regions largely determine the\neconomic effect of the lockdown in the region. In particular, when a region\nlifts its lockdown, its economic recovery substantially varies depending on\nwhether it lifts lockdown alone or together with another region closely linked\nthrough supply chains. These results propose the need for inter-region policy\ncoordination to reduce the economic loss from lockdowns.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 07:14:48 GMT"}, {"version": "v2", "created": "Thu, 7 Jan 2021 09:02:17 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Inoue", "Hiroyasu", ""], ["Murase", "Yohsuke", ""], ["Todo", "Yasuyuki", ""]]}, {"id": "2009.06965", "submitter": "Renming Liu", "authors": "Renming Liu (1), Siyu Chen (2), Yu Jiang (1), Ravi Seshadri (3), Moshe\n  E. Ben-Akiva (2), Carlos Lima Azevedo (1) ((1) DTU Management, Technical\n  University of Denmark, Denmark, (2) CEE, Massachusetts Institute of\n  Technology, United States, (3) Singapore-MIT Alliance for Research and\n  Technology, Singapore)", "title": "Managing network congestion with a tradable credit scheme: a trip-based\n  MFD approach", "comments": "44 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study investigates the efficiency and effectiveness of an area-based\ntradable credit scheme (TCS) using the trip-based Macroscopic Fundamental\nDiagram model for the morning commute problem. In the proposed TCS, the\nregulator distributes initial credits to all travelers and designs a\ntime-varying and trip length specific credit tariff. Credits are traded between\ntravelers and the regulator via a credit market, and the credit price is\ndetermined by the demand and supply of credits. The heterogeneity of travelers\nis considered in terms of desired arrival time, trip length and departure-time\nchoice preferences. The TCS is incorporated into a day-to-day modelling\nframework to examine the travelers' learning process, the evolution of network,\nand the properties of the credit market. The existence of an equilibrium\nsolution and the uniqueness of the credit price at the equilibrium state are\nestablished analytically. Furthermore, an open-source simulation framework is\ndeveloped to validate the analytical properties of the proposed TCS and compare\nit with alternative control strategies in terms of mobility, network\nperformance, and social welfare. Bayesian optimization is then adopted to\noptimize the credit toll scheme. The numerical results demonstrate that the\nproposed TCS outperforms the no-control case and matches the performance of the\ntime-of-day pricing strategy, while maintaining revenue-neutral nature.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 10:15:23 GMT"}, {"version": "v2", "created": "Mon, 4 Jan 2021 10:25:05 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Liu", "Renming", ""], ["Chen", "Siyu", ""], ["Jiang", "Yu", ""], ["Seshadri", "Ravi", ""], ["Ben-Akiva", "Moshe E.", ""], ["Azevedo", "Carlos Lima", ""]]}, {"id": "2009.07124", "submitter": "Patrick Reinwald", "authors": "Patrick Reinwald, Stephan Leitner and Friederike Wall", "title": "An Agent-Based Model of Delegation Relationships With Hidden-Action: On\n  the Effects of Heterogeneous Memory on Performance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA econ.GN physics.soc-ph q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an agent-based model of delegation relationships between a\nprincipal and an agent, which is based on the standard-hidden action model\nintroduced by Holmstr\\\"om and, by doing so, provide a model which can be used\nto further explore theoretical topics in managerial economics, such as the\nefficiency of incentive mechanisms. We employ the concept of agentization,\ni.e., we systematically transform the standard hidden-action model into an\nagent-based model. Our modeling approach allows for a relaxation of some of the\nrather \"heroic\" assumptions included in the standard hidden-action model,\nwhereby we particularly focus on assumptions related to the (i) availability of\ninformation about the environment and the (ii) principal's and agent's\ncognitive capabilities (with a particular focus on their learning capabilities\nand their memory). Our analysis focuses on how close and how fast the incentive\nscheme, which endogenously emerges from the agent-based model, converges to the\nsolution proposed by the standard hidden-action model. Also, we investigate\nwhether a stable solution can emerge from the agent-based model variant. The\nresults show that in stable environments the emergent result can nearly reach\nthe solution proposed by the standard hidden-action model. Surprisingly, the\nresults indicate that turbulence in the environment leads to stability in\nearlier time periods.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 07:08:42 GMT"}, {"version": "v2", "created": "Mon, 28 Sep 2020 12:40:43 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Reinwald", "Patrick", ""], ["Leitner", "Stephan", ""], ["Wall", "Friederike", ""]]}, {"id": "2009.07619", "submitter": "Nieves Montes", "authors": "Nieves Montes, Carles Sierra", "title": "Value Alignment Equilibrium in Multiagent Systems", "comments": "1st TAILOR Workshop at ECAI 2020", "journal-ref": "In: Trustworthy AI - Integrating Learning, Optimization and\n  Reasoning. TAILOR 2020. Lecture Notes in Computer Science, vol 12641.\n  Springer, Cham", "doi": "10.1007/978-3-030-73959-1_17", "report-no": null, "categories": "cs.MA", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Value alignment has emerged in recent years as a basic principle to produce\nbeneficial and mindful Artificial Intelligence systems. It mainly states that\nautonomous entities should behave in a way that is aligned with our human\nvalues. In this work, we summarize a previously developed model that considers\nvalues as preferences over states of the world and defines alignment between\nthe governing norms and the values. We provide a use-case for this framework\nwith the Iterated Prisoner's Dilemma model, which we use to exemplify the\ndefinitions we review. We take advantage of this use-case to introduce new\nconcepts to be integrated with the established framework: alignment equilibrium\nand Pareto optimal alignment. These are inspired on the classical Nash\nequilibrium and Pareto optimality, but are designed to account for any value we\nwish to model in the system.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 11:58:04 GMT"}, {"version": "v2", "created": "Mon, 2 Nov 2020 14:07:16 GMT"}, {"version": "v3", "created": "Fri, 25 Jun 2021 06:26:14 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Montes", "Nieves", ""], ["Sierra", "Carles", ""]]}, {"id": "2009.08302", "submitter": "Pallavi Bagga", "authors": "Pallavi Bagga, Nicola Paoletti and Kostas Stathis", "title": "Learnable Strategies for Bilateral Agent Negotiation over Multiple\n  Issues", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel bilateral negotiation model that allows a self-interested\nagent to learn how to negotiate over multiple issues in the presence of user\npreference uncertainty. The model relies upon interpretable strategy templates\nrepresenting the tactics the agent should employ during the negotiation and\nlearns template parameters to maximize the average utility received over\nmultiple negotiations, thus resulting in optimal bid acceptance and generation.\nOur model also uses deep reinforcement learning to evaluate threshold utility\nvalues, for those tactics that require them, thereby deriving optimal utilities\nfor every environment state. To handle user preference uncertainty, the model\nrelies on a stochastic search to find user model that best agrees with a given\npartial preference profile. Multi-objective optimization and multi-criteria\ndecision-making methods are applied at negotiation time to generate\nPareto-optimal outcomes thereby increasing the number of successful (win-win)\nnegotiations. Rigorous experimental evaluations show that the agent employing\nour model outperforms the winning agents of the 10th Automated Negotiating\nAgents Competition (ANAC'19) in terms of individual as well as social-welfare\nutilities.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 13:52:18 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Bagga", "Pallavi", ""], ["Paoletti", "Nicola", ""], ["Stathis", "Kostas", ""]]}, {"id": "2009.08628", "submitter": "Efstathios Bakolas", "authors": "Efstathios Bakolas and Yoonjae Lee", "title": "Decentralized Game-Theoretic Control for Dynamic Task Allocation\n  Problems for Multi-Agent Systems", "comments": "8 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a decentralized game-theoretic framework for dynamic task\nallocation problems for multi-agent systems. In our problem formulation, the\nagents' utilities depend on both the rewards and the costs associated with the\nsuccessful completion of the tasks assigned to them. The rewards reflect how\nlikely is for the agents to accomplish their assigned tasks whereas the costs\nreflect the effort needed to complete these tasks (this effort is determined by\nthe solution of corresponding optimal control problems). The task allocation\nproblem considered herein corresponds to a dynamic game whose solution depends\non the states of the agents in contrast with classic static (or single-act)\ngame formulations. We propose a greedy solution approach in which the agents\nnegotiate with each other to find a mutually agreeable (or individually\nrational) task assignment profile based on evaluations of the task utilities\nthat reflect their current states. We illustrate the main ideas of this work by\nmeans of extensive numerical simulations.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 05:03:00 GMT"}, {"version": "v2", "created": "Tue, 29 Sep 2020 20:18:35 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Bakolas", "Efstathios", ""], ["Lee", "Yoonjae", ""]]}, {"id": "2009.08632", "submitter": "Sid Chi-Kin Chau", "authors": "Sid Chi-Kin Chau, Khaled Elbassioni and Yue Zhou", "title": "Approximately Socially-Optimal Decentralized Coalition Formation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coalition formation is a central part of social interactions. In the emerging\nera of social peer-to-peer interactions (e.g., sharing economy), coalition\nformation will be often carried out in a decentralized manner, based on\nparticipants' individual preferences. A likely outcome will be a stable\ncoalition structure, where no group of participants could cooperatively opt out\nto form another coalition that induces higher preferences to all its members.\nRemarkably, there exist a number of fair cost-sharing mechanisms (e.g.,\nequal-split, proportional-split, egalitarian and Nash bargaining solutions of\nbargaining games) that model practical cost-sharing applications with desirable\nproperties, such as the existence of a stable coalition structure with a small\nstrong price-of-anarchy (SPoA) to approximate the social optimum. In this\npaper, we close several gaps on the previous results of decentralized coalition\nformation: (1) We establish a logarithmic lower bound on SPoA, and hence, show\nseveral previously known fair cost-sharing mechanisms are the best practical\nmechanisms with minimal SPoA. (2) We improve the SPoA of egalitarian and Nash\nbargaining cost-sharing mechanisms to match the lower bound. (3) We derive the\nSPoA of a mix of different cost-sharing mechanisms. (4) We present a\ndecentralized algorithm to form a stable coalition structure. (5) Finally, we\napply our results to a novel application of peer-to-peer energy sharing that\nallows households to jointly utilize mutual energy resources. We also present\nand analyze an empirical study of decentralized coalition formation in a\nreal-world P2P energy sharing project.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 05:22:11 GMT"}, {"version": "v2", "created": "Mon, 26 Jul 2021 01:23:27 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Chau", "Sid Chi-Kin", ""], ["Elbassioni", "Khaled", ""], ["Zhou", "Yue", ""]]}, {"id": "2009.08807", "submitter": "Amit Surana", "authors": "Kunal Srivastava, Amit Surana", "title": "Monte Carlo Tree Search Based Tactical Maneuvering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we explore the application of simultaneous move Monte Carlo\nTree Search (MCTS) based online framework for tactical maneuvering between two\nunmanned aircrafts. Compared to other techniques, MCTS enables efficient search\nover long horizons and uses self-play to select best maneuver in the current\nstate while accounting for the opponent aircraft tactics. We explore different\nalgorithmic choices in MCTS and demonstrate the framework numerically in a\nsimulated 2D tactical maneuvering application.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 02:03:25 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Srivastava", "Kunal", ""], ["Surana", "Amit", ""]]}, {"id": "2009.09537", "submitter": "Aniket Shirsat", "authors": "Aniket Shirsat, Karthik Elamvazhuthi, and Spring Berman", "title": "Multi-Robot Target Search using Probabilistic Consensus on Discrete\n  Markov Chains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.MA", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we propose a probabilistic consensus-based multi-robot search\nstrategy that is robust to communication link failures, and thus is suitable\nfor disaster affected areas. The robots, capable of only local communication,\nexplore a bounded environment according to a random walk modeled by a\ndiscrete-time discrete-state (DTDS) Markov chain and exchange information with\nneighboring robots, resulting in a time-varying communication network topology.\nThe proposed strategy is proved to achieve consensus, here defined as agreement\non the presence of a static target, with no assumptions on the connectivity of\nthe communication network. Using numerical simulations, we investigate the\neffect of the robot population size, domain size, and information uncertainty\non the consensus time statistics under this scheme. We also validate our\ntheoretical results with 3D physics-based simulations in Gazebo. The\nsimulations demonstrate that all robots achieve consensus in finite time with\nthe proposed search strategy over a range of robot densities in the\nenvironment.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 22:31:23 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Shirsat", "Aniket", ""], ["Elamvazhuthi", "Karthik", ""], ["Berman", "Spring", ""]]}, {"id": "2009.09575", "submitter": "Francisco Cruz", "authors": "Adam Bignold, Francisco Cruz, Richard Dazeley, Peter Vamplew, Cameron\n  Foale", "title": "Human Engagement Providing Evaluative and Informative Advice for\n  Interactive Reinforcement Learning", "comments": "33 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning is an approach used by intelligent agents to\nautonomously learn new skills. Although reinforcement learning has been\ndemonstrated to be an effective learning approach in several different\ncontexts, a common drawback exhibited is the time needed in order to\nsatisfactorily learn a task, especially in large state-action spaces. To\naddress this issue, interactive reinforcement learning proposes the use of\nexternally-sourced information in order to speed up the learning process. Up to\nnow, different information sources have been used to give advice to the learner\nagent, among them human-sourced advice. When interacting with a learner agent,\nhumans may provide either evaluative or informative advice. From the agent's\nperspective these styles of interaction are commonly referred to as\nreward-shaping and policy-shaping respectively. Evaluation requires the human\nto provide feedback on the prior action performed, while informative advice\nthey provide advice on the best action to select for a given situation. Prior\nresearch has focused on the effect of human-sourced advice on the interactive\nreinforcement learning process, specifically aiming to improve the learning\nspeed of the agent, while reducing the engagement with the human. This work\npresents an experimental setup for a human-trial designed to compare the\nmethods people use to deliver advice in term of human engagement. Obtained\nresults show that users giving informative advice to the learner agents provide\nmore accurate advice, are willing to assist the learner agent for a longer\ntime, and provide more advice per episode. Additionally, self-evaluation from\nparticipants using the informative approach has indicated that the agent's\nability to follow the advice is higher, and therefore, they feel their own\nadvice to be of higher accuracy when compared to people providing evaluative\nadvice.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 02:14:02 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Bignold", "Adam", ""], ["Cruz", "Francisco", ""], ["Dazeley", "Richard", ""], ["Vamplew", "Peter", ""], ["Foale", "Cameron", ""]]}, {"id": "2009.09734", "submitter": "Ehud Shapiro", "authors": "Ehud Shapiro and Nimrod Talmon", "title": "Electing the Executive Branch", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The executive branch, or government, is typically not elected directly by the\npeople, but rather formed by another elected body or person such as the\nparliament or the president. As a result, its members are not directly\naccountable to the people, individually or as a group. We consider a scenario\nin which the members of the government are elected directly by the people, and\nwish to achieve proportionality while doing so.\n  We propose a formal model consisting of $k$ offices, each with its own\ndisjoint set of candidates, and a set of voters who provide approval ballots\nfor all offices. We wish to identify good aggregation rules that assign one\ncandidate to each office.\n  As using a simple majority vote for each office independently might result in\ndisregarding minority preferences altogether, here we consider an adaptation of\nthe greedy variant of Proportional Approval Voting (GreedyPAV) to our setting,\nand demonstrate -- through computer-based simulations -- how voting for all\noffices together using this rule overcomes this weakness. We note that the\napproach is applicable also to a party that employs direct democracy, where\nparty members elect the party's representatives in a coalition government.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 10:07:56 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 17:19:21 GMT"}, {"version": "v3", "created": "Mon, 8 Feb 2021 10:10:10 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Shapiro", "Ehud", ""], ["Talmon", "Nimrod", ""]]}, {"id": "2009.09842", "submitter": "Karush Suri", "authors": "Karush Suri, Xiao Qi Shi, Konstantinos Plataniotis, Yuri Lawryshyn", "title": "Energy-based Surprise Minimization for Multi-Agent Value Factorization", "comments": "Preprint, Under Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-Agent Reinforcement Learning (MARL) has demonstrated significant\nsuccess in training decentralised policies in a centralised manner by making\nuse of value factorization methods. However, addressing surprise across\nspurious states and approximation bias remain open problems for multi-agent\nsettings. Towards this goal, we introduce the Energy-based MIXer (EMIX), an\nalgorithm which minimizes surprise utilizing the energy across agents. Our\ncontributions are threefold; (1) EMIX introduces a novel surprise minimization\ntechnique across multiple agents in the case of multi-agent\npartially-observable settings. (2) EMIX highlights a practical use of energy\nfunctions in MARL with theoretical guarantees and experiment validations of the\nenergy operator. Lastly, (3) EMIX extends Maxmin Q-learning for addressing\noverestimation bias across agents in MARL. In a study of challenging StarCraft\nII micromanagement scenarios, EMIX demonstrates consistent stable performance\nfor multiagent surprise minimization. Moreover, our ablation study highlights\nthe necessity of the energy-based scheme and the need for elimination of\noverestimation bias in MARL. Our implementation of EMIX can be found at\nkarush17.github.io/emix-web/.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 19:42:42 GMT"}, {"version": "v2", "created": "Mon, 28 Sep 2020 16:26:43 GMT"}, {"version": "v3", "created": "Mon, 5 Oct 2020 16:10:26 GMT"}, {"version": "v4", "created": "Mon, 18 Jan 2021 03:06:32 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Suri", "Karush", ""], ["Shi", "Xiao Qi", ""], ["Plataniotis", "Konstantinos", ""], ["Lawryshyn", "Yuri", ""]]}, {"id": "2009.09915", "submitter": "Yuan Chang", "authors": "Yuan Chang, Zhiyong Sun, Han Zhou, Xiangke Wang, Lincheng Shen,\n  Tianjiang Hu", "title": "Collaborative Target Tracking in Elliptic Coordinates: a Binocular\n  Coordination Approach", "comments": "6 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper concentrates on the collaborative target tracking control of a\npair of tracking vehicles with formation constraints. The proposed controller\nrequires only distance measurements between tracking vehicles and the target.\nIts novelty lies in two aspects: 1) the elliptic coordinates are used to\nrepresent an arbitrary tracking formation without singularity, which can be\ndeduced from inter-agent distances, and 2) the regulation of the tracking\nvehicle system obeys a binocular coordination principle, which simplifies the\ndesign of the control law by leveraging rich physical meanings of elliptic\ncoordinates. The tracking system with the proposed controller is proven to be\nexponentially convergent when the target is stationary. When the target drifts\nwith a small velocity, the desired tracking formation is achieved within a\nsmall margin proportional to the magnitude of the target's drift velocity.\nSimulation examples are provided to demonstrate the tracking performance of the\nproposed controller.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 14:36:03 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Chang", "Yuan", ""], ["Sun", "Zhiyong", ""], ["Zhou", "Han", ""], ["Wang", "Xiangke", ""], ["Shen", "Lincheng", ""], ["Hu", "Tianjiang", ""]]}, {"id": "2009.09946", "submitter": "Giacomo Como", "authors": "Giacomo Como, St\\'ephane Durand, and Fabio Fagnani", "title": "Optimal Targeting in Super-Modular Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.MA cs.SY eess.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study an optimal targeting problem for super-modular games with binary\nactions and finitely many players. The considered problem consists in the\nselection of a subset of players of minimum size such that, when the actions of\nthese players are forced to a controlled value while the others are left to\nrepeatedly play a best response action, the system will converge to the\ngreatest Nash equilibrium of the game. Our main contributions consist in\nshowing that the problem is NP-complete and in proposing an efficient iterative\nalgorithm with provable convergence properties for its solution. We discuss in\ndetail the special case of network coordination games and its relation with the\nnotion of cohesiveness. Finally, we show with simulations the strength of our\napproach with respect to naive heuristics based on classical network centrality\nmeasures.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 15:12:27 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Como", "Giacomo", ""], ["Durand", "St\u00e9phane", ""], ["Fagnani", "Fabio", ""]]}, {"id": "2009.10033", "submitter": "Atrisha Sarkar", "authors": "Atrisha Sarkar, Krzysztof Czarnecki", "title": "Solution Concepts in Hierarchical Games under Bounded Rationality with\n  Applications to Autonomous Driving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With autonomous vehicles (AV) set to integrate further into regular human\ntraffic, there is an increasing consensus of treating AV motion planning as a\nmulti-agent problem. However, the traditional game theoretic assumption of\ncomplete rationality is too strong for the purpose of human driving, and there\nis a need for understanding human driving as a \\emph{bounded rational} activity\nthrough a behavioral game theoretic lens. To that end, we adapt three\nmetamodels of bounded rational behavior; two based on Quantal level-k and one\nbased on Nash equilibrium with quantal errors. We formalize the different\nsolution concepts that can be applied in the context of hierarchical games, a\nframework used in multi-agent motion planning, for the purpose of creating game\ntheoretic models of driving behavior. Furthermore, based on a contributed\ndataset of human driving at a busy urban intersection with a total of ~4k\nagents and ~44k decision points, we evaluate the behavior models on the basis\nof model fit to naturalistic data, as well as their predictive capacity. Our\nresults suggest that among the behavior models evaluated, modeling driving\nbehavior as pure strategy NE with quantal errors at the level of maneuvers with\nbounds sampling of actions at the level of trajectories provides the best fit\nto naturalistic driving behavior, and there is a significant impact of\nsituational factors on the performance of behavior models.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 17:13:50 GMT"}, {"version": "v2", "created": "Wed, 16 Dec 2020 20:00:54 GMT"}, {"version": "v3", "created": "Mon, 21 Dec 2020 17:10:49 GMT"}, {"version": "v4", "created": "Thu, 21 Jan 2021 17:49:20 GMT"}], "update_date": "2021-01-22", "authors_parsed": [["Sarkar", "Atrisha", ""], ["Czarnecki", "Krzysztof", ""]]}, {"id": "2009.10061", "submitter": "Gabriele Farina", "authors": "Gabriele Farina and Andrea Celli and Nicola Gatti and Tuomas Sandholm", "title": "Faster Algorithms for Optimal Ex-Ante Coordinated Collusive Strategies\n  in Extensive-Form Zero-Sum Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on the problem of finding an optimal strategy for a team of two\nplayers that faces an opponent in an imperfect-information zero-sum\nextensive-form game. Team members are not allowed to communicate during play\nbut can coordinate before the game. In that setting, it is known that the best\nthe team can do is sample a profile of potentially randomized strategies (one\nper player) from a joint (a.k.a. correlated) probability distribution at the\nbeginning of the game. In this paper, we first provide new modeling results\nabout computing such an optimal distribution by drawing a connection to a\ndifferent literature on extensive-form correlation. Second, we provide an\nalgorithm that computes such an optimal distribution by only using profiles\nwhere only one of the team members gets to randomize in each profile. We can\nalso cap the number of such profiles we allow in the solution. This begets an\nanytime algorithm by increasing the cap. We find that often a handful of\nwell-chosen such profiles suffices to reach optimal utility for the team. This\nenables team members to reach coordination through a relatively simple and\nunderstandable plan. Finally, inspired by this observation and leveraging\ntheoretical concepts that we introduce, we develop an efficient\ncolumn-generation algorithm for finding an optimal distribution for the team.\nWe evaluate it on a suite of common benchmark games. It is three orders of\nmagnitude faster than the prior state of the art on games that the latter can\nsolve and it can also solve several games that were previously unsolvable.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 17:51:57 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Farina", "Gabriele", ""], ["Celli", "Andrea", ""], ["Gatti", "Nicola", ""], ["Sandholm", "Tuomas", ""]]}, {"id": "2009.10249", "submitter": "EPTCS", "authors": "Basem Atiq (Sabanci University), Volkan Patoglu (Sabanci University),\n  Esra Erdem (Sabanci University)", "title": "Dynamic Multi-Agent Path Finding based on Conflict Resolution using\n  Answer Set Programming", "comments": "In Proceedings ICLP 2020, arXiv:2009.09158", "journal-ref": "EPTCS 325, 2020, pp. 223-229", "doi": "10.4204/EPTCS.325.27", "report-no": null, "categories": "cs.AI cs.LO cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a dynamic version of multi-agent path finding problem (called\nD-MAPF) where existing agents may leave and new agents may join the team at\ndifferent times. We introduce a new method to solve D-MAPF based on\nconflict-resolution. The idea is, when a set of new agents joins the team and\nthere are conflicts, instead of replanning for the whole team, to replan only\nfor a minimal subset of agents whose plans conflict with each other. We utilize\nanswer set programming as part of our method for planning, replanning and\nidentifying minimal set of conflicts.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 00:50:35 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Atiq", "Basem", "", "Sabanci University"], ["Patoglu", "Volkan", "", "Sabanci University"], ["Erdem", "Esra", "", "Sabanci University"]]}, {"id": "2009.10638", "submitter": "Armin Moin", "authors": "Armin Moin", "title": "Sense-Deliberate-Act Cognitive Agents for Sense-Compute-Control\n  Applications in the Internet of Things & Services", "comments": "International Internet of Things Summit - IoT360 2014: Internet of\n  Things. User-Centric IoT pp 23-28", "journal-ref": "Internet of Things. User-Centric IoT, 2015", "doi": "10.1007/978-3-319-19656-5_4", "report-no": null, "categories": "cs.MA cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we advocate Agent-Oriented Software Engi-neering (AOSE)\nthrough employing Belief-Desire-Intention (BDI) intel-ligent agents for\ndeveloping Sense-Compute-Control (SCC) applications in the Internet of Things\nand Services (IoTS). We argue that not only the agent paradigm, in general, but\nalso cognitive BDI agents with sense-deliberate-act cycle, in particular, fit\nvery well to the nature of SCC applications in the IoTS. However, considering\nthe highly constrained heterogeneous devices that are prevalent in the IoTS,\nexisting BDI agent frameworks, even those especially created for Wireless\nSensor Networks (WSNs), do not work. We elaborate on the challenges and propose\npos-sible approaches to address them.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 15:52:21 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Moin", "Armin", ""]]}, {"id": "2009.10689", "submitter": "Vasiliy Gurianov", "authors": "Vasyliy I. Gurianov", "title": "Simulation model of spacetime with the Minkowski metric", "comments": "8 pages, 5 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a simulation model of spacetime as a discrete model\nof physical space. The model is based on the ideas of Stephen Wolfram and uses\nnon-numerical modelling. The simulation model is described as an ontology. We\nuse object-oriented simulation (OOS), but the model is also suitable for\nagent-based simulation (ABS). We use UML2 SP (UML Scientific Profile), an\nobject-oriented simulation language used in scientific fields. This paper\ndescribes several experiments that demonstrate time dilation and dynamic\nrelativistic effects. The reproducibility of experimental results can be\nverified. We provide a link to the repository in this paper. The model is\nimplemented in Python.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 17:03:38 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Gurianov", "Vasyliy I.", ""]]}, {"id": "2009.10890", "submitter": "Amin Shojaeighadikolaei", "authors": "Amin Shojaeighadikolaei, Arman Ghasemi, Kailani R. Jones, Alexandru G.\n  Bardas, Morteza Hashemi, Reza Ahmadi", "title": "Demand Responsive Dynamic Pricing Framework for Prosumer Dominated\n  Microgrids using Multiagent Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Demand Response (DR) has a widely recognized potential for improving grid\nstability and reliability while reducing customers energy bills. However, the\nconventional DR techniques come with several shortcomings, such as inability to\nhandle operational uncertainties and incurring customer disutility, impeding\ntheir wide spread adoption in real-world applications. This paper proposes a\nnew multiagent Reinforcement Learning (RL) based decision-making environment\nfor implementing a Real-Time Pricing (RTP) DR technique in a prosumer dominated\nmicrogrid. The proposed technique addresses several shortcomings common to\ntraditional DR methods and provides significant economic benefits to the grid\noperator and prosumers. To show its better efficacy, the proposed DR method is\ncompared to a baseline traditional operation scenario in a small-scale\nmicrogrid system. Finally, investigations on the use of prosumers energy\nstorage capacity in this microgrid highlight the advantages of the proposed\nmethod in establishing a balanced market setup.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 01:44:57 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Shojaeighadikolaei", "Amin", ""], ["Ghasemi", "Arman", ""], ["Jones", "Kailani R.", ""], ["Bardas", "Alexandru G.", ""], ["Hashemi", "Morteza", ""], ["Ahmadi", "Reza", ""]]}, {"id": "2009.10905", "submitter": "Amin Shojaeighadikolaei", "authors": "Arman Ghasemi, Amin Shojaeighadikolaei, Kailani Jones, Morteza\n  Hashemi, Alexandru G. Bardas, Reza Ahmadi", "title": "A Multi-Agent Deep Reinforcement Learning Approach for a Distributed\n  Energy Marketplace in Smart Grids", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a Reinforcement Learning (RL) based energy market for a\nprosumer dominated microgrid. The proposed market model facilitates a real-time\nand demanddependent dynamic pricing environment, which reduces grid costs and\nimproves the economic benefits for prosumers. Furthermore, this market model\nenables the grid operator to leverage prosumers storage capacity as a\ndispatchable asset for grid support applications. Simulation results based on\nthe Deep QNetwork (DQN) framework demonstrate significant improvements of the\n24-hour accumulative profit for both prosumers and the grid operator, as well\nas major reductions in grid reserve power utilization.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 02:17:51 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Ghasemi", "Arman", ""], ["Shojaeighadikolaei", "Amin", ""], ["Jones", "Kailani", ""], ["Hashemi", "Morteza", ""], ["Bardas", "Alexandru G.", ""], ["Ahmadi", "Reza", ""]]}, {"id": "2009.11225", "submitter": "Aditya Jyoti Paul", "authors": "Aditya Jyoti Paul", "title": "Randomized fast no-loss expert system to play tic tac toe like a human", "comments": "Author's version of the paper published in IET Cognitive Computation\n  and Systems. For the journal-typeset version, please see\n  https://doi.org/10.1049/ccs.2020.0018", "journal-ref": "Cognitive Computation and Systems, Volume 2, Issue 4, December\n  2020, pp. 231 - 241", "doi": "10.1049/ccs.2020.0018", "report-no": null, "categories": "cs.AI cs.GT cs.HC cs.MA", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This paper introduces a blazingly fast, no-loss expert system for Tic Tac Toe\nusing Decision Trees called T3DT, that tries to emulate human gameplay as\nclosely as possible. It does not make use of any brute force, minimax or\nevolutionary techniques, but is still always unbeatable. In order to make the\ngameplay more human-like, randomization is prioritized and T3DT randomly\nchooses one of the multiple optimal moves at each step. Since it does not need\nto analyse the complete game tree at any point, T3DT is exceptionally faster\nthan any brute force or minimax algorithm, this has been shown theoretically as\nwell as empirically from clock-time analyses in this paper. T3DT also doesn't\nneed the data sets or the time to train an evolutionary model, making it a\npractical no-loss approach to play Tic Tac Toe.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 15:41:10 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 23:37:32 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Paul", "Aditya Jyoti", ""]]}, {"id": "2009.11727", "submitter": "The Anh Han", "authors": "Ogbo Ndidi Bianca, Aiman Elgarig, The Anh Han", "title": "Evolution of Coordination in Pairwise and Multi-player Interactions via\n  Prior Commitments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.GT math-ph math.MP nlin.AO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Upon starting a collective endeavour, it is important to understand your\npartners' preferences and how strongly they commit to a common goal.\nEstablishing a prior commitment or agreement in terms of posterior benefits and\nconsequences from those engaging in it provides an important mechanism for\nsecuring cooperation. Resorting to methods from Evolutionary Game Theory (EGT),\nhere we analyse how prior commitments can also be adopted as a tool for\nenhancing coordination when its outcomes exhibit an asymmetric payoff\nstructure, in both pairwise and multiparty interactions. Arguably, coordination\nis more complex to achieve than cooperation since there might be several\ndesirable collective outcomes in a coordination problem (compared to mutual\ncooperation, the only desirable collective outcome in cooperation dilemmas).\nOur analysis, both analytically and via numerical simulations, shows that\nwhether prior commitment would be a viable evolutionary mechanism for enhancing\ncoordination and the overall population social welfare strongly depends on the\ncollective benefit and severity of competition, and more importantly, how\nasymmetric benefits are resolved in a commitment deal. Moreover, in multiparty\ninteractions, prior commitments prove to be crucial when a high level of group\ndiversity is required for optimal coordination. The results are robust for\ndifferent selection intensities. Overall, our analysis provides new insights\ninto the complexity and beauty of behavioral evolution driven by humans'\ncapacity for commitment, as well as for the design of self-organised and\ndistributed multi-agent systems for ensuring coordination among autonomous\nagents.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 14:36:49 GMT"}, {"version": "v2", "created": "Thu, 17 Dec 2020 12:21:52 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Bianca", "Ogbo Ndidi", ""], ["Elgarig", "Aiman", ""], ["Han", "The Anh", ""]]}, {"id": "2009.12084", "submitter": "Mohammadreza Doostmohammadian", "authors": "Mohammadreza Doostmohammadian, Nader Meskin", "title": "Sensor Fault Detection and Isolation via Networked Estimation: Full-Rank\n  Dynamical Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the problem of simultaneous sensor fault detection,\nisolation, and networked estimation of linear full-rank dynamical systems. The\nproposed networked estimation is a variant of single time-scale protocol and is\nbased on (i) consensus on \\textit{a-priori} estimates and (ii) measurement\ninnovation. The necessary connectivity condition on the sensor network and\nstabilizing block-diagonal gain matrix is derived based on our previous works.\nConsidering additive faults in the presence of system and measurement noise,\nthe estimation error at sensors is derived and proper residuals are defined for\nfault detection. Unlike many works in the literature, no simplifying\nupper-bound condition on the noise is considered and we assume Gaussian\nsystem/measurement noise. A probabilistic threshold is then defined for fault\ndetection based on the estimation error covariance norm. Finally, a\ngraph-theoretic sensor replacement scenario is proposed to recover possible\nloss of networked observability due to removing the faulty sensor. We examine\nthe proposed fault detection and isolation scheme on an illustrative academic\nexample to verify the results and make a comparison study with related\nliterature.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 08:37:24 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Doostmohammadian", "Mohammadreza", ""], ["Meskin", "Nader", ""]]}, {"id": "2009.12106", "submitter": "Hai Zhu", "authors": "\\'Alvaro Serra-G\\'omez, Bruno Brito, Hai Zhu, Jen Jen Chung, Javier\n  Alonso-Mora", "title": "With Whom to Communicate: Learning Efficient Communication for\n  Multi-Robot Collision Avoidance", "comments": "IROS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decentralized multi-robot systems typically perform coordinated motion\nplanning by constantly broadcasting their intentions as a means to cope with\nthe lack of a central system coordinating the efforts of all robots. Especially\nin complex dynamic environments, the coordination boost allowed by\ncommunication is critical to avoid collisions between cooperating robots.\nHowever, the risk of collision between a pair of robots fluctuates through\ntheir motion and communication is not always needed. Additionally, constant\ncommunication makes much of the still valuable information shared in previous\ntime steps redundant. This paper presents an efficient communication method\nthat solves the problem of \"when\" and with \"whom\" to communicate in multi-robot\ncollision avoidance scenarios. In this approach, every robot learns to reason\nabout other robots' states and considers the risk of future collisions before\nasking for the trajectory plans of other robots. We evaluate and verify the\nproposed communication strategy in simulation with four quadrotors and compare\nit with three baseline strategies: non-communicating, broadcasting and a\ndistance-based method broadcasting information with quadrotors within a\npredefined distance.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 09:49:22 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Serra-G\u00f3mez", "\u00c1lvaro", ""], ["Brito", "Bruno", ""], ["Zhu", "Hai", ""], ["Chung", "Jen Jen", ""], ["Alonso-Mora", "Javier", ""]]}, {"id": "2009.12210", "submitter": "Felipe S. Abrah\\~ao", "authors": "Felipe S. Abrah\\~ao, Klaus Wehmuth, Artur Ziviani", "title": "Emergence of complex data from simple local rules in a network game", "comments": "arXiv admin note: text overlap with arXiv:1708.09149", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.GT cs.MA cs.SI cs.SY eess.SY physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As one of the main subjects of investigation in data science, network science\nhas been demonstrated a wide range of applications to real-world networks\nanalysis and modeling. For example, the pervasive presence of structural or\ntopological characteristics, such as the small-world phenomenon,\nsmall-diameter, scale-free properties, or fat-tailed degree distribution were\none of the underlying pillars fostering the study of complex networks. Relating\nthese phenomena with other emergent properties in complex systems became a\nsubject of central importance. By introducing new implications on the interface\nbetween data science and complex systems science with the purpose of tackling\nsome of these issues, in this article we present a model for a network game\nplayed by complex networks in which nodes are computable systems. In\nparticular, we present and discuss how some network topological properties and\nsimple local communication rules are able to generate a phase transition with\nrespect to the emergence of incompressible data.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 19:43:27 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Abrah\u00e3o", "Felipe S.", ""], ["Wehmuth", "Klaus", ""], ["Ziviani", "Artur", ""]]}, {"id": "2009.12211", "submitter": "Juan Chacon", "authors": "Juan Chacon, Mo Chen, and Razvan Fetecau", "title": "Safe Coverage of Moving Domains for Vehicles with Second Order Dynamics", "comments": "15 pages, 12 figures, submitted to ieee-tac. arXiv admin note: text\n  overlap with arXiv:1911.06519", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous coverage of a specified area by robots operating in close\nproximity with each other has many potential applications such as real-time\nmonitoring of rapidly changing environments, and search and rescue; however,\ncoordination and safety are two fundamental challenges. For coordination, we\npropose a distributed controller for covering moving, compact domains for two\ntypes of vehicles with second order dynamics (double integrator and fixed-wing\naircraft) with bounded input forces. This control policy is based on artificial\npotentials and alignment forces designed to promote desired vehicle-domain and\ninter-vehicle separations and relative velocities. We prove that certain\ncoverage configurations are locally asymptotically stable. For safety, we\nestablish energy conditions for collision free motion and utilize\nHamilton-Jacobi (HJ) reachability theory for last-resort pairwise collision\navoidance. We derive an analytical solution to the associated HJ partial\ndifferential equation corresponding to the collision avoidance problem between\ntwo double integrator vehicles. We demonstrate our approach in several\nnumerical simulations involving the two types of vehicles covering convex and\nnon-convex moving domains.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 05:46:25 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Chacon", "Juan", ""], ["Chen", "Mo", ""], ["Fetecau", "Razvan", ""]]}, {"id": "2009.12213", "submitter": "Qi Dai", "authors": "Qi Dai, Xunnong Xu, Wen Guo, Suzhou Huang, Dimitar Filev", "title": "Towards a Systematic Computational Framework for Modeling Multi-Agent\n  Decision-Making at Micro Level for Smart Vehicles in a Smart World", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a multi-agent based computational framework for modeling\ndecision-making and strategic interaction at micro level for smart vehicles in\na smart world. The concepts of Markov game and best response dynamics are\nheavily leveraged. Our aim is to make the framework conceptually sound and\ncomputationally practical for a range of realistic applications, including\nmicro path planning for autonomous vehicles. To this end, we first convert the\nwould-be stochastic game problem into a closely related deterministic one by\nintroducing risk premium in the utility function for each individual agent. We\nshow how the sub-game perfect Nash equilibrium of the simplified deterministic\ngame can be solved by an algorithm based on best response dynamics. In order to\nbetter model human driving behaviors with bounded rationality, we seek to\nfurther simplify the solution concept by replacing the Nash equilibrium\ncondition with a heuristic and adaptive optimization with finite look-ahead\nanticipation. In addition, the algorithm corresponding to the new solution\nconcept drastically improves the computational efficiency. To demonstrate how\nour approach can be applied to realistic traffic settings, we conduct a\nsimulation experiment: to derive merging and yielding behaviors on a\ndouble-lane highway with an unexpected barrier. Despite assumption differences\ninvolved in the two solution concepts, the derived numerical solutions show\nthat the endogenized driving behaviors are very similar. We also briefly\ncomment on how the proposed framework can be further extended in a number of\ndirections in our forthcoming work, such as behavioral calibration using real\ntraffic video data, computational mechanism design for traffic policy\noptimization, and so on.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 13:05:28 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Dai", "Qi", ""], ["Xu", "Xunnong", ""], ["Guo", "Wen", ""], ["Huang", "Suzhou", ""], ["Filev", "Dimitar", ""]]}, {"id": "2009.12738", "submitter": "Han-Lim Choi", "authors": "Lebsework Negash, Han-Lim Choi", "title": "Resilient Networking in Formation Flying UAVs", "comments": "19pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The threats on cyber-physical system have changed much into a level of\nsophistication that elude the traditional security and protection methods. This\nwork addresses a proactive approaches to the cyber security of a formation\nflying UAVs. A resilient formation control of UAVs in the presence of\nnon-cooperative (defective or malicious) UAVs is presented. Based on local\ninformation a resilient consensus in the presence of misbehaving nodes is dealt\nwith fault-tolerant consensus algorithm. In the proposed framework, a\ngraph-theoretic property of network robustness conveying the notion of a direct\ninformation exchange between two sets of UAVs in the network is introduced to\nanalyze the behavior and convergence of the distributed consensus algorithm. A\ndistributed control policy is developed to maintain the network connectivity\nthreshold to satisfy the topological requirement put forward for the resiliency\nof the consensus algorithm. Numerical examples are presented to show the\napplicability of the proactive approach used in dealing with the cyber attack\ntreat on a formation flying UAVs\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 03:47:18 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Negash", "Lebsework", ""], ["Choi", "Han-Lim", ""]]}, {"id": "2009.12842", "submitter": "Navin Raj Prabhu", "authors": "Navin Raj Prabhu, Chirag Raman, Hayley Hung", "title": "Defining and Quantifying Conversation Quality in Spontaneous\n  Interactions", "comments": "10 pages, 8 figures, Companion Publication of the 2020 International\n  Conference on Multimodal Interaction (ICMI '20 Companion), October 25--29,\n  2020, Virtual event, Netherlands", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social interactions in general are multifaceted and there exists a wide set\nof factors and events that influence them. In this paper, we quantify social\ninteractions with a holistic viewpoint on individual experiences, particularly\nfocusing on non-task-directed spontaneous interactions. To achieve this, we\ndesign a novel perceived measure, the perceived Conversation Quality, which\nintends to quantify spontaneous interactions by accounting for several\nsocio-dimensional aspects of individual experiences.\n  To further quantitatively study spontaneous interactions, we devise a\nquestionnaire which measures the perceived Conversation Quality, at both the\nindividual- and at the group- level. Using the questionnaire, we collected\nperceived annotations for conversation quality in a publicly available dataset\nusing naive annotators. The results of the analysis performed on the\ndistribution and the inter-annotator agreeability shows that naive annotators\ntend to agree less in cases of low conversation quality samples, especially\nwhile annotating for group-level conversation quality.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 13:41:27 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Prabhu", "Navin Raj", ""], ["Raman", "Chirag", ""], ["Hung", "Hayley", ""]]}, {"id": "2009.12992", "submitter": "Lintao Ye", "authors": "Lintao Ye, Shreyas Sundaram", "title": "Distributed Maximization of Submodular and Approximately Submodular\n  Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of maximizing a submodular function, subject to a\ncardinality constraint, with a set of agents communicating over a connected\ngraph. We propose a distributed greedy algorithm that allows all the agents to\nconverge to a near-optimal solution to the global maximization problem using\nonly local information and communication with neighbors in the graph. The\nnear-optimal solution approaches the (1-1/e) approximation of the optimal\nsolution to the global maximization problem with an additive factor that\ndepends on the number of communication steps in the algorithm. We then analyze\nconvergence guarantees of the proposed algorithm. This analysis reveals a\ntradeoff between the number of communication steps and the performance of the\nalgorithm. Finally, we extend our analysis to nonsubmodular settings, using the\nnotion of approximate submodularity.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 00:33:58 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Ye", "Lintao", ""], ["Sundaram", "Shreyas", ""]]}, {"id": "2009.13051", "submitter": "Justin Terry", "authors": "Justin K Terry, Nathaniel Grammel, Benjamin Black, Ananth Hari,\n  Caroline Horsch, Luis Santos", "title": "Agent Environment Cycle Games", "comments": "This work of this paper has been merged into the paper \"PettingZoo:\n  Gym for Multi-Agent Reinforcement Learning\" arXiv:2009.14471", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.GT cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Partially Observable Stochastic Games (POSGs) are the most general and common\nmodel of games used in Multi-Agent Reinforcement Learning (MARL). We argue that\nthe POSG model is conceptually ill suited to software MARL environments, and\noffer case studies from the literature where this mismatch has led to severely\nunexpected behavior. In response to this, we introduce the Agent Environment\nCycle Games (AEC Games) model, which is more representative of software\nimplementation. We then prove it's as an equivalent model to POSGs. The AEC\ngames model is also uniquely useful in that it can elegantly represent both all\nforms of MARL environments, whereas for example POSGs cannot elegantly\nrepresent strictly turn based games like chess.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 04:02:08 GMT"}, {"version": "v2", "created": "Mon, 15 Feb 2021 19:06:59 GMT"}, {"version": "v3", "created": "Sat, 1 May 2021 14:24:22 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Terry", "Justin K", ""], ["Grammel", "Nathaniel", ""], ["Black", "Benjamin", ""], ["Hari", "Ananth", ""], ["Horsch", "Caroline", ""], ["Santos", "Luis", ""]]}, {"id": "2009.13609", "submitter": "Lin Song", "authors": "Lin Song, Neng Wan, Aditya Gahlawat, Naira Hovakimyan, and Evangelos\n  A. Theodorou", "title": "Compositionality of Linearly Solvable Optimal Control in Networked\n  Multi-Agent Systems", "comments": "Accepted to the 2021 American Control Conference (ACC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.MA cs.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we discuss the methodology of generalizing the optimal control\nlaw from learned component tasks to unlearned composite tasks on Multi-Agent\nSystems (MASs), by using the linearity composition principle of linearly\nsolvable optimal control (LSOC) problems. The proposed approach achieves both\nthe compositionality and optimality of control actions simultaneously within\nthe cooperative MAS framework in both discrete- and continuous-time in a\nsample-efficient manner, which reduces the burden of re-computation of the\noptimal control solutions for the new task on the MASs. We investigate the\napplication of the proposed approach on the MAS with coordination between\nagents. The experiments show feasible results in investigated scenarios,\nincluding both discrete and continuous dynamical systems for task\ngeneralization without resampling.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 20:21:48 GMT"}, {"version": "v2", "created": "Mon, 22 Mar 2021 19:33:28 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Song", "Lin", ""], ["Wan", "Neng", ""], ["Gahlawat", "Aditya", ""], ["Hovakimyan", "Naira", ""], ["Theodorou", "Evangelos A.", ""]]}, {"id": "2009.14180", "submitter": "Max Smith", "authors": "Max Olan Smith, Thomas Anthony, Yongzhao Wang, Michael P. Wellman", "title": "Learning to Play against Any Mixture of Opponents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intuitively, experience playing against one mixture of opponents in a given\ndomain should be relevant for a different mixture in the same domain. We\npropose a transfer learning method, Q-Mixing, that starts by learning Q-values\nagainst each pure-strategy opponent. Then a Q-value for any distribution of\nopponent strategies is approximated by appropriately averaging the separately\nlearned Q-values. From these components, we construct policies against all\nopponent mixtures without any further training. We empirically validate\nQ-Mixing in two environments: a simple grid-world soccer environment, and a\ncomplicated cyber-security game. We find that Q-Mixing is able to successfully\ntransfer knowledge across any mixture of opponents. We next consider the use of\nobservations during play to update the believed distribution of opponents. We\nintroduce an opponent classifier -- trained in parallel to Q-learning, using\nthe same data -- and use the classifier results to refine the mixing of\nQ-values. We find that Q-Mixing augmented with the opponent classifier function\nperforms comparably, and with lower variance, than training directly against a\nmixed-strategy opponent.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 17:48:10 GMT"}, {"version": "v2", "created": "Thu, 3 Jun 2021 14:36:51 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Smith", "Max Olan", ""], ["Anthony", "Thomas", ""], ["Wang", "Yongzhao", ""], ["Wellman", "Michael P.", ""]]}, {"id": "2009.14279", "submitter": "Logan Beaver", "authors": "Logan E. Beaver and Andreas A. Malikopoulos", "title": "An Overview on Optimal Flocking", "comments": "21 pages, 5 figures", "journal-ref": "Annual Reviews in Control, April 2021", "doi": "10.1016/j.arcontrol.2021.03.004", "report-no": null, "categories": "cs.MA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study of robotic flocking has received considerable attention in the past\ntwenty years. As we begin to deploy flocking control algorithms on physical\nmulti-agent and swarm systems, there is an increasing necessity for rigorous\npromises on safety and performance. In this paper, we present an overview the\nliterature focusing on optimization approaches to achieve flocking behavior\nthat provide strong safety guarantees. We separate the literature into cluster\nand line flocking, and categorize cluster flocking with respect to the\nsystem-level objective, which may be realized by a reactive or planning control\nalgorithm. We also categorize the line flocking literature by the energy-saving\nmechanism that is exploited by the agents. We present several approaches aimed\nat minimizing the communication and computational requirements in real systems\nvia neighbor filtering and event-driven planning, and conclude with our\nperspective on the outlook and future research direction of optimal flocking as\na field.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 19:44:49 GMT"}, {"version": "v2", "created": "Fri, 22 Jan 2021 15:12:18 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Beaver", "Logan E.", ""], ["Malikopoulos", "Andreas A.", ""]]}, {"id": "2009.14363", "submitter": "Yash Vardhan Pant", "authors": "Yash Vardhan Pant, He Yin, Murat Arcak, Sanjit A. Seshia", "title": "Co-design of Control and Planning for Multi-rotor UAVs with Signal\n  Temporal Logic Specifications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.MA cs.RO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Urban Air Mobility (UAM), or the scenario where multiple manned and Unmanned\nAerial Vehicles (UAVs) carry out various tasks over urban airspaces, is a\ntransportation concept of the future that is gaining prominence. UAM missions\nwith complex spatial, temporal and reactive requirements can be succinctly\nrepresented using Signal Temporal Logic (STL), a behavioral specification\nlanguage. However, planning and control of systems with STL specifications is\ncomputationally intensive, usually resulting in planning approaches that do not\nguarantee dynamical feasibility, or control approaches that cannot handle\ncomplex STL specifications. Here, we present an approach to co-design the\nplanner and control such that a given STL specification (possibly over multiple\nUAVs) is satisfied with trajectories that are dynamically feasible and our\ncontroller can track them with a bounded tracking-error that the planner\naccounts for. The tracking controller is formulated for the non-linear dynamics\nof the individual UAVs, and the tracking error bound is computed for this\ncontroller when the trajectories satisfy some kinematic constraints. We also\naugment an existing multi-UAV STL-based trajectory generator in order to\ngenerate trajectories that satisfy such constraints. We show that this\nco-design allows for trajectories that satisfy a given STL specification, and\nare also dynamically feasible in the sense that they can be tracked with\nbounded error. The applicability of this approach is demonstrated through\nsimulations of multi-UAV missions.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 01:00:47 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Pant", "Yash Vardhan", ""], ["Yin", "He", ""], ["Arcak", "Murat", ""], ["Seshia", "Sanjit A.", ""]]}, {"id": "2009.14471", "submitter": "Justin Terry", "authors": "J. K. Terry, Benjamin Black, Nathaniel Grammel, Mario Jayakumar,\n  Ananth Hari, Ryan Sullivan, Luis Santos, Rodrigo Perez, Caroline Horsch,\n  Clemens Dieffendahl, Niall L. Williams, Yashas Lokesh, Praveen Ravi", "title": "PettingZoo: Gym for Multi-Agent Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the PettingZoo library and the accompanying Agent\nEnvironment Cycle (\"AEC\") games model. PettingZoo is a library of diverse sets\nof multi-agent environments with a universal, elegant Python API. PettingZoo\nwas developed with the goal of accelerating research in Multi-Agent\nReinforcement Learning (\"MARL\"), by making work more interchangeable,\naccessible and reproducible akin to what OpenAI's Gym library did for\nsingle-agent reinforcement learning. PettingZoo's API, while inheriting many\nfeatures of Gym, is unique amongst MARL APIs in that it's based around the\nnovel AEC games model. We argue, in part through case studies on major problems\nin popular MARL environments, that the popular game models are poor conceptual\nmodels of the games commonly used with MARL, that they promote severe bugs that\nare hard to detect, and that the AEC games model addresses these problems.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 06:42:09 GMT"}, {"version": "v2", "created": "Wed, 4 Nov 2020 20:04:22 GMT"}, {"version": "v3", "created": "Sat, 14 Nov 2020 08:02:06 GMT"}, {"version": "v4", "created": "Tue, 24 Nov 2020 22:34:21 GMT"}, {"version": "v5", "created": "Thu, 25 Feb 2021 22:08:03 GMT"}, {"version": "v6", "created": "Wed, 16 Jun 2021 00:18:34 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Terry", "J. K.", ""], ["Black", "Benjamin", ""], ["Grammel", "Nathaniel", ""], ["Jayakumar", "Mario", ""], ["Hari", "Ananth", ""], ["Sullivan", "Ryan", ""], ["Santos", "Luis", ""], ["Perez", "Rodrigo", ""], ["Horsch", "Caroline", ""], ["Dieffendahl", "Clemens", ""], ["Williams", "Niall L.", ""], ["Lokesh", "Yashas", ""], ["Ravi", "Praveen", ""]]}, {"id": "2009.14679", "submitter": "Mark Gluzman", "authors": "Jiekun Feng, Mark Gluzman, J. G. Dai", "title": "Scalable Deep Reinforcement Learning for Ride-Hailing", "comments": null, "journal-ref": "IEEE Control Systems Letters, vol. 5, no. 6, pp. 2060-2065, 2021", "doi": "10.1109/LCSYS.2020.3046995", "report-no": null, "categories": "math.OC cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ride-hailing services, such as Didi Chuxing, Lyft, and Uber, arrange\nthousands of cars to meet ride requests throughout the day. We consider a\nMarkov decision process (MDP) model of a ride-hailing service system, framing\nit as a reinforcement learning (RL) problem. The simultaneous control of many\nagents (cars) presents a challenge for the MDP optimization because the action\nspace grows exponentially with the number of cars. We propose a special\ndecomposition for the MDP actions by sequentially assigning tasks to the\ndrivers. The new actions structure resolves the scalability problem and enables\nthe use of deep RL algorithms for control policy optimization. We demonstrate\nthe benefit of our proposed decomposition with a numerical experiment based on\nreal data from Didi Chuxing.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 20:07:12 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Feng", "Jiekun", ""], ["Gluzman", "Mark", ""], ["Dai", "J. G.", ""]]}, {"id": "2009.14763", "submitter": "Nirupam Gupta", "authors": "Nirupam Gupta, Thinh T. Doan and Nitin H. Vaidya", "title": "Byzantine Fault-Tolerance in Decentralized Optimization under Minimal\n  Redundancy", "comments": "An extension of our prior work on fault-tolerant distributed\n  optimization, for the server-based system architecture\n  (https://dl.acm.org/doi/10.1145/3382734.3405748), to the more general\n  peer-to-peer system architecture", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.MA cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the problem of Byzantine fault-tolerance in multi-agent\ndecentralized optimization. In this problem, each agent has a local cost\nfunction. The goal of a decentralized optimization algorithm is to allow the\nagents to cooperatively compute a common minimum point of their aggregate cost\nfunction. We consider the case when a certain number of agents may be Byzantine\nfaulty. Such faulty agents may not follow a prescribed algorithm, and they may\nshare arbitrary or incorrect information with other non-faulty agents. Presence\nof such Byzantine agents renders a typical decentralized optimization algorithm\nineffective. We propose a decentralized optimization algorithm with provable\nexact fault-tolerance against a bounded number of Byzantine agents, provided\nthe non-faulty agents have a minimal redundancy.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 16:02:15 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Gupta", "Nirupam", ""], ["Doan", "Thinh T.", ""], ["Vaidya", "Nitin H.", ""]]}, {"id": "2009.14775", "submitter": "Neng Wan", "authors": "Neng Wan, Aditya Gahlawat, Naira Hovakimyan, Evangelos A. Theodorou,\n  and Petros G. Voulgaris", "title": "Cooperative Path Integral Control for Stochastic Multi-Agent Systems", "comments": "To appear in American Control Conference 2021, New Orleans, LA, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.MA cs.RO cs.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A distributed stochastic optimal control solution is presented for\ncooperative multi-agent systems. The network of agents is partitioned into\nmultiple factorial subsystems, each of which consists of a central agent and\nneighboring agents. Local control actions that rely only on agents' local\nobservations are designed to optimize the joint cost functions of subsystems.\nWhen solving for the local control actions, the joint optimality equation for\neach subsystem is cast as a linear partial differential equation and solved\nusing the Feynman-Kac formula. The solution and the optimal control action are\nthen formulated as path integrals and approximated by a Monte-Carlo method.\nNumerical verification is provided through a simulation example consisting of a\nteam of cooperative UAVs.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 16:24:14 GMT"}, {"version": "v2", "created": "Sun, 21 Mar 2021 03:28:03 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Wan", "Neng", ""], ["Gahlawat", "Aditya", ""], ["Hovakimyan", "Naira", ""], ["Theodorou", "Evangelos A.", ""], ["Voulgaris", "Petros G.", ""]]}, {"id": "2009.14793", "submitter": "Edin Husic", "authors": "Jugal Garg, Edin Husic and Laszlo A. Vegh", "title": "Approximating Nash Social Welfare under Rado Valuations", "comments": "44 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DM cs.DS cs.MA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of approximating maximum Nash social welfare (NSW)\nwhile allocating a set of indivisible items to $n$ agents. The NSW is a popular\nobjective that provides a balanced tradeoff between the often conflicting\nrequirements of fairness and efficiency, defined as the weighted geometric mean\nof agents' valuations. For the symmetric additive case of the problem, where\nagents have the same weight with additive valuations, the first constant-factor\napproximation algorithm was obtained in 2015. This led to a flurry of work\nobtaining constant-factor approximation algorithms for the symmetric case under\nmild generalizations of additive, and $O(n)$-approximation algorithms for more\ngeneral valuations and for the asymmetric case.\n  In this paper, we make significant progress towards both symmetric and\nasymmetric NSW problems. We present the first constant-factor approximation\nalgorithm for the symmetric case under Rado valuations. Rado valuations form a\ngeneral class of valuation functions that arise from maximum cost independent\nmatching problems, including as special cases assignment (OXS) valuations and\nweighted matroid rank functions. Furthermore, our approach also gives the first\nconstant-factor approximation algorithm for the asymmetric case under Rado\nvaluations, provided that the maximum ratio between the weights is bounded by a\nconstant.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 17:07:51 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Garg", "Jugal", ""], ["Husic", "Edin", ""], ["Vegh", "Laszlo A.", ""]]}]