[{"id": "1804.00038", "submitter": "Hang Ma", "authors": "Hang Ma, Wolfgang H\\\"onig, Liron Cohen, Tansel Uras, Hong Xu, T. K.\n  Satish Kumar, Nora Ayanian, Sven Koenig", "title": "Overview: A Hierarchical Framework for Plan Generation and Execution in\n  Multi-Robot Systems", "comments": null, "journal-ref": "IEEE Intelligent Systems, vol. 32, no. 6, pp. 6-12,\n  November/December 2017", "doi": "10.1109/MIS.2017.4531217", "report-no": null, "categories": "cs.AI cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The authors present an overview of a hierarchical framework for coordinating\ntask- and motion-level operations in multirobot systems. Their framework is\nbased on the idea of using simple temporal networks to simultaneously reason\nabout precedence/causal constraints required for task-level coordination and\nsimple temporal constraints required to take some kinematic constraints of\nrobots into account. In the plan-generation phase, the framework provides a\ncomputationally scalable method for generating plans that achieve high-level\ntasks for groups of robots and take some of their kinematic constraints into\naccount. In the plan-execution phase, the framework provides a method for\nabsorbing an imperfect plan execution to avoid time-consuming re-planning in\nmany cases. The authors use the multirobot path-planning problem as a case\nstudy to present the key ideas behind their framework for the long-term\nautonomy of multirobot systems.\n", "versions": [{"version": "v1", "created": "Fri, 30 Mar 2018 19:20:23 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Ma", "Hang", ""], ["H\u00f6nig", "Wolfgang", ""], ["Cohen", "Liron", ""], ["Uras", "Tansel", ""], ["Xu", "Hong", ""], ["Kumar", "T. K. Satish", ""], ["Ayanian", "Nora", ""], ["Koenig", "Sven", ""]]}, {"id": "1804.00638", "submitter": "Hyungbo Shim", "authors": "Jin Gyu Lee, Hyungbo Shim", "title": "A Tool for Analysis and Synthesis of Heterogeneous Multi-agent Systems\n  under Rank-deficient Coupling", "comments": null, "journal-ref": "Automatica, vol. 117, pp. 108952, July 2020", "doi": "10.1016/j.automatica.2020.108952", "report-no": null, "categories": "cs.SY cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The behavior of heterogeneous multi-agent systems is studied when the\ncoupling matrices are possibly all different and/or singular, that is, its rank\nis less than the system dimension. Rank-deficient coupling allows exchange of\nlimited state information, which is suitable for the study of multi-agent\nsystems under output coupling. We present a coordinate change that transforms\nthe heterogeneous multi-agent system into a singularly perturbed form. The slow\ndynamics is still a reduced-order multi-agent system consisting of a weighted\naverage of the vector fields of all agents, and some sub-dynamics of agents.\nThe weighted average is an emergent dynamics, which we call a blended dynamics.\nBy analyzing or synthesizing the blended dynamics, one can predict or design\nthe behavior of a heterogeneous multi-agent system when the coupling gain is\nsufficiently large. For this result, stability of the blended dynamics is\nrequired. Since stability of the individual agent is not asked, the stability\nof the blended dynamics is the outcome of trading off the stability among the\nagents. It can be seen that, under the stability of the blended dynamics, the\ninitial conditions of the individual agents are forgotten as time goes on, and\nthus, the behavior of the synthesized multi-agent system is initialization-free\nand is suitable for plug-and-play operation. As a showcase, we apply the\nproposed tool to four application problems; distributed state estimation for\nlinear systems, practical synchronization of heterogeneous Van der Pol\noscillators, estimation of the number of nodes in a network, and a problem of\ndistributed optimization.\n", "versions": [{"version": "v1", "created": "Mon, 2 Apr 2018 17:35:24 GMT"}, {"version": "v2", "created": "Sat, 29 Feb 2020 06:14:57 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Lee", "Jin Gyu", ""], ["Shim", "Hyungbo", ""]]}, {"id": "1804.00810", "submitter": "Kun Shao", "authors": "Kun Shao, Yuanheng Zhu, Dongbin Zhao", "title": "StarCraft Micromanagement with Reinforcement Learning and Curriculum\n  Transfer Learning", "comments": "12 pages, 14 figures, accepted to IEEE Transactions on Emerging\n  Topics in Computational Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-time strategy games have been an important field of game artificial\nintelligence in recent years. This paper presents a reinforcement learning and\ncurriculum transfer learning method to control multiple units in StarCraft\nmicromanagement. We define an efficient state representation, which breaks down\nthe complexity caused by the large state space in the game environment. Then a\nparameter sharing multi-agent gradientdescent Sarsa({\\lambda}) (PS-MAGDS)\nalgorithm is proposed to train the units. The learning policy is shared among\nour units to encourage cooperative behaviors. We use a neural network as a\nfunction approximator to estimate the action-value function, and propose a\nreward function to help units balance their move and attack. In addition, a\ntransfer learning method is used to extend our model to more difficult\nscenarios, which accelerates the training process and improves the learning\nperformance. In small scale scenarios, our units successfully learn to combat\nand defeat the built-in AI with 100% win rates. In large scale scenarios,\ncurriculum transfer learning method is used to progressively train a group of\nunits, and shows superior performance over some baseline methods in target\nscenarios. With reinforcement learning and curriculum transfer learning, our\nunits are able to learn appropriate strategies in StarCraft micromanagement\nscenarios.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 03:57:02 GMT"}], "update_date": "2018-04-04", "authors_parsed": [["Shao", "Kun", ""], ["Zhu", "Yuanheng", ""], ["Zhao", "Dongbin", ""]]}, {"id": "1804.01144", "submitter": "Carlos Gershenson", "authors": "Carlos Gershenson, Vito Trianni, Justin Werfel, and Hiroki Sayama", "title": "Self-Organization and Artificial Life: A Review", "comments": "8 pages, submitted to ALife 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "nlin.AO cs.AI cs.MA cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-organization has been an important concept within a number of\ndisciplines, which Artificial Life (ALife) also has heavily utilized since its\ninception. The term and its implications, however, are often confusing or\nmisinterpreted. In this work, we provide a mini-review of self-organization and\nits relationship with ALife, aiming at initiating discussions on this important\ntopic with the interested audience. We first articulate some fundamental\naspects of self-organization, outline its usage, and review its applications to\nALife within its soft, hard, and wet domains. We also provide perspectives for\nfurther research.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 19:44:09 GMT"}], "update_date": "2018-04-05", "authors_parsed": [["Gershenson", "Carlos", ""], ["Trianni", "Vito", ""], ["Werfel", "Justin", ""], ["Sayama", "Hiroki", ""]]}, {"id": "1804.01799", "submitter": "Mohammadreza Doostmohammadian", "authors": "Mohammadreza Doostmohammadian, Hamid R. Rabiee, Usman A. Khan", "title": "Structural cost-optimal design of sensor networks for distributed\n  estimation", "comments": null, "journal-ref": "IEEE Signal Processing Letters 2018", "doi": "10.1109/LSP.2018.2824761", "report-no": null, "categories": "cs.SY cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this letter we discuss cost optimization of sensor networks monitoring\nstructurally full-rank systems under distributed observability constraint.\nUsing structured systems theory, the problem is relaxed into two subproblems:\n(i) sensing cost optimization and (ii) networking cost optimization. Both\nproblems are reformulated as combinatorial optimization problems. The sensing\ncost optimization is shown to have a polynomial order solution. The networking\ncost optimization is shown to be NP-hard in general, but has a polynomial order\nsolution under specific conditions. A 2-approximation polynomial order\nrelaxation is provided for general networking cost optimization, which is\napplicable in large-scale system monitoring.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2018 12:14:01 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Doostmohammadian", "Mohammadreza", ""], ["Rabiee", "Hamid R.", ""], ["Khan", "Usman A.", ""]]}, {"id": "1804.02251", "submitter": "Philip Feldman", "authors": "Philip Feldman, Aaron Dant, and Wayne Lutters", "title": "This One Simple Trick Disrupts Digital Communities", "comments": null, "journal-ref": "SASO 2018 Conference Proceedings", "doi": "10.1109/SASO.2018.00016", "report-no": "1949-3681", "categories": "cs.MA cs.CY cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes an agent based simulation used to model human actions in\nbelief space, a high-dimensional subset of information space associated with\nopinions. Using insights from animal collective behavior, we are able to\nsimulate and identify behavior patterns that are similar to nomadic, flocking\nand stampeding patterns of animal groups. These behaviors have analogous\nmanifestations in human interaction, emerging as solitary explorers, the\nfashion-conscious, and members of polarized echo chambers. We demonstrate that\na small portion of nomadic agents that widely traverse belief space can disrupt\na larger population of stampeding agents. Extending the model, we introduce the\nconcept of Adversarial Herding, where bad actors can exploit properties of\ntechnologically mediated communication to artificially create self sustaining\nrunaway polarization. We call this condition the Pishkin Effect as it recalls\nthe large scale buffalo stampedes that could be created by native Americans\nhunters. We then discuss opportunities for system design that could leverage\nthe ability to recognize these negative patterns, and discuss affordances that\nmay disrupt the formation of natural and deliberate echo chambers.\n", "versions": [{"version": "v1", "created": "Fri, 6 Apr 2018 13:17:52 GMT"}, {"version": "v2", "created": "Tue, 26 Jun 2018 20:47:18 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Feldman", "Philip", ""], ["Dant", "Aaron", ""], ["Lutters", "Wayne", ""]]}, {"id": "1804.02512", "submitter": "Yuexin Ma", "authors": "Yuexin Ma, Dinesh Manocha, Wenping Wang", "title": "Efficient Reciprocal Collision Avoidance between Heterogeneous Agents\n  Using CTMAT", "comments": "International Conference on Autonomous Agents and Multiagent Systems\n  (AAMAS 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present a novel algorithm for reciprocal collision avoidance between\nheterogeneous agents of different shapes and sizes. We present a novel CTMAT\nrepresentation based on medial axis transform to compute a tight fitting\nbounding shape for each agent. Each CTMAT is represented using tuples, which\nare composed of circular arcs and line segments. Based on the reciprocal\nvelocity obstacle formulation, we reduce the problem to solving a\nlow-dimensional linear programming between each pair of tuples belonging to\nadjacent agents. We precompute the Minkowski Sums of tuples to accelerate the\nruntime performance. Finally, we provide an efficient method to update the\norientation of each agent in a local manner. We have implemented the algorithm\nand highlight its performance on benchmarks corresponding to road traffic\nscenarios and different vehicles. The overall runtime performance is comparable\nto prior multi-agent collision avoidance algorithms that use circular or\nelliptical agents. Our approach is less conservative and results in fewer false\ncollisions.\n", "versions": [{"version": "v1", "created": "Sat, 7 Apr 2018 05:44:19 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Ma", "Yuexin", ""], ["Manocha", "Dinesh", ""], ["Wang", "Wenping", ""]]}, {"id": "1804.02698", "submitter": "Takumi Ichimura", "authors": "Takumi Ichimura, Daisuke Igaue", "title": "Hierarchical Modular Reinforcement Learning Method and Knowledge\n  Acquisition of State-Action Rule for Multi-target Problem", "comments": "6pages, 10 figures, Proc. of IEEE 6th International Workshop on\n  Computational Intelligence and Applications (IWCIA2013)", "journal-ref": null, "doi": "10.1109/IWCIA.2013.6624799", "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical Modular Reinforcement Learning (HMRL), consists of 2 layered\nlearning where Profit Sharing works to plan a prey position in the higher layer\nand Q-learning method trains the state-actions to the target in the lower\nlayer. In this paper, we expanded HMRL to multi-target problem to take the\ndistance between targets to the consideration. The function, called `AT field',\ncan estimate the interests for an agent according to the distance between 2\nagents and the advantage/disadvantage of the other agent. Moreover, the\nknowledge related to state-action rules is extracted by C4.5. The action under\nthe situation is decided by using the acquired knowledge. To verify the\neffectiveness of proposed method, some experimental results are reported.\n", "versions": [{"version": "v1", "created": "Sun, 8 Apr 2018 14:39:13 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Ichimura", "Takumi", ""], ["Igaue", "Daisuke", ""]]}, {"id": "1804.02822", "submitter": "Takumi Ichimura", "authors": "Takumi Ichimura, Takuya Uemoto", "title": "Analysis of the Social Community Based on the Network Growing Model in\n  Open Source Software Community", "comments": "5 pages, 5 figures, Proc. of IEEE 8th International Workshop on\n  Computational Intelligence and Applications (IWCIA2015)", "journal-ref": null, "doi": "10.1109/IWCIA.2015.7449480", "report-no": null, "categories": "cs.MA cs.CY cs.SE cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The social community in open source software developers has a complex network\nstructure. The network structure represents the relations between the project\nand the engineer in the software developer's community. A project forms some\nteams which consist of engineers categorized into some task group. Source Forge\nis well known to be one of open source websites. The node and arc in the\nnetwork structure means the engineer and their connection among engineers in\nthe Source Forge. In the previous study, we found the growing process of\nproject becomes strong according to the number of developers joining into the\nproject. In the growing phase, we found some characteristic patterns between\nthe number of agents and the produced projects. By such observations, we\ndeveloped a simulation model of performing the growing process of project. In\nthis paper, we introduced the altruism behavior as shown in the Army Ant model\ninto the software developer's simulation model. The efficiency of the software\ndeveloping process was investigated by some experimental simulation results.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 05:47:58 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Ichimura", "Takumi", ""], ["Uemoto", "Takuya", ""]]}, {"id": "1804.02884", "submitter": "Duc Thien Nguyen", "authors": "Duc Thien Nguyen and Akshat Kumar and Hoong Chuin Lau", "title": "Policy Gradient With Value Function Approximation For Collective\n  Multiagent Planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA cs.NE cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decentralized (PO)MDPs provide an expressive framework for sequential\ndecision making in a multiagent system. Given their computational complexity,\nrecent research has focused on tractable yet practical subclasses of\nDec-POMDPs. We address such a subclass called CDEC-POMDP where the collective\nbehavior of a population of agents affects the joint-reward and environment\ndynamics. Our main contribution is an actor-critic (AC) reinforcement learning\nmethod for optimizing CDEC-POMDP policies. Vanilla AC has slow convergence for\nlarger problems. To address this, we show how a particular decomposition of the\napproximate action-value function over agents leads to effective updates, and\nalso derive a new way to train the critic based on local reward signals.\nComparisons on a synthetic benchmark and a real-world taxi fleet optimization\nproblem show that our new AC approach provides better quality solutions than\nprevious best approaches.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 09:45:29 GMT"}], "update_date": "2018-04-11", "authors_parsed": [["Nguyen", "Duc Thien", ""], ["Kumar", "Akshat", ""], ["Lau", "Hoong Chuin", ""]]}, {"id": "1804.02915", "submitter": "Yuexin Ma", "authors": "Yuexin Ma, Dinesh Manocha, Wenping Wang", "title": "AutoRVO: Local Navigation with Dynamic Constraints in Dense\n  Heterogeneous Traffic", "comments": null, "journal-ref": "ACM COMPUTER SCIENCE IN CARS SYMPOSIUM (CSCS 2018)", "doi": null, "report-no": null, "categories": "cs.RO cs.MA", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present a novel algorithm for computing collision-free navigation for\nheterogeneous road-agents such as cars, tricycles, bicycles, and pedestrians in\ndense traffic. Our approach currently assumes the positions, shapes, and\nvelocities of all vehicles and pedestrians are known and computes smooth\ntrajectories for each agent by taking into account the dynamic constraints. We\ndescribe an efficient optimization-based algorithm for each road-agent based on\nreciprocal velocity obstacles that takes into account kinematic and dynamic\nconstraints. Our algorithm uses tight fitting shape representations based on\nmedial axis to compute collision-free trajectories in dense traffic situations.\nWe evaluate the performance of our algorithm in real-world dense traffic\nscenarios and highlight the benefits over prior reciprocal collision avoidance\nschemes.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 11:22:42 GMT"}, {"version": "v2", "created": "Wed, 14 Nov 2018 05:58:48 GMT"}], "update_date": "2018-11-15", "authors_parsed": [["Ma", "Yuexin", ""], ["Manocha", "Dinesh", ""], ["Wang", "Wenping", ""]]}, {"id": "1804.03304", "submitter": "Hiroki Sayama", "authors": "Hiroki Sayama", "title": "Seeking Open-Ended Evolution in Swarm Chemistry II: Analyzing Long-Term\n  Dynamics via Automated Object Harvesting", "comments": "8 pages, 9 figures, to be published in the ALIFE 2018 proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "nlin.AO cs.MA cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We studied the long-term dynamics of evolutionary Swarm Chemistry by\nextending the simulation length ten-fold compared to earlier work and by\ndeveloping and using a new automated object harvesting method. Both macroscopic\ndynamics and microscopic object features were characterized and tracked using\nseveral measures. Results showed that the evolutionary dynamics tended to\nsettle down into a stable state after the initial transient period, and that\nthe extent of environmental perturbations also affected the evolutionary trends\nsubstantially. In the meantime, the automated harvesting method successfully\nproduced a huge collection of spontaneously evolved objects, revealing the\nsystem's autonomous creativity at an unprecedented scale.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 01:34:38 GMT"}, {"version": "v2", "created": "Sun, 3 Jun 2018 01:24:49 GMT"}], "update_date": "2018-06-05", "authors_parsed": [["Sayama", "Hiroki", ""]]}, {"id": "1804.03833", "submitter": "Guillaume Cheze", "authors": "Guillaume Ch\\`eze (IMT)", "title": "Don't cry to be the first!Symmetric fair division exist", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we study a cake cutting problem. More precisely, we study\nsymmetric fair division algorithms, that is to say we study algorithms where\nthe order of the players do not influence the value obtained by each player. In\nthe first part of the article, we give a symmetric and envy-free fair division\nalgorithm. More precisely, we show how to get a symmetric and envy-free fair\ndivision algorithm from an envy-free division algorithm. In the second part, we\ngive a proportional and symmetric fair division algorithm with a complexity in\nO(n 3) in the Robertson-Webb model of complexity. This algorithm is based on\nKuhn's algorithm. Furthermore, our study has led us to introduce a new notion:\naristotelian fair division. This notion is an interpretation of Aristotle's\nprinciple: give equal shares to equal people. We conclude this article with a\ndiscussion and some questions about the Robertson-Webb model of computation.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 06:51:14 GMT"}, {"version": "v2", "created": "Fri, 11 Oct 2019 09:34:20 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Ch\u00e8ze", "Guillaume", "", "IMT"]]}, {"id": "1804.03980", "submitter": "Kris Cao", "authors": "Kris Cao, Angeliki Lazaridou, Marc Lanctot, Joel Z Leibo, Karl Tuyls,\n  Stephen Clark", "title": "Emergent Communication through Negotiation", "comments": "Published as a conference paper at ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-agent reinforcement learning offers a way to study how communication\ncould emerge in communities of agents needing to solve specific problems. In\nthis paper, we study the emergence of communication in the negotiation\nenvironment, a semi-cooperative model of agent interaction. We introduce two\ncommunication protocols -- one grounded in the semantics of the game, and one\nwhich is \\textit{a priori} ungrounded and is a form of cheap talk. We show that\nself-interested agents can use the pre-grounded communication channel to\nnegotiate fairly, but are unable to effectively use the ungrounded channel.\nHowever, prosocial agents do learn to use cheap talk to find an optimal\nnegotiating strategy, suggesting that cooperation is necessary for language to\nemerge. We also study communication behaviour in a setting where one agent\ninteracts with agents in a community with different levels of prosociality and\nshow how agent identifiability can aid negotiation.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 13:48:08 GMT"}], "update_date": "2018-04-12", "authors_parsed": [["Cao", "Kris", ""], ["Lazaridou", "Angeliki", ""], ["Lanctot", "Marc", ""], ["Leibo", "Joel Z", ""], ["Tuyls", "Karl", ""], ["Clark", "Stephen", ""]]}, {"id": "1804.03984", "submitter": "Angeliki  Lazaridou", "authors": "Angeliki Lazaridou, Karl Moritz Hermann, Karl Tuyls, Stephen Clark", "title": "Emergence of Linguistic Communication from Referential Games with\n  Symbolic and Pixel Input", "comments": "To appear at ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability of algorithms to evolve or learn (compositional) communication\nprotocols has traditionally been studied in the language evolution literature\nthrough the use of emergent communication tasks. Here we scale up this research\nby using contemporary deep learning methods and by training\nreinforcement-learning neural network agents on referential communication\ngames. We extend previous work, in which agents were trained in symbolic\nenvironments, by developing agents which are able to learn from raw pixel data,\na more challenging and realistic input representation. We find that the degree\nof structure found in the input data affects the nature of the emerged\nprotocols, and thereby corroborate the hypothesis that structured compositional\nlanguage is most likely to emerge when agents perceive the world as being\nstructured.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 13:51:19 GMT"}], "update_date": "2018-04-12", "authors_parsed": [["Lazaridou", "Angeliki", ""], ["Hermann", "Karl Moritz", ""], ["Tuyls", "Karl", ""], ["Clark", "Stephen", ""]]}, {"id": "1804.04202", "submitter": "Hannes Hornischer", "authors": "Joshua Cherian Varughese, Hannes Hornischer, Ronald Thenius, Payam\n  Zahadat, Franz Wotawa, Thomas Schmickl", "title": "Controlling Swarms: A Programming Paradigm with Minimalistic\n  Communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by natural swarms, numerous control schemes enabling robotic swarms,\nmobile sensor networks and other multi-agent systems to exhibit various\nself-organized behaviors have been suggested. In this work, we present a Wave\nOriented Swarm Programming Paradigm (WOSPP) enabling the control of swarms with\nminimalistic communication bandwidth in a simple manner, yet allowing the\nemergence of diverse complex behaviors and autonomy of the swarm. Communi\ncation in the proposed paradigm is based on \"ping\"-signals inspired by\nstrategies for communication and self organization of slime mold (dictyostelium\ndiscoideum) and fireflies (lampyridae). Signals propagate as information-waves\nthroughout the swarm. We show that even with 1-bit bandwidth communication\nbetween agents suffices for the design of a substantial set of behaviors in the\ndomain of essential behaviors of a collective. Ultimately, the reader will be\nenabled to develop and design a control scheme for individual swarms.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 20:14:31 GMT"}, {"version": "v2", "created": "Mon, 18 Jun 2018 13:52:12 GMT"}], "update_date": "2018-06-19", "authors_parsed": [["Varughese", "Joshua Cherian", ""], ["Hornischer", "Hannes", ""], ["Thenius", "Ronald", ""], ["Zahadat", "Payam", ""], ["Wotawa", "Franz", ""], ["Schmickl", "Thomas", ""]]}, {"id": "1804.04345", "submitter": "EPTCS", "authors": "Eric S. Kim (University of California, Berkeley), Murat Arcak\n  (University of California, Berkeley), Sanjit A. Seshia (University of\n  California, Berkeley), BaekGyu Kim (Toyota InfoTechnology Center, U.S.A.),\n  Shinichi Shiraishi (Toyota InfoTechnology Center, U.S.A.)", "title": "Automatic Generation of Communication Requirements for Enforcing\n  Multi-Agent Safety", "comments": "In Proceedings SCAV 2018, arXiv:1804.03406", "journal-ref": "EPTCS 269, 2018, pp. 3-16", "doi": "10.4204/EPTCS.269.2", "report-no": null, "categories": "cs.SY cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed controllers are often necessary for a multi-agent system to\nsatisfy safety properties such as collision avoidance. Communication and\ncoordination are key requirements in the implementation of a distributed\ncontrol protocol, but maintaining an all-to-all communication topology is\nunreasonable and not always necessary. Given a safety objective and a\ncontroller implementation, we consider the problem of identifying when agents\nneed to communicate with one another and coordinate their actions to satisfy\nthe safety constraint. We define a coordination-free controllable predecessor\noperator that is used to derive a subset of the state space that allows agents\nto act independently, without consulting other agents to double check that the\naction is safe. Applications are shown for identifying an upper bound on\nconnection delays and a self-triggered coordination scheme. Examples are\nprovided which showcase the potential for designers to visually interpret a\nsystem's ability to tolerate delays when initializing a network connection.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 06:52:22 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["Kim", "Eric S.", "", "University of California, Berkeley"], ["Arcak", "Murat", "", "University of California, Berkeley"], ["Seshia", "Sanjit A.", "", "University of\n  California, Berkeley"], ["Kim", "BaekGyu", "", "Toyota InfoTechnology Center, U.S.A."], ["Shiraishi", "Shinichi", "", "Toyota InfoTechnology Center, U.S.A."]]}, {"id": "1804.04746", "submitter": "Changliu Liu", "authors": "Changliu Liu and Mykel J. Kochenderfer", "title": "Analytically Modeling Unmanaged Intersections with Microscopic Vehicle\n  Interactions", "comments": "ITSC 2018. arXiv admin note: text overlap with arXiv:1806.02660", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the emergence of autonomous vehicles, it is important to understand\ntheir impact on the transportation system. However, conventional traffic\nsimulations are time-consuming. In this paper, we introduce an analytical\ntraffic model for unmanaged intersections accounting for microscopic vehicle\ninteractions. The macroscopic property, i.e., delay at the intersection, is\nmodeled as an event-driven stochastic dynamic process, whose dynamics encode\nthe microscopic vehicle behaviors. The distribution of macroscopic properties\ncan be obtained through either direct analysis or event-driven simulation. They\nare more efficient than conventional (time-driven) traffic simulation, and\ncapture more microscopic details compared to conventional macroscopic flow\nmodels. We illustrate the efficiency of this method by delay analyses under two\ndifferent policies at a two-lane intersection. The proposed model allows for 1)\nefficient and effective comparison among different policies, 2) policy\noptimization, 3) traffic prediction, and 4) system optimization (e.g.,\ninfrastructure and protocol).\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 23:11:51 GMT"}, {"version": "v2", "created": "Tue, 8 May 2018 18:19:06 GMT"}, {"version": "v3", "created": "Thu, 6 Sep 2018 16:58:16 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Liu", "Changliu", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "1804.04789", "submitter": "Sam Ganzfried", "authors": "Sam Ganzfried, Austin Nowak, Joannier Pinales", "title": "Successful Nash Equilibrium Agent for a 3-Player Imperfect-Information\n  Game", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.MA econ.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Creating strong agents for games with more than two players is a major open\nproblem in AI. Common approaches are based on approximating game-theoretic\nsolution concepts such as Nash equilibrium, which have strong theoretical\nguarantees in two-player zero-sum games, but no guarantees in non-zero-sum\ngames or in games with more than two players. We describe an agent that is able\nto defeat a variety of realistic opponents using an exact Nash equilibrium\nstrategy in a 3-player imperfect-information game. This shows that, despite a\nlack of theoretical guarantees, agents based on Nash equilibrium strategies can\nbe successful in multiplayer games after all.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2018 05:15:28 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Ganzfried", "Sam", ""], ["Nowak", "Austin", ""], ["Pinales", "Joannier", ""]]}, {"id": "1804.04986", "submitter": "Amanda Prorok", "authors": "Amanda Prorok", "title": "Resilient Assignment Using Redundant Robots on Transport Networks with\n  Uncertain Travel Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the problem of assigning multiple mobile robots to goals\non transport networks with uncertain information about travel times. Our aim is\nto produce optimal assignments, such that the average waiting time at\ndestinations is minimized. Since noisy travel time estimates result in\nsub-optimal assignments, we propose a method that offers resilience to\nuncertainty by making use of redundant robots. However, solving the redundant\nassignment problem optimally is strongly NP-hard. Hence, we exploit structural\nproperties of our mathematical problem formulation to propose a\npolynomial-time, near-optimal solution. We demonstrate that our problem can be\nreduced to minimizing a supermodular cost function subject to a matroid\nconstraint. This allows us to develop a greedy algorithm, for which we derive\nsub-optimality bounds. We demonstrate the effectiveness of our approach with\nsimulations on transport networks, where uncertain edge costs and uncertain\nnode positions lead to noisy travel time estimates. Comparisons to benchmark\nalgorithms show that our method performs near-optimally and significantly\nbetter than non-redundant assignment. Finally, our findings include results on\nthe benefit of diversity and complementarity in redundant robot coalitions;\nthese insights contribute towards providing resilience to uncertainty through\ntargeted robot team compositions.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2018 15:14:33 GMT"}, {"version": "v2", "created": "Thu, 18 Apr 2019 21:07:38 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Prorok", "Amanda", ""]]}, {"id": "1804.05409", "submitter": "Philip Feldman", "authors": "Philip Feldman, Aaron Dant, Wayne Lutters", "title": "Simon's Anthill: Mapping and Navigating Belief Spaces", "comments": "Collective Intelligence 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the parable of Simon's Ant, an ant follows a complex path along a beach on\nto reach its goal. The story shows how the interaction of simple rules and a\ncomplex environment result in complex behavior. But this relationship can be\nlooked at in another way - given path and rules, we can infer the environment.\nWith a large population of agents - human or animal - it should be possible to\nbuild a detailed map of a population's social and physical environment. In this\nabstract, we describe the development of a framework to create such maps of\nhuman belief space. These maps are built from the combined trajectories of a\nlarge number of agents. Currently, these maps are built using multidimensional\nagent-based simulation, but the framework is designed to work using data from\ncomputer-mediated human communication. Maps incorporating human data should\nsupport visualization and navigation of the \"plains of research\", \"fashionable\nfoothills\" and \"conspiracy cliffs\" of human belief spaces.\n", "versions": [{"version": "v1", "created": "Sun, 15 Apr 2018 19:03:17 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Feldman", "Philip", ""], ["Dant", "Aaron", ""], ["Lutters", "Wayne", ""]]}, {"id": "1804.06011", "submitter": "Konstantinos Georgiou", "authors": "Jurek Czyzowicz, Konstantinos Georgiou, Ryan Killick, Evangelos\n  Kranakis, Danny Krizanc, Lata Narayanan, Jaroslav Opatrny and Sunil Shende", "title": "God Save the Queen", "comments": "33 pages, 8 Figures. This is the full version of the paper with the\n  same title which will appear in the proceedings of the 9th International\n  Conference on Fun with Algorithms, (FUN'18), June 13--15, 2018, La Maddalena,\n  Maddalena Islands, Italy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Queen Daniela of Sardinia is asleep at the center of a round room at the top\nof the tower in her castle. She is accompanied by her faithful servant, Eva.\nSuddenly, they are awakened by cries of \"Fire\". The room is pitch black and\nthey are disoriented. There is exactly one exit from the room somewhere along\nits boundary. They must find it as quickly as possible in order to save the\nlife of the queen. It is known that with two people searching while moving at\nmaximum speed 1 anywhere in the room, the room can be evacuated (i.e., with\nboth people exiting) in $1 + \\frac{2\\pi}{3} + \\sqrt{3} \\approx 4.8264$ time\nunits and this is optimal~[Czyzowicz et al., DISC'14], assuming that the first\nperson to find the exit can directly guide the other person to the exit using\nher voice. Somewhat surprisingly, in this paper we show that if the goal is to\nsave the queen (possibly leaving Eva behind to die in the fire) there is a\nslightly better strategy. We prove that this \"priority\" version of evacuation\ncan be solved in time at most $4.81854$. Furthermore, we show that any strategy\nfor saving the queen requires time at least $3 + \\pi/6 + \\sqrt{3}/2 \\approx\n4.3896$ in the worst case. If one or both of the queen's other servants (Biddy\nand/or Lili) are with her, we show that the time bounds can be improved to\n$3.8327$ for two servants, and $3.3738$ for three servants. Finally we show\nlower bounds for these cases of $3.6307$ (two servants) and $3.2017$ (three\nservants). The case of $n\\geq 4$ is the subject of an independent study by\nQueen Daniela's Royal Scientific Team.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 01:42:44 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Czyzowicz", "Jurek", ""], ["Georgiou", "Konstantinos", ""], ["Killick", "Ryan", ""], ["Kranakis", "Evangelos", ""], ["Krizanc", "Danny", ""], ["Narayanan", "Lata", ""], ["Opatrny", "Jaroslav", ""], ["Shende", "Sunil", ""]]}, {"id": "1804.06268", "submitter": "Michael Schaub", "authors": "Michael T. Schaub and Jean-Charles Delvenne and Renaud Lambiotte and\n  Mauricio Barahona", "title": "Structured networks and coarse-grained descriptions: a dynamical\n  perspective", "comments": "21 pages; 7 figures; To appear as a chapter in \"Advances in Network\n  Clustering and Blockmodeling\" edited by P. Doreian, V. Batagelj & A. Ferligoj\n  (Wiley, New York, 2018)", "journal-ref": "Advances in Network Clustering and Blockmodeling, Ed.P. Doreian,\n  V. Batagelj, and A. Ferligoj John Wiley & Sons, Ltd, 2019, ch.12, pp. 333-361", "doi": "10.1002/9781119483298.ch12", "report-no": null, "categories": "cs.SI cs.MA physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This chapter discusses the interplay between structure and dynamics in\ncomplex networks. Given a particular network with an endowed dynamics, our goal\nis to find partitions aligned with the dynamical process acting on top of the\nnetwork. We thus aim to gain a reduced description of the system that takes\ninto account both its structure and dynamics. In the first part, we introduce\nthe general mathematical setup for the types of dynamics we consider throughout\nthe chapter. We provide two guiding examples, namely consensus dynamics and\ndiffusion processes (random walks), motivating their connection to social\nnetwork analysis, and provide a brief discussion on the general dynamical\nframework and its possible extensions. In the second part, we focus on the\ninfluence of graph structure on the dynamics taking place on the network,\nfocusing on three concepts that allow us to gain insight into this notion.\nFirst, we describe how time scale separation can appear in the dynamics on a\nnetwork as a consequence of graph structure. Second, we discuss how the\npresence of particular symmetries in the network give rise to invariant\ndynamical subspaces that can be precisely described by graph partitions. Third,\nwe show how this dynamical viewpoint can be extended to study dynamics on\nnetworks with signed edges, which allow us to discuss connections to concepts\nin social network analysis, such as structural balance. In the third part, we\ndiscuss how to use dynamical processes unfolding on the network to detect\nmeaningful network substructures. We then show how such dynamical measures can\nbe related to seemingly different algorithm for community detection and\ncoarse-graining proposed in the literature. We conclude with a brief summary\nand highlight interesting open future directions.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 14:05:12 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Schaub", "Michael T.", ""], ["Delvenne", "Jean-Charles", ""], ["Lambiotte", "Renaud", ""], ["Barahona", "Mauricio", ""]]}, {"id": "1804.06311", "submitter": "Thomy Phan", "authors": "Thomy Phan, Lenz Belzner, Thomas Gabor and Kyrill Schmid", "title": "Leveraging Statistical Multi-Agent Online Planning with Emergent Value\n  Function Approximation", "comments": "Accepted at AAMAS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Making decisions is a great challenge in distributed autonomous environments\ndue to enormous state spaces and uncertainty. Many online planning algorithms\nrely on statistical sampling to avoid searching the whole state space, while\nstill being able to make acceptable decisions. However, planning often has to\nbe performed under strict computational constraints making online planning in\nmulti-agent systems highly limited, which could lead to poor system\nperformance, especially in stochastic domains. In this paper, we propose\nEmergent Value function Approximation for Distributed Environments (EVADE), an\napproach to integrate global experience into multi-agent online planning in\nstochastic domains to consider global effects during local planning. For this\npurpose, a value function is approximated online based on the emergent system\nbehaviour by using methods of reinforcement learning. We empirically evaluated\nEVADE with two statistical multi-agent online planning algorithms in a highly\ncomplex and stochastic smart factory environment, where multiple agents need to\nprocess various items at a shared set of machines. Our experiments show that\nEVADE can effectively improve the performance of multi-agent online planning\nwhile offering efficiency w.r.t. the breadth and depth of the planning process.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 15:10:44 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Phan", "Thomy", ""], ["Belzner", "Lenz", ""], ["Gabor", "Thomas", ""], ["Schmid", "Kyrill", ""]]}, {"id": "1804.06568", "submitter": "Xianghui Mao", "authors": "Xianghui Mao, Kun Yuan, Yubin Hu, Yuantao Gu, Ali H. Sayed, and Wotao\n  Yin", "title": "Walkman: A Communication-Efficient Random-Walk Algorithm for\n  Decentralized Optimization", "comments": "Submitted for review", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DC cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses consensus optimization problems in a multi-agent\nnetwork, where all agents collaboratively find a minimizer for the sum of their\nprivate functions. We develop a new decentralized algorithm in which each agent\ncommunicates only with its neighbors.\n  State-of-the-art decentralized algorithms use communications between either\nall pairs of adjacent agents or a random subset of them at each iteration.\nAnother class of algorithms uses a random walk incremental strategy, which\nsequentially activates a succession of nodes; these incremental algorithms\nrequire diminishing step sizes to converge to the solution, so their\nconvergence is relatively slow.\n  In this work, we propose a random walk algorithm that uses a fixed step size\nand converges faster than the existing random walk incremental algorithms. Our\nalgorithm is also communication efficient. Each iteration uses only one link to\ncommunicate the latest information for an agent to another. Since this\ncommunication rule mimics a man walking around the network, we call our new\nalgorithm Walkman. We establish convergence for convex and nonconvex\nobjectives. For decentralized least squares, we derive a linear rate of\nconvergence and obtain a better communication complexity than those of other\ndecentralized algorithms. Numerical experiments verify our analysis results.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 06:26:38 GMT"}, {"version": "v2", "created": "Mon, 14 May 2018 18:47:01 GMT"}, {"version": "v3", "created": "Fri, 30 Nov 2018 22:54:05 GMT"}, {"version": "v4", "created": "Tue, 2 Jul 2019 08:53:21 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Mao", "Xianghui", ""], ["Yuan", "Kun", ""], ["Hu", "Yubin", ""], ["Gu", "Yuantao", ""], ["Sayed", "Ali H.", ""], ["Yin", "Wotao", ""]]}, {"id": "1804.06647", "submitter": "Sven Linker", "authors": "Maryam Kamali, Sven Linker, Michael Fisher", "title": "Modular Verification of Vehicle Platooning with Respect to Decisions,\n  Space and Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The spread of autonomous systems into safety-critical areas has increased the\ndemand for their formal verification, not only due to stronger certification\nrequirements but also to public uncertainty over these new technologies.\nHowever, the complex nature of such systems, for example, the intricate\ncombination of discrete and continuous aspects, ensures that whole system\nverification is often infeasible. This motivates the need for novel analysis\napproaches that modularise the problem, allowing us to restrict our analysis to\none particular aspect of the system while abstracting away from others. For\ninstance, while verifying the real-time properties of an autonomous system we\nmight hide the details of the internal decision-making components. In this\npaper we describe verification of a range of properties across distinct\ndimesnions on a practical hybrid agent architecture. This allows us to verify\nthe autonomous decision-making, real-time aspects, and spatial aspects of an\nautonomous vehicle platooning system. This modular approach also illustrates\nhow both algorithmic and deductive verification techniques can be applied for\nthe analysis of different system subcomponents.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 10:50:57 GMT"}], "update_date": "2018-04-19", "authors_parsed": [["Kamali", "Maryam", ""], ["Linker", "Sven", ""], ["Fisher", "Michael", ""]]}, {"id": "1804.07178", "submitter": "Cinjon Resnick", "authors": "Cinjon Resnick, Ilya Kulikov, Kyunghyun Cho, Jason Weston", "title": "Vehicle Communication Strategies for Simulated Highway Driving", "comments": "NIPS 2017 Workshop on Emergent Communication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interest in emergent communication has recently surged in Machine Learning.\nThe focus of this interest has largely been either on investigating the\nproperties of the learned protocol or on utilizing emergent communication to\nbetter solve problems that already have a viable solution. Here, we consider\nself-driving cars coordinating with each other and focus on how communication\ninfluences the agents' collective behavior. Our main result is that\ncommunication helps (most) with adverse conditions.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 14:02:07 GMT"}, {"version": "v2", "created": "Tue, 14 Aug 2018 12:35:41 GMT"}], "update_date": "2018-08-15", "authors_parsed": [["Resnick", "Cinjon", ""], ["Kulikov", "Ilya", ""], ["Cho", "Kyunghyun", ""], ["Weston", "Jason", ""]]}, {"id": "1804.07183", "submitter": "Vahid Yazdanpanah", "authors": "Vahid Yazdanpanah, Devrim Murat Yazan, Henk Zijm", "title": "Industrial Symbiotic Networks as Coordinated Games", "comments": "3 pages, Proc. of the 17th International Conference on Autonomous\n  Agents and Multiagent Systems (AAMAS 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approach for implementing a specific form of collaborative\nindustrial practices-called Industrial Symbiotic Networks (ISNs)-as MC-Net\ncooperative games and address the so called ISN implementation problem. This\nis, the characteristics of ISNs may lead to inapplicability of fair and stable\nbenefit allocation methods even if the collaboration is a collectively desired\none. Inspired by realistic ISN scenarios and the literature on normative\nmulti-agent systems, we consider regulations and normative socioeconomic\npolicies as two elements that in combination with ISN games resolve the\nsituation and result in the concept of coordinated ISNs.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 14:16:50 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Yazdanpanah", "Vahid", ""], ["Yazan", "Devrim Murat", ""], ["Zijm", "Henk", ""]]}, {"id": "1804.07406", "submitter": "Soham De", "authors": "Soham De, Dana S. Nau, Xinyue Pan, Michele J. Gelfand", "title": "Tipping Points for Norm Change in Human Cultures", "comments": "SBP-BRiMS 2018", "journal-ref": null, "doi": "10.1007/978-3-319-93372-6_7", "report-no": null, "categories": "q-bio.PE cs.CY cs.GT cs.MA physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans interact with each other on a daily basis by developing and\nmaintaining various social norms and it is critical to form a deeper\nunderstanding of how such norms develop, how they change, and how fast they\nchange. In this work, we develop an evolutionary game-theoretic model based on\nresearch in cultural psychology that shows that humans in various cultures\ndiffer in their tendencies to conform with those around them. Using this model,\nwe analyze the evolutionary relationships between the tendency to conform and\nhow quickly a population reacts when conditions make a change in norm\ndesirable. Our analysis identifies conditions when a tipping point is reached\nin a population, causing norms to change rapidly.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 23:43:28 GMT"}, {"version": "v2", "created": "Mon, 2 Jul 2018 01:05:42 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["De", "Soham", ""], ["Nau", "Dana S.", ""], ["Pan", "Xinyue", ""], ["Gelfand", "Michele J.", ""]]}, {"id": "1804.07464", "submitter": "Juan Afanador", "authors": "Juan Afanador, Nir Oren, Murilo S. Baptista", "title": "Delegating via Quitting Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Delegation allows an agent to request that another agent completes a task. In\nmany situations the task may be delegated onwards, and this process can repeat\nuntil it is eventually, successfully or unsuccessfully, performed. We consider\npolicies to guide an agent in choosing who to delegate to when such recursive\ninteractions are possible. These policies, based on quitting games and\nmulti-armed bandits, were empirically tested for effectiveness. Our results\nindicate that the quitting game based policies outperform those which do not\nexplicitly account for the recursive nature of delegation.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 06:45:28 GMT"}], "update_date": "2018-04-23", "authors_parsed": [["Afanador", "Juan", ""], ["Oren", "Nir", ""], ["Baptista", "Murilo S.", ""]]}, {"id": "1804.07699", "submitter": "Kananart Kuwaranancharoen", "authors": "Kananart Kuwaranancharoen and Shreyas Sundaram", "title": "On the Location of the Minimizer of the Sum of Two Strongly Convex\n  Functions", "comments": "8 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of finding the minimizer of a sum of convex functions is central\nto the field of distributed optimization. Thus, it is of interest to understand\nhow that minimizer is related to the properties of the individual functions in\nthe sum. In this paper, we provide an upper bound on the region containing the\nminimizer of the sum of two strongly convex functions. We consider two\nscenarios with different constraints on the upper bound of the gradients of the\nfunctions. In the first scenario, the gradient constraint is imposed on the\nlocation of the potential minimizer, while in the second scenario, the gradient\nconstraint is imposed on a given convex set in which the minimizers of two\noriginal functions are embedded. We characterize the boundaries of the regions\ncontaining the minimizer in both scenarios.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 15:58:55 GMT"}, {"version": "v2", "created": "Mon, 3 Dec 2018 22:28:10 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["Kuwaranancharoen", "Kananart", ""], ["Sundaram", "Shreyas", ""]]}, {"id": "1804.08062", "submitter": "Karthik Abinav Sankararaman", "authors": "Brian Brubach and Karthik Abinav Sankararaman and Aravind Srinivasan\n  and Pan Xu", "title": "Attenuate Locally, Win Globally: An Attenuation-based Framework for\n  Online Stochastic Matching with Timeouts", "comments": "A short version appeared in AAMAS-2017. This version fixes some bugs\n  in the camera-ready version of the paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online matching problems have garnered significant attention in recent years\ndue to numerous applications in e-commerce, online advertisements,\nride-sharing, etc. Many of them capture the uncertainty in the real world by\nincluding stochasticity in both the arrival process and the matching process.\nThe Online Stochastic Matching with Timeouts problem introduced by Bansal, et\nal., (Algorithmica, 2012) models matching markets (e.g., E-Bay, Amazon). Buyers\narrive from an independent and identically distributed (i.i.d.) known\ndistribution on buyer profiles and can be shown a list of items one at a time.\nEach buyer has some probability of purchasing each item and a limit (timeout)\non the number of items they can be shown.\n  Bansal et al., (Algorithmica, 2012) gave a 0.12-competitive algorithm which\nwas improved by Adamczyk, et al., (ESA, 2015) to 0.24. We present an online\nattenuation framework that uses an algorithm for offline stochastic matching as\na black box. On the upper bound side, we show that this framework, combined\nwith a black-box adapted from Bansal et al., (Algorithmica, 2012), yields an\nonline algorithm which nearly doubles the ratio to 0.46. On the lower bound\nside, we show that no algorithm can achieve a ratio better than 0.632 using the\nstandard LP for this problem. This framework has a high potential for further\nimprovements since new algorithms for offline stochastic matching can directly\nimprove the ratio for the online problem.\n  Our online framework also has the potential for a variety of extensions. For\nexample, we introduce a natural generalization: Online Stochastic Matching with\nTwo-sided Timeouts in which both online and offline vertices have timeouts. Our\nframework provides the first algorithm for this problem achieving a ratio of\n0.30. We once again use the algorithm of Adamczyk et al., (ESA, 2015) as a\nblack-box and plug-it into our framework.\n", "versions": [{"version": "v1", "created": "Sun, 22 Apr 2018 03:20:56 GMT"}, {"version": "v2", "created": "Fri, 21 Jun 2019 16:16:21 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Brubach", "Brian", ""], ["Sankararaman", "Karthik Abinav", ""], ["Srinivasan", "Aravind", ""], ["Xu", "Pan", ""]]}, {"id": "1804.08667", "submitter": "Daniel Fu", "authors": "Daniel Y. Fu, Emily S. Wang, Peter M. Krafft, Barbara J. Grosz", "title": "Influencing Flock Formation in Low-Density Settings", "comments": "9 pages, 5 figures, accepted to AAMAS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Flocking is a coordinated collective behavior that results from local sensing\nbetween individual agents that have a tendency to orient towards each other.\nFlocking is common among animal groups and might also be useful in robotic\nswarms. In the interest of learning how to control flocking behavior, recent\nwork in the multiagent systems literature has explored the use of influencing\nagents for guiding flocking agents to face a target direction. The existing\nwork in this domain has focused on simulation settings of small areas with\ntoroidal shapes. In such settings, agent density is high, so interactions are\ncommon, and flock formation occurs easily. In our work, we study new\nenvironments with lower agent density, wherein interactions are more rare. We\nstudy the efficacy of placement strategies and influencing agent behaviors\ndrawn from the literature, and find that the behaviors that have been shown to\nwork well in high-density conditions tend to be much less effective in lower\ndensity environments. The source of this ineffectiveness is that the\ninfluencing agents explored in prior work tended to face directions optimized\nfor maximal influence, but which actually separate the influencing agents from\nthe flock. We find that in low-density conditions maintaining a connection to\nthe flock is more important than rushing to orient towards the desired\ndirection. We use these insights to propose new influencing agent behaviors,\nwhich we dub \"follow-then-influence\"; agents act like normal members of the\nflock to achieve positions that allow for control and then exert their\ninfluence. This strategy overcomes the difficulties posed by low density\nenvironments.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 18:55:05 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Fu", "Daniel Y.", ""], ["Wang", "Emily S.", ""], ["Krafft", "Peter M.", ""], ["Grosz", "Barbara J.", ""]]}, {"id": "1804.08676", "submitter": "Aamodh Suresh", "authors": "Aamodh Suresh, Sonia Martinez", "title": "Gesture based Human-Swarm Interactions for Formation Control using\n  interpreters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel Human-Swarm Interaction (HSI) framework which enables the\nuser to control a swarm shape and formation. The user commands the swarm\nutilizing just arm gestures and motions which are recorded by an off-the-shelf\nwearable armband. We propose a novel interpreter system, which acts as an\nintermediary between the user and the swarm to simplify the user's role in the\ninteraction. The interpreter takes in a high level input drawn using gestures\nby the user, and translates it into low level swarm control commands. This\ninterpreter employs machine learning, Kalman filtering and optimal control\ntechniques to translate the user input into swarm control parameters. A notion\nof Human Interpretable dynamics is introduced, which is used by the interpreter\nfor planning as well as to provide feedback to the user. The dynamics of the\nswarm are controlled using a novel decentralized formation controller based on\ndistributed linear iterations and dynamic average consensus. The framework is\ndemonstrated theoretically as well as experimentally in a 2D environment, with\na human controlling a swarm of simulated robots in real time.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 19:15:46 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Suresh", "Aamodh", ""], ["Martinez", "Sonia", ""]]}, {"id": "1804.08986", "submitter": "Fabian Mager", "authors": "Fabian Mager, Dominik Baumann, Romain Jacob, Lothar Thiele, Sebastian\n  Trimpe, Marco Zimmerling", "title": "Feedback Control Goes Wireless: Guaranteed Stability over Low-power\n  Multi-hop Networks", "comments": "Accepted final version to appear in: 10th ACM/IEEE International\n  Conference on Cyber-Physical Systems (with CPS-IoT Week 2019) (ICCPS '19),\n  April 16--18, 2019, Montreal, QC, Canada", "journal-ref": null, "doi": "10.1145/3302509.3311046", "report-no": null, "categories": "cs.NI cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Closing feedback loops fast and over long distances is key to emerging\napplications; for example, robot motion control and swarm coordination require\nupdate intervals of tens of milliseconds. Low-power wireless technology is\npreferred for its low cost, small form factor, and flexibility, especially if\nthe devices support multi-hop communication. So far, however, feedback control\nover wireless multi-hop networks has only been shown for update intervals on\nthe order of seconds. This paper presents a wireless embedded system that tames\nimperfections impairing control performance (e.g., jitter and message loss),\nand a control design that exploits the essential properties of this system to\nprovably guarantee closed-loop stability for physical processes with linear\ntime-invariant dynamics. Using experiments on a cyber-physical testbed with 20\nwireless nodes and multiple cart-pole systems, we are the first to demonstrate\nand evaluate feedback control and coordination over wireless multi-hop networks\nfor update intervals of 20 to 50 milliseconds.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 12:27:20 GMT"}, {"version": "v2", "created": "Fri, 2 Nov 2018 10:21:55 GMT"}, {"version": "v3", "created": "Sun, 17 Feb 2019 19:21:28 GMT"}, {"version": "v4", "created": "Tue, 19 Feb 2019 07:40:44 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Mager", "Fabian", ""], ["Baumann", "Dominik", ""], ["Jacob", "Romain", ""], ["Thiele", "Lothar", ""], ["Trimpe", "Sebastian", ""], ["Zimmerling", "Marco", ""]]}, {"id": "1804.10781", "submitter": "Lenz Belzner", "authors": "Lenz Belzner, Kyrill Schmid, Thomy Phan, Thomas Gabor and Martin\n  Wirsing", "title": "The Sharer's Dilemma in Collective Adaptive Systems of Self-Interested\n  Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In collective adaptive systems (CAS), adaptation can be implemented by\noptimization wrt. utility. Agents in a CAS may be self-interested, while their\nutilities may depend on other agents' choices. Independent optimization of\nagent utilities may yield poor individual and global reward due to locally\ninterfering individual preferences. Joint optimization may scale poorly, and is\nimpossible if agents cannot expose their preferences due to privacy or security\nissues. In this paper, we study utility sharing for mitigating this issue.\nSharing utility with others may incentivize individuals to consider choices\nthat are locally suboptimal but increase global reward. We illustrate our\napproach with a utility sharing variant of distributed cross entropy\noptimization. Empirical results show that utility sharing increases expected\nindividual and global payoff in comparison to optimization without utility\nsharing. We also investigate the effect of greedy defectors in a CAS of\nsharing, self-interested agents. We observe that defection increases the mean\nexpected individual payoff at the expense of sharing individuals' payoff. We\nempirically show that the choice between defection and sharing yields a\nfundamental dilemma for self-interested agents in a CAS.\n", "versions": [{"version": "v1", "created": "Sat, 28 Apr 2018 10:12:47 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Belzner", "Lenz", ""], ["Schmid", "Kyrill", ""], ["Phan", "Thomy", ""], ["Gabor", "Thomas", ""], ["Wirsing", "Martin", ""]]}, {"id": "1804.10817", "submitter": "Virginia Dignum", "authors": "Virginia Dignum and Frank Dignum", "title": "A Logic of Agent Organizations", "comments": null, "journal-ref": "Logic Journal of the IGPL, vol. 20, no. 1, pp. 283-316, Feb. 2012", "doi": "10.1093/jigpal/jzr041", "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Organization concepts and models are increasingly being adopted for the\ndesign and specification of multi-agent systems. Agent organizations can be\nseen as mechanisms of social order, created to achieve global (or\norganizational) objectives by more or less autonomous agents. In order to\ndevelop a theory on the relation between organizational structures,\norganizational objectives and the actions of agents fulfilling roles in the\norganization a theoretical framework is needed to describe organizational\nstructures and actions of (groups of) agents. Current logical formalisms focus\non specific aspects of organizations (e.g. power, delegation, agent actions, or\nnormative issues) but a framework that integrates and relates different aspects\nis missing. Given the amount of aspects involved and the subsequent complexity\nof a formalism encompassing them all, it is difficult to realize. In this\npaper, a first step is taken to solve this problem. We present a generic formal\nmodel that enables to specify and relate the main concepts of an organization\n(including, activity, structure, environment and others) so that organizations\ncan be analyzed at a high level of abstraction. However, for some aspects we\nuse a simplified model in order to avoid the complexity of combining many\ndifferent types of (modal) operators.\n", "versions": [{"version": "v1", "created": "Sat, 28 Apr 2018 15:09:10 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Dignum", "Virginia", ""], ["Dignum", "Frank", ""]]}]