[{"id": "1807.00376", "submitter": "Noam Hazon", "authors": "Chaya Levinger, Amos Azaria, Noam Hazon", "title": "Human Satisfaction as the Ultimate Goal in Ridesharing", "comments": null, "journal-ref": null, "doi": "10.1016/j.future.2020.05.028", "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transportation services play a crucial part in the development of modern\nsmart cities. In particular, on-demand ridesharing services, which group\ntogether passengers with similar itineraries, are already operating in several\nmetropolitan areas. These services can be of significant social and\nenvironmental benefit, by reducing travel costs, road congestion and co2\nemissions. The deployment of autonomous cars in the near future will surely\nchange the way people are traveling. It is even more promising for a\nridesharing service, since it will be easier and cheaper for a company to\nhandle a fleet of autonomous cars that can serve the demands of different\npassengers.\n  We argue that user satisfaction should be the main objective when trying to\nfind the best assignment of passengers to vehicles and the determination of\ntheir routes. Moreover, the model of user satisfaction should be rich enough to\ncapture the traveling distance, cost, and other factors as well. We show that\nit is more important to capture a rich model of human satisfaction than peruse\nan optimal performance. That is, we developed a practical algorithm for\nassigning passengers to vehicles, which outperforms assignment algorithms that\nare optimal, but use a simpler satisfaction model.\n  To the best of our knowledge, this is the first paper to exclusively\nconcentrate on a rich and realistic function of user satisfaction as the\nobjective, which is (arguably) the most important aspect to consider for\nachieving a widespread adaption of ridesharing services.\n", "versions": [{"version": "v1", "created": "Sun, 1 Jul 2018 19:18:09 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Levinger", "Chaya", ""], ["Azaria", "Amos", ""], ["Hazon", "Noam", ""]]}, {"id": "1807.00479", "submitter": "Zhijian Ji", "authors": "Shaobin Cao, Zhijian Ji, Hai Lin, Haisheng Yu", "title": "Perfectly Controllable Multi-Agent Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This note investigates how to design topology structures to ensure the\ncontrollability of multi-agent networks (MASs) under any selection of leaders.\nWe put forward a concept of perfect controllability, which means that a\nmulti-agent system is controllable with no matter how the leaders are chosen.\nIn this situation, both the number and the locations of leader agents are\narbitrary. A necessary and sufficient condition is derived for the perfect\ncontrollability. Moreover, a step-by-step design procedure is proposed by which\ntopologies are constructed and are proved to be perfectly controllable. The\nprinciple of the proposed design method is interpreted by schematic diagrams\nalong with the corresponding topology structures from simple to complex. We\nshow that the results are valid for any number and any location of leaders.\nBoth the construction process and the corresponding topology structures are\nclearly outlined.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 06:15:35 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Cao", "Shaobin", ""], ["Ji", "Zhijian", ""], ["Lin", "Hai", ""], ["Yu", "Haisheng", ""]]}, {"id": "1807.00771", "submitter": "Anton Andreychuk", "authors": "Anton Andreychuk and Konstantin Yakovlev", "title": "Path Finding for the Coalition of Co-operative Agents Acting in the\n  Environment with Destructible Obstacles", "comments": "10 pages, 7 figures, conference paper, ICR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of planning a set of paths for the coalition of robots (agents)\nwith different capabilities is considered in the paper. Some agents can modify\nthe environment by destructing the obstacles thus allowing the other ones to\nshorten their paths to the goal. As a result the mutual solution of lower cost,\ne.g. time to completion, may be acquired. We suggest an original procedure to\nidentify the obstacles for further removal that can be embedded into almost any\nheuristic search planner (we use Theta*) and evaluate it empirically. Results\nof the evaluation show that time-to-complete the mission can be decreased up to\n9-12 % by utilizing the proposed technique.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 16:15:35 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Andreychuk", "Anton", ""], ["Yakovlev", "Konstantin", ""]]}, {"id": "1807.01014", "submitter": "Jiajian Xiao", "authors": "Jiajian Xiao, Philipp Andelfinger, David Eckhoff, Wentong Cai, Alois\n  Knoll", "title": "A Survey on Agent-based Simulation using Hardware Accelerators", "comments": "Submitted for review to ACM Computing Surveys on 24/05/2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to decelerating gains in single-core CPU performance, computationally\nexpensive simulations are increasingly executed on highly parallel hardware\nplatforms. Agent-based simulations, where simulated entities act with a certain\ndegree of autonomy, frequently provide ample opportunities for parallelisation.\nThus, a vast variety of approaches proposed in the literature demonstrated\nconsiderable performance gains using hardware platforms such as many-core CPUs\nand GPUs, merged CPU-GPU chips as well as FPGAs. Typically, a combination of\ntechniques is required to achieve high performance for a given simulation\nmodel, putting substantial burden on modellers. To the best of our knowledge,\nno systematic overview of techniques for agent-based simulations on hardware\naccelerators has been given in the literature. To close this gap, we provide an\noverview and categorisation of the literature according to the applied\ntechniques. Since at the current state of research, challenges such as the\npartitioning of a model for execution on heterogeneous hardware are still a\nlargely manual process, we sketch directions for future research towards\nautomating the hardware mapping and execution. This survey targets modellers\nseeking an overview of suitable hardware platforms and execution techniques for\na specific simulation model, as well as methodology researchers interested in\npotential research gaps requiring further exploration.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 08:21:07 GMT"}], "update_date": "2018-07-04", "authors_parsed": [["Xiao", "Jiajian", ""], ["Andelfinger", "Philipp", ""], ["Eckhoff", "David", ""], ["Cai", "Wentong", ""], ["Knoll", "Alois", ""]]}, {"id": "1807.01366", "submitter": "Richard Darlington", "authors": "Richard B. Darlington", "title": "Are Condorcet and minimax voting systems the best?", "comments": "37 pages, no figures. Sections 4.1 and 5.2 are completely rewritten.\n  Now recommending a somewhat different version of minimax. Many smaller\n  changes", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For decades, the minimax voting system was well known to experts on voting\nsystems, but was not widely considered to be one of the best systems. But in\nrecent years, two important experts, Nicolaus Tideman and Andrew Myers, have\nboth recognized minimax as one of the best systems. I agree with that. This\npaper presents my own reasons for preferring minimax. The paper explicitly\ndiscusses about 20 systems.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jun 2018 02:04:40 GMT"}, {"version": "v2", "created": "Mon, 16 Jul 2018 14:27:30 GMT"}, {"version": "v3", "created": "Mon, 12 Nov 2018 17:06:47 GMT"}, {"version": "v4", "created": "Wed, 5 Dec 2018 16:12:42 GMT"}, {"version": "v5", "created": "Mon, 4 Nov 2019 14:12:05 GMT"}, {"version": "v6", "created": "Tue, 19 Nov 2019 15:16:51 GMT"}, {"version": "v7", "created": "Thu, 12 Mar 2020 16:01:40 GMT"}, {"version": "v8", "created": "Tue, 30 Mar 2021 14:59:54 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Darlington", "Richard B.", ""]]}, {"id": "1807.01628", "submitter": "Rusheng Zhang", "authors": "Rusheng Zhang, Akihiro Ishikawa, Wenli Wang, Benjamin Striner, Ozan\n  Tonguz", "title": "Using Reinforcement Learning with Partial Vehicle Detection for\n  Intelligent Traffic Signal Control", "comments": "10 pages, 14 figures, submitted to IEEE ITS transaction, Special\n  Issue of Intelligent transportation systems empowered by AI technologies on\n  June 15, 2018 Accepted and will publish in 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intelligent Transportation Systems (ITS) have attracted the attention of\nresearchers and the general public alike as a means to alleviate traffic\ncongestion. Recently, the maturity of wireless technology has enabled a\ncost-efficient way to achieve ITS by detecting vehicles using Vehicle to\nInfrastructure (V2I) communications. Traditional ITS algorithms, in most cases,\nassume that every vehicle is observed, such as by a camera or a loop detector,\nbut a V2I implementation would detect only those vehicles with wireless\ncommunications capability. We examine a family of transportation systems, which\nwe will refer to as `Partially Detected Intelligent Transportation Systems'. An\nalgorithm that can act well under a small detection rate is highly desirable\ndue to gradual penetration rates of the underlying wireless technologies such\nas Dedicated Short Range Communications (DSRC) technology. Artificial\nIntelligence (AI) techniques for Reinforcement Learning (RL) are suitable tools\nfor finding such an algorithm due to utilizing varied inputs and not requiring\nexplicit analytic understanding or modeling of the underlying system dynamics.\nIn this paper, we report a RL algorithm for partially observable ITS based on\nDSRC. The performance of this system is studied under different car flows,\ndetection rates, and topologies of the road network. Our system is able to\nefficiently reduce the average waiting time of vehicles at an intersection,\neven with a low detection rate.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2018 15:12:02 GMT"}, {"version": "v2", "created": "Mon, 4 Feb 2019 18:22:13 GMT"}, {"version": "v3", "created": "Sat, 29 Feb 2020 00:02:04 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Zhang", "Rusheng", ""], ["Ishikawa", "Akihiro", ""], ["Wang", "Wenli", ""], ["Striner", "Benjamin", ""], ["Tonguz", "Ozan", ""]]}, {"id": "1807.01909", "submitter": "Konstantin Yakovlev S", "authors": "Anton Andreychuk and Konstantin Yakovlev", "title": "Multi-robot Path Planning in Well-formed Infrastructures: Prioritized\n  Planning vs. Prioritized Wait Adjustment (Preliminary Results)", "comments": "Submitted to the Federated AI for Robotics Workshop (FAIR) 2018\n  (https://sites.google.com/site/federatedai4robotics2018/home) held at July 15\n  2018 as part of the Federated AI Meeting (joint IJCAI-ECAI/ICML/AAMAS\n  conferences)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of planning collision-free paths for a group of\nhomogeneous robots. We propose a novel approach for turning the paths that were\nplanned egocentrically by the robots, e.g. without taking other robots' moves\ninto account, into collision-free trajectories and evaluate it empirically.\nSuggested algorithm is much faster (up to one order of magnitude) than\nstate-of-the-art but this comes at the price of notable drop-down of the\nsolution cost.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2018 09:19:00 GMT"}], "update_date": "2018-07-06", "authors_parsed": [["Andreychuk", "Anton", ""], ["Yakovlev", "Konstantin", ""]]}, {"id": "1807.02648", "submitter": "Chairi Kiourt", "authors": "Chairi Kiourt, Dimitris Kalles and Panagiotis Kanellopoulos", "title": "How game complexity affects the playing behavior of synthetic agents", "comments": "15th European Conference on Multi-Agent Systems, Evry, France, 14-15\n  December 2017", "journal-ref": "Multi-Agent Systems and Agreement Technologies. EUMAS 2017, AT\n  2017. Lecture Notes in Computer Science", "doi": "10.1007/978-3-030-01713-2_22", "report-no": null, "categories": "cs.AI cs.CC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Agent based simulation of social organizations, via the investigation of\nagents' training and learning tactics and strategies, has been inspired by the\nability of humans to learn from social environments which are rich in agents,\ninteractions and partial or hidden information. Such richness is a source of\ncomplexity that an effective learner has to be able to navigate. This paper\nfocuses on the investigation of the impact of the environmental complexity on\nthe game playing-and-learning behavior of synthetic agents. We demonstrate our\napproach using two independent turn-based zero-sum games as the basis of\nforming social events which are characterized both by competition and\ncooperation. The paper's key highlight is that as the complexity of a social\nenvironment changes, an effective player has to adapt its learning and playing\nprofile to maintain a given performance profile\n", "versions": [{"version": "v1", "created": "Sat, 7 Jul 2018 11:57:21 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Kiourt", "Chairi", ""], ["Kalles", "Dimitris", ""], ["Kanellopoulos", "Panagiotis", ""]]}, {"id": "1807.02856", "submitter": "Rohollah Moghadam", "authors": "Aquib Mustafa, Rohollah Moghadam and Hamidreza Modares", "title": "Resilient Synchronization of Distributed Multi-agent Systems under\n  Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we first address adverse effects of cyber-physical attacks on\ndistributed synchronization of multi-agent systems, by providing conditions\nunder which an attacker can destabilize the underlying network, as well as\nanother set of conditions under which local neighborhood tracking errors of\nintact agents converge to zero. Based on this analysis, we propose a\nKullback-Liebler divergence based criterion in view of which each agent detects\nits neighbors' misbehavior and, consequently, forms a self-belief about the\ntrustworthiness of the information it receives. Agents continuously update\ntheir self-beliefs and communicate them with their neighbors to inform them of\nthe significance of their outgoing information. Moreover, if the self-belief of\nan agent is low, it forms trust on its neighbors. Agents incorporate their\nneighbors' self-beliefs and their own trust values on their control protocols\nto slow down and mitigate attacks. We show that using the proposed resilient\napproach, an agent discards the information it receives from a neighbor only if\nits neighbor is compromised, and not solely based on the discrepancy among\nneighbors' information, which might be caused by legitimate changes, and not\nattacks. The proposed approach is guaranteed to work under mild connectivity\nassumptions.\n", "versions": [{"version": "v1", "created": "Sun, 8 Jul 2018 17:51:02 GMT"}, {"version": "v2", "created": "Thu, 19 Jul 2018 23:09:44 GMT"}, {"version": "v3", "created": "Wed, 25 Jul 2018 04:30:24 GMT"}, {"version": "v4", "created": "Thu, 29 Nov 2018 06:06:09 GMT"}, {"version": "v5", "created": "Wed, 8 May 2019 16:04:30 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Mustafa", "Aquib", ""], ["Moghadam", "Rohollah", ""], ["Modares", "Hamidreza", ""]]}, {"id": "1807.02870", "submitter": "Saptarshi Sengupta", "authors": "Saptarshi Sengupta, Sanchita Basak and Richard Alan Peters II", "title": "QDDS: A Novel Quantum Swarm Algorithm Inspired by a Double Dirac Delta\n  Potential", "comments": "8 pages, 14 figures and 9 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper a novel Quantum Double Delta Swarm (QDDS) algorithm modeled\nafter the mechanism of convergence to the center of attractive potential field\ngenerated within a single well in a double Dirac delta well setup has been put\nforward and the preliminaries discussed. Theoretical foundations and\nexperimental illustrations have been incorporated to provide a first basis for\nfurther development, specifically in refinement of solutions and applicability\nto problems in high dimensional spaces. Simulations are carried out over\nvarying dimensionality on four benchmark functions, viz. Rosenbrock,\nRastrigrin, Griewank and Sphere as well as the multidimensional Finite Impulse\nResponse (FIR) Filter design problem with different population sizes. Test\nresults illustrate the algorithm yields superior results to some related\nreports in the literature while reinforcing the need of substantial future work\nto deliver near-optimal results consistently, especially if dimensionality\nscales up.\n", "versions": [{"version": "v1", "created": "Sun, 8 Jul 2018 19:32:02 GMT"}, {"version": "v2", "created": "Sun, 16 Sep 2018 02:35:47 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Sengupta", "Saptarshi", ""], ["Basak", "Sanchita", ""], ["Peters", "Richard Alan", "II"]]}, {"id": "1807.02987", "submitter": "Fuat Basik", "authors": "Fuat Basik, Bugra Gedik, Hakan Ferhatosmanoglu, Kun-Lung Wu", "title": "Fair Task Allocation in Crowdsourced Delivery", "comments": "To Appear in IEEE Transactions on Services Computing", "journal-ref": null, "doi": "10.1109/TSC.2018.2854866", "report-no": null, "categories": "cs.MA cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Faster and more cost-efficient, crowdsourced delivery is needed to meet the\ngrowing customer demands of many industries, including online shopping,\non-demand local delivery, and on-demand transportation. The power of\ncrowdsourced delivery stems from the large number of workers potentially\navailable to provide services and reduce costs. It has been shown in social\npsychology literature that fairness is key to ensuring high worker\nparticipation. However, existing assignment solutions fall short on modeling\nthe dynamic fairness metric. In this work, we introduce a new assignment\nstrategy for crowdsourced delivery tasks. This strategy takes fairness towards\nworkers into consideration, while maximizing the task allocation ratio. Since\nredundant assignments are not possible in delivery tasks, we first introduce a\n2-phase allocation model that increases the reliability of a worker to complete\na given task. To realize the effectiveness of our model in practice, we present\nboth offline and online versions of our proposed algorithm called F-Aware.\nGiven a task-to-worker bipartite graph, F-Aware assigns each task to a worker\nthat minimizes unfairness, while allocating tasks to use worker capacities as\nmuch as possible. We present an evaluation of our algorithms with respect to\nrunning time, task allocation ratio (TAR), as well as unfairness and assignment\nratio. Experiments show that F-Aware runs around 10^7 x faster than the\nTAR-optimal solution and allocates 96.9% of the tasks that can be allocated by\nit. Moreover, it is shown that, F-Aware is able to provide a much fair\ndistribution of tasks to workers than the best competitor algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 08:45:47 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Basik", "Fuat", ""], ["Gedik", "Bugra", ""], ["Ferhatosmanoglu", "Hakan", ""], ["Wu", "Kun-Lung", ""]]}, {"id": "1807.03352", "submitter": "Michal \\v{C}\\'ap", "authors": "Davide Fiedler, Michal \\v{C}ertick\\'y, Javier Alonso-Mora, Michal\n  \\v{C}\\'ap", "title": "The Impact of Ridesharing in Mobility-on-Demand Systems: Simulation Case\n  Study in Prague", "comments": "Accepted for ITSC 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In densely populated-cities, the use of private cars for personal\ntransportation is unsustainable, due to high parking and road capacity\nrequirements. The mobility-on-demand systems have been proposed as an\nalternative to a private car. Such systems consist of a fleet of vehicles that\nthe user of the system can hail for one-way point-to-point trips. These systems\nemploy large-scale vehicle sharing, i.e., one vehicle can be used by several\npeople during one day and consequently the fleet size and the parking space\nrequirements can be reduced, but, at the cost of a non-negligible increase in\nvehicles miles driven in the system. The miles driven in the system can be\nreduced by ridesharing, where several people traveling in a similar direction\nare matched and travel in one vehicle. We quantify the potential of ridesharing\nin a hypothetical mobility-on-demand system designed to serve all trips that\nare currently realized by private car in the city of Prague. Our results show\nthat by employing a ridesharing strategy that guarantees travel time\nprolongation of no more than 10 minutes, the average occupancy of a vehicle\nwill increase to 2.7 passengers. Consequently, the number of vehicle miles\ntraveled will decrease to 35% of the amount in the MoD system without\nridesharing and to 60% of the amount in the present state.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2018 15:25:27 GMT"}], "update_date": "2018-07-11", "authors_parsed": [["Fiedler", "Davide", ""], ["\u010certick\u00fd", "Michal", ""], ["Alonso-Mora", "Javier", ""], ["\u010c\u00e1p", "Michal", ""]]}, {"id": "1807.03488", "submitter": "Bo Yang", "authors": "Bo Yang and Qianxiao Li", "title": "Dynamics of Taxi-like Logistics Systems: Theory and Microscopic\n  Simulations", "comments": "12 pages, comments very welcome", "journal-ref": "Transportmetrica B: Transport Dynamics, 8:1, 129-149 (2020)", "doi": null, "report-no": null, "categories": "nlin.AO cs.MA nlin.CD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the dynamics of a class of bi-agent logistics systems\nconsisting of two types of agents interacting on an arbitrary complex network.\nBy approximating the system with simple microscopic models and solving them\nanalytically, we reveal some universal dynamical features of such logistics\nsystems, and propose the applications of such features for system\noptimisations. Large scale agent-based numerical simulations are also carried\nout to explore more realistic and complicated systems, with interesting\nemergent behaviours that can be well understood from our analytical studies.\nUsing the taxi system as a typical logistics system with commuters and empty\ntaxis as two types of agents, we illustrate two dynamical phases with distinct\nbehaviours, separated by a phase boundary that can be identified as the optimal\nnumber of taxis for a particular taxi system. We show that these features, and\nthe tuning of the optimal number of taxis, can be applied to various\nsituations, including taxi systems allowing real-time dynamical ride-sharing.\nOur studies could lead to a theoretical basis for the understanding of a large\nclass of bi-agent logistics systems, that can be useful for systematic\noptimisations via judicious benchmarking of routing and resource allocation\nstrategies.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 06:07:16 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 13:05:52 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Yang", "Bo", ""], ["Li", "Qianxiao", ""]]}, {"id": "1807.03492", "submitter": "Takumi Ichimura", "authors": "Takumi Ichimura, Takuya Uemoto, Shin Kamada", "title": "The Recommendation System to SNS Community for Tourists by Using\n  Altruistic Behaviors", "comments": "6 pages, 9 figures", "journal-ref": "Proc. of IEEE 9th International Workshop on Computational\n  Intelligence and Applications (IWCIA2016)", "doi": "10.1109/IWCIA.2016.7805747", "report-no": null, "categories": "cs.MA cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We have already developed the recommendation system of sightseeing\ninformation on SNS by using smartphone based user participatory sensing system.\nThe system can post the attractive information for tourists to the specified\nFacebook page by our developed smartphone application. The users in Facebook,\nwho are interested in sightseeing, can come flocking through information space\nfrom far and near. However, the activities in the community on SNS are only\nsupported by the specified people called a hub. We proposed the method of\nvitalization of tourist behaviors to give a stimulus to the people. We\ndeveloped the simulation system for multi agent system with altruistic\nbehaviors inspired by the Army Ants. The army ant takes feeding action with\naltruistic behaviors to suppress selfish behavior to a common object used by a\nplurality of users in common. In this paper, we introduced the altruism\nbehavior determined by some simulation to vitalize the SNS community. The\nefficiency of the revitalization process of the community was investigated by\nsome experimental simulation results.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 06:26:28 GMT"}, {"version": "v2", "created": "Wed, 11 Jul 2018 07:47:34 GMT"}], "update_date": "2018-07-12", "authors_parsed": [["Ichimura", "Takumi", ""], ["Uemoto", "Takuya", ""], ["Kamada", "Shin", ""]]}, {"id": "1807.03646", "submitter": "Dejan Lavbi\\v{c}", "authors": "Dejan Lavbi\\v{c}, Olegas Vasilecas and Rok Rupnik", "title": "Ontology-based multi-agent system to support business users and\n  management", "comments": "17 pages, 6 figures", "journal-ref": "Technological and Economic Development of Economy 16 (2010)\n  327-347", "doi": "10.3846/tede.2010.21", "report-no": null, "categories": "cs.MA cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For some decision processes a significant added value is achieved when\nenterprises' internal Data Warehouse (DW) can be integrated and combined with\nexternal data gained from web sites of competitors and other relevant Web\nsources. In this paper we discuss the agent-based integration approach using\nontologies (DSS-MAS). In this approach data from internal DW and external\nsources are scanned by coordinated group of agents, while semantically\nintegrated and relevant data is reported to business users according to\nbusiness rules. After data from internal DW, Web sources and business rules are\nacquired, agents using these data and rules can infer new knowledge and\ntherefore facilitate decision making process. Knowledge represented in\nenterprises' ontologies is acquired from business users without extensive\ntechnical knowledge using user friendly user interface based on constraints and\npredefined templates. The approach presented in the paper was verified using\nthe case study from the domain of mobile communications with the emphasis on\nsupply and demand of mobile phones.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 13:48:29 GMT"}], "update_date": "2018-07-11", "authors_parsed": [["Lavbi\u010d", "Dejan", ""], ["Vasilecas", "Olegas", ""], ["Rupnik", "Rok", ""]]}, {"id": "1807.04118", "submitter": "Takumi Ichimura", "authors": "Takumi Ichimura, Takuya Uemoto, Akira Hara", "title": "Emergence of Altruism Behavior for Multi Feeding Areas in Army Ant\n  Social Evolutionary System", "comments": "6 pages, 11 figures", "journal-ref": "Proc. of 2014 IEEE International Conference on Systems, Man, and\n  Cybernetics (IEEE SMC 2014)", "doi": "10.1109/SMC.2014.6973902", "report-no": null, "categories": "cs.MA cs.ET cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Army ants perform the altruism that an ant sacrifices its own well-being for\nthe benefit of another ants. Army ants build bridges using their own bodies\nalong the path from a food to the nest. We developed the army ant inspired\nsocial evolutionary system which can perform the altruism. The system has 2\nkinds of ant agents, `Major ant' and `Minor ant' and the ants communicate with\neach other via pheromones. One ants can recognize them as the signals from the\nother ants. The pheromones evaporate with the certain ratio and diffused into\nthe space of neighbors stochastically. If the optimal bridge is found, the path\nthrough the bridge is the shortest route from foods to the nest. We define the\nprobability for an ant to leave a bridge at a low occupancy condition of ants\nand propose the constructing method of the optimal route. In this paper, the\nbehaviors of ant under the environment with two or more feeding spots are\nobserved. Some experimental results show the behaviors of great interest with\nrespect to altruism of ants. The description in some computer simulation is\nreported in this paper.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 04:40:38 GMT"}], "update_date": "2018-07-12", "authors_parsed": [["Ichimura", "Takumi", ""], ["Uemoto", "Takuya", ""], ["Hara", "Akira", ""]]}, {"id": "1807.04631", "submitter": "David Mateo", "authors": "David Mateo and Nikolaj Horsevad and Vahid Hassani and Mohammadreza\n  Chamanbaz and Roland Bouffanais", "title": "Optimal Network Topology for Effective Collective Response", "comments": null, "journal-ref": "Science Advances 03 Apr 2019: Vol. 5, no. 4, eaau0999", "doi": "10.1126/sciadv.aau0999", "report-no": null, "categories": "cs.SY cs.MA math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Natural, social, and artificial multi-agent systems usually operate in\ndynamic environments, where the ability to respond to changing circumstances is\na crucial feature. An effective collective response requires suitable\ninformation transfer among agents, and thus is critically dependent on the\nagents' interaction network. In order to investigate the influence of the\nnetwork topology on collective response, we consider an archetypal model of\ndistributed decision-making---the leader-follower linear consensus---and study\nthe collective capacity of the system to follow a dynamic driving signal (the\n\"leader\") for a range of topologies and system sizes. The analysis reveals a\nnontrivial relationship between optimal topology and frequency of the driving\nsignal. Interestingly, the response is optimal when each individual interacts\nwith a certain number of agents which decreases monotonically with the\nfrequency and, for large enough systems, is independent of the size of the\nsystem. This phenomenology is investigated in experiments of collective motion\nusing a swarm of land robots. The emergent collective response to both a slow-\nand a fast-changing leader is measured and analyzed for a range of interaction\ntopologies. These results have far-reaching practical implications for the\ndesign and understanding of distributed systems, since they highlight that a\ndynamic rewiring of the interaction network is paramount to the effective\ncollective operations of multi-agent systems at different time-scales.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 04:01:41 GMT"}, {"version": "v2", "created": "Sat, 22 Dec 2018 00:44:52 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Mateo", "David", ""], ["Horsevad", "Nikolaj", ""], ["Hassani", "Vahid", ""], ["Chamanbaz", "Mohammadreza", ""], ["Bouffanais", "Roland", ""]]}, {"id": "1807.04862", "submitter": "Jose Fontanari", "authors": "Paulo R. A. Campos and Jos\\'e F. Fontanari", "title": "Predictability of the imitative learning trajectories", "comments": null, "journal-ref": "J. Stat. Mech. (2019) 013501", "doi": "10.1088/1742-5468/aaf634", "report-no": null, "categories": "q-bio.PE cs.MA physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fitness landscape metaphor plays a central role on the modeling of\noptimizing principles in many research fields, ranging from evolutionary\nbiology, where it was first introduced, to management research. Here we\nconsider the ensemble of trajectories of the imitative learning search, in\nwhich agents exchange information on their fitness and imitate the fittest\nagent in the population aiming at reaching the global maximum of the fitness\nlandscape. We assess the degree to which the starting and ending points\ndetermine the learning trajectories using two measures, namely, the\npredictability that yields the probability that two randomly chosen\ntrajectories are the same, and the mean path divergence that gauges the\ndissimilarity between two learning trajectories. We find that the\npredictability is greater in rugged landscapes than in smooth ones. The mean\npath divergence, however, is strongly affected by the search parameters --\npopulation size and imitation propensity -- that obliterate the influence of\nthe underlying landscape. The learning trajectories become more deterministic,\nin the sense that there are fewer distinct trajectories and those trajectories\nare more similar to each other, with increasing population size and imitation\npropensity. In addition, we find that the roughness of the learning\ntrajectories, which measures the deviation from additivity of the fitness\nfunction, is always greater than the roughness estimated over the entire\nfitness landscape.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 23:32:47 GMT"}, {"version": "v2", "created": "Mon, 16 Jul 2018 23:46:40 GMT"}, {"version": "v3", "created": "Thu, 15 Nov 2018 17:42:47 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Campos", "Paulo R. A.", ""], ["Fontanari", "Jos\u00e9 F.", ""]]}, {"id": "1807.05177", "submitter": "Dante Kalise", "authors": "Young-Pil Choi and Dante Kalise and Jan Peszek and Andr\\'es A. Peters", "title": "A collisionless singular Cucker-Smale model with decentralized formation\n  control", "comments": "26 pages, 5 figures, SIAM Journal of Applied Dynamical Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.MA math.DS nlin.AO nlin.PS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the design of decentralized feedback control laws inducing\nconsensus and prescribed spatial patterns over a singular interacting particle\nsystem of Cucker-Smale type. The control design consists of a feedback term\nregulating the distance between each agent and pre-assigned subset of\nneighbours. Such a design represents a multidimensional extension of existing\ncontrol laws for 1d platoon formation control. For the proposed controller we\nstudy consensus emergence, collision-avoidance and formation control features\nin terms of energy estimates for the closed-loop system. Numerical experiments\nin 1, 2 and 3 dimensions assess the different features of the proposed design.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jul 2018 16:50:49 GMT"}, {"version": "v2", "created": "Thu, 9 Aug 2018 23:10:39 GMT"}, {"version": "v3", "created": "Wed, 30 Jan 2019 04:21:33 GMT"}, {"version": "v4", "created": "Thu, 5 Sep 2019 20:37:43 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Choi", "Young-Pil", ""], ["Kalise", "Dante", ""], ["Peszek", "Jan", ""], ["Peters", "Andr\u00e9s A.", ""]]}, {"id": "1807.05283", "submitter": "Davide Grossi", "authors": "Krzysztof R. Apt, Davide Grossi, Wiebe van der Hoek", "title": "When Are Two Gossips the Same? Types of Communication in Epistemic\n  Gossip Protocols", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide an in-depth study of the knowledge-theoretic aspects of\ncommunication in so-called gossip protocols. Pairs of agents communicate by\nmeans of calls in order to spread information---so-called secrets---within the\ngroup. Depending on the nature of such calls knowledge spreads in different\nways within the group. Systematizing existing literature, we identify 18\ndifferent types of communication, and model their epistemic effects through\ncorresponding indistinguishability relations. We then provide a classification\nof these relations and show its usefulness for an epistemic analysis in\npresence of different communication types. Finally, we explain how to formalise\nthe assumption that the agents have common knowledge of a distributed epistemic\ngossip protocol.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jul 2018 21:11:15 GMT"}, {"version": "v2", "created": "Mon, 8 Oct 2018 09:14:28 GMT"}, {"version": "v3", "created": "Thu, 11 Oct 2018 10:15:18 GMT"}], "update_date": "2018-10-12", "authors_parsed": [["Apt", "Krzysztof R.", ""], ["Grossi", "Davide", ""], ["van der Hoek", "Wiebe", ""]]}, {"id": "1807.05424", "submitter": "Wenhao Ding", "authors": "Wenhao Ding, Shuaijun Li and Huihuan Qian", "title": "Hierarchical Reinforcement Learning Framework towards Multi-agent\n  Navigation", "comments": "7 pages, 4 figures, submitted to ROBIO 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a navigation algorithm oriented to multi-agent\nenvironment. This algorithm is expressed as a hierarchical framework that\ncontains a Hidden Markov Model (HMM) and a Deep Reinforcement Learning (DRL)\nstructure. For simplification, we term our method Hierarchical Navigation\nReinforcement Network (HNRN). In high- level architecture, we train an HMM to\nevaluate the agent's perception to obtain a score. According to this score,\nadaptive control action will be chosen. While in low-level architecture, two\nsub-systems are introduced, one is a differential target- driven system, which\naims at heading to the target; the other is a collision avoidance DRL system,\nwhich is used for avoiding dynamic obstacles. The advantage of this\nhierarchical structure is decoupling the target-driven and collision avoidance\ntasks, leading to a faster and more stable model to be trained. The experiments\nindicate that our algorithm has higher learning efficiency and rate of success\nthan traditional Velocity Obstacle (VO) algorithms or hybrid DRL method.\n", "versions": [{"version": "v1", "created": "Sat, 14 Jul 2018 18:07:32 GMT"}, {"version": "v2", "created": "Tue, 17 Jul 2018 14:01:30 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Ding", "Wenhao", ""], ["Li", "Shuaijun", ""], ["Qian", "Huihuan", ""]]}, {"id": "1807.05806", "submitter": "Derrik Asher", "authors": "Derrik E. Asher, Erin Zaroukian, Sean L. Barton", "title": "Adapting the Predator-Prey Game Theoretic Environment to Army Tactical\n  Edge Scenarios with Computational Multiagent Systems", "comments": "Concept paper: Modifying the predator-prey pursuit environment to\n  simulate tactical edge scenarios, 9 pages, 1 figure, International Command\n  and Control Research and Technology Symposium (ICCRTS - 2018)", "journal-ref": "US Army Research Laboratory Aberdeen Proving Ground United States,\n  2018", "doi": null, "report-no": "ARL-TR-8453", "categories": "cs.MA cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The historical origins of the game theoretic predator-prey pursuit problem\ncan be traced back to Benda, et al., 1985 [1]. Their work adapted the\npredator-prey ecology problem into a pursuit environment which focused on the\ndynamics of cooperative behavior between predator agents. Modifications to the\npredator-prey ecology problem [2] have been implemented to understand how\nvariations to predator [3] and prey [3-5] attributes, including communication\n[6], can modify dynamic interactions between entities that emerge within that\nenvironment [7-9]. Furthermore, the predator-prey pursuit environment has\nbecome a testbed for simulation experiments with computational multiagent\nsystems [10-12]. This article extends the theoretical contributions of previous\nwork by providing 1) additional variations to predator and prey attributes for\nsimulated multiagent systems in the pursuit problem, and 2) military-relevant\npredator-prey environments simulating highly dynamic, tactical edge scenarios\nthat Soldiers might encounter on future battlefields. Through this exploration\nof simulated tactical edge scenarios with computational multiagent systems,\nSoldiers will have a greater chance to achieve overmatch on the battlefields of\ntomorrow.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 11:51:11 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Asher", "Derrik E.", ""], ["Zaroukian", "Erin", ""], ["Barton", "Sean L.", ""]]}, {"id": "1807.05826", "submitter": "Cm Pintea", "authors": "Camelia-M. Pintea, Andreea Camelia Tripon, Anca Avram, Gloria-Cerasela\n  Crisan", "title": "Multi-agents features on Android platforms", "comments": "6 pages, 2 figures", "journal-ref": "Complex Adaptive Systems Modeling 6(10):1-12 (2018)", "doi": "10.1186/s40294-018-0061-7", "report-no": null, "categories": "cs.MA cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The current paper shows the multi-agents capabilities to make a valid and\nflexible application when using a framework. Agent-based functions were used\nwithin JADE framework to make an Android messenger application with all\nrequirements included. In the paper are described the architecture, the main\nfunctions and the databases integration of the user friendly agent-based\napplication. There are included existing and possible multi-agents\ncharacteristics to provide integration with mobile platforms and storage\nchallenges to improve the user experience through data mining.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 12:57:00 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Pintea", "Camelia-M.", ""], ["Tripon", "Andreea Camelia", ""], ["Avram", "Anca", ""], ["Crisan", "Gloria-Cerasela", ""]]}, {"id": "1807.06103", "submitter": "Hadi Hosseini", "authors": "Angelina Brilliantova, Anton Pletenev, Liliya Doronina, Hadi Hosseini", "title": "An agent-based model of an endangered population of the Arctic fox from\n  Mednyi Island", "comments": "The AI for Wildlife Conservation (AIWC) Workshop at IJCAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence techniques such as agent-based modeling and\nprobabilistic reasoning have shown promise in modeling complex biological\nsystems and testing ecological hypotheses through simulation. We develop an\nagent-based model of Arctic foxes from Medniy Island while utilizing\nProbabilistic Graphical Models to capture the conditional dependencies between\nthe random variables. Such models provide valuable insights in analyzing\nfactors behind catastrophic degradation of this population and in revealing\nevolutionary mechanisms of its persistence in high-density environment. Using\nempirical data from studies in Medniy Island, we create a realistic model of\nArctic foxes as agents, and study their survival and population dynamics under\na variety of conditions.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 20:49:12 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Brilliantova", "Angelina", ""], ["Pletenev", "Anton", ""], ["Doronina", "Liliya", ""], ["Hosseini", "Hadi", ""]]}, {"id": "1807.06613", "submitter": "Maximilian H\\\"uttenrauch", "authors": "Maximilian H\\\"uttenrauch, Adrian \\v{S}o\\v{s}i\\'c, Gerhard Neumann", "title": "Deep Reinforcement Learning for Swarm Systems", "comments": "31 pages, 12 figures, version 3 (published in JMLR Volume 20)", "journal-ref": "Journal of Machine Learning Research 20(54):1-31, 2019", "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, deep reinforcement learning (RL) methods have been applied\nsuccessfully to multi-agent scenarios. Typically, these methods rely on a\nconcatenation of agent states to represent the information content required for\ndecentralized decision making. However, concatenation scales poorly to swarm\nsystems with a large number of homogeneous agents as it does not exploit the\nfundamental properties inherent to these systems: (i) the agents in the swarm\nare interchangeable and (ii) the exact number of agents in the swarm is\nirrelevant. Therefore, we propose a new state representation for deep\nmulti-agent RL based on mean embeddings of distributions. We treat the agents\nas samples of a distribution and use the empirical mean embedding as input for\na decentralized policy. We define different feature spaces of the mean\nembedding using histograms, radial basis functions and a neural network learned\nend-to-end. We evaluate the representation on two well known problems from the\nswarm literature (rendezvous and pursuit evasion), in a globally and locally\nobservable setup. For the local setup we furthermore introduce simple\ncommunication protocols. Of all approaches, the mean embedding representation\nusing neural network features enables the richest information exchange between\nneighboring agents facilitating the development of more complex collective\nstrategies.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 18:27:03 GMT"}, {"version": "v2", "created": "Mon, 15 Oct 2018 13:57:21 GMT"}, {"version": "v3", "created": "Thu, 6 Jun 2019 10:27:01 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["H\u00fcttenrauch", "Maximilian", ""], ["\u0160o\u0161i\u0107", "Adrian", ""], ["Neumann", "Gerhard", ""]]}, {"id": "1807.06666", "submitter": "Dong Hao", "authors": "Dong Hao, Kai Li, Tao Zhou", "title": "Payoff Control in the Iterated Prisoner's Dilemma", "comments": null, "journal-ref": "Proceedings of the Twenty-Seventh International Joint Conference\n  on Artificial Intelligence. Main track. Pages 296-302. 2018", "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Repeated game has long been the touchstone model for agents' long-run\nrelationships. Previous results suggest that it is particularly difficult for a\nrepeated game player to exert an autocratic control on the payoffs since they\nare jointly determined by all participants. This work discovers that the scale\nof a player's capability to unilaterally influence the payoffs may have been\nmuch underestimated. Under the conventional iterated prisoner's dilemma, we\ndevelop a general framework for controlling the feasible region where the\nplayers' payoff pairs lie. A control strategy player is able to confine the\npayoff pairs in her objective region, as long as this region has feasible\nlinear boundaries. With this framework, many well-known existing strategies can\nbe categorized and various new strategies with nice properties can be further\nidentified. We show that the control strategies perform well either in a\ntournament or against a human-like opponent.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 20:44:51 GMT"}], "update_date": "2018-07-19", "authors_parsed": [["Hao", "Dong", ""], ["Li", "Kai", ""], ["Zhou", "Tao", ""]]}, {"id": "1807.06822", "submitter": "Dong Hao", "authors": "Bin Li, Dong Hao, Dengji Zhao, Tao Zhou", "title": "Customer Sharing in Economic Networks with Costs", "comments": "Proceedings of the Twenty-Seventh International Joint Conference on\n  Artificial Intelligence. Main track. Pages 368-374. 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.MA cs.SI econ.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In an economic market, sellers, infomediaries and customers constitute an\neconomic network. Each seller has her own customer group and the seller's\nprivate customers are unobservable to other sellers. Therefore, a seller can\nonly sell commodities among her own customers unless other sellers or\ninfomediaries share her sale information to their customer groups. However, a\nseller is not incentivized to share others' sale information by default, which\nleads to inefficient resource allocation and limited revenue for the sale. To\ntackle this problem, we develop a novel mechanism called customer sharing\nmechanism (CSM) which incentivizes all sellers to share each other's sale\ninformation to their private customer groups. Furthermore, CSM also\nincentivizes all customers to truthfully participate in the sale. In the end,\nCSM not only allocates the commodities efficiently but also optimizes the\nseller's revenue.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 08:55:27 GMT"}], "update_date": "2018-07-23", "authors_parsed": [["Li", "Bin", ""], ["Hao", "Dong", ""], ["Zhao", "Dengji", ""], ["Zhou", "Tao", ""]]}, {"id": "1807.07957", "submitter": "Souma Chowdhury", "authors": "Payam Ghassemi and Souma Chowdhury", "title": "Decentralized Task Allocation in Multi-Robot Systems via Bipartite Graph\n  Matching Augmented with Fuzzy Clustering", "comments": "The ASME 2018 International Design Engineering Technical Conferences\n  & Computers and Information in Engineering Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robotic systems, working together as a team, are becoming valuable players in\ndifferent real-world applications, from disaster response to warehouse\nfulfillment services. Centralized solutions for coordinating multi-robot teams\noften suffer from poor scalability and vulnerability to communication\ndisruptions. This paper develops a decentralized multi-agent task allocation\n(Dec-MATA) algorithm for multi-robot applications. The task planning problem is\nposed as a maximum-weighted matching of a bipartite graph, the solution of\nwhich using the blossom algorithm allows each robot to autonomously identify\nthe optimal sequence of tasks it should undertake. The graph weights are\ndetermined based on a soft clustering process, which also plays a problem\ndecomposition role seeking to reduce the complexity of the individual-agents'\ntask assignment problems. To evaluate the new Dec-MATA algorithm, a series of\ncase studies (of varying complexity) are performed, with tasks being\ndistributed randomly over an observable 2D environment. A centralized approach,\nbased on a state-of-the-art MILP formulation of the multi-Traveling Salesman\nproblem is used for comparative analysis. While getting within 7-28% of the\noptimal cost obtained by the centralized algorithm, the Dec-MATA algorithm is\nfound to be 1-3 orders of magnitude faster and minimally sensitive to\ntask-to-robot ratios, unlike the centralized algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jul 2018 17:59:58 GMT"}], "update_date": "2018-07-23", "authors_parsed": [["Ghassemi", "Payam", ""], ["Chowdhury", "Souma", ""]]}, {"id": "1807.08262", "submitter": "Neeraj Mumbuveetil Sasankan", "authors": "Neeraj Mumbuveetil Sasankan", "title": "Mutual Influences in Interwoven Systems and their detection in the\n  context of Organic Computing", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Technical systems have evolved over time into large and complex Interwoven\nSystems consisting of several to a huge number of (possibly heterogeneous)\nsubsystems that have interdependencies. The resultant mutual influences among\nsubsystems have made them so complex that they are no longer manageable by\nhumans and it is assumed to intensify rapidly. Identifying such mutual\ninfluences is the first step towards mastering the complexity of such systems.\nThis paper presents mutual influences in Interwoven Systems by describing\nreal-world examples and a methodology to detect them in the context of Organic\nComputing. The methodology is evaluated with the help of an example. Further, a\ntaxonomy of Organic Computing applications helpful for selecting suitable\nmethods for detecting hidden mutual influences is described briefly.\n", "versions": [{"version": "v1", "created": "Sun, 22 Jul 2018 09:12:32 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Sasankan", "Neeraj Mumbuveetil", ""]]}, {"id": "1807.08531", "submitter": "Youngjoo Kim", "authors": "Youngjoo Kim and Hyochoong Bang", "title": "Multisensor Management Algorithm for Airborne Sensors Using Frank-Wolfe\n  Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study proposes an airborne multisensor management algorithm for target\ntracking, taking each of multiple unmanned aircraft as a sensor. The purpose of\nthe algorithm is to determine the configuration of the sensor deployment and to\nguide the mobile sensors to track moving targets in an optimal way. The cost\nfunction as a performance metric is defined as a combination of the\nD-optimality criterion of the Fisher information matrix. The convexity of the\ncost function is proved and the optimal solution for deployment and guidance\nproblem is derived by the Frank-Wolfe method, also known as the conditional\ngradient descent method. An intuitive optimal approach to deal with the problem\nis to direct the sensor to the optimal position obtained by solving a nonlinear\noptimization problem. On the other hand, the proposed method takes the\nconditional gradient of the cost function as the command to the deployed\nsensors, so that the sensors are guaranteed to be in the feasible points and\nthey achieve the current best performance. Simulation results demonstrate that\nthe proposed algorithm provides better performance than directing each sensor\nto its optimal position.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2018 11:10:53 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Kim", "Youngjoo", ""], ["Bang", "Hyochoong", ""]]}, {"id": "1807.08545", "submitter": "Vivek Nallur", "authors": "Francis Lawlor and Rem Collier and Vivek Nallur", "title": "Towards a Programmable Framework for Agent Game Playing", "comments": "Adaptive Learning Agents Workshop at AAMAS'2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The field of Game Theory provides a useful mechanism for modeling many\ndecision-making scenarios. In participating in these scenarios individuals and\ngroups adopt particular strategies, which generally perform with varying levels\nof success. However, most results have focussed on players that play the same\ngame in an iterated fashion. This paper describes a framework which can be used\nto observe agents when they do not know in advance which game they are going to\nplay. That is, the same group of agents could first play a few rounds of the\nIterated Prisoner's Dilemma, and then a few rounds of the Linear Public Goods\nGame, and then a few rounds of Minority Game, or perhaps all games in a\nstrictly alternating fashion or a randomized instantiation of games. This\nframework will allow for investigation of agents in more complex settings, when\nthere is uncertainty about the future, and limited resources to store\nstrategies.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2018 11:48:02 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Lawlor", "Francis", ""], ["Collier", "Rem", ""], ["Nallur", "Vivek", ""]]}, {"id": "1807.08663", "submitter": "Sean Barton", "authors": "Sean L. Barton, Nicholas R. Waytowich, Erin Zaroukian, and Derrik E.\n  Asher", "title": "Measuring collaborative emergent behavior in multi-agent reinforcement\n  learning", "comments": "1st International Conference on Human Systems Engineering and Design,\n  6 pages, 2 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-agent reinforcement learning (RL) has important implications for the\nfuture of human-agent teaming. We show that improved performance with\nmulti-agent RL is not a guarantee of the collaborative behavior thought to be\nimportant for solving multi-agent tasks. To address this, we present a novel\napproach for quantitatively assessing collaboration in continuous spatial tasks\nwith multi-agent RL. Such a metric is useful for measuring collaboration\nbetween computational agents and may serve as a training signal for\ncollaboration in future RL paradigms involving humans.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2018 15:09:25 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Barton", "Sean L.", ""], ["Waytowich", "Nicholas R.", ""], ["Zaroukian", "Erin", ""], ["Asher", "Derrik E.", ""]]}, {"id": "1807.09936", "submitter": "Jiaming Song", "authors": "Jiaming Song, Hongyu Ren, Dorsa Sadigh, Stefano Ermon", "title": "Multi-Agent Generative Adversarial Imitation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation learning algorithms can be used to learn a policy from expert\ndemonstrations without access to a reward signal. However, most existing\napproaches are not applicable in multi-agent settings due to the existence of\nmultiple (Nash) equilibria and non-stationary environments. We propose a new\nframework for multi-agent imitation learning for general Markov games, where we\nbuild upon a generalized notion of inverse reinforcement learning. We further\nintroduce a practical multi-agent actor-critic algorithm with good empirical\nperformance. Our method can be used to imitate complex behaviors in\nhigh-dimensional environments with multiple cooperative or competing agents.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2018 03:21:49 GMT"}], "update_date": "2018-07-27", "authors_parsed": [["Song", "Jiaming", ""], ["Ren", "Hongyu", ""], ["Sadigh", "Dorsa", ""], ["Ermon", "Stefano", ""]]}, {"id": "1807.10978", "submitter": "Shantanu Chakraborty D.Eng.", "authors": "Shantanu Chakraborty, Tim Baarslag and Michael Kaisers", "title": "Energy Contract Settlements through Automated Negotiation in Residential\n  Cooperatives", "comments": "6 pages, 4 figures, accepted in IEEE SGComm 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an automated peer-to-peer (P2P) negotiation strategy for\nsettling energy contracts among prosumers in a Residential Energy Cooperative\n(REC) considering heterogeneous prosumer preferences. The heterogeneity arises\nfrom prosumers' evaluation of energy contracts through multiple societal and\nenvironmental criteria and the prosumers' private preferences over those\ncriteria. The prosumers engage in bilateral negotiations with peers to mutually\nagree on periodical energy contracts/loans that consist of an energy volume to\nbe exchanged at that period and the return time of the exchanged energy. The\nprosumers keep an ordered preference profile of possible energy contracts by\nevaluating the contracts from their own valuations on the entailed criteria,\nand iteratively offer the peers contracts until an agreement is formed. A\nprosumer embeds the valuations into a utility function that further considers\nuncertainties imposed by demand and generation profiles. Empirical evaluation\non real demand, generation and storage profiles illustrates that the proposed\nnegotiation based strategy is able to increase the system efficiency (measured\nby utilitarian social welfare) and fairness (measured by Nash social welfare)\nover a baseline strategy and an individual flexibility control strategy. We\nthus elicit system benefits from P2P flexibility exchange already with few\nagents and without central coordination, providing a simple yet flexible and\neffective paradigm that may complement existing markets.\n", "versions": [{"version": "v1", "created": "Sat, 28 Jul 2018 21:37:12 GMT"}, {"version": "v2", "created": "Tue, 31 Jul 2018 18:36:05 GMT"}, {"version": "v3", "created": "Mon, 22 Oct 2018 05:41:34 GMT"}, {"version": "v4", "created": "Tue, 23 Oct 2018 01:07:44 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Chakraborty", "Shantanu", ""], ["Baarslag", "Tim", ""], ["Kaisers", "Michael", ""]]}, {"id": "1807.11105", "submitter": "Ehud Shapiro", "authors": "Gal Shahaf, Ehud Shapiro, and Nimrod Talmon", "title": "Sybil-Resilient Reality-Aware Social Choice", "comments": "To appear in Proceedings of IJCAI'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Sybil attacks, in which fake or duplicate identities (\\emph{sybils})\ninfiltrate an online community, pose a serious threat to such communities, as\nthey might tilt community-wide decisions in their favor. While the extensive\nresearch on sybil identification may help keep the fraction of sybils in such\ncommunities low, it cannot however ensure their complete eradication. Thus, our\ngoal is to enhance social choice theory with effective group decision\nmechanisms for communities with bounded sybil penetration. Inspired by\nReality-Aware Social Choice, we use the status quo as the anchor of \\emph{sybil\nresilience}, characterized by \\emph{sybil safety} -- the inability of sybils to\nchange the status quo against the will of the genuine agents, and \\emph{sybil\nliveness} -- the ability of the genuine agents to change the status quo against\nthe will of the sybils.\n  We consider the social choice settings of deciding on a single proposal, on\nmultiple proposals, and on updating a parameter. For each, we present social\nchoice rules that are sybil-safe and, under certain conditions, satisfy\nsybil-liveness.\n", "versions": [{"version": "v1", "created": "Sun, 29 Jul 2018 19:42:58 GMT"}, {"version": "v2", "created": "Sun, 11 Nov 2018 07:23:43 GMT"}, {"version": "v3", "created": "Tue, 26 Feb 2019 13:05:23 GMT"}, {"version": "v4", "created": "Sun, 21 Apr 2019 18:02:40 GMT"}, {"version": "v5", "created": "Thu, 16 May 2019 08:27:00 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Shahaf", "Gal", ""], ["Shapiro", "Ehud", ""], ["Talmon", "Nimrod", ""]]}, {"id": "1807.11332", "submitter": "Gurkirt Singh", "authors": "Valentina Fontana, Gurkirt Singh, Stephen Akrigg, Manuele Di Maio,\n  Suman Saha, Fabio Cuzzolin", "title": "Action Detection from a Robot-Car Perspective", "comments": "intial version, more to come - soon", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the new Road Event and Activity Detection (READ) dataset, designed\nand created from an autonomous vehicle perspective to take action detection\nchallenges to autonomous driving. READ will give scholars in computer vision,\nsmart cars and machine learning at large the opportunity to conduct research\ninto exciting new problems such as understanding complex (road) activities,\ndiscerning the behaviour of sentient agents, and predicting both the label and\nthe location of future actions and events, with the final goal of supporting\nautonomous decision making.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2018 13:11:21 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Fontana", "Valentina", ""], ["Singh", "Gurkirt", ""], ["Akrigg", "Stephen", ""], ["Di Maio", "Manuele", ""], ["Saha", "Suman", ""], ["Cuzzolin", "Fabio", ""]]}, {"id": "1807.11367", "submitter": "Warut Suksompong", "authors": "Hoon Oh, Ariel D. Procaccia, Warut Suksompong", "title": "Fairly Allocating Many Goods with Few Queries", "comments": "A preliminary version appears in the 33rd AAAI Conference on\n  Artificial Intelligence (AAAI), 2019", "journal-ref": "SIAM Journal on Discrete Mathematics, 35(2): 788-813 (2021)", "doi": "10.1137/20M1313349", "report-no": null, "categories": "cs.GT cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the query complexity of the fair allocation of indivisible\ngoods. For two agents with arbitrary monotonic utilities, we design an\nalgorithm that computes an allocation satisfying envy-freeness up to one good\n(EF1), a relaxation of envy-freeness, using a logarithmic number of queries. We\nshow that the logarithmic query complexity bound also holds for three agents\nwith additive utilities, and that a polylogarithmic bound holds for three\nagents with monotonic utilities. These results suggest that it is possible to\nfairly allocate goods in practice even when the number of goods is extremely\nlarge. By contrast, we prove that computing an allocation satisfying\nenvy-freeness and another of its relaxations, envy-freeness up to any good\n(EFX), requires a linear number of queries even when there are only two agents\nwith identical additive utilities.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2018 14:27:52 GMT"}, {"version": "v2", "created": "Mon, 19 Apr 2021 06:21:06 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Oh", "Hoon", ""], ["Procaccia", "Ariel D.", ""], ["Suksompong", "Warut", ""]]}, {"id": "1807.11456", "submitter": "Stevan Tomic", "authors": "Stevan Tomic, Federico Pecora, Alessandro Saffiotti", "title": "Norms, Institutions, and Robots", "comments": "12 pages, 8 figures. This work has been submitted to the IEEE for\n  possible publication. Copyright may be transferred without notice, after\n  which this version may no longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interactions within human societies are usually regulated by social norms. If\nrobots are to be accepted into human society, it is essential that they are\naware of and capable of reasoning about social norms. In this paper, we focus\non how to represent social norms in societies with humans and robots, and how\nartificial agents such as robots can reason about social norms in order to plan\nappropriate behavior. We use the notion of institution as a way to formally\ndefine and encapsulate norms, and we provide a formal framework for\ninstitutions. Our framework borrows ideas from the field of multi-agent systems\nto define abstract normative models, and ideas from the field of robotics to\ndefine physical executions as state-space trajectories. By bridging the two in\na common model, our framework allows us to use the same abstract institution\nacross physical domains and agent types. We then make our framework\ncomputational via a reduction to CSP and show experiments where this reduction\nis used for norm verification, planning, and plan execution in a domain\nincluding a mixture of humans and robots.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2018 17:27:06 GMT"}, {"version": "v2", "created": "Thu, 20 Aug 2020 12:43:40 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Tomic", "Stevan", ""], ["Pecora", "Federico", ""], ["Saffiotti", "Alessandro", ""]]}, {"id": "1807.11919", "submitter": "Sylvain Bouveret", "authors": "Aur\\'elie Beynier and Sylvain Bouveret and Michel Lema\\^itre and\n  Nicolas Maudet and Simon Rey", "title": "Efficiency, Sequenceability and Deal-Optimality in Fair Division of\n  Indivisible Goods", "comments": "arXiv admin note: substantial text overlap with arXiv:1604.01734", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In fair division of indivisible goods, using sequences of sincere choices (or\npicking sequences) is a natural way to allocate the objects. The idea is as\nfollows: at each stage, a designated agent picks one object among those that\nremain. Another intuitive way to obtain an allocation is to give objects to\nagents in the first place, and to let agents exchange them as long as such\n\"deals\" are beneficial. This paper investigates these notions, when agents have\nadditive preferences over objects, and unveils surprising connections between\nthem, and with other efficiency and fairness notions. In particular, we show\nthat an allocation is sequenceable iff it is optimal for a certain type of\ndeals, namely cycle deals involving a single object. Furthermore, any\nPareto-optimal allocation is sequenceable, but not the converse. Regarding\nfairness, we show that an allocation can be envy-free and non-sequenceable, but\nthat every competitive equilibrium with equal incomes is sequenceable. To\ncomplete the picture, we show how some domain restrictions may affect the\nrelations between these notions. Finally, we experimentally explore the links\nbetween the scales of efficiency and fairness.\n", "versions": [{"version": "v1", "created": "Sat, 28 Jul 2018 12:13:31 GMT"}], "update_date": "2018-08-01", "authors_parsed": [["Beynier", "Aur\u00e9lie", ""], ["Bouveret", "Sylvain", ""], ["Lema\u00eetre", "Michel", ""], ["Maudet", "Nicolas", ""], ["Rey", "Simon", ""]]}]