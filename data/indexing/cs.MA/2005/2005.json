[{"id": "2005.00110", "submitter": "Shane Steinert-Threlkeld", "authors": "Nur Geffen Lan, Emmanuel Chemla, Shane Steinert-Threlkeld", "title": "On the Spontaneous Emergence of Discrete and Compositional Signals", "comments": "ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a general framework to study language emergence through signaling\ngames with neural agents. Using a continuous latent space, we are able to (i)\ntrain using backpropagation, (ii) show that discrete messages nonetheless\nnaturally emerge. We explore whether categorical perception effects follow and\nshow that the messages are not compositional.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 21:15:19 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Lan", "Nur Geffen", ""], ["Chemla", "Emmanuel", ""], ["Steinert-Threlkeld", "Shane", ""]]}, {"id": "2005.00565", "submitter": "Wouter van Heeswijk PhD", "authors": "Wouter van Heeswijk", "title": "Smart Containers With Bidding Capacity: A Policy Gradient Algorithm for\n  Semi-Cooperative Learning", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smart modular freight containers -- as propagated in the Physical Internet\nparadigm -- are equipped with sensors, data storage capability and intelligence\nthat enable them to route themselves from origin to destination without manual\nintervention or central governance. In this self-organizing setting, containers\ncan autonomously place bids on transport services in a spot market setting.\nHowever, for individual containers it may be difficult to learn good bidding\npolicies due to limited observations. By sharing information and costs between\none another, smart containers can jointly learn bidding policies, even though\nsimultaneously competing for the same transport capacity. We replicate this\nbehavior by learning stochastic bidding policies in a semi-cooperative multi\nagent setting. To this end, we develop a reinforcement learning algorithm based\non the policy gradient framework. Numerical experiments show that sharing\nsolely bids and acceptance decisions leads to stable bidding policies.\nAdditional system information only marginally improves performance; individual\njob properties suffice to place appropriate bids. Furthermore, we find that\ncarriers may have incentives not to share information with the smart\ncontainers. The experiments give rise to several directions for follow-up\nresearch, in particular the interaction between smart containers and transport\nservices in self-organizing logistics.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 18:37:38 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["van Heeswijk", "Wouter", ""]]}, {"id": "2005.00815", "submitter": "Bilal Farooq", "authors": "Shadi Djavadian and Ran Tu and Bilal Farooq and Marianne Hatzopoulou", "title": "Multi-Objective Eco-Routing for Dynamic Control of Connected & Automated\n  Vehicles", "comments": null, "journal-ref": "Transportation Research Part D: Transport and Environment. 87C:\n  1-16 (2020)", "doi": "10.1016/j.trc.2020.01.002", "report-no": null, "categories": "math.OC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advent of intelligent vehicles that can communicate with infrastructure\nas well as automate the movement provides a range of new options to address key\nurban traffic issues such as congestion and pollution, without the need for\ncentralized traffic control. Furthermore, the advances in the information,\ncommunication, and sensing technologies have provided access to real-time\ntraffic and emission data. Leveraging these advancements, a dynamic\nmulti-objective eco-routing strategy for connected & automated vehicles (CAVs)\nis proposed and implemented in a distributed traffic management system. It is\napplied to the road network of downtown Toronto in an in-house agent-based\ntraffic simulation platform. The performance of the proposed system is compared\nto various single-objective optimizations. Simulation results show the\nsignificance of incorporating real-time emission and traffic state into the\ndynamic routing, along with considering the expected delays at the downstream\nintersections. The proposed multi-objective eco-routing has the potential of\nreducing GHG and NOx emissions by 43% and 18.58%, respectively, while reducing\naverage travel time by 40%.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 12:28:44 GMT"}, {"version": "v2", "created": "Thu, 27 Aug 2020 00:29:09 GMT"}, {"version": "v3", "created": "Thu, 8 Oct 2020 18:19:36 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Djavadian", "Shadi", ""], ["Tu", "Ran", ""], ["Farooq", "Bilal", ""], ["Hatzopoulou", "Marianne", ""]]}, {"id": "2005.00935", "submitter": "Yasin Yilmaz", "authors": "Ammar Haydari, Yasin Yilmaz", "title": "Deep Reinforcement Learning for Intelligent Transportation Systems: A\n  Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA cs.SY eess.SP eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latest technological improvements increased the quality of transportation.\nNew data-driven approaches bring out a new research direction for all\ncontrol-based systems, e.g., in transportation, robotics, IoT and power\nsystems. Combining data-driven applications with transportation systems plays a\nkey role in recent transportation applications. In this paper, the latest deep\nreinforcement learning (RL) based traffic control applications are surveyed.\nSpecifically, traffic signal control (TSC) applications based on (deep) RL,\nwhich have been studied extensively in the literature, are discussed in detail.\nDifferent problem formulations, RL parameters, and simulation environments for\nTSC are discussed comprehensively. In the literature, there are also several\nautonomous driving applications studied with deep RL models. Our survey\nextensively summarizes existing works in this field by categorizing them with\nrespect to application types, control models and studied algorithms. In the\nend, we discuss the challenges and open questions regarding deep RL-based\ntransportation applications.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 22:44:50 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Haydari", "Ammar", ""], ["Yilmaz", "Yasin", ""]]}, {"id": "2005.01011", "submitter": "Roee Mordechai Francos", "authors": "Roee M. Francos and Alfred M. Bruckstein", "title": "Search for Smart Evaders with Swarms of Sweeping Agents", "comments": "arXiv admin note: text overlap with arXiv:1905.04006", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suppose that in a given planar circular region, there are some smart mobile\nevaders and we would like to find them using sweeping agents. We assume that\neach agent has a line sensor of length 2r. We propose procedures for designing\ncooperative sweeping processes that ensure the successful completion of the\ntask, thereby deriving conditions on the sweeping velocity of the agents and\ntheir paths. Successful completion of the task means that evaders with a given\nlimit on their velocity cannot escape the sweeping agents. A simpler task for\nthe sweeping swarm is the confinement of the evaders to their initial domain.\nThe feasibility of completing these tasks depends on geometric and dynamic\nconstraints that impose a lower bound on the velocity that the sweeper swarm\nmust have. This critical velocity is derived to ensure the satisfaction of the\nconfinement task. Increasing the velocity above the lower bound enables the\nagents to complete the search task as well. We present results on the total\nsearch time as a function of the sweeping velocity of the swarm's agents given\nthe initial conditions on the size of the search region and the maximal\nvelocity of the evaders.\n", "versions": [{"version": "v1", "created": "Sun, 3 May 2020 07:21:34 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Francos", "Roee M.", ""], ["Bruckstein", "Alfred M.", ""]]}, {"id": "2005.01117", "submitter": "Kshitija Taywade", "authors": "Kshitija Taywade, Judy Goldsmith, Brent Harrison", "title": "Multi-agent Reinforcement Learning for Decentralized Stable Matching", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the real world, people/entities usually find matches independently and\nautonomously, such as finding jobs, partners, roommates, etc. It is possible\nthat this search for matches starts with no initial knowledge of the\nenvironment. We propose the use of a multi-agent reinforcement learning (MARL)\nparadigm for a spatially formulated decentralized two-sided matching market\nwith independent and autonomous agents. Having autonomous agents acting\nindependently makes our environment very dynamic and uncertain. Moreover,\nagents lack the knowledge of preferences of other agents and have to explore\nthe environment and interact with other agents to discover their own\npreferences through noisy rewards. We think such a setting better approximates\nthe real world and we study the usefulness of our MARL approach for it. Along\nwith conventional stable matching case where agents have strictly ordered\npreferences, we check the applicability of our approach for stable matching\nwith incomplete lists and ties. We investigate our results for stability, level\nof instability (for unstable results), and fairness. Our MARL approach mostly\nyields stable and fair outcomes.\n", "versions": [{"version": "v1", "created": "Sun, 3 May 2020 15:28:41 GMT"}, {"version": "v2", "created": "Fri, 1 Jan 2021 00:21:07 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Taywade", "Kshitija", ""], ["Goldsmith", "Judy", ""], ["Harrison", "Brent", ""]]}, {"id": "2005.01627", "submitter": "Dimitri Bertsekas", "authors": "Dimitri Bertsekas", "title": "Multiagent Value Iteration Algorithms in Dynamic Programming and\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.LG cs.MA cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider infinite horizon dynamic programming problems, where the control\nat each stage consists of several distinct decisions, each one made by one of\nseveral agents. In an earlier work we introduced a policy iteration algorithm,\nwhere the policy improvement is done one-agent-at-a-time in a given order, with\nknowledge of the choices of the preceding agents in the order. As a result, the\namount of computation for each policy improvement grows linearly with the\nnumber of agents, as opposed to exponentially for the standard\nall-agents-at-once method. For the case of a finite-state discounted problem,\nwe showed convergence to an agent-by-agent optimal policy. In this paper, this\nresult is extended to value iteration and optimistic versions of policy\niteration, as well as to more general DP problems where the Bellman operator is\na contraction mapping, such as stochastic shortest path problems with all\npolicies being proper.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 16:34:24 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Bertsekas", "Dimitri", ""]]}, {"id": "2005.01642", "submitter": "Shayegan Omidshafiei", "authors": "Shayegan Omidshafiei, Karl Tuyls, Wojciech M. Czarnecki, Francisco C.\n  Santos, Mark Rowland, Jerome Connor, Daniel Hennes, Paul Muller, Julien\n  Perolat, Bart De Vylder, Audrunas Gruslys, Remi Munos", "title": "Navigating the Landscape of Multiplayer Games", "comments": null, "journal-ref": null, "doi": "10.1038/s41467-020-19244-4", "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiplayer games have long been used as testbeds in artificial intelligence\nresearch, aptly referred to as the Drosophila of artificial intelligence.\nTraditionally, researchers have focused on using well-known games to build\nstrong agents. This progress, however, can be better informed by characterizing\ngames and their topological landscape. Tackling this latter question can\nfacilitate understanding of agents and help determine what game an agent should\ntarget next as part of its training. Here, we show how network measures applied\nto response graphs of large-scale games enable the creation of a landscape of\ngames, quantifying relationships between games of varying sizes and\ncharacteristics. We illustrate our findings in domains ranging from canonical\ngames to complex empirical games capturing the performance of trained agents\npitted against one another. Our results culminate in a demonstration leveraging\nthis information to generate new and interesting games, including mixtures of\nempirical games synthesized from real world games.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 16:58:17 GMT"}, {"version": "v2", "created": "Mon, 24 Aug 2020 15:47:57 GMT"}, {"version": "v3", "created": "Tue, 17 Nov 2020 17:22:03 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Omidshafiei", "Shayegan", ""], ["Tuyls", "Karl", ""], ["Czarnecki", "Wojciech M.", ""], ["Santos", "Francisco C.", ""], ["Rowland", "Mark", ""], ["Connor", "Jerome", ""], ["Hennes", "Daniel", ""], ["Muller", "Paul", ""], ["Perolat", "Julien", ""], ["De Vylder", "Bart", ""], ["Gruslys", "Audrunas", ""], ["Munos", "Remi", ""]]}, {"id": "2005.01980", "submitter": "Floriana Gargiulo", "authors": "Sylvie Huet1, Floriana Gargiulo, and Felicia Pratto", "title": "Can gender inequality be created without inter-group discrimination?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.CY cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding human societies requires knowing how they develop gender\nhierarchies which are ubiquitous. We test whether a simple agent-based dynamic\nprocess could create gender inequality. Relying on evidence of gendered status\nconcerns, self-construals, and cognitive habits, our model included a gender\ndifference in how responsive male-like and female-like agents are to others'\nopinions about the level of esteem for someone. We simulate a population who\ninteract in pairs of randomly selected agents to influence each other about\ntheir esteem judgments of self and others. Half the agents are more influenced\nby their relative status rank during the interaction than the others. Without\nprejudice, stereotypes, segregation, or categorization, our model produces\ninter-group inequality of self-esteem and status that is stable, consensual,\nand exhibits characteristics of glass ceiling effects. Outcomes are not\naffected by relative group size. We discuss implications for group orientation\nto dominance and individuals' motivations to exchange.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 07:33:27 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Huet1", "Sylvie", ""], ["Gargiulo", "Floriana", ""], ["Pratto", "Felicia", ""]]}, {"id": "2005.01982", "submitter": "Guillaume Cheze", "authors": "Guillaume Ch\\`eze (IMT)", "title": "Envy-free cake cutting: A polynomial number of queries with high\n  probability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.MA math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we propose a probabilistic framework in order to study the\nfair division of a divisible good, e.g. a cake, between n players. Our\nframework follows the same idea than the ''Full independence model'' used in\nthe study of fair division of indivisible goods. We show that, in this\nframework, there exists an envy-free division algorithm satisfying the\nfollowing probability estimate:$$\\mathbb{P}\\big( C(\\mu_1, \\ldots,\\mu_n) \\geq\nn^{7+b}\\big) = \\mathcal{O}\\Big(n^{-\\frac{b-1}{3}+1+o(1)}\\Big),$$where\n$\\mu_1,\\ldots, \\mu_n$ correspond to the preferences of the $n$\nplayers,$C(\\mu_1, \\ldots,\\mu_n)$ is the number of queries used by the algorithm\nand $b>4$.In particular, this gives$$\\lim_{n \\rightarrow +\n\\infty}\\mathbb{P}\\big( C(\\mu_1, \\ldots,\\mu_n) \\geq n^{12}\\big) = 0.$$It must be\nnoticed that nowadays few things are known about the complexity of envy-free\ndivision algorithms. Indeed, Procaccia has given a lower bound in $\\Omega(n^2)$\nand Aziz and Mackenzie have given an upper bound in $n^{n^{n^{n^{n^{n}}}}}$. As\nour estimate means that we have $C(\\mu_1, \\ldots, \\mu_n)<n^{12}$ with a high\nprobability, this gives a new insight on the complexity of envy-free cake\ncutting algorithms.\\\\Our result follows from a study of Webb's algorithm and a\ntheorem of Tao and Vu about the smallest singular value of a random matrix.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 07:35:18 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Ch\u00e8ze", "Guillaume", "", "IMT"]]}, {"id": "2005.02077", "submitter": "Claudio Angione", "authors": "Claudio Angione, Eric Silverman, Elisabeth Yaneske", "title": "Using Machine Learning to Emulate Agent-Based Simulations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this proof-of-concept work, we evaluate the performance of multiple\nmachine-learning methods as statistical emulators for use in the analysis of\nagent-based models (ABMs). Analysing ABM outputs can be challenging, as the\nrelationships between input parameters can be non-linear or even chaotic even\nin relatively simple models, and each model run can require significant CPU\ntime. Statistical emulation, in which a statistical model of the ABM is\nconstructed to facilitate detailed model analyses, has been proposed as an\nalternative to computationally costly Monte Carlo methods. Here we compare\nmultiple machine-learning methods for ABM emulation in order to determine the\napproaches best suited to emulating the complex behaviour of ABMs. Our results\nsuggest that, in most scenarios, artificial neural networks (ANNs) and\ngradient-boosted trees outperform Gaussian process emulators, currently the\nmost commonly used method for the emulation of complex computational models.\nANNs produced the most accurate model replications in scenarios with high\nnumbers of model runs, although training times were longer than the other\nmethods. We propose that agent-based modelling would benefit from using\nmachine-learning methods for emulation, as this can facilitate more robust\nsensitivity analyses for the models while also reducing CPU time consumption\nwhen calibrating and analysing the simulation.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 11:48:36 GMT"}, {"version": "v2", "created": "Sat, 24 Jul 2021 16:04:13 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Angione", "Claudio", ""], ["Silverman", "Eric", ""], ["Yaneske", "Elisabeth", ""]]}, {"id": "2005.02096", "submitter": "Daniel Tang", "authors": "Daniel Tang", "title": "Finding the maximum-a-posteriori behaviour of agents in an agent-based\n  model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we consider the problem of finding the most probable set of\nevents that could have led to a set of partial, noisy observations of some\ndynamical system. In particular, we consider the case of a dynamical system\nthat is a (possibly stochastic) time-stepping agent-based model with a discrete\nstate space, the (possibly noisy) observations are the number of agents that\nhave some given property and the events we're interested in are the decisions\nmade by the agents (their ``expressed behaviours'') as the model evolves.\n  We show that this problem can be reduced to an integer linear programming\nproblem which can subsequently be solved numerically using a standard\nbranch-and-cut algorithm. We describe two implementations, an ``offline''\nalgorithm that finds the maximum-a-posteriori expressed behaviours given a set\nof observations over a finite time window, and an ``online'' algorithm that\nincrementally builds a feasible set of behaviours from a stream of observations\nthat may have no natural beginning or end.\n  We demonstrate both algorithms on a spatial predator-prey model on a 32x32\ngrid with an initial population of 100 agents.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 12:16:29 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Tang", "Daniel", ""]]}, {"id": "2005.02218", "submitter": "Matthias Bentert", "authors": "Luis M\\\"uller and Matthias Bentert", "title": "On Reachable Assignments in Cycles and Cliques", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The efficient and fair distribution of indivisible resources among agents is\na common problem in the field of \\emph{Multi-Agent-Systems}. We consider a\ngraph-based version of this problem called Reachable Assignments, introduced by\nGourves, Lesca, and Wilczynski [AAAI, 2017]. The input for this problem\nconsists of a set of agents, a set of objects, the agent's preferences over the\nobjects, a graph with the agents as vertices and edges encoding which agents\ncan trade resources with each other, and an initial and a target distribution\nof the objects, where each agent owns exactly one object in each distribution.\nThe question is then whether the target distribution is reachable via a\nsequence of rational trades. A trade is rational when the two participating\nagents are neighbors in the graph and both obtain an object they prefer over\nthe object they previously held. We show that Reachable Assignments is NP-hard\neven when restricting the input graph to be a clique and develop an\n$O(n^3)$-time algorithm for the case where the input graph is a cycle with $n$\nvertices.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 14:23:55 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["M\u00fcller", "Luis", ""], ["Bentert", "Matthias", ""]]}, {"id": "2005.02289", "submitter": "Marzio Pennisi", "authors": "Giulia Russo, Marzio Pennisi, Marco Viceconti, Francesco Pappalardo", "title": "In Silico Trial to test COVID-19 candidate vaccines: a case study with\n  UISS platform", "comments": "8 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.MA q-bio.PE q-bio.TO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  SARS-CoV-2 is a severe respiratory infection that infects humans. Its\noutburst entitled it as a pandemic emergence. To get a grip on this, outbreak\nspecific preventive and therapeutic interventions are urgently needed. It must\nbe said that, until now, there are no existing vaccines for coronaviruses. To\npromptly and rapidly respond to pandemic events, the application of in silico\ntrials can be used for designing and testing medicines against SARS-CoV-2 and\nspeed-up the vaccine discovery pipeline, predicting any therapeutic failure and\nminimizing undesired effects. Here, we present an in silico platform that\nshowed to be in very good agreement with the latest literature in predicting\nSARS- CoV-2 dynamics and related immune system host response. Moreover, it has\nbeen used to predict the outcome of one of the latest suggested approach to\ndesign an effective vaccine, based on monoclonal antibody. UISS is then\npotentially ready to be used as an in silico trial platform to predict the\noutcome of vaccination strategy against SARS-CoV-2.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 15:42:56 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Russo", "Giulia", ""], ["Pennisi", "Marzio", ""], ["Viceconti", "Marco", ""], ["Pappalardo", "Francesco", ""]]}, {"id": "2005.02298", "submitter": "Bastian Lampe", "authors": "Bastian Lampe and Raphael van Kempen, Timo Woopen, Alexandru Kampmann,\n  Bassam Alrifaee, Lutz Eckstein", "title": "Reducing Uncertainty by Fusing Dynamic Occupancy Grid Maps in a\n  Cloud-based Collective Environment Model", "comments": "Accepted to be published in 2020 IEEE Intelligent Vehicles Symposium\n  (IV), Las Vegas, NV, USA, October 20-23, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate environment perception is essential for automated vehicles. Since\nocclusions and inaccuracies regularly occur, the exchange and combination of\nperception data of multiple vehicles seems promising. This paper describes a\nmethod to combine perception data of automated and connected vehicles in the\nform of evidential Dynamic Occupany Grid Maps (DOGMas) in a cloud-based system.\nThis system is called the Collective Environment Model and is part of the cloud\nsystem developed in the project UNICARagil. The presented concept extends\nexisting approaches that fuse evidential grid maps representing static\nenvironments of a single vehicle to evidential grid maps computed by multiple\nvehicles in dynamic environments. The developed fusion process additionally\nincorporates self-reported data provided by connected vehicles instead of only\nrelying on perception data. We show that the uncertainty in a DOGMa described\nby Shannon entropy as well as the uncertainty described by a non-specificity\nmeasure can be reduced. This enables automated and connected vehicles to behave\nin ways not before possible due to unknown but relevant information about the\nenvironment.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 15:53:36 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Lampe", "Bastian", ""], ["van Kempen", "Raphael", ""], ["Woopen", "Timo", ""], ["Kampmann", "Alexandru", ""], ["Alrifaee", "Bassam", ""], ["Eckstein", "Lutz", ""]]}, {"id": "2005.02471", "submitter": "Armin Sadeghi", "authors": "Armin Sadeghi, Ahmad Bilal Asghar, Stephen L. Smith", "title": "Approximation Algorithms for Distributed Multi-Robot Coverage in\n  Non-Convex Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we revisit the distributed coverage control problem with\nmultiple robots on both metric graphs and in non-convex continuous\nenvironments. Traditionally, the solutions provided for this problem converge\nto a locally optimal solution with no guarantees on the quality of the\nsolution. We consider sub-additive sensing functions, which capture the\nscenarios where sensing an event requires the robot to visit the event\nlocation. For these sensing functions, we provide the first constant factor\napproximation algorithms for the distributed coverage problem. The\napproximation results require twice the conventional communication range in the\nexisting coverage algorithms. However, we show through extensive simulation\nresults that the proposed approximation algorithms outperform several existing\nalgorithms in convex, non-convex continuous, and discrete environments even\nwith the conventional communication ranges. Moreover, the proposed algorithms\nmatch the state-of-the-art centralized algorithms in the solution quality.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 20:21:36 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Sadeghi", "Armin", ""], ["Asghar", "Ahmad Bilal", ""], ["Smith", "Stephen L.", ""]]}, {"id": "2005.02530", "submitter": "Hao-Tsung Yang", "authors": "Peyman Afshani, Mark De Berg, Kevin Buchin, Jie Gao, Maarten Loffler,\n  Amir Nayyeri, Benjamin Raichel, Rik Sarkar, Haotian Wang, Hao-Tsung Yang", "title": "Approximation Algorithms for Multi-Robot Patrol-Scheduling with Min-Max\n  Latency", "comments": "Proceedings of the 14th International Workshop on the Algorithmic\n  Foundations of Robotics (WAFR 20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.CG cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of finding patrol schedules for $k$ robots to visit a\ngiven set of $n$ sites in a metric space. Each robot has the same maximum speed\nand the goal is to minimize the weighted maximum latency of any site, where the\nlatency of a site is defined as the maximum time duration between consecutive\nvisits of that site. The problem is NP-hard, as it has the traveling salesman\nproblem as a special case (when $k=1$ and all sites have the same weight). We\npresent a polynomial-time algorithm with an approximation factor of $O(k^2 \\log\n\\frac{w_{\\max}}{w_{\\min}})$ to the optimal solution, where $w_{\\max}$ and\n$w_{\\min}$ are the maximum and minimum weight of the sites respectively.\nFurther, we consider the special case where the sites are in 1D. When all sites\nhave the same weight, we present a polynomial-time algorithm to solve the\nproblem exactly. If the sites may have different weights, we present a\n$12$-approximate solution, which runs in polynomial time when the number of\nrobots, $k$, is a constant.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 23:18:53 GMT"}, {"version": "v2", "created": "Sat, 23 May 2020 15:28:03 GMT"}, {"version": "v3", "created": "Tue, 14 Jul 2020 02:39:07 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Afshani", "Peyman", ""], ["De Berg", "Mark", ""], ["Buchin", "Kevin", ""], ["Gao", "Jie", ""], ["Loffler", "Maarten", ""], ["Nayyeri", "Amir", ""], ["Raichel", "Benjamin", ""], ["Sarkar", "Rik", ""], ["Wang", "Haotian", ""], ["Yang", "Hao-Tsung", ""]]}, {"id": "2005.03143", "submitter": "Milad Siami", "authors": "Milad Siami and Ali Jadbabaie", "title": "A Separation Theorem for Joint Sensor and Actuator Scheduling with\n  Guaranteed Performance Bounds", "comments": "arXiv admin note: text overlap with arXiv:1805.00606", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.MA cs.SY math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of jointly designing a sparse sensor and actuator\nschedule for linear dynamical systems while guaranteeing a control/estimation\nperformance that approximates the fully sensed/actuated setting. We further\nprove a separation principle, showing that the problem can be decomposed into\nfinding sensor and actuator schedules separately. However, it is shown that\nthis problem cannot be efficiently solved or approximated in polynomial, or\neven quasi-polynomial time for time-invariant sensor/actuator schedules;\ninstead, we develop deterministic polynomial-time algorithms for a time-varying\nsensor/actuator schedule with guaranteed approximation bounds. Our main result\nis to provide a polynomial-time joint actuator and sensor schedule that on\naverage selects only a constant number of sensors and actuators at each time\nstep, irrespective of the dimension of the system. The key idea is to sparsify\nthe controllability and observability Gramians while providing approximation\nguarantees for Hankel singular values. This idea is inspired by recent results\nin theoretical computer science literature on sparsification.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 21:25:38 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Siami", "Milad", ""], ["Jadbabaie", "Ali", ""]]}, {"id": "2005.03352", "submitter": "Felipe Maldonado", "authors": "Felipe Maldonado, Gerardo Berbeglia and Pascal Van Hentenryck", "title": "Pricing under a multinomial logit model with non linear network effects", "comments": "18 pages plus 9 pages appendix, 7 figures. Working paper, to be\n  submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the problem of pricing under a Multinomial Logit model where we\nincorporate network effects over the consumer's decisions. We analyse both\ncases, when sellers compete or collaborate. In particular, we pay special\nattention to the overall expected revenue and how the behaviour of the no\npurchase option is affected under variations of a network effect parameter.\nWhere for example we prove that the market share for the no purchase option, is\ndecreasing in terms of the value of the network effect, meaning that stronger\ncommunication among costumers increases the expected amount of sales. We also\nanalyse how the customer's utility is altered when network effects are\nincorporated into the market, comparing the cases where both competitive and\nmonopolistic prices are displayed. We use tools from stochastic approximation\nalgorithms to prove that the probability of purchasing the available products\nconverges to a unique stationary distribution. We model that the sellers can\nuse this stationary distribution to establish their strategies. Finding that\nunder those settings, a pure Nash Equilibrium represents the pricing strategies\nin the case of competition, and an optimal (that maximises the total revenue)\nfixed price characterise the case of collaboration.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 09:37:56 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Maldonado", "Felipe", ""], ["Berbeglia", "Gerardo", ""], ["Van Hentenryck", "Pascal", ""]]}, {"id": "2005.04007", "submitter": "Enrico Ronchi", "authors": "Enrico Ronchi, Ruggiero Lovreglio", "title": "EXPOSED: An occupant exposure model for confined spaces to retrofit\n  crowd models during a pandemic", "comments": null, "journal-ref": "Safety Science, 2020", "doi": "10.1016/j.ssci.2020.104834", "report-no": null, "categories": "physics.soc-ph cs.CY cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crowd models can be used for the simulation of people movement in the built\nenvironment. Crowd model outputs have been used for evaluating safety and\ncomfort of pedestrians, inform crowd management and perform forensic\ninvestigations. Microscopic crowd models allow the representation of each\nperson and the obtainment of information concerning their location over time\nand interactions with the physical space/other people. Pandemics such as\nCOVID-19 have posed several questions on safe building usage, given the risk of\ndisease transmission among building occupants. Here we show how crowd modelling\ncan be used to assess occupant exposure in confined spaces. The policies\nadopted concerning building usage and social distancing during a pandemic can\nvary greatly, and they are mostly based on the macroscopic analysis of the\nspread of disease rather than a safety assessment performed at a building\nlevel. The proposed model allows the investigation of occupant exposure in\nbuildings based on the analysis of microscopic people movement. Risk assessment\nis performed by retrofitting crowd models with a universal model for exposure\nassessment which can account for different types of disease transmissions. This\nwork allows policy makers to perform informed decisions concerning building\nusage during a pandemic.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 13:00:19 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Ronchi", "Enrico", ""], ["Lovreglio", "Ruggiero", ""]]}, {"id": "2005.04455", "submitter": "Martin Kouteck\\'y", "authors": "Martin Kouteck\\'y, Nimrod Talmon", "title": "Multi-Party Campaigning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.DS cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a social choice setting of manipulation in elections and extend the\nusual model in two major ways: first, instead of considering a single\nmanipulating agent, in our setting there are several, possibly competing ones;\nsecond, instead of evaluating an election after the first manipulative action,\nwe allow several back-and-forth rounds to take place. We show that in certain\nsituations, such as in elections with only a few candidates, optimal strategies\nfor each of the manipulating agents can be computed efficiently.\n  Our algorithmic results rely on formulating the problem of finding an optimal\nstrategy as sentences of Presburger arithmetic that are short and only involve\nsmall coefficients, which we show is fixed-parameter tractable -- indeed, one\nof our contributions is a general result regarding fixed-parameter tractability\nof Presburger arithmetic that might be useful in other settings. Following our\ngeneral theorem, we design quite general algorithms; in particular, we describe\nhow to design efficient algorithms for various settings, including settings in\nwhich we model diffusion of opinions in a social network, complex budgeting\nschemes available to the manipulating agents, and various realistic\nrestrictions on adversary actions.\n", "versions": [{"version": "v1", "created": "Sat, 9 May 2020 14:45:01 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Kouteck\u00fd", "Martin", ""], ["Talmon", "Nimrod", ""]]}, {"id": "2005.04694", "submitter": "Bayu Jayawardhana", "authors": "Nelson P.K. Chan, Bayu Jayawardhana, Hector Garcia de Marina", "title": "Angle-Constrained Formation Control for Circular Mobile Robots", "comments": "6 pages, submitted to the 59th IEEE Conf. Dec. Control and IEEE\n  Control Systems Letters", "journal-ref": null, "doi": "10.1109/LCSYS.2020.3000061", "report-no": null, "categories": "eess.SY cs.MA cs.RO cs.SY math.OC", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this letter, we investigate the formation control problem of mobile robots\nmoving in the plane where, instead of assuming robots to be simple points, each\nrobot is assumed to have the form of a disk with equal radius. Based on\ninterior angle measurements of the neighboring robots' disk, which can be\nobtained from low-cost vision sensors, we propose a gradient-based distributed\ncontrol law and show the exponential convergence property of the associated\nerror system. By construction, the proposed control law has the appealing\nproperty of ensuring collision avoidance between neighboring robots. We also\npresent simulation results for {a team} of four circular mobile robots forming\na rectangular shape.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 15:20:52 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Chan", "Nelson P. K.", ""], ["Jayawardhana", "Bayu", ""], ["de Marina", "Hector Garcia", ""]]}, {"id": "2005.04855", "submitter": "Toby Walsh", "authors": "Toby Walsh", "title": "Fair Division: The Computer Scientist's Perspective", "comments": "To appear in Proceedings of IJCAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  I survey recent progress on a classic and challenging problem in social\nchoice: the fair division of indivisible items. I discuss how a computational\nperspective has provided interesting insights into and understanding of how to\ndivide items fairly and efficiently. This has involved bringing to bear tools\nsuch as those used in knowledge representation, computational complexity,\napproximation methods, game theory, online analysis and communication\ncomplexity\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 04:19:38 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Walsh", "Toby", ""]]}, {"id": "2005.05420", "submitter": "Zhe Liu", "authors": "Binyu Wang and Zhe Liu and Qingbiao Li and Amanda Prorok", "title": "Mobile Robot Path Planning in Dynamic Environments through Globally\n  Guided Reinforcement Learning", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Path planning for mobile robots in large dynamic environments is a\nchallenging problem, as the robots are required to efficiently reach their\ngiven goals while simultaneously avoiding potential conflicts with other robots\nor dynamic objects. In the presence of dynamic obstacles, traditional solutions\nusually employ re-planning strategies, which re-call a planning algorithm to\nsearch for an alternative path whenever the robot encounters a conflict.\nHowever, such re-planning strategies often cause unnecessary detours. To\naddress this issue, we propose a learning-based technique that exploits\nenvironmental spatio-temporal information. Different from existing\nlearning-based methods, we introduce a globally guided reinforcement learning\napproach (G2RL), which incorporates a novel reward structure that generalizes\nto arbitrary environments. We apply G2RL to solve the multi-robot path planning\nproblem in a fully distributed reactive manner. We evaluate our method across\ndifferent map types, obstacle densities, and the number of robots. Experimental\nresults show that G2RL generalizes well, outperforming existing distributed\nmethods, and performing very similarly to fully centralized state-of-the-art\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 20:42:29 GMT"}, {"version": "v2", "created": "Fri, 11 Sep 2020 21:14:15 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Wang", "Binyu", ""], ["Liu", "Zhe", ""], ["Li", "Qingbiao", ""], ["Prorok", "Amanda", ""]]}, {"id": "2005.05441", "submitter": "Baiming Chen", "authors": "Baiming Chen, Mengdi Xu, Zuxin Liu, Liang Li, Ding Zhao", "title": "Delay-Aware Multi-Agent Reinforcement Learning for Cooperative and\n  Competitive Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Action and observation delays exist prevalently in the real-world\ncyber-physical systems which may pose challenges in reinforcement learning\ndesign. It is particularly an arduous task when handling multi-agent systems\nwhere the delay of one agent could spread to other agents. To resolve this\nproblem, this paper proposes a novel framework to deal with delays as well as\nthe non-stationary training issue of multi-agent tasks with model-free deep\nreinforcement learning. We formally define the Delay-Aware Markov Game that\nincorporates the delays of all agents in the environment. To solve Delay-Aware\nMarkov Games, we apply centralized training and decentralized execution that\nallows agents to use extra information to ease the non-stationarity issue of\nthe multi-agent systems during training, without the need of a centralized\ncontroller during execution. Experiments are conducted in multi-agent particle\nenvironments including cooperative communication, cooperative navigation, and\ncompetitive experiments. We also test the proposed algorithm in traffic\nscenarios that require coordination of all autonomous vehicles to show the\npractical value of delay-awareness. Results show that the proposed delay-aware\nmulti-agent reinforcement learning algorithm greatly alleviates the performance\ndegradation introduced by delay. Codes and demo videos are available at:\nhttps://github.com/baimingc/delay-aware-MARL.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 21:21:50 GMT"}, {"version": "v2", "created": "Sat, 29 Aug 2020 01:27:43 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Chen", "Baiming", ""], ["Xu", "Mengdi", ""], ["Liu", "Zuxin", ""], ["Li", "Liang", ""], ["Zhao", "Ding", ""]]}, {"id": "2005.05516", "submitter": "Venkata Sriram Siddhardh Nadendla", "authors": "Doris E. M. Brown, Venkata Sriram Siddhardh Nadendla", "title": "Framing Effects on Strategic Information Design under Receiver Distrust\n  and Unknown State", "comments": "12 pages, 5 figures; This is a working draft, and can potentially\n  have errors. Any feedback will be greatly appreciated, and will be\n  acknowledged in the subsequent versions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.IR cs.MA cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Strategic information design is a framework where a sender designs\ninformation strategically to steer its receiver's decision towards a desired\nchoice. Traditionally, such frameworks have always assumed that the sender and\nthe receiver comprehends the state of the choice environment, and that the\nreceiver always trusts the sender's signal. This paper deviates from these\nassumptions and re-investigates strategic information design in the presence of\ndistrustful receiver and when both sender and receiver cannot\nobserve/comprehend the environment state space. Specifically, we assume that\nboth sender and receiver has access to non-identical beliefs about choice\nrewards (with sender's belief being more accurate), but not the environment\nstate that determines these rewards. Furthermore, given that the receiver does\nnot trust the sender, we also assume that the receiver updates its prior in a\nnon-Bayesian manner. We evaluate the Stackelberg equilibrium and investigate\neffects of information framing (i.e. send complete signal, or just expected\nvalue of the signal) on the equilibrium. Furthermore, we also investigate trust\ndynamics at the receiver, under the assumption that the receiver minimizes\nregret in hindsight. Simulation results are presented to illustrate signaling\neffects and trust dynamics in strategic information design.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 01:55:56 GMT"}, {"version": "v2", "created": "Wed, 21 Jul 2021 22:16:37 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Brown", "Doris E. M.", ""], ["Nadendla", "Venkata Sriram Siddhardh", ""]]}, {"id": "2005.05521", "submitter": "Venkata Sriram Siddhardh Nadendla", "authors": "Venkata Sriram Siddhardh Nadendla, Lav R. Varshney", "title": "A Difficulty in Controlling Blockchain Mining Costs via Cryptopuzzle\n  Difficulty", "comments": "8 pages. This is a working draft and can potentially have errors. Any\n  feedback will be greatly appreciated and will be acknowledged in the updated\n  version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CR cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockchain systems often employ proof-of-work consensus protocols to validate\nand add transactions into hashchains. These protocols stimulate competition\namong miners in solving cryptopuzzles (e.g. SHA-256 hash computation in\nBitcoin) in exchange for a monetary reward. Here, we model mining as an all-pay\nauction, where miners' computational efforts are interpreted as bids, and the\nallocation function is the probability of solving the cryptopuzzle in a single\nattempt with unit (normalized) computational capability. Such an allocation\nfunction captures how blockchain systems control the difficulty of the\ncryptopuzzle as a function of miners' computational abilities (bids). In an\nattempt to reduce mining costs, we investigate designing a mining auction\nmechanism which induces a logit equilibrium amongst the miners with choice\ndistributions that are unilaterally decreasing with costs at each miner. We\nshow it is impossible to design a lenient allocation function that does this.\nSpecifically, we show that there exists no allocation function that discourages\nminers to bid higher costs at logit equilibrium, if the rate of change of\ndifficulty with respect to each miner's cost is bounded by the inverse of the\nsum of costs at all the miners.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 02:07:06 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Nadendla", "Venkata Sriram Siddhardh", ""], ["Varshney", "Lav R.", ""]]}, {"id": "2005.05874", "submitter": "Tania Panayiotou", "authors": "Tania Panayiotou and Georgios Ellinas", "title": "Fair Resource Allocation in Optical Networks under Tidal Traffic", "comments": "accepted for presentation at the IEEE GLOBECOM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an alpha-fair routing and spectrum allocation (RSA) framework for\nreconfigurable elastic optical networks under modeled tidal traffic, that is\nbased on the maximization of the social welfare function parameterized by a\nscalar alpha (the inequality aversion parameter). The objective is to\napproximate an egalitarian spectrum allocation (SA) that maximizes the minimum\npossible SA over all connections contending for the network resources, shifting\nfrom the widely used utilitarian SA that merely maximizes the network\nefficiency. A set of existing metrics are examined (i.e., connection blocking,\nresource utilization, coefficient of variation (CV) of utilities), and a set of\nnew measures are also introduced (i.e., improvement on connection over- (COP)\nand under-provisioning (CUP), CV of unserved traffic), allowing a network\noperator to derive and evaluate in advance a set of alpha-fair RSA solutions\nand select the one that best fits the performance requirements of both the\nindividual connections and the overall network. We show that an egalitarian SA\nbetter utilizes the network resources by significantly improving both COP (up\nto 20%) and CUP (up to 80%), compared to the utilitarian allocation, while\nattaining zero blocking. Importantly, the CVs of utilities and unserved traffic\nindicate that a SA that is fairest with respect to the amount of utilities\nallocated to the connections does not imply that the SA is also fairest with\nrespect to the achievable QoS of the connections, while an egalitarian SA\nbetter approximates a fairest QoS-based SA.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 15:48:44 GMT"}, {"version": "v2", "created": "Wed, 13 May 2020 06:11:53 GMT"}, {"version": "v3", "created": "Sun, 31 May 2020 08:23:47 GMT"}, {"version": "v4", "created": "Sat, 5 Dec 2020 08:03:46 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Panayiotou", "Tania", ""], ["Ellinas", "Georgios", ""]]}, {"id": "2005.06261", "submitter": "Ehud Shapiro", "authors": "Luca Cardelli, Liav Orgad, Gal Shahaf, Ehud Shapiro and Nimrod Talmon", "title": "Digital Social Contracts: A Foundation for an Egalitarian and Just\n  Digital Society", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.MA cs.PL cs.SI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Almost two centuries ago Pierre-Joseph Proudhon proposed social contracts --\nvoluntary agreements among free people -- as a foundation from which an\negalitarian and just society can emerge. A \\emph{digital social contract} is\nthe novel incarnation of this concept for the digital age: a voluntary\nagreement between people that is specified, undertaken, and fulfilled in the\ndigital realm. It embodies the notion of \"code-is-law\" in its purest form, in\nthat a digital social contract is in fact a program -- code in a social\ncontracts programming language, which specifies the digital actions parties to\nthe social contract may take; and the parties to the contract are entrusted,\nequally, with the task of ensuring that each party abides by the contract.\nParties to a social contract are identified via their public keys, and the one\nand only type of action a party to a digital social contract may take is a\n\"digital speech act\" -- signing an utterance with her private key and sending\nit to the other parties to the contract. Here, we present a formal definition\nof a digital social contract as agents that communicate asynchronously via\ncrypto-speech acts, where the output of each agent is the input of all the\nother agents. We outline an abstract design for a social contracts programming\nlanguage and show, via programming examples, that key application areas,\nincluding social community; simple sharing-economy applications; egalitarian\ncurrency networks; and democratic community governance, can all be expressed\nelegantly and efficiently as digital social contracts.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 11:45:49 GMT"}, {"version": "v2", "created": "Mon, 18 May 2020 09:40:06 GMT"}, {"version": "v3", "created": "Fri, 26 Jun 2020 09:34:56 GMT"}, {"version": "v4", "created": "Wed, 1 Jul 2020 22:33:03 GMT"}, {"version": "v5", "created": "Sun, 19 Jul 2020 18:42:36 GMT"}, {"version": "v6", "created": "Thu, 17 Sep 2020 08:39:43 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Cardelli", "Luca", ""], ["Orgad", "Liav", ""], ["Shahaf", "Gal", ""], ["Shapiro", "Ehud", ""], ["Talmon", "Nimrod", ""]]}, {"id": "2005.07156", "submitter": "Jack Reinhardt", "authors": "Jack Reinhardt", "title": "Competing in a Complex Hidden Role Game with Information Set Monte Carlo\n  Tree Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Advances in intelligent game playing agents have led to successes in perfect\ninformation games like Go and imperfect information games like Poker. The\nInformation Set Monte Carlo Tree Search (ISMCTS) family of algorithms\noutperforms previous algorithms using Monte Carlo methods in imperfect\ninformation games. In this paper, Single Observer Information Set Monte Carlo\nTree Search (SO-ISMCTS) is applied to Secret Hitler, a popular social deduction\nboard game that combines traditional hidden role mechanics with the randomness\nof a card deck. This combination leads to a more complex information model than\nthe hidden role and card deck mechanics alone. It is shown in 10108 simulated\ngames that SO-ISMCTS plays as well as simpler rule based agents, and\ndemonstrates the potential of ISMCTS algorithms in complicated information set\ndomains.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 17:21:10 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Reinhardt", "Jack", ""]]}, {"id": "2005.07303", "submitter": "Jack Henderson", "authors": "Jack Henderson, Jochen Trumpf, Mohammad Zamani", "title": "A Minimum Energy Filter for Distributed Multirobot Localisation", "comments": "To be published at 21st IFAC World Congress, Berlin, Germany, July\n  12-17, 2020", "journal-ref": null, "doi": "10.1016/j.ifacol.2020.12.1068", "report-no": null, "categories": "eess.SY cs.MA cs.RO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new approach to the cooperative localisation problem by applying\nthe theory of minimum energy filtering. We consider the problem of estimating\nthe pose of a group of mobile robots in an environment where robots can\nperceive fixed landmarks and neighbouring robots as well as share information\nwith others over a communication channel. Whereas the vast majority of the\nexisting literature applies some variant of a Kalman Filter, we derive a set of\nfilter equations for the global state estimate based on the principle of\nminimum energy filtering. We show how the filter equations can be decoupled and\nthe calculations distributed among the robots in the network without requiring\na central processing node. Finally, we provide a demonstration of the filter's\nperformance in simulation.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 00:21:10 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Henderson", "Jack", ""], ["Trumpf", "Jochen", ""], ["Zamani", "Mohammad", ""]]}, {"id": "2005.07371", "submitter": "Jiaoyang Li", "authors": "Jiaoyang Li, Andrew Tinka, Scott Kiesel, Joseph W. Durham, T. K.\n  Satish Kumar and Sven Koenig", "title": "Lifelong Multi-Agent Path Finding in Large-Scale Warehouses", "comments": "Published at AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-Agent Path Finding (MAPF) is the problem of moving a team of agents to\ntheir goal locations without collisions. In this paper, we study the lifelong\nvariant of MAPF, where agents are constantly engaged with new goal locations,\nsuch as in large-scale automated warehouses. We propose a new framework\nRolling-Horizon Collision Resolution (RHCR) for solving lifelong MAPF by\ndecomposing the problem into a sequence of Windowed MAPF instances, where a\nWindowed MAPF solver resolves collisions among the paths of the agents only\nwithin a bounded time horizon and ignores collisions beyond it. RHCR is\nparticularly well suited to generating pliable plans that adapt to continually\narriving new goal locations. We empirically evaluate RHCR with a variety of\nMAPF solvers and show that it can produce high-quality solutions for up to\n1,000 agents (= 38.9\\% of the empty cells on the map) for simulated warehouse\ninstances, significantly outperforming existing work.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 06:07:15 GMT"}, {"version": "v2", "created": "Fri, 12 Mar 2021 18:56:15 GMT"}], "update_date": "2021-03-15", "authors_parsed": [["Li", "Jiaoyang", ""], ["Tinka", "Andrew", ""], ["Kiesel", "Scott", ""], ["Durham", "Joseph W.", ""], ["Kumar", "T. K. Satish", ""], ["Koenig", "Sven", ""]]}, {"id": "2005.07697", "submitter": "Wenbin Wan", "authors": "Wenbin Wan, Hunmin Kim, Yikun Cheng, Naira Hovakimyan, Petros G.\n  Voulgaris and Lui Sha", "title": "Safety Constrained Multi-UAV Time Coordination: A Bi-level Control\n  Framework in GPS Denied Environment", "comments": "arXiv admin note: substantial text overlap with arXiv:1910.10826", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unmanned aerial vehicles (UAVs) suffer from sensor drifts in GPS denied\nenvironments, which can cause safety issues. To avoid intolerable sensor drifts\nwhile completing the time-critical coordination task for multi-UAV systems, we\npropose a safety constrained bi-level control framework. The first level is the\ntime-critical coordination level that achieves a consensus of coordination\nstates and provides a virtual target which is a function of the coordination\nstate. The second level is the safety-critical control level that is designed\nto follow the virtual target while adapting the attacked UAV(s) at a path\nre-planning level to support resilient state estimation. In particular, the\ntime-critical coordination level framework generates the desired speed and\nposition profile of the virtual target based on the multi-UAV cooperative\nmission by the proposed consensus protocol algorithm. The safety-critical\ncontrol level is able to make each UAV follow its assigned path while detecting\nthe attacks, estimating the state resiliently, and driving the UAV(s) outside\nthe effective range of the spoofing device within the escape time. The\nnumerical simulations of a three-UAV system demonstrate the effectiveness of\nthe proposed safety constrained bi-level control framework.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 01:06:31 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 04:48:31 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Wan", "Wenbin", ""], ["Kim", "Hunmin", ""], ["Cheng", "Yikun", ""], ["Hovakimyan", "Naira", ""], ["Voulgaris", "Petros G.", ""], ["Sha", "Lui", ""]]}, {"id": "2005.08153", "submitter": "Zhuoyuan Song", "authors": "Sachin Shriwastav and Zhuoyuan Song", "title": "Coordinated Coverage and Fault Tolerance using Fixed-Wing Unmanned\n  Aerial Vehicles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an approach for deploying and maintaining a fleet of\nhomogeneous fixed-wing unmanned aerial vehicles (UAVs) for all-time coverage of\nan area. Two approaches for loiter circle packing have been presented: square\nand hexagon packing, and the benefits of hexagon packing for minimizing the\nnumber of deployed UAVs have been shown. Based on the number of UAVs available\nand the desired loitering altitude, the proposed algorithm solves an\noptimization problem to calculate the centres of the loitering circles and the\nloitering radius for that altitude. The algorithm also incorporates fault\nrecovery capacity in case of simultaneous multiple UAV failures. These failures\ncould form clusters of survivor (active) UAVs over the area with no overall\nsurvivor information. The algorithm deploys a super-agent with a larger\ncommunication capacity at a higher altitude to recover from the failure. The\nsuper-agent collects the information of survivors, and updates the homogeneous\nradius and the locations of the loitering circles at the same altitude to\nrestore the full coverage. The individual survivor UAVs are then informed and\ntransit to the new loitering circles using Dubin's paths. The relationship with\nthe extent of recoverable loss fractions of the deployed UAVs have been\nanalysed for varying the initial loiter radii. Simulation results have been\npresented to demonstrate the applicability of the approach and compare the two\npresented packing approaches.\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2020 03:03:30 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Shriwastav", "Sachin", ""], ["Song", "Zhuoyuan", ""]]}, {"id": "2005.08633", "submitter": "Peter Hillmann", "authors": "Peter Hillmann, Bastian K\\\"uhnel, Tobias Uhlig, Gabi Dreo Rodosek, and\n  Oliver Rose", "title": "Optimized Travel to Meetings on a Common Location of Geographical\n  Distributed Participants", "comments": "International Conference on Service Operations and Logistics, and\n  Informatics, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.CY cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Members of international organizations often meet in person at a common\nlocation for discussions. There is frequently disagreement over the place and\ntime of the meeting due to the different travel efforts of the members. They\nusually travel by plane and their travel expenses depend on the flight\nconnections. This paper presents an approach to calculate the optimized\nlocation and time, where and when distributed partners should meet. The\npresented system considers the requirements and specifications of each\nindividual member. It respects earliest starting time of an event and non night\nflights. The optimized result is evaluated with regard to multiple objectives.\nWe focus on the minimization of costs and travel time. Our search algorithm\nidentifies individual travel data for all members for a potential event. The\noutput provides recommendations for the global best appointments and offers\nfurther information for the partners. Our system saves expenses and time for\nall members and allows adjustment as well as compensation.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 07:54:28 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Hillmann", "Peter", ""], ["K\u00fchnel", "Bastian", ""], ["Uhlig", "Tobias", ""], ["Rodosek", "Gabi Dreo", ""], ["Rose", "Oliver", ""]]}, {"id": "2005.09408", "submitter": "Filippo Fabiani", "authors": "Filippo Fabiani, Kostas Margellos, Paul J. Goulart", "title": "On the robustness of equilibria in generalized aggregative games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.GT cs.MA cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of assessing the robustness of the equilibria in\nuncertain, multi-agent games. Specifically, we focus on generalized Nash\nequilibrium problems in aggregative form subject to linear coupling constraints\naffected by uncertainty with a possibly unknown probability distribution.\nWithin a data-driven context, we apply the scenario approach paradigm to\nprovide a-posteriori feasibility certificates for the entire set of generalized\nNash equilibria of the game. Then, we show that assessing the violation\nprobability of such set merely requires to enumerate the constraints that\n``shape'' it. For the class of aggregative games, this results in solving a\nfeasibility problem on each active facet of the feasibility region, for which\nwe propose a semi-decentralized algorithm. We demonstrate our theoretical\nresults by means of an academic example.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 13:05:51 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Fabiani", "Filippo", ""], ["Margellos", "Kostas", ""], ["Goulart", "Paul J.", ""]]}, {"id": "2005.09453", "submitter": "Zhenhui Ye", "authors": "Zhenhui Ye, Yining Chen, Guanghua Song, Bowei Yang, Shen Fan", "title": "Experience Augmentation: Boosting and Accelerating Off-Policy\n  Multi-Agent Reinforcement Learning", "comments": "10 pages, 4 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploration of the high-dimensional state action space is one of the biggest\nchallenges in Reinforcement Learning (RL), especially in multi-agent domain. We\npresent a novel technique called Experience Augmentation, which enables a\ntime-efficient and boosted learning based on a fast, fair and thorough\nexploration to the environment. It can be combined with arbitrary off-policy\nMARL algorithms and is applicable to either homogeneous or heterogeneous\nenvironments. We demonstrate our approach by combining it with MADDPG and\nverifing the performance in two homogeneous and one heterogeneous environments.\nIn the best performing scenario, the MADDPG with experience augmentation\nreaches to the convergence reward of vanilla MADDPG with 1/4 realistic time,\nand its convergence beats the original model by a significant margin. Our\nablation studies show that experience augmentation is a crucial ingredient\nwhich accelerates the training process and boosts the convergence.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 13:57:11 GMT"}, {"version": "v2", "created": "Wed, 20 May 2020 02:12:08 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Ye", "Zhenhui", ""], ["Chen", "Yining", ""], ["Song", "Guanghua", ""], ["Yang", "Bowei", ""], ["Fan", "Shen", ""]]}, {"id": "2005.09460", "submitter": "Carole Adam", "authors": "Carole Adam", "title": "VigiFlood: evaluating the impact of a change of perspective on flood\n  vigilance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emergency managers receive communication training about the importance of\nbeing 'first, right and credible', and taking into account the psychology of\ntheir audience and their particular reasoning under stress and risk. But we\nbelieve that citizens should be similarly trained about how to deal with risk\ncommunication. In particular, such messages necessarily carry a part of\nuncertainty since most natural risks are difficult to accurately forecast ahead\nof time. Yet, citizens should keep trusting the emergency communicators even\nafter they made forecasting errors in the past.\n  We have designed a serious game called Vigiflood, based on a real case study\nof flash floods hitting the South West of France in October 2018. In this game,\nthe user changes perspective by taking the role of an emergency communicator,\nhaving to set the level of vigilance to alert the population, based on\nuncertain clues. Our hypothesis is that this change of perspective can improve\nthe player's awareness and response to future flood vigilance announcements. We\nevaluated this game through an online survey where people were asked to answer\na questionnaire about flood risk awareness and behavioural intentions before\nand after playing the game, in order to assess its impact.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 14:05:11 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Adam", "Carole", ""]]}, {"id": "2005.10007", "submitter": "Juste Raimbault", "authors": "Juste Raimbault and Eric Denis and Denise Pumain", "title": "Empowering Urban Governance through Urban Science: Multi-scale Dynamics\n  of Urban Systems Worldwide", "comments": "25 pages, 9 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.CY cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current science of cities can provide a useful foundation for future\nurban policies, provided that these proposals have been validated by correct\nobservations of the diversity of situations in the world. However,\ninternational comparisons of the evolution of cities often produce uncertain\nresults because national territorial frameworks are not always in strict\ncorrespondence with the dynamics of urban systems. We propose to provide\nvarious compositions of systems of cities to better take into account the\ndynamic networking of cities that go beyond regional and national territorial\nboundaries. Different models conceived for explaining city size and urban\ngrowth distributions enable to establish a correspondence between urban\ntrajectories when observed at the level of cities and systems of cities. We\ntest the validity and representativeness of several dynamic models of complex\nurban systems and their variations across regions of the world, at the\nmacroscopic scale of systems of cities. The originality of the approach is in\nconsidering spatial interaction and evolutionary path dependence as major\nfeatures in the general behavior of urban entities. The models studied include\ndiverse and complementary processes, such as economic exchanges, diffusion of\ninnovations and physical network flows. Complex systems' dynamics is in\nprinciple unpredictable, but contextualizing it regarding demographic, income\nand resource components may help in minimizing the forecasting errors.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 12:47:40 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Raimbault", "Juste", ""], ["Denis", "Eric", ""], ["Pumain", "Denise", ""]]}, {"id": "2005.10161", "submitter": "Mu Mu", "authors": "Mu Mu, Murtada Dohan, Alison Goodyear, Gary Hill, Cleyon Johns, and\n  Andreas Mauthe", "title": "User Attention and Behaviour in Virtual Reality Art Encounter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.MA cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the proliferation of consumer virtual reality (VR) headsets and creative\ntools, content creators have started to experiment with new forms of\ninteractive audience experience using immersive media. Understanding user\nattention and behaviours in virtual environment can greatly inform creative\nprocesses in VR. We developed an abstract VR painting and an experimentation\nsystem to study audience encounters through eye gaze and movement tracking. The\ndata from a user experiment with 35 participants reveal a range of user\nactivity patterns in art exploration. Deep learning models are used to study\nthe connections between behavioural data and audience background. New\nintegrated methods to visualise user attention as part of the artwork are also\ndeveloped as a feedback loop to the content creator.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 16:09:57 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Mu", "Mu", ""], ["Dohan", "Murtada", ""], ["Goodyear", "Alison", ""], ["Hill", "Gary", ""], ["Johns", "Cleyon", ""], ["Mauthe", "Andreas", ""]]}, {"id": "2005.10297", "submitter": "Joseph Y. Halpern", "authors": "Natasha Alechina, Joseph Y. Halpern, and Brian Logan", "title": "Causality, Responsibility and Blame in Team Plans", "comments": "{\\em Proceedings of the Sixteenth Appears in \\emph{Proceedings of the\n  International Joint Conference on Autonomous Agents and Multiagent Systems\n  (AAMAS 2017)}, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many objectives can be achieved (or may be achieved more effectively) only by\na group of agents executing a team plan. If a team plan fails, it is often of\ninterest to determine what caused the failure, the degree of responsibility of\neach agent for the failure, and the degree of blame attached to each agent. We\nshow how team plans can be represented in terms of structural equations, and\nthen apply the definitions of causality introduced by Halpern [2015] and degree\nof responsibility and blame introduced by Chockler and Halpern [2004] to\ndetermine the agent(s) who caused the failure and what their degree of\nresponsibility/blame is. We also prove new results on the complexity of\ncomputing causality and degree of responsibility and blame, showing that they\ncan be determined in polynomial time for many team plans of interest.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 18:21:19 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Alechina", "Natasha", ""], ["Halpern", "Joseph Y.", ""], ["Logan", "Brian", ""]]}, {"id": "2005.10346", "submitter": "Alexander Kell Mr", "authors": "Alexander J. M. Kell, Matthew Forshaw, A. Stephen McGough", "title": "Long-term electricity market agent based model validation using genetic\n  algorithm based optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electricity market modelling is often used by governments, industry and\nagencies to explore the development of scenarios over differing timeframes. For\nexample, how would the reduction in cost of renewable energy impact investments\nin gas power plants or what would be an optimum strategy for carbon tax or\nsubsidies? Cost optimization based solutions are the dominant approach for\nunderstanding different long-term energy scenarios. However, these types of\nmodels have certain limitations such as the need to be interpreted in a\nnormative manner, and the assumption that the electricity market remains in\nequilibrium throughout. Through this work, we show that agent-based models are\na viable technique to simulate decentralised electricity markets. The aim of\nthis paper is to validate an agent-based modelling framework to increase\nconfidence in its ability to be used in policy and decision making. Our\nframework can model heterogeneous agents with imperfect information. The model\nuses a rules-based approach to approximate the underlying dynamics of a real\nworld, decentralised electricity market. We use the UK as a case study,\nhowever, our framework is generalisable to other countries. We increase the\ntemporal granularity of the model by selecting representative days of\nelectricity demand and weather using a $k$-means clustering approach. We show\nthat our framework can model the transition from coal to gas observed in the UK\nbetween 2013 and 2018. We are also able to simulate a future scenario to 2035\nwhich is similar to the UK Government, Department for Business and Industrial\nStrategy (BEIS) projections. We show a more realistic increase in nuclear power\nover this time period. This is due to the fact that with current nuclear\ntechnology, electricity is generated almost instantaneously and has a low\nshort-run marginal cost \\cite{Department2016}.\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2020 10:30:58 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Kell", "Alexander J. M.", ""], ["Forshaw", "Matthew", ""], ["McGough", "A. Stephen", ""]]}, {"id": "2005.10738", "submitter": "Bruno Perez", "authors": "Bruno Perez, Julien Henriet, Christophe Lang, Laurent Philippe", "title": "Multi-agent model for risk prediction in surgery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Risk management resulting from the actions and states of the different\nelements making up a operating room is a major concern during a surgical\nprocedure. Agent-based simulation shows an interest through its interaction\nconcepts, interactivity and autonomy of different simulator entities. We want\nin our study to implement a generator of alerts to listen the evolution of\ndifferent settings applied to the simulator of agents (human fatigue, material\nefficiency, infection rate ...). This article presents our model, its\nimplementation and the first results obtained. It should be noted that this\nstudy also made it possible to identify several scientific obstacles, such as\nthe integration of different levels of abstraction, the coupling of species,\nthe coexistence of several scales in the same environment and the deduction of\nunpredictable alerts. Case-based reasoning (CBR) is a beginning of response\nrelative to the last lock mentioned and will be discussed in this paper.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 15:45:27 GMT"}, {"version": "v2", "created": "Wed, 22 Jul 2020 13:39:15 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Perez", "Bruno", ""], ["Henriet", "Julien", ""], ["Lang", "Christophe", ""], ["Philippe", "Laurent", ""]]}, {"id": "2005.11429", "submitter": "Aron Laszka", "authors": "Scott Eisele and Taha Eghtesad and Nicholas Troutman and Aron Laszka\n  and Abhishek Dubey", "title": "Mechanisms for Outsourcing Computation via a Decentralized Market", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the number of personal computing and IoT devices grows rapidly, so does\nthe amount of computational power that is available at the edge. Since many of\nthese devices are often idle, there is a vast amount of computational power\nthat is currently untapped, and which could be used for outsourcing\ncomputation. Existing solutions for harnessing this power, such as volunteer\ncomputing (e.g., BOINC), are centralized platforms in which a single\norganization or company can control participation and pricing. By contrast, an\nopen market of computational resources, where resource owners and resource\nusers trade directly with each other, could lead to greater participation and\nmore competitive pricing. To provide an open market, we introduce MODiCuM, a\ndecentralized system for outsourcing computation. MODiCuM deters participants\nfrom misbehaving-which is a key problem in decentralized systems-by resolving\ndisputes via dedicated mediators and by imposing enforceable fines. However,\nunlike other decentralized outsourcing solutions, MODiCuM minimizes\ncomputational overhead since it does not require global trust in mediation\nresults. We provide analytical results proving that MODiCuM can deter\nmisbehavior, and we evaluate the overhead of MODiCuM using experimental results\nbased on an implementation of our platform.\n", "versions": [{"version": "v1", "created": "Sat, 23 May 2020 00:00:19 GMT"}, {"version": "v2", "created": "Sun, 19 Jul 2020 16:18:21 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Eisele", "Scott", ""], ["Eghtesad", "Taha", ""], ["Troutman", "Nicholas", ""], ["Laszka", "Aron", ""], ["Dubey", "Abhishek", ""]]}, {"id": "2005.11853", "submitter": "Deepanshu Vasal", "authors": "Rajesh K Mishra, Deepanshu Vasal, and Sriram Vishwanath", "title": "Model-free Reinforcement Learning for Stochastic Stackelberg Security\n  Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider a sequential stochastic Stackelberg game with two\nplayers, a leader and a follower. The follower has access to the state of the\nsystem while the leader does not. Assuming that the players act in their\nrespective best interests, the follower's strategy is to play the best response\nto the leader's strategy. In such a scenario, the leader has the advantage of\ncommitting to a policy which maximizes its own returns given the knowledge that\nthe follower is going to play the best response to its policy. Thus, both\nplayers converge to a pair of policies that form the Stackelberg equilibrium of\nthe game. Recently,~[1] provided a sequential decomposition algorithm to\ncompute the Stackelberg equilibrium for such games which allow for the\ncomputation of Markovian equilibrium policies in linear time as opposed to\ndouble exponential, as before. In this paper, we extend the idea to an MDP\nwhose dynamics are not known to the players, to propose an RL algorithm based\non Expected Sarsa that learns the Stackelberg equilibrium policy by simulating\na model of the MDP. We use particle filters to estimate the belief update for a\ncommon agent which computes the optimal policy based on the information which\nis common to both the players. We present a security game example to illustrate\nthe policy learned by our algorithm. by simulating a model of the MDP. We use\nparticle filters to estimate the belief update for a common agent which\ncomputes the optimal policy based on the information which is common to both\nthe players. We present a security game example to illustrate the policy\nlearned by our algorithm.\n", "versions": [{"version": "v1", "created": "Sun, 24 May 2020 22:34:20 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Mishra", "Rajesh K", ""], ["Vasal", "Deepanshu", ""], ["Vishwanath", "Sriram", ""]]}, {"id": "2005.12214", "submitter": "Emmanuel Sin", "authors": "Emmanuel Sin, He Yin and Murat Arcak", "title": "Passivity-based distributed acquisition and station-keeping control of a\n  satellite constellation in areostationary orbit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a distributed control law to assemble a cluster of satellites into\nan equally-spaced, planar constellation in a desired circular orbit about a\nplanet. We assume each satellite only uses local information, transmitted\nthrough communication links with neighboring satellites. The same control law\nis used to maintain relative angular positions in the presence of disturbance\nforces. The stability of the constellation in the desired orbit is proved using\na compositional approach. We first show the existence and uniqueness of an\nequilibrium of the interconnected system. We then certify each satellite and\ncommunication link is equilibrium-independent passive with respective storage\nfunctions. By leveraging the skew symmetric coupling structure of the\nconstellation and the equilibrium-independent passivity property of each\nsubsystem, we show that the equilibrium of the interconnected system is stable\nwith a Lyapunov function composed of the individual subsystem storage\nfunctions. We further prove that the angular velocity of each satellite\nconverges to the desired value necessary to maintain circular, areostationary\norbit. Finally, we present simulation results to demonstrate the efficacy of\nthe proposed control law in acquisition and station-keeping of an\nequally-spaced satellite constellation in areostationary orbit despite the\npresence of unmodeled disturbance forces.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 16:32:38 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Sin", "Emmanuel", ""], ["Yin", "He", ""], ["Arcak", "Murat", ""]]}, {"id": "2005.12226", "submitter": "Emmanuel Sin", "authors": "Emmanuel Sin, Murat Arcak, Andrew Packard, Douglas Philbrick, Peter\n  Seiler", "title": "Optimal assignment of collaborating agents in multi-body asset-guarding\n  games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a multi-body asset-guarding game in missile defense where teams of\ninterceptor missiles collaborate to defend a non-manuevering asset against a\ngroup of threat missiles. We approach the problem in two steps. We first\nformulate an assignment problem where we optimally assign subsets of\ncollaborating interceptors to each threat so that all threats are intercepted\nas far away from the asset as possible. We assume that each interceptor is\ncontrolled by a collaborative guidance law derived from linear quadratic\ndynamic games. Our results include a 6-DOF simulation of a 5-interceptor versus\n3-threat missile engagement where each agent is modeled as a missile airframe\ncontrolled by an autopilot. Despite the assumption of linear dynamics in our\ncollaborative guidance law and the unmodeled dynamics in the simulation\nenvironment (e.g., varying density and gravity), we show that the simulated\ntrajectories match well with those predicted by our approach. Furthermore, we\nshow that a more agile threat, with greater speed and acceleration, can be\nintercepted by inferior interceptors when they collaborate. We believe the\nconcepts introduced in this paper may be applied in asymmetric missile defense\nscenarios, including defense against advanced cruise missiles and hypersonic\nvehicles.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 16:57:05 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Sin", "Emmanuel", ""], ["Arcak", "Murat", ""], ["Packard", "Andrew", ""], ["Philbrick", "Douglas", ""], ["Seiler", "Peter", ""]]}, {"id": "2005.12547", "submitter": "Gabriele Bernardini", "authors": "Marco D'Orazio, Gabriele Bernardini, Enrico Quagliarini", "title": "Sustainable and resilient strategies for touristic cities against\n  COVID-19: an agent-based approach", "comments": "21 pages; 16 figures; 3 tables; submitted to Safety Science", "journal-ref": null, "doi": "10.1016/j.ssci.2021.105399", "report-no": null, "categories": "physics.soc-ph cs.CY cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Touristic cities will suffer from COVID-19 emergency because of its economic\nimpact on their communities. The first emergency phases involved a wide closure\nof such areas to support \"social distancing\" measures (i.e. travels limitation;\nlockdown of (over)crowd-prone activities). In the second phase, individual's\nrisk-mitigation strategies (facial masks) could be properly linked to \"social\ndistancing\" to ensure re-opening touristic cities to visitors. Simulation tools\ncould support the effectiveness evaluation of risk-mitigation measures to look\nfor an economic and social optimum for activities restarting. This work\nmodifies an existing Agent-Based Model to estimate the virus spreading in\ntouristic areas, including tourists and residents' behaviours, movement and\nvirus effects on them according to a probabilistic approach. Consolidated\nproximity-based and exposure-time-based contagion spreading rules are included\naccording to international health organizations and previous calibration\nthrough experimental data. Effects of tourists' capacity (as \"social\ndistancing\"-based measure) and other strategies (i.e. facial mask\nimplementation) are evaluated depending on virus-related conditions (i.e.\ninitial infector percentages). An idealized scenario representing a significant\ncase study has been analysed to demonstrate the tool capabilities and compare\nthe effectiveness of those solutions. Results show that \"social distancing\"\nseems to be more effective at the highest infectors' rates, although represents\nan extreme measure with important economic effects. This measure loses its full\neffectiveness (on the community) as the infectors' rate decreases and\nindividuals' protection measures become predominant (facial masks). The model\ncould be integrated to consider other recurring issues on tourist-related\nfruition and schedule of urban spaces and facilities (e.g. cultural/leisure\nbuildings).\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 07:17:38 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["D'Orazio", "Marco", ""], ["Bernardini", "Gabriele", ""], ["Quagliarini", "Enrico", ""]]}, {"id": "2005.12553", "submitter": "Chang Wang", "authors": "Hao Chen, Chang Wang, Jian Huang, Jianxing Gong", "title": "Efficient Use of heuristics for accelerating XCS-based Policy Learning\n  in Markov Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT cs.MA cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Markov games, playing against non-stationary opponents with learning\nability is still challenging for reinforcement learning (RL) agents, because\nthe opponents can evolve their policies concurrently. This increases the\ncomplexity of the learning task and slows down the learning speed of the RL\nagents. This paper proposes efficient use of rough heuristics to speed up\npolicy learning when playing against concurrent learners. Specifically, we\npropose an algorithm that can efficiently learn explainable and generalized\naction selection rules by taking advantages of the representation of\nquantitative heuristics and an opponent model with an eXtended classifier\nsystem (XCS) in zero-sum Markov games. A neural network is used to model the\nopponent from their behaviors and the corresponding policy is inferred for\naction selection and rule evolution. In cases of multiple heuristic policies,\nwe introduce the concept of Pareto optimality for action selection. Besides,\ntaking advantages of the condition representation and matching mechanism of\nXCS, the heuristic policies and the opponent model can provide guidance for\nsituations with similar feature representation. Furthermore, we introduce an\naccuracy-based eligibility trace mechanism to speed up rule evolution, i.e.,\nclassifiers that can match the historical traces are reinforced according to\ntheir accuracy. We demonstrate the advantages of the proposed algorithm over\nseveral benchmark algorithms in a soccer and a thief-and-hunter scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 07:47:27 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Chen", "Hao", ""], ["Wang", "Chang", ""], ["Huang", "Jian", ""], ["Gong", "Jianxing", ""]]}, {"id": "2005.12623", "submitter": "Julian Portmann", "authors": "Sebastian Brandt, Julian Portmann, Jara Uitto", "title": "Tight Bounds for Deterministic High-Dimensional Grid Exploration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of exploring an oriented grid with autonomous agents\ngoverned by finite automata. In the case of a 2-dimensional grid, the question\nhow many agents are required to explore the grid, or equivalently, find a\nhidden treasure in the grid, is fully understood in both the synchronous and\nthe semi-synchronous setting. For higher dimensions, Dobrev, Narayanan,\nOpatrny, and Pankratov [ICALP'19] showed very recently that, surprisingly, a\n(small) constant number of agents suffices to find the treasure, independent of\nthe number of dimensions, thereby disproving a conjecture by Cohen, Emek,\nLouidor, and Uitto [SODA'17]. Dobrev et al. left as an open question whether\ntheir bounds on the number of agents can be improved. We answer this question\nin the affirmative for deterministic finite automata: we show that 3\nsynchronous and 4 semi-synchronous agents suffice to explore an $n$-dimensional\ngrid for any constant $n$. The bounds are optimal and notably, the matching\nlower bounds already hold in the 2-dimensional case.\n  Our techniques can also be used to make progress on other open questions\nasked by Dobrev et al.: we prove that 4 synchronous and 5 semi-synchronous\nagents suffice for polynomial-time exploration, and we show that, under a\nnatural assumption, 3 synchronous and 4 semi-synchronous agents suffice to\nexplore unoriented grids of arbitrary dimension (which, again, is tight).\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 10:48:00 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Brandt", "Sebastian", ""], ["Portmann", "Julian", ""], ["Uitto", "Jara", ""]]}, {"id": "2005.12649", "submitter": "Alistair Letcher", "authors": "Alistair Letcher", "title": "On the Impossibility of Global Convergence in Multi-Loss Optimization", "comments": "26 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.GT cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Under mild regularity conditions, gradient-based methods converge globally to\na critical point in the single-loss setting. This is known to break down for\nvanilla gradient descent when moving to multi-loss optimization, but can we\nhope to build some algorithm with global guarantees? We negatively resolve this\nopen problem by proving that desirable convergence properties cannot\nsimultaneously hold for any algorithm. Our result has more to do with the\nexistence of games with no satisfactory outcomes, than with algorithms per se.\nMore explicitly we construct a two-player game with zero-sum interactions whose\nlosses are both coercive and analytic, but whose only simultaneous critical\npoint is a strict maximum. Any 'reasonable' algorithm, defined to avoid strict\nmaxima, will therefore fail to converge. This is fundamentally different from\nsingle losses, where coercivity implies existence of a global minimum.\nMoreover, we prove that a wide range of existing gradient-based methods almost\nsurely have bounded but non-convergent iterates in a constructed zero-sum game\nfor suitably small learning rates. It nonetheless remains an open question\nwhether such behavior can arise in high-dimensional games of interest to ML\npractitioners, such as GANs or multi-agent RL.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 12:11:18 GMT"}, {"version": "v2", "created": "Sat, 3 Oct 2020 12:49:09 GMT"}, {"version": "v3", "created": "Sun, 17 Jan 2021 09:14:59 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Letcher", "Alistair", ""]]}, {"id": "2005.12712", "submitter": "Benedikt Kleinmeier", "authors": "Benedikt Kleinmeier, Gerta K\\\"oster, John Drury", "title": "Agent-Based Simulation of Collective Cooperation: From Experiment to\n  Model", "comments": "16 pages, 19 figures, 5 tables, 4 listings, interdisciplinary work\n  between computer science and psychology", "journal-ref": "Journal of the Royal Society Interface (October 2020, Volume 17,\n  Issue 171)", "doi": "10.1098/rsif.2020.0396", "report-no": null, "categories": "cs.MA cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Simulation models of pedestrian dynamics have become an invaluable tool for\nevacuation planning. Typically crowds are assumed to stream unidirectionally\ntowards a safe area. Simulated agents avoid collisions through mechanisms that\nbelong to each individual, such as being repelled from each other by imaginary\nforces. But classic locomotion models fail when collective cooperation is\ncalled for, notably when an agent, say a first-aid attendant, needs to forge a\npath through a densely packed group. We present a controlled experiment to\nobserve what happens when humans pass through a dense static crowd. We\nformulate and test hypothesis on salient phenomena. We discuss our observations\nin a psychological framework. We derive a model that incorporates: agents'\nperception and cognitive processing of a situation that needs cooperation;\nselection from a portfolio of behaviours, such as being cooperative; and a\nsuitable action, such as swapping places. Agents' ability to successfully get\nthrough a dense crowd emerges as an effect of the psychological model.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 13:29:08 GMT"}, {"version": "v2", "created": "Wed, 7 Oct 2020 09:40:47 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Kleinmeier", "Benedikt", ""], ["K\u00f6ster", "Gerta", ""], ["Drury", "John", ""]]}, {"id": "2005.13187", "submitter": "Keisuke Okumura", "authors": "Keisuke Okumura, Yasumasa Tamura, Xavier D\\'efago", "title": "Time-Independent Planning for Multiple Moving Agents", "comments": "10 pages, 5 figures, to be presented at AAAI-21, Feb 2021, Virtual\n  Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Typical Multi-agent Path Finding (MAPF) solvers assume that agents move\nsynchronously, thus neglecting the reality gap in timing assumptions, e.g.,\ndelays caused by an imperfect execution of asynchronous moves. So far, two\npolicies enforce a robust execution of MAPF plans taken as input: either by\nforcing agents to synchronize or by executing plans while preserving temporal\ndependencies. This paper proposes an alternative approach, called\ntime-independent planning, which is both online and distributed. We represent\nreality as a transition system that changes configurations according to atomic\nactions of agents, and use it to generate a time-independent schedule.\nEmpirical results in a simulated environment with stochastic delays of agents'\nmoves support the validity of our proposal.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 06:16:15 GMT"}, {"version": "v2", "created": "Sun, 29 Nov 2020 04:27:04 GMT"}, {"version": "v3", "created": "Mon, 14 Dec 2020 05:04:42 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Okumura", "Keisuke", ""], ["Tamura", "Yasumasa", ""], ["D\u00e9fago", "Xavier", ""]]}, {"id": "2005.13527", "submitter": "David Mguni", "authors": "David Mguni", "title": "Stochastic Potential Games", "comments": "The submission contains an overlap with and has been superseded by\n  arXiv:2103.09284", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computing the Nash equilibrium (NE) for N-player non-zerosum stochastic games\nis a formidable challenge. Currently, algorithmic methods in stochastic game\ntheory are unable to compute NE for stochastic games (SGs) for settings in all\nbut extreme cases in which the players either play as a team or have\ndiametrically opposed objectives in a two-player setting. This greatly impedes\nthe application of the SG framework to numerous problems within economics and\npractical systems of interest. In this paper, we provide a method of computing\nNash equilibria in nonzero-sum settings and for populations of players more\nthan two. In particular, we identify a subset of SGs known as stochastic\npotential games (SPGs) for which the (Markov perfect) Nash equilibrium can be\ncomputed tractably and in polynomial time. Unlike SGs for which, in general,\ncomputing the NE is PSPACE-hard, we show that SGs with the potential property\nare P-Complete. We further demonstrate that for each SPG there is a dual Markov\ndecision process whose solution coincides with the MP-NE of the SPG. We lastly\nprovide algorithms that tractably compute the MP-NE for SGs with more than two\nplayers.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 17:53:49 GMT"}, {"version": "v2", "created": "Wed, 24 Mar 2021 15:32:06 GMT"}], "update_date": "2021-03-25", "authors_parsed": [["Mguni", "David", ""]]}, {"id": "2005.13625", "submitter": "Justin Terry", "authors": "Justin K Terry, Nathaniel Grammel, Ananth Hari, Luis Santos, Benjamin\n  Black", "title": "Revisiting Parameter Sharing In Multi-Agent Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \"Nonstationarity\" is a fundamental problem in cooperative multi-agent\nreinforcement learning (MARL). It results from every agent's policy changing\nduring learning, while being part of the environment from the perspective of\nother agents. This causes information to inherently oscillate between agents\nduring learning, greatly slowing convergence. We use the MAILP model of\ninformation transfer during multi-agent learning to show that increasing\ncentralization during learning arbitrarily mitigates the slowing of convergence\ndue to nonstationarity. The most centralized case of learning is parameter\nsharing, an uncommonly used MARL method, specific to environments with\nhomogeneous agents. It bootstraps single-agent reinforcement learning (RL)\nmethods and learns an identical policy for each agent. We experimentally\nreplicate our theoretical result of increased learning centralization leading\nto better performance. We further apply parameter sharing to 8 more modern\nsingle-agent deep RL methods for the first time, achieving up to 44 times more\naverage reward in 16% as many episodes compared to previous parameter sharing\nexperiments. We finally give a formal proof of a set of methods that allow\nparameter sharing to serve in environments with heterogeneous agents.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 20:14:28 GMT"}, {"version": "v2", "created": "Fri, 5 Jun 2020 08:33:31 GMT"}, {"version": "v3", "created": "Tue, 7 Jul 2020 23:17:06 GMT"}, {"version": "v4", "created": "Fri, 24 Jul 2020 05:39:03 GMT"}, {"version": "v5", "created": "Wed, 11 Nov 2020 01:19:15 GMT"}, {"version": "v6", "created": "Thu, 25 Feb 2021 22:24:34 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Terry", "Justin K", ""], ["Grammel", "Nathaniel", ""], ["Hari", "Ananth", ""], ["Santos", "Luis", ""], ["Black", "Benjamin", ""]]}, {"id": "2005.13706", "submitter": "Yifeng Zeng", "authors": "Bilian Chen, Biyang Ma, Yifeng Zeng, Langcai Cao, Jing Tang", "title": "Tensor Decomposition for Multi-agent Predictive State Representation", "comments": "20 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictive state representation~(PSR) uses a vector of action-observation\nsequence to represent the system dynamics and subsequently predicts the\nprobability of future events. It is a concise knowledge representation that is\nwell studied in a single-agent planning problem domain. To the best of our\nknowledge, there is no existing work on using PSR to solve multi-agent planning\nproblems. Learning a multi-agent PSR model is quite difficult especially with\nthe increasing number of agents, not to mention the complexity of a problem\ndomain. In this paper, we resort to tensor techniques to tackle the challenging\ntask of multi-agent PSR model development problems. By first focusing on a\ntwo-agent setting, we construct the system dynamics matrix as a high order\ntensor for a PSR model, learn the prediction parameters and deduce state\nvectors directly through two different tensor decomposition methods\nrespectively, and derive the transition parameters via linear regression.\nSubsequently, we generalize the PSR learning approaches in a multi-agent\nsetting. Experimental results show that our methods can effectively solve\nmulti-agent PSR modelling problems in multiple problem domains.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 23:19:18 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Chen", "Bilian", ""], ["Ma", "Biyang", ""], ["Zeng", "Yifeng", ""], ["Cao", "Langcai", ""], ["Tang", "Jing", ""]]}, {"id": "2005.13714", "submitter": "Jingwen Qian", "authors": "Yiwei Chen, Jingwen Qian, Junming Wang, Lirong Xia and Gavriel Zahavi", "title": "OPRA: An Open-Source Online Preference Reporting and Aggregation System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the Online Preference Reporting and Aggregation (OPRA) system,\nan open-source online system that aims at providing support for group\ndecision-making. We illustrate OPRA's distinctive features: UI for reporting\nrankings with ties, comprehensive analytics of preferences, and group\ndecision-making in combinatorial domains. We also discuss our work in an\nautomatic mentor matching system. We hope that the open-source nature of OPRA\nwill foster the development of computerized group decision support systems.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 00:16:54 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Chen", "Yiwei", ""], ["Qian", "Jingwen", ""], ["Wang", "Junming", ""], ["Xia", "Lirong", ""], ["Zahavi", "Gavriel", ""]]}, {"id": "2005.14220", "submitter": "Arsham Mostaani", "authors": "Arsham Mostaani, Thang X. Vu, Symeon Chatzinotas, Bj\\\"orn Ottersten", "title": "Task-Based Information Compression for Multi-Agent Communication\n  Problems with Channel Rate Constraints", "comments": "13 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG cs.MA cs.SY eess.SY math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A collaborative task is assigned to a multiagent system (MAS) in which agents\nare allowed to communicate. The MAS runs over an underlying Markov decision\nprocess and its task is to maximize the averaged sum of discounted one-stage\nrewards. Although knowing the global state of the environment is necessary for\nthe optimal action selection of the MAS, agents are limited to individual\nobservations. The inter-agent communication can tackle the issue of local\nobservability, however, the limited rate of the inter-agent communication\nprevents the agent from acquiring the precise global state information. To\novercome this challenge, agents need to communicate their observations in a\ncompact way such that the MAS compromises the minimum possible sum of rewards.\nWe show that this problem is equivalent to a form of rate-distortion problem\nwhich we call the task-based information compression. We introduce a scheme for\ntask-based information compression titled State aggregation for information\ncompression (SAIC), for which a state aggregation algorithm is analytically\ndesigned. The SAIC is shown to be capable of achieving near-optimal performance\nin terms of the achieved sum of discounted rewards. The proposed algorithm is\napplied to a rendezvous problem and its performance is compared with several\nbenchmarks. Numerical experiments confirm the superiority of the proposed\nalgorithm.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 18:29:21 GMT"}, {"version": "v2", "created": "Tue, 27 Jul 2021 14:27:26 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Mostaani", "Arsham", ""], ["Vu", "Thang X.", ""], ["Chatzinotas", "Symeon", ""], ["Ottersten", "Bj\u00f6rn", ""]]}, {"id": "2005.14455", "submitter": "Yajing Wang", "authors": "Yajing Wang (1), Xiangke Wang (1), Shulong Zhao (1), Lincheng Shen (1)\n  ((1) National University of Defense Technology, P.R. China)", "title": "A Hierarchical Collision Avoidance Architecture for Multiple Fixed-Wing\n  UAVs in an Integrated Airspace", "comments": "6 pages, 3 figures, 21st IFAC World Congress 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the collision avoidance problem for autonomous multiple\nfixedwing UAVs in the complex integrated airspace. By studying and combining\nthe online path planning method, the distributed model predictive control\nalgorithm, and the geometric reactive control approach, a three-layered\ncollision avoidance system integrating conflict detection and resolution\nprocedures is developed for multiple fixed-wing UAVs modeled by unicycle\nkinematics subject to input constraints. The effectiveness of the proposed\nmethodology is evaluated and validated via test results of comparative\nsimulations under both deterministic and probabilistic sensing conditions.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 08:59:43 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Wang", "Yajing", "", "National University of Defense Technology, P.R. China"], ["Wang", "Xiangke", "", "National University of Defense Technology, P.R. China"], ["Zhao", "Shulong", "", "National University of Defense Technology, P.R. China"], ["Shen", "Lincheng", "", "National University of Defense Technology, P.R. China"]]}, {"id": "2005.14631", "submitter": "Ehud Shapiro", "authors": "Gal Shahaf, Ehud Shapiro and Nimrod Talmon", "title": "Egalitarian and Just Digital Currency Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.GN cs.GT cs.MA cs.SI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Cryptocurrencies are a digital medium of exchange with decentralized control\nthat renders the community operating the cryptocurrency its sovereign. Leading\ncryptocurrencies use proof-of-work or proof-of-stake to reach consensus, thus\nare inherently plutocratic. This plutocracy is reflected not only in control\nover execution, but also in the distribution of new wealth, giving rise to\n``rich get richer'' phenomena. Here, we explore the possibility of an\nalternative digital currency that is egalitarian in control and just in the\ndistribution of created wealth. Such currencies can form and grow in grassroots\nand sybil-resilient way. A single currency community can achieve distributive\njustice by egalitarian coin minting, whereby each member mints one coin at\nevery time step. Egalitarian minting results, in the limit, in the dilution of\nany inherited assets and in each member having an equal share of the minted\ncurrency, adjusted by the relative productivity of the members. Our main\ntheorem shows that a currency network, where agents can be members of more than\none currency community, can achieve distributive justice globally across the\nnetwork by joint egalitarian minting, whereby each agent mints one coin in only\none community at each timestep. Specifically, we show that a sufficiently large\nintersection between two communities -- relative to the gap in their\nproductivity -- will cause the exchange rates between their currencies to\nconverge to 1:1, resulting in global distributive justice.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 15:49:14 GMT"}, {"version": "v2", "created": "Mon, 1 Jun 2020 15:52:10 GMT"}, {"version": "v3", "created": "Sun, 5 Jul 2020 10:45:44 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Shahaf", "Gal", ""], ["Shapiro", "Ehud", ""], ["Talmon", "Nimrod", ""]]}]