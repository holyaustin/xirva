[{"id": "1412.0055", "submitter": "Vin\\'icius Antonio Battagello", "authors": "Vin\\'icius A. Battagello, Carlos H. C. Ribeiro", "title": "Analysis of the Effects of Failure and Noise in the Distributed\n  Connectivity Maintenance of a Multi-robot System", "comments": "6 pages, 7 figures, published in CINTI 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To perform cooperative tasks in a decentralized manner, multi-robot systems\nare often required to communicate with each other. Therefore, maintaining the\ncommunication graph connectivity is a fundamental issue when roaming a\nterritory with obstacles. However, when dealing with real-robot systems,\nseveral sources of data corruption can appear in the agent interaction. In this\npaper, the effects of failure and noise in the communication between agents are\nanalyzed upon a connectivity maintenance control strategy. The results show\nthat the connectivity strategy is resilient to the negative effects of such\ndisturbances under realistic settings that consider a bandwidth limit for the\ncontrol effort. This opens the perspective of applying the connectivity\nmaintenance strategy in adaptive schemes that consider, for instance,\nautonomous adaptation to constraints other than connectivity itself, e.g.\ncommunication efficiency and energy harvesting.\n", "versions": [{"version": "v1", "created": "Sat, 29 Nov 2014 00:44:43 GMT"}], "update_date": "2014-12-02", "authors_parsed": [["Battagello", "Vin\u00edcius A.", ""], ["Ribeiro", "Carlos H. C.", ""]]}, {"id": "1412.0301", "submitter": "Ajay Deshpande", "authors": "Ajay Deshpande", "title": "Guaranteed sensor coverage with the weighted-$D^2$ sampling", "comments": "Submitted to Automatica", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.MA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we focus on the mobile sensor coverage problem formulated as a\ncontinuous locational optimization problem. Cort\\`es et al. first proposed a\ndistributed version of the Lloyd descent algorithm with guaranteed convergence\nto a local optima. Since then researchers have studied a number of variations\nof the coverage problem. The quality of the final solution with the Lloyd\ndescent depends on the initial sensor configuration. Inspired by the recent\nresults on a related $k$-means problem, in this paper we propose the\nweighted-$D^2$ sampling to choose the initial sensor configuration and show\nthat it yields $O(\\log k)$-competitive sensor coverage before even applying the\nLloyd descent. Through extensive numerical simulations, we show that the\ninitial coverage with the weighted-$D^2$ sampling is significantly lower than\nthat with the uniform random initial sensor configuration. We also show that\nthe average distance traveled by the sensors to reach the final configuration\nthrough the Lloyd descent is also significantly lower than that with the\nuniform random configuration. This also implies considerable savings in the\nenergy spent by the sensors during motion and faster convergence.\n", "versions": [{"version": "v1", "created": "Sun, 30 Nov 2014 22:44:06 GMT"}], "update_date": "2014-12-02", "authors_parsed": [["Deshpande", "Ajay", ""]]}, {"id": "1412.0543", "submitter": "Panayotis Mertikopoulos", "authors": "Steven Perkins and Panayotis Mertikopoulos and David S. Leslie", "title": "Game-theoretical control with continuous action sets", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.GT cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the recent applications of game-theoretical learning techniques\nto the design of distributed control systems, we study a class of control\nproblems that can be formulated as potential games with continuous action sets,\nand we propose an actor-critic reinforcement learning algorithm that provably\nconverges to equilibrium in this class of problems. The method employed is to\nanalyse the learning process under study through a mean-field dynamical system\nthat evolves in an infinite-dimensional function space (the space of\nprobability distributions over the players' continuous controls). To do so, we\nextend the theory of finite-dimensional two-timescale stochastic approximation\nto an infinite-dimensional, Banach space setting, and we prove that the\ncontinuous dynamics of the process converge to equilibrium in the case of\npotential games. These results combine to give a provably-convergent learning\nalgorithm in which players do not need to keep track of the controls selected\nby the other agents.\n", "versions": [{"version": "v1", "created": "Mon, 1 Dec 2014 17:07:34 GMT"}], "update_date": "2014-12-03", "authors_parsed": [["Perkins", "Steven", ""], ["Mertikopoulos", "Panayotis", ""], ["Leslie", "David S.", ""]]}, {"id": "1412.1468", "submitter": "Chung-Kai Yu", "authors": "Chung-Kai Yu, Mihaela van der Schaar, Ali H. Sayed", "title": "Information-Sharing over Adaptive Networks with Self-interested Agents", "comments": "19 pages, 8 figures. To appear in IEEE Transactions on Signal and\n  Information Processing over Networks", "journal-ref": null, "doi": "10.1109/TSIPN.2015.2447832", "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine the behavior of multi-agent networks where information-sharing is\nsubject to a positive communications cost over the edges linking the agents. We\nconsider a general mean-square-error formulation where all agents are\ninterested in estimating the same target vector. We first show that, in the\nabsence of any incentives to cooperate, the optimal strategy for the agents is\nto behave in a selfish manner with each agent seeking the optimal solution\nindependently of the other agents. Pareto inefficiency arises as a result of\nthe fact that agents are not using historical data to predict the behavior of\ntheir neighbors and to know whether they will reciprocate and participate in\nsharing information. Motivated by this observation, we develop a reputation\nprotocol to summarize the opponent's past actions into a reputation score,\nwhich can then be used to form a belief about the opponent's subsequent\nactions. The reputation protocol entices agents to cooperate and turns their\noptimal strategy into an action-choosing strategy that enhances the overall\nsocial benefit of the network. In particular, we show that when the\ncommunications cost becomes large, the expected social benefit of the proposed\nprotocol outperforms the social benefit that is obtained by cooperative agents\nthat always share data. We perform a detailed mean-square-error analysis of the\nevolution of the network over three domains: far field, near-field, and\nmiddle-field, and show that the network behavior is stable for sufficiently\nsmall step-sizes. The various theoretical results are illustrated by numerical\nsimulations.\n", "versions": [{"version": "v1", "created": "Wed, 3 Dec 2014 20:51:59 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2015 07:20:45 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Yu", "Chung-Kai", ""], ["van der Schaar", "Mihaela", ""], ["Sayed", "Ali H.", ""]]}, {"id": "1412.1523", "submitter": "Bicheng Ying", "authors": "Bicheng Ying and Ali H. Sayed", "title": "Information Exchange and Learning Dynamics over Weakly-Connected\n  Adaptive Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.IT cs.LG math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The paper examines the learning mechanism of adaptive agents over\nweakly-connected graphs and reveals an interesting behavior on how information\nflows through such topologies. The results clarify how asymmetries in the\nexchange of data can mask local information at certain agents and make them\ntotally dependent on other agents. A leader-follower relationship develops with\nthe performance of some agents being fully determined by the performance of\nother agents that are outside their domain of influence. This scenario can\narise, for example, due to intruder attacks by malicious agents or as the\nresult of failures by some critical links. The findings in this work help\nexplain why strong-connectivity of the network topology, adaptation of the\ncombination weights, and clustering of agents are important ingredients to\nequalize the learning abilities of all agents against such disturbances. The\nresults also clarify how weak-connectivity can be helpful in reducing the\neffect of outlier data on learning performance.\n", "versions": [{"version": "v1", "created": "Thu, 4 Dec 2014 00:01:52 GMT"}, {"version": "v2", "created": "Sun, 6 Dec 2015 20:48:53 GMT"}], "update_date": "2015-12-08", "authors_parsed": [["Ying", "Bicheng", ""], ["Sayed", "Ali H.", ""]]}, {"id": "1412.1798", "submitter": "Roula Nassif", "authors": "Roula Nassif, C\\'edric Richard, Andr\\'e Ferrari, Ali H. Sayed", "title": "Multitask diffusion adaptation over asynchronous networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The multitask diffusion LMS is an efficient strategy to simultaneously infer,\nin a collaborative manner, multiple parameter vectors. Existing works on\nmultitask problems assume that all agents respond to data synchronously. In\nseveral applications, agents may not be able to act synchronously because\nnetworks can be subject to several sources of uncertainties such as changing\ntopology, random link failures, or agents turning on and off for energy\nconservation. In this work, we describe a model for the solution of multitask\nproblems over asynchronous networks and carry out a detailed mean and\nmean-square error analysis. Results show that sufficiently small step-sizes can\nstill ensure both stability and performance. Simulations and illustrative\nexamples are provided to verify the theoretical findings. The framework is\napplied to a particular application involving spectral sensing.\n", "versions": [{"version": "v1", "created": "Thu, 4 Dec 2014 20:30:57 GMT"}, {"version": "v2", "created": "Fri, 12 Aug 2016 15:23:01 GMT"}], "update_date": "2016-08-15", "authors_parsed": [["Nassif", "Roula", ""], ["Richard", "C\u00e9dric", ""], ["Ferrari", "Andr\u00e9", ""], ["Sayed", "Ali H.", ""]]}, {"id": "1412.4039", "submitter": "Jonas Degrave", "authors": "Jonas Degrave", "title": "Resolving multi-proxy transitive vote delegation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Solving a delegation graph for transitive votes is already a non-trivial task\nfor many programmers. When extending the current main paradigm, where each\nvoter can only appoint a single transitive delegation, to a system where each\nvote can be separated over multiple delegations, solving the delegation graph\nbecomes even harder. This article presents a solution of an example graph, and\na non-formal proof of why this algorithm works.\n", "versions": [{"version": "v1", "created": "Thu, 11 Dec 2014 13:06:38 GMT"}], "update_date": "2014-12-15", "authors_parsed": [["Degrave", "Jonas", ""]]}, {"id": "1412.4166", "submitter": "Arjun Muralidharan", "authors": "Arjun Muralidharan, Yuan Yan and Yasamin Mostofi", "title": "Binary Log-Linear Learning with Stochastic Communication Links", "comments": "Double column, 7 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider distributed decision-making over stochastic\ncommunication links in multi-agent systems. We show how to extend the current\nliterature on potential games with binary log-linear learning (which mainly\nfocuses on ideal communication links) to consider the impact of stochastic\ncommunication channels. More specifically, we derive conditions on the\nprobability of link connectivity to achieve a target probability for the set of\npotential maximizers (in the stationary distribution). Furthermore, our toy\nexample demonstrates a transition phenomenon for achieving any target\nprobability for the set of potential maximizers.\n", "versions": [{"version": "v1", "created": "Fri, 12 Dec 2014 23:59:42 GMT"}], "update_date": "2014-12-16", "authors_parsed": [["Muralidharan", "Arjun", ""], ["Yan", "Yuan", ""], ["Mostofi", "Yasamin", ""]]}, {"id": "1412.5459", "submitter": "Mariam Kiran Dr.", "authors": "Mariam Kiran and Wei Liu", "title": "Converting a Systems Dynamic Model to an Agent-based model for studying\n  the Bicoid morphogen gradient in Drosophila embryo", "comments": "21 pages, 13 figures, technical report, exploratory study", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.CE q-bio.QM", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  The concentration gradient of the Bicoid morphogen, which is established\nduring the early stages of a Drosophila melanogaster embryonic development,\ndetermines the differential spatial patterns of gene expression and subsequent\ncell fate determination. This is mainly achieved by diffusion elicited by the\ndifferent concentrations of the Bicoid protein in the embryo. Such chemical\ndynamic progress can be simulated by stochastic models, particularly the\nGillespie alogrithm. However, as with various modelling approaches in biology,\neach technique involves drawing assumptions and reducing the model complexity\nsometimes limiting the model capability. This is mainly due to the complexity\nof the software modelling approaches to construct these models. Agent-based\nmodelling is a technique which is becoming increasingly popular for modelling\nthe behaviour of individual molecules or cells in computational biology.\n  This paper attempts to compare these two popular modelling techniques of\nstochastic and agent-based modelling to show how the model can be studied in\ndetail using the different approaches. This paper presents how to use these\ntechniques with the advantages and disadvantages of using either of these.\nThrough various comparisons, such as computation complexity and results\nobtained, we show that although the same model is implemented, both approaches\ncan give varying results. The results of the paper show that the stochastic\nmodel is able to give smoother results compared to the agent-based model which\nmay need further analysis at a later stage. We discuss the reasons for these\nresults and how these could be rectified in systems biology research.\n", "versions": [{"version": "v1", "created": "Wed, 17 Dec 2014 16:14:55 GMT"}], "update_date": "2014-12-18", "authors_parsed": [["Kiran", "Mariam", ""], ["Liu", "Wei", ""]]}, {"id": "1412.6049", "submitter": "Qipeng Liu", "authors": "Qipeng Liu, Jiuhua Zhao, and Xiaofan Wang", "title": "Distributed Detection via Bayesian Updates and Consensus", "comments": "6 pages, 3 figures. This paper has been submitted to Chinese Control\n  Conference 2015 at Hangzhou, People's Republic of China", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.MA cs.SY physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we discuss a class of distributed detection algorithms which\ncan be viewed as implementations of Bayes' law in distributed settings. Some of\nthe algorithms are proposed in the literature most recently, and others are\nfirst developed in this paper. The common feature of these algorithms is that\nthey all combine (i) certain kinds of consensus protocols with (ii) Bayesian\nupdates. They are different mainly in the aspect of the type of consensus\nprotocol and the order of the two operations. After discussing their\nsimilarities and differences, we compare these distributed algorithms by\nnumerical examples. We focus on the rate at which these algorithms detect the\nunderlying true state of an object. We find that (a) The algorithms with\nconsensus via geometric average is more efficient than that via arithmetic\naverage; (b) The order of consensus aggregation and Bayesian update does not\napparently influence the performance of the algorithms; (c) The existence of\ncommunication delay dramatically slows down the rate of convergence; (d) More\ncommunication between agents with different signal structures improves the rate\nof convergence.\n", "versions": [{"version": "v1", "created": "Wed, 17 Dec 2014 00:35:25 GMT"}, {"version": "v2", "created": "Sat, 7 Nov 2015 07:00:54 GMT"}], "update_date": "2015-11-10", "authors_parsed": [["Liu", "Qipeng", ""], ["Zhao", "Jiuhua", ""], ["Wang", "Xiaofan", ""]]}, {"id": "1412.6546", "submitter": "Seyed Rasoul Etesami", "authors": "Seyed Rasoul Etesami, Tamer Basar", "title": "Game-Theoretic Analysis of the Hegselmann-Krause Model for Opinion\n  Dynamics in Finite Dimensions", "comments": "The paper is accepted in IEEE Transactions on Automatic Control and\n  will appear soon", "journal-ref": null, "doi": "10.1109/TAC.2015.2394954", "report-no": null, "categories": "cs.GT cs.DM cs.MA cs.RO math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the Hegselmann-Krause model for opinion dynamics and study the\nevolution of the system under various settings. We first analyze the\ntermination time of the synchronous Hegselmann-Krause dynamics in arbitrary\nfinite dimensions and show that the termination time in general only depends on\nthe number of agents involved in the dynamics. To the best of our knowledge,\nthat is the sharpest bound for the termination time of such dynamics that\nremoves dependency of the termination time from the dimension of the ambient\nspace. This answers an open question in [1] on how to obtain a tighter upper\nbound for the termination time. Furthermore, we study the asynchronous\nHegselmann-Krause model from a novel game-theoretic approach and show that the\nevolution of an asynchronous Hegselmann-Krause model is equivalent to a\nsequence of best response updates in a well-designed potential game. We then\nprovide a polynomial upper bound for the expected time and expected number of\nswitching topologies until the dynamic reaches an arbitrarily small\nneighborhood of its equilibrium points, provided that the agents update\nuniformly at random. This is a step toward analysis of heterogeneous\nHegselmann-Krause dynamics. Finally, we consider the heterogeneous\nHegselmann-Krause dynamics and provide a necessary condition for the finite\ntermination time of such dynamics. In particular, we sketch some future\ndirections toward more detailed analysis of the heterogeneous Hegselmann-Krause\nmodel.\n", "versions": [{"version": "v1", "created": "Fri, 19 Dec 2014 22:03:03 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Etesami", "Seyed Rasoul", ""], ["Basar", "Tamer", ""]]}, {"id": "1412.6924", "submitter": "Klaus Jaffe Dr", "authors": "Klaus Jaffe", "title": "Visualizing the Invisible Hand of Markets: Simulating complex dynamic\n  economic interactions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA q-fin.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In complex systems, many different parts interact in non-obvious ways.\nTraditional research focuses on a few or a single aspect of the problem so as\nto analyze it with the tools available. To get a better insight of phenomena\nthat emerge from complex interactions, we need instruments that can analyze\nsimultaneously complex interactions between many parts. Here, a simulator\nmodeling different types of economies, is used to visualize complex\nquantitative aspects that affect economic dynamics. The main conclusions are:\n1- Relatively simple economic settings produce complex non-linear dynamics and\ntherefore linear regressions are often unsuitable to capture complex economic\ndynamics; 2- Flexible pricing of goods by individual agents according to their\nmicro-environment increases the health and wealth of the society, but\nasymmetries in price sensitivity between buyers and sellers increase price\ninflation; 3- Prices for goods conferring risky long term benefits are not\ntracked efficiently by simple market forces. 4- Division of labor creates\nsynergies that improve enormously the health and wealth of the society by\nincreasing the efficiency of economic activity. 5- Stochastic modeling improves\nour understanding of real economies, and didactic games based on them might\nhelp policy makers and non specialists in grasping the complex dynamics\nunderlying even simple economic settings.\n", "versions": [{"version": "v1", "created": "Mon, 22 Dec 2014 11:04:57 GMT"}, {"version": "v2", "created": "Thu, 2 Apr 2015 10:35:48 GMT"}], "update_date": "2015-04-03", "authors_parsed": [["Jaffe", "Klaus", ""]]}, {"id": "1412.7116", "submitter": "Saghar Hosseini", "authors": "Saghar Hosseini, Airlie Chapman, and Mehran Mesbahi", "title": "Online Distributed ADMM on Networks", "comments": "Submitted to The IEEE Transactions on Control of Network Systems,\n  2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DC cs.DS cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper examines online distributed Alternating Direction Method of\nMultipliers (ADMM). The goal is to distributively optimize a global objective\nfunction over a network of decision makers under linear constraints. The global\nobjective function is composed of convex cost functions associated with each\nagent. The local cost functions, on the other hand, are assumed to have been\ndecomposed into two distinct convex functions, one of which is revealed to the\ndecision makers over time and one known a priori. In addition, the agents must\nachieve consensus on the global variable that relates to the private local\nvariables via linear constraints. In this work, we extend online ADMM to a\ndistributed setting based on dual-averaging and distributed gradient descent.\nWe then propose a performance metric for such online distributed algorithms and\nexplore the performance of the sequence of decisions generated by the algorithm\nas compared with the best fixed decision in hindsight. This performance metric\nis called the social regret. A sub-linear upper bound on the social regret of\nthe proposed algorithm is then obtained that underscores the role of the\nunderlying network topology and certain condition measures associated with the\nlinear constraints. The online distributed ADMM algorithm is then applied to a\nformation acquisition problem demonstrating the application of the proposed\nsetup in distributed robotics.\n", "versions": [{"version": "v1", "created": "Mon, 22 Dec 2014 19:55:56 GMT"}, {"version": "v2", "created": "Fri, 2 Oct 2015 19:59:48 GMT"}], "update_date": "2015-10-05", "authors_parsed": [["Hosseini", "Saghar", ""], ["Chapman", "Airlie", ""], ["Mesbahi", "Mehran", ""]]}, {"id": "1412.7215", "submitter": "Saghar Hosseini", "authors": "Saghar Hosseini, Airlie Chapman, and Mehran Mesbahi", "title": "Online Distributed Optimization on Dynamic Networks", "comments": "Submitted to The IEEE Transactions on Automatic Control, 2014", "journal-ref": null, "doi": "10.1109/TAC.2016.2525928", "report-no": null, "categories": "math.OC cs.DS cs.LG cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a distributed optimization scheme over a network of\nagents in the presence of cost uncertainties and over switching communication\ntopologies. Inspired by recent advances in distributed convex optimization, we\npropose a distributed algorithm based on a dual sub-gradient averaging. The\nobjective of this algorithm is to minimize a cost function cooperatively.\nFurthermore, the algorithm changes the weights on the communication links in\nthe network to adapt to varying reliability of neighboring agents. A\nconvergence rate analysis as a function of the underlying network topology is\nthen presented, followed by simulation results for representative classes of\nsensor networks.\n", "versions": [{"version": "v1", "created": "Mon, 22 Dec 2014 23:57:30 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Hosseini", "Saghar", ""], ["Chapman", "Airlie", ""], ["Mesbahi", "Mehran", ""]]}, {"id": "1412.7223", "submitter": "Mo Chen", "authors": "Mo Chen and Jaime F. Fisac and Shankar Sastry and Claire J. Tomlin", "title": "Safe Sequential Path Planning of Multi-Vehicle Systems via\n  Double-Obstacle Hamilton-Jacobi-Isaacs Variational Inequality", "comments": "European Control Conference 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of planning trajectories for a group of $N$ vehicles,\neach aiming to reach its own target set while avoiding danger zones of other\nvehicles. The analysis of problems like this is extremely important\npractically, especially given the growing interest in utilizing unmanned\naircraft systems for civil purposes. The direct solution of this problem by\nsolving a single-obstacle Hamilton-Jacobi-Isaacs (HJI) variational inequality\n(VI) is numerically intractable due to the exponential scaling of computation\ncomplexity with problem dimensionality. Furthermore, the single-obstacle HJI VI\ncannot directly handle situations in which vehicles do not have a common\nscheduled arrival time. Instead, we perform sequential path planning by\nconsidering vehicles in order of priority, modeling higher-priority vehicles as\ntime-varying obstacles for lower-priority vehicles. To do this, we solve a\ndouble-obstacle HJI VI which allows us to obtain the reach-avoid set, defined\nas the set of states from which a vehicle can reach its target while staying\nwithin a time-varying state constraint set. From the solution of the\ndouble-obstacle HJI VI, we can also extract the latest start time and the\noptimal control for each vehicle. This is a first application of the\ndouble-obstacle HJI VI which can handle systems with time-varying dynamics,\ntarget sets, and state constraint sets, and results in computation complexity\nthat scales linearly, as opposed to exponentially, with the number of vehicles\nin consideration.\n", "versions": [{"version": "v1", "created": "Tue, 23 Dec 2014 00:32:16 GMT"}, {"version": "v2", "created": "Mon, 21 Mar 2016 01:37:57 GMT"}], "update_date": "2016-03-22", "authors_parsed": [["Chen", "Mo", ""], ["Fisac", "Jaime F.", ""], ["Sastry", "Shankar", ""], ["Tomlin", "Claire J.", ""]]}, {"id": "1412.7281", "submitter": "Shanying Zhu", "authors": "Shanying Zhu, Yeng Chai Soh, Lihua Xie", "title": "Distributed Parameter Estimation with Quantized Communication via\n  Running Average", "comments": "13 pages, 6 figures; IEEE Transactions on Signal Processing, 2015", "journal-ref": null, "doi": "10.1109/TSP.2015.2441034", "report-no": null, "categories": "cs.SY cs.DC cs.MA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the parameter estimation problem over sensor\nnetworks in the presence of quantized data and directed communication links. We\npropose a two-stage algorithm aiming at achieving the centralized sample mean\nestimate in a distributed manner. Different from the existing algorithms, a\nrunning average technique is utilized in the proposed algorithm to smear out\nthe randomness caused by the probabilistic quantization scheme. With the\nrunning average technique, it is shown that the centralized sample mean\nestimate can be achieved both in the mean square and almost sure senses, which\nis not observed in the conventional consensus algorithms. In addition, the\nrates of convergence are given to quantify the mean square and almost sure\nperformances. Finally, simulation results are presented to illustrate the\neffectiveness of the proposed algorithm and highlight the improvements by using\nrunning average technique.\n", "versions": [{"version": "v1", "created": "Tue, 23 Dec 2014 07:56:44 GMT"}, {"version": "v2", "created": "Fri, 24 Jul 2015 06:08:35 GMT"}], "update_date": "2015-07-27", "authors_parsed": [["Zhu", "Shanying", ""], ["Soh", "Yeng Chai", ""], ["Xie", "Lihua", ""]]}, {"id": "1412.7824", "submitter": "Soumic Sarkar", "authors": "Soumic Sarkar and Indra Narayan Kar", "title": "Multi Time Scale Behaviour of The Formation of Multiple Groups of\n  Nonholonomic Wheeled Mobile Robots", "comments": "arXiv admin note: text overlap with arXiv:1412.6164", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Different geometric patterns and shapes are generated using groups of agents,\nand this needs formation control. In this paper, Centroid Based Transformation\n(CBT), has been applied to decompose the combined dynamics of nonholonomic\nWheeled Mobile Robots (WMRs) into three subsystems: intra and inter group shape\ndynamics, and the dynamics of the centroid. The intra group shape dynamics can\nfurther be partitioned into the shape dynamics of each group, giving the notion\nof multiple group. Thus separate controllers have been designed for each\nsubsystem. The gains of the controllers are such chosen that the overall system\nbecomes singularly perturbed system, and different subsystems converge to their\ndesired values at different times. Then multi-time scale convergence analysis\nhas been carried out in this paper. Negative gradient of a potential based\nfunction has been added to the controller to ensure collision avoidance among\nthe robots. Simulation results have been provided to demonstrate the\neffectiveness of the proposed controller.\n", "versions": [{"version": "v1", "created": "Thu, 25 Dec 2014 13:35:25 GMT"}], "update_date": "2014-12-30", "authors_parsed": [["Sarkar", "Soumic", ""], ["Kar", "Indra Narayan", ""]]}, {"id": "1412.8736", "submitter": "Michael Neely", "authors": "Michael J. Neely", "title": "Sharing Information Without Regret in Managed Stochastic Games", "comments": "14 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers information sharing in a multi-player repeated game.\nEvery round, each player observes a subset of components of a random vector and\nthen takes a control action. The utility earned by each player depends on the\nfull random vector and on the actions of others. An example is a game where\ndifferent rewards are placed over multiple locations, each player only knows\nthe rewards in a subset of the locations, and players compete to collect the\nrewards. Sharing information can help others, but can also increase competition\nfor desirable locations. Standard Nash equilibrium and correlated equilibrium\nconcepts are inadequate in this scenario. Instead, this paper develops an\nalgorithm where, every round, all players pass their information and intended\nactions to a game manager. The manager provides suggested actions for each\nplayer that, if taken, maximize a concave function of average utilities subject\nto the constraint that each player gets an average utility no worse than it\nwould get without sharing. The algorithm acts online using information given at\neach round and does not require a specific model of random events or player\nactions. Thus, the analytical results of this paper apply in non-ergodic\nsituations with any sequence of actions taken by human players.\n", "versions": [{"version": "v1", "created": "Tue, 30 Dec 2014 19:13:37 GMT"}], "update_date": "2014-12-31", "authors_parsed": [["Neely", "Michael J.", ""]]}]