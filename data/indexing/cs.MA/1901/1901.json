[{"id": "1901.00441", "submitter": "Li-Xin Wang", "authors": "Li-Xin Wang", "title": "Hierarchical Fuzzy Opinion Networks: Top-Down for Social Organizations\n  and Bottom-Up for Election", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.SI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fuzzy opinion is a Gaussian fuzzy set with the center representing the\nopinion and the standard deviation representing the uncertainty about the\nopinion, and a fuzzy opinion network is a connection of a number of fuzzy\nopinions in a structured way. In this paper, we propose: (a) a top-down\nhierarchical fuzzy opinion network to model how the opinion of a top leader is\npenetrated into the members in social organizations, and (b) a bottom-up fuzzy\nopinion network to model how the opinions of a large number of agents are\nagglomerated layer-by-layer into a consensus or a few opinions in the social\nprocesses such as an election. For the top-down hierarchical fuzzy opinion\nnetwork, we prove that the opinions of all the agents converge to the leaders\nopinion, but the uncertainties of the agents in different groups are generally\nconverging to different values. We demonstrate that the speed of convergence is\ngreatly improved by organizing the agents in a hierarchical structure of small\ngroups. For the bottom-up hierarchical fuzzy opinion network, we simulate how a\nwide spectrum of opinions are negotiating and summarizing with each other in a\nlayer-by-layer fashion in some typical situations.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2018 18:10:11 GMT"}], "update_date": "2019-01-03", "authors_parsed": [["Wang", "Li-Xin", ""]]}, {"id": "1901.00611", "submitter": "Chang-Shen Lee", "authors": "Chang-Shen Lee, Nicol\\`o Michelusi, Gesualdo Scutari", "title": "Finite rate distributed weight-balancing and average consensus over\n  digraphs", "comments": "A preliminary version arXiv:1809.06440 of this paper has appeared at\n  IEEE CDC 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes the first distributed algorithm that solves the\nweight-balancing problem using only finite rate and simplex communications\namong nodes, compliant with the directed nature of the graph edges. It is\nproved that the algorithm converges to a weight-balanced solution at sublinear\nrate. The analysis builds upon a new metric inspired by positional system\nrepresentations, which characterizes the dynamics of information exchange over\nthe network, and on a novel step-size rule. Building on this result, a novel\ndistributed algorithm is proposed that solves the average consensus problem\nover digraphs, using, at each timeslot, finite rate simplex communications\nbetween adjacent nodes -- some bits for the weight-balancing problem and others\nfor the average consensus. Convergence of the proposed quantized consensus\nalgorithm to the average of the node's unquantized initial values is\nestablished, both almost surely and in the moment generating function of the\nerror; and a sublinear convergence rate is proved for sufficiently large\nstep-sizes. Numerical results validate our theoretical findings.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jan 2019 05:02:54 GMT"}, {"version": "v2", "created": "Sat, 29 Feb 2020 19:36:45 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Lee", "Chang-Shen", ""], ["Michelusi", "Nicol\u00f2", ""], ["Scutari", "Gesualdo", ""]]}, {"id": "1901.00758", "submitter": "Wiktor Daszczuk", "authors": "Bogdan Czejdo, Wiktor B. Daszczuk, Waldemar Grabski, Sambit\n  Bhattacharya", "title": "Cooperation of Multiple Autonomous Robots and Analysis of their Swarm\n  Behavior", "comments": "8 pages, 10 figures. arXiv admin note: text overlap with\n  arXiv:1705.04263", "journal-ref": "Autobusy-TEST Vol. 226, 2018, No. 12, pp.872-879", "doi": "10.24136/atest.2018.516", "report-no": null, "categories": "cs.RO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we extended previous studies of cooperating autonomous robots\nto include situations when environmental changes and changes in the number of\nrobots in the swarm can affect the efficiency to execute tasks assigned to the\nswarm of robots. We have presented a novel approach based on partition of the\nrobot behavior. The sub-diagrams describing sub-routs allowed us to model\nadvanced interactions between autonomous robots using limited number of state\ncombinations avoiding combinatorial explosion of reachability. We identified\nthe systems for which we can ensure the correctness of robots interactions. New\ntechniques were presented to verify and analyze combined robots' behavior. The\npartitioned diagrams allowed us to model advanced interactions between\nautonomous robots and detect irregularities such as deadlocks, lack of\ntermination etc. The techniques were presented to verify and analyze combined\nrobots' behavior using model checking approach. The described system, Dedan\nverifier, is still under development. In the near future, timed and\nprobabilistic verification are planned.\n", "versions": [{"version": "v1", "created": "Fri, 28 Dec 2018 20:07:48 GMT"}], "update_date": "2019-01-04", "authors_parsed": [["Czejdo", "Bogdan", ""], ["Daszczuk", "Wiktor B.", ""], ["Grabski", "Waldemar", ""], ["Bhattacharya", "Sambit", ""]]}, {"id": "1901.02391", "submitter": "Bernardo Furtado", "authors": "Bernardo Alves Furtado", "title": "Modeling tax distribution in metropolitan regions with PolicySpace", "comments": "10 pages, 1 figure, submitted to CAPS2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.GN cs.MA q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brazilian executive body has consistently vetoed legislative initiatives\neasing creation and emancipation of municipalities. The literature lists\nevidence of the negative results of municipal fragmentation, especially so for\nmetropolitan regions. In order to provide evidences for the argument of\nmetropolitan union, this paper quantifies the quality of life of metropolitan\ncitizens in the face of four alternative rules of distribution of municipal tax\ncollection. Methodologically, a validated agent-based spatial model is\nsimulated. On top of that, econometric models are tested using real exogenous\nvariables and simulated data. Results suggest two central conclusions. First,\nthe progressiveness of the Municipal Participation Fund and its relevance to a\nbetter quality of life in metropolitan municipalities is confirmed. Second,\nmunicipal financial merging would improve citizens' quality of life, compared\nto the status quo for 23 Brazilian metropolises. Further, the paper presents\nquantitative evidence that allows comparing alternative tax distributions for\neach of the 40 simulated metropolises, identifying more efficient forms of\nfiscal distribution and contributing to the literature and to contemporary\nparliamentary debate.\n", "versions": [{"version": "v1", "created": "Mon, 31 Dec 2018 19:01:03 GMT"}], "update_date": "2019-01-09", "authors_parsed": [["Furtado", "Bernardo Alves", ""]]}, {"id": "1901.02885", "submitter": "Antonio Luca Alfeo", "authors": "A.L. Alfeo, M.G.C.A. Cimino, N. De Francesco, A. Lazzeri, M. Lega, G.\n  Vaglini", "title": "Swarm coordination of mini-UAVs for target search using imperfect\n  sensors", "comments": null, "journal-ref": "Intelligent Decision Technologies, IOS Press, Vol. 12, Issue 2,\n  Pages 149-162, 2018", "doi": "10.3233/IDT-170317", "report-no": null, "categories": "cs.MA", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Unmanned Aerial Vehicles (UAVs) have a great potential to support search\ntasks in unstructured environments. Small, lightweight, low speed and agile\nUAVs, such as multi-rotors platforms can incorporate many kinds of sensors that\nare suitable for detecting object of interests in cluttered outdoor areas.\nHowever, due to their limited endurance, moderate computing power, and\nimperfect sensing, mini-UAVs should be into groups using swarm coordination\nalgorithms to perform tasks in a scalable, reliable and robust manner. In this\npaper a biologically-inspired mechanisms is adopted to coordinate drones\nperforming target search with imperfect sensors. In essence, coordination can\nbe achieved by combining stigmergic and flocking behaviors. Stigmergy occurs\nwhen a drone releases digital pheromone upon sensing of a potential target.\nSuch pheromones can be aggregated and diffused between flocking drones,\ncreating a spatiotemporal attractive potential field. Flocking occurs, as an\nemergent effect of alignment, separation and cohesion, where drones self\norganise with similar heading and dynamic arrangement as a group. The emergent\ncoordination of drones relies on the alignment of stigmergy and flocking\nstrategies. This paper reports on the design of the novel swarming algorithm,\nreviewing different strategies and measuring their performance on a number of\nsynthetic and real-world scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jan 2019 13:18:54 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Alfeo", "A. L.", ""], ["Cimino", "M. G. C. A.", ""], ["De Francesco", "N.", ""], ["Lazzeri", "A.", ""], ["Lega", "M.", ""], ["Vaglini", "G.", ""]]}, {"id": "1901.03258", "submitter": "Hyo-Sang Shin PhD", "authors": "Hyo-Sang Shin, Teng Li, Pau Segui-Gasco", "title": "Sample Greedy Based Task Allocation for Multiple Robot Systems", "comments": "25 pages. 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the task allocation problem for multi-robot systems. The\nmain issue with the task allocation problem is inherent complexity that makes\nfinding an optimal solution within a reasonable time almost impossible. To hand\nthe issue, this paper develops a task allocation algorithm that can be\ndecentralised by leveraging the submodularity concepts and sampling process.\nThe theoretical analysis reveals that the proposed algorithm can provide\napproximation guarantee of $1/2$ for the monotone submodular case and $1/4$ for\nthe non-monotone submodular case in average sense with polynomial time\ncomplexity. To examine the performance of the proposed algorithm and validate\nthe theoretical analysis results, we design a task allocation problem and\nperform numerical simulations. The simulation results confirm that the proposed\nalgorithm achieves solution quality, which is comparable to a state-of-the-art\nalgorithm in the monotone case, and much better quality in the non-monotone\ncase with significantly less computational complexity.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2019 16:36:22 GMT"}], "update_date": "2019-01-11", "authors_parsed": [["Shin", "Hyo-Sang", ""], ["Li", "Teng", ""], ["Segui-Gasco", "Pau", ""]]}, {"id": "1901.03426", "submitter": "Andr\\'e C. R. Martins", "authors": "Andr\\'e C. R. Martins", "title": "Network generation and evolution based on spatial and opinion dynamics\n  components", "comments": null, "journal-ref": null, "doi": "10.1142/S0129183119500773", "report-no": null, "categories": "physics.soc-ph cs.MA cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a model for a spatial network evolution based on a Metropolis\nsimulation is presented. The model uses an energy function that depends both on\nthe distance between the nodes and the stated preferences. The agents influence\ntheir network neighbors opinions using the CODA model. That means each agent\nhas a preference between two options based on its probabilistic assessment of\nwhich option is the best one. The algorithm generates realistic networks for\nopinion problems as well as temporal dynamics for those networks. The\ntransition from a random state to an ordered situation, as temperature\ndecreases, is described. Different types of networks appear based on the\nrelative strength of the spatial and opinion components of the energy.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2019 22:49:22 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Martins", "Andr\u00e9 C. R.", ""]]}, {"id": "1901.03656", "submitter": "Zhiyong Sun", "authors": "Zhiyong Sun, Qingchen Liu, Na Huang, Changbin Yu, and Brian D. O.\n  Anderson", "title": "Cooperative event-based rigid formation control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.MA cs.RO math.OC nlin.PS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses cooperative stabilization control of rigid formations\nvia an event-based approach. We first design a centralized event-based\nformation control system, in which a central event controller determines the\nnext triggering time and broadcasts the event signal to all the agents for\ncontrol input update. We then build on this approach to propose a distributed\nevent control strategy, in which each agent can use its local event trigger and\nlocal information to update the control input at its own event time. For both\ncases, the triggering condition, event function and triggering behavior are\ndiscussed in detail, and the exponential convergence of the event-based\nformation system is guaranteed.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jan 2019 17:11:47 GMT"}], "update_date": "2019-01-14", "authors_parsed": [["Sun", "Zhiyong", ""], ["Liu", "Qingchen", ""], ["Huang", "Na", ""], ["Yu", "Changbin", ""], ["Anderson", "Brian D. O.", ""]]}, {"id": "1901.03887", "submitter": "Emanuele Pesce Mr.", "authors": "Emanuele Pesce, Giovanni Montana", "title": "Improving Coordination in Small-Scale Multi-Agent Deep Reinforcement\n  Learning through Memory-driven Communication", "comments": null, "journal-ref": "Machine Learning (2020)", "doi": "10.1007/s10994-019-05864-5", "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning algorithms have recently been used to train\nmultiple interacting agents in a centralised manner whilst keeping their\nexecution decentralised. When the agents can only acquire partial observations\nand are faced with tasks requiring coordination and synchronisation skills,\ninter-agent communication plays an essential role. In this work, we propose a\nframework for multi-agent training using deep deterministic policy gradients\nthat enables concurrent, end-to-end learning of an explicit communication\nprotocol through a memory device. During training, the agents learn to perform\nread and write operations enabling them to infer a shared representation of the\nworld. We empirically demonstrate that concurrent learning of the communication\ndevice and individual policies can improve inter-agent coordination and\nperformance in small-scale systems. Our experimental results show that the\nproposed method achieves superior performance in scenarios with up to six\nagents. We illustrate how different communication patterns can emerge on six\ndifferent tasks of increasing complexity. Furthermore, we study the effects of\ncorrupting the communication channel, provide a visualisation of the\ntime-varying memory content as the underlying task is being solved and validate\nthe building blocks of the proposed memory device through ablation studies.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jan 2019 18:12:15 GMT"}, {"version": "v2", "created": "Thu, 29 Aug 2019 10:30:21 GMT"}, {"version": "v3", "created": "Tue, 29 Oct 2019 14:36:46 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Pesce", "Emanuele", ""], ["Montana", "Giovanni", ""]]}, {"id": "1901.04518", "submitter": "Markus Fr\\\"ohle", "authors": "Markus Fr\\\"ohle, Karl Granstr\\\"om, Henk Wymeersch", "title": "Decentralized Poisson Multi-Bernoulli Filtering for Vehicle Tracking", "comments": "14 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A decentralized Poisson multi-Bernoulli filter is proposed to track multiple\nvehicles using multiple high-resolution sensors. Independent filters estimate\nthe vehicles' presence, state, and shape using a Gaussian process extent model;\na decentralized filter is realized through fusion of the filters posterior\ndensities. An efficient implementation is achieved by parametric state\nrepresentation, utilization of single hypothesis tracks, and fusion of vehicle\ninformation based on a fusion mapping. Numerical results demonstrate the\nperformance.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jan 2019 19:03:41 GMT"}, {"version": "v2", "created": "Thu, 5 Mar 2020 13:58:10 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Fr\u00f6hle", "Markus", ""], ["Granstr\u00f6m", "Karl", ""], ["Wymeersch", "Henk", ""]]}, {"id": "1901.04585", "submitter": "Merim Dzaferagic", "authors": "Merim Dzaferagic, M. Majid Butt, Maria Murphy, Nicholas Kaminski, and\n  Nicola Marchetti", "title": "Agent-Based Modelling Approach for Distributed Decision Support in an\n  IoT Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An increasing number of emerging applications, e.g., internet of things,\nvehicular communications, augmented reality, and the growing complexity due to\nthe interoperability requirements of these systems, lead to the need to change\nthe tools used for the modeling and analysis of those networks. Agent-Based\nModeling (ABM) as a bottom-up modeling approach considers a network of\nautonomous agents interacting with each other, and therefore represents an\nideal framework to comprehend the interactions of heterogeneous nodes in a\ncomplex environment. Here, we investigate the suitability of ABM to model the\ncommunication aspects of a road traffic management system, as an example of an\nInternet of Things (IoT) network. We model, analyze and compare various Medium\nAccess Control (MAC) layer protocols for two different scenarios, namely\nuncoordinated and coordinated. Besides, we model the scheduling mechanisms for\nthe coordinated scenario as a high level MAC protocol by using three different\napproaches: Centralized Decision Maker, DESYNC and decentralized learning MAC\n(L-MAC). The results clearly show the importance of coordination between\nmultiple decision makers in order to improve the accuracy of information and\nspectrum utilization of the system.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jan 2019 13:19:14 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Dzaferagic", "Merim", ""], ["Butt", "M. Majid", ""], ["Murphy", "Maria", ""], ["Kaminski", "Nicholas", ""], ["Marchetti", "Nicola", ""]]}, {"id": "1901.04836", "submitter": "George Hassan-Coring", "authors": "George Hassan-Coring", "title": "Inferring Causality in Agent-Based Simulations - Literature Review", "comments": null, "journal-ref": null, "doi": "10.13140/RG.2.2.10905.67684", "report-no": null, "categories": "cs.MA stat.AP", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Complex systems have interested researchers across a broad range of fields\nfor many years and as computing has become more accesible and feasible, it is\nnow possible to simulate aspects of these systems. A major point of research is\nhow emergent behaviour arises and the underlying causes of it. This paper aims\nto discuss and compare different methods of identifying causal links between\nagents in such systems in order to gain further understanding of the structure.\n", "versions": [{"version": "v1", "created": "Mon, 24 Dec 2018 01:27:48 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Hassan-Coring", "George", ""]]}, {"id": "1901.04882", "submitter": "Wenjie Huang", "authors": "Wenjie Huang, Pham Viet Hai, William B. Haskell", "title": "Model and Reinforcement Learning for Markov Games with Risk Preferences", "comments": "38 pages, 6 tables, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.MA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We motivate and propose a new model for non-cooperative Markov game which\nconsiders the interactions of risk-aware players. This model characterizes the\ntime-consistent dynamic \"risk\" from both stochastic state transitions (inherent\nto the game) and randomized mixed strategies (due to all other players). An\nappropriate risk-aware equilibrium concept is proposed and the existence of\nsuch equilibria is demonstrated in stationary strategies by an application of\nKakutani's fixed point theorem. We further propose a simulation-based\nQ-learning type algorithm for risk-aware equilibrium computation. This\nalgorithm works with a special form of minimax risk measures which can\nnaturally be written as saddle-point stochastic optimization problems, and\ncovers many widely investigated risk measures. Finally, the almost sure\nconvergence of this simulation-based algorithm to an equilibrium is\ndemonstrated under some mild conditions. Our numerical experiments on a two\nplayer queuing game validate the properties of our model and algorithm, and\ndemonstrate their worth and applicability in real life competitive\ndecision-making.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2019 15:29:55 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 05:29:16 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Huang", "Wenjie", ""], ["Hai", "Pham Viet", ""], ["Haskell", "William B.", ""]]}, {"id": "1901.05669", "submitter": "Olivier Cardin", "authors": "Olivier Cardin (PSI, LS2N, IUT NANTES), Anne L'anton (IUT NANTES,\n  LS2N, PSI)", "title": "Proposition of an implementation framework enabling benchmarking of\n  Holonic Manufacturing Systems", "comments": null, "journal-ref": "Service Orientation in Holonic and Multi-Agent Manufacturing,\n  Proceedings of SOHOMA 2017, pp.267-280, 2018", "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Performing an overview of the benchmarking initiatives oriented towards the\nperformance evaluation of Holonic Manufacturing Systems shows that there are\nvery few of them. However, a comparison between all the isolated emu-lation\ndevelopments for benchmarking in literature was made, and showed that many\ncommon features could be extracted. Several deadlocks for a generic approach of\nthese developments are also exhibited. A global architecture dedicated to a\ngeneric performance evaluation platform design is suggested. This architecture\nintegrates a scenario manager, whose main specificities were detailed and\njustified. Those features are meant to both integrate the best practices\nencountered in literature and fulfil the missing aspects to respond to the\nproblematics.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jan 2019 07:57:54 GMT"}], "update_date": "2019-01-18", "authors_parsed": [["Cardin", "Olivier", "", "PSI, LS2N, IUT NANTES"], ["L'anton", "Anne", "", "IUT NANTES,\n  LS2N, PSI"]]}, {"id": "1901.05671", "submitter": "Olivier Cardin", "authors": "Carlos Indriago (IRCCyN, LS2N, PSI), Lat\\'efa Ghomri, Olivier Cardin\n  (PSI, LS2N, IUT NANTES)", "title": "H${}^2$CM-based holonic modeling of a gas pipeline", "comments": null, "journal-ref": "Service Orientation in Holonic and Multi-Agent Manufacturing,\n  Proceedings of SOHOMA 2017, pp.407-419, 2018", "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A gas pipeline is a relatively simple physical system, but the optimality of\nthe control is difficult to achieve. When switching from one kind of gas to\nanother , a volume of useless mixture is generated. Therefore, the control\nneeds to both respond to the demand and minimize the volume of lost gas. In\ncase of stable and perfectly known demand, scheduling techniques can be used,\nbut in other cases , calculation times are incompatible with an industrial\napplication. This article introduces the application of H${}^2$CM (Holonic\nHybrid Control Model) generic architecture on this specific case. The study\ncase is extensively presented. Then, the defined holonic architecture\n(H${}^2$CM compatible) is detailed, and the role and functions of each holon\nare presented. Finally, a tentative general control algorithm is suggested,\nwhich gives an insight on the actual algorithms that will be developed in\nperspective of this work.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jan 2019 08:00:12 GMT"}], "update_date": "2019-01-18", "authors_parsed": [["Indriago", "Carlos", "", "IRCCyN, LS2N, PSI"], ["Ghomri", "Lat\u00e9fa", "", "PSI, LS2N, IUT NANTES"], ["Cardin", "Olivier", "", "PSI, LS2N, IUT NANTES"]]}, {"id": "1901.06085", "submitter": "Max Kleiman-Weiner", "authors": "Michael Shum, Max Kleiman-Weiner, Michael L. Littman, Joshua B.\n  Tenenbaum", "title": "Theory of Minds: Understanding Behavior in Groups Through Inverse\n  Planning", "comments": "published in AAAI 2019; Michael Shum and Max Kleiman-Weiner\n  contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human social behavior is structured by relationships. We form teams, groups,\ntribes, and alliances at all scales of human life. These structures guide\nmulti-agent cooperation and competition, but when we observe others these\nunderlying relationships are typically unobservable and hence must be inferred.\nHumans make these inferences intuitively and flexibly, often making rapid\ngeneralizations about the latent relationships that underlie behavior from just\nsparse and noisy observations. Rapid and accurate inferences are important for\ndetermining who to cooperate with, who to compete with, and how to cooperate in\norder to compete. Towards the goal of building machine-learning algorithms with\nhuman-like social intelligence, we develop a generative model of multi-agent\naction understanding based on a novel representation for these latent\nrelationships called Composable Team Hierarchies (CTH). This representation is\ngrounded in the formalism of stochastic games and multi-agent reinforcement\nlearning. We use CTH as a target for Bayesian inference yielding a new\nalgorithm for understanding behavior in groups that can both infer hidden\nrelationships as well as predict future actions for multiple agents interacting\ntogether. Our algorithm rapidly recovers an underlying causal model of how\nagents relate in spatial stochastic games from just a few observations. The\npatterns of inference made by this algorithm closely correspond with human\njudgments and the algorithm makes the same rapid generalizations that people\ndo.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jan 2019 04:50:08 GMT"}], "update_date": "2019-01-21", "authors_parsed": [["Shum", "Michael", ""], ["Kleiman-Weiner", "Max", ""], ["Littman", "Michael L.", ""], ["Tenenbaum", "Joshua B.", ""]]}, {"id": "1901.06230", "submitter": "Alexander Peysakhovich", "authors": "Christian Kroer, Alexander Peysakhovich, Eric Sodomka, Nicolas E.\n  Stier-Moses", "title": "Computing large market equilibria using abstractions", "comments": null, "journal-ref": "Proceedings of the 2019 ACM Conference on Economics and\n  Computation. Association for Computing Machinery, New York, NY, USA, 745-746,\n  2019", "doi": "10.1145/3328526.3329553", "report-no": null, "categories": "cs.GT cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computing market equilibria is an important practical problem for market\ndesign (e.g. fair division, item allocation). However, computing equilibria\nrequires large amounts of information (e.g. all valuations for all buyers for\nall items) and compute power. We consider ameliorating these issues by applying\na method used for solving complex games: constructing a coarsened abstraction\nof a given market, solving for the equilibrium in the abstraction, and lifting\nthe prices and allocations back to the original market. We show how to bound\nimportant quantities such as regret, envy, Nash social welfare, Pareto\noptimality, and maximin share when the abstracted prices and allocations are\nused in place of the real equilibrium. We then study two abstraction methods of\ninterest for practitioners: 1) filling in unknown valuations using techniques\nfrom matrix completion, 2) reducing the problem size by aggregating groups of\nbuyers/items into smaller numbers of representative buyers/items and solving\nfor equilibrium in this coarsened market. We find that in real data\nallocations/prices that are relatively close to equilibria can be computed from\neven very coarse abstractions.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jan 2019 13:50:35 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Kroer", "Christian", ""], ["Peysakhovich", "Alexander", ""], ["Sodomka", "Eric", ""], ["Stier-Moses", "Nicolas E.", ""]]}, {"id": "1901.06709", "submitter": "Piotr Skowron", "authors": "Grzegorz Pierczy\\'nski and Piotr Skowron", "title": "Approval-Based Elections and Distortion of Voting Rules", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider elections where both voters and candidates can be associated with\npoints in a metric space and voters prefer candidates that are closer to those\nthat are farther away. It is often assumed that the optimal candidate is the\none that minimizes the total distance to the voters. Yet, the voting rules\noften do not have access to the metric space $M$ and only see preference\nrankings induced by $M$.Consequently, they often are incapable of selecting the\noptimal candidate. The distortion of a voting rule measures the worst-case loss\nof the quality being the result of having access only to preference rankings.\nWe extend the idea of distortion to approval-based preferences. First, we\ncompute the distortion of Approval Voting. Second, we introduce the concept of\nacceptability-based distortion---the main idea behind is that the optimal\ncandidate is the one that is acceptable to most voters. We determine\nacceptability-distortion for a number of rules, including Plurality, Borda,\n$k$-Approval, Veto, the Copeland's rule, Ranked Pairs, the Schulze's method,\nand STV.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jan 2019 18:22:58 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Pierczy\u0144ski", "Grzegorz", ""], ["Skowron", "Piotr", ""]]}, {"id": "1901.07531", "submitter": "Sebastian Trimpe", "authors": "Sebastian Trimpe and Dominik Baumann", "title": "Resource-aware IoT Control: Saving Communication through Predictive\n  Triggering", "comments": "16 pages, 15 figures, accepted article to appear in IEEE Internet of\n  Things Journal. arXiv admin note: text overlap with arXiv:1609.07534", "journal-ref": null, "doi": "10.1109/JIOT.2019.2894628", "report-no": null, "categories": "cs.SY cs.MA cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet of Things (IoT) interconnects multiple physical devices in\nlarge-scale networks. When the 'things' coordinate decisions and act\ncollectively on shared information, feedback is introduced between them.\nMultiple feedback loops are thus closed over a shared, general-purpose network.\nTraditional feedback control is unsuitable for design of IoT control because it\nrelies on high-rate periodic communication and is ignorant of the shared\nnetwork resource. Therefore, recent event-based estimation methods are applied\nherein for resource-aware IoT control allowing agents to decide online whether\ncommunication with other agents is needed, or not. While this can reduce\nnetwork traffic significantly, a severe limitation of typical event-based\napproaches is the need for instantaneous triggering decisions that leave no\ntime to reallocate freed resources (e.g., communication slots), which hence\nremain unused. To address this problem, novel predictive and self triggering\nprotocols are proposed herein. From a unified Bayesian decision framework, two\nschemes are developed: self triggers that predict, at the current triggering\ninstant, the next one; and predictive triggers that check at every time step,\nwhether communication will be needed at a given prediction horizon. The\nsuitability of these triggers for feedback control is demonstrated in hardware\nexperiments on a cart-pole, and scalability is discussed with a multi-vehicle\nsimulation.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jan 2019 21:45:55 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Trimpe", "Sebastian", ""], ["Baumann", "Dominik", ""]]}, {"id": "1901.07621", "submitter": "Eric Steinberger", "authors": "Eric Steinberger", "title": "Single Deep Counterfactual Regret Minimization", "comments": "4th version changes: fix minor notational errors; improve format;\n  incorporate structural feedback from NeurIPS review; *RESULTS ARE UNCHANGED*", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Counterfactual Regret Minimization (CFR) is the most successful algorithm for\nfinding approximate Nash equilibria in imperfect information games. However,\nCFR's reliance on full game-tree traversals limits its scalability. For this\nreason, the game's state- and action-space is often abstracted (i.e.\nsimplified) for CFR, and the resulting strategy is then translated back to the\nfull game, which requires extensive expert-knowledge and often converges to\nhighly exploitable policies. A recently proposed method, Deep CFR, applies deep\nlearning directly to CFR, allowing the agent to intrinsically abstract and\ngeneralize over the state-space from samples, without requiring expert\nknowledge. In this paper, we introduce Single Deep CFR (SD-CFR), a simplified\nvariant of Deep CFR that has a lower overall approximation error by avoiding\nthe training of an average strategy network. We show that SD-CFR is more\nattractive from a theoretical perspective and empirically outperforms Deep CFR\nwith respect to exploitability and one-on-one play in poker.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2019 21:52:29 GMT"}, {"version": "v2", "created": "Sun, 10 Feb 2019 15:04:02 GMT"}, {"version": "v3", "created": "Wed, 13 Mar 2019 17:32:41 GMT"}, {"version": "v4", "created": "Fri, 4 Oct 2019 14:55:20 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Steinberger", "Eric", ""]]}, {"id": "1901.07865", "submitter": "Lijun Sun", "authors": "Lijun Sun, Chao Lyu, Yuhui Shi", "title": "Cooperative coevolution of real predator robots and virtual robots in\n  the pursuit domain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The pursuit domain, or predator-prey problem is a standard testbed for the\nstudy of coordination techniques. In spite that its problem setup is apparently\nsimple, it is challenging for the research of the emerged swarm intelligence.\nThis paper presents a particle swarm optimization (PSO) based cooperative\ncoevolutionary algorithm for the predator robots, called CCPSO-R, where real\nand virtual robots coexist for the first time in an evolutionary algorithm\n(EA). Virtual robots sample and explore the vicinity of the corresponding real\nrobot and act as their action spaces, while the real robots consist of the real\npredators swarm who actually pursue the prey robot without fixed behavior rules\nunder the immediate guidance of the fitness function, which is designed in a\nmodular manner with very limited domain knowledges. In addition, kinematic\nlimits and collision avoidance considerations are integrated into the update\nrules of robots. Experiments are conducted on a scalable predator robots swarm\nwith 4 types of preys, the statistical results of which show the reliability,\ngenerality, and scalability of the proposed CCPSO-R. Finally, the codes of this\npaper are public availabe at: https://github.com/LijunSun90/pursuitCCPSO_R.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 13:15:20 GMT"}], "update_date": "2019-01-24", "authors_parsed": [["Sun", "Lijun", ""], ["Lyu", "Chao", ""], ["Shi", "Yuhui", ""]]}, {"id": "1901.08015", "submitter": "Tiancheng Li", "authors": "Tiancheng Li, Hongqi Fan, Jes\\'us G. Herrero and Juan M Corchado", "title": "Second Order Statistics Analysis and Comparison between Arithmetic and\n  Geometric Average Fusion", "comments": "17 pages, 8 figures", "journal-ref": "Information Fusion, 2019", "doi": "10.1016/j.inffus.2019.02.009", "report-no": null, "categories": "cs.SY cs.MA math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two fundamental approaches to information averaging are based on linear and\nlogarithmic combination, yielding the arithmetic average (AA) and geometric\naverage (GA) of the fusing initials, respectively. In the context of target\ntracking, the two most common formats of data to be fused are random variables\nand probability density functions, namely $v$-fusion and $f$-fusion,\nrespectively. In this work, we analyze and compare the second order statistics\n(including variance and mean square error) of AA and GA in terms of both\n$v$-fusion and $f$-fusion. The case of weighted Gaussian mixtures representing\nmultitarget densities in the presence of false alarms and misdetection (whose\nweight sums are not necessarily unit) is also considered, the result of which\nappears significantly different from that for a single target. In addition to\nexact derivation, exemplifying analysis and illustrations are provided.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 17:24:19 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Li", "Tiancheng", ""], ["Fan", "Hongqi", ""], ["Herrero", "Jes\u00fas G.", ""], ["Corchado", "Juan M", ""]]}, {"id": "1901.08021", "submitter": "Richard Klima", "authors": "Richard Klima, Daan Bloembergen, Michael Kaisers, Karl Tuyls", "title": "Robust Temporal Difference Learning for Critical Domains", "comments": "AAMAS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new Q-function operator for temporal difference (TD) learning\nmethods that explicitly encodes robustness against significant rare events\n(SRE) in critical domains. The operator, which we call the $\\kappa$-operator,\nallows to learn a robust policy in a model-based fashion without actually\nobserving the SRE. We introduce single- and multi-agent robust TD methods using\nthe operator $\\kappa$. We prove convergence of the operator to the optimal\nrobust Q-function with respect to the model using the theory of Generalized\nMarkov Decision Processes. In addition we prove convergence to the optimal\nQ-function of the original MDP given that the probability of SREs vanishes.\nEmpirical evaluations demonstrate the superior performance of $\\kappa$-based TD\nmethods both in the early learning phase as well as in the final converged\nstage. In addition we show robustness of the proposed method to small model\nerrors, as well as its applicability in a multi-agent context.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 17:34:51 GMT"}, {"version": "v2", "created": "Wed, 13 Mar 2019 09:27:46 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Klima", "Richard", ""], ["Bloembergen", "Daan", ""], ["Kaisers", "Michael", ""], ["Tuyls", "Karl", ""]]}, {"id": "1901.08106", "submitter": "David Balduzzi", "authors": "David Balduzzi, Marta Garnelo, Yoram Bachrach, Wojciech M. Czarnecki,\n  Julien Perolat, Max Jaderberg, Thore Graepel", "title": "Open-ended Learning in Symmetric Zero-sum Games", "comments": "ICML 2019, final version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Zero-sum games such as chess and poker are, abstractly, functions that\nevaluate pairs of agents, for example labeling them `winner' and `loser'. If\nthe game is approximately transitive, then self-play generates sequences of\nagents of increasing strength. However, nontransitive games, such as\nrock-paper-scissors, can exhibit strategic cycles, and there is no longer a\nclear objective -- we want agents to increase in strength, but against whom is\nunclear. In this paper, we introduce a geometric framework for formulating\nagent objectives in zero-sum games, in order to construct adaptive sequences of\nobjectives that yield open-ended learning. The framework allows us to reason\nabout population performance in nontransitive games, and enables the\ndevelopment of a new algorithm (rectified Nash response, PSRO_rN) that uses\ngame-theoretic niching to construct diverse populations of effective agents,\nproducing a stronger set of agents than existing algorithms. We apply PSRO_rN\nto two highly nontransitive resource allocation games and find that PSRO_rN\nconsistently outperforms the existing alternatives.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 19:56:17 GMT"}, {"version": "v2", "created": "Mon, 13 May 2019 16:53:45 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Balduzzi", "David", ""], ["Garnelo", "Marta", ""], ["Bachrach", "Yoram", ""], ["Czarnecki", "Wojciech M.", ""], ["Perolat", "Julien", ""], ["Jaderberg", "Max", ""], ["Graepel", "Thore", ""]]}, {"id": "1901.08463", "submitter": "Warut Suksompong", "authors": "Maria Kyropoulou, Warut Suksompong, Alexandros A. Voudouris", "title": "Almost Envy-Freeness in Group Resource Allocation", "comments": "Appears in the 28th International Joint Conference on Artificial\n  Intelligence (IJCAI), 2019", "journal-ref": "Theoretical Computer Science, 841:110-123 (2020)", "doi": "10.1016/j.tcs.2020.07.008", "report-no": null, "categories": "cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of fairly allocating indivisible goods between groups of\nagents using the recently introduced relaxations of envy-freeness. We consider\nthe existence of fair allocations under different assumptions on the valuations\nof the agents. In particular, our results cover cases of arbitrary monotonic,\nresponsive, and additive valuations, while for the case of binary valuations we\nfully characterize the cardinalities of two groups of agents for which a fair\nallocation can be guaranteed with respect to both envy-freeness up to one good\n(EF1) and envy-freeness up to any good (EFX). Moreover, we introduce a new\nmodel where the agents are not partitioned into groups in advance, but instead\nthe partition can be chosen in conjunction with the allocation of the goods. In\nthis model, we show that for agents with arbitrary monotonic valuations, there\nis always a partition of the agents into two groups of any given sizes along\nwith an EF1 allocation of the goods. We also provide an extension of this\nresult to any number of groups.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 15:49:07 GMT"}, {"version": "v2", "created": "Wed, 15 Jul 2020 00:49:36 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Kyropoulou", "Maria", ""], ["Suksompong", "Warut", ""], ["Voudouris", "Alexandros A.", ""]]}, {"id": "1901.08492", "submitter": "Sanjeevan Ahilan", "authors": "Sanjeevan Ahilan and Peter Dayan", "title": "Feudal Multi-Agent Hierarchies for Cooperative Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate how reinforcement learning agents can learn to cooperate.\nDrawing inspiration from human societies, in which successful coordination of\nmany individuals is often facilitated by hierarchical organisation, we\nintroduce Feudal Multi-agent Hierarchies (FMH). In this framework, a 'manager'\nagent, which is tasked with maximising the environmentally-determined reward\nfunction, learns to communicate subgoals to multiple, simultaneously-operating,\n'worker' agents. Workers, which are rewarded for achieving managerial subgoals,\ntake concurrent actions in the world. We outline the structure of FMH and\ndemonstrate its potential for decentralised learning and control. We find that,\ngiven an adequate set of subgoals from which to choose, FMH performs, and\nparticularly scales, substantially better than cooperative approaches that use\na shared reward function.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 16:44:16 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Ahilan", "Sanjeevan", ""], ["Dayan", "Peter", ""]]}, {"id": "1901.08761", "submitter": "Lenz Belzner", "authors": "Thomy Phan, Kyrill Schmid, Lenz Belzner, Thomas Gabor, Sebastian Feld,\n  Claudia Linnhoff-Popien", "title": "Distributed Policy Iteration for Scalable Approximation of Cooperative\n  Multi-Agent Policies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision making in multi-agent systems (MAS) is a great challenge due to\nenormous state and joint action spaces as well as uncertainty, making\ncentralized control generally infeasible. Decentralized control offers better\nscalability and robustness but requires mechanisms to coordinate on joint tasks\nand to avoid conflicts. Common approaches to learn decentralized policies for\ncooperative MAS suffer from non-stationarity and lacking credit assignment,\nwhich can lead to unstable and uncoordinated behavior in complex environments.\nIn this paper, we propose Strong Emergent Policy approximation (STEP), a\nscalable approach to learn strong decentralized policies for cooperative MAS\nwith a distributed variant of policy iteration. For that, we use function\napproximation to learn from action recommendations of a decentralized\nmulti-agent planning algorithm. STEP combines decentralized multi-agent\nplanning with centralized learning, only requiring a generative model for\ndistributed black box optimization. We experimentally evaluate STEP in two\nchallenging and stochastic domains with large state and joint action spaces and\nshow that STEP is able to learn stronger policies than standard multi-agent\nreinforcement learning algorithms, when combining multi-agent open-loop\nplanning with centralized function approximation. The learned policies can be\nreintegrated into the multi-agent planning process to further improve\nperformance.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 07:13:29 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Phan", "Thomy", ""], ["Schmid", "Kyrill", ""], ["Belzner", "Lenz", ""], ["Gabor", "Thomas", ""], ["Feld", "Sebastian", ""], ["Linnhoff-Popien", "Claudia", ""]]}, {"id": "1901.09216", "submitter": "Yaodong Yang Mr.", "authors": "Ying Wen, Yaodong Yang, Rui Luo, Jun Wang", "title": "Modelling Bounded Rationality in Multi-Agent Interactions by Generalized\n  Recursive Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Though limited in real-world decision making, most multi-agent reinforcement\nlearning (MARL) models assume perfectly rational agents -- a property hardly\nmet due to individual's cognitive limitation and/or the tractability of the\ndecision problem. In this paper, we introduce generalized recursive reasoning\n(GR2) as a novel framework to model agents with different \\emph{hierarchical}\nlevels of rationality; our framework enables agents to exhibit varying levels\nof \"thinking\" ability thereby allowing higher-level agents to best respond to\nvarious less sophisticated learners. We contribute both theoretically and\nempirically. On the theory side, we devise the hierarchical framework of GR2\nthrough probabilistic graphical models and prove the existence of a perfect\nBayesian equilibrium. Within the GR2, we propose a practical actor-critic\nsolver, and demonstrate its convergent property to a stationary point in\ntwo-player games through Lyapunov analysis. On the empirical side, we validate\nour findings on a variety of MARL benchmarks. Precisely, we first illustrate\nthe hierarchical thinking process on the Keynes Beauty Contest, and then\ndemonstrate significant improvements compared to state-of-the-art opponent\nmodeling baselines on the normal-form games and the cooperative navigation\nbenchmark.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jan 2019 13:55:55 GMT"}, {"version": "v2", "created": "Mon, 20 Jan 2020 22:28:11 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Wen", "Ying", ""], ["Yang", "Yaodong", ""], ["Luo", "Rui", ""], ["Wang", "Jun", ""]]}, {"id": "1901.09217", "submitter": "Piotr Faliszewski", "authors": "Edith Elkind, Piotr Faliszewski, Jean-Francois Laslier, Piotr Skowron,\n  Arkadii Slinko, Nimrod Talmon", "title": "What Do Multiwinner Voting Rules Do? An Experiment Over the\n  Two-Dimensional Euclidean Domain", "comments": "20 pages, 6 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We visualize aggregate outputs of popular multiwinner voting rules--SNTV,\nSTV, Bloc, k-Borda, Monroe, Chamberlin--Courant, and HarmonicBorda--for\nelections generated according to the two-dimensional Euclidean model. We\nconsider three applications of multiwinner voting, namely, parliamentary\nelections, portfolio/movie selection, and shortlisting, and use our results to\nunderstand which of our rules seem to be best suited for each application. In\nparticular, we show that STV (one of the few nontrivial rules used in real\nhigh-stake elections) exhibits excellent performance, whereas the Bloc rule\n(also often used in practice) performs poorly.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jan 2019 14:03:04 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Elkind", "Edith", ""], ["Faliszewski", "Piotr", ""], ["Laslier", "Jean-Francois", ""], ["Skowron", "Piotr", ""], ["Slinko", "Arkadii", ""], ["Talmon", "Nimrod", ""]]}, {"id": "1901.09367", "submitter": "Nicolas Loizou", "authors": "Filip Hanzely, Jakub Kone\\v{c}n\\'y, Nicolas Loizou, Peter Richt\\'arik,\n  Dmitry Grishchenko", "title": "A Privacy Preserving Randomized Gossip Algorithm via Controlled Noise\n  Insertion", "comments": "NeurIPS 2018, Privacy Preserving Machine Learning Workshop (camera\n  ready version). The full-length paper, which includes a number of additional\n  algorithms and results (including proofs of statements and experiments), is\n  available in arXiv:1706.07636", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DC cs.LG cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we present a randomized gossip algorithm for solving the average\nconsensus problem while at the same time protecting the information about the\ninitial private values stored at the nodes. We give iteration complexity bounds\nfor the method and perform extensive numerical experiments.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jan 2019 12:40:31 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Hanzely", "Filip", ""], ["Kone\u010dn\u00fd", "Jakub", ""], ["Loizou", "Nicolas", ""], ["Richt\u00e1rik", "Peter", ""], ["Grishchenko", "Dmitry", ""]]}, {"id": "1901.09660", "submitter": "Zhonghua Han", "authors": "Zhonghua Han, Xutian Tian, Xiaoting Dong, Fanyi Xie", "title": "Swarm Intelligent Algorithm For Re-entrant Hybrid Flow shop Scheduling\n  Problems", "comments": "Accepted for publication by International Journal of Simulation and\n  Process Modelling (IJSPM)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to solve Re-entrant Hybrid Flowshop (RHFS) scheduling problems and\nestablish simulations and processing models, this paper uses Wolf Pack\nAlgorithm (WPA) as global optimization. For local assignment, it takes minimum\nremaining time rule. Scouting behaviors of wolf are changed in former\noptimization by means of levy flight, extending searching ranges and increasing\nrapidity of convergence. When it comes to local extremum of WPA, dynamic\nregenerating individuals with high similarity adds diversity. Hanming distance\nis used to judge individual similarity for increased quality of individuals,\nenhanced search performance of the algorithm in solution space and promoted\nevolutionary vitality.A painting workshop in a bus manufacture enterprise owns\ntypical features of re-entrant hybrid flowshop. Regarding it as the algorithm\napplied target, this paper focus on resolving this problem with LDWPA (Dynamic\nwolf pack algorithm based on Levy Flight). Results show that LDWPA can solve\nre-entrant hybrid flowshop scheduling problems effectively.\n", "versions": [{"version": "v1", "created": "Sun, 9 Dec 2018 06:34:33 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Han", "Zhonghua", ""], ["Tian", "Xutian", ""], ["Dong", "Xiaoting", ""], ["Xie", "Fanyi", ""]]}, {"id": "1901.09833", "submitter": "Hassam Sheikh", "authors": "Hassam Ullah Sheikh, Ladislau B\\\"ol\\\"oni", "title": "The Emergence of Complex Bodyguard Behavior Through Multi-Agent\n  Reinforcement Learning", "comments": "Accepted at Autonomy in Teams Workshop at ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we are considering a scenario where a team of robot bodyguards\nare providing physical protection to a VIP in a crowded public space. We show\nthat the problem involves a complex mesh of interactions between the VIP and\nthe robots, between the robots themselves and the robots and the bystanders\nrespectively. We show how recently proposed multi-agent policy gradient\nreinforcement learning algorithms such as MADDPG can be successfully adapted to\nlearn collaborative robot behaviors that provide protection to the VIP.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 17:29:40 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Sheikh", "Hassam Ullah", ""], ["B\u00f6l\u00f6ni", "Ladislau", ""]]}, {"id": "1901.09837", "submitter": "Hassam Sheikh", "authors": "Hassam Ullah Sheikh, Ladislau B\\\"ol\\\"oni", "title": "Designing a Multi-Objective Reward Function for Creating Teams of\n  Robotic Bodyguards Using Deep Reinforcement Learning", "comments": "Accepted at the 1st Workshop on Goal Specifications for Reinforcement\n  Learning at ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We are considering a scenario where a team of bodyguard robots provides\nphysical protection to a VIP in a crowded public space. We use deep\nreinforcement learning to learn the policy to be followed by the robots. As the\nrobot bodyguards need to follow several difficult-to-reconcile goals, we study\nseveral primitive and composite reward functions and their impact on the\noverall behavior of the robotic bodyguards.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 17:33:45 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Sheikh", "Hassam Ullah", ""], ["B\u00f6l\u00f6ni", "Ladislau", ""]]}, {"id": "1901.09869", "submitter": "Juste Raimbault", "authors": "Juste Raimbault", "title": "Space and complexities of territorial systems", "comments": "11 pages, 3 figures. Translated from French, \"Espace et complexit\\'es\n  des syst\\`emes territoriaux\", Journ\\'ees de Rochebrune 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The spatial character of territorial systems plays a crucial role in the\nemergence of their complexities. This contribution aims at illustrating to what\nextent different types of complexities can be exhibited in models of such\nsystems. We develop from a theoretical viewpoint some arguments illustrating\nontological complexity, in the sense of the diversity and multidimensionality\nof possible representations, and then complexity in the sense of emergence,\ni.e. the necessity of the existence of several autonomous levels. We then\npropose numerical experiments to explore properties of complexity (dynamical\ncomplexity and co-evolution) within two simple models of urban morphogenesis.\nWe finally suggest other dimensions of complexity which could be typical of\nterritorial systems.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 18:24:02 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Raimbault", "Juste", ""]]}, {"id": "1901.10059", "submitter": "Fan-Yun Sun", "authors": "Fan-Yun Sun, Yen-Yu Chang, Yueh-Hua Wu, Shou-De Lin", "title": "A Regulation Enforcement Solution for Multi-agent Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human behaviors are regularized by a variety of norms or regulations, either\nto maintain orders or to enhance social welfare. If artificially intelligent\n(AI) agents make decisions on behalf of human beings, we would hope they can\nalso follow established regulations while interacting with humans or other AI\nagents. However, it is possible that an AI agent can opt to disobey the\nregulations (being defective) for self-interests. In this paper, we aim to\nanswer the following question: Consider a multi-agent decentralized\nenvironment. Agents make decisions in complete isolation of other agents. Each\nagent knows the state of its own MDP and its own actions but it does not know\nthe states and the actions taken by other players. There is a set of\nregulations for all agents to follow. Although most agents are benign and will\ncomply to regulations but not all agents are compliant at first, can we develop\na framework such that it is in the self-interest of non-compliant agents to\ncomply after all?. We first introduce the problem as Regulation Enforcement and\nformulate it using reinforcement learning and game theory under the scenario\nwhere agents make decisions in complete isolation of other agents. We then\npropose a solution based on the key idea that although we could not alter how\ndefective agents choose to behave, we can, however, leverage the aggregated\npower of compliant agents to boycott the defective ones. We conducted simulated\nexperiments on two scenarios: Replenishing Resource Management Dilemma and\nDiminishing Reward Shaping Enforcement, using deep multi-agent reinforcement\nlearning algorithms. We further use empirical game-theoretic analysis to show\nthat the method alters the resulting empirical payoff matrices in a way that\npromotes compliance (making mutual compliant a Nash Equilibrium).\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 01:12:25 GMT"}, {"version": "v2", "created": "Sat, 8 Jun 2019 15:44:47 GMT"}, {"version": "v3", "created": "Sat, 15 Jun 2019 17:56:43 GMT"}, {"version": "v4", "created": "Wed, 23 Oct 2019 16:24:17 GMT"}, {"version": "v5", "created": "Fri, 25 Oct 2019 13:37:09 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Sun", "Fan-Yun", ""], ["Chang", "Yen-Yu", ""], ["Wu", "Yueh-Hua", ""], ["Lin", "Shou-De", ""]]}, {"id": "1901.10421", "submitter": "Ruwan Wickramarachchi", "authors": "Sameh M. Saad, Terence Perera and Ruwan Wickramarachchi", "title": "A structured approach for the implementation of distributed\n  manufacturing simulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Manufacturing has been changing from a mainly inhouse effort to a distributed\nstyle in order to meet new challenges owing to globalization of markets and\nworldwide competition. Distributed simulation provides an attractive solution\nto construct cross enterprise simulations to evaluate the viability of the\nproposed distributed manufacturing enterprises. However, due to its complexity\nand high cost distributed simulation failed to gain a wide acceptance from\nindustrial users. The main objective of this paper is to address these issues\nand present a new structured approach to implement distributed simulation with\ncost effective and easy to implementable tools. A simplified approach for model\npartitioning for distributed simulation is also included in the proposed\napproach. The implementation of distributed manufacturing simulation is\nillustrated with Arena, Microsoft Message Queue (MSMQ) and Visual Basic for\nApplications (VBA).\n", "versions": [{"version": "v1", "created": "Tue, 1 Jan 2019 17:22:43 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Saad", "Sameh M.", ""], ["Perera", "Terence", ""], ["Wickramarachchi", "Ruwan", ""]]}, {"id": "1901.10564", "submitter": "Tairan Liu", "authors": "Tairan Liu, Marcio de Queiroz, Pengpeng Zhang and Milad Khaledyan", "title": "Directed Formation Control of n Planar Agents with Distance and Area\n  Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we take a first step towards generalizing a recently proposed\nmethod for dealing with the problem of convergence to incorrect equilibrium\npoints of distance-based formation controllers. Specifically, we introduce a\ndistance and area-based scheme for the formation control of $n$-agent systems\nin two dimensions using directed graphs and the single-integrator model. We\nshow that under certain conditions on the edge lengths of the triangulated\ndesired formation, the control ensures almost-global convergence to the correct\nformation.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 21:25:00 GMT"}, {"version": "v2", "created": "Mon, 4 Feb 2019 21:46:45 GMT"}], "update_date": "2019-02-06", "authors_parsed": [["Liu", "Tairan", ""], ["de Queiroz", "Marcio", ""], ["Zhang", "Pengpeng", ""], ["Khaledyan", "Milad", ""]]}, {"id": "1901.10923", "submitter": "David Mguni", "authors": "David Mguni, Joel Jennings, Sergio Valcarcel Macua, Emilio Sison,\n  Sofia Ceppi, Enrique Munoz de Cote", "title": "Coordinating the Crowd: Inducing Desirable Equilibria in Non-Cooperative\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world systems such as taxi systems, traffic networks and smart\ngrids involve self-interested actors that perform individual tasks in a shared\nenvironment. However, in such systems, the self-interested behaviour of agents\nproduces welfare inefficient and globally suboptimal outcomes that are\ndetrimental to all - some common examples are congestion in traffic networks,\ndemand spikes for resources in electricity grids and over-extraction of\nenvironmental resources such as fisheries. We propose an incentive-design\nmethod which modifies agents' rewards in non-cooperative multi-agent systems\nthat results in independent, self-interested agents choosing actions that\nproduce optimal system outcomes in strategic settings. Our framework combines\nmulti-agent reinforcement learning to simulate (real-world) agent behaviour and\nblack-box optimisation to determine the optimal modifications to the agents'\nrewards or incentives given some fixed budget that results in optimal system\nperformance. By modifying the reward functions and generating agents'\nequilibrium responses within a sequence of offline Markov games, our method\nenables optimal incentive structures to be determined offline through iterative\nupdates of the reward functions of a simulated game. Our theoretical results\nshow that our method converges to reward modifications that induce system\noptimality. We demonstrate the applications of our framework by tackling a\nchallenging problem within economics that involves thousands of selfish agents\nand tackle a traffic congestion problem.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 16:10:07 GMT"}], "update_date": "2019-01-31", "authors_parsed": [["Mguni", "David", ""], ["Jennings", "Joel", ""], ["Macua", "Sergio Valcarcel", ""], ["Sison", "Emilio", ""], ["Ceppi", "Sofia", ""], ["de Cote", "Enrique Munoz", ""]]}, {"id": "1901.10927", "submitter": "Nuno Crokidakis", "authors": "Andr\\'e L. Oestereich, Marcelo A. Pires, Nuno Crokidakis", "title": "Three-state opinion dynamics in modular networks", "comments": "11 pages, 7 figures, to appear in Phys. Rev. E", "journal-ref": "Phys. Rev. E 100, 032312 (2019)", "doi": "10.1103/PhysRevE.100.032312", "report-no": null, "categories": "physics.soc-ph cond-mat.stat-mech cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we study the opinion evolution in a community-based population\nwith intergroup interactions. We address two issues. First, we consider that\nsuch intergroup interactions can be negative with some probability $p$. We\ndevelop a coupled mean-field approximation that still preserves the community\nstructure and it is able to capture the richness of the results arising from\nour Monte Carlo simulations: continuous and discontinuous order-disorder\ntransitions as well as nonmonotonic ordering for an intermediate community\nstrength. In the second part, we consider only positive interactions, but with\nthe presence of inflexible agents holding a minority opinion. We also consider\nan indecision noise: a probability $q$ that allows the spontaneous change of\nopinions to the neutral state. Our results show that the modular structure\nleads to a nonmonotonic global ordering as $q$ increases. This inclination\ntoward neutrality plays a dual role: a moderated propensity to neutrality helps\nthe initial minority to become a majority, but this noise-driven opinion\nswitching becomes less pronounced if the agents are too susceptible to become\nneutral.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 16:21:12 GMT"}, {"version": "v2", "created": "Wed, 11 Sep 2019 17:17:43 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Oestereich", "Andr\u00e9 L.", ""], ["Pires", "Marcelo A.", ""], ["Crokidakis", "Nuno", ""]]}, {"id": "1901.11000", "submitter": "James Usevitch", "authors": "James Usevitch, Dimitra Panagou", "title": "Determining r- and (r,s)-Robustness of Digraphs Using Mixed Integer\n  Linear Programming", "comments": "arXiv admin note: text overlap with arXiv:1810.01784. AUTHOR NOTES:\n  This is the extended preprint version of the article accepted by Automatica.\n  The file arXiv:1810.01784 is the conference version of this article", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been an increase in the use of resilient control algorithms based\non the graph theoretic properties of $r$- and $(r,s)$-robustness. These\nalgorithms guarantee consensus of normally behaving agents in the presence of a\nbounded number of arbitrarily misbehaving agents if the values of the integers\n$r$ and $s$ are sufficiently large. However, determining an arbitrary graph's\nrobustness is a highly nontrivial problem. This paper introduces a novel method\nfor determining the $r$- and $(r,s)$-robustness of digraphs using mixed integer\nlinear programming; to the best of the authors' knowledge it is the first time\nthat mixed integer programming methods have been applied to the robustness\ndetermination problem. The approach only requires knowledge of the graph\nLaplacian matrix, and can be formulated with binary integer variables. Mixed\ninteger programming algorithms such as branch-and-bound are used to iteratively\ntighten the lower and upper bounds on $r$ and $s$. Simulations are presented\nwhich compare the performance of this approach to prior robustness\ndetermination algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 18:47:36 GMT"}, {"version": "v2", "created": "Tue, 13 Aug 2019 20:19:52 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Usevitch", "James", ""], ["Panagou", "Dimitra", ""]]}, {"id": "1901.11282", "submitter": "Keisuke Okumura", "authors": "Keisuke Okumura, Manao Machida, Xavier D\\'efago, Yasumasa Tamura", "title": "Priority Inheritance with Backtracking for Iterative Multi-agent Path\n  Finding", "comments": "8 pages, 2 figures, 2 tables, to be presented at IJCAI-19, Aug 2019,\n  Macao", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.DC cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Multi-agent Path Finding (MAPF) problem consists in all agents having to\nmove to their own destinations while avoiding collisions. In practical\napplications to the problem, such as for navigation in an automated warehouse,\nMAPF must be solved iteratively. We present here a novel approach to iterative\nMAPF, that we call Priority Inheritance with Backtracking (PIBT). PIBT gives a\nunique priority to each agent every timestep, so that all movements are\nprioritized. Priority inheritance, which aims at dealing effectively with\npriority inversion in path adjustment within a small time window, can be\napplied iteratively and a backtracking protocol prevents agents from being\nstuck. We prove that, regardless of their number, all agents are guaranteed to\nreach their destination within finite time, when the environment is a graph\nsuch that all pairs of adjacent nodes belong to a simple cycle of length 3 or\nmore (e.g., biconnected). Our implementation of PIBT can be fully decentralized\nwithout global communication. Experimental results over various scenarios\nconfirm that PIBT is adequate both for finding paths in large environments with\nmany agents, as well as for conveying packages in an automated warehouse.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 09:27:22 GMT"}, {"version": "v2", "created": "Thu, 7 Mar 2019 09:27:33 GMT"}, {"version": "v3", "created": "Sun, 23 Jun 2019 04:03:27 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Okumura", "Keisuke", ""], ["Machida", "Manao", ""], ["D\u00e9fago", "Xavier", ""], ["Tamura", "Yasumasa", ""]]}, {"id": "1901.11454", "submitter": "Minne Li", "authors": "Minne Li, Zhiwei (Tony) Qin, Yan Jiao, Yaodong Yang, Zhichen Gong, Jun\n  Wang, Chenxi Wang, Guobin Wu, Jieping Ye", "title": "Efficient Ridesharing Order Dispatching with Mean Field Multi-Agent\n  Reinforcement Learning", "comments": "11 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental question in any peer-to-peer ridesharing system is how to, both\neffectively and efficiently, dispatch user's ride requests to the right driver\nin real time. Traditional rule-based solutions usually work on a simplified\nproblem setting, which requires a sophisticated hand-crafted weight design for\neither centralized authority control or decentralized multi-agent scheduling\nsystems. Although recent approaches have used reinforcement learning to provide\ncentralized combinatorial optimization algorithms with informative weight\nvalues, their single-agent setting can hardly model the complex interactions\nbetween drivers and orders. In this paper, we address the order dispatching\nproblem using multi-agent reinforcement learning (MARL), which follows the\ndistributed nature of the peer-to-peer ridesharing problem and possesses the\nability to capture the stochastic demand-supply dynamics in large-scale\nridesharing scenarios. Being more reliable than centralized approaches, our\nproposed MARL solutions could also support fully distributed execution through\nrecent advances in the Internet of Vehicles (IoV) and the Vehicle-to-Network\n(V2N). Furthermore, we adopt the mean field approximation to simplify the local\ninteractions by taking an average action among neighborhoods. The mean field\napproximation is capable of globally capturing dynamic demand-supply variations\nby propagating many local interactions between agents and the environment. Our\nextensive experiments have shown the significant improvements of MARL order\ndispatching algorithms over several strong baselines on the gross merchandise\nvolume (GMV), and order response rate measures. Besides, the simulated\nexperiments with real data have also justified that our solution can alleviate\nthe supply-demand gap during the rush hours, thus possessing the capability of\nreducing traffic congestion.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 16:26:48 GMT"}], "update_date": "2019-02-01", "authors_parsed": [["Li", "Minne", "", "Tony"], ["Zhiwei", "", "", "Tony"], ["Qin", "", ""], ["Jiao", "Yan", ""], ["Yang", "Yaodong", ""], ["Gong", "Zhichen", ""], ["Wang", "Jun", ""], ["Wang", "Chenxi", ""], ["Wu", "Guobin", ""], ["Ye", "Jieping", ""]]}, {"id": "1901.11463", "submitter": "Sixie Yu", "authors": "Sixie Yu, Yevgeniy Vorobeychik", "title": "Distributionally Robust Removal of Malicious Nodes from Networks", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA cs.SI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  An important problem in networked systems is detection and removal of\nsuspected malicious nodes. A crucial consideration in such settings is the\nuncertainty endemic in detection, coupled with considerations of network\nconnectivity, which impose indirect costs from mistakely removing benign nodes\nas well as failing to remove malicious nodes. A recent approach proposed to\naddress this problem directly tackles these considerations, but has a\nsignificant limitation: it assumes that the decision maker has accurate\nknowledge of the joint maliciousness probability of the nodes on the network.\nThis is clearly not the case in practice, where such a distribution is at best\nan estimate from limited evidence. To address this problem, we propose a\ndistributionally robust framework for optimal node removal. While the problem\nis NP-Hard, we propose a principled algorithmic technique for solving it\napproximately based on duality combined with Semidefinite Programming\nrelaxation. A combination of both theoretical and empirical analysis, the\nlatter using both synthetic and real data, provide strong evidence that our\nalgorithmic approach is highly effective and, in particular, is significantly\nmore robust than the state of the art.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 16:40:27 GMT"}], "update_date": "2019-02-01", "authors_parsed": [["Yu", "Sixie", ""], ["Vorobeychik", "Yevgeniy", ""]]}]