[{"id": "1908.00600", "submitter": "Shahin Khobahi", "authors": "Shahin Khobahi, Mojtaba Soltanalian, Feng Jiang and A. Lee\n  Swindlehurst", "title": "Optimized Transmission for Parameter Estimation in Wireless Sensor\n  Networks", "comments": "Accepted for publication in IEEE Transactions on Signal and\n  Information Processing over Networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.DC cs.MA cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A central problem in analog wireless sensor networks is to design the gain or\nphase-shifts of the sensor nodes (i.e. the relaying configuration) in order to\nachieve an accurate estimation of some parameter of interest at a fusion\ncenter, or more generally, at each node by employing a distributed parameter\nestimation scheme. In this paper, by using an over-parametrization of the\noriginal design problem, we devise a cyclic optimization approach that can\nhandle tuning both gains and phase-shifts of the sensor nodes, even in\nintricate scenarios involving sensor selection or discrete phase-shifts. Each\niteration of the proposed design framework consists of a combination of the\nGram-Schmidt process and power method-like iterations, and as a result, enjoys\na low computational cost. Along with formulating the design problem for a\nfusion center, we further present a consensus-based framework for decentralized\nestimation of deterministic parameters in a distributed network, which results\nin a similar sensor gain design problem. The numerical results confirm the\ncomputational advantage of the suggested approach in comparison with the\nstate-of-the-art methods---an advantage that becomes more pronounced when the\nsensor network grows large.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 19:57:56 GMT"}], "update_date": "2019-08-05", "authors_parsed": [["Khobahi", "Shahin", ""], ["Soltanalian", "Mojtaba", ""], ["Jiang", "Feng", ""], ["Swindlehurst", "A. Lee", ""]]}, {"id": "1908.01022", "submitter": "Ross Allen", "authors": "Ross E. Allen, Jayesh K. Gupta, Jaime Pena, Yutai Zhou, Javona White\n  Bear, Mykel J. Kochenderfer", "title": "Health-Informed Policy Gradients for Multi-Agent Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a definition of system health in the context of multiple\nagents optimizing a joint reward function. We use this definition as a credit\nassignment term in a policy gradient algorithm to distinguish the contributions\nof individual agents to the global reward. The health-informed credit\nassignment is then extended to a multi-agent variant of the proximal policy\noptimization algorithm and demonstrated on particle and multiwalker robot\nenvironments that have characteristics such as system health, risk-taking,\nsemi-expendable agents, continuous action spaces, and partial observability. We\nshow significant improvement in learning performance compared to policy\ngradient methods that do not perform multi-agent credit assignment.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 19:20:29 GMT"}, {"version": "v2", "created": "Thu, 17 Oct 2019 16:12:54 GMT"}, {"version": "v3", "created": "Thu, 19 Mar 2020 20:44:39 GMT"}, {"version": "v4", "created": "Mon, 4 Jan 2021 20:16:46 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Allen", "Ross E.", ""], ["Gupta", "Jayesh K.", ""], ["Pena", "Jaime", ""], ["Zhou", "Yutai", ""], ["Bear", "Javona White", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "1908.01059", "submitter": "Xin Wang", "authors": "Xin Wang, Hideaki Ishii, Linkang Du, Peng Cheng, Jiming Chen", "title": "Privacy-preserving Distributed Machine Learning via Local Randomization\n  and ADMM Perturbation", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2020.3009007", "report-no": null, "categories": "cs.LG cs.CR cs.DC cs.MA cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the proliferation of training data, distributed machine learning (DML)\nis becoming more competent for large-scale learning tasks. However, privacy\nconcerns have to be given priority in DML, since training data may contain\nsensitive information of users. In this paper, we propose a privacy-preserving\nADMM-based DML framework with two novel features: First, we remove the\nassumption commonly made in the literature that the users trust the server\ncollecting their data. Second, the framework provides heterogeneous privacy for\nusers depending on data's sensitive levels and servers' trust degrees. The\nchallenging issue is to keep the accumulation of privacy losses over ADMM\niterations minimal. In the proposed framework, a local randomization approach,\nwhich is differentially private, is adopted to provide users with\nself-controlled privacy guarantee for the most sensitive information. Further,\nthe ADMM algorithm is perturbed through a combined noise-adding method, which\nsimultaneously preserves privacy for users' less sensitive information and\nstrengthens the privacy protection of the most sensitive information. We\nprovide detailed analyses on the performance of the trained model according to\nits generalization error. Finally, we conduct extensive experiments using\nreal-world datasets to validate the theoretical results and evaluate the\nclassification performance of the proposed framework.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 06:31:16 GMT"}, {"version": "v2", "created": "Mon, 9 Sep 2019 07:47:40 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Wang", "Xin", ""], ["Ishii", "Hideaki", ""], ["Du", "Linkang", ""], ["Cheng", "Peng", ""], ["Chen", "Jiming", ""]]}, {"id": "1908.01161", "submitter": "Rihab Abdul Razak", "authors": "Rihab Abdul Razak, Srikant Sukumar, Hoam Chung", "title": "Distributed Adaptive Coverage Control of Differential Drive Robotic\n  Sensors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.MA cs.RO cs.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with the deployment of multiple mobile robots in\norder to autonomously cover a region Q. The region to be covered is described\nusing a density function which may not be apriori known. In this paper, we pose\nthe coverage problem as an optimization problem over some space of functions on\nQ. In particular, we look at L 2 -distance based coverage algorithm and derive\nadaptive control laws for the same. We also propose a modified adaptive control\nlaw incorporating consensus for better parameter convergence. We implement the\nalgorithms on real differential drive robots with both simulated density\nfunction as well as density function implemented using light sources. We also\ncompare the L 2 -distance based method with the locational optimization method\nusing experiments.\n", "versions": [{"version": "v1", "created": "Sat, 3 Aug 2019 12:45:28 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Razak", "Rihab Abdul", ""], ["Sukumar", "Srikant", ""], ["Chung", "Hoam", ""]]}, {"id": "1908.01421", "submitter": "Hossein K. Mousavi", "authors": "Hossein K. Mousavi and Nader Motee", "title": "Explicit Characterization of Performance of a Class of Networked Linear\n  Control Systems", "comments": "detailed version of a paper of the same name to be submitted to IEEE\n  TCNS", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.MA cs.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We show that the steady-state variance as a performance measure for a class\nof networked linear control systems is expressible as the summation of a\nrational function over the Laplacian eigenvalues of the network graph.\nMoreover, we characterize the role of connectivity thresholds for the feedback\n(and observer) gain design of these networks. We use our framework to derive\nbounds and scaling laws for the performance of the dynamical network. Our\napproach generalizes and unifies the previous results on the performance\nmeasure of these networks for the case of arbitrary nodal dynamics. We bring\nextensions of our methodology for the case of decentralized observer-based\noutput feedback as well as a class of composite networks. Numerous examples\nsupport our theoretical contributions.\n", "versions": [{"version": "v1", "created": "Sun, 4 Aug 2019 23:14:29 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Mousavi", "Hossein K.", ""], ["Motee", "Nader", ""]]}, {"id": "1908.01695", "submitter": "Koen Holtman", "authors": "Koen Holtman", "title": "Corrigibility with Utility Preservation", "comments": "Version 2 has improvements to the presentation and fixes typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Corrigibility is a safety property for artificially intelligent agents. A\ncorrigible agent will not resist attempts by authorized parties to alter the\ngoals and constraints that were encoded in the agent when it was first started.\nThis paper shows how to construct a safety layer that adds corrigibility to\narbitrarily advanced utility maximizing agents, including possible future\nagents with Artificial General Intelligence (AGI). The layer counter-acts the\nemergent incentive of advanced agents to resist such alteration. A detailed\nmodel for agents which can reason about preserving their utility function is\ndeveloped, and used to prove that the corrigibility layer works as intended in\na large set of non-hostile universes. The corrigible agents have an emergent\nincentive to protect key elements of their corrigibility layer. However,\nhostile universes may contain forces strong enough to break safety features.\nSome open problems related to graceful degradation when an agent is\nsuccessfully attacked are identified. The results in this paper were obtained\nby concurrently developing an AGI agent simulator, an agent model, and proofs.\nThe simulator is available under an open source license. The paper contains\nsimulation results which illustrate the safety related properties of corrigible\nAGI agents in detail.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 15:40:45 GMT"}, {"version": "v2", "created": "Fri, 3 Apr 2020 09:50:09 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Holtman", "Koen", ""]]}, {"id": "1908.02034", "submitter": "Juste Raimbault", "authors": "Juste Raimbault", "title": "Second-order Control of Complex Systems with Correlated Synthetic Data", "comments": "18 pages, 5 figures", "journal-ref": "Complex Adaptive Systems Modeling, 7, 4 (2019)", "doi": "10.1186/s40294-019-0065-y", "report-no": null, "categories": "stat.AP cs.MA physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The generation of synthetic data is an essential tool to study complex\nsystems, allowing for example to test models of these in precisely controlled\nsettings, or to parametrize simulation models when data is missing. This paper\nfocuses on the generation of synthetic data with an emphasis on correlation\nstructure. We introduce a new methodology to generate such correlated synthetic\ndata. It is implemented in the field of socio-spatial systems, more precisely\nby coupling an urban growth model with a transportation network generation\nmodel. We also show the genericity of the method with an application on\nfinancial time-series. The simulation results show that the generation of\ncorrelated synthetic data for such systems is indeed feasible within a broad\nrange of correlations, and suggest applications of such synthetic datasets.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 09:18:17 GMT"}, {"version": "v2", "created": "Fri, 22 Nov 2019 18:34:42 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Raimbault", "Juste", ""]]}, {"id": "1908.02138", "submitter": "Stevan Tomic", "authors": "Stevan Tomic, Federico Pecora and Alessandro Saffiotti", "title": "Robby is Not a Robber (anymore): On the Use of Institutions for Learning\n  Normative Behavior", "comments": "16 pages, 11 figures, Submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Future robots should follow human social norms in order to be useful and\naccepted in human society. In this paper, we leverage already existing social\nknowledge in human societies by capturing it in our framework through the\nnotion of social norms. We show how norms can be used to guide a reinforcement\nlearning agent towards achieving normative behavior and apply the same set of\nnorms over different domains. Thus, we are able to: (1) provide a way to\nintuitively encode social knowledge (through norms); (2) guide learning towards\nnormative behaviors (through an automatic norm reward system); and (3) achieve\na transfer of learning by abstracting policies; Finally, (4) the method is not\ndependent on a particular RL algorithm. We show how our approach can be seen as\na means to achieve abstract representation and learn procedural knowledge based\non the declarative semantics of norms and discuss possible implications of this\nin some areas of cognitive science.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 23:46:55 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Tomic", "Stevan", ""], ["Pecora", "Federico", ""], ["Saffiotti", "Alessandro", ""]]}, {"id": "1908.02269", "submitter": "Julien Roy", "authors": "Julien Roy, Paul Barde, F\\'elix G. Harvey, Derek Nowrouzezahrai and\n  Christopher Pal", "title": "Promoting Coordination through Policy Regularization in Multi-Agent Deep\n  Reinforcement Learning", "comments": "23 pages, 16 figures. This revised version contains additional\n  results and minor edits", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multi-agent reinforcement learning, discovering successful collective\nbehaviors is challenging as it requires exploring a joint action space that\ngrows exponentially with the number of agents. While the tractability of\nindependent agent-wise exploration is appealing, this approach fails on tasks\nthat require elaborate group strategies. We argue that coordinating the agents'\npolicies can guide their exploration and we investigate techniques to promote\nsuch an inductive bias. We propose two policy regularization methods: TeamReg,\nwhich is based on inter-agent action predictability and CoachReg that relies on\nsynchronized behavior selection. We evaluate each approach on four challenging\ncontinuous control tasks with sparse rewards that require varying levels of\ncoordination as well as on the discrete action Google Research Football\nenvironment. Our experiments show improved performance across many cooperative\nmulti-agent problems. Finally, we analyze the effects of our proposed methods\non the policies that our agents learn and show that our methods successfully\nenforce the qualities that we propose as proxies for coordinated behaviors.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 17:48:17 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 20:33:08 GMT"}, {"version": "v3", "created": "Tue, 11 Feb 2020 19:24:21 GMT"}, {"version": "v4", "created": "Mon, 9 Nov 2020 16:30:41 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Roy", "Julien", ""], ["Barde", "Paul", ""], ["Harvey", "F\u00e9lix G.", ""], ["Nowrouzezahrai", "Derek", ""], ["Pal", "Christopher", ""]]}, {"id": "1908.02357", "submitter": "Kaiqing Zhang", "authors": "Kaiqing Zhang and Erik Miehling and Tamer Ba\\c{s}ar", "title": "Online Planning for Decentralized Stochastic Control with Partial\n  History Sharing", "comments": "Accepted to American Control Conference (ACC) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In decentralized stochastic control, standard approaches for sequential\ndecision-making, e.g. dynamic programming, quickly become intractable due to\nthe need to maintain a complex information state. Computational challenges are\nfurther compounded if agents do not possess complete model knowledge. In this\npaper, we take advantage of the fact that in many problems agents share some\ncommon information, or history, termed partial history sharing. Under this\ninformation structure the policy search space is greatly reduced. We propose a\nprovably convergent, online tree-search based algorithm that does not require a\nclosed-form model or explicit communication among agents. Interestingly, our\nalgorithm can be viewed as a generalization of several existing heuristic\nsolvers for decentralized partially observable Markov decision processes. To\ndemonstrate the applicability of the model, we propose a novel collaborative\nintrusion response model, where multiple agents (defenders) possessing\nasymmetric information aim to collaboratively defend a computer network.\nNumerical results demonstrate the performance of our algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 20:38:58 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Zhang", "Kaiqing", ""], ["Miehling", "Erik", ""], ["Ba\u015far", "Tamer", ""]]}, {"id": "1908.02747", "submitter": "Brian Swenson", "authors": "Brian Swenson, Ryan Murray, H. Vincent Poor, and Soummya Kar", "title": "Distributed Gradient Descent: Nonconvergence to Saddle Points and the\n  Stable-Manifold Theorem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper studies a distributed gradient descent (DGD) process and considers\nthe problem of showing that in nonconvex optimization problems, DGD typically\nconverges to local minima rather than saddle points. The paper considers\nunconstrained minimization of a smooth objective function. In centralized\nsettings, the problem of demonstrating nonconvergence to saddle points of\ngradient descent (and variants) is typically handled by way of the\nstable-manifold theorem from classical dynamical systems theory. However, the\nclassical stable-manifold theorem is not applicable in distributed settings.\nThe paper develops an appropriate stable-manifold theorem for DGD showing that\nconvergence to saddle points may only occur from a low-dimensional stable\nmanifold. Under appropriate assumptions (e.g., coercivity), this result implies\nthat DGD typically converges to local minima and not to saddle points.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 17:57:59 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2019 17:46:35 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Swenson", "Brian", ""], ["Murray", "Ryan", ""], ["Poor", "H. Vincent", ""], ["Kar", "Soummya", ""]]}, {"id": "1908.02805", "submitter": "Dongsheng Ding", "authors": "Dongsheng Ding, Xiaohan Wei, Zhuoran Yang, Zhaoran Wang, and Mihailo\n  R. Jovanovi\\'c", "title": "Fast Multi-Agent Temporal-Difference Learning via Homotopy Stochastic\n  Primal-Dual Optimization", "comments": "26 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a distributed multi-agent policy evaluation problem in\nreinforcement learning. In our setup, a group of agents with jointly observed\nstates and private local actions and rewards collaborates to learn the value\nfunction of a given policy. When the dimension of state-action space is large,\nthe temporal-difference learning with linear function approximation is widely\nused. Under the assumption that the samples are i.i.d., the best-known\nconvergence rate for multi-agent temporal-difference learning is\n$O(1/\\sqrt{T})$ minimizing the mean square projected Bellman error. In this\npaper, we formulate the temporal-difference learning as a distributed\nstochastic saddle point problem, and propose a new homotopy primal-dual\nalgorithm by adaptively restarting the gradient update from the average of\nprevious iterations. We prove that our algorithm enjoys an $O(1/T)$ convergence\nrate up to logarithmic factors of $T$, thereby significantly improving the\npreviously-known convergence results on multi-agent temporal-difference\nlearning. Furthermore, since our result explicitly takes into account the\nMarkovian nature of the sampling in policy evaluation, it addresses a broader\nclass of problems than the commonly used i.i.d. sampling scenario. From a\nstochastic optimization perspective, to the best of our knowledge, the proposed\nhomotopy primal-dual algorithm is the first to achieve $O(1/T)$ convergence\nrate for distributed stochastic saddle point problem.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 19:25:37 GMT"}, {"version": "v2", "created": "Sat, 24 Aug 2019 19:43:07 GMT"}, {"version": "v3", "created": "Wed, 2 Sep 2020 05:57:16 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Ding", "Dongsheng", ""], ["Wei", "Xiaohan", ""], ["Yang", "Zhuoran", ""], ["Wang", "Zhaoran", ""], ["Jovanovi\u0107", "Mihailo R.", ""]]}, {"id": "1908.02999", "submitter": "Fabian Schilling", "authors": "Fabian Schilling and Julien Lecoeur and Fabrizio Schiano and Dario\n  Floreano", "title": "Learning Vision-based Flight in Drone Swarms by Imitation", "comments": "8 pages, 8 figures, accepted for publication in the IEEE Robotics and\n  Automation Letters (RA-L) on July 28, 2019. arXiv admin note: substantial\n  text overlap with arXiv:1809.00543", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decentralized drone swarms deployed today either rely on sharing of positions\namong agents or detecting swarm members with the help of visual markers. This\nwork proposes an entirely visual approach to coordinate markerless drone swarms\nbased on imitation learning. Each agent is controlled by a small and efficient\nconvolutional neural network that takes raw omnidirectional images as inputs\nand predicts 3D velocity commands that match those computed by a flocking\nalgorithm. We start training in simulation and propose a simple yet effective\nunsupervised domain adaptation approach to transfer the learned controller to\nthe real world. We further train the controller with data collected in our\nmotion capture hall. We show that the convolutional neural network trained on\nthe visual inputs of the drone can learn not only robust inter-agent collision\navoidance but also cohesion of the swarm in a sample-efficient manner. The\nneural controller effectively learns to localize other agents in the visual\ninput, which we show by visualizing the regions with the most influence on the\nmotion of an agent. We remove the dependence on sharing positions among swarm\nmembers by taking only local visual information into account for control. Our\nwork can therefore be seen as the first step towards a fully decentralized,\nvision-based swarm without the need for communication or visual markers.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 10:19:48 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Schilling", "Fabian", ""], ["Lecoeur", "Julien", ""], ["Schiano", "Fabrizio", ""], ["Floreano", "Dario", ""]]}, {"id": "1908.03080", "submitter": "Paulin Jacquot Dr", "authors": "Olivier Beaude, Pascal Benchimol, St\\'ephane Gaubert, Paulin Jacquot,\n  Nadia Oudjane", "title": "A Privacy-preserving Method to Optimize Distributed Resource Allocation", "comments": "35 pages, revised version accepted for publication in SIAM journal on\n  Optimization (SIOPT)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CR cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a resource allocation problem involving a large number of agents\nwith individual constraints subject to privacy, and a central operator whose\nobjective is to optimize a global, possibly nonconvex, cost while satisfying\nthe agents' constraints, for instance an energy operator in charge of the\nmanagement of energy consumption flexibilities of many individual consumers. We\nprovide a privacy-preserving algorithm that does compute the optimal allocation\nof resources, avoiding each agent to reveal her private information\n(constraints and individual solution profile) neither to the central operator\nnor to a third party. Our method relies on an aggregation procedure: we compute\niteratively a global allocation of resources, and gradually ensure existence of\na disaggregation, that is individual profiles satisfying agents' private\nconstraints, by a protocol involving the generation of polyhedral cuts and\nsecure multiparty computations (SMC). To obtain these cuts, we use an alternate\nprojection method, which is implemented locally by each agent, preserving her\nprivacy needs. We adress especially the case in which the local and global\nconstraints define a transportation polytope. Then, we provide theoretical\nconvergence estimates together with numerical results, showing that the\nalgorithm can be effectively used to solve the allocation problem in high\ndimension, while addressing privacy issues.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 07:09:41 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 15:02:41 GMT"}, {"version": "v3", "created": "Mon, 22 Jun 2020 21:51:56 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Beaude", "Olivier", ""], ["Benchimol", "Pascal", ""], ["Gaubert", "St\u00e9phane", ""], ["Jacquot", "Paulin", ""], ["Oudjane", "Nadia", ""]]}, {"id": "1908.03309", "submitter": "Dongjun Kim", "authors": "Dongjun Kim, Tae-Sub Yun, Il-Chul Moon", "title": "Automatic Calibration of Dynamic and Heterogeneous Parameters in\n  Agent-based Model", "comments": "31 pages, 12 figures, Journal of Autonomous Agents and Multi-Agent\n  Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While simulations have been utilized in diverse domains, such as urban growth\nmodeling, market dynamics modeling, etc; some of these applications may require\nvalidations based upon some real-world observations modeled in the simulation,\nas well. This validation has been categorized into either qualitative\nface-validation or quantitative empirical validation, but as the importance and\nthe accumulation of data grows, the importance of the quantitative validation\nhas been highlighted in the recent studies, i.e. digital twin. The key\ncomponent of quantitative validation is finding a calibrated set of parameters\nto regenerate the real-world observations with simulation models. While this\nparameter calibration has been fixed throughout a simulation execution, this\npaper expands the static parameter calibration in two dimensions: dynamic\ncalibration and heterogeneous calibration. First, dynamic calibration changes\nthe parameter values over the simulation period by reflecting the simulation\noutput trend. Second, heterogeneous calibration changes the parameter values\nper simulated entity clusters by considering the similarities of entity states.\nWe experimented the suggested calibrations on one hypothetical case and another\nreal-world case. As a hypothetical scenario, we use the Wealth Distribution\nModel to illustrate how our calibration works. As a real-world scenario, we\nselected Real Estate Market Model because of three reasons. First, the models\nhave heterogeneous entities as being agent-based models; second, they are\neconomic models with real-world trends over time; and third, they are\napplicable to the real-world scenarios where we can gather validation data.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 04:33:54 GMT"}], "update_date": "2019-08-12", "authors_parsed": [["Kim", "Dongjun", ""], ["Yun", "Tae-Sub", ""], ["Moon", "Il-Chul", ""]]}, {"id": "1908.03761", "submitter": "Xiaoqiang Wang", "authors": "Xiaoqiang Wang, Liangjun Ke, Zhimin Qiao, and Xinghua Chai", "title": "Large-Scale Traffic Signal Control Using a Novel Multi-Agent\n  Reinforcement Learning", "comments": "14 pages, 11 figures", "journal-ref": null, "doi": "10.1109/TCYB.2020.3015811", "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding the optimal signal timing strategy is a difficult task for the\nproblem of large-scale traffic signal control (TSC). Multi-Agent Reinforcement\nLearning (MARL) is a promising method to solve this problem. However, there is\nstill room for improvement in extending to large-scale problems and modeling\nthe behaviors of other agents for each individual agent. In this paper, a new\nMARL, called Cooperative double Q-learning (Co-DQL), is proposed, which has\nseveral prominent features. It uses a highly scalable independent double\nQ-learning method based on double estimators and the UCB policy, which can\neliminate the over-estimation problem existing in traditional independent\nQ-learning while ensuring exploration. It uses mean field approximation to\nmodel the interaction among agents, thereby making agents learn a better\ncooperative strategy. In order to improve the stability and robustness of the\nlearning process, we introduce a new reward allocation mechanism and a local\nstate sharing method. In addition, we analyze the convergence properties of the\nproposed algorithm. Co-DQL is applied on TSC and tested on a multi-traffic\nsignal simulator. According to the results obtained on several traffic\nscenarios, Co- DQL outperforms several state-of-the-art decentralized MARL\nalgorithms. It can effectively shorten the average waiting time of the vehicles\nin the whole road system.\n", "versions": [{"version": "v1", "created": "Sat, 10 Aug 2019 14:19:21 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 12:01:34 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Wang", "Xiaoqiang", ""], ["Ke", "Liangjun", ""], ["Qiao", "Zhimin", ""], ["Chai", "Xinghua", ""]]}, {"id": "1908.03821", "submitter": "Sidney Feygin", "authors": "Sidney A. Feygin, Jessica R. Lazarus, Edward H. Forscher, Valentine\n  Golfier-Vetterli, Jonathan W. Lee, Abhishek Gupta, Rashid A. Waraich, Colin\n  J.R. Sheppard, Alexandre M. Bayen", "title": "BISTRO: Berkeley Integrated System for Transportation Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article introduces BISTRO, a new open source transportation planning\ndecision support system that uses an agent-based simulation and optimization\napproach to anticipate and develop adaptive plans for possible technological\ndisruptions and growth scenarios. The new framework was evaluated in the\ncontext of a machine learning competition hosted within Uber Technologies,\nInc., in which over 400 engineers and data scientists participated. For the\npurposes of this competition, a benchmark model, based on the city of Sioux\nFalls, South Dakota, was adapted to the BISTRO framework. An important finding\nof this study was that in spite of rigorous analysis and testing done prior to\nthe competition, the two top-scoring teams discovered an unbounded region of\nthe search space, rendering the solutions largely uninterpretable for the\npurposes of decision-support. On the other hand, a follow-on study aimed to fix\nthe objective function, served to demonstrate BISTRO's utility as a\nhuman-in-the-loop cyberphysical system: one that uses scenario-based\noptimization algorithms as a feedback mechanism to assist urban planners with\niteratively refining objective function and constraints specification on\nintervention strategies such that the portfolio of transportation intervention\nstrategy alternatives eventually chosen achieves high-level regional planning\ngoals developed through participatory stakeholder engagement practices.\n", "versions": [{"version": "v1", "created": "Sat, 10 Aug 2019 22:43:12 GMT"}, {"version": "v2", "created": "Wed, 22 Jan 2020 18:18:02 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Feygin", "Sidney A.", ""], ["Lazarus", "Jessica R.", ""], ["Forscher", "Edward H.", ""], ["Golfier-Vetterli", "Valentine", ""], ["Lee", "Jonathan W.", ""], ["Gupta", "Abhishek", ""], ["Waraich", "Rashid A.", ""], ["Sheppard", "Colin J. R.", ""], ["Bayen", "Alexandre M.", ""]]}, {"id": "1908.03963", "submitter": "Afshin Oroojlooy", "authors": "Afshin OroojlooyJadid and Davood Hajinezhad", "title": "A Review of Cooperative Multi-Agent Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Reinforcement Learning has made significant progress in multi-agent\nsystems in recent years. In this review article, we have focused on presenting\nrecent approaches on Multi-Agent Reinforcement Learning (MARL) algorithms. In\nparticular, we have focused on five common approaches on modeling and solving\ncooperative multi-agent reinforcement learning problems: (I) independent\nlearners, (II) fully observable critic, (III) value function factorization,\n(IV) consensus, and (IV) learn to communicate. First, we elaborate on each of\nthese methods, possible challenges, and how these challenges were mitigated in\nthe relevant papers. If applicable, we further make a connection among\ndifferent papers in each category. Next, we cover some new emerging research\nareas in MARL along with the relevant recent papers. Due to the recent success\nof MARL in real-world applications, we assign a section to provide a review of\nthese applications and corresponding articles.\n  Also, a list of available environments for MARL research is provided in this\nsurvey. Finally, the paper is concluded with proposals on the possible research\ndirections.\n", "versions": [{"version": "v1", "created": "Sun, 11 Aug 2019 21:40:11 GMT"}, {"version": "v2", "created": "Wed, 18 Sep 2019 02:59:54 GMT"}, {"version": "v3", "created": "Sun, 14 Jun 2020 03:06:48 GMT"}, {"version": "v4", "created": "Fri, 30 Apr 2021 04:14:28 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["OroojlooyJadid", "Afshin", ""], ["Hajinezhad", "Davood", ""]]}, {"id": "1908.04425", "submitter": "Navid Rezazadeh", "authors": "Navid Rezazadeh and Solmaz S. Kia", "title": "A sub-modular receding horizon solution for mobile multi-agent\n  persistent monitoring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of persistent monitoring of a finite number of\ninter-connected geographical nodes by a group of heterogeneous mobile agents.\nWe assign to each geographical node a concave and increasing reward function\nthat resets to zero after an agent's visit. Then, we design the optimal\ndispatch policy of which nodes to visit at what time and by what agent by\nfinding a policy set that maximizes a utility that is defined as the total\nreward collected at visit times. We show that this optimization problem is\nNP-hard and its computational complexity increases exponentially with the\nnumber of the agents and the length of the mission horizon. By showing that the\nutility function is a monotone increasing and submodular set function of\nagents' policy, we proceed to propose a suboptimal dispatch policy design with\na known optimality gap. To reduce the time complexity of constructing the\nfeasible search set and also to induce robustness to changes in the operational\nfactors, we perform our suboptimal policy design in a receding horizon fashion.\nThen, to compensate for the shortsightedness of the receding horizon approach\nfor reward distribution beyond the feasible policies of the agents over the\nreceding horizon, we add a new term to our utility, which provides a measure of\nnodal importance beyond the receding horizon's sight. This term gives the\npolicy design an intuition to steer the agents towards the nodes with higher\nrewards on the patrolling graph. Finally, we discuss how our proposed algorithm\ncan be implemented in a decentralized manner. A simulation study demonstrates\nour results.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 22:24:19 GMT"}, {"version": "v2", "created": "Tue, 24 Mar 2020 06:04:31 GMT"}, {"version": "v3", "created": "Wed, 21 Oct 2020 05:05:07 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Rezazadeh", "Navid", ""], ["Kia", "Solmaz S.", ""]]}, {"id": "1908.04469", "submitter": "Chaowei Tan", "authors": "Chaowei Tan, Zhennan Yan, Shaoting Zhang, Kang Li, and Dimitris N.\n  Metaxas", "title": "Collaborative Multi-agent Learning for MR Knee Articular Cartilage\n  Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG cs.MA", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The 3D morphology and quantitative assessment of knee articular cartilages\n(i.e., femoral, tibial, and patellar cartilage) in magnetic resonance (MR)\nimaging is of great importance for knee radiographic osteoarthritis (OA)\ndiagnostic decision making. However, effective and efficient delineation of all\nthe knee articular cartilages in large-sized and high-resolution 3D MR knee\ndata is still an open challenge. In this paper, we propose a novel framework to\nsolve the MR knee cartilage segmentation task. The key contribution is the\nadversarial learning based collaborative multi-agent segmentation network. In\nthe proposed network, we use three parallel segmentation agents to label\ncartilages in their respective region of interest (ROI), and then fuse the\nthree cartilages by a novel ROI-fusion layer. The collaborative learning is\ndriven by an adversarial sub-network. The ROI-fusion layer not only fuses the\nindividual cartilages from multiple agents, but also backpropagates the\ntraining loss from the adversarial sub-network to each agent to enable joint\nlearning of shape and spatial constraints. Extensive evaluations are conducted\non a dataset including hundreds of MR knee volumes with diverse populations,\nand the proposed method shows superior performance.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 02:58:17 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Tan", "Chaowei", ""], ["Yan", "Zhennan", ""], ["Zhang", "Shaoting", ""], ["Li", "Kang", ""], ["Metaxas", "Dimitris N.", ""]]}, {"id": "1908.04486", "submitter": "Ziqi Yan", "authors": "Ziqi Yan, Gang Li, Jiqiang Liu", "title": "Private Rank Aggregation under Local Differential Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a method for answer aggregation in crowdsourced data management, rank\naggregation aims to combine different agents' answers or preferences over the\ngiven alternatives into an aggregate ranking which agrees the most with the\npreferences. However, since the aggregation procedure relies on a data curator,\nthe privacy within the agents' preference data could be compromised when the\ncurator is untrusted. Existing works that guarantee differential privacy in\nrank aggregation all assume that the data curator is trusted. In this paper, we\nformulate and address the problem of locally differentially private rank\naggregation, in which the agents have no trust in the data curator. By\nleveraging the approximate rank aggregation algorithm KwikSort, the Randomized\nResponse mechanism, and the Laplace mechanism, we propose an effective and\nefficient protocol LDP-KwikSort. Theoretical and empirical results show that\nthe solution LDP-KwikSort:RR can achieve the acceptable trade-off between the\nutility of aggregate ranking and the privacy protection of agents' pairwise\npreferences.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 04:46:10 GMT"}, {"version": "v2", "created": "Mon, 9 Mar 2020 04:14:25 GMT"}, {"version": "v3", "created": "Tue, 30 Jun 2020 10:17:26 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Yan", "Ziqi", ""], ["Li", "Gang", ""], ["Liu", "Jiqiang", ""]]}, {"id": "1908.04573", "submitter": "Yue Wang", "authors": "Yue Wang, Yao Wan, Chenwei Zhang, Lixin Cui, Lu Bai, and Philip S. Yu", "title": "Competitive Multi-Agent Deep Reinforcement Learning with Counterfactual\n  Thinking", "comments": "This paper is accepted by ICDM'19 as a short paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Counterfactual thinking describes a psychological phenomenon that people\nre-infer the possible results with different solutions about things that have\nalready happened. It helps people to gain more experience from mistakes and\nthus to perform better in similar future tasks. This paper investigates the\ncounterfactual thinking for agents to find optimal decision-making strategies\nin multi-agent reinforcement learning environments. In particular, we propose a\nmulti-agent deep reinforcement learning model with a structure which mimics the\nhuman-psychological counterfactual thinking process to improve the competitive\nabilities for agents. To this end, our model generates several possible actions\n(intent actions) with a parallel policy structure and estimates the rewards and\nregrets for these intent actions based on its current understanding of the\nenvironment. Our model incorporates a scenario-based framework to link the\nestimated regrets with its inner policies. During the iterations, our model\nupdates the parallel policies and the corresponding scenario-based regrets for\nagents simultaneously. To verify the effectiveness of our proposed model, we\nconduct extensive experiments on two different environments with real-world\napplications. Experimental results show that counterfactual thinking can\nactually benefit the agents to obtain more accumulative rewards from the\nenvironments with fair information by comparing to their opponents while\nkeeping high performing efficiency.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 10:55:24 GMT"}, {"version": "v2", "created": "Fri, 16 Aug 2019 13:40:16 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Wang", "Yue", ""], ["Wan", "Yao", ""], ["Zhang", "Chenwei", ""], ["Cui", "Lixin", ""], ["Bai", "Lu", ""], ["Yu", "Philip S.", ""]]}, {"id": "1908.05135", "submitter": "Elia Bruni", "authors": "Mathijs Mul, Diane Bouchacourt, Elia Bruni", "title": "Mastering emergent language: learning to guide in simulated navigation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To cooperate with humans effectively, virtual agents need to be able to\nunderstand and execute language instructions. A typical setup to achieve this\nis with a scripted teacher which guides a virtual agent using language\ninstructions. However, such setup has clear limitations in scalability and,\nmore importantly, it is not interactive. Here, we introduce an autonomous agent\nthat uses discrete communication to interactively guide other agents to\nnavigate and act on a simulated environment. The developed communication\nprotocol is trainable, emergent and requires no additional supervision. The\nemergent language speeds up learning of new agents, it generalizes across\nincrementally more difficult tasks and, contrary to most other emergent\nlanguages, it is highly interpretable. We demonstrate how the emitted messages\ncorrelate with particular actions and observations, and how new agents become\nless dependent on this guidance as training progresses. By exploiting the\ncorrelations identified in our analysis, we manage to successfully address the\nagents in their own language.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 14:10:21 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Mul", "Mathijs", ""], ["Bouchacourt", "Diane", ""], ["Bruni", "Elia", ""]]}, {"id": "1908.05347", "submitter": "Jeffrey Peters", "authors": "Jeffrey R. Peters, Amit Surana, Grant S. Taylor, Terry S. Turpin,\n  Francesco Bullo", "title": "UAV Surveillance Under Visibility and Dwell-Time Constraints: A\n  Sampling-Based Approach", "comments": null, "journal-ref": "J. Dyn. Sys., Meas., Control. 2019;141(6):064501-064501-6", "doi": "10.1115/1.4042669", "report-no": null, "categories": "eess.SY cs.MA cs.RO cs.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A framework is introduced for planning unmanned aerial vehicle flight paths\nfor visual surveillance of ground targets, each having particular viewing\nrequirements. Specifically, each target is associated with a set of imaging\nparameters, including a desired (i) tilt angle, (ii) azimuth, with the option\nof a 360-degree view, and (iii) dwell-time. Tours are sought to image the\ntargets, while minimizing both the total mission time and the time required to\nreach the initial target. An epsilon-constraint scalarization is used to pose\nthe multi-objective problem as a constrained optimization, which, through\ncareful discretization, can be approximated as a discrete graph-search. It is\nshown that, in many cases, this approximation is equivalent to a generalized\ntraveling salesperson problem. A heuristic procedure for solving the discrete\napproximation and recovering solutions to the full routing problem is\npresented, and is shown to have resolution completeness properties. Algorithms\nare illustrated through numerical studies.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 16:01:56 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Peters", "Jeffrey R.", ""], ["Surana", "Amit", ""], ["Taylor", "Grant S.", ""], ["Turpin", "Terry S.", ""], ["Bullo", "Francesco", ""]]}, {"id": "1908.05437", "submitter": "Emilio Ferrara", "authors": "Jim Blythe, John Bollenbacher, Di Huang, Pik-Mai Hui, Rachel Krohn,\n  Diogo Pacheco, Goran Muric, Anna Sapienza, Alexey Tregubov, Yong-Yeol Ahn,\n  Alessandro Flammini, Kristina Lerman, Filippo Menczer, Tim Weninger, Emilio\n  Ferrara", "title": "Massive Multi-Agent Data-Driven Simulations of the GitHub Ecosystem", "comments": null, "journal-ref": "International Conference on Practical Applications of Agents and\n  Multi-Agent Systems, pp. 3-15. Springer, Cham, 2019", "doi": "10.1007/978-3-030-24209-1_1", "report-no": null, "categories": "cs.MA cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simulating and predicting planetary-scale techno-social systems poses heavy\ncomputational and modeling challenges. The DARPA SocialSim program set the\nchallenge to model the evolution of GitHub, a large collaborative\nsoftware-development ecosystem, using massive multi-agent simulations. We\ndescribe our best performing models and our agent-based simulation framework,\nwhich we are currently extending to allow simulating other planetary-scale\ntechno-social systems. The challenge problem measured participant's ability,\ngiven 30 months of meta-data on user activity on GitHub, to predict the next\nmonths' activity as measured by a broad range of metrics applied to ground\ntruth, using agent-based simulation. The challenge required scaling to a\nsimulation of roughly 3 million agents producing a combined 30 million actions,\nacting on 6 million repositories with commodity hardware. It was also important\nto use the data optimally to predict the agent's next moves. We describe the\nagent framework and the data analysis employed by one of the winning teams in\nthe challenge. Six different agent models were tested based on a variety of\nmachine learning and statistical methods. While no single method proved the\nmost accurate on every metric, the broadly most successful sampled from a\nstationary probability distribution of actions and repositories for each agent.\nTwo reasons for the success of these agents were their use of a distinct\ncharacterization of each agent, and that GitHub users change their behavior\nrelatively slowly.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 06:44:27 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Blythe", "Jim", ""], ["Bollenbacher", "John", ""], ["Huang", "Di", ""], ["Hui", "Pik-Mai", ""], ["Krohn", "Rachel", ""], ["Pacheco", "Diogo", ""], ["Muric", "Goran", ""], ["Sapienza", "Anna", ""], ["Tregubov", "Alexey", ""], ["Ahn", "Yong-Yeol", ""], ["Flammini", "Alessandro", ""], ["Lerman", "Kristina", ""], ["Menczer", "Filippo", ""], ["Weninger", "Tim", ""], ["Ferrara", "Emilio", ""]]}, {"id": "1908.05630", "submitter": "Yasin Yazicioglu", "authors": "Raghavendra Bhat, Yasin Yazicioglu, and Derya Aksaray", "title": "Distributed Path Planning for Executing Cooperative Tasks with Time\n  Windows", "comments": "Accepted to the 8th IFAC Workshop on Distributed Estimation and\n  Control in Networked Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.MA cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the distributed planning of robot trajectories for optimal\nexecution of cooperative tasks with time windows. In this setting, each task\nhas a value and is completed if sufficiently many robots are simultaneously\npresent at the necessary location within the specified time window. Tasks keep\narriving periodically over cycles. The task specifications (required number of\nrobots, location, time window, and value) are unknown a priori and the robots\ntry to maximize the value of completed tasks by planning their own trajectories\nfor the upcoming cycle based on their past observations in a distributed\nmanner. Considering the recharging and maintenance needs, robots are required\nto start and end each cycle at their assigned stations located in the\nenvironment. We map this problem to a game theoretic formulation and maximize\nthe collective performance through distributed learning. Some simulation\nresults are also provided to demonstrate the performance of the proposed\napproach.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 16:41:56 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Bhat", "Raghavendra", ""], ["Yazicioglu", "Yasin", ""], ["Aksaray", "Derya", ""]]}, {"id": "1908.05737", "submitter": "EPTCS", "authors": "Francesco Olivieri (Data61, CSIRO (Australia)), Guido Governatori\n  (Data61, CSIRO (Australia)), Claudio Tomazzoli (Department of Computer\n  Science, University of Verona), Matteo Cristani (Department of Computer\n  Science, University of Verona)", "title": "Applications of Linear Defeasible Logic: combining resource consumption\n  and exceptions to energy management and business processes", "comments": "In Proceedings DICE-FOPARA 2019, arXiv:1908.04478. arXiv admin note:\n  substantial text overlap with arXiv:1809.03656", "journal-ref": "EPTCS 298, 2019, pp. 1-14", "doi": "10.4204/EPTCS.298.1", "report-no": null, "categories": "cs.AI cs.LO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear Logic and Defeasible Logic have been adopted to formalise different\nfeatures of knowledge representation: consumption of resources, and non\nmonotonic reasoning in particular to represent exceptions. Recently, a\nframework to combine sub-structural features, corresponding to the consumption\nof resources, with defeasibility aspects to handle potentially conflicting\ninformation, has been discussed in literature, by some of the authors. Two\napplications emerged that are very relevant: energy management and business\nprocess management. We illustrate a set of guide lines to determine how to\napply linear defeasible logic to those contexts.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 01:57:11 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Olivieri", "Francesco", "", "Data61, CSIRO"], ["Governatori", "Guido", "", "Data61, CSIRO"], ["Tomazzoli", "Claudio", "", "Department of Computer\n  Science, University of Verona"], ["Cristani", "Matteo", "", "Department of Computer\n  Science, University of Verona"]]}, {"id": "1908.05822", "submitter": "Roland Bouffanais", "authors": "Jabez L. Kit, Audelia G. Dharmawan, David Mateo, Shaohui Foong, Gim\n  Song Soh, Roland Bouffanais, and Kristin L. Wood", "title": "Decentralized Multi-Floor Exploration by a Swarm of Miniature Robots\n  Teaming with Wall-Climbing Units", "comments": "Accepted for publication in IEEE-MRS 2019, Rutgers University, New\n  Brunswick (NJ), USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of collectively exploring unknown and\ndynamic environments with a decentralized heterogeneous multi-robot system\nconsisting of multiple units of two variants of a miniature robot. The first\nvariant-a wheeled ground unit-is at the core of a swarm of floor-mapping robots\nexhibiting scalability, robustness and flexibility. These properties are\nsystematically tested and quantitatively evaluated in unstructured and dynamic\nenvironments, in the absence of any supporting infrastructure. The results of\nrepeated sets of experiments show a consistent performance for all three\nfeatures, as well as the possibility to inject units into the system while it\nis operating. Several units of the second variant-a wheg-based wall-climbing\nunit-are used to support the swarm of mapping robots when simultaneously\nexploring multiple floors by expanding the distributed communication channel\nnecessary for the coordinated behavior among platforms. Although the\noccupancy-grid maps obtained can be large, they are fully distributed. Not a\nsingle robotic unit possesses the overall map, which is not required by our\ncooperative path-planning strategy.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 02:52:23 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Kit", "Jabez L.", ""], ["Dharmawan", "Audelia G.", ""], ["Mateo", "David", ""], ["Foong", "Shaohui", ""], ["Soh", "Gim Song", ""], ["Bouffanais", "Roland", ""], ["Wood", "Kristin L.", ""]]}, {"id": "1908.05964", "submitter": "Christian M\\\"uller", "authors": "Helmut Seidl, Christian M\\\"uller, Bernd Finkbeiner", "title": "How to Win First-Order Safety Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  First-order (FO) transition systems have recently attracted attention for the\nverification of parametric systems such as network protocols, software-defined\nnetworks or multi-agent workflows like conference management systems. Desirable\nproperties of these systems such as functional correctness or noninterference\nhave conveniently been formulated as safety properties. In order to\nautomatically synthesize strategies that enforce safety or noninterference, we\ngeneralize FO transition systems to FO safety games. We prove that the\nexistence of a winning strategy of safety player in finite games is in fact,\nequivalent to second-order quantifier elimination. For the important case of FO\ngames with monadic predicates only, we provide a complete classification into\ndecidable and undecidable cases. For games with non-monadic predicates, we\nconcentrate on universal first-order invariants, since these are sufficient to\nexpress a large class of noninterference properties. Based on general\ntechniques for second-order quantifier elimination, we provide abstraction and\nrefinement techniques in order to synthesize FO strategies that enforce safety.\nWe demonstrate the usefulness of our approach by inferring nontrivial FO\nspecifications in a leader election protocol as well as for paper assignment in\na conference mangagement system to exclude unappreciated disclosure of reports.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 13:19:13 GMT"}, {"version": "v2", "created": "Thu, 14 Nov 2019 03:39:28 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Seidl", "Helmut", ""], ["M\u00fcller", "Christian", ""], ["Finkbeiner", "Bernd", ""]]}, {"id": "1908.06634", "submitter": "Hossein Moradian", "authors": "Hossein Moradian, Solmaz S. Kia", "title": "Cluster-based Distributed Augmented Lagrangian Algorithm for a Class of\n  Constrained Convex Optimization Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a distributed solution for a constrained convex optimization\nproblem over a network of clustered agents each consisted of a set of\nsubagents. The communication range of the clustered agents is such that they\ncan form a connected undirected graph topology. The total cost in this\noptimization problem is the sum of the local convex costs of the subagents of\neach cluster. We seek a minimizer of this cost subject to a set of affine\nequality constraints, and a set of affine inequality constraints specifying the\nbounds on the decision variables if such bounds exist. We design our\ndistributed algorithm in a cluster-based framework which results in a\nsignificant reduction in communication and computation costs. Our proposed\ndistributed solution is a novel continuous-time algorithm that is linked to the\naugmented Lagrangian approach. It converges asymptotically when the local cost\nfunctions are convex and exponentially when they are strongly convex and have\nLipschitz gradients. Moreover, we use an $\\epsilon$-exact penalty function to\naddress the inequality constraints and derive an explicit lower bound on the\npenalty function weight to guarantee convergence to $\\epsilon$-neighborhood of\nthe global minimum value of the cost. A numerical example demonstrates our\nresults.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 08:14:07 GMT"}, {"version": "v2", "created": "Sun, 23 Feb 2020 22:47:27 GMT"}, {"version": "v3", "created": "Thu, 29 Oct 2020 07:24:59 GMT"}, {"version": "v4", "created": "Fri, 2 Apr 2021 22:52:56 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Moradian", "Hossein", ""], ["Kia", "Solmaz S.", ""]]}, {"id": "1908.06970", "submitter": "Ge Chu", "authors": "Ge Chu, Alexei Lisitsa", "title": "Agent-based (BDI) modeling for automation of penetration testing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Penetration testing (or pentesting) is one of the widely used and important\nmethodologies to assess the security of computer systems and networks.\nTraditional pentesting relies on the domain expert knowledge and requires\nconsiderable human effort all of which incurs a high cost. The automation can\nsignificantly improve the efficiency, availability and lower the cost of\npenetration testing. Existing approaches to the automation include those which\nmap vulnerability scanner results to the corresponding exploit tools, and those\naddressing the pentesting as a planning problem expressed in terms of attack\ngraphs. Due to mainly non-interactive processing, such solutions can deal\neffectively only with static and simple targets. In this paper, we propose an\nautomated penetration testing approach based on the belief-desire-intention\n(BDI) agent model, which is central in the research on agent-based processing\nin that it deals interactively with dynamic, uncertain and complex\nenvironments. Penetration testing actions are defined as a series of BDI plans\nand the BDI reasoning cycle is used to represent the penetration testing\nprocess. The model is extensible and new plans can be added, once they have\nbeen elicited from the human experts. We report on the results of testing of\nproof of concept BDI-based penetration testing tool in the simulated\nenvironment.\n", "versions": [{"version": "v1", "created": "Sun, 18 Aug 2019 15:41:36 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Chu", "Ge", ""], ["Lisitsa", "Alexei", ""]]}, {"id": "1908.07315", "submitter": "Jaroslav Opatrny", "authors": "Iman Bagheri, Lata Narayanan, Jaroslav Opatrny", "title": "Evacuation of equilateral triangles by mobile agents of limited\n  communication range", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of evacuating $k \\geq 2$ mobile agents from a\nunit-sided equilateral triangle through an exit located at an unknown location\non the perimeter of the triangle. The agents are initially located at the\ncentroid of the triangle and they can communicate with other agents at distance\nat most $r$ with $0\\leq r \\leq 1$. An agent can move at speed at most one, and\nfinds the exit only when it reaches the point where the exit is located. The\nagents can collaborate in the search for the exit. The goal of the {\\em\nevacuation problem} is to minimize the evacuation time, defined as the\nworst-case time for {\\em all} the agents to reach the exit. We propose and\nanalyze several algorithms for the problem of evacuation by $k \\geq 2$ agents;\nour results indicate that the best strategy to be used varies depending on the\nvalues of $r$ and $k$. For two agents, we give three algorithms, each of which\nachieves the best performance for different sub-ranges of $r$ in the range $0\n\\leq r \\leq 1$. Finally, we show that for any $r$, evacuation of $k=6\n+2\\lceil(\\frac{1}{r}-1)\\rceil$ agents can be done in time $1+\\sqrt{3}/3$, which\nis optimal in terms of time, and asymptotically optimal in terms of the number\nof agents.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 12:56:16 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Bagheri", "Iman", ""], ["Narayanan", "Lata", ""], ["Opatrny", "Jaroslav", ""]]}, {"id": "1908.08098", "submitter": "Waheed Bajwa", "authors": "Zhixiong Yang and Waheed U. Bajwa", "title": "BRIDGE: Byzantine-resilient Decentralized Gradient Descent", "comments": "18 pages, 1 figure, 1 table; preprint of a conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.LG cs.MA eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decentralized optimization techniques are increasingly being used to learn\nmachine learning models from data distributed over multiple locations without\ngathering the data at any one location. Unfortunately, methods that are\ndesigned for faultless networks typically fail in the presence of node\nfailures. In particular, Byzantine failures---corresponding to the scenario in\nwhich faulty/compromised nodes are allowed to arbitrarily deviate from an\nagreed-upon protocol---are the hardest to safeguard against in decentralized\nsettings. This paper introduces a Byzantine-resilient decentralized gradient\ndescent (BRIDGE) method for decentralized learning that, when compared to\nexisting works, is more efficient and scalable in higher-dimensional settings\nand that is deployable in networks having topologies that go beyond the star\ntopology. The main contributions of this work include theoretical analysis of\nBRIDGE for strongly convex learning objectives and numerical experiments\ndemonstrating the efficacy of BRIDGE for both convex and nonconvex learning\ntasks.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 19:49:56 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Yang", "Zhixiong", ""], ["Bajwa", "Waheed U.", ""]]}, {"id": "1908.08288", "submitter": "Le-Minh Kieu Dr", "authors": "Le-Minh Kieu, Nicolas Malleson, Alison Heppenstall", "title": "Dealing with uncertainty in agent-based models for short-term\n  predictions", "comments": "Manuscript under review at the Royal Society Open Science", "journal-ref": null, "doi": "10.1098/rsos.191074", "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Agent-based models (ABM) are gaining traction as one of the most powerful\nmodelling tools within the social sciences. They are particularly suited to\nsimulating complex systems. Despite many methodological advances within ABM,\none of the major drawbacks is their inability to incorporate real-time data to\nmake accurate short-term predictions. This paper presents an approach that\nallows ABMs to be dynamically optimised. Through a combination of parameter\ncalibration and data assimilation (DA), the accuracy of model-based predictions\nusing ABM in real time is increased. We use the exemplar of a bus route system\nto explore these methods. The bus route ABMs developed in this research are\nexamples of ABMs that can be dynamically optimised by a combination of\nparameter calibration and DA. The proposed model and framework can also be used\nin an passenger information system, or in an Intelligent Transport Systems to\nprovide forecasts of bus locations and arrival times.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 10:03:15 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Kieu", "Le-Minh", ""], ["Malleson", "Nicolas", ""], ["Heppenstall", "Alison", ""]]}, {"id": "1908.08634", "submitter": "EPTCS", "authors": "Frank Valencia (CNRS-LIX, Ecole Polytechnique de Paris and Univ.\n  Javeriana Cali.)", "title": "Semantic Structures for Spatially-Distributed Multi-Agent Systems", "comments": "In Proceedings EXPRESS/SOS 2019, arXiv:1908.08213. This is an invited\n  contribution to EXPRESS/SOS 2019 based on my invited talk", "journal-ref": "EPTCS 300, 2019, pp. 39-53", "doi": "10.4204/EPTCS.300.3", "report-no": null, "categories": "cs.MA cs.DC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatial constraint systems (scs) are semantic structures for reasoning about\nspatial and epistemic information in concurrent systems. They have been used to\nreason about beliefs, lies, and group epistemic behaviour inspired by social\nnetworks. They have also been used for proving new results about modal logics\nand giving semantics to process calculi. In this paper we will discuss the\ntheory and main results about scs.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 01:55:26 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Valencia", "Frank", "", "CNRS-LIX, Ecole Polytechnique de Paris and Univ.\n  Javeriana Cali."]]}, {"id": "1908.08637", "submitter": "EPTCS", "authors": "Tobias Prehn (Technische Universit\\\"at Berlin), Myron Rotter\n  (Technische Universit\\\"at Berlin)", "title": "Immediate Observation in Mediated Population Protocols", "comments": "In Proceedings EXPRESS/SOS 2019, arXiv:1908.08213", "journal-ref": "EPTCS 300, 2019, pp. 102-113", "doi": "10.4204/EPTCS.300.7", "report-no": null, "categories": "cs.MA cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we analyze the computational power of variants of population\nprotocols (PP), a formalism for distributed systems with anonymous agents\nhaving very limited capabilities. The capabilities of agents are enhanced in\nmediated population protocols (MPP) by recording the states in the edges of the\ninteraction graph. Restricting the interactions to the communication model of\nimmediate observation (IO) reduces the computational power of the resulting\nformalism. We show that this enhancement and restriction, when combined, yield\na model (IOMPP) at least as powerful as the basic PP. The proof requires a\nnovel notion of configurations in the MPP model allowing differentiation of\nagents and uses techniques similar to methods of analyzing encoding criteria,\nnamely operational correspondence. The constructional part of the proof is\ngeneric in a way that all protocols can be translated into the new model\nwithout losing the desirable properties they might have besides a stable\noutput. Furthermore, we illustrate how this approach could be utilized to prove\nour conjecture of IOMPP model being even as expressive as the MPP model. If our\nconjecture holds, this would result in a sharp characterization of the\ncomputational power and reveal the nonnecessity of two-way communication in the\ncontext of mediated population protocols.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 01:57:30 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Prehn", "Tobias", "", "Technische Universit\u00e4t Berlin"], ["Rotter", "Myron", "", "Technische Universit\u00e4t Berlin"]]}, {"id": "1908.08787", "submitter": "Bruce MacLennan", "authors": "Bruce J. MacLennan and Allen C. McBride", "title": "Swarm Intelligence for Morphogenetic Engineering", "comments": "31 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA nlin.PS q-bio.TO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We argue that embryological morphogenesis provides a model of how massive\nswarms of microscopic agents can be coordinated to assemble complex, multiscale\nhierarchical structures. This is accomplished by understanding natural\nmorphogenetic processes in mathematical terms, abstracting from the biological\nspecifics, and implementing these mathematical principles in artificial\nsystems. We have developed a notation based on partial differential equations\nfor artificial morphogenesis and have designed a prototype morphogenetic\nprogramming language, which permits precise description of morphogenetic\nalgorithms and their automatic translation to simulation software.\nMorphogenetic programming is illustrated by two examples: (1) use of a modified\nflocking algorithm to route dense fiber bundles between regions of an\nartificial cortex while avoiding other bundles; (2) use of the\nclock-and-wavefront model of spinal segmentation for the assembly of the\nsegmented spine of an insect-like robot body and for assembling segmented legs\non the robot's spine. Finally, we show how a variation of smoothed particle\nhydrodynamics (SPH) swarm robotic control can be applied to the global-to-local\ncompilation problem, that is, the derivation of individual agent control from\nglobal PDE specifications.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 22:29:57 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["MacLennan", "Bruce J.", ""], ["McBride", "Allen C.", ""]]}, {"id": "1908.08793", "submitter": "Naci Saldi", "authors": "Naci Saldi", "title": "Discrete-time average-cost mean-field games on Polish spaces", "comments": "18 pages. arXiv admin note: text overlap with arXiv:1705.02036,\n  arXiv:1808.03929", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In stochastic dynamic games, when the number of players is sufficiently large\nand the interactions between agents depend on empirical state distribution, one\nway to approximate the original game is to introduce infinite-population limit\nof the problem. In the infinite population limit, a generic agent is faced with\na \\emph{so-called} mean-field game. In this paper, we study discrete-time\nmean-field games with average-cost criteria. Using average cost optimality\nequation and Kakutani's fixed point theorem, we establish the existence of Nash\nequilibria for mean-field games under drift and minorization conditions on the\ndynamics of each agent. Then, we show that the equilibrium policy in the\nmean-field game, when adopted by each agent, is an approximate Nash equilibrium\nfor the corresponding finite-agent game with sufficiently many agents.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 08:47:19 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Saldi", "Naci", ""]]}, {"id": "1908.09184", "submitter": "Hassam Sheikh", "authors": "Hassam Ullah Sheikh, Ladislau B\\\"ol\\\"oni", "title": "Universal Policies to Learn Them All", "comments": "arXiv admin note: substantial text overlap with arXiv:1809.04500", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We explore a collaborative and cooperative multi-agent reinforcement learning\nsetting where a team of reinforcement learning agents attempt to solve a single\ncooperative task in a multi-scenario setting. We propose a novel multi-agent\nreinforcement learning algorithm inspired by universal value function\napproximators that not only generalizes over state space but also over a set of\ndifferent scenarios. Additionally, to prove our claim, we are introducing a\nchallenging 2D multi-agent urban security environment where the learning agents\nare trying to protect a person from nearby bystanders in a variety of\nscenarios. Our study shows that state-of-the-art multi-agent reinforcement\nlearning algorithms fail to generalize a single task over multiple scenarios\nwhile our proposed solution works equally well as scenario-dependent policies.\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2019 18:36:17 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Sheikh", "Hassam Ullah", ""], ["B\u00f6l\u00f6ni", "Ladislau", ""]]}, {"id": "1908.09453", "submitter": "Marc Lanctot", "authors": "Marc Lanctot, Edward Lockhart, Jean-Baptiste Lespiau, Vinicius\n  Zambaldi, Satyaki Upadhyay, Julien P\\'erolat, Sriram Srinivasan, Finbarr\n  Timbers, Karl Tuyls, Shayegan Omidshafiei, Daniel Hennes, Dustin Morrill,\n  Paul Muller, Timo Ewalds, Ryan Faulkner, J\\'anos Kram\\'ar, Bart De Vylder,\n  Brennan Saeta, James Bradbury, David Ding, Sebastian Borgeaud, Matthew Lai,\n  Julian Schrittwieser, Thomas Anthony, Edward Hughes, Ivo Danihelka, Jonah\n  Ryan-Davis", "title": "OpenSpiel: A Framework for Reinforcement Learning in Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  OpenSpiel is a collection of environments and algorithms for research in\ngeneral reinforcement learning and search/planning in games. OpenSpiel supports\nn-player (single- and multi- agent) zero-sum, cooperative and general-sum,\none-shot and sequential, strictly turn-taking and simultaneous-move, perfect\nand imperfect information games, as well as traditional multiagent environments\nsuch as (partially- and fully- observable) grid worlds and social dilemmas.\nOpenSpiel also includes tools to analyze learning dynamics and other common\nevaluation metrics. This document serves both as an overview of the code base\nand an introduction to the terminology, core concepts, and algorithms across\nthe fields of reinforcement learning, computational game theory, and search.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 03:31:35 GMT"}, {"version": "v2", "created": "Wed, 28 Aug 2019 20:57:01 GMT"}, {"version": "v3", "created": "Thu, 12 Sep 2019 04:26:51 GMT"}, {"version": "v4", "created": "Thu, 10 Oct 2019 17:06:01 GMT"}, {"version": "v5", "created": "Tue, 31 Dec 2019 05:55:04 GMT"}, {"version": "v6", "created": "Sat, 26 Sep 2020 11:49:05 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Lanctot", "Marc", ""], ["Lockhart", "Edward", ""], ["Lespiau", "Jean-Baptiste", ""], ["Zambaldi", "Vinicius", ""], ["Upadhyay", "Satyaki", ""], ["P\u00e9rolat", "Julien", ""], ["Srinivasan", "Sriram", ""], ["Timbers", "Finbarr", ""], ["Tuyls", "Karl", ""], ["Omidshafiei", "Shayegan", ""], ["Hennes", "Daniel", ""], ["Morrill", "Dustin", ""], ["Muller", "Paul", ""], ["Ewalds", "Timo", ""], ["Faulkner", "Ryan", ""], ["Kram\u00e1r", "J\u00e1nos", ""], ["De Vylder", "Bart", ""], ["Saeta", "Brennan", ""], ["Bradbury", "James", ""], ["Ding", "David", ""], ["Borgeaud", "Sebastian", ""], ["Lai", "Matthew", ""], ["Schrittwieser", "Julian", ""], ["Anthony", "Thomas", ""], ["Hughes", "Edward", ""], ["Danihelka", "Ivo", ""], ["Ryan-Davis", "Jonah", ""]]}, {"id": "1908.09466", "submitter": "Yanbing Mao", "authors": "Yanbing Mao, Hamidreza Jafarnejadsani, Pan Zhao, Emrah Akyol, and\n  Naira Hovakimyan", "title": "Novel Stealthy Attack and Defense Strategies for Networked Control\n  Systems", "comments": "to appear in IEEE TAC", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.DC cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies novel attack and defense strategies, based on a class of\nstealthy attacks, namely the zero-dynamics attack (ZDA), for multi-agent\ncontrol systems. ZDA poses a formidable security challenge since its attack\nsignal is hidden in the null-space of the state-space representation of the\ncontrol system and hence it can evade conventional detection methods. An\nintuitive defense strategy builds on changing the aforementioned representation\nvia switching through a set of carefully crafted topologies. In this paper, we\npropose realistic ZDA variations where the attacker is aware of this\ntopology-switching strategy, and hence employs the following policies to avoid\ndetection: (i) pause, update and resume ZDA according to the knowledge of\nswitching topologies; (ii) cooperate with a concurrent stealthy topology attack\nthat alters network topology at switching times, such that the original ZDA is\nfeasible under the corrupted topology. We first systematically study the\nproposed ZDA variations, and then develop defense strategies against them under\nthe realistic assumption that the defender has no knowledge of attack starting,\npausing, and resuming times and the number of misbehaving agents. Particularly,\nwe characterize conditions for detectability of the proposed ZDA variations, in\nterms of the network topologies to be maintained, the set of agents to be\nmonitored, and the measurements of the monitored agents that should be\nextracted, while simultaneously preserving the privacy of the states of the\nnon-monitored agents. We then propose an attack detection algorithm based on\nthe Luenberger observer, using the characterized detectability conditions. We\nprovide numerical simulation results to demonstrate our theoretical findings.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 04:41:00 GMT"}, {"version": "v2", "created": "Sat, 25 Apr 2020 19:07:49 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Mao", "Yanbing", ""], ["Jafarnejadsani", "Hamidreza", ""], ["Zhao", "Pan", ""], ["Akyol", "Emrah", ""], ["Hovakimyan", "Naira", ""]]}, {"id": "1908.09658", "submitter": "Rasmus Kr{\\ae}mmer Rendsvig", "authors": "Andr\\'es Occhipinti Liberman and Rasmus K. Rendsvig", "title": "Dynamic Term-Modal Logic for Epistemic Social Network Dynamics (Extended\n  Version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.LO cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Logics for social networks have been studied in recent literature. This paper\npresents a framework based on *dynamic term-modal logic* (DTML), a quantified\nvariant of dynamic epistemic logic (DEL). In contrast with DEL where it is\ncommonly known to whom agent names refer, DTML can represent dynamics with\nuncertainty about agent identity. We exemplify dynamics where such uncertainty\nand de re/de dicto distinctions are key to social network epistemics.\nTechnically, we show that DTML semantics can represent a popular class of\nhybrid logic epistemic social network models. We also show that DTML can encode\npreviously discussed dynamics for which finding a complete logic was left open.\nAs complete reduction axioms systems exist for DTML, this yields a complete\nsystem for the dynamics in question.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 13:08:49 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Liberman", "Andr\u00e9s Occhipinti", ""], ["Rendsvig", "Rasmus K.", ""]]}, {"id": "1908.09707", "submitter": "Thayne Walker", "authors": "Thayne T. Walker and Nathan R. Sturtevant", "title": "Collision Detection for Agents in Multi-Agent Pathfinding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CG cs.GR cs.MA cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work on the multi-agent pathfinding problem (MAPF) has begun to study\nagents with motion that is more complex, for example, with non-unit action\ndurations and kinematic constraints. An important aspect of MAPF is collision\ndetection. Many collision detection approaches exist, but often suffer from\nissues such as high computational cost or causing false negative or false\npositive detections. In practice, these issues can result in problems that\nrange from inefficiency and annoyance to catastrophic. The main contribution of\nthis technical report is to provide a high-level overview of major categories\nof collision detection, along with methods of collision detection and\nanticipatory collision avoidance for agents that are both computationally\nefficient and highly accurate.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 14:35:11 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 14:41:46 GMT"}, {"version": "v3", "created": "Fri, 15 Nov 2019 18:27:40 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Walker", "Thayne T.", ""], ["Sturtevant", "Nathan R.", ""]]}, {"id": "1908.09813", "submitter": "Shouvik Roy", "authors": "Shouvik Roy, Usama Mehmood, Radu Grosu, Scott A. Smolka, Scott D.\n  Stoller, Ashish Tiwari", "title": "Neural Flocking: MPC-based Supervised Learning of Flocking Controllers", "comments": "This is an updated version of our previous submission. The updated\n  version includes an additional section of experiments using quadrotors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how a distributed flocking controller can be synthesized using deep\nlearning from a centralized controller which generates the trajectories of the\nflock. Our approach is based on supervised learning, with the centralized\ncontroller providing the training data to the learning agent, i.e., the\nsynthesized distributed controller. We use Model Predictive Control (MPC) for\nthe centralized controller, an approach that has been successfully demonstrated\non flocking problems. MPC-based flocking controllers are high-performing but\nalso computationally expensive. By learning a symmetric distributed neural\nflocking controller from a centralized MPC-based flocking controller, we\nachieve the best of both worlds: the neural controllers have high performance\n(on par with the MPC controllers) and high efficiency. Our experimental results\ndemonstrate the sophisticated nature of the distributed controllers we learn.\nIn particular, the neural controllers are capable of achieving myriad\nflocking-oriented control objectives, including flocking formation, collision\navoidance, obstacle avoidance, predator avoidance, and target seeking.\nMoreover, they generalize the behavior seen in the training data in order to\nachieve these objectives in a significantly broader range of scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 17:35:56 GMT"}, {"version": "v2", "created": "Fri, 17 Jan 2020 06:09:27 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Roy", "Shouvik", ""], ["Mehmood", "Usama", ""], ["Grosu", "Radu", ""], ["Smolka", "Scott A.", ""], ["Stoller", "Scott D.", ""], ["Tiwari", "Ashish", ""]]}, {"id": "1908.09893", "submitter": "Gabriele Farina", "authors": "Gabriele Farina and Tommaso Bianchi and Tuomas Sandholm", "title": "Coarse Correlation in Extensive-Form Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coarse correlation models strategic interactions of rational agents\ncomplemented by a correlation device, that is a mediator that can recommend\nbehavior but not enforce it. Despite being a classical concept in the theory of\nnormal-form games for more than forty years, not much is known about the merits\nof coarse correlation in extensive-form settings. In this paper, we consider\ntwo instantiations of the idea of coarse correlation in extensive-form games:\nnormal-form coarse-correlated equilibrium (NFCCE), already defined in the\nliterature, and extensive-form coarse-correlated equilibrium (EFCCE), which we\nintroduce for the first time. We show that EFCCE is a subset of NFCCE and a\nsuperset of the related extensive-form correlated equilibrium. We also show\nthat, in two-player extensive-form games, social-welfare-maximizing EFCCEs and\nNFCEEs are bilinear saddle points, and give new efficient algorithms for the\nspecial case of games with no chance moves. In our experiments, our proposed\nalgorithm for NFCCE is two to four orders of magnitude faster than the prior\nstate of the art.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 19:58:48 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Farina", "Gabriele", ""], ["Bianchi", "Tommaso", ""], ["Sandholm", "Tuomas", ""]]}, {"id": "1908.10404", "submitter": "Zijia Zhong", "authors": "Zijia Zhong and Joyoung Lee", "title": "The Effectiveness of Managed Lane Strategies for the Near-term\n  Deployment of Cooperative Adaptive Cruise Control", "comments": "22 pages, 15 figures", "journal-ref": "Transportation Research Part A: Policy and Practice 2019", "doi": "10.1016/j.tra.2019.08.015", "report-no": null, "categories": "cs.MA eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traffic simulation is a cost-effective way to test the deployment of\nCooperative Adaptive Cruise Control (CACC) vehicles in a large-scale\ntransportation network. By using a previously developed microscopic simulation\ntestbed, this paper examines the impacts of four managed lane strategies for\nthe near-term deployment of CACC vehicles under mixed traffic conditions.\nNetwork-wide performance measures are investigated from the perspectives of\nmobility, safety, equity, and environmental impacts. In addition, the platoon\nformation performance of CACC vehicles is evaluated with platoon-orientated\nmeasures, such as the percentage of platooned CACC vehicles, average platoon\ndepth, and vehicle-hour-platooned that is proposed in this paper under the\nimperfect DSRC communication environment. Moreover, managed lane score matrices\nare developed to incorporate heterogeneous categories of performance measures,\naiming to provide a more comprehensive picture for stakeholders. The results\nshow that mixing CACC traffic along with non-CACC traffic across all travel\nlanes is an acceptable option when the market penetration (MP) is lower than\n30% for roadways where a managed lane is absent. Providing CACC with priority\naccess to an existing managed lane, if available, is also a good strategy for\nimproving the overall traffic performance when the MP is lower than 40%. When\nthe MP reaches above 40%, a dedicated lane for CACC vehicles is recommended, as\nit provides greater opportunity for CACC vehicles to form platoons. The\nfacilitation of homogeneous CACC traffic flow could make further improvements\npossible in the future.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 18:38:34 GMT"}, {"version": "v2", "created": "Tue, 3 Sep 2019 03:43:47 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Zhong", "Zijia", ""], ["Lee", "Joyoung", ""]]}, {"id": "1908.10450", "submitter": "Marcelo Veloso Maciel", "authors": "Marcelo V. Maciel, Andr\\'e C. R. Martins", "title": "Ideologically Motivated Biases in a Multiple Issues Opinion Model", "comments": "18 pages,10 figures", "journal-ref": null, "doi": "10.1016/j.physa.2020.124293", "report-no": null, "categories": "physics.soc-ph cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been observed people tend to have opinions that are far more\ninternally consistent than it would be reasonable to expect. Here, we study how\nthat observation might emerge from changing how agents trust the opinions of\ntheir peers in a model for opinion dynamics with multiple issues. A previous\nBayesian inspired opinion model for continuous opinions is extended to include\nmultiple issues. In the original model, agents tended to trust less opinions\nthat were too different from their own. We investigate the properties of the\nextended model in its natural form. And we also introduce the possibility the\ntrust of the agent might depend not only on the specific issue but on the\naverage opinions over the many issues. By adopting such a ideological point of\nview, we observe an important decrease in the spread of individual opinions.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 20:15:03 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Maciel", "Marcelo V.", ""], ["Martins", "Andr\u00e9 C. R.", ""]]}, {"id": "1908.10577", "submitter": "Yanan Wang", "authors": "Yanan Wang, Tong Xu, Xin Niu, Chang Tan, Enhong Chen, Hui Xiong", "title": "STMARL: A Spatio-Temporal Multi-Agent Reinforcement Learning Approach\n  for Cooperative Traffic Light Control", "comments": "Accepted to IEEE Transactions on Mobile Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of intelligent traffic light control systems is essential for\nsmart transportation management. While some efforts have been made to optimize\nthe use of individual traffic lights in an isolated way, related studies have\nlargely ignored the fact that the use of multi-intersection traffic lights is\nspatially influenced and there is a temporal dependency of historical traffic\nstatus for current traffic light control. To that end, in this paper, we\npropose a novel SpatioTemporal Multi-Agent Reinforcement Learning (STMARL)\nframework for effectively capturing the spatio-temporal dependency of multiple\nrelated traffic lights and control these traffic lights in a coordinating way.\nSpecifically, we first construct the traffic light adjacency graph based on the\nspatial structure among traffic lights. Then, historical traffic records will\nbe integrated with current traffic status via Recurrent Neural Network\nstructure. Moreover, based on the temporally-dependent traffic information, we\ndesign a Graph Neural Network based model to represent relationships among\nmultiple traffic lights, and the decision for each traffic light will be made\nin a distributed way by the deep Q-learning method. Finally, the experimental\nresults on both synthetic and real-world data have demonstrated the\neffectiveness of our STMARL framework, which also provides an insightful\nunderstanding of the influence mechanism among multi-intersection traffic\nlights.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 07:16:39 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 11:45:35 GMT"}, {"version": "v3", "created": "Sun, 29 Nov 2020 16:39:47 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Wang", "Yanan", ""], ["Xu", "Tong", ""], ["Niu", "Xin", ""], ["Tan", "Chang", ""], ["Chen", "Enhong", ""], ["Xiong", "Hui", ""]]}, {"id": "1908.10743", "submitter": "EPTCS", "authors": "Giorgio Audrito (University of Turin, Italy), Ferruccio Damiani\n  (University of Turin, Italy), Volker Stolz (Western Norway University of\n  Applied Sciences, Norway), Mirko Viroli (University of Bologna, Italy)", "title": "On Distributed Runtime Verification by Aggregate Computing", "comments": "In Proceedings VORTEX 2018, arXiv:1908.09302", "journal-ref": "EPTCS 302, 2019, pp. 47-61", "doi": "10.4204/EPTCS.302.4", "report-no": null, "categories": "cs.SE cs.DC cs.MA cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Runtime verification is a computing analysis paradigm based on observing a\nsystem at runtime (to check its expected behaviour) by means of monitors\ngenerated from formal specifications. Distributed runtime verification is\nruntime verification in connection with distributed systems: it comprises both\nmonitoring of distributed systems and using distributed systems for monitoring.\nAggregate computing is a programming paradigm based on a reference computing\nmachine that is the aggregate collection of devices that cooperatively carry\nout a computational process: the details of behaviour, position and number of\ndevices are largely abstracted away, to be replaced with a space-filling\ncomputational environment. In this position paper we argue, by means of simple\nexamples, that aggregate computing is particularly well suited for implementing\ndistributed monitors. Our aim is to foster further research on how to generate\naggregate computing monitors from suitable formal specifications.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 06:20:41 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Audrito", "Giorgio", "", "University of Turin, Italy"], ["Damiani", "Ferruccio", "", "University of Turin, Italy"], ["Stolz", "Volker", "", "Western Norway University of\n  Applied Sciences, Norway"], ["Viroli", "Mirko", "", "University of Bologna, Italy"]]}, {"id": "1908.11360", "submitter": "Tim Lyon", "authors": "Tim Lyon and Kees van Berkel", "title": "Automating Agential Reasoning: Proof-Calculi and Syntactic Decidability\n  for STIT Logics", "comments": "Included version of the paper \"Automating Agential Reasoning:\n  Proof-Calculi and Syntactic Decidability for STIT Logics\", accepted to the\n  22nd International Conference on Principles and Practice of Multi-Agent\n  Systems (PRIMA 2019)", "journal-ref": null, "doi": "10.1007/978-3-030-33792-6_13", "report-no": null, "categories": "cs.LO cs.AI cs.MA math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work provides proof-search algorithms and automated counter-model\nextraction for a class of STIT logics. With this, we answer an open problem\nconcerning syntactic decision procedures and cut-free calculi for STIT logics.\nA new class of cut-free complete labelled sequent calculi G3LdmL^m_n, for\nmulti-agent STIT with at most n-many choices, is introduced. We refine the\ncalculi G3LdmL^m_n through the use of propagation rules and demonstrate the\nadmissibility of their structural rules, resulting in auxiliary calculi\nLdm^m_nL. In the single-agent case, we show that the refined calculi Ldm^m_nL\nderive theorems within a restricted class of (forestlike) sequents, allowing us\nto provide proof-search algorithms that decide single-agent STIT logics. We\nprove that the proof-search algorithms are correct and terminate.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 17:33:37 GMT"}, {"version": "v2", "created": "Fri, 11 Oct 2019 13:48:33 GMT"}, {"version": "v3", "created": "Wed, 16 Oct 2019 17:16:02 GMT"}, {"version": "v4", "created": "Sat, 15 Feb 2020 08:29:26 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Lyon", "Tim", ""], ["van Berkel", "Kees", ""]]}, {"id": "1908.11623", "submitter": "Frank Schweitzer", "authors": "Frank Schweitzer, Tamas Krivachy, David Garcia", "title": "How emotions drive opinion polarization: An agent-based model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.MA nlin.AO q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide an agent-based model to explain the emergence of collective\nopinions not based on feedback between different opinions, but based on\nemotional interactions between agents. The driving variable is the emotional\nstate of agents, characterized by their valence and their arousal. Both\ndetermine their emotional expression, from which collective emotional\ninformation is generated. This information feeds back on the dynamics of\nemotional states and of individual opinions in a non-linear manner. We derive\nthe critical conditions for emotional interactions to obtain either consensus\nor polarization of opinions. Stochastic agent-based simulations and formal\nanalyses of the model explain our results. Possible ways to validate the model\nare discussed.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 10:03:24 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Schweitzer", "Frank", ""], ["Krivachy", "Tamas", ""], ["Garcia", "David", ""]]}, {"id": "1908.11811", "submitter": "Gabriele D'Angelo", "authors": "Edoardo Rosa, Gabriele D'Angelo, Stefano Ferretti", "title": "Agent-based Simulation of Blockchains", "comments": "Proceedings of the 19-th Asia Simulation Conference (AsiaSim 2019)", "journal-ref": null, "doi": "10.1007/978-981-15-1078-6_10", "report-no": null, "categories": "cs.CR cs.DC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe LUNES-Blockchain, an agent-based simulator of\nblockchains that is able to exploit Parallel and Distributed Simulation (PADS)\ntechniques to offer a high level of scalability. To assess the preliminary\nimplementation of our simulator, we provide a simplified modelling of the\nBitcoin protocol and we study the effect of a security attack on the consensus\nprotocol in which a set of malicious nodes implements a filtering denial of\nservice (i.e. Sybil Attack). The results confirm the viability of the\nagent-based modelling of blockchains implemented by means of PADS.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 14:15:13 GMT"}, {"version": "v2", "created": "Wed, 6 Nov 2019 15:37:25 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Rosa", "Edoardo", ""], ["D'Angelo", "Gabriele", ""], ["Ferretti", "Stefano", ""]]}]