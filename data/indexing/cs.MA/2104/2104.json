[{"id": "2104.00203", "submitter": "Marina Haliem", "authors": "Marina Haliem, Vaneet Aggarwal and Bharat Bhargava", "title": "AdaPool: A Diurnal-Adaptive Fleet Management Framework using Model-Free\n  Deep Reinforcement Learning and Change Point Detection", "comments": "arXiv admin note: text overlap with arXiv:2010.01755", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces an adaptive model-free deep reinforcement approach that\ncan recognize and adapt to the diurnal patterns in the ride-sharing environment\nwith car-pooling. Deep Reinforcement Learning (RL) suffers from catastrophic\nforgetting due to being agnostic to the timescale of changes in the\ndistribution of experiences. Although RL algorithms are guaranteed to converge\nto optimal policies in Markov decision processes (MDPs), this only holds in the\npresence of static environments. However, this assumption is very restrictive.\nIn many real-world problems like ride-sharing, traffic control, etc., we are\ndealing with highly dynamic environments, where RL methods yield only\nsub-optimal decisions. To mitigate this problem in highly dynamic environments,\nwe (1) adopt an online Dirichlet change point detection (ODCP) algorithm to\ndetect the changes in the distribution of experiences, (2) develop a Deep Q\nNetwork (DQN) agent that is capable of recognizing diurnal patterns and making\ninformed dispatching decisions according to the changes in the underlying\nenvironment. Rather than fixing patterns by time of week, the proposed approach\nautomatically detects that the MDP has changed, and uses the results of the new\nmodel. In addition to the adaptation logic in dispatching, this paper also\nproposes a dynamic, demand-aware vehicle-passenger matching and route planning\nframework that dynamically generates optimal routes for each vehicle based on\nonline demand, vehicle capacities, and locations. Evaluation on New York City\nTaxi public dataset shows the effectiveness of our approach in improving the\nfleet utilization, where less than 50% of the fleet are utilized to serve the\ndemand of up to 90% of the requests, while maximizing profits and minimizing\nidle times.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 02:14:01 GMT"}, {"version": "v2", "created": "Mon, 14 Jun 2021 15:42:28 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Haliem", "Marina", ""], ["Aggarwal", "Vaneet", ""], ["Bhargava", "Bharat", ""]]}, {"id": "2104.00357", "submitter": "Charlotte Roman", "authors": "Charlotte Roman, Paolo Turrini", "title": "Bounding the Inefficiency of Route Control in Intelligent Transport\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Route controlled autonomous vehicles could have a significant impact in\nreducing congestion in the future. Before applying multi-agent reinforcement\nlearning algorithms to route control, we can model the system using a\ncongestion game to predict and mitigate potential issues. We consider the\nproblem of distributed operating systems in a transportation network that\ncontrol the routing choices of their assigned vehicles. We formulate an\nassociated network control game, consisting of multiple actors seeking to\noptimise the social welfare of their assigned subpopulations in an underlying\nnonatomic congestion game. Then we find the inefficiency of the routing\nequilibria by calculating the Price of Anarchy for polynomial cost functions.\nFinally, we extend the analysis to allow vehicles to choose their operating\nsystem.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 09:23:54 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Roman", "Charlotte", ""], ["Turrini", "Paolo", ""]]}, {"id": "2104.00394", "submitter": "Mohammadreza Doostmohammadian", "authors": "Mohammadreza Doostmohammadian, Usman A. Khan, and Themistoklis\n  Charalambous", "title": "Delay-Tolerant Consensus-based Distributed Estimation: Full-Rank Systems\n  with Potentially Unstable Dynamics", "comments": "submitted to CDC21", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.MA cs.SI cs.SY eess.SP math.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Classical distributed estimation scenarios typically assume timely and\nreliable exchange of information over the multi-agent network. This paper, in\ncontrast, considers single time-scale distributed estimation of (potentially)\nunstable full-rank dynamical systems via a multi-agent network subject to\ntransmission time-delays. The proposed networked estimator consists of two\nsteps: (i) consensus on (delayed) a-priori estimates, and (ii) measurement\nupdate. The agents only share their a-priori estimates with their in-neighbors\nover time-delayed transmission links. Considering the most general case, the\ndelays are assumed to be time-varying, arbitrary, unknown, but upper-bounded.\nIn contrast to most recent distributed observers assuming system observability\nin the neighborhood of each agent, our proposed estimator makes no such\nassumption. This may significantly reduce the communication/sensing loads on\nagents in large-scale, while making the (distributed) observability analysis\nmore challenging. Using the notions of augmented matrices and Kronecker\nproduct, the geometric convergence of the proposed estimator over\nstrongly-connected networks is proved irrespective of the bound on the\ntime-delay. Simulations are provided to support our theoretical results.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 10:55:20 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Doostmohammadian", "Mohammadreza", ""], ["Khan", "Usman A.", ""], ["Charalambous", "Themistoklis", ""]]}, {"id": "2104.00563", "submitter": "Roger Girgis", "authors": "Roger Girgis, Florian Golemo, Felipe Codevilla, Jim Aldon D'Souza,\n  Martin Weiss, Samira Ebrahimi Kahou, Felix Heide, Christopher Pal", "title": "Autobots: Latent Variable Sequential Set Transformers", "comments": "21 pages, 15 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Robust multi-agent trajectory prediction is essential for the safe control of\nrobots and vehicles that interact with humans. Many existing methods treat\nsocial and temporal information separately and therefore fall short of\nmodelling the joint future trajectories of all agents in a socially consistent\nway. To address this, we propose a new class of Latent Variable Sequential Set\nTransformers which autoregressively model multi-agent trajectories. We refer to\nthese architectures as \"AutoBots\". AutoBots model the contents of sets (e.g.\nrepresenting the properties of agents in a scene) over time and employ\nmulti-head self-attention blocks over these sequences of sets to encode the\nsociotemporal relationships between the different actors of a scene. This\nproduces either the trajectory of one ego-agent or a distribution over the\nfuture trajectories for all agents under consideration. Our approach works for\ngeneral sequences of sets and we provide illustrative experiments modelling the\nsequential structure of the multiple strokes that make up symbols in the\nOmniglot data. For the single-agent prediction case, we validate our model on\nthe NuScenes motion prediction task and achieve competitive results on the\nglobal leaderboard. In the multi-agent forecasting setting, we validate our\nmodel on TrajNet. We find that our method outperforms physical extrapolation\nand recurrent network baselines and generates scene-consistent trajectories.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 18:53:26 GMT"}, {"version": "v2", "created": "Wed, 16 Jun 2021 19:06:13 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Girgis", "Roger", ""], ["Golemo", "Florian", ""], ["Codevilla", "Felipe", ""], ["D'Souza", "Jim Aldon", ""], ["Weiss", "Martin", ""], ["Kahou", "Samira Ebrahimi", ""], ["Heide", "Felix", ""], ["Pal", "Christopher", ""]]}, {"id": "2104.00654", "submitter": "Bo Chen", "authors": "Bo Chen, Calvin Hawkins, Kasra Yazdani, Matthew Hale", "title": "Edge Differential Privacy for Algebraic Connectivity of Graphs", "comments": "8 pages, 5 figures, submitted to 60th IEEE Conference on Decision and\n  Control 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.MA cs.SI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphs are the dominant formalism for modeling multi-agent systems. The\nalgebraic connectivity of a graph is particularly important because it provides\nthe convergence rates of consensus algorithms that underlie many multi-agent\ncontrol and optimization techniques. However, sharing the value of algebraic\nconnectivity can inadvertently reveal sensitive information about the topology\nof a graph, such as connections in social networks. Therefore, in this work we\npresent a method to release a graph's algebraic connectivity under a\ngraph-theoretic form of differential privacy, called edge differential privacy.\nEdge differential privacy obfuscates differences among graphs' edge sets and\nthus conceals the absence or presence of sensitive connections therein. We\nprovide privacy with bounded Laplace noise, which improves accuracy relative to\nconventional unbounded noise. The private algebraic connectivity values are\nanalytically shown to provide accurate estimates of consensus convergence\nrates, as well as accurate bounds on the diameter of a graph and the mean\ndistance between its nodes. Simulation results confirm the utility of private\nalgebraic connectivity in these contexts.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 17:50:18 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Chen", "Bo", ""], ["Hawkins", "Calvin", ""], ["Yazdani", "Kasra", ""], ["Hale", "Matthew", ""]]}, {"id": "2104.01066", "submitter": "Jacob Taylor PhD", "authors": "Rafael Kaufmann, Pranav Gupta, Jacob Taylor", "title": "An active inference model of collective intelligence", "comments": "32 pages, 10 figures, manuscript under review", "journal-ref": null, "doi": "10.3390/e23070830", "report-no": null, "categories": "cs.SI cs.AI cs.MA cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  To date, formal models of collective intelligence have lacked a plausible\nmathematical description of the relationship between local-scale interactions\nbetween highly autonomous sub-system components (individuals) and global-scale\nbehavior of the composite system (the collective). In this paper we use the\nActive Inference Formulation (AIF), a framework for explaining the behavior of\nany non-equilibrium steady state system at any scale, to posit a minimal\nagent-based model that simulates the relationship between local\nindividual-level interaction and collective intelligence (operationalized as\nsystem-level performance). We explore the effects of providing baseline AIF\nagents (Model 1) with specific cognitive capabilities: Theory of Mind (Model\n2); Goal Alignment (Model 3), and Theory of Mind with Goal Alignment (Model 4).\nThese stepwise transitions in sophistication of cognitive ability are motivated\nby the types of advancements plausibly required for an AIF agent to persist and\nflourish in an environment populated by other AIF agents, and have also\nrecently been shown to map naturally to canonical steps in human cognitive\nability. Illustrative results show that stepwise cognitive transitions increase\nsystem performance by providing complementary mechanisms for alignment between\nagents' local and global optima. Alignment emerges endogenously from the\ndynamics of interacting AIF agents themselves, rather than being imposed\nexogenously by incentives to agents' behaviors (contra existing computational\nmodels of collective intelligence) or top-down priors for collective behavior\n(contra existing multiscale simulations of AIF). These results shed light on\nthe types of generic information-theoretic patterns conducive to collective\nintelligence in human and other complex adaptive systems.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 14:32:01 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Kaufmann", "Rafael", ""], ["Gupta", "Pranav", ""], ["Taylor", "Jacob", ""]]}, {"id": "2104.01445", "submitter": "Hao Xiong", "authors": "Hao Xiong, Huanhui Cao, Lin Zhang, and Wenjie Lu", "title": "A Dynamics Perspective of Pursuit-Evasion Games of Intelligent Agents\n  with the Ability to Learn", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pursuit-evasion games are ubiquitous in nature and in an artificial world. In\nnature, pursuer(s) and evader(s) are intelligent agents that can learn from\nexperience, and dynamics (i.e., Newtonian or Lagrangian) is vital for the\npursuer and the evader in some scenarios. To this end, this paper addresses the\npursuit-evasion game of intelligent agents from the perspective of dynamics. A\nbio-inspired dynamics formulation of a pursuit-evasion game and baseline\npursuit and evasion strategies are introduced at first. Then, reinforcement\nlearning techniques are used to mimic the ability of intelligent agents to\nlearn from experience. Based on the dynamics formulation and reinforcement\nlearning techniques, the effects of improving both pursuit and evasion\nstrategies based on experience on pursuit-evasion games are investigated at two\nlevels 1) individual runs and 2) ranges of the parameters of pursuit-evasion\ngames. Results of the investigation are consistent with nature observations and\nthe natural law - survival of the fittest. More importantly, with respect to\nthe result of a pursuit-evasion game of agents with baseline strategies, this\nstudy achieves a different result. It is shown that, in a pursuit-evasion game\nwith a dynamics formulation, an evader is not able to escape from a slightly\nfaster pursuer with an effective learned pursuit strategy, based on agile\nmaneuvers and an effective learned evasion strategy.\n", "versions": [{"version": "v1", "created": "Sat, 3 Apr 2021 16:36:29 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Xiong", "Hao", ""], ["Cao", "Huanhui", ""], ["Zhang", "Lin", ""], ["Lu", "Wenjie", ""]]}, {"id": "2104.01520", "submitter": "Gabriele Farina", "authors": "Gabriele Farina, Andrea Celli, Alberto Marchesi, Nicola Gatti", "title": "Simple Uncoupled No-Regret Learning Dynamics for Extensive-Form\n  Correlated Equilibrium", "comments": "Extended version of our NeurIPS 2020 paper. Compared to the\n  conference version, this preprint gives finer, in-high-probability regret\n  bounds. We also better connected our work to the phi-regret minimization\n  framework", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The existence of simple uncoupled no-regret learning dynamics that converge\nto correlated equilibria in normal-form games is a celebrated result in the\ntheory of multi-agent systems. Specifically, it has been known for more than 20\nyears that when all players seek to minimize their internal regret in a\nrepeated normal-form game, the empirical frequency of play converges to a\nnormal-form correlated equilibrium. Extensive-form games generalize normal-form\ngames by modeling both sequential and simultaneous moves, as well as imperfect\ninformation. Because of the sequential nature and presence of private\ninformation in the game, correlation in extensive-form games possesses\nsignificantly different properties than its counterpart in normal-form games,\nmany of which are still open research directions. Extensive-form correlated\nequilibrium (EFCE) has been proposed as the natural extensive-form counterpart\nto the classical notion of correlated equilibrium in normal-form games.\nCompared to the latter, the constraints that define the set of EFCEs are\nsignificantly more complex, as the correlation device must keep into account\nthe evolution of beliefs of each player as they make observations throughout\nthe game. Due to that significant added complexity, the existence of uncoupled\nlearning dynamics leading to an EFCE has remained a challenging open research\nquestion for a long time. In this article, we settle that question by giving\nthe first uncoupled no-regret dynamics that converge to the set of EFCEs in\nn-player general-sum extensive-form games with perfect recall. We show that\neach iterate can be computed in time polynomial in the size of the game tree,\nand that, when all players play repeatedly according to our learning dynamics,\nthe empirical frequency of play is proven to be a O(T^-0.5)-approximate EFCE\nwith high probability after T game repetitions, and an EFCE almost surely in\nthe limit.\n", "versions": [{"version": "v1", "created": "Sun, 4 Apr 2021 02:26:26 GMT"}, {"version": "v2", "created": "Thu, 27 May 2021 06:03:22 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Farina", "Gabriele", ""], ["Celli", "Andrea", ""], ["Marchesi", "Alberto", ""], ["Gatti", "Nicola", ""]]}, {"id": "2104.01650", "submitter": "Adway Mitra", "authors": "Gaurav Suryawanshi, Varun Madhavan, Adway Mitra, Partha Pratim\n  Chakrabarti", "title": "City-scale Simulation of Covid-19 Pandemic and Intervention Policies\n  using Agent-based Modelling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  During the Covid-19 pandemic, most governments across the world imposed\npolicies like lock-down of public spaces and restrictions on people's movements\nto minimize the spread of the virus through physical contact. However, such\npolicies have grave social and economic costs, and so it is important to\npre-assess their impacts. In this work we aim to visualize the dynamics of the\npandemic in a city under different intervention policies, by simulating the\nbehavior of the residents. We develop a very detailed agent-based model for a\ncity, including its residents, physical and social spaces like homes,\nmarketplaces, workplaces, schools/colleges etc. We parameterize our model for\nKolkata city in India using ward-level demographic and civic data. We\ndemonstrate that under appropriate choice of parameters, our model is able to\nreproduce the observed dynamics of the Covid-19 pandemic in Kolkata, and also\nindicate the counter-factual outcomes of alternative intervention policies.\n", "versions": [{"version": "v1", "created": "Sun, 4 Apr 2021 17:30:57 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Suryawanshi", "Gaurav", ""], ["Madhavan", "Varun", ""], ["Mitra", "Adway", ""], ["Chakrabarti", "Partha Pratim", ""]]}, {"id": "2104.01939", "submitter": "Quanlin Chen", "authors": "Quanlin Chen", "title": "NQMIX: Non-monotonic Value Function Factorization for Deep Multi-Agent\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-agent value-based approaches recently make great progress, especially\nvalue decomposition methods. However, there are still a lot of limitations in\nvalue function factorization. In VDN, the joint action-value function is the\nsum of per-agent action-value function while the joint action-value function of\nQMIX is the monotonic mixing of per-agent action-value function. To some\nextent, QTRAN reduces the limitation of joint action-value functions that can\nbe represented, but it has unsatisfied performance in complex tasks. In this\npaper, in order to extend the class of joint value functions that can be\nrepresented, we propose a novel actor-critic method called NQMIX. NQMIX\nintroduces an off-policy policy gradient on QMIX and modify its network\narchitecture, which can remove the monotonicity constraint of QMIX and\nimplement a non-monotonic value function factorization for the joint\naction-value function. In addition, NQMIX takes the state-value as the learning\ntarget, which overcomes the problem in QMIX that the learning target is\noverestimated. Furthermore, NQMIX can be extended to continuous action space\nsettings by introducing deterministic policy gradient on itself. Finally, we\nevaluate our actor-critic methods on SMAC domain, and show that it has a\nstronger performance than COMA and QMIX on complex maps with heterogeneous\nagent types. In addition, our ablation results show that our modification of\nmixer is effective.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 14:56:09 GMT"}, {"version": "v2", "created": "Sun, 18 Apr 2021 05:10:30 GMT"}, {"version": "v3", "created": "Mon, 21 Jun 2021 14:29:54 GMT"}, {"version": "v4", "created": "Tue, 13 Jul 2021 11:13:45 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Chen", "Quanlin", ""]]}, {"id": "2104.01959", "submitter": "Israel Donato Ridgley", "authors": "Israel L. Donato Ridgley, Randy A. Freeman, Kevin M. Lynch", "title": "Self-Healing First-Order Distributed Optimization", "comments": "Corrected equation (40) by changing \"min\" to \"max\", results\n  unaffected", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.MA cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we describe a parameterized family of first-order distributed\noptimization algorithms that enable a network of agents to collaboratively\ncalculate a decision variable that minimizes the sum of cost functions at each\nagent. These algorithms are self-healing in that their correctness is\nguaranteed even if they are initialized randomly, agents drop in or out of the\nnetwork, local cost functions change, or communication packets are dropped. Our\nalgorithms are the first single-Laplacian methods to exhibit all of these\ncharacteristics. We achieve self-healing by sacrificing internal stability, a\nfundamental trade-off for single-Laplacian methods.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 15:20:02 GMT"}, {"version": "v2", "created": "Mon, 12 Apr 2021 16:01:49 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Ridgley", "Israel L. Donato", ""], ["Freeman", "Randy A.", ""], ["Lynch", "Kevin M.", ""]]}, {"id": "2104.02278", "submitter": "The Danh Phan", "authors": "Danh T. Phan and Hai L. Vu", "title": "A novel activity pattern generation incorporating deep learning for\n  transport demand models", "comments": "21 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Activity generation plays an important role in activity-based demand\nmodelling systems. While machine learning, especially deep learning, has been\nincreasingly used for mode choice and traffic flow prediction, much less\nresearch exploiting the advantage of deep learning for activity generation\ntasks. This paper proposes a novel activity pattern generation framework by\nincorporating deep learning with travel domain knowledge. We model each\nactivity schedule as one primary activity tour and several secondary activity\ntours. We then develop different deep neural networks with entity embedding and\nrandom forest models to classify activity type, as well as to predict activity\ntimes. The proposed framework can capture the activity patterns for individuals\nin both training and validation sets. Results show high accuracy for the start\ntime and end time of work and school activities. The framework also replicates\nthe start time patterns of stop-before and stop-after primary work activity\nwell. This provides a promising direction to deploy advanced machine learning\nmethods to generate more reliable activity-travel patterns for transport demand\nsystems and their applications.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 04:07:05 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Phan", "Danh T.", ""], ["Vu", "Hai L.", ""]]}, {"id": "2104.02291", "submitter": "Chainarong Amornbunchornvej", "authors": "Chainarong Amornbunchornvej and Tanya Berger-Wolf", "title": "Framework for Inferring Leadership Dynamics of Complex Movement from\n  Time Series", "comments": "This paper was appeared in the proceeding of the 2018 SIAM\n  International Conference on Data Mining (SDM). The R package is available at\n  https://github.com/DarkEyes/mFLICA", "journal-ref": "Proceedings of the 2018 SIAM International Conference on Data\n  Mining (SDM)", "doi": "10.1137/1.9781611975321.62", "report-no": null, "categories": "cs.SI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Leadership plays a key role in social animals, including humans,\ndecision-making and coalescence in coordinated activities such as hunting,\nmigration, sport, diplomatic negotiation etc. In these coordinated activities,\nleadership is a process that organizes interactions among members to make a\ngroup achieve collective goals. Understanding initiation of coordinated\nactivities allows scientists to gain more insight into social species\nbehaviors. However, by using only time series of activities data, inferring\nleadership as manifested by the initiation of coordinated activities faces many\nchallenging issues. First, coordinated activities are dynamic and are changing\nover time. Second, several different coordinated activities might occur\nsimultaneously among subgroups. Third, there is no fundamental concept to\ndescribe these activities computationally. In this paper, we formalize Faction\nInitiator Inference Problem and propose a leadership inference framework as a\nsolution of this problem. The framework makes no assumption about the\ncharacteristics of a leader or the parameters of the coordination process. The\nframework performs better than our non-trivial baseline in both simulated and\nbiological datasets (schools of fish). Moreover, we demonstrate the application\nof our framework as a tool to study group merging and splitting dynamics on\nanother biological dataset of trajectories of wild baboons. In addition, our\nproblem formalization and framework enable opportunities for scientists to\nanalyze coordinated activities and generate scientific hypotheses about\ncollective behaviors that can be tested statistically and in the field.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 05:14:32 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Amornbunchornvej", "Chainarong", ""], ["Berger-Wolf", "Tanya", ""]]}, {"id": "2104.02809", "submitter": "Thomas Pike", "authors": "Thomas Pike, Samantha Golden, Daniel Lowdermilk, Brandon Luong,\n  Benjamin Rosado", "title": "Growing the Simulation Ecosystem", "comments": "14 Pages 4 figures, tied to GitHub Repo\n  https://github.com/projectmesadata", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This research represents an attempt to ignite the growth of a crowd sourced\nsimulation ecosystem of reusable subcomponents for Agent-Based Models. Due to\nthe inherent complexity of simulations, developing this ecosystem will be more\ndifficult than other knowledge sharing ecosystems, such as machine learning\nlibraries. This difficulty is due to the number of disparate parts that must\nwork together to provide a verified and validated simulation. Not only is it\ndifficult to ensure interoperability of component parts, but each part can also\nhave a significant number of possible variations. These variations can include\neverything from simple choices such as agent order to trained machine learning\nmodels with various architectures. However, due to the dynamics of complex\nsystems, the need for subcomponents cannot be ignored. Otherwise, the\nenvironment will consist of an incomprehensible number of standalone models,\nwithout reusable parts and without reproducibility. The goal of this research\nis to create a seed to encourage the development and sharing of the basic\ncomponents of a simulation (data ingestion, behaviors and processes, and\nplatform extensions) that will grow and develop into a robust ecosystem that\ndemocratizes simulations development and usage for both researchers and\npractitioners. A robust simulation ecosystem will help humanity further explore\nand probe the depths of complex systems, enhancing understanding and helping\nhumanity evolve.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 21:51:24 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Pike", "Thomas", ""], ["Golden", "Samantha", ""], ["Lowdermilk", "Daniel", ""], ["Luong", "Brandon", ""], ["Rosado", "Benjamin", ""]]}, {"id": "2104.03113", "submitter": "Andy Jones", "authors": "Andy L. Jones", "title": "Scaling Scaling Laws with Board Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The largest experiments in machine learning now require resources far beyond\nthe budget of all but a few institutions. Fortunately, it has recently been\nshown that the results of these huge experiments can often be extrapolated from\nthe results of a sequence of far smaller, cheaper experiments. In this work, we\nshow that not only can the extrapolation be done based on the size of the\nmodel, but on the size of the problem as well. By conducting a sequence of\nexperiments using AlphaZero and Hex, we show that the performance achievable\nwith a fixed amount of compute degrades predictably as the game gets larger and\nharder. Along with our main result, we further show that the test-time and\ntrain-time compute available to an agent can be traded off while maintaining\nperformance.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 13:34:25 GMT"}, {"version": "v2", "created": "Thu, 15 Apr 2021 10:03:37 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Jones", "Andy L.", ""]]}, {"id": "2104.03151", "submitter": "Rui Liu", "authors": "Yijiang Pang, Chao Huang, Rui Liu", "title": "Synthesized Trust Learning from Limited Human Feedback for\n  Human-Load-Reduced Multi-Robot Deployments", "comments": "6 pages, 7 figures and in Proc. of RO-MAN 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human multi-robot system (MRS) collaboration is demonstrating potentials in\nwide application scenarios due to the integration of human cognitive skills and\na robot team's powerful capability introduced by its multi-member structure.\nHowever, due to limited human cognitive capability, a human cannot\nsimultaneously monitor multiple robots and identify the abnormal ones, largely\nlimiting the efficiency of the human-MRS collaboration. There is an urgent need\nto proactively reduce unnecessary human engagements and further reduce human\ncognitive loads. Human trust in human MRS collaboration reveals human\nexpectations on robot performance. Based on trust estimation, the work between\na human and MRS will be reallocated that an MRS will self-monitor and only\nrequest human guidance in critical situations. Inspired by that, a novel\nSynthesized Trust Learning (STL) method was developed to model human trust in\nthe collaboration. STL explores two aspects of human trust (trust level and\ntrust preference), meanwhile accelerates the convergence speed by integrating\nactive learning to reduce human workload. To validate the effectiveness of the\nmethod, tasks \"searching victims in the context of city rescue\" were designed\nin an open-world simulation environment, and a user study with 10 volunteers\nwas conducted to generate real human trust feedback. The results showed that by\nmaximally utilizing human feedback, the STL achieved higher accuracy in trust\nmodeling with a few human feedback, effectively reducing human interventions\nneeded for modeling an accurate trust, therefore reducing human cognitive load\nin the collaboration.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 14:32:17 GMT"}, {"version": "v2", "created": "Tue, 13 Jul 2021 22:00:24 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Pang", "Yijiang", ""], ["Huang", "Chao", ""], ["Liu", "Rui", ""]]}, {"id": "2104.03404", "submitter": "Nicholas Guttenberg", "authors": "Nicholas Guttenberg, Marek Rosa", "title": "Bootstrapping of memetic from genetic evolution via inter-agent\n  selection pressures", "comments": "9 pages, 3 figures, submitted to ALife 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We create an artificial system of agents (attention-based neural networks)\nwhich selectively exchange messages with each-other in order to study the\nemergence of memetic evolution and how memetic evolutionary pressures interact\nwith genetic evolution of the network weights. We observe that the ability of\nagents to exert selection pressures on each-other is essential for memetic\nevolution to bootstrap itself into a state which has both high-fidelity\nreplication of memes, as well as continuing production of new memes over time.\nHowever, in this system there is very little interaction between this memetic\n'ecology' and underlying tasks driving individual fitness - the emergent meme\nlayer appears to be neither helpful nor harmful to agents' ability to learn to\nsolve tasks. Sourcecode for these experiments is available at\nhttps://github.com/GoodAI/memes\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 21:31:05 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Guttenberg", "Nicholas", ""], ["Rosa", "Marek", ""]]}, {"id": "2104.03503", "submitter": "Zhiwei Xu", "authors": "Zhiwei Xu, Bin Zhang, Yunpeng Bai, Dapeng Li, Guoliang Fan", "title": "Learning to Coordinate via Multiple Graph Neural Networks", "comments": "12 pages, 4 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The collaboration between agents has gradually become an important topic in\nmulti-agent systems. The key is how to efficiently solve the credit assignment\nproblems. This paper introduces MGAN for collaborative multi-agent\nreinforcement learning, a new algorithm that combines graph convolutional\nnetworks and value-decomposition methods. MGAN learns the representation of\nagents from different perspectives through multiple graph networks, and\nrealizes the proper allocation of attention between all agents. We show the\namazing ability of the graph network in representation learning by visualizing\nthe output of the graph network, and therefore improve interpretability for the\nactions of each agent in the multi-agent system.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 04:33:00 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Xu", "Zhiwei", ""], ["Zhang", "Bin", ""], ["Bai", "Yunpeng", ""], ["Li", "Dapeng", ""], ["Fan", "Guoliang", ""]]}, {"id": "2104.03741", "submitter": "The Anh Han", "authors": "The Anh Han, Tom Lenaerts, Francisco C. Santos, and Luis Moniz Pereira", "title": "Voluntary safety commitments provide an escape from over-regulation in\n  AI development", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.MA nlin.AO nlin.CD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the introduction of Artificial Intelligence (AI) and related\ntechnologies in our daily lives, fear and anxiety about their misuse as well as\nthe hidden biases in their creation have led to a demand for regulation to\naddress such issues. Yet blindly regulating an innovation process that is not\nwell understood, may stifle this process and reduce benefits that society may\ngain from the generated technology, even under the best intentions. In this\npaper, starting from a baseline model that captures the fundamental dynamics of\na race for domain supremacy using AI technology, we demonstrate how socially\nunwanted outcomes may be produced when sanctioning is applied unconditionally\nto risk-taking, i.e. potentially unsafe, behaviours. As an alternative to\nresolve the detrimental effect of over-regulation, we propose a voluntary\ncommitment approach wherein technologists have the freedom of choice between\nindependently pursuing their course of actions or establishing binding\nagreements to act safely, with sanctioning of those that do not abide to what\nthey pledged. Overall, this work reveals for the first time how voluntary\ncommitments, with sanctions either by peers or an institution, leads to\nsocially beneficial outcomes in all scenarios envisageable in a short-term race\ntowards domain supremacy through AI technology. These results are directly\nrelevant for the design of governance and regulatory policies that aim to\nensure an ethical and responsible AI technology development process.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 12:54:56 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Han", "The Anh", ""], ["Lenaerts", "Tom", ""], ["Santos", "Francisco C.", ""], ["Pereira", "Luis Moniz", ""]]}, {"id": "2104.03809", "submitter": "Vikram Shree", "authors": "Vikram Shree, Beatriz Asfora, Rachel Zheng, Samantha Hong, Jacopo\n  Banfi, and Mark Campbell", "title": "Exploiting Natural Language for Efficient Risk-Aware Multi-robot SaR\n  Planning", "comments": "8 pages, 5 figures. To be presented at the IEEE International\n  Conference on Robotics and Automation, 2021. Dataset available at:\n  https://github.com/vikshree/DISC-L.git", "journal-ref": "IEEE Robotics and Automation Letters, vol. 6, no. 2, pp.\n  3152-3159, April 2021", "doi": "10.1109/LRA.2021.3062798", "report-no": null, "categories": "cs.RO cs.HC cs.MA", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The ability to develop a high-level understanding of a scene, such as\nperceiving danger levels, can prove valuable in planning multi-robot search and\nrescue (SaR) missions. In this work, we propose to uniquely leverage natural\nlanguage descriptions from the mission commander in chief and image data\ncaptured by robots to estimate scene danger. Given a description and an image,\na state-of-the-art deep neural network is used to assess a corresponding\nsimilarity score, which is then converted into a probabilistic distribution of\ndanger levels. Because commonly used visio-linguistic datasets do not represent\nSaR missions well, we collect a large-scale image-description dataset from\nsynthetic images taken from realistic disaster scenes and use it to train our\nmachine learning model. A risk-aware variant of the Multi-robot Efficient\nSearch Path Planning (MESPP) problem is then formulated to use the danger\nestimates in order to account for high-risk locations in the environment when\nplanning the searchers' paths. The problem is solved via a distributed approach\nbased on Mixed-Integer Linear Programming. Our experiments demonstrate that our\nframework allows to plan safer yet highly successful search missions, abiding\nto the two most important aspects of SaR missions: to ensure both searchers'\nand victim safety.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 14:41:51 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Shree", "Vikram", ""], ["Asfora", "Beatriz", ""], ["Zheng", "Rachel", ""], ["Hong", "Samantha", ""], ["Banfi", "Jacopo", ""], ["Campbell", "Mark", ""]]}, {"id": "2104.04159", "submitter": "Harel Yedidsion", "authors": "Harel Yedidsion, Shani Alkoby, Peter Stone", "title": "Sequential Online Chore Division for Autonomous Vehicle Convoy Formation", "comments": "9 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chore division is a class of fair division problems in which some undesirable\n\"resource\" must be shared among a set of participants, with each participant\nwanting to get as little as possible. Typically the set of participants is\nfixed and known at the outset. This paper introduces a novel variant, called\nsequential online chore division (SOCD), in which participants arrive and\ndepart online, while the chore is being performed: both the total number of\nparticipants and their arrival/departure times are initially unknown. In SOCD,\nexactly one agent must be performing the chore at any give time (e.g. keeping\nlookout), and switching the performer incurs a cost. In this paper, we propose\nand analyze three mechanisms for SOCD: one centralized mechanism using side\npayments, and two distributed ones that seek to balance the participants'\nloads. Analysis and results are presented in a domain motivated by autonomous\nvehicle convoy formation, where the chore is leading the convoy so that all\nfollowers can enjoy reduced wind resistance.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 02:28:28 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Yedidsion", "Harel", ""], ["Alkoby", "Shani", ""], ["Stone", "Peter", ""]]}, {"id": "2104.04477", "submitter": "Xueyuan Wang", "authors": "Xueyuan Wang, M. Cenk Gursoy, Tugba Erpek and Yalin E. Sagduyu", "title": "Jamming-Resilient Path Planning for Multiple UAVs via Deep Reinforcement\n  Learning", "comments": "To be published in IEEE International Conference on Communications\n  (ICC) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Unmanned aerial vehicles (UAVs) are expected to be an integral part of\nwireless networks. In this paper, we aim to find collision-free paths for\nmultiple cellular-connected UAVs, while satisfying requirements of connectivity\nwith ground base stations (GBSs) in the presence of a dynamic jammer. We first\nformulate the problem as a sequential decision making problem in discrete\ndomain, with connectivity, collision avoidance, and kinematic constraints. We,\nthen, propose an offline temporal difference (TD) learning algorithm with\nonline signal-to-interference-plus-noise ratio (SINR) mapping to solve the\nproblem. More specifically, a value network is constructed and trained offline\nby TD method to encode the interactions among the UAVs and between the UAVs and\nthe environment; and an online SINR mapping deep neural network (DNN) is\ndesigned and trained by supervised learning, to encode the influence and\nchanges due to the jammer. Numerical results show that, without any information\non the jammer, the proposed algorithm can achieve performance levels close to\nthat of the ideal scenario with the perfect SINR-map. Real-time navigation for\nmulti-UAVs can be efficiently performed with high success rates, and collisions\nare avoided.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 16:52:33 GMT"}, {"version": "v2", "created": "Thu, 15 Apr 2021 19:11:40 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Wang", "Xueyuan", ""], ["Gursoy", "M. Cenk", ""], ["Erpek", "Tugba", ""], ["Sagduyu", "Yalin E.", ""]]}, {"id": "2104.04913", "submitter": "Anirudh Sridhar", "authors": "Anirudh Sridhar, Soummya Kar", "title": "On the Accuracy of Deterministic Models for Viral Spread on Networks", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.MA cs.SI cs.SY eess.SY math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the emergent behavior of viral spread when agents in a large\npopulation interact with each other over a contact network. When the number of\nagents is large and the contact network is a complete graph, it is well known\nthat the population behavior -- that is, the fraction of susceptible, infected\nand recovered agents -- converges to the solution of an ordinary differential\nequation (ODE) known as the classical SIR model as the population size\napproaches infinity. In contrast, we study interactions over contact networks\nwith generic topologies and derive conditions under which the population\nbehavior concentrates around either the classic SIR model or other\ndeterministic models. Specifically, we show that when most vertex degrees in\nthe contact network are sufficiently large, the population behavior\nconcentrates around an ODE known as the network SIR model. We then study the\nshort and intermediate-term evolution of the network SIR model and show that if\nthe contact network has an expander-type property or the initial set of\ninfections is well-mixed in the population, the network SIR model reduces to\nthe classical SIR model. To complement these results, we illustrate through\nsimulations that the two models can yield drastically different predictions,\nhence use of the classical SIR model can be misleading in certain cases.\n", "versions": [{"version": "v1", "created": "Sun, 11 Apr 2021 04:27:43 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Sridhar", "Anirudh", ""], ["Kar", "Soummya", ""]]}, {"id": "2104.05082", "submitter": "Reshef Meir", "authors": "Reshef Meir", "title": "The Core of Approval Participatory Budgeting with Uniform Costs (or with\n  up to Four Projects) is Non-Empty", "comments": "Found an error in the proof of theorem 17, Section 6", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the Approval Participatory Budgeting problem an agent prefers a set of\nprojects $W'$ over $W$ if she approves strictly more projects in $W'$. A set of\nprojects $W$ is in the core, if there is no other set of projects $W'$ and set\nof agents $K$ that both prefer $W'$ over $W$ and can fund $W'$. It is an open\nproblem whether the core can be empty, even when project costs are uniform. the\nlatter case is known as the multiwinner voting core.\n  We show that in any instance with uniform costs or with at most four projects\n(and any number of agents), the core is nonempty.\n", "versions": [{"version": "v1", "created": "Sun, 11 Apr 2021 19:22:11 GMT"}, {"version": "v2", "created": "Wed, 14 Apr 2021 22:08:11 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Meir", "Reshef", ""]]}, {"id": "2104.05305", "submitter": "Jordan Ivanchev", "authors": "Corvin Deboeser, Jordan Ivanchev, Thomas Braud, Alois Knoll, David\n  Eckhoff, Alberto Sangiovanni-Vincentelli", "title": "A Hierarchical State-Machine-Based Framework for Platoon Manoeuvre\n  Descriptions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.CL cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This paper introduces the SEAD framework that simplifies the process of\ndesigning and describing autonomous vehicle platooning manoeuvres. Although a\nlarge body of research has been formulating platooning manoeuvres, it is still\nchallenging to design, describe, read, and understand them. This difficulty\nlargely arises from missing formalisation. To fill this gap, we analysed\nexisting ways of describing manoeuvres, derived the causes of difficulty, and\ndesigned a framework that simplifies the manoeuvre design process. Alongside, a\nManoeuvre Design Language was developed to structurally describe manoeuvres in\na machine-readable format. Unlike state-of-the-art manoeuvre descriptions that\nrequire one state machine for every participating vehicle, the SEAD framework\nallows describing any manoeuvre from the single perspective of the platoon\nleader. %As a proof of concept, the proposed framework was implemented in the\nmixed traffic simulation environment BEHAVE for an autonomous highway scenario.\nUsing this framework, we implemented several manoeuvres as they were described\nin literature. To demonstrate the applicability of the framework, an experiment\nwas performed to evaluate the execution time performance of multiple\nalternatives of the Join-Middle manoeuvre. This proof-of-concept experiment\nrevealed that the manoeuvre execution time can be reduced by 28 \\% through\nparallelising various steps without considerable secondary effects. We hope\nthat the SEAD framework will pave the way for further research in the area of\nnew manoeuvre design and optimisation by largely simplifying and unifying\nplatooning manoeuvre representation.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 09:25:35 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Deboeser", "Corvin", ""], ["Ivanchev", "Jordan", ""], ["Braud", "Thomas", ""], ["Knoll", "Alois", ""], ["Eckhoff", "David", ""], ["Sangiovanni-Vincentelli", "Alberto", ""]]}, {"id": "2104.05610", "submitter": "Daan Klijn", "authors": "Daan Klijn, A.E. Eiben", "title": "A coevolutionary approach to deep multi-agent reinforcement learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditionally, Deep Artificial Neural Networks (DNN's) are trained through\ngradient descent. Recent research shows that Deep Neuroevolution (DNE) is also\ncapable of evolving multi-million-parameter DNN's, which proved to be\nparticularly useful in the field of Reinforcement Learning (RL). This is mainly\ndue to its excellent scalability and simplicity compared to the traditional\nMDP-based RL methods. So far, DNE has only been applied to complex single-agent\nproblems. As evolutionary methods are a natural choice for multi-agent\nproblems, the question arises whether DNE can also be applied in a complex\nmulti-agent setting. In this paper, we describe and validate a new approach\nbased on Coevolution. To validate our approach, we benchmark two Deep\nCoevolutionary Algorithms on a range of multi-agent Atari games and compare our\nresults against the results of Ape-X DQN. Our results show that these Deep\nCoevolutionary algorithms (1) can be successfully trained to play various\ngames, (2) outperform Ape-X DQN in some of them, and therefore (3) show that\nCoevolution can be a viable approach to solving complex multi-agent\ndecision-making problems.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 16:30:03 GMT"}, {"version": "v2", "created": "Tue, 13 Apr 2021 10:07:16 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Klijn", "Daan", ""], ["Eiben", "A. E.", ""]]}, {"id": "2104.05810", "submitter": "Lu An", "authors": "Lu An, Jie Duan, Mo-Yuen Chow, Alexandra Duel-Hallen", "title": "A Distributed and Resilient Bargaining Game for Weather-Predictive\n  Microgrid Energy Cooperation", "comments": "9 pages, 8 figures, published in IEEE Transactions on Industrial\n  Informatics", "journal-ref": "IEEE Transactions on Industrial Informatics 15 (8), 4721-4730,\n  2019", "doi": "10.1109/TII.2019.2907380", "report-no": null, "categories": "cs.MA cs.GT cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A bargaining game is investigated for cooperative energy management in\nmicrogrids. This game incorporates a fully distributed and realistic\ncooperative power scheduling algorithm (CoDES) as well as a distributed Nash\nBargaining Solution (NBS)-based method of allocating the overall power bill\nresulting from CoDES. A novel weather-based stochastic renewable generation\n(RG) prediction method is incorporated in the power scheduling. We demonstrate\nthe proposed game using a 4-user grid-connected microgrid model with diverse\nuser demands, storage, and RG profiles and examine the effect of weather\nprediction on day-ahead power scheduling and cost/profit allocation. Finally,\nthe impact of users' ambivalence about cooperation and /or dishonesty on the\nbargaining outcome is investigated, and it is shown that the proposed game is\nresilient to malicious users' attempts to avoid payment of their fair share of\nthe overall bill.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 20:49:19 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["An", "Lu", ""], ["Duan", "Jie", ""], ["Chow", "Mo-Yuen", ""], ["Duel-Hallen", "Alexandra", ""]]}, {"id": "2104.05849", "submitter": "Shashank Motepalli", "authors": "Shashank Motepalli and Hans-Arno Jacobsen", "title": "Reward Mechanism for Blockchains Using Evolutionary Game Theory", "comments": "Cite: @inproceedings{motepalli2021reward, title={Reward Mechanism for\n  Blockchains Using Evolutionary Game Theory}, author={Motepalli, Shashank and\n  Jacobsen, Hans-Arno}, booktitle={2021 3rd Conference on Blockchain Research &\n  Applications for Innovative Networks and Services (BRAINS)}, year={2021} }", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CE cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockchains have witnessed widespread adoption in the past decade in various\nfields. The growing demand makes their scalability and sustainability\nchallenges more evident than ever. As a result, more and more blockchains have\nbegun to adopt proof-of-stake (PoS) consensus protocols to address those\nchallenges. One of the fundamental characteristics of any blockchain technology\nis its crypto-economics and incentives. Lately, each PoS blockchain has\ndesigned a unique reward mechanism, yet, many of them are prone to free-rider\nand nothing-at-stake problems. To better understand the ad-hoc design of reward\nmechanisms, in this paper, we develop a reward mechanism framework that could\napply to many PoS blockchains. We formulate the block validation game wherein\nthe rewards are distributed for validating the blocks correctly. Using\nevolutionary game theory, we analyze how the participants' behaviour could\npotentially evolve with the reward mechanism. Also, penalties are found to play\na central role in maintaining the integrity of blockchains.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 22:38:32 GMT"}, {"version": "v2", "created": "Thu, 8 Jul 2021 18:56:06 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Motepalli", "Shashank", ""], ["Jacobsen", "Hans-Arno", ""]]}, {"id": "2104.06588", "submitter": "Jiayi Wei", "authors": "Jiayi Wei, Tongrui Li, Swarat Chaudhuri, Isil Dillig, Joydeep Biswas", "title": "OneVision: Centralized to Distributed Controller Synthesis with Delay\n  Compensation", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.MA cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new algorithm to simplify the controller development for\ndistributed robotic systems subject to external observations, disturbances, and\ncommunication delays. Unlike prior approaches that propose specialized\nsolutions to handling communication latency for specific robotic applications,\nour algorithm uses an arbitrary centralized controller as the specification and\nautomatically generates distributed controllers with communication management\nand delay compensation. We formulate our goal as nonlinear optimal control --\nusing a regret minimizing objective that measures how much the distributed\nagents behave differently from the delay-free centralized response -- and solve\nfor optimal actions w.r.t. local estimations of this objective using\ngradient-based optimization. We analyze our proposed algorithm's behavior under\na linear time-invariant special case and prove that the closed-loop dynamics\nsatisfy a form of input-to-state stability w.r.t. unexpected disturbances and\nobservations. Our experimental results on both simulated and real-world robotic\ntasks demonstrate the practical usefulness of our approach and show significant\nimprovement over several baseline approaches.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 02:16:11 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Wei", "Jiayi", ""], ["Li", "Tongrui", ""], ["Chaudhuri", "Swarat", ""], ["Dillig", "Isil", ""], ["Biswas", "Joydeep", ""]]}, {"id": "2104.06654", "submitter": "Pegah Rokhforoz", "authors": "Pegah Rokhforoz, Olga Fink", "title": "Maintenance scheduling of manufacturing systems based on optimal price\n  of the network", "comments": "16 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Goods can exhibit positive externalities impacting decisions of customers in\nsocials networks. Suppliers can integrate these externalities in their pricing\nstrategies to increase their revenue. Besides optimizing the prize, suppliers\nalso have to consider their production and maintenance costs. Predictive\nmaintenance has the potential to reduce the maintenance costs and improve the\nsystem availability. To address the joint optimization of pricing with network\nexternalities and predictive maintenance scheduling based on the condition of\nthe system, we propose a bi-level optimization solution based on game theory.\nIn the first level, the manufacturing company decides about the predictive\nmaintenance scheduling of the units and the price of the goods. In the second\nlevel, the customers decide about their consumption using an optimization\napproach in which the objective function depends on their consumption, the\nconsumption levels of other customers who are connected through the graph, and\nthe price of the network which is determined by the supplier. To solve the\nproblem, we propose the leader-multiple-followers game where the supplier as a\nleader predicts the strategies of the followers. Then, customers as the\nfollowers obtain their strategies based on the leader's and other followers'\nstrategies. We demonstrate the effectiveness of our proposed method on a\nsimulated case study. The results demonstrate that knowledge of the social\nnetwork graph results in an increased revenue compared to the case when the\nunderlying social network graph is not known. Moreover, the results demonstrate\nthat obtaining the predictive maintenance scheduling based on the proposed\noptimization approach leads to an increased profit compared to the baseline\ndecision-making (perform maintenance at the degradation limit).\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 07:01:53 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Rokhforoz", "Pegah", ""], ["Fink", "Olga", ""]]}, {"id": "2104.06655", "submitter": "Yuan Pu", "authors": "Yuan Pu, Shaochen Wang, Rui Yang, Xin Yao, Bin Li", "title": "Decomposed Soft Actor-Critic Method for Cooperative Multi-Agent\n  Reinforcement Learning", "comments": "11 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep reinforcement learning methods have shown great performance on many\nchallenging cooperative multi-agent tasks. Two main promising research\ndirections are multi-agent value function decomposition and multi-agent policy\ngradients. In this paper, we propose a new decomposed multi-agent soft\nactor-critic (mSAC) method, which effectively combines the advantages of the\naforementioned two methods. The main modules include decomposed Q network\narchitecture, discrete probabilistic policy and counterfactual advantage\nfunction (optinal). Theoretically, mSAC supports efficient off-policy learning\nand addresses credit assignment problem partially in both discrete and\ncontinuous action spaces. Tested on StarCraft II micromanagement cooperative\nmultiagent benchmark, we empirically investigate the performance of mSAC\nagainst its variants and analyze the effects of the different components.\nExperimental results demonstrate that mSAC significantly outperforms\npolicy-based approach COMA, and achieves competitive results with SOTA\nvalue-based approach Qmix on most tasks in terms of asymptotic perfomance\nmetric. In addition, mSAC achieves pretty good results on large action space\ntasks, such as 2c_vs_64zg and MMM2.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 07:02:40 GMT"}, {"version": "v2", "created": "Sat, 8 May 2021 03:34:07 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Pu", "Yuan", ""], ["Wang", "Shaochen", ""], ["Yang", "Rui", ""], ["Yao", "Xin", ""], ["Li", "Bin", ""]]}, {"id": "2104.06737", "submitter": "Gregor Betz", "authors": "Gregor Betz", "title": "Natural-Language Multi-Agent Simulations of Argumentative Opinion\n  Dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY cs.MA cs.SI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This paper develops a natural-language agent-based model of argumentation\n(ABMA). Its artificial deliberative agents (ADAs) are constructed with the help\nof so-called neural language models recently developed in AI and computational\nlinguistics. ADAs are equipped with a minimalist belief system and may generate\nand submit novel contributions to a conversation. The natural-language ABMA\nallows us to simulate collective deliberation in English, i.e. with arguments,\nreasons, and claims themselves -- rather than with their mathematical\nrepresentations (as in formal models). This paper uses the natural-language\nABMA to test the robustness of formal reason-balancing models of argumentation\n[Maes & Flache 2013, Singer et al. 2019]: First of all, as long as ADAs remain\npassive, confirmation bias and homophily updating trigger polarization, which\nis consistent with results from formal models. However, once ADAs start to\nactively generate new contributions, the evolution of a conservation is\ndominated by properties of the agents *as authors*. This suggests that the\ncreation of new arguments, reasons, and claims critically affects a\nconversation and is of pivotal importance for understanding the dynamics of\ncollective deliberation. The paper closes by pointing out further fruitful\napplications of the model and challenges for future research.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 09:45:22 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Betz", "Gregor", ""]]}, {"id": "2104.06940", "submitter": "Roee Mordechai Francos", "authors": "Roee M. Francos and Alfred M. Bruckstein", "title": "Pincer-based vs. Same-direction Search Strategies After Smart Evaders by\n  Swarms of Agents", "comments": "arXiv admin note: substantial text overlap with arXiv:2005.01011,\n  arXiv:1905.04006", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Suppose in a given planar region, there are smart mobile evaders and we want\nto detect them using sweeping agents. We assume that the agents have line\nsensors of equal length. We propose procedures for designing cooperative\nsweeping processes that ensure successful completion of the task, thereby\nderiving conditions on the sweeping velocity of the agents and their paths.\nSuccessful completion of the task means that evaders with a known limit on\ntheir velocity cannot escape the sweeping agents. A simpler task for the\nsweeping swarm is the confinement of the evaders to their initial domain. The\nfeasibility of completing these tasks depends on geometric and dynamic\nconstraints that impose a lower bound on the velocity the sweeping agent must\nhave. This critical velocity is derived to ensure the satisfaction of the\nconfinement task. Increasing the velocity above the lower bound enables the\nagents to complete the search task as well. We present a quantitative and\nqualitative comparison analysis between the total search time of same-direction\nsweep processes and pincer-movement search strategies. We evaluate the\ndifferent strategies by using two metrics, total search time and the minimal\ncritical velocity required for a successful search. We compare two types of\npincer-movement search processes, circular and spiral, with their\nsame-direction counterparts, for any even number of sweeping agents. We prove\nthat pincer based strategies provide superior results for all practical\nscenarios and that the spiral pincer sweep process allows detection of all\nevaders while sweeping at nearly theoretically optimal velocities.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 16:07:35 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Francos", "Roee M.", ""], ["Bruckstein", "Alfred M.", ""]]}, {"id": "2104.07494", "submitter": "Antonio Bucchiarone Dr.", "authors": "Antonio Bucchiarone, Martina De Sanctis, Nelly Bencomo", "title": "Agent-based Framework for Self-Organization of Collective and Autonomous\n  Shuttle Fleets", "comments": "13 pages, 10 Figures, Early Access Article published at the IEEE\n  Transactions on Intelligent Transportation Systems", "journal-ref": null, "doi": "10.1109/TITS.2020.3021592", "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The mobility of people is at the center of transportation planning and\ndecision-making of the cities of the future. In order to accelerate the\ntransition to zero-emissions and to maximize air quality benefits, smart cities\nare prioritizing walking, cycling, shared mobility services and public\ntransport over the use of private cars. Extensive progress has been made in\nautonomous and electric cars. Autonomous Vehicles (AV) are increasingly capable\nof moving without full control of humans, automating some aspects of driving,\nsuch as steering or braking. For these reasons, cities are investing in the\ninfrastructure and technology needed to support connected, multi-modal transit\nnetworks that include shared electric Autonomous Vehicles (AV). The\nrelationship between traditional public transport and new mobility services is\nin the spotlight and need to be rethought. This paper proposes an agent-based\nsimulation framework that allows for the creation and simulation of mobility\nscenarios to investigate the impact of new mobility modes on a city daily life.\nIt lets traffic planners explore the cooperative integration of AV using a\ndecentralized control approach. A prototype has been implemented and validated\nwith data of the city of Trento.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 14:39:57 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Bucchiarone", "Antonio", ""], ["De Sanctis", "Martina", ""], ["Bencomo", "Nelly", ""]]}, {"id": "2104.07620", "submitter": "Thomas Seel", "authors": "Michael Meindl, Fabio Molinari, Dustin Lehmann, Thomas Seel", "title": "Collective Iterative Learning Control: Exploiting Diversity in\n  Multi-Agent Systems for Reference Tracking Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.MA cs.RO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers a group of autonomous agents learning to track the same\ngiven reference trajectory in a possibly small number of trials. We propose a\nnovel collective learning control method (namely, CILC) that combines Iterative\nLearning Control (ILC) with a collective input update strategy. We derive\nconditions for desirable convergence properties of such systems. We show that\nthe proposed method allows the collective to combine the advantages of the\nagents' individual learning strategies and thereby overcomes trade-offs and\nlimitations of single-agent ILC. This benefit is leveraged by designing a\nheterogeneous collective, i.e., a different learning law is assigned to each\nagent. All theoretical results are confirmed in simulations and experiments\nwith two-wheeled-inverted-pendulums robots (TWIPRs) that jointly learn to\nperform a desired maneuver.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 17:36:00 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Meindl", "Michael", ""], ["Molinari", "Fabio", ""], ["Lehmann", "Dustin", ""], ["Seel", "Thomas", ""]]}, {"id": "2104.07741", "submitter": "Hossein Rastgoftar", "authors": "Hossein Rastgoftar and Ilya Kolmanovsky", "title": "Safe Affine Transformation-Based Guidance of a Large-Scale\n  Multi-Quadcopter System (MQS)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the problem of affine transformation-based guidance of a\nmulti-quadcopter system (MQS) in an obstacle-laden environment. Such MQSs can\nperform a variety of cooperative tasks including information collection,\ninspection mapping, disinfection, and firefighting. The MQS affine\ntransformation is an approach to a decentralized leader-follower coordination\nguided by n +1 leaders, where leaders are located at vertices of an n-D\nsimplex, called leading simplex, at any time t. The remaining agents are\nfollowers acquiring the desired affine transformation via local communication.\nFollowers are contained in a rigid-size ball at any time t but they can be\ndistributed either inside or outside the leading simplex. By\neigen-decomposition of the affine transformation coordination, safety in a\nlarge-scale MQS coordination can be ensured by constraining eigenvalues of the\naffine transformation. Given the initial and final configurations of the MQS,\nA-star search is applied to optimally plan safe coordination of a large-scale\nMQS minimizing the travel distance between the the initial and final\nconfiguration. The paper also proposes a proximity-based communication topology\nfor followers to assign communication weights with their in-neighbors and\nacquire the desired coordination with minimal computation cost.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 19:40:03 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Rastgoftar", "Hossein", ""], ["Kolmanovsky", "Ilya", ""]]}, {"id": "2104.07750", "submitter": "Dennis Lee", "authors": "Dennis Lee, Natasha Jaques, Chase Kew, Douglas Eck, Dale Schuurmans,\n  Aleksandra Faust", "title": "Joint Attention for Multi-Agent Coordination and Social Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Joint attention - the ability to purposefully coordinate attention with\nanother agent, and mutually attend to the same thing -- is a critical component\nof human social cognition. In this paper, we ask whether joint attention can be\nuseful as a mechanism for improving multi-agent coordination and social\nlearning. We first develop deep reinforcement learning (RL) agents with a\nrecurrent visual attention architecture. We then train agents to minimize the\ndifference between the attention weights that they apply to the environment at\neach timestep, and the attention of other agents. Our results show that this\njoint attention incentive improves agents' ability to solve difficult\ncoordination tasks, by reducing the exponential cost of exploring the joint\nmulti-agent action space. Joint attention leads to higher performance than a\ncompetitive centralized critic baseline across multiple environments. Further,\nwe show that joint attention enhances agents' ability to learn from experts\npresent in their environment, even when completing hard exploration tasks that\ndo not require coordination. Taken together, these findings suggest that joint\nattention may be a useful inductive bias for multi-agent learning.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 20:14:19 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Lee", "Dennis", ""], ["Jaques", "Natasha", ""], ["Kew", "Chase", ""], ["Eck", "Douglas", ""], ["Schuurmans", "Dale", ""], ["Faust", "Aleksandra", ""]]}, {"id": "2104.07989", "submitter": "Fabian Mager", "authors": "Fabian Mager, Dominik Baumann, Carsten Herrmann, Sebastian Trimpe,\n  Marco Zimmerling", "title": "Scaling Beyond Bandwidth Limitations: Wireless Control With Stability\n  Guarantees Under Overload", "comments": "Submitted to ACM Transactions on Cyber-Physical Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.MA cs.NI cs.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  An important class of cyber-physical systems relies on multiple agents that\njointly perform a task by coordinating their actions over a wireless network.\nExamples include self-driving cars in intelligent transportation and production\nrobots in smart manufacturing. However, the scalability of existing\ncontrol-over-wireless solutions is limited as they cannot resolve overload\nsituations in which the communication demand exceeds the available bandwidth.\nThis paper presents a novel co-design of distributed control and wireless\ncommunication that overcomes this limitation by dynamically allocating the\navailable bandwidth to agents with the greatest need to communicate.\nExperiments on a real cyber-physical testbed with 20 agents, each consisting of\na wireless node and a cart-pole system, demonstrate that our solution achieves\nsignificantly better control performance under overload than the state of the\nart. We further prove that our co-design guarantees closed-loop stability for\nphysical systems with stochastic linear time-invariant dynamics.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 09:32:11 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Mager", "Fabian", ""], ["Baumann", "Dominik", ""], ["Herrmann", "Carsten", ""], ["Trimpe", "Sebastian", ""], ["Zimmerling", "Marco", ""]]}, {"id": "2104.08010", "submitter": "Ezra Tampubolon", "authors": "Ezra Tampubolon and Holger Boche", "title": "Welfare Measure for Resource Allocation with Algorithmic Implementation:\n  Beyond Average and Max-Min", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.GT cs.MA cs.NI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose an axiomatic approach for measuring the\nperformance/welfare of a system consisting of concurrent agents in a\nresource-driven system. Our approach provides a unifying view on popular system\noptimality principles, such as the maximal average/total utilities and the\nmax-min fairness. Moreover, it gives rise to other system optimality notions\nthat have not been fully exploited yet, such as the maximal lowest total\nsubgroup utilities. For the axiomatically defined welfare measures, we provide\na generic gradient-based method to find an optimal resource allocation and\npresent a theoretical guarantee for its success. Lastly, we demonstrate the\npower of our approach through the power control application in wireless\nnetworks.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 10:11:01 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Tampubolon", "Ezra", ""], ["Boche", "Holger", ""]]}, {"id": "2104.08203", "submitter": "Tesfamariam M Abuhay", "authors": "Tesfamariam M. Abuhay, Adane Mamuye, Stewart Robinson, Sergey V.\n  Kovalchuk", "title": "Why Machine Learning Integrated Patient Flow Simulation?", "comments": "Proceedings of the Operational Research Society Simulation Workshop\n  2021 (SW21)", "journal-ref": "Proceedings of the Operational Research Society Simulation\n  Workshop 2021 (SW21)", "doi": "10.36819/SW21.041", "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Patient flow analysis can be studied from a clinical and or operational\nperspective using simulation. Traditional statistical methods such as\nstochastic distribution methods have been used to construct patient flow\nsimulation submodels such as patient inflow, Length of Stay (LoS), Cost of\nTreatment (CoT) and Clinical Pathway (CP) models. However, patient inflow\ndemonstrates seasonality, trend and variation over time. LoS, CoT and CP are\nsignificantly determined by attributes of patients and clinical and laboratory\ntest results. For this reason, patient flow simulation models constructed using\ntraditional statistical methods are criticized for ignoring heterogeneity and\ntheir contribution to personalized and value based healthcare. On the other\nhand, machine learning methods have proven to be efficient to study and predict\nadmission rate, LoS, CoT, and CP. This paper, hence, describes why coupling\nmachine learning with patient flow simulation is important and proposes a\nconceptual architecture that shows how to integrate machine learning with\npatient flow simulation.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 16:23:17 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Abuhay", "Tesfamariam M.", ""], ["Mamuye", "Adane", ""], ["Robinson", "Stewart", ""], ["Kovalchuk", "Sergey V.", ""]]}, {"id": "2104.08355", "submitter": "Amit Chopra", "authors": "Samuel H. Christie V, Amit K. Chopra, Munindar P. Singh", "title": "Hercule: Representing and Reasoning about Norms as a Foundation for\n  Declarative Contracts over Blockchain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current blockchain approaches for business contracts are based on smart\ncontracts, namely, software programs placed on a blockchain that are\nautomatically executed to realize a contract. However, smart contracts lack\nflexibility and interfere with the autonomy of the parties concerned.\n  We propose Hercule, an approach for declaratively specifying blockchain\napplications in a manner that reflects business contracts. Hercule represents a\ncontract via regulatory norms that capture the involved parties' expectations\nof one another. It computes the states of norms (hence, of contracts) from\nevents in the blockchain. Hercule's novelty and significance lie in that it\noperationalizes declarative contracts over semistructured databases, the\nunderlying representation for practical blockchain such as Hyperledger Fabric\nand Ethereum. Specifically, it exploits the map-reduce capabilities of such\nstores to compute norm states.\n  We demonstrate that our implementation over Hyperledger Fabric can process\nthousands of events per second, sufficient for many applications.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 20:15:57 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Christie", "Samuel H.", "V"], ["Chopra", "Amit K.", ""], ["Singh", "Munindar P.", ""]]}, {"id": "2104.08594", "submitter": "Dominik Peters", "authors": "Dominik Peters", "title": "Proportionality and Strategyproofness in Multiwinner Elections", "comments": "9 pages, AAMAS-18 paper with an error corrected (see note on first\n  page)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiwinner voting rules can be used to select a fixed-size committee from a\nlarger set of candidates. We consider approval-based committee rules, which\nallow voters to approve or disapprove candidates. In this setting, several\nvoting rules such as Proportional Approval Voting (PAV) and Phragm\\'en's rules\nhave been shown to produce committees that are proportional, in the sense that\nthey proportionally represent voters' preferences; all of these rules are\nstrategically manipulable by voters. On the other hand, a generalisation of\nApproval Voting gives a non-proportional but strategyproof voting rule. We show\nthat there is a fundamental tradeoff between these two properties: we prove\nthat no multiwinner voting rule can simultaneously satisfy a weak form of\nproportionality (a weakening of justified representation) and a weak form of\nstrategyproofness. Our impossibility is obtained using a formulation of the\nproblem in propositional logic and applying SAT solvers; a human-readable\nversion of the computer-generated proof is obtained by extracting a minimal\nunsatisfiable set (MUS). We also discuss several related axiomatic questions in\nthe domain of committee elections.\n", "versions": [{"version": "v1", "created": "Sat, 17 Apr 2021 16:40:45 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Peters", "Dominik", ""]]}, {"id": "2104.08759", "submitter": "Ofir Gordon", "authors": "Ofir Gordon, Yuval Filmus, Oren Salzman", "title": "Revisiting the Complexity Analysis of Conflict-Based Search: New\n  Computational Techniques and Improved Bounds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.CC cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The problem of Multi-Agent Path Finding (MAPF) calls for finding a set of\nconflict-free paths for a fleet of agents operating in a given environment.\nArguably, the state-of-the-art approach to computing optimal solutions is\nConflict-Based Search (CBS). In this work we revisit the complexity analysis of\nCBS to provide tighter bounds on the algorithm's run-time in the worst-case.\nOur analysis paves the way to better pinpoint the parameters that govern (in\nthe worst case) the algorithm's computational complexity.\n  Our analysis is based on two complementary approaches: In the first approach\nwe bound the run-time using the size of a Multi-valued Decision Diagram (MDD)\n-- a layered graph which compactly contains all possible single-agent paths\nbetween two given vertices for a specific path length.\n  In the second approach we express the running time by a novel recurrence\nrelation which bounds the algorithm's complexity. We use generating\nfunctions-based analysis in order to tightly bound the recurrence.\n  Using these technique we provide several new upper-bounds on CBS's\ncomplexity. The results allow us to improve the existing bound on the running\ntime of CBS for many cases. For example, on a set of common benchmarks we\nimprove the upper-bound by a factor of at least $2^{10^{7}}$.\n", "versions": [{"version": "v1", "created": "Sun, 18 Apr 2021 07:46:28 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Gordon", "Ofir", ""], ["Filmus", "Yuval", ""], ["Salzman", "Oren", ""]]}, {"id": "2104.08904", "submitter": "Vincent Hill", "authors": "Vincent W. Hill, Ryan W. Thomas, and Jordan D. Larson", "title": "Autonomous Situational Awareness for UAS Swarms", "comments": "IEEE Aerospace 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.MA cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper describes a technique for the autonomous mission planning of\nunmanned aerial system swarms. Given a swarm operating in a known area, a\ncentral command system generates measurements from the swarm. If those\nmeasurements indicate changes to the mission situation such as target movement,\nthe swarm planning is updated to reflect the new situation and guidance updates\nare broadcast to the swarm. The primary algorithms featured in this work are A*\npathfinding and the Generalized Labeled Multi-Bernoulli multi-target tracking\nmethod.\n", "versions": [{"version": "v1", "created": "Sun, 18 Apr 2021 16:41:56 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Hill", "Vincent W.", ""], ["Thomas", "Ryan W.", ""], ["Larson", "Jordan D.", ""]]}, {"id": "2104.09336", "submitter": "Hesham Rakha", "authors": "Kyoungho Ahn, Youssef Bichiou, Mohamed Farag, Hesham A. Rakha", "title": "Multi-objective Eco-Routing Model Development and Evaluation for Battery\n  Electric Vehicles", "comments": "Paper submitted to Transportation Research Board Annual Meeting", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.MA cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops and investigates the impacts of multi-objective Nash\noptimum (user equilibrium) traffic assignment on a large-scale network for\nbattery electric vehicles (BEVs) and internal combustion engine vehicles\n(ICEVs) in a microscopic traffic simulation environment. Eco-routing is a\ntechnique that finds the most energy efficient route. ICEV and BEV energy\nconsumption patterns are significantly different with regard to their\nsensitivity to driving cycles. Unlike ICEVs, BEVs are more energy efficient on\nlow-speed arterial trips compared to highway trips. Different energy\nconsumption patterns require different eco-routing strategies for ICEVs and\nBEVs. This study found that eco-routing could reduce energy consumption for\nBEVs but also significantly increases their average travel time. The simulation\nstudy found that multi-objective routing could reduce the energy consumption of\nBEVs by 13.5, 14.2, 12.9, and 10.7 percent, as well as the fuel consumption of\nICEVs by 0.1, 4.3, 3.4, and 10.6 percent for \"not congested\", \"slightly\ncongested\", \"moderately congested\", and \"highly congested\" conditions,\nrespectively. The study also found that multi-objective user equilibrium\nrouting reduced the average vehicle travel time by up to 10.1% compared to the\nstandard user equilibrium traffic assignment for the highly congested\nconditions, producing a solution closer to the system optimum traffic\nassignment. The results indicate that the multi-objective eco-routing can\neffectively reduce fuel/energy consumption with minimum impacts on travel times\nfor both BEVs and ICEVs.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 15:55:04 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Ahn", "Kyoungho", ""], ["Bichiou", "Youssef", ""], ["Farag", "Mohamed", ""], ["Rakha", "Hesham A.", ""]]}, {"id": "2104.09998", "submitter": "Hossein Rastgoftar", "authors": "Hossein Rastgoftar, Sergey Nersesov, and Hashem Ashrafiuon", "title": "Continuum Deformation Coordination of Multi-Agent Systems Using\n  Cooperative Localization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the problem of decentralized continuum deformation\ncoordination of multi-agent systems aided by cooperative localization. We treat\nagents as particles inside a triangular continuum (deformable body) in a2-D\nmotion space and let the continuum deformation coordination be defined by three\nleaders located at vertices of a triangle, called the leading triangle. The\nleaders desired trajectories are assigned as the solution of a constrained\noptimal control problem such that safety requirements are satisfied in the\npresence of disturbance and measurement noise. Followers distributed inside the\nleading tri-angle acquire continuum deformation in a decentralized fashion by\nintegrating cooperative localization and local communication. Specifically,\ncooperative localization estimates the global positions of all agents using\nrelative position measurements based primarily on proximity of agents.\nSimulation results are presented for a network of ten agents.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 14:26:46 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Rastgoftar", "Hossein", ""], ["Nersesov", "Sergey", ""], ["Ashrafiuon", "Hashem", ""]]}, {"id": "2104.10394", "submitter": "Gioele Zardini", "authors": "Gioele Zardini and Nicolas Lanzetti and Laura Guerrini and Emilio\n  Frazzoli and Florian D\\\"orfler", "title": "Game Theory to Study Interactions between Mobility Stakeholders", "comments": "8 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.SY eess.SY math.OC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Increasing urbanization and exacerbation of sustainability goals threaten the\noperational efficiency of current transportation systems and confront cities\nwith complex choices with huge impact on future generations. At the same time,\nthe rise of private, profit-maximizing Mobility Service Providers leveraging\npublic resources, such as ride-hailing companies, entangles current regulation\nschemes. This calls for tools to study such complex socio-technical problems.\nIn this paper, we provide a game-theoretic framework to study interactions\nbetween stakeholders of the mobility ecosystem, modeling regulatory aspects\nsuch as taxes and public transport prices, as well as operational matters for\nMobility Service Providers such as pricing strategy, fleet sizing, and vehicle\ndesign. Our framework is modular and can readily accommodate different types of\nMobility Service Providers, actions of municipalities, and low-level models of\ncustomers choices in the mobility system. Through both an analytical and a\nnumerical case study for the city of Berlin, Germany, we showcase the ability\nof our framework to compute equilibria of the problem, to study fundamental\ntradeoffs, and to inform stakeholders and policy makers on the effects of\ninterventions. Among others, we show tradeoffs between customers satisfaction,\nenvironmental impact, and public revenue, as well as the impact of strategic\ndecisions on these metrics.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 07:51:15 GMT"}, {"version": "v2", "created": "Sat, 3 Jul 2021 15:39:03 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Zardini", "Gioele", ""], ["Lanzetti", "Nicolas", ""], ["Guerrini", "Laura", ""], ["Frazzoli", "Emilio", ""], ["D\u00f6rfler", "Florian", ""]]}, {"id": "2104.10508", "submitter": "Timy Phan", "authors": "Timy Phan", "title": "Searching with Opponent-Awareness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Searching with Opponent-Awareness (SOA), an approach to leverage\nopponent-aware planning without explicit or a priori opponent models for\nimproving performance and social welfare in multi-agent systems. To this end,\nwe develop an opponent-aware MCTS scheme using multi-armed bandits based on\nLearning with Opponent-Learning Awareness (LOLA) and compare its effectiveness\nwith other bandits, including UCB1. Our evaluations include several different\nsettings and show the benefits of SOA are especially evident with increasing\nnumber of agents.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 12:59:47 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Phan", "Timy", ""]]}, {"id": "2104.10639", "submitter": "Kathinka Frieswijk", "authors": "Kathinka Frieswijk, Alain Govaert, Ming Cao", "title": "Exerting Control in Repeated Social Dilemmas with Thresholds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Situations in which immediate self-interest and long-term collective interest\nconflict often require some form of influence to prevent them from leading to\nundesirable or unsustainable outcomes. Next to sanctioning, social influence\nand social structure, it is possible that strategic solutions can exist for\nthese social dilemmas. However, the existence of strategies that enable a\nplayer to exert control in the long-run outcomes can be difficult to show and\ndifferent situations allow for different levels of strategic influence. Here,\nwe investigate the effect of threshold nonlinearities on the possibilities of\nexerting unilateral control in finitely repeated n-player public goods games\nand snowdrift games. These models can describe situations in which a collective\neffort is necessary in order for a benefit to be created. We identify\nconditions in terms of a cooperator threshold for the existence of generous,\nextortionate and equalizing zero-determinant (ZD) strategies. Our results show\nthat, for both games, the thresholds prevent equalizing ZD strategies from\nexisting. In the snowdrift game, introducing a cooperator threshold has no\neffect on the region of feasible extortionate ZD strategies. For extortionate\nstrategies in the public goods game, the threshold only restricts the region of\nenforceable strategies for small values of the public goods multiplier.\nGenerous ZD strategies exist for both games, but introducing a cooperator\nthreshold forces the slope more towards the value of a fair strategy, where the\nplayer has approximately the same payoff as the average payoff of his\nopponents.\n", "versions": [{"version": "v1", "created": "Sun, 21 Feb 2021 09:56:32 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Frieswijk", "Kathinka", ""], ["Govaert", "Alain", ""], ["Cao", "Ming", ""]]}, {"id": "2104.10923", "submitter": "Sagar Sudhakara", "authors": "Sagar Sudhakara, Dhruva Kartik, Rahul Jain, Ashutosh Nayyar", "title": "Optimal communication and control strategies in a multi-agent MDP\n  problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The problem of controlling multi-agent systems under different models of\ninformation sharing among agents has received significant attention in the\nrecent literature. In this paper, we consider a setup where rather than\ncommitting to a fixed information sharing protocol (e.g. periodic sharing or no\nsharing etc), agents can dynamically decide at each time step whether to share\ninformation with each other and incur the resulting communication cost. This\nsetup requires a joint design of agents' communication and control strategies\nin order to optimize the trade-off between communication costs and control\nobjective. We first show that agents can ignore a big part of their private\ninformation without compromising the system performance. We then provide a\ncommon information approach based solution for the strategy optimization\nproblem. This approach relies on constructing a fictitious POMDP whose solution\n(obtained via a dynamic program) characterizes the optimal strategies for the\nagents. We also show that our solution can be easily modified to incorporate\nconstraints on when and how frequently agents can communicate.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 08:27:39 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Sudhakara", "Sagar", ""], ["Kartik", "Dhruva", ""], ["Jain", "Rahul", ""], ["Nayyar", "Ashutosh", ""]]}, {"id": "2104.10998", "submitter": "Yehia Abd Alrahman", "authors": "Yehia Abd Alrahman and Nir Piterman", "title": "Modelling and Verification of Reconfigurable Multi-Agent Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a formalism to model and reason about reconfigurable multi-agent\nsystems. In our formalism, agents interact and communicate in different modes\nso that they can pursue joint tasks; agents may dynamically synchronize,\nexchange data, adapt their behaviour, and reconfigure their communication\ninterfaces. Inspired by existing multi-robot systems, we represent a system as\na set of agents (each with local state), executing independently and only\ninfluence each other by means of message exchange. Agents are able to sense\ntheir local states and partially their surroundings. We extend LTL to be able\nto reason explicitly about the intentions of agents in the interaction and\ntheir communication protocols. We also study the complexity of satisfiability\nand model-checking of this extension.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 11:43:09 GMT"}, {"version": "v2", "created": "Fri, 23 Apr 2021 08:49:33 GMT"}, {"version": "v3", "created": "Tue, 27 Apr 2021 19:27:49 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Alrahman", "Yehia Abd", ""], ["Piterman", "Nir", ""]]}, {"id": "2104.11455", "submitter": "Tonghan Wang", "authors": "Heng Dong, Tonghan Wang, Jiayuan Liu, Chi Han, Chongjie Zhang", "title": "Birds of a Feather Flock Together: A Close Look at Cooperation Emergence\n  via Multi-Agent RL", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How cooperation emerges is a long-standing and interdisciplinary problem.\nGame-theoretical studies on social dilemmas reveal that altruistic incentives\nare critical to the emergence of cooperation but their analyses are limited to\nstateless games. For more realistic scenarios, multi-agent reinforcement\nlearning has been used to study sequential social dilemmas (SSDs). Recent works\nshow that learning to incentivize other agents can promote cooperation in SSDs.\nHowever, we find that, with these incentivizing mechanisms, the team\ncooperation level does not converge and regularly oscillates between\ncooperation and defection during learning. We show that a second-order social\ndilemma resulting from the incentive mechanisms is the main reason for such\nfragile cooperation. We formally analyze the dynamics of second-order social\ndilemmas and find that a typical tendency of humans, called homophily, provides\na promising solution. We propose a novel learning framework to encourage\nhomophilic incentives and show that it achieves stable cooperation in both SSDs\nof public goods and tragedy of the commons.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 08:00:45 GMT"}, {"version": "v2", "created": "Sat, 5 Jun 2021 12:44:20 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Dong", "Heng", ""], ["Wang", "Tonghan", ""], ["Liu", "Jiayuan", ""], ["Han", "Chi", ""], ["Zhang", "Chongjie", ""]]}, {"id": "2104.11763", "submitter": "Frank Bentrem", "authors": "Frank W. Bentrem, Michael A. Corsello, and Joshua J. Palm", "title": "Leveraging Sharing Communities to Achieve Federated Learning for\n  Cybersecurity", "comments": "7 pages, SDM AI4CS 2021", "journal-ref": "In Proceedings of the 2021 SIAM AI/ML for Cybersecurity Workshop\n  (AI4CS)", "doi": null, "report-no": null, "categories": "cs.CR cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Automated cyber threat detection in computer networks is a major challenge in\ncybersecurity. The cyber domain has inherent challenges that make traditional\nmachine learning techniques problematic, specifically the need to learn\ncontinually evolving attacks through global collaboration while maintaining\ndata privacy, and the varying resources available to network owners. We present\na scheme to mitigate these difficulties through an architectural approach using\ncommunity model sharing with a streaming analytic pipeline. Our streaming\napproach trains models incrementally as each log record is processed, thereby\nadjusting to concept drift resulting from changing attacks. Further, we\ndesigned a community sharing approach which federates learning through merging\nmodels without the need to share sensitive cyber-log data. Finally, by\nstandardizing data and Machine Learning processes in a modular way, we provide\nnetwork security operators the ability to manage cyber threat events and model\nsensitivity through community member and analytic method weighting in ways that\nare best suited for their available resources and data.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 18:07:43 GMT"}, {"version": "v2", "created": "Tue, 27 Apr 2021 18:45:10 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Bentrem", "Frank W.", ""], ["Corsello", "Michael A.", ""], ["Palm", "Joshua J.", ""]]}, {"id": "2104.11809", "submitter": "Pavel Surynek", "authors": "Pavel Surynek", "title": "Compilation-based Solvers for Multi-Agent Path Finding: a Survey,\n  Discussion, and Future Opportunities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-agent path finding (MAPF) attracts considerable attention in artificial\nintelligence community as well as in robotics, and other fields such as\nwarehouse logistics. The task in the standard MAPF is to find paths through\nwhich agents can navigate from their starting positions to specified individual\ngoal positions. The combination of two additional requirements makes the\nproblem computationally challenging: (i) agents must not collide with each\nother and (ii) the paths must be optimal with respect to some objective. Two\nmajor approaches to optimal MAPF solving include (1) dedicated search-based\nmethods, which solve MAPF directly, and (2) compilation-based methods that\nreduce a MAPF instance to an instance in a different well established\nformalism, for which an efficient solver exists. The compilation-based MAPF\nsolving can benefit from advancements accumulated during the development of the\ntarget solver often decades long. We summarize and compare contemporary\ncompilation-based solvers for MAPF using formalisms like ASP, MIP, and SAT. We\nshow the lessons learned from past developments and current trends in the topic\nand discuss its wider impact.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 20:13:12 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Surynek", "Pavel", ""]]}, {"id": "2104.11884", "submitter": "Garima Shakya", "authors": "Deepesh Kumar Lall, Garima Shakya, Swaprava Nath", "title": "Prior-free Strategic Multiagent Scheduling with focus on Social\n  Distancing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Motivated by the need for social distancing during a pandemic, we consider an\napproach to schedule the visitors of a facility. The algorithm takes input from\ncitizens and schedules the store's time-slots based on their importance to\nvisit the facility (e.g., a general store). Naturally, the formulation applies\nto several similar problems. We consider the single slot and multiple slot\ndemands of the requests. The salient properties of our approach are: it (a)\nensures social distancing by ensuring a maximum population in a given time-slot\nat the facility, (b) prioritizes individuals based on the users' importance of\nthe jobs, (c) maintains truthfulness of the reported importance by adding a\ncooling-off period after their allocated time-slot, during which the individual\ncannot re-access the same facility, (d) guarantees voluntary participation of\nthe citizens, and yet (e) is computationally tractable. We show that the\nproblem becomes NP-complete as soon as the multi-slot demands are indivisible\nand provide a polynomial-time mechanism that is truthful, individually\nrational, and approximately optimal. Experiments show that visitors with more\nimportant jobs are allocated more preferred slots, which comes at the cost of a\nlonger delay to re-access the store. We show that it reduces the social\ncongestion significantly using users' visit data from a store. For the\nmulti-slot indivisible jobs, our approximately optimal mechanism performs well\nin practice.\n", "versions": [{"version": "v1", "created": "Sat, 24 Apr 2021 05:23:35 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Lall", "Deepesh Kumar", ""], ["Shakya", "Garima", ""], ["Nath", "Swaprava", ""]]}, {"id": "2104.11980", "submitter": "Michael Alcorn", "authors": "Michael A. Alcorn, Anh Nguyen", "title": "baller2vec++: A Look-Ahead Multi-Entity Transformer For Modeling\n  Coordinated Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many multi-agent spatiotemporal systems, the agents are under the\ninfluence of shared, unobserved variables (e.g., the play a team is executing\nin a game of basketball). As a result, the trajectories of the agents are often\nstatistically dependent at any given time step; however, almost universally,\nmulti-agent models implicitly assume the agents' trajectories are statistically\nindependent at each time step. In this paper, we introduce baller2vec++, a\nmulti-entity Transformer that can effectively model coordinated agents.\nSpecifically, baller2vec++ applies a specially designed self-attention mask to\na mixture of location and \"look-ahead\" trajectory sequences to learn the\ndistributions of statistically dependent agent trajectories. We show that,\nunlike baller2vec (baller2vec++'s predecessor), baller2vec++ can learn to\nemulate the behavior of perfectly coordinated agents in a simulated toy\ndataset. Additionally, when modeling the trajectories of professional\nbasketball players, baller2vec++ outperforms baller2vec by a wide margin.\n", "versions": [{"version": "v1", "created": "Sat, 24 Apr 2021 16:20:47 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Alcorn", "Michael A.", ""], ["Nguyen", "Anh", ""]]}, {"id": "2104.12473", "submitter": "Marcin Maleszka", "authors": "Marcin Maleszka", "title": "Influence of group characteristics on agent voting", "comments": "9 pages, 3 figures, paper from the conference ACIIDS 2017", "journal-ref": "In: Nguyen N., Tojo S., Nguyen L., Trawinski B. (eds) Intelligent\n  Information and Database Systems. ACIIDS 2017. Lecture Notes in Computer\n  Science, vol 10191. Springer, Cham", "doi": "10.1007/978-3-319-54472-4_6", "report-no": null, "categories": "cs.MA", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  A collective of identical agents in a multi-agent system often works together\ntowards the common goal. In situations where no supervisor agents are present\nto make decisions for the group, these agents must achieve some consensus via\nnegotiations and other types of communications. We have previously shown that\nthe structure of the group and the priority of communication has a high\ninfluence on the group decision if consensus theory methods are used. In this\npaper, we explore the influence of preferential communication channels in\nasynchronous group communication in situations, where majority vote and\ndominant value are used. We also show how this relates to consensus approach in\nsuch groups and how to use a combination of both approaches to improve\nperformance of real-life multi-agent systems.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 11:12:35 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Maleszka", "Marcin", ""]]}, {"id": "2104.12895", "submitter": "Claude Kl\\\"ockl", "authors": "Christoph Graf, Viktor Zobernig, Johannes Schmidt, Claude Kl\\\"ockl", "title": "Computational Performance of Deep Reinforcement Learning to find Nash\n  Equilibria", "comments": "48 pages + 9 figures, comments welcome!", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.LG cs.MA econ.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We test the performance of deep deterministic policy gradient (DDPG), a deep\nreinforcement learning algorithm, able to handle continuous state and action\nspaces, to learn Nash equilibria in a setting where firms compete in prices.\nThese algorithms are typically considered model-free because they do not\nrequire transition probability functions (as in e.g., Markov games) or\npredefined functional forms. Despite being model-free, a large set of\nparameters are utilized in various steps of the algorithm. These are e.g.,\nlearning rates, memory buffers, state-space dimensioning, normalizations, or\nnoise decay rates and the purpose of this work is to systematically test the\neffect of these parameter configurations on convergence to the analytically\nderived Bertrand equilibrium. We find parameter choices that can reach\nconvergence rates of up to 99%. The reliable convergence may make the method a\nuseful tool to study strategic behavior of firms even in more complex settings.\nKeywords: Bertrand Equilibrium, Competition in Uniform Price Auctions, Deep\nDeterministic Policy Gradient Algorithm, Parameter Sensitivity Analysis\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 22:14:17 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Graf", "Christoph", ""], ["Zobernig", "Viktor", ""], ["Schmidt", "Johannes", ""], ["Kl\u00f6ckl", "Claude", ""]]}, {"id": "2104.12993", "submitter": "Javad Sabzehali", "authors": "Javad Sabzehali, Vijay K. Shah, Harpreet S. Dhillon, and Jeffrey H.\n  Reed", "title": "3D Placement and Orientation of mmWave-based UAVs for Guaranteed LoS\n  Coverage", "comments": "To appear in IEEE Wireless Communications Letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.MA cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unmanned aerial vehicles (UAVs), as aerial base stations, are a promising\nsolution for providing wireless communications, thanks to their high\nflexibility and autonomy. Moreover, emerging services, such as extended\nreality, require high-capacity communications. To achieve this, millimeter wave\n(mmWave), and recently, terahertz bands have been considered for UAV\ncommunications. However, communication at these high frequencies requires a\nline-of-sight (LoS) to the terminals, which may be located in 3D space and may\nhave extremely limited direct-line-of-view (LoV) due to blocking objects, like\nbuildings and trees. In this paper, we investigate the problem of determining\n3D placement and orientation of UAVs such that users have guaranteed LoS\ncoverage by at least one UAV and the signal-to-noise ratio (SNR) between the\nUAV-user pairs are maximized. We formulate the problem as an integer linear\nprogramming(ILP) problem and prove its NP-hardness. Next, we propose a\nlow-complexity geometry-based greedy algorithm to solve the problem\nefficiently. Our simulation results show that the proposed algorithm (almost)\nalways guarantees LoS coverage to all users in all considered simulation\nsettings.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 05:55:18 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Sabzehali", "Javad", ""], ["Shah", "Vijay K.", ""], ["Dhillon", "Harpreet S.", ""], ["Reed", "Jeffrey H.", ""]]}, {"id": "2104.13446", "submitter": "Bozhidar Vasilev", "authors": "Bozhidar Vasilev, Tarun Gupta, Bei Peng, Shimon Whiteson", "title": "Semi-On-Policy Training for Sample Efficient Multi-Agent Policy\n  Gradients", "comments": "AAMAS Adaptive and Learning Agents Workshop. 20th International\n  Conference on Autonomous Agents and Multiagent Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Policy gradient methods are an attractive approach to multi-agent\nreinforcement learning problems due to their convergence properties and\nrobustness in partially observable scenarios. However, there is a significant\nperformance gap between state-of-the-art policy gradient and value-based\nmethods on the popular StarCraft Multi-Agent Challenge (SMAC) benchmark. In\nthis paper, we introduce semi-on-policy (SOP) training as an effective and\ncomputationally efficient way to address the sample inefficiency of on-policy\npolicy gradient methods. We enhance two state-of-the-art policy gradient\nalgorithms with SOP training, demonstrating significant performance\nimprovements. Furthermore, we show that our methods perform as well or better\nthan state-of-the-art value-based methods on a variety of SMAC tasks.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 19:37:01 GMT"}, {"version": "v2", "created": "Thu, 6 May 2021 15:25:59 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Vasilev", "Bozhidar", ""], ["Gupta", "Tarun", ""], ["Peng", "Bei", ""], ["Whiteson", "Shimon", ""]]}, {"id": "2104.13463", "submitter": "Rui Yao", "authors": "Rui Yao, Shlomo Bekhor", "title": "A ridesharing simulation platform that considers dynamic supply-demand\n  interactions", "comments": "38 pages, 16 figures, submitted to Transportation Research Part C:\n  Emerging Technologies", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new ridesharing simulation platform that accounts for\ndynamic driver supply and passenger demand, and complex interactions between\ndrivers and passengers. The proposed simulation platform explicitly considers\ndriver and passenger acceptance/rejection on the matching options, and\ncancellation before/after being matched. New simulation events, procedures and\nmodules have been developed to handle these realistic interactions. The\ncapabilities of the simulation platform are illustrated using numerical\nexperiments. The experiments confirm the importance of considering supply and\ndemand interactions and provide new insights to ridesharing operations. Results\nshow that increase of driver supply does not always increase matching option\naccept rate, and larger matching window could have negative impacts on overall\nridesharing success rate. These results emphasize the importance of a careful\nplanning of a ridesharing system.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 20:31:55 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Yao", "Rui", ""], ["Bekhor", "Shlomo", ""]]}, {"id": "2104.13630", "submitter": "Lorenzo Rapetti", "authors": "Lorenzo Rapetti, Yeshasvi Tirupachuri, Alberto Ranavolo, Tomohiro\n  Kawakami, Takahide Yoshiike, Daniele Pucci", "title": "Shared Control of Robot-Robot Collaborative Lifting with Agent Postural\n  and Force Ergonomic Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans show specialized strategies for efficient collaboration. Transferring\nsimilar strategies to humanoid robots can improve their capability to interact\nwith other agents, leading the way to complex collaborative scenarios with\nmultiple agents acting on a shared environment. In this paper we present a\ncontrol framework for robot-robot collaborative lifting. The proposed shared\ncontroller takes into account the joint action of both the robots thanks to a\ncentralized controller that communicates with them, and solves the whole-system\noptimization. Efficient collaboration is ensured by taking into account the\nergonomic requirements of the robots through the optimization of posture and\ncontact forces. The framework is validated in an experimental scenario with two\niCub humanoid robots performing different payload lifting sequences.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 08:31:54 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Rapetti", "Lorenzo", ""], ["Tirupachuri", "Yeshasvi", ""], ["Ranavolo", "Alberto", ""], ["Kawakami", "Tomohiro", ""], ["Yoshiike", "Takahide", ""], ["Pucci", "Daniele", ""]]}, {"id": "2104.14089", "submitter": "Ronal Singh", "authors": "Ronal Singh, Tim Miller, Darryn Reid", "title": "Collaborative Human-Agent Planning for Resilience", "comments": "International Workshop on Coordination, Organizations, Institutions,\n  Norms and Ethics for Governance of Multi-Agent Systems (COINE), co-located\n  with AAMAS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intelligent agents powered by AI planning assist people in complex scenarios,\nsuch as managing teams of semi-autonomous vehicles. However, AI planning models\nmay be incomplete, leading to plans that do not adequately meet the stated\nobjectives, especially in unpredicted situations. Humans, who are apt at\nidentifying and adapting to unusual situations, may be able to assist planning\nagents in these situations by encoding their knowledge into a planner at\nrun-time. We investigate whether people can collaborate with agents by\nproviding their knowledge to an agent using linear temporal logic (LTL) at\nrun-time without changing the agent's domain model. We presented 24\nparticipants with baseline plans for situations in which a planner had\nlimitations, and asked the participants for workarounds for these limitations.\nWe encoded these workarounds as LTL constraints. Results show that\nparticipants' constraints improved the expected return of the plans by 10% ($p\n< 0.05$) relative to baseline plans, demonstrating that human insight can be\nused in collaborative planning for resilience. However, participants used more\ndeclarative than control constraints over time, but declarative constraints\nproduced plans less similar to the expectation of the participants, which could\nlead to potential trust issues.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 03:21:31 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Singh", "Ronal", ""], ["Miller", "Tim", ""], ["Reid", "Darryn", ""]]}, {"id": "2104.14858", "submitter": "Jakub Marecek", "authors": "Ramen Ghosh and Wynita M. Griggs and Jakub Marecek and Robert N.\n  Shorten", "title": "Unique Ergodicity in the Interconnections of Ensembles with Applications\n  to Two-Sided Markets", "comments": "arXiv admin note: text overlap with arXiv:1807.03256", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.MA cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been much recent interest in two-sided markets and dynamics\nthereof. In a rather a general discrete-time feedback model, which we show\nconditions that assure that for each agent, there exists the limit of a\nlong-run average allocation of a resource to the agent, which is independent of\nany initial conditions. We call this property the unique ergodicity.\n  Our model encompasses two-sided markets and more complicated interconnections\nof workers and customers, such as in a supply chain. It allows for\nnon-linearity of the response functions of market participants. It allows for\nuncertainty in the response of market participants by considering a set of the\npossible responses to either price or other signals and a measure to sample\nfrom these. Finally, it allows for an arbitrary delay between the arrival of\nincoming data and the clearing of a market.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 09:21:15 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Ghosh", "Ramen", ""], ["Griggs", "Wynita M.", ""], ["Marecek", "Jakub", ""], ["Shorten", "Robert N.", ""]]}, {"id": "2104.14892", "submitter": "Nicolas Troquard", "authors": "Nicolas Troquard", "title": "Tracking and managing deemed abilities", "comments": null, "journal-ref": null, "doi": "10.1007/s11229-019-02387-3", "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information about the powers and abilities of acting entities is used to\ncoordinate their actions in societies, either physical or digital. Yet, the\ncommonsensical meaning of an acting entity being deemed able to do something is\nstill missing from the existing specification languages for the web or for\nmulti-agent systems. We advance a general purpose abstract logical account of\nevidence-based ability. A basic model can be thought of as the ongoing trace of\na multi-agent system. Every state records systemic confirmations and\ndisconfirmations of whether an acting entity is able to bring about something.\nQualitative inductive reasoning is then used in order to infer what acting\nentities are deemed able to bring about in the multi-agent system. A\ntemporalised modal language is used to talk about deemed ability, actual\nagency, and confirmation and disconfirmation of deemed ability. What\nconstitutes a confirmation and a disconfirmation is left to the modeller as in\ngeneral it depends on the application at hand. So to illustrate the methodology\nwe propose two extended examples, one in practical philosophy, the other in\nsystem engineering. We first use a logic of agency and ability to obtain a\nversion of Mele's general practical abilities. Then, we look at the management\nof abilities in a supervised system.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 10:34:00 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Troquard", "Nicolas", ""]]}, {"id": "2104.14900", "submitter": "Kai Cui", "authors": "Kai Cui, Anam Tahir, Mark Sinzger, Heinz Koeppl", "title": "Discrete-Time Mean Field Control with Environment States", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-agent reinforcement learning methods have shown remarkable potential in\nsolving complex multi-agent problems but mostly lack theoretical guarantees.\nRecently, mean field control and mean field games have been established as a\ntractable solution for large-scale multi-agent problems with many agents. In\nthis work, driven by a motivating scheduling problem, we consider a\ndiscrete-time mean field control model with common environment states. We\nrigorously establish approximate optimality as the number of agents grows in\nthe finite agent case and find that a dynamic programming principle holds,\nresulting in the existence of an optimal stationary policy. As exact solutions\nare difficult in general due to the resulting continuous action space of the\nlimiting mean field Markov decision process, we apply established deep\nreinforcement learning methods to solve the associated mean field control\nproblem. The performance of the learned mean field control policy is compared\nto typical multi-agent reinforcement learning approaches and is found to\nconverge to the mean field performance for sufficiently many agents, verifying\nthe obtained theoretical results and reaching competitive solutions.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 10:58:01 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Cui", "Kai", ""], ["Tahir", "Anam", ""], ["Sinzger", "Mark", ""], ["Koeppl", "Heinz", ""]]}, {"id": "2104.15034", "submitter": "Sz-Ting Tzeng", "authors": "Sz-Ting Tzeng (1), Nirav Ajmeri (2) and Munindar P. Singh (1) ((1)\n  North Carolina State University, (2) University of Bristol)", "title": "Noe: Norms Emergence and Robustness Based on Emotions in Multiagent\n  Systems", "comments": "15 pages with 8 figures. Accepted at COINE 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social norms characterize collective and acceptable group conducts in human\nsociety. Furthermore, some social norms emerge from interactions of agents or\nhumans. To achieve agent autonomy and make norm satisfaction explainable, we\ninclude emotions into the normative reasoning process, which evaluate whether\nto comply or violate a norm. Specifically, before selecting an action to\nexecute, an agent observes the environment and infer the state and consequences\nwith its internal states after norm satisfaction or violation of a social norm.\nBoth norm satisfaction and violation provoke further emotions, and the\nsubsequent emotions affect norm enforcement. This paper investigates how\nmodeling emotions affect the emergence and robustness of social norms via\nsocial simulation experiments. We find that an ability in agents to consider\nemotional responses to the outcomes of norm satisfaction and violation (1)\npromote norm compliance; and (2) improve societal welfare.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 14:42:22 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Tzeng", "Sz-Ting", ""], ["Ajmeri", "Nirav", ""], ["Singh", "Munindar P.", ""]]}, {"id": "2104.15075", "submitter": "Jiehua Chen", "authors": "Jiehua Chen, Martin Lackner, Jan Maly", "title": "Participatory Budgeting with Donations and Diversity Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.CC cs.DS cs.GT", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Participatory budgeting (PB) is a democratic process where citizens jointly\ndecide on how to allocate public funds to indivisible projects. This paper\nfocuses on PB processes where citizens may give additional money to projects\nthey want to see funded. We introduce a formal framework for this kind of PB\nwith donations. Our framework also allows for diversity constraints, meaning\nthat each project belongs to one or more types, and there are lower and upper\nbounds on the number of projects of the same type that can be funded. We\npropose three general classes of methods for aggregating the citizens'\npreferences in the presence of donations and analyze their axiomatic\nproperties. Furthermore, we investigate the computational complexity of\ndetermining the outcome of a PB process with donations and of finding a\ncitizen's optimal donation strategy.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 15:48:25 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Chen", "Jiehua", ""], ["Lackner", "Martin", ""], ["Maly", "Jan", ""]]}]