[{"id": "1703.00320", "submitter": "Hadi Hosseini", "authors": "Hadi Hosseini, Kate Larson, Robin Cohen", "title": "Investigating the Characteristics of One-Sided Matching Mechanisms Under\n  Various Preferences and Risk Attitudes", "comments": "arXiv admin note: text overlap with arXiv:1503.01488", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One-sided matching mechanisms are fundamental for assigning a set of\nindivisible objects to a set of self-interested agents when monetary transfers\nare not allowed. Two widely-studied randomized mechanisms in multiagent\nsettings are the Random Serial Dictatorship (RSD) and the Probabilistic Serial\nRule (PS). Both mechanisms require only that agents specify ordinal preferences\nand have a number of desirable economic and computational properties. However,\nthe induced outcomes of the mechanisms are often incomparable and thus there\nare challenges when it comes to deciding which mechanism to adopt in practice.\nIn this paper, we first consider the space of general ordinal preferences and\nprovide empirical results on the (in)comparability of RSD and PS. We analyze\ntheir respective economic properties under general and lexicographic\npreferences. We then instantiate utility functions with the goal of gaining\ninsights on the manipulability, efficiency, and envyfreeness of the mechanisms\nunder different risk-attitude models. Our results hold under various preference\ndistribution models, which further confirm the broad use of RSD in most\npractical applications.\n", "versions": [{"version": "v1", "created": "Wed, 1 Mar 2017 14:42:20 GMT"}], "update_date": "2017-03-02", "authors_parsed": [["Hosseini", "Hadi", ""], ["Larson", "Kate", ""], ["Cohen", "Robin", ""]]}, {"id": "1703.01931", "submitter": "Bruno da Silva", "authors": "Dan Garant and Bruno da Silva and Victor Lesser and Chongjie Zhang", "title": "Context-Based Concurrent Experience Sharing in Multiagent Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the key challenges for multi-agent learning is scalability. In this\npaper, we introduce a technique for speeding up multi-agent learning by\nexploiting concurrent and incremental experience sharing. This solution\nadaptively identifies opportunities to transfer experiences between agents and\nallows for the rapid acquisition of appropriate policies in large-scale,\nstochastic, homogeneous multi-agent systems. We introduce an online,\ndistributed, supervisor-directed transfer technique for constructing high-level\ncharacterizations of an agent's dynamic learning environment---called\ncontexts---which are used to identify groups of agents operating under\napproximately similar dynamics within a short temporal window. A set of\nsupervisory agents computes contextual information for groups of subordinate\nagents, thereby identifying candidates for experience sharing. Our method uses\na tiered architecture to propagate, with low communication overhead, state,\naction, and reward data amongst the members of each dynamically-identified\ninformation-sharing group. We applied this method to a large-scale distributed\ntask allocation problem with hundreds of information-sharing agents operating\nin an unknown, non-stationary environment. We demonstrate that our approach\nresults in significant performance gains, that it is robust to noise-corrupted\nor suboptimal context features, and that communication costs scale linearly\nwith the supervisor-to-subordinate ratio.\n", "versions": [{"version": "v1", "created": "Mon, 6 Mar 2017 15:44:10 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["Garant", "Dan", ""], ["da Silva", "Bruno", ""], ["Lesser", "Victor", ""], ["Zhang", "Chongjie", ""]]}, {"id": "1703.02192", "submitter": "EPTCS", "authors": "Thomas Bolander", "title": "A Gentle Introduction to Epistemic Planning: The DEL Approach", "comments": "In Proceedings M4M9 2017, arXiv:1703.01736", "journal-ref": "EPTCS 243, 2017, pp. 1-22", "doi": "10.4204/EPTCS.243.1", "report-no": null, "categories": "cs.AI cs.LO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Epistemic planning can be used for decision making in multi-agent situations\nwith distributed knowledge and capabilities. Dynamic Epistemic Logic (DEL) has\nbeen shown to provide a very natural and expressive framework for epistemic\nplanning. In this paper, we aim to give an accessible introduction to DEL-based\nepistemic planning. The paper starts with the most classical framework for\nplanning, STRIPS, and then moves towards epistemic planning in a number of\nsmaller steps, where each step is motivated by the need to be able to model\nmore complex planning scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 7 Mar 2017 03:15:08 GMT"}], "update_date": "2017-03-08", "authors_parsed": [["Bolander", "Thomas", ""]]}, {"id": "1703.02196", "submitter": "EPTCS", "authors": "Thorsten Engesser (Albert-Ludwigs-Universit\\\"at Freiburg), Thomas\n  Bolander (Technical University of Denmark), Robert Mattm\\\"uller\n  (Albert-Ludwigs-Universit\\\"at Freiburg), Bernhard Nebel\n  (Albert-Ludwigs-Universit\\\"at Freiburg)", "title": "Cooperative Epistemic Multi-Agent Planning for Implicit Coordination", "comments": "In Proceedings M4M9 2017, arXiv:1703.01736", "journal-ref": "EPTCS 243, 2017, pp. 75-90", "doi": "10.4204/EPTCS.243.6", "report-no": null, "categories": "cs.AI cs.LO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Epistemic planning can be used for decision making in multi-agent situations\nwith distributed knowledge and capabilities. Recently, Dynamic Epistemic Logic\n(DEL) has been shown to provide a very natural and expressive framework for\nepistemic planning. We extend the DEL-based epistemic planning framework to\ninclude perspective shifts, allowing us to define new notions of sequential and\nconditional planning with implicit coordination. With these, it is possible to\nsolve planning tasks with joint goals in a decentralized manner without the\nagents having to negotiate about and commit to a joint policy at plan time.\nFirst we define the central planning notions and sketch the implementation of a\nplanning system built on those notions. Afterwards we provide some case studies\nin order to evaluate the planner empirically and to show that the concept is\nuseful for multi-agent systems in practice.\n", "versions": [{"version": "v1", "created": "Tue, 7 Mar 2017 03:16:22 GMT"}], "update_date": "2017-03-08", "authors_parsed": [["Engesser", "Thorsten", "", "Albert-Ludwigs-Universit\u00e4t Freiburg"], ["Bolander", "Thomas", "", "Technical University of Denmark"], ["Mattm\u00fcller", "Robert", "", "Albert-Ludwigs-Universit\u00e4t Freiburg"], ["Nebel", "Bernhard", "", "Albert-Ludwigs-Universit\u00e4t Freiburg"]]}, {"id": "1703.02367", "submitter": "Paula Chocron", "authors": "Paula Chocron and Marco Schorlemmer", "title": "Vocabulary Alignment in Openly Specified Interactions", "comments": "14 pages, accepted at AAMAS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of achieving common understanding between agents that use\ndifferent vocabularies has been mainly addressed by designing techniques that\nexplicitly negotiate mappings between their vocabularies, requiring agents to\nshare a meta-language. In this paper we consider the case of agents that use\ndifferent vocabularies and have no meta-language in common, but share the\nknowledge of how to perform a task, given by the specification of an\ninteraction protocol. For this situation, we present a framework that lets\nagents learn a vocabulary alignment from the experience of interacting. Unlike\nprevious work in this direction, we use open protocols that constrain possible\nactions instead of defining procedures, making our approach more general. We\npresent two techniques that can be used either to learn an alignment from\nscratch or to repair an existent one, and we evaluate experimentally their\nperformance.\n", "versions": [{"version": "v1", "created": "Tue, 7 Mar 2017 13:18:14 GMT"}], "update_date": "2017-03-08", "authors_parsed": [["Chocron", "Paula", ""], ["Schorlemmer", "Marco", ""]]}, {"id": "1703.02399", "submitter": "Gildas Morvan", "authors": "Gildas Morvan and Yoann Kubera", "title": "On time and consistency in multi-level agent-based simulations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The integration of multiple viewpoints became an increasingly popular\napproach to deal with agent-based simulations. Despite their disparities,\nrecent approaches successfully manage to run such multi-level simulations. Yet,\nare they doing it appropriately?\n  This paper tries to answer that question, with an analysis based on a generic\nmodel of the temporal dynamics of multi-level simulations. This generic model\nis then used to build an orthogonal approach to multi-level simulation called\nSIMILAR. In this approach, most time-related issues are explicitly modeled,\nowing to an implementation-oriented approach based on the influence/reaction\nprinciple.\n", "versions": [{"version": "v1", "created": "Tue, 7 Mar 2017 14:33:00 GMT"}], "update_date": "2017-03-08", "authors_parsed": [["Morvan", "Gildas", ""], ["Kubera", "Yoann", ""]]}, {"id": "1703.02685", "submitter": "Jingwen Yi", "authors": "Jing-Wen Yi and Li Chai", "title": "New results on multi-agent system consensus: A graph signal processing\n  perspective", "comments": "5pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper revisits the problem of multi-agent consensus from a graph signal\nprocessing perspective. By defining the graph filter from the consensus\nprotocol, we establish the direct relation between average consensus of\nmulti-agent systems and filtering of graph signals. This relation not only\nprovides new insights of the average consensus, it also turns out to be a\npowerful tool to design effective consensus protocols for uncertain networks,\nwhich is difficult to deal with by existing time-domain methods. In this paper,\nwe consider two cases, one is uncertain networks modeled by an estimated\nLaplacian matrix and a fixed eigenvalue bound, the other is connected graphs\nwith unknown topology. The consensus protocols are designed for both cases\nbased on the protocol filter. Several numerical examples are given to\ndemonstrate the effectiveness of our methods.\n", "versions": [{"version": "v1", "created": "Wed, 8 Mar 2017 03:31:16 GMT"}], "update_date": "2017-03-09", "authors_parsed": [["Yi", "Jing-Wen", ""], ["Chai", "Li", ""]]}, {"id": "1703.02702", "submitter": "Lerrel Pinto Mr", "authors": "Lerrel Pinto, James Davidson, Rahul Sukthankar and Abhinav Gupta", "title": "Robust Adversarial Reinforcement Learning", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks coupled with fast simulation and improved computation\nhave led to recent successes in the field of reinforcement learning (RL).\nHowever, most current RL-based approaches fail to generalize since: (a) the gap\nbetween simulation and real world is so large that policy-learning approaches\nfail to transfer; (b) even if policy learning is done in real world, the data\nscarcity leads to failed generalization from training to test scenarios (e.g.,\ndue to different friction or object masses). Inspired from H-infinity control\nmethods, we note that both modeling errors and differences in training and test\nscenarios can be viewed as extra forces/disturbances in the system. This paper\nproposes the idea of robust adversarial reinforcement learning (RARL), where we\ntrain an agent to operate in the presence of a destabilizing adversary that\napplies disturbance forces to the system. The jointly trained adversary is\nreinforced -- that is, it learns an optimal destabilization policy. We\nformulate the policy learning as a zero-sum, minimax objective function.\nExtensive experiments in multiple environments (InvertedPendulum, HalfCheetah,\nSwimmer, Hopper and Walker2d) conclusively demonstrate that our method (a)\nimproves training stability; (b) is robust to differences in training/test\nconditions; and c) outperform the baseline even in the absence of the\nadversary.\n", "versions": [{"version": "v1", "created": "Wed, 8 Mar 2017 04:58:51 GMT"}], "update_date": "2017-03-09", "authors_parsed": [["Pinto", "Lerrel", ""], ["Davidson", "James", ""], ["Sukthankar", "Rahul", ""], ["Gupta", "Abhinav", ""]]}, {"id": "1703.03943", "submitter": "Tatsuya Sasaki", "authors": "Hitoshi Yamamoto, Isamu Okada, Satoshi Uchida, Tatsuya Sasaki", "title": "A norm knockout method on indirect reciprocity to reveal indispensable\n  norms", "comments": "15 pages (incl. supplementary materials), 6 figures, 7 table", "journal-ref": "Scientific Reports 7, 44146 (2017)", "doi": "10.1038/srep44146", "report-no": null, "categories": "physics.soc-ph cs.MA cs.NE q-bio.PE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Although various norms for reciprocity-based cooperation have been suggested\nthat are evolutionarily stable against invasion from free riders, the process\nof alternation of norms and the role of diversified norms remain unclear in the\nevolution of cooperation. We clarify the co-evolutionary dynamics of norms and\ncooperation in indirect reciprocity and also identify the indispensable norms\nfor the evolution of cooperation. Inspired by the gene knockout method, a\ngenetic engineering technique, we developed the norm knockout method and\nclarified the norms necessary for the establishment of cooperation. The results\nof numerical investigations revealed that the majority of norms gradually\ntransitioned to tolerant norms after defectors are eliminated by strict norms.\nFurthermore, no cooperation emerges when specific norms that are intolerant to\ndefectors are knocked out.\n", "versions": [{"version": "v1", "created": "Sat, 11 Mar 2017 10:29:57 GMT"}], "update_date": "2017-03-14", "authors_parsed": [["Yamamoto", "Hitoshi", ""], ["Okada", "Isamu", ""], ["Uchida", "Satoshi", ""], ["Sasaki", "Tatsuya", ""]]}, {"id": "1703.04756", "submitter": "Nika Haghtalab", "authors": "Nika Haghtalab, Ritesh Noothigattu, Ariel D. Procaccia", "title": "Weighted Voting Via No-Regret Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Voting systems typically treat all voters equally. We argue that perhaps they\nshould not: Voters who have supported good choices in the past should be given\nhigher weight than voters who have supported bad ones. To develop a formal\nframework for desirable weighting schemes, we draw on no-regret learning.\nSpecifically, given a voting rule, we wish to design a weighting scheme such\nthat applying the voting rule, with voters weighted by the scheme, leads to\nchoices that are almost as good as those endorsed by the best voter in\nhindsight. We derive possibility and impossibility results for the existence of\nsuch weighting schemes, depending on whether the voting rule and the weighting\nscheme are deterministic or randomized, as well as on the social choice axioms\nsatisfied by the voting rule.\n", "versions": [{"version": "v1", "created": "Tue, 14 Mar 2017 22:13:20 GMT"}], "update_date": "2017-03-16", "authors_parsed": [["Haghtalab", "Nika", ""], ["Noothigattu", "Ritesh", ""], ["Procaccia", "Ariel D.", ""]]}, {"id": "1703.04901", "submitter": "Mengbin Ye", "authors": "Mengbin Ye and Ji Liu and Brian David Outram Anderson and Changbin Yu\n  and Tamer Ba\\c{s}ar", "title": "On the Analysis of the DeGroot-Friedkin Model with Dynamic Relative\n  Interaction Matrices", "comments": "This is the extended version of the paper accepted into 20th IFAC\n  World Congress. It contains proofs for the periodic system, and includes\n  arbitrarily issue-varying relative interaction matrices which are all doubly\n  stochastic", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.MA cs.SY physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper analyses the DeGroot-Friedkin model for evolution of the\nindividuals' social powers in a social network when the network topology varies\ndynamically (described by dynamic relative interaction matrices). The\nDeGroot-Friedkin model describes how individual social power (self-appraisal,\nself-weight) evolves as a network of individuals discuss a sequence of issues.\nWe seek to study dynamically changing relative interactions because\ninteractions may change depending on the issue being discussed. In order to\nexplore the problem in detail, two different cases of issue-dependent network\ntopologies are studied. First, if the topology varies between issues in a\nperiodic manner, it is shown that the individuals' self-appraisals admit a\nperiodic solution. Second, if the topology changes arbitrarily, under the\nassumption that each relative interaction matrix is doubly stochastic and\nirreducible, the individuals' self-appraisals asymptotically converge to a\nunique non-trivial equilibrium.\n", "versions": [{"version": "v1", "created": "Wed, 15 Mar 2017 02:59:10 GMT"}], "update_date": "2017-03-22", "authors_parsed": [["Ye", "Mengbin", ""], ["Liu", "Ji", ""], ["Anderson", "Brian David Outram", ""], ["Yu", "Changbin", ""], ["Ba\u015far", "Tamer", ""]]}, {"id": "1703.05233", "submitter": "Daniel Fullmer", "authors": "Daniel Fullmer and A. Stephen Morse", "title": "A Distributed Algorithm for Computing a Common Fixed Point of a Finite\n  Family of Paracontractions", "comments": "submitted to Transactions on Automatic Control", "journal-ref": "IEEE Transactions on Automatic Control (Volume: 63, Issue: 9,\n  Sept. 2018)", "doi": "10.1109/TAC.2018.2800644", "report-no": null, "categories": "math.OC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A distributed algorithm is described for finding a common fixed point of a\nfamily of m>1 nonlinear maps M_i : R^n -> R^n assuming that each map is a\nparacontraction and that at least one such common fixed point exists. The\ncommon fixed point is simultaneously computed by m agents assuming each agent i\nknows only M_i, the current estimates of the fixed point generated by its\nneighbors, and nothing more. Each agent recursively updates its estimate of a\nfixed point by utilizing the current estimates generated by each of its\nneighbors. Neighbor relations are characterized by a time-varying directed\ngraph N(t). It is shown under suitably general conditions on N(t), that the\nalgorithm causes all agents estimates to converge to the same common fixed\npoint of the m nonlinear maps.\n", "versions": [{"version": "v1", "created": "Wed, 15 Mar 2017 16:21:10 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Fullmer", "Daniel", ""], ["Morse", "A. Stephen", ""]]}, {"id": "1703.05240", "submitter": "Bernardo Furtado", "authors": "Francis Tseng, Fei Liu, Bernardo Alves Furtado", "title": "Humans of Simulated New York (HOSNY): an exploratory comprehensive model\n  of city life", "comments": "18 pages, 5 figures, submitted (in review), typos corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The model presented in this paper experiments with a comprehensive simulant\nagent in order to provide an exploratory platform in which simulation modelers\nmay try alternative scenarios and participation in policy decision-making. The\nframework is built in a computationally distributed online format in which\nusers can join in and visually explore the results. Modeled activity involves\ndaily routine errands, such as shopping, visiting the doctor or engaging in the\nlabor market. Further, agents make everyday decisions based on individual\nbehavioral attributes and minimal requirements, according to social and\ncontagion networks. Fully developed firms and governments are also included in\nthe model allowing for taxes collection, production decisions, bankruptcy and\nchange in ownership. The contributions to the literature are multifold. They\ninclude (a) a comprehensive model with detailing of the agents and firms'\nactivities and processes and original use of simultaneously (b) reinforcement\nlearning for firm pricing and demand allocation; (c) social contagion for\ndisease spreading and social network for hiring opportunities; and (d) Bayesian\nnetworks for demographic-like generation of agents. All of that within a (e)\nvisually rich environment and multiple use of databases. Hence, the model\nprovides a comprehensive framework from where interactions among citizens,\nfirms and governments can be easily explored allowing for learning and\nvisualization of policies and scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 15 Mar 2017 16:33:18 GMT"}, {"version": "v2", "created": "Tue, 21 Mar 2017 17:38:04 GMT"}], "update_date": "2017-03-22", "authors_parsed": [["Tseng", "Francis", ""], ["Liu", "Fei", ""], ["Furtado", "Bernardo Alves", ""]]}, {"id": "1703.05519", "submitter": "Florian Brandl", "authors": "Florian Brandl, Felix Brandt", "title": "Arrovian Aggregation of Convex Preferences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider social welfare functions that satisfy Arrow's classic axioms of\nindependence of irrelevant alternatives and Pareto optimality when the outcome\nspace is the convex hull of some finite set of alternatives. Individual and\ncollective preferences are assumed to be continuous and convex, which\nguarantees the existence of maximal elements and the consistency of choice\nfunctions that return these elements, even without insisting on transitivity.\nWe provide characterizations of both the domains of preferences and the social\nwelfare functions that allow for anonymous Arrovian aggregation. The domains\nadmit arbitrary preferences over alternatives, which completely determine an\nagent's preferences over all mixed outcomes. On these domains, Arrow's\nimpossibility turns into a complete characterization of a unique social welfare\nfunction, which can be readily applied in settings involving divisible\nresources such as probability, time, or money.\n", "versions": [{"version": "v1", "created": "Thu, 16 Mar 2017 09:15:51 GMT"}, {"version": "v2", "created": "Sat, 27 May 2017 16:27:45 GMT"}, {"version": "v3", "created": "Tue, 10 Oct 2017 08:53:24 GMT"}, {"version": "v4", "created": "Mon, 14 May 2018 08:27:56 GMT"}, {"version": "v5", "created": "Thu, 18 Oct 2018 08:39:34 GMT"}, {"version": "v6", "created": "Fri, 12 Apr 2019 17:39:10 GMT"}], "update_date": "2019-04-15", "authors_parsed": [["Brandl", "Florian", ""], ["Brandt", "Felix", ""]]}, {"id": "1703.05623", "submitter": "Shayegan Omidshafiei", "authors": "Shayegan Omidshafiei, Shih-Yuan Liu, Michael Everett, Brett T. Lopez,\n  Christopher Amato, Miao Liu, Jonathan P. How, John Vian", "title": "Semantic-level Decentralized Multi-Robot Decision-Making using\n  Probabilistic Macro-Observations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust environment perception is essential for decision-making on robots\noperating in complex domains. Intelligent task execution requires principled\ntreatment of uncertainty sources in a robot's observation model. This is\nimportant not only for low-level observations (e.g., accelerometer data), but\nalso for high-level observations such as semantic object labels. This paper\nformalizes the concept of macro-observations in Decentralized Partially\nObservable Semi-Markov Decision Processes (Dec-POSMDPs), allowing scalable\nsemantic-level multi-robot decision making. A hierarchical Bayesian approach is\nused to model noise statistics of low-level classifier outputs, while\nsimultaneously allowing sharing of domain noise characteristics between\nclasses. Classification accuracy of the proposed macro-observation scheme,\ncalled Hierarchical Bayesian Noise Inference (HBNI), is shown to exceed\nexisting methods. The macro-observation scheme is then integrated into a\nDec-POSMDP planner, with hardware experiments running onboard a team of dynamic\nquadrotors in a challenging domain where noise-agnostic filtering fails. To the\nbest of our knowledge, this is the first demonstration of a real-time,\nconvolutional neural net-based classification framework running fully onboard a\nteam of quadrotors in a multi-robot decision-making domain.\n", "versions": [{"version": "v1", "created": "Thu, 16 Mar 2017 13:59:48 GMT"}], "update_date": "2017-03-17", "authors_parsed": [["Omidshafiei", "Shayegan", ""], ["Liu", "Shih-Yuan", ""], ["Everett", "Michael", ""], ["Lopez", "Brett T.", ""], ["Amato", "Christopher", ""], ["Liu", "Miao", ""], ["How", "Jonathan P.", ""], ["Vian", "John", ""]]}, {"id": "1703.05626", "submitter": "Shayegan Omidshafiei", "authors": "Shayegan Omidshafiei, Christopher Amato, Miao Liu, Michael Everett,\n  Jonathan P. How, John Vian", "title": "Scalable Accelerated Decentralized Multi-Robot Policy Search in\n  Continuous Observation Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the first ever approach for solving\n\\emph{continuous-observation} Decentralized Partially Observable Markov\nDecision Processes (Dec-POMDPs) and their semi-Markovian counterparts,\nDec-POSMDPs. This contribution is especially important in robotics, where a\nvast number of sensors provide continuous observation data. A\ncontinuous-observation policy representation is introduced using Stochastic\nKernel-based Finite State Automata (SK-FSAs). An SK-FSA search algorithm titled\nEntropy-based Policy Search using Continuous Kernel Observations (EPSCKO) is\nintroduced and applied to the first ever continuous-observation\nDec-POMDP/Dec-POSMDP domain, where it significantly outperforms\nstate-of-the-art discrete approaches. This methodology is equally applicable to\nDec-POMDPs and Dec-POSMDPs, though the empirical analysis presented focuses on\nDec-POSMDPs due to their higher scalability. To improve convergence, an entropy\ninjection policy search acceleration approach for both continuous and discrete\nobservation cases is also developed and shown to improve convergence rates\nwithout degrading policy quality.\n", "versions": [{"version": "v1", "created": "Thu, 16 Mar 2017 14:04:38 GMT"}], "update_date": "2017-03-17", "authors_parsed": [["Omidshafiei", "Shayegan", ""], ["Amato", "Christopher", ""], ["Liu", "Miao", ""], ["Everett", "Michael", ""], ["How", "Jonathan P.", ""], ["Vian", "John", ""]]}, {"id": "1703.06182", "submitter": "Shayegan Omidshafiei", "authors": "Shayegan Omidshafiei, Jason Pazis, Christopher Amato, Jonathan P. How,\n  John Vian", "title": "Deep Decentralized Multi-task Multi-Agent Reinforcement Learning under\n  Partial Observability", "comments": "Accepted to ICML 2017", "journal-ref": "Proceedings of the 34th International Conference on Machine\n  Learning (ICML 2017), Sydney, Australia, PMLR 70:2681-2690, 2017", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world tasks involve multiple agents with partial observability and\nlimited communication. Learning is challenging in these settings due to local\nviewpoints of agents, which perceive the world as non-stationary due to\nconcurrently-exploring teammates. Approaches that learn specialized policies\nfor individual tasks face problems when applied to the real world: not only do\nagents have to learn and store distinct policies for each task, but in practice\nidentities of tasks are often non-observable, making these approaches\ninapplicable. This paper formalizes and addresses the problem of multi-task\nmulti-agent reinforcement learning under partial observability. We introduce a\ndecentralized single-task learning approach that is robust to concurrent\ninteractions of teammates, and present an approach for distilling single-task\npolicies into a unified policy that performs well across multiple related\ntasks, without explicit provision of task identity.\n", "versions": [{"version": "v1", "created": "Fri, 17 Mar 2017 19:32:38 GMT"}, {"version": "v2", "created": "Sat, 25 Mar 2017 15:54:36 GMT"}, {"version": "v3", "created": "Wed, 14 Jun 2017 16:09:39 GMT"}, {"version": "v4", "created": "Thu, 13 Jul 2017 17:34:34 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Omidshafiei", "Shayegan", ""], ["Pazis", "Jason", ""], ["Amato", "Christopher", ""], ["How", "Jonathan P.", ""], ["Vian", "John", ""]]}, {"id": "1703.06261", "submitter": "James Russell", "authors": "James Russell, Mengbin Ye, Brian D. O. Anderson, Hatem Hmam, Peter\n  Sarunic", "title": "Cooperative Localisation of a GPS-Denied UAV in 3-Dimensional Space\n  Using Direction of Arrival Measurements", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel approach for localising a GPS (Global Positioning\nSystem)-denied Unmanned Aerial Vehicle (UAV) with the aid of a GPS-equipped UAV\nin three-dimensional space. The GPS-equipped UAV makes discrete-time broadcasts\nof its global coordinates. The GPS-denied UAV simultaneously receives the\nbroadcast and takes direction of arrival (DOA) measurements towards the origin\nof the broadcast in its local coordinate frame (obtained via an inertial\nnavigation system (INS)). The aim is to determine the difference between the\nlocal and global frames, described by a rotation and a translation. In the\nnoiseless case, global coordinates were recovered exactly by solving a system\nof linear equations. When DOA measurements are contaminated with noise, rank\nrelaxed semidefinite programming (SDP) and the Orthogonal Procrustes algorithm\nare employed. Simulations are provided and factors affecting accuracy, such as\nnoise levels and number of measurements, are explored.\n", "versions": [{"version": "v1", "created": "Sat, 18 Mar 2017 07:11:53 GMT"}], "update_date": "2017-03-22", "authors_parsed": [["Russell", "James", ""], ["Ye", "Mengbin", ""], ["Anderson", "Brian D. O.", ""], ["Hmam", "Hatem", ""], ["Sarunic", "Peter", ""]]}, {"id": "1703.06416", "submitter": "Tam Nguyen", "authors": "Tam Nguyen, Takeshi Hatanaka, Mamoru Doi, Emanuele Garone, Masayuki\n  Fujita", "title": "A Passivity-Based Distributed Reference Governor for Constrained Robotic\n  Networks", "comments": "8 pages, International Federation of Automatic Conference 2017, 8\n  figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.DC cs.RO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on a passivity-based distributed reference governor (RG)\napplied to a pre-stabilized mobile robotic network. The novelty of this paper\nlies in the method used to solve the RG problem, where a passivity-based\ndistributed optimization scheme is proposed. In particular, the gradient\ndescent method minimizes the global objective function while the dual ascent\nmethod maximizes the Hamiltonian. To make the agents converge to the agreed\noptimal solution, a proportional-integral consensus estimator is used. This\npaper proves the convergence of the state estimates of the RG to the optimal\nsolution through passivity arguments, considering the physical system static.\nThen, the effectiveness of the scheme considering the dynamics of the physical\nsystem is demonstrated through simulations and experiments.\n", "versions": [{"version": "v1", "created": "Sun, 19 Mar 2017 10:35:17 GMT"}], "update_date": "2017-03-21", "authors_parsed": [["Nguyen", "Tam", ""], ["Hatanaka", "Takeshi", ""], ["Doi", "Mamoru", ""], ["Garone", "Emanuele", ""], ["Fujita", "Masayuki", ""]]}, {"id": "1703.06680", "submitter": "Gabriele D'Angelo", "authors": "Moreno Marzolla, Gabriele D'Angelo", "title": "Parallel Sort-Based Matching for Data Distribution Management on\n  Shared-Memory Multiprocessors", "comments": "Proceedings of the 21-th ACM/IEEE International Symposium on\n  Distributed Simulation and Real Time Applications (DS-RT 2017). Best Paper\n  Award @DS-RT 2017", "journal-ref": null, "doi": "10.1109/DISTRA.2017.8167660", "report-no": null, "categories": "cs.DC cs.DS cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider the problem of identifying intersections between\ntwo sets of d-dimensional axis-parallel rectangles. This is a common problem\nthat arises in many agent-based simulation studies, and is of central\nimportance in the context of High Level Architecture (HLA), where it is at the\ncore of the Data Distribution Management (DDM) service. Several realizations of\nthe DDM service have been proposed; however, many of them are either\ninefficient or inherently sequential. These are serious limitations since\nmulticore processors are now ubiquitous, and DDM algorithms -- being\nCPU-intensive -- could benefit from additional computing power. We propose a\nparallel version of the Sort-Based Matching algorithm for shared-memory\nmultiprocessors. Sort-Based Matching is one of the most efficient serial\nalgorithms for the DDM problem, but is quite difficult to parallelize due to\ndata dependencies. We describe the algorithm and compute its asymptotic running\ntime; we complete the analysis by assessing its performance and scalability\nthrough extensive experiments on two commodity multicore systems based on a\ndual socket Intel Xeon processor, and a single socket Intel Core i7 processor.\n", "versions": [{"version": "v1", "created": "Mon, 20 Mar 2017 11:17:39 GMT"}, {"version": "v2", "created": "Thu, 6 Jul 2017 06:02:24 GMT"}, {"version": "v3", "created": "Wed, 25 Oct 2017 08:42:20 GMT"}, {"version": "v4", "created": "Tue, 7 Aug 2018 07:20:05 GMT"}], "update_date": "2018-08-08", "authors_parsed": [["Marzolla", "Moreno", ""], ["D'Angelo", "Gabriele", ""]]}, {"id": "1703.06853", "submitter": "Anton V. Proskurnikov", "authors": "Anton V. Proskurnikov and Ming Cao", "title": "Modulus consensus in discrete-time signed networks and properties of\n  special recurrent inequalities", "comments": "submitted to IEEE CDC 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.MA math.OC nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently the dynamics of signed networks, where the ties among the agents can\nbe both positive (attractive) or negative (repulsive) have attracted\nsubstantial attention of the research community. Examples of such networks are\nmodels of opinion dynamics over signed graphs, recently introduced by Altafini\n(2012,2013) and extended to discrete-time case by Meng et al. (2014). It has\nbeen shown that under mild connectivity assumptions these protocols provide the\nconvergence of opinions in absolute value, whereas their signs may differ. This\n\"modulus consensus\" may correspond to the polarization of the opinions (or\nbipartite consensus, including the usual consensus as a special case), or their\nconvergence to zero. In this paper, we demonstrate that the phenomenon of\nmodulus consensus in the discrete-time Altafini model is a manifestation of a\nmore general and profound fact, regarding the solutions of a special recurrent\ninequality. Although such a recurrent inequality does not provide the\nuniqueness of a solution, it can be shown that, under some natural assumptions,\neach of its bounded solutions has a limit and, moreover, converges to\nconsensus. A similar property has previously been established for special\ncontinuous-time differential inequalities (Proskurnikov, Cao, 2016). Besides\nanalysis of signed networks, we link the consensus properties of recurrent\ninequalities to the convergence analysis of distributed optimization algorithms\nand the problems of Schur stability of substochastic matrices.\n", "versions": [{"version": "v1", "created": "Mon, 20 Mar 2017 17:12:45 GMT"}], "update_date": "2017-03-21", "authors_parsed": [["Proskurnikov", "Anton V.", ""], ["Cao", "Ming", ""]]}, {"id": "1703.07280", "submitter": "Vasileios Tzoumas", "authors": "Vasileios Tzoumas, Konstantinos Gatsis, Ali Jadbabaie, George J.\n  Pappas", "title": "Resilient Monotone Submodular Function Maximization", "comments": "Improved suboptimality guarantees on proposed algorithm and corrected\n  typo on Algorithm 1's statement", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we focus on applications in machine learning, optimization,\nand control that call for the resilient selection of a few elements, e.g.\nfeatures, sensors, or leaders, against a number of adversarial\ndenial-of-service attacks or failures. In general, such resilient optimization\nproblems are hard, and cannot be solved exactly in polynomial time, even though\nthey often involve objective functions that are monotone and submodular.\nNotwithstanding, in this paper we provide the first scalable,\ncurvature-dependent algorithm for their approximate solution, that is valid for\nany number of attacks or failures, and which, for functions with low curvature,\nguarantees superior approximation performance. Notably, the curvature has been\nknown to tighten approximations for several non-resilient maximization\nproblems, yet its effect on resilient maximization had hitherto been unknown.\nWe complement our theoretical analyses with supporting empirical evaluations.\n", "versions": [{"version": "v1", "created": "Tue, 21 Mar 2017 15:38:50 GMT"}, {"version": "v2", "created": "Tue, 31 Oct 2017 17:00:39 GMT"}], "update_date": "2017-11-01", "authors_parsed": [["Tzoumas", "Vasileios", ""], ["Gatsis", "Konstantinos", ""], ["Jadbabaie", "Ali", ""], ["Pappas", "George J.", ""]]}, {"id": "1703.07306", "submitter": "Karthik Elamvazhuthi", "authors": "Karthik Elamvazhuthi, Hendrik Kuiper, and Spring Berman", "title": "Controllability to Equilibria of the 1-D Fokker-Planck Equation with\n  Zero-Flux Boundary Condition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.MA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of controlling the spatiotemporal probability\ndistribution of a robotic swarm that evolves according to a reflected diffusion\nprocess, using the space- and time-dependent drift vector field parameter as\nthe control variable. In contrast to previous work on control of the\nFokker-Planck equation, a zero-flux boundary condition is imposed on the\npartial differential equation that governs the swarm probability distribution,\nand only bounded vector fields are considered to be admissible as control\nparameters. Under these constraints, we show that any initial probability\ndistribution can be transported to a target probability distribution under\ncertain assumptions on the regularity of the target distribution. In\nparticular, we show that if the target distribution is (essentially) bounded,\nhas bounded first-order and second-order partial derivatives, and is bounded\nfrom below by a strictly positive constant, then this distribution can be\nreached exactly using a drift vector field that is bounded in space and time.\nOur proof is constructive and based on classical linear semigroup theoretic\nconcepts.\n", "versions": [{"version": "v1", "created": "Tue, 21 Mar 2017 16:39:29 GMT"}, {"version": "v2", "created": "Fri, 24 Mar 2017 03:00:40 GMT"}], "update_date": "2017-03-27", "authors_parsed": [["Elamvazhuthi", "Karthik", ""], ["Kuiper", "Hendrik", ""], ["Berman", "Spring", ""]]}, {"id": "1703.07865", "submitter": "Tor Anderson", "authors": "Tor Anderson, Chin-Yao Chang, and Sonia Martinez", "title": "Weight Design of Distributed Approximate Newton Algorithms for\n  Constrained Optimization", "comments": "Submitted to CCTA 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.MA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by economic dispatch and linearly-constrained resource allocation\nproblems, this paper proposes a novel Distributed Approx-Newton algorithm that\napproximates the standard Newton optimization method. A main property of this\ndistributed algorithm is that it only requires agents to exchange constant-size\ncommunication messages. The convergence of this algorithm is discussed and\nrigorously analyzed. In addition, we aim to address the problem of designing\ncommunication topologies and weightings that are optimal for second-order\nmethods. To this end, we propose an effective approximation which is loosely\nbased on completing the square to address the NP-hard bilinear optimization\ninvolved in the design. Simulations demonstrate that our proposed weight design\napplied to the Distributed Approx-Newton algorithm has a superior convergence\nproperty compared to existing weighted and distributed first-order gradient\ndescent methods.\n", "versions": [{"version": "v1", "created": "Wed, 22 Mar 2017 21:29:38 GMT"}], "update_date": "2017-03-24", "authors_parsed": [["Anderson", "Tor", ""], ["Chang", "Chin-Yao", ""], ["Martinez", "Sonia", ""]]}, {"id": "1703.08041", "submitter": "Palash Dey", "authors": "Palash Dey", "title": "Resolving the Complexity of Some Fundamental Problems in Computational\n  Social Choice", "comments": "Ph.D. Thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This thesis is in the area called computational social choice which is an\nintersection area of algorithms and social choice theory.\n", "versions": [{"version": "v1", "created": "Thu, 23 Mar 2017 12:32:10 GMT"}], "update_date": "2017-03-24", "authors_parsed": [["Dey", "Palash", ""]]}, {"id": "1703.08342", "submitter": "Sebastian Trimpe", "authors": "Sebastian Trimpe", "title": "Event-based State Estimation: An Emulation-based Approach", "comments": "21 pages, 8 figures, this article is based on the technical report\n  arXiv:1511.05223 and is accepted for publication in IET Control Theory &\n  Applications", "journal-ref": null, "doi": "10.1049/iet-cta.2016.1021", "report-no": null, "categories": "cs.SY cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An event-based state estimation approach for reducing communication in a\nnetworked control system is proposed. Multiple distributed sensor agents\nobserve a dynamic process and sporadically transmit their measurements to\nestimator agents over a shared bus network. Local event-triggering protocols\nensure that data is transmitted only when necessary to meet a desired\nestimation accuracy. The event-based design is shown to emulate the performance\nof a centralised state observer design up to guaranteed bounds, but with\nreduced communication. The stability results for state estimation are extended\nto the distributed control system that results when the local estimates are\nused for feedback control. Results from numerical simulations and hardware\nexperiments illustrate the effectiveness of the proposed approach in reducing\nnetwork communication.\n", "versions": [{"version": "v1", "created": "Fri, 24 Mar 2017 10:24:47 GMT"}], "update_date": "2017-03-27", "authors_parsed": [["Trimpe", "Sebastian", ""]]}, {"id": "1703.08561", "submitter": "Andrew Best", "authors": "Andrew Best and Sahil Narang and Daniel Barber and Dinesh Manocha", "title": "AutonoVi: Autonomous Vehicle Planning with Dynamic Maneuvers and Traffic\n  Constraints", "comments": "9 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present AutonoVi:, a novel algorithm for autonomous vehicle navigation\nthat supports dynamic maneuvers and satisfies traffic constraints and norms.\nOur approach is based on optimization-based maneuver planning that supports\ndynamic lane-changes, swerving, and braking in all traffic scenarios and guides\nthe vehicle to its goal position. We take into account various traffic\nconstraints, including collision avoidance with other vehicles, pedestrians,\nand cyclists using control velocity obstacles. We use a data-driven approach to\nmodel the vehicle dynamics for control and collision avoidance. Furthermore,\nour trajectory computation algorithm takes into account traffic rules and\nbehaviors, such as stopping at intersections and stoplights, based on an\narc-spline representation. We have evaluated our algorithm in a simulated\nenvironment and tested its interactive performance in urban and highway driving\nscenarios with tens of vehicles, pedestrians, and cyclists. These scenarios\ninclude jaywalking pedestrians, sudden stops from high speeds, safely passing\ncyclists, a vehicle suddenly swerving into the roadway, and high-density\ntraffic where the vehicle must change lanes to progress more effectively.\n", "versions": [{"version": "v1", "created": "Fri, 24 Mar 2017 18:21:16 GMT"}, {"version": "v2", "created": "Wed, 29 Mar 2017 17:15:55 GMT"}], "update_date": "2017-03-30", "authors_parsed": [["Best", "Andrew", ""], ["Narang", "Sahil", ""], ["Barber", "Daniel", ""], ["Manocha", "Dinesh", ""]]}, {"id": "1703.09087", "submitter": "Juan Rodriguez-Aguilar", "authors": "Maite Lopez-Sanchez and Marc Serramia and Juan A. Rodriguez-Aguilar\n  and Javier Morales and Michael Wooldridge", "title": "Automating decision making to help establish norm-based regulations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Norms have been extensively proposed as coordination mechanisms for both\nagent and human societies. Nevertheless, choosing the norms to regulate a\nsociety is by no means straightforward. The reasons are twofold. First, the\nnorms to choose from may not be independent (i.e, they can be related to each\nother). Second, different preference criteria may be applied when choosing the\nnorms to enact. This paper advances the state of the art by modeling a series\nof decision-making problems that regulation authorities confront when choosing\nthe policies to establish. In order to do so, we first identify three different\nnorm relationships -namely, generalisation, exclusivity, and substitutability-\nand we then consider norm representation power, cost, and associated moral\nvalues as alternative preference criteria. Thereafter, we show that the\ndecision-making problems faced by policy makers can be encoded as linear\nprograms, and hence solved with the aid of state-of-the-art solvers.\n", "versions": [{"version": "v1", "created": "Mon, 27 Mar 2017 14:03:24 GMT"}, {"version": "v2", "created": "Mon, 3 Apr 2017 11:46:45 GMT"}], "update_date": "2017-04-04", "authors_parsed": [["Lopez-Sanchez", "Maite", ""], ["Serramia", "Marc", ""], ["Rodriguez-Aguilar", "Juan A.", ""], ["Morales", "Javier", ""], ["Wooldridge", "Michael", ""]]}, {"id": "1703.10970", "submitter": "Pantelis  Pipergias Analytis", "authors": "Pantelis P. Analytis, Hrvoje Stojic, Alexandros Gelastopoulos and\n  Mehdi Moussa\\\"id", "title": "Diversity of preferences can increase collective welfare in sequential\n  exploration problems", "comments": "4 pages, 1 figure, originally presented at the collected intelligence\n  (CI) conference in June 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In search engines, online marketplaces and other human-computer interfaces\nlarge collectives of individuals sequentially interact with numerous\nalternatives of varying quality. In these contexts, trial and error\n(exploration) is crucial for uncovering novel high-quality items or solutions,\nbut entails a high cost for individual users. Self-interested decision makers,\nare often better off imitating the choices of individuals who have already\nincurred the costs of exploration. Although imitation makes sense at the\nindividual level, it deprives the group of additional information that could\nhave been gleaned by individual explorers. In this paper we show that in such\nproblems, preference diversity can function as a welfare enhancing mechanism.\nIt leads to a consistent increase in the quality of the consumed alternatives\nthat outweighs the increased cost of search for the users.\n", "versions": [{"version": "v1", "created": "Tue, 28 Mar 2017 22:11:44 GMT"}, {"version": "v2", "created": "Mon, 3 Apr 2017 01:35:06 GMT"}], "update_date": "2017-04-04", "authors_parsed": [["Analytis", "Pantelis P.", ""], ["Stojic", "Hrvoje", ""], ["Gelastopoulos", "Alexandros", ""], ["Moussa\u00efd", "Mehdi", ""]]}, {"id": "1703.11005", "submitter": "Sergio Rajsbaum", "authors": "Eric Goubault and Sergio Rajsbaum", "title": "A simplicial complex model of dynamic epistemic logic for fault-tolerant\n  distributed computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The usual epistemic S5 model for multi-agent systems is a Kripke graph, whose\nedges are labeled with the agents that do not distinguish between two states.\nWe propose to uncover the higher dimensional information implicit in the Kripke\ngraph, by using as a model its dual, a chromatic simplicial complex. For each\nstate of the Kripke model there is a facet in the complex, with one vertex per\nagent. If an edge (u,v) is labeled with a set of agents S, the facets\ncorresponding to u and v intersect in a simplex consisting of one vertex for\neach agent of S. Then we use dynamic epistemic logic to study how the\nsimplicial complex epistemic model changes after the agents communicate with\neach other. We show that there are topological invariants preserved from the\ninitial epistemic complex to the epistemic complex after an action model is\napplied, that depend on how reliable the communication is. In turn these\ntopological properties determine the knowledge that the agents may gain after\nthe communication happens.\n", "versions": [{"version": "v1", "created": "Fri, 31 Mar 2017 17:53:06 GMT"}, {"version": "v2", "created": "Tue, 4 Apr 2017 12:50:53 GMT"}], "update_date": "2017-04-05", "authors_parsed": [["Goubault", "Eric", ""], ["Rajsbaum", "Sergio", ""]]}]