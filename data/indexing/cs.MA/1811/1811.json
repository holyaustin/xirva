[{"id": "1811.00111", "submitter": "David G\\'omez-Guti\\'errez", "authors": "David G\\'omez-Guti\\'errez, Carlos Renato V\\'azquez, Sergej\n  \\v{C}elikovsk\\'y, Juan Diego S\\'anchez-Torres and Javier Ruiz Le\\'on", "title": "On finite-time and fixed-time consensus algorithms for dynamic networks\n  switching among disconnected digraphs", "comments": "Please cite the publisher's version}. For the publisher's version and\n  full citation details see: https://doi.org/10.1080/00207179.2018.1543896 The\n  following links provide access, for a limited time, to a free copy of the\n  publisher's version:\n  https://www.tandfonline.com/eprint/FSW8JJRVPHMXJ3XUUXZH/full?target=10.1080/00207179.2018.1543896", "journal-ref": "International Journal of Control, 93(9), 2120-2134, 2020", "doi": "10.1080/00207179.2018.1543896", "report-no": null, "categories": "cs.SY cs.MA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this paper is to analyze a class of consensus algorithms with\nfinite-time or fixed-time convergence for dynamic networks formed by agents\nwith first-order dynamics. In particular, in the analyzed class a single\nevaluation of a nonlinear function of the consensus error is performed per each\nnode. The classical assumption of switching among connected graphs is dropped\nhere, allowing to represent failures and intermittent communications between\nagents. Thus, conditions to guarantee finite and fixed-time convergence, even\nwhile switching among disconnected graphs, are provided. Moreover, the\nalgorithms of the considered class are shown to be computationally simpler than\npreviously proposed finite-time consensus algorithms for dynamic networks,\nwhich is an important feature in scenarios with computationally limited nodes\nand energy efficiency requirements such as in sensor networks. The performance\nof the considered consensus algorithms is illustrated through simulations,\ncomparing it to existing approaches for dynamic networks with finite-time and\nfixed-time convergence. It is shown that the settling time of the considered\nalgorithms grows slower when the number of nodes increases than with other\nconsensus algorithms for dynamic networks.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 20:53:01 GMT"}, {"version": "v2", "created": "Fri, 25 Jun 2021 23:30:55 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["G\u00f3mez-Guti\u00e9rrez", "David", ""], ["V\u00e1zquez", "Carlos Renato", ""], ["\u010celikovsk\u00fd", "Sergej", ""], ["S\u00e1nchez-Torres", "Juan Diego", ""], ["Le\u00f3n", "Javier Ruiz", ""]]}, {"id": "1811.01458", "submitter": "Jakob Foerster", "authors": "Jakob N. Foerster, Francis Song, Edward Hughes, Neil Burch, Iain\n  Dunning, Shimon Whiteson, Matthew Botvinick, Michael Bowling", "title": "Bayesian Action Decoder for Deep Multi-Agent Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When observing the actions of others, humans make inferences about why they\nacted as they did, and what this implies about the world; humans also use the\nfact that their actions will be interpreted in this manner, allowing them to\nact informatively and thereby communicate efficiently with others. Although\nlearning algorithms have recently achieved superhuman performance in a number\nof two-player, zero-sum games, scalable multi-agent reinforcement learning\nalgorithms that can discover effective strategies and conventions in complex,\npartially observable settings have proven elusive. We present the Bayesian\naction decoder (BAD), a new multi-agent learning method that uses an\napproximate Bayesian update to obtain a public belief that conditions on the\nactions taken by all agents in the environment. BAD introduces a new Markov\ndecision process, the public belief MDP, in which the action space consists of\nall deterministic partial policies, and exploits the fact that an agent acting\nonly on this public belief state can still learn to use its private information\nif the action space is augmented to be over all partial policies mapping\nprivate information into environment actions. The Bayesian update is closely\nrelated to the theory of mind reasoning that humans carry out when observing\nothers' actions. We first validate BAD on a proof-of-principle two-step matrix\ngame, where it outperforms policy gradient methods; we then evaluate BAD on the\nchallenging, cooperative partial-information card game Hanabi, where, in the\ntwo-player setting, it surpasses all previously published learning and\nhand-coded approaches, establishing a new state of the art.\n", "versions": [{"version": "v1", "created": "Sun, 4 Nov 2018 23:43:54 GMT"}, {"version": "v2", "created": "Wed, 13 Feb 2019 16:51:31 GMT"}, {"version": "v3", "created": "Tue, 10 Sep 2019 21:21:00 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Foerster", "Jakob N.", ""], ["Song", "Francis", ""], ["Hughes", "Edward", ""], ["Burch", "Neil", ""], ["Dunning", "Iain", ""], ["Whiteson", "Shimon", ""], ["Botvinick", "Matthew", ""], ["Bowling", "Michael", ""]]}, {"id": "1811.01590", "submitter": "Andreas Achen", "authors": "Andreas Achen", "title": "Putting the Agents back in the Domain: A Two-Sorted Term-Modal Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.MA math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the present paper syntax and semantics will be presented for an expansion\nof ordinary n-agent QML with constant domain, non-rigid constants, rigid\nvariables and including both functions, relations, and equality. Further, the\nnumber of agents will be specified axiomatically thus ensuring maximal\nflexibility wrt. the cardinality of the set of agents. Domain, variables, and\nconstants will be partitioned in an agent-part and an object-part and the\nsyntax will be expanded to include strings in which indexes of modal operators\nare quantified over as wff's of the language. This will enhance expressiveness\nregarding the epistemic status of agents. Such a term-modal version of the\nlogic K is shown to be sound and complete wrt. the class of (appropriate)\nframes, and a term-version of S4 is shown to be sound and complete wrt. the\nclass of (appropriate) frames in which the relations are transitive. It should\nbe noted that completeness is shown via the framework of canonical models and\nthus allows for non-complicated generalizations to other logics than the\nterm-versions of K and S4.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 10:29:28 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Achen", "Andreas", ""]]}, {"id": "1811.01630", "submitter": "Warut Suksompong", "authors": "Pasin Manurangsi and Warut Suksompong", "title": "When Do Envy-Free Allocations Exist?", "comments": "Appears in the 33rd AAAI Conference on Artificial Intelligence\n  (AAAI), 2019", "journal-ref": "SIAM Journal on Discrete Mathematics, 34(3): 1505-1521 (2020)", "doi": "10.1137/19M1279125", "report-no": null, "categories": "cs.GT cs.MA math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a fair division setting in which $m$ indivisible items are to be\nallocated among $n$ agents, where the agents have additive utilities and the\nagents' utilities for individual items are independently sampled from a\ndistribution. Previous work has shown that an envy-free allocation is likely to\nexist when $m=\\Omega(n\\log n)$ but not when $m=n+o(n)$, and left open the\nquestion of determining where the phase transition from non-existence to\nexistence occurs. We show that, surprisingly, there is in fact no universal\npoint of transition---instead, the transition is governed by the divisibility\nrelation between $m$ and $n$. On the one hand, if $m$ is divisible by $n$, an\nenvy-free allocation exists with high probability as long as $m\\geq 2n$. On the\nother hand, if $m$ is not \"almost\" divisible by $n$, an envy-free allocation is\nunlikely to exist even when $m=\\Theta(n\\log n/\\log\\log n)$.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 11:53:00 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Manurangsi", "Pasin", ""], ["Suksompong", "Warut", ""]]}, {"id": "1811.01683", "submitter": "Yacine Ouzrout", "authors": "Yacine Ouzrout (LIESP), Matteo Savino, Abdelaziz Bouras (LIESP), Carlo\n  Di Domenico", "title": "Supply Chain Management analysis: a simulation approach of the Value\n  Chain Operations Reference model (VCOR)", "comments": null, "journal-ref": "IJVCM, 2009, 3 (3), pp.263-287", "doi": null, "report-no": "Lyon 2", "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The impact of globalization and worldwide competition has forced firms to\nmodify their strategies towards a real time operation with respect to\ncustomer's requirements. This behaviour, together with the communication\npossibilities offered by the actual Information and Communication Technologies,\nallows the top management to move towards the concept of extended enterprise in\nwhich a collaborative link is established among suppliers, commercial partners\nand customers. When the information flows involve each actor of the chain, from\nsuppliers to the final distribution centers, the extended enterprise becomes a\nvirtual firm, that can be defined as a set of stand-alone operational units\nthat acts to reconfigure themselves as a value chain in order to adapt to the\nbusiness opportunities given by the market. The present work is intended to\nverify through a simulation approach the quantitative advantages that can be\nobtained by the introduction of the Value Chain concept into the Supply Chain\nManagement (SCM). The paper, after a description of the two most known (SCM)\nmethods - SCOR and VCOR - makes a comparison between them by the customer's\npoint of view. In the second part of the work a simulation model has been\ndeveloped to verify the advantage that the VCOR is able to obtain, validating\nit on an industrial case study.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 13:53:10 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Ouzrout", "Yacine", "", "LIESP"], ["Savino", "Matteo", "", "LIESP"], ["Bouras", "Abdelaziz", "", "LIESP"], ["Di Domenico", "Carlo", ""]]}, {"id": "1811.01688", "submitter": "Yacine Ouzrout", "authors": "Gilles Neubert (LIESP), Yacine Ouzrout (LIESP), Abdelaziz Bouras\n  (LIESP)", "title": "Collaboration and integration through information technologies in supply\n  chains", "comments": null, "journal-ref": "IJTM, 2004, 28 (2), pp.259-273", "doi": null, "report-no": "Lyon 2", "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supply chain management encompasses various processes including various\nconventional logistics activities, and various other processes These processes\nare supported -- to a certain limit -- by coordination and integration\nmechanisms which are long-term strategies that give competitive advantage\nthrough overall supply chain efficiency. Information Technology, by the way of\ncollecting, sharing and gathering data, exchanging information, optimising\nprocess through package software, is becoming one of the key developments and\nsuccess of these collaboration strategies. This paper proposes a study to\nidentify the methods used for collaborative works in the supply chain and\nfocuses on some of its areas, as between a company and its suppliers (i.e.,\ninventory sharing) and its customers (i.e., customer demand, forecasting), and\nalso the integration of product information in the value chain.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 13:55:25 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Neubert", "Gilles", "", "LIESP"], ["Ouzrout", "Yacine", "", "LIESP"], ["Bouras", "Abdelaziz", "", "LIESP"]]}, {"id": "1811.02052", "submitter": "Charalampos Andriotis", "authors": "C.P. Andriotis, K.G. Papakonstantinou", "title": "Managing engineering systems with large state and action spaces through\n  deep reinforcement learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision-making for engineering systems can be efficiently formulated as a\nMarkov Decision Process (MDP) or a Partially Observable MDP (POMDP). Typical\nMDP and POMDP solution procedures utilize offline knowledge about the\nenvironment and provide detailed policies for relatively small systems with\ntractable state and action spaces. However, in large multi-component systems\nthe sizes of these spaces easily explode, as system states and actions scale\nexponentially with the number of components, whereas environment dynamics are\ndifficult to be described in explicit forms for the entire system and may only\nbe accessible through numerical simulators. In this work, to address these\nissues, an integrated Deep Reinforcement Learning (DRL) framework is\nintroduced. The Deep Centralized Multi-agent Actor Critic (DCMAC) is developed,\nan off-policy actor-critic DRL approach, providing efficient life-cycle\npolicies for large multi-component systems operating in high-dimensional\nspaces. Apart from deep function approximations that parametrize large state\nspaces, DCMAC also adopts a factorized representation of the system actions,\nbeing able to designate individualized component- and subsystem-level\ndecisions, while maintaining a centralized value function for the entire\nsystem. DCMAC compares well against Deep Q-Network (DQN) solutions and exact\npolicies, where applicable, and outperforms optimized baselines that are based\non time-based, condition-based and periodic policies.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 22:01:54 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Andriotis", "C. P.", ""], ["Papakonstantinou", "K. G.", ""]]}, {"id": "1811.02483", "submitter": "Yufei Wang", "authors": "Yufei Wang, Zheyuan Ryan Shi, Lantao Yu, Yi Wu, Rohit Singh, Lucas\n  Joppa, Fei Fang", "title": "Deep Reinforcement Learning for Green Security Games with Real-Time\n  Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Green Security Games (GSGs) have been proposed and applied to optimize\npatrols conducted by law enforcement agencies in green security domains such as\ncombating poaching, illegal logging and overfishing. However, real-time\ninformation such as footprints and agents' subsequent actions upon receiving\nthe information, e.g., rangers following the footprints to chase the poacher,\nhave been neglected in previous work. To fill the gap, we first propose a new\ngame model GSG-I which augments GSGs with sequential movement and the vital\nelement of real-time information. Second, we design a novel deep reinforcement\nlearning-based algorithm, DeDOL, to compute a patrolling strategy that adapts\nto the real-time information against a best-responding attacker. DeDOL is built\nupon the double oracle framework and the policy-space response oracle, solving\na restricted game and iteratively adding best response strategies to it through\ntraining deep Q-networks. Exploring the game structure, DeDOL uses\ndomain-specific heuristic strategies as initial strategies and constructs\nseveral local modes for efficient and parallelized training. To our knowledge,\nthis is the first attempt to use Deep Q-Learning for security games.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 16:43:47 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Wang", "Yufei", ""], ["Shi", "Zheyuan Ryan", ""], ["Yu", "Lantao", ""], ["Wu", "Yi", ""], ["Singh", "Rohit", ""], ["Joppa", "Lucas", ""], ["Fang", "Fei", ""]]}, {"id": "1811.02921", "submitter": "Ben Abramowitz", "authors": "Ben Abramowitz, Nicholas Mattei", "title": "Flexible Representative Democracy: An Introduction with Binary Issues", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Flexible Representative Democracy (FRD), a novel hybrid of\nRepresentative Democracy (RD) and direct democracy (DD), in which voters can\nalter the issue-dependent weights of a set of elected representatives. In line\nwith the literature on Interactive Democracy, our model allows the voters to\nactively determine the degree to which the system is direct versus\nrepresentative. However, unlike Liquid Democracy, FRD uses strictly\nnon-transitive delegations, making delegation cycles impossible, and maintains\na fixed set of accountable elected representatives. We present FRD and analyze\nit using a computational approach with issues that are binary and symmetric; we\ncompare the outcomes of various democratic systems using Direct Democracy with\nmajority voting as an ideal baseline. First, we demonstrate the shortcomings of\nRepresentative Democracy in our model. We provide NP-Hardness results for\nelecting an ideal set of representatives, discuss pathologies, and demonstrate\nempirically that common multi-winner election rules for selecting\nrepresentatives do not perform well in expectation. To analyze the behavior of\nFRD, we begin by providing theoretical results on how issue-specific\ndelegations determine outcomes. Finally, we provide empirical results comparing\nthe outcomes of RD with fixed sets of proxies across issues versus FRD with\nissue-specific delegations. Our results show that variants of Proxy Voting\nyield no discernible benefit over RD and reveal the potential for FRD to\nimprove outcomes as voter participation increases, further motivating the use\nof issue-specific delegations.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2018 15:07:01 GMT"}, {"version": "v2", "created": "Mon, 1 Apr 2019 21:53:09 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Abramowitz", "Ben", ""], ["Mattei", "Nicholas", ""]]}, {"id": "1811.03158", "submitter": "Lin Chen", "authors": "Lin Chen, Lei Xu, Shouhuai Xu, Zhimin Gao, Weidong Shi", "title": "Election with Bribed Voter Uncertainty: Hardness and Approximation\n  Algorithm", "comments": "Accepted at AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bribery in election (or computational social choice in general) is an\nimportant problem that has received a considerable amount of attention. In the\nclassic bribery problem, the briber (or attacker) bribes some voters in\nattempting to make the briber's designated candidate win an election. In this\npaper, we introduce a novel variant of the bribery problem, \"Election with\nBribed Voter Uncertainty\" or BVU for short, accommodating the uncertainty that\nthe vote of a bribed voter may or may not be counted. This uncertainty occurs\neither because a bribed voter may not cast its vote in fear of being caught, or\nbecause a bribed voter is indeed caught and therefore its vote is discarded. As\na first step towards ultimately understanding and addressing this important\nproblem, we show that it does not admit any multiplicative $O(1)$-approximation\nalgorithm modulo standard complexity assumptions. We further show that there is\nan approximation algorithm that returns a solution with an additive-$\\epsilon$\nerror in FPT time for any fixed $\\epsilon$.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2018 21:49:00 GMT"}], "update_date": "2018-11-12", "authors_parsed": [["Chen", "Lin", ""], ["Xu", "Lei", ""], ["Xu", "Shouhuai", ""], ["Gao", "Zhimin", ""], ["Shi", "Weidong", ""]]}, {"id": "1811.03539", "submitter": "Marcos Oliveira", "authors": "Marcos Oliveira, Diego Pinheiro, Mariana Macedo, Carmelo Bastos-Filho,\n  Ronaldo Menezes", "title": "Uncovering the Social Interaction in Swarm Intelligence with Network\n  Science", "comments": "23 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.MA cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Swarm intelligence is the collective behavior emerging in systems with\nlocally interacting components. Because of their self-organization\ncapabilities, swarm-based systems show essential properties for handling\nreal-world problems such as robustness, scalability, and flexibility. Yet, we\ndo not know why swarm-based algorithms work well and neither we can compare the\ndifferent approaches in the literature. The lack of a common framework capable\nof characterizing these several swarm-based algorithms, transcending their\nparticularities, has led to a stream of publications inspired by different\naspects of nature without a systematic comparison over existing approaches.\nHere, we address this gap by introducing a network-based framework---the\ninteraction network---to examine computational swarm-based systems via the\noptics of the social dynamics of such interaction network; a clear example of\nnetwork science being applied to bring further clarity to a complicated field\nwithin artificial intelligence. We discuss the social interactions of four\nwell-known swarm-based algorithms and provide an in-depth case study of the\nParticle Swarm Optimization. The interaction network enables researchers to\nstudy swarm algorithms as systems, removing the algorithm particularities from\nthe analyses while focusing on the structure of the social interactions.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 16:36:11 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2019 10:27:16 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Oliveira", "Marcos", ""], ["Pinheiro", "Diego", ""], ["Macedo", "Mariana", ""], ["Bastos-Filho", "Carmelo", ""], ["Menezes", "Ronaldo", ""]]}, {"id": "1811.03657", "submitter": "Andrea Camisa", "authors": "Andrea Camisa, Ivano Notarnicola, Giuseppe Notarstefano", "title": "A Primal Decomposition Method with Suboptimality Bounds for Distributed\n  Mixed-Integer Linear Programming", "comments": "57th IEEE Conference on Decision and Control", "journal-ref": null, "doi": "10.1109/CDC.2018.8619597", "report-no": null, "categories": "cs.SY cs.DC cs.MA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we deal with a network of agents seeking to solve in a\ndistributed way Mixed-Integer Linear Programs (MILPs) with a coupling\nconstraint (modeling a limited shared resource) and local constraints. MILPs\nare NP-hard problems and several challenges arise in a distributed framework,\nso that looking for suboptimal solutions is of interest. To achieve this goal,\nthe presence of a linear coupling calls for tailored decomposition approaches.\nWe propose a fully distributed algorithm based on a primal decomposition\napproach and a suitable tightening of the coupling constraints. Agents\nrepeatedly update local allocation vectors, which converge to an optimal\nresource allocation of an approximate version of the original problem. Based on\nsuch allocation vectors, agents are able to (locally) compute a mixed-integer\nsolution, which is guaranteed to be feasible after a sufficiently large time.\nAsymptotic and finite-time suboptimality bounds are established for the\ncomputed solution. Numerical simulations highlight the efficacy of the proposed\nmethodology.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 19:32:41 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Camisa", "Andrea", ""], ["Notarnicola", "Ivano", ""], ["Notarstefano", "Giuseppe", ""]]}, {"id": "1811.03761", "submitter": "Liping Li", "authors": "Liping Li, Wei Xu, Tianyi Chen, Georgios B. Giannakis, and Qing Ling", "title": "RSA: Byzantine-Robust Stochastic Aggregation Methods for Distributed\n  Learning from Heterogeneous Datasets", "comments": "To appear in AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.MA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a class of robust stochastic subgradient methods\nfor distributed learning from heterogeneous datasets at presence of an unknown\nnumber of Byzantine workers. The Byzantine workers, during the learning\nprocess, may send arbitrary incorrect messages to the master due to data\ncorruptions, communication failures or malicious attacks, and consequently bias\nthe learned model. The key to the proposed methods is a regularization term\nincorporated with the objective function so as to robustify the learning task\nand mitigate the negative effects of Byzantine attacks. The resultant\nsubgradient-based algorithms are termed Byzantine-Robust Stochastic Aggregation\nmethods, justifying our acronym RSA used henceforth. In contrast to most of the\nexisting algorithms, RSA does not rely on the assumption that the data are\nindependent and identically distributed (i.i.d.) on the workers, and hence fits\nfor a wider class of applications. Theoretically, we show that: i) RSA\nconverges to a near-optimal solution with the learning error dependent on the\nnumber of Byzantine workers; ii) the convergence rate of RSA under Byzantine\nattacks is the same as that of the stochastic gradient descent method, which is\nfree of Byzantine attacks. Numerically, experiments on real dataset corroborate\nthe competitive performance of RSA and a complexity reduction compared to the\nstate-of-the-art alternatives.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 03:46:46 GMT"}, {"version": "v2", "created": "Mon, 11 Nov 2019 08:01:36 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Li", "Liping", ""], ["Xu", "Wei", ""], ["Chen", "Tianyi", ""], ["Giannakis", "Georgios B.", ""], ["Ling", "Qing", ""]]}, {"id": "1811.03819", "submitter": "Chao Yu", "authors": "Chao Yu", "title": "The Price of Governance: A Middle Ground Solution to Coordination in\n  Organizational Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Achieving coordination is crucial in organizational control. This paper\ninvestigates a middle ground solution between decentralized interactions and\ncentralized administrations for coordinating agents beyond inefficient\nbehavior. We first propose the price of governance (PoG) to evaluate how such a\nmiddle ground solution performs in terms of effectiveness and cost. We then\npropose a hierarchical supervision framework to explicitly model the PoG, and\ndefine step by step how to realize the core principle of the framework and\ncompute the optimal PoG for a control problem. Two illustrative case studies\nare carried out to exemplify the applications of the proposed framework and its\nmethodology. Results show that by properly formulating and implementing each\nstep, the hierarchical supervision framework is capable of promoting\ncoordination among agents while bounding administrative cost to a minimum in\ndifferent kinds of organizational control problems.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 08:58:16 GMT"}], "update_date": "2018-11-12", "authors_parsed": [["Yu", "Chao", ""]]}, {"id": "1811.04786", "submitter": "Brandon Fain", "authors": "Brandon Fain, Ashish Goel, Kamesh Munagala, Nina Prabhu", "title": "Random Dictators with a Random Referee: Constant Sample Complexity\n  Mechanisms for Social Choice", "comments": "Conference version Published in AAAI 2019\n  (https://aaai.org/Conferences/AAAI-19/)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study social choice mechanisms in an implicit utilitarian framework with a\nmetric constraint, where the goal is to minimize \\textit{Distortion}, the worst\ncase social cost of an ordinal mechanism relative to underlying cardinal\nutilities. We consider two additional desiderata: Constant sample complexity\nand Squared Distortion. Constant sample complexity means that the mechanism\n(potentially randomized) only uses a constant number of ordinal queries\nregardless of the number of voters and alternatives. Squared Distortion is a\nmeasure of variance of the Distortion of a randomized mechanism.\n  Our primary contribution is the first social choice mechanism with constant\nsample complexity \\textit{and} constant Squared Distortion (which also implies\nconstant Distortion). We call the mechanism Random Referee, because it uses a\nrandom agent to compare two alternatives that are the favorites of two other\nrandom agents. We prove that the use of a comparison query is necessary: no\nmechanism that only elicits the top-k preferred alternatives of voters (for\nconstant k) can have Squared Distortion that is sublinear in the number of\nalternatives. We also prove that unlike any top-k only mechanism, the\nDistortion of Random Referee meaningfully improves on benign metric spaces,\nusing the Euclidean plane as a canonical example. Finally, among top-1 only\nmechanisms, we introduce Random Oligarchy. The mechanism asks just 3 queries\nand is essentially optimal among the class of such mechanisms with respect to\nDistortion.\n  In summary, we demonstrate the surprising power of constant sample complexity\nmechanisms generally, and just three random voters in particular, to provide\nsome of the best known results in the implicit utilitarian framework.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2018 15:26:22 GMT"}, {"version": "v2", "created": "Tue, 13 Nov 2018 15:20:44 GMT"}, {"version": "v3", "created": "Wed, 1 Jul 2020 21:10:11 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Fain", "Brandon", ""], ["Goel", "Ashish", ""], ["Munagala", "Kamesh", ""], ["Prabhu", "Nina", ""]]}, {"id": "1811.05053", "submitter": "Alireza Shamsoshoara", "authors": "Alireza Shamsoshoara, Mehrdad Khaledi, Fatemeh Afghah, Abolfazl Razi,\n  Jonathan Ashdown", "title": "Distributed Cooperative Spectrum Sharing in UAV Networks Using\n  Multi-Agent Reinforcement Learning", "comments": "16 Pages, 8 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop a distributed mechanism for spectrum sharing among\na network of unmanned aerial vehicles (UAV) and licensed terrestrial networks.\nThis method can provide a practical solution for situations where the UAV\nnetwork may need external spectrum when dealing with congested spectrum or need\nto change its operating frequency due to security threats. Here we study a\nscenario where the UAV network performs a remote sensing mission. In this\nmodel, the UAVs are categorized into two clusters of relaying and sensing UAVs.\nThe relay UAVs provide a relaying service for a licensed network to obtain\nspectrum access for the rest of UAVs that perform the sensing task. We develop\na distributed mechanism in which the UAVs locally decide whether they need to\nparticipate in relaying or sensing considering the fact that communications\namong UAVs may not be feasible or reliable. The UAVs learn the optimal task\nallocation using a distributed reinforcement learning algorithm. Convergence of\nthe algorithm is discussed and simulation results are presented for different\nscenarios to verify the convergence.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 00:13:24 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Shamsoshoara", "Alireza", ""], ["Khaledi", "Mehrdad", ""], ["Afghah", "Fatemeh", ""], ["Razi", "Abolfazl", ""], ["Ashdown", "Jonathan", ""]]}, {"id": "1811.05438", "submitter": "Zack Fitzsimmons", "authors": "Zack Fitzsimmons, Edith Hemaspaandra, Alexander Hoover, David E.\n  Narv\\'aez", "title": "Very Hard Electoral Control Problems", "comments": "A version of this paper will appear in the Proceedings of AAAI-2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is important to understand how the outcome of an election can be modified\nby an agent with control over the structure of the election. Electoral control\nhas been studied for many election systems, but for all studied systems the\nwinner problem is in P, and so control is in NP. There are election systems,\nsuch as Kemeny, that have many desirable properties, but whose winner problems\nare not in NP. Thus for such systems control is not in NP, and in fact we show\nthat it is typically complete for $\\Sigma_2^p$ (i.e., ${\\rm NP}^{\\rm NP}$, the\nsecond level of the polynomial hierarchy). This is a very high level of\ncomplexity. Approaches that perform quite well for solving NP problems do not\nnecessarily work for $\\Sigma_2^p$-complete problems. However, answer set\nprogramming is suited to express problems in $\\Sigma_2^p$, and we present an\nencoding for Kemeny control.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 18:04:53 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Fitzsimmons", "Zack", ""], ["Hemaspaandra", "Edith", ""], ["Hoover", "Alexander", ""], ["Narv\u00e1ez", "David E.", ""]]}, {"id": "1811.05624", "submitter": "Wen Shen", "authors": "Wen Shen, Yang Feng and Cristina V. Lopes", "title": "Multi-Winner Contests for Strategic Diffusion in Social Networks", "comments": "9 pages, 6 figures, In Proceedings of The Thirty-Third AAAI\n  Conference on Artificial Intelligence (AAAI-19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.MA", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Strategic diffusion encourages participants to take active roles in promoting\nstakeholders' agendas by rewarding successful referrals. As social media\ncontinues to transform the way people communicate, strategic diffusion has\nbecome a powerful tool for stakeholders to influence people's decisions or\nbehaviors for desired objectives. Existing reward mechanisms for strategic\ndiffusion are usually either vulnerable to false-name attacks or not\nindividually rational for participants that have made successful referrals.\nHere, we introduce a novel multi-winner contests (MWC) mechanism for strategic\ndiffusion in social networks. The MWC mechanism satisfies several desirable\nproperties, including false-name-proofness, individual rationality, budget\nconstraint, monotonicity, and subgraph constraint. Numerical experiments on\nfour real-world social network datasets demonstrate that stakeholders can\nsignificantly boost participants' aggregated efforts with proper design of\ncompetitions. Our work sheds light on how to design manipulation-resistant\nmechanisms with appropriate contests.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2018 03:40:15 GMT"}, {"version": "v2", "created": "Mon, 11 Mar 2019 00:47:42 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Shen", "Wen", ""], ["Feng", "Yang", ""], ["Lopes", "Cristina V.", ""]]}, {"id": "1811.05931", "submitter": "Jane Wang", "authors": "Jane X. Wang, Edward Hughes, Chrisantha Fernando, Wojciech M.\n  Czarnecki, Edgar A. Duenez-Guzman, Joel Z. Leibo", "title": "Evolving intrinsic motivations for altruistic behavior", "comments": "10 pages, 6 figures. In Proc. of the 18th International Conference on\n  Autonomous Agents and Multiagent Systems (AAMAS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-agent cooperation is an important feature of the natural world. Many\ntasks involve individual incentives that are misaligned with the common good,\nyet a wide range of organisms from bacteria to insects and humans are able to\novercome their differences and collaborate. Therefore, the emergence of\ncooperative behavior amongst self-interested individuals is an important\nquestion for the fields of multi-agent reinforcement learning (MARL) and\nevolutionary theory. Here, we study a particular class of multi-agent problems\ncalled intertemporal social dilemmas (ISDs), where the conflict between the\nindividual and the group is particularly sharp. By combining MARL with\nappropriately structured natural selection, we demonstrate that individual\ninductive biases for cooperation can be learned in a model-free way. To achieve\nthis, we introduce an innovative modular architecture for deep reinforcement\nlearning agents which supports multi-level selection. We present results in two\nchallenging environments, and interpret these in the context of cultural and\necological evolution.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2018 18:01:10 GMT"}, {"version": "v2", "created": "Mon, 11 Mar 2019 13:04:28 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Wang", "Jane X.", ""], ["Hughes", "Edward", ""], ["Fernando", "Chrisantha", ""], ["Czarnecki", "Wojciech M.", ""], ["Duenez-Guzman", "Edgar A.", ""], ["Leibo", "Joel Z.", ""]]}, {"id": "1811.06196", "submitter": "Vu Tran Phi", "authors": "Vu Phi Tran, Matthew Garratt and Ian R.Petersen", "title": "Distributed Obstacle and Multi-Robot Collision Avoidance in Uncertain\n  Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper tackles the distributed leader-follower (L-F) control problem for\nheterogeneous mobile robots in unknown environments requiring obstacle\navoidance, inter-robot collision avoidance, and reliable robot communications.\nTo prevent an inter-robot collision, we employ a virtual propulsive force\nbetween robots. For obstacle avoidance, we present a novel distributed\nNegative-Imaginary (NI) variant formation tracking control approach and a\ndynamic network topology methodology which allows the formation to change its\nshape and the robot to switch their roles. In the case of communication or\nsensor loss, a UAV, controlled by a Strictly-Negative-Imaginary (SNI)\ncontroller with good wind resistance characteristics, is utilized to track the\nposition of the UGV formation using its camera. Simulations and indoor\nexperiments have been conducted to validate the proposed methods.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 06:22:27 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Tran", "Vu Phi", ""], ["Garratt", "Matthew", ""], ["Petersen", "Ian R.", ""]]}, {"id": "1811.06206", "submitter": "Vu Tran Phi", "authors": "Vu Phi Tran, Matthew Garratt and Ian R.Petersen", "title": "Time-Varying Formation Control of a Collaborative Multi-Agent System\n  Using Negative-Imaginary Systems Theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The movement of cooperative robots in a densely cluttered environment may not\nbe possible if the formation type is invariant. Hence, we investigate a new\nmethod for time-varying formation control for a group of heterogeneous\nautonomous vehicles, which may include Unmanned Ground Vehicles (UGV) and\nUnmanned Aerial Vehicles (UAV). We have extended a Negative-Imaginary (NI)\nconsensus control approach to switch the formation shape of the robots whilst\nonly using the relative distance between agents and between agents and\nobstacles. All agents can automatically create a new safe formation to overcome\nobstacles based on a novel geometric method, then restore the prototype\nformation once the obstacles are cleared. Furthermore, we improve the position\nconsensus at sharp corners by achieving yaw consensus between robots.\nSimulation and experimental results are then analyzed to validate the\nfeasibility of our proposed approach.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 06:54:41 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Tran", "Vu Phi", ""], ["Garratt", "Matthew", ""], ["Petersen", "Ian R.", ""]]}, {"id": "1811.06350", "submitter": "Zhiyong Sun", "authors": "Marcus Greiff, Zhiyong Sun, Anders Robertsson and Rolf Johansson", "title": "Temporal viability regulation for control affine systems with\n  applications to mobile vehicle coordination under time-varying motion\n  constraints", "comments": "7 pages, 3 figures. Submitted to a conference for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.MA cs.RO cs.SC math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Controlled invariant set and viability regulation of dynamical control\nsystems have played important roles in many control and coordination\napplications. In this paper we develop a temporal viability regulation theory\nfor general dynamical control systems, and in particular for control affine\nsystems. The time-varying viable set is parameterized by time-varying\nconstraint functions, with the aim to regulate a dynamical control system to be\ninvariant in the time-varying viable set so that temporal state-dependent\nconstraints are enforced. We consider both time-varying equality and inequality\nconstraints in defining a temporal viable set. We also present sufficient\nconditions for the existence of feasible control input for the control affine\nsystems. The developed temporal viability regulation theory is applied to\nmobile vehicle coordination.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 14:03:33 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Greiff", "Marcus", ""], ["Sun", "Zhiyong", ""], ["Robertsson", "Anders", ""], ["Johansson", "Rolf", ""]]}, {"id": "1811.06355", "submitter": "Thierry Moyaux", "authors": "Thierry Moyaux (DISP), Eric Marcon (LASPI)", "title": "Cost of selfishness in the allocation of cities in the Multiple\n  Travelling Salesmen Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The decision to centralise or decentralise human organisations requires\nquantified evidence but little is available in the literature. We provide such\ndata in a variant of the Multiple Travelling Salesmen Problem (MTSP) in which\nwe study how the allocation sub-problem may be decentralised among selfish\nselfmen. Our contributions are (i) this modification of the MTSP in order to\ninclude selfishness, (ii) the proposition of organisations to solve this\nmodified MTSP, and (iii) the comparison of these organisations. Our 5\norganisations may be summarised as follows: (i) OptDecentr is a pure\nCentralised Organisation (CO) in which a Central Authority (CA) finds the best\nsolution which could be found by a Decentralised Organisation (DO), (ii)\nCluster and (iii) Auction are CO/DO hybrids, and (iv) P2P and (v) CNP are pure\nDO. Sixth and seventh organisations are used as benchmarks: (vi) NoRealloc is a\npure DO which ignores the allocation problem, and (vii) FullCentr is a pure CO\nwhich solves a different problem, viz., the traditional MTSP. Comparing the\nefficiency of pairs of these mechanisms quantify the price of decentralising an\norganisation. In particular, our model of selfishness in OptDecentr makes the\ntotal route length 30% (respectively, 60%) longer with 5 (respectively, 9)\nsalesmen than the traditional MTSP in FullCentr when the computation time is\nlimited to 30 minutes. With this time limit, our results also seem to indicate\nthat the level of coercion of the CA impacts more the total route length than\nthe level of centralisation.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 14:06:50 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Moyaux", "Thierry", "", "DISP"], ["Marcon", "Eric", "", "LASPI"]]}, {"id": "1811.06503", "submitter": "Anup Aprem", "authors": "Anup Aprem, Stephen J. Roberts", "title": "A Bayesian optimization approach to compute the Nash equilibria of\n  potential games using bandit feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computing Nash equilibria for strategic multi-agent systems is challenging\nfor expensive black box systems. Motivated by the ubiquity of games involving\nexploitation of common resources, this paper considers the above problem for\npotential games. We use the Bayesian optimization framework to obtain novel\nalgorithms to solve finite (discrete action spaces) and infinite (real interval\naction spaces) potential games, utilizing the structure of potential games.\nNumerical results illustrate the efficiency of the approach in computing the\nNash equilibria of static potential games and linear Nash equilibria of dynamic\npotential games.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 18:00:09 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Aprem", "Anup", ""], ["Roberts", "Stephen J.", ""]]}, {"id": "1811.07029", "submitter": "Hangyu Mao", "authors": "Hangyu Mao, Zhengchao Zhang, Zhen Xiao, and Zhibo Gong", "title": "Modelling the Dynamic Joint Policy of Teammates with Attention\n  Multi-agent DDPG", "comments": "Attention-based Multi-agent DDPG. Experimental results show that it\n  not only outperforms the state-of-the-art RL-based methods and rule-based\n  methods by a large margin, but also achieves better performance in terms of\n  scalability and robustness", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Modelling and exploiting teammates' policies in cooperative multi-agent\nsystems have long been an interest and also a big challenge for the\nreinforcement learning (RL) community. The interest lies in the fact that if\nthe agent knows the teammates' policies, it can adjust its own policy\naccordingly to arrive at proper cooperations; while the challenge is that the\nagents' policies are changing continuously due to they are learning\nconcurrently, which imposes difficulty to model the dynamic policies of\nteammates accurately. In this paper, we present \\emph{ATTention Multi-Agent\nDeep Deterministic Policy Gradient} (ATT-MADDPG) to address this challenge.\nATT-MADDPG extends DDPG, a single-agent actor-critic RL method, with two\nspecial designs. First, in order to model the teammates' policies, the agent\nshould get access to the observations and actions of teammates. ATT-MADDPG\nadopts a centralized critic to collect such information. Second, to model the\nteammates' policies using the collected information in an effective way,\nATT-MADDPG enhances the centralized critic with an attention mechanism. This\nattention mechanism introduces a special structure to explicitly model the\ndynamic joint policy of teammates, making sure that the collected information\ncan be processed efficiently. We evaluate ATT-MADDPG on both benchmark tasks\nand the real-world packet routing tasks. Experimental results show that it not\nonly outperforms the state-of-the-art RL-based methods and rule-based methods\nby a large margin, but also achieves better performance in terms of scalability\nand robustness.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 11:30:29 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Mao", "Hangyu", ""], ["Zhang", "Zhengchao", ""], ["Xiao", "Zhen", ""], ["Gong", "Zhibo", ""]]}, {"id": "1811.07229", "submitter": "Giacomo Vaccario Dr.", "authors": "Giacomo Vaccario, Luca Verginer and Frank Schweitzer", "title": "Reproducing scientists' mobility: A data-driven model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High skill labour is an important factor underpinning the competitive\nadvantage of modern economies. Therefore, attracting and retaining scientists\nhas become a major concern for migration policy. In this work, we study the\nmigration of scientists on a global scale, by combining two large data sets\ncovering the publications of 3.5 Mio scientists over 60 years. We analyse their\ngeographical distances moved for a new affiliation and their age when moving,\nthis way reconstructing their geographical \"career paths\". These paths are used\nto derive the world network of scientists mobility between cities and to\nanalyse its topological properties. We further develop and calibrate an\nagent-based model, such that it reproduces the empirical findings both at the\nlevel of scientists and of the global network. Our model takes into account\nthat the academic hiring process is largely demand-driven and demonstrates that\nthe probability of scientists to relocate decreases both with age and with\ndistance. Our results allow interpreting the model assumptions as micro-based\ndecision rules that can explain the observed mobility patterns of scientists.\n", "versions": [{"version": "v1", "created": "Sat, 17 Nov 2018 21:56:30 GMT"}, {"version": "v2", "created": "Tue, 27 Nov 2018 10:44:18 GMT"}, {"version": "v3", "created": "Fri, 23 Oct 2020 13:42:40 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Vaccario", "Giacomo", ""], ["Verginer", "Luca", ""], ["Schweitzer", "Frank", ""]]}, {"id": "1811.07569", "submitter": "Filippo Fabiani", "authors": "Filippo Fabiani and Andrea Caiti", "title": "Nash equilibrium seeking in potential games with double-integrator\n  agents", "comments": "6 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.GT cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we show the equivalence between a constrained, multi-agent\ncontrol problem, modeled within the port-Hamiltonian framework, and an exact\npotential game. Specifically, critical distance-based constraints determine a\nnetwork of double-integrator agents, which can be represented as a graph.\nVirtual couplings, i.e., pairs of spring-damper, assigned to each edge of the\ngraph, allow to synthesize a distributed, gradient-based control law that\nsteers the network to an invariant set of stable configurations. We\ncharacterize the points belonging to such set as Nash equilibria of the\nassociated potential game, relating the parameters of the virtual couplings\nwith the equilibrium seeking problem, since they are crucial to shape the\ntransient behaviour (i.e., the convergence) and, ideally, the set of reachable\nequilibria.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 09:29:20 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Fabiani", "Filippo", ""], ["Caiti", "Andrea", ""]]}, {"id": "1811.07799", "submitter": "Kaiqing Zhang", "authors": "Kaiqing Zhang, Yang Liu, Ji Liu, Mingyan Liu, Tamer Ba\\c{s}ar", "title": "Distributed Learning of Average Belief Over Networks Using Sequential\n  Observations", "comments": "Accepted to Automatica", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of distributed learning of average belief\nwith sequential observations, in which a network of $n>1$ agents aim to reach a\nconsensus on the average value of their beliefs, by exchanging information only\nwith their neighbors. Each agent has sequentially arriving samples of its\nbelief in an online manner. The neighbor relationships among the $n$ agents are\ndescribed by a graph which is possibly time-varying, whose vertices correspond\nto agents and whose edges depict neighbor relationships. Two distributed online\nalgorithms are introduced for undirected and directed graphs, which are both\nshown to converge to the average belief almost surely. Moreover, the sequences\ngenerated by both algorithms are shown to reach consensus with an $O(1/t)$ rate\nwith high probability, where $t$ is the number of iterations. For undirected\ngraphs, the corresponding algorithm is modified for the case with quantized\ncommunication and limited precision of the division operation. It is shown that\nthe modified algorithm causes all $n$ agents to either reach a quantized\nconsensus or enter a small neighborhood around the average of their beliefs.\nNumerical simulations are then provided to corroborate the theoretical results.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 16:55:30 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Zhang", "Kaiqing", ""], ["Liu", "Yang", ""], ["Liu", "Ji", ""], ["Liu", "Mingyan", ""], ["Ba\u015far", "Tamer", ""]]}, {"id": "1811.08225", "submitter": "Danilo Vasconcellos  Vargas", "authors": "Danilo Vasconcellos Vargas and Hirotaka Takano and Junichi Murata", "title": "Self Organizing Classifiers: First Steps in Structured Evolutionary\n  Machine Learning", "comments": null, "journal-ref": "Evolutionary Intelligence 6 (2), 57-72 (2013)", "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning classifier systems (LCSs) are evolutionary machine learning\nalgorithms, flexible enough to be applied to reinforcement, supervised and\nunsupervised learning problems with good performance. Recently, self organizing\nclassifiers were proposed which are similar to LCSs but have the advantage that\nin its structured population no balance between niching and fitness pressure is\nnecessary. However, more tests and analysis are required to verify its\nbenefits. Here, a variation of the first algorithm is proposed which uses a\nparameterless self organizing map (SOM). This algorithm is applied in\nchallenging problems such as big, noisy as well as dynamically changing\ncontinuous input-action mazes (growing and compressing mazes are included) with\ngood performance. Moreover, a genetic operator is proposed which utilizes the\ntopological information of the SOM's population structure, improving the\nresults. Thus, the first steps in structured evolutionary machine learning are\nshown, nonetheless, the problems faced are more difficult than the state-of-art\ncontinuous input-action multi-step ones.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 13:00:51 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Vargas", "Danilo Vasconcellos", ""], ["Takano", "Hirotaka", ""], ["Murata", "Junichi", ""]]}, {"id": "1811.08226", "submitter": "Danilo Vasconcellos  Vargas", "authors": "Danilo Vasconcellos Vargas and Hirotaka Takano and Junichi Murata", "title": "Self Organizing Classifiers and Niched Fitness", "comments": "arXiv admin note: text overlap with arXiv:1811.08225", "journal-ref": "Proceedings of the 15th annual conference on Genetic and\n  evolutionary computation (GECCO 2013)", "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning classifier systems are adaptive learning systems which have been\nwidely applied in a multitude of application domains. However, there are still\nsome generalization problems unsolved. The hurdle is that fitness and niching\npressures are difficult to balance. Here, a new algorithm called Self\nOrganizing Classifiers is proposed which faces this problem from a different\nperspective. Instead of balancing the pressures, both pressures are separated\nand no balance is necessary. In fact, the proposed algorithm possesses a\ndynamical population structure that self-organizes itself to better project the\ninput space into a map. The niched fitness concept is defined along with its\ndynamical population structure, both are indispensable for the understanding of\nthe proposed method. Promising results are shown on two continuous multi-step\nproblems. One of which is yet more challenging than previous problems of this\nclass in the literature.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 13:01:29 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Vargas", "Danilo Vasconcellos", ""], ["Takano", "Hirotaka", ""], ["Murata", "Junichi", ""]]}, {"id": "1811.08469", "submitter": "Alistair Letcher", "authors": "Alistair Letcher, Jakob Foerster, David Balduzzi, Tim Rockt\\\"aschel,\n  Shimon Whiteson", "title": "Stable Opponent Shaping in Differentiable Games", "comments": "20 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A growing number of learning methods are actually differentiable games whose\nplayers optimise multiple, interdependent objectives in parallel -- from GANs\nand intrinsic curiosity to multi-agent RL. Opponent shaping is a powerful\napproach to improve learning dynamics in these games, accounting for player\ninfluence on others' updates. Learning with Opponent-Learning Awareness (LOLA)\nis a recent algorithm that exploits this response and leads to cooperation in\nsettings like the Iterated Prisoner's Dilemma. Although experimentally\nsuccessful, we show that LOLA agents can exhibit 'arrogant' behaviour directly\nat odds with convergence. In fact, remarkably few algorithms have theoretical\nguarantees applying across all (n-player, non-convex) games. In this paper we\npresent Stable Opponent Shaping (SOS), a new method that interpolates between\nLOLA and a stable variant named LookAhead. We prove that LookAhead converges\nlocally to equilibria and avoids strict saddles in all differentiable games.\nSOS inherits these essential guarantees, while also shaping the learning of\nopponents and consistently either matching or outperforming LOLA\nexperimentally.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 20:06:37 GMT"}, {"version": "v2", "created": "Sun, 27 Jan 2019 15:56:30 GMT"}, {"version": "v3", "created": "Sun, 17 Jan 2021 09:21:26 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Letcher", "Alistair", ""], ["Foerster", "Jakob", ""], ["Balduzzi", "David", ""], ["Rockt\u00e4schel", "Tim", ""], ["Whiteson", "Shimon", ""]]}, {"id": "1811.08614", "submitter": "Jiajun Xu", "authors": "Jiajun Xu, Sam Huang", "title": "Tetris", "comments": "22 pages, 3 figures. arXiv admin note: text overlap with\n  arXiv:cs/0006009 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tetris is an Asynchronous Byzantine Fault Tolerance consensus algorithm\ndesigned for next generation high-throughput permission and permissionless\nblockchain. The core concept of Tetris is derived from Reasoning About\nKnowledge, which we believe to be the most appropriate tools for revealing and\nanalyzing the fundamental complexity of distributed systems. By analyzing the\nstates of knowledge that each participant attained in an unreliable system, we\ncan capture some of the basis underlying structure of the system, then help us\ndesigning effective & efficient protocols. Plus the adoption of Full\nInformation Protocol (FIP) with the optimized message traffic model, Tetris has\nfinally got high performance, with proved safety. Tetris achieve consensus\nfinality in seconds, means transactions can be confirmed greatly faster than\nother scheme like Pow/Dpos. Tetris also achieve fairness, which is critically\nimportant in some areas such as stock market etc.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2018 07:23:58 GMT"}, {"version": "v2", "created": "Fri, 7 Dec 2018 06:32:48 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Xu", "Jiajun", ""], ["Huang", "Sam", ""]]}, {"id": "1811.09306", "submitter": "Pavel Chebotarev", "authors": "Sergei Parsegov and Pavel Chebotarev", "title": "Second-Order Agents on Ring Digraphs", "comments": "6 pages, 10 figures", "journal-ref": "Proceedings of the 22nd International Conference on System Theory,\n  Control, and Computing (ICSTCC 2018, Sinaia, Romania). Sinaia, Romania: IEEE,\n  2018. P. 609-614", "doi": "10.1109/ICSTCC.2018.8540656", "report-no": null, "categories": "cs.MA cs.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper addresses the problem of consensus seeking among second-order\nlinear agents interconnected in a specific ring topology. Unlike the existing\nresults in the field dealing with one-directional digraphs arising in various\ncyclic pursuit algorithms or two-directional graphs, we focus on the case where\nsome arcs in a two-directional ring graph are dropped in a regular fashion. The\nderived condition for achieving consensus turns out to be independent of the\nnumber of agents in a network.\n", "versions": [{"version": "v1", "created": "Thu, 22 Nov 2018 21:04:52 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Parsegov", "Sergei", ""], ["Chebotarev", "Pavel", ""]]}, {"id": "1811.09414", "submitter": "Aniq Ur Rahman", "authors": "Aniq Ur Rahman, Agnivesh Adhikari", "title": "Feedback based Mobility Control Algorithm for Maximizing Node Coverage\n  by Drone Base Stations", "comments": "4 pages, 8 figures. Was accepted at ICUFN 2018 but later withdrawn\n  due to financial issues", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.NI cs.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Drone base stations (DBSs) have recently gained wide popularity as a possible\nsolution to provide wireless connectivity in a variety of scenarios, for\nexample, in inaccessible terrains such as connectivity over vast areas of a\nwater body or in rural areas where the physical deployment of base stations is\nnot feasible at the moment, also in the case of terrestrial infrastructure\nfailure where DBSs can be rapidly deployed to re-establish communication\nchannel. In this paper we propose an algorithm for controlling the motion of\nthe DBSs which maximizes the number of DBS to mobile ground node connections.\nThe overlap extent between the drones is limited to reduce the count of\nredundant connections. The overall approach aims at minimizing the number of\ndrones required to be deployed in a given region by maximizing connectivity per\ndrone.\n", "versions": [{"version": "v1", "created": "Fri, 23 Nov 2018 10:12:48 GMT"}, {"version": "v2", "created": "Sat, 19 Dec 2020 06:45:14 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Rahman", "Aniq Ur", ""], ["Adhikari", "Agnivesh", ""]]}, {"id": "1811.09759", "submitter": "Minhae Kwon", "authors": "Minhae Kwon and Juhyeon Lee and Hyunggon Park", "title": "Learning to Activate Relay Nodes: Deep Reinforcement Learning Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a distributed solution to design a multi-hop ad hoc\nnetwork where mobile relay nodes strategically determine their wireless\ntransmission ranges based on a deep reinforcement learning approach. We\nconsider scenarios where only a limited networking infrastructure is available\nbut a large number of wireless mobile relay nodes are deployed in building a\nmulti-hop ad hoc network to deliver source data to the destination. A mobile\nrelay node is considered as a decision-making agent that strategically\ndetermines its transmission range in a way that maximizes network throughput\nwhile minimizing the corresponding transmission power consumption. Each relay\nnode collects information from its partial observations and learns its\nenvironment through a sequence of experiences. Hence, the proposed solution\nrequires only a minimal amount of information from the system. We show that the\nactions that the relay nodes take from its policy are determined as to activate\nor inactivate its transmission, i.e., only necessary relay nodes are activated\nwith the maximum transmit power, and nonessential nodes are deactivated to\nminimize power consumption. Using extensive experiments, we confirm that the\nproposed solution builds a network with higher network performance than current\nstate-of-the-art solutions in terms of system goodput and connectivity ratio.\n", "versions": [{"version": "v1", "created": "Sat, 24 Nov 2018 04:02:55 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Kwon", "Minhae", ""], ["Lee", "Juhyeon", ""], ["Park", "Hyunggon", ""]]}, {"id": "1811.09914", "submitter": "Aaron Huang", "authors": "Aaron Huang, Benjamin J. Ayton, Brian C. Williams", "title": "RADMPC: A Fast Decentralized Approach for Chance-Constrained\n  Multi-Vehicle Path-Planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.AI cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust multi-vehicle path-planning is important for ensuring the safety of\nmulti-vehicle systems in applications like transportation, search and rescue,\nand robotic exploration. Chance-constrained methods like Iterative Risk\nAllocation (IRA)\\cite{IRA} have been developed for situations where\nenvironmental disturbances are unbounded. However, chance-constrained methods\nfor the multi-vehicle case generally use centralized strategies where the\nvehicle set is planned with couplings between all vehicle pairs. This approach\nis intractable as fleet size increases because computation time is exponential\nwith respect to the number of vehicles being planned over due to a polynomial\nincrease in coupling constraints between vehicle pairs. We present a faster\napproach for chance-constrained multi-vehicle path-planning that relies upon a\ndecentralized path-planning method called Risk-Aware Decentralized Model\nPredictive Control (RADMPC) to rapidly approximate a centralized IRA approach.\nThe RADMPC approximation is evaluated for vehicle interactions to determine the\nvehicle sets that should be planned in a coupled manner. Applying IRA to the\nsmaller vehicle sets determined from the RADMPC approximation rapidly plans\nsafe paths for the entire fleet. A Monte Carlo simulation analysis demonstrates\nthe correctness of our approach and a significant improvement in computation\ntime compared to a centralized IRA approach.\n", "versions": [{"version": "v1", "created": "Sun, 25 Nov 2018 00:43:32 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Huang", "Aaron", ""], ["Ayton", "Benjamin J.", ""], ["Williams", "Brian C.", ""]]}, {"id": "1811.10114", "submitter": "Matjaz Perc", "authors": "Marcos Cardinot, Josephine Griffith, Colm O'Riordan, Matjaz Perc", "title": "Cooperation in the spatial prisoner's dilemma game with probabilistic\n  abstention", "comments": "7 pages, 4 figures; published in Scientific Reports", "journal-ref": "Sci. Rep. 8, 14531 (2018)", "doi": "10.1038/s41598-018-32933-x", "report-no": null, "categories": "cs.GT cs.MA cs.NE physics.data-an physics.soc-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Research has shown that the addition of abstention as an option transforms\nsocial dilemmas to rock-paper-scissor type games, where defectors dominate\ncooperators, cooperators dominate abstainers (loners), and abstainers (loners),\nin turn, dominate defectors. In this way, abstention can sustain cooperation\neven under adverse conditions, although defection also persists due to cyclic\ndominance. However, to abstain or to act as a loner has, to date, always been\nconsidered as an independent, third strategy to complement traditional\ncooperation and defection. Here we consider probabilistic abstention, where\neach player is assigned a probability to abstain in a particular instance of\nthe game. In the two limiting cases, the studied game reverts to the prisoner's\ndilemma game without loners or to the optional prisoner's dilemma game. For\nintermediate probabilities, we have a new hybrid game, which turns out to be\nmost favorable for the successful evolution of cooperation. We hope this novel\nhybrid game provides a more realistic view of the dilemma of optional/voluntary\nparticipation.\n", "versions": [{"version": "v1", "created": "Sun, 25 Nov 2018 23:19:07 GMT"}, {"version": "v2", "created": "Mon, 10 Dec 2018 21:10:50 GMT"}], "update_date": "2018-12-12", "authors_parsed": [["Cardinot", "Marcos", ""], ["Griffith", "Josephine", ""], ["O'Riordan", "Colm", ""], ["Perc", "Matjaz", ""]]}, {"id": "1811.10116", "submitter": "Marcos Cardinot", "authors": "Marcos Cardinot, Colm O'Riordan, Josephine Griffith, Matja\\v{z} Perc", "title": "Evoplex: A platform for agent-based modeling on networks", "comments": "6 pages, 5 figures; accepted for publication in SoftwareX [software\n  available at https://evoplex.org]", "journal-ref": "SoftwareX 9, 199-204 (2019)", "doi": "10.1016/j.softx.2019.02.009", "report-no": null, "categories": "cs.MA cs.NE physics.soc-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Agent-based modeling and network science have been used extensively to\nadvance our understanding of emergent collective behavior in systems that are\ncomposed of a large number of simple interacting individuals or agents. With\nthe increasing availability of high computational power in affordable personal\ncomputers, dedicated efforts to develop multi-threaded, scalable and\neasy-to-use software for agent-based simulations are needed more than ever.\nEvoplex meets this need by providing a fast, robust and extensible platform for\ndeveloping agent-based models and multi-agent systems on networks. Each agent\nis represented as a node and interacts with its neighbors, as defined by the\nnetwork structure. Evoplex is ideal for modeling complex systems, for example\nin evolutionary game theory and computational social science. In Evoplex, the\nmodels are not coupled to the execution parameters or the visualization tools,\nand there is a user-friendly graphical interface which makes it easy for all\nusers, ranging from newcomers to experienced, to create, analyze, replicate and\nreproduce the experiments.\n", "versions": [{"version": "v1", "created": "Sun, 25 Nov 2018 23:32:48 GMT"}, {"version": "v2", "created": "Tue, 12 Mar 2019 21:00:16 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Cardinot", "Marcos", ""], ["O'Riordan", "Colm", ""], ["Griffith", "Josephine", ""], ["Perc", "Matja\u017e", ""]]}, {"id": "1811.10430", "submitter": "Pavel Chebotarev", "authors": "Rafig Agaev and Pavel Chebotarev", "title": "Two Models of Latent Consensus in Multi-Agent Systems", "comments": "arXiv admin note: substantial text overlap with arXiv:1612.05201", "journal-ref": "Proceedings of The 6th International Conference on Control and\n  Optimization with Industrial Applications (Baku, Azerbaijan, 2018). Baku:\n  Malumat Hesablama Markazi, 2018. V.1. P.26-28", "doi": null, "report-no": null, "categories": "math.OC cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose several consensus protocols of the first and second\norder for networked multi-agent systems and provide explicit representations\nfor their asymptotic states. These representations involve the eigenprojection\nof the Laplacian matrix of the dependency digraph. In particular, we study\nregularization models for the problem of coordination when the dependency\ndigraph does not contain a converging tree. In such models of the first kind,\nthe system is supplemented by a dummy agent, a \"hub\" that uniformly, but very\nweakly influences the agents and, in turn, depends on them. In the models of\nthe second kind, we assume the presence of very weak background links between\nthe agents. Besides that, we present a description of the asymptotics of the\nclassical second-order consensus protocol.\n", "versions": [{"version": "v1", "created": "Fri, 23 Nov 2018 05:38:31 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Agaev", "Rafig", ""], ["Chebotarev", "Pavel", ""]]}, {"id": "1811.10431", "submitter": "Liane Gabora", "authors": "Liane Gabora and Cameron M. Smith", "title": "Two Cognitive Transitions Underlying the Capacity for Cultural Evolution", "comments": "31 pages, 4 figures, 3 tables. arXiv admin note: text overlap with\n  arXiv:1310.4086", "journal-ref": "Journal of Anthropological Sciences, 96, 1-26 (2018)", "doi": "10.4436/jass.96008", "report-no": null, "categories": "q-bio.NC cs.MA q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes that the distinctively human capacity for cumulative,\nadaptive, open-ended cultural evolution came about through two\ntemporally-distinct cognitive transitions. First, the origin of Homo-specific\nculture over two MYA was made possible by the onset of a finer-grained\nassociative memory that allowed episodes to be encoded in greater detail. This\nin turn meant more overlap amongst the distributed representations of these\nepisodes, such that they could more readily evoke one another through\nself-triggered recall (STR). STR enabled representational redescription, the\nchaining of thoughts and actions, and the capacity for a stream of thought.\nSecond, fully cognitive modernity following the appearance of anatomical\nmodernity after 200,000 BP, was made possible by the onset of contextual focus\n(CF): the ability to shift between an explicit convergent mode conducive to\nlogic and refinement of ideas, and an implicit divergent mode conducive to\nfree-association, viewing situations from radically new perspectives, concept\ncombination, analogical thinking, and insight. This paved the way for an\nintegrated, creative internal network of understandings, and behavioral\nmodernity. We discuss feasible neural mechanisms for this two-stage proposal,\nand outline how STR and CF differ from other proposals. We provide\ncomputational evidence for the proposal obtained with an agent-based model of\ncultural evolution in which agents invent ideas for actions and imitate the\nfittest of their neighbors' actions. Mean fitness and diversity of actions\nacross the artificial society increased with STR, and even more so with CF, but\nCF was only effective if STR was already in place. CF was most effective\nfollowing a change in task, which supports its hypothesized role in escaping\nmental fixation. The proposal is discussed in the context of transition theory\nin the life sciences.\n", "versions": [{"version": "v1", "created": "Fri, 23 Nov 2018 06:11:50 GMT"}, {"version": "v2", "created": "Fri, 5 Jul 2019 22:02:14 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Gabora", "Liane", ""], ["Smith", "Cameron M.", ""]]}, {"id": "1811.10792", "submitter": "Mahmoud Assran", "authors": "Mahmoud Assran, Nicolas Loizou, Nicolas Ballas, Michael Rabbat", "title": "Stochastic Gradient Push for Distributed Deep Learning", "comments": "ICML 2019", "journal-ref": "International Conference on Machine Learning 97 (2019) 344-353", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC cs.MA math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed data-parallel algorithms aim to accelerate the training of deep\nneural networks by parallelizing the computation of large mini-batch gradient\nupdates across multiple nodes. Approaches that synchronize nodes using exact\ndistributed averaging (e.g., via AllReduce) are sensitive to stragglers and\ncommunication delays. The PushSum gossip algorithm is robust to these issues,\nbut only performs approximate distributed averaging. This paper studies\nStochastic Gradient Push (SGP), which combines PushSum with stochastic gradient\nupdates. We prove that SGP converges to a stationary point of smooth,\nnon-convex objectives at the same sub-linear rate as SGD, and that all nodes\nachieve consensus. We empirically validate the performance of SGP on image\nclassification (ResNet-50, ImageNet) and machine translation (Transformer,\nWMT'16 En-De) workloads. Our code will be made publicly available.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 03:47:26 GMT"}, {"version": "v2", "created": "Fri, 25 Jan 2019 02:58:36 GMT"}, {"version": "v3", "created": "Tue, 14 May 2019 19:59:00 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Assran", "Mahmoud", ""], ["Loizou", "Nicolas", ""], ["Ballas", "Nicolas", ""], ["Rabbat", "Michael", ""]]}, {"id": "1811.10827", "submitter": "Shashi Ranjan Kumar", "authors": "Dwaipayan Mukherjee and Shashi Ranjan Kumar", "title": "Finite-time Heterogeneous Cyclic Pursuit with Application to Target\n  Interception", "comments": "12 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a finite-time heterogeneous cyclic pursuit scheme that\nensures consensus among agents modelled as integrators. It is shown that for\nthe proposed sliding mode control, even when the gains corresponding to each\nagent are non-identical, consensus results within a finite-time provided all\nthe gains are positive. An algorithm is presented to compute the consensus\nvalue and consensus time for a given set of gains and initial states of the\nagents. The set of values where consensus can occur, by varying the gains, has\nbeen derived and a second algorithm aids in determining the gains that enable\nconsensus at any point in the aforementioned set, within a given finite-time.\nAs an application, the finite-time consensus in line-of-sight (LOS) rates, over\na cycle digraph, for a group of interceptors is shown to be effective in\nensuring co-operative collision-free interception of a target, for both\nkinematic and realistic models of the interceptors. Simulations vindicate the\ntheoretical results.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 06:11:30 GMT"}, {"version": "v2", "created": "Wed, 28 Nov 2018 11:55:02 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Mukherjee", "Dwaipayan", ""], ["Kumar", "Shashi Ranjan", ""]]}, {"id": "1811.10981", "submitter": "Rijk Mercuur", "authors": "Rijk Mercuur, Virginia Dignum, Catholijn M. Jonker", "title": "Modelling Agents Endowed with Social Practices: Static Aspects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To understand societal phenomena through simulation, we need computational\nvariants of socio-cognitive theories. Social Practice Theory has provided a\nunique understanding of social phenomena regarding the routinized, social and\ninterconnected aspects of behaviour. This paper provides the Social Practice\nAgent (SoPrA) model that enables the use of Social Practice Theory (SPT) for\nagent-based simulations. We extract requirements from SPT, construct a\ncomputational model in the Unified Modelling Language, verify its\nimplementation in Netlogo and Prot\\'eg\\'e and show how SoPrA maps on a use case\nof commuting. The next step is to model the dynamic aspect of SPT and validate\nSoPrA's ability to provide understanding in different scenario's. This paper\nprovides the groundwork with a computational model that is a correct depiction\nof SPT, computational feasible and can be directly mapped to the habitual,\nsocial and interconnected aspects of a target scenario.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 13:49:47 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Mercuur", "Rijk", ""], ["Dignum", "Virginia", ""], ["Jonker", "Catholijn M.", ""]]}, {"id": "1811.11197", "submitter": "Richard Garcia-Lebron", "authors": "Richard Garcia-Lebron, David J. Myers, Shouhuai Xu and Jie Sun", "title": "Node Diversification in Complex Networks by Decentralized Coloring", "comments": null, "journal-ref": "Journal of Complex Networks (2018)", "doi": "10.1093/comnet/cny031", "report-no": null, "categories": "cs.SI cs.CR cs.DS cs.MA physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a decentralized coloring approach to diversify the nodes in a\ncomplex network. The key is the introduction of a local conflict index that\nmeasures the color conflicts arising at each node which can be efficiently\ncomputed using only local information. We demonstrate via both synthetic and\nreal-world networks that the proposed approach significantly outperforms random\ncoloring as measured by the size of the largest color-induced connected\ncomponent. Interestingly, for scale-free networks further improvement of\ndiversity can be achieved by tuning a degree-biasing weighting parameter in the\nlocal conflict index.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 19:02:36 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Garcia-Lebron", "Richard", ""], ["Myers", "David J.", ""], ["Xu", "Shouhuai", ""], ["Sun", "Jie", ""]]}, {"id": "1811.12253", "submitter": "Anshuka Rangi", "authors": "Anshuka Rangi, Massimo Franceschetti and Long Tran-Thanh", "title": "Unifying the stochastic and the adversarial Bandits with Knapsack", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the adversarial Bandits with Knapsack (BwK) online\nlearning problem, where a player repeatedly chooses to perform an action, pays\nthe corresponding cost, and receives a reward associated with the action. The\nplayer is constrained by the maximum budget $B$ that can be spent to perform\nactions, and the rewards and the costs of the actions are assigned by an\nadversary. This problem has only been studied in the restricted setting where\nthe reward of an action is greater than the cost of the action, while we\nprovide a solution in the general setting. Namely, we propose EXP3.BwK, a novel\nalgorithm that achieves order optimal regret. We also propose EXP3++.BwK, which\nis order optimal in the adversarial BwK setup, and incurs an almost optimal\nexpected regret with an additional factor of $\\log(B)$ in the stochastic BwK\nsetup. Finally, we investigate the case of having large costs for the actions\n(i.e., they are comparable to the budget size $B$), and show that for the\nadversarial setting, achievable regret bounds can be significantly worse,\ncompared to the case of having costs bounded by a constant, which is a common\nassumption within the BwK literature.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 04:34:30 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Rangi", "Anshuka", ""], ["Franceschetti", "Massimo", ""], ["Tran-Thanh", "Long", ""]]}, {"id": "1811.12557", "submitter": "Tegg Sung", "authors": "Aleksandra Malysheva, Tegg Taekyong Sung, Chae-Bong Sohn, Daniel\n  Kudenko, Aleksei Shpilman", "title": "Deep Multi-Agent Reinforcement Learning with Relevance Graphs", "comments": "The first two authors contributed equally. Author ordering determined\n  by coin flip over a Google Hangout. Accepted at NIPS 2018 Deep RL Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over recent years, deep reinforcement learning has shown strong successes in\ncomplex single-agent tasks, and more recently this approach has also been\napplied to multi-agent domains. In this paper, we propose a novel approach,\ncalled MAGnet, to multi-agent reinforcement learning (MARL) that utilizes a\nrelevance graph representation of the environment obtained by a self-attention\nmechanism, and a message-generation technique inspired by the NerveNet\narchitecture. We applied our MAGnet approach to the Pommerman game and the\nresults show that it significantly outperforms state-of-the-art MARL solutions,\nincluding DQN, MADDPG, and MCTS.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 00:38:18 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Malysheva", "Aleksandra", ""], ["Sung", "Tegg Taekyong", ""], ["Sohn", "Chae-Bong", ""], ["Kudenko", "Daniel", ""], ["Shpilman", "Aleksei", ""]]}, {"id": "1811.12598", "submitter": "Kyle Vedder", "authors": "Kyle Vedder and Joydeep Biswas", "title": "X*: Anytime Multi-Agent Path Finding for Sparse Domains using\n  Window-Based Iterative Repairs", "comments": null, "journal-ref": null, "doi": "10.1016/j.artint.2020.103417", "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-world multi-agent systems such as warehouse robots operate under\nsignificant time constraints -- in such settings, rather than spending\nsignificant amounts of time solving for optimal paths, it is instead preferable\nto find valid collision-free paths quickly, even if suboptimal, and given\nadditional time, to iteratively refine such paths to improve their cost. In\nsuch domains, we observe that agent-agent collisions are sparse -- they involve\nsmall local subsets of agents, and are geographically contained within a small\nregion of the overall space.\n  Leveraging this insight, we can first plan paths for each agent individually,\nand in the cases of collisions between agents, perform small local repairs\nlimited to local subspace windows. As time permits, these windows can be\nsuccessively grown and the repairs within them refined, thereby improving the\npath quality, and eventually converging to the global joint optimal solution.\nUsing these insights, we present two algorithmic contributions: 1) the Windowed\nAnytime Multiagent Planning Framework (WAMPF) for a class of anytime planners\nthat quickly generate valid paths with suboptimality estimates and generate\noptimal paths given sufficient time, and 2) X*, an efficient WAMPF-based\nplanner. X* is able to efficiently find successive valid solutions by employing\nre-use techniques during the repair growth step of WAMPF.\n  Experimentally, we demonstrate that in sparse domains: 1) X* outperforms\nstate-of-the-art anytime or optimal MAPF solvers in time to valid path, 2) X*\nis competitive with state-of-the-art anytime or optimal MAPF solvers in time to\noptimal path, 3) X* quickly converges to very tight suboptimality bounds, and\n4) X* is competitive with state-of-the-art suboptimal MAPF solvers in time to\nvalid path for small numbers of agents while providing much higher quality\npaths.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 03:21:40 GMT"}, {"version": "v2", "created": "Mon, 9 Sep 2019 17:40:50 GMT"}, {"version": "v3", "created": "Sat, 2 May 2020 23:08:45 GMT"}, {"version": "v4", "created": "Mon, 10 Aug 2020 22:42:07 GMT"}, {"version": "v5", "created": "Wed, 28 Oct 2020 02:57:35 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Vedder", "Kyle", ""], ["Biswas", "Joydeep", ""]]}]