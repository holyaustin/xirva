[{"id": "1911.00584", "submitter": "Timo Korthals", "authors": "Timo Korthals and Malte Schilling and J\\\"urgen Leitner", "title": "A Perceived Environment Design using a Multi-Modal Variational\n  Autoencoder for learning Active-Sensing", "comments": "Extended Abstract for the IROS 2019 Workshop on Deep Probabilistic\n  Generative Models for Cognitive Architecture in Robotics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This contribution comprises the interplay between a multi-modal variational\nautoencoder and an environment to a perceived environment, on which an agent\ncan act. Furthermore, we conclude our work with a comparison to\ncuriosity-driven learning.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 20:38:37 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Korthals", "Timo", ""], ["Schilling", "Malte", ""], ["Leitner", "J\u00fcrgen", ""]]}, {"id": "1911.00997", "submitter": "Yichuan Charlie Tang", "authors": "Yichuan Charlie Tang, Ruslan Salakhutdinov", "title": "Multiple Futures Prediction", "comments": "In proceedings of NeurIPS 2019, Vancouver, British Columbia, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.MA cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Temporal prediction is critical for making intelligent and robust decisions\nin complex dynamic environments. Motion prediction needs to model the\ninherently uncertain future which often contains multiple potential outcomes,\ndue to multi-agent interactions and the latent goals of others. Towards these\ngoals, we introduce a probabilistic framework that efficiently learns latent\nvariables to jointly model the multi-step future motions of agents in a scene.\nOur framework is data-driven and learns semantically meaningful latent\nvariables to represent the multimodal future, without requiring explicit\nlabels. Using a dynamic attention-based state encoder, we learn to encode the\npast as well as the future interactions among agents, efficiently scaling to\nany number of agents. Finally, our model can be used for planning via computing\na conditional probability density over the trajectories of other agents given a\nhypothetical rollout of the 'self' agent. We demonstrate our algorithms by\npredicting vehicle trajectories of both simulated and real data, demonstrating\nthe state-of-the-art results on several vehicle trajectory datasets.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 00:42:01 GMT"}, {"version": "v2", "created": "Fri, 6 Dec 2019 23:36:01 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Tang", "Yichuan Charlie", ""], ["Salakhutdinov", "Ruslan", ""]]}, {"id": "1911.01003", "submitter": "Saad Alqithami", "authors": "Saad Alqithami, Musaad Alzahrani, Abdulkareem Alzahrani, and Ahmed\n  Mostafa", "title": "Modeling an Augmented Reality Game Environment to Enhance Behavior of\n  ADHD Patients", "comments": "The 12th International Conference on Brain Informatics (BI 2019) ---\n  Brain Science meets Artificial Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper generically models an augmented reality game-based environment to\nproject the gamification of an online cognitive behavioral therapist that\nperforms instant measurements for patients with a predefined Attention Deficit\nHyperactivity Disorder (ADHD). ADHD is one of the most common\nneurodevelopmental disorders in which patients have difficulties related to\ninattention, hyperactivity, and impulsivity. Those patients are in need for a\npsychological therapy; the use of cognitive behavioral therapy as a\nfirmly-established treatment is to help in enhancing the way they think and\nbehave. A major limitation in traditional cognitive behavioral therapies is\nthat therapists may face difficulty to optimize patients' neuropsychological\nstimulus following a specified treatment plan, i.e., therapists struggle to\ndraw clear images when stimulating patients' mindset to a point where they\nshould be. Other limitations recognized here include availability,\naccessibility and level-of-experience of the therapists. Therefore, the paper\npresent a gamification model, we term as \"AR-Therapist,\" in order to take\nadvantages of augmented reality developments to engage patients in both real\nand virtual game-based environments. The model provides an on-time measurements\nof patients' progress throughout the treatment sessions which, in result,\novercomes limitations observed in traditional cognitive behavioral therapies.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 01:57:13 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Alqithami", "Saad", ""], ["Alzahrani", "Musaad", ""], ["Alzahrani", "Abdulkareem", ""], ["Mostafa", "Ahmed", ""]]}, {"id": "1911.01165", "submitter": "Tarik A. Rashid", "authors": "Danial A. Muhammed, Soran Saeed, Tarik A. Rashid", "title": "A Comprehensive Study on Pedestrians' Evacuation", "comments": null, "journal-ref": "International Journal of Recent Contributions from Engineering,\n  Science & IT (iJES), Vol. 7, No. 4, 2019", "doi": "10.3991/ijes.v7i4.11767", "report-no": null, "categories": "cs.MA physics.soc-ph", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Human beings face threats because of unexpected happenings, which can be\navoided through an adequate crisis evacuation plan, which is vital to stop\nwound and demise as its negative results. Consequently, different typical\nevacuation pedestrians have been created. Moreover, through applied research,\nthese models for various applications, reproductions, and conditions have been\nexamined to present an operational model. Furthermore, new models have been\ndeveloped to cooperate with system evacuation in residential places in case of\nunexpected events. This research has taken into account an inclusive and a\n'systematic survey of pedestrian evacuation' to demonstrate models methods by\nfocusing on the applications' features, techniques, implications, and after\nthat gather them under various types, for example, classical models, hybridized\nmodels, and generic model. The current analysis assists scholars in this field\nof study to write their forthcoming papers about it, which can suggest a novel\nstructure to recent typical intelligent reproduction with novel features.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 12:42:14 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Muhammed", "Danial A.", ""], ["Saeed", "Soran", ""], ["Rashid", "Tarik A.", ""]]}, {"id": "1911.01203", "submitter": "Alexander Kell Mr", "authors": "Alexander J. M. Kell, Matthew Forshaw, A. Stephen McGough", "title": "ElecSim: Monte-Carlo Open-Source Agent-Based Model to Inform Policy for\n  Long-Term Electricity Planning", "comments": "e-Energy '19 Proceedings of the Tenth ACM International Conference on\n  Future Energy Systems", "journal-ref": null, "doi": "10.1145/3307772.3335321", "report-no": null, "categories": "cs.MA q-fin.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the threat of climate change, a transition from a fossil-fuel based\nsystem to one based on zero-carbon is required. However, this is not as simple\nas instantaneously closing down all fossil fuel energy generation and replacing\nthem with renewable sources -- careful decisions need to be taken to ensure\nrapid but stable progress. To aid decision makers, we present a new tool,\nElecSim, which is an open-sourced agent-based modelling framework used to\nexamine the effect of policy on long-term investment decisions in electricity\ngeneration. ElecSim allows non-experts to rapidly prototype new ideas.\n  Different techniques to model long-term electricity decisions are reviewed\nand used to motivate why agent-based models will become an important strategic\ntool for policy. We motivate why an open-source toolkit is required for\nlong-term electricity planning.\n  Actual electricity prices are compared with our model and we demonstrate that\nthe use of a Monte-Carlo simulation in the system improves performance by\n$52.5\\%$. Further, using ElecSim we demonstrate the effect of a carbon tax to\nencourage a low-carbon electricity supply. We show how a {\\pounds}40 ($\\$50$)\nper tonne of CO2 emitted would lead to 70% renewable electricity by 2050.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 10:55:46 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Kell", "Alexander J. M.", ""], ["Forshaw", "Matthew", ""], ["McGough", "A. Stephen", ""]]}, {"id": "1911.01366", "submitter": "Chainarong Amornbunchornvej", "authors": "Chainarong Amornbunchornvej and Tanya Berger-Wolf", "title": "Framework for Inferring Following Strategies from Time Series of\n  Movement Data", "comments": "This is the revised version of the preprint entitled \"Inferring\n  Coordination Strategies from Time Series of Movement Data\" following\n  reviewers' suggestions", "journal-ref": "ACM Transactions on Knowledge Discovery from Data (TKDD), 14(3),\n  35 (2020)", "doi": "10.1145/3385730", "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.MA physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How do groups of individuals achieve consensus in movement decisions? Do\nindividuals follow their friends, the one predetermined leader, or whomever\njust happens to be nearby? To address these questions computationally, we\nformalize \"Coordination Strategy Inference Problem\". In this setting, a group\nof multiple individuals moves in a coordinated manner towards a target path.\nEach individual uses a specific strategy to follow others (e.g. nearest\nneighbors, pre-defined leaders, preferred friends). Given a set of time series\nthat includes coordinated movement and a set of candidate strategies as inputs,\nwe provide the first methodology (to the best of our knowledge) to infer\nwhether each individual uses local-agreement-system or dictatorship-like\nstrategy to achieve movement coordination at the group level. We evaluate and\ndemonstrate the performance of the proposed framework by predicting the\ndirection of movement of an individual in a group in both simulated datasets as\nwell as two real-world datasets: a school of fish and a troop of baboons.\nMoreover, since there is no prior methodology for inferring individual-level\nstrategies, we compare our framework with the state-of-the-art approach for the\ntask of classification of group-level-coordination models. The results show\nthat our approach is highly accurate in inferring the correct strategy in\nsimulated datasets even in complicated mixed strategy settings, which no\nexisting method can infer. In the task of classification of\ngroup-level-coordination models, our framework performs better than the\nstate-of-the-art approach in all datasets. Animal data experiments show that\nfish, as expected, follow their neighbors, while baboons have a preference to\nfollow specific individuals. Our methodology generalizes to arbitrary time\nseries data of real numbers, beyond movement data.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 17:51:23 GMT"}, {"version": "v2", "created": "Sun, 12 Jan 2020 09:46:22 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Amornbunchornvej", "Chainarong", ""], ["Berger-Wolf", "Tanya", ""]]}, {"id": "1911.01697", "submitter": "Antonio Celani", "authors": "Mihir Durve, Fernando Peruani, Antonio Celani", "title": "Learning to flock through reinforcement", "comments": null, "journal-ref": "Phys. Rev. E 102, 012601 (2020)", "doi": "10.1103/PhysRevE.102.012601", "report-no": null, "categories": "physics.soc-ph cond-mat.stat-mech cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Flocks of birds, schools of fish, insects swarms are examples of coordinated\nmotion of a group that arises spontaneously from the action of many\nindividuals. Here, we study flocking behavior from the viewpoint of multi-agent\nreinforcement learning. In this setting, a learning agent tries to keep contact\nwith the group using as sensory input the velocity of its neighbors. This goal\nis pursued by each learning individual by exerting a limited control on its own\ndirection of motion. By means of standard reinforcement learning algorithms we\nshow that: i) a learning agent exposed to a group of teachers, i.e. hard-wired\nflocking agents, learns to follow them, and ii) that in the absence of\nteachers, a group of independently learning agents evolves towards a state\nwhere each agent knows how to flock. In both scenarios, i) and ii), the\nemergent policy (or navigation strategy) corresponds to the polar velocity\nalignment mechanism of the well-known Vicsek model. These results show that a)\nsuch a velocity alignment may have naturally evolved as an adaptive behavior\nthat aims at minimizing the rate of neighbor loss, and b) prove that this\nalignment does not only favor (local) polar order, but it corresponds to best\npolicy/strategy to keep group cohesion when the sensory input is limited to the\nvelocity of neighboring agents. In short, to stay together, steer together.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 10:13:35 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Durve", "Mihir", ""], ["Peruani", "Fernando", ""], ["Celani", "Antonio", ""]]}, {"id": "1911.02658", "submitter": "Shirantha Welikala", "authors": "Shirantha Welikala and Christos G. Cassandras", "title": "Asymptotic Analysis for Greedy Initialization of Threshold-Based\n  Distributed Optimization of Persistent Monitoring on Graphs", "comments": "Submitted to Automatica", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the optimal multi-agent persistent monitoring problem\ndefined for a team of agents on a set of nodes (targets) interconnected\naccording to a fixed network topology. The aim is to control this team so as to\nminimize a measure of overall node state uncertainty evaluated over a finite\ntime interval. A class of distributed threshold-based parametric controllers\nhas been proposed in prior work to control agent dwell times at nodes and\nnext-node destinations by enforcing thresholds on the respective node states.\nUnder such a Threshold Control Policy (TCP), an on-line gradient technique was\nused to determine optimal threshold values. However, due to the non-convexity\nof the problem, this approach often leads to a poor local optima highly\ndependent on the initial thresholds used. To overcome this initialization\nchallenge, we develop a computationally efficient off-line greedy technique\nbased on the asymptotic analysis of the network system. This analysis is then\nused to generate a high-performing set of initial thresholds. Extensive\nnumerical results show that such initial thresholds are almost immediately\n(locally) optimal or quickly lead to optimal values. In all cases, they perform\nsignificantly better than the locally optimal solutions known to date.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 22:48:03 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2019 00:52:01 GMT"}, {"version": "v3", "created": "Fri, 11 Dec 2020 02:42:40 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Welikala", "Shirantha", ""], ["Cassandras", "Christos G.", ""]]}, {"id": "1911.03277", "submitter": "Giona Casiraghi", "authors": "Giona Casiraghi and Antonios Garas and Frank Schweitzer", "title": "Probing the robustness of nested multi-layer networks", "comments": "20 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cond-mat.stat-mech cs.MA cs.SI nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a multi-layer network with two layers, $\\mathcal{L}_{1}$,\n$\\mathcal{L}_{2}$. Their intra-layer topology shows a scale-free degree\ndistribution and a core-periphery structure. A nested structure describes the\ninter-layer topology, i.e., some nodes from $\\mathcal{L}_{1}$, the generalists,\nhave many links to nodes in $\\mathcal{L}_{2}$, specialists only have a few.\nThis structure is verified by analyzing two empirical networks from ecology and\neconomics. To probe the robustness of the multi-layer network, we remove nodes\nfrom $\\mathcal{L}_{1}$ with their inter- and intra-layer links and measure the\nimpact on the size of the largest connected component, $F_{2}$, in\n$\\mathcal{L}_{2}$, which we take as a robustness measure. We test different\nattack scenarios by preferably removing peripheral or core nodes. We also vary\nthe intra-layer coupling between generalists and specialists, to study their\nimpact on the robustness of the multi-layer network. We find that some\ncombinations of attack scenario and intra-layer coupling lead to very low\nrobustness values, whereas others demonstrate high robustness of the\nmulti-layer network because of the intra-layer links. Our results shed new\nlight on the robustness of bipartite networks, which consider only inter-layer,\nbut no intra-layer links.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 14:17:58 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Casiraghi", "Giona", ""], ["Garas", "Antonios", ""], ["Schweitzer", "Frank", ""]]}, {"id": "1911.03380", "submitter": "Guillermo Angeris", "authors": "Guillermo Angeris, Hsien-Tang Kao, Rei Chiang, Charlie Noyes, Tarun\n  Chitra", "title": "An analysis of Uniswap markets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.TR cs.MA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uniswap -- and other constant product markets -- appear to work well in\npractice despite their simplicity. In this paper, we give a simple formal\nanalysis of constant product markets and their generalizations, showing that,\nunder some common conditions, these markets must closely track the reference\nmarket price. We also show that Uniswap satisfies many other desirable\nproperties and numerically demonstrate, via a large-scale agent-based\nsimulation, that Uniswap is stable under a wide range of market conditions.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 17:00:11 GMT"}, {"version": "v2", "created": "Mon, 11 Nov 2019 19:50:58 GMT"}, {"version": "v3", "created": "Wed, 13 Nov 2019 21:20:52 GMT"}, {"version": "v4", "created": "Thu, 21 Nov 2019 21:34:39 GMT"}, {"version": "v5", "created": "Sat, 1 Feb 2020 19:02:01 GMT"}, {"version": "v6", "created": "Fri, 15 May 2020 21:05:55 GMT"}, {"version": "v7", "created": "Tue, 9 Feb 2021 20:19:12 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Angeris", "Guillermo", ""], ["Kao", "Hsien-Tang", ""], ["Chiang", "Rei", ""], ["Noyes", "Charlie", ""], ["Chitra", "Tarun", ""]]}, {"id": "1911.03743", "submitter": "Homagni Saha", "authors": "Homagni Saha, Vijay Venkataraman, Alberto Speranzon, Soumik Sarkar", "title": "A perspective on multi-agent communication for information fusion", "comments": "NeuRIPS 2019, Workshop on Visually Grounded Interaction and Language,\n  Vancouver, CA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaborative decision making in multi-agent systems typically requires a\npredefined communication protocol among agents. Usually, agent-level\nobservations are locally processed and information is exchanged using the\npredefined protocol, enabling the team to perform more efficiently than each\nagent operating in isolation. In this work, we consider the situation where\nagents, with complementary sensing modalities must co-operate to achieve a\ncommon goal/task by learning an efficient communication protocol. We frame the\nproblem within an actor-critic scheme, where the agents learn optimal policies\nin a centralized fashion, while taking action in a distributed manner. We\nprovide an interpretation of the emergent communication between the agents. We\nobserve that the information exchanged is not just an encoding of the raw\nsensor data but is, rather, a specific set of directive actions that depend on\nthe overall task. Simulation results demonstrate the interpretability of the\nlearnt communication in a variety of tasks.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 17:56:47 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Saha", "Homagni", ""], ["Venkataraman", "Vijay", ""], ["Speranzon", "Alberto", ""], ["Sarkar", "Soumik", ""]]}, {"id": "1911.03927", "submitter": "Jinmingwu Jiang", "authors": "Jinmingwu Jiang, Kaigui Wu", "title": "Cooperative Pathfinding based on memory-efficient Multi-agent RRT*", "comments": "IROS 2020, October 25-29, Las Vegas, NV, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In cooperative pathfinding problems, no-conflicts paths that bring several\nagents from their start location to their destination need to be planned. This\nproblem can be efficiently solved by Multi-agent RRT*(MA-RRT*) algorithm, which\nis still state-of-the-art in the field of coupled methods. However, the\nimplementation of this algorithm is hindered in systems with limited memory\nbecause the number of nodes in the tree grows indefinitely as the paths get\noptimized. This paper proposes an improved version of MA-RRT*, called\nMulti-agent RRT* Fixed Node(MA-RRT*FN), which limits the number of nodes stored\nin the tree by removing the weak nodes on the path which are not likely to\nreach the goal. The results show that MA-RRT*FN performs close to MA-RRT* in\nterms of scalability and solution quality while the memory required is much\nlower and fixed.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 13:21:14 GMT"}, {"version": "v2", "created": "Sat, 16 Nov 2019 12:45:44 GMT"}, {"version": "v3", "created": "Wed, 4 Mar 2020 03:19:25 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Jiang", "Jinmingwu", ""], ["Wu", "Kaigui", ""]]}, {"id": "1911.04074", "submitter": "Panpan Cai", "authors": "Panpan Cai, Yiyuan Lee, Yuanfu Luo, David Hsu", "title": "SUMMIT: A Simulator for Urban Driving in Massive Mixed Traffic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous driving in an unregulated urban crowd is an outstanding challenge,\nespecially, in the presence of many aggressive, high-speed traffic\nparticipants. This paper presents SUMMIT, a high-fidelity simulator that\nfacilitates the development and testing of crowd-driving algorithms. By\nleveraging the open-source OpenStreetMap map database and a heterogeneous\nmulti-agent motion prediction model developed in our earlier work, SUMMIT\nsimulates dense, unregulated urban traffic for heterogeneous agents at any\nworldwide locations that OpenStreetMap supports. SUMMIT is built as an\nextension of CARLA and inherits from it the physics and visual realism for\nautonomous driving simulation. SUMMIT supports a wide range of applications,\nincluding perception, vehicle control and planning, and end-to-end learning. We\nprovide a context-aware planner together with benchmark scenarios and show that\nSUMMIT generates complex, realistic traffic behaviors in challenging\ncrowd-driving settings.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 04:57:04 GMT"}, {"version": "v2", "created": "Fri, 13 Mar 2020 09:07:42 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Cai", "Panpan", ""], ["Lee", "Yiyuan", ""], ["Luo", "Yuanfu", ""], ["Hsu", "David", ""]]}, {"id": "1911.04082", "submitter": "Behdad Chalaki", "authors": "Behdad Chalaki and Andreas A. Malikopoulos", "title": "Time-Optimal Coordination for Connected and Automated Vehicles at\n  Adjacent Intersections", "comments": "14 pages, 4 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a decentralized optimal control framework for\nconnected and automated vehicles (CAVs) crossing two adjacent intersections.\nThe framework consists of an upper-level scheduling problem and a low-level\noptimal control problem. The solution of the upper-level problem designates the\noptimal time of each CAV aimed at minimizing its travel time to cross the\nintersections. The outcome of the upper-level scheduling problem becomes the\ninput of the low-level problem, the solution of which yields the optimal\ncontrol input (acceleration/deceleration) of each CAV to exit the intersections\nat the time specified in the upper-level scheduling problem. We demonstrate the\neffectiveness of the proposed framework through simulation and comparison with\na signalized intersection.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 05:25:41 GMT"}, {"version": "v2", "created": "Thu, 25 Jun 2020 03:48:36 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Chalaki", "Behdad", ""], ["Malikopoulos", "Andreas A.", ""]]}, {"id": "1911.04094", "submitter": "Xinghu Yao", "authors": "Xinghu Yao, Chao Wen, Yuhui Wang and Xiaoyang Tan", "title": "SMIX($\\lambda$): Enhancing Centralized Value Functions for Cooperative\n  Multi-Agent Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning a stable and generalizable centralized value function (CVF) is a\ncrucial but challenging task in multi-agent reinforcement learning (MARL), as\nit has to deal with the issue that the joint action space increases\nexponentially with the number of agents in such scenarios. This paper proposes\nan approach, named SMIX(${\\lambda}$), to address the issue using an efficient\noff-policy centralized training method within a flexible learner search space.\nAs importance sampling for such off-policy training is both computationally\ncostly and numerically unstable, we proposed to use the ${\\lambda}$-return as a\nproxy to compute the TD error. With this new loss function objective, we adopt\na modified QMIX network structure as the base to train our model. By further\nconnecting it with the ${Q(\\lambda)}$ approach from an unified expectation\ncorrection viewpoint, we show that the proposed SMIX(${\\lambda}$) is equivalent\nto ${Q(\\lambda)}$ and hence shares its convergence properties, while without\nbeing suffered from the aforementioned curse of dimensionality problem inherent\nin MARL. Experiments on the StarCraft Multi-Agent Challenge (SMAC) benchmark\ndemonstrate that our approach not only outperforms several state-of-the-art\nMARL methods by a large margin, but also can be used as a general tool to\nimprove the overall performance of other CTDE-type algorithms by enhancing\ntheir CVFs.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 05:56:13 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2019 07:45:04 GMT"}, {"version": "v3", "created": "Mon, 18 Nov 2019 12:21:26 GMT"}, {"version": "v4", "created": "Wed, 13 May 2020 14:46:31 GMT"}, {"version": "v5", "created": "Sun, 9 Aug 2020 15:40:16 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Yao", "Xinghu", ""], ["Wen", "Chao", ""], ["Wang", "Yuhui", ""], ["Tan", "Xiaoyang", ""]]}, {"id": "1911.04096", "submitter": "Mehdi Rahmati", "authors": "Mehdi Rahmati, Mohammad Nadeem, Vidyasagar Sadhu, and Dario Pompili", "title": "UW-MARL: Multi-Agent Reinforcement Learning for Underwater Adaptive\n  Sampling using Autonomous Vehicles", "comments": null, "journal-ref": null, "doi": "10.1145/3366486.3366533", "report-no": null, "categories": "eess.SY cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Near-real-time water-quality monitoring in uncertain environments such as\nrivers, lakes, and water reservoirs of different variables is critical to\nprotect the aquatic life and to prevent further propagation of the potential\npollution in the water. In order to measure the physical values in a region of\ninterest, adaptive sampling is helpful as an energy- and time-efficient\ntechnique since an exhaustive search of an area is not feasible with a single\nvehicle. We propose an adaptive sampling algorithm using multiple autonomous\nvehicles, which are well-trained, as agents, in a Multi-Agent Reinforcement\nLearning (MARL) framework to make efficient sequence of decisions on the\nadaptive sampling procedure. The proposed solution is evaluated using\nexperimental data, which is fed into a simulation framework. Experiments were\nconducted in the Raritan River, Somerset and in Carnegie Lake, Princeton, NJ\nduring July 2019.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 06:18:04 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Rahmati", "Mehdi", ""], ["Nadeem", "Mohammad", ""], ["Sadhu", "Vidyasagar", ""], ["Pompili", "Dario", ""]]}, {"id": "1911.04146", "submitter": "Shenke Xiao", "authors": "Shenke Xiao, Zihe Wang, Mengjing Chen, Pingzhong Tang, Xiwang Yang", "title": "Optimal Common Contract with Heterogeneous Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.GT", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We consider the principal-agent problem with heterogeneous agents. Previous\nworks assume that the principal signs independent incentive contracts with\nevery agent to make them invest more efforts on the tasks. However, in many\ncircumstances, these contracts need to be identical for the sake of fairness.\nWe investigate the optimal common contract problem. To our knowledge, this is\nthe first attempt to consider this natural and important generalization. We\nfirst show this problem is NP-complete. Then we provide a dynamic programming\nalgorithm to compute the optimal contract in $O(n^2m)$ time, where $n,m$ are\nthe number of agents and actions, under the assumption that the agents' cost\nfunctions obey increasing difference property. At last, we generalize the\nsetting such that each agent can choose to directly produce a reward in\n$[0,1]$. We provide an $O(\\log n)$-approximate algorithm for this\ngeneralization.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 09:03:06 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Xiao", "Shenke", ""], ["Wang", "Zihe", ""], ["Chen", "Mengjing", ""], ["Tang", "Pingzhong", ""], ["Yang", "Xiwang", ""]]}, {"id": "1911.04175", "submitter": "Praveen Palanisamy", "authors": "Praveen Palanisamy", "title": "Multi-Agent Connected Autonomous Driving using Deep Reinforcement\n  Learning", "comments": "Accepted, Machine Learning for Autonomous Driving Workshop at the\n  33rd Conference on Neural Information Processing Systems(NeurIPS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The capability to learn and adapt to changes in the driving environment is\ncrucial for developing autonomous driving systems that are scalable beyond\ngeo-fenced operational design domains. Deep Reinforcement Learning (RL)\nprovides a promising and scalable framework for developing adaptive learning\nbased solutions. Deep RL methods usually model the problem as a (Partially\nObservable) Markov Decision Process in which an agent acts in a stationary\nenvironment to learn an optimal behavior policy. However, driving involves\ncomplex interaction between multiple, intelligent (artificial or human) agents\nin a highly non-stationary environment. In this paper, we propose the use of\nPartially Observable Markov Games(POSG) for formulating the connected\nautonomous driving problems with realistic assumptions. We provide a taxonomy\nof multi-agent learning environments based on the nature of tasks, nature of\nagents and the nature of the environment to help in categorizing various\nautonomous driving problems that can be addressed under the proposed\nformulation. As our main contributions, we provide MACAD-Gym, a Multi-Agent\nConnected, Autonomous Driving agent learning platform for furthering research\nin this direction. Our MACAD-Gym platform provides an extensible set of\nConnected Autonomous Driving (CAD) simulation environments that enable the\nresearch and development of Deep RL- based integrated sensing, perception,\nplanning and control algorithms for CAD systems with unlimited operational\ndesign domain under realistic, multi-agent settings. We also share the\nMACAD-Agents that were trained successfully using the MACAD-Gym platform to\nlearn control policies for multiple vehicle agents in a partially observable,\nstop-sign controlled, 3-way urban intersection environment with raw (camera)\nsensor observations.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 10:55:25 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Palanisamy", "Praveen", ""]]}, {"id": "1911.04646", "submitter": "Li Ning Dr.", "authors": "Li Ning, Yong Zhang", "title": "LAC-Nav: Collision-Free Mutiagent Navigation Based on The Local Action\n  Cells", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collision avoidance is one of the most primary requirement in the\ndecentralized multiagent navigations: while the agents are moving towards their\nown targets, attentions should be paid to avoid the collisions with the others.\nIn this paper, we introduce the concept of local action cell, which provides\nfor each agent a set of velocities that are safe to perform. Based on the\nrealtime updated local action cells, we propose the LAC-Nav approach to\nnavigate the agent with the properly selected velocity; and furthermore, we\ncoupled the local action cell with an adaptive learning framework, in which the\neffect of selections are evaluated and used as the references for making\ndecisions in the following updates. Through the experiments for three commonly\nconsidered scenarios, we demonstrated the efficiency of the proposed\napproaches, with the comparison to several widely studied strategies.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 03:07:36 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Ning", "Li", ""], ["Zhang", "Yong", ""]]}, {"id": "1911.04863", "submitter": "Daniela Briola", "authors": "Daniela Briola, Viviana Mascardi, Massimiliano Gioseffi", "title": "OntoScene, A Logic-based Scene Interpreter: Implementation and\n  Application in the Rock Art Domain", "comments": "Under consideration in Theory and Practice of Logic Programming\n  (TPLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present OntoScene, a framework aimed at understanding the semantics of\nvisual scenes starting from the semantics of their elements and the spatial\nrelations holding between them. OntoScene exploits ontologies for representing\nknowledge and Prolog for specifying the interpretation rules that domain\nexperts may adopt, and for implementing the SceneInterpreter engine. Ontologies\nallow the designer to formalize the domain in a reusable way, and make the\nsystem modular and interoperable with existing multiagent systems, while Prolog\nprovides a solid basis to define complex rules of interpretation in a way that\ncan be affordable even for people with no background in Computational Logics.\nThe domain selected for experimenting OntoScene is that of prehistoric rock\nart, which provides us with a fascinating and challenging testbed. Under\nconsideration in Theory and Practice of Logic Programming (TPLP)\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 13:22:05 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Briola", "Daniela", ""], ["Mascardi", "Viviana", ""], ["Gioseffi", "Massimiliano", ""]]}, {"id": "1911.04870", "submitter": "Elsa Rizk", "authors": "Elsa Rizk, Roula Nassif, Ali H. Sayed", "title": "Network Classifiers With Output Smoothing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work introduces two strategies for training network classifiers with\nheterogeneous agents. One strategy promotes global smoothing over the graph and\na second strategy promotes local smoothing over neighbourhoods. It is assumed\nthat the feature sizes can vary from one agent to another, with some agents\nobserving insufficient attributes to be able to make reliable decisions on\ntheir own. As a result, cooperation with neighbours is necessary. However, due\nto the fact that the feature dimensions are different across the agents, their\nclassifier dimensions will also be different. This means that cooperation\ncannot rely on combining the classifier parameters. We instead propose\nsmoothing the outputs of the classifiers, which are the predicted labels. By\ndoing so, the dynamics that describes the evolution of the network classifier\nbecomes more challenging than usual because the classifier parameters end up\nappearing as part of the regularization term as well. We illustrate performance\nby means of computer simulations.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 14:28:16 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Rizk", "Elsa", ""], ["Nassif", "Roula", ""], ["Sayed", "Ali H.", ""]]}, {"id": "1911.05438", "submitter": "Etienne Bennequin", "authors": "Mohamed Salah Za\\\"iem and Etienne Bennequin", "title": "Learning to Communicate in Multi-Agent Reinforcement Learning : A Review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the issue of multiple agents learning to communicate through\nreinforcement learning within partially observable environments, with a focus\non information asymmetry in the second part of our work. We provide a review of\nthe recent algorithms developed to improve the agents' policy by allowing the\nsharing of information between agents and the learning of communication\nstrategies, with a focus on Deep Recurrent Q-Network-based models. We also\ndescribe recent efforts to interpret the languages generated by these agents\nand study their properties in an attempt to generate human-language-like\nsentences. We discuss the metrics used to evaluate the generated communication\nstrategies and propose a novel entropy-based evaluation metric. Finally, we\naddress the issue of the cost of communication and introduce the idea of an\nexperimental setup to expose this cost in cooperative-competitive game.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 13:08:46 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Za\u00efem", "Mohamed Salah", ""], ["Bennequin", "Etienne", ""]]}, {"id": "1911.05859", "submitter": "Luca Ballotta", "authors": "Luca Ballotta, Luca Schenato, Luca Carlone", "title": "Computation-Communication Trade-offs and Sensor Selection in Real-time\n  Estimation for Processing Networks", "comments": "15 pages, 16 figures. Accepted journal version", "journal-ref": null, "doi": "10.1109/TNSE.2020.3008337", "report-no": null, "categories": "math.OC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in electronics are enabling substantial processing to be\nperformed at each node (robots, sensors) of a networked system. Local\nprocessing enables data compression and may mitigate measurement noise, but it\nis still slower compared to a central computer (it entails a larger\ncomputational delay). However, while nodes can process the data in parallel,\nthe centralized computational is sequential in nature. On the other hand, if a\nnode sends raw data to a central computer for processing, it incurs\ncommunication delay. This leads to a fundamental communication-computation\ntrade-off, where each node has to decide on the optimal amount of preprocessing\nin order to maximize the network performance. We consider a network in charge\nof estimating the state of a dynamical system and provide three contributions.\nFirst, we provide a rigorous problem formulation for optimal real-time\nestimation in processing networks in the presence of delays. Second, we show\nthat, in the case of a homogeneous network (where all sensors have the same\ncomputation) that monitors a continuous-time scalar linear system, the optimal\namount of local preprocessing maximizing the network estimation performance can\nbe computed analytically. Third, we consider the realistic case of a\nheterogeneous network monitoring a discrete-time multi-variate linear system\nand provide algorithms to decide on suitable preprocessing at each node, and to\nselect a sensor subset when computational constraints make using all sensors\nsuboptimal. Numerical simulations show that selecting the sensors is crucial.\nMoreover, we show that if the nodes apply the preprocessing policy suggested by\nour algorithms, they can largely improve the network estimation performance.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 23:41:33 GMT"}, {"version": "v2", "created": "Fri, 15 Nov 2019 18:39:59 GMT"}, {"version": "v3", "created": "Thu, 21 Nov 2019 21:54:02 GMT"}, {"version": "v4", "created": "Tue, 26 Nov 2019 17:13:05 GMT"}, {"version": "v5", "created": "Thu, 19 Mar 2020 16:18:54 GMT"}, {"version": "v6", "created": "Fri, 20 Mar 2020 00:45:08 GMT"}, {"version": "v7", "created": "Fri, 29 May 2020 15:01:08 GMT"}, {"version": "v8", "created": "Mon, 6 Jul 2020 23:09:30 GMT"}, {"version": "v9", "created": "Mon, 3 Aug 2020 12:46:21 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Ballotta", "Luca", ""], ["Schenato", "Luca", ""], ["Carlone", "Luca", ""]]}, {"id": "1911.05885", "submitter": "Andrew Estornell", "authors": "Andrew Estornell, Sanmay Das, Yevgeniy Vorobeychik", "title": "Deception through Half-Truths", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deception is a fundamental issue across a diverse array of settings, from\ncybersecurity, where decoys (e.g., honeypots) are an important tool, to\npolitics that can feature politically motivated \"leaks\" and fake news about\ncandidates.Typical considerations of deception view it as providing false\ninformation.However, just as important but less frequently studied is a more\ntacit form where information is strategically hidden or leaked.We consider the\nproblem of how much an adversary can affect a principal's decision by\n\"half-truths\", that is, by masking or hiding bits of information, when the\nprincipal is oblivious to the presence of the adversary. The principal's\nproblem can be modeled as one of predicting future states of variables in a\ndynamic Bayes network, and we show that, while theoretically the principal's\ndecisions can be made arbitrarily bad, the optimal attack is NP-hard to\napproximate, even under strong assumptions favoring the attacker. However, we\nalso describe an important special case where the dependency of future states\non past states is additive, in which we can efficiently compute an\napproximately optimal attack. Moreover, in networks with a linear transition\nfunction we can solve the problem optimally in polynomial time.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 01:36:05 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Estornell", "Andrew", ""], ["Das", "Sanmay", ""], ["Vorobeychik", "Yevgeniy", ""]]}, {"id": "1911.05892", "submitter": "Sumitra Ganesh", "authors": "Sumitra Ganesh, Nelson Vadori, Mengda Xu, Hua Zheng, Prashant Reddy,\n  Manuela Veloso", "title": "Reinforcement Learning for Market Making in a Multi-agent Dealer Market", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.TR cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Market makers play an important role in providing liquidity to markets by\ncontinuously quoting prices at which they are willing to buy and sell, and\nmanaging inventory risk. In this paper, we build a multi-agent simulation of a\ndealer market and demonstrate that it can be used to understand the behavior of\na reinforcement learning (RL) based market maker agent. We use the simulator to\ntrain an RL-based market maker agent with different competitive scenarios,\nreward formulations and market price trends (drifts). We show that the\nreinforcement learning agent is able to learn about its competitor's pricing\npolicy; it also learns to manage inventory by smartly selecting asymmetric\nprices on the buy and sell sides (skewing), and maintaining a positive (or\nnegative) inventory depending on whether the market price drift is positive (or\nnegative). Finally, we propose and test reward formulations for creating risk\naverse RL-based market maker agents.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 01:55:31 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Ganesh", "Sumitra", ""], ["Vadori", "Nelson", ""], ["Xu", "Mengda", ""], ["Zheng", "Hua", ""], ["Reddy", "Prashant", ""], ["Veloso", "Manuela", ""]]}, {"id": "1911.05907", "submitter": "Marlo Souza", "authors": "Marlo Souza, \\'Alvaro Moreira, Renata Vieira, John-Jules Ch. Meyer", "title": "A Dynamic Preference Logic for reasoning about Agent Programming", "comments": "piblished on BRACIS 2017", "journal-ref": null, "doi": "10.1109/BRACIS.2017.43", "report-no": null, "categories": "cs.MA cs.LO", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this work, we investigate the use of Dynamic Preference Logic to encode\nBDI mental attitudes. Further, exploring this codification and the\nrepresentation of preferences over possible worlds by preferences over\npropositional formulas, here called priority graphs, we comment on how to\ninterpret BDI agent programs in this logic. Also, using the connection between\ndynamic operations defined over preference models and their encoding as\ntransformations on priority graphs, we show how our logic can be used not only\nto reason about agent programs, but as a tool to specify reasoning mechanisms\nto guarantee certain properties in the theory of rationality for the\nprogramming language.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 02:45:50 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Souza", "Marlo", ""], ["Moreira", "\u00c1lvaro", ""], ["Vieira", "Renata", ""], ["Meyer", "John-Jules Ch.", ""]]}, {"id": "1911.05908", "submitter": "Marlo Souza", "authors": "Marlo Souza, \\'Alvaro Moreira, Renata Vieira", "title": "Tractable reasoning about Agent Programming in Dynamic Preference Logic", "comments": "Published in BRACIS 2018", "journal-ref": null, "doi": "10.1109/BRACIS.2018.00070", "report-no": null, "categories": "cs.MA cs.LO", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  While several BDI logics have been proposed in the area of Agent Programming,\nit is not clear how these logics are connected to the agent programs they are\nsupposed to specify. More yet, the reasoning problems in these logics, being\nbased on modal logic, are not tractable in general, limiting their usage to\ntackle real-world problems. In this work, we use of Dynamic Preference Logic to\nprovide a semantic foundation to BDI agent programming languages and\ninvestigate tractable expressive fragments of this logic to reason about agent\nprograms. With that, we aim to provide a way of implementing semantically\ngrounded agent programming languages with tractable reasoning cycles.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 02:50:23 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Souza", "Marlo", ""], ["Moreira", "\u00c1lvaro", ""], ["Vieira", "Renata", ""]]}, {"id": "1911.06367", "submitter": "Juan Afanador", "authors": "Juan Afanador", "title": "Arguing Ecosystem Values with Paraconsistent Logics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The valuation of ecosystem services prompts dialogical settings where\nnon-trivially inconsistent arguments are often invoked. Here, I propose an\napproach to the valuation of ecosystem services circumscribed to a logic-based\nargumentation framework that caters for valid inconsistencies. This framework\naccounts for preference formation processes underpinned by a paraconsistent\nmodel of logical entailment. The value of an ecosystem service is produced in\nthe form of an ordering over competing land-use practices, as per the arguments\nsurviving semantical probing.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 20:10:07 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Afanador", "Juan", ""]]}, {"id": "1911.06519", "submitter": "Juan Chacon", "authors": "Juan Chacon, Mo Chen and Razvan C. Fetecau", "title": "Safe Coverage of Compact Domains For Second Order Dynamical Systems", "comments": "8 pages, 6 figures, IFAC 2020 initial submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous systems operating in close proximity with each other to cover a\nspecified area has many potential applications, but to achieve effective\ncoordination, two key challenges need to be addressed: coordination and safety.\nFor coordination, we propose a locally asymptotically stable distributed\ncoverage controller for compact domains in the plane and homogeneous vehicles\nmodeled with second order dynamics with bounded input forces. This control\npolicy is based on artificial potentials designed to enforce desired\nvehicle-domain and inter-vehicle separations, and can be applied to arbitrary\ncompact domains including non-convex ones. We prove, using Lyapunov theory,\nthat certain coverage configurations are locally asymptotically stable. For\nsafety, we utilize Hamilton-Jacobi (HJ) reachability theory to guarantee\npairwise collision avoidance. Rather than computing numerical solutions of the\nassociated HJ partial differential equation as is typically done, we derive an\nanalytical solution for our second-order vehicle model. This provides an exact,\nglobal solution rather than an approximate, local one within some computational\ndomain. In addition to considerably reducing collision count, the collision\navoidance controller also reduces oscillatory behaviour of vehicles, helping\nthe system reach steady state faster. We demonstrate our approach in three\nrepresentative simulations involving a square domain, triangle domain, and a\nnon-convex moving domain.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 08:51:21 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Chacon", "Juan", ""], ["Chen", "Mo", ""], ["Fetecau", "Razvan C.", ""]]}, {"id": "1911.06665", "submitter": "Ivano Notarnicola", "authors": "Michelangelo Bin, Ivano Notarnicola, Lorenzo Marconi, Giuseppe\n  Notarstefano", "title": "A System Theoretical Perspective to Gradient-Tracking Algorithms for\n  Distributed Quadratic Optimization", "comments": null, "journal-ref": null, "doi": "10.1109/CDC40024.2019.9029824", "report-no": null, "categories": "eess.SY cs.MA cs.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider a recently developed distributed optimization\nalgorithm based on gradient tracking. We propose a system theory framework to\nanalyze its structural properties on a preliminary, quadratic optimization\nset-up. Specifically, we focus on a scenario in which agents in a static\nnetwork want to cooperatively minimize the sum of quadratic cost functions. We\nshow that the gradient tracking distributed algorithm for the investigated\nprogram can be viewed as a sparse closed-loop linear system in which the\ndynamic state-feedback controller includes consensus matrices and optimization\n(stepsize) parameters. The closed-loop system turns out to be not completely\nreachable and asymptotic stability can be shown restricted to a proper\ninvariant set. Convergence to the global minimum, in turn, can be obtained only\nby means of a proper initialization. The proposed system interpretation of the\ndistributed algorithm provides also additional insights on other structural\nproperties and possible design choices that are discussed in the last part of\nthe paper as a starting point for future developments.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 14:33:31 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Bin", "Michelangelo", ""], ["Notarnicola", "Ivano", ""], ["Marconi", "Lorenzo", ""], ["Notarstefano", "Giuseppe", ""]]}, {"id": "1911.06783", "submitter": "Martyn Amos", "authors": "Jamie Webster and Martyn Amos", "title": "A Turing Test for Crowds", "comments": "Submitted", "journal-ref": "Royal Society Open Science 7:7, 2020", "doi": "10.1098/rsos.200307", "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The realism and believability of crowd simulations underpins computational\nstudies of human collective behaviour, with implications for urban design,\npolicing, security and many other areas. Realism concerns the closeness of the\nfit between a simulation and observed data, and believability concerns the\nhuman perception of plausibility. In this paper, we ask two questions, via a\nso-called \"Turing Test\" for crowds: (1) Can human observers distinguish between\nreal and simulated crowds, and (2) Can human observers identify real crowds\nversus simulated crowds? In a study with student volunteers (n=384), we find\nconvincing evidence that non-specialist individuals are able to reliably\ndistinguish between real and simulated crowds. A rather more surprising result\nis that such individuals are overwhelmingly unable to identify real crowds.\nThat is, they can tell real from simulated crowds, but are unable to say which\nis which. Our main conclusion is that (to the lay-person, at least) realistic\ncrowds are not believable (and vice versa).\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 17:58:41 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Webster", "Jamie", ""], ["Amos", "Martyn", ""]]}, {"id": "1911.06992", "submitter": "Rundong Wang", "authors": "Rundong Wang, Xu He, Runsheng Yu, Wei Qiu, Bo An, Zinovi Rabinovich", "title": "Learning Efficient Multi-agent Communication: An Information Bottleneck\n  Approach", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of the limited-bandwidth communication for\nmulti-agent reinforcement learning, where agents cooperate with the assistance\nof a communication protocol and a scheduler. The protocol and scheduler jointly\ndetermine which agent is communicating what message and to whom. Under the\nlimited bandwidth constraint, a communication protocol is required to generate\ninformative messages. Meanwhile, an unnecessary communication connection should\nnot be established because it occupies limited resources in vain. In this\npaper, we develop an Informative Multi-Agent Communication (IMAC) method to\nlearn efficient communication protocols as well as scheduling. First, from the\nperspective of communication theory, we prove that the limited bandwidth\nconstraint requires low-entropy messages throughout the transmission. Then\ninspired by the information bottleneck principle, we learn a valuable and\ncompact communication protocol and a weight-based scheduler. To demonstrate the\nefficiency of our method, we conduct extensive experiments in various\ncooperative and competitive multi-agent tasks with different numbers of agents\nand different bandwidths. We show that IMAC converges faster and leads to\nefficient communication among agents under the limited bandwidth as compared to\nmany baseline methods.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 08:32:49 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 07:55:05 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Wang", "Rundong", ""], ["He", "Xu", ""], ["Yu", "Runsheng", ""], ["Qiu", "Wei", ""], ["An", "Bo", ""], ["Rabinovich", "Zinovi", ""]]}, {"id": "1911.07048", "submitter": "Shengxin Liu", "authors": "Xiaohui Bei, Zihao Li, Jinyan Liu, Shengxin Liu, Xinhang Lu", "title": "Fair Division of Mixed Divisible and Indivisible Goods", "comments": "Appears in the 34th AAAI Conference on Artificial Intelligence\n  (AAAI), 2020", "journal-ref": "Artificial Intelligence, 293:103436 (2021)", "doi": "10.1016/j.artint.2020.103436", "report-no": null, "categories": "cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of fair division when the resources contain both\ndivisible and indivisible goods. Classic fairness notions such as envy-freeness\n(EF) and envy-freeness up to one good (EF1) cannot be directly applied to the\nmixed goods setting. In this work, we propose a new fairness notion\nenvy-freeness for mixed goods (EFM), which is a direct generalization of both\nEF and EF1 to the mixed goods setting. We prove that an EFM allocation always\nexists for any number of agents. We also propose efficient algorithms to\ncompute an EFM allocation for two agents and for $n$ agents with piecewise\nlinear valuations over the divisible goods. Finally, we relax the envy-free\nrequirement, instead asking for $\\epsilon$-envy-freeness for mixed goods\n($\\epsilon$-EFM), and present an algorithm that finds an $\\epsilon$-EFM\nallocation in time polynomial in the number of agents, the number of\nindivisible goods, and $1/\\epsilon$.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 15:24:31 GMT"}, {"version": "v2", "created": "Thu, 5 Mar 2020 07:22:51 GMT"}, {"version": "v3", "created": "Wed, 27 Jan 2021 03:23:09 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Bei", "Xiaohui", ""], ["Li", "Zihao", ""], ["Liu", "Jinyan", ""], ["Liu", "Shengxin", ""], ["Lu", "Xinhang", ""]]}, {"id": "1911.07213", "submitter": "Filippo Fabiani", "authors": "Filippo Fabiani, Sergio Grammatico", "title": "A preconditioned Forward-Backward method for partially separable\n  SemiDefinite Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present semi-decentralized and distributed algorithms, designed via a\npreconditioned forward-backward operator splitting, for solving large-scale,\ndecomposable semidefinite programs (SDPs). We exploit a chordal aggregate\nsparsity pattern assumption on the original SDP to obtain a set of mutually\ncoupled SDPs defined on positive semidefinite (PSD) cones of reduced\ndimensions. We show that the proposed algorithms converge to a solution of the\noriginal SDP via iterations of reasonable computational cost. Finally, we\ncompare the performances of the two proposed algorithms with respect to others\navailable in the literature.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 12:06:20 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Fabiani", "Filippo", ""], ["Grammatico", "Sergio", ""]]}, {"id": "1911.07266", "submitter": "Farhad Mehdifar", "authors": "Farhad Mehdifar, Charalampos P. Bechlioulis, Farzad Hashemzadeh, Mahdi\n  Baradarannia", "title": "Prescribed Performance Distance-Based Formation Control of Multi-Agent\n  Systems (Extended Version)", "comments": "17 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.MA cs.RO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel control protocol for robust distance-based\nformation control with prescribed performance in which agents are subjected to\nunknown external disturbances. Connectivity maintenance and collision avoidance\namong neighboring agents are also handled by the appropriate design of certain\nperformance bounds that constrain the inter-agent distance errors. As an\nextension to the proposed scheme, distance-based formation centroid maneuvering\nis also studied for disturbance-free agents, in which the formation centroid\ntracks a desired time-varying velocity. The proposed control laws are\ndecentralized, in the sense that each agent employs local relative information\nregarding its neighbors to calculate its control signal. Therefore, the control\nscheme is implementable on the agents' local coordinate frames. Using rigid\ngraph theory, input-to-state stability, and Lyapunov based analysis, the\nresults are established for minimally and infinitesimally rigid formations in\n2-D or 3-D space. Furthermore, it is argued that the proposed approach\nincreases formation robustness against shape distortions and can prevent\nformation convergence to incorrect shapes, which is likely to happen in\nconventional distance-based formation control methods. Finally, extensive\nsimulation studies clarify and verify the proposed approach.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 16:03:12 GMT"}, {"version": "v2", "created": "Wed, 22 Jan 2020 10:52:43 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Mehdifar", "Farhad", ""], ["Bechlioulis", "Charalampos P.", ""], ["Hashemzadeh", "Farzad", ""], ["Baradarannia", "Mahdi", ""]]}, {"id": "1911.07290", "submitter": "EPTCS", "authors": "Werner Damm, Martin Fr\\\"anzle, Willem Hagemann, Paul Kr\\\"oger, Astrid\n  Rakow", "title": "Dynamic Conflict Resolution Using Justification Based Reasoning", "comments": "In Proceedings CREST 2019, arXiv:1910.13641. arXiv admin note:\n  substantial text overlap with arXiv:1905.11764", "journal-ref": "EPTCS 308, 2019, pp. 47-65", "doi": "10.4204/EPTCS.308.4", "report-no": null, "categories": "cs.MA cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study conflict situations that dynamically arise in traffic scenarios,\nwhere different agents try to achieve their set of goals and have to decide on\nwhat to do based on their local perception. We distinguish several types of\nconflicts for this setting. In order to enable modelling of conflict situations\nand the reasons for conflicts, we present a logical framework that adopts\nconcepts from epistemic and modal logic, justification and temporal logic.\nUsing this framework, we illustrate how conflicts can be identified and how we\nderive a chain of justifications leading to this conflict. We discuss how\nconflict resolution can be done when a vehicle has local, incomplete\ninformation, vehicle to vehicle communication (V2V) and partially ordered\ngoals.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 02:30:45 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Damm", "Werner", ""], ["Fr\u00e4nzle", "Martin", ""], ["Hagemann", "Willem", ""], ["Kr\u00f6ger", "Paul", ""], ["Rakow", "Astrid", ""]]}, {"id": "1911.07503", "submitter": "Jairo Inga", "authors": "Jairo Inga, Esther Bischoff, Florian K\\\"opf, S\\\"oren Hohmann", "title": "Inverse Dynamic Games Based on Maximum Entropy Inverse Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.GT cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the inverse problem of dynamic games, where cost function\nparameters are sought which explain observed behavior of interacting players.\nMaximum entropy inverse reinforcement learning is extended to the N-player case\nin order to solve inverse dynamic games with continuous-valued state and\ncontrol spaces. We present methods for identification of cost function\nparameters from observed data which correspond to (i) a Pareto efficient\nsolution, (ii) an open-loop Nash equilibrium or (iii) a feedback Nash\nequilibrium. Furthermore, we give results on the unbiasedness of the estimation\nof cost function parameters for each arising class of inverse dynamic game. The\napplicability of the methods is demonstrated with simulation examples of a\nnonlinear and a linear-quadratic dynamic game.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 09:41:47 GMT"}, {"version": "v2", "created": "Fri, 24 Jul 2020 09:29:52 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Inga", "Jairo", ""], ["Bischoff", "Esther", ""], ["K\u00f6pf", "Florian", ""], ["Hohmann", "S\u00f6ren", ""]]}, {"id": "1911.07591", "submitter": "Arcile Johan", "authors": "Johan Arcile (IBISC), Raymond Devillers, Hanna Klaudel (IBISC)", "title": "Dynamic exploration of multi-agent systems with timed periodic tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formalise and study multi-agent timed models MAPTs (Multi-Agent with timed\nPeriodic Tasks), where each agent is associated to a regular timed schema upon\nwhich all possibles actions of the agent rely. MAPTs allow for an accelerated\nsemantics and a layered structure of the state space, so that it is possible to\nexplore the latter dynamically and use heuristics to greatly reduce the\ncomputation time needed to address reachability problems. We apply MAPTs to\nexplore state spaces of autonomous vehicles and compare it with other\napproaches in terms of expressivity, abstraction level and computation time.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 12:44:14 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Arcile", "Johan", "", "IBISC"], ["Devillers", "Raymond", "", "IBISC"], ["Klaudel", "Hanna", "", "IBISC"]]}, {"id": "1911.07690", "submitter": "M. Hadi Amini", "authors": "Ahmed Imteaj, M. Hadi Amini, Javad Mohammadi", "title": "Leveraging Decentralized Artificial Intelligence to Enhance Resilience\n  of Energy Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DC cs.MA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper reintroduces the notion of resilience in the context of recent\nissues originated from climate change triggered events including severe\nhurricanes and wildfires. A recent example is PG&E's forced power outage to\ncontain wildfire risk which led to widespread power disruption. This paper\nfocuses on answering two questions: who is responsible for resilience? and how\nto quantify the monetary value of resilience? To this end, we first provide\npreliminary definitions of resilience for power systems. We then investigate\nthe role of natural hazards, especially wildfire, on power system resilience.\nFinally, we will propose a decentralized strategy for a resilient management\nsystem using distributed storage and demand response resources. Our proposed\nhigh fidelity model provides utilities, operators, and policymakers with a\nclearer picture for strategic decision making and preventive decisions.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 15:13:48 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Imteaj", "Ahmed", ""], ["Amini", "M. Hadi", ""], ["Mohammadi", "Javad", ""]]}, {"id": "1911.07706", "submitter": "Hongtao Lv", "authors": "Hongtao Lv, Chaoli Zhang, Zhenzhe Zheng, Tie Luo, Fan Wu, Guihai Chen", "title": "Mechanism Design with Predicted Task Revenue for Bike Sharing Systems", "comments": "Accepted by AAAI 2020; This is the full version that contains all the\n  proofs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bike sharing systems have been widely deployed around the world in recent\nyears. A core problem in such systems is to reposition the bikes so that the\ndistribution of bike supply is reshaped to better match the dynamic bike\ndemand. When the bike-sharing company or platform is able to predict the\nrevenue of each reposition task based on historic data, an additional\nconstraint is to cap the payment for each task below its predicted revenue. In\nthis paper, we propose an incentive mechanism called {\\em TruPreTar} to\nincentivize users to park bicycles at locations desired by the platform toward\nrebalancing supply and demand. TruPreTar possesses four important economic and\ncomputational properties such as truthfulness and budget feasibility.\nFurthermore, we prove that even when the payment budget is tight, the total\nrevenue still exceeds or equals the budget. Otherwise, TruPreTar achieves\n2-approximation as compared to the optimal (revenue-maximizing) solution, which\nis close to the lower bound of at least $\\sqrt{2}$ that we also prove. Using an\nindustrial dataset obtained from a large bike-sharing company, our experiments\nshow that TruPreTar is effective in rebalancing bike supply and demand and, as\na result, generates high revenue that outperforms several benchmark mechanisms.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 15:34:11 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 17:49:38 GMT"}, {"version": "v3", "created": "Sun, 24 Nov 2019 08:38:07 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Lv", "Hongtao", ""], ["Zhang", "Chaoli", ""], ["Zheng", "Zhenzhe", ""], ["Luo", "Tie", ""], ["Wu", "Fan", ""], ["Chen", "Guihai", ""]]}, {"id": "1911.07823", "submitter": "Rahul Chandan", "authors": "Rahul Chandan and Dario Paccagnan and Jason R. Marden", "title": "When Smoothness is Not Enough: Toward Exact Quantification and\n  Optimization of the Price of Anarchy", "comments": "25 pages, 5 figures, 1 table, in review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.MA cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The price of anarchy (PoA) is a popular metric for analyzing the inefficiency\nof self-interested decision making. Although its study is widespread,\ncharacterizing the PoA can be challenging. A commonly employed approach is\nbased on the smoothness framework, which provides tight PoA values under the\nassumption that the system objective consists in the sum of the agents'\nindividual welfares. Unfortunately, several important classes of problems do\nnot satisfy this requirement (e.g., taxation in congestion games), and our\nfirst result demonstrates that the smoothness framework does *not* tightly\ncharacterize the PoA for such settings. Motivated by this observation, this\nwork develops a framework that achieves two chief objectives: i) to tightly\ncharacterize the PoA for such scenarios, and ii) to do so through a tractable\napproach. As a direct consequence, the proposed framework recovers and\ngeneralizes many existing PoA results, and enables efficient computation of\nincentives that optimize the PoA. We conclude by highlighting the applicability\nof our contributions to incentive design in congestion games and utility design\nin distributed welfare games.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 18:38:19 GMT"}, {"version": "v2", "created": "Mon, 24 May 2021 23:25:34 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Chandan", "Rahul", ""], ["Paccagnan", "Dario", ""], ["Marden", "Jason R.", ""]]}, {"id": "1911.07840", "submitter": "Jinmingwu Jiang", "authors": "Jinmingwu Jiang, Kaigui Wu", "title": "Cooperative Pathfinding based on Multi-agent RRT* Fixed Node", "comments": "arXiv admin note: substantial text overlap with arXiv:1911.03927", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In cooperative pathfinding problems, non-conflict paths that bring several\nagents from their start location to their destination need to be planned. This\nproblem can be efficiently solved by Multi-agent RRT*(MA-RRT*) algorithm, which\nis still state-of-the-art in the field of coupled methods. However, the\nimplementation of this algorithm is hindered in systems with limited memory\nbecause the number of nodes in the tree of RRT* grows indefinitely as the paths\nget optimized. This paper proposes an improved version of MA-RRT*, called\nMulti-agent RRT* Fixed Node(MA-RRT*FN), which limits the number of nodes stored\nin the tree of RRT* by removing the weak nodes on the path which are not likely\nto reach the goal. The results show that MA-RRT*FN performs close to MA-RRT* in\nterms of scalability and solution quality while the memory required is much\nlower and fixed.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 13:02:59 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 03:09:06 GMT"}, {"version": "v3", "created": "Sun, 21 Feb 2021 09:39:03 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Jiang", "Jinmingwu", ""], ["Wu", "Kaigui", ""]]}, {"id": "1911.08182", "submitter": "Davide Grossi", "authors": "Andrea Bracciali, Davide Grossi, Ronald de Haan", "title": "Decentralization in Open Quorum Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decentralisation is one of the promises introduced by blockchain\ntechnologies: fair and secure interaction amongst peers with no dominant\npositions, single points of failure or censorship. Decentralisation, however,\nappears difficult to be formally defined, possibly a continuum property of\nsystems that can be more or less decentralised, or can tend to decentralisation\nin their lifetime. In this paper we focus on decentralisation in quorum-based\napproaches to open (permissionless) consensus as illustrated in influential\nprotocols such as the Ripple and Stellar protocols. Drawing from game theory\nand computational complexity, we establish limiting results concerning the\ndecentralisation vs. safety trade-off in Ripple and Stellar, and we propose a\nnovel methodology to formalise and quantitatively analyse decentralisation in\nthis type of blockchains.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 10:01:03 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Bracciali", "Andrea", ""], ["Grossi", "Davide", ""], ["de Haan", "Ronald", ""]]}, {"id": "1911.08260", "submitter": "Susobhan Ghosh", "authors": "Susobhan Ghosh, Sujit Gujar, Praveen Paruchuri, Easwar Subramanian,\n  Sanjay P. Bhat", "title": "Bidding in Smart Grid PDAs: Theory, Analysis and Strategy (Extended\n  Version)", "comments": "Accepted for publication in the proceedings of the Thirty-Fourth AAAI\n  Conference on Artificial Intelligence (AAAI-20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.MA q-fin.TR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Periodic Double Auctions (PDAs) are commonly used in the real world for\ntrading, e.g. in stock markets to determine stock opening prices, and energy\nmarkets to trade energy in order to balance net demand in smart grids,\ninvolving trillions of dollars in the process. A bidder, participating in such\nPDAs, has to plan for bids in the current auction as well as for the future\nauctions, which highlights the necessity of good bidding strategies. In this\npaper, we perform an equilibrium analysis of single unit single-shot double\nauctions with a certain clearing price and payment rule, which we refer to as\nACPR, and find it intractable to analyze as number of participating agents\nincrease. We further derive the best response for a bidder with complete\ninformation in a single-shot double auction with ACPR. Leveraging the theory\ndeveloped for single-shot double auction and taking the PowerTAC wholesale\nmarket PDA as our testbed, we proceed by modeling the PDA of PowerTAC as an\nMDP. We propose a novel bidding strategy, namely MDPLCPBS. We empirically show\nthat MDPLCPBS follows the equilibrium strategy for double auctions that we\npreviously analyze. In addition, we benchmark our strategy against the baseline\nand the state-of-the-art bidding strategies for the PowerTAC wholesale market\nPDAs, and show that MDPLCPBS outperforms most of them consistently.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 13:46:53 GMT"}, {"version": "v2", "created": "Sat, 23 Nov 2019 21:29:05 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Ghosh", "Susobhan", ""], ["Gujar", "Sujit", ""], ["Paruchuri", "Praveen", ""], ["Subramanian", "Easwar", ""], ["Bhat", "Sanjay P.", ""]]}, {"id": "1911.08443", "submitter": "Carlo Cenedese", "authors": "Carlo Cenedese and Giuseppe Belgioioso and Sergio Grammatico and Ming\n  Cao", "title": "Time-varying constrained proximal type dynamics in multi-agent network\n  games", "comments": "This paper has been submitted to 2020 European Control Conference\n  (ECC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.MA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study multi-agent network games subject to affine\ntime-varying coupling constraints and a time-varying communication network. We\nfocus on the class of games adopting proximal dynamics and study their\nconvergence to a persistent equilibrium. The assumptions considered to solve\nthe problem are discussed and motivated. We develop an iterative equilibrium\nseeking algorithm, using only local information, that converges to a special\nclass of game equilibria. Its derivation is motivated by several examples,\nshowing that the original game dynamics fail to converge. Finally, we apply the\ndesigned algorithm to solve a constrained consensus problem, validating the\ntheoretical results.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 18:10:07 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Cenedese", "Carlo", ""], ["Belgioioso", "Giuseppe", ""], ["Grammatico", "Sergio", ""], ["Cao", "Ming", ""]]}, {"id": "1911.08626", "submitter": "Filip Klaesson", "authors": "Filip Klaesson, Petter Nilsson, Aaron D. Ames, Richard M. Murray", "title": "Intermittent Connectivity for Exploration in Communication-Constrained\n  Multi-Agent Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.MA cs.SY eess.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by exploration of communication-constrained underground\nenvironments using robot teams, we study the problem of planning for\nintermittent connectivity in multi-agent systems. We propose a novel concept of\ninformation-consistency to handle situations where the plan is not initially\nknown by all agents, and suggest an integer linear program for synthesizing\ninformation-consistent plans that also achieve auxiliary goals. Furthermore,\ninspired by network flow problems we propose a novel way to pose connectivity\nconstraints that scales much better than previous methods. In the second part\nof the paper we apply these results in an exploration setting, and propose a\nclustering method that separates a large exploration problem into smaller\nproblems that can be solved independently. We demonstrate how the resulting\nexploration algorithm is able to coordinate a team of ten agents to explore a\nlarge environment.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 23:16:41 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Klaesson", "Filip", ""], ["Nilsson", "Petter", ""], ["Ames", "Aaron D.", ""], ["Murray", "Richard M.", ""]]}, {"id": "1911.08642", "submitter": "Adam Eck", "authors": "Adam Eck, Maulik Shah, Prashant Doshi, and Leen-Kiat Soh", "title": "Scalable Decision-Theoretic Planning in Open and Typed Multiagent\n  Systems", "comments": "Pre-print with appendices for AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In open agent systems, the set of agents that are cooperating or competing\nchanges over time and in ways that are nontrivial to predict. For example, if\ncollaborative robots were tasked with fighting wildfires, they may run out of\nsuppressants and be temporarily unavailable to assist their peers. We consider\nthe problem of planning in these contexts with the additional challenges that\nthe agents are unable to communicate with each other and that there are many of\nthem. Because an agent's optimal action depends on the actions of others, each\nagent must not only predict the actions of its peers, but, before that, reason\nwhether they are even present to perform an action. Addressing openness thus\nrequires agents to model each other's presence, which becomes computationally\nintractable with high numbers of agents. We present a novel, principled, and\nscalable method in this context that enables an agent to reason about others'\npresence in its shared environment and their actions. Our method extrapolates\nmodels of a few peers to the overall behavior of the many-agent system, and\ncombines it with a generalization of Monte Carlo tree search to perform\nindividual agent reasoning in many-agent open environments. Theoretical\nanalyses establish the number of agents to model in order to achieve acceptable\nworst case bounds on extrapolation error, as well as regret bounds on the\nagent's utility from modeling only some neighbors. Simulations of multiagent\nwildfire suppression problems demonstrate our approach's efficacy compared with\nalternative baselines.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 00:39:36 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Eck", "Adam", ""], ["Shah", "Maulik", ""], ["Doshi", "Prashant", ""], ["Soh", "Leen-Kiat", ""]]}, {"id": "1911.09137", "submitter": "Stefan Ivi\\'c", "authors": "Stefan Ivi\\'c", "title": "Motion control for autonomous heterogeneous multi-agent area search in\n  uncertain conditions", "comments": "v1", "journal-ref": null, "doi": "10.1109/TCYB.2020.3022952", "report-no": null, "categories": "math.OC cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using multiple mobile robots in search missions offers a lot of benefits, but\none needs a suitable and competent motion control algorithm which is able to\nconsider sensors characteristics, the uncertainty of target detection and\ncomplexity of needed maneuvers in order to make a multi-agent search\nautonomous. This paper provides a methodology for an autonomous two-dimensional\nsearch using multiple unmanned search agents. The proposed methodology relies\non an accurate calculation of target occurrence probability distribution based\non the initial estimated target distribution and continuous action of spatial\nvariant search agent sensors. The core of the autonomous search process is a\nhigh-level motion control for multiple search agents which utilizes the\nprobabilistic model of target occurrence via Heat Equation Driven Area Coverage\n(HEDAC) method. This centralized motion control algorithm is tailored for\nhandling a group of search agents which are heterogeneous in both motion and\nsensing characteristics. The motion of agents is directed by the gradient of\nthe potential field which provides near-ergodic exploration of the search\nspace. The proposed method is tested on three realistic search mission\nsimulations and compared with three alternative methods, where HEDAC\noutperforms all alternatives in all tests. Conventional search strategies need\nabout double the time to achieve proportionate detection rate when compared to\nHEDAC controlled search. The scalability test showed that increasing the number\nof HEDAC controlled search agents, although somewhat deteriorating the search\nefficiency, provides needed speed-up of the search. This study shows the\nflexibility and competence of the proposed method and gives a strong foundation\nfor possible real-world applications.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 19:19:14 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Ivi\u0107", "Stefan", ""]]}, {"id": "1911.09146", "submitter": "Jaskaran Grover", "authors": "Jaskaran Grover, Changliu Liu, Katia Sycara", "title": "Deadlock Analysis and Resolution in Multi-Robot Systems (Extended\n  Version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.MA cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collision avoidance for multirobot systems is a well studied problem.\nRecently, control barrier functions (CBFs) have been proposed for synthesizing\ncontrollers guarantee collision avoidance and goal stabilization for multiple\nrobots. However, it has been noted reactive control synthesis methods (such as\nCBFs) are prone to deadlock, an equilibrium of system dynamics causes robots to\ncome to a standstill before reaching their goals. In this paper, we formally\nderive characteristics of deadlock in a multirobot system uses CBFs. We propose\na novel approach to analyze deadlocks resulting from optimization based\ncontrollers (CBFs) by borrowing tools from duality theory and graph\nenumeration. Our key insight is system deadlock is characterized by a\nforce-equilibrium on robots and we show how complexity of deadlock analysis\nincreases approximately exponentially with the number of robots. This analysis\nallows us to interpret deadlock as a subset of the state space, and we prove\nthis set is non-empty, bounded and located on the boundary of the safety set.\nFinally, we use these properties to develop a provably correct decentralized\nalgorithm for deadlock resolution which ensures robots converge to their goals\nwhile avoiding collisions. We show simulation results of the resolution\nalgorithm for two and three robots and experimentally validate this algorithm\non Khepera-IV robots.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 19:52:00 GMT"}, {"version": "v2", "created": "Mon, 13 Jul 2020 04:04:44 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Grover", "Jaskaran", ""], ["Liu", "Changliu", ""], ["Sycara", "Katia", ""]]}, {"id": "1911.09484", "submitter": "Christoph Gote", "authors": "Christoph Gote, Ingo Scholtes, Frank Schweitzer", "title": "Analysing Time-Stamped Co-Editing Networks in Software Development Teams\n  using git2net", "comments": "44 pages, 24 figures, 16 tables, extended version of arXiv:1903.10180", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.MA cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data from software repositories have become an important foundation for the\nempirical study of software engineering processes. A recurring theme in the\nrepository mining literature is the inference of developer networks capturing\ne.g. collaboration, coordination, or communication from the commit history of\nprojects. Most of the studied networks are based on the co-authorship of\nsoftware artefacts. Because this neglects detailed information on code changes\nand code ownership we introduce git2net, a scalable python software that\nfacilitates the extraction of fine-grained co-editing networks in large git\nrepositories. It uses text mining techniques to analyse the detailed history of\ntextual modifications within files. We apply our tool in two case studies using\nGitHub repositories of multiple Open Source as well as a commercial software\nproject. Specifically, we use data on more than 1.2 million commits and more\nthan 25'000 developers to test a hypothesis on the relation between developer\nproductivity and co-editing patterns in software teams. We argue that git2net\nopens up a massive new source of high-resolution data on human collaboration\npatterns that can be used to advance theory in empirical software engineering,\ncomputational social science, and organisational studies.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 14:23:54 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Gote", "Christoph", ""], ["Scholtes", "Ingo", ""], ["Schweitzer", "Frank", ""]]}, {"id": "1911.09535", "submitter": "Oluwafemi Azeez", "authors": "Siddharth Ghiya, Oluwafemi Azeez, Brendan Miller", "title": "Agent Probing Interaction Policies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning in a multi agent system is difficult because these\nsystems are inherently non-stationary in nature. In such a case, identifying\nthe type of the opposite agent is crucial and can help us address this\nnon-stationary environment. We have investigated if we can employ some probing\npolicies which help us better identify the type of the other agent in the\nenvironment. We've made a simplifying assumption that the other agent has a\nstationary policy that our probing policy is trying to approximate. Our work\nextends Environmental Probing Interaction Policy framework to handle multi\nagent environments.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 15:20:43 GMT"}, {"version": "v2", "created": "Tue, 26 Nov 2019 17:56:37 GMT"}, {"version": "v3", "created": "Fri, 13 Dec 2019 16:10:42 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Ghiya", "Siddharth", ""], ["Azeez", "Oluwafemi", ""], ["Miller", "Brendan", ""]]}, {"id": "1911.09807", "submitter": "Hoa Van Nguyen", "authors": "Hoa Van Nguyen, Hamid Rezatofighi, Ba-Ngu Vo, Damith C. Ranasinghe", "title": "Multi-Objective Multi-Agent Planning for Jointly Discovering and\n  Tracking Mobile Object", "comments": "Accepted for publication to the Thirty-Fourth AAAI Conference on\n  Artificial Intelligence (AAAI-20). Added algorithm 1, background on MPOMDP\n  and OSPA", "journal-ref": null, "doi": "10.1609/aaai.v34i05.6213", "report-no": null, "categories": "cs.MA cs.RO cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the challenging problem of online planning for a team of agents\nto autonomously search and track a time-varying number of mobile objects under\nthe practical constraint of detection range limited onboard sensors. A standard\nPOMDP with a value function that either encourages discovery or accurate\ntracking of mobile objects is inadequate to simultaneously meet the conflicting\ngoals of searching for undiscovered mobile objects whilst keeping track of\ndiscovered objects. The planning problem is further complicated by\nmisdetections or false detections of objects caused by range limited sensors\nand noise inherent to sensor measurements. We formulate a novel multi-objective\nPOMDP based on information theoretic criteria, and an online multi-object\ntracking filter for the problem. Since controlling multi-agent is a well known\ncombinatorial optimization problem, assigning control actions to agents\nnecessitates a greedy algorithm. We prove that our proposed multi-objective\nvalue function is a monotone submodular set function; consequently, the greedy\nalgorithm can achieve a (1-1/e) approximation for maximizing the submodular\nmulti-objective function.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 01:51:02 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Van Nguyen", "Hoa", ""], ["Rezatofighi", "Hamid", ""], ["Vo", "Ba-Ngu", ""], ["Ranasinghe", "Damith C.", ""]]}, {"id": "1911.10055", "submitter": "Dmitry Gnatyshak", "authors": "Dmitry Gnatyshak, Luis Oliva-Felipe, Sergio \\'Alvarez-Napagao, Julian\n  Padget, Javier V\\'azquez-Salceda, Dario Garcia-Gasulla, Ulises Cort\\'es", "title": "Towards a Goal-oriented Agent-based Simulation framework for\n  High-Performance Computing", "comments": null, "journal-ref": "Frontiers in Artificial Intelligence and Applications 319 (2019)\n  329-338", "doi": "10.3233/FAIA190142", "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Currently, agent-based simulation frameworks force the user to choose between\nsimulations involving a large number of agents (at the expense of limited agent\nreasoning capability) or simulations including agents with increased reasoning\ncapabilities (at the expense of a limited number of agents per simulation).\nThis paper describes a first attempt at putting goal-oriented agents into large\nagent-based (micro-)simulations. We discuss a model for goal-oriented agents in\nHigh-Performance Computing (HPC) and then briefly discuss its implementation in\nPyCOMPSs (a library that eases the parallelisation of tasks) to build such a\nplatform that benefits from a large number of agents with the capacity to\nexecute complex cognitive agents.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 14:13:36 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Gnatyshak", "Dmitry", ""], ["Oliva-Felipe", "Luis", ""], ["\u00c1lvarez-Napagao", "Sergio", ""], ["Padget", "Julian", ""], ["V\u00e1zquez-Salceda", "Javier", ""], ["Garcia-Gasulla", "Dario", ""], ["Cort\u00e9s", "Ulises", ""]]}, {"id": "1911.10098", "submitter": "Alex Raymond", "authors": "Alex Raymond, Hatice Gunes, Amanda Prorok", "title": "Culture-Based Explainable Human-Agent Deconfliction", "comments": "9 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.HC cs.LO cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Law codes and regulations help organise societies for centuries, and as AI\nsystems gain more autonomy, we question how human-agent systems can operate as\npeers under the same norms, especially when resources are contended. We posit\nthat agents must be accountable and explainable by referring to which rules\njustify their decisions. The need for explanations is associated with user\nacceptance and trust. This paper's contribution is twofold: i) we propose an\nargumentation-based human-agent architecture to map human regulations into a\nculture for artificial agents with explainable behaviour. Our architecture\nleans on the notion of argumentative dialogues and generates explanations from\nthe history of such dialogues; and ii) we validate our architecture with a user\nstudy in the context of human-agent path deconfliction. Our results show that\nexplanations provide a significantly higher improvement in human performance\nwhen systems are more complex. Consequently, we argue that the criteria\ndefining the need of explanations should also consider the complexity of a\nsystem. Qualitative findings show that when rules are more complex,\nexplanations significantly reduce the perception of challenge for humans.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 15:51:18 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Raymond", "Alex", ""], ["Gunes", "Hatice", ""], ["Prorok", "Amanda", ""]]}, {"id": "1911.10120", "submitter": "Timothy Verstraeten", "authors": "Timothy Verstraeten and Eugenio Bargiacchi and Pieter JK Libin and Jan\n  Helsen and Diederik M Roijers and Ann Now\\'e", "title": "Multi-Agent Thompson Sampling for Bandit Applications with Sparse\n  Neighbourhood Structures", "comments": null, "journal-ref": "Sci Rep 10, 6728 (2020)", "doi": "10.1038/s41598-020-62939-3", "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-agent coordination is prevalent in many real-world applications.\nHowever, such coordination is challenging due to its combinatorial nature. An\nimportant observation in this regard is that agents in the real world often\nonly directly affect a limited set of neighbouring agents. Leveraging such\nloose couplings among agents is key to making coordination in multi-agent\nsystems feasible. In this work, we focus on learning to coordinate.\nSpecifically, we consider the multi-agent multi-armed bandit framework, in\nwhich fully cooperative loosely-coupled agents must learn to coordinate their\ndecisions to optimize a common objective. We propose multi-agent Thompson\nsampling (MATS), a new Bayesian exploration-exploitation algorithm that\nleverages loose couplings. We provide a regret bound that is sublinear in time\nand low-order polynomial in the highest number of actions of a single agent for\nsparse coordination graphs. Additionally, we empirically show that MATS\noutperforms the state-of-the-art algorithm, MAUCE, on two synthetic benchmarks,\nand a novel benchmark with Poisson distributions. An example of a\nloosely-coupled multi-agent system is a wind farm. Coordination within the wind\nfarm is necessary to maximize power production. As upstream wind turbines only\naffect nearby downstream turbines, we can use MATS to efficiently learn the\noptimal control mechanism for the farm. To demonstrate the benefits of our\nmethod toward applications we apply MATS to a realistic wind farm control task.\nIn this task, wind turbines must coordinate their alignments with respect to\nthe incoming wind vector in order to optimize power production. Our results\nshow that MATS improves significantly upon state-of-the-art coordination\nmethods in terms of performance, demonstrating the value of using MATS in\npractical applications with sparse neighbourhood structures.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 16:21:25 GMT"}, {"version": "v2", "created": "Fri, 7 Feb 2020 10:42:24 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Verstraeten", "Timothy", ""], ["Bargiacchi", "Eugenio", ""], ["Libin", "Pieter JK", ""], ["Helsen", "Jan", ""], ["Roijers", "Diederik M", ""], ["Now\u00e9", "Ann", ""]]}, {"id": "1911.10283", "submitter": "Saad Alqithami", "authors": "Saad Alqithami, Musaad Alzahrani, Fahad Alghamdi, Rahmat Budiarto,\n  Henry Hexmoor", "title": "A Measurement of Social Capital in an Open Source Software Project", "comments": "SBP-BRiMS 2019 -- International Conference on Social Computing,\n  Behavioral-Cultural Modeling & Prediction and Behavior Representation in\n  Modeling and Simulation", "journal-ref": null, "doi": "10.13140/RG.2.2.30730.41927", "report-no": null, "categories": "cs.SI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper provides an understanding of social capital in organizations that\nare open membership multi-agent systems with an emphasis in our formulation on\nthe dynamic network of social interaction that, in part, elucidate evolving\nstructures and impromptu topologies of networks. This paper, therefore, models\nan open source project as an organizational network. It provides definitions of\nsocial capital for this organizational network and formulation of the mechanism\nto optimize the social capital for achieving its goal that is optimized\nproductivity. A case study of an open source Apache-Hadoop project is\nconsidered and empirically evaluated. An analysis of how social capital can be\ncreated within this type of organizations and driven to a measurement for its\nvalue is provided. Finally, a verification on whether the social capital of the\norganizational network is proportional towards optimizing their productivity is\nconsidered.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 23:57:46 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Alqithami", "Saad", ""], ["Alzahrani", "Musaad", ""], ["Alghamdi", "Fahad", ""], ["Budiarto", "Rahmat", ""], ["Hexmoor", "Henry", ""]]}, {"id": "1911.10406", "submitter": "Elie Adam", "authors": "Elie M. Adam, Munther A. Dahleh", "title": "Generativity and Interactional Effects: an Overview", "comments": "31 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.MA cs.SI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a means to relate properties of an interconnected system to its\nseparate component systems in the presence of cascade-like phenomena. Building\non a theory of interconnection reminiscent of the behavioral approach to\nsystems theory, we introduce the notion of generativity, and its byproduct,\ngenerative effects. Cascade effects, enclosing contagion phenomena and\ncascading failures, are seen as instances of generative effects. The latter are\nprecisely the instances where properties of interest are not preserved or\nbehave very badly when systems interact. The goal is to overcome that\nobstruction. We will show how to extract mathematical objects from the systems,\nthat encode their generativity: their potential to generate new phenomena upon\ninteraction. Those objects may then be used to link the properties of the\ninterconnected system to its separate systems. Such a link will be executed\nthrough the use of exact sequences from commutative algebra.\n", "versions": [{"version": "v1", "created": "Sat, 23 Nov 2019 19:33:43 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Adam", "Elie M.", ""], ["Dahleh", "Munther A.", ""]]}, {"id": "1911.10519", "submitter": "Priyansh Saxena", "authors": "Priyansh Saxena, Shivani Tayal, Raahat Gupta, Akshat Maheshwari,\n  Gaurav Kaushal, Ritu Tiwari", "title": "Three Dimensional Route Planning for Multiple Unmanned Aerial Vehicles\n  using Salp Swarm Algorithm", "comments": "An author was mistakenly added in the paper dur to some human error.\n  Moreover the research is still under progress and we would like to upload the\n  paper with the final results once the work is complete", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.MA cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Route planning for multiple Unmanned Aerial Vehicles (UAVs) is a series of\ntranslation and rotational steps from a given start location to the destination\ngoal location. The goal of the route planning problem is to determine the most\noptimal route avoiding any collisions with the obstacles present in the\nenvironment. Route planning is an NP-hard optimization problem. In this paper,\na newly proposed Salp Swarm Algorithm (SSA) is used, and its performance is\ncompared with deterministic and other Nature-Inspired Algorithms (NIAs). The\nresults illustrate that SSA outperforms all the other meta-heuristic algorithms\nin route planning for multiple UAVs in a 3D environment. The proposed approach\nimproves the average cost and overall time by 1.25% and 6.035% respectively\nwhen compared to recently reported data. Route planning is involved in many\nreal-life applications like robot navigation, self-driving car, autonomous UAV\nfor search and rescue operations in dangerous ground-zero situations, civilian\nsurveillance, military combat and even commercial services like package\ndelivery by drones.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 12:36:18 GMT"}, {"version": "v2", "created": "Wed, 18 Dec 2019 11:31:55 GMT"}, {"version": "v3", "created": "Wed, 19 May 2021 15:14:31 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Saxena", "Priyansh", ""], ["Tayal", "Shivani", ""], ["Gupta", "Raahat", ""], ["Maheshwari", "Akshat", ""], ["Kaushal", "Gaurav", ""], ["Tiwari", "Ritu", ""]]}, {"id": "1911.10578", "submitter": "Konstantin Yakovlev S", "authors": "Konstantin Yakovlev, Anton Andreychuk, Vitaly Vorobyev", "title": "Prioritized Multi-agent Path Finding for Differential Drive Robots", "comments": "This is a pre-print version of the paper accepted to ECMR 2019\n  (https://ieeexplore.ieee.org/document/8870957)", "journal-ref": "In Proceedings of the 2019 European Conference on Mobile Robots\n  (ECMR 2019), Prague, Czech Republic, 2019, pp. 1-6", "doi": "10.1109/ECMR.2019.8870957", "report-no": null, "categories": "cs.RO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Methods for centralized planning of the collision-free trajectories for a\nfleet of mobile robots typically solve the discretized version of the problem\nand rely on numerous simplifying assumptions, e.g. moves of uniform duration,\ncardinal only translations, equal speed and size of the robots etc., thus the\nresultant plans can not always be directly executed by the real robotic\nsystems. To mitigate this issue we suggest a set of modifications to the\nprominent prioritized planner -- AA-SIPP(m) -- aimed at lifting the most\nrestrictive assumptions (syncronized translation only moves, equal size and\nspeed of the robots) and at providing robustness to the solutions. We evaluate\nthe suggested algorithm in simulation and on differential drive robots in\ntypical lab environment (indoor polygon with external video-based navigation\nsystem). The results of the evaluation provide a clear evidence that the\nalgorithm scales well to large number of robots (up to hundreds in simulation)\nand is able to produce solutions that are safely executed by the robots prone\nto imperfect trajectory following. The video of the experiments can be found at\nhttps://youtu.be/Fer_irn4BG0.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 17:38:06 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Yakovlev", "Konstantin", ""], ["Andreychuk", "Anton", ""], ["Vorobyev", "Vitaly", ""]]}, {"id": "1911.10635", "submitter": "Kaiqing Zhang", "authors": "Kaiqing Zhang, Zhuoran Yang, and Tamer Ba\\c{s}ar", "title": "Multi-Agent Reinforcement Learning: A Selective Overview of Theories and\n  Algorithms", "comments": "Invited Chapter in Handbook on RL and Control (Springer Studies in\n  Systems, Decision and Control); Proofread version from the Publisher", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have witnessed significant advances in reinforcement learning\n(RL), which has registered great success in solving various sequential\ndecision-making problems in machine learning. Most of the successful RL\napplications, e.g., the games of Go and Poker, robotics, and autonomous\ndriving, involve the participation of more than one single agent, which\nnaturally fall into the realm of multi-agent RL (MARL), a domain with a\nrelatively long history, and has recently re-emerged due to advances in\nsingle-agent RL techniques. Though empirically successful, theoretical\nfoundations for MARL are relatively lacking in the literature. In this chapter,\nwe provide a selective overview of MARL, with focus on algorithms backed by\ntheoretical analysis. More specifically, we review the theoretical results of\nMARL algorithms mainly within two representative frameworks, Markov/stochastic\ngames and extensive-form games, in accordance with the types of tasks they\naddress, i.e., fully cooperative, fully competitive, and a mix of the two. We\nalso introduce several significant but challenging applications of these\nalgorithms. Orthogonal to the existing reviews on MARL, we highlight several\nnew angles and taxonomies of MARL theory, including learning in extensive-form\ngames, decentralized MARL with networked agents, MARL in the mean-field regime,\n(non-)convergence of policy-based methods for learning in games, etc. Some of\nthe new angles extrapolate from our own research endeavors and interests. Our\noverall goal with this chapter is, beyond providing an assessment of the\ncurrent state of the field on the mark, to identify fruitful future research\ndirections on theoretical studies of MARL. We expect this chapter to serve as\ncontinuing stimulus for researchers interested in working on this exciting\nwhile challenging topic.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 22:50:32 GMT"}, {"version": "v2", "created": "Wed, 28 Apr 2021 21:33:13 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Zhang", "Kaiqing", ""], ["Yang", "Zhuoran", ""], ["Ba\u015far", "Tamer", ""]]}, {"id": "1911.10715", "submitter": "Weixun Wang", "authors": "Yong Liu, Weixun Wang, Yujing Hu, Jianye Hao, Xingguo Chen, Yang Gao", "title": "Multi-Agent Game Abstraction via Graph Attention Neural Network", "comments": "Accepted by AAAI2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In large-scale multi-agent systems, the large number of agents and complex\ngame relationship cause great difficulty for policy learning. Therefore,\nsimplifying the learning process is an important research issue. In many\nmulti-agent systems, the interactions between agents often happen locally,\nwhich means that agents neither need to coordinate with all other agents nor\nneed to coordinate with others all the time. Traditional methods attempt to use\npre-defined rules to capture the interaction relationship between agents.\nHowever, the methods cannot be directly used in a large-scale environment due\nto the difficulty of transforming the complex interactions between agents into\nrules. In this paper, we model the relationship between agents by a complete\ngraph and propose a novel game abstraction mechanism based on two-stage\nattention network (G2ANet), which can indicate whether there is an interaction\nbetween two agents and the importance of the interaction. We integrate this\ndetection mechanism into graph neural network-based multi-agent reinforcement\nlearning for conducting game abstraction and propose two novel learning\nalgorithms GA-Comm and GA-AC. We conduct experiments in Traffic Junction and\nPredator-Prey. The results indicate that the proposed methods can simplify the\nlearning process and meanwhile get better asymptotic performance compared with\nstate-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 06:24:46 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Liu", "Yong", ""], ["Wang", "Weixun", ""], ["Hu", "Yujing", ""], ["Hao", "Jianye", ""], ["Chen", "Xingguo", ""], ["Gao", "Yang", ""]]}, {"id": "1911.11053", "submitter": "Nicolas Maudet", "authors": "Parham Shams and Aur\\'elie Beynier and Sylvain Bouveret and Nicolas\n  Maudet", "title": "Fair in the Eyes of Others", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Envy-freeness is a widely studied notion in resource allocation, capturing\nsome aspects of fairness. The notion of envy being inherently subjective\nthough, it might be the case that an agent envies another agent, but that she\nobjectively has no reason to do so. The difficulty here is to define the notion\nof objectivity, since no ground-truth can properly serve as a basis of this\ndefinition. A natural approach is to consider the judgement of the other agents\nas a proxy for objectivity. Building on previous work by Parijs (who introduced\n\"unanimous envy\") we propose the notion of approval envy: an agent $a_i$\nexperiences approval envy towards $a_j$ if she is envious of $a_j$, and\nsufficiently many agents agree that this should be the case, from their own\nperspectives. Some interesting properties of this notion are put forward.\nComputing the minimal threshold guaranteeing approval envy clearly inherits\nwell-known intractable results from envy-freeness, but (i) we identify some\ntractable cases such as house allocation; and (ii) we provide a general method\nbased on a mixed integer programming encoding of the problem, which proves to\nbe efficient in practice. This allows us in particular to show experimentally\nthat existence of such allocations, with a rather small threshold, is very\noften observed.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 17:05:27 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Shams", "Parham", ""], ["Beynier", "Aur\u00e9lie", ""], ["Bouveret", "Sylvain", ""], ["Maudet", "Nicolas", ""]]}, {"id": "1911.11356", "submitter": "Viet Trinh", "authors": "Viet Trinh, Roberto Manduchi", "title": "Semantic Interior Mapology: A Toolbox For Indoor Scene Description From\n  Architectural Floor Plans", "comments": "9 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the Semantic Interior Mapology (SIM) toolbox for the conversion\nof a floor plan and its room contents (such as furnitures) to a vectorized\nform. The toolbox is composed of the Map Conversion toolkit and the Map\nPopulation toolkit. The Map Conversion toolkit allows one to quickly trace the\nlayout of a floor plan, and to generate a GeoJSON file that can be rendered in\n3D using web applications such as Mapbox. The Map Population toolkit takes the\n3D scan of a room in the building (acquired from an RGB-D camera), and, through\na semi-automatic process, populates individual objects of interest with a\ncorrect dimension and position in the GeoJSON representation of the building.\nSIM is easy to use and produces accurate results even in the case of complex\nbuilding layouts.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 05:56:43 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Trinh", "Viet", ""], ["Manduchi", "Roberto", ""]]}, {"id": "1911.11381", "submitter": "Mohammadreza Doostmohammadian", "authors": "Mohammadreza Doostmohammadian, Usman Khan", "title": "On the Complexity of Minimum-Cost Networked Estimation of Self-Damped\n  Dynamical Systems", "comments": "accepted at IEEE transactions on network Science and Engineering", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.MA cs.SI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the optimal design of networked estimators to\nminimize the communication/measurement cost under the networked observability\nconstraint. This problem is known as the minimum-cost networked estimation\nproblem, which is generally claimed to be NP-hard. The main contribution of\nthis work is to provide a polynomial-order solution for this problem under the\nconstraint that the underlying dynamical system is self-damped. Using\nstructural analysis, we subdivide the main problem into two NP-hard subproblems\nknown as (i) optimal sensor selection, and (ii) minimum-cost communication\nnetwork. For self-damped dynamical systems, we provide a polynomial-order\nsolution for subproblem (i). Further, we show that the subproblem (ii) is of\npolynomial-order complexity if the links in the communication network are\nbidirectional. We provide an illustrative example to explain the methodologies.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 07:44:23 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Doostmohammadian", "Mohammadreza", ""], ["Khan", "Usman", ""]]}, {"id": "1911.11555", "submitter": "Zhiliang Chen", "authors": "Zhiliang Chen", "title": "Fair Multi-party Machine Learning -- a Game Theoretic approach", "comments": "Undergraduate Thesis at National University of Singapore, School of\n  Computer Science; in preparation for publication in 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  High performance machine learning models have become highly dependent on the\navailability of large quantity and quality of training data. To achieve this,\nvarious central agencies such as the government have suggested for different\ndata providers to pool their data together to learn a unified predictive model,\nwhich performs better. However, these providers are usually profit-driven and\nwould only agree to participate inthe data sharing process if the process is\ndeemed both profitable and fair for themselves. Due to the lack of existing\nliterature, it is unclear whether a fair and stable outcome is possible in such\ndata sharing processes. Hence, we wish to investigate the outcomes surrounding\nthese scenarios and study if data providers would even agree to collaborate in\nthe first place. Tapping on cooperative game concepts in Game Theory, we\nintroduce the data sharing process between a group of agents as a new class of\ncooperative games with modified definition of stability and fairness. Using\nthese new definitions, we then theoretically study the optimal and suboptimal\noutcomes of such data sharing processes and their sensitivity to\nperturbation.Through experiments, we present intuitive insights regarding\ntheoretical results analysed in this paper and discuss various ways in which\ndata can be valued reasonably.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 07:31:21 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Chen", "Zhiliang", ""]]}, {"id": "1911.11699", "submitter": "Jacopo Panerati", "authors": "Rupert Mitchell, Jenny Fletcher, Jacopo Panerati, Amanda Prorok\n  (University of Cambridge)", "title": "Multi-Vehicle Mixed-Reality Reinforcement Learning for Autonomous\n  Multi-Lane Driving", "comments": "10 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous driving promises to transform road transport. Multi-vehicle and\nmulti-lane scenarios, however, present unique challenges due to constrained\nnavigation and unpredictable vehicle interactions. Learning-based\nmethods---such as deep reinforcement learning---are emerging as a promising\napproach to automatically design intelligent driving policies that can cope\nwith these challenges. Yet, the process of safely learning multi-vehicle\ndriving behaviours is hard: while collisions---and their near-avoidance---are\nessential to the learning process, directly executing immature policies on\nautonomous vehicles raises considerable safety concerns. In this article, we\npresent a safe and efficient framework that enables the learning of driving\npolicies for autonomous vehicles operating in a shared workspace, where the\nabsence of collisions cannot be guaranteed. Key to our learning procedure is a\nsim2real approach that uses real-world online policy adaptation in a\nmixed-reality setup, where other vehicles and static obstacles exist in the\nvirtual domain. This allows us to perform safe learning by simulating (and\nlearning from) collisions between the learning agent(s) and other objects in\nvirtual reality. Our results demonstrate that, after only a few runs in\nmixed-reality, collisions are significantly reduced.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 17:08:40 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 21:06:43 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Mitchell", "Rupert", "", "University of Cambridge"], ["Fletcher", "Jenny", "", "University of Cambridge"], ["Panerati", "Jacopo", "", "University of Cambridge"], ["Prorok", "Amanda", "", "University of Cambridge"]]}, {"id": "1911.12266", "submitter": "Mattia Bianchi", "authors": "Mattia Bianchi and Sergio Grammatico", "title": "Continuous-time fully distributed generalized Nash equilibrium seeking\n  for multi-integrator agents", "comments": "Accepted in Automatica", "journal-ref": "Automatica, Volume 129, July 2021", "doi": "10.1016/j.automatica.2021.109660", "report-no": null, "categories": "math.OC cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider strongly monotone games with convex separable coupling\nconstraints, played by dynamical agents, in a partial-decision information\nscenario. We start by designing continuous-time fully distributed feedback\ncontrollers, based on consensus and primal-dual gradient dynamics, to seek a\ngeneralized Nash equilibrium in networks of single-integrator agents. Our first\nsolution adopts a fixed gain, whose choice requires the knowledge of some\nglobal parameters of the game. To relax this requirement, we conceive a\ncontroller that can be tuned in a completely decentralized fashion, thanks to\nthe use of uncoordinated integral adaptive weights. We further introduce\nalgorithms specifically devised for generalized aggregative games. Finally, we\nadapt all our control schemes to deal with heterogeneous multi-integrator\nagents and, in turn, with nonlinear feedback-linearizable dynamical systems.\nFor all the proposed dynamics, we show convergence to a variational\nequilibrium, by leveraging monotonicity properties and stability theory for\nprojected dynamical systems.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 08:59:19 GMT"}, {"version": "v2", "created": "Fri, 19 Mar 2021 12:32:22 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Bianchi", "Mattia", ""], ["Grammatico", "Sergio", ""]]}, {"id": "1911.12303", "submitter": "Shantanu Chakraborty D.Eng.", "authors": "Shantanu Chakraborty, Tim Baarslag, Michael Kaisers", "title": "Automated Peer-to-peer Negotiation for Energy Contract Settlements in\n  Residential Cooperatives", "comments": "arXiv admin note: substantial text overlap with arXiv:1807.10978", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an automated peer-to-peer negotiation strategy for\nsettling energy contracts among prosumers in a Residential Energy Cooperative\nconsidering heterogeneity prosumer preferences. The heterogeneity arises from\nprosumers' evaluation of energy contracts through multiple societal and\nenvironmental criteria and the prosumers' private preferences over those\ncriteria. The prosumers engage in bilateral negotiations with peers to mutually\nagree on periodical energy contracts/loans consisting of the energy volume to\nbe exchanged at that period and the return time of the exchanged energy. The\nnegotiating prosumers navigate through a common negotiation domain consisting\nof potential energy contracts and evaluate those contracts from their\nvaluations on the entailed criteria against a utility function that is robust\nagainst generation and demand uncertainty. From the repeated interactions, a\nprosumer gradually learns about the compatibility of its peers in reaching\nenergy contracts that are closer to Nash solutions. Empirical evaluation on\nreal demand, generation and storage profiles -- in multiple system scales --\nillustrates that the proposed negotiation based strategy can increase the\nsystem efficiency (measured by utilitarian social welfare) and fairness\n(measured by Nash social welfare) over a baseline strategy and an individual\nflexibility control strategy representing the status quo strategy. We thus\nelicit system benefits from peer-to-peer flexibility exchange already without\nany central coordination and market operator, providing a simple yet flexible\nand effective paradigm that complements existing markets.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 02:28:01 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Chakraborty", "Shantanu", ""], ["Baarslag", "Tim", ""], ["Kaisers", "Michael", ""]]}, {"id": "1911.12504", "submitter": "Xing Xu", "authors": "Xing Xu, Rongpeng Li, Zhifeng Zhao, Honggang Zhang", "title": "Stigmergic Independent Reinforcement Learning for Multi-Agent\n  Collaboration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid evolution of wireless mobile devices, there emerges an\nincreased need to design effective collaboration mechanisms between intelligent\nagents, so as to gradually approach the final collective objective through\ncontinuously learning from the environment based on their individual\nobservations. In this regard, independent reinforcement learning (IRL) is often\ndeployed in multi-agent collaboration to alleviate the problem of a\nnon-stationary learning environment. However, behavioral strategies of\nintelligent agents in IRL can only be formulated upon their local individual\nobservations of the global environment, and appropriate communication\nmechanisms must be introduced to reduce their behavioral localities. In this\npaper, we address the problem of communication between intelligent agents in\nIRL by jointly adopting mechanisms with two different scales. For the large\nscale, we introduce the stigmergy mechanism as an indirect communication bridge\nbetween independent learning agents, and carefully design a mathematical method\nto indicate the impact of digital pheromone. For the small scale, we propose a\nconflict-avoidance mechanism between adjacent agents by implementing an\nadditionally embedded neural network to provide more opportunities for\nparticipants with higher action priorities. In addition, we present a federal\ntraining method to effectively optimize the neural network of each agent in a\ndecentralized manner. Finally, we establish a simulation scenario in which a\nnumber of mobile agents in a certain area move automatically to form a\nspecified target shape. Extensive simulations demonstrate the effectiveness of\nour proposed method.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 03:11:17 GMT"}, {"version": "v2", "created": "Sat, 10 Oct 2020 02:43:50 GMT"}, {"version": "v3", "created": "Sat, 30 Jan 2021 04:55:57 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Xu", "Xing", ""], ["Li", "Rongpeng", ""], ["Zhao", "Zhifeng", ""], ["Zhang", "Honggang", ""]]}, {"id": "1911.12716", "submitter": "Chen Dingding", "authors": "Dingding Chen and Yanchen Deng and Ziyu Chen and Wenxing Zhang and\n  Zhongshi He", "title": "HS-CAI: A Hybrid DCOP Algorithm via Combining Search with Context-based\n  Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Search and inference are two main strategies for optimally solving\nDistributed Constraint Optimization Problems (DCOPs). Recently, several\nalgorithms were proposed to combine their advantages. Unfortunately, such\nalgorithms only use an approximated inference as a one-shot preprocessing phase\nto construct the initial lower bounds which lead to inefficient pruning under\nthe limited memory budget. On the other hand, iterative inference algorithms\n(e.g., MB-DPOP) perform a context-based complete inference for all possible\ncontexts but suffer from tremendous traffic overheads. In this paper, $(i)$\nhybridizing search with context-based inference, we propose a complete\nalgorithm for DCOPs, named {HS-CAI} where the inference utilizes the contexts\nderived from the search process to establish tight lower bounds while the\nsearch uses such bounds for efficient pruning and thereby reduces contexts for\nthe inference. Furthermore, $(ii)$ we introduce a context evaluation mechanism\nto select the context patterns for the inference to further reduce the\noverheads incurred by iterative inferences. Finally, $(iii)$ we prove the\ncorrectness of our algorithm and the experimental results demonstrate its\nsuperiority over the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 13:54:24 GMT"}, {"version": "v2", "created": "Fri, 20 Dec 2019 13:26:56 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Chen", "Dingding", ""], ["Deng", "Yanchen", ""], ["Chen", "Ziyu", ""], ["Zhang", "Wenxing", ""], ["He", "Zhongshi", ""]]}, {"id": "1911.12825", "submitter": "Jhelum Chakravorty", "authors": "Jhelum Chakravorty, Nadeem Ward, Julien Roy, Maxime\n  Chevalier-Boisvert, Sumana Basu, Andrei Lupu, Doina Precup", "title": "Option-Critic in Cooperative Multi-agent Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA cs.SY eess.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate learning temporal abstractions in cooperative\nmulti-agent systems, using the options framework (Sutton et al, 1999). First,\nwe address the planning problem for the decentralized POMDP represented by the\nmulti-agent system, by introducing a \\emph{common information approach}. We use\nthe notion of \\emph{common beliefs} and broadcasting to solve an equivalent\ncentralized POMDP problem. Then, we propose the Distributed Option Critic (DOC)\nalgorithm, which uses centralized option evaluation and decentralized\nintra-option improvement. We theoretically analyze the asymptotic convergence\nof DOC and build a new multi-agent environment to demonstrate its validity. Our\nexperiments empirically show that DOC performs competitively against baselines\nand scales with the number of agents.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 18:38:19 GMT"}, {"version": "v2", "created": "Mon, 6 Jan 2020 05:50:51 GMT"}, {"version": "v3", "created": "Thu, 19 Mar 2020 23:11:08 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Chakravorty", "Jhelum", ""], ["Ward", "Nadeem", ""], ["Roy", "Julien", ""], ["Chevalier-Boisvert", "Maxime", ""], ["Basu", "Sumana", ""], ["Lupu", "Andrei", ""], ["Precup", "Doina", ""]]}, {"id": "1911.13044", "submitter": "Todor Davchev", "authors": "Todor Davchev, Michael Burke, Subramanian Ramamoorthy", "title": "Learning Structured Representations of Spatial and Interactive Dynamics\n  for Trajectory Prediction in Crowded Scenes", "comments": null, "journal-ref": "IEEE Robotics and Automation Letters 2021", "doi": "10.1109/LRA.2020.3047778", "report-no": null, "categories": "cs.LG cs.CV cs.MA cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Context plays a significant role in the generation of motion for dynamic\nagents in interactive environments. This work proposes a modular method that\nutilises a learned model of the environment for motion prediction. This\nmodularity explicitly allows for unsupervised adaptation of trajectory\nprediction models to unseen environments and new tasks by relying on unlabelled\nimage data only. We model both the spatial and dynamic aspects of a given\nenvironment alongside the per agent motions. This results in more informed\nmotion prediction and allows for performance comparable to the\nstate-of-the-art. We highlight the model's prediction capability using a\nbenchmark pedestrian prediction problem and a robot manipulation task and show\nthat we can transfer the predictor across these tasks in a completely\nunsupervised way. The proposed approach allows for robust and label efficient\nforward modelling, and relaxes the need for full model re-training in new\nenvironments.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 10:42:10 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 10:56:41 GMT"}, {"version": "v3", "created": "Fri, 17 Jan 2020 11:34:06 GMT"}, {"version": "v4", "created": "Sat, 16 May 2020 09:29:35 GMT"}, {"version": "v5", "created": "Sun, 16 Aug 2020 18:47:40 GMT"}, {"version": "v6", "created": "Sat, 2 Jan 2021 13:24:01 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Davchev", "Todor", ""], ["Burke", "Michael", ""], ["Ramamoorthy", "Subramanian", ""]]}]