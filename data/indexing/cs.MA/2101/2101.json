[{"id": "2101.00161", "submitter": "Jin Gyu Lee Dr", "authors": "Jin Gyu Lee, Hyungbo Shim", "title": "Design of heterogeneous multi-agent system for distributed computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A group behavior of a heterogeneous multi-agent system is studied which obeys\nan \"average of individual vector fields\" under strong couplings among the\nagents. Under stability of the averaged dynamics (not asking stability of\nindividual agents), the behavior of heterogeneous multi-agent system can be\nestimated by the solution to the averaged dynamics. A following idea is to\n\"design\" individual agent's dynamics such that the averaged dynamics performs\nthe desired task. A few applications are discussed including estimation of the\nnumber of agents in a network, distributed least-squares or median solver,\ndistributed optimization, distributed state estimation, and robust\nsynchronization of coupled oscillators. Since stability of the averaged\ndynamics makes the initial conditions forgotten as time goes on, these\nalgorithms are initialization-free and suitable for plug-and-play operation. At\nlast, nonlinear couplings are also considered, which potentially asserts that\nenforced synchronization gives rise to an emergent behavior of a heterogeneous\nmulti-agent system.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jan 2021 04:39:06 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Lee", "Jin Gyu", ""], ["Shim", "Hyungbo", ""]]}, {"id": "2101.00201", "submitter": "Jun Ma", "authors": "Xiaoxue Zhang, Zilong Cheng, Jun Ma, Sunan Huang, Frank L. Lewis, Tong\n  Heng Lee", "title": "Semi-Definite Relaxation Based ADMM for Cooperative Planning and Control\n  of Connected Autonomous Vehicles", "comments": "11 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the cooperative planning and control problem for\nmultiple connected autonomous vehicles (CAVs) in different scenarios. In the\nexisting literature, most of the methods suffer from significant problems in\ncomputational efficiency. Besides, as the optimization problem is nonlinear and\nnonconvex, it typically poses great difficultly in determining the optimal\nsolution. To address this issue, this work proposes a novel and completely\nparallel computation framework by leveraging the alternating direction method\nof multipliers (ADMM). The nonlinear and nonconvex optimization problem in the\nautonomous driving problem can be divided into two manageable subproblems; and\nthe resulting subproblems can be solved by using effective optimization methods\nin a parallel framework. Here, the differential dynamic programming (DDP)\nalgorithm is capable of addressing the nonlinearity of the system dynamics\nrather effectively; and the nonconvex coupling constraints with small\ndimensions can be approximated by invoking the notion of semi-definite\nrelaxation (SDR), which can also be solved in a very short time. Due to the\nparallel computation and efficient relaxation of nonconvex constraints, our\nproposed approach effectively realizes real-time implementation and thus also\nextra assurance of driving safety is provided. In addition, two transportation\nscenarios for multiple CAVs are used to illustrate the effectiveness and\nefficiency of the proposed method.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jan 2021 09:08:01 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Zhang", "Xiaoxue", ""], ["Cheng", "Zilong", ""], ["Ma", "Jun", ""], ["Huang", "Sunan", ""], ["Lewis", "Frank L.", ""], ["Lee", "Tong Heng", ""]]}, {"id": "2101.00202", "submitter": "Jun Ma", "authors": "Xiaoxue Zhang, Jun Ma, Zilong Cheng, Frank L. Lewis, Tong Heng Lee", "title": "Sequential Convex Programming for Collaboration of Connected and\n  Automated Vehicles", "comments": "11 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.MA cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the collaboration of multiple connected and automated\nvehicles (CAVs) in different scenarios. In general, the collaboration of CAVs\ncan be formulated as a nonlinear and nonconvex model predictive control (MPC)\nproblem. Most of the existing approaches available for utilization to solve\nsuch an optimization problem suffer from the drawback of considerable\ncomputational burden, which hinders the practical implementation in real time.\nThis paper proposes the use of sequential convex programming (SCP), which is a\npowerful approach to solving the nonlinear and nonconvex MPC problem in real\ntime. To appropriately deploy the methodology, as a first stage, SCP requires\nlinearization and discretization when addressing the nonlinear dynamics of the\nsystem model adequately. Based on the linearization and discretization, the\noriginal MPC problem can be transformed into a quadratically constrained\nquadratic programming (QCQP) problem. Besides, SCP also involves\nconvexification to handle the associated nonconvex constraints. Thus, the\nnonconvex QCQP can be reduced to a quadratic programming (QP) problem that can\nbe solved rather quickly. Therefore, the computational efficiency is suitably\nimproved despite the existence of nonlinear and nonconvex characteristics,\nwhereby the implementation is realized in real time. Furthermore, simulation\nresults in three different scenarios of autonomous driving are presented to\nvalidate the effectiveness and efficiency of our proposed approach.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jan 2021 09:19:04 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Zhang", "Xiaoxue", ""], ["Ma", "Jun", ""], ["Cheng", "Zilong", ""], ["Lewis", "Frank L.", ""], ["Lee", "Tong Heng", ""]]}, {"id": "2101.00671", "submitter": "Ahmad Reza Cheraghi", "authors": "Ahmad Reza Cheraghi, Sahdia Shahzad, Kalman Graffi", "title": "Past, Present, and Future of Swarm Robotics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Swarm Robotics is an emerging field of adapting the phenomenon of natural\nswarms to robotics. It is a study of robots that are aimed to mimic natural\nswarms, like ants and birds, to form a system that is scalable, flexible, and\nrobust. These robots show self-organization, autonomy, cooperation, and\ncoordination amongst themselves. The cost and design complexity factor is aimed\nto keep low, hence trying to form systems that are very much similar to natural\nswarms. The robots operate without any central entity to control them, and the\ncommunication amongst the robots can either be direct (robot-to-robot) or\nindirect (robot-to-environment). Swarm robotics has a wide range of application\nfields, from simple household tasks to military missions. This paper reviews\nthe swarm robotics approach from its history to its future. It discusses the\nbasic idea of swarm robotics, its important features, simulators, projects,\nreal life applications and some future ideas.\n", "versions": [{"version": "v1", "created": "Sun, 3 Jan 2021 17:27:36 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Cheraghi", "Ahmad Reza", ""], ["Shahzad", "Sahdia", ""], ["Graffi", "Kalman", ""]]}, {"id": "2101.00746", "submitter": "Liwen Zhu", "authors": "Liwen Zhu, Peixi Peng, Zongqing Lu, Xiangqian Wang, Yonghong Tian", "title": "Variationally and Intrinsically motivated reinforcement learning for\n  decentralized traffic signal control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  One of the biggest challenges in multi-agent reinforcement learning is\ncoordination, a typical application scenario of this is traffic signal control.\nRecently, it has attracted a rising number of researchers and has become a hot\nresearch field with great practical significance. In this paper, we propose a\nnovel method called MetaVRS~(Meta Variational RewardShaping) for traffic signal\ncoordination control. By heuristically applying the intrinsic reward to the\nenvironmental reward, MetaVRS can wisely capture the agent-to-agent interplay.\nBesides, latent variables generated by VAE are brought into policy for\nautomatically tradeoff between exploration and exploitation to optimize the\npolicy. In addition, meta learning was used in decoder for faster adaptation\nand better approximation. Empirically, we demonstate that MetaVRS substantially\noutperforms existing methods and shows superior adaptability, which predictably\nhas a far-reaching significance to the multi-agent traffic signal coordination\ncontrol.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2021 03:06:08 GMT"}, {"version": "v2", "created": "Tue, 5 Jan 2021 07:09:38 GMT"}, {"version": "v3", "created": "Wed, 6 Jan 2021 02:18:51 GMT"}, {"version": "v4", "created": "Wed, 20 Jan 2021 06:56:50 GMT"}], "update_date": "2021-01-21", "authors_parsed": [["Zhu", "Liwen", ""], ["Peng", "Peixi", ""], ["Lu", "Zongqing", ""], ["Wang", "Xiangqian", ""], ["Tian", "Yonghong", ""]]}, {"id": "2101.01300", "submitter": "Waheed Bajwa", "authors": "Arpita Gang and Waheed U. Bajwa", "title": "A Linearly Convergent Algorithm for Distributed Principal Component\n  Analysis", "comments": "33 pages; 15 figures; preprint of a journal paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.MA eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Principal Component Analysis (PCA) is the workhorse tool for dimensionality\nreduction in this era of big data. While often overlooked, the purpose of PCA\nis not only to reduce data dimensionality, but also to yield features that are\nuncorrelated. Furthermore, the ever-increasing volume of data in the modern\nworld often requires storage of data samples across multiple machines, which\nprecludes the use of centralized PCA algorithms. This paper focuses on the dual\nobjective of PCA, namely, dimensionality reduction and decorrelation of\nfeatures, but in a distributed setting. This requires estimating the\neigenvectors of the data covariance matrix, as opposed to only estimating the\nsubspace spanned by the eigenvectors, when data is distributed across a network\nof machines. Although a few distributed solutions to the PCA problem have been\nproposed recently, convergence guarantees and/or communications overhead of\nthese solutions remain a concern. With an eye towards communications\nefficiency, this paper introduces a feedforward neural network-based one\ntime-scale distributed PCA algorithm termed Distributed Sanger's Algorithm\n(DSA) that estimates the eigenvectors of the data covariance matrix when data\nis distributed across an undirected and arbitrarily connected network of\nmachines. Furthermore, the proposed algorithm is shown to converge linearly to\na neighborhood of the true solution. Numerical results are also provided to\ndemonstrate the efficacy of the proposed solution.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2021 00:51:14 GMT"}, {"version": "v2", "created": "Fri, 28 May 2021 20:04:10 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Gang", "Arpita", ""], ["Bajwa", "Waheed U.", ""]]}, {"id": "2101.01572", "submitter": "Anshuka Rangi", "authors": "Anshuka Rangi, Massimo Franceschetti and Long Tran-Thanh", "title": "Sequential Choice Bandits with Feedback for Personalizing users'\n  experience", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we study sequential choice bandits with feedback. We propose\nbandit algorithms for a platform that personalizes users' experience to\nmaximize its rewards. For each action directed to a given user, the platform is\ngiven a positive reward, which is a non-decreasing function of the action, if\nthis action is below the user's threshold. Users are equipped with a patience\nbudget, and actions that are above the threshold decrease the user's patience.\nWhen all patience is lost, the user abandons the platform. The platform\nattempts to learn the thresholds of the users in order to maximize its rewards,\nbased on two different feedback models describing the information pattern\navailable to the platform at each action. We define a notion of regret by\ndetermining the best action to be taken when the platform knows that the user's\nthreshold is in a given interval. We then propose bandit algorithms for the two\nfeedback models and show that upper and lower bounds on the regret are of the\norder of $\\tilde{O}(N^{2/3})$ and $\\tilde\\Omega(N^{2/3})$, respectively, where\n$N$ is the total number of users. Finally, we show that the waiting time of any\nuser before receiving a personalized experience is uniform in $N$.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2021 15:04:10 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Rangi", "Anshuka", ""], ["Franceschetti", "Massimo", ""], ["Tran-Thanh", "Long", ""]]}, {"id": "2101.01860", "submitter": "Aaquib Tabrez", "authors": "Aaquib Tabrez, Ryan Leonard, Bradley Hayes", "title": "One-shot Policy Elicitation via Semantic Reward Manipulation", "comments": "17 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Synchronizing expectations and knowledge about the state of the world is an\nessential capability for effective collaboration. For robots to effectively\ncollaborate with humans and other autonomous agents, it is critical that they\nbe able to generate intelligible explanations to reconcile differences between\ntheir understanding of the world and that of their collaborators. In this work\nwe present Single-shot Policy Explanation for Augmenting Rewards (SPEAR), a\nnovel sequential optimization algorithm that uses semantic explanations derived\nfrom combinations of planning predicates to augment agents' reward functions,\ndriving their policies to exhibit more optimal behavior. We provide an\nexperimental validation of our algorithm's policy manipulation capabilities in\ntwo practically grounded applications and conclude with a performance analysis\nof SPEAR on domains of increasingly complex state space and predicate counts.\nWe demonstrate that our method makes substantial improvements over the\nstate-of-the-art in terms of runtime and addressable problem size, enabling an\nagent to leverage its own expertise to communicate actionable information to\nimprove another's performance.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jan 2021 04:11:22 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Tabrez", "Aaquib", ""], ["Leonard", "Ryan", ""], ["Hayes", "Bradley", ""]]}, {"id": "2101.01978", "submitter": "Madhu Vadali", "authors": "Aditya Rathi, Rohith G, and Madhu Vadali", "title": "Dynamic Prioritization for Conflict-Free Path Planning of Multi-Robot\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.MA", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Planning collision-free paths for multi-robot systems (MRS) is a challenging\nproblem because of the safety and efficiency constraints required for\nreal-world solutions. Even though coupled path planning approaches provide\noptimal collision-free paths for each agent of the MRS, they search the\ncomposite space of all the agents and therefore, suffer from exponential\nincrease in computation with the number of robots. On the other hand,\nprioritized approaches provide a practical solution to applications with large\nnumber of robots, especially when path computation time and collision avoidance\ntake precedence over guaranteed globally optimal solution. While most\ncentrally-planned algorithms use static prioritization, a dynamic\nprioritization algorithm, PD*, is proposed that employs a novel metric, called\nfreedom index, to decide the priority order of the robots at each time step.\nThis allows the PD* algorithm to simultaneously plan the next step for all\nrobots while ensuring collision-free operation in obstacle ridden environments.\nExtensive simulations were performed to test and compare the performance of the\nproposed PD* scheme with other state-of-the-art algorithms. It was found that\nPD* improves upon the computational time by 25% while providing solutions of\nsimilar path lengths. Increase in efficiency was particularly prominent in\nscenarios with large number of robots and/or higher obstacle densities, where\nthe probability of collisions is higher, suggesting the suitability of PD* in\nsolving such problems.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jan 2021 11:31:44 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Rathi", "Aditya", ""], ["G", "Rohith", ""], ["Vadali", "Madhu", ""]]}, {"id": "2101.02074", "submitter": "Tobias Kronauer", "authors": "Tobias Kronauer, Joshwa Pohlmann, Maximilian Matthe, Till Smejkal,\n  Gerhard Fettweis", "title": "Latency Analysis of ROS2 Multi-Node Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.DC cs.MA cs.PF cs.SE", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The Robot Operating System 2 (ROS2) targets distributed real-time systems and\nis widely used in the robotics community. Especially in these systems, latency\nin data processing and communication can lead to instabilities. Though being\nhighly configurable with respect to latency, ROS2 is often used with its\ndefault settings.\n  In this paper, we investigate the end-to-end latency of ROS2 for distributed\nsystems with default settings and different Data Distribution Service (DDS)\nmiddlewares. In addition, we profile the ROS2 stack and point out latency\nbottlenecks. Our findings indicate that end-to-end latency strongly depends on\nthe used DDS middleware. Moreover, we show that ROS2 can lead to 50% latency\noverhead compared to using low-level DDS communications. Our results imply\nguidelines for designing distributed ROS2 architectures and indicate\npossibilities for reducing the ROS2 overhead.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jan 2021 14:50:09 GMT"}, {"version": "v2", "created": "Tue, 12 Jan 2021 09:15:21 GMT"}, {"version": "v3", "created": "Fri, 11 Jun 2021 06:10:04 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Kronauer", "Tobias", ""], ["Pohlmann", "Joshwa", ""], ["Matthe", "Maximilian", ""], ["Smejkal", "Till", ""], ["Fettweis", "Gerhard", ""]]}, {"id": "2101.02349", "submitter": "Diddigi Raghuram Bharadwaj", "authors": "P.Parnika, Raghuram Bharadwaj Diddigi, Sai Koti Reddy Danda and\n  Shalabh Bhatnagar", "title": "Attention Actor-Critic algorithm for Multi-Agent Constrained\n  Co-operative Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we consider the problem of computing optimal actions for\nReinforcement Learning (RL) agents in a co-operative setting, where the\nobjective is to optimize a common goal. However, in many real-life\napplications, in addition to optimizing the goal, the agents are required to\nsatisfy certain constraints specified on their actions. Under this setting, the\nobjective of the agents is to not only learn the actions that optimize the\ncommon objective but also meet the specified constraints. In recent times, the\nActor-Critic algorithm with an attention mechanism has been successfully\napplied to obtain optimal actions for RL agents in multi-agent environments. In\nthis work, we extend this algorithm to the constrained multi-agent RL setting.\nThe idea here is that optimizing the common goal and satisfying the constraints\nmay require different modes of attention. By incorporating different attention\nmodes, the agents can select useful information required for optimizing the\nobjective and satisfying the constraints separately, thereby yielding better\nactions. Through experiments on benchmark multi-agent environments, we show the\neffectiveness of our proposed algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2021 03:21:15 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Parnika", "P.", ""], ["Diddigi", "Raghuram Bharadwaj", ""], ["Danda", "Sai Koti Reddy", ""], ["Bhatnagar", "Shalabh", ""]]}, {"id": "2101.02476", "submitter": "Joseph Singleton", "authors": "Joseph Singleton and Richard Booth", "title": "Rankings for Bipartite Tournaments via Chain Editing", "comments": "Presented at AAMAS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Ranking the participants of a tournament has applications in voting, paired\ncomparisons analysis, sports and other domains. In this paper we introduce\nbipartite tournaments, which model situations in which two different kinds of\nentity compete indirectly via matches against players of the opposite kind;\nexamples include education (students/exam questions) and solo sports\n(golfers/courses). In particular, we look to find rankings via chain graphs,\nwhich correspond to bipartite tournaments in which the sets of adversaries\ndefeated by the players on one side are nested with respect to set inclusion.\nTournaments of this form have a natural and appealing ranking associated with\nthem. We apply chain editing -- finding the minimum number of edge changes\nrequired to form a chain graph -- as a new mechanism for tournament ranking.\nThe properties of these rankings are investigated in a probabilistic setting,\nwhere they arise as maximum likelihood estimators, and through the axiomatic\nmethod of social choice theory. Despite some nice properties, two problems\nremain: an important anonymity axiom is violated, and chain editing is NP-hard.\nWe address both issues by relaxing the minimisation constraint in chain\nediting, and characterise the resulting ranking methods via a greedy\napproximation algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2021 10:49:57 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Singleton", "Joseph", ""], ["Booth", "Richard", ""]]}, {"id": "2101.02766", "submitter": "Han Ching Ou", "authors": "Han-Ching Ou, Haipeng Chen, Shahin Jabbari and Milind Tambe", "title": "Active Screening for Recurrent Diseases: A Reinforcement Learning\n  Approach", "comments": "The short version of this paper appears in the proceedings of\n  AAMAS-21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Active screening is a common approach in controlling the spread of recurring\ninfectious diseases such as tuberculosis and influenza. In this approach,\nhealth workers periodically select a subset of population for screening.\nHowever, given the limited number of health workers, only a small subset of the\npopulation can be visited in any given time period. Given the recurrent nature\nof the disease and rapid spreading, the goal is to minimize the number of\ninfections over a long time horizon. Active screening can be formalized as a\nsequential combinatorial optimization over the network of people and their\nconnections. The main computational challenges in this formalization arise from\ni) the combinatorial nature of the problem, ii) the need of sequential planning\nand iii) the uncertainties in the infectiousness states of the population.\n  Previous works on active screening fail to scale to large time horizon while\nfully considering the future effect of current interventions. In this paper, we\npropose a novel reinforcement learning (RL) approach based on Deep Q-Networks\n(DQN), with several innovative adaptations that are designed to address the\nabove challenges. First, we use graph convolutional networks (GCNs) to\nrepresent the Q-function that exploit the node correlations of the underlying\ncontact network. Second, to avoid solving a combinatorial optimization problem\nin each time period, we decompose the node set selection as a sub-sequence of\ndecisions, and further design a two-level RL framework that solves the problem\nin a hierarchical way. Finally, to speed-up the slow convergence of RL which\narises from reward sparseness, we incorporate ideas from curriculum learning\ninto our hierarchical RL approach. We evaluate our RL algorithm on several\nreal-world networks.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2021 21:07:35 GMT"}, {"version": "v2", "created": "Wed, 27 Jan 2021 16:41:05 GMT"}, {"version": "v3", "created": "Mon, 19 Apr 2021 16:43:43 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Ou", "Han-Ching", ""], ["Chen", "Haipeng", ""], ["Jabbari", "Shahin", ""], ["Tambe", "Milind", ""]]}, {"id": "2101.02889", "submitter": "Quan Quan", "authors": "Quan Quan, Rao Fu, Kai-Yuan Cai", "title": "Practical Control for Multicopters to Avoid Non-Cooperative Moving\n  Obstacles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unmanned Aerial Vehicles (UAVs) are now becoming increasingly accessible to\namateur and commercial users alike. The main task for UAVs is to keep a\nprescribed separation with obstacles in the air. In this paper, a\ncollision-avoidance control method for non-cooperative moving obstacles is\nproposed for a multicopter with the altitude hold mode by using a Lyapunov-like\nbarrier function. Lyapunov-like functions are designed elaborately, based on\nwhich formal analysis and proofs of the proposed control are made to show that\nthe collision-avoidance control problem can be solved if the moving obstacle is\nslower than the multicopter. The result can be extended to some cases of\nmultiple obstacles. What is more, by the proposed control, a multicopter can\nkeep away from obstacles as soon as possible, once obstacles enter into the\nsafety area of the multicopter accidentally, and converge to the waypoint.\nSimulations and experiments are given to show the effectiveness of the proposed\nmethod by showing the distance between UAV and waypoint, obstacles\nrespectively.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jan 2021 07:47:11 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Quan", "Quan", ""], ["Fu", "Rao", ""], ["Cai", "Kai-Yuan", ""]]}, {"id": "2101.02900", "submitter": "Forrest Laine", "authors": "Forrest Laine, David Fridovich-Keil, Chih-Yuan Chiu, Claire Tomlin", "title": "The Computation of Approximate Generalized Feedback Nash Equilibria", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.GT cs.MA cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present the concept of a Generalized Feedback Nash Equilibrium (GFNE) in\ndynamic games, extending the Feedback Nash Equilibrium concept to games in\nwhich players are subject to state and input constraints. We formalize\nnecessary and sufficient conditions for (local) GFNE solutions at the\ntrajectory level, which enable the development of efficient numerical methods\nfor their computation. Specifically, we propose a Newton-style method for\nfinding game trajectories which satisfy the necessary conditions, which can\nthen be checked against the sufficiency conditions. We show that the evaluation\nof the necessary conditions in general requires computing a series of nested,\nimplicitly-defined derivatives, which quickly becomes intractable. To this end,\nwe introduce an approximation to the necessary conditions which is amenable to\nefficient evaluation, and in turn, computation of solutions. We term the\nsolutions to the approximate necessary conditions Generalized Feedback Quasi\nNash Equilibria (GFQNE), and we introduce numerical methods for their\ncomputation. In particular, we develop a Sequential Linear-Quadratic Game\napproach, in which a locally approximate LQ game is solved at each iteration.\nThe development of this method relies on the ability to compute a GFNE to\ninequality- and equality-constrained LQ games, and therefore specific methods\nfor the solution of these special cases are developed in detail. We demonstrate\nthe effectiveness of the proposed solution approach on a dynamic game arising\nin an autonomous driving application.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jan 2021 08:17:36 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Laine", "Forrest", ""], ["Fridovich-Keil", "David", ""], ["Chiu", "Chih-Yuan", ""], ["Tomlin", "Claire", ""]]}, {"id": "2101.03230", "submitter": "Junjie Zhong", "authors": "Junjie Zhong and Hiromitsu Hattori", "title": "Generation of Traffic Flows in Multi-Agent Traffic Simulation with Agent\n  Behavior Model based on Deep Reinforcement Learning", "comments": "Experiment data maybe wrong due to the method \" Repeated and Partial\n  Training\". This method may not converge to the optimal policy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multi-agent based traffic simulation, agents are always supposed to move\nfollowing existing instructions, and mechanically and unnaturally imitate human\nbehavior. The human drivers perform acceleration or deceleration irregularly\nall the time, which seems unnecessary in some conditions. For letting agents in\ntraffic simulation behave more like humans and recognize other agents' behavior\nin complex conditions, we propose a unified mechanism for agents learn to\ndecide various accelerations by using deep reinforcement learning based on a\ncombination of regenerated visual images revealing some notable features, and\nnumerical vectors containing some important data such as instantaneous speed.\nBy handling batches of sequential data, agents are enabled to recognize\nsurrounding agents' behavior and decide their own acceleration. In addition, we\ncan generate a traffic flow behaving diversely to simulate the real traffic\nflow by using an architecture of fully decentralized training and fully\ncentralized execution without violating Markov assumptions.\n", "versions": [{"version": "v1", "created": "Sat, 26 Dec 2020 15:13:06 GMT"}, {"version": "v2", "created": "Mon, 25 Jan 2021 05:00:00 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Zhong", "Junjie", ""], ["Hattori", "Hiromitsu", ""]]}, {"id": "2101.03238", "submitter": "Yichen Yang", "authors": "Jeevana Priya Inala, Yichen Yang, James Paulos, Yewen Pu, Osbert\n  Bastani, Vijay Kumar, Martin Rinard, Armando Solar-Lezama", "title": "Neurosymbolic Transformers for Multi-Agent Communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of inferring communication structures that can solve\ncooperative multi-agent planning problems while minimizing the amount of\ncommunication. We quantify the amount of communication as the maximum degree of\nthe communication graph; this metric captures settings where agents have\nlimited bandwidth. Minimizing communication is challenging due to the\ncombinatorial nature of both the decision space and the objective; for\ninstance, we cannot solve this problem by training neural networks using\ngradient descent. We propose a novel algorithm that synthesizes a control\npolicy that combines a programmatic communication policy used to generate the\ncommunication graph with a transformer policy network used to choose actions.\nOur algorithm first trains the transformer policy, which implicitly generates a\n\"soft\" communication graph; then, it synthesizes a programmatic communication\npolicy that \"hardens\" this graph, forming a neurosymbolic transformer. Our\nexperiments demonstrate how our approach can synthesize policies that generate\nlow-degree communication graphs while maintaining near-optimal performance.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2021 04:13:57 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Inala", "Jeevana Priya", ""], ["Yang", "Yichen", ""], ["Paulos", "James", ""], ["Pu", "Yewen", ""], ["Bastani", "Osbert", ""], ["Kumar", "Vijay", ""], ["Rinard", "Martin", ""], ["Solar-Lezama", "Armando", ""]]}, {"id": "2101.03273", "submitter": "Saeed Kaviani", "authors": "Saeed Kaviani, Bo Ryu, Ejaz Ahmed, Kevin A. Larson, Anh Le, Alex\n  Yahja, Jae H. Kim", "title": "Robust and Scalable Routing with Multi-Agent Deep Reinforcement Learning\n  for MANETs", "comments": "14 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Highly dynamic mobile ad-hoc networks (MANETs) are continuing to serve as one\nof the most challenging environments to develop and deploy robust, efficient,\nand scalable routing protocols. In this paper, we present DeepCQ+ routing\nwhich, in a novel manner, integrates emerging multi-agent deep reinforcement\nlearning (MADRL) techniques into existing Q-learning-based routing protocols\nand their variants, and achieves persistently higher performance across a wide\nrange of MANET configurations while training only on a limited range of network\nparameters and conditions. Quantitatively, DeepCQ+ shows consistently higher\nend-to-end throughput with lower overhead compared to its Q-learning-based\ncounterparts with the overall gain of 10-15% in its efficiency. Qualitatively\nand more significantly, DeepCQ+ maintains remarkably similar performance gains\nunder many scenarios that it was not trained for in terms of network sizes,\nmobility conditions, and traffic dynamics. To the best of our knowledge, this\nis the first successful demonstration of MADRL for the MANET routing problem\nthat achieves and maintains a high degree of scalability and robustness even in\nthe environments that are outside the trained range of scenarios. This implies\nthat the proposed hybrid design approach of DeepCQ+ that combines MADRL and\nQ-learning significantly increases its practicality and explainability because\nthe real-world MANET environment will likely vary outside the trained range of\nMANET scenarios.\n", "versions": [{"version": "v1", "created": "Sat, 9 Jan 2021 02:26:14 GMT"}, {"version": "v2", "created": "Mon, 29 Mar 2021 02:53:58 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Kaviani", "Saeed", ""], ["Ryu", "Bo", ""], ["Ahmed", "Ejaz", ""], ["Larson", "Kevin A.", ""], ["Le", "Anh", ""], ["Yahja", "Alex", ""], ["Kim", "Jae H.", ""]]}, {"id": "2101.03580", "submitter": "Safia Sadji", "authors": "Safia Sadji", "title": "A negotiating protocol for group decision support systems", "comments": "in French", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Our contribution concerns interactive decision support systems for group\ndecision support. Through this study, we apply to implement a decisional\nprocess aiming to represent the multiplicity of actors, their diversity, their\nbehaviors and their interactions. In this context, we contribute to the design\nand development of a group decision support system. The system is modeled by a\nmulti agents system while exploiting a negotiation protocol based on mediation\nand concession. This protocol allows decision-makers to express their\npreferences using multicriteria analysis methods, mainly the method by total\naggregation AHP (Hierarchical Process Analysis) and the method by partial\naggregation PROMETHEE II .\n", "versions": [{"version": "v1", "created": "Sun, 10 Jan 2021 16:52:51 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Sadji", "Safia", ""]]}, {"id": "2101.03864", "submitter": "Luisa Zintgraf", "authors": "Luisa Zintgraf, Sam Devlin, Kamil Ciosek, Shimon Whiteson, Katja\n  Hofmann", "title": "Deep Interactive Bayesian Reinforcement Learning via Meta-Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Agents that interact with other agents often do not know a priori what the\nother agents' strategies are, but have to maximise their own online return\nwhile interacting with and learning about others. The optimal adaptive\nbehaviour under uncertainty over the other agents' strategies w.r.t. some prior\ncan in principle be computed using the Interactive Bayesian Reinforcement\nLearning framework. Unfortunately, doing so is intractable in most settings,\nand existing approximation methods are restricted to small tasks. To overcome\nthis, we propose to meta-learn approximate belief inference and Bayes-optimal\nbehaviour for a given prior. To model beliefs over other agents, we combine\nsequential and hierarchical Variational Auto-Encoders, and meta-train this\ninference model alongside the policy. We show empirically that our approach\noutperforms existing methods that use a model-free approach, sample from the\napproximate posterior, maintain memory-free models of others, or do not fully\nutilise the known structure of the environment.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jan 2021 13:25:13 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Zintgraf", "Luisa", ""], ["Devlin", "Sam", ""], ["Ciosek", "Kamil", ""], ["Whiteson", "Shimon", ""], ["Hofmann", "Katja", ""]]}, {"id": "2101.04057", "submitter": "Bernardo Furtado", "authors": "L\\'igia Mori Madeira, Bernardo Alves Furtado, Alan Rafael Dill", "title": "VIDA: A simulation model of domestic VIolence in times of social\n  DistAncing", "comments": "20 pages, 3 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Violence against women occurs predominantly in the family and domestic\ncontext. The COVID-19 pandemic led Brazil to recommend and, at times, impose\nsocial distancing, with the partial closure of economic activities, schools,\nand restrictions on events and public services. Preliminary evidence shows that\nintense coexistence increases domestic violence, while social distancing\nmeasures may have prevented access to public services and networks,\ninformation, and help. We propose an agent-based model (ABM), called VIDA, to\nillustrate and examine multi-causal factors that influence events that generate\nviolence. A central part of the model is the multi-causal stress indicator,\ncreated as a probability trigger of domestic violence occurring within the\nfamily environment. Two experimental design tests were performed: (a) absence\nor presence of the deterrence system of domestic violence against women and (b)\nmeasures to increase social distancing. VIDA presents comparative results for\nmetropolitan regions and neighbourhoods considered in the experiments. Results\nsuggest that social distancing measures, particularly those encouraging staying\nat home, may have increased domestic violence against women by about 10%. VIDA\nsuggests further that more populated areas have comparatively fewer cases per\nhundred thousand women than less populous capitals or rural areas of urban\nconcentrations. This paper contributes to the literature by formalising, to the\nbest of our knowledge, the first model of domestic violence through agent-based\nmodelling, using empirical detailed socioeconomic, demographic, educational,\ngender, and race data at the intraurban level (census sectors).\n", "versions": [{"version": "v1", "created": "Mon, 11 Jan 2021 17:42:49 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Madeira", "L\u00edgia Mori", ""], ["Furtado", "Bernardo Alves", ""], ["Dill", "Alan Rafael", ""]]}, {"id": "2101.04667", "submitter": "Emmanouil Vasileios Vlatakis Gkaragkounis", "authors": "Angeliki Giannou, Emmanouil-Vasileios Vlatakis-Gkaragkounis, Panayotis\n  Mertikopoulos", "title": "Survival of the strictest: Stable and unstable equilibria under\n  regularized learning with partial information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG cs.MA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we examine the Nash equilibrium convergence properties of\nno-regret learning in general N-player games. For concreteness, we focus on the\narchetypal follow the regularized leader (FTRL) family of algorithms, and we\nconsider the full spectrum of uncertainty that the players may encounter - from\nnoisy, oracle-based feedback, to bandit, payoff-based information. In this\ngeneral context, we establish a comprehensive equivalence between the stability\nof a Nash equilibrium and its support: a Nash equilibrium is stable and\nattracting with arbitrarily high probability if and only if it is strict (i.e.,\neach equilibrium strategy has a unique best response). This equivalence extends\nexisting continuous-time versions of the folk theorem of evolutionary game\ntheory to a bona fide algorithmic learning setting, and it provides a clear\nrefinement criterion for the prediction of the day-to-day behavior of no-regret\nlearning in games\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2021 18:55:11 GMT"}, {"version": "v2", "created": "Thu, 4 Feb 2021 14:45:34 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Giannou", "Angeliki", ""], ["Vlatakis-Gkaragkounis", "Emmanouil-Vasileios", ""], ["Mertikopoulos", "Panayotis", ""]]}, {"id": "2101.04788", "submitter": "Jayesh Gupta", "authors": "Shushman Choudhury, Jayesh K. Gupta, Peter Morales, Mykel J.\n  Kochenderfer", "title": "Scalable Anytime Planning for Multi-Agent MDPs", "comments": "First two authors contributed equally. Accepted at AAMAS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a scalable tree search planning algorithm for large multi-agent\nsequential decision problems that require dynamic collaboration. Teams of\nagents need to coordinate decisions in many domains, but naive approaches fail\ndue to the exponential growth of the joint action space with the number of\nagents. We circumvent this complexity through an anytime approach that allows\nus to trade computation for approximation quality and also dynamically\ncoordinate actions. Our algorithm comprises three elements: online planning\nwith Monte Carlo Tree Search (MCTS), factored representations of local agent\ninteractions with coordination graphs, and the iterative Max-Plus method for\njoint action selection. We evaluate our approach on the benchmark SysAdmin\ndomain with static coordination graphs and achieve comparable performance with\nmuch lower computation cost than our MCTS baselines. We also introduce a\nmulti-drone delivery domain with dynamic, i.e., state-dependent coordination\ngraphs, and demonstrate how our approach scales to large problems on this\ndomain that are intractable for other MCTS methods. We provide an open-source\nimplementation of our algorithm at\nhttps://github.com/JuliaPOMDP/FactoredValueMCTS.jl.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2021 22:50:17 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Choudhury", "Shushman", ""], ["Gupta", "Jayesh K.", ""], ["Morales", "Peter", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "2101.04835", "submitter": "Sriramya Bhamidipati", "authors": "Sriramya Bhamidipati and Grace Xingxin Gao", "title": "GPS Spoofing Mitigation and Timing Risk Analysis in Networked PMUs via\n  Stochastic Reachability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.RO cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  To address PMU vulnerability against spoofing, we propose a set-valued state\nestimation technique known as Stochastic Reachability-based Distributed Kalman\nFilter (SR-DKF) that computes secure GPS timing across a network of receivers.\nUtilizing stochastic reachability, we estimate not only GPS time but also its\nstochastic reachable set, which is parameterized via probabilistic zonotope\n(p-Zonotope). While requiring known measurement error bounds in only\nnon-spoofed conditions, we design a two-tier approach: We first perform\nmeasurement-level spoofing mitigation via deviation of measurement innovation\nfrom its expected p-Zonotope and second perform state-level timing risk\nanalysis via intersection probability of estimated pZonotope with an unsafe set\nthat violates IEEE C37.118.1a-2014 standards. We validate the proposed SR-DKF\nby subjecting a simulated receiver network to coordinated signal-level\nspoofing. We demonstrate improved GPS timing accuracy and successful spoofing\nmitigation via our SR-DKF. We validate the robustness of the estimated timing\nrisk as the number of receivers is varied.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2021 02:15:17 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Bhamidipati", "Sriramya", ""], ["Gao", "Grace Xingxin", ""]]}, {"id": "2101.05399", "submitter": "Cevahir K\\\"opr\\\"ul\\\"u", "authors": "Cevahir K\\\"opr\\\"ul\\\"u and Y{\\i}ld{\\i}ray Y{\\i}ld{\\i}z", "title": "Act to Reason: A Dynamic Game Theoretical Model of Driving", "comments": "17 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The focus of this paper is to propose a driver model that incorporates human\nreasoning levels as actions during interactions with other drivers. Different\nfrom earlier work using game theoretical human reasoning levels, we propose a\ndynamic approach, where the actions are the levels themselves, instead of\nconventional driving actions such as accelerating or braking. This results in a\ndynamic behavior, where the agent adapts to its environment by exploiting\ndifferent behavior models as available moves to choose from, depending on the\nrequirements of the traffic situation. The bounded rationality assumption is\npreserved since the selectable strategies are designed by adhering to the fact\nthat humans are cognitively limited in their understanding and decision making.\nUsing a highway merging scenario, it is demonstrated that the proposed dynamic\napproach produces more realistic outcomes compared to the conventional method\nthat employs fixed human reasoning levels.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jan 2021 00:16:01 GMT"}, {"version": "v2", "created": "Sun, 17 Jan 2021 15:08:55 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["K\u00f6pr\u00fcl\u00fc", "Cevahir", ""], ["Y\u0131ld\u0131z", "Y\u0131ld\u0131ray", ""]]}, {"id": "2101.05436", "submitter": "Zengyi Qin", "authors": "Zengyi Qin, Kaiqing Zhang, Yuxiao Chen, Jingkai Chen, Chuchu Fan", "title": "Learning Safe Multi-Agent Control with Decentralized Neural Barrier\n  Certificates", "comments": "Published at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the multi-agent safe control problem where agents should avoid\ncollisions to static obstacles and collisions with each other while reaching\ntheir goals. Our core idea is to learn the multi-agent control policy jointly\nwith learning the control barrier functions as safety certificates. We propose\na novel joint-learning framework that can be implemented in a decentralized\nfashion, with generalization guarantees for certain function classes. Such a\ndecentralized framework can adapt to an arbitrarily large number of agents.\nBuilding upon this framework, we further improve the scalability by\nincorporating neural network architectures that are invariant to the quantity\nand permutation of neighboring agents. In addition, we propose a new\nspontaneous policy refinement method to further enforce the certificate\ncondition during testing. We provide extensive experiments to demonstrate that\nour method significantly outperforms other leading multi-agent control\napproaches in terms of maintaining safety and completing original tasks. Our\napproach also shows exceptional generalization capability in that the control\npolicy can be trained with 8 agents in one scenario, while being used on other\nscenarios with up to 1024 agents in complex multi-agent environments and\ndynamics.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jan 2021 03:17:17 GMT"}, {"version": "v2", "created": "Sat, 16 Jan 2021 15:47:04 GMT"}, {"version": "v3", "created": "Sun, 31 Jan 2021 11:29:46 GMT"}, {"version": "v4", "created": "Sat, 17 Apr 2021 05:34:12 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Qin", "Zengyi", ""], ["Zhang", "Kaiqing", ""], ["Chen", "Yuxiao", ""], ["Chen", "Jingkai", ""], ["Fan", "Chuchu", ""]]}, {"id": "2101.05507", "submitter": "Paul Knott PhD MPhys BSc", "authors": "Paul Knott, Micah Carroll, Sam Devlin, Kamil Ciosek, Katja Hofmann, A.\n  D. Dragan and Rohin Shah", "title": "Evaluating the Robustness of Collaborative Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order for agents trained by deep reinforcement learning to work alongside\nhumans in realistic settings, we will need to ensure that the agents are\n\\emph{robust}. Since the real world is very diverse, and human behavior often\nchanges in response to agent deployment, the agent will likely encounter novel\nsituations that have never been seen during training. This results in an\nevaluation challenge: if we cannot rely on the average training or validation\nreward as a metric, then how can we effectively evaluate robustness? We take\ninspiration from the practice of \\emph{unit testing} in software engineering.\nSpecifically, we suggest that when designing AI agents that collaborate with\nhumans, designers should search for potential edge cases in \\emph{possible\npartner behavior} and \\emph{possible states encountered}, and write tests which\ncheck that the behavior of the agent in these edge cases is reasonable. We\napply this methodology to build a suite of unit tests for the Overcooked-AI\nenvironment, and use this test suite to evaluate three proposals for improving\nrobustness. We find that the test suite provides significant insight into the\neffects of these proposals that were generally not revealed by looking solely\nat the average validation reward.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jan 2021 09:02:45 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Knott", "Paul", ""], ["Carroll", "Micah", ""], ["Devlin", "Sam", ""], ["Ciosek", "Kamil", ""], ["Hofmann", "Katja", ""], ["Dragan", "A. D.", ""], ["Shah", "Rohin", ""]]}, {"id": "2101.05567", "submitter": "Moulik Choraria", "authors": "Moulik Choraria, Arpan Chattopadhyay, Urbashi Mitra, Erik Strom", "title": "Design of false data injection attack on distributed process estimation", "comments": "arXiv admin note: substantial text overlap with arXiv:2002.01545", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Herein, design of false data injection attack on a distributed cyber-physical\nsystem is considered. A stochastic process with linear dynamics and Gaussian\nnoise is measured by multiple agent nodes, each equipped with multiple sensors.\nThe agent nodes form a multi-hop network among themselves. Each agent node\ncomputes an estimate of the process by using its sensor observation and\nmessages obtained from neighboring nodes, via Kalman-consensus filtering. An\nexternal attacker, capable of arbitrarily manipulating the sensor observations\nof some or all agent nodes, injects errors into those sensor observations. The\ngoal of the attacker is to steer the estimates at the agent nodes as close as\npossible to a pre-specified value, while respecting a constraint on the attack\ndetection probability. To this end, a constrained optimization problem is\nformulated to find the optimal parameter values of a certain class of linear\nattacks. The parameters of linear attack are learnt on-line via a combination\nof stochastic approximation based update of a Lagrange multiplier, and an\noptimization technique involving either the Karush-Kuhn-Tucker (KKT) conditions\nor online stochastic gradient descent. The problem turns out to be convex for\nsome special cases. Desired convergence of the proposed algorithms are proved\nby exploiting the convexity and properties of stochastic approximation\nalgorithms. Finally, numerical results demonstrate the efficacy of the attack.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jan 2021 12:27:38 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Choraria", "Moulik", ""], ["Chattopadhyay", "Arpan", ""], ["Mitra", "Urbashi", ""], ["Strom", "Erik", ""]]}, {"id": "2101.05580", "submitter": "Frank Schweitzer", "authors": "Frank Schweitzer, Luca Verginer, Giacomo Vaccario", "title": "Should the government reward cooperation? Insights from an agent-based\n  model of wealth redistribution", "comments": null, "journal-ref": null, "doi": "10.1142/S0219525920500186", "report-no": null, "categories": "physics.soc-ph cs.MA econ.GN nlin.AO q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In our multi-agent model agents generate wealth from repeated interactions\nfor which a prisoner's dilemma payoff matrix is assumed. Their gains are taxed\nby a government at a rate $\\alpha$. The resulting budget is spent to cover\nadministrative costs and to pay a bonus to cooperative agents, which can be\nidentified correctly only with a probability $p$. Agents decide at each time\nstep to choose either cooperation or defection based on different information.\nIn the local scenario, they compare their potential gains from both strategies.\nIn the global scenario, they compare the gains of the cooperative and defective\nsubpopulations. We derive analytical expressions for the critical bonus needed\nto make cooperation as attractive as defection. We show that for the local\nscenario the government can establish only a medium level of cooperation,\nbecause the critical bonus increases with the level of cooperation. In the\nglobal scenario instead full cooperation can be achieved once the cold-start\nproblem is solved, because the critical bonus decreases with the level of\ncooperation. This allows to lower the tax rate, while maintaining high\ncooperation.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jan 2021 13:19:02 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Schweitzer", "Frank", ""], ["Verginer", "Luca", ""], ["Vaccario", "Giacomo", ""]]}, {"id": "2101.05700", "submitter": "Marin Lujak", "authors": "Marin Lujak and Alberto Fern\\'andez and Eva Onaindia", "title": "Spillover Algorithm: A Decentralized Coordination Approach for\n  Multi-Robot Production Planning in Open Shared Factories", "comments": null, "journal-ref": null, "doi": "10.1016/j.rcim.2020.102110", "report-no": null, "categories": "cs.RO cs.AI cs.DM cs.MA", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Open and shared manufacturing factories typically dispose of a limited number\nof robots that should be properly allocated to tasks in time and space for an\neffective and efficient system performance. In particular, we deal with the\ndynamic capacitated production planning problem with sequence independent setup\ncosts where quantities of products to manufacture and location of robots need\nto be determined at consecutive periods within a given time horizon and\nproducts can be anticipated or backordered related to the demand period. We\nconsider a decentralized multi-agent variant of this problem in an open factory\nsetting with multiple owners of robots as well as different owners of the items\nto be produced, both considered self-interested and individually rational.\nExisting solution approaches to the classic constrained lot-sizing problem are\ncentralized exact methods that require sharing of global knowledge of all the\nparticipants' private and sensitive information and are not applicable in the\ndescribed multi-agent context. Therefore, we propose a computationally\nefficient decentralized approach based on the spillover effect that solves this\nNP-hard problem by distributing decisions in an intrinsically decentralized\nmulti-agent system environment while protecting private and sensitive\ninformation. To the best of our knowledge, this is the first decentralized\nalgorithm for the solution of the studied problem in intrinsically\ndecentralized environments where production resources and/or products are owned\nby multiple stakeholders with possibly conflicting objectives. To show its\nefficiency, the performance of the Spillover Algorithm is benchmarked against\nstate-of-the-art commercial solver CPLEX 12.8.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jan 2021 16:23:45 GMT"}, {"version": "v2", "created": "Sat, 23 Jan 2021 18:40:40 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Lujak", "Marin", ""], ["Fern\u00e1ndez", "Alberto", ""], ["Onaindia", "Eva", ""]]}, {"id": "2101.06288", "submitter": "Heeseung Bang", "authors": "Heeseung Bang, Logan Beaver, Andreas A. Malikopoulos", "title": "Energy-Optimal Goal Assignment of Multi-Agent System with Goal\n  Trajectories in Polynomials", "comments": "7 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an approach for solving an energy-optimal goal\nassignment problem to generate the desired formation in multi-agent systems.\nEach agent solves a decentralized optimization problem with only local\ninformation about its neighboring agents and the goals. The optimization\nproblem consists of two sub-problems. The first problem seeks to minimize the\nenergy for each agent to reach certain goals, while the second problem entreats\nan optimal combination of goal and agent pairs that minimizes the energy cost.\nBy assuming the goal trajectories are given in a polynomial form, we prove the\nsolution to the formulated problem exists globally. Finally, the effectiveness\nof the proposed approach is validated through the simulation.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jan 2021 20:03:15 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Bang", "Heeseung", ""], ["Beaver", "Logan", ""], ["Malikopoulos", "Andreas A.", ""]]}, {"id": "2101.06838", "submitter": "Jaime Arias", "authors": "Jaime Arias, {\\L}ukasz Ma\\'sko, Wojciech Penczek, Laure Petrucci and\n  Teofil Sidoruk", "title": "Minimal Schedule with Minimal Number of Agents in Attack-Defence Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Expressing attack-defence trees in a multi-agent setting allows for studying\na new aspect of security scenarios, namely how the number of agents and their\ntask assignment impact the performance, e.g. attack time, of strategies\nexecuted by opposing coalitions. Optimal scheduling of agents' actions, a\nnon-trivial problem, is thus vital. We discuss associated caveats and propose\nan algorithm that synthesises such an assignment, targeting minimal attack time\nand using minimal number of agents for a given attack-defence tree.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2021 02:08:53 GMT"}, {"version": "v2", "created": "Mon, 1 Feb 2021 18:38:37 GMT"}, {"version": "v3", "created": "Sun, 14 Feb 2021 09:49:51 GMT"}, {"version": "v4", "created": "Mon, 26 Apr 2021 07:35:59 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Arias", "Jaime", ""], ["Ma\u015bko", "\u0141ukasz", ""], ["Penczek", "Wojciech", ""], ["Petrucci", "Laure", ""], ["Sidoruk", "Teofil", ""]]}, {"id": "2101.06890", "submitter": "Heechang Ryu", "authors": "Heechang Ryu, Hayong Shin, Jinkyoo Park", "title": "Cooperative and Competitive Biases for Multi-Agent Reinforcement\n  Learning", "comments": "Accepted as a full paper at the Twentieth International Conference on\n  Autonomous Agents and Multiagent Systems (AAMAS-21), Virtual Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Training a multi-agent reinforcement learning (MARL) algorithm is more\nchallenging than training a single-agent reinforcement learning algorithm,\nbecause the result of a multi-agent task strongly depends on the complex\ninteractions among agents and their interactions with a stochastic and dynamic\nenvironment. We propose an algorithm that boosts MARL training using the biased\naction information of other agents based on a friend-or-foe concept. For a\ncooperative and competitive environment, there are generally two groups of\nagents: cooperative-agents and competitive-agents. In the proposed algorithm,\neach agent updates its value function using its own action and the biased\naction information of other agents in the two groups. The biased joint action\nof cooperative agents is computed as the sum of their actual joint action and\nthe imaginary cooperative joint action, by assuming all the cooperative agents\njointly maximize the target agent's value function. The biased joint action of\ncompetitive agents can be computed similarly. Each agent then updates its own\nvalue function using the biased action information, resulting in a biased value\nfunction and corresponding biased policy. Subsequently, the biased policy of\neach agent is inevitably subjected to recommend an action to cooperate and\ncompete with other agents, thereby introducing more active interactions among\nagents and enhancing the MARL policy learning. We empirically demonstrate that\nour algorithm outperforms existing algorithms in various mixed\ncooperative-competitive environments. Furthermore, the introduced biases\ngradually decrease as the training proceeds and the correction based on the\nimaginary assumption vanishes.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2021 05:52:22 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Ryu", "Heechang", ""], ["Shin", "Hayong", ""], ["Park", "Jinkyoo", ""]]}, {"id": "2101.06961", "submitter": "The Anh Han", "authors": "Xinglong Qu and Shun Kurokawa and The Anh Han", "title": "Social cohesion V.S. task cohesion: An evolutionary game theory study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.MA nlin.AO nlin.CD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Using methods from evolutionary game theory, this paper investigates the\ndifference between social cohesion and task cohesion in promoting the evolution\nof cooperation in group interactions. Players engage in public goods games and\nare allowed to leave their groups if too many defections occur. Both social\ncohesion and task cohesion may prevent players from leaving. While a higher\nlevel of social cohesion increases a player's tolerance towards defections,\ntask cohesion is associated with her group performance in the past. With a\nhigher level of task cohesion, it is more likely that a dissatisfied player\nwill refer to the history and remains in her group if she was satisfied in the\npast. Our results reveal that social cohesion is detrimental to the evolution\nof cooperation while task cohesion facilitates it. This is because social\ncohesion hinders the conditional dissociation mechanism but task cohesion\nimproves the robustness of cooperative groups which are usually vulnerable to\nmistakes. We also discuss other potential aspects of cohesion and how they can\nbe investigated through our modelling. Overall, our analysis provides novel\ninsights into the relationship between group cohesion and group performance\nthrough studying the group dynamics and suggests further application of\nevolutionary game theory in this area.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2021 09:52:16 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Qu", "Xinglong", ""], ["Kurokawa", "Shun", ""], ["Han", "The Anh", ""]]}, {"id": "2101.07107", "submitter": "Jeremy Turiel", "authors": "Antonio Briola, Jeremy Turiel, Riccardo Marcaccioli, Tomaso Aste", "title": "Deep Reinforcement Learning for Active High Frequency Trading", "comments": "9 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA q-fin.TR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We introduce the first end-to-end Deep Reinforcement Learning (DRL) based\nframework for active high frequency trading. We train DRL agents to trade one\nunit of Intel Corporation stock by employing the Proximal Policy Optimization\nalgorithm. The training is performed on three contiguous months of high\nfrequency Limit Order Book data, of which the last month constitutes the\nvalidation data. In order to maximise the signal to noise ratio in the training\ndata, we compose the latter by only selecting training samples with largest\nprice changes. The test is then carried out on the following month of data.\nHyperparameters are tuned using the Sequential Model Based Optimization\ntechnique. We consider three different state characterizations, which differ in\ntheir LOB-based meta-features. Analysing the agents' performances on test data,\nwe argue that the agents are able to create a dynamic representation of the\nunderlying environment. They identify occasional regularities present in the\ndata and exploit them to create long-term profitable trading strategies.\nIndeed, agents learn trading strategies able to produce stable positive returns\nin spite of the highly stochastic and non-stationary environment.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2021 15:09:28 GMT"}, {"version": "v2", "created": "Thu, 4 Feb 2021 11:46:03 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Briola", "Antonio", ""], ["Turiel", "Jeremy", ""], ["Marcaccioli", "Riccardo", ""], ["Aste", "Tomaso", ""]]}, {"id": "2101.07385", "submitter": "Maximilian Amsler", "authors": "Sebastian Ament, Maximilian Amsler, Duncan R. Sutherland, Ming-Chiang\n  Chang, Dan Guevarra, Aine B. Connolly, John M. Gregoire, Michael O. Thompson,\n  Carla P. Gomes, R. Bruce van Dover", "title": "Autonomous synthesis of metastable materials", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.mtrl-sci cs.AI cs.LG cs.MA physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous experimentation enabled by artificial intelligence (AI) offers a\nnew paradigm for accelerating scientific discovery. Non-equilibrium materials\nsynthesis is emblematic of complex, resource-intensive experimentation whose\nacceleration would be a watershed for materials discovery and development. The\nmapping of non-equilibrium synthesis phase diagrams has recently been\naccelerated via high throughput experimentation but still limits materials\nresearch because the parameter space is too vast to be exhaustively explored.\nWe demonstrate accelerated synthesis and exploration of metastable materials\nthrough hierarchical autonomous experimentation governed by the Scientific\nAutonomous Reasoning Agent (SARA). SARA integrates robotic materials synthesis\nand characterization along with a hierarchy of AI methods that efficiently\nreveal the structure of processing phase diagrams. SARA designs lateral\ngradient laser spike annealing (lg-LSA) experiments for parallel materials\nsynthesis and employs optical spectroscopy to rapidly identify phase\ntransitions. Efficient exploration of the multi-dimensional parameter space is\nachieved with nested active learning (AL) cycles built upon advanced machine\nlearning models that incorporate the underlying physics of the experiments as\nwell as end-to-end uncertainty quantification. With this, and the coordination\nof AL at multiple scales, SARA embodies AI harnessing of complex scientific\ntasks. We demonstrate its performance by autonomously mapping synthesis phase\nboundaries for the Bi$_2$O$_3$ system, leading to orders-of-magnitude\nacceleration in establishment of a synthesis phase diagram that includes\nconditions for kinetically stabilizing $\\delta$-Bi$_2$O$_3$ at room\ntemperature, a critical development for electrochemical technologies such as\nsolid oxide fuel cells.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jan 2021 00:29:26 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Ament", "Sebastian", ""], ["Amsler", "Maximilian", ""], ["Sutherland", "Duncan R.", ""], ["Chang", "Ming-Chiang", ""], ["Guevarra", "Dan", ""], ["Connolly", "Aine B.", ""], ["Gregoire", "John M.", ""], ["Thompson", "Michael O.", ""], ["Gomes", "Carla P.", ""], ["van Dover", "R. Bruce", ""]]}, {"id": "2101.07435", "submitter": "Ankang Sun", "authors": "Ankang Sun, Bo Chen, Xuan Vinh Doan", "title": "Connections between Fairness Criteria and Efficiency for Allocating\n  Indivisible Chores", "comments": "This article is a complete version of a conference paper, which\n  appeared in 20th International Conference on Autonomous Agents and Multiagent\n  Systems (AAMAS-2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study several fairness notions in allocating indivisible chores (i.e.,\nitems with non-positive values): envy-freeness and its relaxations. For\nallocations under each fairness criterion, we establish their approximation\nguarantee for other fairness criteria. Under the setting of additive cost\nfunctions, our results show strong connections between these fairness criteria\nand, at the same time, reveal intrinsic differences between goods allocation\nand chores allocation. Furthermore, we investigate the efficiency loss under\nthese fairness constraints and establish their prices of fairness.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jan 2021 03:08:43 GMT"}, {"version": "v2", "created": "Fri, 22 Jan 2021 02:18:59 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Sun", "Ankang", ""], ["Chen", "Bo", ""], ["Doan", "Xuan Vinh", ""]]}, {"id": "2101.07540", "submitter": "Rafael Lahoz-Beltra", "authors": "A. Gargantilla Becerra, M. Guti\\'errez, R. Lahoz-Beltra", "title": "A synthetic biology approach for the design of genetic algorithms with\n  bacterial agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.MA", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Bacteria have been a source of inspiration for the design of evolutionary\nalgorithms. At the beginning of the 20th century synthetic biology was born, a\ndiscipline whose goal is the design of biological systems that do not exist in\nnature, for example, programmable synthetic bacteria. In this paper, we\nintroduce as a novelty the designing of evolutionary algorithms where all the\nsteps are conducted by synthetic bacteria. To this end, we designed a genetic\nalgorithm, which we have named BAGA, illustrating its utility solving simple\ninstances of optimization problems such as function optimization, 0/1 knapsack\nproblem, Hamiltonian path problem. The results obtained open the possibility of\nconceiving evolutionary algorithms inspired by principles, mechanisms and\ngenetic circuits from synthetic biology. In summary, we can conclude that\nsynthetic biology is a source of inspiration either for the design of\nevolutionary algorithms or for some of their steps, as shown by the results\nobtained in our simulation experiments.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jan 2021 09:59:33 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Becerra", "A. Gargantilla", ""], ["Guti\u00e9rrez", "M.", ""], ["Lahoz-Beltra", "R.", ""]]}, {"id": "2101.07578", "submitter": "Quan Quan", "authors": "Quan Quan, Rao Fu, Mengxin Li, Donghui Wei, Yan Gao and Kai-Yuan Cai", "title": "Practical Distributed Control for VTOL UAVs to Pass a Tunnel", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unmanned Aerial Vehicles (UAVs) are now becoming increasingly accessible to\namateur and commercial users alike. An air traffic management (ATM) system is\nneeded to help ensure that this newest entrant into the skies does not collide\nwith others. In an ATM, airspace can be composed of airways, intersections and\nnodes. In this paper, for simplicity, distributed coordinating the motions of\nVertical TakeOff and Landing (VTOL) UAVs to pass an airway is focused. This is\nformulated as a tunnel passing problem, which includes passing a tunnel,\ninter-agent collision avoidance and keeping within the tunnel. Lyapunov-like\nfunctions are designed elaborately, and formal analysis based on invariant set\ntheorem is made to show that all UAVs can pass the tunnel without getting\ntrapped, avoid collision and keep within the tunnel. What is more, by the\nproposed distributed control, a VTOL UAV can keep away from another VTOL UAV or\nreturn back to the tunnel as soon as possible, once it enters into the safety\narea of another or has a collision with the tunnel during it is passing the\ntunnel. Simulations and experiments are carried out to show the effectiveness\nof the proposed method and the comparison with other methods.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jan 2021 11:52:30 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Quan", "Quan", ""], ["Fu", "Rao", ""], ["Li", "Mengxin", ""], ["Wei", "Donghui", ""], ["Gao", "Yan", ""], ["Cai", "Kai-Yuan", ""]]}, {"id": "2101.08074", "submitter": "Chao Yan", "authors": "Chao Yan, Xiaojia Xiang, Chang Wang, Zhen Lan", "title": "Flocking and Collision Avoidance for a Dynamic Squad of Fixed-Wing UAVs\n  Using Deep Reinforcement Learning", "comments": "Accepted for publication in the proceedings of the 2021 IEEE/RSJ\n  International Conference on Intelligent Robots and Systems (IROS 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.AI cs.LG cs.MA cs.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Developing the flocking behavior for a dynamic squad of fixed-wing UAVs is\nstill a challenge due to kinematic complexity and environmental uncertainty. In\nthis paper, we deal with the decentralized flocking and collision avoidance\nproblem through deep reinforcement learning (DRL). Specifically, we formulate a\ndecentralized DRL-based decision making framework from the perspective of every\nfollower, where a collision avoidance mechanism is integrated into the flocking\ncontroller. Then, we propose a novel reinforcement learning algorithm PS-CACER\nfor training a shared control policy for all the followers. Besides, we design\na plug-n-play embedding module based on convolutional neural networks and the\nattention mechanism. As a result, the variable-length system state can be\nencoded into a fixed-length embedding vector, which makes the learned DRL\npolicy independent with the number and the order of followers. Finally,\nnumerical simulation results demonstrate the effectiveness of the proposed\nmethod, and the learned policies can be directly transferred to semi-physical\nsimulation without any parameter finetuning.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jan 2021 11:23:35 GMT"}, {"version": "v2", "created": "Thu, 22 Jul 2021 11:37:13 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Yan", "Chao", ""], ["Xiang", "Xiaojia", ""], ["Wang", "Chang", ""], ["Lan", "Zhen", ""]]}, {"id": "2101.08657", "submitter": "Bilal Farooq", "authors": "Seyed Mehdi Meshkani and Bilal Farooq", "title": "Graph-based many-to-one dynamic ride-matching for shared mobility\n  services in congested networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  On-demand shared mobility systems require matching of one (one-to-one) or\nmultiple riders (many- to-one) to a vehicle based on real-time information. We\npropose a novel graph-based algorithm (GMO- Match) for dynamic many-to-one\nmatching problem in the presence of traffic congestion. The proposed algorithm,\nwhich is an iterative two-step method, provides high service quality and is\nefficient in terms of computational complexity. GMOMatch starts with a\none-to-one matching in step 1 and is followed by solving a maximum weight\nmatching problem is step 2 to combine the travel requests. To evaluate the\nperformance of the proposed algorithm, it is compared with a ride-matching\nalgorithm by IBM (Simonetto et al., 2019). Both algorithms are implemented in a\nmicro-traffic simulator to assess their performance and also their impacts on\ntraffic congestion. Downtown Toronto road network is chosen as the study area.\nIn comparison to IBM algorithm, GMOMatch improves the service quality and\ntraffic travel time by 32% and 4%, respectively. A sensitivity analysis is also\nconducted over different parameters to show their impacts on the service\nquality.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2021 15:02:36 GMT"}, {"version": "v2", "created": "Mon, 15 Feb 2021 23:47:55 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Meshkani", "Seyed Mehdi", ""], ["Farooq", "Bilal", ""]]}, {"id": "2101.09178", "submitter": "Tabish Rashid", "authors": "Tabish Rashid, Cheng Zhang, Kamil Ciosek", "title": "Estimating $\\alpha$-Rank by Maximizing Information Gain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Game theory has been increasingly applied in settings where the game is not\nknown outright, but has to be estimated by sampling. For example, meta-games\nthat arise in multi-agent evaluation can only be accessed by running a\nsuccession of expensive experiments that may involve simultaneous deployment of\nseveral agents. In this paper, we focus on $\\alpha$-rank, a popular\ngame-theoretic solution concept designed to perform well in such scenarios. We\naim to estimate the $\\alpha$-rank of the game using as few samples as possible.\nOur algorithm maximizes information gain between an epistemic belief over the\n$\\alpha$-ranks and the observed payoff. This approach has two main benefits.\nFirst, it allows us to focus our sampling on the entries that matter the most\nfor identifying the $\\alpha$-rank. Second, the Bayesian formulation provides a\nfacility to build in modeling assumptions by using a prior over game payoffs.\nWe show the benefits of using information gain as compared to the confidence\ninterval criterion of ResponseGraphUCB (Rowland et al. 2019), and provide\ntheoretical results justifying our method.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jan 2021 15:46:35 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Rashid", "Tabish", ""], ["Zhang", "Cheng", ""], ["Ciosek", "Kamil", ""]]}, {"id": "2101.09241", "submitter": "Wojciech Jamroga", "authors": "Wojciech Jamroga", "title": "A Survey of Requirements for COVID-19 Mitigation Strategies. Part II:\n  Elicitation of Requirements", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.MA", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The COVID-19 pandemic has influenced virtually all aspects of our lives.\nAcross the world, countries have applied various mitigation strategies, based\non social, political, and technological instruments. We postulate that\nmulti-agent systems can provide a common platform to study (and balance) their\nessential properties. We also show how to obtain a comprehensive list of the\nproperties by \"distilling\" them from media snippets. Finally, we present a\npreliminary take on their formal specification, using ideas from multi-agent\nlogics.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jan 2021 17:52:20 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Jamroga", "Wojciech", ""]]}, {"id": "2101.09644", "submitter": "Anirudh Sridhar", "authors": "Anirudh Sridhar, Soummya Kar", "title": "Mean-field Approximation for Stochastic Population Processes in Networks\n  under Imperfect Information", "comments": "59 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.MA cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies a general class of stochastic population processes in\nwhich agents interact with one another over a network. Agents update their\nbehaviors in a random and decentralized manner based only on their current\nstate and the states of their neighbors. It is well known that when the number\nof agents is large and the network is a complete graph (has all-to-all\ninformation access), the macroscopic behavior of the population converges to a\ndifferential equation called a {\\it mean-field approximation}. When the network\nis not complete, it is unclear in general whether there exists a suitable\nmean-field approximation for the macroscopic behavior of the population. This\npaper provides general conditions on the network and policy dynamics for which\na suitable mean-field approximation exists. First, we show that as long as the\nnetwork is well-connected, the macroscopic behavior of the population\nconcentrates around the {\\it same} mean-field system as the complete-graph\ncase. Next, we show that as long as the network is sufficiently dense, the\nmacroscopic behavior of the population concentrates around a mean-field system\nthat is, in general, {\\it different} from the mean-field system obtained in the\ncomplete-graph case. Finally, we provide conditions under which the mean-field\napproximation is equivalent to the one obtained in the complete-graph case.\n", "versions": [{"version": "v1", "created": "Sun, 24 Jan 2021 04:18:53 GMT"}, {"version": "v2", "created": "Sun, 11 Apr 2021 03:47:08 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Sridhar", "Anirudh", ""], ["Kar", "Soummya", ""]]}, {"id": "2101.09662", "submitter": "Nilanjan Sinhababu", "authors": "Nilanjan Sinhababu, Rahul Saxena, Monalisa Sarma and Debasis Samanta", "title": "Medical Information Retrieval and Interpretation: A Question-Answer\n  based Interaction Model", "comments": "39 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Internet has become a very powerful platform where diverse medical\ninformation are expressed daily. Recently, a huge growth is seen in searches\nlike symptoms, diseases, medicines, and many other health related queries\naround the globe. The search engines typically populate the result by using the\nsingle query provided by the user and hence reaching to the final result may\nrequire a lot of manual filtering from the user's end. Current search engines\nand recommendation systems still lack real time interactions that may provide\nmore precise result generation. This paper proposes an intelligent and\ninteractive system tied up with the vast medical big data repository on the web\nand illustrates its potential in finding medical information.\n", "versions": [{"version": "v1", "created": "Sun, 24 Jan 2021 07:01:06 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Sinhababu", "Nilanjan", ""], ["Saxena", "Rahul", ""], ["Sarma", "Monalisa", ""], ["Samanta", "Debasis", ""]]}, {"id": "2101.09723", "submitter": "Anton Andreychuk", "authors": "Anton Andreychuk, Konstantin Yakovlev, Eli Boyarski and Roni Stern", "title": "Improving Continuous-time Conflict Based Search", "comments": "This is a pre-print of the paper accepted to AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Conflict-Based Search (CBS) is a powerful algorithmic framework for optimally\nsolving classical multi-agent path finding (MAPF) problems, where time is\ndiscretized into the time steps. Continuous-time CBS (CCBS) is a recently\nproposed version of CBS that guarantees optimal solutions without the need to\ndiscretize time. However, the scalability of CCBS is limited because it does\nnot include any known improvements of CBS. In this paper, we begin to close\nthis gap and explore how to adapt successful CBS improvements, namely,\nprioritizing conflicts (PC), disjoint splitting (DS), and high-level\nheuristics, to the continuous time setting of CCBS. These adaptions are not\ntrivial, and require careful handling of different types of constraints,\napplying a generalized version of the Safe interval path planning (SIPP)\nalgorithm, and extending the notion of cardinal conflicts. We evaluate the\neffect of the suggested enhancements by running experiments both on general\ngraphs and $2^k$-neighborhood grids. CCBS with these improvements significantly\noutperforms vanilla CCBS, solving problems with almost twice as many agents in\nsome cases and pushing the limits of multiagent path finding in continuous-time\ndomains.\n", "versions": [{"version": "v1", "created": "Sun, 24 Jan 2021 14:34:25 GMT"}, {"version": "v2", "created": "Tue, 2 Mar 2021 18:37:38 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Andreychuk", "Anton", ""], ["Yakovlev", "Konstantin", ""], ["Boyarski", "Eli", ""], ["Stern", "Roni", ""]]}, {"id": "2101.09817", "submitter": "John Stevenson PhD", "authors": "John C. Stevenson", "title": "Population and Inequality Dynamics in Simple Economies", "comments": "29 pages with 22 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.MA econ.GN q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the use of spatial agent-based and individual-based models has\nflourished across many scientific disciplines, the complexities these models\ngenerate are often difficult to manage and quantify. This research reduces\npopulation-driven, spatial modeling of individuals to the simplest\nconfigurations and parameters: an equal resource opportunity landscape with\nequally capable individuals; and asks the question, \"Will valid complex\npopulation and inequality dynamics emerge from this simple economic model?\" Two\nforaging economies are modeled: subsistence and surplus. The resulting,\nemergent population dynamics are characterized by their sensitivities to agent\nand landscape parameters. The various steady and oscillating regimes of\nsingle-species population dynamics are generated by appropriate selection of\nmodel growth parameters. These emergent dynamics are shown to be consistent\nwith the equation-based, continuum modeling of single-species populations in\nbiology and ecology. The intrinsic growth rates, carry capacities, and delay\nparameters of these models are implied for these simple economies. Aggregate\nmeasures of individual distributions are used to understand the sensitivities\nto model parameters. New local measures are defined to describe complex\nbehaviors driven by spatial effects, especially extinctions. This simple\neconomic model is shown to generate significantly complex population and\ninequality dynamics. Model parameters generating the intrinsic growth rate have\nstrong effects on these dynamics, including large variations in inequality.\nSignificant inequality effects are shown to be caused by birth costs above and\nbeyond their contribution to the intrinsic growth rate. The highest levels of\ninequality are found during the initial non-equilibrium period and are driven\nby factors different than those driving steady state inequality.\n", "versions": [{"version": "v1", "created": "Sun, 24 Jan 2021 22:45:25 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Stevenson", "John C.", ""]]}, {"id": "2101.09894", "submitter": "Jun Ma", "authors": "Zilong Cheng, Jun Ma, Xiaoxue Zhang, Clarence W. de Silva, Tong Heng\n  Lee", "title": "ADMM-Based Parallel Optimization for Multi-Agent Collision-Free Model\n  Predictive Control", "comments": "13 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.SY eess.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the multi-agent collision-free control problem for\nmedium and large scale systems. For such multi-agent systems, it is the typical\nsituation where conventional methods using either the usual centralized model\npredictive control (MPC), or even the distributed counterpart, would suffer\nfrom substantial difficulty in balancing optimality and computational\nefficiency. Additionally, the non-convex characteristics that invariably arise\nin such collision-free control and optimization problems render it difficult to\neffectively derive a reliable solution (and also to thoroughly analyze the\nassociated convergence properties). To overcome these challenging issues, this\nwork establishes a suitably novel parallel computation framework through an\ninnovative mathematical problem formulation; and then with this framework and\nformulation, the alternating direction method of multipliers (ADMM) algorithm\nis presented to solve the sub-problems arising from the resulting parallel\nstructure. Furthermore, an efficient and intuitive initialization procedure is\ndeveloped to accelerate the optimization process, and the optimum is thus\ndetermined with significantly improved computational efficiency. As supported\nby rigorous proofs, the convergence of the proposed ADMM iterations for this\nnon-convex optimization problem is analyzed and discussed in detail. Finally, a\nmulti-agent system with a group of unmanned aerial vehicles (UAVs) serves as an\nillustrative example here to demonstrate the effectiveness and efficiency of\nthe proposed approach.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2021 04:54:01 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Cheng", "Zilong", ""], ["Ma", "Jun", ""], ["Zhang", "Xiaoxue", ""], ["de Silva", "Clarence W.", ""], ["Lee", "Tong Heng", ""]]}, {"id": "2101.10072", "submitter": "George Datseris Dr", "authors": "George Datseris, Ali R. Vahdati, Timothy C. DuBois", "title": "Agents.jl: A performant and feature-full agent based modelling software\n  of minimal code complexity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA nlin.CG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Agent based modelling is a simulation method in which autonomous agents\ninteract with their environment and one another, given a predefined set of\nrules. It is an integral method for modelling and simulating complex systems,\nsuch as socio-economic problems. Since agent based models are not described by\nsimple and concise mathematical equations, code that generates them is\ntypically complicated, large, and slow. Here we present Agents.jl, a\nJulia-based software that provides an ABM analysis platform with minimal code\ncomplexity. We compare our software with some of the most popular ABM software\nin other programming languages. We find that Agents.jl is not only the most\nperformant, but also the least complicated software, providing the same (and\nsometimes more) features as the competitors with less input required from the\nuser. Agents.jl also integrates excellently with the entire Julia ecosystem,\nincluding interactive applications, differential equations, parameter\noptimization, and more. This removes any ``extensions library'' requirement\nfrom Agents.jl, which is paramount in many other tools.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2021 13:36:28 GMT"}, {"version": "v2", "created": "Sun, 18 Apr 2021 12:26:54 GMT"}, {"version": "v3", "created": "Thu, 15 Jul 2021 15:45:54 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Datseris", "George", ""], ["Vahdati", "Ali R.", ""], ["DuBois", "Timothy C.", ""]]}, {"id": "2101.10276", "submitter": "Michael Noukhovitch", "authors": "Michael Noukhovitch, Travis LaCroix, Angeliki Lazaridou, Aaron\n  Courville", "title": "Emergent Communication under Competition", "comments": "To be presented at AAMAS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The literature in modern machine learning has only negative results for\nlearning to communicate between competitive agents using standard RL. We\nintroduce a modified sender-receiver game to study the spectrum of\npartially-competitive scenarios and show communication can indeed emerge in a\ncompetitive setting. We empirically demonstrate three key takeaways for future\nresearch. First, we show that communication is proportional to cooperation, and\nit can occur for partially competitive scenarios using standard learning\nalgorithms. Second, we highlight the difference between communication and\nmanipulation and extend previous metrics of communication to the competitive\ncase. Third, we investigate the negotiation game where previous work failed to\nlearn communication between independent agents (Cao et al., 2018). We show\nthat, in this setting, both agents must benefit from communication for it to\nemerge; and, with a slight modification to the game, we demonstrate successful\ncommunication between competitive agents. We hope this work overturns\nmisconceptions and inspires more research in competitive emergent\ncommunication.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2021 17:58:22 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Noukhovitch", "Michael", ""], ["LaCroix", "Travis", ""], ["Lazaridou", "Angeliki", ""], ["Courville", "Aaron", ""]]}, {"id": "2101.10305", "submitter": "Michael Dennis", "authors": "Charlotte Roman, Michael Dennis, Andrew Critch, Stuart Russell", "title": "Accumulating Risk Capital Through Investing in Cooperation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work on promoting cooperation in multi-agent learning has resulted in\nmany methods which successfully promote cooperation at the cost of becoming\nmore vulnerable to exploitation by malicious actors. We show that this is an\nunavoidable trade-off and propose an objective which balances these concerns,\npromoting both safety and long-term cooperation. Moreover, the trade-off\nbetween safety and cooperation is not severe, and you can receive exponentially\nlarge returns through cooperation from a small amount of risk. We study both an\nexact solution method and propose a method for training policies that targets\nthis objective, Accumulating Risk Capital Through Investing in Cooperation\n(ARCTIC), and evaluate them in iterated Prisoner's Dilemma and Stag Hunt.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2021 18:41:45 GMT"}, {"version": "v2", "created": "Wed, 21 Apr 2021 00:37:42 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Roman", "Charlotte", ""], ["Dennis", "Michael", ""], ["Critch", "Andrew", ""], ["Russell", "Stuart", ""]]}, {"id": "2101.10495", "submitter": "Jayam Umesh Patel", "authors": "Jayam Patel, Tyagaraja Ramaswamy, Zhi Li, and Carlo Pinciroli", "title": "Transparency in Multi-Human Multi-Robot Interaction", "comments": "8 pages, submitted to IEEE Robotics and Automation Letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.HC cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Transparency is a key factor in improving the performance of human-robot\ninteraction. A transparent interface allows humans to be aware of the state of\na robot and to assess the progress of the tasks at hand. When multi-robot\nsystems are involved, transparency is an even greater challenge, due to the\nlarger number of variables affecting the behavior of the robots as a whole.\nSignificant effort has been devoted to studying transparency when single\noperators interact with multiple robots. However, studies on transparency that\nfocus on multiple human operators interacting with a multi-robot systems are\nlimited. This paper aims to fill this gap by presenting a human-swarm\ninteraction interface with graphical elements that can be enabled and disabled.\nThrough this interface, we study which graphical elements are contribute to\ntransparency by comparing four \"transparency modes\": (i) no transparency (no\noperator receives information from the robots), (ii) central transparency (the\noperators receive information only relevant to their personal task), (iii)\nperipheral transparency (the operators share information on each others'\ntasks), and (iv) mixed transparency (both central and peripheral). We report\nthe results in terms of awareness, trust, and workload of a user study\ninvolving 18 participants engaged in a complex multi-robot task.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2021 00:13:58 GMT"}, {"version": "v2", "created": "Fri, 14 May 2021 20:05:03 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Patel", "Jayam", ""], ["Ramaswamy", "Tyagaraja", ""], ["Li", "Zhi", ""], ["Pinciroli", "Carlo", ""]]}, {"id": "2101.10723", "submitter": "Mehmet Ismail", "authors": "Shaun Hargreaves Heap and Mehmet S. Ismail", "title": "Liberalism, rationality, and Pareto optimality", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.TH cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rational players in game theory are neoliberal in the sense that they can\nchoose any available action so as to maximize their payoffs. It is well known\nthat this can result in Pareto inferior outcomes (e.g. the Prisoner's Dilemma).\nClassical liberalism, in contrast, argues that people should be constrained by\na no-harm principle (NHP) when they act. We show, for the first time to the\nbest of our knowledge, that rational players constrained by the NHP will\nproduce Pareto efficient outcomes in n-person non-cooperative games. We also\nshow that both rationality and the NHP are required for this result.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2021 11:34:51 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Heap", "Shaun Hargreaves", ""], ["Ismail", "Mehmet S.", ""]]}, {"id": "2101.11093", "submitter": "Xiaoyi Cai", "authors": "Xiaoyi Cai, Brent Schlotfeldt, Kasra Khosoussi, Nikolay Atanasov,\n  George J. Pappas, Jonathan P. How", "title": "Non-Monotone Energy-Aware Information Gathering for Heterogeneous Robot\n  Teams", "comments": "To appear in ICRA 2021. Video:\n  https://www.youtube.com/watch?v=xWgFi6fwex0", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the problem of planning trajectories for a team of\nsensor-equipped robots to reduce uncertainty about a dynamical process.\nOptimizing the trade-off between information gain and energy cost (e.g.,\ncontrol effort, distance travelled) is desirable but leads to a non-monotone\nobjective function in the set of robot trajectories. Therefore, common\nmulti-robot planning algorithms based on techniques such as coordinate descent\nlose their performance guarantees. Methods based on local search provide\nperformance guarantees for optimizing a non-monotone submodular function, but\nrequire access to all robots' trajectories, making it not suitable for\ndistributed execution. This work proposes a distributed planning approach based\non local search and shows how lazy/greedy methods can be adopted to reduce the\ncomputation and communication of the approach. We demonstrate the efficacy of\nthe proposed method by coordinating robot teams composed of both ground and\naerial vehicles with different sensing/control profiles and evaluate the\nalgorithm's performance in two target tracking scenarios. Compared to the naive\ndistributed execution of local search, our approach saves up to 60%\ncommunication and 80--92% computation on average when coordinating up to 10\nrobots, while outperforming the coordinate descent based algorithm in achieving\na desirable trade-off between sensing and energy cost.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2021 21:38:55 GMT"}, {"version": "v2", "created": "Fri, 26 Mar 2021 04:48:10 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Cai", "Xiaoyi", ""], ["Schlotfeldt", "Brent", ""], ["Khosoussi", "Kasra", ""], ["Atanasov", "Nikolay", ""], ["Pappas", "George J.", ""], ["How", "Jonathan P.", ""]]}, {"id": "2101.11116", "submitter": "Ofer Dagan", "authors": "Ofer Dagan, Nisar R. Ahmed", "title": "Exact and Approximate Heterogeneous Bayesian Decentralized Data Fusion", "comments": "13 pages, 6 figures, 2 tables, submitted to IEEE Transactions on\n  Robotics (T-RO)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.MA cs.SY eess.SP eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In Bayesian peer-to-peer decentralized data fusion for static and dynamic\nsystems, the underlying estimated or communicated distributions are frequently\nassumed to be homogeneous between agents. This requires each agent to process\nand communicate the full global joint distribution, and thus leads to high\ncomputation and communication costs irrespective of relevancy to specific local\nobjectives. This work considers a family of heterogeneous decentralized fusion\nproblems, where we consider the set of problems in which either the\ncommunicated or the estimated distributions describe different, but\noverlapping, states of interest that are subsets of a larger full global joint\nstate. We exploit the conditional independence structure of such problems and\nprovide a rigorous derivation for a family of exact and approximate\nheterogeneous conditionally factorized channel filter methods. We further\nextend existing methods for approximate conservative filtering and\ndecentralized fusion in heterogeneous dynamic problems. Numerical examples show\nmore than 99.5% potential communication reduction for heterogeneous channel\nfilter fusion, and a multi-target tracking simulation shows that these methods\nprovide consistent estimates.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2021 22:26:05 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Dagan", "Ofer", ""], ["Ahmed", "Nisar R.", ""]]}, {"id": "2101.11538", "submitter": "Carole Adam", "authors": "Albin Soutif and Carole Adam and Sylvain Bouveret", "title": "Multi-agent simulation of voter's behaviour", "comments": "internship report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The goal of this paper is to simulate the voters behaviour given a voting\nmethod. Our approach uses a multi-agent simulation in order to model a voting\nprocess through many iterations, so that the voters can vote by taking into\naccount the results of polls. Here we only tried basic rules and a single\nvoting method, but further attempts could explore new features.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2021 16:48:03 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Soutif", "Albin", ""], ["Adam", "Carole", ""], ["Bouveret", "Sylvain", ""]]}, {"id": "2101.11548", "submitter": "Carole Adam", "authors": "Yassine Bouachrine and Carole Adam", "title": "Modelling the Impact of Scandals: the case of the 2017 French\n  Presidential Election", "comments": "internship report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper proposes an agent-based simulation of a presidential election,\ninspired by the French 2017 presidential election. The simulation is based on\ndata extracted from polls, media coverage, and Twitter. The main contribution\nis to consider the impact of scandals and media bashing on the result of the\nelection. In particular, it is shown that scandals can lead to higher\nabstention at the election, as voters have no relevant candidate left to vote\nfor. The simulation is implemented in Unity 3D and is available to play online.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2021 17:08:38 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Bouachrine", "Yassine", ""], ["Adam", "Carole", ""]]}, {"id": "2101.11967", "submitter": "Patrick Mannion", "authors": "David O'Callaghan and Patrick Mannion", "title": "Exploring the Impact of Tunable Agents in Sequential Social Dilemmas", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  When developing reinforcement learning agents, the standard approach is to\ntrain an agent to converge to a fixed policy that is as close to optimal as\npossible for a single fixed reward function. If different agent behaviour is\nrequired in the future, an agent trained in this way must normally be either\nfully or partially retrained, wasting valuable time and resources. In this\nstudy, we leverage multi-objective reinforcement learning to create tunable\nagents, i.e. agents that can adopt a range of different behaviours according to\nthe designer's preferences, without the need for retraining. We apply this\ntechnique to sequential social dilemmas, settings where there is inherent\ntension between individual and collective rationality. Learning a single fixed\npolicy in such settings leaves one at a significant disadvantage if the\nopponents' strategies change after learning is complete. In our work, we\ndemonstrate empirically that the tunable agents framework allows easy adaption\nbetween cooperative and competitive behaviours in sequential social dilemmas\nwithout the need for retraining, allowing a single trained agent model to be\nadjusted to cater for a wide range of behaviours and opponent strategies.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jan 2021 12:44:31 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["O'Callaghan", "David", ""], ["Mannion", "Patrick", ""]]}, {"id": "2101.12204", "submitter": "Cong Shen", "authors": "Chengshuai Shi and Cong Shen", "title": "Federated Multi-Armed Bandits", "comments": "AAAI 2021, Camera Ready. Code is available at:\n  https://github.com/ShenGroup/FMAB", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT cs.MA math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated multi-armed bandits (FMAB) is a new bandit paradigm that parallels\nthe federated learning (FL) framework in supervised learning. It is inspired by\npractical applications in cognitive radio and recommender systems, and enjoys\nfeatures that are analogous to FL. This paper proposes a general framework of\nFMAB and then studies two specific federated bandit models. We first study the\napproximate model where the heterogeneous local models are random realizations\nof the global model from an unknown distribution. This model introduces a new\nuncertainty of client sampling, as the global model may not be reliably learned\neven if the finite local models are perfectly known. Furthermore, this\nuncertainty cannot be quantified a priori without knowledge of the\nsuboptimality gap. We solve the approximate model by proposing Federated Double\nUCB (Fed2-UCB), which constructs a novel \"double UCB\" principle accounting for\nuncertainties from both arm and client sampling. We show that gradually\nadmitting new clients is critical in achieving an O(log(T)) regret while\nexplicitly considering the communication cost. The exact model, where the\nglobal bandit model is the exact average of heterogeneous local models, is then\nstudied as a special case. We show that, somewhat surprisingly, the\norder-optimal regret can be achieved independent of the number of clients with\na careful choice of the update periodicity. Experiments using both synthetic\nand real-world datasets corroborate the theoretical analysis and demonstrate\nthe effectiveness and efficiency of the proposed algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jan 2021 18:59:19 GMT"}, {"version": "v2", "created": "Wed, 3 Mar 2021 14:36:34 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Shi", "Chengshuai", ""], ["Shen", "Cong", ""]]}, {"id": "2101.12725", "submitter": "Juste Raimbault", "authors": "Juste Raimbault", "title": "Strong coupling between scales in a multi-scalar model of urban dynamics", "comments": "15 pages, 7 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.CY cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Urban evolution processes occur at different scales, with intricate\ninteractions between levels and relatively distinct type of processes. To what\nextent actual urban dynamics include an actual strong coupling between scales,\nin the sense of both top-down and bottom-up feedbacks, remains an open issue\nwith important practical implications for the sustainable management of\nterritories. We introduce in this paper a multi-scalar simulation model of\nurban growth, coupling a system of cities interaction model at the macroscopic\nscale with morphogenesis models for the evolution of urban form at the scale of\nmetropolitan areas. Strong coupling between scales is achieved through an\nupdate of model parameters at each scale depending on trajectories at the other\nscale. The model is applied and explored on synthetic systems of cities.\nSimulation results show a non-trivial effect of the strong coupling. As a\nconsequence, an optimal action on policy parameters such as containing urban\nsprawl is shifted. We also run a multi-objective optimization algorithm on the\nmodel, showing showing that compromise between scales are captured. Our\napproach opens new research directions towards more operational urban dynamics\nmodels including a strong feedback between scales.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jan 2021 18:37:44 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Raimbault", "Juste", ""]]}]