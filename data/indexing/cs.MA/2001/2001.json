[{"id": "2001.00034", "submitter": "Bernardo Furtado", "authors": "Bernardo Alves Furtado", "title": "Contributions of Talent, Perspective, Context and Luck to Success", "comments": "9 pages, 5 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.CY cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a controlled simulation within a competitive sum-zero environment\nas a proxy for disaggregating components of success. Given a simulation of the\nRisk board game, we consider (a) Talent to be one of three rule-based\nstrategies used by players; (b) Context as the setting of each run of the game\nwith opponents' strategies, goals and luck; and (c) Perspective as the\nobjective of each player. Success is attained when a first player conquers its\ngoal. We simulate 100,000 runs of an agent-based model and analyze the results.\nThe simulation results strongly suggest that luck, talent and context are all\nrelevant to determine success. Perspective -- as the description of the goal\nthat defines success -- is not. As such, we present a quantitative,\nreproducible environment in which we are able to significantly separate the\nconcepts, reproducing previous results of the literature and adding arguments\nfor context and perspective. Finally, we also find that the simulation offers\ninsights on the relevance of resilience and opportunity.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 19:00:33 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 19:28:56 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Furtado", "Bernardo Alves", ""]]}, {"id": "2001.00141", "submitter": "Mohammadreza Doostmohammadian", "authors": "Mohammadreza Doostmohammadian", "title": "Single-Bit Consensus with Finite-Time Convergence: Theory and\n  Applications", "comments": null, "journal-ref": "IEEE Transactions on Aerospace and Electronic Systems 2020", "doi": null, "report-no": null, "categories": "eess.SY cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this brief paper, a new consensus protocol based on the sign of\ninnovations is proposed. Based on this protocol each agent only requires\nsingle-bit of information about its relative state to its neighboring agents.\nThis is significant in real-time applications, since it requires less\ncomputation and/or communication load on agents. Using Lyapunov stability\ntheorem the convergence is proved for networks having a spanning tree. Further,\nthe convergence is shown to be in finite-time, which is significant as compared\nto most asymptotic protocols in the literature. Time-variant network topologies\nare also considered in this paper, and final consensus value is derived for\nundirected networks. Applications of the proposed consensus protocol in (i)\n2D/3D rendezvous task, (ii) distributed estimation, (iii) distributed\noptimization, and (iv) formation control are considered and significance of\napplying this protocol is discussed. Numerical simulations are provided to\ncompare the protocol with the existing protocols in the literature.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jan 2020 05:09:29 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Doostmohammadian", "Mohammadreza", ""]]}, {"id": "2001.00440", "submitter": "Yunus Emre Sahin", "authors": "Yunus Emre Sahin, Necmiye Ozay", "title": "From Drinking Philosophers to Wandering Robots", "comments": "13 pages, 7 figures. Under submission for a journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.MA cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the multi-robot path execution problem where a\ngroup of robots move on predefined paths from their initial to target positions\nwhile avoiding collisions and deadlocks in the face of asynchrony. We first\nshow that this problem can be reformulated as a distributed resource allocation\nproblem and, in particular, as an instance of the well-known Drinking\nPhilosophers Problem (DrPP). By careful construction of the drinking sessions\ncapturing shared resources, we show that any existing solutions to DrPP can be\nused to design robot control policies that are collectively collision and\ndeadlock-free. We then propose modifications to an existing DrPP algorithm to\nallow more concurrent behavior, and provide conditions under which our method\nis deadlock-free. Our method do not require robots to know or to estimate the\nspeed profiles of other robots, and results in distributed control policies. We\ndemonstrate the efficacy of our method on simulation examples, which show\ncompetitive performance against the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 13:59:26 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Sahin", "Yunus Emre", ""], ["Ozay", "Necmiye", ""]]}, {"id": "2001.00543", "submitter": "S. Rasoul Etesami", "authors": "S. Rasoul Etesami, Negar Kiyavash, Vincent Leon, H. Vincent Poor", "title": "Toward Optimal Adversarial Policies in the Multiplicative Learning\n  System with a Malicious Expert", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a learning system based on the conventional multiplicative weight\n(MW) rule that combines experts' advice to predict a sequence of true outcomes.\nIt is assumed that one of the experts is malicious and aims to impose the\nmaximum loss on the system. The loss of the system is naturally defined to be\nthe aggregate absolute difference between the sequence of predicted outcomes\nand the true outcomes. We consider this problem under both offline and online\nsettings. In the offline setting where the malicious expert must choose its\nentire sequence of decisions a priori, we show somewhat surprisingly that a\nsimple greedy policy of always reporting false prediction is asymptotically\noptimal with an approximation ratio of $1+O(\\sqrt{\\frac{\\ln N}{N}})$, where $N$\nis the total number of prediction stages. In particular, we describe a policy\nthat closely resembles the structure of the optimal offline policy. For the\nonline setting where the malicious expert can adaptively make its decisions, we\nshow that the optimal online policy can be efficiently computed by solving a\ndynamic program in $O(N^3)$. Our results provide a new direction for\nvulnerability assessment of commonly used learning algorithms to adversarial\nattacks where the threat is an integral part of the system.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 18:04:46 GMT"}, {"version": "v2", "created": "Fri, 18 Sep 2020 02:43:53 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Etesami", "S. Rasoul", ""], ["Kiyavash", "Negar", ""], ["Leon", "Vincent", ""], ["Poor", "H. Vincent", ""]]}, {"id": "2001.00560", "submitter": "Hesham Rakha", "authors": "Ahmed A. Hussein and Hesham A. Rakha", "title": "Vehicle Platooning Impact on Drag Coefficients and Energy/Fuel Saving\n  Implications", "comments": "In review in the Journal of Applied Energy", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, empirical data from the literature are used to develop general\npower models that capture the impact of a vehicle position, in a platoon of\nhomogeneous vehicles, and the distance gap to its lead (and following) vehicle\non its drag coefficient. These models are developed for light duty vehicles,\nbuses, and heavy duty trucks. The models were fit using a constrained\noptimization framework to fit a general power function using either direct drag\nforce or fuel measurements. The model is then used to extrapolate the empirical\nmeasurements to a wide range of vehicle distance gaps within a platoon. Using\nthese models we estimate the potential fuel reduction associated with\nhomogeneous platoons of light duty vehicles, buses, and heavy duty trucks. The\nresults show a significant reduction in the vehicle fuel consumption when\ncompared with those based on a constant drag coefficient assumption.\nSpecifically, considering a minimum time gap between vehicles of $0.5 \\; secs$\n(which is typical considering state-of-practice communication and mechanical\nsystem latencies) running at a speed of $100 \\; km/hr$, the optimum fuel\nreduction that is achieved is $4.5 \\%$, $15.5 \\%$, and $7.0 \\%$ for light duty\nvehicle, bus, and heavy duty truck platoons, respectively. For longer time\ngaps, the bus and heavy duty truck platoons still produce fuel reductions in\nthe order of $9.0 \\%$ and $4.5 \\%$, whereas light duty vehicles produce\nnegligible fuel savings.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 18:53:07 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2020 19:43:58 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Hussein", "Ahmed A.", ""], ["Rakha", "Hesham A.", ""]]}, {"id": "2001.00567", "submitter": "Faheem Zafari", "authors": "Faheem Zafari, Kin K. Leung, Don Towsley, Prithwish Basu, Ananthram\n  Swami and Jian Li", "title": "Let's Share: A Game-Theoretic Framework for Resource Sharing in Mobile\n  Edge Clouds", "comments": "The paper is currently under review in IEEE Transactions on Network\n  and Service Management", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile edge computing seeks to provide resources to different delay-sensitive\napplications. This is a challenging problem as an edge cloud-service provider\nmay not have sufficient resources to satisfy all resource requests.\nFurthermore, allocating available resources optimally to different applications\nis also challenging. Resource sharing among different edge cloud-service\nproviders can address the aforementioned limitation as certain service\nproviders may have resources available that can be ``rented'' by other service\nproviders. However, edge cloud service providers can have different objectives\nor \\emph{utilities}. Therefore, there is a need for an efficient and effective\nmechanism to share resources among service providers, while considering the\ndifferent objectives of various providers. We model resource sharing as a\nmulti-objective optimization problem and present a solution framework based on\n\\emph{Cooperative Game Theory} (CGT). We consider the strategy where each\nservice provider allocates resources to its native applications first and\nshares the remaining resources with applications from other service providers.\nWe prove that for a monotonic, non-decreasing utility function, the game is\ncanonical and convex. Hence, the \\emph{core} is not empty and the grand\ncoalition is stable. We propose two algorithms \\emph{Game-theoretic Pareto\noptimal allocation} (GPOA) and \\emph{Polyandrous-Polygamous Matching based\nPareto Optimal Allocation} (PPMPOA) that provide allocations from the core.\nHence the obtained allocations are \\emph{Pareto} optimal and the grand\ncoalition of all the service providers is stable. Experimental results confirm\nthat our proposed resource sharing framework improves utilities of edge\ncloud-service providers and application request satisfaction.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 18:58:26 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Zafari", "Faheem", ""], ["Leung", "Kin K.", ""], ["Towsley", "Don", ""], ["Basu", "Prithwish", ""], ["Swami", "Ananthram", ""], ["Li", "Jian", ""]]}, {"id": "2001.00786", "submitter": "Alessandro Paolo Capasso", "authors": "Alessandro Paolo Capasso, Giulio Bacchiani, Daniele Molinari", "title": "Intelligent Roundabout Insertion using Deep Reinforcement Learning", "comments": null, "journal-ref": "Proceedings of ICAART 2020, ISBN: 978-989-758-395-7", "doi": "10.5220/0008915003780385", "report-no": null, "categories": "cs.LG cs.AI cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important topic in the autonomous driving research is the development of\nmaneuver planning systems. Vehicles have to interact and negotiate with each\nother so that optimal choices, in terms of time and safety, are taken. For this\npurpose, we present a maneuver planning module able to negotiate the entering\nin busy roundabouts. The proposed module is based on a neural network trained\nto predict when and how entering the roundabout throughout the whole duration\nof the maneuver. Our model is trained with a novel implementation of A3C, which\nwe will call Delayed A3C (D-A3C), in a synthetic environment where vehicles\nmove in a realistic manner with interaction capabilities. In addition, the\nsystem is trained such that agents feature a unique tunable behavior, emulating\nreal world scenarios where drivers have their own driving styles. Similarly,\nthe maneuver can be performed using different aggressiveness levels, which is\nparticularly useful to manage busy scenarios where conservative rule-based\npolicies would result in undefined waits.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 11:16:41 GMT"}, {"version": "v2", "created": "Wed, 13 May 2020 11:24:33 GMT"}, {"version": "v3", "created": "Wed, 28 Apr 2021 09:22:53 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Capasso", "Alessandro Paolo", ""], ["Bacchiani", "Giulio", ""], ["Molinari", "Daniele", ""]]}, {"id": "2001.00907", "submitter": "Korosh Mahmoodi", "authors": "Korosh Mahmoodi, Bruce J. West and Cleotilde Gonzalez", "title": "Selfish Algorithm and Emergence of Collective Intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "nlin.AO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a model for demonstrating spontaneous emergence of collective\nintelligent behavior from selfish individual agents. Agents' behavior is\nmodeled using our proposed selfish algorithm ($SA$) with three learning\nmechanisms: reinforced learning ($SAL$), trust ($SAT$) and connection ($SAC$).\nEach of these mechanisms provides a distinctly different way an agent can\nincrease the individual benefit accrued through playing the prisoner's dilemma\ngame ($PDG$) with other agents. The $SA$ provides a generalization of the\nself-organized temporal criticality ($SOTC$) model and shows that\nself-interested individuals can simultaneously produce maximum social benefit\nfrom their decisions. The mechanisms in the $SA$ are self-tuned by the internal\ndynamics and without having a pre-established network structure. Our results\ndemonstrate emergence of mutual cooperation, emergence of dynamic networks, and\nadaptation and resilience of social systems after perturbations. The\nimplications and applications of the $SA$ are discussed.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 17:42:26 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Mahmoodi", "Korosh", ""], ["West", "Bruce J.", ""], ["Gonzalez", "Cleotilde", ""]]}, {"id": "2001.00918", "submitter": "Wenhang Bao", "authors": "Wenhang Bao", "title": "Fairness in Multi-agent Reinforcement Learning for Stock Trading", "comments": "arXiv admin note: substantial text overlap with arXiv:1906.11046;\n  text overlap with arXiv:1907.10323 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.TR cs.LG cs.MA q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unfair stock trading strategies have been shown to be one of the most\nnegative perceptions that customers can have concerning trading and may result\nin long-term losses for a company. Investment banks usually place trading\norders for multiple clients with the same target assets but different order\nsizes and diverse requirements such as time frame and risk aversion level,\nthereby total earning and individual earning cannot be optimized at the same\ntime. Orders executed earlier would affect the market price level, so late\nexecution usually means additional implementation cost. In this paper, we\npropose a novel scheme that utilizes multi-agent reinforcement learning systems\nto derive stock trading strategies for all clients which keep a balance between\nrevenue and fairness. First, we demonstrate that Reinforcement learning (RL) is\nable to learn from experience and adapt the trading strategies to the complex\nmarket environment. Secondly, we show that the Multi-agent RL system allows\ndeveloping trading strategies for all clients individually, thus optimizing\nindividual revenue. Thirdly, we use the Generalized Gini Index (GGI)\naggregation function to control the fairness level of the revenue across all\nclients. Lastly, we empirically demonstrate the superiority of the novel scheme\nin improving fairness meanwhile maintaining optimization of revenue.\n", "versions": [{"version": "v1", "created": "Sat, 14 Dec 2019 16:58:51 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Bao", "Wenhang", ""]]}, {"id": "2001.01096", "submitter": "Weiya Ren", "authors": "Weiya Ren", "title": "Represented Value Function Approach for Large Scale Multi Agent\n  Reinforcement Learning", "comments": "9 pages the code is published and the result is reproducible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of large scale multi agent\nreinforcement learning. Firstly, we studied the representation problem of the\npairwise value function to reduce the complexity of the interactions among\nagents. Secondly, we adopt a l2-norm trick to ensure the trivial term of the\napproximated value function is bounded. Thirdly, experimental results on battle\ngame demonstrate the effectiveness of the proposed approach.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jan 2020 16:29:13 GMT"}, {"version": "v2", "created": "Fri, 10 Jan 2020 01:57:34 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Ren", "Weiya", ""]]}, {"id": "2001.01918", "submitter": "Qun Liu", "authors": "Supratik Mukhopadhyay, Qun Liu, Edward Collier, Yimin Zhu, Ravindra\n  Gudishala, Chanachok Chokwitthaya, Robert DiBiano, Alimire Nabijiang, Sanaz\n  Saeidi, Subhajit Sidhanta, Arnab Ganguly", "title": "Context-Aware Design of Cyber-Physical Human Systems (CPHS)", "comments": "Paper was accepted at the 12th International Conference on\n  Communication Systems and Networks (COMSNETS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, it has been widely accepted by the research community that\ninteractions between humans and cyber-physical infrastructures have played a\nsignificant role in determining the performance of the latter. The existing\nparadigm for designing cyber-physical systems for optimal performance focuses\non developing models based on historical data. The impacts of context factors\ndriving human system interaction are challenging and are difficult to capture\nand replicate in existing design models. As a result, many existing models do\nnot or only partially address those context factors of a new design owing to\nthe lack of capabilities to capture the context factors. This limitation in\nmany existing models often causes performance gaps between predicted and\nmeasured results. We envision a new design environment, a cyber-physical human\nsystem (CPHS) where decision-making processes for physical infrastructures\nunder design are intelligently connected to distributed resources over\ncyberinfrastructure such as experiments on design features and empirical\nevidence from operations of existing instances. The framework combines existing\ndesign models with context-aware design-specific data involving\nhuman-infrastructure interactions in new designs, using a machine learning\napproach to create augmented design models with improved predictive powers.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 07:31:36 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Mukhopadhyay", "Supratik", ""], ["Liu", "Qun", ""], ["Collier", "Edward", ""], ["Zhu", "Yimin", ""], ["Gudishala", "Ravindra", ""], ["Chokwitthaya", "Chanachok", ""], ["DiBiano", "Robert", ""], ["Nabijiang", "Alimire", ""], ["Saeidi", "Sanaz", ""], ["Sidhanta", "Subhajit", ""], ["Ganguly", "Arnab", ""]]}, {"id": "2001.02112", "submitter": "Roula Nassif", "authors": "Roula Nassif, Stefan Vlaski, Cedric Richard, Jie Chen, and Ali H.\n  Sayed", "title": "Multitask learning over graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of learning simultaneously several related tasks has received\nconsiderable attention in several domains, especially in machine learning with\nthe so-called multitask learning problem or learning to learn problem [1], [2].\nMultitask learning is an approach to inductive transfer learning (using what is\nlearned for one problem to assist in another problem) and helps improve\ngeneralization performance relative to learning each task separately by using\nthe domain information contained in the training signals of related tasks as an\ninductive bias. Several strategies have been derived within this community\nunder the assumption that all data are available beforehand at a fusion center.\nHowever, recent years have witnessed an increasing ability to collect data in a\ndistributed and streaming manner. This requires the design of new strategies\nfor learning jointly multiple tasks from streaming data over distributed (or\nnetworked) systems. This article provides an overview of multitask strategies\nfor learning and adaptation over networks. The working hypothesis for these\nstrategies is that agents are allowed to cooperate with each other in order to\nlearn distinct, though related tasks. The article shows how cooperation steers\nthe network limiting point and how different cooperation rules allow to promote\ndifferent task relatedness models. It also explains how and when cooperation\nover multitask networks outperforms non-cooperative strategies.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 15:32:57 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Nassif", "Roula", ""], ["Vlaski", "Stefan", ""], ["Richard", "Cedric", ""], ["Chen", "Jie", ""], ["Sayed", "Ali H.", ""]]}, {"id": "2001.02443", "submitter": "Stefano Mariani", "authors": "Stefano Mariani, Giacomo Cabri, and Franco Zambonelli", "title": "Coordination of Autonomous Vehicles: Taxonomy and Survey", "comments": "31 pages, 1 figure, submitted to ACM CSUR", "journal-ref": null, "doi": "10.1145/3431231", "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the near future, our streets will be populated by myriads of autonomous\nself-driving vehicles to serve our diverse mobility needs. This will raise the\nneed to coordinate their movements in order to properly handle both access to\nshared resources (e.g., intersections and parking slots) and the execution of\nmobility tasks (e.g., platooning and ramp merging). In this paper, we firstly\nintroduce the general issues associated to coordination of autonomous vehicles,\nby identifying and framing the key classes of coordination problems. Following,\nwe overview the different approaches that can be adopted to manage such\ncoordination problems, by classifying them in terms of the degree of autonomy\nin decision making that is left to autonomous vehicles during coordination.\nFinally, we overview some further peculiar challenges that research will have\nto address before autonomously coordinated vehicles can safely hit our streets.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 10:47:47 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Mariani", "Stefano", ""], ["Cabri", "Giacomo", ""], ["Zambonelli", "Franco", ""]]}, {"id": "2001.02906", "submitter": "Mirko Salaris", "authors": "Mirko Salaris (1), Alessandro Riva (1) and Francesco Amigoni (1) ((1)\n  Politecnico di Milano)", "title": "Multirobot Coverage of Linear Modular Environments", "comments": "11 pages, 5 figures. Submitted to AAMAS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.RO", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Multirobot systems for covering environments are increasingly used in\napplications like cleaning, industrial inspection, patrolling, and precision\nagriculture. The problem of covering a given environment using multiple robots\ncan be naturally formulated and studied as a multi-Traveling Salesperson\nProblem (mTSP). In a mTSP, the environment is represented as a graph and the\ngoal is to find tours (starting and ending at the same depot) for the robots in\norder to visit all the vertices with minimum global cost, namely the length of\nthe longest tour. The mTSP is an NP-hard problem for which several\napproximation algorithms have been proposed. These algorithms usually assume\ngeneric environments, but tighter approximation bounds can be reached focusing\non specific environments. In this paper, we address the case of environments\ncomposed of sub-parts, called modules, that can be reached from each other only\nthrough some linking structures. Examples are multi-floor buildings, in which\nthe modules are the floors and the linking structures are the staircases or the\nelevators, and floors of large hotels or hospitals, in which the modules are\nthe rooms and the linking structures are the corridors. We focus on linear\nmodular environments, with the modules organized sequentially, presenting an\nefficient (with polynomial worst-case time complexity) algorithm that finds a\nsolution for the mTSP whose cost is within a bounded distance from the cost of\nthe optimal solution. The main idea of our algorithm is to allocate disjoint\n\"blocks\" of adjacent modules to the robots, in such a way that each module is\ncovered by only one robot. We experimentally compare our algorithm against some\nstate-of-the-art algorithms for solving mTSPs in generic environments and show\nthat it is able to provide solutions with lower makespan and spending a\ncomputing time several orders of magnitude shorter.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 10:03:24 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Salaris", "Mirko", ""], ["Riva", "Alessandro", ""], ["Amigoni", "Francesco", ""]]}, {"id": "2001.03020", "submitter": "Henry M. Kim", "authors": "Marek Laskowski, Michael Zargham, Hjalmar Turesson, Matt Barlin, Danil\n  Kabanov, Eden Dhaliwal", "title": "Evidence Based Decision Making in Blockchain Economic Systems: From\n  Theory to Practice", "comments": "arXiv admin note: text overlap with arXiv:1910.02064", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a methodology for evidence based design of cryptoeconomic systems,\nand elucidate a real-world example of how this methodology was used in the\ndesign of a blockchain network. This work provides a rare insight into the\napplication of Data Science and Stochastic Simulation and Modelling to Token\nEngineering. We demonstrate how the described process has the ability to\nuncover previously unexpected system level behaviors. Furthermore, it is\nobserved that the process itself creates opportunities for the discovery of new\nknowledge and business understanding while developing the system from a high\nlevel specification to one precise enough to be executed as a computational\nmodel. Discovery of performance issues during design time can spare costly\nemergency interventions that would be necessary if issues instead became\napparent in a production network. For this reason, network designers are\nincreasingly adopting evidence-based design practices, such as the one\ndescribed herein.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 12:47:43 GMT"}, {"version": "v2", "created": "Sat, 9 May 2020 20:17:24 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Laskowski", "Marek", ""], ["Zargham", "Michael", ""], ["Turesson", "Hjalmar", ""], ["Barlin", "Matt", ""], ["Kabanov", "Danil", ""], ["Dhaliwal", "Eden", ""]]}, {"id": "2001.03133", "submitter": "Vijay Garg", "authors": "Vijay K. Garg", "title": "A Generalization of Teo and Sethuraman's Median Stable Marriage Theorem", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $L$ be any finite distributive lattice and $B$ be any boolean predicate\ndefined on $L$ such that the set of elements satisfying $B$ is a sublattice of\n$L$. Consider any subset $M$ of $L$ of size $k$ of elements of $L$ that satisfy\n$B$. Then, we show that $k$ generalized median elements generated from $M$ also\nsatisfy $B$. We call this result generalized median theorem on finite\ndistributive lattices. When this result is applied to the stable matching, we\nget Teo and Sethuraman's median stable matching theorem. Our proof is much\nsimpler than that of Teo and Sethuraman. When the generalized median theorem is\napplied to the assignment problem, we get an analogous result for market\nclearing price vectors.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 17:51:32 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Garg", "Vijay K.", ""]]}, {"id": "2001.03238", "submitter": "Asma Khatun Dr.", "authors": "Asma Khatun and Sk. Golam Sarowar Hossain", "title": "Open Challenges and Issues: Artificial Intelligence for Transactive\n  Management", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advancement of Artificial Intelligence (AI) has improved the automation\nof energy managements. In smart energy management or in a smart grid framework,\nall the devices and the distributed resources and renewable resources are\nembedded which leads to reduce cost. A smart energy management system,\nTransactive management (TM) is a concept to improve the efficiency and\nreliability of the power system. The aim of this article is to look for the\ncurrent development of TM methods based on AI and Machine Learning (ML)\ntechnology. In AI paradigm, MultiAgent System (MAS) based method is an active\nresearch area and are still in evolution. Hence this article describes how MAS\nbased method applied in TM. This paper also finds that MAS based method faces\nmajor difficulty to design or set up goal to various agents and describes how\nML technique can contribute to that solution. A brief comparison analysis\nbetween MAS and ML techniques are also presented. At the end, this article\nsummarizes the most relevant open challenges and issues on the AI based methods\nfor transactive energy management.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 17:33:07 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Khatun", "Asma", ""], ["Hossain", "Sk. Golam Sarowar", ""]]}, {"id": "2001.03384", "submitter": "Evangelos Pournaras", "authors": "Brionna Davis, Grace Jennings, Taylor Pothast, Ilias Gerostathopoulos,\n  Evangelos Pournaras, Raphael E. Stern", "title": "Decentralized Optimization of Vehicle Route Planning -- A Cross-City\n  Comparative Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.AI cs.DC cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  New mobility concepts are at the forefront of research and innovation in\nsmart cities. The introduction of connected and autonomous vehicles enables new\npossibilities in vehicle routing. Specifically, knowing the origin and\ndestination of each agent in the network can allow for real-time routing of the\nvehicles to optimize network performance. However, this relies on individual\nvehicles being \"altruistic\" i.e., being willing to accept an alternative\nnon-preferred route in order to achieve a network-level performance goal. In\nthis work, we conduct a study to compare different levels of agent altruism and\nthe resulting effect on the network-level traffic performance. Specifically,\nthis study compares the effects of different underlying urban structures on the\noverall network performance, and investigates which characteristics of the\nnetwork make it possible to realize routing improvements using a decentralized\noptimization router. The main finding is that, with increased vehicle altruism,\nit is possible to balance traffic flow among the links of the network. We show\nevidence that the decentralized optimization router is more effective with\nnetworks of high load while we study the influence of cities characteristics,\nin particular: networks with a higher number of nodes (intersections) or edges\n(roads) per unit area allow for more possible alternate routes, and thus higher\npotential to improve network performance.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 11:02:51 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Davis", "Brionna", ""], ["Jennings", "Grace", ""], ["Pothast", "Taylor", ""], ["Gerostathopoulos", "Ilias", ""], ["Pournaras", "Evangelos", ""], ["Stern", "Raphael E.", ""]]}, {"id": "2001.03415", "submitter": "Minghuan Liu", "authors": "Minghuan Liu, Ming Zhou, Weinan Zhang, Yuzheng Zhuang, Jun Wang,\n  Wulong Liu, Yong Yu", "title": "Multi-Agent Interactions Modeling with Correlated Policies", "comments": "20 pages (10 pages of supplementary), 5 figures, Accepted by The\n  Eighth International Conference on Learning Representations (ICLR 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multi-agent systems, complex interacting behaviors arise due to the high\ncorrelations among agents. However, previous work on modeling multi-agent\ninteractions from demonstrations is primarily constrained by assuming the\nindependence among policies and their reward structures. In this paper, we cast\nthe multi-agent interactions modeling problem into a multi-agent imitation\nlearning framework with explicit modeling of correlated policies by\napproximating opponents' policies, which can recover agents' policies that can\nregenerate similar interactions. Consequently, we develop a Decentralized\nAdversarial Imitation Learning algorithm with Correlated policies (CoDAIL),\nwhich allows for decentralized training and execution. Various experiments\ndemonstrate that CoDAIL can better regenerate complex interactions close to the\ndemonstrators and outperforms state-of-the-art multi-agent imitation learning\nmethods. Our code is available at \\url{https://github.com/apexrl/CoDAIL}.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jan 2020 17:31:53 GMT"}, {"version": "v2", "created": "Mon, 20 Jan 2020 01:17:40 GMT"}, {"version": "v3", "created": "Thu, 11 Jun 2020 11:22:24 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Liu", "Minghuan", ""], ["Zhou", "Ming", ""], ["Zhang", "Weinan", ""], ["Zhuang", "Yuzheng", ""], ["Wang", "Jun", ""], ["Liu", "Wulong", ""], ["Yu", "Yong", ""]]}, {"id": "2001.03494", "submitter": "Gian Maria Campedelli", "authors": "Gian Maria Campedelli, Francesco Calderoni, Mario Paolucci, Tommaso\n  Comunale, Daniele Vilone, Federico Cecconi, and Giulia Andrighetto", "title": "A Policy-oriented Agent-based Model of Recruitment into Organized Crime", "comments": "15 pages, 2 figures. Paper accepted and in press for the Proceedings\n  of the 2019 Social Simulation Conference (Mainz, Germany)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.CY cs.SI nlin.CD", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Criminal organizations exploit their presence on territories and local\ncommunities to recruit new workforce in order to carry out their criminal\nactivities and business. The ability to attract individuals is crucial for\nmaintaining power and control over the territories in which these groups are\nsettled. This study proposes the formalization, development and analysis of an\nagent-based model (ABM) that simulates a neighborhood of Palermo (Sicily) with\nthe aim to understand the pathways that lead individuals to recruitment into\norganized crime groups (OCGs). Using empirical data on social, economic and\ncriminal conditions of the area under analysis, we use a multi-layer network\napproach to simulate this scenario. As the final goal, we test different\npolicies to counter recruitment into OCGs. These scenarios are based on two\ndifferent dimensions of prevention and intervention: (i) primary and secondary\nsocialization and (ii) law enforcement targeting strategies.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 15:06:52 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Campedelli", "Gian Maria", ""], ["Calderoni", "Francesco", ""], ["Paolucci", "Mario", ""], ["Comunale", "Tommaso", ""], ["Vilone", "Daniele", ""], ["Cecconi", "Federico", ""], ["Andrighetto", "Giulia", ""]]}, {"id": "2001.04229", "submitter": "Faheem Zafari", "authors": "Faheem Zafari, Prithwish Basu, Kin K. Leung, Jian Li, Ananthram Swami\n  and Don Towsley", "title": "Resource Sharing in the Edge: A Distributed Bargaining-Theoretic\n  Approach", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DC cs.MA cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing demand for edge computing resources, particularly due to\nincreasing popularity of Internet of Things (IoT), and distributed machine/deep\nlearning applications poses a significant challenge. On the one hand, certain\nedge service providers (ESPs) may not have sufficient resources to satisfy\ntheir applications according to the associated service-level agreements. On the\nother hand, some ESPs may have additional unused resources. In this paper, we\npropose a resource-sharing framework that allows different ESPs to optimally\nutilize their resources and improve the satisfaction level of applications\nsubject to constraints such as communication cost for sharing resources across\nESPs. Our framework considers that different ESPs have their own objectives for\nutilizing their resources, thus resulting in a multi-objective optimization\nproblem. We present an $N$-person \\emph{Nash Bargaining Solution} (NBS) for\nresource allocation and sharing among ESPs with \\emph{Pareto} optimality\nguarantee. Furthermore, we propose a \\emph{distributed}, primal-dual algorithm\nto obtain the NBS by proving that the strong-duality property holds for the\nresultant resource sharing optimization problem.\n  Using synthetic and real-world data traces, we show numerically that the\nproposed NBS based framework not only enhances the ability to satisfy\napplications' resource demands, but also improves utilities of different ESPs.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 13:26:05 GMT"}, {"version": "v2", "created": "Mon, 27 Apr 2020 01:27:00 GMT"}, {"version": "v3", "created": "Sat, 4 Jul 2020 11:33:41 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Zafari", "Faheem", ""], ["Basu", "Prithwish", ""], ["Leung", "Kin K.", ""], ["Li", "Jian", ""], ["Swami", "Ananthram", ""], ["Towsley", "Don", ""]]}, {"id": "2001.04560", "submitter": "Anna Guerra", "authors": "Anna Guerra, Davide Dardari, Petar M. Djuric", "title": "Dynamic Radar Network of UAVs: A Joint Navigation and Tracking Approach", "comments": null, "journal-ref": null, "doi": "10.1109/ACCESS.2020.3001393", "report-no": null, "categories": "cs.IT cs.LG cs.MA math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays there is a growing research interest on the possibility of enriching\nsmall flying robots with autonomous sensing and online navigation capabilities.\nThis will enable a large number of applications spanning from remote\nsurveillance to logistics, smarter cities and emergency aid in hazardous\nenvironments. In this context, an emerging problem is to track unauthorized\nsmall unmanned aerial vehicles (UAVs) hiding behind buildings or concealing in\nlarge UAV networks. In contrast with current solutions mainly based on static\nand on-ground radars, this paper proposes the idea of a dynamic radar network\nof UAVs for real-time and high-accuracy tracking of malicious targets. To this\nend, we describe a solution for real-time navigation of UAVs to track a dynamic\ntarget using heterogeneously sensed information. Such information is shared by\nthe UAVs with their neighbors via multi-hops, allowing tracking the target by a\nlocal Bayesian estimator running at each agent. Since not all the paths are\nequal in terms of information gathering point-of-view, the UAVs plan their own\ntrajectory by minimizing the posterior covariance matrix of the target state\nunder UAV kinematic and anti-collision constraints. Our results show how a\ndynamic network of radars attains better localization results compared to a\nfixed configuration and how the on-board sensor technology impacts the accuracy\nin tracking a target with different radar cross sections, especially in non\nline-of-sight (NLOS) situations.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 23:23:09 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Guerra", "Anna", ""], ["Dardari", "Davide", ""], ["Djuric", "Petar M.", ""]]}, {"id": "2001.04678", "submitter": "David Balduzzi", "authors": "David Balduzzi, Wojciech M Czarnecki, Thomas W Anthony, Ian M Gemp,\n  Edward Hughes, Joel Z Leibo, Georgios Piliouras, Thore Graepel", "title": "Smooth markets: A basic mechanism for organizing gradient-based learners", "comments": "18 pages, 3 figures", "journal-ref": "ICLR 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.GT cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the success of modern machine learning, it is becoming increasingly\nimportant to understand and control how learning algorithms interact.\nUnfortunately, negative results from game theory show there is little hope of\nunderstanding or controlling general n-player games. We therefore introduce\nsmooth markets (SM-games), a class of n-player games with pairwise zero sum\ninteractions. SM-games codify a common design pattern in machine learning that\nincludes (some) GANs, adversarial training, and other recent algorithms. We\nshow that SM-games are amenable to analysis and optimization using first-order\nmethods.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 09:19:39 GMT"}, {"version": "v2", "created": "Sat, 18 Jan 2020 09:09:22 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Balduzzi", "David", ""], ["Czarnecki", "Wojciech M", ""], ["Anthony", "Thomas W", ""], ["Gemp", "Ian M", ""], ["Hughes", "Edward", ""], ["Leibo", "Joel Z", ""], ["Piliouras", "Georgios", ""], ["Graepel", "Thore", ""]]}, {"id": "2001.05161", "submitter": "Jing Li", "authors": "Jing Li and Jing Xu and Fangwei Zhong and Xiangyu Kong and Yu Qiao and\n  Yizhou Wang", "title": "Pose-Assisted Multi-Camera Collaboration for Active Object Tracking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active Object Tracking (AOT) is crucial to many visionbased applications,\ne.g., mobile robot, intelligent surveillance. However, there are a number of\nchallenges when deploying active tracking in complex scenarios, e.g., target is\nfrequently occluded by obstacles. In this paper, we extend the single-camera\nAOT to a multi-camera setting, where cameras tracking a target in a\ncollaborative fashion. To achieve effective collaboration among cameras, we\npropose a novel Pose-Assisted Multi-Camera Collaboration System, which enables\na camera to cooperate with the others by sharing camera poses for active object\ntracking. In the system, each camera is equipped with two controllers and a\nswitcher: The vision-based controller tracks targets based on observed images.\nThe pose-based controller moves the camera in accordance to the poses of the\nother cameras. At each step, the switcher decides which action to take from the\ntwo controllers according to the visibility of the target. The experimental\nresults demonstrate that our system outperforms all the baselines and is\ncapable of generalizing to unseen environments. The code and demo videos are\navailable on our website\nhttps://sites.google.com/view/pose-assistedcollaboration.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 07:49:49 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Li", "Jing", ""], ["Xu", "Jing", ""], ["Zhong", "Fangwei", ""], ["Kong", "Xiangyu", ""], ["Qiao", "Yu", ""], ["Wang", "Yizhou", ""]]}, {"id": "2001.05232", "submitter": "Iacovos Ioannou I.I.", "authors": "Iacovos Ioannou, Vasos Vassiliou, Christophoros Christophorou, and\n  Andreas Pitsillides", "title": "Distributed Artificial Intelligence Solution for D2D Communication in 5G\n  Networks", "comments": "10 pages,9 figures", "journal-ref": null, "doi": "10.1109/JSYST.2020.2979044.", "report-no": null, "categories": "cs.NI cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Device to Device (D2D) Communication is one of the technology components of\nthe evolving 5G architecture, as it promises improvements in energy efficiency,\nspectral efficiency, overall system capacity, and higher data rates. The above\nnoted improvements in network performance spearheaded a vast amount of research\nin D2D, which have identified significant challenges that need to be addressed\nbefore realizing their full potential in emerging 5G Networks. Towards this\nend, this paper proposes the use of a distributed intelligent approach to\ncontrol the generation of D2D networks. More precisely, the proposed approach\nuses Belief-Desire-Intention (BDI) intelligent agents with extended\ncapabilities (BDIx) to manage each D2D node independently and autonomously,\nwithout the help of the Base Station. The paper includes detailed algorithmic\ndescription for the decision of transmission mode, which maximizes the data\nrate, minimizes the power consumptions, while taking into consideration the\ncomputational load. Simulations show the applicability of BDI agents in jointly\nsolving D2D challenges.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 11:02:58 GMT"}, {"version": "v2", "created": "Mon, 20 Jan 2020 13:50:40 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Ioannou", "Iacovos", ""], ["Vassiliou", "Vasos", ""], ["Christophorou", "Christophoros", ""], ["Pitsillides", "Andreas", ""]]}, {"id": "2001.05271", "submitter": "Ehud Shapiro", "authors": "Reshef Meir, Gal Shahaf, Ehud Shapiro and Nimrod Talmon", "title": "Sybil-Resilient Social Choice with Partial Participation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.SI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Voting rules may fail to implement the will of the society when only some\nvoters actively participate, and/or in the presence of sybil (fake or\nduplicate) voters. Here we aim to address social choice in the presence of\nsybils and voter abstention.\n  To do so we assume the status-quo (Reality) as an ever-present distinguished\nalternative, and study Reality Enforcing voting rules, which add virtual votes\nin support of the status-quo. We measure the tradeoff between safety and\nliveness (the ability of active honest voters to maintain/change the\nstatus-quo, respectively) in a variety of domains, and show that the Reality\nEnforcing voting rule is optimal in this respect.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 12:31:32 GMT"}, {"version": "v2", "created": "Tue, 7 Jul 2020 05:59:26 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Meir", "Reshef", ""], ["Shahaf", "Gal", ""], ["Shapiro", "Ehud", ""], ["Talmon", "Nimrod", ""]]}, {"id": "2001.05994", "submitter": "Mycal Tucker", "authors": "Mycal Tucker, Yilun Zhou, Julie Shah", "title": "Adversarially Guided Self-Play for Adopting Social Conventions", "comments": "9 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robotic agents must adopt existing social conventions in order to be\neffective teammates. These social conventions, such as driving on the right or\nleft side of the road, are arbitrary choices among optimal policies, but all\nagents on a successful team must use the same convention. Prior work has\nidentified a method of combining self-play with paired input-output data\ngathered from existing agents in order to learn their social convention without\ninteracting with them. We build upon this work by introducing a technique\ncalled Adversarial Self-Play (ASP) that uses adversarial training to shape the\nspace of possible learned policies and substantially improves learning\nefficiency. ASP only requires the addition of unpaired data: a dataset of\noutputs produced by the social convention without associated inputs.\nTheoretical analysis reveals how ASP shapes the policy space and the\ncircumstances (when behaviors are clustered or exhibit some other structure)\nunder which it offers the greatest benefits. Empirical results across three\ndomains confirm ASP's advantages: it produces models that more closely match\nthe desired social convention when given as few as two paired datapoints.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 18:51:42 GMT"}, {"version": "v2", "created": "Wed, 7 Oct 2020 20:41:11 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Tucker", "Mycal", ""], ["Zhou", "Yilun", ""], ["Shah", "Julie", ""]]}, {"id": "2001.06056", "submitter": "Karol Rydzewski", "authors": "Jerzy Konorski and Karol Rydzewski", "title": "Nodal cooperation equilibrium analysis in multihop wireless ad hoc\n  networks with a reputation system", "comments": "presented at International Conference on Mathematical Methods,\n  Models, and Architectures for Computer Network Security; 12 pages; 2 figures;\n  keywords: wireless environment, multihop network, utility, cost,\n  reputation,cooperation, strategy, security", "journal-ref": "MMM-ACNS 2017. Lecture Notes in Computer Science, vol 10446.\n  Springer", "doi": "10.1007/978-3-319-65127-9_11", "report-no": null, "categories": "cs.NI cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Motivated by the concerns of cooperation security, this work examines\nselected principles of state-of-the-art reputation systems for multihop adhoc\nnetworks and their impact upon optimal strategies for rational nodes. An\nanalytic framework is proposed and used for identification of effective\ncooperation-enforcement schemes. It is pointed out that an optimum rather than\nhigh reputation can be expected to be sought by rational nodes.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 20:08:15 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Konorski", "Jerzy", ""], ["Rydzewski", "Karol", ""]]}, {"id": "2001.06487", "submitter": "Kai Yan", "authors": "Yunlong Lu and Kai Yan", "title": "Algorithms in Multi-Agent Systems: A Holistic Perspective from\n  Reinforcement Learning and Game Theory", "comments": "14 pages, review. Reorganizing the expressions in part of\n  introduction and background", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.LG cs.MA", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Deep reinforcement learning (RL) has achieved outstanding results in recent\nyears, which has led a dramatic increase in the number of methods and\napplications. Recent works are exploring learning beyond single-agent scenarios\nand considering multi-agent scenarios. However, they are faced with lots of\nchallenges and are seeking for help from traditional game-theoretic algorithms,\nwhich, in turn, show bright application promise combined with modern algorithms\nand boosting computing power. In this survey, we first introduce basic concepts\nand algorithms in single agent RL and multi-agent systems; then, we summarize\nthe related algorithms from three aspects. Solution concepts from game theory\ngive inspiration to algorithms which try to evaluate the agents or find better\nsolutions in multi-agent systems. Fictitious self-play becomes popular and has\na great impact on the algorithm of multi-agent reinforcement learning.\nCounterfactual regret minimization is an important tool to solve games with\nincomplete information, and has shown great strength when combined with deep\nlearning.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 15:08:04 GMT"}, {"version": "v2", "created": "Fri, 24 Jan 2020 13:28:37 GMT"}, {"version": "v3", "created": "Fri, 31 Jan 2020 02:16:05 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Lu", "Yunlong", ""], ["Yan", "Kai", ""]]}, {"id": "2001.06722", "submitter": "Chunheng Jiang", "authors": "Chunheng Jiang, Jianxi Gao, Malik Magdon-Ismail", "title": "True Nonlinear Dynamics from Incomplete Networks", "comments": "AAAI 2020, 9 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study nonlinear dynamics on complex networks. Each vertex $i$ has a state\n$x_i$ which evolves according to a networked dynamics to a steady-state\n$x_i^*$. We develop fundamental tools to learn the true steady-state of a small\npart of the network, without knowing the full network. A naive approach and the\ncurrent state-of-the-art is to follow the dynamics of the observed partial\nnetwork to local equilibrium. This dramatically fails to extract the true\nsteady state. We use a mean-field approach to map the dynamics of the unseen\npart of the network to a single node, which allows us to recover accurate\nestimates of steady-state on as few as 5 observed vertices in domains ranging\nfrom ecology to social networks to gene regulation. Incomplete networks are the\nnorm in practice, and we offer new ways to think about nonlinear dynamics when\nonly sparse information is available.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jan 2020 20:36:47 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Jiang", "Chunheng", ""], ["Gao", "Jianxi", ""], ["Magdon-Ismail", "Malik", ""]]}, {"id": "2001.06882", "submitter": "Wayes Tushar", "authors": "Wayes Tushar, Tapan K. Saha, Chau Yuen, David Smith, and H. Vincent\n  Poor", "title": "Peer-to-Peer Trading in Electricity Networks: An Overview", "comments": "15 pages, overview paper, accepted", "journal-ref": "IEEE Transactions on Smart Grid, 2020", "doi": null, "report-no": null, "categories": "cs.MA cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Peer-to-peer trading is a next-generation energy management technique that\neconomically benefits proactive consumers (prosumers) transacting their energy\nas goods and services. At the same time, peer-to-peer energy trading is also\nexpected to help the grid by reducing peak demand, lowering reserve\nrequirements, and curtailing network loss. However, large-scale deployment of\npeer-to-peer trading in electricity networks poses a number of challenges in\nmodeling transactions in both the virtual and physical layers of the network.\nAs such, this article provides a comprehensive review of the state-of-the-art\nin research on peer-to-peer energy trading techniques. By doing so, we provide\nan overview of the key features of peer-to-peer trading and its benefits of\nrelevance to the grid and prosumers. Then, we systematically classify the\nexisting research in terms of the challenges that the studies address in the\nvirtual and the physical layers. We then further identify and discuss those\ntechnical approaches that have been extensively used to address the challenges\nin peer-to-peer transactions. Finally, the paper is concluded with potential\nfuture research directions.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jan 2020 18:41:23 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Tushar", "Wayes", ""], ["Saha", "Tapan K.", ""], ["Yuen", "Chau", ""], ["Smith", "David", ""], ["Poor", "H. Vincent", ""]]}, {"id": "2001.07141", "submitter": "Bastien Maubert", "authors": "Bastien Maubert, Aniello Murano, Sophie Pinchinat, Fran\\c{c}ois\n  Schwarzentruber and Silvia Stranieri", "title": "Dynamic Epistemic Logic Games with Epistemic Temporal Goals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic Epistemic Logic (DEL) is a logical framework in which one can\ndescribe in great detail how actions are perceived by the agents, and how they\naffect the world. DEL games were recently introduced as a way to define classes\nof games with imperfect information where the actions available to the players\nare described very precisely. This framework makes it possible to define\neasily, for instance, classes of games where players can only use public\nactions or public announcements. These games have been studied for reachability\nobjectives, where the aim is to reach a situation satisfying some epistemic\nproperty expressed in epistemic logic; several (un)decidability results have\nbeen established. In this work we show that the decidability results obtained\nfor reachability objectives extend to a much more general class of winning\nconditions, namely those expressible in the epistemic temporal logic LTLK. To\ndo so we establish that the infinite game structures generated by DEL public\nactions are regular, and we describe how to obtain finite representations on\nwhich we rely to solve them.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 15:27:23 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Maubert", "Bastien", ""], ["Murano", "Aniello", ""], ["Pinchinat", "Sophie", ""], ["Schwarzentruber", "Fran\u00e7ois", ""], ["Stranieri", "Silvia", ""]]}, {"id": "2001.07145", "submitter": "Michael Crosscombe", "authors": "Jonathan Lawry, Michael Crosscombe, David Harvey", "title": "Distributed Possibilistic Learning in Multi-Agent Systems", "comments": "3rd International Symposium on Swarm Behavior and Bio-Inspired\n  Robotics (SWARM 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Possibility theory is proposed as an uncertainty representation framework for\ndistributed learning in multi-agent systems and robot swarms. In particular, we\ninvestigate its application to the best-of-n problem where the aim is for a\npopulation of agents to identify the highest quality out of n options through\nlocal interactions between individuals and limited direct feedback from the\nenvironment. In this context we claim that possibility theory provides\nefficient mechanisms by which an agent can learn about the state of the world,\nand which can allow them to handle inconsistencies between what they and others\nbelieve by varying the level of imprecision of their own beliefs. We introduce\na discrete time model of a population of agents applying possibility theory to\nthe best-of-n problem. Simulation experiments are then used to investigate the\naccuracy of possibility theory in this context as well as its robustness to\nnoise under varying amounts of direct evidence. Finally, we compare possibility\ntheory in this context with a similar probabilistic approach.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 15:31:05 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Lawry", "Jonathan", ""], ["Crosscombe", "Michael", ""], ["Harvey", "David", ""]]}, {"id": "2001.07527", "submitter": "Eugenio Bargiacchi", "authors": "Eugenio Bargiacchi, Timothy Verstraeten, Diederik M. Roijers, Ann\n  Now\\'e", "title": "Model-based Multi-Agent Reinforcement Learning with Cooperative\n  Prioritized Sweeping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new model-based reinforcement learning algorithm, Cooperative\nPrioritized Sweeping, for efficient learning in multi-agent Markov decision\nprocesses. The algorithm allows for sample-efficient learning on large problems\nby exploiting a factorization to approximate the value function. Our approach\nonly requires knowledge about the structure of the problem in the form of a\ndynamic decision network. Using this information, our method learns a model of\nthe environment and performs temporal difference updates which affect multiple\njoint states and actions at once. Batch updates are additionally performed\nwhich efficiently back-propagate knowledge throughout the factored Q-function.\nOur method outperforms the state-of-the-art algorithm sparse cooperative\nQ-learning algorithm, both on the well-known SysAdmin benchmark and randomized\nenvironments.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 19:13:44 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Bargiacchi", "Eugenio", ""], ["Verstraeten", "Timothy", ""], ["Roijers", "Diederik M.", ""], ["Now\u00e9", "Ann", ""]]}, {"id": "2001.07752", "submitter": "Luyao Yuan", "authors": "Luyao Yuan, Zipeng Fu, Jingyue Shen, Lu Xu, Junhong Shen, Song-Chun\n  Zhu", "title": "Emergence of Pragmatics from Referential Game between Theory of Mind\n  Agents", "comments": null, "journal-ref": "Emergent Communication Workshop, 33rd Conference on Neural\n  Information Processing Systems (NeurIPS 2019)", "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pragmatics studies how context can contribute to language meanings [1]. In\nhuman communication, language is never interpreted out of context, and\nsentences can usually convey more information than their literal meanings [2].\nHowever, this mechanism is missing in most multi-agent systems [3, 4, 5, 6],\nrestricting the communication efficiency and the capability of human-agent\ninteraction. In this paper, we propose an algorithm, using which agents can\nspontaneously learn the ability to \"read between lines\" without any explicit\nhand-designed rules. We integrate the theory of mind (ToM) [7, 8] in a\ncooperative multi-agent pedagogical situation and propose an adaptive\nreinforcement learning (RL) algorithm to develop a communication protocol. ToM\nis a profound cognitive science concept, claiming that people regularly reason\nabout other's mental states, including beliefs, goals, and intentions, to\nobtain performance advantage in competition, cooperation or coalition. With\nthis ability, agents consider language as not only messages but also rational\nacts reflecting others' hidden states. Our experiments demonstrate the\nadvantage of pragmatic protocols over non-pragmatic protocols. We also show the\nteaching complexity following the pragmatic protocol empirically approximates\nto recursive teaching dimension (RTD).\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 19:37:33 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Yuan", "Luyao", ""], ["Fu", "Zipeng", ""], ["Shen", "Jingyue", ""], ["Xu", "Lu", ""], ["Shen", "Junhong", ""], ["Zhu", "Song-Chun", ""]]}, {"id": "2001.07993", "submitter": "Rajiv Ranjan Kumar", "authors": "Rajiv Ranjan Kumar, Pradeep Varakantham", "title": "On Solving Cooperative MARL Problems with a Few Good Experiences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cooperative Multi-agent Reinforcement Learning (MARL) is crucial for\ncooperative decentralized decision learning in many domains such as search and\nrescue, drone surveillance, package delivery and fire fighting problems. In\nthese domains, a key challenge is learning with a few good experiences, i.e.,\npositive reinforcements are obtained only in a few situations (e.g., on\nextinguishing a fire or tracking a crime or delivering a package) and in most\nother situations there is zero or negative reinforcement. Learning decisions\nwith a few good experiences is extremely challenging in cooperative MARL\nproblems due to three reasons. First, compared to the single agent case,\nexploration is harder as multiple agents have to be coordinated to receive a\ngood experience. Second, environment is not stationary as all the agents are\nlearning at the same time (and hence change policies). Third, scale of problem\nincreases significantly with every additional agent.\n  Relevant existing work is extensive and has focussed on dealing with a few\ngood experiences in single-agent RL problems or on scalable approaches for\nhandling non-stationarity in MARL problems. Unfortunately, neither of these\napproaches (or their extensions) are able to address the problem of sparse good\nexperiences effectively. Therefore, we provide a novel fictitious self\nimitation approach that is able to simultaneously handle non-stationarity and\nsparse good experiences in a scalable manner. Finally, we provide a thorough\ncomparison (experimental or descriptive) against relevant cooperative MARL\nalgorithms to demonstrate the utility of our approach.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 12:53:53 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Kumar", "Rajiv Ranjan", ""], ["Varakantham", "Pradeep", ""]]}, {"id": "2001.08016", "submitter": "Shikha Singh", "authors": "Shikha Singh, Deepak Khemani", "title": "Subjective Knowledge and Reasoning about Agents in Multi-Agent Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Though a lot of work in multi-agent systems is focused on reasoning about\nknowledge and beliefs of artificial agents, an explicit representation and\nreasoning about the presence/absence of agents, especially in the scenarios\nwhere agents may be unaware of other agents joining in or going offline in a\nmulti-agent system, leading to partial knowledge/asymmetric knowledge of the\nagents is mostly overlooked by the MAS community. Such scenarios lay the\nfoundations of cases where an agent can influence other agents' mental states\nby (mis)informing them about the presence/absence of collaborators or\nadversaries. In this paper, we investigate how Kripke structure-based epistemic\nmodels can be extended to express the above notion based on an agent's\nsubjective knowledge and we discuss the challenges that come along.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 13:50:26 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Singh", "Shikha", ""], ["Khemani", "Deepak", ""]]}, {"id": "2001.08031", "submitter": "Edith Elkind", "authors": "Edith Elkind, Davide Grossi, Ehud Shapiro and Nimrod Talmon", "title": "United for Change: Deliberative Coalition Formation to Change the Status\n  Quo", "comments": "this version appeared in COMSOC'21 and is the most complete version\n  to date", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a setting in which a community wishes to identify a strongly\nsupported proposal from a large space of alternatives, in order to change the\nstatus quo. We describe a process -- called deliberation -- in which agents\ndynamically form coalitions around proposals they prefer over the status quo.\nWe formulate conditions (on the space of proposals and on the ways in which\ncoalitions are formed) that guarantee deliberation to succeed, that is, to\nterminate by identifying a majority-supported proposal with largest possible\nsupport, as long as such a proposal exists. Our results provide theoretical\nfoundations for the analysis of deliberative processes in systems for\ndemocratic deliberation support, such as, e.g., LiquidFeedback.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 14:27:43 GMT"}, {"version": "v2", "created": "Mon, 14 Sep 2020 23:06:44 GMT"}, {"version": "v3", "created": "Thu, 17 Sep 2020 08:44:16 GMT"}, {"version": "v4", "created": "Thu, 8 Jul 2021 11:07:54 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Elkind", "Edith", ""], ["Grossi", "Davide", ""], ["Shapiro", "Ehud", ""], ["Talmon", "Nimrod", ""]]}, {"id": "2001.08177", "submitter": "Roxana R\\u{a}dulescu", "authors": "Roxana R\\u{a}dulescu, Patrick Mannion, Yijie Zhang, Diederik M.\n  Roijers, and Ann Now\\'e", "title": "A utility-based analysis of equilibria in multi-objective normal form\n  games", "comments": "Under review since 16 January 2020", "journal-ref": null, "doi": "10.1017/S0269888920000351", "report-no": null, "categories": "cs.GT cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multi-objective multi-agent systems (MOMAS), agents explicitly consider\nthe possible tradeoffs between conflicting objective functions. We argue that\ncompromises between competing objectives in MOMAS should be analysed on the\nbasis of the utility that these compromises have for the users of a system,\nwhere an agent's utility function maps their payoff vectors to scalar utility\nvalues. This utility-based approach naturally leads to two different\noptimisation criteria for agents in a MOMAS: expected scalarised returns (ESR)\nand scalarised expected returns (SER). In this article, we explore the\ndifferences between these two criteria using the framework of multi-objective\nnormal form games (MONFGs). We demonstrate that the choice of optimisation\ncriterion (ESR or SER) can radically alter the set of equilibria in a MONFG\nwhen non-linear utility functions are used.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 22:27:38 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["R\u0103dulescu", "Roxana", ""], ["Mannion", "Patrick", ""], ["Zhang", "Yijie", ""], ["Roijers", "Diederik M.", ""], ["Now\u00e9", "Ann", ""]]}, {"id": "2001.08245", "submitter": "Theodor Cimpeanu", "authors": "Theodor Cimpeanu and The Anh Han", "title": "Making an Example: Signalling Threat in the Evolution of Cooperation", "comments": "8 pages, 4 figures, submitted to IEEE CEC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social punishment has been suggested as a key approach to ensuring high\nlevels of cooperation and norm compliance in one-shot (i.e. non-repeated)\ninteractions. However, it has been shown that it only works when punishment is\nhighly cost-efficient. On the other hand, signalling retribution hearkens back\nto medieval sovereignty, insofar as the very word for gallows in French stems\nfrom the Latin word for power and serves as a grim symbol of the ruthlessness\nof high justice. Here we introduce the mechanism of signalling an act of\npunishment and a special type of defector emerges, one who can recognise this\nsignal and avoid punishment by way of fear. We describe the analytical\nconditions under which threat signalling can maintain high levels of\ncooperation. Moreover, we perform extensive agent-based simulations so as to\nconfirm and expand our understanding of the external factors that influence the\nsuccess of social punishment. We show that our suggested mechanism catalyses\ncooperation, even when signalling is costly or when punishment would be\nimpractical. We observe the preventive nature of advertising retributive acts\nand we contend that the resulting social prosperity is a desirable outcome in\nthe contexts of AI and multi-agent systems. To conclude, we argue that fear\nacts as an effective stimulus to pro-social behaviour.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 19:42:56 GMT"}, {"version": "v2", "created": "Wed, 29 Jan 2020 11:29:34 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Cimpeanu", "Theodor", ""], ["Han", "The Anh", ""]]}, {"id": "2001.08284", "submitter": "Andre Vieira", "authors": "A. P. Vieira, E. Goles, H. J. Herrmann", "title": "Dynamics of extended Schelling models", "comments": null, "journal-ref": "Journal of Statistical Mechanics: Theory and Experiment (2020)\n  013212", "doi": "10.1088/1742-5468/ab5b8d", "report-no": null, "categories": "cond-mat.stat-mech cs.MA nlin.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore extensions of Schelling's model of social dynamics, in which two\ntypes of agents live on a checkerboard lattice and move in order to optimize\ntheir own satisfaction, which depends on how many agents among their neighbors\nare of their same type. For each number $n$ of same-type nearest neighbors we\nindependently assign a binary satisfaction variable $s_{k}$ which is equal to\none only if the agent is satisfied with that condition, and is equal to zero\notherwise. This defines 32 different satisfaction rules, which we investigate\nin detail, focusing on pattern formation and measuring segregation with the\nhelp of an \"energy\" function which is related to the number of neighboring\nagents of different types and plays no role in the dynamics. We consider the\ncheckerboard lattice to be fully occupied and the dynamics consists of\nswitching the locations of randomly selected unsatisfied agents of opposite\ntypes. We show that, starting from a random distribution of agents, only a\nsmall number of rules lead to (nearly) fully segregated patterns in the long\nrun, with many rules leading to chaotic steady-state behavior. Nevertheless,\nother interesting patterns may also be dynamically generated, such as\n\"anti-segregate d\" patterns as well as patterns resembling sponges.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 21:23:20 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Vieira", "A. P.", ""], ["Goles", "E.", ""], ["Herrmann", "H. J.", ""]]}, {"id": "2001.08335", "submitter": "Ryuta Arisaka", "authors": "Ryuta Arisaka and Takayuki Ito", "title": "Numerical Abstract Persuasion Argumentation for Expressing Concurrent\n  Multi-Agent Negotiations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A negotiation process by 2 agents e1 and e2 can be interleaved by another\nnegotiation process between, say, e1 and e3. The interleaving may alter the\nresource allocation assumed at the inception of the first negotiation process.\nExisting proposals for argumentation-based negotiations have focused primarily\non two-agent bilateral negotiations, but scarcely on the concurrency of\nmulti-agent negotiations. To fill the gap, we present a novel argumentation\ntheory, basing its development on abstract persuasion argumentation (which is\nan abstract argumentation formalism with a dynamic relation). Incorporating\ninto it numerical information and a mechanism of handshakes among members of\nthe dynamic relation, we show that the extended theory adapts well to\nconcurrent multi-agent negotiations over scarce resources.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 01:46:58 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Arisaka", "Ryuta", ""], ["Ito", "Takayuki", ""]]}, {"id": "2001.08525", "submitter": "Yehia Elrakaiby", "authors": "Yehia Elrakaiby and Paola Spoletini and Bashar Nuseibeh", "title": "Optimal by Design: Model-Driven Synthesis of Adaptation Strategies for\n  Autonomous Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many software systems have become too large and complex to be managed\nefficiently by human administrators, particularly when they operate in\nuncertain and dynamic environments and require frequent changes.\nRequirements-driven adaptation techniques have been proposed to endow systems\nwith the necessary means to autonomously decide ways to satisfy their\nrequirements. However, many current approaches rely on general-purpose\nlanguages, models and/or frameworks to design, develop and analyze autonomous\nsystems. Unfortunately, these tools are not tailored towards the\ncharacteristics of adaptation problems in autonomous systems. In this paper, we\npresent Optimal by Design (ObD ), a framework for model-based\nrequirements-driven synthesis of optimal adaptation strategies for autonomous\nsystems. ObD proposes a model (and a language) for the high-level description\nof the basic elements of self-adaptive systems, namely the system,\ncapabilities, requirements and environment. Based on those elements, a Markov\nDecision Process (MDP) is constructed to compute the optimal strategy or the\nmost rewarding system behaviour. Furthermore, this defines a reflex controller\nthat can ensure timely responses to changes. One novel feature of the framework\nis that it benefits both from goal-oriented techniques, developed for\nrequirement elicitation, refinement and analysis, and synthesis capabilities\nand extensive research around MDPs, their extensions and tools. Our preliminary\nevaluation results demonstrate the practicality and advantages of the\nframework.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 12:49:55 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Elrakaiby", "Yehia", ""], ["Spoletini", "Paola", ""], ["Nuseibeh", "Bashar", ""]]}, {"id": "2001.08996", "submitter": "Mengjing Chen", "authors": "Mengjing Chen, Yang Liu, Weiran Shen, Yiheng Shen, Pingzhong Tang,\n  Qiang Yang", "title": "Mechanism Design for Multi-Party Machine Learning", "comments": "22 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a multi-party machine learning system, different parties cooperate on\noptimizing towards better models by sharing data in a privacy-preserving way. A\nmajor challenge in learning is the incentive issue. For example, if there is\ncompetition among the parties, one may strategically hide his data to prevent\nother parties from getting better models.\n  In this paper, we study the problem through the lens of mechanism design and\nincorporate the features of multi-party learning in our setting. First, each\nagent's valuation has externalities that depend on others' types and actions.\nSecond, each agent can only misreport a type lower than his true type, but not\nthe other way round. We call this setting interdependent value with\ntype-dependent action spaces. We provide the optimal truthful mechanism in the\nquasi-monotone utility setting. We also provide necessary and sufficient\nconditions for truthful mechanisms in the most general case. Finally, we show\nthe existence of such mechanisms is highly affected by the market growth rate\nand provide empirical analysis.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 13:38:08 GMT"}, {"version": "v2", "created": "Fri, 19 Jun 2020 03:08:31 GMT"}, {"version": "v3", "created": "Sun, 9 Aug 2020 15:54:03 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Chen", "Mengjing", ""], ["Liu", "Yang", ""], ["Shen", "Weiran", ""], ["Shen", "Yiheng", ""], ["Tang", "Pingzhong", ""], ["Yang", "Qiang", ""]]}, {"id": "2001.09001", "submitter": "Priyabrata Saha", "authors": "Priyabrata Saha, Arslan Ali, Burhan A. Mudassar, Yun Long, and Saibal\n  Mukhopadhyay", "title": "MagNet: Discovering Multi-agent Interaction Dynamics using Neural\n  Network", "comments": "Accepted manuscript by ICRA 2020", "journal-ref": "ICRA 2020, pp. 8158-8164", "doi": "10.1109/ICRA40945.2020.9196846", "report-no": null, "categories": "cs.LG cs.MA cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the MagNet, a neural network-based multi-agent interaction model\nto discover the governing dynamics and predict evolution of a complex\nmulti-agent system from observations. We formulate a multi-agent system as a\ncoupled non-linear network with a generic ordinary differential equation (ODE)\nbased state evolution, and develop a neural network-based realization of its\ntime-discretized model. MagNet is trained to discover the core dynamics of a\nmulti-agent system from observations, and tuned on-line to learn agent-specific\nparameters of the dynamics to ensure accurate prediction even when physical or\nrelational attributes of agents, or number of agents change. We evaluate MagNet\non a point-mass system in two-dimensional space, Kuramoto phase synchronization\ndynamics and predator-swarm interaction dynamics demonstrating orders of\nmagnitude improvement in prediction accuracy over traditional deep learning\nmodels.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 13:41:01 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 21:17:45 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Saha", "Priyabrata", ""], ["Ali", "Arslan", ""], ["Mudassar", "Burhan A.", ""], ["Long", "Yun", ""], ["Mukhopadhyay", "Saibal", ""]]}, {"id": "2001.09063", "submitter": "Abhinav Gupta", "authors": "Agnieszka S{\\l}owik, Abhinav Gupta, William L. Hamilton, Mateja\n  Jamnik, Sean B. Holden", "title": "Towards Graph Representation Learning in Emergent Communication", "comments": "The first two authors contributed equally. Accepted at the\n  Reinforcement Learning in Games workshop at AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent findings in neuroscience suggest that the human brain represents\ninformation in a geometric structure (for instance, through conceptual spaces).\nIn order to communicate, we flatten the complex representation of entities and\ntheir attributes into a single word or a sentence. In this paper we use graph\nconvolutional networks to support the evolution of language and cooperation in\nmulti-agent systems. Motivated by an image-based referential game, we propose a\ngraph referential game with varying degrees of complexity, and we provide\nstrong baseline models that exhibit desirable properties in terms of language\nemergence and cooperation. We show that the emerged communication protocol is\nrobust, that the agents uncover the true factors of variation in the game, and\nthat they learn to generalize beyond the samples encountered during training.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 15:55:59 GMT"}, {"version": "v2", "created": "Tue, 4 Feb 2020 14:18:31 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["S\u0142owik", "Agnieszka", ""], ["Gupta", "Abhinav", ""], ["Hamilton", "William L.", ""], ["Jamnik", "Mateja", ""], ["Holden", "Sean B.", ""]]}, {"id": "2001.09066", "submitter": "Murat Cubuktepe", "authors": "Murat Cubuktepe, Zhe Xu, Ufuk Topcu", "title": "Policy Synthesis for Factored MDPs with Graph Temporal Logic\n  Specifications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.LO math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the synthesis of policies for multi-agent systems to implement\nspatial-temporal tasks. We formalize the problem as a factored Markov decision\nprocess subject to so-called graph temporal logic specifications. The\ntransition function and the spatial-temporal task of each agent depend on the\nagent itself and its neighboring agents. The structure in the model and the\nspecifications enable to develop a distributed algorithm that, given a factored\nMarkov decision process and a graph temporal logic formula, decomposes the\nsynthesis problem into a set of smaller synthesis problems, one for each agent.\nWe prove that the algorithm runs in time linear in the total number of agents.\nThe size of the synthesis problem for each agent is exponential only in the\nnumber of neighboring agents, which is typically much smaller than the number\nof agents. We demonstrate the algorithm in case studies on disease control and\nurban security. The numerical examples show that the algorithm can scale to\nhundreds of agents.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 16:03:34 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Cubuktepe", "Murat", ""], ["Xu", "Zhe", ""], ["Topcu", "Ufuk", ""]]}, {"id": "2001.09297", "submitter": "Mirmojtaba Gharibi", "authors": "Mirmojtaba Gharibi, Steven L. Waslander, Raouf Boutaba", "title": "Vehicle Scheduling Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define a new problem called the Vehicle Scheduling Problem (VSP). The goal\nis to minimize an objective function, such as the number of tardy vehicles over\na transportation network subject to maintaining safety distances, meeting hard\ndeadlines, and maintaining speeds on each link between the allowed minimums and\nmaximums. We prove VSP is an NP-hard problem for multiple objective functions\nthat are commonly used in the context of job shop scheduling. With the number\nof tardy vehicles as the objective function, we formulate VSP in terms of a\nMixed Integer Linear Programming (MIP) and design a heuristic algorithm. We\nanalyze the complexity of our algorithm and compare the quality of the\nsolutions to the optimal solution for the MIP formulation in the small cases.\nOur main motivation for defining VSP is the upcoming integration of Unmanned\nAerial Vehicles (UAVs) into the airspace for which this novel scheduling\nframework is of paramount importance.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jan 2020 11:45:25 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Gharibi", "Mirmojtaba", ""], ["Waslander", "Steven L.", ""], ["Boutaba", "Raouf", ""]]}, {"id": "2001.09318", "submitter": "Raphael Koster", "authors": "Raphael K\\\"oster, Dylan Hadfield-Menell, Gillian K. Hadfield, Joel Z.\n  Leibo", "title": "Silly rules improve the capacity of agents to learn stable enforcement\n  and compliance behaviors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How can societies learn to enforce and comply with social norms? Here we\ninvestigate the learning dynamics and emergence of compliance and enforcement\nof social norms in a foraging game, implemented in a multi-agent reinforcement\nlearning setting. In this spatiotemporally extended game, individuals are\nincentivized to implement complex berry-foraging policies and punish\ntransgressions against social taboos covering specific berry types. We show\nthat agents benefit when eating poisonous berries is taboo, meaning the\nbehavior is punished by other agents, as this helps overcome a\ncredit-assignment problem in discovering delayed health effects. Critically,\nhowever, we also show that introducing an additional taboo, which results in\npunishment for eating a harmless berry, improves the rate and stability with\nwhich agents learn to punish taboo violations and comply with taboos.\nCounterintuitively, our results show that an arbitrary taboo (a \"silly rule\")\ncan enhance social learning dynamics and achieve better outcomes in the middle\nstages of learning. We discuss the results in the context of studying\nnormativity as a group-level emergent phenomenon.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jan 2020 14:00:33 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["K\u00f6ster", "Raphael", ""], ["Hadfield-Menell", "Dylan", ""], ["Hadfield", "Gillian K.", ""], ["Leibo", "Joel Z.", ""]]}, {"id": "2001.10039", "submitter": "Jose Fontanari", "authors": "Davi A. Nobre and Jos\\'e F. Fontanari", "title": "Prediction diversity and selective attention in the wisdom of crowds", "comments": null, "journal-ref": "Complex Systems (2020) 29: 861-875", "doi": "10.25088/ComplexSystems.29.4.861", "report-no": null, "categories": "cs.IT cs.MA math.IT physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The wisdom of crowds is the idea that the combination of independent\nestimates of the magnitude of some quantity yields a remarkably accurate\nprediction, which is always more accurate than the average individual estimate.\nIn addition, it is largely believed that the accuracy of the crowd can be\nimproved by increasing the diversity of the estimates. Here we report the\nresults of three experiments to probe the current understanding of the wisdom\nof crowds, namely, the estimates of the number of candies in a jar, the length\nof a paper strip, and the number of pages of a book. We find that the\ncollective estimate is better than the majority of the individual estimates in\nall three experiments. In disagreement with the prediction diversity theorem,\nwe find no significant correlation between the prediction diversity and the\ncollective error. The poor accuracy of the crowd on some experiments lead us to\nconjecture that its alleged accuracy is most likely an artifice of selective\nattention.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 19:53:41 GMT"}, {"version": "v2", "created": "Sun, 14 Jun 2020 13:01:06 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Nobre", "Davi A.", ""], ["Fontanari", "Jos\u00e9 F.", ""]]}, {"id": "2001.10092", "submitter": "Silviu Pitis", "authors": "Silviu Pitis and Michael R. Zhang", "title": "Objective Social Choice: Using Auxiliary Information to Improve Voting\n  Outcomes", "comments": "10 pages, 3 figures. To appear in proceedings of AAMAS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.LG econ.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How should one combine noisy information from diverse sources to make an\ninference about an objective ground truth? This frequently recurring, normative\nquestion lies at the core of statistics, machine learning, policy-making, and\neveryday life. It has been called \"combining forecasts\", \"meta-analysis\",\n\"ensembling\", and the \"MLE approach to voting\", among other names. Past studies\ntypically assume that noisy votes are identically and independently distributed\n(i.i.d.), but this assumption is often unrealistic. Instead, we assume that\nvotes are independent but not necessarily identically distributed and that our\nensembling algorithm has access to certain auxiliary information related to the\nunderlying model governing the noise in each vote. In our present work, we: (1)\ndefine our problem and argue that it reflects common and socially relevant real\nworld scenarios, (2) propose a multi-arm bandit noise model and count-based\nauxiliary information set, (3) derive maximum likelihood aggregation rules for\nranked and cardinal votes under our noise model, (4) propose, alternatively, to\nlearn an aggregation rule using an order-invariant neural network, and (5)\nempirically compare our rules to common voting rules and naive\nexperience-weighted modifications. We find that our rules successfully use\nauxiliary information to outperform the naive baselines.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 21:21:19 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Pitis", "Silviu", ""], ["Zhang", "Michael R.", ""]]}, {"id": "2001.10122", "submitter": "Seyed Mohammad Asghari", "authors": "Seyed Mohammad Asghari, Yi Ouyang, and Ashutosh Nayyar", "title": "Regret Bounds for Decentralized Learning in Cooperative Multi-Agent\n  Dynamical Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regret analysis is challenging in Multi-Agent Reinforcement Learning (MARL)\nprimarily due to the dynamical environments and the decentralized information\namong agents. We attempt to solve this challenge in the context of\ndecentralized learning in multi-agent linear-quadratic (LQ) dynamical systems.\nWe begin with a simple setup consisting of two agents and two dynamically\ndecoupled stochastic linear systems, each system controlled by an agent. The\nsystems are coupled through a quadratic cost function. When both systems'\ndynamics are unknown and there is no communication among the agents, we show\nthat no learning policy can generate sub-linear in $T$ regret, where $T$ is the\ntime horizon. When only one system's dynamics are unknown and there is\none-directional communication from the agent controlling the unknown system to\nthe other agent, we propose a MARL algorithm based on the construction of an\nauxiliary single-agent LQ problem. The auxiliary single-agent problem in the\nproposed MARL algorithm serves as an implicit coordination mechanism among the\ntwo learning agents. This allows the agents to achieve a regret within\n$O(\\sqrt{T})$ of the regret of the auxiliary single-agent problem.\nConsequently, using existing results for single-agent LQ regret, our algorithm\nprovides a $\\tilde{O}(\\sqrt{T})$ regret bound. (Here $\\tilde{O}(\\cdot)$ hides\nconstants and logarithmic factors). Our numerical experiments indicate that\nthis bound is matched in practice. From the two-agent problem, we extend our\nresults to multi-agent LQ systems with certain communication patterns.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 23:37:41 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Asghari", "Seyed Mohammad", ""], ["Ouyang", "Yi", ""], ["Nayyar", "Ashutosh", ""]]}, {"id": "2001.10199", "submitter": "Yong Xiao", "authors": "Yong Xiao and Marwan Krunz", "title": "Distributed Optimization for Energy-efficient Fog Computing in the\n  Tactile Internet", "comments": null, "journal-ref": "Published at IEEE Journal on Selected Areas in Communications,\n  vol. 36, no. 11, pp. 2390 - 2400, November 2018", "doi": "10.1109/JSAC.2018.2872287", "report-no": null, "categories": "cs.NI cs.DC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tactile Internet is an emerging concept that focuses on supporting\nhigh-fidelity, ultra-responsive, and widely available human-to-machine\ninteractions. To reduce the transmission latency and alleviate Internet\ncongestion, fog computing has been advocated as an important component of the\nTactile Internet. In this paper, we focus on energy-efficient design of fog\ncomputing networks that support low-latency Tactile Internet applications. We\ninvestigate two performance metrics: Service response time of end-users and\npower usage efficiency of fog nodes. We quantify the fundamental tradeoff\nbetween these two metrics and then extend our analysis to fog computing\nnetworks involving cooperation between fog nodes. We introduce a novel\ncooperative fog computing concept, referred to as offload forwarding, in which\na set of fog nodes with different computing and energy resources can cooperate\nwith each other. The objective of this cooperation is to balance the workload\nprocessed by different fog nodes, further reduce the service response time, and\nimprove the efficiency of power usage. We develop a distributed optimization\nframework based on dual decomposition to achieve the optimal tradeoff. Our\nframework does not require fog nodes to disclose their private information nor\nconduct back-and-forth negotiations with each other. Two distributed\noptimization algorithms are proposed. One is based on the subgradient method\nwith dual decomposition and the other is based on distributed ADMM-VS. We prove\nthat both algorithms can achieve the optimal workload allocation that minimizes\nthe response time under the given power efficiency constraints of fog nodes.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 07:44:10 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Xiao", "Yong", ""], ["Krunz", "Marwan", ""]]}, {"id": "2001.10208", "submitter": "Yichuan Charlie Tang", "authors": "Yichuan Charlie Tang", "title": "Towards Learning Multi-agent Negotiations via Self-Play", "comments": "Autonomous Driving Workshop, IEEE International Conference on\n  Computer Vision (ICCV 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Making sophisticated, robust, and safe sequential decisions is at the heart\nof intelligent systems. This is especially critical for planning in complex\nmulti-agent environments, where agents need to anticipate other agents'\nintentions and possible future actions. Traditional methods formulate the\nproblem as a Markov Decision Process, but the solutions often rely on various\nassumptions and become brittle when presented with corner cases. In contrast,\ndeep reinforcement learning (Deep RL) has been very effective at finding\npolicies by simultaneously exploring, interacting, and learning from\nenvironments. Leveraging the powerful Deep RL paradigm, we demonstrate that an\niterative procedure of self-play can create progressively more diverse\nenvironments, leading to the learning of sophisticated and robust multi-agent\npolicies. We demonstrate this in a challenging multi-agent simulation of\nmerging traffic, where agents must interact and negotiate with others in order\nto successfully merge on or off the road. While the environment starts off\nsimple, we increase its complexity by iteratively adding an increasingly\ndiverse set of agents to the agent \"zoo\" as training progresses. Qualitatively,\nwe find that through self-play, our policies automatically learn interesting\nbehaviors such as defensive driving, overtaking, yielding, and the use of\nsignal lights to communicate intentions to other agents. In addition,\nquantitatively, we show a dramatic improvement of the success rate of merging\nmaneuvers from 63% to over 98%.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 08:37:33 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Tang", "Yichuan Charlie", ""]]}, {"id": "2001.10330", "submitter": "Nikolai Bode", "authors": "Nikolai Bode", "title": "Parameter Calibration in Crowd Simulation Models using Approximate\n  Bayesian Computation", "comments": "8 pages, 4 figures; preprint submitted to Proceedings of Pedestrian\n  and Evacuation Dynamics conference, August 21-24 2018, Lund, Sweden", "journal-ref": "Collective Dynamics, 5, 1-8 (2020)", "doi": "10.17815/CD.2020.68", "report-no": null, "categories": "cs.MA stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simulation models for pedestrian crowds are a ubiquitous tool in research and\nindustry. It is crucial that the parameters of these models are calibrated\ncarefully and ultimately it will be of interest to compare competing models to\ndecide which model is best suited for a particular purpose. In this\ncontribution, I demonstrate how Approximate Bayesian Computation (ABC), which\nis already a popular tool in other areas of science, can be used for model\nfitting and model selection in a pedestrian dynamics context. I fit two\ndifferent models for pedestrian dynamics to data on a crowd passing in one\ndirection through a bottleneck. One model describes movement in\ncontinuous-space, the other model is a cellular automaton and thus describes\nmovement in discrete-space. In addition, I compare models to data using two\nmetrics. The first is based on egress times and the second on the velocity of\npedestrians in front of the bottleneck. My results show that while model\nfitting is successful, a substantial degree of uncertainty about the value of\nsome model parameters remains after model fitting. Importantly, the choice of\nmetric in model fitting can influence parameter estimates. Model selection is\ninconclusive for the egress time metric but supports the continuous-space model\nfor the velocity-based metric. These findings show that ABC is a flexible\napproach and highlight the difficulties associated with model fitting and model\nselection for pedestrian dynamics. ABC requires many simulation runs and\nchoosing appropriate metrics for comparing data to simulations requires careful\nattention. Despite this, I suggest ABC is a promising tool, because it is\nversatile and easily implemented for the growing number of openly available\ncrowd simulators and data sets.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 14:08:53 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Bode", "Nikolai", ""]]}, {"id": "2001.10640", "submitter": "Jie Zhang", "authors": "Zihe Wang and Zhide Wei and Jie Zhang", "title": "Bounded Incentives in Manipulating the Probabilistic Serial Rule", "comments": "To appear in AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Probabilistic Serial mechanism is well-known for its desirable fairness\nand efficiency properties. It is one of the most prominent protocols for the\nrandom assignment problem. However, Probabilistic Serial is not\nincentive-compatible, thereby these desirable properties only hold for the\nagents' declared preferences, rather than their genuine preferences. A\nsubstantial utility gain through strategic behaviors would trigger\nself-interested agents to manipulate the mechanism and would subvert the very\nfoundation of adopting the mechanism in practice. In this paper, we\ncharacterize the extent to which an individual agent can increase its utility\nby strategic manipulation. We show that the incentive ratio of the mechanism is\n$\\frac{3}{2}$. That is, no agent can misreport its preferences such that its\nutility becomes more than 1.5 times of what it is when reports truthfully. This\nratio is a worst-case guarantee by allowing an agent to have complete\ninformation about other agents' reports and to figure out the best response\nstrategy even if it is computationally intractable in general. To complement\nthis worst-case study, we further evaluate an agent's utility gain on average\nby experiments. The experiments show that an agent' incentive in manipulating\nthe rule is very limited. These results shed some light on the robustness of\nProbabilistic Serial against strategic manipulation, which is one step further\nthan knowing that it is not incentive-compatible.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 23:53:37 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Wang", "Zihe", ""], ["Wei", "Zhide", ""], ["Zhang", "Jie", ""]]}, {"id": "2001.11165", "submitter": "Sam Ganzfried", "authors": "Sam Ganzfried", "title": "Fictitious Play Outperforms Counterfactual Regret Minimization", "comments": "Fixed a bug in the 5-player CFR implementation from prior version and\n  reran the 5-player experiments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.MA econ.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We compare the performance of two popular algorithms, fictitious play and\ncounterfactual regret minimization, in approximating Nash equilibrium in\nmultiplayer games. Despite recent success of counterfactual regret minimization\nin multiplayer poker and conjectures of its superiority, we show that\nfictitious play leads to improved Nash equilibrium approximation over a variety\nof game classes and sizes.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 03:47:09 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 18:55:50 GMT"}, {"version": "v3", "created": "Wed, 8 Apr 2020 00:06:01 GMT"}, {"version": "v4", "created": "Mon, 18 May 2020 22:01:27 GMT"}, {"version": "v5", "created": "Thu, 23 Jul 2020 19:02:20 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Ganzfried", "Sam", ""]]}, {"id": "2001.11710", "submitter": "Mohitvishnu S. Gadde", "authors": "Nishant Mohanty, Mohitvishnu S. Gadde, Suresh Sundaram, Narasimhan\n  Sundararajan, P. B. Sujit", "title": "Context-Aware Deep Q-Network for Decentralized Cooperative\n  Reconnaissance by a Robotic Swarm", "comments": "\"For associated video file, refer to http://bit.ly/cadqnvideo\"", "journal-ref": null, "doi": null, "report-no": "T-ASE-2020-1171", "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the crucial problems in robotic swarm-based operation is to search and\nneutralize heterogeneous targets in an unknown and uncertain environment,\nwithout any communication within the swarm. Here, some targets can be\nneutralized by a single robot, while others need multiple robots in a\nparticular sequence to neutralize them. The complexity in the problem arises\ndue to the scalability and information uncertainty, which restricts the robot's\nawareness of the swarm and the target distribution. In this paper, this problem\nis addressed by proposing a novel Context-Aware Deep Q-Network (CA-DQN)\nframework to obtain communication free cooperation between the robots in the\nswarm. Each robot maintains an adaptive grid representation of the vicinity\nwith the context information embedded into it to keep the swarm intact while\nsearching and neutralizing the targets. The problem formulation uses a\nreinforcement learning framework where two Deep Q-Networks (DQNs) handle\n'conflict' and 'conflict-free' scenarios separately. The self-play-in-based\napproach is used to determine the optimal policy for the DQNs. Monte-Carlo\nsimulations and comparison studies with a state-of-the-art coalition formation\nalgorithm are performed to verify the performance of CA-DQN with varying\nenvironmental parameters. The results show that the approach is invariant to\nthe number of detected targets and the number of robots in the swarm. The paper\nalso presents the real-time implementation of CA-DQN for different scenarios\nusing ground robots in a laboratory environment to demonstrate the working of\nCA-DQN with low-power computing devices.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 08:50:22 GMT"}, {"version": "v2", "created": "Fri, 13 Nov 2020 04:38:34 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Mohanty", "Nishant", ""], ["Gadde", "Mohitvishnu S.", ""], ["Sundaram", "Suresh", ""], ["Sundararajan", "Narasimhan", ""], ["Sujit", "P. B.", ""]]}, {"id": "2001.11785", "submitter": "Pallavi Bagga", "authors": "Pallavi Bagga, Nicola Paoletti, Bedour Alrayes, Kostas Stathis", "title": "A Deep Reinforcement Learning Approach to Concurrent Bilateral\n  Negotiation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel negotiation model that allows an agent to learn how to\nnegotiate during concurrent bilateral negotiations in unknown and dynamic\ne-markets. The agent uses an actor-critic architecture with model-free\nreinforcement learning to learn a strategy expressed as a deep neural network.\nWe pre-train the strategy by supervision from synthetic market data, thereby\ndecreasing the exploration time required for learning during negotiation. As a\nresult, we can build automated agents for concurrent negotiations that can\nadapt to different e-market settings without the need to be pre-programmed. Our\nexperimental evaluation shows that our deep reinforcement learning-based agents\noutperform two existing well-known negotiation strategies in one-to-many\nconcurrent bilateral negotiations for a range of e-market settings.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 12:05:46 GMT"}, {"version": "v2", "created": "Mon, 3 Feb 2020 13:42:44 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Bagga", "Pallavi", ""], ["Paoletti", "Nicola", ""], ["Alrayes", "Bedour", ""], ["Stathis", "Kostas", ""]]}, {"id": "2001.11989", "submitter": "Juste Raimbault", "authors": "Juste Raimbault", "title": "Hierarchy and co-evolution processes in urban systems", "comments": "16 pages, 4 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The concept of hierarchy in complex systems is tightly linked to\nco-evolutionary processes. We propose here to explore it in the case of the\nco-evolution between transportation networks and territories. More precisely,\nwe extend a co-evolution model for systems of cities and infrastructure\nnetworks, and systematically study its behavior following specific hierarchy\nindicators we introduce. We show that population hierarchy and network\nhierarchy are tightly linked, but that a broad range of regimes can exist.\nModel exploration furthermore yields non-trivial stylized facts which can be\ntaken into account for territorial planning on such long time scales with\nco-evolutionary processes.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 18:23:55 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Raimbault", "Juste", ""]]}, {"id": "2001.12004", "submitter": "Joseph Suarez", "authors": "Joseph Suarez, Yilun Du, Igor Mordatch, Phillip Isola", "title": "Neural MMO v1.3: A Massively Multiagent Game Environment for Training\n  and Evaluating Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Progress in multiagent intelligence research is fundamentally limited by the\nnumber and quality of environments available for study. In recent years,\nsimulated games have become a dominant research platform within reinforcement\nlearning, in part due to their accessibility and interpretability. Previous\nworks have targeted and demonstrated success on arcade, first person shooter\n(FPS), real-time strategy (RTS), and massive online battle arena (MOBA) games.\nOur work considers massively multiplayer online role-playing games (MMORPGs or\nMMOs), which capture several complexities of real-world learning that are not\nwell modeled by any other game genre. We present Neural MMO, a massively\nmultiagent game environment inspired by MMOs and discuss our progress on two\nmore general challenges in multiagent systems engineering for AI research:\ndistributed infrastructure and game IO. We further demonstrate that standard\npolicy gradient methods and simple baseline models can learn interesting\nemergent exploration and specialization behaviors in this setting.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 18:50:02 GMT"}, {"version": "v2", "created": "Fri, 17 Apr 2020 01:58:32 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Suarez", "Joseph", ""], ["Du", "Yilun", ""], ["Mordatch", "Igor", ""], ["Isola", "Phillip", ""]]}]