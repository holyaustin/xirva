[{"id": "2106.00083", "submitter": "Daniel Engel", "authors": "Daniel Engel, Maurice Herlihy", "title": "Composing Networks of Automated Market Makers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Automated market makers (AMMs) are automata that trade electronic assets at\nrates set by mathematical formulas. AMMs are usually implemented by smart\ncontracts on blockchains. In practice, AMMs are often composed: and outputs\nfrom AMMs can be directed into other compatible AMMs. This paper proposes a\nmathematical model for AMM composition. We define sequential and parallel\ncomposition operators for AMMs in a way that ensures that AMMs are closed under\ncomposition, in a way that works for \"higher-dimensional\" AMMs that manage more\nthan two asset classes, and so the composition of AMMs in \"stable\" states\nremains stable.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 20:09:26 GMT"}, {"version": "v2", "created": "Wed, 16 Jun 2021 17:53:07 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Engel", "Daniel", ""], ["Herlihy", "Maurice", ""]]}, {"id": "2106.00198", "submitter": "Runyu Zhang Ms.", "authors": "Runyu Zhang, Zhaolin Ren, Na Li", "title": "Gradient Play in Multi-Agent Markov Stochastic Games: Stationary Points\n  and Convergence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT cs.MA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the performance of the gradient play algorithm for multi-agent\ntabular Markov decision processes (MDPs), which are also known as stochastic\ngames (SGs), where each agent tries to maximize its own total discounted reward\nby making decisions independently based on current state information which is\nshared between agents. Policies are directly parameterized by the probability\nof choosing a certain action at a given state. We show that Nash equilibria\n(NEs) and first order stationary policies are equivalent in this setting, and\ngive a non-asymptotic global convergence rate analysis to an $\\epsilon$-NE for\na subclass of multi-agent MDPs called Markov potential games, which includes\nthe cooperative setting with identical rewards among agents as an important\nspecial case. Our result shows that the number of iterations to reach an\n$\\epsilon$-NE scales linearly, instead of exponentially, with the number of\nagents. Local geometry and local stability are also considered. For Markov\npotential games, we prove that strict NEs are local maxima of the total\npotential function and fully-mixed NEs are saddle points. We also give a local\nconvergence rate around strict NEs for more general settings.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 03:03:45 GMT"}, {"version": "v2", "created": "Thu, 17 Jun 2021 19:26:45 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Zhang", "Runyu", ""], ["Ren", "Zhaolin", ""], ["Li", "Na", ""]]}, {"id": "2106.00199", "submitter": "Andr\\'e C. R. Martins", "authors": "Andre C. R. Martins", "title": "Agent mental models and Bayesian rules as a tool to create opinion\n  dynamics models", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.MA nlin.AO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Traditional opinion dynamics models are simple and yet, enough to explore the\nconsequences in basic scenarios. But, to better describe problems such as\npolarization and extremism, we might need to include details about human biases\nand other cognitive characteristics. In this paper, I explain how we can\ndescribe and use mental models and assumptions of the agents using\nBayesian-inspired model building. The relationship between human rationality\nand Bayesian methods will be explored, and we will see that Bayesian ideas can\nindeed be used to explain how humans reason. We will see how to use\nBayesian-inspired rules using the simplest version of the Continuous Opinions\nand Discrete Actions (CODA) model. From that, we will explore how we can obtain\nupdate rules that include human behavioral characteristics such as confirmation\nbias, motivated reasoning, or our tendency to change opinions much less than we\nshould.\n  Keywords: Opinion dynamics, Bayesian methods, Cognition, CODA, Agent-based\nmodels\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 03:10:31 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Martins", "Andre C. R.", ""]]}, {"id": "2106.00285", "submitter": "Jiahui Li", "authors": "Jiahui Li, Kun Kuang, Baoxiang Wang, Furui Liu, Long Chen, Fei Wu and\n  Jun Xiao", "title": "Shapley Counterfactual Credits for Multi-Agent Reinforcement Learning", "comments": null, "journal-ref": null, "doi": "10.1145/3447548.3467420", "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Centralized Training with Decentralized Execution (CTDE) has been a popular\nparadigm in cooperative Multi-Agent Reinforcement Learning (MARL) settings and\nis widely used in many real applications. One of the major challenges in the\ntraining process is credit assignment, which aims to deduce the contributions\nof each agent according to the global rewards. Existing credit assignment\nmethods focus on either decomposing the joint value function into individual\nvalue functions or measuring the impact of local observations and actions on\nthe global value function. These approaches lack a thorough consideration of\nthe complicated interactions among multiple agents, leading to an unsuitable\nassignment of credit and subsequently mediocre results on MARL. We propose\nShapley Counterfactual Credit Assignment, a novel method for explicit credit\nassignment which accounts for the coalition of agents. Specifically, Shapley\nValue and its desired properties are leveraged in deep MARL to credit any\ncombinations of agents, which grants us the capability to estimate the\nindividual credit for each agent. Despite this capability, the main technical\ndifficulty lies in the computational complexity of Shapley Value who grows\nfactorially as the number of agents. We instead utilize an approximation method\nvia Monte Carlo sampling, which reduces the sample complexity while maintaining\nits effectiveness. We evaluate our method on StarCraft II benchmarks across\ndifferent scenarios. Our method outperforms existing cooperative MARL\nalgorithms significantly and achieves the state-of-the-art, with especially\nlarge margins on tasks with more severe difficulties.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 07:38:34 GMT"}, {"version": "v2", "created": "Tue, 22 Jun 2021 04:49:11 GMT"}, {"version": "v3", "created": "Thu, 22 Jul 2021 15:01:22 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Li", "Jiahui", ""], ["Kuang", "Kun", ""], ["Wang", "Baoxiang", ""], ["Liu", "Furui", ""], ["Chen", "Long", ""], ["Wu", "Fei", ""], ["Xiao", "Jun", ""]]}, {"id": "2106.00379", "submitter": "Luca Capezzuto", "authors": "Luca Capezzuto, Danesh Tarapore, and Sarvapali D. Ramchurn", "title": "Large-scale, Dynamic and Distributed Coalition Formation with Spatial\n  and Temporal Constraints", "comments": "18 pages, 3 figures, accepted at EUMAS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The Coalition Formation with Spatial and Temporal constraints Problem (CFSTP)\nis a multi-agent task allocation problem in which few agents have to perform\nmany tasks, each with its deadline and workload. To maximize the number of\ncompleted tasks, the agents need to cooperate by forming, disbanding and\nreforming coalitions. The original mathematical programming formulation of the\nCFSTP is difficult to implement, since it is lengthy and based on the\nproblematic Big-M method. In this paper, we propose a compact and\neasy-to-implement formulation. Moreover, we design D-CTS, a distributed version\nof the state-of-the-art CFSTP algorithm. Using public London Fire Brigade\nrecords, we create a dataset with $347588$ tasks and a test framework that\nsimulates the mobilization of firefighters in dynamic environments. In problems\nwith up to $150$ agents and $3000$ tasks, compared to DSA-SDP, a\nstate-of-the-art distributed algorithm, D-CTS completes $3.79\\% \\pm [42.22\\%,\n1.96\\%]$ more tasks, and is one order of magnitude more efficient in terms of\ncommunication overhead and time complexity. D-CTS sets the first large-scale,\ndynamic and distributed CFSTP benchmark.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 10:41:49 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Capezzuto", "Luca", ""], ["Tarapore", "Danesh", ""], ["Ramchurn", "Sarvapali D.", ""]]}, {"id": "2106.00655", "submitter": "Michael Crosscombe", "authors": "Michael Crosscombe and Jonathan Lawry", "title": "The Impact of Network Connectivity on Collective Learning", "comments": "13 pages, 5 figures. To appear at the 15th International Symposium on\n  Distributed Autonomous Robotic Systems 2021. Presented at the joint\n  DARS-SWARM 2021 symposium held (virtually) in Kyoto, Japan", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In decentralised autonomous systems it is the interactions between individual\nagents which govern the collective behaviours of the system. These local-level\ninteractions are themselves often governed by an underlying network structure.\nThese networks are particularly important for collective learning and\ndecision-making whereby agents must gather evidence from their environment and\npropagate this information to other agents in the system. Models for collective\nbehaviours may often rely upon the assumption of total connectivity between\nagents to provide effective information sharing within the system, but this\nassumption may be ill-advised. In this paper we investigate the impact that the\nunderlying network has on performance in the context of collective learning.\nThrough simulations we study small-world networks with varying levels of\nconnectivity and randomness and conclude that totally-connected networks result\nin higher average error when compared to networks with less connectivity.\nFurthermore, we show that networks of high regularity outperform networks with\nincreasing levels of random connectivity.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 17:39:26 GMT"}, {"version": "v2", "created": "Fri, 18 Jun 2021 14:10:45 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Crosscombe", "Michael", ""], ["Lawry", "Jonathan", ""]]}, {"id": "2106.00845", "submitter": "Babatunji Omoniwa", "authors": "Babatunji Omoniwa, Boris Galkin, Ivana Dusparic", "title": "Energy-aware placement optimization of UAV base stations via\n  decentralized multi-agent Q-learning", "comments": "Submitted to IEEE Globecom SAC 2021, Spain", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unmanned aerial vehicles serving as aerial base stations (UAV-BSs) can be\ndeployed to provide wireless connectivity to ground devices in events of\nincreased network demand, points-of-failure in existing infrastructure, or\ndisasters. However, it is challenging to conserve the energy of UAVs during\nprolonged coverage tasks, considering their limited on-board battery capacity.\nReinforcement learning-based (RL) approaches have been previously used to\nimprove energy utilization of multiple UAVs, however, a central cloud\ncontroller is assumed to have complete knowledge of the end-devices' locations,\ni.e., the controller periodically scans and sends updates for UAV\ndecision-making. This assumption is impractical in dynamic network environments\nwith mobile ground devices. To address this problem, we propose a decentralized\nQ-learning approach, where each UAV-BS is equipped with an autonomous agent\nthat maximizes the connectivity to ground devices while improving its energy\nutilization. Experimental results show that the proposed design significantly\noutperforms the centralized approaches in jointly maximizing the number of\nconnected ground devices and the energy utilization of the UAV-BSs.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 22:49:42 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Omoniwa", "Babatunji", ""], ["Galkin", "Boris", ""], ["Dusparic", "Ivana", ""]]}, {"id": "2106.00897", "submitter": "Wanqi Xue", "authors": "Wanqi Xue, Youzhi Zhang, Shuxin Li, Xinrun Wang, Bo An, Chai Kiat Yeo", "title": "Solving Large-Scale Extensive-Form Network Security Games via Neural\n  Fictitious Self-Play", "comments": "Published as a conference paper in IJCAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Securing networked infrastructures is important in the real world. The\nproblem of deploying security resources to protect against an attacker in\nnetworked domains can be modeled as Network Security Games (NSGs).\nUnfortunately, existing approaches, including the deep learning-based\napproaches, are inefficient to solve large-scale extensive-form NSGs. In this\npaper, we propose a novel learning paradigm, NSG-NFSP, to solve large-scale\nextensive-form NSGs based on Neural Fictitious Self-Play (NFSP). Our main\ncontributions include: i) reforming the best response (BR) policy network in\nNFSP to be a mapping from action-state pair to action-value, to make the\ncalculation of BR possible in NSGs; ii) converting the average policy network\nof an NFSP agent into a metric-based classifier, helping the agent to assign\ndistributions only on legal actions rather than all actions; iii) enabling NFSP\nwith high-level actions, which can benefit training efficiency and stability in\nNSGs; and iv) leveraging information contained in graphs of NSGs by learning\nefficient graph node embeddings. Our algorithm significantly outperforms\nstate-of-the-art algorithms in both scalability and solution quality.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 02:22:52 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Xue", "Wanqi", ""], ["Zhang", "Youzhi", ""], ["Li", "Shuxin", ""], ["Wang", "Xinrun", ""], ["An", "Bo", ""], ["Yeo", "Chai Kiat", ""]]}, {"id": "2106.01031", "submitter": "Yushan Li", "authors": "Yushan Li, Jianping He, Cailian Chen and Xinping Guan", "title": "On Topology Inference for Networked Dynamical Systems: Principles and\n  Performances", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topology inference for networked dynamical systems (NDSs) plays a crucial\nrole in many areas. Knowledge of the system topology can aid in detecting\nanomalies, spotting trends, predicting future behavior and so on. Different\nfrom the majority of pioneering works, this paper investigates the principles\nand performances of topology inference from the perspective of node causality\nand correlation. Specifically, we advocate a comprehensive analysis framework\nto unveil the mutual relationship, convergence and accuracy of the proposed\nmethods and other benchmark methods, i.e., the Granger and ordinary least\nsquare (OLS) estimators. Our method allows for unknown observation noises, both\nasymptotic and marginal stabilities for NDSs, while encompasses a\ncorrelation-based modification design to alleviate performance degradation in\nsmall observation scale. To explicitly demonstrate the inference performance of\nthe estimators, we leverage the concentration measure in Gaussian space, and\nderive the non-asymptotic rates of the inference errors for linear\ntime-invariant (LTI) cases. Considering when the observations are not\nsufficient to support the estimators, we provide an excitation-based method to\ninfer the one-hop and multi-hop neighbors with probability guarantees.\nFurthermore, we point out the theoretical results can be extended to switching\ntopologies and nonlinear dynamics cases. Extensive simulations highlight the\noutperformance of the proposed method.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 08:54:59 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Li", "Yushan", ""], ["He", "Jianping", ""], ["Chen", "Cailian", ""], ["Guan", "Xinping", ""]]}, {"id": "2106.01086", "submitter": "Junyoung Park", "authors": "Junyoung Park, Jaehyeong Chun, Sang Hun Kim, Youngkook Kim, Jinkyoo\n  Park", "title": "Learning to schedule job-shop problems: Representation and policy\n  learning using graph neural network and reinforcement learning", "comments": "16 pages, 8 figures", "journal-ref": "International Journal of Production Research International Journal\n  of Production Research, Volume 59, 2021 - Issue 11, Pages 3360-3377", "doi": "10.1080/00207543.2020.1870013", "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a framework to learn to schedule a job-shop problem (JSSP) using a\ngraph neural network (GNN) and reinforcement learning (RL). We formulate the\nscheduling process of JSSP as a sequential decision-making problem with graph\nrepresentation of the state to consider the structure of JSSP. In solving the\nformulated problem, the proposed framework employs a GNN to learn that node\nfeatures that embed the spatial structure of the JSSP represented as a graph\n(representation learning) and derive the optimum scheduling policy that maps\nthe embedded node features to the best scheduling action (policy learning). We\nemploy Proximal Policy Optimization (PPO) based RL strategy to train these two\nmodules in an end-to-end fashion. We empirically demonstrate that the GNN\nscheduler, due to its superb generalization capability, outperforms practically\nfavored dispatching rules and RL-based schedulers on various benchmark JSSP. We\nalso confirmed that the proposed framework learns a transferable scheduling\npolicy that can be employed to schedule a completely new JSSP (in terms of size\nand parameters) without further training.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 11:40:22 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Park", "Junyoung", ""], ["Chun", "Jaehyeong", ""], ["Kim", "Sang Hun", ""], ["Kim", "Youngkook", ""], ["Park", "Jinkyoo", ""]]}, {"id": "2106.01254", "submitter": "Tim Weninger PhD", "authors": "Paul Resnick, Yuqing Kong, Grant Schoenebeck, Tim Weninger", "title": "Survey Equivalence: A Procedure for Measuring Classifier Accuracy\n  Against Human Labels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In many classification tasks, the ground truth is either noisy or subjective.\nExamples include: which of two alternative paper titles is better? is this\ncomment toxic? what is the political leaning of this news article? We refer to\nsuch tasks as survey settings because the ground truth is defined through a\nsurvey of one or more human raters. In survey settings, conventional\nmeasurements of classifier accuracy such as precision, recall, and\ncross-entropy confound the quality of the classifier with the level of\nagreement among human raters. Thus, they have no meaningful interpretation on\ntheir own. We describe a procedure that, given a dataset with predictions from\na classifier and K ratings per item, rescales any accuracy measure into one\nthat has an intuitive interpretation. The key insight is to score the\nclassifier not against the best proxy for the ground truth, such as a majority\nvote of the raters, but against a single human rater at a time. That score can\nbe compared to other predictors' scores, in particular predictors created by\ncombining labels from several other human raters. The survey equivalence of any\nclassifier is the minimum number of raters needed to produce the same expected\nscore as that found for the classifier.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 16:07:32 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Resnick", "Paul", ""], ["Kong", "Yuqing", ""], ["Schoenebeck", "Grant", ""], ["Weninger", "Tim", ""]]}, {"id": "2106.01895", "submitter": "Abhinav Sinha", "authors": "Abhinav Sinha, Shashi Ranjan Kumar, Dwaipayan Mukherjee", "title": "Three-agent Time-constrained Cooperative Pursuit-Evasion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.MA cs.RO cs.SY math.OC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper considers a pursuit-evasion scenario among three agents -- an\nevader, a pursuer, and a defender. We design cooperative guidance laws for the\nevader and the defender team to safeguard the evader from an attacking pursuer.\nUnlike differential games, optimal control formulations, and other heuristic\nmethods, we propose a novel perspective on designing effective nonlinear\nfeedback control laws for the evader-defender team using a time-constrained\nguidance approach. The evader lures the pursuer on the collision course by\noffering itself as bait. At the same time, the defender protects the evader\nfrom the pursuer by exercising control over the engagement duration. Depending\non the nature of the mission, the defender may choose to take an aggressive or\ndefensive stance. Such consideration widens the applicability of the proposed\nmethods in various three-agent motion planning scenarios such as aircraft\ndefense, asset guarding, search and rescue, surveillance, and secure\ntransportation. We use a fixed-time sliding mode control strategy to design the\ncontrol laws for the evader-defender team and a nonlinear finite-time\ndisturbance observer to estimate the pursuer's maneuver. Finally, we present\nsimulations to demonstrate favorable performance under various engagement\ngeometries, thus vindicating the efficacy of the proposed designs.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 14:38:37 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Sinha", "Abhinav", ""], ["Kumar", "Shashi Ranjan", ""], ["Mukherjee", "Dwaipayan", ""]]}, {"id": "2106.01901", "submitter": "Max Smith", "authors": "Max Olan Smith, Thomas Anthony, Michael P. Wellman", "title": "Iterative Empirical Game Solving via Single Policy Best Response", "comments": null, "journal-ref": "ICLR 2021", "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy-Space Response Oracles (PSRO) is a general algorithmic framework for\nlearning policies in multiagent systems by interleaving empirical game analysis\nwith deep reinforcement learning (Deep RL). At each iteration, Deep RL is\ninvoked to train a best response to a mixture of opponent policies. The\nrepeated application of Deep RL poses an expensive computational burden as we\nlook to apply this algorithm to more complex domains. We introduce two\nvariations of PSRO designed to reduce the amount of simulation required during\nDeep RL training. Both algorithms modify how PSRO adds new policies to the\nempirical game, based on learned responses to a single opponent policy. The\nfirst, Mixed-Oracles, transfers knowledge from previous iterations of Deep RL,\nrequiring training only against the opponent's newest policy. The second,\nMixed-Opponents, constructs a pure-strategy opponent by mixing existing\nstrategy's action-value estimates, instead of their policies. Learning against\na single policy mitigates variance in state outcomes that is induced by an\nunobserved distribution of opponents. We empirically demonstrate that these\nalgorithms substantially reduce the amount of simulation during training\nrequired by PSRO, while producing equivalent or better solutions to the game.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 14:44:46 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Smith", "Max Olan", ""], ["Anthony", "Thomas", ""], ["Wellman", "Michael P.", ""]]}, {"id": "2106.02067", "submitter": "Daniela Mihai", "authors": "Daniela Mihai, Jonathon Hare", "title": "Learning to Draw: Emergent Communication through Sketching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evidence that visual communication preceded written language and provided a\nbasis for it goes back to prehistory, in forms such as cave and rock paintings\ndepicting traces of our distant ancestors. Emergent communication research has\nsought to explore how agents can learn to communicate in order to\ncollaboratively solve tasks. Existing research has focused on language, with a\nlearned communication channel transmitting sequences of discrete tokens between\nthe agents. In this work, we explore a visual communication channel between\nagents that are allowed to draw with simple strokes. Our agents are\nparameterised by deep neural networks, and the drawing procedure is\ndifferentiable, allowing for end-to-end training. In the framework of a\nreferential communication game, we demonstrate that agents can not only\nsuccessfully learn to communicate by drawing, but with appropriate inductive\nbiases, can do so in a fashion that humans can interpret. We hope to encourage\nfuture research to consider visual communication as a more flexible and\ndirectly interpretable alternative of training collaborative agents.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 18:17:55 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Mihai", "Daniela", ""], ["Hare", "Jonathon", ""]]}, {"id": "2106.02322", "submitter": "Alejandro Puente-Castro Mr", "authors": "Alejandro Puente-Castro, Daniel Rivero, Alejandro Pazos, Enrique\n  Fernandez-Blanco", "title": "UAV Swarm Path Planning with Reinforcement Learning for Field\n  prospecting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Unmanned Aerial Vehicle (UAV) swarms adoption shows a steady growth among\noperators due to the benefits in time and cost arisen from their use. However,\nthis kind of system faces an important problem which is the calculation of many\noptimal paths for each UAV. Solving this problem would allow a to control many\nUAVs without human intervention at the same time while saving battery between\nrecharges and performing several tasks simultaneously. The main aim is to\ndevelop a system capable of calculating the optimal flight path for a UAV\nswarm. The aim of these paths is to achieve full coverage of a flight area for\ntasks such as field prospection. All this, regardless of the size of maps and\nthe number of UAVs in the swarm. It is not necessary to establish targets or\nany other previous knowledge other than the given map. Experiments have been\nconducted to determine whether it is optimal to establish a single control for\nall UAVs in the swarm or a control for each UAV. The results show that it is\nbetter to use one control for all UAVs because of the shorter flight time. In\naddition, the flight time is greatly affected by the size of the map. The\nresults give starting points for future research such as finding the optimal\nmap size for each situation.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 08:04:14 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Puente-Castro", "Alejandro", ""], ["Rivero", "Daniel", ""], ["Pazos", "Alejandro", ""], ["Fernandez-Blanco", "Enrique", ""]]}, {"id": "2106.02394", "submitter": "L\\^e-Nguy\\^en Hoang", "authors": "El-Mahdi El-Mhamdi, Sadegh Farhadkhani, Rachid Guerraoui and\n  L\\^e-Nguy\\^en Hoang", "title": "On the Strategyproofness of the Geometric Median", "comments": "53 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The geometric median of a tuple of vectors is the vector that minimizes the\nsum of Euclidean distances to the vectors of the tuple. Interestingly, the\ngeometric median can also be viewed as the equilibrium of a process where each\nvector of the tuple pulls on a common decision point with a unitary force\ntowards them, promoting the \"one voter, one unit force\" fairness principle.\n  In this paper, we analyze the strategyproofness of the geometric median as a\nvoting system. Assuming that voters want to minimize the Euclidean distance\nbetween their preferred vector and the outcome of the vote, we first prove\nthat, in the general case, the geometric median is not even\n$\\alpha$-strategyproof. However, in the limit of a large number of voters,\nassuming that voters' preferred vectors are drawn i.i.d. from a distribution of\npreferred vectors, we also prove that the geometric median is asymptotically\n$\\alpha$-strategyproof. The bound $\\alpha$ describes what a voter can gain (at\nmost) by deviating from truthfulness. We show how to compute this bound as a\nfunction of the distribution followed by the vectors. We then generalize our\nresults to the case where each voter actually cares more about some dimensions\nrather than others. Roughly, we show that, if some dimensions are more\npolarized and regarded as more important, then the geometric median becomes\nless strategyproof. Interestingly, we also show how the skewed geometric\nmedians can be used to improve strategyproofness. Nevertheless, if voters care\ndifferently about different dimensions, we prove that no skewed geometric\nmedian can achieve strategyproofness for all of them. Overall, our results\nprovide insight into the extent to which the (skewed) geometric median is a\nsuitable approach to aggregate high-dimensional disagreements.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 10:17:55 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["El-Mhamdi", "El-Mahdi", ""], ["Farhadkhani", "Sadegh", ""], ["Guerraoui", "Rachid", ""], ["Hoang", "L\u00ea-Nguy\u00ean", ""]]}, {"id": "2106.02540", "submitter": "Mohamed Sana", "authors": "Mohamed Sana, Nicola di Pietro, Emilio Calvanese Strinati", "title": "Transferable and Distributed User Association Policies for 5G and Beyond\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the problem of user association, namely finding the optimal\nassignment of user equipment to base stations to achieve a targeted network\nperformance. In this paper, we focus on the knowledge transferability of\nassociation policies. Indeed, traditional non-trivial user association schemes\nare often scenario-specific or deployment-specific and require a policy\nre-design or re-learning when the number or the position of the users change.\nIn contrast, transferability allows to apply a single user association policy,\ndevised for a specific scenario, to other distinct user deployments, without\nneeding a substantial re-learning or re-design phase and considerably reducing\nits computational and management complexity. To achieve transferability, we\nfirst cast user association as a multi-agent reinforcement learning problem.\nThen, based on a neural attention mechanism that we specifically conceived for\nthis context, we propose a novel distributed policy network architecture, which\nis transferable among users with zero-shot generalization capability i.e.,\nwithout requiring additional training.Numerical results show the effectiveness\nof our solution in terms of overall network communication rate, outperforming\ncentralized benchmarks even when the number of users doubles with respect to\nthe initial training point.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 15:08:39 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Sana", "Mohamed", ""], ["di Pietro", "Nicola", ""], ["Strinati", "Emilio Calvanese", ""]]}, {"id": "2106.02708", "submitter": "Venkata Sriram Siddhardh Nadendla", "authors": "Sainath Sanga and Venkata Sriram Siddhardh Nadendla", "title": "On the Design of Strategic Task Recommendations for Sustainable\n  Crowdsourcing-Based Content Moderation", "comments": "Presented at International Workshop on Autonomous Agents for Social\n  Good (AASG), May 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.CY cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crowdsourcing-based content moderation is a platform that hosts content\nmoderation tasks for crowd workers to review user submissions (e.g. text,\nimages and videos) and make decisions regarding the admissibility of the posted\ncontent, along with a gamut of other tasks such as image labeling and\nspeech-to-text conversion. In an attempt to reduce cognitive overload at the\nworkers and improve system efficiency, these platforms offer personalized task\nrecommendations according to the worker's preferences. However, the current\nstate-of-the-art recommendation systems disregard the effects on worker's\nmental health, especially when they are repeatedly exposed to content\nmoderation tasks with extreme content (e.g. violent images, hate-speech). In\nthis paper, we propose a novel, strategic recommendation system for the\ncrowdsourcing platform that recommends jobs based on worker's mental status.\nSpecifically, this paper models interaction between the crowdsourcing\nplatform's recommendation system (leader) and the worker (follower) as a\nBayesian Stackelberg game where the type of the follower corresponds to the\nworker's cognitive atrophy rate and task preferences. We discuss how rewards\nand costs should be designed to steer the game towards desired outcomes in\nterms of maximizing the platform's productivity, while simultaneously improving\nthe working conditions of crowd workers.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 20:35:14 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Sanga", "Sainath", ""], ["Nadendla", "Venkata Sriram Siddhardh", ""]]}, {"id": "2106.02745", "submitter": "Yaodong Yang Mr.", "authors": "Xidong Feng, Oliver Slumbers, Yaodong Yang, Ziyu Wan, Bo Liu, Stephen\n  McAleer, Ying Wen, Jun Wang", "title": "Discovering Multi-Agent Auto-Curricula in Two-Player Zero-Sum Games", "comments": "corresponding to <yaodong.yang@outlook.com>", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When solving two-player zero-sum games, multi-agent reinforcement learning\n(MARL) algorithms often create populations of agents where, at each iteration,\na new agent is discovered as the best response to a mixture over the opponent\npopulation. Within such a process, the update rules of \"who to compete with\"\n(i.e., the opponent mixture) and \"how to beat them\" (i.e., finding best\nresponses) are underpinned by manually developed game theoretical principles\nsuch as fictitious play and Double Oracle. In this paper we introduce a\nframework, LMAC, based on meta-gradient descent that automates the discovery of\nthe update rule without explicit human design. Specifically, we parameterise\nthe opponent selection module by neural networks and the best-response module\nby optimisation subroutines, and update their parameters solely via interaction\nwith the game engine, where both players aim to minimise their exploitability.\nSurprisingly, even without human design, the discovered MARL algorithms achieve\ncompetitive or even better performance with the state-of-the-art\npopulation-based game solvers (e.g., PSRO) on Games of Skill, differentiable\nLotto, non-transitive Mixture Games, Iterated Matching Pennies, and Kuhn Poker.\nAdditionally, we show that LMAC is able to generalise from small games to large\ngames, for example training on Kuhn Poker and outperforming PSRO on Leduc\nPoker. Our work inspires a promising future direction to discover general MARL\nalgorithms solely from data.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 22:30:25 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Feng", "Xidong", ""], ["Slumbers", "Oliver", ""], ["Yang", "Yaodong", ""], ["Wan", "Ziyu", ""], ["Liu", "Bo", ""], ["McAleer", "Stephen", ""], ["Wen", "Ying", ""], ["Wang", "Jun", ""]]}, {"id": "2106.02748", "submitter": "Muhammed Omer Sayin", "authors": "Muhammed O. Sayin, Kaiqing Zhang, David S. Leslie, Tamer Basar, Asuman\n  Ozdaglar", "title": "Decentralized Q-Learning in Zero-sum Markov Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG cs.MA math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study multi-agent reinforcement learning (MARL) in infinite-horizon\ndiscounted zero-sum Markov games. We focus on the practical but challenging\nsetting of decentralized MARL, where agents make decisions without coordination\nby a centralized controller, but only based on their own payoffs and local\nactions executed. The agents need not observe the opponent's actions or\npayoffs, possibly being even oblivious to the presence of the opponent, nor be\naware of the zero-sum structure of the underlying game, a setting also referred\nto as radically uncoupled in the literature of learning in games. In this\npaper, we develop for the first time a radically uncoupled Q-learning dynamics\nthat is both rational and convergent: the learning dynamics converges to the\nbest response to the opponent's strategy when the opponent follows an\nasymptotically stationary strategy; the value function estimates converge to\nthe payoffs at a Nash equilibrium when both agents adopt the dynamics. The key\nchallenge in this decentralized setting is the non-stationarity of the learning\nenvironment from an agent's perspective, since both her own payoffs and the\nsystem evolution depend on the actions of other agents, and each agent adapts\ntheir policies simultaneously and independently. To address this issue, we\ndevelop a two-timescale learning dynamics where each agent updates her local\nQ-function and value function estimates concurrently, with the latter happening\nat a slower timescale.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 22:42:56 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Sayin", "Muhammed O.", ""], ["Zhang", "Kaiqing", ""], ["Leslie", "David S.", ""], ["Basar", "Tamer", ""], ["Ozdaglar", "Asuman", ""]]}, {"id": "2106.02851", "submitter": "Zhihuan Huang", "authors": "Zhihuan Huang, Shengwei Xu, You Shan, Yuxuan Lu, Yuqing Kong, Tracy\n  Xiao Liu, Grant Schoenebeck", "title": "SURPRISE! and When to Schedule It", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information flow measures, over the duration of a game, the audience's belief\nof who will win, and thus can reflect the amount of surprise in a game. To\nquantify the relationship between information flow and audiences' perceived\nquality, we conduct a case study where subjects watch one of the world's\nbiggest esports events, LOL S10. In addition to eliciting information flow, we\nalso ask subjects to report their rating for each game. We find that the amount\nof surprise in the end of the game plays a dominant role in predicting the\nrating. This suggests the importance of incorporating when the surprise occurs,\nin addition to the amount of surprise, in perceived quality models. For content\nproviders, it implies that everything else being equal, it is better for twists\nto be more likely to happen toward the end of a show rather than uniformly\nthroughout.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jun 2021 09:36:27 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Huang", "Zhihuan", ""], ["Xu", "Shengwei", ""], ["Shan", "You", ""], ["Lu", "Yuxuan", ""], ["Kong", "Yuqing", ""], ["Liu", "Tracy Xiao", ""], ["Schoenebeck", "Grant", ""]]}, {"id": "2106.03051", "submitter": "Junyoung Park", "authors": "Junyoung Park, Sanjar Bakhtiyar, Jinkyoo Park", "title": "ScheduleNet: Learn to solve multi-agent scheduling problems with\n  reinforcement learning", "comments": "9 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose ScheduleNet, a RL-based real-time scheduler, that can solve\nvarious types of multi-agent scheduling problems. We formulate these problems\nas a semi-MDP with episodic reward (makespan) and learn ScheduleNet, a\ndecentralized decision-making policy that can effectively coordinate multiple\nagents to complete tasks. The decision making procedure of ScheduleNet\nincludes: (1) representing the state of a scheduling problem with the\nagent-task graph, (2) extracting node embeddings for agent and tasks nodes, the\nimportant relational information among agents and tasks, by employing the\ntype-aware graph attention (TGA), and (3) computing the assignment probability\nwith the computed node embeddings. We validate the effectiveness of ScheduleNet\nas a general learning-based scheduler for solving various types of multi-agent\nscheduling tasks, including multiple salesman traveling problem (mTSP) and job\nshop scheduling problem (JSP).\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2021 07:08:58 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Park", "Junyoung", ""], ["Bakhtiyar", "Sanjar", ""], ["Park", "Jinkyoo", ""]]}, {"id": "2106.03132", "submitter": "Karthik Soma", "authors": "Vivek Shankar Vardharajan, Karthik Soma, Giovanni Beltrame", "title": "Collective transport via sequential caging", "comments": "Number of Pages - 14 Number of figures - 9 Accepted by Distributed\n  Autonomous Robotic Systems ' 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a decentralized algorithm to collaboratively transport arbitrarily\nshaped objects using a swarm of robots. Our approach starts with a task\nallocation phase that sequentially distributes locations around the object to\nbe transported starting from a seed robot that makes first contact with the\nobject. Our approach does not require previous knowledge of the shape of the\nobject to ensure caging. To push the object to a goal location, we estimate the\nrobots required to apply force on the object based on the angular difference\nbetween the target and the object. During transport, the robots follow a\nsequence of intermediate goal locations specifying the required pose of the\nobject at that location. We evaluate our approach in a physics-based simulator\nwith up to 100 robots, using three generic paths. Experiments using a group of\nKheperaIV robots demonstrate the effectiveness of our approach in a real\nsetting.\n  Keywords: Collaborative transport, Task Allocation, Caging, Robot Swarms\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2021 14:21:21 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Vardharajan", "Vivek Shankar", ""], ["Soma", "Karthik", ""], ["Beltrame", "Giovanni", ""]]}, {"id": "2106.03215", "submitter": "Neehar Peri", "authors": "Neehar Peri, Michael J. Curry, Samuel Dooley, John P. Dickerson", "title": "PreferenceNet: Encoding Human Preferences in Auction Design with Deep\n  Learning", "comments": "First two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.LG cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The design of optimal auctions is a problem of interest in economics, game\ntheory and computer science. Despite decades of effort, strategyproof,\nrevenue-maximizing auction designs are still not known outside of restricted\nsettings. However, recent methods using deep learning have shown some success\nin approximating optimal auctions, recovering several known solutions and\noutperforming strong baselines when optimal auctions are not known. In addition\nto maximizing revenue, auction mechanisms may also seek to encourage socially\ndesirable constraints such as allocation fairness or diversity. However, these\nphilosophical notions neither have standardization nor do they have widely\naccepted formal definitions. In this paper, we propose PreferenceNet, an\nextension of existing neural-network-based auction mechanisms to encode\nconstraints using (potentially human-provided) exemplars of desirable\nallocations. In addition, we introduce a new metric to evaluate an auction\nallocations' adherence to such socially desirable constraints and demonstrate\nthat our proposed method is competitive with current state-of-the-art\nneural-network based auction designs. We validate our approach through human\nsubject research and show that we are able to effectively capture real human\npreferences. Our code is available at\nhttps://github.com/neeharperi/PreferenceNet\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2021 19:29:40 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Peri", "Neehar", ""], ["Curry", "Michael J.", ""], ["Dooley", "Samuel", ""], ["Dickerson", "John P.", ""]]}, {"id": "2106.03548", "submitter": "Gauthier Picard", "authors": "Gauthier Picard", "title": "Auction-based and Distributed Optimization Approaches for Scheduling\n  Observations in Satellite Constellations with Exclusive Orbit Portions", "comments": null, "journal-ref": "International Workshop on Planning and Scheduling for Space\n  (IWPSS'21), Jul 2021, virtuel, United States", "doi": null, "report-no": null, "categories": "cs.AI cs.MA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the use of multi-agent allocation techniques on problems\nrelated to Earth observation scenarios with multiple users and satellites. We\nfocus on the problem of coordinating users having reserved exclusive orbit\nportions and one central planner having several requests that may use some\nintervals of these exclusives. We define this problem as Earth Observation\nSatellite Constellation Scheduling Problem (EOSCSP) and map it to a Mixed\nInteger Linear Program. As to solve EOSCSP, we propose market-based techniques\nand a distributed problem solving technique based on Distributed Constraint\nOptimization (DCOP), where agents cooperate to allocate requests without\nsharing their own schedules. These contributions are experimentally evaluated\non randomly generated EOSCSP instances based on real large-scale or highly\nconflicting observation order books.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 09:34:20 GMT"}, {"version": "v2", "created": "Mon, 21 Jun 2021 09:30:47 GMT"}, {"version": "v3", "created": "Tue, 27 Jul 2021 06:33:47 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Picard", "Gauthier", ""]]}, {"id": "2106.03585", "submitter": "Mathieu Even", "authors": "Mathieu Even, Hadrien Hendrikx, Laurent Massoulie", "title": "Decentralized Optimization with Heterogeneous Delays: a Continuous-Time\n  Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.MA math.PR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In decentralized optimization, nodes of a communication network privately\npossess a local objective function, and communicate using gossip-based methods\nin order to minimize the average of these per-node objectives. While\nsynchronous algorithms can be heavily slowed down by a few nodes and edges in\nthe graph (the straggler problem), their asynchronous counterparts lack from a\nsharp analysis taking into account heterogeneous delays in the communication\nnetwork. In this paper, we propose a novel continuous-time framework to analyze\nasynchronous algorithms, which does not require to define a global ordering of\nthe events, and allows to finely characterize the time complexity in the\npresence of (heterogeneous) delays. Using this framework, we describe a fully\nasynchronous decentralized algorithm to minimize the sum of smooth and strongly\nconvex functions. Our algorithm (DCDM, Delayed Coordinate Dual Method), based\non delayed randomized gossip communications and local computational updates,\nachieves an asynchronous speed-up: the rate of convergence is tightly\ncharacterized in terms of the eigengap of the graph weighted by local delays\nonly, instead of the global worst-case delays as in previous analyses.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 13:09:25 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Even", "Mathieu", ""], ["Hendrikx", "Hadrien", ""], ["Massoulie", "Laurent", ""]]}, {"id": "2106.03611", "submitter": "Lasse Peters", "authors": "Lasse Peters, David Fridovich-Keil, Vicen\\c{c} Rubies-Royo, Claire J.\n  Tomlin, Cyrill Stachniss", "title": "Inferring Objectives in Continuous Dynamic Games from Noise-Corrupted\n  Partial State Observations", "comments": "Submitted to RSS2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robots and autonomous systems must interact with one another and their\nenvironment to provide high-quality services to their users. Dynamic game\ntheory provides an expressive theoretical framework for modeling scenarios\ninvolving multiple agents with differing objectives interacting over time. A\ncore challenge when formulating a dynamic game is designing objectives for each\nagent that capture desired behavior. In this paper, we propose a method for\ninferring parametric objective models of multiple agents based on observed\ninteractions. Our inverse game solver jointly optimizes player objectives and\ncontinuous-state estimates by coupling them through Nash equilibrium\nconstraints. Hence, our method is able to directly maximize the observation\nlikelihood rather than other non-probabilistic surrogate criteria. Our method\ndoes not require full observations of game states or player strategies to\nidentify player objectives. Instead, it robustly recovers this information from\nnoisy, partial state observations. As a byproduct of estimating player\nobjectives, our method computes a Nash equilibrium trajectory corresponding to\nthose objectives. Thus, it is suitable for downstream trajectory forecasting\ntasks. We demonstrate our method in several simulated traffic scenarios.\nResults show that it reliably estimates player objectives from a short sequence\nof noise-corrupted partial state observations. Furthermore, using the estimated\nobjectives, our method makes accurate predictions of each player's trajectory.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 13:37:42 GMT"}, {"version": "v2", "created": "Wed, 16 Jun 2021 19:43:20 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Peters", "Lasse", ""], ["Fridovich-Keil", "David", ""], ["Rubies-Royo", "Vicen\u00e7", ""], ["Tomlin", "Claire J.", ""], ["Stachniss", "Cyrill", ""]]}, {"id": "2106.03787", "submitter": "Matthieu Geist", "authors": "Matthieu Geist, Julien P\\'erolat, Mathieu Lauri\\`ere, Romuald Elie,\n  Sarah Perrin, Olivier Bachem, R\\'emi Munos, Olivier Pietquin", "title": "Concave Utility Reinforcement Learning: the Mean-field Game viewpoint", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Concave Utility Reinforcement Learning (CURL) extends RL from linear to\nconcave utilities in the occupancy measure induced by the agent's policy. This\nencompasses not only RL but also imitation learning and exploration, among\nothers. Yet, this more general paradigm invalidates the classical Bellman\nequations, and calls for new algorithms. Mean-field Games (MFGs) are a\ncontinuous approximation of many-agent RL. They consider the limit case of a\ncontinuous distribution of identical agents, anonymous with symmetric\ninterests, and reduce the problem to the study of a single representative agent\nin interaction with the full population. Our core contribution consists in\nshowing that CURL is a subclass of MFGs. We think this important to bridge\ntogether both communities. It also allows to shed light on aspects of both\nfields: we show the equivalence between concavity in CURL and monotonicity in\nthe associated MFG, between optimality conditions in CURL and Nash equilibrium\nin MFG, or that Fictitious Play (FP) for this class of MFGs is simply\nFrank-Wolfe, bringing the first convergence rate for discrete-time FP for MFGs.\nWe also experimentally demonstrate that, using algorithms recently introduced\nfor solving MFGs, we can address the CURL problem more efficiently.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 16:51:07 GMT"}, {"version": "v2", "created": "Wed, 9 Jun 2021 09:27:45 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Geist", "Matthieu", ""], ["P\u00e9rolat", "Julien", ""], ["Lauri\u00e8re", "Mathieu", ""], ["Elie", "Romuald", ""], ["Perrin", "Sarah", ""], ["Bachem", "Olivier", ""], ["Munos", "R\u00e9mi", ""], ["Pietquin", "Olivier", ""]]}, {"id": "2106.03927", "submitter": "Stephen McAleer", "authors": "Stephen McAleer, John Lanier, Michael Dennis, Pierre Baldi, Roy Fox", "title": "Improving Social Welfare While Preserving Autonomy via a Pareto Mediator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.LG cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine learning algorithms often make decisions on behalf of agents with\nvaried and sometimes conflicting interests. In domains where agents can choose\nto take their own action or delegate their action to a central mediator, an\nopen question is how mediators should take actions on behalf of delegating\nagents. The main existing approach uses delegating agents to punish\nnon-delegating agents in an attempt to get all agents to delegate, which tends\nto be costly for all. We introduce a Pareto Mediator which aims to improve\noutcomes for delegating agents without making any of them worse off. Our\nexperiments in random normal form games, a restaurant recommendation game, and\na reinforcement learning sequential social dilemma show that the Pareto\nMediator greatly increases social welfare. Also, even when the Pareto Mediator\nis based on an incorrect model of agent utility, performance gracefully\ndegrades to the pre-intervention level, due to the individual autonomy\npreserved by the voluntary mediator.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 19:34:42 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["McAleer", "Stephen", ""], ["Lanier", "John", ""], ["Dennis", "Michael", ""], ["Baldi", "Pierre", ""], ["Fox", "Roy", ""]]}, {"id": "2106.04029", "submitter": "Rohit Konda", "authors": "Rohit Konda, Rahul Chandan, Jason R. Marden", "title": "Mission Level Uncertainty in Multi-Agent Resource Allocation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years, a significant research effort has been devoted to the design\nof distributed protocols for the control of multi-agent systems, as the scale\nand limited communication bandwidth characteristic of such systems render\ncentralized control impossible. Given the strict operating conditions, it is\nunlikely that every agent in a multi-agent system will have local information\nthat is consistent with the true system state. Yet, the majority of works in\nthe literature assume that agents share perfect knowledge of their environment.\nThis paper focuses on understanding the impact that inconsistencies in agents'\nlocal information can have on the performance of multi-agent systems. More\nspecifically, we consider the design of multi-agent operations under a game\ntheoretic lens where individual agents are assigned utilities that guide their\nlocal decision making. We provide a tractable procedure for designing utilities\nthat optimize the efficiency of the resulting collective behavior (i.e., price\nof anarchy) for classes of set covering games where the extent of the\ninformation inconsistencies is known. In the setting where the extent of the\ninformational inconsistencies is not known, we show -- perhaps surprisingly --\nthat underestimating the level of uncertainty leads to better price of anarchy\nthan overestimating it.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 00:48:42 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Konda", "Rohit", ""], ["Chandan", "Rahul", ""], ["Marden", "Jason R.", ""]]}, {"id": "2106.04075", "submitter": "Hongchang Wu", "authors": "Ziyu Guan, Hongchang Wu, Qingyu Cao, Hao Liu, Wei Zhao, Sheng Li, Cai\n  Xu, Guang Qiu, Jian Xu, Bo Zheng", "title": "Multi-Agent Cooperative Bidding Games for Multi-Objective Optimization\n  in e-Commercial Sponsored Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bid optimization for online advertising from single advertiser's perspective\nhas been thoroughly investigated in both academic research and industrial\npractice. However, existing work typically assume competitors do not change\ntheir bids, i.e., the wining price is fixed, leading to poor performance of the\nderived solution. Although a few studies use multi-agent reinforcement learning\nto set up a cooperative game, they still suffer the following drawbacks: (1)\nThey fail to avoid collusion solutions where all the advertisers involved in an\nauction collude to bid an extremely low price on purpose. (2) Previous works\ncannot well handle the underlying complex bidding environment, leading to poor\nmodel convergence. This problem could be amplified when handling multiple\nobjectives of advertisers which are practical demands but not considered by\nprevious work. In this paper, we propose a novel multi-objective cooperative\nbid optimization formulation called Multi-Agent Cooperative bidding Games\n(MACG). MACG sets up a carefully designed multi-objective optimization\nframework where different objectives of advertisers are incorporated. A global\nobjective to maximize the overall profit of all advertisements is added in\norder to encourage better cooperation and also to protect self-bidding\nadvertisers. To avoid collusion, we also introduce an extra platform revenue\nconstraint. We analyze the optimal functional form of the bidding formula\ntheoretically and design a policy network accordingly to generate auction-level\nbids. Then we design an efficient multi-agent evolutionary strategy for model\noptimization. Offline experiments and online A/B tests conducted on the Taobao\nplatform indicate both single advertiser's objective and global profit have\nbeen significantly improved compared to state-of-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 03:18:28 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Guan", "Ziyu", ""], ["Wu", "Hongchang", ""], ["Cao", "Qingyu", ""], ["Liu", "Hao", ""], ["Zhao", "Wei", ""], ["Li", "Sheng", ""], ["Xu", "Cai", ""], ["Qiu", "Guang", ""], ["Xu", "Jian", ""], ["Zheng", "Bo", ""]]}, {"id": "2106.04219", "submitter": "Shayegan Omidshafiei", "authors": "Shayegan Omidshafiei, Daniel Hennes, Marta Garnelo, Eugene Tarassov,\n  Zhe Wang, Romuald Elie, Jerome T. Connor, Paul Muller, Ian Graham, William\n  Spearman, Karl Tuyls", "title": "Time-series Imputation of Temporally-occluded Multiagent Trajectories", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multiagent environments, several decision-making individuals interact\nwhile adhering to the dynamics constraints imposed by the environment. These\ninteractions, combined with the potential stochasticity of the agents'\ndecision-making processes, make such systems complex and interesting to study\nfrom a dynamical perspective. Significant research has been conducted on\nlearning models for forward-direction estimation of agent behaviors, for\nexample, pedestrian predictions used for collision-avoidance in self-driving\ncars. However, in many settings, only sporadic observations of agents may be\navailable in a given trajectory sequence. For instance, in football, subsets of\nplayers may come in and out of view of broadcast video footage, while\nunobserved players continue to interact off-screen. In this paper, we study the\nproblem of multiagent time-series imputation, where available past and future\nobservations of subsets of agents are used to estimate missing observations for\nother agents. Our approach, called the Graph Imputer, uses forward- and\nbackward-information in combination with graph networks and variational\nautoencoders to enable learning of a distribution of imputed trajectories. We\nevaluate our approach on a dataset of football matches, using a projective\ncamera module to train and evaluate our model for the off-screen player state\nestimation setting. We illustrate that our method outperforms several\nstate-of-the-art approaches, including those hand-crafted for football.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 09:58:43 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Omidshafiei", "Shayegan", ""], ["Hennes", "Daniel", ""], ["Garnelo", "Marta", ""], ["Tarassov", "Eugene", ""], ["Wang", "Zhe", ""], ["Elie", "Romuald", ""], ["Connor", "Jerome T.", ""], ["Muller", "Paul", ""], ["Graham", "Ian", ""], ["Spearman", "William", ""], ["Tuyls", "Karl", ""]]}, {"id": "2106.04258", "submitter": "Roberto Dess\\`i", "authors": "Roberto Dess\\`i, Eugene Kharitonov, Marco Baroni", "title": "Interpretable agent communication from scratch(with a generic visual\n  processor emerging on the side)", "comments": "9 pages main text, 13 pages total", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.MA", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  As deep networks begin to be deployed as autonomous agents, the issue of how\nthey can communicate with each other becomes important. Here, we train two deep\nnets from scratch to perform realistic referent identification through\nunsupervised emergent communication. We show that the largely interpretable\nemergent protocol allows the nets to successfully communicate even about object\ntypes they did not see at training time. The visual representations induced as\na by-product of our training regime, moreover, show comparable quality, when\nre-used as generic visual features, to a recent self-supervised learning model.\nOur results provide concrete evidence of the viability of (interpretable)\nemergent deep net communication in a more realistic scenario than previously\nconsidered, as well as establishing an intriguing link between this field and\nself-supervised visual learning.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 11:32:11 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Dess\u00ec", "Roberto", ""], ["Kharitonov", "Eugene", ""], ["Baroni", "Marco", ""]]}, {"id": "2106.04461", "submitter": "Kasey Jones", "authors": "Kasey Jones, Emily Hadley, Sandy Preiss, Caroline Kery, Peter\n  Baumgartner, Marie Stoner, Sarah Rhea", "title": "North Carolina COVID-19 Agent-Based Model Framework for Hospitalization\n  Forecasting Overview, Design Concepts, and Details Protocol", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA stat.AP", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This Overview, Design Concepts, and Details Protocol (ODD) provides a\ndetailed description of an agent-based model (ABM) that was developed to\nsimulate hospitalizations during the COVID-19 pandemic. Using the descriptions\nof submodels, provided parameters, and the links to data sources, modelers will\nbe able to replicate the creation and results of this model.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 15:43:02 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Jones", "Kasey", ""], ["Hadley", "Emily", ""], ["Preiss", "Sandy", ""], ["Kery", "Caroline", ""], ["Baumgartner", "Peter", ""], ["Stoner", "Marie", ""], ["Rhea", "Sarah", ""]]}, {"id": "2106.04512", "submitter": "Matt Luckcuck", "authors": "Matt Luckcuck and Rafael C. Cardoso", "title": "Formal Verification of a Map Merging Protocol in the Multi-Agent\n  Programming Contest", "comments": "EMAS 2021 Proceedings Submitted Version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Communication is a critical part of enabling multi-agent systems to\ncooperate. This means that applying formal methods to protocols governing\ncommunication within multi-agent systems provides useful confidence in its\nreliability. In this paper, we describe the formal verification of a complex\ncommunication protocol that coordinates agents merging maps of their\nenvironment. The protocol was used by the LFC team in the 2019 edition of the\nMulti-Agent Programming Contest (MAPC). Our specification of the protocol is\nwritten in Communicating Sequential Processes (CSP), which is a well-suited\napproach to specifying agent communication protocols due to its focus on\nconcurrent communicating systems. We validate the specification's behaviour\nusing scenarios where the correct behaviour is known, and verify that\neventually all the maps have merged.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 16:49:53 GMT"}, {"version": "v2", "created": "Tue, 22 Jun 2021 10:18:10 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Luckcuck", "Matt", ""], ["Cardoso", "Rafael C.", ""]]}, {"id": "2106.04678", "submitter": "Erdem B{\\i}y{\\i}k", "authors": "Erdem B{\\i}y{\\i}k, Daniel A. Lazar, Ramtin Pedarsani, Dorsa Sadigh", "title": "Incentivizing Efficient Equilibria in Traffic Networks with Mixed\n  Autonomy", "comments": "12 pages, 7 figures, 2 tables. To appear at IEEE Transactions on\n  Control of Network Systems (TCNS). arXiv admin note: substantial text overlap\n  with arXiv:1904.02209", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traffic congestion has large economic and social costs. The introduction of\nautonomous vehicles can potentially reduce this congestion by increasing road\ncapacity via vehicle platooning and by creating an avenue for influencing\npeople's choice of routes. We consider a network of parallel roads with two\nmodes of transportation: (i) human drivers, who will choose the quickest route\navailable to them, and (ii) a ride hailing service, which provides an array of\nautonomous vehicle route options, each with different prices, to users. We\nformalize a model of vehicle flow in mixed autonomy and a model of how\nautonomous service users make choices between routes with different prices and\nlatencies. Developing an algorithm to learn the preferences of the users, we\nformulate a planning optimization that chooses prices to maximize a social\nobjective. We demonstrate the benefit of the proposed scheme by comparing the\nresults to theoretical benchmarks which we show can be efficiently calculated.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 03:01:46 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["B\u0131y\u0131k", "Erdem", ""], ["Lazar", "Daniel A.", ""], ["Pedarsani", "Ramtin", ""], ["Sadigh", "Dorsa", ""]]}, {"id": "2106.04679", "submitter": "Qin Yang", "authors": "Qin Yang", "title": "Self-Adaptive Swarm System (SASS)", "comments": "The preprint for IJCAI 2021 Doctoral Consortium (The Final Version)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.GT cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed artificial intelligence (DAI) studies artificial intelligence\nentities working together to reason, plan, solve problems, organize behaviors\nand strategies, make collective decisions and learn. This Ph.D. research\nproposes a principled Multi-Agent Systems (MAS) cooperation framework,\nSelf-Adaptive Swarm System (SASS), to bridge the fourth level automation gap\nbetween perception, communication, planning, execution, decision-making, and\nlearning.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 22:46:36 GMT"}, {"version": "v2", "created": "Tue, 29 Jun 2021 02:54:53 GMT"}, {"version": "v3", "created": "Fri, 2 Jul 2021 20:14:29 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Yang", "Qin", ""]]}, {"id": "2106.04958", "submitter": "Ying Wen", "authors": "Xiangyu Liu, Hangtian Jia, Ying Wen, Yaodong Yang, Yujing Hu, Yingfeng\n  Chen, Changjie Fan, Zhipeng Hu", "title": "Unifying Behavioral and Response Diversity for Open-ended Learning in\n  Zero-sum Games", "comments": "We investigate a new perspective on unifying diversity measures for\n  open-ended learning in zero-sum games, which shapes an auto-curriculum to\n  induce diverse yet effective behaviors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.GT cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Measuring and promoting policy diversity is critical for solving games with\nstrong non-transitive dynamics where strategic cycles exist, and there is no\nconsistent winner (e.g., Rock-Paper-Scissors). With that in mind, maintaining a\npool of diverse policies via open-ended learning is an attractive solution,\nwhich can generate auto-curricula to avoid being exploited. However, in\nconventional open-ended learning algorithms, there are no widely accepted\ndefinitions for diversity, making it hard to construct and evaluate the diverse\npolicies. In this work, we summarize previous concepts of diversity and work\ntowards offering a unified measure of diversity in multi-agent open-ended\nlearning to include all elements in Markov games, based on both Behavioral\nDiversity (BD) and Response Diversity (RD). At the trajectory distribution\nlevel, we re-define BD in the state-action space as the discrepancies of\noccupancy measures. For the reward dynamics, we propose RD to characterize\ndiversity through the responses of policies when encountering different\nopponents. We also show that many current diversity measures fall in one of the\ncategories of BD or RD but not both. With this unified diversity measure, we\ndesign the corresponding diversity-promoting objective and population\neffectivity when seeking the best responses in open-ended learning. We validate\nour methods in both relatively simple games like matrix game, non-transitive\nmixture model, and the complex \\textit{Google Research Football} environment.\nThe population found by our methods reveals the lowest exploitability, highest\npopulation effectivity in matrix game and non-transitive mixture model, as well\nas the largest goal difference when interacting with opponents of various\nlevels in \\textit{Google Research Football}.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 10:11:06 GMT"}, {"version": "v2", "created": "Thu, 10 Jun 2021 16:00:18 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Liu", "Xiangyu", ""], ["Jia", "Hangtian", ""], ["Wen", "Ying", ""], ["Yang", "Yaodong", ""], ["Hu", "Yujing", ""], ["Chen", "Yingfeng", ""], ["Fan", "Changjie", ""], ["Hu", "Zhipeng", ""]]}, {"id": "2106.04984", "submitter": "Matteo Pozzi", "authors": "Shuo Li, Matteo Pozzi", "title": "Information Avoidance and Overvaluation in Sequential Decision Making\n  under Epistemic Constraints", "comments": "submitted to Rel. Eng. Sys. Saf", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IT cs.MA cs.SY eess.SY math.IT", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Decision makers involved in the management of civil assets and systems\nusually take actions under constraints imposed by societal regulations. Some of\nthese constraints are related to epistemic quantities, as the probability of\nfailure events and the corresponding risks. Sensors and inspectors can provide\nuseful information supporting the control process (e.g. the maintenance process\nof an asset), and decisions about collecting this information should rely on an\nanalysis of its cost and value. When societal regulations encode an economic\nperspective that is not aligned with that of the decision makers, the Value of\nInformation (VoI) can be negative (i.e., information sometimes hurts), and\nalmost irrelevant information can even have a significant value (either\npositive or negative), for agents acting under these epistemic constraints. We\nrefer to these phenomena as Information Avoidance (IA) and Information\nOverValuation (IOV). In this paper, we illustrate how to assess VoI in\nsequential decision making under epistemic constraints (as those imposed by\nsocietal regulations), by modeling a Partially Observable Markov Decision\nProcesses (POMDP) and evaluating non optimal policies via Finite State\nControllers (FSCs). We focus on the value of collecting information at current\ntime, and on that of collecting sequential information, we illustrate how these\nvalues are related and we discuss how IA and IOV can occur in those settings.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 11:05:13 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Li", "Shuo", ""], ["Pozzi", "Matteo", ""]]}, {"id": "2106.05018", "submitter": "Nicolo' Brandizzi", "authors": "Nicolo' Brandizzi, Davide Grossi, Luca Iocchi", "title": "RLupus: Cooperation through emergent communication in The Werewolf\n  social deduction game", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper focuses on the emergence of communication to support cooperation\nin environments modeled as social deduction games (SDG), that are games where\nplayers communicate freely to deduce each others' hidden intentions. We first\nstate the problem by giving a general formalization of SDG and a possible\nsolution framework based on reinforcement learning. Next, we focus on a\nspecific SDG, known as The Werewolf, and study if and how various forms of\ncommunication influence the outcome of the game. Experimental results show that\nintroducing a communication signal greatly increases the winning chances of a\nclass of players. We also study the effect of the signal's length and range on\nthe overall performance showing a non-linear relationship.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 12:29:29 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Brandizzi", "Nicolo'", ""], ["Grossi", "Davide", ""], ["Iocchi", "Luca", ""]]}, {"id": "2106.05188", "submitter": "Shyni Thomas", "authors": "Shyni Thomas, M. Narasimha Murty", "title": "Decentralised Approach for Multi Agent Path Finding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Multi Agent Path Finding (MAPF) requires identification of conflict free\npaths for agents which could be point-sized or with dimensions. In this paper,\nwe propose an approach for MAPF for spatially-extended agents. These find\napplication in real world problems like Convoy Movement Problem, Train\nScheduling etc. Our proposed approach, Decentralised Multi Agent Path Finding\n(DeMAPF), handles MAPF as a sequence of pathplanning and allocation problems\nwhich are solved by two sets of agents Travellers and Routers respectively,\nover multiple iterations. The approach being decentralised allows an agent to\nsolve the problem pertinent to itself, without being aware of other agents in\nthe same set. This allows the agents to be executed on independent machines,\nthereby leading to scalability to handle large sized problems. We prove, by\ncomparison with other distributed approaches, that the approach leads to a\nfaster convergence to a conflict-free solution, which may be suboptimal, with\nlesser memory requirement.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 18:07:26 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Thomas", "Shyni", ""], ["Murty", "M. Narasimha", ""]]}, {"id": "2106.05308", "submitter": "Eduardo Arnold", "authors": "Eduardo Arnold, Sajjad Mozaffari, Mehrdad Dianati, Paul Jennings", "title": "Visual Sensor Pose Optimisation Using Rendering-based Visibility Models\n  for Robust Cooperative Perception", "comments": "15 pages, 10 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Visual Sensor Networks can be used in a variety of perception applications\nsuch as infrastructure support for autonomous driving in complex road segments.\nThe pose of the sensors in such networks directly determines the coverage of\nthe environment and objects therein, which impacts the performance of\napplications such as object detection and tracking. Existing sensor pose\noptimisation methods in the literature either maximise the coverage of ground\nsurfaces, or consider the visibility of the target objects as binary variables,\nwhich cannot represent various degrees of visibility. Such formulations cannot\nguarantee the visibility of the target objects as they fail to consider\nocclusions. This paper proposes two novel sensor pose optimisation methods,\nbased on gradient-ascent and Integer Programming techniques, which maximise the\nvisibility of multiple target objects in cluttered environments. Both methods\nconsider a realistic visibility model based on a rendering engine that provides\npixel-level visibility information about the target objects. The proposed\nmethods are evaluated in a complex environment and compared to existing methods\nin the literature. The evaluation results indicate that explicitly modelling\nthe visibility of target objects is critical to avoid occlusions in cluttered\nenvironments. Furthermore, both methods significantly outperform existing\nmethods in terms of object visibility.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 18:02:32 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Arnold", "Eduardo", ""], ["Mozaffari", "Sajjad", ""], ["Dianati", "Mehrdad", ""], ["Jennings", "Paul", ""]]}, {"id": "2106.05521", "submitter": "Michael Thrun PhD", "authors": "Michael C. Thrun and Alfred Ultsch", "title": "Swarm Intelligence for Self-Organized Clustering", "comments": "54 pages, 21 figures", "journal-ref": "Artificial intelligence, Vol. 290, pp. 103237. 2021", "doi": "10.1016/j.artint.2020.103237", "report-no": null, "categories": "cs.NE cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithms implementing populations of agents which interact with one another\nand sense their environment may exhibit emergent behavior such as\nself-organization and swarm intelligence. Here a swarm system, called\nDatabionic swarm (DBS), is introduced which is able to adapt itself to\nstructures of high-dimensional data characterized by distance and/or\ndensity-based structures in the data space. By exploiting the interrelations of\nswarm intelligence, self-organization and emergence, DBS serves as an\nalternative approach to the optimization of a global objective function in the\ntask of clustering. The swarm omits the usage of a global objective function\nand is parameter-free because it searches for the Nash equilibrium during its\nannealing process. To our knowledge, DBS is the first swarm combining these\napproaches. Its clustering can outperform common clustering methods such as\nK-means, PAM, single linkage, spectral clustering, model-based clustering, and\nWard, if no prior knowledge about the data is available. A central problem in\nclustering is the correct estimation of the number of clusters. This is\naddressed by a DBS visualization called topographic map which allows assessing\nthe number of clusters. It is known that all clustering algorithms construct\nclusters, irrespective of the data set contains clusters or not. In contrast to\nmost other clustering algorithms, the topographic map identifies, that\nclustering of the data is meaningless if the data contains no (natural)\nclusters. The performance of DBS is demonstrated on a set of benchmark data,\nwhich are constructed to pose difficult clustering problems and in two\nreal-world applications.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 06:21:48 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Thrun", "Michael C.", ""], ["Ultsch", "Alfred", ""]]}, {"id": "2106.05727", "submitter": "Niko Grupen", "authors": "Niko A. Grupen, Bart Selman, Daniel D. Lee", "title": "Fairness for Cooperative Multi-Agent Learning with Equivariant Policies", "comments": "15 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study fairness through the lens of cooperative multi-agent learning. Our\nwork is motivated by empirical evidence that naive maximization of team reward\nyields unfair outcomes for individual team members. To address fairness in\nmulti-agent contexts, we introduce team fairness, a group-based fairness\nmeasure for multi-agent learning. We then incorporate team fairness into policy\noptimization -- introducing Fairness through Equivariance (Fair-E), a novel\nlearning strategy that achieves provably fair reward distributions. We then\nintroduce Fairness through Equivariance Regularization (Fair-ER) as a\nsoft-constraint version of Fair-E and show that Fair-ER reaches higher levels\nof utility than Fair-E and fairer outcomes than policies with no equivariance.\nFinally, we investigate the fairness-utility trade-off in multi-agent settings.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 13:17:46 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Grupen", "Niko A.", ""], ["Selman", "Bart", ""], ["Lee", "Daniel D.", ""]]}, {"id": "2106.05802", "submitter": "Zongqing Lu", "authors": "Yifan Yu, Haobin Jiang, Zongqing Lu", "title": "Informative Policy Representations in Multi-Agent Reinforcement Learning\n  via Joint-Action Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In multi-agent reinforcement learning, the inherent non-stationarity of the\nenvironment caused by other agents' actions posed significant difficulties for\nan agent to learn a good policy independently. One way to deal with\nnon-stationarity is agent modeling, by which the agent takes into consideration\nthe influence of other agents' policies. Most existing work relies on\npredicting other agents' actions or goals, or discriminating between their\npolicies. However, such modeling fails to capture the similarities and\ndifferences between policies simultaneously and thus cannot provide useful\ninformation when generalizing to unseen policies. To address this, we propose a\ngeneral method to learn representations of other agents' policies via the\njoint-action distributions sampled in interactions. The similarities and\ndifferences between policies are naturally captured by the policy distance\ninferred from the joint-action distributions and deliberately reflected in the\nlearned representations. Agents conditioned on the policy representations can\nwell generalize to unseen agents. We empirically demonstrate that our method\noutperforms existing work in multi-agent tasks when facing unseen agents.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 15:09:33 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Yu", "Yifan", ""], ["Jiang", "Haobin", ""], ["Lu", "Zongqing", ""]]}, {"id": "2106.06019", "submitter": "David Mathias", "authors": "H. David Mathias and Annie S. Wu and Daniel Dang", "title": "Analysis of Evolved Response Thresholds for Decentralized Dynamic Task\n  Allocation", "comments": "22 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We investigate the application of a multi-objective genetic algorithm to the\nproblem of task allocation in a self-organizing, decentralized, threshold-based\nswarm. Each agent in our system is capable of performing four tasks with a\nresponse threshold for each, and we seek to assign response threshold values to\nall of the agents a swarm such that the collective behavior of the swarm is\noptimized. Random assignment of threshold values according to a uniform\ndistribution is known to be effective; however, this method does not consider\nfeatures of particular problem instances. Dynamic response thresholds have some\nflexibility to address problem specific features through real-time adaptivity,\noften improving swarm performance.\n  In this work, we use a multi-objective genetic algorithm to evolve response\nthresholds for a simulated swarm engaged in a dynamic task allocation problem:\ntwo-dimensional collective tracking. We show that evolved thresholds not only\noutperform uniformly distributed thresholds and dynamic thresholds but achieve\nnearly optimal performance on a variety of tracking problem instances (target\npaths). More importantly, we demonstrate that thresholds evolved for one of\nseveral problem instances generalize to all other problem instances eliminating\nthe need to evolve new thresholds for each problem to be solved. We analyze the\nproperties that allow these paths to serve as universal training instances and\nshow that they are quite natural.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 19:53:53 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Mathias", "H. David", ""], ["Wu", "Annie S.", ""], ["Dang", "Daniel", ""]]}, {"id": "2106.06060", "submitter": "Panayiotis Danassis", "authors": "Panayiotis Danassis, Aris Filos-Ratsikas, Boi Faltings", "title": "Achieving Diverse Objectives with AI-driven Prices in Deep Reinforcement\n  Learning Multi-agent Markets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a practical approach to computing market prices and allocations\nvia a deep reinforcement learning policymaker agent, operating in an\nenvironment of other learning agents. Compared to the idealized market\nequilibrium outcome -- which we use as a benchmark -- our policymaker is much\nmore flexible, allowing us to tune the prices with regard to diverse objectives\nsuch as sustainability and resource wastefulness, fairness, buyers' and\nsellers' welfare, etc. To evaluate our approach, we design a realistic market\nwith multiple and diverse buyers and sellers. Additionally, the sellers, which\nare deep learning agents themselves, compete for resources in a common-pool\nappropriation environment based on bio-economic models of commercial fisheries.\n  We demonstrate that: (a) The introduced policymaker is able to achieve\ncomparable performance to the market equilibrium, showcasing the potential of\nsuch approaches in markets where the equilibrium prices can not be efficiently\ncomputed. (b) Our policymaker can notably outperform the equilibrium solution\non certain metrics, while at the same time maintaining comparable performance\nfor the remaining ones. (c) As a highlight of our findings, our policymaker is\nsignificantly more successful in maintaining resource sustainability, compared\nto the market outcome, in scarce resource environments.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 21:26:17 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Danassis", "Panayiotis", ""], ["Filos-Ratsikas", "Aris", ""], ["Faltings", "Boi", ""]]}, {"id": "2106.06198", "submitter": "Haibin Shao", "authors": "Lulu Pan, Haibin Shao, Dewei Li, and Yugeng Xi", "title": "Dynamic Event-Triggered Consensus of Multi-agent Systems on\n  Matrix-weighted Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper examines event-triggered consensus of multi-agent systems on\nmatrix-weighted networks, where the interdependencies among higher-dimensional\nstates of neighboring agents are characterized by matrix-weighted edges in the\nnetwork. Specifically, a distributed dynamic event-triggered coordination\nstrategy is proposed for this category of generalized networks, in which an\nauxiliary system is employed for each agent to dynamically adjust the trigger\nthreshold, which plays an essential role in guaranteeing that the triggering\ntime sequence does not exhibit Zeno behavior. Distributed event-triggered\ncontrol protocols are proposed to guarantee leaderless and leader-follower\nconsensus for multi-agent systems on matrix-weighted networks, respectively. It\nis shown that that the spectral properties of matrix-valued weights are crucial\nin event-triggered mechanism design for matrix-weighted networks. Finally,\nsimulation examples are provided to demonstrate the theoretical results.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 06:59:49 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Pan", "Lulu", ""], ["Shao", "Haibin", ""], ["Li", "Dewei", ""], ["Xi", "Yugeng", ""]]}, {"id": "2106.06220", "submitter": "Olivier Lindamulage De Silva", "authors": "Olivier Lindamulage De Silva, Samson Lasaulce and Irinel-Constantin\n  Mor\\u{a}rescu", "title": "On the efficiency of decentralized epidemic management and application\n  to Covid-19", "comments": "Accepted for publication in LCSS", "journal-ref": null, "doi": "10.1109/LCSYS.2021.3087101", "report-no": null, "categories": "cs.GT cs.MA cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we introduce a game that allows one to assess the potential\nloss of efficiency induced by a decentralized control or local management of a\nglobal epidemic. Each player typically represents a region or a country which\nis assumed to choose its control action to implement a tradeoff between\nsocioeconomic aspects and the health aspect. We conduct the Nash equilibrium\nanalysis of this game. Since the analysis is not trivial in general, sufficient\nconditions for existence and uniqueness are provided. Then we quantify through\nnumerical results the loss induced by decentralization, measured in terms of\nprice of anarchy (PoA) and price of connectedness (PoC). These results allow\none to clearly identify scenarios where decentralization is acceptable or not\nregarding to the retained global efficiency measures.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 08:01:17 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["De Silva", "Olivier Lindamulage", ""], ["Lasaulce", "Samson", ""], ["Mor\u0103rescu", "Irinel-Constantin", ""]]}, {"id": "2106.06224", "submitter": "Chao Wen", "authors": "Chao Wen, Miao Xu, Zhilin Zhang, Zhenzhe Zheng, Yuhui Wang, Xiangyu\n  Liu, Yu Rong, Dong Xie, Xiaoyang Tan, Chuan Yu, Jian Xu, Fan Wu, Guihai Chen,\n  Xiaoqiang Zhu", "title": "A Cooperative-Competitive Multi-Agent Framework for Auto-bidding in\n  Online Advertising", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In online advertising, auto-bidding has become an essential tool for\nadvertisers to optimize their preferred ad performance metrics by simply\nexpressing the high-level campaign objectives and constraints. Previous works\nconsider the design of auto-bidding agents from the single-agent view without\nmodeling the mutual influence between agents. In this paper, we instead\nconsider this problem from the perspective of a distributed multi-agent system,\nand propose a general Multi-Agent reinforcement learning framework for\nAuto-Bidding, namely MAAB, to learn the auto-bidding strategies. First, we\ninvestigate the competition and cooperation relation among auto-bidding agents,\nand propose temperature-regularized credit assignment for establishing a mixed\ncooperative-competitive paradigm. By carefully making a competition and\ncooperation trade-off among the agents, we can reach an equilibrium state that\nguarantees not only individual advertiser's utility but also the system\nperformance (social welfare). Second, due to the observed collusion behaviors\nof bidding low prices underlying the cooperation, we further propose bar agents\nto set a personalized bidding bar for each agent, and then to alleviate the\ndegradation of revenue. Third, to deploy MAAB to the large-scale advertising\nsystem with millions of advertisers, we propose a mean-field approach. By\ngrouping advertisers with the same objective as a mean auto-bidding agent, the\ninteractions among advertisers are greatly simplified, making it practical to\ntrain MAAB efficiently. Extensive experiments on the offline industrial dataset\nand Alibaba advertising platform demonstrate that our approach outperforms\nseveral baseline methods in terms of social welfare and guarantees the ad\nplatform's revenue.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 08:07:14 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Wen", "Chao", ""], ["Xu", "Miao", ""], ["Zhang", "Zhilin", ""], ["Zheng", "Zhenzhe", ""], ["Wang", "Yuhui", ""], ["Liu", "Xiangyu", ""], ["Rong", "Yu", ""], ["Xie", "Dong", ""], ["Tan", "Xiaoyang", ""], ["Yu", "Chuan", ""], ["Xu", "Jian", ""], ["Wu", "Fan", ""], ["Chen", "Guihai", ""], ["Zhu", "Xiaoqiang", ""]]}, {"id": "2106.06762", "submitter": "Victor-Alexandru Darvariu", "authors": "Victor-Alexandru Darvariu, Stephen Hailes, Mirco Musolesi", "title": "Solving Graph-based Public Good Games with Tree Search and Imitation\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Public goods games represent insightful settings for studying incentives for\nindividual agents to make contributions that, while costly for each of them,\nbenefit the wider society. In this work, we adopt the perspective of a central\nplanner with a global view of a network of self-interested agents and the goal\nof maximizing some desired property in the context of a best-shot public goods\ngame. Existing algorithms for this known NP-complete problem find solutions\nthat are sub-optimal and cannot optimize for criteria other than social\nwelfare.\n  In order to efficiently solve public goods games, our proposed method\ndirectly exploits the correspondence between equilibria and the Maximal\nIndependent Set (mIS) structural property of graphs. In particular, we define a\nMarkov Decision Process, which incrementally generates an mIS, and adopt a\nplanning method to search for equilibria, outperforming existing methods.\nFurthermore, we devise an imitation learning technique that uses demonstrations\nof the search to obtain a graph neural network parametrized policy which\nquickly generalizes to unseen game instances. Our evaluation results show that\nthis policy is able to reach 99.5% of the performance of the planning method\nwhile being approximately three orders of magnitude faster to evaluate on the\nlargest graphs tested. The methods presented in this work can be applied to a\nlarge class of public goods games of potentially high societal impact.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jun 2021 12:46:44 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Darvariu", "Victor-Alexandru", ""], ["Hailes", "Stephen", ""], ["Musolesi", "Mirco", ""]]}, {"id": "2106.06828", "submitter": "Ying Wen", "authors": "Ying Wen, Hui Chen, Yaodong Yang, Zheng Tian, Minne Li, Xu Chen, Jun\n  Wang", "title": "A Game-Theoretic Approach to Multi-Agent Trust Region Optimization", "comments": "A Multi-Agent Trust Region Learning (MATRL) algorithm that augments\n  the single-agent trust region policy optimization with a weak stable fixed\n  point approximated by the policy-space meta-game", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Trust region methods are widely applied in single-agent reinforcement\nlearning problems due to their monotonic performance-improvement guarantee at\nevery iteration. Nonetheless, when applied in multi-agent settings, the\nguarantee of trust region methods no longer holds because an agent's payoff is\nalso affected by other agents' adaptive behaviors. To tackle this problem, we\nconduct a game-theoretical analysis in the policy space, and propose a\nmulti-agent trust region learning method (MATRL), which enables trust region\noptimization for multi-agent learning. Specifically, MATRL finds a stable\nimprovement direction that is guided by the solution concept of Nash\nequilibrium at the meta-game level. We derive the monotonic improvement\nguarantee in multi-agent settings and empirically show the local convergence of\nMATRL to stable fixed points in the two-player rotational differential game. To\ntest our method, we evaluate MATRL in both discrete and continuous multiplayer\ngeneral-sum games including checker and switch grid worlds, multi-agent MuJoCo,\nand Atari games. Results suggest that MATRL significantly outperforms strong\nmulti-agent reinforcement learning baselines.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jun 2021 18:21:26 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Wen", "Ying", ""], ["Chen", "Hui", ""], ["Yang", "Yaodong", ""], ["Tian", "Zheng", ""], ["Li", "Minne", ""], ["Chen", "Xu", ""], ["Wang", "Jun", ""]]}, {"id": "2106.06867", "submitter": "Grace Cai", "authors": "Grace Cai, Wendy Wu, Wayne Zhao, Jiajia Zhao, Nancy Lynch", "title": "A Spatially Dependent Probabilistic Model for House Hunting in Ant\n  Colonies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Ant species such as Temnothorax albipennis select a new nest site in a\ndistributed fashion that, if modeled correctly, can serve as useful information\nfor site selection algorithms for robotic swarms and other applications.\nStudying and replicating the ants' house hunting behavior will also illuminate\nuseful distributed strategies that have evolved in nature. Many of the existing\nmodels of househunting behaviour for T. albipennis make the assumption that all\ncandidate nest sites are equally distant from the ants' home nest, or that an\nant has an equal probability of finding each candidate nest site. However,\nrealistically this is not the case, as nests that are further away from the\nhome nest and nests that are difficult to access are less likely to be found,\neven if they are of higher quality. We extend previous house-hunting models to\naccount for a pairwise distance metric between nests, compare our results to\nthose of real colonies, and use our results to examine the effects of house\nhunting in nests of different spatial orientations. Our incorporation of\ndistances in the ant model appear to match empirical data in situations where a\ndistance-quality tradeoff between nests is relevant. Furthermore, the model\ncontinues to be on par with previous house-hunting models in experiments where\nall candidate nests are equidistant from the home nest, as is typically\nassumed.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jun 2021 21:42:51 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Cai", "Grace", ""], ["Wu", "Wendy", ""], ["Zhao", "Wayne", ""], ["Zhao", "Jiajia", ""], ["Lynch", "Nancy", ""]]}, {"id": "2106.07243", "submitter": "Zhuoqing Song", "authors": "Zhuoqing Song, Lei Shi, Shi Pu, Ming Yan", "title": "Compressed Gradient Tracking for Decentralized Optimization Over General\n  Directed Networks", "comments": "working paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DC cs.LG cs.MA eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose two communication-efficient algorithms for\ndecentralized optimization over a multi-agent network with general directed\nnetwork topology. In the first part, we consider a novel\ncommunication-efficient gradient tracking based method, termed Compressed\nPush-Pull (CPP), which combines the Push-Pull method with communication\ncompression. We show that CPP is applicable to a general class of unbiased\ncompression operators and achieves linear convergence for strongly convex and\nsmooth objective functions. In the second part, we propose a broadcast-like\nversion of CPP (B-CPP), which also achieves linear convergence rate under the\nsame conditions for the objective functions. B-CPP can be applied in an\nasynchronous broadcast setting and further reduce communication costs compared\nto CPP. Numerical experiments complement the theoretical analysis and confirm\nthe effectiveness of the proposed methods.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 08:53:30 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Song", "Zhuoqing", ""], ["Shi", "Lei", ""], ["Pu", "Shi", ""], ["Yan", "Ming", ""]]}, {"id": "2106.07551", "submitter": "Ming Zhou", "authors": "Ming Zhou, Ziyu Wan, Hanjing Wang, Muning Wen, Runzhe Wu, Ying Wen,\n  Yaodong Yang, Weinan Zhang, Jun Wang", "title": "MALib: A Parallel Framework for Population-based Multi-agent\n  Reinforcement Learning", "comments": "24 pages, 17 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Population-based multi-agent reinforcement learning (PB-MARL) refers to the\nseries of methods nested with reinforcement learning (RL) algorithms, which\nproduces a self-generated sequence of tasks arising from the coupled population\ndynamics. By leveraging auto-curricula to induce a population of distinct\nemergent strategies, PB-MARL has achieved impressive success in tackling\nmulti-agent tasks. Despite remarkable prior arts of distributed RL frameworks,\nPB-MARL poses new challenges for parallelizing the training frameworks due to\nthe additional complexity of multiple nested workloads between sampling,\ntraining and evaluation involved with heterogeneous policy interactions. To\nsolve these problems, we present MALib, a scalable and efficient computing\nframework for PB-MARL. Our framework is comprised of three key components: (1)\na centralized task dispatching model, which supports the self-generated tasks\nand scalable training with heterogeneous policy combinations; (2) a programming\narchitecture named Actor-Evaluator-Learner, which achieves high parallelism for\nboth training and sampling, and meets the evaluation requirement of\nauto-curriculum learning; (3) a higher-level abstraction of MARL training\nparadigms, which enables efficient code reuse and flexible deployments on\ndifferent distributed computing paradigms. Experiments on a series of complex\ntasks such as multi-agent Atari Games show that MALib achieves throughput\nhigher than 40K FPS on a single machine with $32$ CPU cores; 5x speedup than\nRLlib and at least 3x speedup than OpenSpiel in multi-agent training tasks.\nMALib is publicly available at https://github.com/sjtu-marl/malib.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jun 2021 03:27:08 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Zhou", "Ming", ""], ["Wan", "Ziyu", ""], ["Wang", "Hanjing", ""], ["Wen", "Muning", ""], ["Wu", "Runzhe", ""], ["Wen", "Ying", ""], ["Yang", "Yaodong", ""], ["Zhang", "Weinan", ""], ["Wang", "Jun", ""]]}, {"id": "2106.07644", "submitter": "Mathieu Even", "authors": "Mathieu Even, Rapha\\\"el Berthier, Francis Bach, Nicolas Flammarion,\n  Pierre Gaillard, Hadrien Hendrikx, Laurent Massouli\\'e, Adrien Taylor", "title": "A Continuized View on Nesterov Acceleration for Stochastic Gradient\n  Descent and Randomized Gossip", "comments": "arXiv admin note: substantial text overlap with arXiv:2102.06035", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.MA math.PR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce the continuized Nesterov acceleration, a close variant of\nNesterov acceleration whose variables are indexed by a continuous time\nparameter. The two variables continuously mix following a linear ordinary\ndifferential equation and take gradient steps at random times. This continuized\nvariant benefits from the best of the continuous and the discrete frameworks:\nas a continuous process, one can use differential calculus to analyze\nconvergence and obtain analytical expressions for the parameters; and a\ndiscretization of the continuized process can be computed exactly with\nconvergence rates similar to those of Nesterov original acceleration. We show\nthat the discretization has the same structure as Nesterov acceleration, but\nwith random parameters. We provide continuized Nesterov acceleration under\ndeterministic as well as stochastic gradients, with either additive or\nmultiplicative noise. Finally, using our continuized framework and expressing\nthe gossip averaging problem as the stochastic minimization of a certain energy\nfunction, we provide the first rigorous acceleration of asynchronous gossip\nalgorithms.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 08:35:55 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Even", "Mathieu", ""], ["Berthier", "Rapha\u00ebl", ""], ["Bach", "Francis", ""], ["Flammarion", "Nicolas", ""], ["Gaillard", "Pierre", ""], ["Hendrikx", "Hadrien", ""], ["Massouli\u00e9", "Laurent", ""], ["Taylor", "Adrien", ""]]}, {"id": "2106.07728", "submitter": "Minae Kwon", "authors": "Minae Kwon, Siddharth Karamcheti, Mariano-Florentino Cuellar, Dorsa\n  Sadigh", "title": "Targeted Data Acquisition for Evolving Negotiation Agents", "comments": "The Thirty-eighth International Conference on Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Successful negotiators must learn how to balance optimizing for self-interest\nand cooperation. Yet current artificial negotiation agents often heavily depend\non the quality of the static datasets they were trained on, limiting their\ncapacity to fashion an adaptive response balancing self-interest and\ncooperation. For this reason, we find that these agents can achieve either high\nutility or cooperation, but not both. To address this, we introduce a targeted\ndata acquisition framework where we guide the exploration of a reinforcement\nlearning agent using annotations from an expert oracle. The guided exploration\nincentivizes the learning agent to go beyond its static dataset and develop new\nnegotiation strategies. We show that this enables our agents to obtain\nhigher-reward and more Pareto-optimal solutions when negotiating with both\nsimulated and human partners compared to standard supervised learning and\nreinforcement learning methods. This trend additionally holds when comparing\nagents using our targeted data acquisition framework to variants of agents\ntrained with a mix of supervised learning and reinforcement learning, or to\nagents using tailored reward functions that explicitly optimize for utility and\nPareto-optimality.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 19:45:59 GMT"}, {"version": "v2", "created": "Wed, 16 Jun 2021 17:49:13 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Kwon", "Minae", ""], ["Karamcheti", "Siddharth", ""], ["Cuellar", "Mariano-Florentino", ""], ["Sadigh", "Dorsa", ""]]}, {"id": "2106.07892", "submitter": "Juan Rojas", "authors": "Guanglin Ji, Junyan Yan, Jingxin Du, Wanquan Yan, Jibiao Chen,\n  Yongkang Lu, Juan Rojas, and Shing Shin Cheng", "title": "Towards Safe Control of Continuum Manipulator Using Shielded Multiagent\n  Reinforcement Learning", "comments": "8 pages, 12 figs, 1 table, 2 pseudo-code", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.MA", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Continuum robotic manipulators are increasingly adopted in minimal invasive\nsurgery. However, their nonlinear behavior is challenging to model accurately,\nespecially when subject to external interaction, potentially leading to poor\ncontrol performance. In this letter, we investigate the feasibility of adopting\na model-free multiagent reinforcement learning (RL), namely multiagent deep Q\nnetwork (MADQN), to control a 2-degree of freedom (DoF) cable-driven continuum\nsurgical manipulator. The control of the robot is formulated as a one-DoF, one\nagent problem in the MADQN framework to improve the learning efficiency.\nCombined with a shielding scheme that enables dynamic variation of the action\nset boundary, MADQN leads to efficient and importantly safer control of the\nrobot. Shielded MADQN enabled the robot to perform point and trajectory\ntracking with submillimeter root mean square errors under external loads, soft\nobstacles, and rigid collision, which are common interaction scenarios\nencountered by surgical manipulators. The controller was further proven to be\neffective in a miniature continuum robot with high structural nonlinearitiy,\nachieving trajectory tracking with submillimeter accuracy under external\npayload.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 05:55:05 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Ji", "Guanglin", ""], ["Yan", "Junyan", ""], ["Du", "Jingxin", ""], ["Yan", "Wanquan", ""], ["Chen", "Jibiao", ""], ["Lu", "Yongkang", ""], ["Rojas", "Juan", ""], ["Cheng", "Shing Shin", ""]]}, {"id": "2106.08413", "submitter": "Lily Xu", "authors": "Lily Xu, Andrew Perrault, Fei Fang, Haipeng Chen, Milind Tambe", "title": "Robust Reinforcement Learning Under Minimax Regret for Green Security", "comments": "Accepted at the Conference on Uncertainty in Artificial Intelligence\n  (UAI) 2021. 11 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Green security domains feature defenders who plan patrols in the face of\nuncertainty about the adversarial behavior of poachers, illegal loggers, and\nillegal fishers. Importantly, the deterrence effect of patrols on adversaries'\nfuture behavior makes patrol planning a sequential decision-making problem.\nTherefore, we focus on robust sequential patrol planning for green security\nfollowing the minimax regret criterion, which has not been considered in the\nliterature. We formulate the problem as a game between the defender and nature\nwho controls the parameter values of the adversarial behavior and design an\nalgorithm MIRROR to find a robust policy. MIRROR uses two reinforcement\nlearning-based oracles and solves a restricted game considering limited\ndefender strategies and parameter values. We evaluate MIRROR on real-world\npoaching data.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 20:11:12 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Xu", "Lily", ""], ["Perrault", "Andrew", ""], ["Fang", "Fei", ""], ["Chen", "Haipeng", ""], ["Tambe", "Milind", ""]]}, {"id": "2106.08609", "submitter": "Massimo Cencini Dr.", "authors": "Francesco Borra and Luca Biferale and Massimo Cencini and Antonio\n  Celani", "title": "Reinforcement learning for pursuit and evasion of microswimmers at low\n  Reynolds number", "comments": "6 pages, 3 figures (Supplementary Material in ancillary directory)", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.flu-dyn cs.LG cs.MA nlin.CD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aquatic organisms can use hydrodynamic cues to navigate, find their preys and\nescape from predators. We consider a model of two competing microswimmers\nengaged in a pursue-evasion task while immersed in a low-Reynolds-number\nenvironment. The players have limited abilities: they can only sense\nhydrodynamic disturbances, which provide some cue about the opponent's\nposition, and perform simple manoeuvres. The goal of the pursuer is to\ncapturethe evader in the shortest possible time. Conversely the evader aims at\ndeferring capture as much as possible. We show that by means of Reinforcement\nLearning the players find efficient and physically explainable strategies which\nnon-trivially exploit the hydrodynamic environment. This Letter offers a\nproof-of-concept for the use of Reinforcement Learning to discover\nprey-predator strategies in aquatic environments, with potential applications\nto underwater robotics.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 08:08:40 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Borra", "Francesco", ""], ["Biferale", "Luca", ""], ["Cencini", "Massimo", ""], ["Celani", "Antonio", ""]]}, {"id": "2106.08853", "submitter": "Joshua Kavner", "authors": "Joshua Kavner, Lirong Xia", "title": "Strategic Behavior is Bliss: Iterative Voting Improves Social Welfare", "comments": "21 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work in iterative voting has defined the difference in social welfare\nbetween the truthful winner and worst-case equilibrium winner, due to repeated\nstrategic manipulations, known as the additive dynamic price of anarchy\n(ADPoA). While all iterative plurality winners have been shown to differ from\ntruth by at most one initial vote, it is less understood how agents' welfare\nchanges in equilibrium. To this end, we differentiate agents' utility from\ntheir iteration mechanism and determine iterative plurality's ADPoA in the\nworst- and average-case. We first negatively demonstrate that the worst-case\nADPoA is linear in the number of agents. In expectation, rather, equilibrium\nwinners have a constant order welfare advantage over the truthful winner. Our\npositive results illustrate the prospect for social welfare to increase due to\nstrategic manipulation.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 15:18:37 GMT"}, {"version": "v2", "created": "Fri, 18 Jun 2021 19:34:45 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Kavner", "Joshua", ""], ["Xia", "Lirong", ""]]}, {"id": "2106.09012", "submitter": "Eugene Vinitsky", "authors": "Eugene Vinitsky, Raphael K\\\"oster, John P. Agapiou, Edgar\n  Du\\'e\\~nez-Guzm\\'an, Alexander Sasha Vezhnevets, Joel Z. Leibo", "title": "A learning agent that acquires social norms from public sanctions in\n  decentralized multi-agent settings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Society is characterized by the presence of a variety of social norms:\ncollective patterns of sanctioning that can prevent miscoordination and\nfree-riding. Inspired by this, we aim to construct learning dynamics where\npotentially beneficial social norms can emerge. Since social norms are\nunderpinned by sanctioning, we introduce a training regime where agents can\naccess all sanctioning events but learning is otherwise decentralized. This\nsetting is technologically interesting because sanctioning events may be the\nonly available public signal in decentralized multi-agent systems where reward\nor policy-sharing is infeasible or undesirable. To achieve collective action in\nthis setting we construct an agent architecture containing a classifier module\nthat categorizes observed behaviors as approved or disapproved, and a\nmotivation to punish in accord with the group. We show that social norms emerge\nin multi-agent systems containing this agent and investigate the conditions\nunder which this helps them achieve socially beneficial outcomes.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 17:57:41 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Vinitsky", "Eugene", ""], ["K\u00f6ster", "Raphael", ""], ["Agapiou", "John P.", ""], ["Du\u00e9\u00f1ez-Guzm\u00e1n", "Edgar", ""], ["Vezhnevets", "Alexander Sasha", ""], ["Leibo", "Joel Z.", ""]]}, {"id": "2106.09435", "submitter": "Luke Marris", "authors": "Luke Marris, Paul Muller, Marc Lanctot, Karl Tuyls, Thore Graepel", "title": "Multi-Agent Training beyond Zero-Sum with Correlated Equilibrium\n  Meta-Solvers", "comments": "ICML 2021, 9 pages, coded implementation available in\n  https://github.com/deepmind/open_spiel/ (jpsro.py in examples)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two-player, constant-sum games are well studied in the literature, but there\nhas been limited progress outside of this setting. We propose Joint\nPolicy-Space Response Oracles (JPSRO), an algorithm for training agents in\nn-player, general-sum extensive form games, which provably converges to an\nequilibrium. We further suggest correlated equilibria (CE) as promising\nmeta-solvers, and propose a novel solution concept Maximum Gini Correlated\nEquilibrium (MGCE), a principled and computationally efficient family of\nsolutions for solving the correlated equilibrium selection problem. We conduct\nseveral experiments using CE meta-solvers for JPSRO and demonstrate convergence\non n-player, general-sum games.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 12:34:18 GMT"}, {"version": "v2", "created": "Tue, 22 Jun 2021 16:43:13 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Marris", "Luke", ""], ["Muller", "Paul", ""], ["Lanctot", "Marc", ""], ["Tuyls", "Karl", ""], ["Graepel", "Thore", ""]]}, {"id": "2106.09461", "submitter": "Neel Gandhi Gandhi", "authors": "Neel Gandhi, Shakti Mishra", "title": "Modelling resource allocation in uncertain system environment through\n  deep reinforcement learning", "comments": "Accepted at IRMAS'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA cs.RO cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Reinforcement Learning has applications in field of mechatronics, robotics,\nand other resource-constrained control system. Problem of resource allocation\nis primarily solved using traditional predefined techniques and modern deep\nlearning methods. The drawback of predefined and most deep learning methods for\nresource allocation is failing to meet the requirements in cases of uncertain\nsystem environment. We can approach problem of resource allocation in uncertain\nsystem environment alongside following certain criteria using deep\nreinforcement learning. Also, reinforcement learning has ability for adapting\nto new uncertain environment for prolonged period of time. The paper provides a\ndetailed comparative analysis on various deep reinforcement learning methods by\napplying different components to modify architecture of reinforcement learning\nwith use of noisy layers, prioritized replay, bagging, duelling networks, and\nother related combination to obtain improvement in terms of performance and\nreduction of computational cost. The paper identifies problem of resource\nallocation in uncertain environment could be effectively solved using Noisy\nBagging duelling double deep Q network achieving efficiency of 97.7% by\nmaximizing reward with significant exploration in given simulated environment\nfor resource allocation.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 13:13:34 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Gandhi", "Neel", ""], ["Mishra", "Shakti", ""]]}, {"id": "2106.09543", "submitter": "Naroa Coretti Sanchez", "authors": "Naroa Coretti S\\'anchez, Juan M\\'ugica Gonz\\'alez, Luis Alonso Pastor,\n  Kent Larson", "title": "Future mobility as a bio-inspired collaborative system", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.RO cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The current trends towards vehicle-sharing, electrification, and autonomy are\npredicted to transform mobility. Combined appropriately, they have the\npotential of significantly improving urban mobility. However, what will come\nafter most vehicles are shared, electric, and autonomous remains an open\nquestion, especially regarding the interactions between vehicles and how these\ninteractions will impact system-level behaviour. Inspired by nature and\nsupported by swarm robotics and vehicle platooning models, this paper proposes\na future mobility in which shared, electric, and autonomous vehicles behave as\na bio-inspired collaborative system. The collaboration between vehicles will\nlead to a system-level behaviour analogous to natural swarms. Natural swarms\ncan divide tasks, cluster, build together, or transport cooperatively. In this\nfuture mobility, vehicles will cluster by connecting either physically or\nvirtually, which will enable the possibility of sharing energy, data or\ncomputational power, provide services or transfer cargo, among others. Vehicles\nwill collaborate either with vehicles that are part of the same fleet, or with\nany other vehicle on the road, by finding mutualistic relationships that\nbenefit both parties. The field of swarm robotics has already translated some\nof the behaviours from natural swarms to artificial systems and, if we further\ntranslate these concepts into urban mobility, exciting ideas emerge. Within\nmobility-related research, the coordinated movement proposed in vehicle\nplatooning models can be seen as a first step towards collaborative mobility.\nThis paper contributes with the proposal of a framework for future mobility\nthat integrates current research and mobility trends in a novel and unique way.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 15:13:18 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["S\u00e1nchez", "Naroa Coretti", ""], ["Gonz\u00e1lez", "Juan M\u00fagica", ""], ["Pastor", "Luis Alonso", ""], ["Larson", "Kent", ""]]}, {"id": "2106.09694", "submitter": "Naroa Coretti Sanchez", "authors": "Naroa Coretti S\\'anchez, I\\~nigo Martinez, Luis Alonso Pastor, Kent\n  Larson", "title": "Simulation study on the fleet performance of shared autonomous bicycles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rethinking cities is now more imperative than ever, as society faces global\nchallenges such as population growth and climate change. The design of cities\ncan not be abstracted from the design of its mobility system, and, therefore,\nefficient solutions must be found to transport people and goods throughout the\ncity in an ecological way. An autonomous bicycle-sharing system would combine\nthe most relevant benefits of vehicle sharing, electrification, autonomy, and\nmicro-mobility, increasing the efficiency and convenience of bicycle-sharing\nsystems and incentivizing more people to bike and enjoy their cities in an\nenvironmentally friendly way. Due to the uniqueness and radical novelty of\nintroducing autonomous driving technology into bicycle-sharing systems and the\ninherent complexity of these systems, there is a need to quantify the potential\nimpact of autonomy on fleet performance and user experience. This paper\npresents an ad-hoc agent-based simulator that provides an in-depth\nunderstanding of the fleet behavior of autonomous bicycle-sharing systems in\nrealistic scenarios, including a rebalancing system based on demand prediction.\nIn addition, this work describes the impact of different parameters on system\nefficiency and service quality and quantifies the extent to which an autonomous\nsystem would outperform current bicycle-sharing schemes. The obtained results\nshow that with a fleet size three and a half times smaller than a station-based\nsystem and eight times smaller than a dockless system, an autonomous system can\nprovide overall improved performance and user experience even with no\nrebalancing. These findings indicate that the remarkable efficiency of an\nautonomous bicycle-sharing system could compensate for the additional cost of\nautonomous bicycles.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 17:47:08 GMT"}, {"version": "v2", "created": "Mon, 21 Jun 2021 15:07:57 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["S\u00e1nchez", "Naroa Coretti", ""], ["Martinez", "I\u00f1igo", ""], ["Pastor", "Luis Alonso", ""], ["Larson", "Kent", ""]]}, {"id": "2106.09749", "submitter": "Teshan Liyanage", "authors": "Teshan Liyanage, Subha Fernando", "title": "Optimizing robotic swarm based construction tasks", "comments": "4 pages, 3 figures, submitted to 2021 7th International Conference on\n  Control, Automation and Robotics (ICCAR) Singapore", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Social insects in nature such as ants, termites and bees construct their\ncolonies collaboratively in a very efficient process. In these swarms, each\ninsect contributes to the construction task individually showing redundant and\nparallel behavior of individual entities. But the robotics adaptations of these\nswarm's behaviors haven't yet made it to the real world at a large enough scale\nof commonly being used due to the limitations in the existing approaches to the\nswarm robotics construction. This paper presents an approach that combines the\nexisting swarm construction approaches which results in a swarm robotic system,\ncapable of constructing a given 2 dimensional shape in an optimized manner.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 18:07:01 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Liyanage", "Teshan", ""], ["Fernando", "Subha", ""]]}, {"id": "2106.09825", "submitter": "Keyang He", "authors": "Keyang He, Prashant Doshi, Bikramjit Banerjee", "title": "Many Agent Reinforcement Learning Under Partial Observability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent renewed interest in multi-agent reinforcement learning (MARL) has\ngenerated an impressive array of techniques that leverage deep reinforcement\nlearning, primarily actor-critic architectures, and can be applied to a limited\nrange of settings in terms of observability and communication. However, a\ncontinuing limitation of much of this work is the curse of dimensionality when\nit comes to representations based on joint actions, which grow exponentially\nwith the number of agents. In this paper, we squarely focus on this challenge\nof scalability. We apply the key insight of action anonymity, which leads to\npermutation invariance of joint actions, to two recently presented deep MARL\nalgorithms, MADDPG and IA2C, and compare these instantiations to another recent\ntechnique that leverages action anonymity, viz., mean-field MARL. We show that\nour instantiations can learn the optimal behavior in a broader class of agent\nnetworks than the mean-field method, using a recently introduced pragmatic\ndomain.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 21:24:29 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["He", "Keyang", ""], ["Doshi", "Prashant", ""], ["Banerjee", "Bikramjit", ""]]}, {"id": "2106.10015", "submitter": "Anil Yaman", "authors": "Anil Yaman, Nicolas Bredeche, Onur \\c{C}aylak, Joel Z. Leibo, Sang Wan\n  Lee", "title": "Meta-control of social learning strategies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.MA cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social learning, copying other's behavior without actual experience, offers a\ncost-effective means of knowledge acquisition. However, it raises the\nfundamental question of which individuals have reliable information: successful\nindividuals versus the majority. The former and the latter are known\nrespectively as success-based and conformist social learning strategies. We\nshow here that while the success-based strategy fully exploits the benign\nenvironment of low uncertainly, it fails in uncertain environments. On the\nother hand, the conformist strategy can effectively mitigate this adverse\neffect. Based on these findings, we hypothesized that meta-control of\nindividual and social learning strategies provides effective and\nsample-efficient learning in volatile and uncertain environments. Simulations\non a set of environments with various levels of volatility and uncertainty\nconfirmed our hypothesis. The results imply that meta-control of social\nlearning affords agents the leverage to resolve environmental uncertainty with\nminimal exploration cost, by exploiting others' learning as an external\nknowledge base.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 09:17:21 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Yaman", "Anil", ""], ["Bredeche", "Nicolas", ""], ["\u00c7aylak", "Onur", ""], ["Leibo", "Joel Z.", ""], ["Lee", "Sang Wan", ""]]}, {"id": "2106.10110", "submitter": "Fangwei Zhong", "authors": "Fangwei Zhong, Peng Sun, Wenhan Luo, Tingyun Yan, Yizhou Wang", "title": "Towards Distraction-Robust Active Visual Tracking", "comments": "To appear in ICML2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In active visual tracking, it is notoriously difficult when distracting\nobjects appear, as distractors often mislead the tracker by occluding the\ntarget or bringing a confusing appearance. To address this issue, we propose a\nmixed cooperative-competitive multi-agent game, where a target and multiple\ndistractors form a collaborative team to play against a tracker and make it\nfail to follow. Through learning in our game, diverse distracting behaviors of\nthe distractors naturally emerge, thereby exposing the tracker's weakness,\nwhich helps enhance the distraction-robustness of the tracker. For effective\nlearning, we then present a bunch of practical methods, including a reward\nfunction for distractors, a cross-modal teacher-student learning strategy, and\na recurrent attention mechanism for the tracker. The experimental results show\nthat our tracker performs desired distraction-robust active visual tracking and\ncan be well generalized to unseen environments. We also show that the\nmulti-agent game can be used to adversarially test the robustness of trackers.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 13:05:25 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Zhong", "Fangwei", ""], ["Sun", "Peng", ""], ["Luo", "Wenhan", ""], ["Yan", "Tingyun", ""], ["Wang", "Yizhou", ""]]}, {"id": "2106.10192", "submitter": "Muhammad Najib", "authors": "Julian Gutierrez, Muhammad Najib, Giuseppe Perelli, Michael Wooldridge", "title": "Equilibrium Design for Concurrent Games", "comments": "CONCUR 2019 with appendix", "journal-ref": "Vol. 140, 2019, 22:1--22:16", "doi": "10.4230/LIPIcs.CONCUR.2019.22", "report-no": null, "categories": "cs.GT cs.AI cs.LO cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In game theory, mechanism design is concerned with the design of incentives\nso that a desired outcome of the game can be achieved. In this paper, we study\nthe design of incentives so that a desirable equilibrium is obtained, for\ninstance, an equilibrium satisfying a given temporal logic property -- a\nproblem that we call equilibrium design. We base our study on a framework where\nsystem specifications are represented as temporal logic formulae, games as\nquantitative concurrent game structures, and players' goals as mean-payoff\nobjectives. In particular, we consider system specifications given by LTL and\nGR(1) formulae, and show that implementing a mechanism to ensure that a given\ntemporal logic property is satisfied on some/every Nash equilibrium of the\ngame, whenever such a mechanism exists, can be done in PSPACE for LTL\nproperties and in NP/$\\Sigma^{P}_{2}$ for GR(1) specifications. We also study\nthe complexity of various related decision and optimisation problems, such as\noptimality and uniqueness of solutions, and show that the complexities of all\nsuch problems lie within the polynomial hierarchy. As an application,\nequilibrium design can be used as an alternative solution to the rational\nsynthesis and verification problems for concurrent games with mean-payoff\nobjectives whenever no solution exists, or as a technique to repair, whenever\npossible, concurrent games with undesirable rational outcomes (Nash equilibria)\nin an optimal way.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 15:45:45 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Gutierrez", "Julian", ""], ["Najib", "Muhammad", ""], ["Perelli", "Giuseppe", ""], ["Wooldridge", "Michael", ""]]}, {"id": "2106.10886", "submitter": "EPTCS", "authors": "Joseph Halpern (Cornell University), Andr\\'es Perea (Maastricht\n  University)", "title": "Proceedings Eighteenth Conference on Theoretical Aspects of Rationality\n  and Knowledge", "comments": null, "journal-ref": "EPTCS 335, 2021", "doi": "10.4204/EPTCS.335", "report-no": null, "categories": "cs.GT cs.AI cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The TARK conference (Theoretical Aspects of Rationality and Knowledge) is a\nbiannual conference that aims to bring together researchers from a wide variety\nof fields, including computer science, artificial intelligence, game theory,\ndecision theory, philosophy, logic, linguistics, and cognitive science. Its\ngoal is to further our understanding of interdisciplinary issues involving\nreasoning about rationality and knowledge.\n  Topics of interest include, but are not limited to, semantic models for\nknowledge, belief, awareness and uncertainty, bounded rationality and\nresource-bounded reasoning, commonsense epistemic reasoning, epistemic logic,\nepistemic game theory, knowledge and action, applications of reasoning about\nknowledge and other mental states, belief revision, and foundations of\nmulti-agent systems.\n  These proceedings contain the papers that have been accepted for presentation\nat the Eighteenth Conference on Theoretical Aspects of Rationality and\nKnowledge (TARK 2021), held between June 25 and June 27, 2021, at Tsinghua\nUniversity at Beijing, China.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 07:01:14 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Halpern", "Joseph", "", "Cornell University"], ["Perea", "Andr\u00e9s", "", "Maastricht\n  University"]]}, {"id": "2106.11156", "submitter": "Niko Grupen", "authors": "Niko A. Grupen, Daniel D. Lee, Bart Selman", "title": "Curriculum-Driven Multi-Agent Learning and the Role of Implicit\n  Communication in Teamwork", "comments": "18 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a curriculum-driven learning strategy for solving difficult\nmulti-agent coordination tasks. Our method is inspired by a study of animal\ncommunication, which shows that two straightforward design features (mutual\nreward and decentralization) support a vast spectrum of communication protocols\nin nature. We highlight the importance of similarly interpreting emergent\ncommunication as a spectrum. We introduce a toroidal, continuous-space\npursuit-evasion environment and show that naive decentralized learning does not\nperform well. We then propose a novel curriculum-driven strategy for\nmulti-agent learning. Experiments with pursuit-evasion show that our approach\nenables decentralized pursuers to learn to coordinate and capture a superior\nevader, significantly outperforming sophisticated analytical policies. We argue\nthrough additional quantitative analysis -- including influence-based measures\nsuch as Instantaneous Coordination -- that emergent implicit communication\nplays a large role in enabling superior levels of coordination.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 14:54:07 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Grupen", "Niko A.", ""], ["Lee", "Daniel D.", ""], ["Selman", "Bart", ""]]}, {"id": "2106.11345", "submitter": "Clod\\'eric Mars", "authors": "AI Redefined, Sai Krishna Gottipati, Sagar Kurandwad, Clod\\'eric Mars,\n  Gregory Szriftgiser and Fran\\c{c}ois Chabot", "title": "Cogment: Open Source Framework For Distributed Multi-actor Training,\n  Deployment & Operations", "comments": "16 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.LG cs.MA", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Involving humans directly for the benefit of AI agents' training is getting\ntraction thanks to several advances in reinforcement learning and\nhuman-in-the-loop learning. Humans can provide rewards to the agent,\ndemonstrate tasks, design a curriculum, or act in the environment, but these\nbenefits also come with architectural, functional design and engineering\ncomplexities. We present Cogment, a unifying open-source framework that\nintroduces an actor formalism to support a variety of humans-agents\ncollaboration typologies and training approaches. It is also scalable out of\nthe box thanks to a distributed micro service architecture, and offers\nsolutions to the aforementioned complexities.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 18:21:26 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Redefined", "AI", ""], ["Gottipati", "Sai Krishna", ""], ["Kurandwad", "Sagar", ""], ["Mars", "Clod\u00e9ric", ""], ["Szriftgiser", "Gregory", ""], ["Chabot", "Fran\u00e7ois", ""]]}, {"id": "2106.11365", "submitter": "Hang Ma", "authors": "Ziyuan Ma, Yudong Luo, Hang Ma", "title": "Distributed Heuristic Multi-Agent Path Finding with Communication", "comments": "Published at ICRA 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-Agent Path Finding (MAPF) is essential to large-scale robotic systems.\nRecent methods have applied reinforcement learning (RL) to learn decentralized\npolices in partially observable environments. A fundamental challenge of\nobtaining collision-free policy is that agents need to learn cooperation to\nhandle congested situations. This paper combines communication with deep\nQ-learning to provide a novel learning based method for MAPF, where agents\nachieve cooperation via graph convolution. To guide RL algorithm on\nlong-horizon goal-oriented tasks, we embed the potential choices of shortest\npaths from single source as heuristic guidance instead of using a specific path\nas in most existing works. Our method treats each agent independently and\ntrains the model from a single agent's perspective. The final trained policy is\napplied to each agent for decentralized execution. The whole system is\ndistributed during training and is trained under a curriculum learning\nstrategy. Empirical evaluation in obstacle-rich environment indicates the high\nsuccess rate with low average step of our method.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 18:50:58 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Ma", "Ziyuan", ""], ["Luo", "Yudong", ""], ["Ma", "Hang", ""]]}, {"id": "2106.11454", "submitter": "Hang Ma", "authors": "Hang Ma", "title": "A Competitive Analysis of Online Multi-Agent Path Finding", "comments": "Published at ICAPS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study online Multi-Agent Path Finding (MAPF), where new agents are\nconstantly revealed over time and all agents must find collision-free paths to\ntheir given goal locations. We generalize existing complexity results of\n(offline) MAPF to online MAPF. We classify online MAPF algorithms into\ndifferent categories based on (1) controllability (the set of agents that they\ncan plan paths for at each time) and (2) rationality (the quality of paths they\nplan) and study the relationships between them. We perform a competitive\nanalysis for each category of online MAPF algorithms with respect to\ncommonly-used objective functions. We show that a naive algorithm that routes\nnewly-revealed agents one at a time in sequence achieves a competitive ratio\nthat is asymptotically bounded from both below and above by the number of\nagents with respect to flowtime and makespan. We then show a counter-intuitive\nresult that, if rerouting of previously-revealed agents is not allowed, any\nrational online MAPF algorithms, including ones that plan optimal paths for all\nnewly-revealed agents, have the same asymptotic competitive ratio as the naive\nalgorithm, even on 2D 4-neighbor grids. We also derive constant lower bounds on\nthe competitive ratio of any rational online MAPF algorithms that allow\nrerouting. The results thus provide theoretical insights into the effectiveness\nof using MAPF algorithms in an online setting for the first time.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 00:05:29 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Ma", "Hang", ""]]}, {"id": "2106.11492", "submitter": "EPTCS", "authors": "Carlos Areces (FAMAF, Universidad Nacional de C\\'ordoba, and CONICET,\n  Argentina), Raul Fervari (FAMAF, Universidad Nacional de C\\'ordoba, and\n  CONICET, Argentina), Andr\\'es R. Saravia (FAMAF, Universidad Nacional de\n  C\\'ordoba, and CONICET, Argentina), Fernando R. Vel\\'azquez-Quesada (ILLC,\n  Universiteit van Amsterdam, The Netherlands)", "title": "Uncertainty-Based Semantics for Multi-Agent Knowing How Logics", "comments": "In Proceedings TARK 2021, arXiv:2106.10886", "journal-ref": "EPTCS 335, 2021, pp. 23-37", "doi": "10.4204/EPTCS.335.3", "report-no": null, "categories": "cs.LO cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce a new semantics for a multi-agent epistemic operator of knowing\nhow, based on an indistinguishability relation between plans. Our proposal is,\narguably, closer to the standard presentation of knowing that modalities in\nclassical epistemic logic. We study the relationship between this semantics and\nprevious approaches, showing that our setting is general enough to capture\nthem. We also define a sound and complete axiomatization, and investigate the\ncomputational complexity of its model checking and satisfiability problems.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 02:44:09 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Areces", "Carlos", "", "FAMAF, Universidad Nacional de C\u00f3rdoba, and CONICET,\n  Argentina"], ["Fervari", "Raul", "", "FAMAF, Universidad Nacional de C\u00f3rdoba, and\n  CONICET, Argentina"], ["Saravia", "Andr\u00e9s R.", "", "FAMAF, Universidad Nacional de\n  C\u00f3rdoba, and CONICET, Argentina"], ["Vel\u00e1zquez-Quesada", "Fernando R.", "", "ILLC,\n  Universiteit van Amsterdam, The Netherlands"]]}, {"id": "2106.11499", "submitter": "EPTCS", "authors": "Krisztina Fruzsa (TU Wien), Roman Kuznets (TU Wien), Ulrich Schmid (TU\n  Wien)", "title": "Fire!", "comments": "In Proceedings TARK 2021, arXiv:2106.10886", "journal-ref": "EPTCS 335, 2021, pp. 139-153", "doi": "10.4204/EPTCS.335.13", "report-no": null, "categories": "cs.DC cs.LO cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we provide an epistemic analysis of a simple variant of the\nfundamental consistent broadcasting primitive for byzantine fault-tolerant\nasynchronous distributed systems. Our Firing Rebels with Relay (FRR) primitive\nenables agents with a local preference for acting/not acting to trigger an\naction (FIRE) at all correct agents, in an all-or-nothing fashion. By using the\nepistemic reasoning framework for byzantine multi-agent systems introduced in\nour TARK'19 paper, we develop the necessary and sufficient state of knowledge\nthat needs to be acquired by the agents in order to FIRE. It involves eventual\ncommon hope (a modality related to belief), which we show to be attained\nalready by achieving eventual mutual hope in the case of FRR. We also identify\nsubtle variations of the necessary and sufficient state of knowledge for FRR\nfor different assumptions on the local preferences.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 02:45:51 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Fruzsa", "Krisztina", "", "TU Wien"], ["Kuznets", "Roman", "", "TU Wien"], ["Schmid", "Ulrich", "", "TU\n  Wien"]]}, {"id": "2106.11500", "submitter": "EPTCS", "authors": "Satoshi Fukuda (Department of Decision Sciences and IGIER, Bocconi\n  University)", "title": "Are the Players in an Interactive Belief Model Meta-certain of the Model\n  Itself?", "comments": "In Proceedings TARK 2021, arXiv:2106.10886", "journal-ref": "EPTCS 335, 2021, pp. 155-170", "doi": "10.4204/EPTCS.335.14", "report-no": null, "categories": "cs.GT cs.AI cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In an interactive belief model, are the players \"commonly meta-certain\" of\nthe model itself? This paper formalizes such implicit \"common meta-certainty\"\nassumption. To that end, the paper expands the objects of players' beliefs from\nevents to functions defined on the underlying states. Then, the paper defines a\nplayer's belief-generating map: it associates, with each state, whether a\nplayer believes each event at that state. The paper formalizes what it means\nby: \"a player is (meta-)certain of her own belief-generating map\" or \"the\nplayers are (meta-)certain of the profile of belief-generating maps (i.e., the\nmodel).\" The paper shows: a player is (meta-)certain of her own\nbelief-generating map if and only if her beliefs are introspective. The players\nare commonly (meta-)certain of the model if and only if, for any event which\nsome player i believes at some state, it is common belief at the state that\nplayer i believes the event. This paper then asks whether the \"common\nmeta-certainty\" assumption is needed for an epistemic characterization of\ngame-theoretic solution concepts. The paper shows: if each player is logical\nand (meta-)certain of her own strategy and belief-generating map, then each\nplayer correctly believes her own rationality. Consequently, common belief in\nrationality alone leads to actions that survive iterated elimination of\nstrictly dominated actions.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 02:46:07 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Fukuda", "Satoshi", "", "Department of Decision Sciences and IGIER, Bocconi\n  University"]]}, {"id": "2106.11502", "submitter": "EPTCS", "authors": "Wesley H. Holliday (University of California, Berkeley), Eric Pacuit\n  (University of Maryland)", "title": "Measuring Violations of Positive Involvement in Voting", "comments": "In Proceedings TARK 2021, arXiv:2106.10886", "journal-ref": "EPTCS 335, 2021, pp. 189-209", "doi": "10.4204/EPTCS.335.17", "report-no": null, "categories": "cs.GT cs.MA econ.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the context of computational social choice, we study voting methods that\nassign a set of winners to each profile of voter preferences. A voting method\nsatisfies the property of positive involvement (PI) if for any election in\nwhich a candidate x would be among the winners, adding another voter to the\nelection who ranks x first does not cause x to lose. Surprisingly, a number of\nstandard voting methods violate this natural property. In this paper, we\ninvestigate different ways of measuring the extent to which a voting method\nviolates PI, using computer simulations. We consider the probability (under\ndifferent probability models for preferences) of PI violations in randomly\ndrawn profiles vs. profile-coalition pairs (involving coalitions of different\nsizes). We argue that in order to choose between a voting method that satisfies\nPI and one that does not, we should consider the probability of PI violation\nconditional on the voting methods choosing different winners. We should also\nrelativize the probability of PI violation to what we call voter potency, the\nprobability that a voter causes a candidate to lose. Although absolute\nfrequencies of PI violations may be low, after this conditioning and\nrelativization, we see that under certain voting methods that violate PI, much\nof a voter's potency is turned against them - in particular, against their\ndesire to see their favorite candidate elected.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 02:46:37 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Holliday", "Wesley H.", "", "University of California, Berkeley"], ["Pacuit", "Eric", "", "University of Maryland"]]}, {"id": "2106.11503", "submitter": "EPTCS", "authors": "Gabriel Istrate (West University of Timisoara, Romania)", "title": "Game-Theoretic Models of Moral and Other-Regarding Agents (extended\n  abstract)", "comments": "In Proceedings TARK 2021, arXiv:2106.10886. This is the extended\n  abstract that appears in the Proceedings of TARK 2021. A longer, more\n  complete, version of the paper is available as preprint arXiv:2012.09759", "journal-ref": "EPTCS 335, 2021, pp. 213-227", "doi": "10.4204/EPTCS.335.19", "report-no": null, "categories": "cs.GT cs.AI cs.MA cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We investigate Kantian equilibria in finite normal form games, a class of\nnon-Nashian, morally motivated courses of action that was recently proposed in\nthe economics literature. We highlight a number of problems with such\nequilibria, including computational intractability, a high price of\nmiscoordination, and problematic extension to general normal form games. We\ngive such a generalization based on concept of program equilibria, and point\nout that that a practically relevant generalization may not exist. To remedy\nthis we propose some general, intuitive, computationally tractable,\nother-regarding equilibria that are special cases Kantian equilibria, as well\nas a class of courses of action that interpolates between purely self-regarding\nand Kantian behavior.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 02:46:52 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Istrate", "Gabriel", "", "West University of Timisoara, Romania"]]}, {"id": "2106.11506", "submitter": "EPTCS", "authors": "Aldo Iv\\'an Ram\\'irez Abarca (Utrecht University), Jan Broersen\n  (Utrecht University)", "title": "A Deontic Stit Logic Based on Beliefs and Expected Utility", "comments": "In Proceedings TARK 2021, arXiv:2106.10886", "journal-ref": "EPTCS 335, 2021, pp. 281-294", "doi": "10.4204/EPTCS.335.27", "report-no": null, "categories": "cs.LO cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The formalization of action and obligation using logic languages is a topic\nof increasing relevance in the field of ethics for AI. Having an expressive\nsyntactic and semantic framework to reason about agents' decisions in moral\nsituations allows for unequivocal representations of components of behavior\nthat are relevant when assigning blame (or praise) of outcomes to said agents.\nTwo very important components of behavior in this respect are belief and\nbelief-based action. In this work we present a logic of doxastic oughts by\nextending epistemic deontic stit theory with beliefs. On one hand, the\nsemantics for formulas involving belief operators is based on probability\nmeasures. On the other, the semantics for doxastic oughts relies on a notion of\noptimality, and the underlying choice rule is maximization of expected utility.\nWe introduce an axiom system for the resulting logic, and we address its\nsoundness, completeness, and decidability results. These results are\nsignificant in the line of research that intends to use proof systems of\nepistemic, doxastic, and deontic logics to help in the testing of ethical\nbehavior of AI through theorem-proving and model-checking.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 02:47:43 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Abarca", "Aldo Iv\u00e1n Ram\u00edrez", "", "Utrecht University"], ["Broersen", "Jan", "", "Utrecht University"]]}, {"id": "2106.11652", "submitter": "Zhiwei Xu", "authors": "Zhiwei Xu, Dapeng Li, Yunpeng Bai, Guoliang Fan", "title": "MMD-MIX: Value Function Factorisation with Maximum Mean Discrepancy for\n  Cooperative Multi-Agent Reinforcement Learning", "comments": "7 pages, 2 figures, 2 tables. Accepted by IJCNN 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the real world, many tasks require multiple agents to cooperate with each\nother under the condition of local observations. To solve such problems, many\nmulti-agent reinforcement learning methods based on Centralized Training with\nDecentralized Execution have been proposed. One representative class of work is\nvalue decomposition, which decomposes the global joint Q-value $Q_\\text{jt}$\ninto individual Q-values $Q_a$ to guide individuals' behaviors, e.g. VDN\n(Value-Decomposition Networks) and QMIX. However, these baselines often ignore\nthe randomness in the situation. We propose MMD-MIX, a method that combines\ndistributional reinforcement learning and value decomposition to alleviate the\nabove weaknesses. Besides, to improve data sampling efficiency, we were\ninspired by REM (Random Ensemble Mixture) which is a robust RL algorithm to\nexplicitly introduce randomness into the MMD-MIX. The experiments demonstrate\nthat MMD-MIX outperforms prior baselines in the StarCraft Multi-Agent Challenge\n(SMAC) environment.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 10:21:00 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Xu", "Zhiwei", ""], ["Li", "Dapeng", ""], ["Bai", "Yunpeng", ""], ["Fan", "Guoliang", ""]]}, {"id": "2106.11688", "submitter": "Marcos Oliveira", "authors": "Marcos Oliveira, Fariba Karimi, Maria Zens, Johann Schaible, Mathieu\n  G\\'enois, Markus Strohmaier", "title": "Mixing dynamics and group imbalance lead to degree inequality in\n  face-to-face interaction", "comments": "24 pages; 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.CY cs.MA cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uncovering how inequality emerges from human interaction is imperative for\njust societies. Here we show that the way social groups interact in\nface-to-face situations can enable the emergence of degree inequality. We\npresent a mechanism that integrates group mixing dynamics with individual\npreferences, which reproduces group degree inequality found in six empirical\ndata sets of face-to-face interactions. We uncover the impact of group-size\nimbalance on degree inequality, revealing a critical minority group size that\nchanges social gatherings qualitatively. If the minority group is larger than\nthis 'critical mass' size, it can be a well-connected, cohesive group; if it is\nsmaller, minority cohesion widens degree inequality. Finally, we expose the\nunder-representation of social groups in degree rankings due to mixing dynamics\nand propose a way to reduce such biases.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 11:44:02 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Oliveira", "Marcos", ""], ["Karimi", "Fariba", ""], ["Zens", "Maria", ""], ["Schaible", "Johann", ""], ["G\u00e9nois", "Mathieu", ""], ["Strohmaier", "Markus", ""]]}, {"id": "2106.11996", "submitter": "Juste Raimbault", "authors": "Juste Raimbault and Florent Le N\\'echet", "title": "Introducing endogenous transport provision in a LUTI model to explore\n  polycentric governance systems", "comments": "27 pages with supplementary material, 8 figures, 3 tables", "journal-ref": "Journal of Transport Geography, 94, 103115 (2021)", "doi": "10.1016/j.jtrangeo.2021.103115", "report-no": null, "categories": "physics.soc-ph cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Models focusing on interactions between land-use and transportation mostly\nassume an exogenous provision of transportation infrastructures. We investigate\nhere co-evolutionary processes between land-use and transportation, at the\nscale of Mega-City Regions, by introducing a toy model of corresponding\nprocesses. In particular, our model is specifically tailored to include\ngovernance processes ruling the growth of transportation infrastructure. We\nshow through stylised numerical simulations the potentialities of our model to\nreproduce a variety of dynamics when co-evolution is taken into account. We\nthen apply the model to a case study, by calibrating it for the Pearl River\nDelta Mega-city Region (China, 1990-2010). To go beyond this first modelling\nstep, we elaborate on the challenges to overcome to go further towards more\ncomplex models integrating co-evolution between transportation networks and\nterritories in urban systems.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 18:10:14 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Raimbault", "Juste", ""], ["N\u00e9chet", "Florent Le", ""]]}, {"id": "2106.12079", "submitter": "Thomas Roehr", "authors": "Thomas M. Roehr", "title": "Active Exploitation of Redundancies in Reconfigurable Multi-Robot\n  Systems", "comments": "18 pages, 8 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.MA", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  While traditional robotic systems come with a monolithic system design,\nreconfigurable multi-robot systems can share and shift physical resources in an\non-demand fashion. Multi-robot operations can benefit from this flexibility by\nactively managing system redundancies depending on current tasks and having\nmore options to respond to failure events. To support this active exploitation\nof redundancies in robotic systems, this paper details an organization model as\nbasis for planning with reconfigurable multi-robot systems. The model allows to\nexploit redundancies when optimizing a multi-robot system's probability of\nsurvival with respect to a desired mission. The resulting planning approach\ntrades safety against efficiency in robotic operations and thereby offers a new\nperspective and tool to design and improve multi-robot missions. We use a\nsimulated multi-robot planetary exploration mission to evaluate this approach\nand highlight an exemplary performance landscape.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 22:09:57 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Roehr", "Thomas M.", ""]]}, {"id": "2106.12111", "submitter": "Bo Fu", "authors": "Bo Fu, William Smith, Denise Rizzo, Matthew Castanier, Maani Ghaffari,\n  Kira Barton", "title": "Robust Task Scheduling for Heterogeneous Robot Teams under Capability\n  Uncertainty", "comments": "Video: https://youtu.be/DE1DMnGHwwI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops a stochastic programming framework for multi-agent\nsystems where task decomposition, assignment, and scheduling problems are\nsimultaneously optimized. Due to their inherent flexibility and robustness,\nmulti-agent systems are applied in a growing range of real-world problems that\ninvolve heterogeneous tasks and uncertain information. Most previous works\nassume a unique way to decompose a task into roles that can later be assigned\nto the agents. This assumption is not valid for a complex task where the roles\ncan vary and multiple decomposition structures exist. Meanwhile, it is unclear\nhow uncertainties in task requirements and agent capabilities can be\nsystematically quantified and optimized under a multi-agent system setting. A\nrepresentation for complex tasks is proposed to avoid the non-convex task\ndecomposition enumeration: agent capabilities are represented as a vector of\nrandom distributions, and task requirements are verified by a generalizable\nbinary function. The conditional value at risk (CVaR) is chosen as a metric in\nthe objective function to generate robust plans. An efficient algorithm is\ndescribed to solve the model, and the whole framework is evaluated in two\ndifferent practical test cases: capture-the-flag and robotic service\ncoordination during a pandemic (e.g., COVID-19). Results demonstrate that the\nframework is scalable, generalizable, and provides low-cost plans that ensure a\nhigh probability of success.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 00:57:53 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Fu", "Bo", ""], ["Smith", "William", ""], ["Rizzo", "Denise", ""], ["Castanier", "Matthew", ""], ["Ghaffari", "Maani", ""], ["Barton", "Kira", ""]]}, {"id": "2106.12332", "submitter": "Stefanos Leonardos Mr.", "authors": "Yun Kuen Cheung, Stefanos Leonardos, Georgios Piliouras, Shyam Sridhar", "title": "From Griefing to Stability in Blockchain Mining Economies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DC cs.MA econ.TH math.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study a game-theoretic model of blockchain mining economies and show that\ngriefing, a practice according to which participants harm other participants at\nsome lesser cost to themselves, is a prevalent threat at its Nash equilibria.\nThe proof relies on a generalization of evolutionary stability to\nnon-homogeneous populations via griefing factors (ratios that measure network\nlosses relative to deviator's own losses) which leads to a formal theoretical\nargument for the dissipation of resources, consolidation of power and high\nentry barriers that are currently observed in practice.\n  A critical assumption in this type of analysis is that miners' decisions have\nsignificant influence in aggregate network outcomes (such as network hashrate).\nHowever, as networks grow larger, the miner's interaction more closely\nresembles a distributed production economy or Fisher market and its stability\nproperties change. In this case, we derive a proportional response (PR) update\nprotocol which converges to market equilibria at which griefing is irrelevant.\nConvergence holds for a wide range of miners risk profiles and various degrees\nof resource mobility between blockchains with different mining technologies.\nOur empirical findings in a case study with four mineable cryptocurrencies\nsuggest that risk diversification, restricted mobility of resources (as\nenforced by different mining technologies) and network growth, all are\ncontributing factors to the stability of the inherently volatile blockchain\necosystem.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 11:54:26 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Cheung", "Yun Kuen", ""], ["Leonardos", "Stefanos", ""], ["Piliouras", "Georgios", ""], ["Sridhar", "Shyam", ""]]}, {"id": "2106.12868", "submitter": "Gaia Belardinelli", "authors": "Gaia Belardinelli and Rasmus K. Rendsvig", "title": "Awareness Logic: Kripke Lattices as a Middle Ground between Syntactic\n  and Semantic Models", "comments": "arXiv admin note: substantial text overlap with arXiv:2012.12982", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO cs.MA econ.TH math.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The literature on awareness modeling includes both syntax-free and\nsyntax-based frameworks. Heifetz, Meier \\& Schipper (HMS) propose a lattice\nmodel of awareness that is syntax-free. While their lattice approach is elegant\nand intuitive, it precludes the simple option of relying on formal language to\ninduce lattices, and does not explicitly distinguish uncertainty from\nunawareness. Contra this, the most prominent syntax-based solution, the\nFagin-Halpern (FH) model, accounts for this distinction and offers a simple\nrepresentation of awareness, but lacks the intuitiveness of the lattice\nstructure. Here, we combine these two approaches by providing a lattice of\nKripke models, induced by atom subset inclusion, in which uncertainty and\nunawareness are separate. We show our model equivalent to both HMS and FH\nmodels by defining transformations between them which preserve satisfaction of\nformulas of a language for explicit knowledge, and obtain completeness through\nour and HMS' results. Lastly, we prove that the Kripke lattice model can be\nshown equivalent to the FH model (when awareness is propositionally determined)\nalso with respect to the language of the Logic of General Awareness, for which\nthe FH model where originally proposed.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 10:04:44 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Belardinelli", "Gaia", ""], ["Rendsvig", "Rasmus K.", ""]]}, {"id": "2106.12928", "submitter": "Stefanos Leonardos Mr.", "authors": "Stefanos Leonardos, Georgios Piliouras, Kelly Spendlove,", "title": "Exploration-Exploitation in Multi-Agent Competition: Convergence with\n  Bounded Rationality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG cs.MA econ.TH math.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The interplay between exploration and exploitation in competitive multi-agent\nlearning is still far from being well understood. Motivated by this, we study\nsmooth Q-learning, a prototypical learning model that explicitly captures the\nbalance between game rewards and exploration costs. We show that Q-learning\nalways converges to the unique quantal-response equilibrium (QRE), the standard\nsolution concept for games under bounded rationality, in weighted zero-sum\npolymatrix games with heterogeneous learning agents using positive exploration\nrates. Complementing recent results about convergence in weighted potential\ngames, we show that fast convergence of Q-learning in competitive settings is\nobtained regardless of the number of agents and without any need for parameter\nfine-tuning. As showcased by our experiments in network zero-sum games, these\ntheoretical results provide the necessary guarantees for an algorithmic\napproach to the currently open problem of equilibrium selection in competitive\nmulti-agent settings.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 11:43:38 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Leonardos", "Stefanos", ""], ["Piliouras", "Georgios", ""], ["Spendlove", "Kelly", ""]]}, {"id": "2106.13285", "submitter": "Ofer Dagan", "authors": "Ofer Dagan, Nisar R. Ahmed", "title": "Factor Graphs for Heterogeneous Bayesian Decentralized Data Fusion", "comments": "8 pages, 6 figures, 1 table, submitted to the 24th International\n  Conference on Information Fusion", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.MA eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper explores the use of factor graphs as an inference and analysis\ntool for Bayesian peer-to-peer decentralized data fusion. We propose a\nframework by which agents can each use local factor graphs to represent\nrelevant partitions of a complex global joint probability distribution, thus\nallowing them to avoid reasoning over the entirety of a more complex model and\nsaving communication as well as computation cost. This allows heterogeneous\nmulti-robot systems to cooperate on a variety of real world, task oriented\nmissions, where scalability and modularity are key. To develop the initial\ntheory and analyze the limits of this approach, we focus our attention on\nstatic linear Gaussian systems in tree-structured networks and use Channel\nFilters (also represented by factor graphs) to explicitly track common\ninformation. We discuss how this representation can be used to describe various\nmulti-robot applications and to design and analyze new heterogeneous data\nfusion algorithms. We validate our method in simulations of a multi-agent\nmulti-target tracking and cooperative multi-agent mapping problems, and discuss\nthe computation and communication gains of this approach.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 19:18:14 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Dagan", "Ofer", ""], ["Ahmed", "Nisar R.", ""]]}, {"id": "2106.13358", "submitter": "Fernando Gama", "authors": "Ting-Kuei Hu, Fernando Gama, Tianlong Chen, Wenqing Zheng, Zhangyang\n  Wang, Alejandro Ribeiro, Brian M. Sadler", "title": "Scalable Perception-Action-Communication Loops with Convolutional and\n  Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.MA cs.SY eess.SP eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a perception-action-communication loop design using\nVision-based Graph Aggregation and Inference (VGAI). This multi-agent\ndecentralized learning-to-control framework maps raw visual observations to\nagent actions, aided by local communication among neighboring agents. Our\nframework is implemented by a cascade of a convolutional and a graph neural\nnetwork (CNN / GNN), addressing agent-level visual perception and feature\nlearning, as well as swarm-level communication, local information aggregation\nand agent action inference, respectively. By jointly training the CNN and GNN,\nimage features and communication messages are learned in conjunction to better\naddress the specific task. We use imitation learning to train the VGAI\ncontroller in an offline phase, relying on a centralized expert controller.\nThis results in a learned VGAI controller that can be deployed in a distributed\nmanner for online execution. Additionally, the controller exhibits good scaling\nproperties, with training in smaller teams and application in larger teams.\nThrough a multi-agent flocking application, we demonstrate that VGAI yields\nperformance comparable to or better than other decentralized controllers, using\nonly the visual input modality and without accessing precise location or motion\nstate information.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 23:57:21 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Hu", "Ting-Kuei", ""], ["Gama", "Fernando", ""], ["Chen", "Tianlong", ""], ["Zheng", "Wenqing", ""], ["Wang", "Zhangyang", ""], ["Ribeiro", "Alejandro", ""], ["Sadler", "Brian M.", ""]]}, {"id": "2106.14334", "submitter": "Jian Hu", "authors": "Siyue Hu, Jian Hu, Weixun Wang, Shih-wei Liao", "title": "Noisy-MAPPO: Noisy Advantage Values for Cooperative Multi-agent\n  Actor-Critic methods", "comments": "fix some errors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-Agent Reinforcement Learning (MARL) has seen revolutionary\nbreakthroughs with its successful application to multi-agent cooperative tasks\nsuch as robot swarms control, autonomous vehicle coordination, and computer\ngames. Recent works have applied the Proximal Policy Optimization (PPO) to the\nmulti-agent tasks, called Multi-agent PPO (MAPPO). However, the MAPPO in\ncurrent works lacks theoretical support, and requires artificial agent-specific\nfeatures, called MAPPO-agent-specific (MAPPO-AS). In addition, the performance\nof MAPPO-AS is still lower than the finetuned QMIX on the popular benchmark\nenvironment StarCraft Multi-agent Challenge (SMAC). In this paper, we firstly\ntheoretically generalize single-agent PPO to the vanilla MAPPO, which shows\nthat the vanilla MAPPO is equivalent to optimizing a multi-agent joint policy\nwith the original PPO approximately. Secondly, since the centralized advantages\nfunction in vanilla MAPPO lacks a credit allocation mechanism, which may lead\nto updating the policies of some agents in a suboptimal direction. Then this\nproblem may prevent the agents from exploring better trajectories, called\n\\textit{The Policies Overfitting in Multi-agent Cooperation(POMAC)}. To solve\nthe POMAC, we propose the Noisy Advantage-Values (Noisy-MAPPO and\nAdvantage-Noisy-MAPPO) which smooth out the advantage values, likewise label\nsmoothing. The experimental results show that the average performance of\nNoisy-MAPPO is better than that of finetuned QMIX and MAPPO-AS, and is much\nbetter than the vanilla MAPPO. We open-source the code at\n\\url{https://github.com/hijkzzz/noisy-mappo}.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jun 2021 22:50:35 GMT"}, {"version": "v2", "created": "Thu, 1 Jul 2021 06:02:59 GMT"}, {"version": "v3", "created": "Tue, 13 Jul 2021 12:24:26 GMT"}, {"version": "v4", "created": "Mon, 19 Jul 2021 13:10:15 GMT"}, {"version": "v5", "created": "Thu, 22 Jul 2021 13:32:39 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Hu", "Siyue", ""], ["Hu", "Jian", ""], ["Wang", "Weixun", ""], ["Liao", "Shih-wei", ""]]}, {"id": "2106.14386", "submitter": "Yulun Tian", "authors": "Yulun Tian, Yun Chang, Fernando Herrera Arias, Carlos Nieto-Granda,\n  Jonathan P. How, Luca Carlone", "title": "Kimera-Multi: Robust, Distributed, Dense Metric-Semantic SLAM for\n  Multi-Robot Systems", "comments": "18 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents Kimera-Multi, the first multi-robot system that (i) is\nrobust and capable of identifying and rejecting incorrect inter and intra-robot\nloop closures resulting from perceptual aliasing, (ii) is fully distributed and\nonly relies on local (peer-to-peer) communication to achieve distributed\nlocalization and mapping, and (iii) builds a globally consistent\nmetric-semantic 3D mesh model of the environment in real-time, where faces of\nthe mesh are annotated with semantic labels. Kimera-Multi is implemented by a\nteam of robots equipped with visual-inertial sensors. Each robot builds a local\ntrajectory estimate and a local mesh using Kimera. When communication is\navailable, robots initiate a distributed place recognition and robust pose\ngraph optimization protocol based on a novel distributed graduated\nnon-convexity algorithm. The proposed protocol allows the robots to improve\ntheir local trajectory estimates by leveraging inter-robot loop closures while\nbeing robust to outliers. Finally, each robot uses its improved trajectory\nestimate to correct the local mesh using mesh deformation techniques.\n  We demonstrate Kimera-Multi in photo-realistic simulations, SLAM benchmarking\ndatasets, and challenging outdoor datasets collected using ground robots. Both\nreal and simulated experiments involve long trajectories (e.g., up to 800\nmeters per robot). The experiments show that Kimera-Multi (i) outperforms the\nstate of the art in terms of robustness and accuracy, (ii) achieves estimation\nerrors comparable to a centralized SLAM system while being fully distributed,\n(iii) is parsimonious in terms of communication bandwidth, (iv) produces\naccurate metric-semantic 3D meshes, and (v) is modular and can be also used for\nstandard 3D reconstruction (i.e., without semantic labels) or for trajectory\nestimation (i.e., without reconstructing a 3D mesh).\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 03:56:40 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Tian", "Yulun", ""], ["Chang", "Yun", ""], ["Arias", "Fernando Herrera", ""], ["Nieto-Granda", "Carlos", ""], ["How", "Jonathan P.", ""], ["Carlone", "Luca", ""]]}, {"id": "2106.14446", "submitter": "Xiaowei Wu", "authors": "Jiarui Gan, Bo Li and Xiaowei Wu", "title": "Approximately Envy-Free Budget-Feasible Allocation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the budget-feasible allocation problem, a set of items with varied sizes\nand values are to be allocated to a group of agents. Each agent has a budget\nconstraint on the total size of items she can receive. The goal is to compute a\nfeasible allocation that is envy-free (EF), in which the agents do not envy\neach other for the items they receive, nor do they envy a charity, who is\nendowed with all the unallocated items. Since EF allocations barely exist even\nwithout budget constraints, we are interested in the relaxed notion of\nenvy-freeness up to one item (EF1). The computation of both exact and\napproximate EF1 allocations remains largely open, despite a recent effort by Wu\net al. (IJCAI 2021) in showing that any budget-feasible allocation that\nmaximizes the Nash Social Welfare (NSW) is 1/4-approximate EF1. In this paper,\nwe move one step forward by showing that for agents with identical additive\nvaluations, a 1/2-approximate EF1 allocation can be computed in polynomial\ntime. For the uniform-budget and two-agent cases, we propose efficient\nalgorithms for computing an exact EF1 allocation. We also consider the large\nbudget setting, i.e., when the item sizes are infinitesimal compared with the\nagents' budgets, and show that both the NSW maximizing allocation and the\nallocation our polynomial-time algorithm computes have an approximation close\nto 1 regarding EF1.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 07:57:19 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Gan", "Jiarui", ""], ["Li", "Bo", ""], ["Wu", "Xiaowei", ""]]}, {"id": "2106.14572", "submitter": "Mireia Yurrita", "authors": "Mireia Yurrita, Arnaud Grignard, Luis Alonso, Yan Zhang, Cristian\n  Jara-Figueroa, Markus Elkatsha and Kent Larson", "title": "Dynamic Urban Planning: an Agent-Based Model Coupling Mobility Mode and\n  Housing Choice. Use case Kendall Square", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As cities become increasingly populated, urban planning plays a key role in\nensuring the equitable and inclusive development of metropolitan areas. MIT\nCity Science group created a data-driven tangible platform, CityScope, to help\ndifferent stakeholders, such as government representatives, urban planners,\ndevelopers, and citizens, collaboratively shape the urban scenario through the\nreal-time impact analysis of different urban interventions. This paper presents\nan agent-based model that characterizes citizens' behavioural patterns with\nrespect to housing and mobility choice that will constitute the first step in\nthe development of a dynamic incentive system for an open interactive\ngovernance process. The realistic identification and representation of the\ncriteria that affect this decision-making process will help understand and\nevaluate the impacts of potential housing incentives that aim to promote urban\ncharacteristics such as equality, diversity, walkability, and efficiency. The\ncalibration and validation of the model have been performed in a well-known\ngeographic area for the Group: Kendall Square in Cambridge, MA.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 10:54:44 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Yurrita", "Mireia", ""], ["Grignard", "Arnaud", ""], ["Alonso", "Luis", ""], ["Zhang", "Yan", ""], ["Jara-Figueroa", "Cristian", ""], ["Elkatsha", "Markus", ""], ["Larson", "Kent", ""]]}, {"id": "2106.14668", "submitter": "Shayegan Omidshafiei", "authors": "Georgios Piliouras, Mark Rowland, Shayegan Omidshafiei, Romuald Elie,\n  Daniel Hennes, Jerome Connor, Karl Tuyls", "title": "Evolutionary Dynamics and $\\Phi$-Regret Minimization in Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regret has been established as a foundational concept in online learning, and\nlikewise has important applications in the analysis of learning dynamics in\ngames. Regret quantifies the difference between a learner's performance against\na baseline in hindsight. It is well-known that regret-minimizing algorithms\nconverge to certain classes of equilibria in games; however, traditional forms\nof regret used in game theory predominantly consider baselines that permit\ndeviations to deterministic actions or strategies. In this paper, we revisit\nour understanding of regret from the perspective of deviations over partitions\nof the full \\emph{mixed} strategy space (i.e., probability distributions over\npure strategies), under the lens of the previously-established $\\Phi$-regret\nframework, which provides a continuum of stronger regret measures. Importantly,\n$\\Phi$-regret enables learning agents to consider deviations from and to mixed\nstrategies, generalizing several existing notions of regret such as external,\ninternal, and swap regret, and thus broadening the insights gained from\nregret-based analysis of learning algorithms. We prove here that the\nwell-studied evolutionary learning algorithm of replicator dynamics (RD)\nseamlessly minimizes the strongest possible form of $\\Phi$-regret in generic $2\n\\times 2$ games, without any modification of the underlying algorithm itself.\nWe subsequently conduct experiments validating our theoretical results in a\nsuite of 144 $2 \\times 2$ games wherein RD exhibits a diverse set of behaviors.\nWe conclude by providing empirical evidence of $\\Phi$-regret minimization by RD\nin some larger games, hinting at further opportunity for $\\Phi$-regret based\nstudy of such algorithms from both a theoretical and empirical perspective.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 12:48:15 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Piliouras", "Georgios", ""], ["Rowland", "Mark", ""], ["Omidshafiei", "Shayegan", ""], ["Elie", "Romuald", ""], ["Hennes", "Daniel", ""], ["Connor", "Jerome", ""], ["Tuyls", "Karl", ""]]}, {"id": "2106.14827", "submitter": "Gioele Zardini", "authors": "Gioele Zardini and Nicolas Lanzetti and Marco Pavone and Emilio\n  Frazzoli", "title": "Analysis and Control of Autonomous Mobility-on-Demand Systems: A Review", "comments": "Invited submission for Annual Review of Control, Robotics, and\n  Autonomous Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.MA cs.SY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Challenged by urbanization and increasing travel needs, existing\ntransportation systems call for new mobility paradigms. In this article, we\npresent the emerging concept of Autonomous Mobility-on-Demand, whereby\ncentrally orchestrated fleets of autonomous vehicles provide mobility service\nto customers. We provide a comprehensive review of methods and tools to model\nand solve problems related to Autonomous Mobility-on-Demand systems.\nSpecifically, we first identify problem settings for their analysis and\ncontrol, both from the operational and the planning perspective. We then review\nmodeling aspects, including transportation networks, transportation demand,\ncongestion, operational constraints, and interactions with existing\ninfrastructure. Thereafter, we provide a systematic analysis of existing\nsolution methods and performance metrics, highlighting trends and trade-offs.\nFinally, we present various directions for further research.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 16:03:37 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Zardini", "Gioele", ""], ["Lanzetti", "Nicolas", ""], ["Pavone", "Marco", ""], ["Frazzoli", "Emilio", ""]]}, {"id": "2106.15101", "submitter": "Harsh Sharma", "authors": "Stuti Sehgal (1), Harsh Sharma (1), Akshat Anand (1) ((1) Department\n  of Computer Science and Engineering, SRM Institute of Science and Technology,\n  Kattankulathur, Tamil Nadu, India)", "title": "Smart and Context-Aware System employing Emotions Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  People have the ability to make sensible assumptions about other people's\nemotional states by being sympathetic, and because of our common sense of\nknowledge and the ability to think visually. Over the years, much research has\nbeen done on providing machines with the ability to detect human emotions and\nto develop automated emotional intelligence systems. The computer's ability to\ndetect human emotions is gaining popularity in creating sensitive systems such\nas learning environments, health care systems and real-world. Improving\npeople's health has been the subject of much research. This paper describes the\nformation as conceptual evidence of emotional acquisition and control in\nintelligent health settings. The authors of this paper aim for an\nunconventional approach with a friendly look to get emotional scenarios from\nthe system to establish a functional, non-intrusive and emotionally-sensitive\nenvironment where users can do their normal activities naturally and see the\nprogram only when pleasant mood activating services are received. The\ncontext-sensitive system interacts with users to detect and differentiate\nemotions through facial expressions or speech recognition, to make music\nrecommendations and mood color treatments with the services installed on their\nIoT devices.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 05:36:19 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Sehgal", "Stuti", ""], ["Sharma", "Harsh", ""], ["Anand", "Akshat", ""]]}, {"id": "2106.15691", "submitter": "Annie Wong", "authors": "Annie Wong, Thomas B\\\"ack, Anna V. Kononova, Aske Plaat", "title": "Multiagent Deep Reinforcement Learning: Challenges and Directions\n  Towards Human-Like Approaches", "comments": "37 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper surveys the field of multiagent deep reinforcement learning. The\ncombination of deep neural networks with reinforcement learning has gained\nincreased traction in recent years and is slowly shifting the focus from\nsingle-agent to multiagent environments. Dealing with multiple agents is\ninherently more complex as (a) the future rewards depend on the joint actions\nof multiple players and (b) the computational complexity of functions\nincreases. We present the most common multiagent problem representations and\ntheir main challenges, and identify five research areas that address one or\nmore of these challenges: centralised training and decentralised execution,\nopponent modelling, communication, efficient coordination, and reward shaping.\nWe find that many computational studies rely on unrealistic assumptions or are\nnot generalisable to other settings; they struggle to overcome the curse of\ndimensionality or nonstationarity. Approaches from psychology and sociology\ncapture promising relevant behaviours such as communication and coordination.\nWe suggest that, for multiagent reinforcement learning to be successful, future\nresearch addresses these challenges with an interdisciplinary approach to open\nup new possibilities for more human-oriented solutions in multiagent\nreinforcement learning.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 19:53:15 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Wong", "Annie", ""], ["B\u00e4ck", "Thomas", ""], ["Kononova", "Anna V.", ""], ["Plaat", "Aske", ""]]}, {"id": "2106.15729", "submitter": "Franck Djeumou", "authors": "Franck Djeumou, Zhe Xu, Murat Cubuktepe, and Ufuk Topcu", "title": "Probabilistic Control of Heterogeneous Swarms Subject to Graph Temporal\n  Logic Specifications: A Decentralized and Scalable Approach", "comments": "Initial submission to TAC", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.FL cs.MA cs.SY math.OC", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We develop a probabilistic control algorithm, $\\texttt{GTLProCo}$, for swarms\nof agents with heterogeneous dynamics and objectives, subject to high-level\ntask specifications. The resulting algorithm not only achieves decentralized\ncontrol of the swarm but also significantly improves scalability over\nstate-of-the-art existing algorithms. Specifically, we study a setting in which\nthe agents move along the nodes of a graph, and the high-level task\nspecifications for the swarm are expressed in a recently-proposed language\ncalled graph temporal logic (GTL). By constraining the distribution of the\nswarm over the nodes of the graph, GTL can specify a wide range of properties,\nincluding safety, progress, and response. $\\texttt{GTLProCo}$, agnostic to the\nnumber of agents comprising the swarm, controls the density distribution of the\nswarm in a decentralized and probabilistic manner. To this end, it synthesizes\na time-varying Markov chain modeling the time evolution of the density\ndistribution under the GTL constraints. We first identify a subset of GTL,\nnamely reach-avoid specifications, for which we can reduce the synthesis of\nsuch a Markov chain to either linear or semi-definite programs. Then, in the\ngeneral case, we formulate the synthesis of the Markov chain as a mixed-integer\nnonlinear program (MINLP). We exploit the structure of the problem to provide\nan efficient sequential mixed-integer linear programming scheme with trust\nregions to solve the MINLP. We empirically demonstrate that our sequential\nscheme is at least three orders of magnitude faster than off-the-shelf MINLP\nsolvers and illustrate the effectiveness of $\\texttt{GTLProCo}$ in several\nswarm scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 21:34:55 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Djeumou", "Franck", ""], ["Xu", "Zhe", ""], ["Cubuktepe", "Murat", ""], ["Topcu", "Ufuk", ""]]}, {"id": "2106.15905", "submitter": "Meng Zhang", "authors": "Meng Zhang, Ermin Wei, and Randall Berry", "title": "Faithful Edge Federated Learning: Scalability and Privacy", "comments": "Under review by JSAC", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.GT cs.MA cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Federated learning enables machine learning algorithms to be trained over a\nnetwork of multiple decentralized edge devices without requiring the exchange\nof local datasets. Successfully deploying federated learning requires ensuring\nthat agents (e.g., mobile devices) faithfully execute the intended algorithm,\nwhich has been largely overlooked in the literature. In this study, we first\nuse risk bounds to analyze how the key feature of federated learning,\nunbalanced and non-i.i.d. data, affects agents' incentives to voluntarily\nparticipate and obediently follow traditional federated learning algorithms.\n  To be more specific, our analysis reveals that agents with less typical data\ndistributions and relatively more samples are more likely to opt out of or\ntamper with federated learning algorithms. To this end, we formulate the first\nfaithful implementation problem of federated learning and design two faithful\nfederated learning mechanisms which satisfy economic properties, scalability,\nand privacy. Further, the time complexity of computing all agents' payments in\nthe number of agents is $\\mathcal{O}(1)$. First, we design a Faithful Federated\nLearning (FFL) mechanism which approximates the Vickrey-Clarke-Groves (VCG)\npayments via an incremental computation. We show that it achieves (probably\napproximate) optimality, faithful implementation, voluntary participation, and\nsome other economic properties (such as budget balance). Second, by\npartitioning agents into several subsets, we present a scalable VCG mechanism\napproximation. We further design a scalable and Differentially Private FFL\n(DP-FFL) mechanism, the first differentially private faithful mechanism, that\nmaintains the economic properties. Our mechanism enables one to make three-way\nperformance tradeoffs among privacy, the iterations needed, and payment\naccuracy loss.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 08:46:40 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Zhang", "Meng", ""], ["Wei", "Ermin", ""], ["Berry", "Randall", ""]]}]