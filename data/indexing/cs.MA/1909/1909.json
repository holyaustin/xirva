[{"id": "1909.00059", "submitter": "Govind Saraswat", "authors": "Govind Saraswat, Vivek Khatana, Sourav Patel, Murti V. Salapaka", "title": "Distributed finite-time termination for consensus algorithm in switching\n  topologies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we present a finite time stopping criterion for consensus\nalgorithms in networks with dynamic communication topology. Recent results\nprovide asymptotic convergence to the consensus algorithm. However, the\nasymptotic convergence of these algorithms pose a challenge in the practical\nsettings where the response from agents is required in finite time. To this\nend, we propose a Maximum-Minimum protocol which propagates the global maximum\nand minimum values of agent states (while running consensus algorithm) in the\nnetwork. We establish that global maximum and minimum values are strictly\nmonotonic even for a dynamic topology and can be utilized to distributively\nascertain the closeness to convergence in finite time. We show that each node\ncan have access to the global maximum and minimum by running the proposed\nMaximum-Minimum protocol and use it as a finite time stopping criterion for the\notherwise asymptotic consensus algorithm. The practical utility of the\nalgorithm is illustrated through experiments where each agent is instantiated\nby a NodeJS socket.io server.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 20:22:31 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Saraswat", "Govind", ""], ["Khatana", "Vivek", ""], ["Patel", "Sourav", ""], ["Salapaka", "Murti V.", ""]]}, {"id": "1909.00893", "submitter": "Shashwat Shivam", "authors": "Shashwat Shivam, Aris Kanellopoulos, Kyriakos G. Vamvoudakis, Yorai\n  Wardi", "title": "A Predictive Deep Learning Approach to Output Regulation: The Case of\n  Collaborative Pursuit Evasion", "comments": "Accepted in Control and Decision Conference 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of controlling an underactuated system\nin unknown, and potentially adversarial environments. The emphasis will be on\nautonomous aerial vehicles, modelled by Dubins dynamics. The proposed control\nlaw is based on a variable integrator via online prediction for target\ntracking. To showcase the efficacy of our method, we analyze a pursuit evasion\ngame between multiple autonomous agents. To obviate the need for perfect\nknowledge of the evader's future strategy, we use a deep neural network that is\ntrained to approximate the behavior of the evader based on measurements\ngathered online during the pursuit.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 00:04:24 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Shivam", "Shashwat", ""], ["Kanellopoulos", "Aris", ""], ["Vamvoudakis", "Kyriakos G.", ""], ["Wardi", "Yorai", ""]]}, {"id": "1909.00991", "submitter": "Joel Robertson", "authors": "Joel Robertson", "title": "Modelling Bushfire Evacuation Behaviours", "comments": "84 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bushfires pose a significant threat to Australia's regional areas. To\nminimise risk and increase resilience, communities need robust evacuation\nstrategies that account for people's likely behaviour both before and during a\nbushfire. Agent-based modelling (ABM) offers a practical way to simulate a\nrange of bushfire evacuation scenarios. However, the ABM should reflect the\ndiversity of possible human responses in a given community. The\nBelief-Desire-Intention (BDI) cognitive model captures behaviour in a compact\nrepresentation that is understandable by domain experts. Within a BDI-ABM\nsimulation, individual BDI agents can be assigned profiles that determine their\nlikely behaviour. Over a population of agents their collective behaviour will\ncharacterise the community response. These profiles are drawn from existing\nhuman behaviour research and consultation with emergency services personnel and\ncapture the expected behaviours of identified groups in the population, both\nprior to and during an evacuation. A realistic representation of each community\ncan then be formed, and evacuation scenarios within the simulation can be used\nto explore the possible impact of population structure on outcomes. It is hoped\nthat this will give an improved understanding of the risks associated with\nevacuation, and lead to tailored evacuation plans for each community to help\nthem prepare for and respond to bushfire.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 08:07:27 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Robertson", "Joel", ""]]}, {"id": "1909.01051", "submitter": "Pedro M. Esperan\\c{c}a", "authors": "Fabio Maria Carlucci and Pedro M Esperan\\c{c}a and Marco Singh and\n  Victor Gabillon and Antoine Yang and Hang Xu and Zewei Chen and Jun Wang", "title": "MANAS: Multi-Agent Neural Architecture Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Neural Architecture Search (NAS) problem is typically formulated as a\ngraph search problem where the goal is to learn the optimal operations over\nedges in order to maximise a graph-level global objective. Due to the large\narchitecture parameter space, efficiency is a key bottleneck preventing NAS\nfrom its practical use. In this paper, we address the issue by framing NAS as a\nmulti-agent problem where agents control a subset of the network and coordinate\nto reach optimal architectures. We provide two distinct lightweight\nimplementations, with reduced memory requirements (1/8th of state-of-the-art),\nand performances above those of much more computationally expensive methods.\nTheoretically, we demonstrate vanishing regrets of the form O(sqrt(T)), with T\nbeing the total number of rounds. Finally, aware that random search is an,\noften ignored, effective baseline we perform additional experiments on 3\nalternative datasets and 2 network configurations, and achieve favourable\nresults in comparison.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 10:36:37 GMT"}, {"version": "v2", "created": "Thu, 5 Sep 2019 12:36:50 GMT"}, {"version": "v3", "created": "Tue, 25 Feb 2020 11:37:52 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Carlucci", "Fabio Maria", ""], ["Esperan\u00e7a", "Pedro M", ""], ["Singh", "Marco", ""], ["Gabillon", "Victor", ""], ["Yang", "Antoine", ""], ["Xu", "Hang", ""], ["Chen", "Zewei", ""], ["Wang", "Jun", ""]]}, {"id": "1909.01239", "submitter": "Hyo-Sang Shin PhD", "authors": "Teng Li, Hyo-Sang Shin and Antonios Tsourdos", "title": "Threshold Greedy Based Task Allocation for Multiple Robot Operations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with large-scale decentralised task allocation problems for\nmultiple heterogeneous robots with monotone submodular objective functions. One\nof the significant challenges with the large-scale decentralised task\nallocation problem is the NP-hardness for computation and communication. This\npaper proposes a decentralised Decreasing Threshold Task Allocation (DTTA)\nalgorithm that enables parallel allocation by leveraging a decreasing threshold\nto handle the NP-hardness. Then DTTA is upgraded to a more practical version\nLazy Decreasing Threshold Task Allocation (LDTTA) by combining a variant of\nLazy strategy. DTTA and LDTTA can release both computational and communicating\nburden for multiple robots in a decentralised network while providing an\noptimality bound of solution quality. To examine the performance of the\nproposed algorithms, this paper models a multi-target surveillance scenario and\nconducts Monte-Carlo simulations. Simulation results reveal that the proposed\nalgorithms achieve similar function values but consume much less running time\nand consensus steps compared with benchmark decentralised task allocation\nalgorithms.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 15:11:00 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Li", "Teng", ""], ["Shin", "Hyo-Sang", ""], ["Tsourdos", "Antonios", ""]]}, {"id": "1909.01583", "submitter": "Palash Dey", "authors": "Palash Dey", "title": "Gerrymandering: A Briber's Perspective", "comments": "Under submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DS cs.MA cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We initiate the study of bribery problem in the context of gerrymandering and\nreverse gerrymandering. In our most general problem, the input is a set of\nvoters having votes over a set of alternatives, a graph on the voters, a\npartition of voters into connected districts, cost of every voter for changing\nher district, a budget for the briber, and a favorite alternative of the\nbriber. The briber needs to compute if the given partition can be modified so\nthat (i) the favorite alternative of the briber wins the resulting election,\n(ii) the modification is budget feasible, and (iii) every new district is\nconnected. We study four natural variants of the above problem -- the graph on\nvoter being arbitrary vs complete graph (corresponds to removing connectedness\nrequirement for districts) and the cost of bribing every voter being uniform vs\nnon-uniform. We show that all the four problems are NP-complete even under\nquite restrictive scenarios. Hence our results show that district based\nelections are quite resistant under this new kind of electoral attack. We\ncomplement our hardness results with polynomial time algorithms in some other\ncases.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 07:21:15 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Dey", "Palash", ""]]}, {"id": "1909.01711", "submitter": "Ghazal Tashakor", "authors": "Ghazal Tashakor and Remo Suppi", "title": "Simulation and computational analysis of multiscale graph agent-based\n  tumor model", "comments": "7 pages, 7 figures", "journal-ref": "A Publication of The IEEE, New Jersey, USA 2019 ISBN:\n  978-1-7281-4483-2", "doi": null, "report-no": null, "categories": "cs.MA q-bio.TO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with the cellular biological network analysis of the\ntumor-growth model, consisting of multiple spaces and time scales. In this\npaper, we present a model in graph simulation using ABM for tumor growth. In\nparticular, we propose a graph agent-based modeling and simulation system in\nthe format of tumor growth scenario for evolving analysis. To manage cellular\nbiological network analysis, we developed a workflow that allows us to estimate\nthe tumor model and the complexity of the evolving behavior in a principled\nmanner. By developing the model using Python, which has enabled us to run the\nmodel multiple times (more than what is possible by conventional means) to\ngenerate a large amount of data, we have succeeded in getting deep in to the\nmicro-environment of the tumor, employing network analysis. Combining\nagent-based modeling with graph-based modeling to simulate the structure,\ndynamics, and functions of complex networks is exclusively important for\nbiological systems with a large number of open parameters, e.g., epidemic\nmodels of disease spreading or cancer. Extracting data from evolutionary\ndirected graphs and a set of centrality algorithms helps us to tackle the\nproblems of pathway analysis and to develop the ability to predict, control,\nand design the function of metabolisms. Reproducing and performing complex\nparametric simulations a known phenomenon at a sufficient level of detail for\ncomputational biology could be an impressive achievement for fast analysis\npurposes in clinics, both on the predictive diagnostic and therapeutic side.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 11:53:40 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Tashakor", "Ghazal", ""], ["Suppi", "Remo", ""]]}, {"id": "1909.01741", "submitter": "Jaime Ramos", "authors": "Jaime Ramos", "title": "B\\\"uchi automata for distributed temporal logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The distributed temporal logic DTL is a logic for reasoning about temporal\nproperties of distributed systems from the local point of view of the system's\nagents, which are assumed to execute sequentially and to interact by means of\nsynchronous event sharing. Different versions of DTL have been provided over\nthe years for a number of different applications, reflecting different\nperspectives on how non-local information can be accessed by each agent. In\nthis paper, we propose a novel notion of distributed B\\\"uchi automaton\nenvisaged to encompass DTL with a model-checking mechanism.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 12:46:08 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Ramos", "Jaime", ""]]}, {"id": "1909.01788", "submitter": "Mikhail Prokopenko", "authors": "Mikhail Prokopenko and Peter Wang", "title": "Fractals2019: Combinatorial Optimisation with Dynamic Constraint\n  Annealing", "comments": "12 pages, 1 figure, RoboCup-2019, champion paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DM cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fractals2019 started as a new experimental entry in the RoboCup Soccer 2D\nSimulation League, based on Gliders2d code base, and advanced to become a\nRoboCup-2019 champion. We employ combinatorial optimisation methods, within the\nframework of Guided Self-Organisation, with the search guided by local\nconstraints. We present examples of several tactical tasks based on the\nGliders2d code (version v2), including the search for an optimal assignment of\nheterogeneous player types, as well as blocking behaviours, offside trap, and\nattacking formations. We propose a new method, Dynamic Constraint Annealing,\nfor solving dynamic constraint satisfaction problems, and apply it to optimise\nthermodynamic potential of collective behaviours, under dynamically induced\nconstraints.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 13:31:24 GMT"}, {"version": "v2", "created": "Mon, 14 Oct 2019 03:08:06 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Prokopenko", "Mikhail", ""], ["Wang", "Peter", ""]]}, {"id": "1909.01885", "submitter": "Ghazal Tashakor", "authors": "Ghazal Tashakor and Remo Suppi", "title": "Agent-based model for tumour-analysis using Python+Mesa", "comments": "7 pages, 3figures, The European Modeling And Simulation Symposium\n  (EMSS), Proceedings of a meeting held 17-19 September 2018, Budapest,\n  Hungary. Held at the International Multidisciplinary Modeling and Simulation\n  Multiconference (I3M 2018), ISBN: 9781510872240", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA q-bio.TO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The potential power provided and possibilities presented by computation\ngraphs has steered most of the available modeling techniques to\nre-implementing, utilization and including the complex nature of System Biology\n(SB). To model the dynamics of cellular population, we need to study a plethora\nof scenarios ranging from cell differentiation to tumor growth and etcetera.\nTest and verification of a model in research means running the model multiple\ntimes with different or in some cases identical parameters, to see how the\nmodel interacts and if some of the outputs would change regarding different\nparameters. In this paper, we will describe the development and implementation\nof a new agent-based model using Python. The model can be executed using a\ndevelopment environment (based on Mesa, and extremely simplified for\nconvenience) with different parameters. The result is collecting large sets of\ndata, which will allow an in-depth analysis in the microenvironment of the\ntumor by the means of network analysis.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 15:33:09 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Tashakor", "Ghazal", ""], ["Suppi", "Remo", ""]]}, {"id": "1909.02128", "submitter": "Yuchen Lu", "authors": "Philip Paquette, Yuchen Lu, Steven Bocco, Max O. Smith, Satya\n  Ortiz-Gagne, Jonathan K. Kummerfeld, Satinder Singh, Joelle Pineau, Aaron\n  Courville", "title": "No Press Diplomacy: Modeling Multi-Agent Gameplay", "comments": "Accepted at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diplomacy is a seven-player non-stochastic, non-cooperative game, where\nagents acquire resources through a mix of teamwork and betrayal. Reliance on\ntrust and coordination makes Diplomacy the first non-cooperative multi-agent\nbenchmark for complex sequential social dilemmas in a rich environment. In this\nwork, we focus on training an agent that learns to play the No Press version of\nDiplomacy where there is no dedicated communication channel between players. We\npresent DipNet, a neural-network-based policy model for No Press Diplomacy. The\nmodel was trained on a new dataset of more than 150,000 human games. Our model\nis trained by supervised learning (SL) from expert trajectories, which is then\nused to initialize a reinforcement learning (RL) agent trained through\nself-play. Both the SL and RL agents demonstrate state-of-the-art No Press\nperformance by beating popular rule-based bots.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 21:48:04 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 19:32:29 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Paquette", "Philip", ""], ["Lu", "Yuchen", ""], ["Bocco", "Steven", ""], ["Smith", "Max O.", ""], ["Ortiz-Gagne", "Satya", ""], ["Kummerfeld", "Jonathan K.", ""], ["Singh", "Satinder", ""], ["Pineau", "Joelle", ""], ["Courville", "Aaron", ""]]}, {"id": "1909.02396", "submitter": "Florent Le N\\'echet Dr", "authors": "Florent Le N\\'echet", "title": "Modelling transport provision in a polycentric mega city region", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this paper is to present a model of interaction between transport\nand land use which aims at endogenously integrates the provision of\ntransportation infrastructure and its effects on land use, with a long term\nperspective (Lowry, 1964, Wegener, 2004, Levinson, 2011, Bretagnolle, 2014,\nMimeur et al., 2015). LUTECIA (Land Use, Transport, Evaluation of Cooperation,\nInfrastructure provision and Agglomeration effects) model puts emphasis on\nmultiscale processes of urban growth, in the context of the emergence of\nMega-City Regions (MCR, Hall & Pain, 2006). It allows us, in this exploratory\nphase, to characterize via simulation the conditions of development of\npolycentric metropolises. Nevertheless, we argue that such approaches are all\nthe more necessary that we are in a period of multiple transitions that\nclassical modelling tools have difficulty to capture.\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2019 18:55:10 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["N\u00e9chet", "Florent Le", ""]]}, {"id": "1909.02475", "submitter": "Charles Monnoyer De Galland De Carni\\`eres", "authors": "Charles Monnoyer de Galland and Julien M. Hendrickx", "title": "Lower bound performances for average consensus in open multi-agent\n  systems (extended version)", "comments": "7 pages, 3 figures, submitted to Conference on Decision and Control\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive fundamental limitations on the performances of intrinsic averaging\nalgorithms in open multi-agent systems, which are systems subject to random\narrivals and departures of agents. Each agent holds a value, and their goal is\nto estimate the average of the values of the agents presently in the system. We\nprovide a lower bound on the expected Mean Square Error for any estimation\nalgorithm, assuming that the number of agents remains constant and that\ncommunications are random and pairwise. Our derivation is based on the expected\nerror obtained with an optimal algorithm under conditions more favorable than\nthose the actual problem allows, and relies on an analysis of the constraints\non the information spreading mechanisms in the system, and relaxations of\nthese.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 15:17:43 GMT"}, {"version": "v2", "created": "Wed, 11 Sep 2019 14:12:40 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["de Galland", "Charles Monnoyer", ""], ["Hendrickx", "Julien M.", ""]]}, {"id": "1909.02712", "submitter": "Jiaqi Zhang", "authors": "Jiaqi Zhang and Keyou You", "title": "Decentralized Stochastic Gradient Tracking for Non-convex Empirical Risk\n  Minimization", "comments": "This paper has been revised and theoretical results are improved", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.MA cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies a decentralized stochastic gradient tracking (DSGT)\nalgorithm for non-convex empirical risk minimization problems over a\npeer-to-peer network of nodes, which is in sharp contrast to the existing DSGT\nonly for convex problems. To ensure exact convergence and handle the variance\namong decentralized datasets, each node performs a stochastic gradient (SG)\ntracking step by using a mini-batch of samples, where the batch size is\ndesigned to be proportional to the size of the local dataset. We explicitly\nevaluate the convergence rate of DSGT with respect to the number of iterations\nin terms of algebraic connectivity of the network, mini-batch size, gradient\nvariance, etc. Under certain conditions, we further show that DSGT has a\nnetwork independence property in the sense that the network topology only\naffects the convergence rate up to a constant factor. Hence, the convergence\nrate of DSGT can be comparable to the centralized SGD method. Moreover, a\nlinear speedup of DSGT with respect to the number of nodes is achievable for\nsome scenarios. Numerical experiments for neural networks and logistic\nregression problems on CIFAR-10 finally illustrate the advantages of DSGT.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 05:05:45 GMT"}, {"version": "v2", "created": "Sat, 26 Oct 2019 05:28:08 GMT"}, {"version": "v3", "created": "Sat, 15 Aug 2020 08:38:02 GMT"}, {"version": "v4", "created": "Fri, 28 Aug 2020 11:46:28 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Zhang", "Jiaqi", ""], ["You", "Keyou", ""]]}, {"id": "1909.02790", "submitter": "Weixun Wang", "authors": "Weixun Wang, Tianpei Yang, Yong Liu, Jianye Hao, Xiaotian Hao, Yujing\n  Hu, Yingfeng Chen, Changjie Fan, Yang Gao", "title": "From Few to More: Large-scale Dynamic Multiagent Curriculum Learning", "comments": "Accepted by AAAI2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A lot of efforts have been devoted to investigating how agents can learn\neffectively and achieve coordination in multiagent systems. However, it is\nstill challenging in large-scale multiagent settings due to the complex\ndynamics between the environment and agents and the explosion of state-action\nspace. In this paper, we design a novel Dynamic Multiagent Curriculum Learning\n(DyMA-CL) to solve large-scale problems by starting from learning on a\nmultiagent scenario with a small size and progressively increasing the number\nof agents. We propose three transfer mechanisms across curricula to accelerate\nthe learning process. Moreover, due to the fact that the state dimension varies\nacross curricula,, and existing network structures cannot be applied in such a\ntransfer setting since their network input sizes are fixed. Therefore, we\ndesign a novel network structure called Dynamic Agent-number Network (DyAN) to\nhandle the dynamic size of the network input. Experimental results show that\nDyMA-CL using DyAN greatly improves the performance of large-scale multiagent\nlearning compared with state-of-the-art deep reinforcement learning approaches.\nWe also investigate the influence of three transfer mechanisms across curricula\nthrough extensive simulations.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 09:26:05 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 02:48:33 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Wang", "Weixun", ""], ["Yang", "Tianpei", ""], ["Liu", "Yong", ""], ["Hao", "Jianye", ""], ["Hao", "Xiaotian", ""], ["Hu", "Yujing", ""], ["Chen", "Yingfeng", ""], ["Fan", "Changjie", ""], ["Gao", "Yang", ""]]}, {"id": "1909.02940", "submitter": "Vaneet Aggarwal", "authors": "Mridul Agarwal and Vaneet Aggarwal", "title": "Reinforcement Learning for Joint Optimization of Multiple Rewards", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.GT cs.IT cs.MA math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning (RL) algorithms such as DQN owe their success to\nMarkov Decision Processes, and the fact that maximizing the sum of rewards\nallows using backward induction and reduce to the Bellman optimality equation.\nHowever, many real-world problems require optimization of an objective that is\nnon-linear in cumulative rewards for which dynamic programming cannot be\napplied directly. For example, in a resource allocation problem, one of the\nobjectives is to maximize long-term fairness among the users. We notice that\nwhen the function of the sum of rewards is considered, the problem loses its\nMarkov nature. This paper addresses and formalizes the problem of optimizing a\nnon-linear function of the long term average of rewards. We propose model-based\nand model-free algorithms to learn the policy, where the model-based policy is\nshown to achieve a regret of $\\Tilde{O}\\left(KDSA\\sqrt{\\frac{A}{T}}\\right)$ for\n$K$ users. Further, using the fairness in cellular base-station scheduling, and\nqueueing system scheduling as examples, the proposed algorithm is shown to\nsignificantly outperform the conventional RL approaches.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 14:48:07 GMT"}, {"version": "v2", "created": "Thu, 28 Nov 2019 20:42:51 GMT"}, {"version": "v3", "created": "Fri, 19 Mar 2021 05:10:01 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Agarwal", "Mridul", ""], ["Aggarwal", "Vaneet", ""]]}, {"id": "1909.02964", "submitter": "Roxana R\\u{a}dulescu", "authors": "Roxana R\\u{a}dulescu, Patrick Mannion, Diederik M. Roijers, Ann Now\\'e", "title": "Multi-Objective Multi-Agent Decision Making: A Utility-based Analysis\n  and Survey", "comments": "Under review since 15 May 2019", "journal-ref": null, "doi": "10.1007/s10458-019-09433-x", "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The majority of multi-agent system (MAS) implementations aim to optimise\nagents' policies with respect to a single objective, despite the fact that many\nreal-world problem domains are inherently multi-objective in nature.\nMulti-objective multi-agent systems (MOMAS) explicitly consider the possible\ntrade-offs between conflicting objective functions. We argue that, in MOMAS,\nsuch compromises should be analysed on the basis of the utility that these\ncompromises have for the users of a system. As is standard in multi-objective\noptimisation, we model the user utility using utility functions that map value\nor return vectors to scalar values. This approach naturally leads to two\ndifferent optimisation criteria: expected scalarised returns (ESR) and\nscalarised expected returns (SER). We develop a new taxonomy which classifies\nmulti-objective multi-agent decision making settings, on the basis of the\nreward structures, and which and how utility functions are applied. This allows\nus to offer a structured view of the field, to clearly delineate the current\nstate-of-the-art in multi-objective multi-agent decision making approaches and\nto identify promising directions for future research. Starting from the\nexecution phase, in which the selected policies are applied and the utility for\nthe users is attained, we analyse which solution concepts apply to the\ndifferent settings in our taxonomy. Furthermore, we define and discuss these\nsolution concepts under both ESR and SER optimisation criteria. We conclude\nwith a summary of our main findings and a discussion of many promising future\nresearch directions in multi-objective multi-agent systems.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 15:09:31 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["R\u0103dulescu", "Roxana", ""], ["Mannion", "Patrick", ""], ["Roijers", "Diederik M.", ""], ["Now\u00e9", "Ann", ""]]}, {"id": "1909.02966", "submitter": "Yousef Emam", "authors": "Yousef Emam, Paul Glotfelter and Magnus Egerstedt", "title": "Robust Barrier Functions for a Fully Autonomous, Remotely Accessible\n  Swarm-Robotics Testbed", "comments": "Submitted and accepted for the 58th IEEE Conference on Decision and\n  Control (CDC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.MA cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Robotarium, a remotely accessible swarm-robotics testbed, has provided\nfree, open access to robotics and controls research for hundreds of users in\nthousands of experiments. This high level of usage requires autonomy in the\nsystem, which mainly corresponds to constraint satisfaction in the context of\nusers' submissions. In other words, in case that the users' inputs to the\nrobots may lead to collisions, these inputs must be altered to avoid these\ncollisions automatically. However, these alterations must be minimal so as to\npreserve the users' objective in the experiment. Toward this end, the system\nhas utilized barrier functions, which admit a minimally invasive\ncontroller-synthesis procedure. However, barrier functions are yet to be\nrobustified with respect to unmodeled disturbances (e.g., wheel slip or packet\nloss) in a manner conducive to real-time synthesis. As such, this paper\nformulates robust barrier functions for a general class of disturbed\ncontrol-affine systems that, in turn, is key for the Robotarium to operate\nfully autonomously (i.e., without human supervision). Experimental results\nshowcase the effectiveness of this robust formulation in a long-term experiment\nin the Robotarium.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 15:16:58 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Emam", "Yousef", ""], ["Glotfelter", "Paul", ""], ["Egerstedt", "Magnus", ""]]}, {"id": "1909.03070", "submitter": "Zainab Alalawi", "authors": "Zainab Alalawi, Yifeng Zeng, The Anh Han and Aiman Elragig", "title": "Modelling Cooperation in a Dynamic Healthcare System", "comments": "2Pages, 2 Figures, Conference: 2019 International Workshop on\n  Agent-Based Modelling of Human Behaviour (ABMHuB)At: Newcastle, UK. arXiv\n  admin note: substantial text overlap with arXiv:1907.07132", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.MA econ.TH math.DS", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Our research is concerned with studying behavioural changes within a dynamic\nsystem, i.e. health care, and their effects on the decision-making process.\nEvolutionary Game theory is applied to investigate the most probable\nstrategy(ies) adopted by individuals in a finite population based on the\ninteractions among them with an eye to modelling behaviour using the following\nmetrics: cost of investment, cost of management, cost of treatment, reputation\nbenefit for the provider(s), and the gained health benefit for the patient.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 17:23:39 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Alalawi", "Zainab", ""], ["Zeng", "Yifeng", ""], ["Han", "The Anh", ""], ["Elragig", "Aiman", ""]]}, {"id": "1909.03162", "submitter": "Palash Dey", "authors": "Aditya Anand and Palash Dey", "title": "Distance Restricted Manipulation in Voting", "comments": "Under submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.DS cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the notion of {\\em Distance Restricted Manipulation}, where\ncolluding manipulator(s) need to compute if there exist votes which make their\npreferred alternative win the election when their knowledge about the others'\nvotes is a little inaccurate. We use the Kendall-Tau distance to model the\nmanipulators' confidence in the non-manipulators' votes. To this end, we study\nthis problem in two settings - one where the manipulators need to compute a\nmanipulating vote that succeeds irrespective of perturbations in others' votes\n({\\em Distance Restricted Strong Manipulation}), and the second where the\nmanipulators need to compute a manipulating vote that succeeds for at least one\npossible vote profile of the others ({\\em Distance Restricted Weak\nManipulation}). We show that {\\em Distance Restricted Strong Manipulation}\nadmits polynomial-time algorithms for every scoring rule, maximin, Bucklin, and\nsimplified Bucklin voting rules for a single manipulator, and for the\n$k$-approval rule for any number of manipulators, but becomes intractable for\nthe Copeland$^\\alpha$ voting rule for every $\\alpha\\in[0,1]$ even for a single\nmanipulator. In contrast, {\\em Distance Restricted Weak Manipulation} is\nintractable for almost all the common voting rules, with the exception of the\nplurality rule. For a constant number of alternatives, we show that both the\nproblems are polynomial-time solvable for every anonymous and efficient voting\nrule.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 01:29:32 GMT"}, {"version": "v2", "created": "Fri, 27 Nov 2020 11:19:49 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Anand", "Aditya", ""], ["Dey", "Palash", ""]]}, {"id": "1909.03475", "submitter": "Danny Weyns", "authors": "Danny Weyns and Flavio Oquendo", "title": "An Architectural Style for Self-Adaptive Multi-Agent Systems", "comments": "60 pages, 2 online appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern distributed software systems often operate in dynamic environments in\nwhich operation conditions change continuously and subsystems may come and go\nat will, e.g. intelligent traffic management and multi-robot systems. To manage\nthese dynamics, these systems have to self-adapt their structures and behaviors\ndynamically. While we have witnessed significant progress over the past decade\nin the manner in which such systems are designed, persistent challenges remain.\nIn particular, dealing with distribution and decentralized control remains one\nof the major challenges in self-adaptive systems. This report presents an\narchitecture style that supports software architects with designing\narchitectures for a family of decentralized self-adaptive systems. The\narchitecture style structures the software in a number of interacting\nautonomous entities (agents) that cooperatively realize the system tasks.\nMulti-agent systems derived from the architectural style realize flexibility\n(agents adapt their behavior and interactions to variable operating conditions)\nand openness (agents cope autonomously with other agents that enter and leave\nthe system). The architectural style consists of five related patterns that\ndistill domain-specific architectural knowledge derived from extensive\nexperiences with developing various multi-agent systems. The architectural\npatterns are specified using pi-ADL, a formal architectural description\nlanguage supporting specification of dynamic architectures. This specification\nprovides architects with a rigorous description of the architecture elements of\nthe patterns, their interactions and behavior. We illustrate how we have\napplied the architectural style with excerpts of two cases from our practice:\nan experimental system for anticipatory traffic routing and an industrial\nlogistic system for automated transportation in warehouse environments.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 14:18:31 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Weyns", "Danny", ""], ["Oquendo", "Flavio", ""]]}, {"id": "1909.03510", "submitter": "Haifeng Zhang", "authors": "Haifeng Zhang, Weizhe Chen, Zeren Huang, Minne Li, Yaodong Yang,\n  Weinan Zhang, Jun Wang", "title": "Bi-level Actor-Critic for Multi-agent Coordination", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coordination is one of the essential problems in multi-agent systems.\nTypically multi-agent reinforcement learning (MARL) methods treat agents\nequally and the goal is to solve the Markov game to an arbitrary Nash\nequilibrium (NE) when multiple equilibra exist, thus lacking a solution for NE\nselection. In this paper, we treat agents \\emph{unequally} and consider\nStackelberg equilibrium as a potentially better convergence point than Nash\nequilibrium in terms of Pareto superiority, especially in cooperative\nenvironments. Under Markov games, we formally define the bi-level reinforcement\nlearning problem in finding Stackelberg equilibrium. We propose a novel\nbi-level actor-critic learning method that allows agents to have different\nknowledge base (thus intelligent), while their actions still can be executed\nsimultaneously and distributedly. The convergence proof is given, while the\nresulting learning algorithm is tested against the state of the arts. We found\nthat the proposed bi-level actor-critic algorithm successfully converged to the\nStackelberg equilibria in matrix games and find an asymmetric solution in a\nhighway merge environment.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 17:10:50 GMT"}, {"version": "v2", "created": "Tue, 24 Mar 2020 09:18:05 GMT"}, {"version": "v3", "created": "Sat, 4 Apr 2020 09:52:55 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Zhang", "Haifeng", ""], ["Chen", "Weizhe", ""], ["Huang", "Zeren", ""], ["Li", "Minne", ""], ["Yang", "Yaodong", ""], ["Zhang", "Weinan", ""], ["Wang", "Jun", ""]]}, {"id": "1909.03868", "submitter": "Florian K\\\"opf", "authors": "Florian K\\\"opf, Alexander Nitsch, Michael Flad and S\\\"oren Hohmann", "title": "Partner Approximating Learners (PAL): Simulation-Accelerated Learning\n  with Explicit Partner Modeling in Multi-Agent Domains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.AI cs.LG cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mixed cooperative-competitive control scenarios such as human-machine\ninteraction with individual goals of the interacting partners are very\nchallenging for reinforcement learning agents. In order to contribute towards\nintuitive human-machine collaboration, we focus on problems in the continuous\nstate and control domain where no explicit communication is considered and the\nagents do not know the others' goals or control laws but only sense their\ncontrol inputs retrospectively. Our proposed framework combines a learned\npartner model based on online data with a reinforcement learning agent that is\ntrained in a simulated environment including the partner model. Thus, we\novercome drawbacks of independent learners and, in addition, benefit from a\nreduced amount of real world data required for reinforcement learning which is\nvital in the human-machine context. We finally analyze an example that\ndemonstrates the merits of our proposed framework which learns fast due to the\nsimulated environment and adapts to the continuously changing partner due to\nthe partner approximation.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 13:58:15 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 09:41:21 GMT"}, {"version": "v3", "created": "Mon, 2 Mar 2020 17:17:32 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["K\u00f6pf", "Florian", ""], ["Nitsch", "Alexander", ""], ["Flad", "Michael", ""], ["Hohmann", "S\u00f6ren", ""]]}, {"id": "1909.04224", "submitter": "Liheng Chen", "authors": "Liheng Chen, Hongyi Guo, Yali Du, Fei Fang, Haifeng Zhang, Yaoming\n  Zhu, Ming Zhou, Weinan Zhang, Qing Wang, Yong Yu", "title": "Signal Instructed Coordination in Cooperative Multi-agent Reinforcement\n  Learning", "comments": "13 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many real-world problems, a team of agents need to collaborate to maximize\nthe common reward. Although existing works formulate this problem into a\ncentralized learning with decentralized execution framework, which avoids the\nnon-stationary problem in training, their decentralized execution paradigm\nlimits the agents' capability to coordinate. Inspired by the concept of\ncorrelated equilibrium, we propose to introduce a coordination signal to\naddress this limitation, and theoretically show that following mild conditions,\ndecentralized agents with the coordination signal can coordinate their\nindividual policies as manipulated by a centralized controller. The idea of\nintroducing coordination signal is to encapsulate coordinated strategies into\nthe signals, and use the signals to instruct the collaboration in decentralized\nexecution. To encourage agents to learn to exploit the coordination signal, we\npropose Signal Instructed Coordination (SIC), a novel coordination module that\ncan be integrated with most existing MARL frameworks. SIC casts a common signal\nsampled from a pre-defined distribution to all agents, and introduces an\ninformation-theoretic regularization to facilitate the consistency between the\nobserved signal and agents' policies. Our experiments show that SIC\nconsistently improves performance over well-recognized MARL models in both\nmatrix games and a predator-prey game with high-dimensional strategy space.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 01:28:25 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 08:30:30 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Chen", "Liheng", ""], ["Guo", "Hongyi", ""], ["Du", "Yali", ""], ["Fang", "Fei", ""], ["Zhang", "Haifeng", ""], ["Zhu", "Yaoming", ""], ["Zhou", "Ming", ""], ["Zhang", "Weinan", ""], ["Wang", "Qing", ""], ["Yu", "Yong", ""]]}, {"id": "1909.04255", "submitter": "Cesar A. Uribe", "authors": "C\\'esar A. Uribe, James Z. Hare, Lance Kaplan, and Ali Jadbabaie", "title": "Non-Bayesian Social Learning with Uncertain Models over Time-Varying\n  Directed Graphs", "comments": "To appear at CDC2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.MA cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of non-Bayesian social learning with uncertain models,\nin which a network of agents seek to cooperatively identify the state of the\nworld based on a sequence of observed signals. In contrast with the existing\nliterature, we focus our attention on the scenario where the statistical models\nheld by the agents about possible states of the world are built from finite\nobservations. We show that existing non-Bayesian social learning approaches may\nselect a wrong hypothesis with non-zero probability under these conditions.\nTherefore, we propose a new algorithm to iteratively construct a set of beliefs\nthat indicate whether a certain hypothesis is supported by the empirical\nevidence. This new algorithm can be implemented over time-varying directed\ngraphs, with non{-}doubly stochastic weights.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 03:10:57 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Uribe", "C\u00e9sar A.", ""], ["Hare", "James Z.", ""], ["Kaplan", "Lance", ""], ["Jadbabaie", "Ali", ""]]}, {"id": "1909.04421", "submitter": "Mohammad Malekzadeh", "authors": "Mohammad Malekzadeh, Dimitrios Athanasakis, Hamed Haddadi and Benjamin\n  Livshits", "title": "Privacy-Preserving Bandits", "comments": "13 pages, 7 figures", "journal-ref": "In Proceedings of the 3rd Conference on Machine Learning and\n  Systems (MLSys 2020)", "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contextual bandit algorithms~(CBAs) often rely on personal data to provide\nrecommendations. Centralized CBA agents utilize potentially sensitive data from\nrecent interactions to provide personalization to end-users. Keeping the\nsensitive data locally, by running a local agent on the user's device, protects\nthe user's privacy, however, the agent requires longer to produce useful\nrecommendations, as it does not leverage feedback from other users. This paper\nproposes a technique we call Privacy-Preserving Bandits (P2B); a system that\nupdates local agents by collecting feedback from other local agents in a\ndifferentially-private manner. Comparisons of our proposed approach with a\nnon-private, as well as a fully-private (local) system, show competitive\nperformance on both synthetic benchmarks and real-world data. Specifically, we\nobserved only a decrease of 2.6% and 3.6% in multi-label classification\naccuracy, and a CTR increase of 0.0025 in online advertising for a privacy\nbudget $\\epsilon \\approx 0.693$. These results suggest P2B is an effective\napproach to challenges arising in on-device privacy-preserving personalization.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 11:39:58 GMT"}, {"version": "v2", "created": "Thu, 12 Sep 2019 22:36:09 GMT"}, {"version": "v3", "created": "Wed, 26 Feb 2020 16:12:00 GMT"}, {"version": "v4", "created": "Wed, 11 Mar 2020 12:39:06 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Malekzadeh", "Mohammad", ""], ["Athanasakis", "Dimitrios", ""], ["Haddadi", "Hamed", ""], ["Livshits", "Benjamin", ""]]}, {"id": "1909.04585", "submitter": "Bin Han", "authors": "Bin Han, Vincenzo Sciancalepore, Xavier Costa-Perez, Di Feng, and Hans\n  D. Schotten", "title": "Multiservice-based Network Slicing Orchestration with Impatient Tenants", "comments": "Accepted by IEEE Transactions on Wireless Communications on\n  10.04.2020. arXiv admin note: substantial text overlap with arXiv:1901.06399,\n  arXiv:1809.06815", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The combination of recent emerging technologies such as network function\nvirtualization (NFV) and network programmability (SDN) gave birth to the novel\nNetwork Slicing paradigm. 5G networks consist of multi-tenant infrastructures\ncapable of offering leased network \"slices\" to new customers (e.g., vertical\nindustries) enabling a new telecom business model: Slice-as-a-Service (SlaaS).\nHowever, as the service demand gets increasingly dense, slice requests\ncongestion may occur leading to undesired waiting periods. This may turn into\nimpatient tenant behaviors that increase potential loss of the business\nattractiveness to customers. In this paper, we aim to i study the slicing\nadmission control problem by means of a multi-queuing system for heterogeneous\ntenant requests, ii) derive its statistical behavior model, iii) find out the\nrational strategy of impatient tenants waiting in queue-based slice admission\ncontrol systems, iv) prove mathematically and empirically the benefits of\nallowing infrastructure providers to share its information with the upcoming\ntenants, and v) provide a utility model for network slices admission\noptimization. Our results analyze the capability of the proposed SlaaS system\nto be approximately Markovian and evaluate its performance as compared to a\nbaseline solution.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 21:53:36 GMT"}, {"version": "v2", "created": "Fri, 10 Apr 2020 17:02:40 GMT"}, {"version": "v3", "created": "Thu, 16 Apr 2020 06:30:37 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Han", "Bin", ""], ["Sciancalepore", "Vincenzo", ""], ["Costa-Perez", "Xavier", ""], ["Feng", "Di", ""], ["Schotten", "Hans D.", ""]]}, {"id": "1909.04591", "submitter": "Frank Schweitzer", "authors": "Frank Schweitzer, Pavlin Mavrodiev, Adrian M. Seufert, David Garcia", "title": "Modeling User Reputation in Online Social Networks: The Role of Costs,\n  Benefits, and Reciprocity", "comments": null, "journal-ref": null, "doi": "10.3390/e22101073", "report-no": null, "categories": "cs.SI cs.MA nlin.AO physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze an agent-based model to estimate how the costs and benefits of\nusers in an online social network (OSN) impact the robustness of the OSN.\nBenefits are measured in terms of relative reputation that users receives from\ntheir followers. They can be increased by direct and indirect reciprocity in\nfollowing each other, which leads to a core-periphery structure of the OSN.\nCosts relate to the effort to login, to maintain the profile, etc. and are\nassumed as constant for all users. The robustness of the OSN depends on the\nentry and exit of users over time. Intuitively, one would expect that higher\ncosts lead to more users leaving and hence to a less robust OSN. We demonstrate\nthat an optimal cost level exists, which maximizes both the performance of the\nOSN, measured by means of the long-term average benefit of its users, and the\nrobustness of the OSN, measured by means of the life-time of the core of the\nOSN. Our mathematical and computational analyses unfold how changes in the cost\nlevel impact reciprocity and subsequently the core-periphery structure of the\nOSN, to explain the optimal cost level.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 16:02:11 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Schweitzer", "Frank", ""], ["Mavrodiev", "Pavlin", ""], ["Seufert", "Adrian M.", ""], ["Garcia", "David", ""]]}, {"id": "1909.04615", "submitter": "Armin Sadeghi", "authors": "Armin Sadeghi, Stephen L. Smith", "title": "On Re-Balancing Self-Interested Agents in Ride-Sourcing Transportation\n  Networks", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on the problem of controlling self-interested drivers in\nride-sourcing applications. Each driver has the objective of maximizing its\nprofit, while the ride-sourcing company focuses on customer experience by\nseeking to minimizing the expected wait time for pick-up. These objectives are\nnot usually aligned, and the company has no direct control on the waiting\nlocations of the drivers. In this paper, we provide two indirect control\nmethods to optimize the set of waiting locations of the drivers, thereby\nminimizing the expected wait time of the customers: 1) sharing the location of\nall drivers with a subset of drivers, and 2) paying the drivers to relocate. We\nshow that finding the optimal control for each method is NP-hard and we provide\nalgorithms to find near-optimal control in each case. We evaluate the\nperformance of the proposed control methods on real-world data and show that we\ncan achieve between 20% to 80% improvement in the expected response.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 16:45:16 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Sadeghi", "Armin", ""], ["Smith", "Stephen L.", ""]]}, {"id": "1909.04713", "submitter": "Noam Hazon", "authors": "Chaya Levinger, Noam Hazon, Amos Azaria", "title": "Fair Sharing: The Shapley Value for Ride-Sharing and Routing Games", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ride-sharing services are gaining popularity and are crucial for a\nsustainable environment. A special case in which such services are most\napplicable, is the last mile variant. In this variant it is assumed that all\nthe passengers are positioned at the same origin location (e.g. an airport),\nand each have a different destination. One of the major issues in a shared ride\nis fairly splitting of the ride cost among the passengers.\n  In this paper we use the Shapley value, which is one of the most significant\nsolution concepts in cooperative game theory, for fairly splitting the cost of\na shared ride. We consider two scenarios. In the first scenario there exists a\nfixed priority order in which the passengers are dropped-off (e.g. elderly,\ninjured etc.), and we show a method for efficient computation of the Shapley\nvalue in this setting. Our results are also applicable for efficient\ncomputation of the Shapley value in routing games.\n  In the second scenario there is no predetermined priority order. We show that\nthe Shapley value cannot be efficiently computed in this setting. However,\nextensive simulations reveal that our approach for the first scenario can serve\nas an excellent proxy for the second scenario, outperforming other known\nproxies.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 19:25:29 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Levinger", "Chaya", ""], ["Hazon", "Noam", ""], ["Azaria", "Amos", ""]]}, {"id": "1909.04838", "submitter": "Mirmojtaba Gharibi", "authors": "Mirmojtaba Gharibi, Raouf Boutaba, and Steven L. Waslander", "title": "3D traffic flow model for UAVs", "comments": "1 Table, 6 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we introduce a microscopic traffic flow model called Scalar\nCapacity Model (SCM) which can be used to study the formation of traffic on an\nairway link for autonomous Unmanned Aerial Vehicles (UAV) as well as for the\nground vehicles on the road. Given the 3D nature of UAV flights, the main\nnovelty in our model is to eliminate the commonly used notion of lanes and\nreplace it with a notion of density and capacity of flow, but in such a way\nthat individual vehicle motions can still be modeled. We name this a\nDensity/Capacity View (DCV) of the link capacity and how vehicles utilize it\nversus the traditional One/Multi-Lane View (OMV). An interesting feature of\nthis model is exhibiting both passing and blocking regimes (analogous to\nmulti-lane or single-lane) depending on the set scalar parameter for capacity.\nWe show the model has linear local (platoon) and string stability. Also, we\nperform numerical simulations and show evidence for non-linear stability. Our\ntraffic flow model is represented by a nonlinear differential equation which we\ntransform into a linear form. This makes our model analytically solvable in the\nblocking regime and piece-wise analytically solvable in the passing regime.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 03:25:09 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Gharibi", "Mirmojtaba", ""], ["Boutaba", "Raouf", ""], ["Waslander", "Steven L.", ""]]}, {"id": "1909.05232", "submitter": "Yilun Zhou", "authors": "Yilun Zhou, Derrik E. Asher, Nicholas R. Waytowich, Julie A. Shah", "title": "On Memory Mechanism in Multi-Agent Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-agent reinforcement learning (MARL) extends (single-agent)\nreinforcement learning (RL) by introducing additional agents and (potentially)\npartial observability of the environment. Consequently, algorithms for solving\nMARL problems incorporate various extensions beyond traditional RL methods,\nsuch as a learned communication protocol between cooperative agents that\nenables exchange of private information or adaptive modeling of opponents in\ncompetitive settings. One popular algorithmic construct is a memory mechanism\nsuch that an agent's decisions can depend not only upon the current state but\nalso upon the history of observed states and actions. In this paper, we study\nhow a memory mechanism can be useful in environments with different properties,\nsuch as observability, internality and presence of a communication channel.\nUsing both prior work and new experiments, we show that a memory mechanism is\nhelpful when learning agents need to model other agents and/or when\ncommunication is constrained in some way; however we must to be cautious of\nagents achieving effective memoryfulness through other means.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 17:42:14 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Zhou", "Yilun", ""], ["Asher", "Derrik E.", ""], ["Waytowich", "Nicholas R.", ""], ["Shah", "Julie A.", ""]]}, {"id": "1909.05377", "submitter": "Xiaotian Xu", "authors": "Xiaotian Xu and Yancy Diaz-Mercado", "title": "Multi-Agent Control Using Coverage Over Time-Varying Domains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-agent coverage control is used as a mechanism to influence the behavior\nof a group of robots by introducing time-varying domain. The coverage\noptimization problem is modified to adopt time-varying domains, and the\nproposed control law possesses an exponential convergence characteristic.\nCumbrous control for many robots is simplified by deploying distribution and\nbehavior of the robot team as a whole. In the proposed approach, the inputs to\nthe multi-agent system, i.e., time-varying density and time-varying domain, are\nagnostic to the size of the system. Analytic expressions of surface and line\nintegrals present in the control law are obtained under uniform density. The\nscalability of the proposed control strategy is explained and verified via\nnumerical simulation. Experiments on real robots are used to test the proposed\ncontrol law.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 21:13:49 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Xu", "Xiaotian", ""], ["Diaz-Mercado", "Yancy", ""]]}, {"id": "1909.05415", "submitter": "Samaneh Hoseini", "authors": "Samaneh Hosseini Semnani, Anton de Ruiter, Hugh Liu", "title": "Force-based Algorithm for Motion Planning of Large Agent Teams", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a distributed, efficient, scalable and real-time motion\nplanning algorithm for a large group of agents moving in 2 or 3-dimensional\nspaces. This algorithm enables autonomous agents to generate individual\ntrajectories independently with only the relative position information of\nneighboring agents. Each agent applies a force-based control that contains two\nmain terms: collision avoidance and navigational feedback. The first term keeps\ntwo agents separate with a certain distance, while the second term attracts\neach agent toward its goal location. Compared with existing collision-avoidance\nalgorithms, the proposed force-based motion planning (FMP) algorithm is able to\nfind collision-free motions with lower transition time, free from velocity\nstate information of neighbouring agents. It leads to less computational\noverhead. The performance of proposed FMP is examined over several dense and\ncomplex 2D and 3D benchmark simulation scenarios, with results outperforming\nexisting methods.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 14:43:45 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Semnani", "Samaneh Hosseini", ""], ["de Ruiter", "Anton", ""], ["Liu", "Hugh", ""]]}, {"id": "1909.05583", "submitter": "Abhijnan Chakraborty", "authors": "Ana-Andreea Stoica, Abhijnan Chakraborty, Palash Dey, Krishna P.\n  Gummadi", "title": "Minimizing Margin of Victory for Fair Political and Educational\n  Districting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many practical scenarios, a population is divided into disjoint groups for\nbetter administration, e.g., electorates into political districts, employees\ninto departments, students into school districts, and so on. However, grouping\npeople arbitrarily may lead to biased partitions, raising concerns of\ngerrymandering in political districting, racial segregation in schools, etc. To\ncounter such issues, in this paper, we conceptualize such problems in a voting\nscenario, and propose FAIR DISTRICTING problem to divide a given set of people\nhaving preference over candidates into k groups such that the maximum margin of\nvictory of any group is minimized. We also propose the FAIR CONNECTED\nDISTRICTING problem which additionally requires each group to be connected. We\nshow that the FAIR DISTRICTING problem is NP-complete for plurality voting even\nif we have only 3 candidates but admits polynomial time algorithms if we assume\nk to be some constant or everyone can be moved to any group. In contrast, we\nshow that the FAIR CONNECTED DISTRICTING problem is NP-complete for plurality\nvoting even if we have only 2 candidates and k = 2. Finally, we propose\nheuristic algorithms for both the problems and show their effectiveness in UK\npolitical districting and in lowering racial segregation in public schools in\nthe US.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 11:50:25 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Stoica", "Ana-Andreea", ""], ["Chakraborty", "Abhijnan", ""], ["Dey", "Palash", ""], ["Gummadi", "Krishna P.", ""]]}, {"id": "1909.05815", "submitter": "Bowen Jing", "authors": "Bowen Jing and William Yin", "title": "Modeling Sensorimotor Coordination as Multi-Agent Reinforcement Learning\n  with Differentiable Communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-agent reinforcement learning has shown promise on a variety of\ncooperative tasks as a consequence of recent developments in differentiable\ninter-agent communication. However, most architectures are limited to pools of\nhomogeneous agents, limiting their applicability. Here we propose a modular\nframework for learning complex tasks in which a traditional monolithic agent is\nframed as a collection of cooperating heterogeneous agents. We apply this\napproach to model sensorimotor coordination in the neocortex as a multi-agent\nreinforcement learning problem. Our results demonstrate proof-of-concept of the\nproposed architecture and open new avenues for learning complex tasks and for\nunderstanding functional localization in the brain and future intelligent\nsystems.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 17:20:15 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Jing", "Bowen", ""], ["Yin", "William", ""]]}, {"id": "1909.05863", "submitter": "Ethan Perez", "authors": "Ethan Perez, Siddharth Karamcheti, Rob Fergus, Jason Weston, Douwe\n  Kiela, Kyunghyun Cho", "title": "Finding Generalizable Evidence by Learning to Convince Q&A Models", "comments": "EMNLP 2019. Code available at https://github.com/ethanjperez/convince", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a system that finds the strongest supporting evidence for a given\nanswer to a question, using passage-based question-answering (QA) as a testbed.\nWe train evidence agents to select the passage sentences that most convince a\npretrained QA model of a given answer, if the QA model received those sentences\ninstead of the full passage. Rather than finding evidence that convinces one\nmodel alone, we find that agents select evidence that generalizes; agent-chosen\nevidence increases the plausibility of the supported answer, as judged by other\nQA models and humans. Given its general nature, this approach improves QA in a\nrobust manner: using agent-selected evidence (i) humans can correctly answer\nquestions with only ~20% of the full passage and (ii) QA models can generalize\nto longer passages and harder questions.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 18:00:00 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Perez", "Ethan", ""], ["Karamcheti", "Siddharth", ""], ["Fergus", "Rob", ""], ["Weston", "Jason", ""], ["Kiela", "Douwe", ""], ["Cho", "Kyunghyun", ""]]}, {"id": "1909.06037", "submitter": "Jiangjun Tang", "authors": "Jiangjun Tang and George Leu and Yu-Bin Yang", "title": "Optimisation of Air-Ground Swarm Teaming for Target Search, using\n  Differential Evolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a swarm teaming perspective that enhances the scope of\nclassic investigations on survivable networks. A target searching generic\ncontext is considered as test-bed, in which a swarm of ground agents and a\nswarm of UAVs cooperate so that the ground agents reach as many targets as\npossible in the field while also remaining connected as much as possible at all\ntimes. To optimise the system against both these objectives in the same time,\nwe use an evolutionary computation approach in the form of a differential\nevolution algorithm. Results are encouraging, showing a good evolution of the\nfitness function used as part of the differential evolution, and a good\nperformance of the evolved dual-swarm system, which exhibits an optimal\ntrade-off between target reaching and connectivity.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 05:16:55 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Tang", "Jiangjun", ""], ["Leu", "George", ""], ["Yang", "Yu-Bin", ""]]}, {"id": "1909.06168", "submitter": "Moumita Choudhury", "authors": "Moumita Choudhury, Saaduddin Mahmud and Md. Mosaddek Khan", "title": "A Particle Swarm Based Algorithm for Functional Distributed Constraint\n  Optimization Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed Constraint Optimization Problems (DCOPs) are a widely studied\nconstraint handling framework. The objective of a DCOP algorithm is to optimize\na global objective function that can be described as the aggregation of a\nnumber of distributed constraint cost functions. In a DCOP, each of these\nfunctions is defined by a set of discrete variables. However, in many\napplications, such as target tracking or sleep scheduling in sensor networks,\ncontinuous valued variables are more suited than the discrete ones. Considering\nthis, Functional DCOPs (F-DCOPs) have been proposed that is able to explicitly\nmodel a problem containing continuous variables. Nevertheless, the\nstate-of-the-art F-DCOPs approaches experience onerous memory or computation\noverhead. To address this issue, we propose a new F-DCOP algorithm, namely\nParticle Swarm Based F-DCOP (PFD), which is inspired by a meta-heuristic,\nParticle Swarm Optimization (PSO). Although it has been successfully applied to\nmany continuous optimization problems, the potential of PSO has not been\nutilized in F-DCOPs. To be exact, PFD devises a distributed method of solution\nconstruction while significantly reducing the computation and memory\nrequirements. Moreover, we theoretically prove that PFD is an anytime\nalgorithm. Finally, our empirical results indicate that PFD outperforms the\nstate-of-the-art approaches in terms of solution quality and computation\noverhead.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 12:27:00 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Choudhury", "Moumita", ""], ["Mahmud", "Saaduddin", ""], ["Khan", "Md. Mosaddek", ""]]}, {"id": "1909.06254", "submitter": "Saaduddin Mahmud", "authors": "Saaduddin Mahmud, Moumita Choudhury, Md. Mosaddek Khan, Long\n  Tran-Thanh and Nicholas R. Jennings", "title": "AED: An Anytime Evolutionary DCOP Algorithm", "comments": "9 pages, 6 figures, 2 tables. Appeared in the proceedings of the 19th\n  International Conference on Autonomous Agents and Multi-Agent Systems (AAMAS\n  2020)", "journal-ref": null, "doi": "10.5555/3398761.3398859", "report-no": null, "categories": "cs.MA cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evolutionary optimization is a generic population-based metaheuristic that\ncan be adapted to solve a wide variety of optimization problems and has proven\nvery effective for combinatorial optimization problems. However, the potential\nof this metaheuristic has not been utilized in Distributed Constraint\nOptimization Problems (DCOPs), a well-known class of combinatorial optimization\nproblems prevalent in Multi-Agent Systems. In this paper, we present a novel\npopulation-based algorithm, Anytime Evolutionary DCOP (AED), that uses\nevolutionary optimization to solve DCOPs. In AED, the agents cooperatively\nconstruct an initial set of random solutions and gradually improve them through\na new mechanism that considers an optimistic approximation of local benefits.\nMoreover, we present a new anytime update mechanism for AED that identifies the\nbest among a distributed set of candidate solutions and notifies all the agents\nwhen a new best is found. In our theoretical analysis, we prove that AED is\nanytime. Finally, we present empirical results indicating AED outperforms the\nstate-of-the-art DCOP algorithms in terms of solution quality.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 14:26:31 GMT"}, {"version": "v2", "created": "Sat, 16 Nov 2019 11:29:11 GMT"}, {"version": "v3", "created": "Sat, 7 Mar 2020 14:49:45 GMT"}, {"version": "v4", "created": "Wed, 2 Sep 2020 05:46:25 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Mahmud", "Saaduddin", ""], ["Choudhury", "Moumita", ""], ["Khan", "Md. Mosaddek", ""], ["Tran-Thanh", "Long", ""], ["Jennings", "Nicholas R.", ""]]}, {"id": "1909.06480", "submitter": "Sarah Al-Hussaini", "authors": "Sarah Al-Hussaini, Jason M. Gregory, Shaurya Shriyam, Satyandra K.\n  Gupta", "title": "An Alert-Generation Framework for Improving Resiliency in\n  Human-Supervised, Multi-Agent Teams", "comments": null, "journal-ref": null, "doi": null, "report-no": "AI-HRI/2019/22", "categories": "cs.AI cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human-supervision in multi-agent teams is a critical requirement to ensure\nthat the decision-maker's risk preferences are utilized to assign tasks to\nrobots. In stressful complex missions that pose risk to human health and life,\nsuch as humanitarian-assistance and disaster-relief missions, human mistakes or\ndelays in tasking robots can adversely affect the mission. To assist human\ndecision making in such missions, we present an alert-generation framework\ncapable of detecting various modes of potential failure or performance\ndegradation. We demonstrate that our framework, based on state machine\nsimulation and formal methods, offers probabilistic modeling to estimate the\nlikelihood of unfavorable events. We introduce smart simulation that offers a\ncomputationally-efficient way of detecting low-probability situations compared\nto standard Monte-Carlo simulations. Moreover, for certain class of problems,\nour inference-based method can provide guarantees on correctly detecting task\nfailures.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 22:39:08 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Al-Hussaini", "Sarah", ""], ["Gregory", "Jason M.", ""], ["Shriyam", "Shaurya", ""], ["Gupta", "Satyandra K.", ""]]}, {"id": "1909.06508", "submitter": "Connor Brooks", "authors": "Connor Brooks and Daniel Szafir", "title": "Building Second-Order Mental Models for Human-Robot Interaction", "comments": null, "journal-ref": "2019 AAAI Fall Symposium Series", "doi": null, "report-no": "AI-HRI/2019/18", "categories": "cs.RO cs.HC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The mental models that humans form of other agents---encapsulating human\nbeliefs about agent goals, intentions, capabilities, and more---create an\nunderlying basis for interaction. These mental models have the potential to\naffect both the human's decision making during the interaction and the human's\nsubjective assessment of the interaction. In this paper, we surveyed existing\nmethods for modeling how humans view robots, then identified a potential method\nfor improving these estimates through inferring a human's model of a robot\nagent directly from their actions. Then, we conducted an online study to\ncollect data in a grid-world environment involving humans moving an avatar past\na virtual agent. Through our analysis, we demonstrated that participants'\naction choices leaked information about their mental models of a virtual agent.\nWe conclude by discussing the implications of these findings and the potential\nfor such a method to improve human-robot interactions.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 02:08:06 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Brooks", "Connor", ""], ["Szafir", "Daniel", ""]]}, {"id": "1909.06537", "submitter": "Mashrur Rashik", "authors": "Mashrur Rashik, Md. Musfiqur Rahman, Md. Mamun-or-Rashid, Md. Mosaddek\n  Khan", "title": "Speeding Up Distributed Pseudo-tree Optimization Procedure with Cross\n  Edge Consistency to Solve DCOPs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed Pseudo-tree Optimization Procedure (DPOP) is a well-known message\npassing algorithm that has been used to provide optimal solutions of\nDistributed Constraint Optimization Problems (DCOPs) -- a framework that is\ndesigned to optimize constraints in cooperative multi-agent systems. The\ntraditional DCOP formulation does not consider those constraints that must be\nsatisfied (also known as hard constraints), rather it concentrates only on soft\nconstraints. However, the presence of both types of constraints are observed in\na number of applications, such as Distributed Radio Link Frequency Assignment\nand Distributed Event Scheduling, etc. Although the combination of these types\nof constraints is recently incorporated in DPOP to solve DCOPs, scalability\nremains an issue for them as finding an optimal solution is NP-hard.\nAdditionally, in DPOP, the agents are arranged as a DFS pseudo-tree. Recently\nit has been observed that the constructed pseudo-trees in this way often come\nto be chain-like and greatly impair the algorithm's performance. To address\nthese issues, we develop an algorithm that speeds up the DPOP algorithm by\nreducing the size of the messages exchanged and increasing parallelism in the\npseudo tree. Our empirical evidence suggests that our approach outperforms the\nstate-of-the-art algorithms by a significant margin.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 05:38:50 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Rashik", "Mashrur", ""], ["Rahman", "Md. Musfiqur", ""], ["Mamun-or-Rashid", "Md.", ""], ["Khan", "Md. Mosaddek", ""]]}, {"id": "1909.06711", "submitter": "Joseph Monaco", "authors": "Joseph D. Monaco, Grace M. Hwang, Kevin M. Schultz, Kechen Zhang", "title": "Cognitive swarming in complex environments with attractor dynamics and\n  oscillatory computing", "comments": "16 pages, 7 figures", "journal-ref": "Biol Cybern 114, 269-284 (2020)", "doi": "10.1007/s00422-020-00823-z", "report-no": null, "categories": "cs.MA cs.NE cs.RO nlin.AO q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neurobiological theories of spatial cognition developed with respect to\nrecording data from relatively small and/or simplistic environments compared to\nanimals' natural habitats. It has been unclear how to extend theoretical models\nto large or complex spaces. Complementarily, in autonomous systems technology,\napplications have been growing for distributed control methods that scale to\nlarge numbers of low-footprint mobile platforms. Animals and many-robot groups\nmust solve common problems of navigating complex and uncertain environments.\nHere, we introduce the 'NeuroSwarms' control framework to investigate whether\nadaptive, autonomous swarm control of minimal artificial agents can be achieved\nby direct analogy to neural circuits of rodent spatial cognition. NeuroSwarms\nanalogizes agents to neurons and swarming groups to recurrent networks. We\nimplemented neuron-like agent interactions in which mutually visible agents\noperate as if they were reciprocally-connected place cells in an attractor\nnetwork. We attributed a phase state to agents to enable patterns of\noscillatory synchronization similar to hippocampal models of theta-rhythmic\n(5-12 Hz) sequence generation. We demonstrate that multi-agent swarming and\nreward-approach dynamics can be expressed as a mobile form of Hebbian learning\nand that NeuroSwarms supports a single-entity paradigm that directly informs\ntheoretical models of animal cognition. We present emergent behaviors including\nphase-organized rings and trajectory sequences that interact with environmental\ncues and geometry in large, fragmented mazes. Thus, NeuroSwarms is a model\nartificial spatial system that integrates autonomous control and theoretical\nneuroscience to potentially uncover common principles to advance both domains.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 02:02:22 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Monaco", "Joseph D.", ""], ["Hwang", "Grace M.", ""], ["Schultz", "Kevin M.", ""], ["Zhang", "Kechen", ""]]}, {"id": "1909.06890", "submitter": "Saar Tochner", "authors": "Saar Tochner, Stefan Schmid and Aviv Zohar", "title": "Hijacking Routes in Payment Channel Networks: A Predictability Tradeoff", "comments": "13 pages, 20 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.GT cs.MA cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Off-chain transaction networks can mitigate the scalability issues of today's\ntrustless electronic cash systems such as Bitcoin. However, these peer-to-peer\nnetworks also introduce a new attack surface which is not well-understood\ntoday. This paper identifies and analyzes, a novel Denial-of-Service attack\nwhich is based on route hijacking, i.e., which exploits the way transactions\nare routed and executed along the created channels of the network. This attack\nis conceptually interesting as even a limited attacker that manipulates the\ntopology through the creation of new channels can navigate tradeoffs related to\nthe way it attacks the network. Furthermore, the attack also highlights a\nfundamental design tradeoff for the defender (who determines its own routes):\nto become less predictable and hence secure, a rational node has to pay higher\nfees to nodes that forward its payments. We find that the three most common\nimplementations for payment channels in Bitcoin (lnd, C-lightning, Eclair)\napproach routing differently. We begin by surveying the current state of the\nLightning network and explore the routes chosen by these implementations. We\nfind that in the current network nearly 60\\% of all routes pass through only\nfive nodes, while 80\\% go through only 10 nodes. Thus, a relatively small\nnumber of colluding nodes can deny service to a large fraction of the network.\n  We then turn to study an external attacker who creates links to the network\nand draws more routes through its nodes by asking for lower fees. We find that\njust five new links are enough to draw the majority (65\\% - 75\\%) of the\ntraffic regardless of the implementation being used. The cost of creating these\nlinks is very low.\n  We discuss the differences between implementations and eventually derive our\nown suggested routing policy, which is based on a novel combination of existing\napproaches.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 21:34:59 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Tochner", "Saar", ""], ["Schmid", "Stefan", ""], ["Zohar", "Aviv", ""]]}, {"id": "1909.06963", "submitter": "Wilko Schwarting", "authors": "Wilko Schwarting, Alyssa Pierson, Sertac Karaman, Daniela Rus", "title": "Stochastic Dynamic Games in Belief Space", "comments": "Accepted in IEEE Transactions on Robotics (T-RO) 2021", "journal-ref": "IEEE Transactions on Robotics (T-RO) 2021", "doi": null, "report-no": null, "categories": "cs.RO cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information gathering while interacting with other agents under sensing and\nmotion uncertainty is critical in domains such as driving, service robots,\nracing, or surveillance. The interests of agents may be at odds with others,\nresulting in a stochastic non-cooperative dynamic game. Agents must predict\nothers' future actions without communication, incorporate their actions into\nthese predictions, account for uncertainty and noise in information gathering,\nand consider what information their actions reveal. Our solution uses local\niterative dynamic programming in Gaussian belief space to solve a\ngame-theoretic continuous POMDP. Solving a quadratic game in the backward pass\nof a game-theoretic belief-space variant of iLQG achieves a runtime polynomial\nin the number of agents and linear in the planning horizon. Our algorithm\nyields linear feedback policies for our robot, and predicted feedback policies\nfor other agents. We present three applications: active surveillance, guiding\neyes for a blind agent, and autonomous racing. Agents with game-theoretic\nbelief-space planning win 44% more races than without game theory and 34% more\nthan without belief-space planning.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 03:11:40 GMT"}, {"version": "v2", "created": "Thu, 13 May 2021 01:08:18 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Schwarting", "Wilko", ""], ["Pierson", "Alyssa", ""], ["Karaman", "Sertac", ""], ["Rus", "Daniela", ""]]}, {"id": "1909.07487", "submitter": "Jayam Umesh Patel", "authors": "Jayam Patel and Carlo Pinciroli", "title": "Improving Human Performance Using Mixed Granularity of Control in\n  Multi-Human Multi-Robot Interaction", "comments": "8 pages, submitted to IEEE ROMAN 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the potentially large number of units involved, the interaction with a\nmulti-robot system is likely to exceed the limits of the span of apprehension\nof any individual human operator. In previous work, we studied how this issue\ncan be tackled by interacting with the robots in two modalities --\nenvironment-oriented and robot-oriented. In this paper, we study how this\nconcept can be applied to the case in which multiple human operators perform\nsupervisory control on a multi-robot system. While the presence of extra\noperators suggests that more complex tasks could be accomplished, little\nresearch exists on how this could be achieved efficiently. In particular, one\nchallenge arises -- the out-of-the-loop performance problem caused by a lack of\nengagement in the task, awareness of its state, and trust in the system and in\nthe other operators. Through a user study involving 28 human operators and 8\nreal robots, we study how the concept of mixed granularity in multi-human\nmulti-robot interaction affects user engagement, awareness, and trust while\nbalancing the workload between multiple operators.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 21:17:00 GMT"}, {"version": "v2", "created": "Wed, 29 Apr 2020 13:55:56 GMT"}, {"version": "v3", "created": "Fri, 24 Jul 2020 14:34:19 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Patel", "Jayam", ""], ["Pinciroli", "Carlo", ""]]}, {"id": "1909.07528", "submitter": "Bowen Baker", "authors": "Bowen Baker, Ingmar Kanitscheider, Todor Markov, Yi Wu, Glenn Powell,\n  Bob McGrew, Igor Mordatch", "title": "Emergent Tool Use From Multi-Agent Autocurricula", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Through multi-agent competition, the simple objective of hide-and-seek, and\nstandard reinforcement learning algorithms at scale, we find that agents create\na self-supervised autocurriculum inducing multiple distinct rounds of emergent\nstrategy, many of which require sophisticated tool use and coordination. We\nfind clear evidence of six emergent phases in agent strategy in our\nenvironment, each of which creates a new pressure for the opposing team to\nadapt; for instance, agents learn to build multi-object shelters using moveable\nboxes which in turn leads to agents discovering that they can overcome\nobstacles using ramps. We further provide evidence that multi-agent competition\nmay scale better with increasing environment complexity and leads to behavior\nthat centers around far more human-relevant skills than other self-supervised\nreinforcement learning methods such as intrinsic motivation. Finally, we\npropose transfer and fine-tuning as a way to quantitatively evaluate targeted\ncapabilities, and we compare hide-and-seek agents to both intrinsic motivation\nand random initialization baselines in a suite of domain-specific intelligence\ntests.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 00:17:02 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 00:56:50 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Baker", "Bowen", ""], ["Kanitscheider", "Ingmar", ""], ["Markov", "Todor", ""], ["Wu", "Yi", ""], ["Powell", "Glenn", ""], ["McGrew", "Bob", ""], ["Mordatch", "Igor", ""]]}, {"id": "1909.07543", "submitter": "Bogdan Mazoure", "authors": "Thang Doan, Bogdan Mazoure, Moloud Abdar, Audrey Durand, Joelle\n  Pineau, R Devon Hjelm", "title": "Attraction-Repulsion Actor-Critic for Continuous Control Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuous control tasks in reinforcement learning are important because they\nprovide an important framework for learning in high-dimensional state spaces\nwith deceptive rewards, where the agent can easily become trapped into\nsuboptimal solutions. One way to avoid local optima is to use a population of\nagents to ensure coverage of the policy space, yet learning a population with\nthe \"best\" coverage is still an open problem. In this work, we present a novel\napproach to population-based RL in continuous control that leverages properties\nof normalizing flows to perform attractive and repulsive operations between\ncurrent members of the population and previously observed policies. Empirical\nresults on the MuJoCo suite demonstrate a high performance gain for our\nalgorithm compared to prior work, including Soft-Actor Critic (SAC).\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 01:28:20 GMT"}, {"version": "v2", "created": "Tue, 24 Sep 2019 16:29:36 GMT"}, {"version": "v3", "created": "Thu, 9 Jul 2020 13:51:16 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Doan", "Thang", ""], ["Mazoure", "Bogdan", ""], ["Abdar", "Moloud", ""], ["Durand", "Audrey", ""], ["Pineau", "Joelle", ""], ["Hjelm", "R Devon", ""]]}, {"id": "1909.07650", "submitter": "Georgios Amanatidis", "authors": "Georgios Amanatidis, Apostolos Ntokos, Evangelos Markakis", "title": "Multiple Birds with One Stone: Beating $1/2$ for EFX and GMMS via Envy\n  Cycle Elimination", "comments": null, "journal-ref": "Theor. Comput. Sci. 841: 94-109 (2020)", "doi": "10.1016/j.tcs.2020.07.006", "report-no": null, "categories": "cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several relaxations of envy-freeness, tailored to fair division in settings\nwith indivisible goods, have been introduced within the last decade. Due to the\nlack of general existence results for most of these concepts, great attention\nhas been paid to establishing approximation guarantees. In this work, we\npropose a simple algorithm that is universally fair in the sense that it\nreturns allocations that have good approximation guarantees with respect to\nfour such fairness notions at once. In particular, this is the first algorithm\nachieving a $(\\phi-1)$-approximation of envy-freeness up to any good (EFX) and\na $\\frac{2}{\\phi +2}$-approximation of groupwise maximin share fairness (GMMS),\nwhere $\\phi$ is the golden ratio ($\\phi \\approx 1.618$). The best known\napproximation factor for either one of these fairness notions prior to this\nwork was $1/2$. Moreover, the returned allocation achieves envy-freeness up to\none good (EF1) and a $2/3$-approximation of pairwise maximin share fairness\n(PMMS). While EFX is our primary focus, we also exhibit how to fine-tune our\nalgorithm and improve the guarantees for GMMS or PMMS. Finally, we show that\nGMMS -- and thus PMMS and EFX -- allocations always exist when the number of\ngoods does not exceed the number of agents by more than two.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 08:46:46 GMT"}, {"version": "v2", "created": "Sat, 6 Mar 2021 02:33:37 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Amanatidis", "Georgios", ""], ["Ntokos", "Apostolos", ""], ["Markakis", "Evangelos", ""]]}, {"id": "1909.07775", "submitter": "Junhua Liu", "authors": "Junhua Liu, Kristin L. Wood, Kwan Hui Lim", "title": "Strategic and Crowd-Aware Itinerary Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a rapidly growing demand for itinerary planning in tourism but this\ntask remains complex and difficult, especially when considering the need to\noptimize for queuing time and crowd levels for multiple users. This difficulty\nis further complicated by the large amount of parameters involved, i.e.,\nattraction popularity, queuing time, walking time, operating hours, etc. Many\nrecent works propose solutions based on the single-person perspective, but\notherwise do not address real-world problems resulting from natural crowd\nbehavior, such as the Selfish Routing problem, which describes the consequence\nof ineffective network and sub-optimal social outcome by leaving agents to\ndecide freely. In this work, we propose the Strategic and Crowd-Aware Itinerary\nRecommendation (SCAIR) algorithm which optimizes social welfare in real-world\nsituations. We formulate the strategy of route recommendation as Markov chains\nwhich enables our simulations to be carried out in poly-time. We then evaluate\nour proposed algorithm against various competitive and realistic baselines\nusing a theme park dataset. Our simulation results highlight the existence of\nthe Selfish Routing problem and show that SCAIR outperforms the baselines in\nhandling this issue.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 11:09:47 GMT"}, {"version": "v2", "created": "Sun, 6 Oct 2019 12:52:32 GMT"}, {"version": "v3", "created": "Sun, 26 Apr 2020 17:00:56 GMT"}, {"version": "v4", "created": "Tue, 9 Jun 2020 14:55:22 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Liu", "Junhua", ""], ["Wood", "Kristin L.", ""], ["Lim", "Kwan Hui", ""]]}, {"id": "1909.07867", "submitter": "Braden Hurl", "authors": "Braden Hurl, Robin Cohen, Krzysztof Czarnecki, Steven Waslander", "title": "TruPercept: Trust Modelling for Autonomous Vehicle Cooperative\n  Perception from Synthetic Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.CV cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inter-vehicle communication for autonomous vehicles (AVs) stands to provide\nsignificant benefits in terms of perception robustness. We propose a novel\napproach for AVs to communicate perceptual observations, tempered by trust\nmodelling of peers providing reports. Based on the accuracy of reported object\ndetections as verified locally, communicated messages can be fused to augment\nperception performance beyond line of sight and at great distance from the ego\nvehicle. Also presented is a new synthetic dataset which can be used to test\ncooperative perception. The TruPercept dataset includes unreliable and\nmalicious behaviour scenarios to experiment with some challenges cooperative\nperception introduces. The TruPercept runtime and evaluation framework allows\nmodular component replacement to facilitate ablation studies as well as the\ncreation of new trust scenarios we are able to show.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 14:57:45 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Hurl", "Braden", ""], ["Cohen", "Robin", ""], ["Czarnecki", "Krzysztof", ""], ["Waslander", "Steven", ""]]}, {"id": "1909.08008", "submitter": "Yi-Fan Chung", "authors": "Yi-Fan Chung and Solmaz S. Kia", "title": "Distributed Leader Following of an Active Leader for Linear\n  Heterogeneous Multi-Agent Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers a leader-following problem for a group of heterogeneous\nlinear time invariant (LTI) followers that are interacting over a directed\nacyclic graph. Only a subset of the followers has access to the state of the\nleader in specific sampling times. The dynamics of the leader that generates\nits sampled states is unknown to the followers. For interaction topologies in\nwhich the leader is a global sink in the graph, we propose a distributed\nalgorithm that allows the followers to arrive at the sampled state of the\nleader by the time the next sample arrives. Our algorithm is a practical\nsolution for a leader-following problem when there is no information available\nabout the state of the leader except its instantaneous value at the sampling\ntimes. Our algorithm also allows the followers to track the sampled state of\nthe leader with a locally chosen offset that can be time-varying. When the\nfollowers are mobile agents whose state or part of their state is their\nposition vector, the offset mechanism can be used to enable the followers to\nform a transnational invariant formation about the sampled state of the leader.\nWe prove that the control input of the followers to take them from one sampled\nstate to the next one is minimum energy. We also show in case of the\nhomogeneous followers, after the first sampling epoch the states and inputs of\nall the followers are synchronized with each other. Numerical examples\ndemonstrate our results.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 18:12:08 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 19:22:22 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Chung", "Yi-Fan", ""], ["Kia", "Solmaz S.", ""]]}, {"id": "1909.08259", "submitter": "EPTCS", "authors": "Francesco Fabiano (University of Udine)", "title": "Design of a Solver for Multi-Agent Epistemic Planning", "comments": "In Proceedings ICLP 2019, arXiv:1909.07646. arXiv admin note: text\n  overlap with arXiv:1511.01960 by other authors", "journal-ref": "EPTCS 306, 2019, pp. 403-412", "doi": "10.4204/EPTCS.306.54", "report-no": null, "categories": "cs.AI cs.IT cs.LO cs.MA math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the interest in Artificial Intelligence continues to grow it is becoming\nmore and more important to investigate formalization and tools that allow us to\nexploit logic to reason about the world. In particular, given the increasing\nnumber of multi-agents systems that could benefit from techniques of automated\nreasoning, exploring new ways to define not only the world's status but also\nthe agents' information is constantly growing in importance. This type of\nreasoning, i.e., about agents' perception of the world and also about agents'\nknowledge of her and others' knowledge, is referred to as epistemic reasoning.\n  In our work we will try to formalize this concept, expressed through\nepistemic logic, for dynamic domains. In particular we will attempt to define a\nnew action-based language for multi-agent epistemic planning and to implement\nan epistemic planner based on it. This solver should provide a tool flexible\nenough to be able to reason on different domains, e.g., economy, security,\njustice and politics, where reasoning about others' beliefs could lead to\nwinning strategies or help in changing a group of agents' view of the world.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 07:14:28 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Fabiano", "Francesco", "", "University of Udine"]]}, {"id": "1909.08290", "submitter": "Indranil Saha", "authors": "Sankar Das and Swaprava Nath and Indranil Saha", "title": "SPARCAS: A Decentralized, Truthful Multi-Agent Collision-free Path\n  Finding Mechanism", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a decentralized collision-avoidance mechanism for a group of\nindependently controlled robots moving on a shared workspace. Existing\nalgorithms achieve multi-robot collision avoidance either (a) in a centralized\nsetting, or (b) in a decentralized setting with collaborative robots. We focus\non the setting with competitive robots in a decentralized environment, where\nrobots may strategically reveal their information to get prioritized. We\npropose the mechanism SPARCAS in this setting that, using principles of\nmechanism design, ensures truthful revelation of the robots' private\ninformation and provides locally efficient movement of the robots. It is free\nfrom collisions and deadlocks, and handles a dynamic arrival of robots. In\npractice, this mechanism scales well for a large number of robots where the\noptimal collision-avoiding path-finding algorithm (M*) does not scale. Yet,\nSPARCAS does not compromise the path optimality too much. Our mechanism\nprioritizes the robots in the order of their `true' higher needs, but for a\nhigher payment. It uses monetary transfers which is small enough compared to\nthe value received by the robots.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 08:56:21 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Das", "Sankar", ""], ["Nath", "Swaprava", ""], ["Saha", "Indranil", ""]]}, {"id": "1909.08345", "submitter": "Jianxiang Xi", "authors": "Jianxiang Xi, Cheng Wang, Xiaojun Yang, Bailong Yang", "title": "Limited-budget output consensus for descriptor multiagent systems with\n  energy constraints", "comments": "10 pages, 5 figures", "journal-ref": "IEEE Transactions on Cybernetics 2020", "doi": "10.1109/TCYB.2019.2963172", "report-no": null, "categories": "cs.MA cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current paper deals with limited-budget output consensus for descriptor\nmultiagent systems with two types of switching communication topologies; that\nis, switching connected ones and jointly connected ones. Firstly, a singular\ndynamic output feedback control protocol with switching communication\ntopologies is proposed on the basis of the observable decomposition, where an\nenergy constraint is involved and protocol states of neighboring agents are\nutilized to derive a new two-step design approach of gain matrices. Then,\nlimited-budget output consensus problems are transformed into asymptotic\nstability ones and a valid candidate of the output consensus function is\ndetermined. Furthermore, sufficient conditions for limited-budget output\nconsensus design for two types of switching communication topologies are\nproposed, respectively. Finally, two numerical simulations are shown to\ndemonstrate theoretical conclusions.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 10:43:09 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Xi", "Jianxiang", ""], ["Wang", "Cheng", ""], ["Yang", "Xiaojun", ""], ["Yang", "Bailong", ""]]}, {"id": "1909.08540", "submitter": "Pier Giuseppe Sessa", "authors": "Pier Giuseppe Sessa, Ilija Bogunovic, Maryam Kamgarpour, Andreas\n  Krause", "title": "No-Regret Learning in Unknown Games with Correlated Payoffs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning to play a repeated multi-agent game with\nan unknown reward function. Single player online learning algorithms attain\nstrong regret bounds when provided with full information feedback, which\nunfortunately is unavailable in many real-world scenarios. Bandit feedback\nalone, i.e., observing outcomes only for the selected action, yields\nsubstantially worse performance. In this paper, we consider a natural model\nwhere, besides a noisy measurement of the obtained reward, the player can also\nobserve the opponents' actions. This feedback model, together with a regularity\nassumption on the reward function, allows us to exploit the correlations among\ndifferent game outcomes by means of Gaussian processes (GPs). We propose a\nnovel confidence-bound based bandit algorithm GP-MW, which utilizes the GP\nmodel for the reward function and runs a multiplicative weight (MW) method. We\nobtain novel kernel-dependent regret bounds that are comparable to the known\nbounds in the full information setting, while substantially improving upon the\nexisting bandit results. We experimentally demonstrate the effectiveness of\nGP-MW in random matrix games, as well as real-world problems of traffic routing\nand movie recommendation. In our experiments, GP-MW consistently outperforms\nseveral baselines, while its performance is often comparable to methods that\nhave access to full information feedback.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 16:09:09 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 09:08:04 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Sessa", "Pier Giuseppe", ""], ["Bogunovic", "Ilija", ""], ["Kamgarpour", "Maryam", ""], ["Krause", "Andreas", ""]]}, {"id": "1909.08914", "submitter": "Leonardo Colombo", "authors": "Leonardo Colombo, Hector Garcia de Marina, Mar\\'ia Barbero Li\\~n\\'an\n  and David Mart\\'in de Diego", "title": "On the observability of relative positions in left-invariant multi-agent\n  control systems and its application to formation control", "comments": "Accepted paper for CDC conference 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.MA cs.RO cs.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the localization problem between agents while they run a\nformation control algorithm. These algorithms typically demand from the agents\nthe information about their relative positions with respect to their neighbors.\nWe assume that this information is not available. Therefore, the agents need to\nsolve the observability problem of reconstructing their relative positions\nbased on other measurements between them. We first model the relative\nkinematics between the agents as a left-invariant control system so that we can\nexploit its appealing properties to solve the observability problem. Then, as a\nparticular application, we will focus on agents running a distance-based\ncontrol algorithm where their relative positions are not accessible but the\ndistances between them are.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 10:53:44 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Colombo", "Leonardo", ""], ["de Marina", "Hector Garcia", ""], ["Li\u00f1\u00e1n", "Mar\u00eda Barbero", ""], ["de Diego", "David Mart\u00edn", ""]]}, {"id": "1909.08974", "submitter": "Jianxiang Xi", "authors": "Le Wang, Jianxiang Xi, Ming He, Guangbin Liu", "title": "Robust time-varying formation design for multi-agent systems with\n  disturbances: Extended-state-observer method", "comments": "14 pages, 5 figures", "journal-ref": "INTERNATIONAL JOURNAL OF ROBUST AND NONLINEAR CONTROL Volume: 30\n  Issue: 7 Pages: 2796-2808 Published: MAY 10 2020", "doi": "10.1002/rnc.4941", "report-no": null, "categories": "cs.MA cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust time-varying formation design problems for second-order multi-agent\nsystems subjected to external disturbances are investigated. Firstly, by\nconstructing an extended state observer, the disturbance compensation is\nestimated, which is a critical term in the proposed robust time-varying\nformation control protocol. Then, an explicit expression of the formation\ncenter function is determined and impacts of disturbance compensations on the\nformation center function are presented. With the formation feasibility\nconditions, robust time-varying formation design criteria are derived to\ndetermine the gain matrix of the formation control protocol by utilizing the\nalgebraic Riccati equation technique. Furthermore, the tracking performance and\nthe robustness property of multi-agent systems are analyzed. Finally, the\nnumerical simulation is provided to illustrate the effectiveness of theoretical\nresults.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 13:22:54 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Wang", "Le", ""], ["Xi", "Jianxiang", ""], ["He", "Ming", ""], ["Liu", "Guangbin", ""]]}, {"id": "1909.08996", "submitter": "Andrea Loreggia", "authors": "Cristina Cornelio, Michele Donini, Andrea Loreggia, Maria Silvia Pini\n  and Francesca Rossi", "title": "Voting with Random Classifiers (VORACE): Theoretical and Experimental\n  Analysis", "comments": null, "journal-ref": "Autonomous Agents and Multi-Agent Systems volume 35, Article\n  number: 22 (2021)", "doi": "10.1007/s10458-021-09504-y", "report-no": null, "categories": "cs.LG cs.AI cs.GT cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many machine learning scenarios, looking for the best classifier that fits\na particular dataset can be very costly in terms of time and resources.\nMoreover, it can require deep knowledge of the specific domain. We propose a\nnew technique which does not require profound expertise in the domain and\navoids the commonly used strategy of hyper-parameter tuning and model\nselection. Our method is an innovative ensemble technique that uses voting\nrules over a set of randomly-generated classifiers. Given a new input sample,\nwe interpret the output of each classifier as a ranking over the set of\npossible classes. We then aggregate these output rankings using a voting rule,\nwhich treats them as preferences over the classes. We show that our approach\nobtains good results compared to the state-of-the-art, both providing a\ntheoretical analysis and an empirical evaluation of the approach on several\ndatasets.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 08:13:53 GMT"}, {"version": "v2", "created": "Tue, 3 Dec 2019 09:37:08 GMT"}, {"version": "v3", "created": "Mon, 24 May 2021 08:00:06 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Cornelio", "Cristina", ""], ["Donini", "Michele", ""], ["Loreggia", "Andrea", ""], ["Pini", "Maria Silvia", ""], ["Rossi", "Francesca", ""]]}, {"id": "1909.09087", "submitter": "Dung Tran Hoang", "authors": "Hoang-Dung Tran, Luan Viet Nguyen, Patrick Musau, Weiming Xiang, and\n  Taylor T. Johnson", "title": "Real-Time Verification for Distributed Cyber-Physical Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Safety-critical distributed cyber-physical systems (CPSs) have been found in\na wide range of applications. Notably, they have displayed a great deal of\nutility in intelligent transportation, where autonomous vehicles communicate\nand cooperate with each other via a high-speed communication network. Such\nsystems require an ability to identify maneuvers in real-time that cause\ndangerous circumstances and ensure the implementation always meets\nsafety-critical requirements. In this paper, we propose a real-time\ndecentralized reachability approach for safety verification of a distributed\nmulti-agent CPS with the underlying assumption that all agents are\ntime-synchronized with a low degree of error. In the proposed approach, each\nagent periodically computes its local reachable set and exchanges this\nreachable set with the other agents with the goal of verifying the system\nsafety. Our method, implemented in Java, takes advantages of the timing\ninformation and the reachable set information that are available in the\nexchanged messages to reason about the safety of the whole system in a\ndecentralized manner. Any particular agent can also perform local safety\nverification tasks based on their local clocks by analyzing the messages it\nreceives. We applied the proposed method to verify, in real-time, the safety\nproperties of a group of quadcopters performing a distributed search mission.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 16:42:21 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Tran", "Hoang-Dung", ""], ["Nguyen", "Luan Viet", ""], ["Musau", "Patrick", ""], ["Xiang", "Weiming", ""], ["Johnson", "Taylor T.", ""]]}, {"id": "1909.09228", "submitter": "James Hare", "authors": "James Z. Hare and Cesar A. Uribe and Lance Kaplan and Ali Jadbabaie", "title": "Non-Bayesian Social Learning with Uncertain Models", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2020.3006755", "report-no": null, "categories": "cs.AI cs.MA cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-Bayesian social learning theory provides a framework that models\ndistributed inference for a group of agents interacting over a social network.\nIn this framework, each agent iteratively forms and communicates beliefs about\nan unknown state of the world with their neighbors using a learning rule.\nExisting approaches assume agents have access to precise statistical models (in\nthe form of likelihoods) for the state of the world. However in many\nsituations, such models must be learned from finite data. We propose a social\nlearning rule that takes into account uncertainty in the statistical models\nusing second-order probabilities. Therefore, beliefs derived from uncertain\nmodels are sensitive to the amount of past evidence collected for each\nhypothesis. We characterize how well the hypotheses can be tested on a social\nnetwork, as consistent or not with the state of the world. We explicitly show\nthe dependency of the generated beliefs with respect to the amount of prior\nevidence. Moreover, as the amount of prior evidence goes to infinity, learning\noccurs and is consistent with traditional social learning theory.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 19:58:50 GMT"}, {"version": "v2", "created": "Fri, 27 Sep 2019 18:19:15 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Hare", "James Z.", ""], ["Uribe", "Cesar A.", ""], ["Kaplan", "Lance", ""], ["Jadbabaie", "Ali", ""]]}, {"id": "1909.09390", "submitter": "Gildas Morvan", "authors": "Yu-Lin Huang and Gildas Morvan and Fr\\'ed\\'eric Pichon and David\n  Mercier", "title": "SPSC: a new execution policy for exploring discrete-time stochastic\n  simulations", "comments": "Accepted in PRIMA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a new method called SPSC (Simulation,\nPartitioning, Selection, Cloning) to estimate efficiently the probability of\npossible solutions in stochastic simulations. This method can be applied to any\ntype of simulation, however it is particularly suitable for multi-agent-based\nsimulations (MABS). Therefore, its performance is evaluated on a well-known\nMABS and compared to the classical approach, i.e., Monte Carlo.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 09:37:06 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Huang", "Yu-Lin", ""], ["Morvan", "Gildas", ""], ["Pichon", "Fr\u00e9d\u00e9ric", ""], ["Mercier", "David", ""]]}, {"id": "1909.09397", "submitter": "Nick Malleson", "authors": "Nick Malleson, Kevin Minors, Le-Minh Kieu, Jonathan A. Ward, Andrew A.\n  West, Alison Heppenstall", "title": "Simulating Crowds in Real Time with Agent-Based Modelling and a Particle\n  Filter", "comments": null, "journal-ref": null, "doi": "10.18564/jasss.4266", "report-no": null, "categories": "cs.MA", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Agent-based modelling is a valuable approach for systems whose behaviour is\ndriven by the interactions between distinct entities. They have shown\nparticular promise as a means of modelling crowds of people in streets, public\ntransport terminals, stadiums, etc. However, the methodology faces a\nfundamental difficulty: there are no established mechanisms for dynamically\nincorporating real-time data into models. This limits simulations that are\ninherently dynamic, such as pedestrian movements, to scenario testing of, for\nexample, the potential impacts of new architectural configurations on\nmovements. This paper begins to address this fundamental gap by demonstrating\nhow a particle filter could be used to incorporate real data into an\nagent-based model of pedestrian movements at run time. The experiments show\nthat it is indeed possible to use a particle filter to perform online (real\ntime) model optimisation. However, as the number of agents increases, the\nnumber of individual particles (and hence the computational complexity)\nrequired increases exponentially. By laying the groundwork for the real-time\nsimulation of crowd movements, this paper has implications for the management\nof complex environments (both nationally and internationally) such as\ntransportation hubs, hospitals, shopping centres, etc.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 09:54:30 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Malleson", "Nick", ""], ["Minors", "Kevin", ""], ["Kieu", "Le-Minh", ""], ["Ward", "Jonathan A.", ""], ["West", "Andrew A.", ""], ["Heppenstall", "Alison", ""]]}, {"id": "1909.09417", "submitter": "Stefan Vlaski", "authors": "Stefan Vlaski, Lieven Vandenberghe, Ali H. Sayed", "title": "Regularized Diffusion Adaptation via Conjugate Smoothing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DC cs.MA eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of this work is to develop and study a distributed strategy for\nPareto optimization of an aggregate cost consisting of regularized risks. Each\nrisk is modeled as the expectation of some loss function with unknown\nprobability distribution while the regularizers are assumed deterministic, but\nare not required to be differentiable or even continuous. The individual,\nregularized, cost functions are distributed across a strongly-connected network\nof agents and the Pareto optimal solution is sought by appealing to a\nmulti-agent diffusion strategy. To this end, the regularizers are smoothed by\nmeans of infimal convolution and it is shown that the Pareto solution of the\napproximate, smooth problem can be made arbitrarily close to the solution of\nthe original, non-smooth problem. Performance bounds are established under\nconditions that are weaker than assumed before in the literature, and hence\napplicable to a broader class of adaptation and learning problems.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 10:39:45 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Vlaski", "Stefan", ""], ["Vandenberghe", "Lieven", ""], ["Sayed", "Ali H.", ""]]}, {"id": "1909.09461", "submitter": "Cedric Buron", "authors": "C\\'edric Buron, Zahia Guessoum (CRESTIC), Sylvain Ductor (UECE)", "title": "MCTS-based Automated Negotiation Agent", "comments": null, "journal-ref": "The 22nd International Conference on Principles and Practice of\n  Multi-Agent Systems (PRIMA2019), Oct 2019, Torino, Italy", "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new negotiating agent model for automated\nnegotiation. We focus on applications without time pressure with\nmultidi-mensional negotiation on both continuous and discrete domains. The\nagent bidding strategy relies on Monte Carlo Tree Search, which is a trendy\nmethod since it has been used with success on games with high branching factor\nsuch as Go. It also exploits opponent modeling techniques thanks to Gaussian\nprocess regression and Bayesian learning. Evaluation is done by confronting the\nexisting agents that are able to negotiate in such context: Random Walker,\nTit-for-tat and Nice Tit-for-Tat. None of those agents succeeds in beating our\nagent. Also, the modular and adaptive nature of our approach is a huge\nadvantage when it comes to optimize it in specific applicative contexts.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 11:32:48 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Buron", "C\u00e9dric", "", "CRESTIC"], ["Guessoum", "Zahia", "", "CRESTIC"], ["Ductor", "Sylvain", "", "UECE"]]}, {"id": "1909.09721", "submitter": "Renhao Wang", "authors": "Renhao Wang, Adam Scibior, Frank Wood", "title": "Safer End-to-End Autonomous Driving via Conditional Imitation Learning\n  and Command Augmentation", "comments": "Architecture fails to sufficiently disentangle representations and\n  obey varied commands", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation learning is a promising approach to end-to-end training of\nautonomous vehicle controllers. Typically the driving process with such\napproaches is entirely automatic and black-box, although in practice it is\ndesirable to control the vehicle through high-level commands, such as telling\nit which way to go at an intersection. In existing work this has been\naccomplished by the application of a branched neural architecture, since\ndirectly providing the command as an additional input to the controller often\nresults in the command being ignored. In this work we overcome this limitation\nby learning a disentangled probabilistic latent variable model that generates\nthe steering commands. We achieve faithful command-conditional generation\nwithout using a branched architecture and demonstrate improved stability of the\ncontroller, applying only a variational objective without any domain-specific\nadjustments. On top of that, we extend our model with an additional latent\nvariable and augment the dataset to train a controller that is robust to unsafe\ncommands, such as asking it to turn into a wall. The main contribution of this\nwork is a recipe for building controllable imitation driving agents that\nimproves upon multiple aspects of the current state of the art relating to\nrobustness and interpretability.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 21:24:05 GMT"}, {"version": "v2", "created": "Tue, 17 Mar 2020 08:33:10 GMT"}, {"version": "v3", "created": "Fri, 20 Nov 2020 17:50:16 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Wang", "Renhao", ""], ["Scibior", "Adam", ""], ["Wood", "Frank", ""]]}, {"id": "1909.09849", "submitter": "Shayegan Omidshafiei", "authors": "Mark Rowland, Shayegan Omidshafiei, Karl Tuyls, Julien Perolat, Michal\n  Valko, Georgios Piliouras, Remi Munos", "title": "Multiagent Evaluation under Incomplete Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the evaluation of learned multiagent strategies in\nthe incomplete information setting, which plays a critical role in ranking and\ntraining of agents. Traditionally, researchers have relied on Elo ratings for\nthis purpose, with recent works also using methods based on Nash equilibria.\nUnfortunately, Elo is unable to handle intransitive agent interactions, and\nother techniques are restricted to zero-sum, two-player settings or are limited\nby the fact that the Nash equilibrium is intractable to compute. Recently, a\nranking method called {\\alpha}-Rank, relying on a new graph-based\ngame-theoretic solution concept, was shown to tractably apply to general games.\nHowever, evaluations based on Elo or {\\alpha}-Rank typically assume noise-free\ngame outcomes, despite the data often being collected from noisy simulations,\nmaking this assumption unrealistic in practice. This paper investigates\nmultiagent evaluation in the incomplete information regime, involving\ngeneral-sum many-player games with noisy outcomes. We derive sample complexity\nguarantees required to confidently rank agents in this setting. We propose\nadaptive algorithms for accurate ranking, provide correctness and sample\ncomplexity guarantees, then introduce a means of connecting uncertainties in\nnoisy match outcomes to uncertainties in rankings. We evaluate the performance\nof these approaches in several domains, including Bernoulli games, a soccer\nmeta-game, and Kuhn poker.\n", "versions": [{"version": "v1", "created": "Sat, 21 Sep 2019 16:05:31 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 16:21:02 GMT"}, {"version": "v3", "created": "Thu, 21 Nov 2019 10:05:19 GMT"}, {"version": "v4", "created": "Fri, 10 Jan 2020 09:59:37 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Rowland", "Mark", ""], ["Omidshafiei", "Shayegan", ""], ["Tuyls", "Karl", ""], ["Perolat", "Julien", ""], ["Valko", "Michal", ""], ["Piliouras", "Georgios", ""], ["Munos", "Remi", ""]]}, {"id": "1909.10070", "submitter": "Vivek Khatana", "authors": "Vivek Khatana, Govind Saraswat, Sourav Patel, Murti V. Salapaka", "title": "Gradient-Consensus: Linearly Convergent Distributed Optimization\n  Algorithm over Directed Graphs", "comments": "14 pages, 3 figures, 1 Appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we propose a new approach, optimize then agree for\nminimizing a sum $ f = \\sum_{i=1}^n f_i(x)$ of convex objective functions over\na directed graph. The optimize then agree approach decouples the optimization\nstep and the consensus step in a distributed optimization framework. The key\nmotivation for optimize then agree is to guarantee that the disagreement\nbetween the estimates of the agents during every iteration of the distributed\noptimization algorithm remains under any apriori specified tolerance; existing\nalgorithms do not provide such a guarantee which is required in many practical\nscenarios. In this method, each agent during each iteration maintains an\nestimate of the optimal solution and, utilizes its locally available gradient\ninformation along with a finite-time approximate consensus protocol to move\ntowards the optimal solution (hence the name Gradient-Consensus algorithm). We\nestablish that the proposed algorithm has a global R-linear rate of convergence\nif the aggregate function $f$ is strongly convex and Lipschitz differentiable.\nWe also show that under the relaxed assumption of $f_i$'s being convex and\nLipschitz differentiable, the objective function error residual decreases at a\nQ-linear rate (in terms of the number of gradient computation steps) until it\nreaches a small value, which can be managed using the tolerance value specified\non the finite-time approximate consensus protocol; no existing method in the\nliterature has such strong convergence guarantees when $f_i$ are not\nnecessarily strongly convex functions. The communication overhead for the\nimproved guarantees on meeting constraints and better convergence of our\nalgorithm is $O(k\\log k)$ iterates in comparison to $O(k)$ of the traditional\nalgorithms. Further, we numerically evaluate the performance of the proposed\nalgorithm by solving a distributed logistic regression problem.\n", "versions": [{"version": "v1", "created": "Sun, 22 Sep 2019 19:04:27 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 22:08:04 GMT"}, {"version": "v3", "created": "Thu, 23 Apr 2020 06:50:24 GMT"}, {"version": "v4", "created": "Thu, 30 Jul 2020 18:15:48 GMT"}, {"version": "v5", "created": "Mon, 26 Apr 2021 22:06:33 GMT"}, {"version": "v6", "created": "Sat, 22 May 2021 16:04:46 GMT"}, {"version": "v7", "created": "Wed, 26 May 2021 04:25:34 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Khatana", "Vivek", ""], ["Saraswat", "Govind", ""], ["Patel", "Sourav", ""], ["Salapaka", "Murti V.", ""]]}, {"id": "1909.10093", "submitter": "Jakub Mare\\v{c}ek", "authors": "Ramen Ghosh, Jakub Marecek, Robert Shorten", "title": "Iterated Piecewise-Stationary Random Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.MA cs.SY eess.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Within the study of uncertain dynamical systems, iterated random functions\nare a key tool. There, one samples a family of functions according to a\nstationary distribution. Here, we introduce an extension, where one sample\nfunctions according to a time-varying distribution over the family of\nfunctions. For such iterated piecewise-stationary random functions on Polish\nspaces, we prove a number of results, including a bound on the tracking error.\n", "versions": [{"version": "v1", "created": "Sun, 22 Sep 2019 21:05:25 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Ghosh", "Ramen", ""], ["Marecek", "Jakub", ""], ["Shorten", "Robert", ""]]}, {"id": "1909.10378", "submitter": "Jacopo Panerati", "authors": "Jacopo Panerati (1), Benjamin Ramtoula (1), David St-Onge (1), Yanjun\n  Cao (1), Marcel Kaufmann (1), Aidan Cowley (2), Lorenzo Sabattini (3),\n  Giovanni Beltrame (1) ((1) Polytechnique Montreal, (2) European Astronaut\n  Centre, (3) University of Modena and Reggio Emilia)", "title": "Decentralized Connectivity Control in Quadcopters: a Field Study of\n  Communication Performance", "comments": "7 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Redundancy and parallelism make decentralized multi-robot systems appealing\nsolutions for the exploration of extreme environments. However, effective\ncooperation often requires team-wide connectivity and a carefully designed\ncommunication strategy. Several recently proposed decentralized connectivity\nmaintenance approaches exploit elegant algebraic results drawn from spectral\ngraph theory. Yet, these proposals are rarely taken beyond simulations or\nlaboratory implementations. In this work, we present two major contributions:\n(i) we describe the full-stack implementation---from hardware to software---of\na decentralized control law for robust connectivity maintenance; and (ii) we\nassess, in the field, our setup's ability to correctly exchange all the\nnecessary information required to maintain connectivity in a team of\nquadcopters.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 14:11:15 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Panerati", "Jacopo", ""], ["Ramtoula", "Benjamin", ""], ["St-Onge", "David", ""], ["Cao", "Yanjun", ""], ["Kaufmann", "Marcel", ""], ["Cowley", "Aidan", ""], ["Sabattini", "Lorenzo", ""], ["Beltrame", "Giovanni", ""]]}, {"id": "1909.10387", "submitter": "Jacopo Panerati", "authors": "Hehui Zheng (1), Jacopo Panerati (2), Giovanni Beltrame (2), Amanda\n  Prorok (1) ((1) University of Cambridge, (2) Polytechnique Montreal)", "title": "An Adversarial Approach to Private Flocking in Mobile Robot Teams", "comments": "10 pages, 13 figures", "journal-ref": "IEEE Robotics and Automation Letters (2020)", "doi": "10.1109/LRA.2020.2967331", "report-no": null, "categories": "cs.RO cs.LG cs.MA cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Privacy is an important facet of defence against adversaries. In this letter,\nwe introduce the problem of private flocking. We consider a team of mobile\nrobots flocking in the presence of an adversary, who is able to observe all\nrobots' trajectories, and who is interested in identifying the leader. We\npresent a method that generates private flocking controllers that hide the\nidentity of the leader robot. Our approach towards privacy leverages a\ndata-driven adversarial co-optimization scheme. We design a mechanism that\noptimizes flocking control parameters, such that leader inference is hindered.\nAs the flocking performance improves, we successively train an adversarial\ndiscriminator that tries to infer the identity of the leader robot. To evaluate\nthe performance of our co-optimization scheme, we investigate different classes\nof reference trajectories. Although it is reasonable to assume that there is an\ninherent trade-off between flocking performance and privacy, our results\ndemonstrate that we are able to achieve high flocking performance and\nsimultaneously reduce the risk of revealing the leader.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 14:28:56 GMT"}, {"version": "v2", "created": "Mon, 9 Dec 2019 12:58:07 GMT"}, {"version": "v3", "created": "Fri, 24 Jan 2020 17:23:47 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Zheng", "Hehui", "", "University of Cambridge"], ["Panerati", "Jacopo", "", "Polytechnique Montreal"], ["Beltrame", "Giovanni", "", "Polytechnique Montreal"], ["Prorok", "Amanda", "", "University of Cambridge"]]}, {"id": "1909.10476", "submitter": "Binil Starly", "authors": "Binil Starly, Atin Angrish, Paul Cohen", "title": "Research Directions in Democratizing Innovation through Design\n  Automation, One-Click Manufacturing Services and Intelligent Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.CV cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The digitalization of manufacturing has created opportunities for consumers\nto customize products that fit their individualized needs which in turn would\ndrive demand for manufacturing services. However, this pull-based manufacturing\nsystem production of extremely low quantity and limitless variety for products\nis expensive to implement. New emerging technology in design automation driven\nby data-driven computational design, manufacturing-as-a-service marketplaces\nand digitally enabled micro-factories holds promise towards democratization of\ninnovation. In this paper, scientific, technology and infrastructure challenges\nare identified and if solved, the impact of these emerging technologies on\nproduct innovation and future factory organization is discussed.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 16:56:08 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Starly", "Binil", ""], ["Angrish", "Atin", ""], ["Cohen", "Paul", ""]]}, {"id": "1909.10651", "submitter": "Zhi Zhang", "authors": "Zhi Zhang, Jiachen Yang, Hongyuan Zha", "title": "Integrating independent and centralized multi-agent reinforcement\n  learning for traffic signal network optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traffic congestion in metropolitan areas is a world-wide problem that can be\nameliorated by traffic lights that respond dynamically to real-time conditions.\nRecent studies applying deep reinforcement learning (RL) to optimize single\ntraffic lights have shown significant improvement over conventional control.\nHowever, optimization of global traffic condition over a large road network\nfundamentally is a cooperative multi-agent control problem, for which\nsingle-agent RL is not suitable due to environment non-stationarity and\ninfeasibility of optimizing over an exponential joint-action space. Motivated\nby these challenges, we propose QCOMBO, a simple yet effective multi-agent\nreinforcement learning (MARL) algorithm that combines the advantages of\nindependent and centralized learning. We ensure scalability by selecting\nactions from individually optimized utility functions, which are shaped to\nmaximize global performance via a novel consistency regularization loss between\nindividual utility and a global action-value function. Experiments on diverse\nroad topologies and traffic flow conditions in the SUMO traffic simulator show\ncompetitive performance of QCOMBO versus recent state-of-the-art MARL\nalgorithms. We further show that policies trained on small sub-networks can\neffectively generalize to larger networks under different traffic flow\nconditions, providing empirical evidence for the suitability of MARL for\nintelligent traffic control.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 23:39:00 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Zhang", "Zhi", ""], ["Yang", "Jiachen", ""], ["Zha", "Hongyuan", ""]]}, {"id": "1909.10737", "submitter": "Weihao Xuan", "authors": "Weihao Xuan, Ruijie Ren", "title": "Multi-agent Interactive Prediction under Challenging Driving Scenarios", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to drive safely on the road, autonomous vehicle is expected to\npredict future outcomes of its surrounding environment and react properly. In\nfact, many researchers have been focused on solving behavioral prediction\nproblems for autonomous vehicles. However, very few of them consider\nmulti-agent prediction under challenging driving scenarios such as urban\nenvironment. In this paper, we proposed a prediction method that is able to\npredict various complicated driving scenarios where heterogeneous road\nentities, signal lights, and static map information are taken into account.\nMoreover, the proposed multi-agent interactive prediction (MAIP) system is\ncapable of simultaneously predicting any number of road entities while\nconsidering their mutual interactions. A case study of a simulated challenging\nurban intersection scenario is provided to demonstrate the performance and\ncapability of the proposed prediction system.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 07:16:32 GMT"}, {"version": "v2", "created": "Fri, 7 Feb 2020 05:47:39 GMT"}, {"version": "v3", "created": "Tue, 3 Nov 2020 16:09:21 GMT"}, {"version": "v4", "created": "Tue, 10 Nov 2020 19:09:37 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Xuan", "Weihao", ""], ["Ren", "Ruijie", ""]]}, {"id": "1909.10873", "submitter": "Dominik Baumann", "authors": "Dominik Baumann, Fabian Mager, Romain Jacob, Lothar Thiele, Marco\n  Zimmerling, and Sebastian Trimpe", "title": "Fast Feedback Control over Multi-hop Wireless Networks with Mode Changes\n  and Stability Guarantees", "comments": "Accepted for publication in ACM Transactions on Cyber-Physical\n  Systems. arXiv admin note: text overlap with arXiv:1804.08986", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Closing feedback loops fast and over long distances is key to emerging\ncyber-physical applications; for example, robot motion control and swarm\ncoordination require update intervals of tens of milliseconds. Low-power\nwireless communication technology is preferred for its low cost, small form\nfactor, and flexibility, especially if the devices support multi-hop\ncommunication. Thus far, however, feedback control over multi-hop low-power\nwireless networks has only been demonstrated for update intervals on the order\nof seconds. To fill this gap, this paper presents a wireless embedded system\nthat supports dynamic mode changes and tames imperfections impairing control\nperformance (e.g., jitter and message loss), and a control design that exploits\nthe essential properties of this system to provably guarantee closed-loop\nstability for physical processes with linear time-invariant dynamics in the\npresence of mode changes. Using experiments on a cyber-physical testbed with 20\nwireless devices and multiple cart-pole systems, we are the first to\ndemonstrate and evaluate feedback control and coordination with mode changes\nover multi-hop networks for update intervals of 20 to 50 milliseconds.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 19:22:09 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Baumann", "Dominik", ""], ["Mager", "Fabian", ""], ["Jacob", "Romain", ""], ["Thiele", "Lothar", ""], ["Zimmerling", "Marco", ""], ["Trimpe", "Sebastian", ""]]}, {"id": "1909.10874", "submitter": "Mostafa Safi", "authors": "Mostafa Safi, Seyed Mehran Dibaji and Mohammad Pirani", "title": "Resilient Coordinated Movement of Connected Autonomous Vehicles", "comments": "10 pages, 7 figures, 1 algorithm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.CR cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider coordinated movement of a network of vehicles\nconsisting of a bounded number of malicious agents, that is, vehicles must\nreach consensus in longitudinal position and a common predefined velocity. The\nmotions of vehicles are modeled by double-integrator dynamics and\ncommunications over the network are asynchronous with delays. Each normal\nvehicle updates its states by utilizing the information it receives from\nvehicles in its vicinity. On the other hand, misbehaving vehicles make updates\narbitrarily and might threaten the consensus within the network by\nintentionally changing their moving direction or broadcasting faulty\ninformation in their neighborhood. We propose an asynchronous updating strategy\nfor normal vehicles, based on filtering extreme values received from\nneighboring vehicles, to save them from being misguided by malicious vehicles.\nWe show that there exist topological constraints on the network in terms of\ngraph robustness under which the vehicles resiliently achieve coordinated\nmovement. Numerical simulations are provided to evaluate the results.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 00:57:48 GMT"}, {"version": "v2", "created": "Wed, 11 Nov 2020 17:06:42 GMT"}, {"version": "v3", "created": "Tue, 15 Dec 2020 12:06:50 GMT"}, {"version": "v4", "created": "Thu, 29 Jul 2021 06:45:56 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Safi", "Mostafa", ""], ["Dibaji", "Seyed Mehran", ""], ["Pirani", "Mohammad", ""]]}, {"id": "1909.10925", "submitter": "Alexander Peysakhovich", "authors": "Christian Kroer, Alexander Peysakhovich", "title": "Scalable Fair Division for 'At Most One' Preferences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.MA econ.EM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Allocating multiple scarce items across a set of individuals is an important\npractical problem. In the case of divisible goods and additive preferences a\nconvex program can be used to find the solution that maximizes Nash welfare\n(MNW). The MNW solution is equivalent to finding the equilibrium of a market\neconomy (aka. the competitive equilibrium from equal incomes, CEEI) and thus\nhas good properties such as Pareto optimality, envy-freeness, and incentive\ncompatibility in the large. Unfortunately, this equivalence (and nice\nproperties) breaks down for general preference classes. Motivated by real world\nproblems such as course allocation and recommender systems we study the case of\nadditive `at most one' (AMO) preferences - individuals want at most 1 of each\nitem and lotteries are allowed. We show that in this case the MNW solution is\nstill a convex program and importantly is a CEEI solution when the instance\ngets large but has a `low rank' structure. Thus a polynomial time algorithm can\nbe used to scale CEEI (which is in general PPAD-hard) for AMO preferences. We\nexamine whether the properties guaranteed in the limit hold approximately in\nfinite samples using several real datasets.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 13:50:06 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Kroer", "Christian", ""], ["Peysakhovich", "Alexander", ""]]}, {"id": "1909.11046", "submitter": "Youngjae Min", "authors": "Youngjae Min, Soon-Seo Park, Han-Lim Choi", "title": "Informative Planning of Mobile Sensor Networks in GPS-Denied\n  Environments", "comments": "14 pages, 10 figures, Accepted to 2020 AIAA SciTech: Guidance,\n  Navigation, and Control (GN&C)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.MA cs.SY stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the problem to plan mobile sensor networks for target\nlocalization task in GPS-denied environments. Most researches on mobile sensor\nnetworks assume that the states of the sensing agents are precisely known\nduring their missions, which is not feasible under the absence of external\ninfrastructures such as GPS. Thus, we propose a new algorithm to solve this\nproblem by: (i) estimating the states of the sensing agents in addition to the\ntarget's through the combination of a particle filter (PF) and extended Kalman\nfilters (EKF) and (ii) involving the uncertainty of the states of the sensing\nagents in planning the sensor networks based on the combined filters. This\napproach does not require any additional internal/external sensors nor the\nprior knowledge of the surrounding environments. We demonstrate the limitations\nof prior works in GPS-denied environments and the improvements from the\nproposed algorithm through Monte Carlo experiments.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 16:58:01 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Min", "Youngjae", ""], ["Park", "Soon-Seo", ""], ["Choi", "Han-Lim", ""]]}, {"id": "1909.11084", "submitter": "Gabriel Istrate", "authors": "Gabriel Istrate, Cosmin Bonchis and Claudiu Gatina", "title": "It's Not Whom You Know, It's What You (or Your Friends) Can Do: Succint\n  Coalitional Frameworks for Network Centralities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the representation of measures of network centrality using a\nframework that blends a social network representation with the succint\nformalism of cooperative skill games. We discuss the expressiveness of the new\nframework and highlight some of its advantages, including a fixed-parameter\ntractability result for computing centrality measures under such\nrepresentations. As an application we introduce new network centrality measures\nthat capture the extent to which neighbors of a certain node can help it\ncomplete relevant tasks.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 17:59:26 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Istrate", "Gabriel", ""], ["Bonchis", "Cosmin", ""], ["Gatina", "Claudiu", ""]]}, {"id": "1909.11191", "submitter": "Rustam Pirmagomedov", "authors": "Rustam Pirmagomedov and Yevgeni Koucheryavy", "title": "IoT Technologies for Augmented Human: a Survey", "comments": "9 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.MA eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet of Things (IoT) technology has delivered new enablers for improving\nhuman abilities. These enablers promise an enhanced quality of life and\nprofessional efficiency; however, the synthesis of IoT and human augmentation\ntechnologies has also extended IoT-related challenges far beyond the current\nscope. These potential challenges associated with IoT-empowered Augmented Human\n(AH) have so far not been well-investigated. Thus, this article attempts to\nintroduce readers to AH concept as well as summarize notable research\nchallenges raised by such systems, in order to facilitate reader's further\ninterest in this topic. The article considers emerging IoT applications for\nhuman augmentation, devices and design principles, connectivity demands, and\nsecurity aspects.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 21:20:40 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Pirmagomedov", "Rustam", ""], ["Koucheryavy", "Yevgeni", ""]]}, {"id": "1909.11227", "submitter": "Kishan Chandan", "authors": "Kishan Chandan, Vidisha Kudalkar, Xiang Li, Shiqi Zhang", "title": "Negotiation-based Human-Robot Collaboration via Augmented Reality", "comments": null, "journal-ref": null, "doi": null, "report-no": "AI-HRI/2019/28", "categories": "cs.RO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective human-robot collaboration (HRC) requires extensive communication\namong the human and robot teammates, because their actions can potentially\nproduce conflicts, synergies, or both. We develop a novel augmented reality\n(AR) interface to bridge the communication gap between human and robot\nteammates. Building on our AR interface, we develop an AR-mediated,\nnegotiation-based (ARN) framework for HRC. We have conducted experiments both\nin simulation and on real robots in an office environment, where multiple\nmobile robots work on delivery tasks. The robots could not complete the tasks\non their own, but sometimes need help from their human teammate, rendering\nhuman-robot collaboration necessary. Results suggest that ARN significantly\nreduced the human-robot team's task completion time compared to a non-AR\nbaseline approach.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 23:34:36 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2020 18:08:01 GMT"}, {"version": "v3", "created": "Fri, 13 Mar 2020 01:39:24 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Chandan", "Kishan", ""], ["Kudalkar", "Vidisha", ""], ["Li", "Xiang", ""], ["Zhang", "Shiqi", ""]]}, {"id": "1909.11468", "submitter": "Xiaotian Hao", "authors": "Xiaotian Hao, Weixun Wang, Jianye Hao and Yaodong Yang", "title": "Independent Generative Adversarial Self-Imitation Learning in\n  Cooperative Multiagent Systems", "comments": "accepted as a full paper by AAMAS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many tasks in practice require the collaboration of multiple agents through\nreinforcement learning. In general, cooperative multiagent reinforcement\nlearning algorithms can be classified into two paradigms: Joint Action Learners\n(JALs) and Independent Learners (ILs). In many practical applications, agents\nare unable to observe other agents' actions and rewards, making JALs\ninapplicable. In this work, we focus on independent learning paradigm in which\neach agent makes decisions based on its local observations only. However,\nlearning is challenging in independent settings due to the local viewpoints of\nall agents, which perceive the world as a non-stationary environment due to the\nconcurrently exploring teammates. In this paper, we propose a novel framework\ncalled Independent Generative Adversarial Self-Imitation Learning (IGASIL) to\naddress the coordination problems in fully cooperative multiagent environments.\nTo the best of our knowledge, we are the first to combine self-imitation\nlearning with generative adversarial imitation learning (GAIL) and apply it to\ncooperative multiagent systems. Besides, we put forward a Sub-Curriculum\nExperience Replay mechanism to pick out the past beneficial experiences as much\nas possible and accelerate the self-imitation learning process. Evaluations\nconducted in the testbed of StarCraft unit micromanagement and a commonly\nadopted benchmark show that our IGASIL produces state-of-the-art results and\neven outperforms JALs in terms of both convergence speed and final performance.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 13:11:33 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Hao", "Xiaotian", ""], ["Wang", "Weixun", ""], ["Hao", "Jianye", ""], ["Yang", "Yaodong", ""]]}, {"id": "1909.11628", "submitter": "Yaodong Yang Mr.", "authors": "Yaodong Yang, Rasul Tutunov, Phu Sakulwongtana, Haitham Bou Ammar", "title": "$\\alpha^{\\alpha}$-Rank: Practically Scaling $\\alpha$-Rank through\n  Stochastic Optimisation", "comments": "AAMAS 2020 Full Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, $\\alpha$-Rank, a graph-based algorithm, has been proposed as a\nsolution to ranking joint policy profiles in large scale multi-agent systems.\n$\\alpha$-Rank claimed tractability through a polynomial time implementation\nwith respect to the total number of pure strategy profiles. Here, we note that\ninputs to the algorithm were not clearly specified in the original\npresentation; as such, we deem complexity claims as not grounded, and\nconjecture solving $\\alpha$-Rank is NP-hard. The authors of $\\alpha$-Rank\nsuggested that the input to $\\alpha$-Rank can be an exponentially-sized payoff\nmatrix; a claim promised to be clarified in subsequent manuscripts. Even though\n$\\alpha$-Rank exhibits a polynomial-time solution with respect to such an\ninput, we further reflect additional critical problems. We demonstrate that due\nto the need of constructing an exponentially large Markov chain, $\\alpha$-Rank\nis infeasible beyond a small finite number of agents. We ground these claims by\nadopting amount of dollars spent as a non-refutable evaluation metric.\nRealising such scalability issue, we present a stochastic implementation of\n$\\alpha$-Rank with a double oracle mechanism allowing for reductions in joint\nstrategy spaces. Our method, $\\alpha^\\alpha$-Rank, does not need to save\nexponentially-large transition matrix, and can terminate early under required\nprecision. Although theoretically our method exhibits similar worst-case\ncomplexity guarantees compared to $\\alpha$-Rank, it allows us, for the first\ntime, to practically conduct large-scale multi-agent evaluations. On $10^4\n\\times 10^4$ random matrices, we achieve $1000x$ speed reduction. Furthermore,\nwe also show successful results on large joint strategy profiles with a maximum\nsize in the order of $\\mathcal{O}(2^{25})$ ($\\approx 33$ million joint\nstrategies) -- a setting not evaluable using $\\alpha$-Rank with reasonable\ncomputational budget.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 17:21:45 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2019 15:38:30 GMT"}, {"version": "v3", "created": "Sat, 28 Sep 2019 22:50:53 GMT"}, {"version": "v4", "created": "Sun, 17 Nov 2019 16:41:39 GMT"}, {"version": "v5", "created": "Thu, 21 Nov 2019 15:41:17 GMT"}, {"version": "v6", "created": "Tue, 3 Mar 2020 00:00:34 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Yang", "Yaodong", ""], ["Tutunov", "Rasul", ""], ["Sakulwongtana", "Phu", ""], ["Ammar", "Haitham Bou", ""]]}, {"id": "1909.11650", "submitter": "David Byrd", "authors": "David Byrd", "title": "Explaining Agent-Based Financial Market Simulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA q-fin.TR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is intended to explain, in simple terms, some of the mechanisms\nand agents common to multiagent financial market simulations. We first discuss\nthe necessity to include an exogenous price time series (\"the fundamental\nvalue\") for each asset and three methods for generating that series. We then\nillustrate one process by which a Bayesian agent may receive limited\nobservations of the fundamental series and estimate its current and future\nvalues. Finally, we present two such agents widely examined in the literature,\nthe Zero Intelligence agent and the Heuristic Belief Learning agent, which\nimplement different approaches to order placement.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 17:54:03 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Byrd", "David", ""]]}, {"id": "1909.11840", "submitter": "Shushman Choudhury", "authors": "Shushman Choudhury, Kiril Solovey, Mykel J. Kochenderfer, Marco Pavone", "title": "Efficient Large-Scale Multi-Drone Delivery Using Transit Networks", "comments": "Final version of IEEE ICRA 2020 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of controlling a large fleet of drones to deliver\npackages simultaneously across broad urban areas. To conserve energy, drones\nhop between public transit vehicles (e.g., buses and trams). We design a\ncomprehensive algorithmic framework that strives to minimize the maximum time\nto complete any delivery. We address the multifaceted complexity of the problem\nthrough a two-layer approach. First, the upper layer assigns drones to package\ndelivery sequences with a near-optimal polynomial-time task allocation\nalgorithm. Then, the lower layer executes the allocation by periodically\nrouting the fleet over the transit network while employing efficient\nbounded-suboptimal multi-agent pathfinding techniques tailored to our setting.\nExperiments demonstrate the efficiency of our approach on settings with up to\n$200$ drones, $5000$ packages, and transit networks with up to $8000$ stops in\nSan Francisco and Washington DC. Our results show that the framework computes\nsolutions typically within a few seconds on commodity hardware, and that drones\ntravel up to $360 \\%$ of their flight range with public transit.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 01:47:18 GMT"}, {"version": "v2", "created": "Sun, 1 Mar 2020 01:15:24 GMT"}, {"version": "v3", "created": "Sun, 26 Apr 2020 22:19:13 GMT"}, {"version": "v4", "created": "Thu, 11 Jun 2020 19:13:42 GMT"}, {"version": "v5", "created": "Tue, 5 Jan 2021 18:52:23 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Choudhury", "Shushman", ""], ["Solovey", "Kiril", ""], ["Kochenderfer", "Mykel J.", ""], ["Pavone", "Marco", ""]]}, {"id": "1909.12557", "submitter": "Heechang Ryu", "authors": "Heechang Ryu, Hayong Shin, Jinkyoo Park", "title": "Multi-Agent Actor-Critic with Hierarchical Graph Attention Network", "comments": "Accepted as a conference paper at the Thirty-Fourth AAAI Conference\n  on Artificial Intelligence (AAAI-20), New York, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Most previous studies on multi-agent reinforcement learning focus on deriving\ndecentralized and cooperative policies to maximize a common reward and rarely\nconsider the transferability of trained policies to new tasks. This prevents\nsuch policies from being applied to more complex multi-agent tasks. To resolve\nthese limitations, we propose a model that conducts both representation\nlearning for multiple agents using hierarchical graph attention network and\npolicy learning using multi-agent actor-critic. The hierarchical graph\nattention network is specially designed to model the hierarchical relationships\namong multiple agents that either cooperate or compete with each other to\nderive more advanced strategic policies. Two attention networks, the\ninter-agent and inter-group attention layers, are used to effectively model\nindividual and group level interactions, respectively. The two attention\nnetworks have been proven to facilitate the transfer of learned policies to new\ntasks with different agent compositions and allow one to interpret the learned\nstrategies. Empirically, we demonstrate that the proposed model outperforms\nexisting methods in several mixed cooperative and competitive tasks.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 08:40:01 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2019 02:38:58 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Ryu", "Heechang", ""], ["Shin", "Hayong", ""], ["Park", "Jinkyoo", ""]]}, {"id": "1909.12777", "submitter": "Ali Rahmati", "authors": "Ali Rahmati, Seyyedali Hosseinalipour, Yavuz Yapici, Xiaofan He,\n  Ismail Guvenc, Huaiyu Dai, Arupjyoti Bhuyan", "title": "Dynamic Interference Management for UAV-Assisted Wireless Networks", "comments": "12 pages, 13 figures. arXiv admin note: substantial text overlap with\n  arXiv:1904.07781", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The deployment of unmanned aerial vehicles (UAVs) is proliferating as they\nare effective, flexible and cost-efficient devices for a variety of\napplications ranging from natural disaster recovery to delivery of goods. We\ninvestigate a transmission mechanism aiming to improve the data rate between a\nbase station (BS) and a user equipment through deploying multiple relaying\nUAVs. We consider the effect of interference, which is incurred by the nodes of\nanother established communication network. Our primary goal is to design the 3D\ntrajectories and power allocation for the UAVs to maximize the data flow while\nthe interference constraint is met. The UAVs can reconfigure their locations to\nevade the unintended/intended interference caused by reckless/smart\ninterferers. We also consider the scenario in which smart jammers chase the\nUAVs to degrade the communication quality. In this case, we investigate the\nproblem from the perspective of both UAV network and smart jammers. An\nalternating-maximization approach is proposed to address the joint 3D\ntrajectory design and power allocation problem. We handle the 3D trajectory\ndesign by resorting to spectral graph theory and subsequently address the power\nallocation through convex optimization techniques. Finally, we demonstrate the\nefficacy of our proposed method through simulations.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 05:24:08 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Rahmati", "Ali", ""], ["Hosseinalipour", "Seyyedali", ""], ["Yapici", "Yavuz", ""], ["He", "Xiaofan", ""], ["Guvenc", "Ismail", ""], ["Dai", "Huaiyu", ""], ["Bhuyan", "Arupjyoti", ""]]}, {"id": "1909.12823", "submitter": "Shayegan Omidshafiei", "authors": "Paul Muller, Shayegan Omidshafiei, Mark Rowland, Karl Tuyls, Julien\n  Perolat, Siqi Liu, Daniel Hennes, Luke Marris, Marc Lanctot, Edward Hughes,\n  Zhe Wang, Guy Lever, Nicolas Heess, Thore Graepel, Remi Munos", "title": "A Generalized Training Approach for Multiagent Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates a population-based training regime based on\ngame-theoretic principles called Policy-Spaced Response Oracles (PSRO). PSRO is\ngeneral in the sense that it (1) encompasses well-known algorithms such as\nfictitious play and double oracle as special cases, and (2) in principle\napplies to general-sum, many-player games. Despite this, prior studies of PSRO\nhave been focused on two-player zero-sum games, a regime wherein Nash\nequilibria are tractably computable. In moving from two-player zero-sum games\nto more general settings, computation of Nash equilibria quickly becomes\ninfeasible. Here, we extend the theoretical underpinnings of PSRO by\nconsidering an alternative solution concept, $\\alpha$-Rank, which is unique\n(thus faces no equilibrium selection issues, unlike Nash) and applies readily\nto general-sum, many-player settings. We establish convergence guarantees in\nseveral games classes, and identify links between Nash equilibria and\n$\\alpha$-Rank. We demonstrate the competitive performance of\n$\\alpha$-Rank-based PSRO against an exact Nash solver-based PSRO in 2-player\nKuhn and Leduc Poker. We then go beyond the reach of prior PSRO applications by\nconsidering 3- to 5-player poker games, yielding instances where $\\alpha$-Rank\nachieves faster convergence than approximate Nash solvers, thus establishing it\nas a favorable general games solver. We also carry out an initial empirical\nvalidation in MuJoCo soccer, illustrating the feasibility of the proposed\napproach in another complex domain.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 17:49:53 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 15:04:45 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Muller", "Paul", ""], ["Omidshafiei", "Shayegan", ""], ["Rowland", "Mark", ""], ["Tuyls", "Karl", ""], ["Perolat", "Julien", ""], ["Liu", "Siqi", ""], ["Hennes", "Daniel", ""], ["Marris", "Luke", ""], ["Lanctot", "Marc", ""], ["Hughes", "Edward", ""], ["Wang", "Zhe", ""], ["Lever", "Guy", ""], ["Heess", "Nicolas", ""], ["Graepel", "Thore", ""], ["Munos", "Remi", ""]]}, {"id": "1909.13204", "submitter": "Zijia Zhong", "authors": "Zijia Zhong, Mark Nejad, Earl E. Lee, Joyoung Lee", "title": "Clustering Strategies of Cooperative Adaptive Cruise Control: Impacts on\n  Human-driven Vehicles", "comments": "7 pages, 6 figures, 2019 IEEE 2nd Connected and Automated Vehicles\n  Symposium", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a promising application of connected and automated vehicles (CAVs),\nCooperative Adaptive Cruise Control (CACC) is expected to be deployed on the\npublic road in the near term. Thus far the majority of the CACC studies have\nbeen focusing on the overall network performance with limited insight on the\npotential impact of CAVs on human-driven vehicles (HVs). This paper aims to\nquantify the influence of CAVs on HVs by studying the high-resolution vehicle\ntrajectory data that is obtained from microscopic simulation. Two clustering\nstrategies for CACC are implemented: an ad hoc coordination one and a local\ncoordination one. Results show that the local coordination outperforms the ad\nhoc coordination across all tested market penetration rates (MPRs) in terms of\nnetwork throughput and productivity. The greatest performance difference\nbetween the two strategies is observed at 30% and 40% MPR for throughput and\nproductivity, respectively. However, the distributions of the hard braking\nobservations (as a potential safety impact) for HVs change significantly under\nlocal coordination strategy. Regardless of the clustering strategy, CAVs\nincrease the average lane change frequency for HVs. 30% MPR is the break-even\npoint for local coordination, after which the average lane change frequency\ndecreases from the peak 5.42 to 5.38. Such inverse relationship to MPR is not\nfound in the ah hoc case and the average lane change frequency reaches the\nhighest 5.48 at 40% MPR.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 05:41:50 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Zhong", "Zijia", ""], ["Nejad", "Mark", ""], ["Lee", "Earl E.", ""], ["Lee", "Joyoung", ""]]}]