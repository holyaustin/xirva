[{"id": "1707.00497", "submitter": "Angela Fontan", "authors": "Angela Fontan, Claudio Altafini", "title": "Multiequilibria analysis for a class of collective decision-making\n  networked systems", "comments": "13 pages, 10 figures", "journal-ref": "IEEE Transactions on Control of Network Systems, Volume 5, Issue\n  4, Dec. 2018", "doi": "10.1109/TCNS.2017.2774014", "report-no": null, "categories": "math.OC cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The models of collective decision-making considered in this paper are\nnonlinear interconnected cooperative systems with saturating interactions.\nThese systems encode the possible outcomes of a decision process into different\nsteady states of the dynamics. In particular, they are characterized by two\nmain attractors in the positive and negative orthant, representing two choices\nof agreement among the agents, associated to the Perron-Frobenius eigenvector\nof the system. In this paper we give conditions for the appearance of other\nequilibria of mixed sign. The conditions are inspired by Perron-Frobenius\ntheory and are related to the algebraic connectivity of the network. We also\nshow how all these equilibria must be contained in a solid disk of radius given\nby the norm of the equilibrium point which is located in the positive orthant.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jul 2017 12:05:58 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Fontan", "Angela", ""], ["Altafini", "Claudio", ""]]}, {"id": "1707.00832", "submitter": "Gabriele D'Angelo", "authors": "Gabriele D'Angelo, Stefano Ferretti, Vittorio Ghini", "title": "Modeling the Internet of Things: a simulation perspective", "comments": "Proceedings of the IEEE 2017 International Conference on High\n  Performance Computing and Simulation (HPCS 2017)", "journal-ref": null, "doi": "10.1109/HPCS.2017.13", "report-no": null, "categories": "cs.DC cs.MA cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with the problem of properly simulating the Internet of\nThings (IoT). Simulating an IoT allows evaluating strategies that can be\nemployed to deploy smart services over different kinds of territories. However,\nthe heterogeneity of scenarios seriously complicates this task. This imposes\nthe use of sophisticated modeling and simulation techniques. We discuss novel\napproaches for the provision of scalable simulation scenarios, that enable the\nreal-time execution of massively populated IoT environments. Attention is given\nto novel hybrid and multi-level simulation techniques that, when combined with\nagent-based, adaptive Parallel and Distributed Simulation (PADS) approaches,\ncan provide means to perform highly detailed simulations on demand. To support\nthis claim, we detail a use case concerned with the simulation of vehicular\ntransportation systems.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jul 2017 07:16:02 GMT"}, {"version": "v2", "created": "Wed, 20 Sep 2017 13:06:53 GMT"}], "update_date": "2017-09-21", "authors_parsed": [["D'Angelo", "Gabriele", ""], ["Ferretti", "Stefano", ""], ["Ghini", "Vittorio", ""]]}, {"id": "1707.01068", "submitter": "Alexander Peysakhovich", "authors": "Adam Lerer and Alexander Peysakhovich", "title": "Maintaining cooperation in complex social dilemmas using deep\n  reinforcement learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social dilemmas are situations where individuals face a temptation to\nincrease their payoffs at a cost to total welfare. Building artificially\nintelligent agents that achieve good outcomes in these situations is important\nbecause many real world interactions include a tension between selfish\ninterests and the welfare of others. We show how to modify modern reinforcement\nlearning methods to construct agents that act in ways that are simple to\nunderstand, nice (begin by cooperating), provokable (try to avoid being\nexploited), and forgiving (try to return to mutual cooperation). We show both\ntheoretically and experimentally that such agents can maintain cooperation in\nMarkov social dilemmas. Our construction does not require training methods\nbeyond a modification of self-play, thus if an environment is such that good\nstrategies can be constructed in the zero-sum case (eg. Atari) then we can\nconstruct agents that solve social dilemmas in this environment.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jul 2017 17:02:05 GMT"}, {"version": "v2", "created": "Mon, 31 Jul 2017 22:40:15 GMT"}, {"version": "v3", "created": "Sat, 28 Oct 2017 15:23:38 GMT"}, {"version": "v4", "created": "Fri, 2 Mar 2018 14:39:55 GMT"}], "update_date": "2018-03-05", "authors_parsed": [["Lerer", "Adam", ""], ["Peysakhovich", "Alexander", ""]]}, {"id": "1707.01417", "submitter": "Andrzej Kaczmarczyk", "authors": "Robert Bredereck, Piotr Faliszewski, Andrzej Kaczmarczyk, Rolf\n  Niedermeier, Piotr Skowron and Nimrod Talmon", "title": "Robustness Among Multiwinner Voting Rules", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate how robust the results of committee elections are to small\nchanges in the input preference orders, depending on the voting rules used. We\nfind that for typical rules the effect of making a single swap of adjacent\ncandidates in a single preference order is either that (1) at most one\ncommittee member might be replaced, or (2) it is possible that the whole\ncommittee will be replaced. We also show that the problem of computing the\nsmallest number of swaps that lead to changing the election outcome is\ntypically NP-hard, but there are natural FPT algorithms. Finally, for a number\nof rules we assess experimentally the average number of random swaps necessary\nto change the election result.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jul 2017 14:30:32 GMT"}, {"version": "v2", "created": "Tue, 23 Jul 2019 16:11:48 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Bredereck", "Robert", ""], ["Faliszewski", "Piotr", ""], ["Kaczmarczyk", "Andrzej", ""], ["Niedermeier", "Rolf", ""], ["Skowron", "Piotr", ""], ["Talmon", "Nimrod", ""]]}, {"id": "1707.01546", "submitter": "Amartya Sanyal", "authors": "Amartya Sanyal, Sanjana Garg, Asim Unmesh", "title": "Agent based simulation of the evolution of society as an alternate\n  maximization problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the evolution of human society, as a complex adaptive system,\nis a task that has been looked upon from various angles. In this paper, we\nsimulate an agent-based model with a high enough population tractably. To do\nthis, we characterize an entity called \\textit{society}, which helps us reduce\nthe complexity of each step from $\\mathcal{O}(n^2)$ to $\\mathcal{O}(n)$. We\npropose a very realistic setting, where we design a joint alternate\nmaximization step algorithm to maximize a certain \\textit{fitness} function,\nwhich we believe simulates the way societies develop. Our key contributions\ninclude (i) proposing a novel protocol for simulating the evolution of a\nsociety with cheap, non-optimal joint alternate maximization steps (ii)\nproviding a framework for carrying out experiments that adhere to this\njoint-optimization simulation framework (iii) carrying out experiments to show\nthat it makes sense empirically (iv) providing an alternate justification for\nthe use of \\textit{society} in the simulations.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jul 2017 19:19:55 GMT"}], "update_date": "2017-07-07", "authors_parsed": [["Sanyal", "Amartya", ""], ["Garg", "Sanjana", ""], ["Unmesh", "Asim", ""]]}, {"id": "1707.01659", "submitter": "Michael Muehlebach", "authors": "Michael Muehlebach and Sebastian Trimpe", "title": "Distributed Event-Based State Estimation for Networked Systems: An\n  LMI-Approach", "comments": "This is an extended version of an article to appear in the IEEE\n  Transactions on Automatic Control (additional parts in the Appendix)", "journal-ref": null, "doi": "10.1109/TAC.2017.2726002", "report-no": null, "categories": "cs.SY cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, a dynamic system is controlled by multiple sensor-actuator\nagents, each of them commanding and observing parts of the system's input and\noutput. The different agents sporadically exchange data with each other via a\ncommon bus network according to local event-triggering protocols. From these\ndata, each agent estimates the complete dynamic state of the system and uses\nits estimate for feedback control. We propose a synthesis procedure for\ndesigning the agents' state estimators and the event triggering thresholds. The\nresulting distributed and event-based control system is guaranteed to be stable\nand to satisfy a predefined estimation performance criterion. The approach is\napplied to the control of a vehicle platoon, where the method's trade-off\nbetween performance and communication, and the scalability in the number of\nagents is demonstrated.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jul 2017 07:13:28 GMT"}], "update_date": "2017-07-14", "authors_parsed": [["Muehlebach", "Michael", ""], ["Trimpe", "Sebastian", ""]]}, {"id": "1707.02871", "submitter": "Guillaume Cheze", "authors": "Guillaume Ch\\`eze (IMT), Luca Amodei (IMT)", "title": "How to cut a cake with a gram matrix", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we study the problem of fair division. In particular we study\na notion introduced by J. Barbanel that generalizes super envy-free fair\ndivision. We give a new proof of his result. Our approach allows us to give an\nexplicit bound for this kind of fair division. Furthermore, we also give a\ntheoretical answer to an open problem posed by Barbanel in 1996. Roughly\nspeaking, this question is: how can we decide if there exists a fair division\nsatisfying some inequalities constraints? Furthermore, when all the measures\nare given with piecewise constant density functions then we show how to\nconstruct effectively such a fair division.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jul 2017 09:21:18 GMT"}], "update_date": "2017-07-11", "authors_parsed": [["Ch\u00e8ze", "Guillaume", "", "IMT"], ["Amodei", "Luca", "", "IMT"]]}, {"id": "1707.03199", "submitter": "Seema Hegde B", "authors": "Seema B Hegde, B.Sathish babu, Pallapa Venkatram", "title": "A Cognitive Theory-based Opportunistic Resource-Pooling Scheme for Ad\n  hoc Networks", "comments": "22 pages, 16 figures,", "journal-ref": "Journal of Intelligent Systems 2017 Volume 26 issuse 1 pp 47-68", "doi": "10.1515/jisys-2015-0050", "report-no": null, "categories": "cs.NI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Resource pooling in ad hoc networks deals with accumulating computing and\nnetwork resources to implement network control schemes such as routing,\ncongestion, traffic management, and so on. Pooling of resources can be\naccomplished using the distributed and dynamic nature of ad hoc networks to\nachieve collaboration between the devices. Ad hoc networks need a\nresource-pooling technique that offers quick response, adaptability, and\nreliability. In this context, we are proposing an opportunistic resource\npooling scheme that uses a cognitive computing model to accumulate the\nresources with faster resource convergence rate, reliability, and lower\nlatency. The proposed scheme is implemented using the behaviors observations\nbeliefs cognitive model, in which the resource pooling decisions are made based\non accumulated knowledge over various behaviors exhibited by nodes in ad hoc\nnetworks.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jul 2017 09:47:26 GMT"}], "update_date": "2017-07-12", "authors_parsed": [["Hegde", "Seema B", ""], ["babu", "B. Sathish", ""], ["Venkatram", "Pallapa", ""]]}, {"id": "1707.04402", "submitter": "Gregory Palmer", "authors": "Gregory Palmer, Karl Tuyls, Daan Bloembergen, Rahul Savani", "title": "Lenient Multi-Agent Deep Reinforcement Learning", "comments": "9 pages, 6 figures, AAMAS2018 Conference Proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much of the success of single agent deep reinforcement learning (DRL) in\nrecent years can be attributed to the use of experience replay memories (ERM),\nwhich allow Deep Q-Networks (DQNs) to be trained efficiently through sampling\nstored state transitions. However, care is required when using ERMs for\nmulti-agent deep reinforcement learning (MA-DRL), as stored transitions can\nbecome outdated because agents update their policies in parallel [11]. In this\nwork we apply leniency [23] to MA-DRL. Lenient agents map state-action pairs to\ndecaying temperature values that control the amount of leniency applied towards\nnegative policy updates that are sampled from the ERM. This introduces optimism\nin the value-function update, and has been shown to facilitate cooperation in\ntabular fully-cooperative multi-agent reinforcement learning problems. We\nevaluate our Lenient-DQN (LDQN) empirically against the related Hysteretic-DQN\n(HDQN) algorithm [22] as well as a modified version we call scheduled-HDQN,\nthat uses average reward learning near terminal states. Evaluations take place\nin extended variations of the Coordinated Multi-Agent Object Transportation\nProblem (CMOTP) [8] which include fully-cooperative sub-tasks and stochastic\nrewards. We find that LDQN agents are more likely to converge to the optimal\npolicy in a stochastic reward CMOTP compared to standard and scheduled-HDQN\nagents.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jul 2017 07:33:20 GMT"}, {"version": "v2", "created": "Tue, 27 Feb 2018 09:36:29 GMT"}], "update_date": "2018-02-28", "authors_parsed": [["Palmer", "Gregory", ""], ["Tuyls", "Karl", ""], ["Bloembergen", "Daan", ""], ["Savani", "Rahul", ""]]}, {"id": "1707.05429", "submitter": "M.Nazif Faqiry", "authors": "Mohammad Nazif Faqiry, Sanjoy Das", "title": "Distributed Bi-level Energy Allocation Mechanism with Grid Constraints\n  and Hidden User Information", "comments": "Published in IEEE transactions on Smart Grid", "journal-ref": null, "doi": "10.1109/TSG.2017.2779826", "report-no": null, "categories": "cs.SY cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel distributed energy allocation mechanism for Distribution System\nOperator (DSO) market through a bi-level iterative auction is proposed. With\nthe locational marginal price at the substation node known, the DSO runs an\nupper level auction with aggregators as intermediate agents competing for\nenergy. This DSO level auction takes into account physical grid constraints\nsuch as line flows, transformer capacities and node voltage limits. This\nauction mechanism is a straightforward implementation of projected gradient\ndescent on the social welfare (SW) of all home level agents. Aggregators, which\nserve home level agents - both buyers and sellers, implement lower level\nauctions in parallel, through proportional allocation and without asking for\nutility functions and generation capacities that are considered private\ninformation. The overall bi-level auction is shown to be efficient and weakly\nbudget balanced.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jul 2017 01:24:50 GMT"}, {"version": "v2", "created": "Wed, 6 Dec 2017 16:46:22 GMT"}], "update_date": "2017-12-07", "authors_parsed": [["Faqiry", "Mohammad Nazif", ""], ["Das", "Sanjoy", ""]]}, {"id": "1707.06444", "submitter": "Vincenzo Matta", "authors": "Vincenzo Matta and Ali H. Sayed", "title": "Consistent Tomography under Partial Observations over Adaptive Networks", "comments": "Submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work studies the problem of inferring whether an agent is directly\ninfluenced by another agent over an adaptive diffusion network. Agent i\ninfluences agent j if they are connected (according to the network topology),\nand if agent j uses the data from agent i to update its online statistic. The\nsolution of this inference task is challenging for two main reasons. First,\nonly the output of the diffusion learning algorithm is available to the\nexternal observer that must perform the inference based on these indirect\nmeasurements. Second, only output measurements from a fraction of the network\nagents is available, with the total number of agents itself being also unknown.\nThe main focus of this article is ascertaining under these demanding conditions\nwhether consistent tomography is possible, namely, whether it is possible to\nreconstruct the interaction profile of the observable portion of the network,\nwith negligible error as the network size increases. We establish a critical\nachievability result, namely, that for symmetric combination policies and for\nany given fraction of observable agents, the interacting and non-interacting\nagent pairs split into two separate clusters as the network size increases.\nThis remarkable property then enables the application of clustering algorithms\nto identify the interacting agents influencing the observations. We provide a\nset of numerical experiments that verify the results for finite network sizes\nand time horizons. The numerical experiments show that the results hold for\nasymmetric combination policies as well, which is particularly relevant in the\ncontext of causation.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jul 2017 11:08:15 GMT"}], "update_date": "2017-07-21", "authors_parsed": [["Matta", "Vincenzo", ""], ["Sayed", "Ali H.", ""]]}, {"id": "1707.06465", "submitter": "Brian Swenson", "authors": "Brian Swenson, Ryan Murray, Soummya Kar", "title": "On Best-Response Dynamics in Potential Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper studies the convergence properties of (continuous) best-response\ndynamics from game theory. Despite their fundamental role in game theory,\nbest-response dynamics are poorly understood in many games of interest due to\nthe discontinuous, set-valued nature of the best-response map. The paper\nfocuses on elucidating several important properties of best-response dynamics\nin the class of multi-agent games known as potential games---a class of games\nwith fundamental importance in multi-agent systems and distributed control. It\nis shown that in almost every potential game and for almost every initial\ncondition, the best-response dynamics (i) have a unique solution, (ii) converge\nto pure-strategy Nash equilibria, and (iii) converge at an exponential rate.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jul 2017 02:12:39 GMT"}, {"version": "v2", "created": "Wed, 7 Feb 2018 03:28:28 GMT"}], "update_date": "2018-02-08", "authors_parsed": [["Swenson", "Brian", ""], ["Murray", "Ryan", ""], ["Kar", "Soummya", ""]]}, {"id": "1707.06466", "submitter": "Brian Swenson", "authors": "Brian Swenson, Ryan Murray, Soummya Kar", "title": "Regular Potential Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental problem with the Nash equilibrium concept is the existence of\ncertain \"structurally deficient\" equilibria that (i) lack fundamental\nrobustness properties, and (ii) are difficult to analyze. The notion of a\n\"regular\" Nash equilibrium was introduced by Harsanyi. Such equilibria are\nisolated, highly robust, and relatively simple to analyze. A game is said to be\nregular if all equilibria in the game are regular. In this paper it is shown\nthat almost all potential games are regular. That is, except for a closed\nsubset with Lebesgue measure zero, all potential games are regular. As an\nimmediate consequence of this, the paper also proves an oddness result for\npotential games: in almost all potential games, the number of Nash equilibrium\nstrategies is finite and odd. Specialized results are given for weighted\npotential games, exact potential games, and games with identical payoffs.\nApplications of the results to game-theoretic learning are discussed.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jul 2017 02:12:30 GMT"}, {"version": "v2", "created": "Wed, 7 Feb 2018 17:10:35 GMT"}, {"version": "v3", "created": "Tue, 30 Jul 2019 14:18:32 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Swenson", "Brian", ""], ["Murray", "Ryan", ""], ["Kar", "Soummya", ""]]}, {"id": "1707.06492", "submitter": "Toru Fujino", "authors": "Toru Fujino and Yu Chen", "title": "Effects of Network Structure on the Performance of a Modeled Traffic\n  Network under Drivers' Bounded Rationality", "comments": "Submitted to Physica A", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a minority route choice game to investigate the effect of the\nnetwork structure on traffic network performance under the assumption of\ndrivers' bounded rationality. We investigate ring-and-hub topologies to capture\nthe nature of traffic networks in cities, and employ a minority game-based\ninductive learning process to model the characteristic behavior under the route\nchoice scenario. Through numerical experiments, we find that topological\nchanges in traffic networks induce a phase transition from an uncongested phase\nto a congested phase. Understanding this phase transition is helpful in\nplanning new traffic networks.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jul 2017 13:11:16 GMT"}], "update_date": "2017-07-21", "authors_parsed": [["Fujino", "Toru", ""], ["Chen", "Yu", ""]]}, {"id": "1707.06600", "submitter": "Joel Leibo", "authors": "Julien Perolat, Joel Z. Leibo, Vinicius Zambaldi, Charles Beattie,\n  Karl Tuyls, Thore Graepel", "title": "A multi-agent reinforcement learning model of common-pool resource\n  appropriation", "comments": "15 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.NE q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humanity faces numerous problems of common-pool resource appropriation. This\nclass of multi-agent social dilemma includes the problems of ensuring\nsustainable use of fresh water, common fisheries, grazing pastures, and\nirrigation systems. Abstract models of common-pool resource appropriation based\non non-cooperative game theory predict that self-interested agents will\ngenerally fail to find socially positive equilibria---a phenomenon called the\ntragedy of the commons. However, in reality, human societies are sometimes able\nto discover and implement stable cooperative solutions. Decades of behavioral\ngame theory research have sought to uncover aspects of human behavior that make\nthis possible. Most of that work was based on laboratory experiments where\nparticipants only make a single choice: how much to appropriate. Recognizing\nthe importance of spatial and temporal resource dynamics, a recent trend has\nbeen toward experiments in more complex real-time video game-like environments.\nHowever, standard methods of non-cooperative game theory can no longer be used\nto generate predictions for this case. Here we show that deep reinforcement\nlearning can be used instead. To that end, we study the emergent behavior of\ngroups of independently learning agents in a partially observed Markov game\nmodeling common-pool resource appropriation. Our experiments highlight the\nimportance of trial-and-error learning in common-pool resource appropriation\nand shed light on the relationship between exclusion, sustainability, and\ninequality.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jul 2017 16:35:02 GMT"}, {"version": "v2", "created": "Wed, 6 Sep 2017 17:32:44 GMT"}], "update_date": "2017-09-07", "authors_parsed": [["Perolat", "Julien", ""], ["Leibo", "Joel Z.", ""], ["Zambaldi", "Vinicius", ""], ["Beattie", "Charles", ""], ["Tuyls", "Karl", ""], ["Graepel", "Thore", ""]]}, {"id": "1707.06607", "submitter": "Anton Andreychuk", "authors": "Anton Andreychuk and Konstantin Yakovlev", "title": "Applying MAPP Algorithm for Cooperative Path Finding in Urban\n  Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper considers the problem of planning a set of non-conflict\ntrajectories for the coalition of intelligent agents (mobile robots). Two\ndivergent approaches, e.g. centralized and decentralized, are surveyed and\nanalyzed. Decentralized planner - MAPP is described and applied to the task of\nfinding trajectories for dozens UAVs performing nap-of-the-earth flight in\nurban environments. Results of the experimental studies provide an opportunity\nto claim that MAPP is a highly efficient planner for solving considered types\nof tasks.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jul 2017 16:57:49 GMT"}], "update_date": "2017-07-21", "authors_parsed": [["Andreychuk", "Anton", ""], ["Yakovlev", "Konstantin", ""]]}, {"id": "1707.06854", "submitter": "Evgeny Ivanko", "authors": "Evgeny Ivanko", "title": "Should Evolution Necessarily be Egolution?", "comments": null, "journal-ref": "E. Ivanko. Is evolution always \"egolution\": Discussion of\n  evolutionary efficiency of altruistic energy exchange, Ecological Complexity,\n  Elsevier Publishing, 2018, vol. 34, pp. 1-8", "doi": "10.1016/j.ecocom.2018.02.001", "report-no": null, "categories": "q-bio.PE cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the article I study the evolutionary adaptivity of two simple population\nmodels, based on either altruistic or egoistic law of energy exchange. The\ncomputational experiments show the convincing advantage of the altruists, which\nbrings us to a small discussion about genetic algorithms and extraterrestrial\nlife.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jul 2017 11:33:31 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Ivanko", "Evgeny", ""]]}, {"id": "1707.07310", "submitter": "Hiroki Sayama", "authors": "Hiroki Sayama, Farnaz Zamani Esfahlani, Ali Jazayeri, J. Scott Turner", "title": "Robust Tracking and Behavioral Modeling of Movements of Biological\n  Collectives from Ordinary Video Recordings", "comments": "8 pages, 14 figures; to be published in the Proceedings of the IEEE\n  SSCI 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.CV nlin.AO q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel computational method to extract information about\ninteractions among individuals with different behavioral states in a biological\ncollective from ordinary video recordings. Assuming that individuals are acting\nas finite state machines, our method first detects discrete behavioral states\nof those individuals and then constructs a model of their state transitions,\ntaking into account the positions and states of other individuals in the\nvicinity. We have tested the proposed method through applications to two\nreal-world biological collectives: termites in an experimental setting and\nhuman pedestrians in a university campus. For each application, a robust\ntracking system was developed in-house, utilizing interactive human\nintervention (for termite tracking) or online agent-based simulation (for\npedestrian tracking). In both cases, significant interactions were detected\nbetween nearby individuals with different states, demonstrating the\neffectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Sun, 23 Jul 2017 14:55:21 GMT"}, {"version": "v2", "created": "Sat, 30 Sep 2017 13:48:00 GMT"}], "update_date": "2017-10-03", "authors_parsed": [["Sayama", "Hiroki", ""], ["Esfahlani", "Farnaz Zamani", ""], ["Jazayeri", "Ali", ""], ["Turner", "J. Scott", ""]]}, {"id": "1707.07399", "submitter": "Miao Liu", "authors": "Miao Liu, Kavinayan Sivakumar, Shayegan Omidshafiei, Christopher\n  Amato, Jonathan P. How", "title": "Learning for Multi-robot Cooperation in Partially Observable Stochastic\n  Environments with Macro-actions", "comments": "Accepted to the 2017 IEEE/RSJ International Conference on Intelligent\n  Robots and Systems (IROS 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a data-driven approach for multi-robot coordination in\npartially-observable domains based on Decentralized Partially Observable Markov\nDecision Processes (Dec-POMDPs) and macro-actions (MAs). Dec-POMDPs provide a\ngeneral framework for cooperative sequential decision making under uncertainty\nand MAs allow temporally extended and asynchronous action execution. To date,\nmost methods assume the underlying Dec-POMDP model is known a priori or a full\nsimulator is available during planning time. Previous methods which aim to\naddress these issues suffer from local optimality and sensitivity to initial\nconditions. Additionally, few hardware demonstrations involving a large team of\nheterogeneous robots and with long planning horizons exist. This work addresses\nthese gaps by proposing an iterative sampling based Expectation-Maximization\nalgorithm (iSEM) to learn polices using only trajectory data containing\nobservations, MAs, and rewards. Our experiments show the algorithm is able to\nachieve better solution quality than the state-of-the-art learning-based\nmethods. We implement two variants of multi-robot Search and Rescue (SAR)\ndomains (with and without obstacles) on hardware to demonstrate the learned\npolicies can effectively control a team of distributed robots to cooperate in a\npartially observable stochastic environment.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jul 2017 04:23:02 GMT"}, {"version": "v2", "created": "Fri, 18 Aug 2017 01:44:18 GMT"}], "update_date": "2017-08-21", "authors_parsed": [["Liu", "Miao", ""], ["Sivakumar", "Kavinayan", ""], ["Omidshafiei", "Shayegan", ""], ["Amato", "Christopher", ""], ["How", "Jonathan P.", ""]]}, {"id": "1707.07642", "submitter": "Hamza Anwar", "authors": "Hamza Anwar and Quanyan Zhu", "title": "Minimax Game-Theoretic Approach to Multiscale H-infinity Optimal\n  Filtering", "comments": "IEEE GlobalSIP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sensing in complex systems requires large-scale information exchange and\non-the-go communications over heterogeneous networks and integrated processing\nplatforms. Many networked cyber-physical systems exhibit hierarchical\ninfrastructures of information flows, which naturally leads to a multi-level\ntree-like information structure in which each level corresponds to a particular\nscale of representation. This work focuses on the multiscale fusion of data\ncollected at multiple levels of the system. We propose a multiscale state-space\nmodel to represent multi-resolution data over the hierarchical information\nsystem and formulate a multi-stage dynamic zero-sum game to design a\nmulti-scale $H_{\\infty}$ robust filter. We present numerical experiments for\none and two-dimensional signals and provide a comparative analysis of the\nminimax filter with the standard Kalman filter to show the improvement in\nsignal-to-noise ratio (SNR).\n", "versions": [{"version": "v1", "created": "Mon, 24 Jul 2017 16:54:56 GMT"}, {"version": "v2", "created": "Tue, 8 Aug 2017 15:26:35 GMT"}], "update_date": "2017-08-09", "authors_parsed": [["Anwar", "Hamza", ""], ["Zhu", "Quanyan", ""]]}, {"id": "1707.08477", "submitter": "Miguel Alberto Mercado", "authors": "Miguel Alberto Mercado, Roy Dong, and Allan Nerves", "title": "Resilient Energy Allocation Model for Supply Shortage Outages", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.MA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supply Shortage Outages are a major concern during peak demand for developing\ncountries. In the Philippines, commercial loads have unused backup generation\nof up to 3000 MW, at the same time there are shortages of as much as 700 MW\nduring peak demand. This gives utilities the incentive to implement Demand\nResponse programs to minimize this shortage. But when considering Demand\nResponse from a modeling perspective, social welfare through profit is always\nthe major objective for program implementation. That isn't always the case\nduring an emergency situation as there can be a trade-off between grid\nresilience and cost of electricity.\n  The question is how the Distribution Utility (DU) shall optimally allocate\nthe unused generation to meet the shortage when this trade-off exists. We\nformulate a combined multi-objective optimal dispatch model where we can make a\ndirect comparison between the least-cost and resilience objectives.\n  We find that this trade-off is due to the monotonically increasing nature of\nenergy cost functions. If the supply is larger than the demand, the DU can\nperform a least-cost approach in the optimal dispatch since maximizing the\nenergy generated in this case can lead to multiple solutions. We also find in\nour simulation that in cases where the supply of energy from the customers is\nless than shortage quantity, the DU must prioritize maximizing the generated\nenergy rather than minimizing cost.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jul 2017 02:45:57 GMT"}], "update_date": "2017-07-27", "authors_parsed": [["Mercado", "Miguel Alberto", ""], ["Dong", "Roy", ""], ["Nerves", "Allan", ""]]}, {"id": "1707.08741", "submitter": "EPTCS", "authors": "Zo\\'e Christoff (University of Bayreuth), Davide Grossi (University of\n  Liverpool)", "title": "Binary Voting with Delegable Proxy: An Analysis of Liquid Democracy", "comments": "In Proceedings TARK 2017, arXiv:1707.08250", "journal-ref": "EPTCS 251, 2017, pp. 134-150", "doi": "10.4204/EPTCS.251.10", "report-no": null, "categories": "cs.MA cs.AI cs.CY cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper provides an analysis of the voting method known as delegable proxy\nvoting, or liquid democracy. The analysis first positions liquid democracy\nwithin the theory of binary aggregation. It then focuses on two issues of the\nsystem: the occurrence of delegation cycles; and the effect of delegations on\nindividual rationality when voting on logically interdependent propositions. It\nfinally points to proposals on how the system may be modified in order to\naddress the above issues.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jul 2017 07:47:30 GMT"}], "update_date": "2017-07-28", "authors_parsed": [["Christoff", "Zo\u00e9", "", "University of Bayreuth"], ["Grossi", "Davide", "", "University of\n  Liverpool"]]}, {"id": "1707.08750", "submitter": "EPTCS", "authors": "Joseph Y. Halpern (Cornell University), Ron van der Meyden (University\n  of New South Wales), Riccardo Pucella (Forrester Research)", "title": "An Epistemic Foundation for Authentication Logics (Extended Abstract)", "comments": "In Proceedings TARK 2017, arXiv:1707.08250", "journal-ref": "EPTCS 251, 2017, pp. 306-323", "doi": "10.4204/EPTCS.251.21", "report-no": null, "categories": "cs.CR cs.AI cs.LO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While there have been many attempts, going back to BAN logic, to base\nreasoning about security protocols on epistemic notions, they have not been all\nthat successful. Arguably, this has been due to the particular logics chosen.\nWe present a simple logic based on the well-understood modal operators of\nknowledge, time, and probability, and show that it is able to handle issues\nthat have often been swept under the rug by other approaches, while being\nflexible enough to capture all the higher- level security notions that appear\nin BAN logic. Moreover, while still assuming that the knowledge operator allows\nfor unbounded computation, it can handle the fact that a computationally\nbounded agent cannot decrypt messages in a natural way, by distinguishing\nstrings and message terms. We demonstrate that our logic can capture BAN logic\nnotions by providing a translation of the BAN operators into our logic,\ncapturing belief by a form of probabilistic knowledge.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jul 2017 07:50:40 GMT"}], "update_date": "2017-07-28", "authors_parsed": [["Halpern", "Joseph Y.", "", "Cornell University"], ["van der Meyden", "Ron", "", "University\n  of New South Wales"], ["Pucella", "Riccardo", "", "Forrester Research"]]}, {"id": "1707.08755", "submitter": "EPTCS", "authors": "Omer Lev (University of Toronto), Moshe Tennenholtz (Technion)", "title": "Group Recommendations: Axioms, Impossibilities, and Random Walks", "comments": "In Proceedings TARK 2017, arXiv:1707.08250", "journal-ref": "EPTCS 251, 2017, pp. 382-397", "doi": "10.4204/EPTCS.251.28", "report-no": null, "categories": "cs.SI cs.AI cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an axiomatic approach to group recommendations, in line of\nprevious work on the axiomatic treatment of trust-based recommendation systems,\nranking systems, and other foundational work on the axiomatic approach to\ninternet mechanisms in social choice settings. In group recommendations we wish\nto recommend to a group of agents, consisting of both opinionated and undecided\nmembers, a joint choice that would be acceptable to them. Such a system has\nmany applications, such as choosing a movie or a restaurant to go to with a\ngroup of friends, recommending games for online game players, & other communal\nactivities.\n  Our method utilizes a given social graph to extract information on the\nundecided, relying on the agents influencing them. We first show that a set of\nfairly natural desired requirements (a.k.a axioms) leads to an impossibility,\nrendering mutual satisfaction of them unreachable. However, we also show a\nmodified set of axioms that fully axiomatize a group variant of the random-walk\nrecommendation system, expanding a previous result from the individual\nrecommendation case.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jul 2017 07:52:24 GMT"}], "update_date": "2017-07-28", "authors_parsed": [["Lev", "Omer", "", "University of Toronto"], ["Tennenholtz", "Moshe", "", "Technion"]]}, {"id": "1707.08761", "submitter": "EPTCS", "authors": "Burkhard C. Schipper (University of California, Davis)", "title": "Self-confirming Games: Unawareness, Discovery, and Equilibrium", "comments": "In Proceedings TARK 2017, arXiv:1707.08250", "journal-ref": "EPTCS 251, 2017, pp. 470-488", "doi": "10.4204/EPTCS.251.35", "report-no": null, "categories": "cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Equilibrium notions for games with unawareness in the literature cannot be\ninterpreted as steady-states of a learning process because players may discover\nnovel actions during play. In this sense, many games with unawareness are\n\"self-destroying\" as a player's representation of the game must change after\nplaying it once. We define discovery processes where at each state there is an\nextensive-form game with unawareness that together with the players' play\ndetermines the transition to possibly another extensive-form games with\nunawareness in which players are now aware of actions that they have previously\ndiscovered. A discovery process is rationalizable if players play\nextensive-form rationalizable strategies in each game with unawareness. We show\nthat for any game with unawareness there is a rationalizable discovery process\nthat leads to a self-confirming game that possesses an extensive-form\nrationalizable self-confirming equilibrium. This notion of equilibrium can be\ninterpreted as steady-state of a learning and discovery process.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jul 2017 07:54:00 GMT"}], "update_date": "2017-07-28", "authors_parsed": [["Schipper", "Burkhard C.", "", "University of California, Davis"]]}, {"id": "1707.09183", "submitter": "Pablo Hernandez-Leal", "authors": "Pablo Hernandez-Leal, Michael Kaisers, Tim Baarslag and Enrique Munoz\n  de Cote", "title": "A Survey of Learning in Multiagent Environments: Dealing with\n  Non-Stationarity", "comments": "64 pages, 7 figures. Under review since November 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The key challenge in multiagent learning is learning a best response to the\nbehaviour of other agents, which may be non-stationary: if the other agents\nadapt their strategy as well, the learning target moves. Disparate streams of\nresearch have approached non-stationarity from several angles, which make a\nvariety of implicit assumptions that make it hard to keep an overview of the\nstate of the art and to validate the innovation and significance of new works.\nThis survey presents a coherent overview of work that addresses\nopponent-induced non-stationarity with tools from game theory, reinforcement\nlearning and multi-armed bandits. Further, we reflect on the principle\napproaches how algorithms model and cope with this non-stationarity, arriving\nat a new framework and five categories (in increasing order of sophistication):\nignore, forget, respond to target models, learn models, and theory of mind. A\nwide range of state-of-the-art algorithms is classified into a taxonomy, using\nthese categories and key characteristics of the environment (e.g.,\nobservability) and adaptation behaviour of the opponents (e.g., smooth,\nabrupt). To clarify even further we present illustrative variations of one\ndomain, contrasting the strengths and limitations of each category. Finally, we\ndiscuss in which environments the different approaches yield most merit, and\npoint to promising avenues of future research.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jul 2017 10:49:41 GMT"}, {"version": "v2", "created": "Mon, 11 Mar 2019 20:17:29 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Hernandez-Leal", "Pablo", ""], ["Kaisers", "Michael", ""], ["Baarslag", "Tim", ""], ["de Cote", "Enrique Munoz", ""]]}, {"id": "1707.09827", "submitter": "Hidetoshi Furukawa", "authors": "Hidetoshi Furukawa", "title": "Bias Estimation for Decentralized Sensor Fusion -- Multi-Agent Based\n  Bias Estimation Method", "comments": "Technical Report, 6 pages, in Japanese, Copyright(C)2017 IEICE", "journal-ref": "IEICE Technical Report, vol.117, no.43, SANE2017-7, pp.35-40, May\n  2017", "doi": null, "report-no": null, "categories": "cs.SY cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multi-sensor data fusion (or sensor fusion), sensor biases (or offsets)\noften affect the accuracy of the correlation and integration results of the\ntracking targets. Therefore, to estimate and compensate the bias, several\nmethods are proposed. However, most methods involve bias estimation and sensor\nfusion simultaneously by using Kalman filter after collecting the plot data\ntogether. Hence, these methods cannot support to fuse the track data prepared\nby tracking filter at each sensor node. This report proposes the new bias\nestimation method based on multi-agent model, in order to estimate and\ncompensate the bias for decentralized sensor fusion.\n", "versions": [{"version": "v1", "created": "Mon, 31 Jul 2017 12:56:43 GMT"}], "update_date": "2017-08-01", "authors_parsed": [["Furukawa", "Hidetoshi", ""]]}]