[{"id": "0903.0353", "submitter": "Rustam Tagiew", "authors": "Rustam Tagiew", "title": "General Game Management Agent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of managing general game playing in a multi-agent system is the\nproblem addressed in this paper. It is considered to be done by an agent. There\nare many reasons for constructing such an agent, called general game management\nagent. This agent manages strategic interactions between other agents -\nplayers, natural or also artificial. The agent records the interaction for\nfurther benchmarking and analysis. He can also be used for a kind of restricted\ncommunications. His behavior is defined by a game description written in a\nlogic-based language. The language, we present for this application, is more\nexpressive than the language GDL, which is already used for such purposes. Our\nlanguage can represent imperfect information and time dependent elements of a\ngame. Time dependent elements like delays and timeouts are of crucial\nimportance for interactions between players with bounded processing power like\nhumans. We provide examples to show the feasibility of our approach. A way for\ngame theoretical solving of an interaction description in our language is\nconsidered as future work.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2009 18:48:40 GMT"}], "update_date": "2009-03-03", "authors_parsed": [["Tagiew", "Rustam", ""]]}, {"id": "0903.1137", "submitter": "Toby Walsh", "authors": "Toby Walsh", "title": "Complexity of Terminating Preference Elicitation", "comments": "7th International Joint Conference on Autonomous Agents and\n  Multiagent Systems (AAMAS 2008)", "journal-ref": "AAMAS 2008: 967-974", "doi": null, "report-no": null, "categories": "cs.AI cs.CC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complexity theory is a useful tool to study computational issues surrounding\nthe elicitation of preferences, as well as the strategic manipulation of\nelections aggregating together preferences of multiple agents. We study here\nthe complexity of determining when we can terminate eliciting preferences, and\nprove that the complexity depends on the elicitation strategy. We show, for\ninstance, that it may be better from a computational perspective to elicit all\npreferences from one agent at a time than to elicit individual preferences from\nmultiple agents. We also study the connection between the strategic\nmanipulation of an election and preference elicitation. We show that what we\ncan manipulate affects the computational complexity of manipulation. In\nparticular, we prove that there are voting rules which are easy to manipulate\nif we can change all of an agent's vote, but computationally intractable if we\ncan change only some of their preferences. This suggests that, as with\npreference elicitation, a fine-grained view of manipulation may be informative.\nFinally, we study the connection between predicting the winner of an election\nand preference elicitation. Based on this connection, we identify a voting rule\nwhere it is computationally difficult to decide the probability of a candidate\nwinning given a probability distribution over the votes.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2009 01:14:44 GMT"}], "update_date": "2012-04-18", "authors_parsed": [["Walsh", "Toby", ""]]}, {"id": "0903.2282", "submitter": "Ian Kash", "authors": "Ian A. Kash, Eric J. Friedman, Joseph Y. Halpern", "title": "Multiagent Learning in Large Anonymous Games", "comments": "8 pages, 2 figures. To Appear in Proceedings of the Eighth\n  International Conference on Autonomous Agents and Multiagent Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In large systems, it is important for agents to learn to act effectively, but\nsophisticated multi-agent learning algorithms generally do not scale. An\nalternative approach is to find restricted classes of games where simple,\nefficient algorithms converge. It is shown that stage learning efficiently\nconverges to Nash equilibria in large anonymous games if best-reply dynamics\nconverge. Two features are identified that improve convergence. First, rather\nthan making learning more difficult, more agents are actually beneficial in\nmany settings. Second, providing agents with statistical information about the\nbehavior of others can significantly reduce the number of observations needed.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2009 21:49:36 GMT"}], "update_date": "2009-03-16", "authors_parsed": [["Kash", "Ian A.", ""], ["Friedman", "Eric J.", ""], ["Halpern", "Joseph Y.", ""]]}, {"id": "0903.2448", "submitter": "Mehrnoosh Sadrzadeh", "authors": "Mehrnoosh Sadrzadeh and Roy Dyckhoff", "title": "Positive Logic with Adjoint Modalities: Proof Theory, Semantics and\n  Reasoning about Information", "comments": "This paper is the full version of the article that is to appear in\n  the ENTCS proceedings of the 25th conference on the Mathematical Foundations\n  of Programming Semantics (MFPS), April 2009, University of Oxford", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a simple modal logic whose non-modal part has conjunction and\ndisjunction as connectives and whose modalities come in adjoint pairs, but are\nnot in general closure operators. Despite absence of negation and implication,\nand of axioms corresponding to the characteristic axioms of (e.g.) T, S4 and\nS5, such logics are useful, as shown in previous work by Baltag, Coecke and the\nfirst author, for encoding and reasoning about information and misinformation\nin multi-agent systems. For such a logic we present an algebraic semantics,\nusing lattices with agent-indexed families of adjoint pairs of operators, and a\ncut-free sequent calculus. The calculus exploits operators on sequents, in the\nstyle of \"nested\" or \"tree-sequent\" calculi; cut-admissibility is shown by\nconstructive syntactic methods. The applicability of the logic is illustrated\nby reasoning about the muddy children puzzle, for which the calculus is\naugmented with extra rules to express the facts of the muddy children scenario.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2009 18:30:55 GMT"}, {"version": "v2", "created": "Thu, 19 Mar 2009 16:46:40 GMT"}, {"version": "v3", "created": "Mon, 23 Mar 2009 18:42:39 GMT"}], "update_date": "2009-03-23", "authors_parsed": [["Sadrzadeh", "Mehrnoosh", ""], ["Dyckhoff", "Roy", ""]]}, {"id": "0903.2543", "submitter": "Khaled Khalil", "authors": "Khaled M. Khalil, M. Abdel-Aziz, Taymour T. Nazmy, Abdel-Badeeh M.\n  Salem", "title": "Multi-Agent Crisis Response systems - Design Requirements and Analysis\n  of Current Systems", "comments": "6 pages, 1 figure, accepted at Fourth International Conference on\n  Intelligent Computing and Information Systems 2009", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crisis response is a critical area of research, with encouraging progress in\nthe past view yeas. The aim of the research is to contribute to building future\ncrisis environment where software agents, robots, responders, crisis managers,\nand crisis organizations interact to provide advice, protection and aid. This\npaper discusses the crisis response domain requirements, and provides analysis\nof five crisis response systems namely: DrillSim [2], DEFACTO [15], ALADDIN\n[1], RoboCup Rescue [18], and FireGrid [3]. Analysis of systems includes\nsystems architecture and methodology. In addition, we identified features and\nlimitations of systems based on crisis response domain requirements.\n", "versions": [{"version": "v1", "created": "Sat, 14 Mar 2009 12:13:32 GMT"}], "update_date": "2009-03-17", "authors_parsed": [["Khalil", "Khaled M.", ""], ["Abdel-Aziz", "M.", ""], ["Nazmy", "Taymour T.", ""], ["Salem", "Abdel-Badeeh M.", ""]]}, {"id": "0903.3537", "submitter": "Boris Oreshkin N.", "authors": "Boris N. Oreshkin, Mark J. Coates, Michael G. Rabbat", "title": "Optimization and Analysis of Distributed Averaging with Short Node\n  Memory", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2010.2043127", "report-no": null, "categories": "cs.DC cs.IT cs.MA math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we demonstrate, both theoretically and by numerical examples,\nthat adding a local prediction component to the update rule can significantly\nimprove the convergence rate of distributed averaging algorithms. We focus on\nthe case where the local predictor is a linear combination of the node's two\nprevious values (i.e., two memory taps), and our update rule computes a\ncombination of the predictor and the usual weighted linear combination of\nvalues received from neighbouring nodes. We derive the optimal mixing parameter\nfor combining the predictor with the neighbors' values, and carry out a\ntheoretical analysis of the improvement in convergence rate that can be\nobtained using this acceleration methodology. For a chain topology on n nodes,\nthis leads to a factor of n improvement over the one-step algorithm, and for a\ntwo-dimensional grid, our approach achieves a factor of n^1/2 improvement, in\nterms of the number of iterations required to reach a prescribed level of\naccuracy.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2009 15:12:13 GMT"}, {"version": "v2", "created": "Sat, 4 Jul 2009 14:46:21 GMT"}, {"version": "v3", "created": "Fri, 5 Feb 2010 15:48:12 GMT"}, {"version": "v4", "created": "Fri, 5 Feb 2010 21:35:10 GMT"}], "update_date": "2015-05-13", "authors_parsed": [["Oreshkin", "Boris N.", ""], ["Coates", "Mark J.", ""], ["Rabbat", "Michael G.", ""]]}, {"id": "0903.5122", "submitter": "Xiaofei Huang", "authors": "Xiaofei Huang", "title": "A Constructive Generalization of Nash Equilibrium for Better Payoffs and\n  Stability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a society of completely selfish individuals where everybody is only\ninterested in maximizing his own payoff, does any equilibrium exist for the\nsociety? John Nash proved more than 50 years ago that an equilibrium always\nexists such that nobody would benefit from unilaterally changing his strategy.\nNash Equilibrium is a central concept in game theory, which offers a\nmathematical foundation for social science and economy. However, it is\nimportant from both a theoretical and a practical point of view to understand\ngame playing where individuals are less selfish. This paper offers a\nconstructive generalization of Nash equilibrium to study n-person games where\nthe selfishness of individuals can be defined at any level, including the\nextreme of complete selfishness. The generalization is constructive since it\noffers a protocol for individuals in a society to reach an equilibrium. Most\nimportantly, this paper presents experimental results and theoretical\ninvestigation to show that the individuals in a society can reduce their\nselfishness level together to reach a new equilibrium where they can have\nbetter payoffs and the society is more stable at the same time. This study\nsuggests that, for the benefit of everyone in a society (including the\nfinancial market), the pursuit of maximal payoff by each individual should be\ncontrolled at some level either by voluntary good citizenship or by imposed\nregulations.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2009 06:38:31 GMT"}], "update_date": "2009-03-31", "authors_parsed": [["Huang", "Xiaofei", ""]]}]