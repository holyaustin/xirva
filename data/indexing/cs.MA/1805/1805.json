[{"id": "1805.00751", "submitter": "Jiamou Liu", "authors": "Bo Yan, Yiping Liu, Jiamou Liu, Yijin Cai, Hongyi Su, Hong Zheng", "title": "From the Periphery to the Center: Information Brokerage in an Evolving\n  Network", "comments": "The conference version of the paper has been accepted at IJCAI-ECAI\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpersonal ties are pivotal to individual efficacy, status and performance\nin an agent society. This paper explores three important and interrelated\nthemes in social network theory: the center/periphery partition of the network;\nnetwork dynamics; and social integration of newcomers. We tackle the question:\nHow would a newcomer harness information brokerage to integrate into a dynamic\nnetwork going from periphery to center? We model integration as the interplay\nbetween the newcomer and the dynamics network and capture information brokerage\nusing a process of relationship building. We analyze theoretical guarantees for\nthe newcomer to reach the center through tactics; proving that a winning tactic\nalways exists for certain types of network dynamics. We then propose three\ntactics and show their superior performance over alternative methods on four\nreal-world datasets and four network models. In general, our tactics place the\nnewcomer to the center by adding very few new edges on dynamic networks with\napproximately 14000 nodes.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 11:58:28 GMT"}], "update_date": "2018-05-03", "authors_parsed": [["Yan", "Bo", ""], ["Liu", "Yiping", ""], ["Liu", "Jiamou", ""], ["Cai", "Yijin", ""], ["Su", "Hongyi", ""], ["Zheng", "Hong", ""]]}, {"id": "1805.00787", "submitter": "Jack Hall", "authors": "Jack Hall", "title": "Cognition in Dynamical Systems, Second Edition", "comments": "50 pages including references. Base file is `cognition.tex`. All\n  figures are generated by TikZ. This is a revised version of my doctoral\n  thesis, which was published under the name of John Wendell Hall since The\n  University of Texas at Austin required my full name. All of this work is\n  unpublished aside from the UT library, where the first edition is stored as\n  my dissertation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cognition is the process of knowing. As carried out by a dynamical system, it\nis the process by which the system absorbs information into its state. A\ncomplex network of agents cognizes knowledge about its environment, internal\ndynamics and initial state by forming emergent, macro-level patterns. Such\npatterns require each agent to find its place while partially aware of the\nwhole pattern. Such partial awareness can be achieved by separating the system\ndynamics into two parts by timescale: the propagation dynamics and the pattern\ndynamics. The fast propagation dynamics describe the spread of signals across\nthe network. If they converge to a fixed point for any quasi-static state of\nthe slow pattern dynamics, that fixed point represents an aggregate of\nmacro-level information. On longer timescales, agents coordinate via positive\nfeedback to form patterns, which are defined using closed walks in the graph of\nagents. Patterns can be coherent, in that every part of the pattern depends on\nevery other part for context. Coherent patterns are acausal, in that (a) they\ncannot be predicted and (b) no part of the stored knowledge can be mapped to\nany part of the pattern, or vice versa. A cognitive network's knowledge is\nencoded or embodied by the selection of patterns which emerge. The theory of\ncognition summarized here can model autocatalytic reaction-diffusion systems,\nartificial neural networks, market economies and ant colony optimization, among\nmany other real and virtual systems. This theory suggests a new understanding\nof complexity as a lattice of contexts rather than a single measure.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 04:12:08 GMT"}], "update_date": "2018-05-03", "authors_parsed": [["Hall", "Jack", ""]]}, {"id": "1805.00913", "submitter": "Noam Hazon", "authors": "Sefi Erlich, Noam Hazon, Sarit Kraus", "title": "Negotiation Strategies for Agents with Ordinal Preferences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Negotiation is a very common interaction between automated agents. Many\ncommon negotiation protocols work with cardinal utilities, even though ordinal\npreferences, which only rank the outcomes, are easier to elicit from humans. In\nthis work we concentrate on negotiation with ordinal preferences over a finite\nset of outcomes. We study an intuitive protocol for bilateral negotiation,\nwhere the two parties make offers alternately. We analyze the negotiation\nprotocol under different settings. First, we assume that each party has full\ninformation about the other party's preference order. We provide elegant\nstrategies that specify a sub-game perfect equilibrium for the agents. We\nfurther show how the studied negotiation protocol almost completely implements\na known bargaining rule. Finally, we analyze the no information setting. We\nstudy several solution concepts that are distribution-free, and analyze both\nthe case where neither party knows the preference order of the other party, and\nthe case where only one party is uninformed.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 17:18:20 GMT"}], "update_date": "2018-05-03", "authors_parsed": [["Erlich", "Sefi", ""], ["Hazon", "Noam", ""], ["Kraus", "Sarit", ""]]}, {"id": "1805.01987", "submitter": "Zheyuan Ryan Shi", "authors": "Zheyuan Ryan Shi, Ziye Tang, Long Tran-Thanh, Rohit Singh, Fei Fang", "title": "Designing the Game to Play: Optimizing Payoff Structure in Security\n  Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective game-theoretic modeling of defender-attacker behavior is becoming\nincreasingly important. In many domains, the defender functions not only as a\nplayer but also the designer of the game's payoff structure. We study\nStackelberg Security Games where the defender, in addition to allocating\ndefensive resources to protect targets from the attacker, can strategically\nmanipulate the attacker's payoff under budget constraints in weighted L^p-norm\nform regarding the amount of change. Focusing on problems with weighted\nL^1-norm form constraint, we present (i) a mixed integer linear program-based\nalgorithm with approximation guarantee; (ii) a branch-and-bound based algorithm\nwith improved efficiency achieved by effective pruning; (iii) a polynomial time\napproximation scheme for a special but practical class of problems. In\naddition, we show that problems under budget constraints in L^0-norm form and\nweighted L^\\infty-norm form can be solved in polynomial time. We provide an\nextensive experimental evaluation of our proposed algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 5 May 2018 03:07:19 GMT"}, {"version": "v2", "created": "Tue, 22 May 2018 04:32:52 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Shi", "Zheyuan Ryan", ""], ["Tang", "Ziye", ""], ["Tran-Thanh", "Long", ""], ["Singh", "Rohit", ""], ["Fang", "Fei", ""]]}, {"id": "1805.02138", "submitter": "Yuke Li", "authors": "Yuke Li, Jiahua Yue, Fengjiao Liu, A. Stephen Morse", "title": "The Power Allocation Game on A Network: Computation Issue", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.MA cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper two algorithms with the goal of generating the equilibrium set\nof the power allocation game first developed in \\cite{allocation} are proposed.\nBased on the first algorithm, the geometric property of the pure strategy Nash\nequilibrium set will be proven to be a collection of convex polytopes. The\nsecond, simulation-based, algorithm is developed to overcome the shortcoming of\nthe first algorithm in terms of generating the equilibrium set efficiently and\nthen making policy-relevant predictions based on the set. The second algorithm\nwill be usefully applied to a real-world case study, which draws on the current\ncrisis between North Korea and certain key players including the US and China.\n", "versions": [{"version": "v1", "created": "Sun, 6 May 2018 02:43:44 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Li", "Yuke", ""], ["Yue", "Jiahua", ""], ["Liu", "Fengjiao", ""], ["Morse", "A. Stephen", ""]]}, {"id": "1805.02241", "submitter": "Juliao Braga", "authors": "Juliao Braga and Nizam Omar and Luciana F. Thome", "title": "Acquisition and use of knowledge over a restricted domain by intelligent\n  agents", "comments": "5 pages", "journal-ref": null, "doi": "10.1145/3077286.3077293", "report-no": null, "categories": "cs.AI cs.MA cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This short paper provides a description of an architecture to acquisition and\nuse of knowledge by intelligent agents over a restricted domain of the Internet\nInfrastructure. The proposed architecture is added to an intelligent agent\ndeployment model over a very useful server for Internet Autonomous System\nadministrators. Such servers, which are heavily dependent on arbitrary and\neventual updates of human beings, become unreliable. This is a position paper\nthat proposes three research questions that are still in progress.\n", "versions": [{"version": "v1", "created": "Sun, 6 May 2018 16:32:19 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Braga", "Juliao", ""], ["Omar", "Nizam", ""], ["Thome", "Luciana F.", ""]]}, {"id": "1805.02356", "submitter": "Jieli Zhou", "authors": "Xin Qian, Ziyi Zhong, Jieli Zhou", "title": "Multimodal Machine Translation with Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.MA cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multimodal machine translation is one of the applications that integrates\ncomputer vision and language processing. It is a unique task given that in the\nfield of machine translation, many state-of-the-arts algorithms still only\nemploy textual information. In this work, we explore the effectiveness of\nreinforcement learning in multimodal machine translation. We present a novel\nalgorithm based on the Advantage Actor-Critic (A2C) algorithm that specifically\ncater to the multimodal machine translation task of the EMNLP 2018 Third\nConference on Machine Translation (WMT18). We experiment our proposed algorithm\non the Multi30K multilingual English-German image description dataset and the\nFlickr30K image entity dataset. Our model takes two channels of inputs, image\nand text, uses translation evaluation metrics as training rewards, and achieves\nbetter results than supervised learning MLE baseline models. Furthermore, we\ndiscuss the prospects and limitations of using reinforcement learning for\nmachine translation. Our experiment results suggest a promising reinforcement\nlearning solution to the general task of multimodal sequence to sequence\nlearning.\n", "versions": [{"version": "v1", "created": "Mon, 7 May 2018 06:12:32 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Qian", "Xin", ""], ["Zhong", "Ziyi", ""], ["Zhou", "Jieli", ""]]}, {"id": "1805.02528", "submitter": "Johan Thunberg", "authors": "Johan Thunberg, Johan Markdahl, Florian Bernard, Jorge Goncalves", "title": "A Lifting method for analyzing distributed synchronization on the unit\n  sphere", "comments": "11 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.MA math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new lifting method for analyzing convergence of\ncontinuous-time distributed synchronization/consensus systems on the unit\nsphere. Points on the d-dimensional unit sphere are lifted to the\n(d+1)-dimensional Euclidean space. The consensus protocol on the unit sphere is\nthe classical one, where agents move toward weighted averages of their\nneighbors in their respective tangent planes. Only local and relative state\ninformation is used. The directed interaction graph topologies are allowed to\nswitch as a function of time. The dynamics of the lifted variables are governed\nby a nonlinear consensus protocol for which the weights contain ratios of the\nnorms of state variables. We generalize previous convergence results for\nhemispheres. For a large class of consensus protocols defined for switching\nuniformly quasi-strongly connected time-varying graphs, we show that the\nconsensus manifold is uniformly asymptotically stable relative to closed balls\ncontained in a hemisphere. Compared to earlier projection based approaches used\nin this context such as the gnomonic projection, which is defined for\nhemispheres only, the lifting method applies globally. With that, the hope is\nthat this method can be useful for future investigations on global convergence.\n", "versions": [{"version": "v1", "created": "Mon, 7 May 2018 13:50:09 GMT"}, {"version": "v2", "created": "Thu, 7 Jun 2018 10:18:15 GMT"}], "update_date": "2018-06-08", "authors_parsed": [["Thunberg", "Johan", ""], ["Markdahl", "Johan", ""], ["Bernard", "Florian", ""], ["Goncalves", "Jorge", ""]]}, {"id": "1805.02777", "submitter": "Chun Kai Ling", "authors": "Chun Kai Ling, Fei Fang, J. Zico Kolter", "title": "What game are we playing? End-to-end learning in normal and extensive\n  form games", "comments": "Fixed typos and updated experimental results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although recent work in AI has made great progress in solving large,\nzero-sum, extensive-form games, the underlying assumption in most past work is\nthat the parameters of the game itself are known to the agents. This paper\ndeals with the relatively under-explored but equally important \"inverse\"\nsetting, where the parameters of the underlying game are not known to all\nagents, but must be learned through observations. We propose a differentiable,\nend-to-end learning framework for addressing this task. In particular, we\nconsider a regularized version of the game, equivalent to a particular form of\nquantal response equilibrium, and develop 1) a primal-dual Newton method for\nfinding such equilibrium points in both normal and extensive form games; and 2)\na backpropagation method that lets us analytically compute gradients of all\nrelevant game parameters through the solution itself. This ultimately lets us\nlearn the game by training in an end-to-end fashion, effectively by integrating\na \"differentiable game solver\" into the loop of larger deep network\narchitectures. We demonstrate the effectiveness of the learning method in\nseveral settings including poker and security game tasks.\n", "versions": [{"version": "v1", "created": "Mon, 7 May 2018 23:17:18 GMT"}, {"version": "v2", "created": "Wed, 27 Jun 2018 21:57:09 GMT"}], "update_date": "2018-06-29", "authors_parsed": [["Ling", "Chun Kai", ""], ["Fang", "Fei", ""], ["Kolter", "J. Zico", ""]]}, {"id": "1805.02836", "submitter": "Mengbin Ye", "authors": "Mengbin Ye, Minh Hoang Trinh, Young-Hun Lim, Brian D.O. Anderson,\n  Hyo-Sung Ahn", "title": "Continuous-time Opinion Dynamics on Multiple Interdependent Topics", "comments": "Extended version of a journal paper submission, with detailed proofs\n  and additional discussion and simulations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.MA cs.SY math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, and inspired by the recent discrete-time model in [1,2], we\nstudy two continuous-time opinion dynamics models (Model 1 and Model 2) where\nthe individuals discuss opinions on multiple logically interdependent topics.\nThe logical interdependence between the different topics is captured by a\n`logic' matrix, which is distinct from the Laplacian matrix capturing\ninteractions between individuals. For each of Model 1 and Model 2, we obtain a\nnecessary and sufficient condition for the network to reach to a consensus on\neach separate topic. The condition on Model 1 involves a combination of the\neigenvalues of the logic matrix and Laplacian matrix, whereas the condition on\nModel 2 requires only separate conditions on the logic matrix and Laplacian\nmatrix. Further investigations of Model 1 yields two sufficient conditions for\nconsensus, and allow us to conclude that one way to guarantee a consensus is to\nreduce the rate of interaction between individuals exchanging opinions. By\nplacing further restrictions on the logic matrix, we also establish a set of\nLaplacian matrices which guarantee consensus for Model 1. The two models are\nalso expanded to include stubborn individuals, who remain attached to their\ninitial opinions. Sufficient conditions are obtained for guaranteeing\nconvergence of the opinion dynamics system, with the final opinions generally\nbeing at a persistent disagreement. Simulations are provided to illustrate the\nresults.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2018 05:10:47 GMT"}, {"version": "v2", "created": "Thu, 30 Aug 2018 11:48:34 GMT"}, {"version": "v3", "created": "Fri, 31 Aug 2018 09:43:11 GMT"}, {"version": "v4", "created": "Tue, 9 Apr 2019 14:10:00 GMT"}, {"version": "v5", "created": "Sat, 11 Jan 2020 20:27:31 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Ye", "Mengbin", ""], ["Trinh", "Minh Hoang", ""], ["Lim", "Young-Hun", ""], ["Anderson", "Brian D. O.", ""], ["Ahn", "Hyo-Sung", ""]]}, {"id": "1805.02878", "submitter": "Andrzej Jarynowski", "authors": "Andrzej Jarynowski, Piotr Nyczka", "title": "Single parameter model of marriage divorce dynamics with countries\n  classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.MA math.DS physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate a marriage divorces problem via agent - based modeling.\nCurrent value of socio-economic pressure p (main model parameter) drives the\ndynamic of first marriage, remarriage or spontaneously marriage breaks up.\nModel reflects the behavior of the heterosexual population (frequency of\nchanging partners, the ratio of singles in society). Theoretical agent-based\nsimulation (with population approaches, e. g. births and deaths) are\nsupplemented by historical values of divorces marriages in various countries of\nthe world from United Nation Registry and World Value Survey. In the model,\nagents have a list of their attributes and preference of a potential partner\nwith Manhattan distance measure applied as a matching function. In the\ndeterministic part of the model randomly selected agents could entry into a new\nrelationship, or exchange partners, with respect to the matching distance and\npressure parameter. Spouses could also spontaneously fall apart with a pressure\ndepended probability. This simple model, although it assumes homogeneity of\nagents (on bipartite graph), and has only one key parameter, gives estimate of\nthe socio-economic pressure values for different societies at given time point,\nknowing the frequency of changing partners, the percentage of married in\nsociety.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2018 07:58:00 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Jarynowski", "Andrzej", ""], ["Nyczka", "Piotr", ""]]}, {"id": "1805.03103", "submitter": "Wennan Zhu", "authors": "Elliot Anshelevich and Wennan Zhu", "title": "Ordinal Approximation for Social Choice, Matching, and Facility Location\n  Problems given Candidate Positions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we consider general facility location and social choice\nproblems, in which sets of agents $\\mathcal{A}$ and facilities $\\mathcal{F}$\nare located in a metric space, and our goal is to assign agents to facilities\n(as well as choose which facilities to open) in order to optimize the social\ncost. We form new algorithms to do this in the presence of only {\\em ordinal\ninformation}, i.e., when the true costs or distances from the agents to the\nfacilities are {\\em unknown}, and only the ordinal preferences of the agents\nfor the facilities are available. The main difference between our work and\nprevious work in this area is that while we assume that only ordinal\ninformation about agent preferences in known, we know the exact locations of\nthe possible facilities $\\mathcal{F}$. Due to this extra information about the\nfacilities, we are able to form powerful algorithms which have small {\\em\ndistortion}, i.e., perform almost as well as omniscient algorithms but use only\nordinal information about agent preferences. For example, we present natural\nsocial choice mechanisms for choosing a single facility to open with distortion\nof at most 3 for minimizing both the total and the median social cost; this\nfactor is provably the best possible. We analyze many general problems\nincluding matching, $k$-center, and $k$-median, and present black-box\nreductions from omniscient approximation algorithms with approximation factor\n$\\beta$ to ordinal algorithms with approximation factor $1+2\\beta$; doing this\ngives new ordinal algorithms for many important problems, and establishes a\ntoolkit for analyzing such problems in the future.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2018 15:24:50 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Anshelevich", "Elliot", ""], ["Zhu", "Wennan", ""]]}, {"id": "1805.03164", "submitter": "Brandon Fain", "authors": "Brandon Fain, Kamesh Munagala, Nisarg Shah", "title": "Fair Allocation of Indivisible Public Goods", "comments": "Published in EC 2018, The 19th ACM Conference on Economics and\n  Computation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CY cs.DS cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of fairly allocating indivisible public goods. We\nmodel the public goods as elements with feasibility constraints on what subsets\nof elements can be chosen, and assume that agents have additive utilities\nacross elements. Our model generalizes existing frameworks such as fair public\ndecision making and participatory budgeting. We study a groupwise fairness\nnotion called the core, which generalizes well-studied notions of\nproportionality and Pareto efficiency, and requires that each subset of agents\nmust receive an outcome that is fair relative to its size.\n  In contrast to the case of divisible public goods (where fractional\nallocations are permitted), the core is not guaranteed to exist when allocating\nindivisible public goods. Our primary contributions are the notion of an\nadditive approximation to the core (with a tiny multiplicative loss), and\npolynomial time algorithms that achieve a small additive approximation, where\nthe additive factor is relative to the largest utility of an agent for an\nelement. If the feasibility constraints define a matroid, we show an additive\napproximation of 2. A similar approach yields a constant additive bound when\nthe feasibility constraints define a matching. More generally, if the\nfeasibility constraints define an arbitrary packing polytope with mild\nrestrictions, we show an additive guarantee that is logarithmic in the width of\nthe polytope. Our algorithms are based on variants of the convex program for\nmaximizing the Nash social welfare, but differ significantly from previous work\nin how it is used. Our guarantees are meaningful even when there are fewer\nelements than the number of agents. As far as we are aware, our work is the\nfirst to approximate the core in indivisible settings.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2018 16:59:54 GMT"}, {"version": "v2", "created": "Wed, 9 May 2018 00:26:32 GMT"}], "update_date": "2018-05-10", "authors_parsed": [["Fain", "Brandon", ""], ["Munagala", "Kamesh", ""], ["Shah", "Nisarg", ""]]}, {"id": "1805.03241", "submitter": "Ruslan Rezin", "authors": "Konstantin Danilov, Ruslan Rezin, Alexander Kolotov and Ilya Afanasyev", "title": "Towards blockchain-based robonomics: autonomous agents behavior\n  validation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.DC cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The decentralized trading market approach, where both autonomous agents and\npeople can consume and produce services expanding own opportunities to reach\ngoals, looks very promising as a part of the Fourth Industrial revolution. The\nkey component of the approach is a blockchain platform that allows an\ninteraction between agents via liability smart contracts. Reliability of a\nservice provider is usually determined by a reputation model. However, this\nsolution only warns future customers about an extent of trust to the service\nprovider in case it could not execute any previous liabilities correctly. From\nthe other hand a blockchain consensus protocol can additionally include a\nvalidation procedure that detects incorrect liability executions in order to\nsuspend payment transactions to questionable service providers. The paper\npresents the validation methodology of a liability execution for agent-based\nservice providers in a decentralized trading market, using the Model Checking\nmethod based on the mathematical model of finite state automata and Temporal\nLogic properties of interest. To demonstrate this concept, we implemented the\nmethodology in the Duckietown application, moving an autonomous mobile robot to\nachieve a mission goal with the following behavior validation at the end of a\ncompleted scenario.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2018 19:24:59 GMT"}], "update_date": "2018-05-10", "authors_parsed": [["Danilov", "Konstantin", ""], ["Rezin", "Ruslan", ""], ["Kolotov", "Alexander", ""], ["Afanasyev", "Ilya", ""]]}, {"id": "1805.03691", "submitter": "Frederik Mallmann-Trenn", "authors": "Anna Dornhaus, Nancy Lynch, Frederik Mallmann-Trenn, Dominik Pajak and\n  Tsvetomira Radeva", "title": "Self-Stabilizing Task Allocation In Spite of Noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of distributed task allocation inspired by the behavior\nof social insects, which perform task allocation in a setting of limited\ncapabilities and noisy environment feedback. We assume that each task has a\ndemand that should be satisfied but not exceeded, i.e., there is an optimal\nnumber of ants that should be working on this task at a given time. The goal is\nto assign a near-optimal number of workers to each task in a distributed manner\nand without explicit access to the values of the demands nor the number of ants\nworking on the task.\n  We seek to answer the question of how the quality of task allocation depends\non the accuracy of assessing whether too many (overload) or not enough (lack)\nants are currently working on a given task. Concretely, we address the open\nquestion of solving task allocation in the model where each ant receives\nfeedback that depends on the deficit defined as the (possibly negative)\ndifference between the optimal demand and the current number of workers in the\ntask. The feedback is modeled as a random variable that takes value lack or\noverload with probability given by a sigmoid of the deficit. Each ants receives\nthe feedback independently, but the higher the overload or lack of workers for\na task, the more likely it is that all the ants will receive the same, correct\nfeedback from this task; the closer the deficit is to zero, the less reliable\nthe feedback becomes. We measure the performance of task allocation algorithms\nusing the notion of regret, defined as the absolute value of the deficit summed\nover all tasks and summed over time.\n  We propose a simple, constant-memory, self-stabilizing, distributed algorithm\nthat quickly converges from any initial distribution to a near-optimal\nassignment. We also show that our algorithm works not only under stochastic\nnoise but also in an adversarial noise setting.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2018 18:40:20 GMT"}, {"version": "v2", "created": "Sun, 13 May 2018 00:36:13 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Dornhaus", "Anna", ""], ["Lynch", "Nancy", ""], ["Mallmann-Trenn", "Frederik", ""], ["Pajak", "Dominik", ""], ["Radeva", "Tsvetomira", ""]]}, {"id": "1805.03721", "submitter": "Natanael Arndt", "authors": "Natanael Arndt, Patrick Naumann, Norman Radtke, Michael Martin, Edgard\n  Marx", "title": "Decentralized Collaborative Knowledge Management using Git", "comments": "Special Issue on Managing the Evolution and Preservation of the Data\n  Web", "journal-ref": null, "doi": "10.1016/j.websem.2018.08.002", "report-no": null, "categories": "cs.DB cs.DC cs.MA cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The World Wide Web and the Semantic Web are designed as a network of\ndistributed services and datasets. The distributed character of the Web brings\nmanifold collaborative possibilities to interchange data. The commonly adopted\ncollaborative solutions for RDF data are centralized (e.g. SPARQL endpoints and\nwiki systems). But to support distributed collaboration, a system is needed,\nthat supports divergence of datasets, brings the possibility to conflate\ndiverged states, and allows distributed datasets to be synchronized. In this\npaper, we present Quit Store, it was inspired by and it builds upon the\nsuccessful Git system. The approach is based on a formal expression of\nevolution and consolidation of distributed datasets. During the collaborative\ncuration process, the system automatically versions the RDF dataset and tracks\nprovenance information. It also provides support to branch, merge, and\nsynchronize distributed RDF datasets. The merging process is guarded by\nspecific merge strategies for RDF data. Finally, we use our reference\nimplementation to show overall good performance and demonstrate the practical\nusability of the system.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2018 20:24:20 GMT"}, {"version": "v2", "created": "Tue, 5 Jun 2018 11:48:38 GMT"}, {"version": "v3", "created": "Tue, 16 Oct 2018 07:53:05 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Arndt", "Natanael", ""], ["Naumann", "Patrick", ""], ["Radtke", "Norman", ""], ["Martin", "Michael", ""], ["Marx", "Edgard", ""]]}, {"id": "1805.03737", "submitter": "Amanda Prorok", "authors": "Amanda Prorok", "title": "Graph Neural Networks for Learning Robot Team Coordination", "comments": "Presented at the Federated AI for Robotics Workshop,\n  IJCAI-ECAI/ICML/AAMAS 2018", "journal-ref": "Federated AI for Robotics Workshop, IJCAI-ECAI/ICML/AAMAS 2018", "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper shows how Graph Neural Networks can be used for learning\ndistributed coordination mechanisms in connected teams of robots. We capture\nthe relational aspect of robot coordination by modeling the robot team as a\ngraph, where each robot is a node, and edges represent communication links.\nDuring training, robots learn how to pass messages and update internal states,\nso that a target behavior is reached. As a proxy for more complex problems,\nthis short paper considers the problem where each robot must locally estimate\nthe algebraic connectivity of the team's network topology.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2018 21:24:50 GMT"}, {"version": "v2", "created": "Sun, 27 Jan 2019 13:42:51 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Prorok", "Amanda", ""]]}, {"id": "1805.04961", "submitter": "Hang Ma", "authors": "Hang Ma, Glenn Wagner, Ariel Felner, Jiaoyang Li, T. K. Satish Kumar,\n  Sven Koenig", "title": "Multi-Agent Path Finding with Deadlines: Preliminary Results", "comments": "AAMAS 2018, to appear", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formalize the problem of multi-agent path finding with deadlines\n(MAPF-DL). The objective is to maximize the number of agents that can reach\ntheir given goal vertices from their given start vertices within a given\ndeadline, without colliding with each other. We first show that the MAPF-DL\nproblem is NP-hard to solve optimally. We then present an optimal MAPF-DL\nalgorithm based on a reduction of the MAPF-DL problem to a flow problem and a\nsubsequent compact integer linear programming formulation of the resulting\nreduced abstracted multi-commodity flow network.\n", "versions": [{"version": "v1", "created": "Sun, 13 May 2018 21:44:19 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Ma", "Hang", ""], ["Wagner", "Glenn", ""], ["Felner", "Ariel", ""], ["Li", "Jiaoyang", ""], ["Kumar", "T. K. Satish", ""], ["Koenig", "Sven", ""]]}, {"id": "1805.05230", "submitter": "Gavin Rens", "authors": "Gavin Rens and Abhaya Nayak and Thomas Meyer", "title": "Maximizing Expected Impact in an Agent Reputation Network -- Technical\n  Report", "comments": "18 pages including bibliography", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many multi-agent systems (MASs) are situated in stochastic environments. Some\nsuch systems that are based on the partially observable Markov decision process\n(POMDP) do not take the benevolence of other agents for granted. We propose a\nnew POMDP-based framework which is general enough for the specification of a\nvariety of stochastic MAS domains involving the impact of agents on each\nother's reputations. A unique feature of this framework is that actions are\nspecified as either undirected (regular) or directed (towards a particular\nagent), and a new directed transition function is provided for modeling the\neffects of reputation in interactions. Assuming that an agent must maintain a\ngood enough reputation to survive in the network, a planning algorithm is\ndeveloped for an agent to select optimal actions in stochastic MASs.\nPreliminary evaluation is provided via an example specification and by\ndetermining the algorithm's complexity.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2018 15:29:26 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Rens", "Gavin", ""], ["Nayak", "Abhaya", ""], ["Meyer", "Thomas", ""]]}, {"id": "1805.05374", "submitter": "Maximilian Naumann", "authors": "Maximilian Naumann and Martin Lauer and Christoph Stiller", "title": "Generating Comfortable, Safe and Comprehensible Trajectories for\n  Automated Vehicles in Mixed Traffic", "comments": null, "journal-ref": "Proc. IEEE Intl. Conf. Intelligent Transportation Systems, pp.\n  575-582, Hawaii, USA, Nov 2018", "doi": "10.1109/ITSC.2018.8569658", "report-no": null, "categories": "cs.RO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While motion planning approaches for automated driving often focus on safety\nand mathematical optimality with respect to technical parameters, they barely\nconsider convenience, perceived safety for the passenger and comprehensibility\nfor other traffic participants. For automated driving in mixed traffic,\nhowever, this is key to reach public acceptance. In this paper, we revise the\nproblem statement of motion planning in mixed traffic: Instead of largely\nsimplifying the motion planning problem to a convex optimization problem, we\nkeep a more complex probabilistic multi agent model and strive for a near\noptimal solution. We assume cooperation of other traffic participants, yet\nbeing aware of violations of this assumption. This approach yields solutions\nthat are provably safe in all situations, and convenient and comprehensible in\nsituations that are also unambiguous for humans. Thus, it outperforms existing\napproaches in mixed traffic scenarios, as we show in simulation.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2018 18:41:52 GMT"}, {"version": "v2", "created": "Sat, 11 May 2019 00:38:15 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Naumann", "Maximilian", ""], ["Lauer", "Martin", ""], ["Stiller", "Christoph", ""]]}, {"id": "1805.05631", "submitter": "William Schueller", "authors": "William Schueller, Vittorio Loreto and Pierre-Yves Oudeyer", "title": "Complexity Reduction in the Negotiation of New Lexical Conventions", "comments": "Published at CogSci 2018 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.CL cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the process of collectively inventing new words for new concepts in a\npopulation, conflicts can quickly become numerous, in the form of synonymy and\nhomonymy. Remembering all of them could cost too much memory, and remembering\ntoo few may slow down the overall process. Is there an efficient behavior that\ncould help balance the two? The Naming Game is a multi-agent computational\nmodel for the emergence of language, focusing on the negotiation of new lexical\nconventions, where a common lexicon self-organizes but going through a phase of\nhigh complexity. Previous work has been done on the control of complexity\ngrowth in this particular model, by allowing agents to actively choose what\nthey talk about. However, those strategies were relying on ad hoc heuristics\nhighly dependent on fine-tuning of parameters. We define here a new principled\nmeasure and a new strategy, based on the beliefs of each agent on the global\nstate of the population. The measure does not rely on heavy computation, and is\ncognitively plausible. The new strategy yields an efficient control of\ncomplexity growth, along with a faster agreement process. Also, we show that\nshort-term memory is enough to build relevant beliefs about the global lexicon.\n", "versions": [{"version": "v1", "created": "Tue, 15 May 2018 08:23:56 GMT"}, {"version": "v2", "created": "Thu, 17 May 2018 17:00:18 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Schueller", "William", ""], ["Loreto", "Vittorio", ""], ["Oudeyer", "Pierre-Yves", ""]]}, {"id": "1805.05999", "submitter": "Mattia Mazzoli", "authors": "Mattia Mazzoli, Tullio Re, Roberto Bertilone, Marco Maggiora and\n  Jacopo Pellegrino", "title": "Agent Based Rumor Spreading in a scale-free network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last years, the study of rumor spreading on social networks produced a\nlot of interest among the scientific community, expecially due to the role of\nsocial networks in the last political events. The goal of this work is to\nreproduce real-like diffusions of information and misinformation in a\nscale-free network using a multi-agent-based model. The data concerning the\nvirtual spreading are easily obtainable, in particular the diffusion of\ninformation during the announcement for the discovery of the Higgs Boson on\nTwitter was recorded and investigated in detail. We made some assumptions on\nthe micro behavior of our agents and registered the effects in a statistical\nanalysis replying the real data diffusion. Then, we studied an hypotetical\nresponse to a misinformation diffusion adding debunking agents and trying to\nmodel a critic response from the agents using real data from a hoax regarding\nthe Occupy Wall Street movement. After tuning our model to reproduce these\nresults, we measured some network properties and proved the emergence of\nsubstantially separated structures like echochambers, independently from the\nnetwork size scale, i.e. with one hundred, one thousand and ten thousand\nagents.\n", "versions": [{"version": "v1", "created": "Tue, 15 May 2018 19:09:41 GMT"}, {"version": "v2", "created": "Thu, 17 May 2018 09:33:35 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Mazzoli", "Mattia", ""], ["Re", "Tullio", ""], ["Bertilone", "Roberto", ""], ["Maggiora", "Marco", ""], ["Pellegrino", "Jacopo", ""]]}, {"id": "1805.06881", "submitter": "Bastien Maubert", "authors": "Aur\\`ele Barri\\`ere, Bastien Maubert, Aniello Murano and Sasha Rubin", "title": "Changing Observations in Epistemic Temporal Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study dynamic changes of agents' observational power in logics of\nknowledge and time. We consider CTL*K, the extension of CTL* with knowledge\noperators, and enrich it with a new operator that models a change in an agent's\nway of observing the system. We extend the classic semantics of knowledge for\nperfect-recall agents to account for changes of observation, and we show that\nthis new operator strictly increases the expressivity of CTL*K. We reduce the\nmodel-checking problem for our logic to that for CTL*K, which is known to be\ndecidable. This provides a solution to the model-checking problem for our\nlogic, but its complexity is not optimal. Indeed we provide a direct decision\nprocedure with better complexity.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2018 17:45:01 GMT"}, {"version": "v2", "created": "Mon, 3 Sep 2018 14:24:22 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Barri\u00e8re", "Aur\u00e8le", ""], ["Maubert", "Bastien", ""], ["Murano", "Aniello", ""], ["Rubin", "Sasha", ""]]}, {"id": "1805.06912", "submitter": "Nikolaos Thomos", "authors": "Eleni Nisioti and Nikolaos Thomos", "title": "Fast reinforcement learning for decentralized MAC optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.MA cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel decentralized framework for optimizing the\ntransmission strategy of Irregular Repetition Slotted ALOHA (IRSA) protocol in\nsensor networks. We consider a hierarchical communication framework that\nensures adaptivity to changing network conditions and does not require\ncentralized control. The proposed solution is inspired by the reinforcement\nlearning literature, and, in particular, Q-learning. To deal with sensor nodes'\nlimited lifetime and communication range, we allow them to decide how many\npacket replicas to transmit considering only their own buffer state. We show\nthat this information is sufficient and can help avoiding packets' collisions\nand improving the throughput significantly. We solve the problem using the\ndecentralized partially observable Markov Decision Process (Dec-POMDP)\nframework, where we allow each node to decide independently of the others how\nmany packet replicas to transmit. We enhance the proposed Q-learning based\nmethod with the concept of virtual experience, and we theoretically and\nexperimentally prove that convergence time is, thus, significantly reduced. The\nexperiments prove that our method leads to large throughput gains, in\nparticular when network traffic is heavy, and scales well with the size of the\nnetwork. To comprehend the effect of the problem's nature on the learning\ndynamics and vice versa, we investigate the waterfall effect, a severe\ndegradation in performance above a particular traffic load, typical for\ncodes-on-graphs and prove that our algorithm learns to alleviate it.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2018 18:19:05 GMT"}], "update_date": "2018-05-21", "authors_parsed": [["Nisioti", "Eleni", ""], ["Thomos", "Nikolaos", ""]]}, {"id": "1805.07456", "submitter": "Hossein Moradian", "authors": "Hossein Moradian and Solmaz S. Kia", "title": "On Robustness Analysis of a Dynamic Average Consensus Algorithm to\n  Communication Delay", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the robustness of a dynamic average consensus algorithm to\ncommunication delay over strongly connected and weight-balanced (SCWB)\ndigraphs. Under delay-free communication, the algorithm of interest achieves a\npractical asymptotic tracking of the dynamic average of the time-varying\nagents' reference signals. For this algorithm, in both its continuous-time and\ndiscrete-time implementations, we characterize the admissible communication\ndelay range and study the effect of the delay on the rate of convergence and\nthe tracking error bound. Our study also includes establishing a relationship\nbetween the admissible delay bound and the maximum degree of the SCWB digraphs.\nWe also show that for delays in the admissible bound, for static signals the\nalgorithms achieve perfect tracking. Moreover, when the interaction topology is\na connected undirected graph, we show that the discrete-time implementation is\nguaranteed to tolerate at least one step delay. Simulations demonstrate our\nresults.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 22:00:04 GMT"}, {"version": "v2", "created": "Wed, 1 Aug 2018 00:55:49 GMT"}, {"version": "v3", "created": "Tue, 11 Dec 2018 09:22:00 GMT"}], "update_date": "2018-12-12", "authors_parsed": [["Moradian", "Hossein", ""], ["Kia", "Solmaz S.", ""]]}, {"id": "1805.07733", "submitter": "Zongqing Lu", "authors": "Jiechuan Jiang and Zongqing Lu", "title": "Learning Attentional Communication for Multi-Agent Cooperation", "comments": "NIPS'18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Communication could potentially be an effective way for multi-agent\ncooperation. However, information sharing among all agents or in predefined\ncommunication architectures that existing methods adopt can be problematic.\nWhen there is a large number of agents, agents cannot differentiate valuable\ninformation that helps cooperative decision making from globally shared\ninformation. Therefore, communication barely helps, and could even impair the\nlearning of multi-agent cooperation. Predefined communication architectures, on\nthe other hand, restrict communication among agents and thus restrain potential\ncooperation. To tackle these difficulties, in this paper, we propose an\nattentional communication model that learns when communication is needed and\nhow to integrate shared information for cooperative decision making. Our model\nleads to efficient and effective communication for large-scale multi-agent\ncooperation. Empirically, we show the strength of our model in a variety of\ncooperative scenarios, where agents are able to develop more coordinated and\nsophisticated strategies than existing methods.\n", "versions": [{"version": "v1", "created": "Sun, 20 May 2018 08:45:50 GMT"}, {"version": "v2", "created": "Wed, 23 May 2018 09:15:28 GMT"}, {"version": "v3", "created": "Thu, 22 Nov 2018 04:09:49 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Jiang", "Jiechuan", ""], ["Lu", "Zongqing", ""]]}, {"id": "1805.07830", "submitter": "Shayegan Omidshafiei", "authors": "Shayegan Omidshafiei, Dong-Ki Kim, Miao Liu, Gerald Tesauro, Matthew\n  Riemer, Christopher Amato, Murray Campbell, Jonathan P. How", "title": "Learning to Teach in Cooperative Multiagent Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collective human knowledge has clearly benefited from the fact that\ninnovations by individuals are taught to others through communication. Similar\nto human social groups, agents in distributed learning systems would likely\nbenefit from communication to share knowledge and teach skills. The problem of\nteaching to improve agent learning has been investigated by prior works, but\nthese approaches make assumptions that prevent application of teaching to\ngeneral multiagent problems, or require domain expertise for problems they can\napply to. This learning to teach problem has inherent complexities related to\nmeasuring long-term impacts of teaching that compound the standard multiagent\ncoordination challenges. In contrast to existing works, this paper presents the\nfirst general framework and algorithm for intelligent agents to learn to teach\nin a multiagent environment. Our algorithm, Learning to Coordinate and Teach\nReinforcement (LeCTR), addresses peer-to-peer teaching in cooperative\nmultiagent reinforcement learning. Each agent in our approach learns both when\nand what to advise, then uses the received advice to improve local learning.\nImportantly, these roles are not fixed; these agents learn to assume the role\nof student and/or teacher at the appropriate moments, requesting and providing\nadvice in order to improve teamwide performance and learning. Empirical\ncomparisons against state-of-the-art teaching methods show that our teaching\nagents not only learn significantly faster, but also learn to coordinate in\ntasks where existing methods fail.\n", "versions": [{"version": "v1", "created": "Sun, 20 May 2018 22:23:46 GMT"}, {"version": "v2", "created": "Tue, 22 May 2018 14:10:38 GMT"}, {"version": "v3", "created": "Tue, 26 Jun 2018 16:21:50 GMT"}, {"version": "v4", "created": "Fri, 31 Aug 2018 18:36:15 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Omidshafiei", "Shayegan", ""], ["Kim", "Dong-Ki", ""], ["Liu", "Miao", ""], ["Tesauro", "Gerald", ""], ["Riemer", "Matthew", ""], ["Amato", "Christopher", ""], ["Campbell", "Murray", ""], ["How", "Jonathan P.", ""]]}, {"id": "1805.07929", "submitter": "Anna Lukina", "authors": "Anna Lukina, Ashish Tiwari, Scott A. Smolka, Radu Grosu", "title": "Adaptive Neighborhood Resizing for Stochastic Reachability in\n  Multi-Agent Systems", "comments": "submitted to conference ATVA 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present DAMPC, a distributed, adaptive-horizon and adaptive-neighborhood\nalgorithm for solving the stochastic reachability problem in multi-agent\nsystems, in particular flocking modeled as a Markov decision process. At each\ntime step, every agent calls a centralized, adaptive-horizon model-predictive\ncontrol (AMPC) algorithm to obtain an optimal solution for its local\nneighborhood. Second, the agents derive the flock-wide optimal solution through\na sequence of consensus rounds. Third, the neighborhood is adaptively resized\nusing a flock-wide, cost-based Lyapunov function V. This way DAMPC improves\nefficiency without compromising convergence. We evaluate DAMPC's performance\nusing statistical model checking. Our results demonstrate that, compared to\nAMPC, DAMPC achieves considerable speed-up (two-fold in some cases) with only a\nslightly lower rate of convergence. The smaller average neighborhood size and\nlookahead horizon demonstrate the benefits of the DAMPC approach for stochastic\nreachability problems involving any controllable multi-agent system that\npossesses a cost function.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 07:50:13 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Lukina", "Anna", ""], ["Tiwari", "Ashish", ""], ["Smolka", "Scott A.", ""], ["Grosu", "Radu", ""]]}, {"id": "1805.08195", "submitter": "Noam Brown", "authors": "Noam Brown, Tuomas Sandholm, Brandon Amos", "title": "Depth-Limited Solving for Imperfect-Information Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental challenge in imperfect-information games is that states do not\nhave well-defined values. As a result, depth-limited search algorithms used in\nsingle-agent settings and perfect-information games do not apply. This paper\nintroduces a principled way to conduct depth-limited solving in\nimperfect-information games by allowing the opponent to choose among a number\nof strategies for the remainder of the game at the depth limit. Each one of\nthese strategies results in a different set of values for leaf nodes. This\nforces an agent to be robust to the different strategies an opponent may\nemploy. We demonstrate the effectiveness of this approach by building a\nmaster-level heads-up no-limit Texas hold'em poker AI that defeats two prior\ntop agents using only a 4-core CPU and 16 GB of memory. Developing such a\npowerful agent would have previously required a supercomputer.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 17:41:32 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Brown", "Noam", ""], ["Sandholm", "Tuomas", ""], ["Amos", "Brandon", ""]]}, {"id": "1805.08320", "submitter": "Sarah Ackerman", "authors": "Sarah M. Ackerman, G. Matthew Fricke, Joshua P. Hecker, Kastro M.\n  Hamed, Samantha R. Fowler, Antonio D. Griego, Jarett C. Jones, J. Jake\n  Nichol, Kurt W. Leucht, and Melanie E. Moses", "title": "The Swarmathon: An Autonomous Swarm Robotics Competition", "comments": "Paper presented May 2018 at ICRA 2018 Workshop: \"Swarms: From Biology\n  to Robotics and Back\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Swarmathon is a swarm robotics programming challenge that engages college\nstudents from minority-serving institutions in NASA's Journey to Mars. Teams\ncompete by programming a group of robots to search for, pick up, and drop off\nresources in a collection zone. The Swarmathon produces prototypes for robot\nswarms that would collect resources on the surface of Mars. Robots operate\ncompletely autonomously with no global map, and each team's algorithm must be\nsufficiently flexible to effectively find resources from a variety of unknown\ndistributions. The Swarmathon includes Physical and Virtual Competitions.\nPhysical competitors test their algorithms on robots they build at their\nschools; they then upload their code to run autonomously on identical robots\nduring the three day competition in an outdoor arena at Kennedy Space Center.\nVirtual competitors complete an identical challenge in simulation. Participants\nmentor local teams to compete in a separate High School Division. In the first\n2 years, over 1,100 students participated. 63% of students were from\nunderrepresented ethnic and racial groups. Participants had significant gains\nin both interest and core robotic competencies that were equivalent across\ngender and racial groups, suggesting that the Swarmathon is effectively\neducating a diverse population of future roboticists.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 23:18:58 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Ackerman", "Sarah M.", ""], ["Fricke", "G. Matthew", ""], ["Hecker", "Joshua P.", ""], ["Hamed", "Kastro M.", ""], ["Fowler", "Samantha R.", ""], ["Griego", "Antonio D.", ""], ["Jones", "Jarett C.", ""], ["Nichol", "J. Jake", ""], ["Leucht", "Kurt W.", ""], ["Moses", "Melanie E.", ""]]}, {"id": "1805.08531", "submitter": "Raphael Berthier", "authors": "Rapha\\\"el Berthier (SIERRA), Francis Bach (SIERRA), Pierre Gaillard\n  (SIERRA)", "title": "Accelerated Gossip in Networks of Given Dimension using Jacobi\n  Polynomial Iterations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a network of agents connected by communication links, where each\nagent holds a real value. The gossip problem consists in estimating the average\nof the values diffused in the network in a distributed manner. We develop a\nmethod solving the gossip problem that depends only on the spectral dimension\nof the network, that is, in the communication network set-up, the dimension of\nthe space in which the agents live. This contrasts with previous work that\nrequired the spectral gap of the network as a parameter, or suffered from slow\nmixing. Our method shows an important improvement over existing algorithms in\nthe non-asymptotic regime, i.e., when the values are far from being fully mixed\nin the network. Our approach stems from a polynomial-based point of view on\ngossip algorithms, as well as an approximation of the spectral measure of the\ngraphs with a Jacobi measure. We show the power of the approach with\nsimulations on various graphs, and with performance guarantees on graphs of\nknown spectral dimension, such as grids and random percolation bonds. An\nextension of this work to distributed Laplacian solvers is discussed. As a side\nresult, we also use the polynomial-based point of view to show the convergence\nof the message passing algorithm for gossip of Moallemi \\& Van Roy on regular\ngraphs. The explicit computation of the rate of the convergence shows that\nmessage passing has a slow rate of convergence on graphs with small spectral\ngap.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 12:02:26 GMT"}, {"version": "v2", "created": "Mon, 18 Feb 2019 14:23:15 GMT"}, {"version": "v3", "created": "Thu, 16 May 2019 07:41:05 GMT"}, {"version": "v4", "created": "Tue, 11 Jun 2019 09:04:43 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Berthier", "Rapha\u00ebl", "", "SIERRA"], ["Bach", "Francis", "", "SIERRA"], ["Gaillard", "Pierre", "", "SIERRA"]]}, {"id": "1805.08535", "submitter": "Roula Nassif", "authors": "Roula Nassif, Stefan Vlaski, Cedric Richard, Ali H. Sayed", "title": "Learning over Multitask Graphs -- Part I: Stability Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper formulates a multitask optimization problem where agents in the\nnetwork have individual objectives to meet, or individual parameter vectors to\nestimate, subject to a smoothness condition over the graph. The smoothness\ncondition softens the transition in the tasks among adjacent nodes and allows\nincorporating information about the graph structure into the solution of the\ninference problem. A diffusion strategy is devised that responds to streaming\ndata and employs stochastic approximations in place of actual gradient vectors,\nwhich are generally unavailable. The approach relies on minimizing a global\ncost consisting of the aggregate sum of individual costs regularized by a term\nthat promotes smoothness. We show in this Part I of the work, under conditions\non the step-size parameter, that the adaptive strategy induces a contraction\nmapping and leads to small estimation errors on the order of the small\nstep-size. The results in the accompanying Part II will reveal explicitly the\ninfluence of the network topology and the regularization strength on the\nnetwork performance and will provide insights into the design of effective\nmultitask strategies for distributed inference over networks.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 12:19:49 GMT"}, {"version": "v2", "created": "Fri, 15 Nov 2019 11:58:59 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Nassif", "Roula", ""], ["Vlaski", "Stefan", ""], ["Richard", "Cedric", ""], ["Sayed", "Ali H.", ""]]}, {"id": "1805.08547", "submitter": "Roula Nassif", "authors": "Roula Nassif, Stefan Vlaski, Cedric Richard, Ali H. Sayed", "title": "Learning over Multitask Graphs -- Part II: Performance Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Part I of this paper formulated a multitask optimization problem where agents\nin the network have individual objectives to meet, or individual parameter\nvectors to estimate, subject to a smoothness condition over the graph. A\ndiffusion strategy was devised that responds to streaming data and employs\nstochastic approximations in place of actual gradient vectors, which are\ngenerally unavailable. The approach relied on minimizing a global cost\nconsisting of the aggregate sum of individual costs regularized by a term that\npromotes smoothness. We examined the first-order, the second-order, and the\nfourth-order stability of the multitask learning algorithm. The results\nidentified conditions on the step-size parameter, regularization strength, and\ndata characteristics in order to ensure stability. This Part II examines\nsteady-state performance of the strategy. The results reveal explicitly the\ninfluence of the network topology and the regularization strength on the\nnetwork performance and provide insights into the design of effective multitask\nstrategies for distributed inference over networks.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 12:42:19 GMT"}, {"version": "v2", "created": "Fri, 15 Nov 2019 12:05:38 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Nassif", "Roula", ""], ["Vlaski", "Stefan", ""], ["Richard", "Cedric", ""], ["Sayed", "Ali H.", ""]]}, {"id": "1805.08588", "submitter": "Hongyao Tang", "authors": "Hongyao Tang, Li Wang, Zan Wang, Tim Baarslag, Jianye Hao", "title": "An Optimal Rewiring Strategy for Reinforcement Social Learning in\n  Cooperative Multiagent Systems", "comments": "9 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiagent coordination in cooperative multiagent systems (MASs) has been\nwidely studied in both fixed-agent repeated interaction setting and the static\nsocial learning framework. However, two aspects of dynamics in real-world\nmultiagent scenarios are currently missing in existing works. First, the\nnetwork topologies can be dynamic where agents may change their connections\nthrough rewiring during the course of interactions. Second, the game matrix\nbetween each pair of agents may not be static and usually not known as a prior.\nBoth the network dynamic and game uncertainty increase the coordination\ndifficulty among agents. In this paper, we consider a multiagent dynamic social\nlearning environment in which each agent can choose to rewire potential\npartners and interact with randomly chosen neighbors in each round. We propose\nan optimal rewiring strategy for agents to select most beneficial peers to\ninteract with for the purpose of maximizing the accumulated payoff in repeated\ninteractions. We empirically demonstrate the effectiveness and robustness of\nour approach through comparing with benchmark strategies. The performance of\nthree representative learning strategies under our social learning framework\nwith our optimal rewiring is investigated as well.\n", "versions": [{"version": "v1", "created": "Sun, 13 May 2018 14:20:11 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Tang", "Hongyao", ""], ["Wang", "Li", ""], ["Wang", "Zan", ""], ["Baarslag", "Tim", ""], ["Hao", "Jianye", ""]]}, {"id": "1805.08629", "submitter": "Ayan Dutta", "authors": "Ayan Dutta, Vladimir Ufimtsev, Asai Asaithambi", "title": "Correlation Clustering Based Coalition Formation For Multi-Robot Task\n  Allocation", "comments": null, "journal-ref": null, "doi": "10.1145/3297280.3297369", "report-no": null, "categories": "cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the multi-robot task allocation problem where a group\nof robots needs to be allocated to a set of tasks so that the tasks can be\nfinished optimally. One task may need more than one robot to finish it.\nTherefore the robots need to form coalitions to complete these tasks.\nMulti-robot coalition formation for task allocation is a well-known NP-hard\nproblem. To solve this problem, we use a linear-programming based graph\npartitioning approach along with a region growing strategy which allocates\n(near) optimal robot coalitions to tasks in a negligible amount of time. Our\nproposed algorithm is fast (only taking 230 secs. for 100 robots and 10 tasks)\nand it also finds a near-optimal solution (up to 97.66% of the optimal). We\nhave empirically demonstrated that the proposed approach in this paper always\nfinds a solution which is closer (up to 9.1 times) to the optimal solution than\na theoretical worst-case bound proved in an earlier work.\n", "versions": [{"version": "v1", "created": "Sun, 20 May 2018 22:50:30 GMT"}], "update_date": "2018-12-14", "authors_parsed": [["Dutta", "Ayan", ""], ["Ufimtsev", "Vladimir", ""], ["Asaithambi", "Asai", ""]]}, {"id": "1805.08776", "submitter": "Arbaaz Khan", "authors": "Arbaaz Khan, Clark Zhang, Daniel D. Lee, Vijay Kumar, Alejandro\n  Ribeiro", "title": "Scalable Centralized Deep Multi-Agent Reinforcement Learning via Policy\n  Gradients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we explore using deep reinforcement learning for problems with\nmultiple agents. Most existing methods for deep multi-agent reinforcement\nlearning consider only a small number of agents. When the number of agents\nincreases, the dimensionality of the input and control spaces increase as well,\nand these methods do not scale well. To address this, we propose casting the\nmulti-agent reinforcement learning problem as a distributed optimization\nproblem. Our algorithm assumes that for multi-agent settings, policies of\nindividual agents in a given population live close to each other in parameter\nspace and can be approximated by a single policy. With this simple assumption,\nwe show our algorithm to be extremely effective for reinforcement learning in\nmulti-agent settings. We demonstrate its effectiveness against existing\ncomparable approaches on co-operative and competitive tasks.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 00:31:03 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Khan", "Arbaaz", ""], ["Zhang", "Clark", ""], ["Lee", "Daniel D.", ""], ["Kumar", "Vijay", ""], ["Ribeiro", "Alejandro", ""]]}, {"id": "1805.09081", "submitter": "Augusto Santos J. A.", "authors": "Augusto Santos, Vincenzo Matta, Ali H. Sayed", "title": "Local Tomography of Large Networks under the Low-Observability Regime", "comments": "To appear in IEEE Transactions on Information Theory", "journal-ref": null, "doi": "10.1109/TIT.2019.2945033", "report-no": null, "categories": "cs.MA cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article studies the problem of reconstructing the topology of a network\nof interacting agents via observations of the state-evolution of the agents. We\nfocus on the large-scale network setting with the additional constraint of\n$partial$ observations, where only a small fraction of the agents can be\nfeasibly observed. The goal is to infer the underlying subnetwork of\ninteractions and we refer to this problem as $local$ $tomography$. In order to\nstudy the large-scale setting, we adopt a proper stochastic formulation where\nthe unobserved part of the network is modeled as an Erd\\\"{o}s-R\\'enyi random\ngraph, while the observable subnetwork is left arbitrary. The main result of\nthis work is establishing that, under this setting, local tomography is\nactually possible with high probability, provided that certain conditions on\nthe network model are met (such as stability and symmetry of the network\ncombination matrix). Remarkably, such conclusion is established under the\n$low$-$observability$ $regime$, where the cardinality of the observable\nsubnetwork is fixed, while the size of the overall network scales to infinity.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 12:10:21 GMT"}, {"version": "v2", "created": "Sat, 28 Sep 2019 20:44:29 GMT"}, {"version": "v3", "created": "Mon, 21 Oct 2019 15:39:21 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Santos", "Augusto", ""], ["Matta", "Vincenzo", ""], ["Sayed", "Ali H.", ""]]}, {"id": "1805.09090", "submitter": "Stefano Bennati", "authors": "Stefano Bennati, Ivana Dusparic, Rhythima Shinde, and Catholijn M.\n  Jonker", "title": "Volunteers in the Smart City: Comparison of Contribution Strategies on\n  Human-Centered Measures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several smart city services rely on users contribution, e.g., data, which can\nbe costly for the users in terms of privacy. High costs lead to reduced user\nparticipation, which undermine the success of smart city technologies. This\nwork develops a scenario-independent design principle, based on public good\ntheory, for resource management in smart city applications, where provision of\na service depends on contributors and free-riders, which benefit from the\nservice without contributing own resources. Following this design principle,\ndifferent classes of algorithms for resource management are evaluated with\nrespect to human-centered measures, i.e., privacy, fairness and social welfare.\nTrade-offs that characterize algorithms are discussed across two smart city\napplication scenarios. These results might help Smart City application\ndesigners to choose a suitable algorithm given a scenario-specific set of\nrequirements, and users to choose a service based on an algorithm that matches\ntheir preferences.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 12:30:23 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Bennati", "Stefano", ""], ["Dusparic", "Ivana", ""], ["Shinde", "Rhythima", ""], ["Jonker", "Catholijn M.", ""]]}, {"id": "1805.09633", "submitter": "Rahul Tallamraju", "authors": "Rahul Tallamraju, Sujit Rajappa, Michael Black, Kamalakar Karlapalem\n  and Aamir Ahmad", "title": "Decentralized MPC based Obstacle Avoidance for Multi-Robot Target\n  Tracking Scenarios", "comments": null, "journal-ref": "2018 IEEE SSRR, Philadelphia, PA, 2018, pp. 1-8", "doi": "10.1109/SSRR.2018.8468655", "report-no": null, "categories": "cs.RO cs.MA cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we consider the problem of decentralized multi-robot target\ntracking and obstacle avoidance in dynamic environments. Each robot executes a\nlocal motion planning algorithm which is based on model predictive control\n(MPC). The planner is designed as a quadratic program, subject to constraints\non robot dynamics and obstacle avoidance. Repulsive potential field functions\nare employed to avoid obstacles. The novelty of our approach lies in embedding\nthese non-linear potential field functions as constraints within a convex\noptimization framework. Our method convexifies non-convex constraints and\ndependencies, by replacing them as pre-computed external input forces in robot\ndynamics. The proposed algorithm additionally incorporates different methods to\navoid field local minima problems associated with using potential field\nfunctions in planning. The motion planner does not enforce predefined\ntrajectories or any formation geometry on the robots and is a comprehensive\nsolution for cooperative obstacle avoidance in the context of multi-robot\ntarget tracking. We perform simulation studies in different environmental\nscenarios to showcase the convergence and efficacy of the proposed algorithm.\nVideo of simulation studies: \\url{https://youtu.be/umkdm82Tt0M}\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 12:22:15 GMT"}, {"version": "v2", "created": "Sun, 1 Sep 2019 20:52:32 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Tallamraju", "Rahul", ""], ["Rajappa", "Sujit", ""], ["Black", "Michael", ""], ["Karlapalem", "Kamalakar", ""], ["Ahmad", "Aamir", ""]]}, {"id": "1805.10109", "submitter": "Sylvie Huet", "authors": "Sylvie Huet, Guillaume Deffuant, Armelle Nugier, Michel Streith, Serge\n  Guimond", "title": "Resisting hostility generated by terror: An agent-based study", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pone.0209907", "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We aim to study through an agent-based model the cultural conditions leading\nto a decrease or an increase of discrimination between groups after a major\ncultural threat such as a terrorist attack. We propose an agent-based model of\ncultural dynamics inspired from the social psychological theories. An agent has\na cultural identity comprised of the most acceptable positions about each of\nthe different cultural worldviews corresponding to the main cultural groups of\nthe considered society and a margin of acceptance around each of these most\nacceptable positions. An agent forms an attitude about another agent depending\non the similarity between their cultural identities. When a terrorist attack is\nperpetrated in the name of an extreme cultural identity, the negatively\nperceived agents from this extreme cultural identity modify their margins of\nacceptance in order to differentiate themselves more from the threatening\ncultural identity. We generated a set of populations with cultural identities\ncompatible with data given by a survey on groups' attitudes among a large\nsample representative of the population of France; we then simulated the\nreaction of these agents facing a threat. For most populations, the average\nattitude toward agents with the same preferred worldview as the terrorists\nbecomes more negative; however, when the population shows some cultural\nproperties, we noticed the opposite effect as the average attitude of the\npopulation becomes less negative. This particular context requires that the\nagents sharing the same preferred worldview with the terrorists strongly\ndifferentiate themselves from the terrorists' extreme cultural identity and\nthat the other agents be aware of these changes.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 12:39:27 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Huet", "Sylvie", ""], ["Deffuant", "Guillaume", ""], ["Nugier", "Armelle", ""], ["Streith", "Michel", ""], ["Guimond", "Serge", ""]]}, {"id": "1805.10176", "submitter": "Sylvie Huet", "authors": "Sylvie Huet, Jean-Denis Mathias", "title": "Few self-involved agents among BC agents can lead to polarized local or\n  global consensus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social issues are generally discussed by highly-involved and less-involved\npeople to build social norms defining what has to be thought and done about\nthem. As self-involved agents share different attitude dynamics to other agents\nWood, Pool et al, 1996, we study the emergence and evolution of norms through\nan individual-based model involving these two types of agents. The dynamics of\nself-involved agents is drawn from Huet and Deffuant, 2010, and the dynamics of\nothers, from Deffuant et al, 2001. The attitude of an agent is represented as a\nsegment on a continuous attitudinal space. Two agents are close if their\nattitude segments share sufficient overlap. Our agents discuss two different\nissues, one of which, called main issue, is more important for the\nself-involved agents than the other, called secondary issue. Self-involved\nagents are attracted on both issues if they are close on main issue, but shift\naway from their peer's opinion if they are only close on secondary issue.\nDifferently, non-self-involved agents are attracted by other agents when they\nare close on both the main and secondary issues. We observe the emergence of\nvarious types of extreme minor clusters. In one or different groups of\nattitudes, they can lead to an already-built moderate norm or a norm polarized\non secondary and/or main issues. They can also push disagreeing agents gathered\nin different groups to a global moderate consensus.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 14:34:51 GMT"}], "update_date": "2018-05-28", "authors_parsed": [["Huet", "Sylvie", ""], ["Mathias", "Jean-Denis", ""]]}, {"id": "1805.10195", "submitter": "Juste Raimbault", "authors": "Juste Raimbault", "title": "Reconciling complexities: for a stronger integration of approaches to\n  complex socio-technical systems", "comments": "13 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.MA physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Systems engineering has developed a mature knowledge on how to design,\nintegrate and manage complex industrial systems, whereas disciplines studying\ncomplex systems in nature or society also propose numerous tools for their\nunderstanding. Socio-technical systems, that situate at their intersection,\ncould benefit from a higher integration between these. This position paper\nadvocates for such integrated approaches. A bibliometric study through citation\nnetworks first illustrates the respective isolation of some of these\napproaches. We then produce a proof-of-concept of how the transfer of concepts\nfrom biology can be useful for the design of complex systems, in the particular\ncase of transportation networks, using a biological network growth model to\nproduce various optimal networks in terms of cost and efficiency. We finally\ndiscuss possible disciplinary positioning of such hybrid approaches.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 15:25:55 GMT"}], "update_date": "2018-05-28", "authors_parsed": [["Raimbault", "Juste", ""]]}, {"id": "1805.10906", "submitter": "Giorgio Forcina", "authors": "Carlo Castagnari, Flavio Corradini, Francesco De Angelis, Jacopo de\n  Berardinis, Giorgio Forcina and Andrea Polini", "title": "Tangramob: an agent-based simulation framework for validating urban\n  smart mobility solutions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating the effects of introducing a range of smart mobility solutions\nwithin an urban area is a crucial concern in urban planning. The lack of a\nDecision Support System (DSS) for the assessment of mobility initiatives,\nforces local public authorities and mobility service providers to base their\ndecisions on guidelines derived from common heuristics and best practices.\nThese approaches can help planners in shaping mobility solutions, but given the\nhigh number of variables to consider the effects are not guaranteed. Therefore,\na solution conceived respecting the available guidelines can result in a\nfailure in a different context. In particular, difficult aspects to consider\nare the interactions between different mobility services available in a given\nurban area, and the acceptance of a given mobility initiative by the\ninhabitants of the area. In order to fill this gap, we introduce Tangramob, an\nagent-based simulation framework capable of assessing the impacts of a Smart\nMobility Initiative (SMI) within an urban area of interest. Tangramob simulates\nhow urban traffic is expected to evolve as citizens start experiencing the\nnewly offered traveling solutions. This allows decision makers to evaluate the\nefficacy of their initiatives taking into account the current urban system. In\nthis paper we provide an overview of the simulation framework along with its\ndesign. To show the potential of Tangramob, 3 mobility initiatives are\nsimulated and compared on the same scenario. This shows how it is possible to\nperform comparative experiments so as to align mobility initiatives to the user\ngoals.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 13:15:52 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Castagnari", "Carlo", ""], ["Corradini", "Flavio", ""], ["De Angelis", "Francesco", ""], ["de Berardinis", "Jacopo", ""], ["Forcina", "Giorgio", ""], ["Polini", "Andrea", ""]]}, {"id": "1805.11384", "submitter": "Bicheng Ying", "authors": "Bicheng Ying and Kun Yuan and Ali H. Sayed", "title": "Supervised Learning Under Distributed Features", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2018.2881661", "report-no": null, "categories": "cs.MA cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work studies the problem of learning under both large datasets and\nlarge-dimensional feature space scenarios. The feature information is assumed\nto be spread across agents in a network, where each agent observes some of the\nfeatures. Through local cooperation, the agents are supposed to interact with\neach other to solve an inference problem and converge towards the global\nminimizer of an empirical risk. We study this problem exclusively in the primal\ndomain, and propose new and effective distributed solutions with guaranteed\nconvergence to the minimizer with linear rate under strong convexity. This is\nachieved by combining a dynamic diffusion construction, a pipeline strategy,\nand variance-reduced techniques. Simulation results illustrate the conclusions.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 12:25:37 GMT"}, {"version": "v2", "created": "Fri, 9 Nov 2018 08:17:47 GMT"}, {"version": "v3", "created": "Fri, 22 May 2020 18:06:47 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Ying", "Bicheng", ""], ["Yuan", "Kun", ""], ["Sayed", "Ali H.", ""]]}]