[{"id": "2010.00004", "submitter": "Soraia Musse", "authors": "Estevso Testa, Rodrigo C. Barros, Soraia Raupp Musse", "title": "CrowdEst: A Method for Estimating (and not Simulating) Crowd Evacuation\n  Parameters in Generic Environments", "comments": null, "journal-ref": "THE VISUAL COMPUTER, 2019", "doi": "10.1007/s00371-019-01684-9", "report-no": null, "categories": "cs.MA cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evacuation plans have been historically used as a safety measure for the\nconstruction of buildings. The existing crowd simulators require fully-modeled\n3D environments and enough time to prepare and simulate scenarios, where the\ndistribution and behavior of the crowd needs to be controlled. In addition, its\npopulation, routes or even doors and passages may change, so the 3D model and\nconfigurations have to be updated accordingly. This is a time-consuming task\nthat commonly has to be addressed within the crowd simulators. With that in\nmind, we present a novel approach to estimate the resulting data of a given\nevacuation scenario without actually simulating it. For such, we divide the\nenvironment into smaller modular rooms with different configurations, in a\ndivide-and-conquer fashion. Next, we train an artificial neural network to\nestimate all required data regarding the evacuation of a single room. After\ncollecting the estimated data from each room, we develop a heuristic capable of\naggregating per-room information so the full environment can be properly\nevaluated. Our method presents an average error of 5% when compared to\nevacuation time in a real-life environment. Our crowd estimator approach has\nseveral advantages, such as not requiring to model the 3D environment, nor\nlearning how to use and configure a crowd simulator, which means any user can\neasily use it. Furthermore, the computational time to estimate evacuation data\n(inference time) is virtually zero, which is much better even when compared to\nthe best-case scenario in a real-time crowd simulator.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 14:42:45 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Testa", "Estevso", ""], ["Barros", "Rodrigo C.", ""], ["Musse", "Soraia Raupp", ""]]}, {"id": "2010.00082", "submitter": "Siamak Sarmady", "authors": "Siamak Sarmady, Fazilah Haron, Abdullah Zawawi Talib", "title": "Simulation of Wheelchair Movements in Crowd Using Fine Grid Cellular\n  Automata", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crowd simulation models are used to assess the performance and safety of\ncrowd systems. In some systems, wheelchairs and other moving objects are\npresent in the crowd. The different size and speed of the wheelchairs could\nsignificantly change the behavior and dynamics of the crowd. In order to\nminimize the risks of overcrowding and other types of accidents, it is\nimportant to properly model the wheelchairs and their interactions with\npedestrians and the environment. Cellular automata are extensively utilized in\ncrowd modeling because of their simple and fast algorithms. Fine grid cellular\nautomata model uses small cells in which moving entities (pedestrians,\nwheelchairs, cars and etc.) occupy several cells. The entities could have\ndifferent sizes, shapes, and speeds. In this article, fine grid cellular\nautomata model has been modified to allow building crowd simulation models with\ndifferent ratios of wheelchairs that could be of different sizes and speed\nprofiles. A scenario of a walkway has been used to evaluate the model. The slow\ndown effect of the slower wheelchairs has been properly reproduced in the\nresults which also match empirical data. Density-speed graphs are also compared\nto crowds comprising of only pedestrians.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 11:39:05 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Sarmady", "Siamak", ""], ["Haron", "Fazilah", ""], ["Talib", "Abdullah Zawawi", ""]]}, {"id": "2010.00161", "submitter": "Olusola Odeyomi", "authors": "Olusola T. Odeyomi", "title": "Unknown Delay for Adversarial Bandit Setting with Multiple Play", "comments": "9 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of unknown delays in adversarial multi-armed\nbandit (MAB) with multiple play. Existing work on similar game setting focused\non only the case where the learner selects an arm in each round. However, there\nare lots of applications in robotics where a learner needs to select more than\none arm per round. It is therefore worthwhile to investigate the effect of\ndelay when multiple arms are chosen. The multiple arms chosen per round in this\nsetting are such that they experience the same amount of delay. There can be an\naggregation of feedback losses from different combinations of arms selected at\ndifferent rounds, and the learner is faced with the challenge of associating\nthe feedback losses to the arms producing them. To address this problem, this\npaper proposes a delayed exponential, exploitation and exploration for multiple\nplay (DEXP3.M) algorithm. The regret bound is only slightly worse than the\nregret of DEXP3 already proposed for the single play setting with unknown\ndelay.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 01:07:19 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Odeyomi", "Olusola T.", ""]]}, {"id": "2010.00386", "submitter": "Fabrizia Auletta", "authors": "Fabrizia Auletta, Davide Fiore, Michael J. Richardson, Mario di\n  Bernardo", "title": "Herding stochastic autonomous agents via local control rules and online\n  global target selection strategies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this Paper we propose a simple yet effective set of local control rules to\nmake a group of \"herder agents\" collect and contain in a desired region an\nensemble of non-cooperative stochastic \"target agents\" in the plane. We\ninvestigate the robustness of the proposed strategies to variations of the\nnumber of target agents and the strength of the repulsive force they feel when\nin proximity of the herders. Extensive numerical simulations confirm the\neffectiveness of the approach and are complemented by a more realistic\nvalidation on commercially available robotic agents via ROS.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 13:26:27 GMT"}, {"version": "v2", "created": "Wed, 2 Dec 2020 13:21:04 GMT"}, {"version": "v3", "created": "Wed, 7 Apr 2021 16:33:14 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Auletta", "Fabrizia", ""], ["Fiore", "Davide", ""], ["Richardson", "Michael J.", ""], ["di Bernardo", "Mario", ""]]}, {"id": "2010.00398", "submitter": "Milad Siami", "authors": "Atefe Darabi and Milad Siami", "title": "Centrality-Based Traffic Restriction in Delayed Epidemic Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.MA cs.SI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During an epidemic, infectious individuals might not be detectable until some\ntime after becoming infected. The studies show that carriers with mild or no\nsymptoms are the main contributors to the transmission of a virus within the\npopulation. The average time it takes to develop the symptoms causes a delay in\nthe spread dynamics of the disease. When considering the influence of delay on\nthe disease propagation in epidemic networks, depending on the value of the\ntime-delay and the network topology, the peak of epidemic could be considerably\ndifferent in time, duration, and intensity. Motivated by the recent worldwide\noutbreak of the COVID-19 virus and the topological extent in which this virus\nhas spread over the course of a few months, this study aims to highlight the\neffect of time-delay in the progress of such infectious diseases in the\nmeta-population networks rather than individuals or a single population. In\nthis regard, the notions of epidemic network centrality in terms of the\nunderlying interaction graph of the network, structure of the uncertainties,\nand symptom development duration are investigated to establish a\ncentrality-based analysis of the disease evolution. A convex traffic volume\noptimization method is then developed to control the outbreak. The control\nprocess is done by identifying the sub-populations with the highest centrality\nand then isolating them while maintaining the same overall traffic volume\n(motivated by economic considerations) in the meta-population level. The\nnumerical results, along with the theoretical expectations, highlight the\nimpact of time-delay as well as the importance of considering the worst-case\nscenarios in investigating the most effective methods of epidemic containment.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 22:43:36 GMT"}, {"version": "v2", "created": "Sun, 15 Nov 2020 05:53:45 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Darabi", "Atefe", ""], ["Siami", "Milad", ""]]}, {"id": "2010.00403", "submitter": "The Anh Han", "authors": "The Anh Han, Luis Moniz Pereira, Tom Lenaerts, Francisco C. Santos", "title": "Mediating Artificial Intelligence Developments through Negative and\n  Positive Incentives", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pone.0244592", "report-no": null, "categories": "cs.AI cs.MA math.DS nlin.AO q-bio.PE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The field of Artificial Intelligence (AI) is going through a period of great\nexpectations, introducing a certain level of anxiety in research, business and\nalso policy. This anxiety is further energised by an AI race narrative that\nmakes people believe they might be missing out. Whether real or not, a belief\nin this narrative may be detrimental as some stake-holders will feel obliged to\ncut corners on safety precautions, or ignore societal consequences just to\n\"win\". Starting from a baseline model that describes a broad class of\ntechnology races where winners draw a significant benefit compared to others\n(such as AI advances, patent race, pharmaceutical technologies), we investigate\nhere how positive (rewards) and negative (punishments) incentives may\nbeneficially influence the outcomes. We uncover conditions in which punishment\nis either capable of reducing the development speed of unsafe participants or\nhas the capacity to reduce innovation through over-regulation. Alternatively,\nwe show that, in several scenarios, rewarding those that follow safety measures\nmay increase the development speed while ensuring safe choices. Moreover, in\n{the latter} regimes, rewards do not suffer from the issue of over-regulation\nas is the case for punishment. Overall, our findings provide valuable insights\ninto the nature and kinds of regulatory actions most suitable to improve safety\ncompliance in the contexts of both smooth and sudden technological shifts.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 13:43:32 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Han", "The Anh", ""], ["Pereira", "Luis Moniz", ""], ["Lenaerts", "Tom", ""], ["Santos", "Francisco C.", ""]]}, {"id": "2010.00575", "submitter": "Ian Gemp", "authors": "Ian Gemp, Kevin R. McKee, Richard Everett, Edgar A.\n  Du\\'e\\~nez-Guzm\\'an, Yoram Bachrach, David Balduzzi, Andrea Tacchetti", "title": "D3C: Reducing the Price of Anarchy in Multi-Agent Learning", "comments": "Added Acknowledgments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Even in simple multi-agent systems, fixed incentives can lead to outcomes\nthat are poor for the group and each individual agent. We propose a method,\nD3C, for online adjustment of agent incentives that reduces the loss incurred\nat a Nash equilibrium. Agents adjust their incentives by learning to mix their\nincentive with that of other agents, until a compromise is reached in a\ndistributed fashion. We show that D3C improves outcomes for each agent and the\ngroup as a whole on several social dilemmas including a traffic network with\nBraess's paradox, a prisoner's dilemma, and several reinforcement learning\ndomains.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 17:50:43 GMT"}, {"version": "v2", "created": "Fri, 2 Oct 2020 09:10:14 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Gemp", "Ian", ""], ["McKee", "Kevin R.", ""], ["Everett", "Richard", ""], ["Du\u00e9\u00f1ez-Guzm\u00e1n", "Edgar A.", ""], ["Bachrach", "Yoram", ""], ["Balduzzi", "David", ""], ["Tacchetti", "Andrea", ""]]}, {"id": "2010.00581", "submitter": "Kamal Ndousse", "authors": "Kamal Ndousse, Douglas Eck, Sergey Levine, Natasha Jaques", "title": "Emergent Social Learning via Multi-agent Reinforcement Learning", "comments": "14 pages, 19 figures. To be published in ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social learning is a key component of human and animal intelligence. By\ntaking cues from the behavior of experts in their environment, social learners\ncan acquire sophisticated behavior and rapidly adapt to new circumstances. This\npaper investigates whether independent reinforcement learning (RL) agents in a\nmulti-agent environment can learn to use social learning to improve their\nperformance. We find that in most circumstances, vanilla model-free RL agents\ndo not use social learning. We analyze the reasons for this deficiency, and\nshow that by imposing constraints on the training environment and introducing a\nmodel-based auxiliary loss we are able to obtain generalized social learning\npolicies which enable agents to: i) discover complex skills that are not\nlearned from single-agent training, and ii) adapt online to novel environments\nby taking cues from experts present in the new environment. In contrast, agents\ntrained with model-free RL or imitation learning generalize poorly and do not\nsucceed in the transfer tasks. By mixing multi-agent and solo training, we can\nobtain agents that use social learning to gain skills that they can deploy when\nalone, even out-performing agents trained alone from the start.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 17:54:14 GMT"}, {"version": "v2", "created": "Sun, 22 Nov 2020 19:02:43 GMT"}, {"version": "v3", "created": "Tue, 22 Jun 2021 21:18:59 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Ndousse", "Kamal", ""], ["Eck", "Douglas", ""], ["Levine", "Sergey", ""], ["Jaques", "Natasha", ""]]}, {"id": "2010.00651", "submitter": "Nimrod Talmon", "authors": "Piotr Faliszewski, Rica Gonen, Martin Kouteck\\'y, Nimrod Talmon", "title": "Opinion Diffusion and Campaigning on Society Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the effects of campaigning, where the society is partitioned into\nvoter clusters and a diffusion process propagates opinions in a network\nconnecting the clusters. Our model is very powerful and can incorporate many\ncampaigning actions, various partitions of the society into clusters, and very\ngeneral diffusion processes. Perhaps surprisingly, we show that computing the\ncheapest campaign for rigging a given election can usually be done efficiently,\neven with arbitrarily-many voters. Moreover, we report on certain computational\nsimulations.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 19:25:55 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Faliszewski", "Piotr", ""], ["Gonen", "Rica", ""], ["Kouteck\u00fd", "Martin", ""], ["Talmon", "Nimrod", ""]]}, {"id": "2010.00802", "submitter": "Thomas Kurbiel", "authors": "Thomas Kurbiel, Akash Sachdeva, Kun Zhao and Markus Buehren", "title": "PrognoseNet: A Generative Probabilistic Framework for Multimodal\n  Position Prediction given Context Information", "comments": "8 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to predict multiple possible future positions of the ego-vehicle\ngiven the surrounding context while also estimating their probabilities is key\nto safe autonomous driving. Most of the current state-of-the-art Deep Learning\napproaches are trained on trajectory data to achieve this task. However\ntrajectory data captured by sensor systems is highly imbalanced, since by far\nmost of the trajectories follow straight lines with an approximately constant\nvelocity. This poses a huge challenge for the task of predicting future\npositions, which is inherently a regression problem. Current state-of-the-art\napproaches alleviate this problem only by major preprocessing of the training\ndata, e.g. resampling, clustering into anchors etc. In this paper we propose an\napproach which reformulates the prediction problem as a classification task,\nallowing for powerful tools, e.g. focal loss, to combat the imbalance. To this\nend we design a generative probabilistic model consisting of a deep neural\nnetwork with a Mixture of Gaussian head. A smart choice of the latent variable\nallows for the reformulation of the log-likelihood function as a combination of\na classification problem and a much simplified regression problem. The output\nof our model is an estimate of the probability density function of future\npositions, hence allowing for prediction of multiple possible positions while\nalso estimating their probabilities. The proposed approach can easily\nincorporate context information and does not require any preprocessing of the\ndata.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 06:13:41 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Kurbiel", "Thomas", ""], ["Sachdeva", "Akash", ""], ["Zhao", "Kun", ""], ["Buehren", "Markus", ""]]}, {"id": "2010.00810", "submitter": "Christoph Benzm\\\"uller", "authors": "Sebastian Reiche and Christoph Benzm\\\"uller", "title": "Public Announcement Logic in HOL", "comments": "3rd DaL\\'i Workshop, Dynamic Logic: New Trends and Applications,\n  Online, 9-10 October 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO cs.MA math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A shallow semantical embedding for public announcement logic with relativized\ncommon knowledge is presented. This embedding enables the first-time automation\nof this logic with off-the-shelf theorem provers for classical higher-order\nlogic. It is demonstrated (i) how meta-theoretical studies can be automated\nthis way, and (ii) how non-trivial reasoning in the target logic (public\nannouncement logic), required e.g. to obtain a convincing encoding and\nautomation of the wise men puzzle, can be realized. Key to the presented\nsemantical embedding -- in contrast, e.g., to related work on the semantical\nembedding of normal modal logics -- is that evaluation domains are modeled\nexplicitly and treated as additional parameter in the encodings of the\nconstituents of the embedded target logic, while they were previously\nimplicitly shared between meta logic and target logic.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 06:46:02 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Reiche", "Sebastian", ""], ["Benzm\u00fcller", "Christoph", ""]]}, {"id": "2010.00993", "submitter": "Sohan Rudra Mr.", "authors": "Anirban Santara, Sohan Rudra, Sree Aditya Buridi, Meha Kaushik,\n  Abhishek Naik, Bharat Kaul, Balaraman Ravindran", "title": "MADRaS : Multi Agent Driving Simulator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present MADRaS, an open-source multi-agent driving simulator\nfor use in the design and evaluation of motion planning algorithms for\nautonomous driving. MADRaS provides a platform for constructing a wide variety\nof highway and track driving scenarios where multiple driving agents can train\nfor motion planning tasks using reinforcement learning and other machine\nlearning algorithms. MADRaS is built on TORCS, an open-source car-racing\nsimulator. TORCS offers a variety of cars with different dynamic properties and\ndriving tracks with different geometries and surface properties. MADRaS\ninherits these functionalities from TORCS and introduces support for\nmulti-agent training, inter-vehicular communication, noisy observations,\nstochastic actions, and custom traffic cars whose behaviours can be programmed\nto simulate challenging traffic conditions encountered in the real world.\nMADRaS can be used to create driving tasks whose complexities can be tuned\nalong eight axes in well-defined steps. This makes it particularly suited for\ncurriculum and continual learning. MADRaS is lightweight and it provides a\nconvenient OpenAI Gym interface for independent control of each car. Apart from\nthe primitive steering-acceleration-brake control mode of TORCS, MADRaS offers\na hierarchical track-position -- speed control that can potentially be used to\nachieve better generalization. MADRaS uses multiprocessing to run each agent as\na parallel process for efficiency and integrates well with popular\nreinforcement learning libraries like RLLib.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 13:38:49 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Santara", "Anirban", ""], ["Rudra", "Sohan", ""], ["Buridi", "Sree Aditya", ""], ["Kaushik", "Meha", ""], ["Naik", "Abhishek", ""], ["Kaul", "Bharat", ""], ["Ravindran", "Balaraman", ""]]}, {"id": "2010.01192", "submitter": "Sanjeevan Ahilan", "authors": "Sanjeevan Ahilan, Peter Dayan", "title": "Correcting Experience Replay for Multi-Agent Communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning to communicate using multi-agent\nreinforcement learning (MARL). A common approach is to learn off-policy, using\ndata sampled from a replay buffer. However, messages received in the past may\nnot accurately reflect the current communication policy of each agent, and this\ncomplicates learning. We therefore introduce a 'communication correction' which\naccounts for the non-stationarity of observed communication induced by\nmulti-agent learning. It works by relabelling the received message to make it\nlikely under the communicator's current policy, and thus be a better reflection\nof the receiver's current environment. To account for cases in which agents are\nboth senders and receivers, we introduce an ordered relabelling scheme. Our\ncorrection is computationally efficient and can be integrated with a range of\noff-policy algorithms. We find in our experiments that it substantially\nimproves the ability of communicating MARL systems to learn across a variety of\ncooperative and competitive tasks.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 20:49:24 GMT"}, {"version": "v2", "created": "Sun, 28 Feb 2021 22:42:12 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Ahilan", "Sanjeevan", ""], ["Dayan", "Peter", ""]]}, {"id": "2010.01361", "submitter": "Vahid Yazdanpanah", "authors": "Vahid Yazdanpanah, Devrim Murat Yazan, W. Henk M. Zijm", "title": "Dynamics and Allocation of Transaction Cost in Multiagent Industrial\n  Symbiosis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses the dynamics of Transaction Cost (TC) in Industrial\nSymbiosis Institutions (ISI) and provides a fair and stable mechanism for TC\nallocation among the involved firms in a given ISI. In principle, industrial\nsymbiosis, as an implementation of the circular economy paradigm in the context\nof industrial relation, is a practice aiming at reducing the material/energy\nfootprint of the firm. The well-engineered form of this practice is proved to\ndecrease the transaction costs at a collective level. This can be achieved\nusing information systems for: identifying potential synergies, evaluating\nmutually beneficial ones, implementing the contracts, and governing the\nbehavior of the established relations. Then the question is \"how to distribute\nthe costs for maintaining such an information system in a fair and stable\nmanner?\" We see such a cost as a collective transaction cost and employ an\nintegrated method rooted in cooperative game theory and multiagent systems\nresearch to develop a fair and stable allocation mechanism for it. The novelty\nis twofold: in developing analytical multiagent methods for capturing the\ndynamics of transaction costs in industrial symbiosis and in presenting a novel\ngame-theoretic mechanism for its allocation in industrial symbiosis\ninstitutions. While the former contributes to the theories of industrial\nsymbiosis (methodological contribution), the latter supports decision makers\naiming to specify fair and stable industrial symbiosis contracts (practical\ncontribution).\n", "versions": [{"version": "v1", "created": "Sat, 3 Oct 2020 13:56:59 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Yazdanpanah", "Vahid", ""], ["Yazan", "Devrim Murat", ""], ["Zijm", "W. Henk M.", ""]]}, {"id": "2010.01367", "submitter": "Jiaoyang Li", "authors": "Jiaoyang Li, Wheeler Ruml, Sven Koenig", "title": "EECBS: A Bounded-Suboptimal Search for Multi-Agent Path Finding", "comments": "Published at AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-Agent Path Finding (MAPF), i.e., finding collision-free paths for\nmultiple robots, is important for many applications where small runtimes are\nnecessary, including the kind of automated warehouses operated by Amazon. CBS\nis a leading two-level search algorithm for solving MAPF optimally. ECBS is a\nbounded-suboptimal variant of CBS that uses focal search to speed up CBS by\nsacrificing optimality and instead guaranteeing that the costs of its solutions\nare within a given factor of optimal. In this paper, we study how to decrease\nits runtime even further using inadmissible heuristics. Motivated by Explicit\nEstimation Search (EES), we propose Explicit Estimation CBS (EECBS), a new\nbounded-suboptimal variant of CBS, that uses online learning to obtain\ninadmissible estimates of the cost of the solution of each high-level node and\nuses EES to choose which high-level node to expand next. We also investigate\nrecent improvements of CBS and adapt them to EECBS. We find that EECBS with the\nimprovements runs significantly faster than the state-of-the-art\nbounded-suboptimal MAPF algorithms ECBS, BCP-7, and eMDD-SAT on a variety of\nMAPF instances. We hope that the scalability of EECBS enables additional\napplications for bounded-suboptimal MAPF algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 3 Oct 2020 14:19:00 GMT"}, {"version": "v2", "created": "Fri, 12 Mar 2021 19:00:29 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Li", "Jiaoyang", ""], ["Ruml", "Wheeler", ""], ["Koenig", "Sven", ""]]}, {"id": "2010.01711", "submitter": "Shiva Navabi", "authors": "Shiva Navabi, Osonde A. Osoba", "title": "A Generative Machine Learning Approach to Policy Optimization in\n  Pursuit-Evasion Games", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a pursuit-evasion game [11] played between two agents, 'Blue'\n(the pursuer) and 'Red' (the evader), over $T$ time steps. Red aims to attack\nBlue's territory. Blue's objective is to intercept Red by time $T$ and thereby\nlimit the success of Red's attack. Blue must plan its pursuit trajectory by\nchoosing parameters that determine its course of movement (speed and angle in\nour setup) such that it intercepts Red by time $T$. We show that Blue's\npath-planning problem in pursuing Red, can be posed as a sequential decision\nmaking problem under uncertainty. Blue's unawareness of Red's action policy\nrenders the analytic dynamic programming approach intractable for finding the\noptimal action policy for Blue. In this work, we are interested in exploring\ndata-driven approaches to the policy optimization problem that Blue faces. We\napply generative machine learning (ML) approaches to learn optimal action\npolicies for Blue. This highlights the ability of generative ML model to learn\nthe relevant implicit representations for the dynamics of simulated\npursuit-evasion games. We demonstrate the effectiveness of our modeling\napproach via extensive statistical assessments. This work can be viewed as a\npreliminary step towards further adoption of generative modeling approaches for\naddressing policy optimization problems that arise in the context of\nmulti-agent learning and planning [1].\n", "versions": [{"version": "v1", "created": "Sun, 4 Oct 2020 22:43:44 GMT"}, {"version": "v2", "created": "Tue, 13 Oct 2020 19:26:06 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Navabi", "Shiva", ""], ["Osoba", "Osonde A.", ""]]}, {"id": "2010.01755", "submitter": "Marina Haliem", "authors": "Marina Haliem, Ganapathy Mani, Vaneet Aggarwal and Bharat Bhargava", "title": "A Distributed Model-Free Ride-Sharing Approach for Joint Matching,\n  Pricing, and Dispatching using Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Significant development of ride-sharing services presents a plethora of\nopportunities to transform urban mobility by providing personalized and\nconvenient transportation while ensuring efficiency of large-scale ride\npooling. However, a core problem for such services is route planning for each\ndriver to fulfill the dynamically arriving requests while satisfying given\nconstraints. Current models are mostly limited to static routes with only two\nrides per vehicle (optimally) or three (with heuristics). In this paper, we\npresent a dynamic, demand aware, and pricing-based vehicle-passenger matching\nand route planning framework that (1) dynamically generates optimal routes for\neach vehicle based on online demand, pricing associated with each ride, vehicle\ncapacities and locations. This matching algorithm starts greedily and optimizes\nover time using an insertion operation, (2) involves drivers in the\ndecision-making process by allowing them to propose a different price based on\nthe expected reward for a particular ride as well as the destination locations\nfor future rides, which is influenced by supply-and demand computed by the Deep\nQ-network, (3) allows customers to accept or reject rides based on their set of\npreferences with respect to pricing and delay windows, vehicle type and\ncarpooling preferences, and (4) based on demand prediction, our approach\nre-balances idle vehicles by dispatching them to the areas of anticipated high\ndemand using deep Reinforcement Learning (RL). Our framework is validated using\nthe New York City Taxi public dataset; however, we consider different vehicle\ntypes and designed customer utility functions to validate the setup and study\ndifferent settings. Experimental results show the effectiveness of our approach\nin real-time and large scale settings.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 03:13:47 GMT"}, {"version": "v2", "created": "Mon, 14 Jun 2021 15:36:50 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Haliem", "Marina", ""], ["Mani", "Ganapathy", ""], ["Aggarwal", "Vaneet", ""], ["Bhargava", "Bharat", ""]]}, {"id": "2010.01792", "submitter": "Sheikh Shams Azam", "authors": "Sheikh Shams Azam, Taejin Kim, Seyyedali Hosseinalipour, Christopher\n  Brinton, Carlee Joe-Wong, Saurabh Bagchi", "title": "Towards Generalized and Distributed Privacy-Preserving Representation\n  Learning", "comments": "18 pages, 22 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Privacy-preserving representation learning (PPRL) aims to learn a data\nencoding that obfuscates sensitive information and retains target information.\nWe develop the Exclusion-Inclusion Generative Adversarial Network (EIGAN),\nwhich generalizes existing adversarial PPRL approaches to account for multiple,\npotentially overlapping ally and adversary objectives in a dataset. We further\nextend EIGAN to the case where the data is distributed and cannot be centrally\naggregated for training due to privacy constraints. In doing so, we introduce\nD-EIGAN, the first distributed PPRL method, which decentralizes EIGAN training\nbased on federated learning with fractional parameter sharing. We theoretically\nanalyze the convergence of EIGAN and behavior of adversaries under the optimal\nEIGAN and D-EIGAN encoders, considering the impact of dependencies among target\nand sensitive objectives on the encoder performance. Our experiments\ndemonstrate the advantages of EIGAN encodings in terms of accuracy, robustness,\nand scalability; EIGAN outperforms the previous state-of-the-art in centralized\nPPRL by a significant margin (47%). The experiments further reveal that\nD-EIGAN's performance is consistent with that of EIGAN under different node\ndata distributions and is resilient to communication constraints.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 05:43:47 GMT"}, {"version": "v2", "created": "Sat, 17 Oct 2020 22:30:21 GMT"}, {"version": "v3", "created": "Sun, 7 Feb 2021 01:59:04 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Azam", "Sheikh Shams", ""], ["Kim", "Taejin", ""], ["Hosseinalipour", "Seyyedali", ""], ["Brinton", "Christopher", ""], ["Joe-Wong", "Carlee", ""], ["Bagchi", "Saurabh", ""]]}, {"id": "2010.01878", "submitter": "Mathieu Rita", "authors": "Mathieu Rita, Rahma Chaabouni, Emmanuel Dupoux", "title": "\"LazImpa\": Lazy and Impatient neural agents learn to communicate\n  efficiently", "comments": "Accepted to CoNLL 2020", "journal-ref": "Proceedings of CoNLL 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous work has shown that artificial neural agents naturally develop\nsurprisingly non-efficient codes. This is illustrated by the fact that in a\nreferential game involving a speaker and a listener neural networks optimizing\naccurate transmission over a discrete channel, the emergent messages fail to\nachieve an optimal length. Furthermore, frequent messages tend to be longer\nthan infrequent ones, a pattern contrary to the Zipf Law of Abbreviation (ZLA)\nobserved in all natural languages. Here, we show that near-optimal and\nZLA-compatible messages can emerge, but only if both the speaker and the\nlistener are modified. We hence introduce a new communication system,\n\"LazImpa\", where the speaker is made increasingly lazy, i.e. avoids long\nmessages, and the listener impatient, i.e.,~seeks to guess the intended content\nas soon as possible.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 09:25:53 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Rita", "Mathieu", ""], ["Chaabouni", "Rahma", ""], ["Dupoux", "Emmanuel", ""]]}, {"id": "2010.02663", "submitter": "Amanda Vu", "authors": "Ceyer Wakilpoor, Patrick J. Martin, Carrie Rebhuhn, Amanda Vu", "title": "Heterogeneous Multi-Agent Reinforcement Learning for Unknown Environment\n  Mapping", "comments": "Presented at AAAI FSS-20: Artificial Intelligence in Government and\n  Public Sector, Washington, DC, USA. 8 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning in heterogeneous multi-agent scenarios is important\nfor real-world applications but presents challenges beyond those seen in\nhomogeneous settings and simple benchmarks. In this work, we present an\nactor-critic algorithm that allows a team of heterogeneous agents to learn\ndecentralized control policies for covering an unknown environment. This task\nis of interest to national security and emergency response organizations that\nwould like to enhance situational awareness in hazardous areas by deploying\nteams of unmanned aerial vehicles. To solve this multi-agent coverage path\nplanning problem in unknown environments, we augment a multi-agent actor-critic\narchitecture with a new state encoding structure and triplet learning loss to\nsupport heterogeneous agent learning. We developed a simulation environment\nthat includes real-world environmental factors such as turbulence, delayed\ncommunication, and agent loss, to train teams of agents as well as probe their\nrobustness and flexibility to such disturbances.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 12:23:05 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Wakilpoor", "Ceyer", ""], ["Martin", "Patrick J.", ""], ["Rebhuhn", "Carrie", ""], ["Vu", "Amanda", ""]]}, {"id": "2010.02868", "submitter": "Jalal Arabneydi", "authors": "Jalal Arabneydi, Masoud Roudneshin and Amir G. Aghdam", "title": "Reinforcement Learning in Deep Structured Teams: Initial Results with\n  Finite and Infinite Valued Features", "comments": "This version corrects some typographical errors", "journal-ref": "IEEE Conference on Control Technology and Applications, pp.\n  148-155, 2020", "doi": "10.1109/CCTA41146.2020.9206397", "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider Markov chain and linear quadratic models for deep\nstructured teams with discounted and time-average cost functions under two\nnon-classical information structures, namely, deep state sharing and no\nsharing. In deep structured teams, agents are coupled in dynamics and cost\nfunctions through deep state, where deep state refers to a set of orthogonal\nlinear regressions of the states. In this article, we consider a homogeneous\nlinear regression for Markov chain models (i.e., empirical distribution of\nstates) and a few orthonormal linear regressions for linear quadratic models\n(i.e., weighted average of states). Some planning algorithms are developed for\nthe case when the model is known, and some reinforcement learning algorithms\nare proposed for the case when the model is not known completely. The\nconvergence of two model-free (reinforcement learning) algorithms, one for\nMarkov chain models and one for linear quadratic models, is established. The\nresults are then applied to a smart grid.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 16:45:49 GMT"}, {"version": "v2", "created": "Sat, 10 Oct 2020 02:03:00 GMT"}, {"version": "v3", "created": "Tue, 13 Oct 2020 14:52:40 GMT"}, {"version": "v4", "created": "Sun, 7 Feb 2021 01:00:13 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Arabneydi", "Jalal", ""], ["Roudneshin", "Masoud", ""], ["Aghdam", "Amir G.", ""]]}, {"id": "2010.02870", "submitter": "Mert Kayaalp", "authors": "Mert Kayaalp, Stefan Vlaski, Ali H. Sayed", "title": "Dif-MAML: Decentralized Multi-Agent Meta-Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The objective of meta-learning is to exploit the knowledge obtained from\nobserved tasks to improve adaptation to unseen tasks. As such, meta-learners\nare able to generalize better when they are trained with a larger number of\nobserved tasks and with a larger amount of data per task. Given the amount of\nresources that are needed, it is generally difficult to expect the tasks, their\nrespective data, and the necessary computational capacity to be available at a\nsingle central location. It is more natural to encounter situations where these\nresources are spread across several agents connected by some graph topology.\nThe formalism of meta-learning is actually well-suited to this decentralized\nsetting, where the learner would be able to benefit from information and\ncomputational power spread across the agents. Motivated by this observation, in\nthis work, we propose a cooperative fully-decentralized multi-agent\nmeta-learning algorithm, referred to as Diffusion-based MAML or Dif-MAML.\nDecentralized optimization algorithms are superior to centralized\nimplementations in terms of scalability, avoidance of communication\nbottlenecks, and privacy guarantees. The work provides a detailed theoretical\nanalysis to show that the proposed strategy allows a collection of agents to\nattain agreement at a linear rate and to converge to a stationary point of the\naggregate MAML objective even in non-convex environments. Simulation results\nillustrate the theoretical findings and the superior performance relative to\nthe traditional non-cooperative setting.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 16:51:09 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Kayaalp", "Mert", ""], ["Vlaski", "Stefan", ""], ["Sayed", "Ali H.", ""]]}, {"id": "2010.02974", "submitter": "Tarun Gupta", "authors": "Tarun Gupta, Anuj Mahajan, Bei Peng, Wendelin B\\\"ohmer, Shimon\n  Whiteson", "title": "UneVEn: Universal Value Exploration for Multi-Agent Reinforcement\n  Learning", "comments": "Published at ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  VDN and QMIX are two popular value-based algorithms for cooperative MARL that\nlearn a centralized action value function as a monotonic mixing of per-agent\nutilities. While this enables easy decentralization of the learned policy, the\nrestricted joint action value function can prevent them from solving tasks that\nrequire significant coordination between agents at a given timestep. We show\nthat this problem can be overcome by improving the joint exploration of all\nagents during training. Specifically, we propose a novel MARL approach called\nUniversal Value Exploration (UneVEn) that learns a set of related tasks\nsimultaneously with a linear decomposition of universal successor features.\nWith the policies of already solved related tasks, the joint exploration\nprocess of all agents can be improved to help them achieve better coordination.\nEmpirical results on a set of exploration games, challenging cooperative\npredator-prey tasks requiring significant coordination among agents, and\nStarCraft II micromanagement benchmarks show that UneVEn can solve tasks where\nother state-of-the-art MARL methods fail.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 19:08:47 GMT"}, {"version": "v2", "created": "Fri, 12 Feb 2021 15:29:15 GMT"}, {"version": "v3", "created": "Thu, 10 Jun 2021 17:48:48 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Gupta", "Tarun", ""], ["Mahajan", "Anuj", ""], ["Peng", "Bei", ""], ["B\u00f6hmer", "Wendelin", ""], ["Whiteson", "Shimon", ""]]}, {"id": "2010.03795", "submitter": "Manojkumar Parmar", "authors": "Palak Sukharamwala and Manojkumar Parmar", "title": "Mapping of Real World Problems to Nature Inspired Algorithm using Goal\n  based Classification and TRIZ", "comments": "17 pages, 9 figures, 3 figures; Under review for publication as book\n  chapter", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG cs.MA cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The technologies and algorithms are growing at an exponential rate. The\ntechnologies are capable enough to solve technically challenging and complex\nproblems which seemed impossible task. However, the trending methods and\napproaches are facing multiple challenges on various fronts of data,\nalgorithms, software, computational complexities, and energy efficiencies.\nNature also faces similar challenges. Nature has solved those challenges and\nformulation of those are available as Nature Inspired Algorithms (NIA), which\nare derived based on the study of nature. A novel method based on TRIZ to map\nthe real-world problems to nature problems is explained here.TRIZ is a Theory\nof inventive problem solving. Using the proposed framework, best NIA can be\nidentified to solve the real-world problems. For this framework to work, a\nnovel classification of NIA based on the end goal that nature is trying to\nachieve is devised. The application of the this framework along with examples\nis also discussed.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 06:55:31 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Sukharamwala", "Palak", ""], ["Parmar", "Manojkumar", ""]]}, {"id": "2010.04041", "submitter": "Ivan Stelmakh", "authors": "Ivan Stelmakh, Nihar B. Shah, Aarti Singh", "title": "Catch Me if I Can: Detecting Strategic Behaviour in Peer Assessment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the issue of strategic behaviour in various peer-assessment\ntasks, including peer grading of exams or homeworks and peer review in hiring\nor promotions. When a peer-assessment task is competitive (e.g., when students\nare graded on a curve), agents may be incentivized to misreport evaluations in\norder to improve their own final standing. Our focus is on designing methods\nfor detection of such manipulations. Specifically, we consider a setting in\nwhich agents evaluate a subset of their peers and output rankings that are\nlater aggregated to form a final ordering. In this paper, we investigate a\nstatistical framework for this problem and design a principled test for\ndetecting strategic behaviour. We prove that our test has strong false alarm\nguarantees and evaluate its detection ability in practical settings. For this,\nwe design and execute an experiment that elicits strategic behaviour from\nsubjects and release a dataset of patterns of strategic behaviour that may be\nof independent interest. We then use the collected data to conduct a series of\nreal and semi-synthetic evaluations that demonstrate a strong detection power\nof our test.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 15:08:40 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Stelmakh", "Ivan", ""], ["Shah", "Nihar B.", ""], ["Singh", "Aarti", ""]]}, {"id": "2010.04686", "submitter": "Noa Agmon", "authors": "Saar Cohen, Noa Agmon", "title": "Converging to a Desired Orientation in a Flock of Agents", "comments": "19 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work concentrates on different aspects of the \\textit{consensus\nproblem}, when applying it to a swarm of flocking agents. We examine the\npossible influence an external agent, referred to as {\\em influencing agent}\nhas on the flock. We prove that even a single influencing agent with a\n\\textit{Face Desired Orientation behaviour} that is injected into the flock is\nsufficient for guaranteeing desired consensus of the flock of agents which\nfollow a Vicsek-inspired Model. We further show that in some cases this can be\nguaranteed also in dynamic environments.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 17:15:01 GMT"}, {"version": "v2", "created": "Mon, 12 Oct 2020 21:02:57 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Cohen", "Saar", ""], ["Agmon", "Noa", ""]]}, {"id": "2010.04740", "submitter": "Navid Naderializadeh", "authors": "Navid Naderializadeh, Fan H. Hung, Sean Soleyman, Deepak Khosla", "title": "Graph Convolutional Value Decomposition in Multi-Agent Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel framework for value function factorization in multi-agent\ndeep reinforcement learning (MARL) using graph neural networks (GNNs). In\nparticular, we consider the team of agents as the set of nodes of a complete\ndirected graph, whose edge weights are governed by an attention mechanism.\nBuilding upon this underlying graph, we introduce a mixing GNN module, which is\nresponsible for i) factorizing the team state-action value function into\nindividual per-agent observation-action value functions, and ii) explicit\ncredit assignment to each agent in terms of fractions of the global team\nreward. Our approach, which we call GraphMIX, follows the centralized training\nand decentralized execution paradigm, enabling the agents to make their\ndecisions independently once training is completed. We show the superiority of\nGraphMIX as compared to the state-of-the-art on several scenarios in the\nStarCraft II multi-agent challenge (SMAC) benchmark. We further demonstrate how\nGraphMIX can be used in conjunction with a recent hierarchical MARL\narchitecture to both improve the agents' performance and enable fine-tuning\nthem on mismatched test scenarios with higher numbers of agents and/or actions.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 18:01:01 GMT"}, {"version": "v2", "created": "Wed, 10 Feb 2021 07:33:31 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Naderializadeh", "Navid", ""], ["Hung", "Fan H.", ""], ["Soleyman", "Sean", ""], ["Khosla", "Deepak", ""]]}, {"id": "2010.04781", "submitter": "Maude J Blondin", "authors": "M.J. Blondin and M.T. Hale", "title": "A Decentralized Multi-Objective Optimization Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the past two decades, multi-agent optimization problems have drawn\nincreased attention from the research community. When multiple objective\nfunctions are present among agents, many works optimize the sum of these\nobjective functions. However, this formulation implies a decision regarding the\nrelative importance of each objective function. In fact, optimizing the sum is\na special case of a multi-objective problem in which all objectives are\nprioritized equally. In this paper, a distributed optimization algorithm that\nexplores Pareto optimal solutions for non-homogeneously weighted sums of\nobjective functions is proposed. This exploration is performed through a new\nrule based on agents' priorities that generates edge weights in agents'\ncommunication graph. These weights determine how agents update their decision\nvariables with information received from other agents in the network. Agents\ninitially disagree on the priorities of the objective functions though they are\ndriven to agree upon them as they optimize. As a result, agents still reach a\ncommon solution. The network-level weight matrix is (non-doubly) stochastic,\nwhich contrasts with many works on the subject in which it is\ndoubly-stochastic. New theoretical analyses are therefore developed to ensure\nconvergence of the proposed algorithm. This paper provides a gradient-based\noptimization algorithm, proof of convergence to solutions, and convergence\nrates of the proposed algorithm. It is shown that agents' initial priorities\ninfluence the convergence rate of the proposed algorithm and that these initial\nchoices affect its long-run behavior. Numerical results performed with\ndifferent numbers of agents illustrate the performance and efficiency of the\nproposed algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 19:55:23 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Blondin", "M. J.", ""], ["Hale", "M. T.", ""]]}, {"id": "2010.04894", "submitter": "Ahmad Esmaeili", "authors": "Ahmad Esmaeili and John C. Gallagher and John A. Springer and Eric T.\n  Matson", "title": "HAMLET: A Hierarchical Agent-based Machine Learning Platform", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical Multi-Agent Systems provide a convenient and relevant way to\nanalyze, model, and simulate complex systems in which a large number of\nentities are interacting at different levels of abstraction. In this paper, we\nintroduce HAMLET (Hierarchical Agent-based Machine LEarning plaTform), a\nplatform based on hierarchical multi-agent systems, to facilitate the research\nand democratization of machine learning entities distributed geographically or\nlocally. This is carried out by firstly modeling the machine learning solutions\nas a hypergraph and then autonomously setting up a multi-level structure\ncomposed of heterogeneous agents based on their innate capabilities and learned\nskills. HAMLET aids the design and management of machine learning systems and\nprovides analytical capabilities for the research communities to assess the\nexisting and/or new algorithms/datasets through flexible and customizable\nqueries. The proposed platform does not assume restrictions on the type of\nmachine learning algorithms/datasets and is theoretically proven to be sound\nand complete with polynomial computational requirements. Additionally, it is\nexamined empirically on 120 training and four generalized batch testing tasks\nperformed on 24 machine learning algorithms and 9 standard datasets. The\nexperimental results provided not only establish confidence in the platform's\nconsistency and correctness but also demonstrates its testing and analytical\ncapacity.\n", "versions": [{"version": "v1", "created": "Sat, 10 Oct 2020 03:46:59 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Esmaeili", "Ahmad", ""], ["Gallagher", "John C.", ""], ["Springer", "John A.", ""], ["Matson", "Eric T.", ""]]}, {"id": "2010.04978", "submitter": "Guangzheng Hu", "authors": "Guangzheng Hu, Yuanheng Zhu, Dongbin Zhao, Mengchen Zhao, Jianye Hao", "title": "Event-Triggered Multi-agent Reinforcement Learning with Communication\n  under Limited-bandwidth Constraint", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Communicating with each other in a distributed manner and behaving as a group\nare essential in multi-agent reinforcement learning. However, real-world\nmulti-agent systems suffer from restrictions on limited-bandwidth\ncommunication. If the bandwidth is fully occupied, some agents are not able to\nsend messages promptly to others, causing decision delay and impairing\ncooperative effects. Recent related work has started to address the problem but\nstill fails in maximally reducing the consumption of communication resources.\nIn this paper, we propose Event-Triggered Communication Network (ETCNet) to\nenhance the communication efficiency in multi-agent systems by sending messages\nonly when necessary. According to the information theory, the limited bandwidth\nis translated to the penalty threshold of an event-triggered strategy, which\ndetermines whether an agent at each step sends a message or not. Then the\ndesign of the event-triggered strategy is formulated as a constrained Markov\ndecision problem, and reinforcement learning finds the best communication\nprotocol that satisfies the limited bandwidth constraint. Experiments on\ntypical multi-agent tasks demonstrate that ETCNet outperforms other methods in\nterms of the reduction of bandwidth occupancy and still preserves the\ncooperative performance of multi-agent systems at the most.\n", "versions": [{"version": "v1", "created": "Sat, 10 Oct 2020 11:51:22 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Hu", "Guangzheng", ""], ["Zhu", "Yuanheng", ""], ["Zhao", "Dongbin", ""], ["Zhao", "Mengchen", ""], ["Hao", "Jianye", ""]]}, {"id": "2010.05042", "submitter": "Daniel Foguelman", "authors": "Daniel J. Foguelman, Philipp Henning, Adelinde Uhrmacher, and Rodrigo\n  Castro", "title": "EB-DEVS: A Formal Framework for Modeling and Simulation of Emergent\n  Behavior in Dynamic Complex Systems", "comments": "38 page document with: original content 25 pages, references 3 pages,\n  appendices 10 pages", "journal-ref": "Journal of Computational Science Volume 53, July 2021, 101387", "doi": "10.1016/j.jocs.2021.101387", "report-no": null, "categories": "cs.MA cs.AI nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emergent behavior is a key feature defining a system under study as a complex\nsystem. Simulation has been recognized as the only way to deal with the study\nof the emergency of properties (at a macroscopic level) among groups of system\ncomponents (at a microscopic level), for the manifestations of emergent\nstructures cannot be deduced from analysing components in isolation. A\nsystems-oriented generalisation must consider the presence of feedback loops\n(micro components react to macro properties), interaction among components of\ndifferent classes (modular composition) and layered interaction of subsystems\noperating at different spatio-temporal scales (hierarchical organisation). In\nthis work we introduce Emergent Behavior-DEVS (EB-DEVS) a Modeling and\nSimulation (M&S) formalism that permits reasoning about complex systems where\nemergent behavior is placed at the forefront of the analysis activity. EB-DEVS\nbuilds on the DEVS formalism, adding upward/downward communication channels to\nwell-established capabilities for modular and hierarchical M&S of heterogeneous\nmulti-formalism systems. EB-DEVS takes a minimalist stance on expressiveness,\nintroducing a small set of extensions on Classic DEVS that can cope with\nemergent behavior, and making both formalisms interoperable (the modeler\ndecides which subsystems deserve to be expressed via micro-macro dynamics). We\npresent three case studies: flocks of birds with learning, population epidemics\nwith vaccination and sub-cellular dynamics with homeostasis, through which we\nshowcase how EB-DEVS performs by placing emergent properties at the center of\nthe M&S process.\n", "versions": [{"version": "v1", "created": "Sat, 10 Oct 2020 16:39:41 GMT"}, {"version": "v2", "created": "Tue, 13 Oct 2020 22:54:20 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Foguelman", "Daniel J.", ""], ["Henning", "Philipp", ""], ["Uhrmacher", "Adelinde", ""], ["Castro", "Rodrigo", ""]]}, {"id": "2010.05115", "submitter": "Henry Chen", "authors": "Henry Chen, Robin Cohen, Kerstin Dautenhahn, Edith Law, Krzysztof\n  Czarnecki", "title": "Autonomous Vehicle Visual Signals for Pedestrians: Experiments and\n  Design Recommendations", "comments": "The 31st IEEE Intelligent Vehicles Symposium", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.MA cs.RO cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous Vehicles (AV) will transform transportation, but also the\ninteraction between vehicles and pedestrians. In the absence of a driver, it is\nnot clear how an AV can communicate its intention to pedestrians. One option is\nto use visual signals. To advance their design, we conduct four\nhuman-participant experiments and evaluate six representative AV visual signals\nfor visibility, intuitiveness, persuasiveness, and usability at pedestrian\ncrossings. Based on the results, we distill twelve practical design\nrecommendations for AV visual signals, with focus on signal pattern design and\nplacement. Moreover, the paper advances the methodology for experimental\nevaluation of visual signals, including lab, closed-course, and public road\ntests using an autonomous vehicle. In addition, the paper also reports insights\non pedestrian crosswalk behaviours and the impacts of pedestrian trust towards\nAVs on the behaviors. We hope that this work will constitute valuable input to\nthe ongoing development of international standards for AV lamps, and thus help\nmature automated driving in general.\n", "versions": [{"version": "v1", "created": "Sat, 10 Oct 2020 22:56:46 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Chen", "Henry", ""], ["Cohen", "Robin", ""], ["Dautenhahn", "Kerstin", ""], ["Law", "Edith", ""], ["Czarnecki", "Krzysztof", ""]]}, {"id": "2010.05290", "submitter": "Alperen G\\\"undogan", "authors": "Alperen G\\\"undogan, H. Murat G\\\"ursu, Volker Pauli, Wolfgang Kellerer", "title": "Distributed Resource Allocation with Multi-Agent Deep Reinforcement\n  Learning for 5G-V2V Communication", "comments": null, "journal-ref": "ACM MobiHoc Workshop on Cooperative data dissemination in future\n  vehicular networks (D2VNet) 2020", "doi": null, "report-no": null, "categories": "cs.NI cs.GT cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the distributed resource selection problem in Vehicle-to-vehicle\n(V2V) communication in the absence of a base station. Each vehicle autonomously\nselects transmission resources from a pool of shared resources to disseminate\nCooperative Awareness Messages (CAMs). This is a consensus problem where each\nvehicle has to select a unique resource. The problem becomes more challenging\nwhen---due to mobility---the number of vehicles in vicinity of each other is\nchanging dynamically. In a congested scenario, allocation of unique resources\nfor each vehicle becomes infeasible and a congested resource allocation\nstrategy has to be developed. The standardized approach in 5G, namely\nsemi-persistent scheduling (SPS) suffers from effects caused by spatial\ndistribution of the vehicles. In our approach, we turn this into an advantage.\nWe propose a novel DIstributed Resource Allocation mechanism using multi-agent\nreinforcement Learning (DIRAL) which builds on a unique state representation.\nOne challenging issue is to cope with the non-stationarity introduced by\nconcurrently learning agents which causes convergence problems in multi-agent\nlearning systems. We aimed to tackle non-stationarity with unique state\nrepresentation. Specifically, we deploy view-based positional distribution as a\nstate representation to tackle non-stationarity and perform complex joint\nbehavior in a distributed fashion. Our results showed that DIRAL improves PRR\nby 20% compared to SPS in challenging congested scenarios.\n", "versions": [{"version": "v1", "created": "Sun, 11 Oct 2020 17:33:10 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["G\u00fcndogan", "Alperen", ""], ["G\u00fcrsu", "H. Murat", ""], ["Pauli", "Volker", ""], ["Kellerer", "Wolfgang", ""]]}, {"id": "2010.05527", "submitter": "Chengcheng Wang", "authors": "Chengcheng Wang, Wee Peng Tay, Ye Wei, Yuan Wang", "title": "Privacy-Preserving Distributed Projection LMS for Linear Multitask\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a privacy-preserving distributed projection least mean squares\n(LMS) strategy over linear multitask networks, where agents' local parameters\nof interest or tasks are linearly related. Each agent is interested in not only\nimproving its local inference performance via in-network cooperation with\nneighboring agents, but also protecting its own individual task against privacy\nleakage. In our proposed strategy, at each time instant, each agent sends a\nnoisy estimate, which is its local intermediate estimate corrupted by a\nzero-mean additive noise, to its neighboring agents. We derive a sufficient\ncondition to determine the amount of noise to add to each agent's intermediate\nestimate to achieve an optimal trade-off between the network\nmean-square-deviation and an inference privacy constraint. We propose a\ndistributed and adaptive strategy to compute the additive noise powers, and\nstudy the mean and mean-square behaviors and privacy-preserving performance of\nthe proposed strategy. Simulation results demonstrate that our strategy is able\nto balance the trade-off between estimation accuracy and privacy preservation.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 08:31:40 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Wang", "Chengcheng", ""], ["Tay", "Wee Peng", ""], ["Wei", "Ye", ""], ["Wang", "Yuan", ""]]}, {"id": "2010.05867", "submitter": "David Byrd", "authors": "David Byrd and Antigoni Polychroniadou", "title": "Differentially Private Secure Multi-Party Computation for Federated\n  Learning in Financial Applications", "comments": "ACM ICAIF 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.MA q-fin.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning enables a population of clients, working with a trusted\nserver, to collaboratively learn a shared machine learning model while keeping\neach client's data within its own local systems. This reduces the risk of\nexposing sensitive data, but it is still possible to reverse engineer\ninformation about a client's private data set from communicated model\nparameters. Most federated learning systems therefore use differential privacy\nto introduce noise to the parameters. This adds uncertainty to any attempt to\nreveal private client data, but also reduces the accuracy of the shared model,\nlimiting the useful scale of privacy-preserving noise. A system can further\nreduce the coordinating server's ability to recover private client information,\nwithout additional accuracy loss, by also including secure multiparty\ncomputation. An approach combining both techniques is especially relevant to\nfinancial firms as it allows new possibilities for collaborative learning\nwithout exposing sensitive client data. This could produce more accurate models\nfor important tasks like optimal trade execution, credit origination, or fraud\ndetection. The key contributions of this paper are: We present a\nprivacy-preserving federated learning protocol to a non-specialist audience,\ndemonstrate it using logistic regression on a real-world credit card fraud data\nset, and evaluate it using an open-source simulation platform which we have\nadapted for the development of federated learning systems.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 17:16:27 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Byrd", "David", ""], ["Polychroniadou", "Antigoni", ""]]}, {"id": "2010.06274", "submitter": "Malintha Fernando", "authors": "Malintha Fernando, Lantao Liu", "title": "Swarming of Aerial Robots with Markov Random Field Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Swarms are highly robust systems that offer unique benefits compared to their\nalternatives. In this work, we propose a bio-inspired and artificial potential\nfield-driven robot swarm control method, where the swarm formation dynamics are\nmodeled on the basis of Markov Random Field (MRF) optimization. We integrate\nthe internal agent-wise local interactions and external environmental\ninfluences into the MRF. The optimized formation configurations at different\nstages of the trajectory can be viewed as formation \"shapes\" which further\nallows us to integrate dynamics-constrained motion control of the robots. We\nshow that this approach can be used to generate dynamically feasible\ntrajectories to navigate teams of aerial robots in complex environments.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 10:33:55 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 00:24:44 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Fernando", "Malintha", ""], ["Liu", "Lantao", ""]]}, {"id": "2010.07015", "submitter": "Sebastien Ducos", "authors": "Rafael Cestari, Sebastien Ducos (LIUPPA), Ernesto Exposito (LIUPPA)", "title": "iPaaS in Agriculture 4.0: An Industrial Case", "comments": null, "journal-ref": "WETICE'2020: 29th IEEE International Conference on Enabling\n  Technologies: Infrastructure for Collaborative Enterprises, 2020", "doi": null, "report-no": null, "categories": "cs.CY cs.MA cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current automation approaches in the Industry 4.0 have generated increased\ninterest in the utilization of Integration Platforms as a Service (iPaaS) cloud\narchitectures in order to unify and synchronize several systems, applications,\nand services in order to build smart solutions for automated and adaptive\nindustrial process management. Existing iPaaS solutions present several\nout-of-the-box connectors and automation engines for easier integration of\ncustomers' projects, but show issues regarding overall adaptation outside their\nscope, brand locking, and occasionally high prices. Moreover, existing\nplatforms fail to respond adequately to the needs of deploying multiple\ndecision models capable of offering automated or semi-automated management of\nprocesses, thanks to the integration of the large diversity of data and event\nsources as well as the different physical or logical action entities. With the\npopularization of open-source software and applications such as BPM Engines,\nMachine Learning libraries, and Integration suites and libraries, it is\npossible to develop a fully customizable and adaptable, open-source iPaaS that\ncan be used both in and outside industrial applications. In this paper, we\npropose a generic iPaaS architecture implemented on the basis of several open\nsource solutions boasting integration, interoperability, and automated\ndecision-making capabilities in the domain of Agriculture 4.0. A\nproof-of-concept based on these solutions is presented, as well as a case study\non MA{\\\"I}SADOUR's grain storage process with a comparison with the currently\nhuman-operated tasks.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 07:52:37 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Cestari", "Rafael", "", "LIUPPA"], ["Ducos", "Sebastien", "", "LIUPPA"], ["Exposito", "Ernesto", "", "LIUPPA"]]}, {"id": "2010.07777", "submitter": "Arnu Pretorius", "authors": "Arnu Pretorius, Scott Cameron, Elan van Biljon, Tom Makkink, Shahil\n  Mawjee, Jeremy du Plessis, Jonathan Shock, Alexandre Laterre, Karim Beguir", "title": "A game-theoretic analysis of networked system control for common-pool\n  resource management using multi-agent reinforcement learning", "comments": "17 pages, 16 Figures, to appear in Advances of Neural Information\n  Processing Systems (NeurIPS) conference, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-agent reinforcement learning has recently shown great promise as an\napproach to networked system control. Arguably, one of the most difficult and\nimportant tasks for which large scale networked system control is applicable is\ncommon-pool resource management. Crucial common-pool resources include arable\nland, fresh water, wetlands, wildlife, fish stock, forests and the atmosphere,\nof which proper management is related to some of society's greatest challenges\nsuch as food security, inequality and climate change. Here we take inspiration\nfrom a recent research program investigating the game-theoretic incentives of\nhumans in social dilemma situations such as the well-known tragedy of the\ncommons. However, instead of focusing on biologically evolved human-like\nagents, our concern is rather to better understand the learning and operating\nbehaviour of engineered networked systems comprising general-purpose\nreinforcement learning agents, subject only to nonbiological constraints such\nas memory, computation and communication bandwidth. Harnessing tools from\nempirical game-theoretic analysis, we analyse the differences in resulting\nsolution concepts that stem from employing different information structures in\nthe design of networked multi-agent systems. These information structures\npertain to the type of information shared between agents as well as the\nemployed communication protocol and network topology. Our analysis contributes\nnew insights into the consequences associated with certain design choices and\nprovides an additional dimension of comparison between systems beyond\nefficiency, robustness, scalability and mean control performance.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 14:12:26 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Pretorius", "Arnu", ""], ["Cameron", "Scott", ""], ["van Biljon", "Elan", ""], ["Makkink", "Tom", ""], ["Mawjee", "Shahil", ""], ["Plessis", "Jeremy du", ""], ["Shock", "Jonathan", ""], ["Laterre", "Alexandre", ""], ["Beguir", "Karim", ""]]}, {"id": "2010.07916", "submitter": "Hepeng Li", "authors": "Hepeng Li and Haibo He", "title": "Multi-Agent Trust Region Policy Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend trust region policy optimization (TRPO) to multi-agent\nreinforcement learning (MARL) problems. We show that the policy update of TRPO\ncan be transformed into a distributed consensus optimization problem for\nmulti-agent cases. By making a series of approximations to the consensus\noptimization model, we propose a decentralized MARL algorithm, which we call\nmulti-agent TRPO (MATRPO). This algorithm can optimize distributed policies\nbased on local observations and private rewards. The agents do not need to know\nobservations, rewards, policies or value/action-value functions of other\nagents. The agents only share a likelihood ratio with their neighbors during\nthe training process. The algorithm is fully decentralized and\nprivacy-preserving. Our experiments on two cooperative games demonstrate its\nrobust performance on complicated MARL tasks.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 17:49:47 GMT"}, {"version": "v2", "created": "Sun, 18 Oct 2020 14:41:40 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Li", "Hepeng", ""], ["He", "Haibo", ""]]}, {"id": "2010.08193", "submitter": "Rhys Newbury", "authors": "Cristino de Souza Jr, Rhys Newbury, Akansel Cosgun, Pedro Castillo,\n  Boris Vidolov, Dana Kulic", "title": "Decentralized Multi-Agent Pursuit using Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pursuit-evasion is the problem of capturing mobile targets with one or more\npursuers. We use deep reinforcement learning for pursuing an omni-directional\ntarget with multiple, homogeneous agents that are subject to unicycle kinematic\nconstraints. We use shared experience to train a policy for a given number of\npursuers that is executed independently by each agent at run-time. The training\nbenefits from curriculum learning, a sweeping-angle ordering to locally\nrepresent neighboring agents and encouraging good formations with reward\nstructure that combines individual and group rewards. Simulated experiments\nwith a reactive evader and up to eight pursuers show that our learning-based\napproach, with non-holonomic agents, performs on par with classical algorithms\nwith omni-directional agents, and outperforms their non-holonomic adaptations.\nThe learned policy is successfully transferred to the real world in a\nproof-of-concept demonstration with three motion-constrained pursuer drones.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 06:58:18 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Souza", "Cristino de", "Jr"], ["Newbury", "Rhys", ""], ["Cosgun", "Akansel", ""], ["Castillo", "Pedro", ""], ["Vidolov", "Boris", ""], ["Kulic", "Dana", ""]]}, {"id": "2010.08531", "submitter": "Tianjun Zhang", "authors": "Tianjun Zhang, Huazhe Xu, Xiaolong Wang, Yi Wu, Kurt Keutzer, Joseph\n  E. Gonzalez, Yuandong Tian", "title": "Multi-Agent Collaboration via Reward Attribution Decomposition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in multi-agent reinforcement learning (MARL) have achieved\nsuper-human performance in games like Quake 3 and Dota 2. Unfortunately, these\ntechniques require orders-of-magnitude more training rounds than humans and\ndon't generalize to new agent configurations even on the same game. In this\nwork, we propose Collaborative Q-learning (CollaQ) that achieves\nstate-of-the-art performance in the StarCraft multi-agent challenge and\nsupports ad hoc team play. We first formulate multi-agent collaboration as a\njoint optimization on reward assignment and show that each agent has an\napproximately optimal policy that decomposes into two parts: one part that only\nrelies on the agent's own state, and the other part that is related to states\nof nearby agents. Following this novel finding, CollaQ decomposes the\nQ-function of each agent into a self term and an interactive term, with a\nMulti-Agent Reward Attribution (MARA) loss that regularizes the training.\nCollaQ is evaluated on various StarCraft maps and shows that it outperforms\nexisting state-of-the-art techniques (i.e., QMIX, QTRAN, and VDN) by improving\nthe win rate by 40% with the same number of samples. In the more challenging ad\nhoc team play setting (i.e., reweight/add/remove units without re-training or\nfinetuning), CollaQ outperforms previous SoTA by over 30%.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 17:42:11 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Zhang", "Tianjun", ""], ["Xu", "Huazhe", ""], ["Wang", "Xiaolong", ""], ["Wu", "Yi", ""], ["Keutzer", "Kurt", ""], ["Gonzalez", "Joseph E.", ""], ["Tian", "Yuandong", ""]]}, {"id": "2010.08595", "submitter": "Nathalie Majcherczyk", "authors": "Nathalie Majcherczyk, Nishan Srishankar and Carlo Pinciroli", "title": "Flow-FL: Data-Driven Federated Learning for Spatio-Temporal Predictions\n  in Multi-Robot Systems", "comments": "8 pages, 7 figures. For associated datasets, see\n  http://www.nestlab.net/doku.php/papers:mrs_fl_dataset", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we show how the Federated Learning (FL) framework enables\nlearning collectively from distributed data in connected robot teams. This\nframework typically works with clients collecting data locally, updating neural\nnetwork weights of their model, and sending updates to a server for aggregation\ninto a global model. We explore the design space of FL by comparing two\nvariants of this concept. The first variant follows the traditional FL approach\nin which a server aggregates the local models. In the second variant, that we\ncall Flow-FL, the aggregation process is serverless thanks to the use of a\ngossip-based shared data structure. In both variants, we use a data-driven\nmechanism to synchronize the learning process in which robots contribute model\nupdates when they collect sufficient data. We validate our approach with an\nagent trajectory forecasting problem in a multi-agent setting. Using a\ncentralized implementation as a baseline, we study the effects of staggered\nonline data collection, and variations in data flow, number of participating\nrobots, and time delays introduced by the decentralization of the framework in\na multi-robot setting.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 19:09:57 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Majcherczyk", "Nathalie", ""], ["Srishankar", "Nishan", ""], ["Pinciroli", "Carlo", ""]]}, {"id": "2010.08885", "submitter": "Rui Prada", "authors": "Ana Salta and Rui Prada and Francisco S. Melo", "title": "A Game AI Competition to foster Collaborative AI research and\n  development", "comments": null, "journal-ref": "IEEE Transactions on Games, pp. 1-12, 2020", "doi": "10.1109/TG.2020.3024160", "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Game AI competitions are important to foster research and development on Game\nAI and AI in general. These competitions supply different challenging problems\nthat can be translated into other contexts, virtual or real. They provide\nframeworks and tools to facilitate the research on their core topics and\nprovide means for comparing and sharing results. A competition is also a way to\nmotivate new researchers to study these challenges. In this document, we\npresent the Geometry Friends Game AI Competition. Geometry Friends is a\ntwo-player cooperative physics-based puzzle platformer computer game. The\nconcept of the game is simple, though its solving has proven to be difficult.\nWhile the main and apparent focus of the game is cooperation, it also relies on\nother AI-related problems such as planning, plan execution, and motion control,\nall connected to situational awareness. All of these must be solved in\nreal-time. In this paper, we discuss the competition and the challenges it\nbrings, and present an overview of the current solutions.\n", "versions": [{"version": "v1", "created": "Sat, 17 Oct 2020 23:03:06 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Salta", "Ana", ""], ["Prada", "Rui", ""], ["Melo", "Francisco S.", ""]]}, {"id": "2010.08925", "submitter": "Keehang Kwon", "authors": "Keehang Kwon", "title": "Implementing Agent-Based Systems via Computability Logic CL2", "comments": "11 pages. This is a revised version and some errors are fixed. arXiv\n  admin note: substantial text overlap with arXiv:1909.07036", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computability logic(CoL) is a powerful computational model. In this paper, we\nshow that CoL naturally supports multi-agent programming models where resources\n(coffee for example) are involved. To be specific, we discuss an implementation\nof the Starbucks based on CoL (CL2 to be exact).\n", "versions": [{"version": "v1", "created": "Sun, 18 Oct 2020 06:07:32 GMT"}, {"version": "v2", "created": "Wed, 9 Jun 2021 11:15:41 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Kwon", "Keehang", ""]]}, {"id": "2010.08992", "submitter": "Isao Yagi", "authors": "Isao Yagi, Mahiro Hoshino, and Takanobu Mizuta", "title": "Analysis of the impact of maker-taker fees on the stock market using\n  agent-based simulation", "comments": "ACM International Conference on AI in Finance 2020 (ICAIF '20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.TR cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, most stock exchanges in the U.S. employ maker-taker fees, in which\nan exchange pays rebates to traders placing orders in the order book and\ncharges fees to traders taking orders from the order book. Maker-taker fees\nencourage traders to place many orders that provide market liquidity to the\nexchange. However, it is not clear how maker-taker fees affect the total cost\nof a taking order, including all the charged fees and the market impact. In\nthis study, we investigated the effect of maker-taker fees on the total cost of\na taking order with our artificial market model, which is an agent-based model\nfor financial markets. We found that maker-taker fees encourage market\nefficiency but increase the total costs of taking orders.\n", "versions": [{"version": "v1", "created": "Sun, 18 Oct 2020 14:12:05 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Yagi", "Isao", ""], ["Hoshino", "Mahiro", ""], ["Mizuta", "Takanobu", ""]]}, {"id": "2010.09054", "submitter": "Raphael Koster", "authors": "Raphael K\\\"oster, Kevin R. McKee, Richard Everett, Laura Weidinger,\n  William S. Isaac, Edward Hughes, Edgar A. Du\\'e\\~nez-Guzm\\'an, Thore Graepel,\n  Matthew Botvinick and Joel Z. Leibo", "title": "Model-free conventions in multi-agent reinforcement learning with\n  heterogeneous preferences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Game theoretic views of convention generally rest on notions of common\nknowledge and hyper-rational models of individual behavior. However, decades of\nwork in behavioral economics have questioned the validity of both foundations.\nMeanwhile, computational neuroscience has contributed a modernized 'dual\nprocess' account of decision-making where model-free (MF) reinforcement\nlearning trades off with model-based (MB) reinforcement learning. The former\ncaptures habitual and procedural learning while the latter captures choices\ntaken via explicit planning and deduction. Some conventions (e.g. international\ntreaties) are likely supported by cognition that resonates with the game\ntheoretic and MB accounts. However, convention formation may also occur via MF\nmechanisms like habit learning; though this possibility has been understudied.\nHere, we demonstrate that complex, large-scale conventions can emerge from MF\nlearning mechanisms. This suggests that some conventions may be supported by\nhabit-like cognition rather than explicit reasoning. We apply MF multi-agent\nreinforcement learning to a temporo-spatially extended game with incomplete\ninformation. In this game, large parts of the state space are reachable only by\ncollective action. However, heterogeneity of tastes makes such coordinated\naction difficult: multiple equilibria are desirable for all players, but\nsubgroups prefer a particular equilibrium over all others. This creates a\ncoordination problem that can be solved by establishing a convention. We\ninvestigate start-up and free rider subproblems as well as the effects of group\nsize, intensity of intrinsic preference, and salience on the emergence dynamics\nof coordination conventions. Results of our simulations show agents establish\nand switch between conventions, even working against their own preferred\noutcome when doing so is necessary for effective coordination.\n", "versions": [{"version": "v1", "created": "Sun, 18 Oct 2020 18:18:37 GMT"}, {"version": "v2", "created": "Mon, 14 Dec 2020 18:11:52 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["K\u00f6ster", "Raphael", ""], ["McKee", "Kevin R.", ""], ["Everett", "Richard", ""], ["Weidinger", "Laura", ""], ["Isaac", "William S.", ""], ["Hughes", "Edward", ""], ["Du\u00e9\u00f1ez-Guzm\u00e1n", "Edgar A.", ""], ["Graepel", "Thore", ""], ["Botvinick", "Matthew", ""], ["Leibo", "Joel Z.", ""]]}, {"id": "2010.09086", "submitter": "Paritosh Ramanan", "authors": "Paritosh Ramanan, Dan Li, Nagi Gebraeel", "title": "Blockchain Based Decentralized Cyber Attack Detection for Large Scale\n  Power Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large scale power systems are comprised of regional utilities with IIoT\nenabled assets that stream sensor readings in real time. In order to detect\ncyberattacks, the globally acquired, real time sensor data needs to be analyzed\nin a centralized fashion. However, owing to operational constraints, such a\ncentralized sharing mechanism turns out to be a major obstacle. In this paper,\nwe propose a blockchain based decentralized framework for detecting coordinated\nreplay attacks with full privacy of sensor data. We develop a Bayesian\ninference mechanism employing locally reported attack probabilities that is\ntailor made for a blockchain framework. We compare our framework to a\ntraditional decentralized algorithm based on the broadcast gossip framework\nboth theoretically as well as empirically. With the help of experiments on a\nprivate Ethereum blockchain, we show that our approach achieves good detection\nquality and significantly outperforms gossip driven approaches in terms of\naccuracy, timeliness and scalability.\n", "versions": [{"version": "v1", "created": "Sun, 18 Oct 2020 19:51:09 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Ramanan", "Paritosh", ""], ["Li", "Dan", ""], ["Gebraeel", "Nagi", ""]]}, {"id": "2010.09087", "submitter": "Dominik Baumann", "authors": "Dominik Baumann, Fabian Mager, Ulf Wetzker, Lothar Thiele, Marco\n  Zimmerling, and Sebastian Trimpe", "title": "Wireless Control for Smart Manufacturing: Recent Approaches and Open\n  Challenges", "comments": "Accepted article to appear in Proceedings of the IEEE", "journal-ref": null, "doi": "10.1109/JPROC.2020.3032633", "report-no": null, "categories": "eess.SY cs.MA cs.NI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smart manufacturing aims to overcome the limitations of today's rigid\nassembly lines by making the material flow and manufacturing process more\nflexible, versatile, and scalable. The main economic drivers are higher\nresource and cost efficiency as the manufacturers can more quickly adapt to\nchanging market needs and also increase the lifespan of their production sites.\nThe ability to close feedback loops fast and reliably over long distances among\nmobile robots, remote sensors, and human operators is a key enabler for smart\nmanufacturing. Thus, this article provides a perspective on control and\ncoordination over wireless networks. Based on an analysis of real-world use\ncases, we identify the main technical challenges that need to be solved to\nclose the large gap between the current state of the art in industry and the\nvision of smart manufacturing. We discuss to what extent existing\ncontrol-over-wireless solutions in the literature address those challenges,\nincluding our own approach toward a tight integration of control and wireless\ncommunication. In addition to a theoretical analysis of closed-loop stability,\npractical experiments on a cyber-physical testbed demonstrate that our approach\nsupports relevant smart manufacturing scenarios. The article concludes with a\ndiscussion of open challenges and future research directions.\n", "versions": [{"version": "v1", "created": "Sun, 18 Oct 2020 19:55:12 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Baumann", "Dominik", ""], ["Mager", "Fabian", ""], ["Wetzker", "Ulf", ""], ["Thiele", "Lothar", ""], ["Zimmerling", "Marco", ""], ["Trimpe", "Sebastian", ""]]}, {"id": "2010.09108", "submitter": "Eric Benhamou", "authors": "Eric Benhamou, David Saltiel, Sandrine Ungari, Abhishek Mukhopadhyay", "title": "Bridging the gap between Markowitz planning and deep reinforcement\n  learning", "comments": "10 pages, ICAPS PRL. arXiv admin note: substantial text overlap with\n  arXiv:2009.14136, arXiv:2010.08497", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA q-fin.PM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While researchers in the asset management industry have mostly focused on\ntechniques based on financial and risk planning techniques like Markowitz\nefficient frontier, minimum variance, maximum diversification or equal risk\nparity, in parallel, another community in machine learning has started working\non reinforcement learning and more particularly deep reinforcement learning to\nsolve other decision making problems for challenging task like autonomous\ndriving, robot learning, and on a more conceptual side games solving like Go.\nThis paper aims to bridge the gap between these two approaches by showing Deep\nReinforcement Learning (DRL) techniques can shed new lights on portfolio\nallocation thanks to a more general optimization setting that casts portfolio\nallocation as an optimal control problem that is not just a one-step\noptimization, but rather a continuous control optimization with a delayed\nreward. The advantages are numerous: (i) DRL maps directly market conditions to\nactions by design and hence should adapt to changing environment, (ii) DRL does\nnot rely on any traditional financial risk assumptions like that risk is\nrepresented by variance, (iii) DRL can incorporate additional data and be a\nmulti inputs method as opposed to more traditional optimization methods. We\npresent on an experiment some encouraging results using convolution networks.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 04:03:27 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Benhamou", "Eric", ""], ["Saltiel", "David", ""], ["Ungari", "Sandrine", ""], ["Mukhopadhyay", "Abhishek", ""]]}, {"id": "2010.09648", "submitter": "Fan Zuo", "authors": "Ding Wang, Fan Zuo, Jingqin Gao, Yueshuai He, Zilin Bian, Suzana Duran\n  Bernardes, Chaekuk Na, Jingxing Wang, John Petinos, Kaan Ozbay, Joseph Y.J.\n  Chow, Shri Iyer, Hani Nassif, Xuegang Jeff Ban", "title": "Agent-based Simulation Model and Deep Learning Techniques to Evaluate\n  and Predict Transportation Trends around COVID-19", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.CV eess.IV physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The COVID-19 pandemic has affected travel behaviors and transportation system\noperations, and cities are grappling with what policies can be effective for a\nphased reopening shaped by social distancing. This edition of the white paper\nupdates travel trends and highlights an agent-based simulation model's results\nto predict the impact of proposed phased reopening strategies. It also\nintroduces a real-time video processing method to measure social distancing\nthrough cameras on city streets.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 05:37:15 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Wang", "Ding", ""], ["Zuo", "Fan", ""], ["Gao", "Jingqin", ""], ["He", "Yueshuai", ""], ["Bian", "Zilin", ""], ["Bernardes", "Suzana Duran", ""], ["Na", "Chaekuk", ""], ["Wang", "Jingxing", ""], ["Petinos", "John", ""], ["Ozbay", "Kaan", ""], ["Chow", "Joseph Y. J.", ""], ["Iyer", "Shri", ""], ["Nassif", "Hani", ""], ["Ban", "Xuegang Jeff", ""]]}, {"id": "2010.09776", "submitter": "Weinan Zhang", "authors": "Ming Zhou, Jun Luo, Julian Villella, Yaodong Yang, David Rusu, Jiayu\n  Miao, Weinan Zhang, Montgomery Alban, Iman Fadakar, Zheng Chen, Aurora\n  Chongxi Huang, Ying Wen, Kimia Hassanzadeh, Daniel Graves, Dong Chen,\n  Zhengbang Zhu, Nhat Nguyen, Mohamed Elsayed, Kun Shao, Sanjeevan Ahilan,\n  Baokuan Zhang, Jiannan Wu, Zhengang Fu, Kasra Rezaee, Peyman Yadmellat,\n  Mohsen Rohani, Nicolas Perez Nieves, Yihan Ni, Seyedershad Banijamali,\n  Alexander Cowen Rivers, Zheng Tian, Daniel Palenicek, Haitham bou Ammar,\n  Hongbo Zhang, Wulong Liu, Jianye Hao, Jun Wang", "title": "SMARTS: Scalable Multi-Agent Reinforcement Learning Training School for\n  Autonomous Driving", "comments": "20 pages, 11 figures. Paper accepted to CoRL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.GT cs.LG cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multi-agent interaction is a fundamental aspect of autonomous driving in the\nreal world. Despite more than a decade of research and development, the problem\nof how to competently interact with diverse road users in diverse scenarios\nremains largely unsolved. Learning methods have much to offer towards solving\nthis problem. But they require a realistic multi-agent simulator that generates\ndiverse and competent driving interactions. To meet this need, we develop a\ndedicated simulation platform called SMARTS (Scalable Multi-Agent RL Training\nSchool). SMARTS supports the training, accumulation, and use of diverse\nbehavior models of road users. These are in turn used to create increasingly\nmore realistic and diverse interactions that enable deeper and broader research\non multi-agent interaction. In this paper, we describe the design goals of\nSMARTS, explain its basic architecture and its key features, and illustrate its\nuse through concrete multi-agent experiments on interactive scenarios. We\nopen-source the SMARTS platform and the associated benchmark tasks and\nevaluation metrics to encourage and empower research on multi-agent learning\nfor autonomous driving. Our code is available at\nhttps://github.com/huawei-noah/SMARTS.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 18:26:10 GMT"}, {"version": "v2", "created": "Sun, 1 Nov 2020 01:32:36 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Zhou", "Ming", ""], ["Luo", "Jun", ""], ["Villella", "Julian", ""], ["Yang", "Yaodong", ""], ["Rusu", "David", ""], ["Miao", "Jiayu", ""], ["Zhang", "Weinan", ""], ["Alban", "Montgomery", ""], ["Fadakar", "Iman", ""], ["Chen", "Zheng", ""], ["Huang", "Aurora Chongxi", ""], ["Wen", "Ying", ""], ["Hassanzadeh", "Kimia", ""], ["Graves", "Daniel", ""], ["Chen", "Dong", ""], ["Zhu", "Zhengbang", ""], ["Nguyen", "Nhat", ""], ["Elsayed", "Mohamed", ""], ["Shao", "Kun", ""], ["Ahilan", "Sanjeevan", ""], ["Zhang", "Baokuan", ""], ["Wu", "Jiannan", ""], ["Fu", "Zhengang", ""], ["Rezaee", "Kasra", ""], ["Yadmellat", "Peyman", ""], ["Rohani", "Mohsen", ""], ["Nieves", "Nicolas Perez", ""], ["Ni", "Yihan", ""], ["Banijamali", "Seyedershad", ""], ["Rivers", "Alexander Cowen", ""], ["Tian", "Zheng", ""], ["Palenicek", "Daniel", ""], ["Ammar", "Haitham bou", ""], ["Zhang", "Hongbo", ""], ["Liu", "Wulong", ""], ["Hao", "Jianye", ""], ["Wang", "Jun", ""]]}, {"id": "2010.09890", "submitter": "Xavier Puig", "authors": "Xavier Puig, Tianmin Shu, Shuang Li, Zilin Wang, Yuan-Hong Liao,\n  Joshua B. Tenenbaum, Sanja Fidler, Antonio Torralba", "title": "Watch-And-Help: A Challenge for Social Perception and Human-AI\n  Collaboration", "comments": "ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we introduce Watch-And-Help (WAH), a challenge for testing\nsocial intelligence in agents. In WAH, an AI agent needs to help a human-like\nagent perform a complex household task efficiently. To succeed, the AI agent\nneeds to i) understand the underlying goal of the task by watching a single\ndemonstration of the human-like agent performing the same task (social\nperception), and ii) coordinate with the human-like agent to solve the task in\nan unseen environment as fast as possible (human-AI collaboration). For this\nchallenge, we build VirtualHome-Social, a multi-agent household environment,\nand provide a benchmark including both planning and learning based baselines.\nWe evaluate the performance of AI agents with the human-like agent as well as\nwith real humans using objective metrics and subjective user ratings.\nExperimental results demonstrate that the proposed challenge and virtual\nenvironment enable a systematic evaluation on the important aspects of machine\nsocial intelligence at scale.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 21:48:31 GMT"}, {"version": "v2", "created": "Mon, 3 May 2021 13:08:55 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Puig", "Xavier", ""], ["Shu", "Tianmin", ""], ["Li", "Shuang", ""], ["Wang", "Zilin", ""], ["Liao", "Yuan-Hong", ""], ["Tenenbaum", "Joshua B.", ""], ["Fidler", "Sanja", ""], ["Torralba", "Antonio", ""]]}, {"id": "2010.09993", "submitter": "Cesar A. Uribe", "authors": "Eduardo Mojica-Nava and David Yanguas-Rojas and C\\'esar A. Uribe", "title": "Robust Asynchronous and Network-Independent Cooperative Learning", "comments": "Submitted to ACC2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DC cs.MA cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the model of cooperative learning via distributed non-Bayesian\nlearning, where a network of agents tries to jointly agree on a hypothesis that\nbest described a sequence of locally available observations. Building upon\nrecently proposed weak communication network models, we propose a robust\ncooperative learning rule that allows asynchronous communications, message\ndelays, unpredictable message losses, and directed communication among nodes.\nWe show that our proposed learning dynamics guarantee that all agents in the\nnetwork will have an asymptotic exponential decay of their beliefs on the wrong\nhypothesis, indicating that the beliefs of all agents will concentrate on the\noptimal hypotheses. Numerical experiments provide evidence on a number of\nnetwork setups.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 03:54:20 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Mojica-Nava", "Eduardo", ""], ["Yanguas-Rojas", "David", ""], ["Uribe", "C\u00e9sar A.", ""]]}, {"id": "2010.10192", "submitter": "Moumita Choudhury", "authors": "Moumita Choudhury, Amit Sarker, Md. Mosaddek Khan, William Yeoh", "title": "A Particle Swarm Inspired Approach for Continuous Distributed Constraint\n  Optimization Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed Constraint Optimization Problems (DCOPs) are a widely studied\nframework for coordinating interactions in cooperative multi-agent systems. In\nclassical DCOPs, variables owned by agents are assumed to be discrete. However,\nin many applications, such as target tracking or sleep scheduling in sensor\nnetworks, continuous-valued variables are more suitable than discrete ones. To\nbetter model such applications, researchers have proposed Continuous DCOPs\n(C-DCOPs), an extension of DCOPs, that can explicitly model problems with\ncontinuous variables. The state-of-the-art approaches for solving C-DCOPs\nexperience either onerous memory or computation overhead and unsuitable for\nnon-differentiable optimization problems. To address this issue, we propose a\nnew C-DCOP algorithm, namely Particle Swarm Optimization Based C-DCOP (PCD),\nwhich is inspired by Particle Swarm Optimization (PSO), a well-known\ncentralized population-based approach for solving continuous optimization\nproblems. In recent years, population-based algorithms have gained significant\nattention in classical DCOPs due to their ability in producing high-quality\nsolutions. Nonetheless, to the best of our knowledge, this class of algorithms\nhas not been utilized to solve C-DCOPs and there has been no work evaluating\nthe potential of PSO in solving classical DCOPs or C-DCOPs. In light of this\nobservation, we adapted PSO, a centralized algorithm, to solve C-DCOPs in a\ndecentralized manner. The resulting PCD algorithm not only produces\ngood-quality solutions but also finds solutions without any requirement for\nderivative calculations. Moreover, we design a crossover operator that can be\nused by PCD to further improve the quality of solutions found. Finally, we\ntheoretically prove that PCD is an anytime algorithm and empirically evaluate\nPCD against the state-of-the-art C-DCOP algorithms in a wide variety of\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 11:04:47 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Choudhury", "Moumita", ""], ["Sarker", "Amit", ""], ["Khan", "Md. Mosaddek", ""], ["Yeoh", "William", ""]]}, {"id": "2010.10380", "submitter": "Yoram Bachrach", "authors": "Yoram Bachrach, Richard Everett, Edward Hughes, Angeliki Lazaridou,\n  Joel Z. Leibo, Marc Lanctot, Michael Johanson, Wojciech M. Czarnecki, Thore\n  Graepel", "title": "Negotiating Team Formation Using Deep Reinforcement Learning", "comments": null, "journal-ref": "Artificial Intelligence 288 (2020): 103356", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When autonomous agents interact in the same environment, they must often\ncooperate to achieve their goals. One way for agents to cooperate effectively\nis to form a team, make a binding agreement on a joint plan, and execute it.\nHowever, when agents are self-interested, the gains from team formation must be\nallocated appropriately to incentivize agreement. Various approaches for\nmulti-agent negotiation have been proposed, but typically only work for\nparticular negotiation protocols. More general methods usually require human\ninput or domain-specific data, and so do not scale. To address this, we propose\na framework for training agents to negotiate and form teams using deep\nreinforcement learning. Importantly, our method makes no assumptions about the\nspecific negotiation protocol, and is instead completely experience driven. We\nevaluate our approach on both non-spatial and spatially extended team-formation\nnegotiation environments, demonstrating that our agents beat hand-crafted bots\nand reach negotiation outcomes consistent with fair solutions predicted by\ncooperative game theory. Additionally, we investigate how the physical location\nof agents influences negotiation outcomes.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 15:41:23 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Bachrach", "Yoram", ""], ["Everett", "Richard", ""], ["Hughes", "Edward", ""], ["Lazaridou", "Angeliki", ""], ["Leibo", "Joel Z.", ""], ["Lanctot", "Marc", ""], ["Johanson", "Michael", ""], ["Czarnecki", "Wojciech M.", ""], ["Graepel", "Thore", ""]]}, {"id": "2010.10667", "submitter": "Sergio Ramirez", "authors": "Michell Guzm\\'an, Sophia Knight, Santiago Quintero, Sergio Ram\\'irez,\n  Camilo Rueda, Frank Valencia", "title": "Algebraic Structures from Concurrent Constraint Programming Calculi for\n  Distributed Information in Multi-Agent Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Spatial constraint systems (scs) are semantic structures for reasoning about\nspatial and epistemic information in concurrent systems. We develop the theory\nof scs to reason about the distributed information of potentially infinite\ngroups. We characterize the notion of distributed information of a group of\nagents as the infimum of the set of join-preserving functions that represent\nthe spaces of the agents in the group. We provide an alternative\ncharacterization of this notion as the greatest family of join-preserving\nfunctions that satisfy certain basic properties. For completely distributive\nlattices, we establish that distributed information of a group is the greatest\ninformation below all possible combinations of information in the spaces of the\nagents in the group that derive a given piece of information. We show\ncompositionality results for these characterizations and conditions under which\ninformation that can be obtained by an infinite group can also be obtained by a\nfinite group. Finally, we provide an application on mathematical morphology\nwhere dilations, one of its fundamental operations, define an scs on a powerset\nlattice. We show that distributed information represents a particular dilation\nin such scs.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 23:13:03 GMT"}, {"version": "v2", "created": "Mon, 8 Feb 2021 13:31:28 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Guzm\u00e1n", "Michell", ""], ["Knight", "Sophia", ""], ["Quintero", "Santiago", ""], ["Ram\u00edrez", "Sergio", ""], ["Rueda", "Camilo", ""], ["Valencia", "Frank", ""]]}, {"id": "2010.10878", "submitter": "Ezra Tampubolon", "authors": "Ezra Tampubolon and Holger Boche", "title": "Coordinated Online Learning for Multi-Agent Systems with Coupled\n  Constraints and Perturbed Utility Observations", "comments": "Preprint: To appear in IEEE Transaction on Automatic Control", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.GT cs.LG cs.MA cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Competitive non-cooperative online decision-making agents whose actions\nincrease congestion of scarce resources constitute a model for widespread\nmodern large-scale applications. To ensure sustainable resource behavior, we\nintroduce a novel method to steer the agents toward a stable population state,\nfulfilling the given coupled resource constraints. The proposed method is a\ndecentralized resource pricing method based on the resource loads resulting\nfrom the augmentation of the game's Lagrangian. Assuming that the online\nlearning agents have only noisy first-order utility feedback, we show that for\na polynomially decaying agents' step size/learning rate, the population's\ndynamic will almost surely converge to generalized Nash equilibrium. A\nparticular consequence of the latter is the fulfillment of resource constraints\nin the asymptotic limit. Moreover, we investigate the finite-time quality of\nthe proposed algorithm by giving a nonasymptotic time decaying bound for the\nexpected amount of resource constraint violation.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 10:11:17 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Tampubolon", "Ezra", ""], ["Boche", "Holger", ""]]}, {"id": "2010.10901", "submitter": "Ezra Tampubolon", "authors": "Ezra Tampubolon, Haris Ceribasic, Holger Boche", "title": "On Information Asymmetry in Competitive Multi-Agent Reinforcement\n  Learning: Convergence and Optimality", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT cs.MA cs.SY econ.TH eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we study the system of interacting non-cooperative two\nQ-learning agents, where one agent has the privilege of observing the other's\nactions. We show that this information asymmetry can lead to a stable outcome\nof population learning, which generally does not occur in an environment of\ngeneral independent learners. The resulting post-learning policies are almost\noptimal in the underlying game sense, i.e., they form a Nash equilibrium.\nFurthermore, we propose in this work a Q-learning algorithm, requiring\npredictive observation of two subsequent opponent's actions, yielding an\noptimal strategy given that the latter applies a stationary strategy, and\ndiscuss the existence of the Nash equilibrium in the underlying information\nasymmetrical game.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 11:19:53 GMT"}, {"version": "v2", "created": "Fri, 22 Jan 2021 22:18:21 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Tampubolon", "Ezra", ""], ["Ceribasic", "Haris", ""], ["Boche", "Holger", ""]]}, {"id": "2010.11025", "submitter": "Ammar Malik", "authors": "Ammar Malik, Hugo Lhachemi, and Robert Shorten", "title": "I-nteract 2.0: A Cyber-Physical System to Design 3D Models using Mixed\n  Reality Technologies and Deep Learning for Additive Manufacturing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  I-nteract is a cyber-physical system that enables real-time interaction with\nboth virtual and real artifacts to design 3D models for additive manufacturing\nby leveraging on mixed reality technologies. This paper presents novel advances\nin the development of the interaction platform I-nteract to generate 3D models\nusing both constructive solid geometry and artificial intelligence. The system\nalso enables the user to adjust the dimensions of the 3D models with respect to\ntheir physical workspace. The effectiveness of the system is demonstrated by\ngenerating 3D models of furniture (e.g., chairs and tables) and fitting them\ninto the physical space in a mixed reality environment.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 14:13:21 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Malik", "Ammar", ""], ["Lhachemi", "Hugo", ""], ["Shorten", "Robert", ""]]}, {"id": "2010.11061", "submitter": "Jesus Tordesillas Torres", "authors": "Jesus Tordesillas and Jonathan P. How", "title": "MADER: Trajectory Planner in Multi-Agent and Dynamic Environments", "comments": "15 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents MADER, a 3D decentralized and asynchronous trajectory\nplanner for UAVs that generates collision-free trajectories in environments\nwith static obstacles, dynamic obstacles, and other planning agents. Real-time\ncollision avoidance with other dynamic obstacles or agents is done by\nperforming outer polyhedral representations of every interval of the\ntrajectories and then including the plane that separates each pair of polyhedra\nas a decision variable in the optimization problem. MADER uses our recently\ndeveloped MINVO basis to obtain outer polyhedral representations with volumes\n2.36 and 254.9 times, respectively, smaller than the Bernstein or B-Spline\nbases used extensively in the planning literature. Our decentralized and\nasynchronous algorithm guarantees safety with respect to other agents by\nincluding their committed trajectories as constraints in the optimization and\nthen executing a collision check-recheck scheme. Finally, extensive simulations\nin challenging cluttered environments show up to a 33.9% reduction in the\nflight time, and a 88.8% reduction in the number of stops compared to the\nBernstein and B-Spline bases, shorter flight distances than centralized\napproaches, and shorter total times on average than synchronous decentralized\napproaches.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 15:10:12 GMT"}, {"version": "v2", "created": "Thu, 15 Apr 2021 12:46:47 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Tordesillas", "Jesus", ""], ["How", "Jonathan P.", ""]]}, {"id": "2010.11146", "submitter": "Arles Rodr\\'iguez", "authors": "Arles Rodr\\'iguez, Jonatan G\\'omez and Ada Diaconescu", "title": "A Decentralised Self-Healing Approach for Network Topology Maintenance", "comments": null, "journal-ref": "Autonomous Agents and Multi-Agent Systems, 35(1), 6 (2020)", "doi": "10.1007/s10458-020-09486-3", "report-no": null, "categories": "cs.MA cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many distributed systems, from cloud to sensor networks, different\nconfigurations impact system performance, while strongly depending on the\nnetwork topology. Hence, topological changes may entail costly reconfiguration\nand optimisation processes. This paper proposes a multi-agent solution for\nrecovering networks from node failures. To preserve the network topology, the\nproposed approach relies on local information about the network's structure,\nwhich is collected and disseminated at runtime. The paper studies two\nstrategies for distributing topological data: one based on Mobile Agents (our\nproposal) and the other based on Trickle (a reference gossiping protocol from\nthe literature). These two strategies were adapted for our self-healing\napproach to collect topological information for recovering the network; and\nwere evaluated in terms of resource overheads. Experimental results show that\nboth variants can recover the network topology, up to a certain node failure\nrate, which depends on the network topology. At the same time, Mobile Agents\ncollect less information, focusing on local dissemination, which suffices for\nnetwork recovery. This entails less bandwidth overheads than when Trickle is\nused. Still, Mobile Agents utilise more memory and exchange more messages,\nduring data-collection, than Trickle does. These results validate the viability\nof the proposed self-healing solution, offering two variant implementations\nwith diverse performance characteristics, which may suit different application\ndomains.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 17:02:38 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Rodr\u00edguez", "Arles", ""], ["G\u00f3mez", "Jonatan", ""], ["Diaconescu", "Ada", ""]]}, {"id": "2010.11376", "submitter": "Bo Fu", "authors": "Bo Fu, William Smith, Denise Rizzo, Matthew Castanier, Kira Barton", "title": "Heterogeneous Vehicle Routing and Teaming with Gaussian Distributed\n  Energy Uncertainty", "comments": "IROS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For robot swarms operating on complex missions in an uncertain environment,\nit is important that the decision-making algorithm considers both heterogeneity\nand uncertainty. This paper presents a stochastic programming framework for the\nvehicle routing problem with stochastic travel energy costs and heterogeneous\nvehicles and tasks. We represent the heterogeneity as linear constraints,\nestimate the uncertain energy cost through Gaussian process regression,\nformulate this stochasticity as chance constraints or stochastic recourse\ncosts, and then solve the stochastic programs using branch and cut algorithms\nto minimize the expected energy cost. The performance and practicality are\ndemonstrated through extensive computational experiments and a practical test\ncase.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 01:52:57 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Fu", "Bo", ""], ["Smith", "William", ""], ["Rizzo", "Denise", ""], ["Castanier", "Matthew", ""], ["Barton", "Kira", ""]]}, {"id": "2010.11425", "submitter": "Abhimanyu Dubey", "authors": "Abhimanyu Dubey and Alex Pentland", "title": "Differentially-Private Federated Linear Bandits", "comments": "22 pages. Camera-ready for NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid proliferation of decentralized learning systems mandates the need\nfor differentially-private cooperative learning. In this paper, we study this\nin context of the contextual linear bandit: we consider a collection of agents\ncooperating to solve a common contextual bandit, while ensuring that their\ncommunication remains private. For this problem, we devise \\textsc{FedUCB}, a\nmultiagent private algorithm for both centralized and decentralized\n(peer-to-peer) federated learning. We provide a rigorous technical analysis of\nits utility in terms of regret, improving several results in cooperative bandit\nlearning, and provide rigorous privacy guarantees as well. Our algorithms\nprovide competitive performance both in terms of pseudoregret bounds and\nempirical benchmark performance in various multi-agent settings.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 03:58:39 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Dubey", "Abhimanyu", ""], ["Pentland", "Alex", ""]]}, {"id": "2010.11585", "submitter": "Andre Romano Alho Dr", "authors": "Andre Alho, Takanori Sakai, Simon Oh, Cheng Cheng, Ravi Seshadri, Wen\n  Han Chong, Yusuke Hara, Julia Caravias, Lynette Cheah, Moshe Ben-Akiva", "title": "A simulation-based evaluation of a Cargo-Hitching service for E-commerce\n  using mobility-on-demand vehicles", "comments": "19 pages, 4 tables, 7 figures. Submitted to Transportation (Springer)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time-sensitive parcel deliveries, shipments requested for delivery in a day\nor less, are an increasingly important research subject. It is challenging to\ndeal with these deliveries from a carrier perspective since it entails\nadditional planning constraints, preventing an efficient consolidation of\ndeliveries which is possible when demand is well known in advance. Furthermore,\nsuch time-sensitive deliveries are requested to a wider spatial scope than\nretail centers, including homes and offices. Therefore, an increase in such\ndeliveries is considered to exacerbate negative externalities such as\ncongestion and emissions. One of the solutions is to leverage spare capacity in\npassenger transport modes. This concept is often denominated as cargo-hitching.\nWhile there are various possible system designs, it is crucial that such\nsolution does not deteriorate the quality of service of passenger trips. This\nresearch aims to evaluate the use of Mobility-On-Demand services to perform\nsame-day parcel deliveries. For this purpose, we use SimMobility, a\nhigh-resolution agent-based simulation platform of passenger and freight flows,\napplied in Singapore. E-commerce demand carrier data are used to characterize\nsimulated parcel delivery demand. Operational scenarios that aim to minimize\nthe adverse effect of fulfilling deliveries with Mobility-On-Demand vehicles on\nMobility-On-Demand passenger flows (fulfillment, wait and travel times) are\nexplored. Results indicate that the Mobility-On-Demand services have potential\nto fulfill a considerable amount of parcel deliveries and decrease freight\nvehicle traffic and total vehicle-kilometers-travelled without compromising the\nquality of Mobility On-Demand for passenger travel.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 10:35:31 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Alho", "Andre", ""], ["Sakai", "Takanori", ""], ["Oh", "Simon", ""], ["Cheng", "Cheng", ""], ["Seshadri", "Ravi", ""], ["Chong", "Wen Han", ""], ["Hara", "Yusuke", ""], ["Caravias", "Julia", ""], ["Cheah", "Lynette", ""], ["Ben-Akiva", "Moshe", ""]]}, {"id": "2010.11835", "submitter": "Mikko Lauri", "authors": "Mikko Lauri and Frans A. Oliehoek", "title": "Multi-agent active perception with prediction rewards", "comments": "34th Conference on Neural Information Processing Systems (NeurIPS\n  2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-agent active perception is a task where a team of agents cooperatively\ngathers observations to compute a joint estimate of a hidden variable. The task\nis decentralized and the joint estimate can only be computed after the task\nends by fusing observations of all agents. The objective is to maximize the\naccuracy of the estimate. The accuracy is quantified by a centralized\nprediction reward determined by a centralized decision-maker who perceives the\nobservations gathered by all agents after the task ends. In this paper, we\nmodel multi-agent active perception as a decentralized partially observable\nMarkov decision process (Dec-POMDP) with a convex centralized prediction\nreward. We prove that by introducing individual prediction actions for each\nagent, the problem is converted into a standard Dec-POMDP with a decentralized\nprediction reward. The loss due to decentralization is bounded, and we give a\nsufficient condition for when it is zero. Our results allow application of any\nDec-POMDP solution algorithm to multi-agent active perception problems, and\nenable planning to reduce uncertainty without explicit computation of joint\nestimates. We demonstrate the empirical usefulness of our results by applying a\nstandard Dec-POMDP algorithm to multi-agent active perception problems, showing\nincreased scalability in the planning horizon.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 16:10:15 GMT"}], "update_date": "2020-10-24", "authors_parsed": [["Lauri", "Mikko", ""], ["Oliehoek", "Frans A.", ""]]}, {"id": "2010.12288", "submitter": "Stefan Vlaski", "authors": "Stefan Vlaski, Ali H. Sayed", "title": "Graph-Homomorphic Perturbations for Private Decentralized Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.MA eess.SP math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decentralized algorithms for stochastic optimization and learning rely on the\ndiffusion of information as a result of repeated local exchanges of\nintermediate estimates. Such structures are particularly appealing in\nsituations where agents may be hesitant to share raw data due to privacy\nconcerns. Nevertheless, in the absence of additional privacy-preserving\nmechanisms, the exchange of local estimates, which are generated based on\nprivate data can allow for the inference of the data itself. The most common\nmechanism for guaranteeing privacy is the addition of perturbations to local\nestimates before broadcasting. These perturbations are generally chosen\nindependently at every agent, resulting in a significant performance loss. We\npropose an alternative scheme, which constructs perturbations according to a\nparticular nullspace condition, allowing them to be invisible (to first order\nin the step-size) to the network centroid, while preserving privacy guarantees.\nThe analysis allows for general nonconvex loss functions, and is hence\napplicable to a large number of machine learning and signal processing\nproblems, including deep learning.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 10:35:35 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Vlaski", "Stefan", ""], ["Sayed", "Ali H.", ""]]}, {"id": "2010.12306", "submitter": "Virginia Bordignon", "authors": "Virginia Bordignon, Stefan Vlaski, Vincenzo Matta, Ali H. Sayed", "title": "Network Classifiers Based on Social Learning", "comments": "to appear in ICASSP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work proposes a new way of combining independently trained classifiers\nover space and time. Combination over space means that the outputs of spatially\ndistributed classifiers are aggregated. Combination over time means that the\nclassifiers respond to streaming data during testing and continue to improve\ntheir performance even during this phase. By doing so, the proposed\narchitecture is able to improve prediction performance over time with unlabeled\ndata. Inspired by social learning algorithms, which require prior knowledge of\nthe observations distribution, we propose a Social Machine Learning (SML)\nparadigm that is able to exploit the imperfect models generated during the\nlearning phase. We show that this strategy results in consistent learning with\nhigh probability, and it yields a robust structure against poorly trained\nclassifiers. Simulations with an ensemble of feedforward neural networks are\nprovided to illustrate the theoretical results.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 11:18:20 GMT"}, {"version": "v2", "created": "Fri, 16 Apr 2021 09:43:59 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Bordignon", "Virginia", ""], ["Vlaski", "Stefan", ""], ["Matta", "Vincenzo", ""], ["Sayed", "Ali H.", ""]]}, {"id": "2010.12327", "submitter": "Dave Braines Mr", "authors": "Dave Braines, Federico Cerutti, Marc Roig Vilamala, Mani Srivastava,\n  Lance Kaplan Alun Preece, Gavin Pearson", "title": "Towards human-agent knowledge fusion (HAKF) in support of distributed\n  coalition teams", "comments": "Presented at AAAI FSS-20: Artificial Intelligence in Government and\n  Public Sector, Washington, DC, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Future coalition operations can be substantially augmented through agile\nteaming between human and machine agents, but in a coalition context these\nagents may be unfamiliar to the human users and expected to operate in a broad\nset of scenarios rather than being narrowly defined for particular purposes. In\nsuch a setting it is essential that the human agents can rapidly build trust in\nthe machine agents through appropriate transparency of their behaviour, e.g.,\nthrough explanations. The human agents are also able to bring their local\nknowledge to the team, observing the situation unfolding and deciding which key\ninformation should be communicated to the machine agents to enable them to\nbetter account for the particular environment. In this paper we describe the\ninitial steps towards this human-agent knowledge fusion (HAKF) environment\nthrough a recap of the key requirements, and an explanation of how these can be\nfulfilled for an example situation. We show how HAKF has the potential to bring\nvalue to both human and machine agents working as part of a distributed\ncoalition team in a complex event processing setting with uncertain sources.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 12:10:40 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Braines", "Dave", ""], ["Cerutti", "Federico", ""], ["Vilamala", "Marc Roig", ""], ["Srivastava", "Mani", ""], ["Preece", "Lance Kaplan Alun", ""], ["Pearson", "Gavin", ""]]}, {"id": "2010.12461", "submitter": "Harald Bayerlein", "authors": "Harald Bayerlein, Mirco Theile, Marco Caccamo, David Gesbert", "title": "Multi-UAV Path Planning for Wireless Data Harvesting with Deep\n  Reinforcement Learning", "comments": "Modifications: final formatting; Code available under\n  https://github.com/hbayerlein/uav_data_harvesting, article extends on\n  arXiv:2007.00544", "journal-ref": "IEEE Open Journal of the Communications Society, vol. 2, pp.\n  1171-1187, 2021", "doi": "10.1109/OJCOMS.2021.3081996", "report-no": null, "categories": "cs.MA cs.IT cs.LG cs.RO cs.SY eess.SY math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Harvesting data from distributed Internet of Things (IoT) devices with\nmultiple autonomous unmanned aerial vehicles (UAVs) is a challenging problem\nrequiring flexible path planning methods. We propose a multi-agent\nreinforcement learning (MARL) approach that, in contrast to previous work, can\nadapt to profound changes in the scenario parameters defining the data\nharvesting mission, such as the number of deployed UAVs, number, position and\ndata amount of IoT devices, or the maximum flying time, without the need to\nperform expensive recomputations or relearn control policies. We formulate the\npath planning problem for a cooperative, non-communicating, and homogeneous\nteam of UAVs tasked with maximizing collected data from distributed IoT sensor\nnodes subject to flying time and collision avoidance constraints. The path\nplanning problem is translated into a decentralized partially observable Markov\ndecision process (Dec-POMDP), which we solve through a deep reinforcement\nlearning (DRL) approach, approximating the optimal UAV control policy without\nprior knowledge of the challenging wireless channel characteristics in dense\nurban environments. By exploiting a combination of centered global and local\nmap representations of the environment that are fed into convolutional layers\nof the agents, we show that our proposed network architecture enables the\nagents to cooperate effectively by carefully dividing the data collection task\namong themselves, adapt to large complex environments and state spaces, and\nmake movement decisions that balance data collection goals, flight-time\nefficiency, and navigation constraints. Finally, learning a control policy that\ngeneralizes over the scenario parameter space enables us to analyze the\ninfluence of individual parameters on collection performance and provide some\nintuition about system-level benefits.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 14:59:30 GMT"}, {"version": "v2", "created": "Mon, 15 Mar 2021 09:07:39 GMT"}, {"version": "v3", "created": "Thu, 3 Jun 2021 11:38:05 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Bayerlein", "Harald", ""], ["Theile", "Mirco", ""], ["Caccamo", "Marco", ""], ["Gesbert", "David", ""]]}, {"id": "2010.12536", "submitter": "Nasim Rahaman", "authors": "Yoshua Bengio, Prateek Gupta, Tegan Maharaj, Nasim Rahaman, Martin\n  Weiss, Tristan Deleu, Eilif Muller, Meng Qu, Victor Schmidt, Pierre-Luc\n  St-Charles, Hannah Alsdurf, Olexa Bilanuik, David Buckeridge, G\\'aetan\n  Marceau Caron, Pierre-Luc Carrier, Joumana Ghosn, Satya Ortiz-Gagne, Chris\n  Pal, Irina Rish, Bernhard Sch\\\"olkopf, Abhinav Sharma, Jian Tang, Andrew\n  Williams", "title": "Predicting Infectiousness for Proactive Contact Tracing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The COVID-19 pandemic has spread rapidly worldwide, overwhelming manual\ncontact tracing in many countries and resulting in widespread lockdowns for\nemergency containment. Large-scale digital contact tracing (DCT) has emerged as\na potential solution to resume economic and social activity while minimizing\nspread of the virus. Various DCT methods have been proposed, each making\ntrade-offs between privacy, mobility restrictions, and public health. The most\ncommon approach, binary contact tracing (BCT), models infection as a binary\nevent, informed only by an individual's test results, with corresponding binary\nrecommendations that either all or none of the individual's contacts\nquarantine. BCT ignores the inherent uncertainty in contacts and the infection\nprocess, which could be used to tailor messaging to high-risk individuals, and\nprompt proactive testing or earlier warnings. It also does not make use of\nobservations such as symptoms or pre-existing medical conditions, which could\nbe used to make more accurate infectiousness predictions. In this paper, we use\na recently-proposed COVID-19 epidemiological simulator to develop and test\nmethods that can be deployed to a smartphone to locally and proactively predict\nan individual's infectiousness (risk of infecting others) based on their\ncontact history and other information, while respecting strong privacy\nconstraints. Predictions are used to provide personalized recommendations to\nthe individual via an app, as well as to send anonymized messages to the\nindividual's contacts, who use this information to better predict their own\ninfectiousness, an approach we call proactive contact tracing (PCT). We find a\ndeep-learning based PCT method which improves over BCT for equivalent average\nmobility, suggesting PCT could help in safe re-opening and second-wave\nprevention.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 17:06:07 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Bengio", "Yoshua", ""], ["Gupta", "Prateek", ""], ["Maharaj", "Tegan", ""], ["Rahaman", "Nasim", ""], ["Weiss", "Martin", ""], ["Deleu", "Tristan", ""], ["Muller", "Eilif", ""], ["Qu", "Meng", ""], ["Schmidt", "Victor", ""], ["St-Charles", "Pierre-Luc", ""], ["Alsdurf", "Hannah", ""], ["Bilanuik", "Olexa", ""], ["Buckeridge", "David", ""], ["Caron", "G\u00e1etan Marceau", ""], ["Carrier", "Pierre-Luc", ""], ["Ghosn", "Joumana", ""], ["Ortiz-Gagne", "Satya", ""], ["Pal", "Chris", ""], ["Rish", "Irina", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["Sharma", "Abhinav", ""], ["Tang", "Jian", ""], ["Williams", "Andrew", ""]]}, {"id": "2010.12761", "submitter": "Deepak Pahwa", "authors": "Deepak Pahwa, Umut Dur, Binil Starly", "title": "Mechanism Design for Stable Matching with Contracts in a Dynamic\n  Manufacturing-as-a-Service (MaaS) Marketplace", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two-sided manufacturing-as-a-service (MaaS) marketplaces connect clients\nrequesting manufacturing services to suppliers providing those services.\nMatching mechanisms i.e. allocation of clients' orders to suppliers is a key\ndesign parameter of the marketplace platform. The platform might perform an\nallocation to maximize its revenue or optimize for social welfare of all\nparticipants. However, individual participants might not get maximum value from\ntheir match and reject it to form matches (called blocking groups) themselves,\nthereby bypassing the platform. This paper considers the bipartite matching\nproblem in MaaS marketplaces in a dynamic environment and proposes\napproximately stable matching solutions using mechanism design and mathematical\nprogramming approaches to limit the formation of blocking groups. Matching is\nbased on non-strict, incomplete and interdependent preferences of participants\nover contracts enabling negotiations between both sides. Empirical simulations\nare used to test the mechanisms in a simulated 3D printing marketplace and to\nevaluate the impact of stability on its performance. It is found that stable\nmatching results in small degradation in social welfare of the marketplace.\nHowever, it leads to a significantly better outcome in terms of stability of\nallocation. Unstable matchings introduce anarchy into marketplace with\nparticipants rejecting its allocation leading to performance poorer than stable\nmatchings.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2020 03:35:11 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Pahwa", "Deepak", ""], ["Dur", "Umut", ""], ["Starly", "Binil", ""]]}, {"id": "2010.12763", "submitter": "Zhaowei Zhu", "authors": "Zhaowei Zhu, Jingxuan Zhu, Ji Liu, Yang Liu", "title": "Federated Bandit: A Gossiping Approach", "comments": "Accepted by ACM SIGMETRICS 2021", "journal-ref": "Proc. ACM Meas. Anal. Comput. Syst., Vol. 5, No. 1, Article 2.\n  Publication date: March 2021", "doi": "10.1145/3447380", "report-no": null, "categories": "cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study \\emph{Federated Bandit}, a decentralized Multi-Armed\nBandit problem with a set of $N$ agents, who can only communicate their local\ndata with neighbors described by a connected graph $G$. Each agent makes a\nsequence of decisions on selecting an arm from $M$ candidates, yet they only\nhave access to local and potentially biased feedback/evaluation of the true\nreward for each action taken. Learning only locally will lead agents to\nsub-optimal actions while converging to a no-regret strategy requires a\ncollection of distributed data. Motivated by the proposal of federated\nlearning, we aim for a solution with which agents will never share their local\nobservations with a central entity, and will be allowed to only share a private\ncopy of his/her own information with their neighbors. We first propose a\ndecentralized bandit algorithm Gossip_UCB, which is a coupling of variants of\nboth the classical gossiping algorithm and the celebrated Upper Confidence\nBound (UCB) bandit algorithm. We show that Gossip_UCB successfully adapts local\nbandit learning into a global gossiping process for sharing information among\nconnected agents, and achieves guaranteed regret at the order of $O(\\max\\{\n\\texttt{poly}(N,M) \\log T, \\texttt{poly}(N,M)\\log_{\\lambda_2^{-1}} N\\})$ for\nall $N$ agents, where $\\lambda_2\\in(0,1)$ is the second largest eigenvalue of\nthe expected gossip matrix, which is a function of $G$. We then propose\nFed_UCB, a differentially private version of Gossip_UCB, in which the agents\npreserve $\\epsilon$-differential privacy of their local data while achieving\n$O(\\max \\{\\frac{\\texttt{poly}(N,M)}{\\epsilon}\\log^{2.5} T, \\texttt{poly}(N,M)\n(\\log_{\\lambda_2^{-1}} N + \\log T) \\})$ regret.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2020 03:44:25 GMT"}, {"version": "v2", "created": "Wed, 7 Apr 2021 04:59:14 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Zhu", "Zhaowei", ""], ["Zhu", "Jingxuan", ""], ["Liu", "Ji", ""], ["Liu", "Yang", ""]]}, {"id": "2010.12797", "submitter": "Bryan Kian Hsiang Low", "authors": "Rachael Hwee Ling Sim, Yehong Zhang, Mun Choon Chan, Bryan Kian Hsiang\n  Low", "title": "Collaborative Machine Learning with Incentive-Aware Model Rewards", "comments": "37th International Conference on Machine Learning (ICML 2020),\n  Extended version with proofs and additional experimental results, 17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaborative machine learning (ML) is an appealing paradigm to build\nhigh-quality ML models by training on the aggregated data from many parties.\nHowever, these parties are only willing to share their data when given enough\nincentives, such as a guaranteed fair reward based on their contributions. This\nmotivates the need for measuring a party's contribution and designing an\nincentive-aware reward scheme accordingly. This paper proposes to value a\nparty's reward based on Shapley value and information gain on model parameters\ngiven its data. Subsequently, we give each party a model as a reward. To\nformally incentivize the collaboration, we define some desirable properties\n(e.g., fairness and stability) which are inspired by cooperative game theory\nbut adapted for our model reward that is uniquely freely replicable. Then, we\npropose a novel model reward scheme to satisfy fairness and trade off between\nthe desirable properties via an adjustable parameter. The value of each party's\nmodel reward determined by our scheme is attained by injecting Gaussian noise\nto the aggregated training data with an optimized noise variance. We\nempirically demonstrate interesting properties of our scheme and evaluate its\nperformance using synthetic and real-world datasets.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2020 06:20:55 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Sim", "Rachael Hwee Ling", ""], ["Zhang", "Yehong", ""], ["Chan", "Mun Choon", ""], ["Low", "Bryan Kian Hsiang", ""]]}, {"id": "2010.12894", "submitter": "Sujunjie Sun", "authors": "Sujunjie Sun, Guopeng Zhang, Haibo Mei, Kezhi Wang, and Kun Yang", "title": "Optimizing Multi-UAV Deployment in 3D Space to Minimize Task Completion\n  Time in UAV-Enabled Mobile Edge Computing Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Unmanned Aerial Vehicle (UAV)-enabled mobile edge computing (MEC) systems,\nUAVs can carry edge servers to help ground user equipment (UEs) offloading\ntheir computing tasks to the UAVs for execution. This paper aims to minimize\nthe total time required for the UAVs to complete the offloaded tasks, while\noptimizing the three-dimensional (3D) deployment of UAVs, including their\nflying height and horizontal positions. Although the formulated optimization is\na mixed integer nonlinear programmming, we convert it to a convex problem and\ndevelop a successive convex approximation (SCA) based algorithm to effectively\nsolve it. The simulation results show that the joint optimization of the\nhorizontal and the vertical position of a group of UAVs can achieve better\nperformance than the traditional algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2020 12:51:05 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Sun", "Sujunjie", ""], ["Zhang", "Guopeng", ""], ["Mei", "Haibo", ""], ["Wang", "Kezhi", ""], ["Yang", "Kun", ""]]}, {"id": "2010.13036", "submitter": "Isao Yagi", "authors": "Isao Yagi, Shunya Maruyama, and Takanobu Mizuta", "title": "Trading Strategies of a Leveraged ETF in a Continuous Double Auction\n  Market Using an Agent-Based Simulation", "comments": null, "journal-ref": "Complexity, 3497689, Vol. 2020", "doi": "10.1155/2020/3497689", "report-no": null, "categories": "q-fin.TR cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A leveraged ETF is a fund aimed at achieving a rate of return several times\ngreater than that of the underlying asset such as Nikkei 225 futures. Recently,\nit has been suggested that rebalancing trades of a leveraged ETF may\ndestabilize the financial markets. An empirical study using an agent-based\nsimulation indicated that a rebalancing trade strategy could affect the price\nformation of an underlying asset market. However, no leveraged ETF trading\nmethod for suppressing the increase in volatility as much as possible has yet\nbeen proposed. In this paper, we compare different strategies of trading for a\nproposed trading model and report the results of our investigation regarding\nhow best to suppress an increase in market volatility. As a result, it was\nfound that as the minimum number of orders in a rebalancing trade increases,\nthe impact on the market price formation decreases.\n", "versions": [{"version": "v1", "created": "Sun, 25 Oct 2020 05:04:20 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Yagi", "Isao", ""], ["Maruyama", "Shunya", ""], ["Mizuta", "Takanobu", ""]]}, {"id": "2010.13038", "submitter": "Isao Yagi", "authors": "Isao Yagi, Yuji Masuda, and Takanobu Mizuta", "title": "Analysis of the Impact of High-Frequency Trading on Artificial Market\n  Liquidity", "comments": null, "journal-ref": "IEEE Transactions on Computational Social Systems 2020", "doi": "10.1109/TCSS.2020.3019352", "report-no": null, "categories": "q-fin.TR cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many empirical studies have discussed market liquidity, which is regarded as\na measure of a booming financial market. Further, various indicators for\nobjectively evaluating market liquidity have also been proposed and their\nmerits have been discussed. In recent years, the impact of high-frequency\ntraders (HFTs) on financial markets has been a focal concern, but no studies\nhave systematically discussed their relationship with major market liquidity\nindicators, including volume, tightness, resiliency, and depth. In this study,\nwe used agent-based simulations to compare the major liquidity indicators in an\nartificial market where an HFT participated was compared to one where no HFT\nparticipated. The results showed that all liquidity indicators in the market\nwhere an HFT participated improved more than those in the market where no HFT\nparticipated. Furthermore, as a result of investigating the correlations\nbetween the major liquidity indicators in our simulations and the extant\nempirical literature, we found that market liquidity can be measured not only\nby the major liquidity indicators but also by execution rate. Therefore, it is\nsuggested that it could be appropriate to employ execution rate as a novel\nliquidity indicator in future studies.\n", "versions": [{"version": "v1", "created": "Sun, 25 Oct 2020 05:11:13 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Yagi", "Isao", ""], ["Masuda", "Yuji", ""], ["Mizuta", "Takanobu", ""]]}, {"id": "2010.13104", "submitter": "Y. Efe Erginbas", "authors": "Y. Efe Erginbas, Stefan Vlaski, Ali H. Sayed", "title": "Gramian-Based Adaptive Combination Policies for Diffusion Learning over\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.DC eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an adaptive combination strategy for distributed learning\nover diffusion networks. Since learning relies on the collaborative processing\nof the stochastic information at the dispersed agents, the overall performance\ncan be improved by designing combination policies that adjust the weights\naccording to the quality of the data. Such policies are important because they\nwould add a new degree of freedom and endow multi-agent systems with the\nability to control the flow of information over their edges for enhanced\nperformance. Most adaptive and static policies available in the literature\noptimize certain performance metrics related to steady-state behavior, to the\ndetriment of transient behavior. In contrast, we develop an adaptive\ncombination rule that aims at optimizing the transient learning performance,\nwhile maintaining the enhanced steady-state performance obtained using policies\npreviously developed in the literature.\n", "versions": [{"version": "v1", "created": "Sun, 25 Oct 2020 12:26:26 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Erginbas", "Y. Efe", ""], ["Vlaski", "Stefan", ""], ["Sayed", "Ali H.", ""]]}, {"id": "2010.13110", "submitter": "Jing Xu", "authors": "Jing Xu, Fangwei Zhong, Yizhou Wang", "title": "Learning Multi-Agent Coordination for Enhancing Target Coverage in\n  Directional Sensor Networks", "comments": "To appear in NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maximum target coverage by adjusting the orientation of distributed sensors\nis an important problem in directional sensor networks (DSNs). This problem is\nchallenging as the targets usually move randomly but the coverage range of\nsensors is limited in angle and distance. Thus, it is required to coordinate\nsensors to get ideal target coverage with low power consumption, e.g. no\nmissing targets or reducing redundant coverage. To realize this, we propose a\nHierarchical Target-oriented Multi-Agent Coordination (HiT-MAC), which\ndecomposes the target coverage problem into two-level tasks: targets assignment\nby a coordinator and tracking assigned targets by executors. Specifically, the\ncoordinator periodically monitors the environment globally and allocates\ntargets to each executor. In turn, the executor only needs to track its\nassigned targets. To effectively learn the HiT-MAC by reinforcement learning,\nwe further introduce a bunch of practical methods, including a self-attention\nmodule, marginal contribution approximation for the coordinator,\ngoal-conditional observation filter for the executor, etc. Empirical results\ndemonstrate the advantage of HiT-MAC in coverage rate, learning efficiency,and\nscalability, comparing to baselines. We also conduct an ablative analysis on\nthe effectiveness of the introduced components in the framework.\n", "versions": [{"version": "v1", "created": "Sun, 25 Oct 2020 13:07:03 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Xu", "Jing", ""], ["Zhong", "Fangwei", ""], ["Wang", "Yizhou", ""]]}, {"id": "2010.13438", "submitter": "Andrea Araldo", "authors": "Ado Adamou Abba Ari, Andrea Araldo, Andr\\'e De Palma, and Vincent\n  Gauthier", "title": "Pooling for First and Last Mile", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.CY cs.SY econ.GN eess.SY q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Carpooling is a system in which drivers accept to add some limited detours to\ntheir habitual journeys to pick-up and drop-off other riders. Most research and\noperating platforms present carpooling as an alternative to fixed schedule\ntransit and only very little work has attempted to integrate it with\nfixed-schedule mass transit. The aim of this paper is to showcase the benefits\nof such integration, under the philosophy of Mobility as a Service (MaaS), in a\ndaily commuting scenario. We present an integrated mass transit plus carpooling\nsystem that, by design, constructs multimodal trips, including transit and\ncarpooling legs. To this aim, the system generates vehicle detours in order to\nserve transit stations. We evaluate the performance of this system via\nsimulation. We compare the ``Current'' System, where carpooling is an\nalternative to transit, to our ``Integrated'' System, where carpooling and\ntransit are integrated in a single system. We show that, by doing this, the\ntransportation accessibility greatly increases: about 40\\% less users remain\nwithout feasible travel options and the overall travel time decreases by about\n10\\%. We achieve this by requiring relatively small driver detours, thanks to a\nbetter utilization vehicle routes, with drivers' vehicles driving on average\nwith more riders on board. The simulation code is available open source.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 09:18:21 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Ari", "Ado Adamou Abba", ""], ["Araldo", "Andrea", ""], ["De Palma", "Andr\u00e9", ""], ["Gauthier", "Vincent", ""]]}, {"id": "2010.13701", "submitter": "Sara Casao", "authors": "Sara Casao, Abel Naya, Ana C. Murillo, Eduardo Montijano", "title": "Distributed Multi-Target Tracking in Camera Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most recent works on multi-target tracking with multiple cameras focus on\ncentralized systems. In contrast, this paper presents a multi-target tracking\napproach implemented in a distributed camera network. The advantages of\ndistributed systems lie in lighter communication management, greater robustness\nto failures and local decision making. On the other hand, data association and\ninformation fusion are more challenging than in a centralized setup, mostly due\nto the lack of global and complete information. The proposed algorithm boosts\nthe benefits of the Distributed-Consensus Kalman Filter with the support of a\nre-identification network and a distributed tracker manager module to\nfacilitate consistent information. These techniques complement each other and\nfacilitate the cross-camera data association in a simple and effective manner.\nWe evaluate the whole system with known public data sets under different\nconditions demonstrating the advantages of combining all the modules. In\naddition, we compare our algorithm to some existing centralized tracking\nmethods, outperforming their behavior in terms of accuracy and bandwidth usage.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 16:34:53 GMT"}, {"version": "v2", "created": "Mon, 15 Mar 2021 16:32:16 GMT"}, {"version": "v3", "created": "Fri, 16 Apr 2021 17:57:21 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Casao", "Sara", ""], ["Naya", "Abel", ""], ["Murillo", "Ana C.", ""], ["Montijano", "Eduardo", ""]]}, {"id": "2010.13846", "submitter": "Reyhane Askari Hemmat", "authors": "Reyhane Askari Hemmat, Amartya Mitra, Guillaume Lajoie, Ioannis\n  Mitliagkas", "title": "LEAD: Least-Action Dynamics for Min-Max Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT cs.MA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial formulations such as generative adversarial networks (GANs) have\nrekindled interest in two-player min-max games. A central obstacle in the\noptimization of such games is the rotational dynamics that hinder their\nconvergence. Existing methods typically employ intuitive, carefully\nhand-designed mechanisms for controlling such rotations. In this paper, we take\na novel approach to address this issue by casting min-max optimization as a\nphysical system. We leverage tools from physics to introduce LEAD (Least-Action\nDynamics), a second-order optimizer for min-max games. Next, using Lyapunov\nstability theory and spectral analysis, we study LEAD's convergence properties\nin continuous and discrete-time settings for bilinear games to demonstrate\nlinear convergence to the Nash equilibrium. Finally, we empirically evaluate\nour method on synthetic setups and CIFAR-10 image generation to demonstrate\nimprovements over baseline methods.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 19:01:49 GMT"}, {"version": "v2", "created": "Fri, 19 Feb 2021 18:45:10 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Hemmat", "Reyhane Askari", ""], ["Mitra", "Amartya", ""], ["Lajoie", "Guillaume", ""], ["Mitliagkas", "Ioannis", ""]]}, {"id": "2010.13860", "submitter": "Sam Ganzfried", "authors": "Sam Ganzfried", "title": "Computing Nash Equilibria in Multiplayer DAG-Structured Stochastic Games\n  with Persistent Imperfect Information", "comments": "Added experimental results for a smaller game that demonstrate\n  algorithm convergence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.CR cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many important real-world settings contain multiple players interacting over\nan unknown duration with probabilistic state transitions, and are naturally\nmodeled as stochastic games. Prior research on algorithms for stochastic games\nhas focused on two-player zero-sum games, games with perfect information, and\ngames with imperfect-information that is local and does not extend between game\nstates. We present an algorithm for approximating Nash equilibrium in\nmultiplayer general-sum stochastic games with persistent imperfect information\nthat extends throughout game play. We experiment on a 4-player\nimperfect-information naval strategic planning scenario. Using a new procedure,\nwe are able to demonstrate that our algorithm computes a strategy that closely\napproximates Nash equilibrium in this game.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 19:27:26 GMT"}, {"version": "v2", "created": "Thu, 18 Feb 2021 02:38:24 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Ganzfried", "Sam", ""]]}, {"id": "2010.14391", "submitter": "Sai Qian Zhang", "authors": "Sai Qian Zhang, Jieyu Lin, Qi Zhang", "title": "Succinct and Robust Multi-Agent Communication With Temporal Message\n  Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have shown that introducing communication between agents can\nsignificantly improve overall performance in cooperative Multi-agent\nreinforcement learning (MARL). However, existing communication schemes often\nrequire agents to exchange an excessive number of messages at run-time under a\nreliable communication channel, which hinders its practicality in many\nreal-world situations. In this paper, we present \\textit{Temporal Message\nControl} (TMC), a simple yet effective approach for achieving succinct and\nrobust communication in MARL. TMC applies a temporal smoothing technique to\ndrastically reduce the amount of information exchanged between agents.\nExperiments show that TMC can significantly reduce inter-agent communication\noverhead without impacting accuracy. Furthermore, TMC demonstrates much better\nrobustness against transmission loss than existing approaches in lossy\nnetworking environments.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 15:55:08 GMT"}, {"version": "v2", "created": "Thu, 24 Dec 2020 23:04:40 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Zhang", "Sai Qian", ""], ["Lin", "Jieyu", ""], ["Zhang", "Qi", ""]]}, {"id": "2010.14443", "submitter": "Ufuk Topcu", "authors": "Ufuk Topcu, Nadya Bliss, Nancy Cooke, Missy Cummings, Ashley Llorens,\n  Howard Shrobe, and Lenore Zuck", "title": "Assured Autonomy: Path Toward Living With Autonomous Systems We Can\n  Trust", "comments": "A Computing Community Consortium (CCC) workshop report, 28 pages", "journal-ref": null, "doi": null, "report-no": "ccc2020report_5", "categories": "cs.CY cs.AI cs.HC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The challenge of establishing assurance in autonomy is rapidly attracting\nincreasing interest in the industry, government, and academia. Autonomy is a\nbroad and expansive capability that enables systems to behave without direct\ncontrol by a human operator. To that end, it is expected to be present in a\nwide variety of systems and applications. A vast range of industrial sectors,\nincluding (but by no means limited to) defense, mobility, health care,\nmanufacturing, and civilian infrastructure, are embracing the opportunities in\nautonomy yet face the similar barriers toward establishing the necessary level\nof assurance sooner or later. Numerous government agencies are poised to tackle\nthe challenges in assured autonomy.\n  Given the already immense interest and investment in autonomy, a series of\nworkshops on Assured Autonomy was convened to facilitate dialogs and increase\nawareness among the stakeholders in the academia, industry, and government.\nThis series of three workshops aimed to help create a unified understanding of\nthe goals for assured autonomy, the research trends and needs, and a strategy\nthat will facilitate sustained progress in autonomy.\n  The first workshop, held in October 2019, focused on current and anticipated\nchallenges and problems in assuring autonomous systems within and across\napplications and sectors. The second workshop held in February 2020, focused on\nexisting capabilities, current research, and research trends that could address\nthe challenges and problems identified in workshop. The third event was\ndedicated to a discussion of a draft of the major findings from the previous\ntwo workshops and the recommendations.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 17:00:01 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Topcu", "Ufuk", ""], ["Bliss", "Nadya", ""], ["Cooke", "Nancy", ""], ["Cummings", "Missy", ""], ["Llorens", "Ashley", ""], ["Shrobe", "Howard", ""], ["Zuck", "Lenore", ""]]}, {"id": "2010.14616", "submitter": "Zeyu Zhang", "authors": "Zeyu Zhang, Guisheng Yin", "title": "Lineage Evolution Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a general agent population learning system, and on this basis, we\npropose lineage evolution reinforcement learning algorithm. Lineage evolution\nreinforcement learning is a kind of derivative algorithm which accords with the\ngeneral agent population learning system. We take the agents in DQN and its\nrelated variants as the basic agents in the population, and add the selection,\nmutation and crossover modules in the genetic algorithm to the reinforcement\nlearning algorithm. In the process of agent evolution, we refer to the\ncharacteristics of natural genetic behavior, add lineage factor to ensure the\nretention of potential performance of agent, and comprehensively consider the\ncurrent performance and lineage value when evaluating the performance of agent.\nWithout changing the parameters of the original reinforcement learning\nalgorithm, lineage evolution reinforcement learning can optimize different\nreinforcement learning algorithms. Our experiments show that the idea of\nevolution with lineage improves the performance of original reinforcement\nlearning algorithm in some games in Atari 2600.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 11:58:16 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Zhang", "Zeyu", ""], ["Yin", "Guisheng", ""]]}, {"id": "2010.14908", "submitter": "Divya Thekke Kanapram", "authors": "Divya Thekke Kanapram, Fabio Patrone, Pablo Marin-Plaza, Mario\n  Marchese, Eliane L. Bodanese, Lucio Marcenaro, David Mart\\'in G\\'omez, Carlo\n  Regazzoni", "title": "Collective Awareness for Abnormality Detection in Connected Autonomous\n  Vehicles", "comments": "IEEE Internet of Things Journal", "journal-ref": null, "doi": "10.1109/JIOT.2020.2974680", "report-no": null, "categories": "cs.LG cs.MA eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advancements in connected and autonomous vehicles in these times demand\nthe availability of tools providing the agents with the capability to be aware\nand predict their own states and context dynamics. This article presents a\nnovel approach to develop an initial level of collective awareness in a network\nof intelligent agents. A specific collective self awareness functionality is\nconsidered, namely, agent centered detection of abnormal situations present in\nthe environment around any agent in the network. Moreover, the agent should be\ncapable of analyzing how such abnormalities can influence the future actions of\neach agent. Data driven dynamic Bayesian network (DBN) models learned from time\nseries of sensory data recorded during the realization of tasks (agent network\nexperiences) are here used for abnormality detection and prediction. A set of\nDBNs, each related to an agent, is used to allow the agents in the network to\neach synchronously aware possible abnormalities occurring when available models\nare used on a new instance of the task for which DBNs have been learned. A\ngrowing neural gas (GNG) algorithm is used to learn the node variables and\nconditional probabilities linking nodes in the DBN models; a Markov jump\nparticle filter (MJPF) is employed for state estimation and abnormality\ndetection in each agent using learned DBNs as filter parameters. Performance\nmetrics are discussed to asses the algorithms reliability and accuracy. The\nimpact is also evaluated by the communication channel used by the network to\nshare the data sensed in a distributed way by each agent of the network. The\nIEEE 802.11p protocol standard has been considered for communication among\nagents. Real data sets are also used acquired by autonomous vehicles performing\ndifferent tasks in a controlled environment.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 12:11:36 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Kanapram", "Divya Thekke", ""], ["Patrone", "Fabio", ""], ["Marin-Plaza", "Pablo", ""], ["Marchese", "Mario", ""], ["Bodanese", "Eliane L.", ""], ["Marcenaro", "Lucio", ""], ["G\u00f3mez", "David Mart\u00edn", ""], ["Regazzoni", "Carlo", ""]]}, {"id": "2010.15045", "submitter": "Javier Lopez Randulfe", "authors": "Javier Lopez Randulfe, Leon Bonde Larsen", "title": "A multi-agent model for growing spiking neural networks", "comments": "79 pages. Master's thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence has looked into biological systems as a source of\ninspiration. Although there are many aspects of the brain yet to be discovered,\nneuroscience has found evidence that the connections between neurons\ncontinuously grow and reshape as a part of the learning process. This differs\nfrom the design of Artificial Neural Networks, that achieve learning by\nevolving the weights in the synapses between them and their topology stays\nunaltered through time.\n  This project has explored rules for growing the connections between the\nneurons in Spiking Neural Networks as a learning mechanism. These rules have\nbeen implemented on a multi-agent system for creating simple logic functions,\nthat establish a base for building up more complex systems and architectures.\nResults in a simulation environment showed that for a given set of parameters\nit is possible to reach topologies that reproduce the tested functions.\n  This project also opens the door to the usage of techniques like genetic\nalgorithms for obtaining the best suited values for the model parameters, and\nhence creating neural networks that can adapt to different functions.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 15:11:29 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Randulfe", "Javier Lopez", ""], ["Larsen", "Leon Bonde", ""]]}, {"id": "2010.15441", "submitter": "Divya Thekke Kanapram", "authors": "Divya Thekke Kanapram, Pablo Marin-Plaza, Lucio Marcenaro, David\n  Martin, Arturo de la Escalera and Carlo Regazzoni", "title": "Self-awareness in intelligent vehicles: Feature based dynamic Bayesian\n  models for abnormality detection", "comments": null, "journal-ref": null, "doi": "10.1016/j.robot.2020.103652", "report-no": null, "categories": "cs.LG cs.MA eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The evolution of Intelligent Transportation Systems in recent times\nnecessitates the development of self-awareness in agents. Before the intensive\nuse of Machine Learning, the detection of abnormalities was manually programmed\nby checking every variable and creating huge nested conditions that are very\ndifficult to track. This paper aims to introduce a novel method to develop\nself-awareness in autonomous vehicles that mainly focuses on detecting abnormal\nsituations around the considered agents. Multi-sensory time-series data from\nthe vehicles are used to develop the data-driven Dynamic Bayesian Network (DBN)\nmodels used for future state prediction and the detection of dynamic\nabnormalities. Moreover, an initial level collective awareness model that can\nperform joint anomaly detection in co-operative tasks is proposed. The GNG\nalgorithm learns the DBN models' discrete node variables; probabilistic\ntransition links connect the node variables. A Markov Jump Particle Filter\n(MJPF) is applied to predict future states and detect when the vehicle is\npotentially misbehaving using learned DBNs as filter parameters. In this paper,\ndatasets from real experiments of autonomous vehicles performing various tasks\nused to learn and test a set of switching DBN models.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2020 09:29:47 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Kanapram", "Divya Thekke", ""], ["Marin-Plaza", "Pablo", ""], ["Marcenaro", "Lucio", ""], ["Martin", "David", ""], ["de la Escalera", "Arturo", ""], ["Regazzoni", "Carlo", ""]]}, {"id": "2010.15896", "submitter": "Kalesha Bullard", "authors": "Kalesha Bullard, Franziska Meier, Douwe Kiela, Joelle Pineau, and\n  Jakob Foerster", "title": "Exploring Zero-Shot Emergent Communication in Embodied Multi-Agent\n  Populations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective communication is an important skill for enabling information\nexchange and cooperation in multi-agent settings. Indeed, emergent\ncommunication is now a vibrant field of research, with common settings\ninvolving discrete cheap-talk channels. One limitation of this setting is that\nit does not allow for the emergent protocols to generalize beyond the training\npartners. Furthermore, so far emergent communication has primarily focused on\nthe use of symbolic channels. In this work, we extend this line of work to a\nnew modality, by studying agents that learn to communicate via actuating their\njoints in a 3D environment. We show that under realistic assumptions, a\nnon-uniform distribution of intents and a common-knowledge energy cost, these\nagents can find protocols that generalize to novel partners. We also explore\nand analyze specific difficulties associated with finding these solutions in\npractice. Finally, we propose and evaluate initial training improvements to\naddress these challenges, involving both specific training curricula and\nproviding the latent feature that can be coordinated on during training.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2020 19:23:10 GMT"}, {"version": "v2", "created": "Thu, 3 Dec 2020 07:45:05 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Bullard", "Kalesha", ""], ["Meier", "Franziska", ""], ["Kiela", "Douwe", ""], ["Pineau", "Joelle", ""], ["Foerster", "Jakob", ""]]}, {"id": "2010.16004", "submitter": "Martin Weiss", "authors": "Prateek Gupta, Tegan Maharaj, Martin Weiss, Nasim Rahaman, Hannah\n  Alsdurf, Abhinav Sharma, Nanor Minoyan, Soren Harnois-Leblanc, Victor\n  Schmidt, Pierre-Luc St. Charles, Tristan Deleu, Andrew Williams, Akshay\n  Patel, Meng Qu, Olexa Bilaniuk, Ga\\'etan Marceau Caron, Pierre Luc Carrier,\n  Satya Ortiz-Gagn\\'e, Marc-Andre Rousseau, David Buckeridge, Joumana Ghosn,\n  Yang Zhang, Bernhard Sch\\\"olkopf, Jian Tang, Irina Rish, Christopher Pal,\n  Joanna Merckx, Eilif B. Muller, Yoshua Bengio", "title": "COVI-AgentSim: an Agent-based Model for Evaluating Methods of Digital\n  Contact Tracing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG cs.MA cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid global spread of COVID-19 has led to an unprecedented demand for\neffective methods to mitigate the spread of the disease, and various digital\ncontact tracing (DCT) methods have emerged as a component of the solution. In\norder to make informed public health choices, there is a need for tools which\nallow evaluation and comparison of DCT methods. We introduce an agent-based\ncompartmental simulator we call COVI-AgentSim, integrating detailed\nconsideration of virology, disease progression, social contact networks, and\nmobility patterns, based on parameters derived from empirical research. We\nverify by comparing to real data that COVI-AgentSim is able to reproduce\nrealistic COVID-19 spread dynamics, and perform a sensitivity analysis to\nverify that the relative performance of contact tracing methods are consistent\nacross a range of settings. We use COVI-AgentSim to perform cost-benefit\nanalyses comparing no DCT to: 1) standard binary contact tracing (BCT) that\nassigns binary recommendations based on binary test results; and 2) a\nrule-based method for feature-based contact tracing (FCT) that assigns a graded\nlevel of recommendation based on diverse individual features. We find all DCT\nmethods consistently reduce the spread of the disease, and that the advantage\nof FCT over BCT is maintained over a wide range of adoption rates.\nFeature-based methods of contact tracing avert more disability-adjusted life\nyears (DALYs) per socioeconomic cost (measured by productive hours lost). Our\nresults suggest any DCT method can help save lives, support re-opening of\neconomies, and prevent second-wave outbreaks, and that FCT methods are a\npromising direction for enriching BCT using self-reported symptoms, yielding\nearlier warning signals and a significantly reduced spread of the virus per\nsocioeconomic cost.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 00:47:01 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Gupta", "Prateek", ""], ["Maharaj", "Tegan", ""], ["Weiss", "Martin", ""], ["Rahaman", "Nasim", ""], ["Alsdurf", "Hannah", ""], ["Sharma", "Abhinav", ""], ["Minoyan", "Nanor", ""], ["Harnois-Leblanc", "Soren", ""], ["Schmidt", "Victor", ""], ["Charles", "Pierre-Luc St.", ""], ["Deleu", "Tristan", ""], ["Williams", "Andrew", ""], ["Patel", "Akshay", ""], ["Qu", "Meng", ""], ["Bilaniuk", "Olexa", ""], ["Caron", "Ga\u00e9tan Marceau", ""], ["Carrier", "Pierre Luc", ""], ["Ortiz-Gagn\u00e9", "Satya", ""], ["Rousseau", "Marc-Andre", ""], ["Buckeridge", "David", ""], ["Ghosn", "Joumana", ""], ["Zhang", "Yang", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["Tang", "Jian", ""], ["Rish", "Irina", ""], ["Pal", "Christopher", ""], ["Merckx", "Joanna", ""], ["Muller", "Eilif B.", ""], ["Bengio", "Yoshua", ""]]}, {"id": "2010.16106", "submitter": "Justin Kottinger", "authors": "Justin Kottinger, Shaull Almagor, Morteza Lahijanian", "title": "MAPS-X: Explainable Multi-Robot Motion Planning via Segmentation", "comments": "To appear in International Conference on Robotics and Automation\n  (ICRA), May 2021. The document is 6 pages in length and contains 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional multi-robot motion planning (MMP) focuses on computing\ntrajectories for multiple robots acting in an environment, such that the robots\ndo not collide when the trajectories are taken simultaneously. In\nsafety-critical applications, a human supervisor may want to verify that the\nplan is indeed collision-free. In this work, we propose a notion of explanation\nfor a plan of MMP, based on visualization of the plan as a short sequence of\nimages representing time segments, where in each time segment the trajectories\nof the agents are disjoint, clearly illustrating the safety of the plan. We\nshow that standard notions of optimality (e.g., makespan) may create conflict\nwith short explanations. Thus, we propose meta-algorithms, namely multi-agent\nplan segmenting-X (MAPS-X) and its lazy variant, that can be plugged on\nexisting centralized sampling-based tree planners X to produce plans with good\nexplanations using a desirable number of images. We demonstrate the efficacy of\nthis explanation-planning scheme and extensively evaluate the performance of\nMAPS-X.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 07:28:36 GMT"}, {"version": "v2", "created": "Mon, 2 Nov 2020 06:44:53 GMT"}, {"version": "v3", "created": "Thu, 22 Apr 2021 16:34:29 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Kottinger", "Justin", ""], ["Almagor", "Shaull", ""], ["Lahijanian", "Morteza", ""]]}, {"id": "2010.16267", "submitter": "Wentong Liao", "authors": "Hao Cheng, Wentong Liao, Xuejiao Tang, Michael Ying Yang, Monika\n  Sester, Bodo Rosenhahn", "title": "Exploring Dynamic Context for Multi-path Trajectory Prediction", "comments": "accpeted by ICRA 2021, code available", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To accurately predict future positions of different agents in traffic\nscenarios is crucial for safely deploying intelligent autonomous systems in the\nreal-world environment. However, it remains a challenge due to the behavior of\na target agent being affected by other agents dynamically and there being more\nthan one socially possible paths the agent could take. In this paper, we\npropose a novel framework, named Dynamic Context Encoder Network (DCENet). In\nour framework, first, the spatial context between agents is explored by using\nself-attention architectures. Then, the two-stream encoders are trained to\nlearn temporal context between steps by taking the respective observed\ntrajectories and the extracted dynamic spatial context as input. The\nspatial-temporal context is encoded into a latent space using a Conditional\nVariational Auto-Encoder (CVAE) module. Finally, a set of future trajectories\nfor each agent is predicted conditioned on the learned spatial-temporal context\nby sampling from the latent space, repeatedly. DCENet is evaluated on one of\nthe most popular challenging benchmarks for trajectory forecasting Trajnet and\nreports a new state-of-the-art performance. It also demonstrates superior\nperformance evaluated on the benchmark inD for mixed traffic at intersections.\nA series of ablation studies is conducted to validate the effectiveness of each\nproposed module. Our code is available at https://github.com/wtliao/DCENet.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 13:39:20 GMT"}, {"version": "v2", "created": "Mon, 2 Nov 2020 11:41:38 GMT"}, {"version": "v3", "created": "Wed, 24 Mar 2021 10:28:47 GMT"}], "update_date": "2021-03-25", "authors_parsed": [["Cheng", "Hao", ""], ["Liao", "Wentong", ""], ["Tang", "Xuejiao", ""], ["Yang", "Michael Ying", ""], ["Sester", "Monika", ""], ["Rosenhahn", "Bodo", ""]]}]