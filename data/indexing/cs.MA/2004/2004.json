[{"id": "2004.00094", "submitter": "Bram Renting", "authors": "Bram M. Renting (1), Holger H. Hoos (2), Catholijn M. Jonker (1 and 2)\n  ((1) Delft University of Technology, (2) Leiden University)", "title": "Automated Configuration of Negotiation Strategies", "comments": "Appears in Proceedings of the 19th International Conference on\n  Autonomous Agents and Multiagent Systems (AAMAS 2020)", "journal-ref": "http://ifaamas.org/Proceedings/aamas2020/pdfs/p1116.pdf", "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bidding and acceptance strategies have a substantial impact on the outcome of\nnegotiations in scenarios with linear additive and nonlinear utility functions.\nOver the years, it has become clear that there is no single best strategy for\nall negotiation settings, yet many fixed strategies are still being developed.\nWe envision a shift in the strategy design question from: What is a good\nstrategy?, towards: What could be a good strategy? For this purpose, we\ndeveloped a method leveraging automated algorithm configuration to find the\nbest strategies for a specific set of negotiation settings. By empowering\nautomated negotiating agents using automated algorithm configuration, we obtain\na flexible negotiation agent that can be configured automatically for a rich\nspace of opponents and negotiation scenarios.\n  To critically assess our approach, the agent was tested in an ANAC-like\nbilateral automated negotiation tournament setting against past competitors. We\nshow that our automatically configured agent outperforms all other agents, with\na 5.1% increase in negotiation payoff compared to the next-best agent. We note\nthat without our agent in the tournament, the top-ranked agent wins by a margin\nof only 0.01%.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 20:31:33 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Renting", "Bram M.", "", "Delft University of Technology"], ["Hoos", "Holger H.", "", "Leiden University"], ["Jonker", "Catholijn M.", "", "1 and 2"]]}, {"id": "2004.00470", "submitter": "Jianyu Su", "authors": "Jianyu Su, Stephen Adams, and Peter A. Beling", "title": "Counterfactual Multi-Agent Reinforcement Learning with Graph Convolution\n  Communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a fully cooperative multi-agent system where agents cooperate to\nmaximize a system's utility in a partial-observable environment. We propose\nthat multi-agent systems must have the ability to (1) communicate and\nunderstand the inter-plays between agents and (2) correctly distribute rewards\nbased on an individual agent's contribution. In contrast, most work in this\nsetting considers only one of the above abilities. In this study, we develop an\narchitecture that allows for communication among agents and tailors the\nsystem's reward for each individual agent. Our architecture represents agent\ncommunication through graph convolution and applies an existing credit\nassignment structure, counterfactual multi-agent policy gradient (COMA), to\nassist agents to learn communication by back-propagation. The flexibility of\nthe graph structure enables our method to be applicable to a variety of\nmulti-agent systems, e.g. dynamic systems that consist of varying numbers of\nagents and static systems with a fixed number of agents. We evaluate our method\non a range of tasks, demonstrating the advantage of marrying communication with\ncredit assignment. In the experiments, our proposed method yields better\nperformance than the state-of-art methods, including COMA. Moreover, we show\nthat the communication strategies offers us insights and interpretability of\nthe system's cooperative policies.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 14:36:13 GMT"}, {"version": "v2", "created": "Tue, 29 Dec 2020 00:57:59 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Su", "Jianyu", ""], ["Adams", "Stephen", ""], ["Beling", "Peter A.", ""]]}, {"id": "2004.00603", "submitter": "Andrea Celli", "authors": "Andrea Celli, Alberto Marchesi, Gabriele Farina, Nicola Gatti", "title": "No-Regret Learning Dynamics for Extensive-Form Correlated Equilibrium", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The existence of simple, uncoupled no-regret dynamics that converge to\ncorrelated equilibria in normal-form games is a celebrated result in the theory\nof multi-agent systems. Specifically, it has been known for more than 20 years\nthat when all players seek to minimize their internal regret in a repeated\nnormal-form game, the empirical frequency of play converges to a normal-form\ncorrelated equilibrium. Extensive-form (that is, tree-form) games generalize\nnormal-form games by modeling both sequential and simultaneous moves, as well\nas private information. Because of the sequential nature and presence of\npartial information in the game, extensive-form correlation has significantly\ndifferent properties than the normal-form counterpart, many of which are still\nopen research directions. Extensive-form correlated equilibrium (EFCE) has been\nproposed as the natural extensive-form counterpart to normal-form correlated\nequilibrium. However, it was currently unknown whether EFCE emerges as the\nresult of uncoupled agent dynamics. In this paper, we give the first uncoupled\nno-regret dynamics that converge to the set of EFCEs in $n$-player general-sum\nextensive-form games with perfect recall. First, we introduce a notion of\ntrigger regret in extensive-form games, which extends that of internal regret\nin normal-form games. When each player has low trigger regret, the empirical\nfrequency of play is close to an EFCE. Then, we give an efficient\nno-trigger-regret algorithm. Our algorithm decomposes trigger regret into local\nsubproblems at each decision point for the player, and constructs a global\nstrategy of the player from the local solutions at each decision point.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 17:39:00 GMT"}, {"version": "v2", "created": "Thu, 2 Apr 2020 08:54:26 GMT"}, {"version": "v3", "created": "Thu, 9 Apr 2020 16:00:40 GMT"}, {"version": "v4", "created": "Sat, 20 Jun 2020 09:32:36 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Celli", "Andrea", ""], ["Marchesi", "Alberto", ""], ["Farina", "Gabriele", ""], ["Gatti", "Nicola", ""]]}, {"id": "2004.01031", "submitter": "Samuel Thiriot", "authors": "Samuel Thiriot, Jean-Daniel Kant", "title": "Generate Country-Scale Networks of Interaction from Scattered Statistics", "comments": "12 pages. arXiv admin note: substantial text overlap with\n  arXiv:2003.02213", "journal-ref": "in Proceedings of The Fifth Conference of the European Social\n  Simulation Association (ESSA'2008), Brescia, Italy", "doi": null, "report-no": null, "categories": "cs.MA cs.SI stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is common to define the structure of interactions among a population of\nagents by a network. Most of agent-based models were shown highly sensitive to\nthat network, so the relevance of simulation results directely depends on the\ndescriptive power of that network. When studying social dynamics in large\npopulations, that network cannot be collected, and is rather generated by\nalgorithms which aim to fit general properties of social networks. However,\nmore precise data is available at a country scale in the form of\nsocio-demographic studies, census or sociological studies. These \"scattered\nstatistics\" provide rich information, especially on agents' attributes, similar\nproperties of tied agents and affiliations. In this paper, we propose a generic\nmethodology to bring up together these scattered statistics with bayesian\nnetworks. We explain how to generate a population of heterogeneous agents, and\nhow to create links by using both scattered statistics and knowledge on social\nselection processes. The methodology is illustrated by generating an\ninteraction network for rural Kenya which includes familial structure,\ncolleagues and friendship constrained given field studies and statistics.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 14:38:40 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Thiriot", "Samuel", ""], ["Kant", "Jean-Daniel", ""]]}, {"id": "2004.01056", "submitter": "Luciano Cavalcante Siebert", "authors": "Luciano Cavalcante Siebert, Rijk Mercuur, Virginia Dignum, Jeroen van\n  den Hoven, Catholijn Jonker", "title": "Improving Confidence in the Estimation of Values and Norms", "comments": "16 pages, 3 figures, pre-print for the International Workshop on\n  Coordination, Organizations, Institutions, Norms and Ethics for Governance of\n  Multi-Agent Systems (COINE), co-located with AAMAS 2020", "journal-ref": null, "doi": "10.1007/978-3-030-72376-7_6", "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous agents (AA) will increasingly be interacting with us in our daily\nlives. While we want the benefits attached to AAs, it is essential that their\nbehavior is aligned with our values and norms. Hence, an AA will need to\nestimate the values and norms of the humans it interacts with, which is not a\nstraightforward task when solely observing an agent's behavior. This paper\nanalyses to what extent an AA is able to estimate the values and norms of a\nsimulated human agent (SHA) based on its actions in the ultimatum game. We\npresent two methods to reduce ambiguity in profiling the SHAs: one based on\nsearch space exploration and another based on counterfactual analysis. We found\nthat both methods are able to increase the confidence in estimating human\nvalues and norms, but differ in their applicability, the latter being more\nefficient when the number of interactions with the agent is to be minimized.\nThese insights are useful to improve the alignment of AAs with human values and\nnorms.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 15:03:03 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Siebert", "Luciano Cavalcante", ""], ["Mercuur", "Rijk", ""], ["Dignum", "Virginia", ""], ["Hoven", "Jeroen van den", ""], ["Jonker", "Catholijn", ""]]}, {"id": "2004.01097", "submitter": "Ivana Kaji\\'c", "authors": "Ivana Kaji\\'c, Eser Ayg\\\"un and Doina Precup", "title": "Learning to cooperate: Emergent communication in multi-agent navigation", "comments": "Accepted to CogSci 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emergent communication in artificial agents has been studied to understand\nlanguage evolution, as well as to develop artificial systems that learn to\ncommunicate with humans. We show that agents performing a cooperative\nnavigation task in various gridworld environments learn an interpretable\ncommunication protocol that enables them to efficiently, and in many cases,\noptimally, solve the task. An analysis of the agents' policies reveals that\nemergent signals spatially cluster the state space, with signals referring to\nspecific locations and spatial directions such as \"left\", \"up\", or \"upper left\nroom\". Using populations of agents, we show that the emergent protocol has\nbasic compositional structure, thus exhibiting a core property of natural\nlanguage.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 16:03:17 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 15:13:39 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Kaji\u0107", "Ivana", ""], ["Ayg\u00fcn", "Eser", ""], ["Precup", "Doina", ""]]}, {"id": "2004.01098", "submitter": "Weichao Mao", "authors": "Weichao Mao, Kaiqing Zhang, Erik Miehling, Tamer Ba\\c{s}ar", "title": "Information State Embedding in Partially Observable Cooperative\n  Multi-Agent Reinforcement Learning", "comments": "Accepted to CDC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-agent reinforcement learning (MARL) under partial observability has\nlong been considered challenging, primarily due to the requirement for each\nagent to maintain a belief over all other agents' local histories -- a domain\nthat generally grows exponentially over time. In this work, we investigate a\npartially observable MARL problem in which agents are cooperative. To enable\nthe development of tractable algorithms, we introduce the concept of an\ninformation state embedding that serves to compress agents' histories. We\nquantify how the compression error influences the resulting value functions for\ndecentralized control. Furthermore, we propose an instance of the embedding\nbased on recurrent neural networks (RNNs). The embedding is then used as an\napproximate information state, and can be fed into any MARL algorithm. The\nproposed embed-then-learn pipeline opens the black-box of existing (partially\nobservable) MARL algorithms, allowing us to establish some theoretical\nguarantees (error bounds of value functions) while still achieving competitive\nperformance with many end-to-end approaches.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 16:03:42 GMT"}, {"version": "v2", "created": "Sat, 18 Apr 2020 16:35:16 GMT"}, {"version": "v3", "created": "Mon, 17 Aug 2020 03:55:46 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Mao", "Weichao", ""], ["Zhang", "Kaiqing", ""], ["Miehling", "Erik", ""], ["Ba\u015far", "Tamer", ""]]}, {"id": "2004.01306", "submitter": "Aritra Mitra", "authors": "Shreyas Sundaram and Aritra Mitra", "title": "Distributed Hypothesis Testing and Social Learning in Finite Time with a\n  Finite Amount of Communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of distributed hypothesis testing (or social\nlearning) where a network of agents seeks to identify the true state of the\nworld from a finite set of hypotheses, based on a series of stochastic signals\nthat each agent receives. Prior work on this problem has provided distributed\nalgorithms that guarantee asymptotic learning of the true state, with\ncorresponding efforts to improve the rate of learning. In this paper, we first\nargue that one can readily modify existing asymptotic learning algorithms to\nenable learning in finite time, effectively yielding arbitrarily large\n(asymptotic) rates. We then provide a simple algorithm for finite-time learning\nwhich only requires the agents to exchange a binary vector (of length equal to\nthe number of possible hypotheses) with their neighbors at each time-step.\nFinally, we show that if the agents know the diameter of the network, our\nalgorithm can be further modified to allow all agents to learn the true state\nand stop transmitting to their neighbors after a finite number of time-steps.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 23:38:13 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Sundaram", "Shreyas", ""], ["Mitra", "Aritra", ""]]}, {"id": "2004.01534", "submitter": "Bla\\v{z} \\v{S}krlj", "authors": "Bla\\v{z} \\v{S}krlj and Benjamin Renoust", "title": "Layer entanglement in multiplex, temporal multiplex, and coupled\n  multilayer networks", "comments": "Accepted to ANS. arXiv admin note: text overlap with arXiv:1910.05300", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.MA cs.SI stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex networks, such as transportation networks, social networks, or\nbiological networks, capture the complex system they model often by\nrepresenting only one type of interactions. In real world systems, there may be\nmany different aspects that connect entities together. These can be captured\nusing multilayer networks, which combine different modalities of interactions\nin a single model. Coupling in multilayer networks may exhibit different\nproperties which can be related to the very nature of the data they model (or\nto events in time-dependant data). We hypothesise that such properties may be\nreflected in the way layers are intertwined. In this paper, we investigated\nthese through the prism of layer entanglement in coupled multilayer networks.\nWe test over 30 real-life networks in 6 different disciplines (social, genetic,\ntransport, co-authorship, trade, and neuronal networks). We further propose a\nrandom generator, displaying comparable patterns of elementary layer\nentanglement and transition coupling entanglement across 1,329,696 synthetic\ncoupled multilayer networks. Our experiments demonstrate difference of layer\nentanglement across disciplines, and even suggest a link between entanglement\nintensity and homophily. We additionally study entanglement in 3 real world\ntemporal datasets displaying a potential rise in entanglement activity prior to\nother network activity.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 17:11:34 GMT"}, {"version": "v2", "created": "Thu, 15 Oct 2020 08:03:01 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["\u0160krlj", "Bla\u017e", ""], ["Renoust", "Benjamin", ""]]}, {"id": "2004.01942", "submitter": "Stefan Vlaski", "authors": "Stefan Vlaski, Elsa Rizk, Ali H. Sayed", "title": "Tracking Performance of Online Stochastic Learners", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.MA eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The utilization of online stochastic algorithms is popular in large-scale\nlearning settings due to their ability to compute updates on the fly, without\nthe need to store and process data in large batches. When a constant step-size\nis used, these algorithms also have the ability to adapt to drifts in problem\nparameters, such as data or model properties, and track the optimal solution\nwith reasonable accuracy. Building on analogies with the study of adaptive\nfilters, we establish a link between steady-state performance derived under\nstationarity assumptions and the tracking performance of online learners under\nrandom walk models. The link allows us to infer the tracking performance from\nsteady-state expressions directly and almost by inspection.\n", "versions": [{"version": "v1", "created": "Sat, 4 Apr 2020 14:16:27 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Vlaski", "Stefan", ""], ["Rizk", "Elsa", ""], ["Sayed", "Ali H.", ""]]}, {"id": "2004.02166", "submitter": "Suman Banerjee", "authors": "Suman Banerjee", "title": "Designing and Connectivity Checking of Implicit Social Networks from the\n  User-Item Rating Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \\emph{Implicit Social Network} is a connected social structure among a group\nof persons, where two of them are linked if they have some common interest. One\nreal\\mbox{-}life example of such networks is the implicit social network among\nthe customers of an online commercial house, where there exists an edge between\ntwo customers if they like similar items. Such networks are often useful for\ndifferent commercial applications such as \\textit{target advertisement},\n\\textit{viral marketing}, etc. In this article, we study two fundamental\nproblems in this direction. The first one is that, given the user\\mbox{-}item\nrating data of an E\\mbox{-}Commerce house, how we can design implicit social\nnetworks among its users and the second one is at the time of designing itself\ncan we obtain the connectivity information among the users. Formally, we call\nthe first problem as the \\textsc{Implicit User Network Design} Problem and the\nsecond one as \\textsc{Implicit User Network Design with Connectivity Checking}\nProblem. For the first problem, we propose three different algorithms, namely\n\\emph{`Exhaustive Search Approach'}, \\emph{`Clique Addition Approach'}, and\n\\textit{`Matrix Multiplication\\mbox{-}Based Approach'}. For the second problem,\nwe propose two different approaches. The first one is the sequential approach:\ndesigning and then connectivity checking, and the other one is a concurrent\napproach, which is basically an incremental algorithm that performs designing\nand connectivity checking simultaneously. Proposed methodologies have\nexperimented with three publicly available rating network datasets such as\n\\emph{Flixter}, \\textit{Movielens}, and \\textit{Epinions}.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 11:44:51 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Banerjee", "Suman", ""]]}, {"id": "2004.02347", "submitter": "Yousef Emam", "authors": "Yousef Emam, Sean Wilson, Mathias Hakenberg, Ulrich Munz, Magnus\n  Egerstedt", "title": "A Receding Horizon Scheduling Approach for Search & Rescue Scenarios", "comments": "Accepted to IFAC World Congress 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many applications involving complex multi-task problems such as disaster\nrelief, logistics and manufacturing necessitate the deployment and coordination\nof heterogeneous multi-agent systems due to the sheer number of tasks that must\nbe executed simultaneously. A fundamental requirement for the successful\ncoordination of such systems is leveraging the specialization of each agent\nwithin the team. This work presents a Receding Horizon Planning (RHP) framework\naimed at scheduling tasks for heterogeneous multi-agent teams in a robust\nmanner. In order to allow for the modular addition and removal of different\ntypes of agents to the team, the proposed framework accounts for the\ncapabilities that each agent exhibits (e.g. quadrotors are agile and agnostic\nto rough terrain but are not suited to transport heavy payloads). An\ninstantiation of the proposed RHP is developed and tested for a search and\nrescue scenario. Moreover, we present an abstracted search and rescue\nsimulation environment, where a heterogeneous team of agents is deployed to\nsimultaneously explore the environment, find and rescue trapped victims, and\nextinguish spreading fires as quickly as possible. We validate the\neffectiveness of our approach through extensive simulations comparing the\npresented framework with various planning horizons to a greedy task allocation\nscheme.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 23:17:32 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Emam", "Yousef", ""], ["Wilson", "Sean", ""], ["Hakenberg", "Mathias", ""], ["Munz", "Ulrich", ""], ["Egerstedt", "Magnus", ""]]}, {"id": "2004.02350", "submitter": "Wesley Holliday", "authors": "Wesley H. Holliday and Eric Pacuit", "title": "Split Cycle: A New Condorcet Consistent Voting Method Independent of\n  Clones and Immune to Spoilers", "comments": "71 pages, 15 figures. Added a new explanation of Split Cycle in\n  Section 1, updated the caption to Figure 2, the discussion in Section 3.3,\n  and Remark 4.11, and strengthened Proposition 6.20 to Theorem 6.20 to cover\n  single-voter resolvability in addition to asymptotic resolvability. Thanks to\n  Nicolaus Tideman for helpful discussion", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.MA econ.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a Condorcet consistent voting method that we call Split Cycle.\nSplit Cycle belongs to the small family of known voting methods that\nsignificantly narrow the choice of winners in the presence of majority cycles\nwhile also satisfying independence of clones. In this family, only Split Cycle\nsatisfies a new criterion we call immunity to spoilers, which concerns adding\ncandidates to elections, as well as the known criteria of positive involvement\nand negative involvement, which concern adding voters to elections. Thus, in\ncontrast to other clone-independent methods, Split Cycle mitigates both\n\"spoiler effects\" and \"strong no show paradoxes.\"\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 23:20:17 GMT"}, {"version": "v2", "created": "Sun, 19 Apr 2020 22:10:58 GMT"}, {"version": "v3", "created": "Thu, 7 May 2020 19:07:46 GMT"}, {"version": "v4", "created": "Sun, 7 Jun 2020 19:35:23 GMT"}, {"version": "v5", "created": "Fri, 11 Sep 2020 02:14:52 GMT"}, {"version": "v6", "created": "Sun, 31 Jan 2021 07:04:20 GMT"}, {"version": "v7", "created": "Wed, 3 Mar 2021 22:56:09 GMT"}, {"version": "v8", "created": "Tue, 23 Mar 2021 18:55:03 GMT"}], "update_date": "2021-03-25", "authors_parsed": [["Holliday", "Wesley H.", ""], ["Pacuit", "Eric", ""]]}, {"id": "2004.02490", "submitter": "Bruno Yun", "authors": "Bruno Yun and Madalina Croitoru", "title": "Trust-based Multiagent Consensus or Weightings Aggregation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a framework for reaching a consensus amongst several agents\ncommunicating via a trust network on conflicting information about their\nenvironment. We formalise our approach and provide an empirical and theoretical\nanalysis of its properties.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 08:50:13 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Yun", "Bruno", ""], ["Croitoru", "Madalina", ""]]}, {"id": "2004.02494", "submitter": "Virginia Bordignon", "authors": "Virginia Bordignon, Vincenzo Matta, Ali H. Sayed", "title": "Adaptive Social Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.IT eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work proposes a novel strategy for social learning by introducing the\ncritical feature of adaptation. In social learning, several distributed agents\nupdate continually their belief about a phenomenon of interest through: i)\ndirect observation of streaming data that they gather locally; and ii)\ndiffusion of their beliefs through local cooperation with their neighbors.\nTraditional social learning implementations are known to learn well the\nunderlying hypothesis (which means that the belief of every individual agent\npeaks at the true hypothesis), achieving steady improvement in the learning\naccuracy under stationary conditions. However, these algorithms do not perform\nwell under nonstationary conditions commonly encountered in online learning,\nexhibiting a significant inertia to track drifts in the streaming data. In\norder to address this gap, we propose an Adaptive Social Learning (ASL)\nstrategy, which relies on a small step-size parameter to tune the adaptation\ndegree. First, we provide a detailed characterization of the learning\nperformance by means of a steady-state analysis. Focusing on the small\nstep-size regime, we establish that the ASL strategy achieves consistent\nlearning under standard global identifiability assumptions. We derive reliable\nGaussian approximations for the probability of error (i.e., of choosing a wrong\nhypothesis) at each individual agent. We carry out a large deviations analysis\nrevealing the universal behavior of adaptive social learning: the error\nprobabilities decrease exponentially fast with the inverse of the step-size,\nand we characterize the resulting exponential learning rate. Second, we\ncharacterize the adaptation performance by means of a detailed transient\nanalysis, which allows us to obtain useful analytical formulas relating the\nadaptation time to the step-size.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 08:55:37 GMT"}, {"version": "v2", "created": "Mon, 26 Jul 2021 08:24:44 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Bordignon", "Virginia", ""], ["Matta", "Vincenzo", ""], ["Sayed", "Ali H.", ""]]}, {"id": "2004.02575", "submitter": "Andreasa Morris-Martin", "authors": "Andreasa Morris-Martin and Marina De Vos and Julian Padget", "title": "A Norm Emergence Framework for Normative MAS -- Position Paper", "comments": "16 pages, 2 figures, pre-print for International Workshop on\n  Coordination, Organizations, Institutions, Norms and Ethics for Governance of\n  Multi-Agent Systems (COINE), co-located with AAMAS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Norm emergence is typically studied in the context of multiagent systems\n(MAS) where norms are implicit, and participating agents use simplistic\ndecision-making mechanisms. These implicit norms are usually unconsciously\nshared and adopted through agent interaction. A norm is deemed to have emerged\nwhen a threshold or predetermined percentage of agents follow the \"norm\".\nConversely, in normative MAS, norms are typically explicit and agents\ndeliberately share norms through communication or are informed about norms by\nan authority, following which an agent decides whether to adopt the norm or\nnot. The decision to adopt a norm by the agent can happen immediately after\nrecognition or when an applicable situation arises. In this paper, we make the\ncase that, similarly, a norm has emerged in a normative MAS when a percentage\nof agents adopt the norm. Furthermore, we posit that agents themselves can and\nshould be involved in norm synthesis, and hence influence the norms governing\nthe MAS, in line with Ostrom's eight principles. Consequently, we put forward a\nframework for the emergence of norms within a normative MAS, that allows\nparticipating agents to propose/request changes to the normative system, while\nspecial-purpose synthesizer agents formulate new norms or revisions in response\nto these requests. Synthesizers must collectively agree that the new norm or\nnorm revision should proceed, and then finally be approved by an \"Oracle\". The\nnormative system is then modified to incorporate the norm.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 11:42:01 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Morris-Martin", "Andreasa", ""], ["De Vos", "Marina", ""], ["Padget", "Julian", ""]]}, {"id": "2004.02764", "submitter": "Elif Surer", "authors": "Medet Kanmaz and Elif Surer", "title": "Using Multi-Agent Reinforcement Learning in Auction Simulations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Game theory has been developed by scientists as a theory of strategic\ninteraction among players who are supposed to be perfectly rational. These\nstrategic interactions might have been presented in an auction, a business\nnegotiation, a chess game, or even in a political conflict aroused between\ndifferent agents. In this study, the strategic (rational) agents created by\nreinforcement learning algorithms are supposed to be bidder agents in various\ntypes of auction mechanisms such as British Auction, Sealed Bid Auction, and\nVickrey Auction designs. Next, the equilibrium points determined by the agents\nare compared with the outcomes of the Nash equilibrium points for these\nenvironments. The bidding strategy of the agents is analyzed in terms of\nindividual rationality, truthfulness (strategy-proof), and computational\nefficiency. The results show that using a multi-agent reinforcement learning\nstrategy improves the outcomes of the auction simulations.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 15:48:28 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Kanmaz", "Medet", ""], ["Surer", "Elif", ""]]}, {"id": "2004.02780", "submitter": "Rishi Hazra", "authors": "Shubham Gupta, Rishi Hazra, Ambedkar Dukkipati", "title": "Networked Multi-Agent Reinforcement Learning with Emergent Communication", "comments": "An abridged version of this paper has been accepted as a short paper\n  at AAMAS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-Agent Reinforcement Learning (MARL) methods find optimal policies for\nagents that operate in the presence of other learning agents. Central to\nachieving this is how the agents coordinate. One way to coordinate is by\nlearning to communicate with each other. Can the agents develop a language\nwhile learning to perform a common task? In this paper, we formulate and study\na MARL problem where cooperative agents are connected to each other via a fixed\nunderlying network. These agents can communicate along the edges of this\nnetwork by exchanging discrete symbols. However, the semantics of these symbols\nare not predefined and, during training, the agents are required to develop a\nlanguage that helps them in accomplishing their goals. We propose a method for\ntraining these agents using emergent communication. We demonstrate the\napplicability of the proposed framework by applying it to the problem of\nmanaging traffic controllers, where we achieve state-of-the-art performance as\ncompared to a number of strong baselines. More importantly, we perform a\ndetailed analysis of the emergent communication to show, for instance, that the\ndeveloped language is grounded and demonstrate its relationship with the\nunderlying network topology. To the best of our knowledge, this is the only\nwork that performs an in depth analysis of emergent communication in a\nnetworked MARL setting while being applicable to a broad class of problems.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 16:13:23 GMT"}, {"version": "v2", "created": "Thu, 9 Apr 2020 04:14:14 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Gupta", "Shubham", ""], ["Hazra", "Rishi", ""], ["Dukkipati", "Ambedkar", ""]]}, {"id": "2004.03050", "submitter": "David Grimsman", "authors": "David Grimsman, Matthew R. Kirchner, Jo\\~ao P. Hespanha, Jason R.\n  Marden", "title": "The Impact of Message Passing in Agent-Based Submodular Maximization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.DS cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Submodular maximization problems are a relevant model set for many real-world\napplications. Since these problems are generally NP-Hard, many methods have\nbeen developed to approximate the optimal solution in polynomial time. One such\napproach uses an agent-based greedy algorithm, where the goal is for each agent\nto choose an action from its action set such that the union of all actions\nchosen is as high-valued as possible. Recent work has shown how the performance\nof the greedy algorithm degrades as the amount of information shared among the\nagents decreases, whereas this work addresses the scenario where agents are\ncapable of sharing more information than allowed in the greedy algorithm.\nSpecifically, we show how performance guarantees increase as agents are capable\nof passing messages, which can augment the allowable decision set for each\nagent. Under these circumstances, we show a near-optimal method for message\npassing, and how much such an algorithm could increase performance for any\ngiven problem instance.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 00:24:55 GMT"}, {"version": "v2", "created": "Mon, 14 Sep 2020 23:21:06 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Grimsman", "David", ""], ["Kirchner", "Matthew R.", ""], ["Hespanha", "Jo\u00e3o P.", ""], ["Marden", "Jason R.", ""]]}, {"id": "2004.03053", "submitter": "Yeping Hu", "authors": "Yeping Hu, Wei Zhan, and Masayoshi Tomizuka", "title": "Scenario-Transferable Semantic Graph Reasoning for Interaction-Aware\n  Probabilistic Prediction", "comments": "17 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurately predicting the possible behaviors of traffic participants is an\nessential capability for autonomous vehicles. Since autonomous vehicles need to\nnavigate in dynamically changing environments, they are expected to make\naccurate predictions regardless of where they are and what driving\ncircumstances they encountered. A number of methodologies have been proposed to\nsolve prediction problems under different traffic situations. However, these\nworks either focus on one particular driving scenario (e.g. highway,\nintersection, or roundabout) or do not take sufficient environment information\n(e.g. road topology, traffic rules, and surrounding agents) into account. In\nfact, the limitation to certain scenario is mainly due to the lackness of\ngeneric representations of the environment. The insufficiency of environment\ninformation further limits the flexibility and transferability of the\npredictor. In this paper, we propose a scenario-transferable and\ninteraction-aware probabilistic prediction algorithm based on semantic graph\nreasoning. We first introduce generic representations for both static and\ndynamic elements in driving environments. Then these representations are\nutilized to describe semantic goals for selected agents and incorporate them\ninto spatial-temporal structures. Finally, we reason internal relations among\nthese structured semantic representations using learning-based method and\nobtain prediction results. The proposed algorithm is thoroughly examined under\nseveral complicated real-world driving scenarios to demonstrate its flexibility\nand transferability, where the predictor can be directly used under unforeseen\ndriving circumstances with different static and dynamic information.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 00:34:36 GMT"}, {"version": "v2", "created": "Thu, 25 Feb 2021 02:56:58 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Hu", "Yeping", ""], ["Zhan", "Wei", ""], ["Tomizuka", "Masayoshi", ""]]}, {"id": "2004.03725", "submitter": "Majid Mazouchi", "authors": "Majid Mazouchi, Farzaneh Tatari, Bahare Kiumarsi, Hamidreza Modares", "title": "Fully-Heterogeneous Containment Control of a Network of Leader-Follower\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops a distributed solution to the fully-heterogeneous\ncontainment control problem (CCP), for which not only the followers' dynamics\nbut also the leaders' dynamics are non-identical. A novel formulation of the\nfully-heterogeneous CCP is first presented in which each follower constructs\nits virtual exo-system. To build these virtual exo-systems by followers, a\nnovel distributed algorithm is developed to calculate the so-called normalized\nlevel of influences (NLIs) of all leaders on each follower and a novel adaptive\ndistributed observer is designed to estimate the dynamics and states of all\nleaders that have an influence on each follower. Then, a distributed control\nprotocol is proposed based on the cooperative output regulation framework,\nutilizing this virtual exo-system. Based on estimations of leaders' dynamics\nand states and NLIs of leaders on each follower, the solutions of the so-called\nlinear regulator equations are calculated in a distributed manner, and\nconsequently, a distributed control protocol is designed for solving the output\ncontainment problem. Finally, theoretical results are verified by performing\nnumerical simulations.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 21:53:54 GMT"}, {"version": "v2", "created": "Sun, 25 Apr 2021 01:21:56 GMT"}, {"version": "v3", "created": "Wed, 9 Jun 2021 23:30:25 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Mazouchi", "Majid", ""], ["Tatari", "Farzaneh", ""], ["Kiumarsi", "Bahare", ""], ["Modares", "Hamidreza", ""]]}, {"id": "2004.04003", "submitter": "Suman Banerjee", "authors": "Suman Banerjee, Mamata Jenamani, Dilip Kumar Pratihar", "title": "Earned Benefit Maximization in Social Networks Under Budget Constraint", "comments": "12 Pages, 16 Figures, Submitted to a Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.DS cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a social network with nonuniform selection cost of the users, the\nproblem of \\textit{Budgeted Influence Maximization} (BIM in short) asks for\nselecting a subset of the nodes within an allocated budget for initial\nactivation, such that due to the cascading effect, influence in the network is\nmaximized. In this paper, we study this problem with a variation, where a set\nof nodes are designated as target nodes, each of them is assigned with a\nbenefit value, that can be earned by influencing them, and our goal is to\nmaximize the earned benefit by initially activating a set of nodes within the\nbudget. We call this problem as the \\textsc{Earned Benefit Maximization\nProblem}. First, we show that this problem is NP\\mbox{-}Hard and the benefit\nfunction is \\textit{monotone}, \\textit{sub\\mbox{-}modular} under the\n\\textit{Independent Cascade Model} of diffusion. We propose an incremental\ngreedy strategy for this problem and show, with minor modification it gives\n$(1-\\frac{1}{\\sqrt{e}})$\\mbox{-}factor approximation guarantee on the earned\nbenefit. Next, by exploiting the sub\\mbox{-}modularity property of the benefit\nfunction, we improve the efficiency of the proposed greedy algorithm. Then, we\npropose a hop\\mbox{-}based heuristic method, which works based on the\ncomputation of the `expected earned benefit' of the effective neighbors\ncorresponding to the target nodes. Finally, we perform a series of extensive\nexperiments with four real\\mbox{-}life, publicly available social network\ndatasets. From the experiments, we observe that the seed sets selected by the\nproposed algorithms can achieve more benefit compared to many existing methods.\nParticularly, the hop\\mbox{-}based approach is found to be more efficient than\nthe other ones for solving this problem.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 14:19:37 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Banerjee", "Suman", ""], ["Jenamani", "Mamata", ""], ["Pratihar", "Dilip Kumar", ""]]}, {"id": "2004.04222", "submitter": "Alexandru Topirceanu", "authors": "Alexandru Topirceanu, Mihai Udrescu, Radu Marculescu", "title": "Centralized and decentralized isolation strategies and their impact on\n  the COVID-19 pandemic dynamics", "comments": "18 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE cs.MA cs.SI physics.soc-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The infectious diseases are spreading due to human interactions enabled by\nvarious social networks. Therefore, when a new pathogen such as SARS-CoV-2\ncauses an outbreak, the non-pharmaceutical isolation strategies (e.g., social\ndistancing) are the only possible response to disrupt its spreading. To this\nend, we introduce the new epidemic model (SICARS) and compare the centralized\n(C), decentralized (D), and combined (C+D) social distancing strategies, and\nanalyze their efficiency to control the dynamics of COVID-19 on heterogeneous\ncomplex networks. Our analysis shows that the centralized social distancing is\nnecessary to minimize the pandemic spreading. The decentralized strategy is\ninsufficient when used alone, but offers the best results when combined with\nthe centralized one. Indeed, the (C+D) is the most efficient isolation strategy\nat mitigating the network superspreaders and reducing the highest node degrees\nto less than 10% of their initial values. Our results also indicate that\nstronger social distancing, e.g., cutting 75% of social ties, can reduce the\noutbreak by 75% for the C isolation, by 33% for the D isolation, and by 87% for\nthe (C+D) isolation strategy. Finally, we study the impact of proactive versus\nreactive isolation strategies, as well as their delayed enforcement. We find\nthat the reactive response to the pandemic is less efficient, and delaying the\nadoption of isolation measures by over one month (since the outbreak onset in a\nregion) can have alarming effects; thus, our study contributes to an\nunderstanding of the COVID-19 pandemic both in space and time. We believe our\ninvestigations have a high social relevance as they provide insights into\nunderstanding how different degrees of social distancing can reduce the peak\ninfection ratio substantially; this can make the COVID-19 pandemic easier to\nunderstand and control over an extended period of time.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 19:48:12 GMT"}, {"version": "v2", "created": "Fri, 10 Apr 2020 13:16:29 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Topirceanu", "Alexandru", ""], ["Udrescu", "Mihai", ""], ["Marculescu", "Radu", ""]]}, {"id": "2004.04722", "submitter": "Paul Van Eecke", "authors": "Paul Van Eecke (1 and 2), Katrien Beuls (1) ((1) Artificial\n  Intelligence Laboratory, Vrije Universiteit Brussel, Brussels, Belgium, (2)\n  ITEC, imec research group at KU Leuven, Kortrijk, Belgium)", "title": "Re-conceptualising the Language Game Paradigm in the Framework of\n  Multi-Agent Reinforcement Learning", "comments": "This paper was accepted for presentation at the 2020 AAAI Spring\n  Symposium `Challenges and Opportunities for Multi-Agent Reinforcement\n  Learning' after a double-blind reviewing process", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we formulate the challenge of re-conceptualising the language\ngame experimental paradigm in the framework of multi-agent reinforcement\nlearning (MARL). If successful, future language game experiments will benefit\nfrom the rapid and promising methodological advances in the MARL community,\nwhile future MARL experiments on learning emergent communication will benefit\nfrom the insights and results gained from language game experiments. We\nstrongly believe that this cross-pollination has the potential to lead to major\nbreakthroughs in the modelling of how human-like languages can emerge and\nevolve in multi-agent systems.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 17:55:15 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Van Eecke", "Paul", "", "1 and 2"], ["Beuls", "Katrien", ""]]}, {"id": "2004.04778", "submitter": "Lucas N. Alegre", "authors": "Lucas N. Alegre, Ana L. C. Bazzan, Bruno C. da Silva", "title": "Quantifying the Impact of Non-Stationarity in Reinforcement\n  Learning-Based Traffic Signal Control", "comments": "13 pages", "journal-ref": "PeerJ Computer Science 2021", "doi": "10.7717/peerj-cs.575", "report-no": "7:e575", "categories": "cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In reinforcement learning (RL), dealing with non-stationarity is a\nchallenging issue. However, some domains such as traffic optimization are\ninherently non-stationary. Causes for and effects of this are manifold. In\nparticular, when dealing with traffic signal controls, addressing\nnon-stationarity is key since traffic conditions change over time and as a\nfunction of traffic control decisions taken in other parts of a network. In\nthis paper we analyze the effects that different sources of non-stationarity\nhave in a network of traffic signals, in which each signal is modeled as a\nlearning agent. More precisely, we study both the effects of changing the\n\\textit{context} in which an agent learns (e.g., a change in flow rates\nexperienced by it), as well as the effects of reducing agent observability of\nthe true environment state. Partial observability may cause distinct states (in\nwhich distinct actions are optimal) to be seen as the same by the traffic\nsignal agents. This, in turn, may lead to sub-optimal performance. We show that\nthe lack of suitable sensors to provide a representative observation of the\nreal state seems to affect the performance more drastically than the changes to\nthe underlying traffic patterns.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 19:20:43 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Alegre", "Lucas N.", ""], ["Bazzan", "Ana L. C.", ""], ["da Silva", "Bruno C.", ""]]}, {"id": "2004.04843", "submitter": "Sujay Bhatt", "authors": "Sujay Bhatt, Alec Koppel, Vikram Krishnamurthy", "title": "Policy Gradient using Weak Derivatives for Reinforcement Learning", "comments": "1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA cs.SY eess.SY math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers policy search in continuous state-action reinforcement\nlearning problems. Typically, one computes search directions using a classic\nexpression for the policy gradient called the Policy Gradient Theorem, which\ndecomposes the gradient of the value function into two factors: the score\nfunction and the Q-function. This paper presents four results:(i) an\nalternative policy gradient theorem using weak (measure-valued) derivatives\ninstead of score-function is established; (ii) the stochastic gradient\nestimates thus derived are shown to be unbiased and to yield algorithms that\nconverge almost surely to stationary points of the non-convex value function of\nthe reinforcement learning problem; (iii) the sample complexity of the\nalgorithm is derived and is shown to be $O(1/\\sqrt(k))$; (iv) finally, the\nexpected variance of the gradient estimates obtained using weak derivatives is\nshown to be lower than those obtained using the popular score-function\napproach. Experiments on OpenAI gym pendulum environment show superior\nperformance of the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 23:05:18 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Bhatt", "Sujay", ""], ["Koppel", "Alec", ""], ["Krishnamurthy", "Vikram", ""]]}, {"id": "2004.05205", "submitter": "Christoforos Mavrogiannis", "authors": "Christoforos Mavrogiannis, Jonathan A. DeCastro, Siddhartha S.\n  Srinivasa", "title": "Implicit Multiagent Coordination at Unsignalized Intersections via\n  Multimodal Inference Enabled by Topological Braids", "comments": "16 pages, 13 figures, new experiments, new explanatory figures for\n  intuition and new title", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.MA cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on navigation among rational, non-communicating agents at\nunsignalized street intersections. Following collision-free motion under such\nsettings demands nuanced implicit coordination among agents. Often, the\nstructure of these domains constrains multiagent trajectories to belong to a\nfinite set of modes. Our key insight is that empowering agents with a model of\nthese modes can enable effective coordination, realized implicitly via intent\nsignals encoded in agents' actions. In this paper, we represent modes of joint\nbehavior in a compact and interpretable fashion using the formalism of\ntopological braids. We design a decentralized planning algorithm that generates\nactions aimed at reducing the uncertainty over the mode of the emerging\nmultiagent behavior. This mechanism enables agents that individually run our\nalgorithm to collectively reject unsafe intersection crossings. We validate our\napproach in a simulated case study featuring challenging multiagent scenarios\nat a four-way unsignalized intersection. Our model is shown to reduce frequency\nof collisions by >65% over a set of baselines explicitly reasoning over\ntrajectories, while maintaining comparable time efficiency.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 19:01:29 GMT"}, {"version": "v2", "created": "Sat, 8 Aug 2020 00:39:09 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Mavrogiannis", "Christoforos", ""], ["DeCastro", "Jonathan A.", ""], ["Srinivasa", "Siddhartha S.", ""]]}, {"id": "2004.05273", "submitter": "Mohammad Javad Khojasteh", "authors": "Richard Cheng, Mohammad Javad Khojasteh, Aaron D. Ames, and Joel W.\n  Burdick", "title": "Safe Multi-Agent Interaction through Robust Control Barrier Functions\n  with Learned Uncertainties", "comments": null, "journal-ref": "59th IEEE Conference on Decision and Control (CDC 2020)", "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.MA cs.SY eess.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robots operating in real world settings must navigate and maintain safety\nwhile interacting with many heterogeneous agents and obstacles. Multi-Agent\nControl Barrier Functions (CBF) have emerged as a computationally efficient\ntool to guarantee safety in multi-agent environments, but they assume perfect\nknowledge of both the robot dynamics and other agents' dynamics. While\nknowledge of the robot's dynamics might be reasonably well known, the\nheterogeneity of agents in real-world environments means there will always be\nconsiderable uncertainty in our prediction of other agents' dynamics. This work\naims to learn high-confidence bounds for these dynamic uncertainties using\nMatrix-Variate Gaussian Process models, and incorporates them into a robust\nmulti-agent CBF framework. We transform the resulting min-max robust CBF into a\nquadratic program, which can be efficiently solved in real time. We verify via\nsimulation results that the nominal multi-agent CBF is often violated during\nagent interactions, whereas our robust formulation maintains safety with a much\nhigher probability and adapts to learned uncertainties\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 00:56:36 GMT"}, {"version": "v2", "created": "Tue, 22 Sep 2020 18:37:44 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Cheng", "Richard", ""], ["Khojasteh", "Mohammad Javad", ""], ["Ames", "Aaron D.", ""], ["Burdick", "Joel W.", ""]]}, {"id": "2004.05935", "submitter": "Suman Banerjee", "authors": "Suman Banerjee and Bithika Pal", "title": "First Stretch then Shrink and Bulk: A Two Phase Approach for Enumeration\n  of Maximal $(\\Delta, \\gamma)$\\mbox{-}Cliques of a Temporal Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DB cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A \\emph{Temporal Network} (also known as \\emph{Link Stream} or\n\\emph{Time-Varying Graph}) is often used to model a time-varying relationship\namong a group of agents. It is typically represented as a collection of\ntriplets of the form $(u,v,t)$ that denotes the interaction between the agents\n$u$ and $v$ at time $t$. For analyzing the contact patterns of the agents\nforming a temporal network, recently the notion of classical \\textit{clique} of\na \\textit{static graph} has been generalized as \\textit{$\\Delta$\\mbox{-}Clique}\nof a Temporal Network. In the same direction, one of our previous studies\nintroduces the notion of \\textit{$(\\Delta, \\gamma)$\\mbox{-}Clique}, which is\nbasically a \\textit{vertex set}, \\textit{time interval} pair, in which every\npair of the clique vertices are linked at least $\\gamma$ times in every\n$\\Delta$ duration of the time interval. In this paper, we propose a different\nmethodology for enumerating all the maximal $(\\Delta, \\gamma)$\\mbox{-}Cliques\nof a given temporal network. The proposed methodology is broadly divided into\ntwo phases. In the first phase, each temporal link is processed for\nconstructing $(\\Delta, \\gamma)$\\mbox{-}Clique(s) with maximum duration. In the\nsecond phase, these initial cliques are expanded by vertex addition to form the\nmaximal cliques. From the experimentation carried out on $5$ real\\mbox{-}world\ntemporal network datasets, we observe that the proposed methodology enumerates\nall the maximal $(\\Delta,\\gamma)$\\mbox{-}Cliques efficiently, particularly when\nthe dataset is sparse. As a special case ($\\gamma=1$), the proposed methodology\nis also able to enumerate $(\\Delta,1) \\equiv \\Delta$\\mbox{-}cliques with much\nless time compared to the existing methods.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 18:42:47 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Banerjee", "Suman", ""], ["Pal", "Bithika", ""]]}, {"id": "2004.06004", "submitter": "Paulin Jacquot Dr", "authors": "Paulin Jacquot", "title": "DLMP-based Coordination Procedure for Decentralized Demand Response\n  under Distribution Network Constraints", "comments": "25pages. Update theoretical proof of convergence of primal-dual\n  Gauss-Seidel iterative algo, add a Mechanism design discussion over the\n  proposed DLMP-based mechanism; add numerical results for ADMM and primal-dual\n  GS convergence", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Load aggregators are independent private entities whose goal is to optimize\nenergy consumption flexibilities offered by multiple residential consumers.\n  Although aggregators optimize their decisions in a decentralized way, they\nare indirectly linked together if their respective consumers belong to the same\ndistribution grid.\n  This is an important issue for a distribution system operator (DSO), in\ncharge of the reliability of the distribution network, it has to ensure that\ndecentralized decisions taken do not violate the grid constraints and do not\nincrease the global system costs.\n  From the information point of view,the network state and characteristics are\nconfidential to the DSO, which makes a decentralized solution even more\nrelevant.\n  To address this issue, we propose a decentralized coordination mechanism\nbetween the DSO and multiple aggregators that computes the optimal demand\nresponse profiles while solving the optimal power flow problem. The procedure,\nbased on distribution locational marginal prices (DLMP), preserves the\ndecentralized structure of information and decisions, and lead to a feasible\nand optimal solution for both the aggregators and the DSO.\n  The procedure is analyzed from a mechanism design perspective, and different\ndecentralized methods that could be used to implement this procedure are\npresented.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 15:23:53 GMT"}, {"version": "v2", "created": "Thu, 27 Aug 2020 14:46:03 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Jacquot", "Paulin", ""]]}, {"id": "2004.06135", "submitter": "S. Bai", "authors": "S. Bai", "title": "An agent-based negotiation model and its implementation in Repast", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an agent-based model, MNegoti, for simulating multilateral\nnegotiation process, which can be naturally employed in group decision support\nsystem. This model can also be applied to any use case in which negotiation is\ninvolved, in order to simulate the negotiation process. In this report, we\ndiscuss the implementation of the MNegoti model on the basis of the agent-based\nsimulation platform, Repast Simphony. It is worth pointing out that this model\ncan be used to create a java module for any use of agent-based negotiation\nsimulation.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 18:07:52 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Bai", "S.", ""]]}, {"id": "2004.06277", "submitter": "Peter Vamplew", "authors": "Peter Vamplew, Cameron Foale and Richard Dazeley", "title": "A Demonstration of Issues with Value-Based Multiobjective Reinforcement\n  Learning Under Stochastic State Transitions", "comments": "6 pages. Accepted for presentation in the Adaptive and Learning\n  Agents Workshop, AAMAS 2020", "journal-ref": "The impact of environmental stochasticity on value-based\n  multiobjective reinforcement learning, Neural Computing and Applications,\n  2021", "doi": "10.1007/s00521-021-05859-1", "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report a previously unidentified issue with model-free, value-based\napproaches to multiobjective reinforcement learning in the context of\nenvironments with stochastic state transitions. An example multiobjective\nMarkov Decision Process (MOMDP) is used to demonstrate that under such\nconditions these approaches may be unable to discover the policy which\nmaximises the Scalarised Expected Return, and in fact may converge to a\nPareto-dominated solution. We discuss several alternative methods which may be\nmore suitable for maximising SER in MOMDPs with stochastic transitions.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 02:55:12 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Vamplew", "Peter", ""], ["Foale", "Cameron", ""], ["Dazeley", "Richard", ""]]}, {"id": "2004.06533", "submitter": "Charles Monnoyer de Galland de Carni\\`eres", "authors": "Charles Monnoyer de Galland and Julien M. Hendrickx", "title": "Fundamental Performance Limitations for Average Consensus in Open\n  Multi-Agent Systems", "comments": "14 pages, 9 figures, submitted to IEEE Transactions on Automatic\n  Control", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive fundamental performance limitations for intrinsic average consensus\nproblems in open multi-agent systems, which are systems subject to frequent\narrivals and departures of agents. Each agent holds a value, and the objective\nof the agents is to collaboratively estimate the average of the values of the\nagents presently in the system. Algorithms solving such problems in open\nsystems are poised to never converge because of the permanent variations in the\ncomposition, size and objective pursued by the agents of the system. We provide\nlower bounds on the expected Mean Square Error of averaging algorithms in open\nsystems of fixed size. Our derivation is based on the analysis of an algorithm\nthat achieves optimal performance for a given model of replacements. We obtain\na general bound that depends on the properties of the model defining the\ninteractions between the agents, and instantiate that result for all-to-one and\none-to-one interaction models. A comparison between those bounds and algorithms\nimplementable with those models is then provided to highlight their validity.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 14:12:43 GMT"}, {"version": "v2", "created": "Thu, 7 Jan 2021 18:26:55 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["de Galland", "Charles Monnoyer", ""], ["Hendrickx", "Julien M.", ""]]}, {"id": "2004.06562", "submitter": "Saad Saleh", "authors": "Saad J Saleh", "title": "On the Optimal Interaction Range for Multi-Agent Systems Under\n  Adversarial Attack", "comments": "Submitted to the 2020 IEEE Conference on Decision and Control", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a consensus-driven multi-agent dynamic system. The interaction\nrange, which defines the set of neighbors for each agent, plays a key role in\ninfluencing connectivity of the underlying network. In this paper, we assume\nthe system is under attack by a predator and explore the question of finding\nthe optimal interaction range that facilitates the most-efficient escape\ntrajectories for the group of agents. We find that for many cases of interest\nthe optimal interaction range is one that forces the network to break up into a\nhandful of disconnected graphs, each containing a subset of agents, thus\noutperforming the two extreme cases corresponding to fully-connected and\nfully-disconnected networks. In other words, the results indicate that some\nconnectivity among the agents is helpful because information is effectively\ntransmitted from the agents closest to the predator to others slightly farther\naway, but also that too much connectivity can be detrimental to the agility of\nthe group, thus hampering efficient and rapid escape.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 14:45:56 GMT"}, {"version": "v2", "created": "Sat, 25 Apr 2020 15:02:20 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Saleh", "Saad J", ""]]}, {"id": "2004.06838", "submitter": "Bilal Farooq", "authors": "Godwin Badu-Marfo, Bilal Farooq, and Zachary Paterson", "title": "Composite Travel Generative Adversarial Networks for Tabular and\n  Sequential Population Synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Agent-based transportation modelling has become the standard to simulate\ntravel behaviour, mobility choices and activity preferences using disaggregate\ntravel demand data for entire populations, data that are not typically readily\navailable. Various methods have been proposed to synthesize population data for\nthis purpose. We present a Composite Travel Generative Adversarial Network\n(CTGAN), a novel deep generative model to estimate the underlying joint\ndistribution of a population, that is capable of reconstructing composite\nsynthetic agents having tabular (e.g. age and sex) as well as sequential\nmobility data (e.g. trip trajectory and sequence). The CTGAN model is compared\nwith other recently proposed methods such as the Variational Autoencoders (VAE)\nmethod, which has shown success in high dimensional tabular population\nsynthesis. We evaluate the performance of the synthesized outputs based on\ndistribution similarity, multi-variate correlations and spatio-temporal\nmetrics. The results show the consistent and accurate generation of synthetic\npopulations and their tabular and spatially sequential attributes, generated\nover varying spatial scales and dimensions.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 00:06:52 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Badu-Marfo", "Godwin", ""], ["Farooq", "Bilal", ""], ["Paterson", "Zachary", ""]]}, {"id": "2004.07197", "submitter": "Ragesh K Ramachandran", "authors": "Ragesh K. Ramachandran, Nicole Fronda and Gaurav S. Sukhatme", "title": "Resilience in multi-robot multi-target tracking with unknown number of\n  targets through reconfiguration", "comments": "21 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.MA cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of maintaining resource availability in a networked\nmulti-robot team performing distributed tracking of unknown number of targets\nin an environment of interest. Based on our model, robots are equipped with\nsensing and computational resources enabling them to cooperatively track a set\nof targets in an environment using a distributed Probability Hypothesis Density\n(PHD) filter. We use the trace of a robot's sensor measurement noise covariance\nmatrix to quantify its sensing quality. While executing the tracking task, if a\nrobot experiences sensor quality degradation, then robot team's communication\nnetwork is reconfigured such that the robot with the faulty sensor may share\ninformation with other robots to improve the team's target tracking ability\nwithout enforcing a large change in the number of active communication links. A\ncentral system which monitors the team executes all the network reconfiguration\ncomputations. We consider two different PHD fusion methods in this paper and\npropose four different Mixed Integer Semi-Definite Programming (MISDP)\nformulations (two formulations for each PHD fusion method) to accomplish our\nobjective. All four MISDP formulations are validated in simulation.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 16:54:24 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Ramachandran", "Ragesh K.", ""], ["Fronda", "Nicole", ""], ["Sukhatme", "Gaurav S.", ""]]}, {"id": "2004.07625", "submitter": "Janos Kramar", "authors": "J\\'anos Kram\\'ar, Neil Rabinowitz, Tom Eccles, Andrea Tacchetti", "title": "Should I tear down this wall? Optimizing social metrics by evaluating\n  novel actions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the fundamental challenges of governance is deciding when and how to\nintervene in multi-agent systems in order to impact group-wide metrics of\nsuccess. This is particularly challenging when proposed interventions are novel\nand expensive. For example, one may wish to modify a building's layout to\nimprove the efficiency of its escape route. Evaluating such interventions would\ngenerally require access to an elaborate simulator, which must be constructed\nad-hoc for each environment, and can be prohibitively costly or inaccurate.\nHere we examine a simple alternative: Optimize By Observational Extrapolation\n(OBOE). The idea is to use observed behavioural trajectories, without any\ninterventions, to learn predictive models mapping environment states to\nindividual agent outcomes, and then use these to evaluate and select changes.\nWe evaluate OBOE in socially complex gridworld environments and consider novel\nphysical interventions that our models were not trained on. We show that neural\nnetwork models trained to predict agent returns on baseline environments are\neffective at selecting among the interventions. Thus, OBOE can provide guidance\nfor challenging questions like: \"which wall should I tear down in order to\nminimize the Gini index of this group?\"\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 12:24:40 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Kram\u00e1r", "J\u00e1nos", ""], ["Rabinowitz", "Neil", ""], ["Eccles", "Tom", ""], ["Tacchetti", "Andrea", ""]]}, {"id": "2004.07707", "submitter": "Declan Oller", "authors": "Declan Oller, Tobias Glasmachers, Giuseppe Cuccu", "title": "Analyzing Reinforcement Learning Benchmarks with Random Weight Guessing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel method for analyzing and visualizing the complexity of\nstandard reinforcement learning (RL) benchmarks based on score distributions. A\nlarge number of policy networks are generated by randomly guessing their\nparameters, and then evaluated on the benchmark task; the study of their\naggregated results provide insights into the benchmark complexity. Our method\nguarantees objectivity of evaluation by sidestepping learning altogether: the\npolicy network parameters are generated using Random Weight Guessing (RWG),\nmaking our method agnostic to (i) the classic RL setup, (ii) any learning\nalgorithm, and (iii) hyperparameter tuning. We show that this approach isolates\nthe environment complexity, highlights specific types of challenges, and\nprovides a proper foundation for the statistical analysis of the task's\ndifficulty. We test our approach on a variety of classic control benchmarks\nfrom the OpenAI Gym, where we show that small untrained networks can provide a\nrobust baseline for a variety of tasks. The networks generated often show good\nperformance even without gradual learning, incidentally highlighting the\ntriviality of a few popular benchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 15:32:52 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Oller", "Declan", ""], ["Glasmachers", "Tobias", ""], ["Cuccu", "Giuseppe", ""]]}, {"id": "2004.08025", "submitter": "Oriana Peltzer", "authors": "Oriana Peltzer, Kyle Brown, Mac Schwager, Mykel J. Kochenderfer,\n  Martin Sehr", "title": "STT-CBS: A Conflict-Based Search Algorithm for Multi-Agent Path Finding\n  with Stochastic Travel Times", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the Multi-Agent Path Finding problem on a graph for agents\nassigned to goals in a known environment and under uncertainty. Our algorithm,\ncalled STT-CBS, uses Conflict-Based Search (CBS) with a stochastic travel time\n(STT) model for the agents. We model robot travel time along each edge of the\ngraph by independent gamma-distributed random variables and propose\nprobabilistic conflict identification and constraint creation methods to\nrobustly handle travel time uncertainty. We show that under reasonable\nassumptions our algorithm is complete and optimal in terms of expected sum of\ntravel times, while ensuring an upper bound on each pairwise conflict\nprobability. Simulations and hardware experiments show that STT-CBS is able to\nsignificantly decrease conflict probability over CBS, while remaining within\nthe same complexity class.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 01:50:18 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Peltzer", "Oriana", ""], ["Brown", "Kyle", ""], ["Schwager", "Mac", ""], ["Kochenderfer", "Mykel J.", ""], ["Sehr", "Martin", ""]]}, {"id": "2004.08216", "submitter": "Evgeny Ivanko", "authors": "Nikolay Markov and Evgeny Ivanko", "title": "\"Perchance to dream?\": Assessing effect of dispersal strategies on the\n  fitness of expanding populations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unraveling patterns of animals' movements is important for understanding the\nfundamental basics of biogeography, tracking range shifts resulting from\nclimate change, predicting and preventing biological invansions. Many\nresearchers have modeled animals' dispersal studying their behavior under the\nassumptions of some movement strategies pre-determined or affected by some\nexternal factor(s) but none of them have compared the efficiency of different\ndispersal strategies in providing population survival and fitness. We\nhypothesize that 1) successful expansion could result from some evolutionary\nstable strategy (ESS) and 2) such strategy could be based particularly on\ndeferred gain, when animals invest in travel to reach some high-quality habitat\n(\"habitat of dream\"). Using simulation model we compare the ecological success\nof three strategies: i) \"Smart\" - choosing the locally optimal cell; ii)\n\"Random\" - random movement between cells without taking into account the\nquality of the environment; iii) \"Dreamer\" - movements that aims to find \"a\nhabitat of dream\" with quality much higher than that of the initial and\nneighboring cells. The population fitness was measured as survival rate,\ndispersal distance, accumulated energy and quality of settled habitat. The most\ngeneral conclusion is that while survival and wealth of the population is\naffected presumably by overall habitat quality, the dispersal depends mainly on\nthe behavioral strategy. The \"Dreamer\" strategy or the strategy of deferred\ngain belongs to the Pareto frontier in the Fitness$\\times$Dispersal space but\nonly in optimal and suboptimal habitat and in the relatively mild climate.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 12:40:58 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Markov", "Nikolay", ""], ["Ivanko", "Evgeny", ""]]}, {"id": "2004.08364", "submitter": "Patrick Scheffe", "authors": "Patrick Scheffe, Janis Maczijewski, Maximilian Kloock, Alexandru\n  Kampmann, Andreas Derks, Stefan Kowalewski, Bassam Alrifaee", "title": "Networked and Autonomous Model-scale Vehicles for Experiments in\n  Research and Education", "comments": "This work has been accepted to IFAC for publication under a Creative\n  Commons Licence CC-BY-NC-ND", "journal-ref": "IFAC-PapersOnLine Volume 53, Issue 2, 2020, Pages 17332-17337", "doi": "10.1016/j.ifacol.2020.12.1821", "report-no": null, "categories": "cs.RO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the $\\mathrm{\\mu}$Car, a 1:18 model-scale vehicle with\nAckermann steering geometry developed for experiments in networked and\nautonomous driving in research and education. The vehicle is open source,\nmoderately costed and highly flexible, which allows for many applications. It\nis equipped with an inertial measurement unit and an odometer and obtains its\npose via WLAN from an indoor positioning system. The two supported operating\nmodes for controlling the vehicle are (1) computing control inputs on external\nhardware, transmitting them via WLAN and applying received inputs to the\nactuators and (2) transmitting a reference trajectory via WLAN, which is then\nfollowed by a controller running on the onboard Raspberry Pi Zero W. The design\nallows identical vehicles to be used at the same time in order to conduct\nexperiments with a large amount of networked agents.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 17:39:57 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Scheffe", "Patrick", ""], ["Maczijewski", "Janis", ""], ["Kloock", "Maximilian", ""], ["Kampmann", "Alexandru", ""], ["Derks", "Andreas", ""], ["Kowalewski", "Stefan", ""], ["Alrifaee", "Bassam", ""]]}, {"id": "2004.08546", "submitter": "Chaoyang He", "authors": "Chaoyang He, Murali Annavaram, Salman Avestimehr", "title": "Towards Non-I.I.D. and Invisible Data with FedNAS: Federated Deep\n  Learning via Neural Architecture Search", "comments": "accepted to CVPR 2020 workshop on neural architecture search and\n  beyond for representation learning. Code is released at https://fedml.ai", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.DC cs.MA stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Federated Learning (FL) has been proved to be an effective learning framework\nwhen data cannot be centralized due to privacy, communication costs, and\nregulatory restrictions. When training deep learning models under an FL\nsetting, people employ the predefined model architecture discovered in the\ncentralized environment. However, this predefined architecture may not be the\noptimal choice because it may not fit data with non-identical and independent\ndistribution (non-IID). Thus, we advocate automating federated learning\n(AutoFL) to improve model accuracy and reduce the manual design effort. We\nspecifically study AutoFL via Neural Architecture Search (NAS), which can\nautomate the design process. We propose a Federated NAS (FedNAS) algorithm to\nhelp scattered workers collaboratively searching for a better architecture with\nhigher accuracy. We also build a system based on FedNAS. Our experiments on\nnon-IID dataset show that the architecture searched by FedNAS can outperform\nthe manually predefined architecture.\n", "versions": [{"version": "v1", "created": "Sat, 18 Apr 2020 08:04:44 GMT"}, {"version": "v2", "created": "Wed, 29 Jul 2020 23:59:20 GMT"}, {"version": "v3", "created": "Mon, 2 Nov 2020 18:47:25 GMT"}, {"version": "v4", "created": "Mon, 4 Jan 2021 02:18:08 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["He", "Chaoyang", ""], ["Annavaram", "Murali", ""], ["Avestimehr", "Salman", ""]]}, {"id": "2004.08883", "submitter": "Chao Qu", "authors": "Chao Qu, Hui Li, Chang Liu, Junwu Xiong, James Zhang, Wei Chu,\n  Weiqiang Wang, Yuan Qi, Le Song", "title": "Intention Propagation for Multi-agent Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A hallmark of an AI agent is to mimic human beings to understand and interact\nwith others. In this paper, we propose a collaborative multi-agent\nreinforcement learning algorithm to learn a \\emph{joint} policy through the\ninteractions over agents. To make a joint decision over the group, each agent\nmakes an initial decision and tells its policy to its neighbors. Then each\nagent modifies its own policy properly based on received messages and spreads\nout its plan. As this intention propagation procedure goes on, we prove that it\nconverges to a mean-field approximation of the joint policy with the framework\nof neural embedded probabilistic inference. We evaluate our algorithm on\nseveral large scale challenging tasks and demonstrate that it outperforms\nprevious state-of-the-arts.\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2020 15:42:55 GMT"}, {"version": "v2", "created": "Sun, 16 Aug 2020 05:13:41 GMT"}, {"version": "v3", "created": "Mon, 18 Jan 2021 02:16:01 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Qu", "Chao", ""], ["Li", "Hui", ""], ["Liu", "Chang", ""], ["Xiong", "Junwu", ""], ["Zhang", "James", ""], ["Chu", "Wei", ""], ["Wang", "Weiqiang", ""], ["Qi", "Yuan", ""], ["Song", "Le", ""]]}, {"id": "2004.09218", "submitter": "Jens Nevens", "authors": "Jens Nevens and Paul Van Eecke and Katrien Beuls", "title": "A Practical Guide to Studying Emergent Communication through Grounded\n  Language Games", "comments": "This paper was officially published at the 'Language Learning for\n  Artificial Agents (L2A2) Symposium' of the 2019 Artificial Intelligence and\n  Simulation of Behaviour (AISB) Convention", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The question of how an effective and efficient communication system can\nemerge in a population of agents that need to solve a particular task attracts\nmore and more attention from researchers in many fields, including artificial\nintelligence, linguistics and statistical physics. A common methodology for\nstudying this question consists of carrying out multi-agent experiments in\nwhich a population of agents takes part in a series of scripted and\ntask-oriented communicative interactions, called 'language games'. While each\nindividual language game is typically played by two agents in the population, a\nlarge series of games allows the population to converge on a shared\ncommunication system. Setting up an experiment in which a rich system for\ncommunicating about the real world emerges is a major enterprise, as it\nrequires a variety of software components for running multi-agent experiments,\nfor interacting with sensors and actuators, for conceptualising and\ninterpreting semantic structures, and for mapping between these semantic\nstructures and linguistic utterances. The aim of this paper is twofold. On the\none hand, it introduces a high-level robot interface that extends the Babel\nsoftware system, presenting for the first time a toolkit that provides flexible\nmodules for dealing with each subtask involved in running advanced grounded\nlanguage game experiments. On the other hand, it provides a practical guide to\nusing the toolkit for implementing such experiments, taking a grounded colour\nnaming game experiment as a didactic example.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 11:48:24 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Nevens", "Jens", ""], ["Van Eecke", "Paul", ""], ["Beuls", "Katrien", ""]]}, {"id": "2004.09312", "submitter": "Peter Hillmann", "authors": "Peter Hillmann, Tobias Uhlig, Gabi Dreo Rodosek, Oliver Rose", "title": "A Novel Multi-Agent System for Complex Scheduling Problems", "comments": null, "journal-ref": "Winter Simulation Conference 2014", "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.CC cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex scheduling problems require a large amount computation power and\ninnovative solution methods. The objective of this paper is the conception and\nimplementation of a multi-agent system that is applicable in various problem\ndomains. Independent specialized agents handle small tasks, to reach a\nsuperordinate target. Effective coordination is therefore required to achieve\nproductive cooperation. Role models and distributed artificial intelligence are\nemployed to tackle the resulting challenges. We simulate a NP-hard scheduling\nproblem to demonstrate the validity of our approach. In addition to the general\nagent based framework we propose new simulation-based optimization heuristics\nto given scheduling problems. Two of the described optimization algorithms are\nimplemented using agents. This paper highlights the advantages of the\nagent-based approach, like the reduction in layout complexity, improved control\nof complicated systems, and extendability.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 14:04:58 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Hillmann", "Peter", ""], ["Uhlig", "Tobias", ""], ["Rodosek", "Gabi Dreo", ""], ["Rose", "Oliver", ""]]}, {"id": "2004.09340", "submitter": "Peter Hillmann", "authors": "Mario Golling, Robert Koch, Peter Hillmann, Volker Eiseler, Lars\n  Stiemert, Andres Rekker", "title": "On the Evaluation of Military Simulations: Towards A Taxonomy of\n  Assessment Criteria", "comments": "Keywords: Simulation; Military; Classification; Taxonomy", "journal-ref": "Military Communications and Information Systems 2015", "doi": null, "report-no": null, "categories": "cs.CY cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the area of military simulations, a multitude of different approaches is\navailable. Close Combat Tactical Trainer, Joint Tactical Combat Training\nSystem, Battle Force Tactical Training or Warfighter's Simulation 2000 are just\nsome examples within the history of the large DoD Development Program in\nModelling and Simulation, representing just a small piece of the variety of\ndiverse solutions. Very often, individual simulators are very unique and so it\nis often difficult to classify military simulations even for experienced users.\nThis circumstance is further boosted due to the fact that in the field of\nmilitary simulations - unlike in other areas - no general classification for\nmilitary simulations exists. To address this shortcoming, this publication is\ndedicated to the idea of providing a first contribution to the development of a\ncommonly accepted taxonomy in the area of military simulations. To this end,\nthe problem field is structured into three main categories (general functional\nrequirements for simulators, special military requirements for simulators and\nnon-functional requirements for simulators). Based upon that, individual\ncategories are provided with appropriate classes. For a better understanding,\nthe taxonomy is also applied to a concrete example (NetLogo Rebellion).\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 14:39:59 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Golling", "Mario", ""], ["Koch", "Robert", ""], ["Hillmann", "Peter", ""], ["Eiseler", "Volker", ""], ["Stiemert", "Lars", ""], ["Rekker", "Andres", ""]]}, {"id": "2004.09581", "submitter": "Jason Cody", "authors": "Jason R. Cody, Karina A. Roundtree, Julie A. Adams", "title": "Human-Collective Collaborative Site Selection", "comments": "27 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robotic collectives are large groups (at least 50) of locally sensing and\ncommunicating robots that encompass characteristics of swarms and colonies,\nwhose emergent behaviors accomplish complex tasks. Future human-collective\nteams will extend the ability of operators to monitor, respond, and make\ndecisions in disaster response, search and rescue, and environmental monitoring\nproblems. This manuscript evaluates two collective best-of-n decision models\nfor enabling collectives to identify and choose the highest valued target from\na finite set of n targets. Two challenges impede the future use of\nhuman-collective shared decisions: 1) environmental bias reduces collective\ndecision accuracy when poorer targets are easier to evaluate than higher\nquality targets, and 2) little is understood about shared human-collective\ndecision making interaction strategies. The two evaluated collective best-of-n\nmodels include an existing insect colony decision model and an extended\nbias-reducing model that attempts to reduce environmental bias in order to\nimprove accuracy. Collectives using these two strategies are compared\nindependently and as members of human-collective teams. Independently, the\nextended model is slower than the original model, but the extended algorithm is\n57% more accurate in decisions where the optimal option is more difficult to\nevaluate. Human-collective teams using the bias-reducing model require less\noperator influence and achieve 25% higher accuracy with difficult decisions,\nthan the human-collective teams using the original model. Further, a novel\nhuman-collective interaction strategy enables operators to adjust collective\nautonomy while making multiple simultaneous decisions.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 19:16:30 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Cody", "Jason R.", ""], ["Roundtree", "Karina A.", ""], ["Adams", "Julie A.", ""]]}, {"id": "2004.10063", "submitter": "Maximilian Kloock", "authors": "Maximilian Kloock, Patrick Scheffe, Janis Maczijewski, Alexandru\n  Kampmann, Armin Mokhtarian, Stefan Kowalewski and Bassam Alrifaee", "title": "Cyber-Physical Mobility Lab: An Open-Source Platform for Networked and\n  Autonomous Vehicles", "comments": "This work has been submitted to IEEE for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces our Cyber-Physical Mobility Lab (CPM Lab). It is an\nopen-source development environment for networked and autonomous vehicles with\nfocus on networked decision-making, trajectory planning, and control. The CPM\nLab hosts 20 physical model-scale vehicles ({\\mu}Cars) which we can seamlessly\nextend by unlimited simulated vehicles. The code and construction plans are\npublicly available to enable rebuilding the CPM Lab. Our four-layered\narchitecture enables the seamless use of the same software in simulations and\nin experiments without any further adaptions. A Data Distribution Service (DDS)\nbased middleware allows adapting the number of vehicles during experiments in a\nseamless manner. The middleware is also responsible for synchronizing all\nentities following a logical execution time approach to achieve determinism and\nreproducibility of experiments. This approach makes the CPM Lab a unique\nplatform for rapid functional prototyping of networked decision-making\nalgorithms. The CPM Lab allows researchers as well as students from different\ndisciplines to see their ideas developing into reality. We demonstrate its\ncapabilities using two example experiments. We are working on a remote access\nto the CPM Lab via a webinterface.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 14:54:30 GMT"}, {"version": "v2", "created": "Mon, 19 Apr 2021 09:56:45 GMT"}, {"version": "v3", "created": "Tue, 20 Apr 2021 07:08:52 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Kloock", "Maximilian", ""], ["Scheffe", "Patrick", ""], ["Maczijewski", "Janis", ""], ["Kampmann", "Alexandru", ""], ["Mokhtarian", "Armin", ""], ["Kowalewski", "Stefan", ""], ["Alrifaee", "Bassam", ""]]}, {"id": "2004.10546", "submitter": "Chunheng Jiang", "authors": "Chunheng Jiang, Jianxi Gao, Malik Magdon-Ismail", "title": "Inferring Degrees from Incomplete Networks and Nonlinear Dynamics", "comments": "IJCAI 2020, 7 pages, 4 figures, network inference, incomplete network", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inferring topological characteristics of complex networks from observed data\nis critical to understand the dynamical behavior of networked systems, ranging\nfrom the Internet and the World Wide Web to biological networks and social\nnetworks. Prior studies usually focus on the structure-based estimation to\ninfer network sizes, degree distributions, average degrees, and more. Little\neffort attempted to estimate the specific degree of each vertex from a sampled\ninduced graph, which prevents us from measuring the lethality of nodes in\nprotein networks and influencers in social networks. The current approaches\ndramatically fail for a tiny sampled induced graph and require a specific\nsampling method and a large sample size. These approaches neglect information\nof the vertex state, representing the dynamical behavior of the networked\nsystem, such as the biomass of species or expression of a gene, which is useful\nfor degree estimation. We fill this gap by developing a framework to infer\nindividual vertex degrees using both information of the sampled topology and\nvertex state. We combine the mean-field theory with combinatorial optimization\nto learn vertex degrees. Experimental results on real networks with a variety\nof dynamics demonstrate that our framework can produce reliable degree\nestimates and dramatically improve existing link prediction methods by\nreplacing the sampled degrees with our estimated degrees.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 07:39:31 GMT"}, {"version": "v2", "created": "Mon, 11 May 2020 18:35:56 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Jiang", "Chunheng", ""], ["Gao", "Jianxi", ""], ["Magdon-Ismail", "Malik", ""]]}, {"id": "2004.10558", "submitter": "Eatai Roth", "authors": "Saber Sheybani, Eduardo J. Izquierdo, Eatai Roth", "title": "Evolving Dyadic Strategies for a Cooperative Physical Task", "comments": "6 pages, 4 figures, IEEE Haptics Symposium 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many cooperative physical tasks require that individuals play specialized\nroles (e.g., leader-follower). Humans are adept cooperators, negotiating these\nroles and transitions between roles innately. Yet how roles are delegated and\nreassigned is not well understood. Using a genetic algorithm, we evolve\nsimulated agents to explore a space of feasible role-switching policies.\nApplying these switching policies in a cooperative manual task, agents process\nvisual and haptic cues to decide when to switch roles. We then analyze the\nevolved virtual population for attributes typically associated with\ncooperation: load sharing and temporal coordination. We find that the best\nperforming dyads exhibit high temporal coordination (anti-synchrony). And in\nturn, anti-synchrony is correlated to symmetry between the parameters of the\ncooperative agents. These simulations furnish hypotheses as to how human\ncooperators might mediate roles in dyadic tasks.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 13:23:12 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Sheybani", "Saber", ""], ["Izquierdo", "Eduardo J.", ""], ["Roth", "Eatai", ""]]}, {"id": "2004.10589", "submitter": "Mohammad Shirvani", "authors": "Mohammad Shirvani, Georges Kesserwani, Paul Richmond", "title": "Agent-based modelling of pedestrian responses during flood emergency:\n  mobility behavioural rules and implications for flood risk analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  An agent-based model (ABM) for simulating flood-pedestrian interaction is\naugmented to particularly explore more realistic responses of evacuating\npedestrians during flooding. Pedestrian agents within the ABM follow navigation\nrules of governing their movement in dry areas. When in floodwater, pedestrian\nagents are assigned extra behavioural rules to factor in their states of\nstability and walking speed, and their different body height and weight. The\nABM is applied to replicate a synthetic test case of a flooded shopping centre,\nconsidering increasingly sophisticated configuration modes for the behavioural\nrules of the evacuating pedestrians. Simulation results are analysed based on\nspatial and temporal indicators informing on the dynamic variations of flood\nrisk states of flooded pedestrians in terms of a commonly used flood Hazard\nRating (HR) metric, variable walking speed, and instability due to toppling\nand/or sliding. Our analysis reveal significantly prolonged evacuation times\nand risk exposure levels as stability and walking speed behavioural rules\nbecome more sophisticated. It also allows to identify more conservative HR\nthresholds due to unstable pedestrians, and a new formula to directly estimate\nwalking speed states as function of HR for stable pedestrian in floodwater.\nAccompanying details for software accessibility are provided.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 14:19:27 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 11:28:20 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Shirvani", "Mohammad", ""], ["Kesserwani", "Georges", ""], ["Richmond", "Paul", ""]]}, {"id": "2004.10808", "submitter": "Ben Kybartas", "authors": "Ben Kybartas, Clark Verbrugge, Jonathan Lessard", "title": "Tension Space Analysis for Emergent Narrative", "comments": "14 pages, 7 figures, IEEE Transactions on Games 2020", "journal-ref": null, "doi": "10.1109/TG.2020.2989072", "report-no": null, "categories": "cs.AI cs.MA cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emergent narratives provide a unique and compelling approach to interactive\nstorytelling through simulation, and have applications in games, narrative\ngeneration, and virtual agents. However the inherent complexity of simulation\nmakes understanding the expressive potential of emergent narratives difficult,\nparticularly at the design phase of development. In this paper, we present a\nnovel approach to emergent narrative using the narratological theory of\npossible worlds and demonstrate how the design of works in such a system can be\nunderstood through a formal means of analysis inspired by expressive range\nanalysis. Lastly, we propose a novel way through which content may be authored\nfor the emergent narrative system using a sketch-based interface.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 19:26:09 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Kybartas", "Ben", ""], ["Verbrugge", "Clark", ""], ["Lessard", "Jonathan", ""]]}, {"id": "2004.10950", "submitter": "Qin Yang", "authors": "Qin Yang and Ramviyas Parasuraman", "title": "A Game-Theoretic Utility Network for Cooperative Multi-Agent Decisions\n  in Adversarial Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many underlying relationships among multi-agent systems (MAS) in various\nscenarios, especially agents working on dangerous, hazardous, and risky\nsituations, can be represented in terms of game theory. In adversarial\nenvironments, the adversaries can be intentional or unintentional based on\ntheir needs and motivations. Agents will adopt suitable decision-making\nstrategies to maximize their current needs and minimize their expected costs.\nIn this paper, we propose a new network model called Game-Theoretic Utility\nTree (GUT) to achieve cooperative decision-making for MAS in adversarial\nenvironments combining the core principles of game theory, utility theory, and\nprobabilistic graphical models. Through calculating multi-level Game-Theoretic\ncomputation units, GUT can decompose high-level strategies into executable\nlower levels. Then, we design Explorers and Monsters Game to validate our model\nagainst a cooperative decision-making algorithm based on the state-of-the-art\nQMIX approach. Also, we implement different predictive models for MAS working\nwith incomplete information to estimate adversaries' state. Our experimental\nresults demonstrate that the GUT significantly enhances cooperation among MAS\nto successfully complete the assigned tasks with lower costs and higher winning\nprobabilities against adversaries.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 03:02:28 GMT"}, {"version": "v2", "created": "Wed, 2 Sep 2020 04:58:00 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Yang", "Qin", ""], ["Parasuraman", "Ramviyas", ""]]}, {"id": "2004.11145", "submitter": "Xiangfeng Wang", "authors": "Wenhao Li and Bo Jin and Xiangfeng Wang and Junchi Yan and Hongyuan\n  Zha", "title": "F2A2: Flexible Fully-decentralized Approximate Actor-critic for\n  Cooperative Multi-agent Reinforcement Learning", "comments": "arXiv admin note: text overlap with arXiv:1810.02912,\n  arXiv:1803.11485 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional centralized multi-agent reinforcement learning (MARL) algorithms\nare sometimes unpractical in complicated applications, due to non-interactivity\nbetween agents, curse of dimensionality and computation complexity. Hence,\nseveral decentralized MARL algorithms are motivated. However, existing\ndecentralized methods only handle the fully cooperative setting where massive\ninformation needs to be transmitted in training. The block coordinate gradient\ndescent scheme they used for successive independent actor and critic steps can\nsimplify the calculation, but it causes serious bias. In this paper, we propose\na flexible fully decentralized actor-critic MARL framework, which can combine\nmost of actor-critic methods, and handle large-scale general cooperative\nmulti-agent setting. A primal-dual hybrid gradient descent type algorithm\nframework is designed to learn individual agents separately for\ndecentralization. From the perspective of each agent, policy improvement and\nvalue evaluation are jointly optimized, which can stabilize multi-agent policy\nlearning. Furthermore, our framework can achieve scalability and stability for\nlarge-scale environment and reduce information transmission, by the parameter\nsharing mechanism and a novel modeling-other-agents methods based on\ntheory-of-mind and online supervised learning. Sufficient experiments in\ncooperative Multi-agent Particle Environment and StarCraft II show that our\ndecentralized MARL instantiation algorithms perform competitively against\nconventional centralized and decentralized methods.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 14:56:29 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Li", "Wenhao", ""], ["Jin", "Bo", ""], ["Wang", "Xiangfeng", ""], ["Yan", "Junchi", ""], ["Zha", "Hongyuan", ""]]}, {"id": "2004.11428", "submitter": "Martin Garriga", "authors": "Christos Tsigkanos, Martin Garriga, Luciano Baresi and Carlo Ghezzi", "title": "Cloud Deployment Tradeoffs for the Analysis of Spatially-Distributed\n  Systems of Internet-of-Things", "comments": "Accepted for publication in ACM Transactions on Internet of Things", "journal-ref": null, "doi": "10.1145/3381452", "report-no": null, "categories": "cs.DC cs.MA cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet-enabled things and devices operating in the physical world are\nincreasingly integrated in modern distributed systems, supporting\nfunctionalities that require assurances that certain critical requirements are\nsatisfied by the overall system. We focus here on spatially-distributed\nInternet-of-Things systems such as smart environments, where the dynamics of\nspatial distribution of entities in the system is crucial to requirements\nsatisfaction. Analysis techniques need to be in place while systems operate to\nensure that requirements are fulfilled. This may be achieved by keeping a model\nof the system at runtime, monitoring events that lead to changes in the spatial\nenvironment, and performing analysis. This computationally-intensive runtime\nassurance method cannot be supported by resource-constrained devices that\npopulate the space and must be offloaded to the cloud. However, challenges\narise regarding resource allocation and cost, especially when the workload is\nunknown at the system's design time. As such, it may be difficult or even\nimpossible to guarantee application service level agreements, e.g., on response\ntimes. To this end, we instantiate spatial verification processes, integrating\nthem to the service layer of an IoT-cloud architecture based on microservices.\nWe propose several cloud deployments for such an architecture for assurance of\nspatial requirements -- based on virtual machines, containers, and the recent\nFunctions-as-a-Service paradigm. Then, we assess deployments' tradeoffs in\nterms of elasticity, performance and cost by using a workload scenario from a\nknown dataset of taxis roaming in Beijing. We argue that the approach can be\nreplicated in the design process of similar kinds of spatially distributed\nInternet-of-Things systems.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 19:05:45 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Tsigkanos", "Christos", ""], ["Garriga", "Martin", ""], ["Baresi", "Luciano", ""], ["Ghezzi", "Carlo", ""]]}, {"id": "2004.11543", "submitter": "Hung Nguyen", "authors": "Hung The Nguyen, Tung Duy Nguyen, Vu Phi Tran, Matthew Garratt,\n  Kathryn Kasmarik, Sreenatha Anavatti, Michael Barlow, and Hussein A. Abbass", "title": "Continuous Deep Hierarchical Reinforcement Learning for Ground-Air Swarm\n  Shepherding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The control and guidance of multi-robots (swarm) is a non-trivial problem due\nto the complexity inherent in the coupled interaction among the group. Whether\nthe swarm is cooperative or non-cooperative, lessons can be learnt from\nsheepdogs herding sheep. Biomimicry of shepherding offers computational methods\nfor swarm control with the potential to generalize and scale in different\nenvironments. However, learning to shepherd is complex due to the large search\nspace that a machine learner is faced with. We present a deep hierarchical\nreinforcement learning approach for shepherding, whereby an unmanned aerial\nvehicle (UAV) learns to act as an aerial sheepdog to control and guide a swarm\nof unmanned ground vehicles (UGVs). The approach extends our previous work on\nmachine education to decompose the search space into a hierarchically organized\ncurriculum. Each lesson in the curriculum is learnt by a deep reinforcement\nlearning model. The hierarchy is formed by fusing the outputs of the model. The\napproach is demonstrated first in a high-fidelity robotic-operating-system\n(ROS)-based simulation environment, then with physical UGVs and a UAV in an\nin-door testing facility. We investigate the ability of the method to\ngeneralize as the models move from simulation to the real-world and as the\nmodels move from one scale to another.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 05:56:19 GMT"}, {"version": "v2", "created": "Mon, 27 Apr 2020 13:54:00 GMT"}, {"version": "v3", "created": "Sun, 23 Aug 2020 05:37:22 GMT"}, {"version": "v4", "created": "Thu, 27 Aug 2020 03:18:12 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Nguyen", "Hung The", ""], ["Nguyen", "Tung Duy", ""], ["Tran", "Vu Phi", ""], ["Garratt", "Matthew", ""], ["Kasmarik", "Kathryn", ""], ["Anavatti", "Sreenatha", ""], ["Barlow", "Michael", ""], ["Abbass", "Hussein A.", ""]]}, {"id": "2004.11856", "submitter": "Mohammad Afshari", "authors": "Mohammad Afshari and Aditya Mahajan", "title": "Decentralized linear quadratic systems with major and minor agents and\n  non-Gaussian noise", "comments": "15 pages, submitted to the IEEE Transactions on Automatic Control", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.MA cs.RO cs.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider a decentralized linear quadratic system with a major agent and a\ncollection of minor agents. The agents are coupled in their dynamics as well as\na quadratic cost. In particular, the dynamics are linear; the state and control\naction of the major agent affect the state evolution of all the minor agents\nbut the state and the control action of the minor agents do not affect the\nstate evolution of the major or other minor agents. The system has partial\noutput feedback with partially nested information structure. In particular, the\nmajor agent perfectly observes its own state while each minor agent perfectly\nobserves the state of the major agent and partially observes its own state. It\nis not assumed that the noise process has a Gaussian distribution. For this\nmodel, we characterize the structure of the optimal and the best linear\nstrategies. We show that the optimal control of the major agent is a linear\nfunction of the major agent's MMSE (minimum mean squared error) estimate of the\nsystem state and the optimal control of a minor agent is a linear function of\nthe major agent's MMSE estimate of the system state and a \"correction term\"\nwhich depends on the difference of the minor agent's MMSE estimate of its local\nstate and the major agent's MMSE estimate of the minor agent's local state. The\nmajor agent's MMSE estimate is a linear function of its observations while the\nminor agent's MMSE estimate is a non-linear function of its observations which\nis updated according to the non-linear Bayesian filter. We show that if we\nreplace the minor agent's MMSE estimate by its LLMS (linear least mean square)\nestimate, then the resultant strategy is the best linear control strategy. We\nprove the result using a direct proof which is based on conditional\nindependence, splitting of the state and control actions, simplifying the\nper-step cost, orthogonality principle, and completion of squares.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 17:02:23 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Afshari", "Mohammad", ""], ["Mahajan", "Aditya", ""]]}, {"id": "2004.12480", "submitter": "Najma Mathema", "authors": "Najma Mathema, Michael A. Goodrich, and Jacob W. Crandall", "title": "Predicting Plans and Actions in Two-Player Repeated Games", "comments": "Accepted in The AAAI 2020 Workshop on Plan, Activity, and Intent\n  Recognition", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT cs.HC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligence (AI) agents will need to interact with both other AI\nagents and humans. Creating models of associates help to predict the modeled\nagents' actions, plans, and intentions. This work introduces algorithms that\npredict actions, plans and intentions in repeated play games, with providing an\nexploration of algorithms. We form a generative Bayesian approach to model S#.\nS# is designed as a robust algorithm that learns to cooperate with its\nassociate in 2 by 2 matrix games. The actions, plans and intentions associated\nwith each S# expert are identified from the literature, grouping the S# experts\naccordingly, and thus predicting actions, plans, and intentions based on their\nstate probabilities. Two prediction methods are explored for Prisoners Dilemma:\nthe Maximum A Posteriori (MAP) and an Aggregation approach. MAP (~89% accuracy)\nperformed the best for action prediction. Both methods predicted plans of S#\nwith ~88% accuracy. Paired T-test shows that MAP performs significantly better\nthan Aggregation for predicting S#'s actions without cheap talk. Intention is\nexplored based on the goals of the S# experts; results show that goals are\npredicted precisely when modeling S#. The obtained results show that the\nproposed Bayesian approach is well suited for modeling agents in two-player\nrepeated games.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2020 21:03:28 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Mathema", "Najma", ""], ["Goodrich", "Michael A.", ""], ["Crandall", "Jacob W.", ""]]}, {"id": "2004.12481", "submitter": "Andrew Wood", "authors": "Andrew Wood, Ali Sydney, Peter Chin, Bishal Thapa, Ryan Ross", "title": "GymFG: A Framework with a Gym Interface for FlightGear", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past decades, progress in deployable autonomous flight systems has\nslowly stagnated. This is reflected in today's production air-crafts, where\npilots only enable simple physics-based systems such as autopilot for takeoff,\nlanding, navigation, and terrain/traffic avoidance. Evidently, autonomy has not\ngained the trust of the community where higher problem complexity and cognitive\nworkload are required. To address trust, we must revisit the process for\ndeveloping autonomous capabilities: modeling and simulation. Given the\nprohibitive costs for live tests, we need to prototype and evaluate autonomous\naerial agents in a high fidelity flight simulator with autonomous learning\ncapabilities applicable to flight systems: such a open-source development\nplatform is not available. As a result, we have developed GymFG: GymFG couples\nand extends a high fidelity, open-source flight simulator and a robust agent\nlearning framework to facilitate learning of more complex tasks. Furthermore,\nwe have demonstrated the use of GymFG to train an autonomous aerial agent using\nImitation Learning. With GymFG, we can now deploy innovative ideas to address\ncomplex problems and build the trust necessary to move prototypes to the\nreal-world.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2020 21:06:20 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Wood", "Andrew", ""], ["Sydney", "Ali", ""], ["Chin", "Peter", ""], ["Thapa", "Bishal", ""], ["Ross", "Ryan", ""]]}, {"id": "2004.12661", "submitter": "Mark Burgess", "authors": "Mark Burgess", "title": "Information and Causality in Promise Theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The explicit link between Promise Theory and Information Theory, while\nperhaps obvious, is laid out explicitly here. It's shown how causally related\nobservations of promised behaviours relate to the probabilistic formulation of\ncausal information in Shannon's theory, and thus clarify the meaning of\nautonomy or causal independence, and further the connection between information\nand causal sets. Promise Theory helps to make clear a number of assumptions\nwhich are commonly taken for granted in causal descriptions. The concept of a\npromise is hard to escape. It serves as proxy for intent, whether a priori or\nby inference, and it is intrinsic to the interpretations of observations in the\nlatter.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 09:18:42 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Burgess", "Mark", ""]]}, {"id": "2004.12797", "submitter": "Ren\\'e Mellema", "authors": "Ren\\'e Mellema, Maarten Jensen, and Frank Dignum", "title": "Social rules for agent systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When creating (open) agent systems it has become common practice to use\nsocial concepts such as social practices, norms and conventions to model the\nway the interactions between the agents are regulated. However, in the\nliterature most papers concentrate on only one of these aspects at the time.\nTherefore there is hardly any research on how these social concepts relate and\nwhen each of them emerges or evolves from another concept. In this paper we\nwill investigate some of the relations between these concepts and also whether\nthey are fundamentally stemming from a single social object or should be seen\nas different types of objects altogether.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 17:16:28 GMT"}, {"version": "v2", "created": "Wed, 6 Jan 2021 11:14:45 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Mellema", "Ren\u00e9", ""], ["Jensen", "Maarten", ""], ["Dignum", "Frank", ""]]}, {"id": "2004.12809", "submitter": "Virginia Dignum", "authors": "Frank Dignum, Virginia Dignum, Paul Davidsson, Amineh Ghorbani, Mijke\n  van der Hurk, Maarten Jensen, Christian Kammler, Fabian Lorig, Luis Gustavo\n  Ludescher, Alexander Melchior, Ren\\'e Mellema, Cezara Pastrav, Lo\\\"is Vanhee,\n  and Harko Verhagen", "title": "Analysing the combined health, social and economic impacts of the\n  corovanvirus pandemic using agent-based social simulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the COVID-19 crisis there have been many difficult decisions\ngovernments and other decision makers had to make. E.g. do we go for a total\nlock down or keep schools open? How many people and which people should be\ntested? Although there are many good models from e.g. epidemiologists on the\nspread of the virus under certain conditions, these models do not directly\ntranslate into the interventions that can be taken by government. Neither can\nthese models contribute to understand the economic and/or social consequences\nof the interventions. However, effective and sustainable solutions need to take\ninto account this combination of factors. In this paper, we propose an\nagent-based social simulation tool, ASSOCC, that supports decision makers\nunderstand possible consequences of policy interventions, bu exploring the\ncombined social, health and economic consequences of these interventions.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 14:46:01 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Dignum", "Frank", ""], ["Dignum", "Virginia", ""], ["Davidsson", "Paul", ""], ["Ghorbani", "Amineh", ""], ["van der Hurk", "Mijke", ""], ["Jensen", "Maarten", ""], ["Kammler", "Christian", ""], ["Lorig", "Fabian", ""], ["Ludescher", "Luis Gustavo", ""], ["Melchior", "Alexander", ""], ["Mellema", "Ren\u00e9", ""], ["Pastrav", "Cezara", ""], ["Vanhee", "Lo\u00efs", ""], ["Verhagen", "Harko", ""]]}, {"id": "2004.12869", "submitter": "Laura Arditti", "authors": "Laura Arditti, Giacomo Como, Fabio Fagnani, and Martina Vanelli", "title": "Robustness of Nash Equilibria in Network Games", "comments": "7 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DM cs.MA cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the robustness of (pure strategy) Nash equilibria for network\ngames against perturbations of the players' utility functions. We first derive\na simple characterization of the margin of robustness, defined as the minimum\nmagnitude of a perturbation that makes a Nash equilibrium of the original game\nstop being so in the perturbed game. Then, we investigate what the maximally\nrobust equilibria are in some standard network games such as the coordination\nand the anti-coordination game. Finally, as an application, we provide some\nsufficient conditions for the existence of Nash equilibria in network games\nwith a mixture of coordinating and anticoordinating games.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 15:26:11 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Arditti", "Laura", ""], ["Como", "Giacomo", ""], ["Fagnani", "Fabio", ""], ["Vanelli", "Martina", ""]]}, {"id": "2004.12927", "submitter": "Gabriele Bernardini", "authors": "Marco D'Orazio, Gabriele Bernardini, Enrico Quagliarini", "title": "How to restart? An agent-based simulation model towards the definition\n  of strategies for COVID-19 \"second phase\" in public buildings", "comments": "21 pages, 16 figures; submitted to Building and Environment", "journal-ref": null, "doi": "10.1007/s12273-021-0770-2", "report-no": null, "categories": "physics.soc-ph cs.CY cs.MA physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Restarting public buildings activities in the \"second phase\" of COVID-19\nemergency should be supported by operational measures to avoid a second virus\nspreading. Buildings hosting the continuous presence of the same users and\nsignificant overcrowd conditions over space/time (e.g. large offices,\nuniversities) are critical scenarios due to the prolonged contact with\ninfectors. Beside individual's risk-mitigation strategies performed (facial\nmasks), stakeholders should promote additional strategies, i.e. occupants' load\nlimitation (towards \"social distancing\") and access control. Simulators could\nsupport the measures effectiveness evaluation. This work provides an\nAgent-Based Model to estimate the virus spreading in the closed built\nenvironment. The model adopts a probabilistic approach to jointly simulate\noccupants' movement and virus transmission according to proximity-based and\nexposure-time-based rules proposed by international health organizations.\nScenarios can be defined in terms of building occupancy, mitigation strategies\nand virus-related aspects. The model is calibrated on experimental data\n(\"Diamond Princess\" cruise) and then applied to a relevant case-study (a part\nof a university campus). Results demonstrate the model capabilities. Concerning\nthe case-study, adopting facial masks seems to be a paramount strategy to\nreduce virus spreading in each initial condition, by maintaining an acceptable\ninfected people's number. The building capacity limitation could support such\nmeasure by potentially moving from FFPk masks to surgical masks use by\noccupants (thus improving users' comfort issues). A preliminary model to\ncombine acceptable mask filters-occupants' density combination is proposed. The\nmodel could be modified to consider other recurring scenarios in other public\nbuildings (e.g. tourist facilities, cultural buildings).\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 16:40:22 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["D'Orazio", "Marco", ""], ["Bernardini", "Gabriele", ""], ["Quagliarini", "Enrico", ""]]}, {"id": "2004.12959", "submitter": "Changliu Liu", "authors": "Changliu Liu", "title": "A Microscopic Epidemic Model and Pandemic Prediction Using Multi-Agent\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a microscopic approach to model epidemics, which can\nexplicitly consider the consequences of individual's decisions on the spread of\nthe disease. We first formulate a microscopic multi-agent epidemic model where\nevery agent can choose its activity level that affects the spread of the\ndisease. Then by minimizing agents' cost functions, we solve for the optimal\ndecisions for individual agents in the framework of game theory and multi-agent\nreinforcement learning. Given the optimal decisions of all agents, we can make\npredictions about the spread of the disease. We show that there are negative\nexternalities in the sense that infected agents do not have enough incentives\nto protect others, which then necessitates external interventions to regulate\nagents' behaviors. In the discussion section, future directions are pointed out\nto make the model more realistic.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 17:17:29 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Liu", "Changliu", ""]]}, {"id": "2004.13439", "submitter": "Thilo Stadelmann", "authors": "Dano Roost, Ralph Meier, Stephan Huschauer, Erik Nygren, Adrian Egli,\n  Andreas Weiler, Thilo Stadelmann", "title": "Improving Sample Efficiency and Multi-Agent Communication in RL-based\n  Train Rescheduling", "comments": "Accepted for publication at the 7th Swiss Conference on Data Science\n  (SDS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present preliminary results from our sixth placed entry to the Flatland\ninternational competition for train rescheduling, including two improvements\nfor optimized reinforcement learning (RL) training efficiency, and two\nhypotheses with respect to the prospect of deep RL for complex real-world\ncontrol tasks: first, that current state of the art policy gradient methods\nseem inappropriate in the domain of high-consequence environments; second, that\nlearning explicit communication actions (an emerging machine-to-machine\nlanguage, so to speak) might offer a remedy. These hypotheses need to be\nconfirmed by future work. If confirmed, they hold promises with respect to\noptimizing highly efficient logistics ecosystems like the Swiss Federal\nRailways railway network.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 11:46:58 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Roost", "Dano", ""], ["Meier", "Ralph", ""], ["Huschauer", "Stephan", ""], ["Nygren", "Erik", ""], ["Egli", "Adrian", ""], ["Weiler", "Andreas", ""], ["Stadelmann", "Thilo", ""]]}, {"id": "2004.13446", "submitter": "Ankit Sharma", "authors": "Ankit Sharma, Garima Gupta, Ranjitha Prasad, Arnab Chatterjee,\n  Lovekesh Vig, Gautam Shroff", "title": "MultiMBNN: Matched and Balanced Causal Inference with Neural Networks", "comments": "7 pages, 3 figures, Accepted in ESANN 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal inference (CI) in observational studies has received a lot of\nattention in healthcare, education, ad attribution, policy evaluation, etc.\nConfounding is a typical hazard, where the context affects both, the treatment\nassignment and response. In a multiple treatment scenario, we propose the\nneural network based MultiMBNN, where we overcome confounding by employing\ngeneralized propensity score based matching, and learning balanced\nrepresentations. We benchmark the performance on synthetic and real-world\ndatasets using PEHE, and mean absolute percentage error over ATE as metrics.\nMultiMBNN outperforms the state-of-the-art algorithms for CI such as TARNet and\nPerfect Match (PM).\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 11:58:38 GMT"}, {"version": "v2", "created": "Wed, 29 Apr 2020 05:34:17 GMT"}, {"version": "v3", "created": "Fri, 18 Dec 2020 10:58:56 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Sharma", "Ankit", ""], ["Gupta", "Garima", ""], ["Prasad", "Ranjitha", ""], ["Chatterjee", "Arnab", ""], ["Vig", "Lovekesh", ""], ["Shroff", "Gautam", ""]]}, {"id": "2004.13815", "submitter": "Shuai Feng", "authors": "Shuai Feng, Hideaki Ishii", "title": "Dynamic Quantized Consensus of General Linear Multi-agent Systems under\n  Denial-of-Service Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study multi-agent consensus problems under\nDenial-of-Service (DoS) attacks with data rate constraints. We first consider\nthe leaderless consensus problem and after that we briefly present the analysis\nof leader-follower consensus. The dynamics of the agents take general forms\nmodeled as homogeneous linear time-invariant systems. In our analysis, we\nderive lower bounds on the data rate for the multi-agent systems to achieve\nleaderless and leader-follower consensus in the presence of DoS attacks without\nquantizer saturation. The main contribution of the paper is the\ncharacterization of the trade-off between the tolerable DoS attack levels for\nleaderless and leader-follower consensus and the required data rates for the\nquantizers during the communication attempts among the agents. To mitigate the\ninfluence of DoS attacks, we employ dynamic quantization with zooming-in and\nzooming-out capabilities for avoiding quantizer saturation.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 21:06:08 GMT"}, {"version": "v2", "created": "Thu, 30 Apr 2020 09:53:58 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Feng", "Shuai", ""], ["Ishii", "Hideaki", ""]]}, {"id": "2004.13997", "submitter": "Jorge Pe\\~na Queralta", "authors": "Jorge Pe\\~na Queralta, Li Qingqing, Tuan Nguyen Gia, Hong-Linh Truong,\n  Tomi Westerlund", "title": "End-to-End Design for Self-Reconfigurable Heterogeneous Robotic Swarms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.DC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  More widespread adoption requires swarms of robots to be more flexible for\nreal-world applications. Multiple challenges remain in complex scenarios where\na large amount of data needs to be processed in real-time and high degrees of\nsituational awareness are required. The options in this direction are limited\nin existing robotic swarms, mostly homogeneous robots with limited operational\nand reconfiguration flexibility. We address this by bringing elastic computing\ntechniques and dynamic resource management from the edge-cloud computing domain\nto the swarm robotics domain. This enables the dynamic provisioning of\ncollective capabilities in the swarm for different applications. Therefore, we\ntransform a swarm into a distributed sensing and computing platform capable of\ncomplex data processing tasks, which can then be offered as a service. In\nparticular, we discuss how this can be applied to adaptive resource management\nin a heterogeneous swarm of drones, and how we are implementing the dynamic\ndeployment of distributed data processing algorithms. With an elastic drone\nswarm built on reconfigurable hardware and containerized services, it will be\npossible to raise the self-awareness, degree of intelligence, and level of\nautonomy of heterogeneous swarms of robots. We describe novel directions for\ncollaborative perception, and new ways of interacting with a robotic swarm.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 07:35:11 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Queralta", "Jorge Pe\u00f1a", ""], ["Qingqing", "Li", ""], ["Gia", "Tuan Nguyen", ""], ["Truong", "Hong-Linh", ""], ["Westerlund", "Tomi", ""]]}, {"id": "2004.14107", "submitter": "He Wang", "authors": "Feixiang He, Yuanhang Xiang, Xi Zhao, He Wang", "title": "Informative Scene Decomposition for Crowd Analysis, Comparison and\n  Simulation Guidance", "comments": "accepted in SIGGRAPH 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.CV cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crowd simulation is a central topic in several fields including graphics. To\nachieve high-fidelity simulations, data has been increasingly relied upon for\nanalysis and simulation guidance. However, the information in real-world data\nis often noisy, mixed and unstructured, making it difficult for effective\nanalysis, therefore has not been fully utilized. With the fast-growing volume\nof crowd data, such a bottleneck needs to be addressed. In this paper, we\npropose a new framework which comprehensively tackles this problem. It centers\nat an unsupervised method for analysis. The method takes as input raw and noisy\ndata with highly mixed multi-dimensional (space, time and dynamics)\ninformation, and automatically structure it by learning the correlations among\nthese dimensions. The dimensions together with their correlations fully\ndescribe the scene semantics which consists of recurring activity patterns in a\nscene, manifested as space flows with temporal and dynamics profiles. The\neffectiveness and robustness of the analysis have been tested on datasets with\ngreat variations in volume, duration, environment and crowd dynamics. Based on\nthe analysis, new methods for data visualization, simulation evaluation and\nsimulation guidance are also proposed. Together, our framework establishes a\nhighly automated pipeline from raw data to crowd analysis, comparison and\nsimulation guidance. Extensive experiments and evaluations have been conducted\nto show the flexibility, versatility and intuitiveness of our framework.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 12:03:32 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["He", "Feixiang", ""], ["Xiang", "Yuanhang", ""], ["Zhao", "Xi", ""], ["Wang", "He", ""]]}, {"id": "2004.14110", "submitter": "Stefan Ivi\\'c", "authors": "Stefan Ivi\\'c, Bojan Crnkovi\\'c, Hassan Arbabi, Sophie Loire, Patrick\n  Clary, Igor Mezi\\'c", "title": "Search strategy in a complex and dynamic environment: the MH370 case", "comments": "15 pages, 9 figures, improved manuscript version", "journal-ref": null, "doi": "10.1038/s41598-020-76274-0", "report-no": null, "categories": "math.OC cs.MA cs.RO eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Search and detection of objects on the ocean surface is a challenging task\ndue to the complexity of the drift dynamics and lack of known optimal solutions\nfor the path of the search agents. This challenge was highlighted by the\nunsuccessful search for Malaysian Flight 370 (MH370) which disappeared on March\n8, 2014. In this paper, we propose an improvement of a search algorithm rooted\nin the ergodic theory of dynamical systems which can accommodate complex\ngeometries and uncertainties of the drifting search areas on the ocean surface.\nWe illustrate the effectiveness of this algorithm in a computational\nreplication of the conducted search for MH370. In comparison to conventional\nsearch methods, the proposed algorithm leads to an order of magnitude\nimprovement in success rate over the time period of the actual search\noperation. Simulations of the proposed search control also indicate that the\ninitial success rate of finding debris increases in the event of delayed search\ncommencement. This is due to the existence of convergence zones in the search\narea which leads to local aggregation of debris in those zones and hence\nreduction of the effective size of the area to be searched.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 12:08:26 GMT"}, {"version": "v2", "created": "Wed, 29 Jul 2020 11:40:21 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Ivi\u0107", "Stefan", ""], ["Crnkovi\u0107", "Bojan", ""], ["Arbabi", "Hassan", ""], ["Loire", "Sophie", ""], ["Clary", "Patrick", ""], ["Mezi\u0107", "Igor", ""]]}, {"id": "2004.14548", "submitter": "Andr\\'e C. R. Martins", "authors": "Andr\\'e C. R. Martins", "title": "Extremism definitions in opinion dynamics models", "comments": "17 pages, 2 figures, 1 table, to appear in the ICCS2020 Proceedings\n  (Tenth International Conference on Complex Systems)", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.MA nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are several opinion dynamics models where extremism is defined as part\nof their characteristics. However, the way extremism is implemented in each\nmodel does not correspond to equivalent definitions. While some models focus on\none aspect of the problem, others focus on different characteristics. This\npaper shows how each model only captures part of the problem and how Bayesian\ninspired opinion models can help put those differences in perspective. That\ndiscussion suggests new ways to introduce variables that can represent the\nproblem of extremism better than we do today.\n  Keywords: Extremism, Opinion dynamics, CODA, Sociophysics\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 02:23:31 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Martins", "Andr\u00e9 C. R.", ""]]}, {"id": "2004.14939", "submitter": "Stanislav Zhydkov", "authors": "Nicholas Mattei, Paolo Turrini, Stanislav Zhydkov", "title": "PeerNomination: Relaxing Exactness for Increased Accuracy in Peer\n  Selection", "comments": "7 pages, 5 figures, submitted to IJCAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In peer selection agents must choose a subset of themselves for an award or a\nprize. As agents are self-interested, we want to design algorithms that are\nimpartial, so that an individual agent cannot affect their own chance of being\nselected. This problem has broad application in resource allocation and\nmechanism design and has received substantial attention in the artificial\nintelligence literature. Here, we present a novel algorithm for impartial peer\nselection, PeerNomination, and provide a theoretical analysis of its accuracy.\nOur algorithm possesses various desirable features. In particular, it does not\nrequire an explicit partitioning of the agents, as previous algorithms in the\nliterature. We show empirically that it achieves higher accuracy than the\nexiting algorithms over several metrics.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 16:39:47 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Mattei", "Nicholas", ""], ["Turrini", "Paolo", ""], ["Zhydkov", "Stanislav", ""]]}, {"id": "2004.15023", "submitter": "Juste Raimbault", "authors": "Juste Raimbault", "title": "A model of urban evolution based on innovation diffusion", "comments": "8 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The dynamics of urban systems can be understood from an evolutionary\nperspective, in some sense extending biological and cultural evolution. Models\nfor systems of cities implementing elementary evolutionary processes remain\nhowever to be investigated. We propose here such a model for urban dynamics at\nthe macroscopic scale, in which the diffusion of innovations between cities\ncaptures transformation processes (mutations) and transmission processes\n(diffusion), using two coupled spatial interaction models. Explorations of the\nmodel on synthetic systems of cities show the role of spatial interaction and\ninnovation diffusion ranges on measures of diversity and utility, and the\nexistence of intermediate ranges yielding an optimal utility. Multi-objective\noptimization shows how the model produces a compromise between utility and\ndiversity. This model paves the way towards more elaborated formalizations of\nurban evolution.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 17:59:38 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Raimbault", "Juste", ""]]}]