[{"id": "1709.00951", "submitter": "Venkata Karteek Yanumula", "authors": "Venkata Karteek Yanumula, Indrani Kar and Somanath Majhi", "title": "Consensus of second order multi-agents with actuator saturation and\n  asynchronous time-delays", "comments": "10 pages", "journal-ref": "IET Control Theory Appl., 2017, Vol. 11 Iss. 17, pp. 3201-321", "doi": "10.1049/iet-cta.2017.0578", "report-no": null, "categories": "cs.MA cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents the consensus of a saturated second order multi-agent\nsystem with non-switching dynamics that can be represented by a directed graph.\nThe system is affected by data processing (input delay) and communication\ntime-delays that are assumed to be asynchronous. The agents have saturation\nnonlinearities, each of them is approximated into separate linear and nonlinear\nelements. Nonlinear elements are represented by describing functions.\nDescribing functions and stability of linear elements are used to estimate the\nexistence of limit cycles in the system with multiple control laws. Stability\nanalysis of the linear element is performed using Lyapunov-Krasovskii functions\nand frequency domain analysis. A comparison of pros and cons of both the\nanalyses with respect to time-delay ranges, applicability and computation\ncomplexity is presented. Simulation and corresponding hardware implementation\nresults are demonstrated to support theoretical results.\n", "versions": [{"version": "v1", "created": "Mon, 4 Sep 2017 13:36:14 GMT"}, {"version": "v2", "created": "Thu, 28 Sep 2017 05:52:52 GMT"}, {"version": "v3", "created": "Thu, 23 Nov 2017 09:16:50 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Yanumula", "Venkata Karteek", ""], ["Kar", "Indrani", ""], ["Majhi", "Somanath", ""]]}, {"id": "1709.01070", "submitter": "Pavel Surynek", "authors": "Marika Ivanov\\'a, Pavel Surynek, Diep Thi Ngoc Nguyen", "title": "Maintaining Ad-Hoc Communication Network in Area Protection Scenarios\n  with Adversarial Agents", "comments": "arXiv admin note: substantial text overlap with arXiv:1708.07285", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address a problem of area protection in graph-based scenarios with\nmultiple mobile agents where connectivity is maintained among agents to ensure\nthey can communicate. The problem consists of two adversarial teams of agents\nthat move in an undirected graph shared by both teams. Agents are placed in\nvertices of the graph; at most one agent can occupy a vertex; and they can move\ninto adjacent vertices in a conflict free way. Teams have asymmetric goals: the\naim of one team - attackers - is to invade into given area while the aim of the\nopponent team - defenders - is to protect the area from being entered by\nattackers by occupying selected vertices. The team of defenders need to\nmaintain connectivity of vertices occupied by its own agents in a visibility\ngraph. The visibility graph models possibility of communication between pairs\nof vertices.\n  We study strategies for allocating vertices to be occupied by the team of\ndefenders to block attacking agents where connectivity is maintained at the\nsame time. To do this we reserve a subset of defending agents that do not try\nto block the attackers but instead are placed to support connectivity of the\nteam. The performance of strategies is tested in multiple benchmarks. The\nsuccess of a strategy is heavily dependent on the type of the instance, and so\none of the contributions of this work is that we identify suitable strategies\nfor diverse instance types.\n", "versions": [{"version": "v1", "created": "Mon, 4 Sep 2017 07:38:17 GMT"}], "update_date": "2017-09-06", "authors_parsed": [["Ivanov\u00e1", "Marika", ""], ["Surynek", "Pavel", ""], ["Nguyen", "Diep Thi Ngoc", ""]]}, {"id": "1709.01150", "submitter": "Milad Siami", "authors": "Milad Siami and Nader Motee", "title": "Abstraction of Linear Consensus Networks with Guaranteed Systemic\n  Performance Measures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.MA math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A proper abstraction of a large-scale linear consensus network with a dense\ncoupling graph is one whose number of coupling links is proportional to its\nnumber of subsystems and its performance is comparable to the original network.\nOptimal design problems for an abstracted network are more amenable to\nefficient optimization algorithms. From the implementation point of view,\nmaintaining such networks are usually more favorable and cost effective due to\ntheir reduced communication requirements across a network. Therefore,\napproximating a given dense linear consensus network by a suitable abstract\nnetwork is an important analysis and synthesis problem. In this paper, we\ndevelop a framework to compute an abstraction of a given large-scale linear\nconsensus network with guaranteed performance bounds using a nearly-linear time\nalgorithm. First, the existence of abstractions of a given network is proven.\nThen, we present an efficient and fast algorithm for computing a proper\nabstraction of a given network. Finally, we illustrate the effectiveness of our\ntheoretical findings via several numerical simulations.\n", "versions": [{"version": "v1", "created": "Mon, 4 Sep 2017 20:52:21 GMT"}], "update_date": "2017-09-06", "authors_parsed": [["Siami", "Milad", ""], ["Motee", "Nader", ""]]}, {"id": "1709.01586", "submitter": "Kunal Garg", "authors": "Kunal Garg, Dongkun Han, Dimitra Panagou", "title": "Robust Semi-Cooperative Multi-Agent Coordination in the Presence of\n  Stochastic Disturbances", "comments": "K. Garg, D. Han and D. Panagou \"Robust Semi-Cooperative Multi-Agent\n  Coordination in the Presence of Stochastic Disturbances\", 56th IEEE Conf. on\n  Decision and Control, Melbourne, Australia, December 2017", "journal-ref": null, "doi": "10.1109/CDC.2017.8264163", "report-no": null, "categories": "cs.SY cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a robust distributed coordination protocol that achieves\ngeneration of collision-free trajectories for multiple unicycle agents in the\npresence of stochastic uncertainties. We build upon our earlier work on\nsemi-cooperative coordination and we redesign the coordination controllers so\nthat the agents counteract a class of state (wind) disturbances and measurement\nnoise. Safety and convergence is proved analytically, while simulation results\ndemonstrate the efficacy of the proposed solution.\n", "versions": [{"version": "v1", "created": "Tue, 5 Sep 2017 20:40:23 GMT"}, {"version": "v2", "created": "Fri, 15 Sep 2017 21:38:23 GMT"}, {"version": "v3", "created": "Fri, 5 Jan 2018 19:04:28 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Garg", "Kunal", ""], ["Han", "Dongkun", ""], ["Panagou", "Dimitra", ""]]}, {"id": "1709.02556", "submitter": "EPTCS", "authors": "L\\'aszl\\'o Z. Varga (ELTE E\\\"otv\\\"os Lor\\'and University)", "title": "Game Theory Models for the Verification of the Collective Behaviour of\n  Autonomous Cars", "comments": "In Proceedings FVAV 2017, arXiv:1709.02126", "journal-ref": "EPTCS 257, 2017, pp. 27-34", "doi": "10.4204/EPTCS.257.4", "report-no": null, "categories": "cs.MA cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The collective of autonomous cars is expected to generate almost optimal\ntraffic. In this position paper we discuss the multi-agent models and the\nverification results of the collective behaviour of autonomous cars. We argue\nthat non-cooperative autonomous adaptation cannot guarantee optimal behaviour.\nThe conjecture is that intention aware adaptation with a constraint on\nsimultaneous decision making has the potential to avoid unwanted behaviour. The\nonline routing game model is expected to be the basis to formally prove this\nconjecture.\n", "versions": [{"version": "v1", "created": "Fri, 8 Sep 2017 06:35:10 GMT"}], "update_date": "2017-09-11", "authors_parsed": [["Varga", "L\u00e1szl\u00f3 Z.", "", "ELTE E\u00f6tv\u00f6s Lor\u00e1nd University"]]}, {"id": "1709.02557", "submitter": "EPTCS", "authors": "Lucas E. R. Fernandes (1), Vinicius Custodio (1), Gleifer V. Alves\n  (1), Michael Fisher (2) ((1) UTFPR, Ponta Grossa, Parana, Brazil, (2)\n  University of Liverpool, Liverpool, United Kingdom)", "title": "A Rational Agent Controlling an Autonomous Vehicle: Implementation and\n  Formal Verification", "comments": "In Proceedings FVAV 2017, arXiv:1709.02126", "journal-ref": "EPTCS 257, 2017, pp. 35-42", "doi": "10.4204/EPTCS.257.5", "report-no": null, "categories": "cs.LO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development and deployment of Autonomous Vehicles (AVs) on our roads is\nnot only realistic in the near future but can also bring significant benefits.\nIn particular, it can potentially solve several problems relating to vehicles\nand traffic, for instance: (i) possible reduction of traffic congestion, with\nthe consequence of improved fuel economy and reduced driver inactivity; (ii)\npossible reduction in the number of accidents, assuming that an AV can minimise\nthe human errors that often cause traffic accidents; and (iii) increased ease\nof parking, especially when one considers the potential for shared AVs. In\norder to deploy an AV there are significant steps that must be completed in\nterms of hardware and software. As expected, software components play a key\nrole in the complex AV system and so, at least for safety, we should assess the\ncorrectness of these components.\n  In this paper, we are concerned with the high-level software component(s)\nresponsible for the decisions in an AV. We intend to model an AV capable of\nnavigation; obstacle avoidance; obstacle selection (when a crash is\nunavoidable) and vehicle recovery, etc, using a rational agent. To achieve\nthis, we have established the following stages. First, the agent plans and\nactions have been implemented within the Gwendolen agent programming language.\nSecond, we have built a simulated automotive environment in the Java language.\nThird, we have formally specified some of the required agent properties through\nLTL formulae, which are then formally verified with the AJPF verification tool.\nFinally, within the MCAPL framework (which comprises all the tools used in\nprevious stages) we have obtained formal verification of our AV agent in terms\nof its specific behaviours. For example, the agent plans responsible for\nselecting an obstacle with low potential damage, instead of a higher damage\nobstacle (when possible) can be formally verified within MCAPL. We must\nemphasise that the major goal (of our present approach) lies in the formal\nverification of agent plans, rather than evaluating real-world applications.\nFor this reason we utilised a simple matrix representation concerning the\nenvironment used by our agent.\n", "versions": [{"version": "v1", "created": "Fri, 8 Sep 2017 06:35:30 GMT"}], "update_date": "2017-09-11", "authors_parsed": [["Fernandes", "Lucas E. R.", ""], ["Custodio", "Vinicius", ""], ["Alves", "Gleifer V.", ""], ["Fisher", "Michael", ""]]}, {"id": "1709.03297", "submitter": "Giuseppe Vizzari", "authors": "Luca Crociani, Gregor L\\\"ammel, H. Joon Park, Giuseppe Vizzari", "title": "Cellular Automaton Based Simulation of Large Pedestrian Facilities - A\n  Case Study on the Staten Island Ferry Terminals", "comments": "96th Transportation Research Board annual meeting, Washington,\n  January 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current metropolises largely depend on a functioning transport infrastructure\nand the increasing demand can only be satisfied by a well organized mass\ntransit. One example for a crucial mass transit system is New York City's\nStaten Island Ferry, connecting the two boroughs of Staten Island and Manhattan\nwith a regular passenger service. Today's demand already exceeds 2500\npassengers for a single cycle during peek hours, and future projections suggest\nthat it will further increase. One way to appraise how the system will cope\nwith future demand is by simulation. This contribution proposes an integrated\nsimulation approach to evaluate the system performance with respect to future\ndemand. The simulation relies on a multiscale modeling approach where the\nterminal buildings are simulated by a microscopic and quantitatively valid\ncellular automata (CA) and the journeys of the ferries themselves are modeled\nby a mesoscopic queue simulation approach. Based on the simulation results\nrecommendations with respect to the future demand are given.\n", "versions": [{"version": "v1", "created": "Mon, 11 Sep 2017 08:48:19 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["Crociani", "Luca", ""], ["L\u00e4mmel", "Gregor", ""], ["Park", "H. Joon", ""], ["Vizzari", "Giuseppe", ""]]}, {"id": "1709.03300", "submitter": "Stanis{\\l}aw  Ambroszkiewicz", "authors": "Kamil Skarzynski, Marcin Stepniak, Waldemar Bartyna, Stanislaw\n  Ambroszkiewicz", "title": "SO-MRS: a multi-robot system architecture based on the SOA paradigm and\n  ontology", "comments": "Summary of the research done by the group", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.MA cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A generic architecture for a class of distributed robotic systems is\npresented. The architecture supports openness and heterogeneity, i.e.\nheterogeneous components may be joined and removed from the systems without\naffecting its basic functionality. The architecture is based on the paradigm of\nService Oriented Architecture (SOA), and a generic representation (ontology) of\nthe environment. A device (e.g. robot) is seen as a collection of its\ncapabilities exposed as services. Generic protocols for publishing,\ndiscovering, arranging services are proposed for creating composite services\nthat can accomplish complex tasks in an automatic way. Also generic protocols\nfor execution of composite services are proposed along with simple protocols\nfor monitoring the executions, and for recovery from failures. A software\nplatform built on a multi-robot system (according to the proposed architecture)\nis a multi-agent system.\n", "versions": [{"version": "v1", "created": "Mon, 11 Sep 2017 09:07:25 GMT"}, {"version": "v2", "created": "Thu, 14 Sep 2017 10:04:03 GMT"}], "update_date": "2017-09-15", "authors_parsed": [["Skarzynski", "Kamil", ""], ["Stepniak", "Marcin", ""], ["Bartyna", "Waldemar", ""], ["Ambroszkiewicz", "Stanislaw", ""]]}, {"id": "1709.03846", "submitter": "Mohammadreza Doostmohammadian", "authors": "Mohammadreza Doostmohammadian, Hamid R. Rabiee, Houman Zarrabi, Usman\n  Khan", "title": "Observational Equivalence in System Estimation: Contractions in Complex\n  Networks", "comments": "IEEE Transactions on Network Science and Engineering", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.MA cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Observability of complex systems/networks is the focus of this paper, which\nis shown to be closely related to the concept of contraction. Indeed, for\nobservable network tracking it is necessary/sufficient to have one node in each\ncontraction measured. Therefore, nodes in a contraction are equivalent to\nrecover for loss of observability, implying that contraction size is a key\nfactor for observability recovery. Here, using a polynomial order contraction\ndetection algorithm, we analyze the distribution of contractions, studying its\nrelation with key network properties. Our results show that contraction size is\nrelated to network clustering coefficient and degree heterogeneity.\nParticularly, in networks with power-law degree distribution, if the clustering\ncoefficient is high there are less contractions with smaller size on average.\nThe implication is that estimation/tracking of such systems requires less\nnumber of measurements, while their observational recovery is more restrictive\nin case of sensor failure. Further, in Small-World networks higher degree\nheterogeneity implies that there are more contractions with smaller size on\naverage. Therefore, the estimation of representing system requires more\nmeasurements, and also the recovery of measurement failure is more limited.\nThese results imply that one can tune the properties of synthetic networks to\nalleviate their estimation/observability recovery.\n", "versions": [{"version": "v1", "created": "Tue, 12 Sep 2017 13:56:50 GMT"}], "update_date": "2017-09-13", "authors_parsed": [["Doostmohammadian", "Mohammadreza", ""], ["Rabiee", "Hamid R.", ""], ["Zarrabi", "Houman", ""], ["Khan", "Usman", ""]]}, {"id": "1709.03855", "submitter": "Mohammadreza Doostmohammadian", "authors": "Mohammadreza Doostmohammadian, Hamid R. Rabiee, Houman Zarrabi, Usman\n  A. Khan", "title": "Distributed Estimation Recovery under Sensor Failure", "comments": "IEEE signal processing letters", "journal-ref": null, "doi": "10.1109/LSP.2017.2749265", "report-no": null, "categories": "cs.SY cs.MA cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Single time-scale distributed estimation of dynamic systems via a network of\nsensors/estimators is addressed in this letter. In single time-scale\ndistributed estimation, the two fusion steps, consensus and measurement\nexchange, are implemented only once, in contrast to, e.g., a large number of\nconsensus iterations at every step of the system dynamics. We particularly\ndiscuss the problem of failure in the sensor/estimator network and how to\nrecover for distributed estimation by adding new sensor measurements from\nequivalent states. We separately discuss the recovery for two types of sensors,\nnamely \\alpha and \\beta sensors. We propose polynomial order algorithms to find\nequivalent state nodes in graph representation of system to recover for\ndistributed observability. The polynomial order solution is particularly\nsignificant for large-scale systems.\n", "versions": [{"version": "v1", "created": "Tue, 12 Sep 2017 14:10:45 GMT"}], "update_date": "2017-10-11", "authors_parsed": [["Doostmohammadian", "Mohammadreza", ""], ["Rabiee", "Hamid R.", ""], ["Zarrabi", "Houman", ""], ["Khan", "Usman A.", ""]]}, {"id": "1709.04049", "submitter": "Wen Shen", "authors": "Wen Shen, Jacob W. Crandall, Ke Yan, Cristina V. Lopes", "title": "Information Design in Crowdfunding under Thresholding Policies", "comments": "9 pages, 2 figures, In Proceedings of the 17th International\n  Conference on Autonomous Agents and Multiagent Systems (AAMAS 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.MA", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Crowdfunding has emerged as a prominent way for entrepreneurs to secure\nfunding without sophisticated intermediation. In crowdfunding, an entrepreneur\noften has to decide how to disclose the campaign status in order to collect as\nmany contributions as possible. Such decisions are difficult to make primarily\ndue to incomplete information. We propose information design as a tool to help\nthe entrepreneur to improve revenue by influencing backers' beliefs. We\nintroduce a heuristic algorithm to dynamically compute information-disclosure\npolicies for the entrepreneur, followed by an empirical evaluation to\ndemonstrate its competitiveness over the widely-adopted immediate-disclosure\npolicy. Our results demonstrate that the immediate-disclosure policy is not\noptimal when backers follow thresholding policies despite its ease of\nimplementation. With appropriate heuristics, an entrepreneur can benefit from\ndynamic information disclosure. Our work sheds light on information design in a\ndynamic setting where agents make decisions using thresholding policies.\n", "versions": [{"version": "v1", "created": "Tue, 12 Sep 2017 20:29:08 GMT"}, {"version": "v2", "created": "Thu, 16 Nov 2017 20:27:16 GMT"}, {"version": "v3", "created": "Tue, 21 Nov 2017 23:32:14 GMT"}, {"version": "v4", "created": "Sat, 17 Mar 2018 18:31:53 GMT"}, {"version": "v5", "created": "Wed, 28 Mar 2018 19:55:42 GMT"}], "update_date": "2018-03-30", "authors_parsed": [["Shen", "Wen", ""], ["Crandall", "Jacob W.", ""], ["Yan", "Ke", ""], ["Lopes", "Cristina V.", ""]]}, {"id": "1709.04511", "submitter": "Yaodong Yang Mr.", "authors": "Yaodong Yang, Lantao Yu, Yiwei Bai, Jun Wang, Weinan Zhang, Ying Wen,\n  Yong Yu", "title": "A Study of AI Population Dynamics with Million-agent Reinforcement\n  Learning", "comments": "Full version of the paper presented at AAMAS 2018 (International\n  Conference on Autonomous Agents and Multiagent Systems)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We conduct an empirical study on discovering the ordered collective dynamics\nobtained by a population of intelligence agents, driven by million-agent\nreinforcement learning. Our intention is to put intelligent agents into a\nsimulated natural context and verify if the principles developed in the real\nworld could also be used in understanding an artificially-created intelligent\npopulation. To achieve this, we simulate a large-scale predator-prey world,\nwhere the laws of the world are designed by only the findings or logical\nequivalence that have been discovered in nature. We endow the agents with the\nintelligence based on deep reinforcement learning (DRL). In order to scale the\npopulation size up to millions agents, a large-scale DRL training platform with\nredesigned experience buffer is proposed. Our results show that the population\ndynamics of AI agents, driven only by each agent's individual self-interest,\nreveals an ordered pattern that is similar to the Lotka-Volterra model studied\nin population biology. We further discover the emergent behaviors of collective\nadaptations in studying how the agents' grouping behaviors will change with the\nenvironmental resources. Both of the two findings could be explained by the\nself-organization theory in nature.\n", "versions": [{"version": "v1", "created": "Wed, 13 Sep 2017 19:21:57 GMT"}, {"version": "v2", "created": "Sun, 17 Sep 2017 23:06:31 GMT"}, {"version": "v3", "created": "Thu, 5 Oct 2017 13:25:18 GMT"}, {"version": "v4", "created": "Mon, 14 May 2018 13:30:45 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Yang", "Yaodong", ""], ["Yu", "Lantao", ""], ["Bai", "Yiwei", ""], ["Wang", "Jun", ""], ["Zhang", "Weinan", ""], ["Wen", "Ying", ""], ["Yu", "Yong", ""]]}, {"id": "1709.04622", "submitter": "Varuna De Silva D", "authors": "Varuna De Silva, Xiongzhao Wang, Deniz Aladagli, Ahmet Kondoz, Erhan\n  Ekmekcioglu", "title": "An Agent-based Modelling Framework for Driving Policy Learning in\n  Connected and Autonomous Vehicles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the complexity of the natural world, a programmer cannot foresee all\npossible situations, a connected and autonomous vehicle (CAV) will face during\nits operation, and hence, CAVs will need to learn to make decisions\nautonomously. Due to the sensing of its surroundings and information exchanged\nwith other vehicles and road infrastructure, a CAV will have access to large\namounts of useful data. While different control algorithms have been proposed\nfor CAVs, the benefits brought about by connectedness of autonomous vehicles to\nother vehicles and to the infrastructure, and its implications on policy\nlearning has not been investigated in literature. This paper investigates a\ndata driven driving policy learning framework through an agent-based modelling\napproaches. The contributions of the paper are two-fold. A dynamic programming\nframework is proposed for in-vehicle policy learning with and without\nconnectivity to neighboring vehicles. The simulation results indicate that\nwhile a CAV can learn to make autonomous decisions, vehicle-to-vehicle (V2V)\ncommunication of information improves this capability. Furthermore, to overcome\nthe limitations of sensing in a CAV, the paper proposes a novel concept for\ninfrastructure-led policy learning and communication with autonomous vehicles.\nIn infrastructure-led policy learning, road-side infrastructure senses and\ncaptures successful vehicle maneuvers and learns an optimal policy from those\ntemporal sequences, and when a vehicle approaches the road-side unit, the\npolicy is communicated to the CAV. Deep-imitation learning methodology is\nproposed to develop such an infrastructure-led policy learning framework.\n", "versions": [{"version": "v1", "created": "Thu, 14 Sep 2017 06:01:56 GMT"}, {"version": "v2", "created": "Mon, 29 Jan 2018 14:42:11 GMT"}, {"version": "v3", "created": "Tue, 17 Apr 2018 14:12:12 GMT"}, {"version": "v4", "created": "Thu, 23 Aug 2018 04:20:34 GMT"}], "update_date": "2018-08-24", "authors_parsed": [["De Silva", "Varuna", ""], ["Wang", "Xiongzhao", ""], ["Aladagli", "Deniz", ""], ["Kondoz", "Ahmet", ""], ["Ekmekcioglu", "Erhan", ""]]}, {"id": "1709.04906", "submitter": "Federico Rossi", "authors": "Federico Rossi, Ramon Iglesias, Mahnoosh Alizadeh, Marco Pavone", "title": "On the interaction between Autonomous Mobility-on-Demand systems and the\n  power network: models and coordination algorithms", "comments": "Extended version of the paper presented at Robotics: Science and\n  Systems XIV and accepted by TCNS. In Version 4, the body of the paper is\n  largely rewritten for clarity and consistency, and new numerical simulations\n  are presented. All source code is available (MIT) at\n  https://dx.doi.org/10.5281/zenodo.3241651", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the interaction between a fleet of electric, self-driving vehicles\nservicing on-demand transportation requests (referred to as Autonomous\nMobility-on-Demand, or AMoD, system) and the electric power network. We propose\na model that captures the coupling between the two systems stemming from the\nvehicles' charging requirements and captures time-varying customer demand and\npower generation costs, road congestion, battery depreciation, and power\ntransmission and distribution constraints. We then leverage the model to\njointly optimize the operation of both systems. We devise an algorithmic\nprocedure to losslessly reduce the problem size by bundling customer requests,\nallowing it to be efficiently solved by off-the-shelf linear programming\nsolvers. Next, we show that the socially optimal solution to the joint problem\ncan be enforced as a general equilibrium, and we provide a dual decomposition\nalgorithm that allows self-interested agents to compute the market clearing\nprices without sharing private information. We assess the performance of the\nmode by studying a hypothetical AMoD system in Dallas-Fort Worth and its impact\non the Texas power network. Lack of coordination between the AMoD system and\nthe power network can cause a 4.4% increase in the price of electricity in\nDallas-Fort Worth; conversely, coordination between the AMoD system and the\npower network could reduce electricity expenditure compared to the case where\nno cars are present (despite the increased demand for electricity) and yield\nsavings of up $147M/year. Finally, we provide a receding-horizon implementation\nand assess its performance with agent-based simulations. Collectively, the\nresults of this paper provide a first-of-a-kind characterization of the\ninteraction between electric-powered AMoD systems and the power network, and\nshed additional light on the economic and societal value of AMoD.\n", "versions": [{"version": "v1", "created": "Thu, 14 Sep 2017 17:53:02 GMT"}, {"version": "v2", "created": "Fri, 22 Sep 2017 00:23:13 GMT"}, {"version": "v3", "created": "Wed, 27 Jun 2018 15:39:50 GMT"}, {"version": "v4", "created": "Sat, 8 Jun 2019 19:54:29 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Rossi", "Federico", ""], ["Iglesias", "Ramon", ""], ["Alizadeh", "Mahnoosh", ""], ["Pavone", "Marco", ""]]}, {"id": "1709.05142", "submitter": "Julien Hendrickx", "authors": "Julien M. Hendrickx and Samuel Martin", "title": "Open Multi-Agent Systems: Gossiping with Random Arrivals and Departures", "comments": "Extended version of a paper Accepted at the 56th IEEE Conference on\n  Decision and Control (CDC 17), Melbourne, Australia 8 pages, 5 pdf figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider open multi-agent systems. Unlike the systems usually studied in\nthe literature, here agents may join or leave while the process studied takes\nplace. The system composition and size evolve thus with time. We focus here on\nsystems where the interactions between agents lead to pairwise gossip averages,\nand where agents either arrive or are replaced at random times. These events\nprevent any convergence of the system. Instead, we describe the expected system\nbehavior by showing that the evolution of scaled moments of the state can be\ncharacterized by a 2-dimensional (possibly time-varying) linear dynamical\nsystem. We apply this technique to two cases : (i) systems with fixed size\nwhere leaving agents are immediately replaced, and (ii) systems where new\nagents keep arriving without ever leaving, and whose size grows thus unbounded.\n", "versions": [{"version": "v1", "created": "Fri, 15 Sep 2017 10:17:56 GMT"}], "update_date": "2017-09-18", "authors_parsed": [["Hendrickx", "Julien M.", ""], ["Martin", "Samuel", ""]]}, {"id": "1709.05273", "submitter": "Maximilian Naumann", "authors": "Eike Rehder, Maximilian Naumann, Niels Ole Salscheider, Christoph\n  Stiller", "title": "Cooperative Motion Planning for Non-Holonomic Agents with Value\n  Iteration Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cooperative motion planning is still a challenging task for robots. Recently,\nValue Iteration Networks (VINs) were proposed to model motion planning tasks as\nNeural Networks. In this work, we extend VINs to solve cooperative planning\ntasks under non-holonomic constraints. For this, we interconnect multiple VINs\nto pay respect to each other's outputs. Policies for cooperation are generated\nvia iterative gradient descend. Validation in simulation shows that the\nresulting networks can resolve non-holonomic motion planning problems that\nrequire cooperation.\n", "versions": [{"version": "v1", "created": "Fri, 15 Sep 2017 15:36:51 GMT"}], "update_date": "2017-09-18", "authors_parsed": [["Rehder", "Eike", ""], ["Naumann", "Maximilian", ""], ["Salscheider", "Niels Ole", ""], ["Stiller", "Christoph", ""]]}, {"id": "1709.05793", "submitter": "Julien Hendrickx", "authors": "Mahmoud Abdelrahim, Julien M. Hendrickx and W.P.M.H. Heemels", "title": "MAX-consensus in open multi-agent systems with gossip interactions", "comments": "To appear in the proceedings of the 56th IEEE Conference on Decision\n  and Control (CDC 17). 8 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of distributed maximum computation in an open\nmulti-agent system, where agents can leave and arrive during the execution of\nthe algorithm. The main challenge comes from the possibility that the agent\nholding the largest value leaves the system, which changes the value to be\ncomputed. The algorithms must as a result be endowed with mechanisms allowing\nto forget outdated information. The focus is on systems in which interactions\nare pairwise gossips between randomly selected agents. We consider situations\nwhere leaving agents can send a last message, and situations where they cannot.\nFor both cases, we provide algorithms able to eventually compute the maximum of\nthe values held by agents.\n", "versions": [{"version": "v1", "created": "Mon, 18 Sep 2017 07:21:33 GMT"}], "update_date": "2017-09-19", "authors_parsed": [["Abdelrahim", "Mahmoud", ""], ["Hendrickx", "Julien M.", ""], ["Heemels", "W. P. M. H.", ""]]}, {"id": "1709.05843", "submitter": "Xiaotian Yang", "authors": "Xiaotian Yang", "title": "Decentralized Collision-Free Control of Multiple Robots in 2D and 3D\n  Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decentralized control of robots has attracted huge research interests.\nHowever, some of the research used unrealistic assumptions without collision\navoidance. This report focuses on the collision-free control for multiple\nrobots in both complete coverage and search tasks in 2D and 3D areas which are\narbitrary unknown. All algorithms are decentralized as robots have limited\nabilities and they are mathematically proved.\n  The report starts with the grid selection in the two tasks. Grid patterns\nsimplify the representation of the area and robots only need to move straightly\nbetween neighbor vertices. For the 100% complete 2D coverage, the equilateral\ntriangular grid is proposed. For the complete coverage ignoring the boundary\neffect, the grid with the fewest vertices is calculated in every situation for\nboth 2D and 3D areas.\n  The second part is for the complete coverage in 2D and 3D areas. A\ndecentralized collision-free algorithm with the above selected grid is\npresented driving robots to sections which are furthest from the reference\npoint. The area can be static or expanding, and the algorithm is simulated in\nMATLAB.\n  Thirdly, three grid-based decentralized random algorithms with collision\navoidance are provided to search targets in 2D or 3D areas. The number of\ntargets can be known or unknown. In the first algorithm, robots choose vacant\nneighbors randomly with priorities on unvisited ones while the second one adds\nthe repulsive force to disperse robots if they are close. In the third\nalgorithm, if surrounded by visited vertices, the robot will use the\nbreadth-first search algorithm to go to one of the nearest unvisited vertices\nvia the grid. The second search algorithm is verified on Pioneer 3-DX robots.\nThe general way to generate the formula to estimate the search time is\ndemonstrated. Algorithms are compared with five other algorithms in MATLAB to\nshow their effectiveness.\n", "versions": [{"version": "v1", "created": "Mon, 18 Sep 2017 10:13:46 GMT"}], "update_date": "2017-09-19", "authors_parsed": [["Yang", "Xiaotian", ""]]}, {"id": "1709.06011", "submitter": "Maximilian Huettenrauch", "authors": "Maximilian H\\\"uttenrauch and Adrian \\v{S}o\\v{s}i\\'c and Gerhard\n  Neumann", "title": "Guided Deep Reinforcement Learning for Swarm Systems", "comments": "15 pages, 8 figures, accepted at the AAMAS 2017 Autonomous Robots and\n  Multirobot Systems (ARMS) Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate how to learn to control a group of cooperative\nagents with limited sensing capabilities such as robot swarms. The agents have\nonly very basic sensor capabilities, yet in a group they can accomplish\nsophisticated tasks, such as distributed assembly or search and rescue tasks.\nLearning a policy for a group of agents is difficult due to distributed partial\nobservability of the state. Here, we follow a guided approach where a critic\nhas central access to the global state during learning, which simplifies the\npolicy evaluation problem from a reinforcement learning point of view. For\nexample, we can get the positions of all robots of the swarm using a camera\nimage of a scene. This camera image is only available to the critic and not to\nthe control policies of the robots. We follow an actor-critic approach, where\nthe actors base their decisions only on locally sensed information. In\ncontrast, the critic is learned based on the true global state. Our algorithm\nuses deep reinforcement learning to approximate both the Q-function and the\npolicy. The performance of the algorithm is evaluated on two tasks with simple\nsimulated 2D agents: 1) finding and maintaining a certain distance to each\nothers and 2) locating a target.\n", "versions": [{"version": "v1", "created": "Mon, 18 Sep 2017 15:37:45 GMT"}], "update_date": "2017-09-19", "authors_parsed": [["H\u00fcttenrauch", "Maximilian", ""], ["\u0160o\u0161i\u0107", "Adrian", ""], ["Neumann", "Gerhard", ""]]}, {"id": "1709.06071", "submitter": "S. Rasoul Etesami", "authors": "Georges El Rahi, S. Rasoul Etesami, Walid Saad, Narayan Mandayam, and\n  H. Vincent Poor", "title": "Managing Price Uncertainty in Prosumer-Centric Energy Trading: A\n  Prospect-Theoretic Stackelberg Game Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the problem of energy trading between smart grid prosumers,\nwho can simultaneously consume and produce energy, and a grid power company is\nstudied. The problem is formulated as a single-leader, multiple-follower\nStackelberg game between the power company and multiple prosumers. In this\ngame, the power company acts as a leader who determines the pricing strategy\nthat maximizes its profits, while the prosumers act as followers who react by\nchoosing the amount of energy to buy or sell so as to optimize their current\nand future profits. The proposed game accounts for each prosumer's subjective\ndecision when faced with the uncertainty of profits, induced by the random\nfuture price. In particular, the framing effect, from the framework of prospect\ntheory (PT), is used to account for each prosumer's valuation of its gains and\nlosses with respect to an individual utility reference point. The reference\npoint changes between prosumers and stems from their past experience and future\naspirations of profits. The followers' noncooperative game is shown to admit a\nunique pure-strategy Nash equilibrium (NE) under classical game theory (CGT)\nwhich is obtained using a fully distributed algorithm. The results are extended\nto account for the case of PT using algorithmic solutions that can achieve an\nNE under certain conditions. Simulation results show that the total grid load\nvaries significantly with the prosumers' reference point and their\nloss-aversion level. In addition, it is shown that the power company's profits\nconsiderably decrease when it fails to account for the prosumers' subjective\nperceptions under PT.\n", "versions": [{"version": "v1", "created": "Mon, 18 Sep 2017 17:57:48 GMT"}], "update_date": "2017-09-19", "authors_parsed": [["Rahi", "Georges El", ""], ["Etesami", "S. Rasoul", ""], ["Saad", "Walid", ""], ["Mandayam", "Narayan", ""], ["Poor", "H. Vincent", ""]]}, {"id": "1709.06461", "submitter": "Nuno Crokidakis", "authors": "Marcelo A. Pires, Andr\\'e L. Oestereich, Nuno Crokidakis", "title": "Sudden transitions in coupled opinion and epidemic dynamics with\n  vaccination", "comments": "25 pages, 11 figures, to appear in JSTAT", "journal-ref": "J. Stat. Mech. 053407 (2018)", "doi": "10.1088/1742-5468/aabfc6", "report-no": null, "categories": "physics.soc-ph cond-mat.stat-mech cs.MA q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work consists of an epidemic model with vaccination coupled with an\nopinion dynamics. Our objective was to study how disease risk perception can\ninfluence opinions about vaccination and therefore the spreading of the\ndisease. Differently from previous works we have considered continuous\nopinions. The epidemic spreading is governed by a SIS-like model with an extra\nvaccinated state. In our model individuals vaccinate with a probability\nproportional to their opinions. The opinions change due to peer influence in\npairwise interactions. The epidemic feedback to the opinion dynamics acts as an\nexternal field increasing the vaccination probability. We performed Monte Carlo\nsimulations in fully-connected populations. Interestingly we observed the\nemergence of a first-order phase transition, besides the usual active-absorbing\nphase transition presented in the SIS model. Our simulations also show that\nwith a certain combination of parameters, an increment in the initial fraction\nof the population that is pro-vaccine has a twofold effect: it can lead to\nsmaller epidemic outbreaks in the short term, but it also contributes to the\nsurvival of the chain of infections in the long term. Our results also suggest\nthat it is possible that more effective vaccines can decrease the long-term\nvaccine coverage. This is a counterintuitive outcome, but it is in line with\nempirical observations that vaccines can become a victim of their own success.\n", "versions": [{"version": "v1", "created": "Tue, 19 Sep 2017 14:39:37 GMT"}, {"version": "v2", "created": "Thu, 19 Apr 2018 18:12:50 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Pires", "Marcelo A.", ""], ["Oestereich", "Andr\u00e9 L.", ""], ["Crokidakis", "Nuno", ""]]}, {"id": "1709.06620", "submitter": "Qiyang Li", "authors": "Qiyang Li, Xintong Du, Yizhou Huang, Quinlan Sykora, and Angela P.\n  Schoellig", "title": "Learning of Coordination Policies for Robotic Swarms", "comments": "8 pages, 11 figures, submitted to 2018 IEEE International Conference\n  on Robotics and Automation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.MA cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by biological swarms, robotic swarms are envisioned to solve\nreal-world problems that are difficult for individual agents. Biological swarms\ncan achieve collective intelligence based on local interactions and simple\nrules; however, designing effective distributed policies for large-scale\nrobotic swarms to achieve a global objective can be challenging. Although it is\noften possible to design an optimal centralized strategy for smaller numbers of\nagents, those methods can fail as the number of agents increases. Motivated by\nthe growing success of machine learning, we develop a deep learning approach\nthat learns distributed coordination policies from centralized policies. In\ncontrast to traditional distributed control approaches, which are usually based\non human-designed policies for relatively simple tasks, this learning-based\napproach can be adapted to more difficult tasks. We demonstrate the efficacy of\nour proposed approach on two different tasks, the well-known rendezvous problem\nand a more difficult particle assignment problem. For the latter, no known\ndistributed policy exists. From extensive simulations, it is shown that the\nperformance of the learned coordination policies is comparable to the\ncentralized policies, surpassing state-of-the-art distributed policies.\nThereby, our proposed approach provides a promising alternative for real-world\ncoordination problems that would be otherwise computationally expensive to\nsolve or intangible to explore.\n", "versions": [{"version": "v1", "created": "Tue, 19 Sep 2017 19:26:20 GMT"}], "update_date": "2017-09-21", "authors_parsed": [["Li", "Qiyang", ""], ["Du", "Xintong", ""], ["Huang", "Yizhou", ""], ["Sykora", "Quinlan", ""], ["Schoellig", "Angela P.", ""]]}, {"id": "1709.06652", "submitter": "Christophe Viel", "authors": "Christophe Viel, Sylvain Bertrand, Michel Kieffer, H\\'el\\`ene\n  Piet-Lahanier", "title": "Distributed event-triggered control for multi-agent formation\n  stabilization and tracking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of formation control and tracking a of\ndesired trajectory by an Euler-Lagrange multi-agent systems. It is inspired by\nrecent results by Qingkai et al. and adopts an event-triggered control strategy\nto reduce the number of communications between agents. For that purpose, to\nevaluate its control input, each agent maintains estimators of the states of\nthe other agents. Communication is triggered when the discrepancy between the\nactual state of an agent and the corresponding estimate reaches some threshold.\nThe impact of additive state perturbations on the formation control is studied.\nA condition for the convergence of the multi-agent system to a stable formation\nis studied. Simulations show the effectiveness of the proposed approach.\n", "versions": [{"version": "v1", "created": "Tue, 19 Sep 2017 21:33:49 GMT"}, {"version": "v2", "created": "Tue, 29 May 2018 18:53:04 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Viel", "Christophe", ""], ["Bertrand", "Sylvain", ""], ["Kieffer", "Michel", ""], ["Piet-Lahanier", "H\u00e9l\u00e8ne", ""]]}, {"id": "1709.06656", "submitter": "Kunal Menda", "authors": "Kunal Menda, Yi-Chun Chen, Justin Grana, James W. Bono, Brendan D.\n  Tracey, Mykel J. Kochenderfer, and David Wolpert", "title": "Deep Reinforcement Learning for Event-Driven Multi-Agent Decision\n  Processes", "comments": "Published in IEEE Transactions on Intelligent Transportation Systems\n  (Volume: 20, Issue: 4, April 2019).\n  https://ieeexplore.ieee.org/document/8419722", "journal-ref": "IEEE Transactions on Intelligent Transportation Systems, vol. 20,\n  no. 4, pp. 1259-1268, April 2019", "doi": "10.1109/TITS.2018.2848264", "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The incorporation of macro-actions (temporally extended actions) into\nmulti-agent decision problems has the potential to address the curse of\ndimensionality associated with such decision problems. Since macro-actions last\nfor stochastic durations, multiple agents executing decentralized policies in\ncooperative environments must act asynchronously. We present an algorithm that\nmodifies generalized advantage estimation for temporally extended actions,\nallowing a state-of-the-art policy optimization algorithm to optimize policies\nin Dec-POMDPs in which agents act asynchronously. We show that our algorithm is\ncapable of learning optimal policies in two cooperative domains, one involving\nreal-time bus holding control and one involving wildfire fighting with unmanned\naircraft. Our algorithm works by framing problems as \"event-driven decision\nprocesses,\" which are scenarios in which the sequence and timing of actions and\nevents are random and governed by an underlying stochastic process. In addition\nto optimizing policies with continuous state and action spaces, our algorithm\nalso facilitates the use of event-driven simulators, which do not require time\nto be discretized into time-steps. We demonstrate the benefit of using\nevent-driven simulation in the context of multiple agents taking asynchronous\nactions. We show that fixed time-step simulation risks obfuscating the sequence\nin which closely separated events occur, adversely affecting the policies\nlearned. In addition, we show that arbitrarily shrinking the time-step scales\npoorly with the number of agents.\n", "versions": [{"version": "v1", "created": "Tue, 19 Sep 2017 21:41:51 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 17:15:10 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Menda", "Kunal", ""], ["Chen", "Yi-Chun", ""], ["Grana", "Justin", ""], ["Bono", "James W.", ""], ["Tracey", "Brendan D.", ""], ["Kochenderfer", "Mykel J.", ""], ["Wolpert", "David", ""]]}, {"id": "1709.07032", "submitter": "Ramon Iglesias", "authors": "Ramon Iglesias and Federico Rossi and Kevin Wang and David Hallac and\n  Jure Leskovec and Marco Pavone", "title": "Data-Driven Model Predictive Control of Autonomous Mobility-on-Demand\n  Systems", "comments": "Submitted to the International Conference on Robotics and Automation\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.MA cs.SY stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this paper is to present an end-to-end, data-driven framework to\ncontrol Autonomous Mobility-on-Demand systems (AMoD, i.e. fleets of\nself-driving vehicles). We first model the AMoD system using a time-expanded\nnetwork, and present a formulation that computes the optimal rebalancing\nstrategy (i.e., preemptive repositioning) and the minimum feasible fleet size\nfor a given travel demand. Then, we adapt this formulation to devise a Model\nPredictive Control (MPC) algorithm that leverages short-term demand forecasts\nbased on historical data to compute rebalancing strategies. We test the\nend-to-end performance of this controller with a state-of-the-art LSTM neural\nnetwork to predict customer demand and real customer data from DiDi Chuxing: we\nshow that this approach scales very well for large systems (indeed, the\ncomputational complexity of the MPC algorithm does not depend on the number of\ncustomers and of vehicles in the system) and outperforms state-of-the-art\nrebalancing strategies by reducing the mean customer wait time by up to to\n89.6%.\n", "versions": [{"version": "v1", "created": "Wed, 20 Sep 2017 18:50:39 GMT"}], "update_date": "2017-09-22", "authors_parsed": [["Iglesias", "Ramon", ""], ["Rossi", "Federico", ""], ["Wang", "Kevin", ""], ["Hallac", "David", ""], ["Leskovec", "Jure", ""], ["Pavone", "Marco", ""]]}, {"id": "1709.07121", "submitter": "Mengbin Ye", "authors": "Ji Liu and Mengbin Ye and Brian D.O. Anderson and Tamer Ba\\c{s}ar and\n  Angelia Nedi\\'c", "title": "Discrete-Time Polar Opinion Dynamics with Susceptibility", "comments": "Extended version, with complete proofs, of a submission to the\n  American Control Conference 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.MA cs.SY math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers a discrete-time opinion dynamics model in which each\nindividual's susceptibility to being influenced by others is dependent on her\ncurrent opinion. We assume that the social network has time-varying topology\nand that the opinions are scalars on a continuous interval. We first propose a\ngeneral opinion dynamics model based on the DeGroot model, with a general\nfunction to describe the functional dependence of each individual's\nsusceptibility on her own opinion, and show that this general model is\nanalogous to the Friedkin-Johnsen model, which assumes a constant\nsusceptibility for each individual. We then consider two specific functions in\nwhich the individual's susceptibility depends on the \\emph{polarity} of her\nopinion, and provide motivating social examples. First, we consider stubborn\npositives, who have reduced susceptibility if their opinions are at one end of\nthe interval and increased susceptibility if their opinions are at the opposite\nend. A court jury is used as a motivating example. Second, we consider stubborn\nneutrals, who have reduced susceptibility when their opinions are in the middle\nof the spectrum, and our motivating examples are social networks discussing\nestablished social norms or institutionalized behavior. For each specific\nsusceptibility model, we establish the initial and graph topology conditions in\nwhich consensus is reached, and develop necessary and sufficient conditions on\nthe initial conditions for the final consensus value to be at either extreme of\nthe opinion interval. Simulations are provided to show the effects of the\nsusceptibility function when compared to the DeGroot model.\n", "versions": [{"version": "v1", "created": "Thu, 21 Sep 2017 01:40:45 GMT"}], "update_date": "2017-09-22", "authors_parsed": [["Liu", "Ji", ""], ["Ye", "Mengbin", ""], ["Anderson", "Brian D. O.", ""], ["Ba\u015far", "Tamer", ""], ["Nedi\u0107", "Angelia", ""]]}, {"id": "1709.07224", "submitter": "Maximilian H\\\"uttenrauch", "authors": "Maximilian H\\\"uttenrauch and Adrian \\v{S}o\\v{s}i\\'c and Gerhard\n  Neumann", "title": "Local Communication Protocols for Learning Complex Swarm Behaviors with\n  Deep Reinforcement Learning", "comments": "13 pages, 4 figures, version 2, accepted at ANTS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Swarm systems constitute a challenging problem for reinforcement learning\n(RL) as the algorithm needs to learn decentralized control policies that can\ncope with limited local sensing and communication abilities of the agents.\nWhile it is often difficult to directly define the behavior of the agents,\nsimple communication protocols can be defined more easily using prior knowledge\nabout the given task. In this paper, we propose a number of simple\ncommunication protocols that can be exploited by deep reinforcement learning to\nfind decentralized control policies in a multi-robot swarm environment. The\nprotocols are based on histograms that encode the local neighborhood relations\nof the agents and can also transmit task-specific information, such as the\nshortest distance and direction to a desired target. In our framework, we use\nan adaptation of Trust Region Policy Optimization to learn complex\ncollaborative tasks, such as formation building and building a communication\nlink. We evaluate our findings in a simulated 2D-physics environment, and\ncompare the implications of different communication protocols.\n", "versions": [{"version": "v1", "created": "Thu, 21 Sep 2017 09:18:09 GMT"}, {"version": "v2", "created": "Wed, 18 Jul 2018 08:39:08 GMT"}], "update_date": "2018-07-19", "authors_parsed": [["H\u00fcttenrauch", "Maximilian", ""], ["\u0160o\u0161i\u0107", "Adrian", ""], ["Neumann", "Gerhard", ""]]}, {"id": "1709.07658", "submitter": "Jordan Ivanchev", "authors": "Jordan Ivanchev, Alois Knoll, Daniel Zehe, Suraj Nair, David Eckhoff", "title": "Potentials and Implications of Dedicated Highway Lanes for Autonomous\n  Vehicles", "comments": "12 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The introduction of autonomous vehicles (AVs) will have far-reaching effects\non road traffic in cities and on highways.The implementation of automated\nhighway system (AHS), possibly with a dedicated lane only for AVs, is believed\nto be a requirement to maximise the benefit from the advantages of AVs. We\nstudy the ramifications of an increasing percentage of AVs on the traffic\nsystem with and without the introduction of a dedicated AV lane on highways. We\nconduct an analytical evaluation of a simplified scenario and a macroscopic\nsimulation of the city of Singapore under user equilibrium conditions with a\nrealistic traffic demand. We present findings regarding average travel time,\nfuel consumption, throughput and road usage. Instead of only considering the\nhighways, we also focus on the effects on the remaining road network. Our\nresults show a reduction of average travel time and fuel consumption as a\nresult of increasing the portion of AVs in the system. We show that the\nintroduction of an AV lane is not beneficial in terms of average commute time.\nExamining the effects of the AV population only, however, the AV lane provides\na considerable reduction of travel time (approx. 25%) at the price of delaying\nconventional vehicles (approx. 7%). Furthermore a notable shift of travel\ndemand away from the highways towards major and small roads is noticed in early\nstages of AV penetration of the system. Finally, our findings show that after a\ncertain threshold percentage of AVs the differences between AV and no AV lane\nscenarios become negligible.\n", "versions": [{"version": "v1", "created": "Fri, 22 Sep 2017 09:45:40 GMT"}], "update_date": "2017-09-25", "authors_parsed": [["Ivanchev", "Jordan", ""], ["Knoll", "Alois", ""], ["Zehe", "Daniel", ""], ["Nair", "Suraj", ""], ["Eckhoff", "David", ""]]}, {"id": "1709.07972", "submitter": "Valentina Breschi", "authors": "Valentina Breschi, Ilya Kolmanovsky, Alberto Bemporad", "title": "Cloud-aided collaborative estimation by ADMM-RLS algorithms for\n  connected vehicle prognostics", "comments": "Extended version, with complete proofs, of a submission to the\n  American Control Conference 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.DC cs.MA eess.SP math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the connectivity of consumer devices is rapidly growing and cloud\ncomputing technologies are becoming more widespread, cloud-aided techniques for\nparameter estimation can be designed to exploit the theoretically unlimited\nstorage memory and computational power of the cloud, while relying on\ninformation provided by multiple sources. With the ultimate goal of developing\nmonitoring and diagnostic strategies, this report focuses on the design of a\nRecursive Least-Squares (RLS) based estimator for identification over a group\nof devices connected to the cloud. The proposed approach, that relies on\nNode-to-Cloud-to-Node (N2C2N) transmissions, is designed so that: (i) estimates\nof the unknown parameters are computed locally and (ii) the local estimates are\nrefined on the cloud. The proposed approach requires minimal changes to local\n(pre-existing) RLS estimators.\n", "versions": [{"version": "v1", "created": "Fri, 22 Sep 2017 23:38:08 GMT"}], "update_date": "2017-09-26", "authors_parsed": [["Breschi", "Valentina", ""], ["Kolmanovsky", "Ilya", ""], ["Bemporad", "Alberto", ""]]}, {"id": "1709.08071", "submitter": "Stefano Albrecht", "authors": "Stefano V. Albrecht, Peter Stone", "title": "Autonomous Agents Modelling Other Agents: A Comprehensive Survey and\n  Open Problems", "comments": "Final manuscript (46 pages), published in Artificial Intelligence\n  Journal. The arXiv version also contains a table of contents after the\n  abstract, but is otherwise identical to the AIJ version. Keywords: autonomous\n  agents, multiagent systems, modelling other agents, opponent modelling", "journal-ref": null, "doi": "10.1016/j.artint.2018.01.002", "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much research in artificial intelligence is concerned with the development of\nautonomous agents that can interact effectively with other agents. An important\naspect of such agents is the ability to reason about the behaviours of other\nagents, by constructing models which make predictions about various properties\nof interest (such as actions, goals, beliefs) of the modelled agents. A variety\nof modelling approaches now exist which vary widely in their methodology and\nunderlying assumptions, catering to the needs of the different sub-communities\nwithin which they were developed and reflecting the different practical uses\nfor which they are intended. The purpose of the present article is to provide a\ncomprehensive survey of the salient modelling methods which can be found in the\nliterature. The article concludes with a discussion of open problems which may\nform the basis for fruitful future research.\n", "versions": [{"version": "v1", "created": "Sat, 23 Sep 2017 16:10:52 GMT"}, {"version": "v2", "created": "Fri, 9 Feb 2018 15:54:18 GMT"}], "update_date": "2018-02-12", "authors_parsed": [["Albrecht", "Stefano V.", ""], ["Stone", "Peter", ""]]}, {"id": "1709.08139", "submitter": "Victor Amelkin", "authors": "Victor Amelkin, Ambuj K. Singh", "title": "Disabling External Influence in Social Networks via Edge Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.DM cs.DS cs.MA math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing socio-psychological studies suggest that users of a social network\nform their opinions relying on the opinions of their neighbors. According to\nDeGroot opinion formation model, one value of particular importance is the\nasymptotic consensus value---the sum of user opinions weighted by the users'\neigenvector centralities. This value plays the role of an attractor for the\nopinions in the network and is a lucrative target for external influence.\nHowever, since any potentially malicious control of the opinion distribution in\na social network is clearly undesirable, it is important to design methods to\nprevent the external attempts to strategically change the asymptotic consensus\nvalue.\n  In this work, we assume that the adversary wants to maximize the asymptotic\nconsensus value by altering the opinions of some users in a network; we, then,\nstate DIVER---an NP-hard problem of disabling such external influence attempts\nby strategically adding a limited number of edges to the network. Relying on\nthe theory of Markov chains, we provide perturbation analysis that shows how\neigenvector centrality and, hence, DIVER's objective function change in\nresponse to an edge's addition to the network. The latter leads to the design\nof a pseudo-linear-time heuristic for DIVER, whose computation relies on\nefficient estimation of mean first passage times in a Markov chain. We confirm\nour theoretical findings in experiments.\n", "versions": [{"version": "v1", "created": "Sun, 24 Sep 2017 02:49:02 GMT"}], "update_date": "2017-09-26", "authors_parsed": [["Amelkin", "Victor", ""], ["Singh", "Ambuj K.", ""]]}, {"id": "1709.08215", "submitter": "Shuai Han", "authors": "Shuai D. Han, Edgar J. Rodriguez, Jingjin Yu", "title": "SEAR: A Polynomial-Time Multi-Robot Path Planning Algorithm with\n  Expected Constant-Factor Optimality Guarantee", "comments": "Submitted to IROS 2018 as contributed paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the labeled multi-robot path planning problem in continuous 2D and\n3D domains in the absence of obstacles where robots must not collide with each\nother. For an arbitrary number of robots in arbitrary initial and goal\narrangements, we derive a polynomial time, complete algorithm that produces\nsolutions with constant-factor optimality guarantees on both makespan and\ndistance optimality, in expectation, under the assumption that the robot labels\nare uniformly randomly distributed. Our algorithm only requires a small\nconstant factor expansion of the initial and goal configuration footprints for\nsolving the problem, i.e., the problem can be solved in a fairly small bounded\nregion. Beside theoretical guarantees, we present a thorough computational\nevaluation of the proposed solution. In addition to the baseline\nimplementation, adapting an effective (but non-polynomial time) routing\nsubroutine, we also provide a highly efficient implementation that quickly\ncomputes near-optimal solutions. Hardware experiments on the microMVP platform\ncomposed of non-holonomic robots confirms the practical applicability of our\nalgorithmic pipeline.\n", "versions": [{"version": "v1", "created": "Sun, 24 Sep 2017 16:01:04 GMT"}, {"version": "v2", "created": "Tue, 27 Feb 2018 19:47:21 GMT"}], "update_date": "2018-03-01", "authors_parsed": [["Han", "Shuai D.", ""], ["Rodriguez", "Edgar J.", ""], ["Yu", "Jingjin", ""]]}, {"id": "1709.08235", "submitter": "J\\\"org P. M\\\"uller", "authors": "Fatema Tuj Johora and Philipp Kraus and J\\\"org P. M\\\"uller", "title": "Dynamic Path Planning and Movement Control in Pedestrian Simulation", "comments": "This paper was accepted for the preproceedings of The 2nd\n  International Workshop on Agent-based modelling of urban systems (ABMUS\n  2017), http://www.modelling-urban-systems.com/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling and simulation of pedestrian behavior is used in applications such\nas planning large buildings, disaster management, or urban planning.\nRealistically simulating pedestrian behavior is challenging, due to the\ncomplexity of individual behavior as well as the complexity of interactions of\npedestrians with each other and with the environment. This work-in-progress\npaper addresses the tactical (path planning) and the operational level\n(movement control) of pedestrian simulation from the perspective of\nmultiagent-based modeling. We propose (1) an novel extension of the JPS routing\nalgorithm for tactical planning, and (2) an architecture how path planning can\nbe integrated with a social-force based movement control. The architecture is\ninspired by layered architectures for robot planning and control. We validate\ncorrectness and efficiency of our approach through simulation runs.\n", "versions": [{"version": "v1", "created": "Sun, 24 Sep 2017 18:40:21 GMT"}], "update_date": "2017-09-26", "authors_parsed": [["Johora", "Fatema Tuj", ""], ["Kraus", "Philipp", ""], ["M\u00fcller", "J\u00f6rg P.", ""]]}, {"id": "1709.08463", "submitter": "Sid Chi-Kin Chau", "authors": "Chien-Ming Tseng, Sid Chi-Kin Chau and Xue Liu", "title": "Improving Viability of Electric Taxis by Taxi Service Strategy\n  Optimization: A Big Data Study of New York City", "comments": "This paper appears in IEEE Transactions on Intelligent Transportation\n  Systems", "journal-ref": "IEEE Transactions on Intelligent Transportation Systems, Vol. 20,\n  No. 3, pp817-829, Mar 2019", "doi": "10.1109/TITS.2018.2839265", "report-no": null, "categories": "cs.CY cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electrification of transportation is critical for a low-carbon society. In\nparticular, public vehicles (e.g., taxis) provide a crucial opportunity for\nelectrification. Despite the benefits of eco-friendliness and energy\nefficiency, adoption of electric taxis faces several obstacles, including\nconstrained driving range, long recharging duration, limited charging stations\nand low gas price, all of which impede taxi drivers' decisions to switch to\nelectric taxis. On the other hand, the popularity of ride-hailing mobile apps\nfacilitates the computerization and optimization of taxi service strategies,\nwhich can provide computer-assisted decisions of navigation and roaming for\ntaxi drivers to locate potential customers. This paper examines the viability\nof electric taxis with the assistance of taxi service strategy optimization, in\ncomparison with conventional taxis with internal combustion engines. A big data\nstudy is provided using a large dataset of real-world taxi trips in New York\nCity. Our methodology is to first model the computerized taxi service strategy\nby Markov Decision Process (MDP), and then obtain the optimized taxi service\nstrategy based on NYC taxi trip dataset. The profitability of electric taxi\ndrivers is studied empirically under various battery capacity and charging\nconditions. Consequently, we shed light on the solutions that can improve\nviability of electric taxis.\n", "versions": [{"version": "v1", "created": "Mon, 25 Sep 2017 12:58:59 GMT"}, {"version": "v2", "created": "Fri, 18 May 2018 13:39:15 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Tseng", "Chien-Ming", ""], ["Chau", "Sid Chi-Kin", ""], ["Liu", "Xue", ""]]}, {"id": "1709.08505", "submitter": "Imtiaz Parvez", "authors": "Imtiaz Parvez, Maryamossadat Aghili, Arif Sarwat", "title": "Key Management and Learning based Two Level Data Security for Metering\n  Infrastructure of Smart Grid", "comments": "8 Pages and 11 Figures. Submitted in IEEE Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the smart grid, smart meters, and numerous control and monitoring\napplications employ bidirectional wireless communication, where security is a\ncritical issue. In key management based encryption method for the smart grid,\nthe Trusted Third Party (TTP), and links between the smart meter and the third\nparty are assumed to be fully trusted and reliable. However, in wired/wireless\nmedium, a man-in-middle may want to interfere, monitor and control the network,\nthus exposing its vulnerability. Acknowledging this, in this paper, we propose\na novel two level encryption method based on two partially trusted simple\nservers (constitutes the TTP) which implement this method without increasing\npacket overhead. One server is responsible for data encryption between the\nmeter and control center/central database, and the other server manages the\nrandom sequence of data transmission. Numerical calculation shows that the\nnumber of iterations required to decode a message is large which is quite\nimpractical. Furthermore, we introduce One-class support vector machine\n(machine learning) algorithm for node-to-node authentication utilizing the\nlocation information and the data transmission history (node identity, packet\nsize and frequency of transmission). This secures data communication privacy\nwithout increasing the complexity of the conventional key management scheme.\n", "versions": [{"version": "v1", "created": "Mon, 25 Sep 2017 14:17:50 GMT"}], "update_date": "2017-09-26", "authors_parsed": [["Parvez", "Imtiaz", ""], ["Aghili", "Maryamossadat", ""], ["Sarwat", "Arif", ""]]}, {"id": "1709.08765", "submitter": "Michael Rabbat", "authors": "Angelia Nedi\\'c, Alex Olshevsky, Michael G. Rabbat", "title": "Network Topology and Communication-Computation Tradeoffs in\n  Decentralized Optimization", "comments": "32 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In decentralized optimization, nodes cooperate to minimize an overall\nobjective function that is the sum (or average) of per-node private objective\nfunctions. Algorithms interleave local computations with communication among\nall or a subset of the nodes. Motivated by a variety of\napplications---distributed estimation in sensor networks, fitting models to\nmassive data sets, and distributed control of multi-robot systems, to name a\nfew---significant advances have been made towards the development of robust,\npractical algorithms with theoretical performance guarantees. This paper\npresents an overview of recent work in this area. In general, rates of\nconvergence depend not only on the number of nodes involved and the desired\nlevel of accuracy, but also on the structure and nature of the network over\nwhich nodes communicate (e.g., whether links are directed or undirected, static\nor time-varying). We survey the state-of-the-art algorithms and their analyses\ntailored to these different scenarios, highlighting the role of the network\ntopology.\n", "versions": [{"version": "v1", "created": "Tue, 26 Sep 2017 00:46:01 GMT"}, {"version": "v2", "created": "Mon, 15 Jan 2018 17:45:04 GMT"}], "update_date": "2018-01-16", "authors_parsed": [["Nedi\u0107", "Angelia", ""], ["Olshevsky", "Alex", ""], ["Rabbat", "Michael G.", ""]]}, {"id": "1709.08992", "submitter": "Nicolas Bredeche", "authors": "Nicolas Bredeche, Evert Haasdijk, Abraham Prieto", "title": "Embodied Evolution in Collective Robotics: A Review", "comments": "23 pages, 1 figure, 1 table", "journal-ref": "(2018) Embodied Evolution in Collective Robotics: A Review. Front.\n  Robot. AI 5:12", "doi": "10.3389/frobt.2018.00012", "report-no": null, "categories": "cs.NE cs.AI cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides an overview of evolutionary robotics techniques applied\nto on-line distributed evolution for robot collectives -- namely, embodied\nevolution. It provides a definition of embodied evolution as well as a thorough\ndescription of the underlying concepts and mechanisms. The paper also presents\na comprehensive summary of research published in the field since its inception\n(1999-2017), providing various perspectives to identify the major trends. In\nparticular, we identify a shift from considering embodied evolution as a\nparallel search method within small robot collectives (fewer than 10 robots) to\nembodied evolution as an on-line distributed learning method for designing\ncollective behaviours in swarm-like collectives. The paper concludes with a\ndiscussion of applications and open questions, providing a milestone for past\nand an inspiration for future research.\n", "versions": [{"version": "v1", "created": "Tue, 26 Sep 2017 13:08:27 GMT"}, {"version": "v2", "created": "Fri, 9 Feb 2018 14:56:37 GMT"}], "update_date": "2018-02-12", "authors_parsed": [["Bredeche", "Nicolas", ""], ["Haasdijk", "Evert", ""], ["Prieto", "Abraham", ""]]}, {"id": "1709.08999", "submitter": "Sebastian Bernhard", "authors": "Sebastian Bernhard, Saman Khodaverdian, J\\\"urgen Adamy", "title": "Optimal Stationary Synchronization of Heterogeneous Linear Multi-Agent\n  Systems", "comments": "8 pages, 2 figures, final version to appear in proceedings of\n  American Control Conference (ACC), 2018", "journal-ref": null, "doi": "10.23919/ACC.2018.8430850", "report-no": null, "categories": "cs.SY cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we address the output synchronization of heterogeneous linear\nnetworks. In the literature, all agents are typically required to synchronize\nexactly to a common trajectory. Here, we introduce optimal stationary\nsynchronization (OSS) instead which permits non-zero steady-state\nsynchronization errors. As a benefit, we are able to relax standard\nrequirements. E.g., agents are allowed to participate in the network even when\nthey usually cannot synchronize exactly. In addition, OSS enables agents to\nsave input-energy by synchronizing within tolerable error-bounds. Our new\nmethod combines the synchronization of bounded exosystems with local\ninfinite-time linear quadratic tracking (LQT). This results in an optimal\nbalance of each agent's synchronization error versus its consumed input-energy.\nMoreover, we extend recent results in LQT such that the derived time-invariant\noptimal control guarantees that the synchronization error satisfies given\nstrict bounds. All these aspects are demonstrated by an illustrative simulation\nexample with a detailed analysis.\n", "versions": [{"version": "v1", "created": "Tue, 26 Sep 2017 13:19:40 GMT"}, {"version": "v2", "created": "Mon, 26 Feb 2018 16:45:54 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Bernhard", "Sebastian", ""], ["Khodaverdian", "Saman", ""], ["Adamy", "J\u00fcrgen", ""]]}, {"id": "1709.09451", "submitter": "Moshe Bitan", "authors": "Moshe Bitan, Sarit Kraus", "title": "Combining Prediction of Human Decisions with ISMCTS in Imperfect\n  Information Games", "comments": "8 Pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monte Carlo Tree Search (MCTS) has been extended to many imperfect\ninformation games. However, due to the added complexity that uncertainty\nintroduces, these adaptations have not reached the same level of practical\nsuccess as their perfect information counterparts. In this paper we consider\nthe development of agents that perform well against humans in imperfect\ninformation games with partially observable actions. We introduce the\nSemi-Determinized-MCTS (SDMCTS), a variant of the Information Set MCTS\nalgorithm (ISMCTS). More specifically, SDMCTS generates a predictive model of\nthe unobservable portion of the opponent's actions from historical behavioral\ndata. Next, SDMCTS performs simulations on an instance of the game where the\nunobservable portion of the opponent's actions are determined. Thereby, it\nfacilitates the use of the predictive model in order to decrease uncertainty.\nWe present an implementation of the SDMCTS applied to the Cheat Game, a\nwell-known card game, with partially observable (and often deceptive) actions.\nResults from experiments with 120 subjects playing a head-to-head Cheat Game\nagainst our SDMCTS agents suggest that SDMCTS performs well against humans, and\nits performance improves as the predictive model's accuracy increases.\n", "versions": [{"version": "v1", "created": "Wed, 27 Sep 2017 11:13:01 GMT"}, {"version": "v2", "created": "Sat, 18 Nov 2017 23:24:09 GMT"}], "update_date": "2017-11-21", "authors_parsed": [["Bitan", "Moshe", ""], ["Kraus", "Sarit", ""]]}, {"id": "1709.09569", "submitter": "Michael Albert", "authors": "Guni Sharon, Michael Albert, Tarun Rambha, Stephen Boyles, and Peter\n  Stone", "title": "Traffic Optimization For a Mixture of Self-interested and Compliant\n  Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on two commonly used path assignment policies for agents\ntraversing a congested network: self-interested routing, and system-optimum\nrouting. In the self-interested routing policy each agent selects a path that\noptimizes its own utility, while the system-optimum routing agents are assigned\npaths with the goal of maximizing system performance. This paper considers a\nscenario where a centralized network manager wishes to optimize utilities over\nall agents, i.e., implement a system-optimum routing policy. In many real-life\nscenarios, however, the system manager is unable to influence the route\nassignment of all agents due to limited influence on route choice decisions.\nMotivated by such scenarios, a computationally tractable method is presented\nthat computes the minimal amount of agents that the system manager needs to\ninfluence (compliant agents) in order to achieve system optimal performance.\nMoreover, this methodology can also determine whether a given set of compliant\nagents is sufficient to achieve system optimum and compute the optimal route\nassignment for the compliant agents to do so. Experimental results are\npresented showing that in several large-scale, realistic traffic networks\noptimal flow can be achieved with as low as 13% of the agent being compliant\nand up to 54%.\n", "versions": [{"version": "v1", "created": "Wed, 27 Sep 2017 15:03:48 GMT"}], "update_date": "2017-09-28", "authors_parsed": [["Sharon", "Guni", ""], ["Albert", "Michael", ""], ["Rambha", "Tarun", ""], ["Boyles", "Stephen", ""], ["Stone", "Peter", ""]]}, {"id": "1709.10082", "submitter": "Jia Pan", "authors": "Pinxin Long, Tingxiang Fan, Xinyi Liao, Wenxi Liu, Hao Zhang and Jia\n  Pan", "title": "Towards Optimally Decentralized Multi-Robot Collision Avoidance via Deep\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developing a safe and efficient collision avoidance policy for multiple\nrobots is challenging in the decentralized scenarios where each robot generate\nits paths without observing other robots' states and intents. While other\ndistributed multi-robot collision avoidance systems exist, they often require\nextracting agent-level features to plan a local collision-free action, which\ncan be computationally prohibitive and not robust. More importantly, in\npractice the performance of these methods are much lower than their centralized\ncounterparts.\n  We present a decentralized sensor-level collision avoidance policy for\nmulti-robot systems, which directly maps raw sensor measurements to an agent's\nsteering commands in terms of movement velocity. As a first step toward\nreducing the performance gap between decentralized and centralized methods, we\npresent a multi-scenario multi-stage training framework to find an optimal\npolicy which is trained over a large number of robots on rich, complex\nenvironments simultaneously using a policy gradient based reinforcement\nlearning algorithm. We validate the learned sensor-level collision avoidance\npolicy in a variety of simulated scenarios with thorough performance\nevaluations and show that the final learned policy is able to find time\nefficient, collision-free paths for a large-scale robot system. We also\ndemonstrate that the learned policy can be well generalized to new scenarios\nthat do not appear in the entire training period, including navigating a\nheterogeneous group of robots and a large-scale scenario with 100 robots.\nVideos are available at https://sites.google.com/view/drlmaca\n", "versions": [{"version": "v1", "created": "Thu, 28 Sep 2017 17:44:09 GMT"}, {"version": "v2", "created": "Fri, 29 Sep 2017 02:20:12 GMT"}, {"version": "v3", "created": "Sun, 20 May 2018 08:36:24 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Long", "Pinxin", ""], ["Fan", "Tingxiang", ""], ["Liao", "Xinyi", ""], ["Liu", "Wenxi", ""], ["Zhang", "Hao", ""], ["Pan", "Jia", ""]]}]