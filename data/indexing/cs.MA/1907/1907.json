[{"id": "1907.00327", "submitter": "Niranjan Balachandar", "authors": "Niranjan Balachandar, Justin Dieter, Govardana Sachithanandam\n  Ramachandran", "title": "Collaboration of AI Agents via Cooperative Multi-Agent Deep\n  Reinforcement Learning", "comments": "9 pages, 7 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are many AI tasks involving multiple interacting agents where agents\nshould learn to cooperate and collaborate to effectively perform the task. Here\nwe develop and evaluate various multi-agent protocols to train agents to\ncollaborate with teammates in grid soccer. We train and evaluate our\nmulti-agent methods against a team operating with a smart hand-coded policy. As\na baseline, we train agents concurrently and independently, with no\ncommunication. Our collaborative protocols were parameter sharing, coordinated\nlearning with communication, and counterfactual policy gradients. Against the\nhand-coded team, the team trained with parameter sharing and the team trained\nwith coordinated learning performed the best, scoring on 89.5% and 94.5% of\nepisodes respectively when playing against the hand-coded team. Against the\nparameter sharing team, with adversarial training the coordinated learning team\nscored on 75% of the episodes, indicating it is the most adaptable of our\nmethods. The insights gained from our work can be applied to other domains\nwhere multi-agent collaboration could be beneficial.\n", "versions": [{"version": "v1", "created": "Sun, 30 Jun 2019 06:12:48 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Balachandar", "Niranjan", ""], ["Dieter", "Justin", ""], ["Ramachandran", "Govardana Sachithanandam", ""]]}, {"id": "1907.00899", "submitter": "Zixuan Zhang", "authors": "Zixuan Zhang", "title": "Engineering Token Economy with System Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cryptocurrencies and blockchain networks have attracted tremendous attention\nfrom their volatile price movements and the promise of decentralization.\nHowever, most projects run on business narratives with no way to test and\nverify their assumptions and promises about the future. The complex nature of\nsystem dynamics within networked economies has rendered it difficult to reason\nabout the growth and evolution of these networks. This paper drew concepts from\ndifferential games, classical control engineering, and stochastic dynamical\nsystem to come up with a framework and example to model, simulate, and engineer\nnetworked token economies. A model on a generalized token economy is proposed\nwhere miners provide service to a platform in exchange for a cryptocurrency and\nusers consume service from the platform. Simulations of this model allow us to\nobserve outcomes of complex dynamics and reason about the evolution of the\nsystem. Speculative price movements and engineered block rewards were then\nexperimented to observe their impact on system dynamics and network-level\ngoals. The model presented is necessarily limited so we conclude by exploring\nthose limitations and outlining future research directions.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 20:53:43 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Zhang", "Zixuan", ""]]}, {"id": "1907.00956", "submitter": "Michael Amir", "authors": "Michael Amir and Alfred M. Bruckstein", "title": "Fast Uniform Dispersion of a Crash-prone Swarm", "comments": "to appear in the proceedings of RSS (Robotics: Science and Systems)\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of completely covering an unknown discrete\nenvironment with a swarm of asynchronous, frequently-crashing autonomous mobile\nrobots. We represent the environment by a discrete graph, and task the robots\nwith occupying every vertex and with constructing an implicit distributed\nspanning tree of the graph. The robotic agents activate independently at random\nexponential waiting times of mean $1$ and enter the graph environment over time\nfrom a source location. They grow the environment's coverage by 'settling' at\nempty locations and aiding other robots' navigation from these locations. The\nrobots are identical and make decisions driven by the same simple and local\nrule of behaviour. The local rule is based only on the presence of neighbouring\nrobots, and on whether a settled robot points to the current location. Whenever\na robot moves, it may crash and disappear from the environment. Each vertex in\nthe environment has limited physical space, so robots frequently obstruct each\nother.\n  Our goal is to show that even under conditions of asynchronicity, frequent\ncrashing, and limited physical space, the simple mobile robots complete their\nmission in linear time asymptotically almost surely, and time to completion\ndegrades gracefully with the frequency of the crashes. Our model and analysis\nare based on the well-studied \"totally asymmetric simple exclusion process\" in\nstatistical mechanics.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 17:51:44 GMT"}, {"version": "v2", "created": "Sun, 1 Dec 2019 15:45:50 GMT"}, {"version": "v3", "created": "Thu, 4 Jun 2020 02:43:03 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Amir", "Michael", ""], ["Bruckstein", "Alfred M.", ""]]}, {"id": "1907.01071", "submitter": "Nathaniel Tucker", "authors": "Nathaniel Tucker, Berkay Turan, Mahnoosh Alizadeh", "title": "Online Charge Scheduling for Electric Vehicles in Autonomous Mobility on\n  Demand Fleets", "comments": "9 pages, 3 figures, Accepted to ITSC 2019, Auckland, NZ", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.MA cs.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we study an online charge scheduling strategy for fleets of\nautonomous-mobility-on-demand electric vechicles (AMoD EVs). We consider the\ncase where vehicles complete trips and then enter a between-ride state\nthroughout the day, with their information becoming available to the fleet\noperator in an online fashion. In the between-ride state, the vehicles must be\nscheduled for charging and then routed to their next passenger pick-up\nlocations. Additionally, due to the unknown daily sequences of ride requests,\nthe problem cannot be solved by any offline approach. As such, we study an\nonline welfare maximization heuristic based on primal-dual methods that\nallocates limited fleet charging resources and rebalances the vehicles while\navoiding congestion at charging facilities and pick-up locations. We discuss a\ncompetitive ratio result comparing the performance of our online solution to\nthe clairvoyant offline solution and provide numerical results highlighting the\nperformance of our heuristic.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 20:52:56 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Tucker", "Nathaniel", ""], ["Turan", "Berkay", ""], ["Alizadeh", "Mahnoosh", ""]]}, {"id": "1907.01101", "submitter": "Kashif Zia Dr.", "authors": "Kashif Zia, Arshad Muhammad, Dinesh Kumar Saini", "title": "A Simulation Study of Social-Networking-Driven Smart Recommendations for\n  Internet of Vehicles", "comments": "A concise version of the paper appeared in the proceeding of the 16th\n  International Conference on Practical Applications of Agents and Multi-Agent\n  Systems 2018 held in Toledo, Spain", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Social aspects of connectivity and information dispersion are often ignored\nwhile weighing the potential of Internet of Things (IoT). In the specialized\ndomain of Internet of Vehicles (IoV), Social IoV (SIoV) is introduced\nrealization its importance. Assuming a more commonly acceptable standardization\nof Big Data generated by IoV, the social dimensions enabling its fruitful usage\nremains a challenge. In this paper, an agent-based model of information sharing\nbetween vehicles for context-aware recommendations is presented. The model\nadheres to social dimensions as that of human society. Some important\nhypotheses are tested under reasonable connectivity and data constraints. The\nsimulation results reveal that closure of social ties and its timing impacts\ndispersion of novel information (necessary for a recommender system)\nsubstantially. It was also observed that as the network evolves as a result of\nincremental interactions, recommendations guaranteeing a fair distribution of\nvehicles across equally good competitors is not possible.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 06:12:05 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Zia", "Kashif", ""], ["Muhammad", "Arshad", ""], ["Saini", "Dinesh Kumar", ""]]}, {"id": "1907.01309", "submitter": "Rihab Abdul Razak", "authors": "Rihab Abdul Razak, Sukumar Srikant, Hoam Chung", "title": "Scalar Field Estimation with Mobile Sensor Networks", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.MA cs.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of estimating a scalar field using a\nnetwork of mobile sensors which can measure the value of the field at their\ninstantaneous location. The scalar field to be estimated is assumed to be\nrepresented by positive definite radial basis kernels and we use techniques\nfrom adaptive control and Lyapunov analysis to prove the stability of the\nproposed estimation algorithm. The convergence of the estimated parameter\nvalues to the true values is guaranteed by planning the motion of the mobile\nsensors to satisfy persistence-like conditions.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 11:58:47 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Razak", "Rihab Abdul", ""], ["Srikant", "Sukumar", ""], ["Chung", "Hoam", ""]]}, {"id": "1907.01405", "submitter": "Xingyu Li", "authors": "Xingyu Li, Mainak Mitra, Bogdan I. Epureanu", "title": "Analysis of the Synergy between Modularity and Autonomy in an Artificial\n  Intelligence Based Fleet Competition", "comments": "4 pages, 4 figures, 2019 NDIA Ground Vehicle Systems Engineering and\n  Technology Symposium", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel approach is provided for evaluating the benefits and burdens from\nvehicle modularity in fleets/units through the analysis of a game theoretical\nmodel of the competition between autonomous vehicle fleets in an\nattacker-defender game. We present an approach to obtain the heuristic\noperational strategies through fitting a decision tree on high-fidelity\nsimulation results of an intelligent agent-based model. A multi-stage game\ntheoretical model is also created for decision making considering military\nresources and impacts of past decisions. Nash equilibria of the operational\nstrategy are revealed, and their characteristics are explored. The benefits of\nfleet modularity are also analyzed by comparing the results of the decision\nmaking process under diverse operational situations.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 14:34:30 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Li", "Xingyu", ""], ["Mitra", "Mainak", ""], ["Epureanu", "Bogdan I.", ""]]}, {"id": "1907.01796", "submitter": "Mark Burgess", "authors": "Mark Burgess and Ewout Prangsma", "title": "Koalja: from Data Plumbing to Smart Workspaces in the Extended Cloud", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.MA cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Koalja describes a generalized data wiring or `pipeline' platform, built on\ntop of Kubernetes, for plugin user code. Koalja makes the Kubernetes underlay\ntransparent to users (for a `serverless' experience), and offers a\nbreadboarding experience for development of data sharing circuitry, to\ncommoditize its gradual promotion to a production system, with a minimum of\ninfrastructure knowledge. Enterprise grade metadata are captured as data\npayloads flow through the circuitry, allowing full tracing of provenance and\nforensic reconstruction of transactional processes, down to the versions of\nsoftware that led to each outcome. Koalja attends to optimizations for avoiding\nunwanted processing and transportation of data, that are rapidly becoming\nsustainability imperatives. Thus one can minimize energy expenditure and waste,\nand design with scaling in mind, especially with regard to edge computing, to\naccommodate an Internet of Things, Network Function Virtualization, and more.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 08:52:42 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Burgess", "Mark", ""], ["Prangsma", "Ewout", ""]]}, {"id": "1907.01848", "submitter": "Stefan Vlaski", "authors": "Stefan Vlaski and Ali H. Sayed", "title": "Distributed Learning in Non-Convex Environments -- Part I: Agreement at\n  a Linear Rate", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.MA eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Driven by the need to solve increasingly complex optimization problems in\nsignal processing and machine learning, there has been increasing interest in\nunderstanding the behavior of gradient-descent algorithms in non-convex\nenvironments. Most available works on distributed non-convex optimization\nproblems focus on the deterministic setting where exact gradients are available\nat each agent. In this work and its Part II, we consider stochastic cost\nfunctions, where exact gradients are replaced by stochastic approximations and\nthe resulting gradient noise persistently seeps into the dynamics of the\nalgorithm. We establish that the diffusion learning strategy continues to yield\nmeaningful estimates non-convex scenarios in the sense that the iterates by the\nindividual agents will cluster in a small region around the network centroid.\nWe use this insight to motivate a short-term model for network evolution over a\nfinite-horizon. In Part II [2] of this work, we leverage this model to\nestablish descent of the diffusion strategy through saddle points in O(1/$\\mu$)\nsteps and the return of approximately second-order stationary points in a\npolynomial number of iterations.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 11:06:11 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Vlaski", "Stefan", ""], ["Sayed", "Ali H.", ""]]}, {"id": "1907.01849", "submitter": "Stefan Vlaski", "authors": "Stefan Vlaski and Ali H. Sayed", "title": "Distributed Learning in Non-Convex Environments -- Part II: Polynomial\n  Escape from Saddle-Points", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.LG eess.SP math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The diffusion strategy for distributed learning from streaming data employs\nlocal stochastic gradient updates along with exchange of iterates over\nneighborhoods. In Part I [2] of this work we established that agents cluster\naround a network centroid and proceeded to study the dynamics of this point. We\nestablished expected descent in non-convex environments in the large-gradient\nregime and introduced a short-term model to examine the dynamics over\nfinite-time horizons. Using this model, we establish in this work that the\ndiffusion strategy is able to escape from strict saddle-points in O(1/$\\mu$)\niterations; it is also able to return approximately second-order stationary\npoints in a polynomial number of iterations. Relative to prior works on the\npolynomial escape from saddle-points, most of which focus on centralized\nperturbed or stochastic gradient descent, our approach requires less\nrestrictive conditions on the gradient noise process.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 11:06:43 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Vlaski", "Stefan", ""], ["Sayed", "Ali H.", ""]]}, {"id": "1907.01851", "submitter": "Aqeel Labash", "authors": "Aqeel Labash, Jaan Aru, Tambet Matiisen, Ardi Tampuu, Raul Vicente", "title": "Perspective Taking in Deep Reinforcement Learning Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Perspective taking is the ability to take the point of view of another agent.\nThis skill is not unique to humans as it is also displayed by other animals\nlike chimpanzees. It is an essential ability for social interactions, including\nefficient cooperation, competition, and communication. Here we present our\nprogress toward building artificial agents with such abilities. We implemented\na perspective taking task inspired by experiments done with chimpanzees. We\nshow that agents controlled by artificial neural networks can learn via\nreinforcement learning to pass simple tests that require perspective taking\ncapabilities. We studied whether this ability is more readily learned by agents\nwith information encoded in allocentric or egocentric form for both their\nvisual perception and motor actions. We believe that, in the long run, building\nbetter artificial agents with perspective taking ability can help us develop\nartificial intelligence that is more human-like and easier to communicate with.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 11:08:28 GMT"}, {"version": "v2", "created": "Thu, 16 Apr 2020 00:57:24 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Labash", "Aqeel", ""], ["Aru", "Jaan", ""], ["Matiisen", "Tambet", ""], ["Tampuu", "Ardi", ""], ["Vicente", "Raul", ""]]}, {"id": "1907.01912", "submitter": "Stefano Albrecht", "authors": "Stefano V. Albrecht, S. Ramamoorthy", "title": "Are You Doing What I Think You Are Doing? Criticising Uncertain Agent\n  Models", "comments": "Proceedings of the 31st Conference on Uncertainty in Artificial\n  Intelligence (UAI), 2015. arXiv admin note: substantial text overlap with\n  arXiv:1507.07688", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The key for effective interaction in many multiagent applications is to\nreason explicitly about the behaviour of other agents, in the form of a\nhypothesised behaviour. While there exist several methods for the construction\nof a behavioural hypothesis, there is currently no universal theory which would\nallow an agent to contemplate the correctness of a hypothesis. In this work, we\npresent a novel algorithm which decides this question in the form of a\nfrequentist hypothesis test. The algorithm allows for multiple metrics in the\nconstruction of the test statistic and learns its distribution during the\ninteraction process, with asymptotic correctness guarantees. We present results\nfrom a comprehensive set of experiments, demonstrating that the algorithm\nachieves high accuracy and scalability at low computational costs.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 14:09:48 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Albrecht", "Stefano V.", ""], ["Ramamoorthy", "S.", ""]]}, {"id": "1907.02125", "submitter": "Shitij Kumar", "authors": "Shitij Kumar, Ferat Sahin", "title": "Sensing Volume Coverage of Robot Workspace using On-Robot Time-of-Flight\n  Sensor Arrays for Safe Human Robot Interaction", "comments": "(Draft) Submitted to IEEE SMC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, an analysis of the sensing volume coverage of robot workspace\nas well as the shared human-robot collaborative workspace for various\nconfigurations of on-robot Time-of-Flight (ToF) sensor array rings is\npresented. A methodology for volumetry using octrees to quantify the\ndetection/sensing volume of the sensors is proposed. The change in sensing\nvolume coverage by increasing the number of sensors per ToF sensor array ring\nand also increasing the number of rings mounted on robot link is also studied.\nConsiderations of maximum ideal volume around the robot workspace that a given\nToF sensor array ring placement and orientation setup should cover for safe\nhuman robot interaction are presented. The sensing volume coverage measurements\nin this maximum ideal volume are tabulated and observations on various ToF\nconfigurations and their coverage for close and far zones of the robot are\ndetermined.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 20:39:47 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Kumar", "Shitij", ""], ["Sahin", "Ferat", ""]]}, {"id": "1907.03053", "submitter": "Ji Liu", "authors": "Yixuan Lin, Kaiqing Zhang, Zhuoran Yang, Zhaoran Wang, Tamer\n  Ba\\c{s}ar, Romeil Sandhu, Ji Liu", "title": "A Communication-Efficient Multi-Agent Actor-Critic Algorithm for\n  Distributed Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers a distributed reinforcement learning problem in which a\nnetwork of multiple agents aim to cooperatively maximize the globally averaged\nreturn through communication with only local neighbors. A randomized\ncommunication-efficient multi-agent actor-critic algorithm is proposed for\npossibly unidirectional communication relationships depicted by a directed\ngraph. It is shown that the algorithm can solve the problem for strongly\nconnected graphs by allowing each agent to transmit only two scalar-valued\nvariables at one time.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jul 2019 00:20:50 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Lin", "Yixuan", ""], ["Zhang", "Kaiqing", ""], ["Yang", "Zhuoran", ""], ["Wang", "Zhaoran", ""], ["Ba\u015far", "Tamer", ""], ["Sandhu", "Romeil", ""], ["Liu", "Ji", ""]]}, {"id": "1907.03470", "submitter": "Farzam Fanitabasi", "authors": "Farzam Fanitabasi, Evangelos Pournaras", "title": "Appliance-level Flexible Scheduling for Socio-technical Smart Grid\n  Optimisation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Participation in residential energy demand response programs requires an\nactive role by the consumers. They contribute flexibility in how they use their\nappliances as the means to adjust energy consumption, and reduce demand peaks,\npossibly at the expense of their own comfort (e.g., thermal). Understanding the\ncollective potential of appliance-level flexibility for reducing demand peaks\nis challenging and complex. For instance, physical characteristics of\nappliances, usage preferences, and comfort requirements all influence consumer\nflexibility, adoption, and effectiveness of demand response programs. To\ncapture and study such socio-technical factors and trade-offs, this paper\ncontributes a novel appliance-level flexible scheduling framework based on\nconsumers' self-determined flexibility and comfort requirements. By utilizing\nthis framework, this paper studies (i) consumers usage preferences across\nvarious appliances, as well as their voluntary contribution of flexibility and\nwillingness to sacrifice comfort for improving grid stability, (ii) impact of\nindividual appliances on the collective goal of reducing demand peaks, and\n(iii) the effect of variable levels of flexibility, cooperation, and\nparticipation on the outcome of coordinated appliance scheduling. Experimental\nevaluation using a novel dataset collected via a smartphone app shows that\nhigher consumer flexibility can significantly reduce demand peaks, with the\noven having the highest system-wide potential for this. Overall, the\ncooperative approach allows for higher peak-shaving compared to non-cooperative\nschemes that focus entirely on the efficiency of individual appliances. The\nfindings of this study can be used to design more cost-effective and granular\n(appliance-level) demand response programs in participatory and decentralized\nSmart Grids.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 09:14:53 GMT"}, {"version": "v2", "created": "Thu, 23 Apr 2020 08:33:00 GMT"}, {"version": "v3", "created": "Tue, 28 Apr 2020 08:04:48 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Fanitabasi", "Farzam", ""], ["Pournaras", "Evangelos", ""]]}, {"id": "1907.03963", "submitter": "Nathaniel Grammel", "authors": "Brian Brubach, Nathaniel Grammel, Will Ma and Aravind Srinivasan", "title": "Follow Your Star: New Frameworks for Online Stochastic Matching with\n  Known and Unknown Patience", "comments": "43 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM cs.MA math.CO math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study several generalizations of the Online Bipartite Matching problem. We\nconsider settings with stochastic rewards, patience constraints, and weights\n(both vertex- and edge-weighted variants). We introduce a stochastic variant of\nthe patience-constrained problem, where the patience is chosen randomly\naccording to some known distribution and is not known until the point at which\npatience has been exhausted. We also consider stochastic arrival settings\n(i.e., online vertex arrival is determined by a known random process), which\nare natural settings that are able to beat the hard worst-case bounds of more\npessimistic adversarial arrivals.\n  Our approach to online matching utilizes black-box algorithms for matching on\nstar graphs under various models of patience. In support of this, we design\nalgorithms which solve the star graph problem optimally for patience with a\nconstant hazard rate and yield a 1/2-approximation for any patience\ndistribution. This 1/2-approximation also improves existing guarantees for\ncascade-click models in the product ranking literature, in which a user must be\nshown a sequence of items with various click-through-rates and the user's\npatience could run out at any time.\n  We then build a framework which uses these star graph algorithms as black\nboxes to solve the online matching problems under different arrival settings.\nWe show improved (or first-known) competitive ratios for these problems.\nFinally, we present negative results that include formalizing the concept of a\nstochasticity gap for LP upper bounds on these problems, bounding the\nworst-case performance of some popular greedy approaches, and showing the\nimpossibility of having an adversarial patience in the product ranking setting.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 03:31:24 GMT"}, {"version": "v2", "created": "Thu, 11 Mar 2021 01:13:41 GMT"}, {"version": "v3", "created": "Sat, 12 Jun 2021 23:44:48 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Brubach", "Brian", ""], ["Grammel", "Nathaniel", ""], ["Ma", "Will", ""], ["Srinivasan", "Aravind", ""]]}, {"id": "1907.04394", "submitter": "Souma Chowdhury", "authors": "Payam Ghassemi, David DePauw, Souma Chowdhury", "title": "Decentralized Dynamic Task Allocation in Swarm Robotic Systems for\n  Disaster Response", "comments": "Accepted for poster presentation in (and publication as extended\n  abstract in the proceedings of) The IEEE 2019 International Symposium on\n  Multi-Robot and Multi-Agent Systems (MRS)", "journal-ref": null, "doi": "10.1109/MRS.2019.8901062", "report-no": null, "categories": "cs.MA cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple robotic systems, working together, can provide important solutions\nto different real-world applications (e.g., disaster response), among which\ntask allocation problems feature prominently. Very few existing decentralized\nmulti-robotic task allocation (MRTA) methods simultaneously offer the following\ncapabilities: consideration of task deadlines, consideration of robot range and\ntask completion capacity limitations, and allowing asynchronous decision-making\nunder dynamic task spaces. To provision these capabilities, this paper presents\na computationally efficient algorithm that involves novel construction and\nmatching of bipartite graphs. Its performance is tested on a multi-UAV flood\nresponse application.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 20:24:15 GMT"}, {"version": "v2", "created": "Sat, 25 Jul 2020 19:03:34 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Ghassemi", "Payam", ""], ["DePauw", "David", ""], ["Chowdhury", "Souma", ""]]}, {"id": "1907.04396", "submitter": "Souma Chowdhury", "authors": "Payam Ghassemi, Souma Chowdhury", "title": "Informative Path Planning with Local Penalization for Decentralized and\n  Asynchronous Swarm Robotic Search", "comments": "Accepted for presentation in (and publication in the proceedings of)\n  The IEEE 2019 International Symposium on Multi-Robot and Multi-Agent Systems\n  (MRS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decentralized swarm robotic solutions to searching for targets that emit a\nspatially varying signal promise task parallelism, time efficiency, and fault\ntolerance. It is, however, challenging for swarm algorithms to offer\nscalability and efficiency, while preserving mathematical insights into the\nexhibited behavior. A new decentralized search method (called Bayes-Swarm),\nfounded on batch Bayesian Optimization (BO) principles, is presented here to\naddress these challenges. Unlike swarm heuristics approaches, Bayes-Swarm\ndecouples the knowledge generation and task planning process, thus preserving\ninsights into the emergent behavior. Key contributions lie in: 1) modeling\nknowledge extraction over trajectories, unlike in BO; 2) time-adaptively\nbalancing exploration/exploitation and using an efficient local penalization\napproach to account for potential interactions among different robots' planned\nsamples; and 3) presenting an asynchronous implementation of the algorithm.\nThis algorithm is tested on case studies with bimodal and highly multimodal\nsignal distributions. Up to 76 times better efficiency is demonstrated compared\nto an exhaustive search baseline. The benefits of exploitation/exploration\nbalancing, asynchronous planning, and local penalization, and scalability with\nswarm size, are also demonstrated.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 20:29:48 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Ghassemi", "Payam", ""], ["Chowdhury", "Souma", ""]]}, {"id": "1907.04740", "submitter": "Shenke Xiao", "authors": "Mengjing Chen, Pingzhong Tang, Zihe Wang, Shenke Xiao, Xiwang Yang", "title": "Optimal mechanisms with budget for user generated contents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.MA", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we design gross product maximization mechanisms which\nincentivize users to upload high-quality contents on user-generated-content\n(UGC) websites. We show that, the proportional division mechanism, which is\nwidely used in practice, can perform arbitrarily bad in the worst case. The\nproblem can be formulated using a linear program with bounded and increasing\nvariables. We then present an $O(n\\log n)$ algorithm to find the optimal\nmechanism, where n is the number of players.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 14:12:41 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Chen", "Mengjing", ""], ["Tang", "Pingzhong", ""], ["Wang", "Zihe", ""], ["Xiao", "Shenke", ""], ["Yang", "Xiwang", ""]]}, {"id": "1907.04810", "submitter": "Guillaume Cheze", "authors": "Guillaume Ch\\`eze (IMT)", "title": "Cake cutting: Explicit examples for impossibility results", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we suggest a model of computation for the cake cutting\nproblem. In this model the mediator can ask the same queries as in the\nRobertson-Webb model but he or she can only perform algebraic operations as in\nthe Blum-Shub-Smale model. All existing algorithms described in the\nRobertson-Webb model can be described in this new model.We show that in this\nmodel there exist explicit couples of measures for which no algorithm outputs\nan equitable fair division with connected parts.We also show that there exist\nexplicit set of measures for which no algorithm in this model outputs a fair\ndivision which maximizes the utilitarian social welfare function.The main tool\nof our approach is Galois theory.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 15:07:27 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Ch\u00e8ze", "Guillaume", "", "IMT"]]}, {"id": "1907.05181", "submitter": "Andrea Tacchetti", "authors": "Andrea Tacchetti and DJ Strouse and Marta Garnelo and Thore Graepel\n  and Yoram Bachrach", "title": "A Neural Architecture for Designing Truthful and Efficient Auctions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Auctions are protocols to allocate goods to buyers who have preferences over\nthem, and collect payments in return. Economists have invested significant\neffort in designing auction rules that result in allocations of the goods that\nare desirable for the group as a whole. However, for settings where\nparticipants' valuations of the items on sale are their private information,\nthe rules of the auction must deter buyers from misreporting their preferences,\nso as to maximize their own utility, since misreported preferences hinder the\nability for the auctioneer to allocate goods to those who want them most.\nManual auction design has yielded excellent mechanisms for specific settings,\nbut requires significant effort when tackling new domains. We propose a deep\nlearning based approach to automatically design auctions in a wide variety of\ndomains, shifting the design work from human to machine. We assume that\nparticipants' valuations for the items for sale are independently sampled from\nan unknown but fixed distribution. Our system receives a data-set consisting of\nsuch valuation samples, and outputs an auction rule encoding the desired\nincentive structure. We focus on producing truthful and efficient auctions that\nminimize the economic burden on participants. We evaluate the auctions designed\nby our framework on well-studied domains, such as multi-unit and combinatorial\nauctions, showing that they outperform known auction designs in terms of the\neconomic burden placed on participants.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 13:22:37 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Tacchetti", "Andrea", ""], ["Strouse", "DJ", ""], ["Garnelo", "Marta", ""], ["Graepel", "Thore", ""], ["Bachrach", "Yoram", ""]]}, {"id": "1907.05247", "submitter": "Stefano Albrecht", "authors": "Stefano V. Albrecht, Jacob W. Crandall, Subramanian Ramamoorthy", "title": "An Empirical Study on the Practical Impact of Prior Beliefs over Policy\n  Types", "comments": "Proceedings of the 29th AAAI Conference on Artificial Intelligence\n  (AAAI), 2015. arXiv admin note: substantial text overlap with\n  arXiv:1507.07688", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many multiagent applications require an agent to learn quickly how to\ninteract with previously unknown other agents. To address this problem,\nresearchers have studied learning algorithms which compute posterior beliefs\nover a hypothesised set of policies, based on the observed actions of the other\nagents. The posterior belief is complemented by the prior belief, which\nspecifies the subjective likelihood of policies before any actions are\nobserved. In this paper, we present the first comprehensive empirical study on\nthe practical impact of prior beliefs over policies in repeated interactions.\nWe show that prior beliefs can have a significant impact on the long-term\nperformance of such methods, and that the magnitude of the impact depends on\nthe depth of the planning horizon. Moreover, our results demonstrate that\nautomatic methods can be used to compute prior beliefs with consistent\nperformance effects. This indicates that prior beliefs could be eliminated as a\nmanual parameter and instead be computed automatically.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 09:47:44 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Albrecht", "Stefano V.", ""], ["Crandall", "Jacob W.", ""], ["Ramamoorthy", "Subramanian", ""]]}, {"id": "1907.05636", "submitter": "Mark Burgess", "authors": "Mark Burgess", "title": "From Observability to Significance in Distributed Information Systems", "comments": "Some typos fixed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.DC cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To understand and explain process behaviour we need to be able to see it, and\ndecide its significance, i.e. be able to tell a story about its behaviours.\nThis paper describes a few of the modelling challenges that underlie monitoring\nand observation of processes in IT, by human or by software. The topic of the\nobservability of systems has been elevated recently in connection with computer\nmonitoring and tracing of processes for debugging and forensics. It raises the\nissue of well-known principles of measurement, in bounded contexts, but these\nissues have been left implicit in the Computer Science literature. This paper\naims to remedy this omission, by laying out a simple promise theoretic model,\nsummarizing a long standing trail of work on the observation of distributed\nsystems, based on elementary distinguishability of observations, and classical\ncausality, with history. Three distinct views of a system are sought, across a\nnumber of scales, that described how information is transmitted (and lost) as\nit moves around the system, aggregated into journals and logs.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 09:11:59 GMT"}, {"version": "v2", "created": "Thu, 25 Jul 2019 12:46:04 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Burgess", "Mark", ""]]}, {"id": "1907.05707", "submitter": "Jianhong Wang", "authors": "Jianhong Wang, Yuan Zhang, Tae-Kyun Kim, Yunjie Gu", "title": "Shapley Q-value: A Local Reward Approach to Solve Global Reward Games", "comments": null, "journal-ref": "AAAI2020", "doi": "10.1609/aaai.v34i05.6220", "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cooperative game is a critical research area in the multi-agent reinforcement\nlearning (MARL). Global reward game is a subclass of cooperative games, where\nall agents aim to maximize the global reward. Credit assignment is an important\nproblem studied in the global reward game. Most of previous works stood by the\nview of non-cooperative-game theoretical framework with the shared reward\napproach, i.e., each agent being assigned a shared global reward directly.\nThis, however, may give each agent an inaccurate reward on its contribution to\nthe group, which could cause inefficient learning. To deal with this problem,\nwe i) introduce a cooperative-game theoretical framework called extended convex\ngame (ECG) that is a superset of global reward game, and ii) propose a local\nreward approach called Shapley Q-value. Shapley Q-value is able to distribute\nthe global reward, reflecting each agent's own contribution in contrast to the\nshared reward approach. Moreover, we derive an MARL algorithm called Shapley\nQ-value deep deterministic policy gradient (SQDDPG), using Shapley Q-value as\nthe critic for each agent. We evaluate SQDDPG on Cooperative Navigation,\nPrey-and-Predator and Traffic Junction, compared with the state-of-the-art\nalgorithms, e.g., MADDPG, COMA, Independent DDPG and Independent A2C. In the\nexperiments, SQDDPG shows a significant improvement on the convergence rate.\nFinally, we plot Shapley Q-value and validate the property of fair credit\nassignment.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 15:12:33 GMT"}, {"version": "v2", "created": "Mon, 9 Sep 2019 09:25:00 GMT"}, {"version": "v3", "created": "Thu, 21 Nov 2019 21:19:38 GMT"}, {"version": "v4", "created": "Mon, 25 Nov 2019 11:26:06 GMT"}, {"version": "v5", "created": "Tue, 24 Nov 2020 17:03:53 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Wang", "Jianhong", ""], ["Zhang", "Yuan", ""], ["Kim", "Tae-Kyun", ""], ["Gu", "Yunjie", ""]]}, {"id": "1907.05945", "submitter": "Bobby Davis", "authors": "Bobby Davis, Ioannis Karamouzas, and Stephen J. Guy", "title": "NH-TTC: A gradient-based framework for generalized anticipatory\n  collision avoidance", "comments": "17 pages, 13 figures. The associated video is available at\n  http://motion.cs.umn.edu/r/NH-TTC", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose NH-TTC, a general method for fast, anticipatory collision\navoidance for autonomous robots having arbitrary equations of motions. Our\nproposed approach exploits implicit differentiation and subgradient descent to\nlocally optimize the non-convex and non-smooth cost functions that arise from\nplanning over the anticipated future positions of nearby obstacles. The result\nis a flexible framework capable of supporting high-quality, collision-free\nnavigation with a wide variety of robot motion models in various challenging\nscenarios. We show results for different navigating tasks, with our method\ncontrolling various numbers of agents (with and without reciprocity), on both\nphysical differential drive robots, and simulated robots with different motion\nmodels and kinematic and dynamic constraints, including acceleration-controlled\nagents, differential-drive agents, and smooth car-like agents. The resulting\npaths are high quality and collision-free, while needing only a few\nmilliseconds of computation as part of an integrated sense-plan-act navigation\nloop.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 20:38:21 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Davis", "Bobby", ""], ["Karamouzas", "Ioannis", ""], ["Guy", "Stephen J.", ""]]}, {"id": "1907.06536", "submitter": "Han Cha", "authors": "Han Cha, Jihong Park, Hyesung Kim, Seong-Lyun Kim, Mehdi Bennis", "title": "Federated Reinforcement Distillation with Proxy Experience Memory", "comments": "To be presented at the 28th International Joint Conference on\n  Artificial Intelligence (IJCAI-19), 1st International Workshop on Federated\n  Machine Learning for User Privacy and Data Confidentiality (FML'19), Macao,\n  China", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In distributed reinforcement learning, it is common to exchange the\nexperience memory of each agent and thereby collectively train their local\nmodels. The experience memory, however, contains all the preceding state\nobservations and their corresponding policies of the host agent, which may\nviolate the privacy of the agent. To avoid this problem, in this work, we\npropose a privacy-preserving distributed reinforcement learning (RL) framework,\ntermed federated reinforcement distillation (FRD). The key idea is to exchange\na proxy experience memory comprising a pre-arranged set of states and\ntime-averaged policies, thereby preserving the privacy of actual experiences.\nBased on an advantage actor-critic RL architecture, we numerically evaluate the\neffectiveness of FRD and investigate how the performance of FRD is affected by\nthe proxy memory structure and different memory exchanging rules.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 15:03:14 GMT"}, {"version": "v2", "created": "Mon, 13 Apr 2020 06:33:38 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Cha", "Han", ""], ["Park", "Jihong", ""], ["Kim", "Hyesung", ""], ["Kim", "Seong-Lyun", ""], ["Bennis", "Mehdi", ""]]}, {"id": "1907.06855", "submitter": "Saber Salehkaleybar", "authors": "Hamidreza Bandealinaeini, Saber Salehkaleybar", "title": "Broadcast Distributed Voting Algorithm in Population Protocols", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of multi-choice majority voting in a network of $n$\nagents where each agent initially selects a choice from a set of $K$ possible\nchoices. The agents try to infer the choice in majority merely by performing\nlocal interactions. Population protocols provide a framework for designing\npairwise interactions between agents in order to perform tasks in a coordinated\nmanner. In this paper, we propose ``Broadcasting Population Protocol\" model as\na counterpart model of conventional population protocols for the networks that\neach agent can send a message to all its neighbors simultaneously. We design\ntwo distributed algorithms for solving the multi-choice majority voting problem\nin the model of broadcasting population protocols. We prove the correctness of\nthese algorithms and analyze their performance in terms of time and message\ncomplexities. Experiments show that the proposed algorithm improves both time\nand message complexities significantly with respect to previous algorithms\nproposed in conventional population protocols and they can be utilized in\nnetworks where messages can be transmitted to a subset of agents simultaneously\nsuch as wireless networks.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 06:07:53 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Bandealinaeini", "Hamidreza", ""], ["Salehkaleybar", "Saber", ""]]}, {"id": "1907.06862", "submitter": "Matvey Soloviev", "authors": "Seunghee Han, Matvey Soloviev and Yuwen Wang", "title": "The Impact of Tribalism on Social Welfare", "comments": "21 pages, including references, figures and appendix. Short form of\n  paper accepted for publication at SAGT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the impact of mutual altruism among the players belonging to the\nsame set -- their tribe -- in a partition of all players in arbitrary strategic\ngames upon the quality of equilibria attained. To this end, we introduce the\nnotion of a {\\tau}-tribal extension of an arbitrary strategic game, in which\nplayers' subjective cost functions are updated to reflect this, and the\nassociated Price of Tribalism, which is the ratio of the social welfare of the\nworst Nash equilibrium of the tribal extension to that of the optimum of social\nwelfare. We show that in a well-known game of friendship cliques, network\ncontribution games as well as atomic linear congestion games, the Price of\nTribalism is higher than the Price of Anarchy of either the purely selfish\nplayers or fully altruistic players (i.e. ones who seek to maximise the social\nwelfare). This phenomenon is observed under a variety of equilibrium concepts.\nIn each instance, we present upper bounds on the Price of Tribalism that match\nthe lower bounds established by our example.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 06:48:33 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Han", "Seunghee", ""], ["Soloviev", "Matvey", ""], ["Wang", "Yuwen", ""]]}, {"id": "1907.06995", "submitter": "Stefano Albrecht", "authors": "Stefano V. Albrecht, Subramanian Ramamoorthy", "title": "On Convergence and Optimality of Best-Response Learning with Policy\n  Types in Multiagent Systems", "comments": "Proceedings of the 30th Conference on Uncertainty in Artificial\n  Intelligence (UAI), 2014. arXiv admin note: substantial text overlap with\n  arXiv:1507.07688", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While many multiagent algorithms are designed for homogeneous systems (i.e.\nall agents are identical), there are important applications which require an\nagent to coordinate its actions without knowing a priori how the other agents\nbehave. One method to make this problem feasible is to assume that the other\nagents draw their latent policy (or type) from a specific set, and that a\ndomain expert could provide a specification of this set, albeit only a\npartially correct one. Algorithms have been proposed by several researchers to\ncompute posterior beliefs over such policy libraries, which can then be used to\ndetermine optimal actions. In this paper, we provide theoretical guidance on\ntwo central design parameters of this method: Firstly, it is important that the\nuser choose a posterior which can learn the true distribution of latent types,\nas otherwise suboptimal actions may be chosen. We analyse convergence\nproperties of two existing posterior formulations and propose a new posterior\nwhich can learn correlated distributions. Secondly, since the types are\nprovided by an expert, they may be inaccurate in the sense that they do not\npredict the agents' observed actions. We provide a novel characterisation of\noptimality which allows experts to use efficient model checking algorithms to\nverify optimality of types.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 09:30:27 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Albrecht", "Stefano V.", ""], ["Ramamoorthy", "Subramanian", ""]]}, {"id": "1907.07132", "submitter": "Zainab Alalawi", "authors": "Zainab Alalawi, The Anh Han, Yifeng Zeng and Aiman Elragig", "title": "Pathways to Good Healthcare Services and Patient Satisfaction: An\n  Evolutionary Game Theoretical Approach", "comments": "8 pages, 6 Figures, The 2019 Conference on Artificial Life", "journal-ref": null, "doi": "10.13140/RG.2.2.30657.10086", "report-no": null, "categories": "physics.soc-ph cs.GT cs.MA econ.TH math.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Spending by the UK's National Health Service (NHS) on independent healthcare\ntreatment has been increased in recent years and is predicted to sustain its\nupward trend with the forecast of population growth. Some have viewed this\nincrease as an attempt not to expand the patients' choices but to privatize\npublic healthcare. This debate poses a social dilemma whether the NHS should\nstop cooperating with Private providers. This paper contributes to healthcare\neconomic modelling by investigating the evolution of cooperation among three\nproposed populations: Public Healthcare Providers, Private Healthcare Providers\nand Patients. The Patient population is included as a main player in the\ndecision-making process by expanding patient's choices of treatment. We develop\na generic basic model that measures the cost of healthcare provision based on\ngiven parameters, such as NHS and private healthcare providers' cost of\ninvestments in both sectors, cost of treatments and gained benefits. A\npatient's costly punishment is introduced as a mechanism to enhance cooperation\namong the three populations. Our findings show that cooperation can be improved\nwith the introduction of punishment (patient's punishment) against defecting\nproviders. Although punishment increases cooperation, it is very costly\nconsidering the small improvement in cooperation in comparison to the basic\nmodel.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jul 2019 15:38:33 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Alalawi", "Zainab", ""], ["Han", "The Anh", ""], ["Zeng", "Yifeng", ""], ["Elragig", "Aiman", ""]]}, {"id": "1907.07433", "submitter": "Ilya Afanasyev", "authors": "Ilya Afanasyev, Alexander Kolotov, Ruslan Rezin, Konstantin Danilov,\n  Manuel Mazzara, Subham Chakraborty, Alexey Kashevnik, Andrey Chechulin,\n  Aleksandr Kapitonov, Vladimir Jotsov, Andon Topalov, Nikola Shakev, Sevil\n  Ahmed", "title": "Towards Blockchain-based Multi-Agent Robotic Systems: Analysis,\n  Classification and Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.DC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decentralization, immutability and transparency make of Blockchain one of the\nmost innovative technology of recent years. This paper presents an overview of\nsolutions based on Blockchain technology for multi-agent robotic systems, and\nprovide an analysis and classification of this emerging field. The reasons for\nimplementing Blockchain in a multi-robot network may be to increase the\ninteraction efficiency between agents by providing more trusted information\nexchange, reaching a consensus in trustless conditions, assessing robot\nproductivity or detecting performance problems, identifying intruders,\nallocating plans and tasks, deploying distributed solutions and joint missions.\nBlockchain-based applications are discussed to demonstrate how distributed\nledger can be used to extend the number of research platforms and libraries for\nmulti-agent robotic systems.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 10:38:56 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Afanasyev", "Ilya", ""], ["Kolotov", "Alexander", ""], ["Rezin", "Ruslan", ""], ["Danilov", "Konstantin", ""], ["Mazzara", "Manuel", ""], ["Chakraborty", "Subham", ""], ["Kashevnik", "Alexey", ""], ["Chechulin", "Andrey", ""], ["Kapitonov", "Aleksandr", ""], ["Jotsov", "Vladimir", ""], ["Topalov", "Andon", ""], ["Shakev", "Nikola", ""], ["Ahmed", "Sevil", ""]]}, {"id": "1907.07600", "submitter": "Madi Zholbaryssov", "authors": "Madi Zholbaryssov, Christoforos N. Hadjicostis, Alejandro D.\n  Dominguez-Garcia", "title": "Fast Distributed Coordination of Distributed Energy Resources Over\n  Time-Varying Communication Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of optimally coordinating the response\nof a group of distributed energy resources (DERs) so they collectively meet the\nelectric power demanded by a collection of loads, while minimizing the total\ngeneration cost and respecting the DER capacity limits. This problem can be\ncast as a convex optimization problem, where the global objective is to\nminimize a sum of convex functions corresponding to individual DER generation\ncost, while satisfying (i) linear inequality constraints corresponding to the\nDER capacity limits and (ii) a linear equality constraint corresponding to the\ntotal power generated by the DERs being equal to the total power demand. We\ndevelop distributed algorithms to solve the DER coordination problem over\ntime-varying communication networks with either bidirectional or unidirectional\ncommunication links. The proposed algorithms can be seen as distributed\nversions of a centralized primal-dual algorithm. One of the algorithms proposed\nfor directed communication graphs has geometric convergence rate even when\ncommunication out-degrees are unknown to agents. We showcase the proposed\nalgorithms using the standard IEEE 39-bus test system, and compare their\nperformance against other ones proposed in the literature.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 15:58:38 GMT"}, {"version": "v2", "created": "Tue, 14 Apr 2020 17:54:56 GMT"}, {"version": "v3", "created": "Mon, 20 Apr 2020 04:03:50 GMT"}, {"version": "v4", "created": "Mon, 4 May 2020 06:37:38 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Zholbaryssov", "Madi", ""], ["Hadjicostis", "Christoforos N.", ""], ["Dominguez-Garcia", "Alejandro D.", ""]]}, {"id": "1907.07631", "submitter": "Pavel Surynek", "authors": "Pavel Surynek", "title": "On the Tour Towards DPLL(MAPF) and Beyond", "comments": "arXiv admin note: substantial text overlap with arXiv:1809.05959", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss milestones on the tour towards DPLL(MAPF), a multi-agent path\nfinding (MAPF) solver fully integrated with the Davis-Putnam-Logemann-Loveland\n(DPLL) propositional satisfiability testing algorithm through satisfiability\nmodulo theories (SMT). The task in MAPF is to navigate agents in an undirected\ngraph in a non-colliding way so that each agent eventually reaches its unique\ngoal vertex. At most one agent can reside in a vertex at a time. Agents can\nmove instantaneously by traversing edges provided the movement does not result\nin a collision. Recently attempts to solve MAPF optimally w.r.t. the\nsum-of-costs or the makespan based on the reduction of MAPF to propositional\nsatisfiability (SAT) have appeared. The most successful methods rely on\nbuilding the propositional encoding for the given MAPF instance lazily by a\nprocess inspired in the SMT paradigm. The integration of satisfiability testing\nby the SAT solver and the high-level construction of the encoding is however\nrelatively loose in existing methods. Therefore the ultimate goal of research\nin this direction is to build the DPLL(MAPF) algorithm, a MAPF solver where the\nconstruction of the encoding is fully integrated with the underlying SAT\nsolver. We discuss the current state-of-the-art in MAPF solving and what steps\nneed to be done to get DPLL(MAPF). The advantages of DPLL(MAPF) in terms of its\npotential to be alternatively parametrized with MAPF$^R$, a theory of\ncontinuous MAPF with geometric agents, are also discussed.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 23:50:09 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Surynek", "Pavel", ""]]}, {"id": "1907.07718", "submitter": "Pietro Pierpaoli", "authors": "Pietro Pierpaoli, Anqi Li, Mohit Srinivasan, Xiaoyi Cai, Samuel\n  Coogan, and Magnus Egerstedt", "title": "A Sequential Composition Framework for Coordinating Multi-Robot\n  Behaviors", "comments": "11 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.MA", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A number of coordinated behaviors have been proposed for achieving specific\ntasks for multi-robot systems. However, since most applications require more\nthan one such behavior, one needs to be able to compose together sequences of\nbehaviors while respecting local information flow constraints. Specifically,\nwhen the inter-agent communication depends on inter-robot distances, these\nconstraints translate into particular configurations that must be reached in\nfinite time in order for the system to be able to transition between the\nbehaviors. To this end, we develop a distributed framework based on finite-time\nconvergence control barrier functions that enables a team of robots to adjust\nits configuration in order to meet the communication requirements for the\ndifferent tasks. In order to demonstrate the significance of the proposed\nframework, we implemented a full-scale scenario where a team of eight planar\nrobots explore an urban environment in order to localize and rescue a subject.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 18:53:57 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2020 19:29:40 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Pierpaoli", "Pietro", ""], ["Li", "Anqi", ""], ["Srinivasan", "Mohit", ""], ["Cai", "Xiaoyi", ""], ["Coogan", "Samuel", ""], ["Egerstedt", "Magnus", ""]]}, {"id": "1907.07847", "submitter": "Qisheng Wang", "authors": "Qisheng Wang and Qichao Wang", "title": "Prioritized Guidance for Efficient Multi-Agent Reinforcement Learning\n  Exploration", "comments": "Theequations (7)-(10) in the paper are incorrectly derived, and need\n  to be withdrawn and revised in many places", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploration efficiency is a challenging problem in multi-agent reinforcement\nlearning (MARL), as the policy learned by confederate MARL depends on the\ncollaborative approach among multiple agents. Another important problem is the\nless informative reward restricts the learning speed of MARL compared with the\ninformative label in supervised learning. In this work, we leverage on a novel\ncommunication method to guide MARL to accelerate exploration and propose a\npredictive network to forecast the reward of current state-action pair and use\nthe guidance learned by the predictive network to modify the reward function.\nAn improved prioritized experience replay is employed to better take advantage\nof the different knowledge learned by different agents which utilizes\nTime-difference (TD) error more effectively. Experimental results demonstrates\nthat the proposed algorithm outperforms existing methods in cooperative\nmulti-agent environments. We remark that this algorithm can be extended to\nsupervised learning to speed up its training.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 02:27:55 GMT"}, {"version": "v2", "created": "Fri, 19 Jul 2019 07:34:39 GMT"}, {"version": "v3", "created": "Wed, 25 Dec 2019 07:05:14 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Wang", "Qisheng", ""], ["Wang", "Qichao", ""]]}, {"id": "1907.08165", "submitter": "Alexandros A. Voudouris", "authors": "Georgios Amanatidis, Georgios Birmpas, Aris Filos-Ratsikas, Alexandros\n  A. Voudouris", "title": "Peeking Behind the Ordinal Curtain: Improving Distortion via Cardinal\n  Queries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aggregating the preferences of individuals into a collective decision is the\ncore subject of study of social choice theory. In 2006, Procaccia and\nRosenschein considered a utilitarian social choice setting, where the agents\nhave explicit numerical values for the alternatives, yet they only report their\nlinear orderings over them. To compare different aggregation mechanisms,\nProcaccia and Rosenschein introduced the notion of distortion, which quantifies\nthe inefficiency of using only ordinal information when trying to maximize the\nsocial welfare, i.e., the sum of the underlying values of the agents for the\nchosen outcome. Since then, this research area has flourished and bounds on the\ndistortion have been obtained for a wide variety of fundamental scenarios.\nHowever, the vast majority of the existing literature is focused on the case\nwhere nothing is known beyond the ordinal preferences of the agents over the\nalternatives. In this paper, we take a more expressive approach, and consider\nmechanisms that are allowed to further ask a few cardinal queries in order to\ngain partial access to the underlying values that the agents have for the\nalternatives. With this extra power, we design new deterministic mechanisms\nthat achieve significantly improved distortion bounds and, in many cases,\noutperform the best-known randomized ordinal mechanisms. We paint an almost\ncomplete picture of the number of queries required by deterministic mechanisms\nto achieve specific distortion bounds.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 17:11:12 GMT"}, {"version": "v2", "created": "Mon, 6 Jan 2020 10:55:38 GMT"}, {"version": "v3", "created": "Thu, 15 Apr 2021 15:53:21 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Amanatidis", "Georgios", ""], ["Birmpas", "Georgios", ""], ["Filos-Ratsikas", "Aris", ""], ["Voudouris", "Alexandros A.", ""]]}, {"id": "1907.08725", "submitter": "Henry M. Kim", "authors": "Shivam Saxena, Hany Farag, Hjalmar Turesson, Henry M. Kim", "title": "Blockchain Based Transactive Energy Systems for Voltage Regulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.MA cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transactive Energy Systems (TES) are modern mechanisms in electric power\nsystems that allow disparate control agents to utilize distributed generation\nunits (DGs) to engage in energy transactions and provide ancillary services to\nthe grid. Although voltage regulation is a crucial ancillary service within\nactive distribution networks (ADNs), previous work has not adequately explored\nhow this service can be offered in terms of its incentivization, contract\nauditability and enforcement. Blockchain technology shows promise in being a\nkey enabler of TES, allowing agents to engage in trustless, persistent\ntransactions that are both enforceable and auditable. To that end, this paper\nproposes a blockchain based TES that enables agents to receive incentives for\nproviding voltage regulation services by i) maintaining an auditable reputation\nrating for each agent that is increased proportionately with each mitigation of\na voltage violation, ii) utilizing smart contracts to enforce the validity of\neach transaction and penalize reputation ratings in case of a mitigation\nfailure and iii) automating the negotiation and bidding of agent services by\nimplementing the contract net protocol (CNP) as a smart contract. Experimental\nresults on both simulated and real-world ADNs are executed to demonstrate the\nefficacy of the proposed system.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 23:05:13 GMT"}, {"version": "v2", "created": "Tue, 23 Jul 2019 23:12:33 GMT"}, {"version": "v3", "created": "Tue, 22 Oct 2019 12:59:16 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Saxena", "Shivam", ""], ["Farag", "Hany", ""], ["Turesson", "Hjalmar", ""], ["Kim", "Henry M.", ""]]}, {"id": "1907.08802", "submitter": "Brian Swenson", "authors": "Brian Swenson, Soummya Kar, H. Vincent Poor, and Jos\\'e M. F. Moura", "title": "Distributed Global Optimization by Annealing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper considers a distributed algorithm for global minimization of a\nnonconvex function. The algorithm is a first-order consensus + innovations type\nalgorithm that incorporates decaying additive Gaussian noise for annealing,\nconverging to the set of global minima under certain technical assumptions. The\npaper presents simple methods for verifying that the required technical\nassumptions hold and illustrates it with a distributed target-localization\napplication.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jul 2019 12:14:35 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Swenson", "Brian", ""], ["Kar", "Soummya", ""], ["Poor", "H. Vincent", ""], ["Moura", "Jos\u00e9 M. F.", ""]]}, {"id": "1907.09101", "submitter": "EPTCS", "authors": "Yifeng Ding (University of California, Berkeley), Wesley H. Holliday\n  (University of California, Berkeley), Cedegao Zhang (University of\n  California, Berkeley)", "title": "When Do Introspection Axioms Matter for Multi-Agent Epistemic Reasoning?", "comments": "In Proceedings TARK 2019, arXiv:1907.08335", "journal-ref": "EPTCS 297, 2019, pp. 121-139", "doi": "10.4204/EPTCS.297.9", "report-no": null, "categories": "cs.LO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The early literature on epistemic logic in philosophy focused on reasoning\nabout the knowledge or belief of a single agent, especially on controversies\nabout \"introspection axioms\" such as the 4 and 5 axioms. By contrast, the later\nliterature on epistemic logic in computer science and game theory has focused\non multi-agent epistemic reasoning, with the single-agent 4 and 5 axioms\nlargely taken for granted. In the relevant multi-agent scenarios, it is often\nimportant to reason about what agent A believes about what agent B believes\nabout what agent A believes; but it is rarely important to reason just about\nwhat agent A believes about what agent A believes. This raises the question of\nthe extent to which single-agent introspection axioms actually matter for\nmulti-agent epistemic reasoning. In this paper, we formalize and answer this\nquestion. To formalize the question, we first define a set of multi-agent\nformulas that we call agent-alternating formulas, including formulas like Box_a\nBox_b Box_a p but not formulas like Box_a Box_a p. We then prove, for the case\nof belief, that if one starts with multi-agent K or KD, then adding both the 4\nand 5 axioms (or adding the B axiom) does not allow the derivation of any new\nagent-alternating formulas -- in this sense, introspection axioms do not\nmatter. By contrast, we show that such conservativity results fail for\nknowledge and multi-agent KT, though they hold with respect to a smaller class\nof agent-nonrepeating formulas.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 03:14:46 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Ding", "Yifeng", "", "University of California, Berkeley"], ["Holliday", "Wesley H.", "", "University of California, Berkeley"], ["Zhang", "Cedegao", "", "University of\n  California, Berkeley"]]}, {"id": "1907.09104", "submitter": "EPTCS", "authors": "Satoshi Fukuda (Department of Decision Sciences and IGIER, Bocconi\n  University)", "title": "On the Consistency among Prior, Posteriors, and Information Sets\n  (Extended Abstract)", "comments": "In Proceedings TARK 2019, arXiv:1907.08335", "journal-ref": "EPTCS 297, 2019, pp. 189-205", "doi": "10.4204/EPTCS.297.13", "report-no": null, "categories": "cs.GT cs.LO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies implications of the consistency conditions among prior,\nposteriors, and information sets on introspective properties of qualitative\nbelief induced from information sets. The main result reformulates the\nconsistency conditions as: (i) the information sets, without any assumption,\nalmost surely form a partition; and (ii) the posterior at a state is equal to\nthe Bayes conditional probability given the corresponding information set.\nImplications are as follows. First, each posterior is uniquely determined.\nSecond, qualitative belief reduces to fully introspective knowledge in a\n``standard'' environment. Thus, a care must be taken when one studies\nnon-veridical belief or non-introspective knowledge. Third, an information\npartition compatible with the consistency conditions is uniquely determined by\nthe posteriors. Fourth, qualitative and probability-one beliefs satisfy truth\naxiom almost surely. The paper also sheds light on how the additivity of the\nposteriors yields negative introspective properties of beliefs.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 03:16:03 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Fukuda", "Satoshi", "", "Department of Decision Sciences and IGIER, Bocconi\n  University"]]}, {"id": "1907.09108", "submitter": "EPTCS", "authors": "Edith Hemaspaandra, Lane A. Hemaspaandra, J\\\"org Rothe", "title": "The Complexity of Online Bribery in Sequential Elections (Extended\n  Abstract)", "comments": "In Proceedings TARK 2019, arXiv:1907.08335", "journal-ref": "EPTCS 297, 2019, pp. 233-251", "doi": "10.4204/EPTCS.297.16", "report-no": null, "categories": "cs.GT cs.CC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prior work on the complexity of bribery assumes that the bribery happens\nsimultaneously, and that the briber has full knowledge of all voters' votes.\nBut neither of those assumptions always holds. In many real-world settings,\nvotes come in sequentially, and the briber may have a use-it-or-lose-it moment\nto decide whether to bribe/alter a given vote, and at the time of making that\ndecision, the briber may not know what votes remaining voters are planning on\ncasting.\n  In this paper, we introduce a model for, and initiate the study of, bribery\nin such an online, sequential setting. We show that even for election systems\nwhose winner-determination problem is polynomial-time computable, an online,\nsequential setting may vastly increase the complexity of bribery, in fact\njumping the problem up to completeness for high levels of the polynomial\nhierarchy or even PSPACE. On the other hand, we show that for some natural,\nimportant election systems, such a dramatic complexity increase does not occur,\nand we pinpoint the complexity of their bribery problems in the online,\nsequential setting.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 03:16:55 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Hemaspaandra", "Edith", ""], ["Hemaspaandra", "Lane A.", ""], ["Rothe", "J\u00f6rg", ""]]}, {"id": "1907.09110", "submitter": "EPTCS", "authors": "Wesley H. Holliday (University of California, Berkeley), Eric Pacuit\n  (University of Maryland)", "title": "Strategic Voting Under Uncertainty About the Voting Method", "comments": "In Proceedings TARK 2019, arXiv:1907.08335", "journal-ref": "EPTCS 297, 2019, pp. 252-272", "doi": "10.4204/EPTCS.297.17", "report-no": null, "categories": "cs.MA cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much of the theoretical work on strategic voting makes strong assumptions\nabout what voters know about the voting situation. A strategizing voter is\ntypically assumed to know how other voters will vote and to know the rules of\nthe voting method. A growing body of literature explores strategic voting when\nthere is uncertainty about how others will vote. In this paper, we study\nstrategic voting when there is uncertainty about the voting method. We\nintroduce three notions of manipulability for a set of voting methods: sure,\nsafe, and expected manipulability. With the help of a computer program, we\nidentify voting scenarios in which uncertainty about the voting method may\nreduce or even eliminate a voter's incentive to misrepresent her preferences.\nThus, it may be in the interest of an election designer who wishes to reduce\nstrategic voting to leave voters uncertain about which of several reasonable\nvoting methods will be used to determine the winners of an election.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 03:17:19 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Holliday", "Wesley H.", "", "University of California, Berkeley"], ["Pacuit", "Eric", "", "University of Maryland"]]}, {"id": "1907.09111", "submitter": "EPTCS", "authors": "Magdalena Ivanovska, Marija Slavkovik", "title": "Aggregating Probabilistic Judgments", "comments": "In Proceedings TARK 2019, arXiv:1907.08335", "journal-ref": "EPTCS 297, 2019, pp. 273-292", "doi": "10.4204/EPTCS.297.18", "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we explore the application of methods for classical judgment\naggregation in pooling probabilistic opinions on logically related issues. For\nthis reason, we first modify the Boolean judgment aggregation framework in the\nway that allows handling probabilistic judgments and then define probabilistic\naggregation functions obtained by generalization of the classical ones. In\naddition, we discuss essential desirable properties for the aggregation\nfunctions and explore impossibility results.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 03:17:47 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Ivanovska", "Magdalena", ""], ["Slavkovik", "Marija", ""]]}, {"id": "1907.09112", "submitter": "EPTCS", "authors": "Roman Kuznets (TU Wien), Laurent Prosperi (ENS Paris-Saclay), Ulrich\n  Schmid (TU Wien), Krisztina Fruzsa (TU Wien)", "title": "Causality and Epistemic Reasoning in Byzantine Multi-Agent Systems", "comments": "In Proceedings TARK 2019, arXiv:1907.08335", "journal-ref": "EPTCS 297, 2019, pp. 293-312", "doi": "10.4204/EPTCS.297.19", "report-no": null, "categories": "cs.MA cs.DC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causality is an important concept both for proving impossibility results and\nfor synthesizing efficient protocols in distributed computing. For asynchronous\nagents communicating over unreliable channels, causality is well studied and\nunderstood. This understanding, however, relies heavily on the assumption that\nagents themselves are correct and reliable. We provide the first epistemic\nanalysis of causality in the presence of byzantine agents, i.e., agents that\ncan deviate from their protocol and, thus, cannot be relied upon. Using our new\nframework for epistemic reasoning in fault-tolerant multi-agent systems, we\ndetermine the byzantine analog of the causal cone and describe a communication\nstructure, which we call a multipede, necessary for verifying preconditions for\nactions in this setting.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 03:18:05 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Kuznets", "Roman", "", "TU Wien"], ["Prosperi", "Laurent", "", "ENS Paris-Saclay"], ["Schmid", "Ulrich", "", "TU Wien"], ["Fruzsa", "Krisztina", "", "TU Wien"]]}, {"id": "1907.09113", "submitter": "EPTCS", "authors": "Grzegorz Lisowski (University of Warwick), Sylvie Doutre (University\n  of Toulouse), Umberto Grandi (University of Toulouse)", "title": "Aggregation in Value-Based Argumentation Frameworks", "comments": "In Proceedings TARK 2019, arXiv:1907.08335", "journal-ref": "EPTCS 297, 2019, pp. 313-331", "doi": "10.4204/EPTCS.297.20", "report-no": null, "categories": "cs.MA cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Value-based argumentation enhances a classical abstract argumentation graph -\nin which arguments are modelled as nodes connected by directed arrows called\nattacks - with labels on arguments, called values, and an ordering on values,\ncalled audience, to provide a more fine-grained justification of the attack\nrelation. With more than one agent facing such an argumentation problem, agents\nmay differ in their ranking of values. When needing to reach a collective view,\nsuch agents face a dilemma between two equally justifiable approaches:\naggregating their views at the level of values, or aggregating their attack\nrelations, remaining therefore at the level of the graphs. We explore the\nstrenghts and limitations of both approaches, employing techniques from\npreference aggregation and graph aggregation, and propose a third possibility\naggregating rankings extracted from given attack relations.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 03:18:29 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Lisowski", "Grzegorz", "", "University of Warwick"], ["Doutre", "Sylvie", "", "University\n  of Toulouse"], ["Grandi", "Umberto", "", "University of Toulouse"]]}, {"id": "1907.09189", "submitter": "Stefano Albrecht", "authors": "Stefano V. Albrecht, Subramanian Ramamoorthy", "title": "Comparative Evaluation of Multiagent Learning Algorithms in a Diverse\n  Set of Ad Hoc Team Problems", "comments": "Proceedings of the 11th International Conference on Autonomous Agents\n  and Multiagent Systems (AAMAS), 2012. This arXiv version of the original\n  paper published in AAMAS 2012 uses an expanded title to spell out \"MAL\", and\n  is otherwise identical", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with evaluating different multiagent learning (MAL)\nalgorithms in problems where individual agents may be heterogenous, in the\nsense of utilizing different learning strategies, without the opportunity for\nprior agreements or information regarding coordination. Such a situation arises\nin ad hoc team problems, a model of many practical multiagent systems\napplications. Prior work in multiagent learning has often been focussed on\nhomogeneous groups of agents, meaning that all agents were identical and a\npriori aware of this fact. Also, those algorithms that are specifically\ndesigned for ad hoc team problems are typically evaluated in teams of agents\nwith fixed behaviours, as opposed to agents which are adapting their\nbehaviours. In this work, we empirically evaluate five MAL algorithms,\nrepresenting major approaches to multiagent learning but originally developed\nwith the homogeneous setting in mind, to understand their behaviour in a set of\nad hoc team problems. All teams consist of agents which are continuously\nadapting their behaviours. The algorithms are evaluated with respect to a\ncomprehensive characterisation of repeated matrix games, using performance\ncriteria that include considerations such as attainment of equilibrium, social\nwelfare and fairness. Our main conclusion is that there is no clear winner.\nHowever, the comparative evaluation also highlights the relative strengths of\ndifferent algorithms with respect to the type of performance criteria, e.g.,\nsocial welfare vs. attainment of equilibrium.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 09:01:08 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Albrecht", "Stefano V.", ""], ["Ramamoorthy", "Subramanian", ""]]}, {"id": "1907.09198", "submitter": "Julian Zilly", "authors": "Andrea Censi, Saverio Bolognani, Julian G. Zilly, Shima Sadat Mousavi,\n  Emilio Frazzoli", "title": "Today Me, Tomorrow Thee: Efficient Resource Allocation in Competitive\n  Settings using Karma Games", "comments": "9 pages, 6 figures, conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new type of coordination mechanism among multiple agents for the\nallocation of a finite resource, such as the allocation of time slots for\npassing an intersection. We consider the setting where we associate one counter\nto each agent, which we call karma value, and where there is an established\nmechanism to decide resource allocation based on agents exchanging karma. The\nidea is that agents might be inclined to pass on using resources today, in\nexchange for karma, which will make it easier for them to claim the resource\nuse in the future. To understand whether such a system might work robustly, we\nonly design the protocol and not the agents' policies. We take a game-theoretic\nperspective and compute policies corresponding to Nash equilibria for the game.\nWe find, surprisingly, that the Nash equilibria for a society of\nself-interested agents are very close in social welfare to a centralized\ncooperative solution. These results suggest that many resource allocation\nproblems can have a simple, elegant, and robust solution, assuming the\navailability of a karma accounting mechanism.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 09:31:09 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Censi", "Andrea", ""], ["Bolognani", "Saverio", ""], ["Zilly", "Julian G.", ""], ["Mousavi", "Shima Sadat", ""], ["Frazzoli", "Emilio", ""]]}, {"id": "1907.09278", "submitter": "Frans A. Oliehoek", "authors": "Frans A. Oliehoek, Stefan Witwicki, Leslie P. Kaelbling", "title": "A Sufficient Statistic for Influence in Structured Multiagent\n  Environments", "comments": null, "journal-ref": "Journal of Artificial Intelligence Research, pp. 789-870, AI\n  Access Foundation, Inc., February 2021", "doi": "10.1613/jair.1.12136", "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Making decisions in complex environments is a key challenge in artificial\nintelligence (AI). Situations involving multiple decision makers are\nparticularly complex, leading to computational intractability of principled\nsolution methods. A body of work in AI has tried to mitigate this problem by\ntrying to distill interaction to its essence: how does the policy of one agent\ninfluence another agent? If we can find more compact representations of such\ninfluence, this can help us deal with the complexity, for instance by searching\nthe space of influences rather than the space of policies. However, so far\nthese notions of influence have been restricted in their applicability to\nspecial cases of interaction. In this paper we formalize influence-based\nabstraction (IBA), which facilitates the elimination of latent state factors\nwithout any loss in value, for a very general class of problems described as\nfactored partially observable stochastic games (fPOSGs). On the one hand, this\ngeneralizes existing descriptions of influence, and thus can serve as the\nfoundation for improvements in scalability and other insights in decision\nmaking in complex multiagent settings. On the other hand, since the presence of\nother agents can be seen as a generalization of single agent settings, our\nformulation of IBA also provides a sufficient statistic for decision making\nunder abstraction for a single agent. We also give a detailed discussion of the\nrelations to such previous works, identifying new insights and interpretations\nof these approaches. In these ways, this paper deepens our understanding of\nabstraction in a wide range of sequential decision making settings, providing\nthe basis for new approaches and algorithms for a large class of problems.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 12:39:48 GMT"}, {"version": "v2", "created": "Mon, 1 Mar 2021 14:26:10 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Oliehoek", "Frans A.", ""], ["Witwicki", "Stefan", ""], ["Kaelbling", "Leslie P.", ""]]}, {"id": "1907.09293", "submitter": "David Powers", "authors": "David M W Powers", "title": "DREAMT -- Embodied Motivational Conversational Storytelling", "comments": "12 pages; to be presented as lightning talk plus poster at StoryNLP\n  on 1 August 2019 at ACL in Florence - poster pdf and powerpoint available", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.HC cs.MA cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Storytelling is fundamental to language, including culture, conversation and\ncommunication in their broadest senses. It thus emerges as an essential\ncomponent of intelligent systems, including systems where natural language is\nnot a primary focus or where we do not usually think of a story being involved.\nIn this paper we explore the emergence of storytelling as a requirement in\nembodied conversational agents, including its role in educational and health\ninterventions, as well as in a general-purpose computer interface for people\nwith disabilities or other constraints that prevent the use of traditional\nkeyboard and speech interfaces. We further present a characterization of\nstorytelling as an inventive fleshing out of detail according to a particular\npersonal perspective, and propose the DREAMT model to focus attention on the\ndifferent layers that need to be present in a character-driven storytelling\nsystem. Most if not all aspects of the DREAMT model have arisen from or been\nexplored in some aspect of our implemented research systems, but currently only\nat a primitive and relatively unintegrated level. However, this experience\nleads us to formalize and elaborate the DREAMT model mnemonically as follows: -\nDescription/Dialogue/Definition/Denotation - Realization/Representation/Role -\nExplanation/Education/Entertainment - Actualization/Activation -\nMotivation/Modelling - Topicalization/Transformation\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 01:49:37 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Powers", "David M W", ""]]}, {"id": "1907.09467", "submitter": "Qing Wang", "authors": "Qing Wang, Jiechao Xiong, Lei Han, Meng Fang, Xinghai Sun, Zhuobin\n  Zheng, Peng Sun, Zhengyou Zhang", "title": "Arena: a toolkit for Multi-Agent Reinforcement Learning", "comments": "21 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Arena, a toolkit for multi-agent reinforcement learning (MARL)\nresearch. In MARL, it usually requires customizing observations, rewards and\nactions for each agent, changing cooperative-competitive agent-interaction, and\nplaying with/against a third-party agent, etc. We provide a novel modular\ndesign, called Interface, for manipulating such routines in essentially two\nways: 1) Different interfaces can be concatenated and combined, which extends\nthe OpenAI Gym Wrappers concept to MARL scenarios. 2) During MARL training or\ntesting, interfaces can be embedded in either wrapped OpenAI Gym compatible\nEnvironments or raw environment compatible Agents. We offer off-the-shelf\ninterfaces for several popular MARL platforms, including StarCraft II,\nPommerman, ViZDoom, Soccer, etc. The interfaces effectively support self-play\nRL and cooperative-competitive hybrid MARL. Also, Arena can be conveniently\nextended to your own favorite MARL platform.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jul 2019 05:13:53 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Wang", "Qing", ""], ["Xiong", "Jiechao", ""], ["Han", "Lei", ""], ["Fang", "Meng", ""], ["Sun", "Xinghai", ""], ["Zheng", "Zhuobin", ""], ["Sun", "Peng", ""], ["Zhang", "Zhengyou", ""]]}, {"id": "1907.09520", "submitter": "Benedikt Z\\\"onnchen", "authors": "Benedikt Kleinmeier, Benedikt Z\\\"onnchen, Marion G\\\"odel, Gerta\n  K\\\"oster", "title": "Vadere: An open-source simulation framework to promote interdisciplinary\n  understanding", "comments": "submitted to Collective Dynamics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Pedestrian dynamics is an interdisciplinary field of research. Psychologists,\nsociologists, traffic engineers, physicists, mathematicians and computer\nscientists all strive to understand the dynamics of a moving crowd. In\nprinciple, computer simulations offer means to further this understanding. Yet,\nunlike for many classic dynamical systems in physics, there is no universally\naccepted locomotion model for crowd dynamics. On the contrary, a multitude of\napproaches, with very different characteristics, compete. Often only the\nexperts in one special model type are able to assess the consequences these\ncharacteristics have on a simulation study. Therefore, scientists from all\ndisciplines who wish to use simulations to analyze pedestrian dynamics need a\ntool to compare competing approaches. Developers, too, would profit from an\neasy way to get insight into an alternative modeling ansatz. Vadere meets this\ninterdisciplinary demand by offering an open-source simulation framework that\nis lightweight in its approach and in its user interface while offering\npre-implemented versions of the most widely spread models.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 12:24:40 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Kleinmeier", "Benedikt", ""], ["Z\u00f6nnchen", "Benedikt", ""], ["G\u00f6del", "Marion", ""], ["K\u00f6ster", "Gerta", ""]]}, {"id": "1907.09597", "submitter": "Pablo Hernandez-Leal", "authors": "Pablo Hernandez-Leal, Bilal Kartal and Matthew E. Taylor", "title": "Agent Modeling as Auxiliary Task for Deep Reinforcement Learning", "comments": "AAAI Conference on Artificial Intelligence and Interactive Digital\n  Entertainment (AIIDE'19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we explore how actor-critic methods in deep reinforcement\nlearning, in particular Asynchronous Advantage Actor-Critic (A3C), can be\nextended with agent modeling. Inspired by recent works on representation\nlearning and multiagent deep reinforcement learning, we propose two\narchitectures to perform agent modeling: the first one based on parameter\nsharing, and the second one based on agent policy features. Both architectures\naim to learn other agents' policies as auxiliary tasks, besides the standard\nactor (policy) and critic (values). We performed experiments in both\ncooperative and competitive domains. The former is a problem of coordinated\nmultiagent object transportation and the latter is a two-player mini version of\nthe Pommerman game. Our results show that the proposed architectures stabilize\nlearning and outperform the standard A3C architecture when learning a best\nresponse in terms of expected rewards.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 21:54:44 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Hernandez-Leal", "Pablo", ""], ["Kartal", "Bilal", ""], ["Taylor", "Matthew E.", ""]]}, {"id": "1907.09810", "submitter": "Stefano Albrecht", "authors": "Stefano V. Albrecht, Jacob W. Crandall, Subramanian Ramamoorthy", "title": "E-HBA: Using Action Policies for Expert Advice and Agent Typification", "comments": "Proceedings of the Second Workshop on Multiagent Interaction without\n  Prior Coordination (MIPC), 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Past research has studied two approaches to utilise predefined policy sets in\nrepeated interactions: as experts, to dictate our own actions, and as types, to\ncharacterise the behaviour of other agents. In this work, we bring these\ncomplementary views together in the form of a novel meta-algorithm, called\nExpert-HBA (E-HBA), which can be applied to any expert algorithm that considers\nthe average (or total) payoff an expert has yielded in the past. E-HBA\ngradually mixes the past payoff with a predicted future payoff, which is\ncomputed using the type-based characterisation. We present results from a\ncomprehensive set of repeated matrix games, comparing the performance of\nseveral well-known expert algorithms with and without the aid of E-HBA. Our\nresults show that E-HBA has the potential to significantly improve the\nperformance of expert algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 10:48:10 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Albrecht", "Stefano V.", ""], ["Crandall", "Jacob W.", ""], ["Ramamoorthy", "Subramanian", ""]]}, {"id": "1907.09871", "submitter": "Xavier Defago", "authors": "Xavier D\\'efago, Adam Heriban, S\\'ebastien Tixeuil, Koichi Wada", "title": "Using Model Checking to Formally Verify Rendezvous Algorithms for Robots\n  with Lights in Euclidean Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper details the first successful attempt at using model-checking\ntechniques to verify the correctness of distributed algorithms for robots\nevolving in a \\emph{continuous} environment. The study focuses on the problem\nof rendezvous of two robots with lights.\n  There exist many different rendezvous algorithms that aim at finding the\nminimal number of colors needed to solve rendezvous in various synchrony models\n(e.g., FSYNC, SSYNC, ASYNC). While these rendezvous algorithms are typically\nvery simple, their analysis and proof of correctness tend to be extremely\ncomplex, tedious, and error-prone as impossibility results are based on subtle\ninteractions between robots activation schedules.\n  The paper presents a generic verification model written for the SPIN\nmodel-checker. In particular, we explain the subtle design decisions that allow\nto keep the search space finite and tractable, as well as prove several\nimportant theorems that support them. As a sanity check, we use the model to\nverify several known rendezvous algorithms in six different models of\nsynchrony. In each case, we find that the results obtained from the\nmodel-checker are consistent with the results known in the literature. The\nmodel-checker outputs a counter-example execution in every case that is known\nto fail.\n  In the course of developing and proving the validity of the model, we\nidentified several fundamental theorems, including the ability for a well\nchosen algorithm and ASYNC scheduler to produce an emerging property of memory\nin a system of oblivious mobile robots, and why it is not a problem for\nluminous rendezvous algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 13:31:39 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["D\u00e9fago", "Xavier", ""], ["Heriban", "Adam", ""], ["Tixeuil", "S\u00e9bastien", ""], ["Wada", "Koichi", ""]]}, {"id": "1907.10384", "submitter": "Chirag Raman", "authors": "Chirag Raman, Hayley Hung", "title": "Towards automatic estimation of conversation floors within F-formations", "comments": "8th International Conference on Affective Computing & Intelligent\n  Interaction EMERGent Workshop, 7 pages, 4 Figures, 2 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.CV cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The detection of free-standing conversing groups has received significant\nattention in recent years. In the absence of a formal definition, most studies\noperationalize the notion of a conversation group either through a spatial or a\ntemporal lens. Spatially, the most commonly used representation is the\nF-formation, defined by social scientists as the configuration in which people\narrange themselves to sustain an interaction. However, the use of this\nrepresentation is often accompanied with the simplifying assumption that a\nsingle conversation occurs within an F-formation. Temporally, various\ncategories have been used to organize conversational units; these include,\namong others, turn, topic, and floor. Some of these concepts are hard to define\nobjectively by themselves. The present work constitutes an initial exploration\ninto unifying these perspectives by primarily posing the question: can we use\nthe observation of simultaneous speaker turns to infer whether multiple\nconversation floors exist within an F-formation? We motivate a metric for the\nexistence of distinct conversation floors based on simultaneous speaker turns,\nand provide an analysis using this metric to characterize conversations across\nF-formations of varying cardinality. We contribute two key findings: firstly,\nat the average speaking turn duration of about two seconds for humans, there is\nevidence for the existence of multiple floors within an F-formation; and\nsecondly, an increase in the cardinality of an F-formation correlates with a\ndecrease in duration of simultaneous speaking turns.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 09:16:05 GMT"}, {"version": "v2", "created": "Wed, 31 Jul 2019 09:31:16 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Raman", "Chirag", ""], ["Hung", "Hayley", ""]]}, {"id": "1907.10491", "submitter": "Zijia Zhong", "authors": "Zijia Zhong and Earl E. Lee", "title": "Alternative Intersection Designs with Connected and Automated Vehicle", "comments": "6 pages, 6 figures, 2019 IEEE 2nd Connected and Automated Vehicles\n  Symposium. arXiv admin note: text overlap with arXiv:1811.03074", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Alternative intersection designs (AIDs) can improve the performance of an\nintersection by not only reducing the number of signal phases but also change\nthe configuration of the conflicting points by re-routing traffic. However the\nAID studies have rarely been extended to Connected and Automated Vehicle (CAV)\nwhich is expected to revolutionize our transportation system. In this study, we\ninvestigate the potential benefits of CAV to two AIDs: the diverging diamond\ninterchange (DDI) and the restricted crossing U-turn intersection. The\npotential enhancements of AID, CAV, and the combination of both are quantified\nvia microscopic traffic simulation. We found that CAV is able to positively\ncontribute to the performance of an intersection. However, converting an\nexisting conventional diamond interchange (CDI) to a diverging one is a more\neffective way according to the simulation results. DDI improves the throughput\nof a CDI by 950 vehicles per hour, a near 20% improvement; whereas with full\npenetration of CAV, the throughput of a CDI is increased only by 300 vehicles\nper hour. A similar trend is observed in the average delay per vehicle as well.\nFurthermore, we assess the impact for the driver's confusion, a concern for\ndeploying AIDs, on the traffic flow. According to the ANOVA test, the negative\nimpacts of driver's confusion are of statistical significance.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 01:41:28 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Zhong", "Zijia", ""], ["Lee", "Earl E.", ""]]}, {"id": "1907.10782", "submitter": "Celal Savur", "authors": "Celal Savur, Shitij Kumar, Ferat Sahin", "title": "A Framework for Monitoring Human Physiological Response during Human\n  Robot Collaborative Task", "comments": "(First Draft) Accepted in IEEE SMC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a framework for monitoring human physiological response during\nHuman-Robot Collaborative (HRC) task is presented. The framework highlights the\nimportance of generation of event markers related to both human and robot, and\nalso synchronization of data collected. This framework enables continuous data\ncollection during an HRC task when changing robot movements as a form of\nstimuli to invoke a human physiological response. It also presents two case\nstudies based on this framework and a data visualization tool for\nrepresentation and easy analysis of the collected data during an HRC\nexperiment.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 01:02:31 GMT"}, {"version": "v2", "created": "Fri, 26 Jul 2019 20:57:47 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Savur", "Celal", ""], ["Kumar", "Shitij", ""], ["Sahin", "Ferat", ""]]}, {"id": "1907.10827", "submitter": "Pablo Hernandez-Leal", "authors": "Bilal Kartal, Pablo Hernandez-Leal and Matthew E. Taylor", "title": "Terminal Prediction as an Auxiliary Task for Deep Reinforcement Learning", "comments": "AAAI Conference on Artificial Intelligence and Interactive Digital\n  Entertainment (AIIDE'19). arXiv admin note: text overlap with\n  arXiv:1812.00045", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning has achieved great successes in recent years, but\nthere are still open challenges, such as convergence to locally optimal\npolicies and sample inefficiency. In this paper, we contribute a novel\nself-supervised auxiliary task, i.e., Terminal Prediction (TP), estimating\ntemporal closeness to terminal states for episodic tasks. The intuition is to\nhelp representation learning by letting the agent predict how close it is to a\nterminal state, while learning its control policy. Although TP could be\nintegrated with multiple algorithms, this paper focuses on Asynchronous\nAdvantage Actor-Critic (A3C) and demonstrating the advantages of A3C-TP. Our\nextensive evaluation includes: a set of Atari games, the BipedalWalker domain,\nand a mini version of the recently proposed multi-agent Pommerman game. Our\nresults on Atari games and the BipedalWalker domain suggest that A3C-TP\noutperforms standard A3C in most of the tested domains and in others it has\nsimilar performance. In Pommerman, our proposed method provides significant\nimprovement both in learning efficiency and converging to better policies\nagainst different opponents.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 16:26:21 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Kartal", "Bilal", ""], ["Hernandez-Leal", "Pablo", ""], ["Taylor", "Matthew E.", ""]]}, {"id": "1907.11461", "submitter": "Weixun Wang", "authors": "Weixun Wang, Tianpei Yang, Yong Liu, Jianye Hao, Xiaotian Hao, Yujing\n  Hu, Yingfeng Chen, Changjie Fan, Yang Gao", "title": "Action Semantics Network: Considering the Effects of Actions in\n  Multiagent Systems", "comments": "accepted by ICLR2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multiagent systems (MASs), each agent makes individual decisions but all\nof them contribute globally to the system evolution. Learning in MASs is\ndifficult since each agent's selection of actions must take place in the\npresence of other co-learning agents. Moreover, the environmental stochasticity\nand uncertainties increase exponentially with the increase in the number of\nagents. Previous works borrow various multiagent coordination mechanisms into\ndeep learning architecture to facilitate multiagent coordination. However, none\nof them explicitly consider action semantics between agents that different\nactions have different influences on other agents. In this paper, we propose a\nnovel network architecture, named Action Semantics Network (ASN), that\nexplicitly represents such action semantics between agents. ASN characterizes\ndifferent actions' influence on other agents using neural networks based on the\naction semantics between them. ASN can be easily combined with existing deep\nreinforcement learning (DRL) algorithms to boost their performance.\nExperimental results on StarCraft II micromanagement and Neural MMO show ASN\nsignificantly improves the performance of state-of-the-art DRL approaches\ncompared with several network architectures.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 09:51:30 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2019 04:05:11 GMT"}, {"version": "v3", "created": "Thu, 16 Jan 2020 02:08:54 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Wang", "Weixun", ""], ["Yang", "Tianpei", ""], ["Liu", "Yong", ""], ["Hao", "Jianye", ""], ["Hao", "Xiaotian", ""], ["Hu", "Yujing", ""], ["Chen", "Yingfeng", ""], ["Fan", "Changjie", ""], ["Gao", "Yang", ""]]}, {"id": "1907.11703", "submitter": "Pablo Hernandez-Leal", "authors": "Bilal Kartal, Pablo Hernandez-Leal and Matthew E. Taylor", "title": "Action Guidance with MCTS for Deep Reinforcement Learning", "comments": "AAAI Conference on Artificial Intelligence and Interactive Digital\n  Entertainment (AIIDE'19). arXiv admin note: substantial text overlap with\n  arXiv:1904.05759, arXiv:1812.00045", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning has achieved great successes in recent years,\nhowever, one main challenge is the sample inefficiency. In this paper, we focus\non how to use action guidance by means of a non-expert demonstrator to improve\nsample efficiency in a domain with sparse, delayed, and possibly deceptive\nrewards: the recently-proposed multi-agent benchmark of Pommerman. We propose a\nnew framework where even a non-expert simulated demonstrator, e.g., planning\nalgorithms such as Monte Carlo tree search with a small number rollouts, can be\nintegrated within asynchronous distributed deep reinforcement learning methods.\nCompared to a vanilla deep RL algorithm, our proposed methods both learn faster\nand converge to better policies on a two-player mini version of the Pommerman\ngame.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 19:19:42 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Kartal", "Bilal", ""], ["Hernandez-Leal", "Pablo", ""], ["Taylor", "Matthew E.", ""]]}, {"id": "1907.11852", "submitter": "Li Ma", "authors": "Li Ma, Weidong Bao, Xiaomin Zhu, Meng Wu, Yuan Wang, Yunxiang Ling,\n  and Wen Zhou", "title": "G-flocking: Flocking Model Optimization based on Genetic Framework", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Flocking model has been widely used to control robotic swarm. However, with\nthe increasing scalability, there exist complex conflicts for robotic swarm in\nautonomous navigation, brought by internal pattern maintenance, external\nenvironment changes, and target area orientation, which results in poor\nstability and adaptability. Hence, optimizing the flocking model for robotic\nswarm in autonomous navigation is an important and meaningful research domain.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jul 2019 04:50:45 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Ma", "Li", ""], ["Bao", "Weidong", ""], ["Zhu", "Xiaomin", ""], ["Wu", "Meng", ""], ["Wang", "Yuan", ""], ["Ling", "Yunxiang", ""], ["Zhou", "Wen", ""]]}, {"id": "1907.12648", "submitter": "Pavel Surynek", "authors": "Pavel Surynek, T. K. Satish Kumar, Sven Koenig", "title": "Multi-Agent Path Finding with Capacity Constraints", "comments": "arXiv admin note: substantial text overlap with arXiv:1809.05959 and\n  arXiv:1907.07631", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multi-agent path finding (MAPF) the task is to navigate agents from their\nstarting positions to given individual goals. The problem takes place in an\nundirected graph whose vertices represent positions and edges define the\ntopology. Agents can move to neighbor vertices across edges. In the standard\nMAPF, space occupation by agents is modeled by a capacity constraint that\npermits at most one agent per vertex. We suggest an extension of MAPF in this\npaper that permits more than one agent per vertex. Propositional satisfiability\n(SAT) models for these extensions of MAPF are studied. We focus on modeling\ncapacity constraints in SAT-based formulations of MAPF and evaluation of\nperformance of these models. We extend two existing SAT-based formulations with\nvertex capacity constraints: MDD-SAT and SMT-CBS where the former is an\napproach that builds the model in an eager way while the latter relies on lazy\nconstruction of the model.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jul 2019 22:41:33 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Surynek", "Pavel", ""], ["Kumar", "T. K. Satish", ""], ["Koenig", "Sven", ""]]}, {"id": "1907.13003", "submitter": "Lanlan Su", "authors": "Lanlan Su, Mengmou Li, Vijay Gupta and Graziano Chesi", "title": "Distributed Resource Allocation over Time-varying Balanced Digraphs with\n  Discrete-time Communication", "comments": "12 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.SY eess.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work is concerned with the problem of distributed resource allocation in\ncontinuous-time setting but with discrete-time communication over infinitely\njointly connected and balanced digraphs. We provide a passivity-based\nperspective for the continuous-time algorithm, based on which an intermittent\ncommunication scheme is developed. Particularly, a periodic communication\nscheme is first derived through analyzing the passivity degradation over output\nsampling of the distributed dynamics at each node. Then, an asynchronous\ndistributed event-triggered scheme is further developed. The sampled-based\nevent-triggered communication scheme is exempt from Zeno behavior as the\nminimum inter-event time is lower bounded by the sampling period. The\nparameters in the proposed algorithm rely only on local information of each\nindividual nodes, which can be designed in a truly distributed fashion\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 15:12:28 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 17:13:07 GMT"}, {"version": "v3", "created": "Fri, 15 Jan 2021 15:42:09 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Su", "Lanlan", ""], ["Li", "Mengmou", ""], ["Gupta", "Vijay", ""], ["Chesi", "Graziano", ""]]}]