[{"id": "1802.00342", "submitter": "Alexandros A. Voudouris", "authors": "Adelina Madhja, Sotiris Nikoletseas, Alexandros A. Voudouris", "title": "Adaptive wireless power transfer in mobile Ad Hoc networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the interesting impact of mobility on the problem of efficient\nwireless power transfer in ad hoc networks. We consider a set of mobile agents\n(consuming energy to perform certain sensing and communication tasks), and a\nsingle static charger (with finite energy) which can recharge the agents when\nthey get in its range. In particular, we focus on the problem of efficiently\ncomputing the appropriate range of the charger with the goal of prolonging the\nnetwork lifetime. We first demonstrate (under the realistic assumption of fixed\nenergy supplies) the limitations of any fixed charging range and, therefore,\nthe need for (and power of) a dynamic selection of the charging range, by\nadapting to the behavior of the mobile agents which is revealed in an online\nmanner. We investigate the complexity of optimizing the selection of such an\nadaptive charging range, by showing that two simplified offline optimization\nproblems (closely related to the online one) are NP-hard. To effectively\naddress the involved performance trade-offs, we finally present a variety of\nadaptive heuristics, assuming different levels of agent information regarding\ntheir mobility and energy.\n", "versions": [{"version": "v1", "created": "Thu, 1 Feb 2018 15:22:37 GMT"}, {"version": "v2", "created": "Mon, 12 Mar 2018 16:17:09 GMT"}, {"version": "v3", "created": "Wed, 8 Apr 2020 16:30:50 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Madhja", "Adelina", ""], ["Nikoletseas", "Sotiris", ""], ["Voudouris", "Alexandros A.", ""]]}, {"id": "1802.00435", "submitter": "Chathika Gunaratne", "authors": "Chathika Gunaratne, Ivan Garibay, Nguyen Dang", "title": "Evolutionary model discovery of causal factors behind the\n  socio-agricultural behavior of the ancestral Pueblo", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Agent-based modeling of artificial societies offers a platform to test\nhuman-interpretable, causal explanations of human behavior that generate\nsociety-scale phenomena. However, parameter calibration is insufficient to\nconduct an adequate data-driven exploration of the importance of causal factors\nthat constitute agent rules, resulting in models with limited causal accuracy\nand robustness. We introduce evolutionary model discovery, a framework that\ncombines genetic programming and random forest regression to evaluate the\nimportance of a set of causal factors hypothesized to affect the individual's\ndecision-making process. We investigated the farm plot seeking behavior of the\nancestral Pueblo of the Long House Valley simulated in the Artificial Anasazi\nmodel our proposed framework. We evaluated the importance of causal factors not\nconsidered in the original model that we hypothesized to have affected the\ndecision-making process. Contrary to the original model, where closeness was\nthe sole factor driving farm plot selection, selection of higher quality land\nand desire for social presence are shown to be more important. In fact, model\nperformance is improved when agents select farm plots further away from their\nfailed farm plot. Farm selection strategies designed using these insights into\nthe socio-agricultural behavior of the ancestral Pueblo significantly improved\nthe model's accuracy and robustness.\n", "versions": [{"version": "v1", "created": "Thu, 1 Feb 2018 18:58:30 GMT"}, {"version": "v2", "created": "Tue, 20 Aug 2019 03:19:24 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Gunaratne", "Chathika", ""], ["Garibay", "Ivan", ""], ["Dang", "Nguyen", ""]]}, {"id": "1802.00899", "submitter": "Sergio Valcarcel Macua", "authors": "Sergio Valcarcel Macua, Javier Zazo, Santiago Zazo", "title": "Learning Parametric Closed-Loop Policies for Markov Potential Games", "comments": "Presented at ICLR2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.GT cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiagent systems where agents interact among themselves and with a\nstochastic environment can be formalized as stochastic games. We study a\nsubclass named Markov potential games (MPGs) that appear often in economic and\nengineering applications when the agents share a common resource. We consider\nMPGs with continuous state-action variables, coupled constraints and nonconvex\nrewards. Previous analysis followed a variational approach that is only valid\nfor very simple cases (convex rewards, invertible dynamics, and no coupled\nconstraints); or considered deterministic dynamics and provided open-loop (OL)\nanalysis, studying strategies that consist in predefined action sequences,\nwhich are not optimal for stochastic environments. We present a closed-loop\n(CL) analysis for MPGs and consider parametric policies that depend on the\ncurrent state. We provide easily verifiable, sufficient and necessary\nconditions for a stochastic game to be an MPG, even for complex parametric\nfunctions (e.g., deep neural networks); and show that a closed-loop Nash\nequilibrium (NE) can be found (or at least approximated) by solving a related\noptimal control problem (OCP). This is useful since solving an OCP--which is a\nsingle-objective problem--is usually much simpler than solving the original set\nof coupled OCPs that form the game--which is a multiobjective control problem.\nThis is a considerable improvement over the previously standard approach for\nthe CL analysis of MPGs, which gives no approximate solution if no NE belongs\nto the chosen parametric family, and which is practical only for simple\nparametric forms. We illustrate the theoretical contributions with an example\nby applying our approach to a noncooperative communications engineering game.\nWe then solve the game with a deep reinforcement learning algorithm that learns\npolicies that closely approximates an exact variational NE of the game.\n", "versions": [{"version": "v1", "created": "Sat, 3 Feb 2018 02:56:54 GMT"}, {"version": "v2", "created": "Tue, 22 May 2018 11:23:55 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Macua", "Sergio Valcarcel", ""], ["Zazo", "Javier", ""], ["Zazo", "Santiago", ""]]}, {"id": "1802.00976", "submitter": "EPTCS", "authors": "Danilo Pianini (University of Bologna), Guido Salvaneschi", "title": "Proceedings First Workshop on Architectures, Languages and Paradigms for\n  IoT", "comments": null, "journal-ref": "EPTCS 264, 2018", "doi": "10.4204/EPTCS.264", "report-no": null, "categories": "cs.DC cs.MA cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The 1st workshop on Architectures, Languages and Paradigms for IoT (ALP4IoT\n2017), was held in Turin on September 19th, 2017. ALP4IoT was a satellite event\nof the 13th International Conference on integrated Formal Methods (iFM 2017).\nThe workshop aimed at critically reviewing the state-of-the-art and the\nstate-of-the-practice of formal techniques and software methods for the IoT,\npresenting open problems and challenges and triggering a discussion among the\nparticipants with different views and backgrounds. The Internet of Things is\nushering a dramatic increase in number and variety of interconnected and smart\nobjects. Communication capabilities and computational power are growingly\nembedded in everyday devices, including personal smart devices, public\ndisplays, cars, drones, and electronic tags. This state of the things opens an\nunprecedented range of research opportunities: the inherent distribution,\nmobility, situatedness, and heterogeneity of such devices call for proper\nscientific understanding of the foundations of such systems as well as for\nnovel software methods. The workshop solicited original contributions on\narchitectures, languages, paradigms, and techniques with potential practical\nand theoretical impact on software systems targeting the IoT, welcoming\ninter-disciplinary approaches.\n", "versions": [{"version": "v1", "created": "Sat, 3 Feb 2018 13:33:37 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["Pianini", "Danilo", "", "University of Bologna"], ["Salvaneschi", "Guido", ""]]}, {"id": "1802.01167", "submitter": "Vahid Yazdanpanah", "authors": "Vahid Yazdanpanah, Devrim Murat Yazan", "title": "Industrial Symbiotic Relations as Cooperative Games", "comments": "Presented at the 7th International Conference on Industrial\n  Engineering and Systems Management (IESM-2017), October 11--13, 2017,\n  Saarbr\\\"ucken, Germany", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a game-theoretical formulation for a specific\nform of collaborative industrial relations called \"Industrial Symbiotic\nRelation (ISR) games\" and provide a formal framework to model, verify, and\nsupport collaboration decisions in this new class of two-person operational\ngames. ISR games are formalized as cooperative cost-allocation games with the\naim to allocate the total ISR-related operational cost to involved industrial\nfirms in a fair and stable manner by taking into account their contribution to\nthe total traditional ISR-related cost. We tailor two types of allocation\nmechanisms using which firms can implement cost allocations that result in a\ncollaboration that satisfies the fairness and stability properties. Moreover,\nwhile industries receive a particular ISR proposal, our introduced methodology\nis applicable as a managerial decision support to systematically verify the\nquality of the ISR in question. This is achievable by analyzing if the\nimplemented allocation mechanism is a stable/fair allocation.\n", "versions": [{"version": "v1", "created": "Sun, 4 Feb 2018 17:58:45 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["Yazdanpanah", "Vahid", ""], ["Yazan", "Devrim Murat", ""]]}, {"id": "1802.01194", "submitter": "Joshua Garland", "authors": "Joshua Garland, Andrew M. Berdahl, Jie Sun and Erik Bollt", "title": "Anatomy of Leadership in Collective Behaviour", "comments": "13 pages, 3 figures", "journal-ref": null, "doi": "10.1063/1.5024395", "report-no": null, "categories": "cs.MA physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the mechanics behind the coordinated movement of mobile animal\ngroups (collective motion) provides key insights into their biology and\necology, while also yielding algorithms for bio-inspired technologies and\nautonomous systems. It is becoming increasingly clear that many mobile animal\ngroups are composed of heterogeneous individuals with differential levels and\ntypes of influence over group behaviors. The ability to infer this differential\ninfluence, or leadership, is critical to understanding group functioning in\nthese collective animal systems. Due to the broad interpretation of leadership,\nmany different measures and mathematical tools are used to describe and infer\n\"leadership\", e.g., position, causality, influence, information flow. But a key\nquestion remains: which, if any, of these concepts actually describes\nleadership? We argue that instead of asserting a single definition or notion of\nleadership, the complex interaction rules and dynamics typical of a group\nimplies that leadership itself is not merely a binary classification (leader or\nfollower), but rather, a complex combination of many different components. In\nthis paper we develop an anatomy of leadership, identify several principle\ncomponents and provide a general mathematical framework for discussing\nleadership. With the intricacies of this taxonomy in mind we present a set of\nleadership-oriented toy models that should be used as a proving ground for\nleadership inference methods going forward. We believe this multifaceted\napproach to leadership will enable a broader understanding of leadership and\nits inference from data in mobile animal groups and beyond.\n", "versions": [{"version": "v1", "created": "Sun, 4 Feb 2018 21:21:48 GMT"}, {"version": "v2", "created": "Thu, 26 Apr 2018 20:02:04 GMT"}], "update_date": "2018-08-15", "authors_parsed": [["Garland", "Joshua", ""], ["Berdahl", "Andrew M.", ""], ["Sun", "Jie", ""], ["Bollt", "Erik", ""]]}, {"id": "1802.01207", "submitter": "Bernard Chazelle", "authors": "Bernard Chazelle", "title": "A Sharp Bound on the $s$-Energy and Its Applications to Averaging\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The {\\em $s$-energy} is a generating function of wide applicability in\nnetwork-based dynamics. We derive an (essentially) optimal bound of $(3/\\rho\ns)^{n-1}$ on the $s$-energy of an $n$-agent symmetric averaging system, for any\npositive real $s\\leq 1$, where~$\\rho$ is a lower bound on the nonzero weights.\nThis is done by introducing the new dynamics of {\\em twist systems}. We show\nhow to use the new bound on the $s$-energy to tighten the convergence rate of\nsystems in opinion dynamics, flocking, and synchronization.\n", "versions": [{"version": "v1", "created": "Sun, 4 Feb 2018 22:20:12 GMT"}, {"version": "v2", "created": "Fri, 28 Dec 2018 17:34:19 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Chazelle", "Bernard", ""]]}, {"id": "1802.01208", "submitter": "Bernard Chazelle", "authors": "Bernard Chazelle", "title": "Toward a Theory of Markov Influence Systems and their Renormalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA math.PR nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the concept of a Markov influence system (MIS) and analyze its\ndynamics. An MIS models a random walk in a graph whose edges and transition\nprobabilities change endogenously as a function of the current distribution.\nThis article consists of two independent parts: in the first one, we generalize\nthe standard classification of Markov chain states to the time-varying case by\nshowing how to \"parse\" graph sequences; in the second part, we use this\nframework to carry out the bifurcation analysis of a few important MIS\nfamilies. We show that, in general, these systems can be chaotic but that\nirreducible MIS are almost always asymptotically periodic. We give an example\nof \"hyper-torpid\" mixing, where a stationary distribution is reached in\nsuper-exponential time, a timescale beyond the reach of any Markov chain.\n", "versions": [{"version": "v1", "created": "Sun, 4 Feb 2018 22:27:01 GMT"}, {"version": "v2", "created": "Thu, 28 Feb 2019 18:18:33 GMT"}, {"version": "v3", "created": "Tue, 26 Mar 2019 23:54:14 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Chazelle", "Bernard", ""]]}, {"id": "1802.01224", "submitter": "Leonardo Colombo", "authors": "Leonardo Colombo, Dimos Dimarogonas", "title": "Optimal Control of Left-Invariant Multi-Agent Systems with Asymmetric\n  Formation Constraints", "comments": "This work was supported by the Swedish Research Council (VR), Knut\n  och Alice Wallenberg foundation (KAW), the H2020 Project Co4Robots and the\n  H2020 ERC Starting Grant BUCOPHSYS. arXiv admin note: text overlap with\n  arXiv:1808.04612", "journal-ref": "2018 European Control Conference (ECC), 1728-1733", "doi": "10.23919/ECC.2018.8550238", "report-no": null, "categories": "math.OC cs.MA cs.SY eess.SY math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we study an optimal control problem for a multi-agent system\nmodeled by an undirected formation graph with nodes describing the kinematics\nof each agent, given by a left-invariant control system on a Lie group. The\nagents should avoid collision between them in the workspace. Such a task is\ndone by introducing some potential functions into the cost function for the\noptimal control problem, corresponding to fictitious forces, induced by the\nformation constraint among agents, that break the symmetry of the individual\nagents and the cost functions, and rendering the optimal control problem\npartially invariant by a Lie group of symmetries. Reduced necessary conditions\nfor the existence of normal extremals are obtained using techniques of\nvariational calculus on manifolds. As an application, we study an optimal\ncontrol problem for multiple unicycles.\n", "versions": [{"version": "v1", "created": "Mon, 5 Feb 2018 00:39:57 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2020 16:45:59 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Colombo", "Leonardo", ""], ["Dimarogonas", "Dimos", ""]]}, {"id": "1802.01730", "submitter": "Flavio L. Pinheiro", "authors": "Fl\\'avio L. Pinheiro and Fernando P. Santos", "title": "Local Wealth Redistribution Promotes Cooperation in Multiagent Systems", "comments": "9 pages, 8 figures, AAMAS2018 Conference Proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.GT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Designing mechanisms that leverage cooperation between agents has been a\nlong-lasting goal in Multiagent Systems. The task is especially challenging\nwhen agents are selfish, lack common goals and face social dilemmas, i.e.,\nsituations in which individual interest conflicts with social welfare. Past\nworks explored mechanisms that explain cooperation in biological and social\nsystems, providing important clues for the aim of designing cooperative\nartificial societies. In particular, several works show that cooperation is\nable to emerge when specific network structures underlie agents' interactions.\nNotwithstanding, social dilemmas in which defection is highly tempting still\npose challenges concerning the effective sustainability of cooperation. Here we\npropose a new redistribution mechanism that can be applied in structured\npopulations of agents. Importantly, we show that, when implemented locally\n(i.e., agents share a fraction of their wealth surplus with their nearest\nneighbors), redistribution excels in promoting cooperation under regimes where,\nbefore, only defection prevailed.\n", "versions": [{"version": "v1", "created": "Mon, 5 Feb 2018 23:30:55 GMT"}], "update_date": "2018-02-07", "authors_parsed": [["Pinheiro", "Fl\u00e1vio L.", ""], ["Santos", "Fernando P.", ""]]}, {"id": "1802.02218", "submitter": "Tin Leelavimolsilp", "authors": "Tin Leelavimolsilp, Long Tran-Thanh, Sebastian Stein", "title": "On the Preliminary Investigation of Selfish Mining Strategy with\n  Multiple Selfish Miners", "comments": "20 pages, 26 figures, currently under peer-review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.CR cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Eyal and Sirer's selfish mining strategy has demonstrated that Bitcoin system\nis not secure even if 50% of total mining power is held by altruistic miners.\nSince then, researchers have been investigating either to improve the\nefficiency of selfish mining, or how to defend against it, typically in a\nsingle selfish miner setting. Yet there is no research on a selfish mining\nstrategies concurrently used by multiple miners in the system. The\neffectiveness of such selfish mining strategies and their required mining power\nunder such multiple selfish miners setting remains unknown.\n  In this paper, a preliminary investigation and our findings of selfish mining\nstrategy used by multiple miners are reported. In addition, the conventional\nmodel of Bitcoin system is slightly redesigned to tackle its shortcoming:\nnamely, a concurrency of individual mining processes. Although a theoretical\nanalysis of selfish mining strategy under this setting is yet to be\nestablished, the current findings based on simulations is promising and of\ngreat interest. In particular, our work shows that a lower bound of power\nthreshold required for selfish mining strategy decreases in proportion to a\nnumber of selfish miners. Moreover, there exist Nash equilibria where all\nselfish miners in the system do not change to an honest mining strategy and\nsimultaneously earn their unfair amount of mining reward given that they\nequally possess sufficiently large mining power. Lastly, our new model yields a\npower threshold for mounting selfish mining strategy slightly greater than one\nfrom the conventional model.\n", "versions": [{"version": "v1", "created": "Tue, 6 Feb 2018 20:56:51 GMT"}], "update_date": "2018-02-08", "authors_parsed": [["Leelavimolsilp", "Tin", ""], ["Tran-Thanh", "Long", ""], ["Stein", "Sebastian", ""]]}, {"id": "1802.02277", "submitter": "Mohammadhosein Hasanbeig", "authors": "Mohammadhosein Hasanbeig, Lacra Pavel", "title": "From Game-theoretic Multi-agent Log Linear Learning to Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main focus of this paper is on enhancement of two types of game-theoretic\nlearning algorithms: log-linear learning and reinforcement learning. The\nstandard analysis of log-linear learning needs a highly structured environment,\ni.e. strong assumptions about the game from an implementation perspective. In\nthis paper, we introduce a variant of log-linear learning that provides\nasymptotic guarantees while relaxing the structural assumptions to include\nsynchronous updates and limitations in information available to the players. On\nthe other hand, model-free reinforcement learning is able to perform even under\nweaker assumptions on players' knowledge about the environment and other\nplayers' strategies. We propose a reinforcement algorithm that uses a\ndouble-aggregation scheme in order to deepen players' insight about the\nenvironment and constant learning step-size which achieves a higher convergence\nrate. Numerical experiments are conducted to verify each algorithm's robustness\nand performance.\n", "versions": [{"version": "v1", "created": "Wed, 7 Feb 2018 01:22:13 GMT"}, {"version": "v2", "created": "Tue, 18 Sep 2018 15:10:20 GMT"}], "update_date": "2018-09-19", "authors_parsed": [["Hasanbeig", "Mohammadhosein", ""], ["Pavel", "Lacra", ""]]}, {"id": "1802.03435", "submitter": "Leonardo Stella", "authors": "Leonardo Stella and Dario Bauso", "title": "Mean-field Games for Bio-inspired Collective Decision-making in\n  Dynamical Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a large number of homogeneous players that are distributed across three\npossible states, we consider the problem in which these players have to control\ntheir transition rates, while minimizing a cost. The optimal transition rates\nare based on the players' knowledge of their current state and of the\ndistribution of all the other players, and this introduces mean-field terms in\nthe running and the terminal cost. The first contribution involves a mean-field\ngame model that brings together macroscopic and microscopic dynamics. We obtain\nthe mean-field equilibrium associated with this model, by solving the\ncorresponding initial-terminal value problem. We perform an asymptotic analysis\nto obtain a stationary equilibrium for the system. The second contribution\ninvolves the study of the microscopic dynamics of the system for a finite\nnumber of players that interact in a structured environment modeled by an\ninteraction topology. The third contribution is the specialization of the model\nto describe honeybee swarms, virus propagation, and cascading failures in\ninterconnected smart-grids. A numerical analysis is conducted which involves\ntwo types of cyber-attacks. We simulate in which ways failures propagate across\nthe interconnected smart grids and the impact on the grids frequencies. We\nreframe our analysis within the context of Lyapunov's linearisation method and\nstability theory of nonlinear systems and Kuramoto coupled oscillators model.\n", "versions": [{"version": "v1", "created": "Fri, 9 Feb 2018 20:01:21 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Stella", "Leonardo", ""], ["Bauso", "Dario", ""]]}, {"id": "1802.03858", "submitter": "Nathalia Moraes do Nascimento", "authors": "Nathalia Nascimento, Paulo Alencar, Carlos Lucena and Donald Cowan", "title": "Machine Learning-based Variability Handling in IoT Agents", "comments": "8 pages, 6 figures, submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Agent-based IoT applications have recently been proposed in several domains,\nsuch as health care, smart cities and agriculture. Deploying these applications\nin specific settings has been very challenging for many reasons including the\ncomplex static and dynamic variability of the physical devices such as sensors\nand actuators, the software application behavior and the environment in which\nthe application is embedded. In this paper, we propose a self-configurable IoT\nagent approach based on feedback-evaluative machine-learning. The approach\ninvolves: i) a variability model of IoT agents; ii) generation of sets of\ncustomized agents; iii) feedback evaluative machine learning; iv) modeling and\ncomposition of a group of IoT agents; and v) a feature-selection method based\non manual and automatic feedback.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 01:31:18 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Nascimento", "Nathalia", ""], ["Alencar", "Paulo", ""], ["Lucena", "Carlos", ""], ["Cowan", "Donald", ""]]}, {"id": "1802.04112", "submitter": "Swaminathan Gopalswamy", "authors": "Swaminathan Gopalswamy, Sivakumar Rathinam", "title": "Infrastructure Enabled Autonomy: A Distributed Intelligence Architecture\n  for Autonomous Vehicles", "comments": "submitted to the IEEE Intelligent Vehicles Symposium 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DC cs.MA cs.RO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Multiple studies have illustrated the potential for dramatic societal,\nenvironmental and economic benefits from significant penetration of autonomous\ndriving. However, all the current approaches to autonomous driving require the\nautomotive manufacturers to shoulder the primary responsibility and liability\nassociated with replacing human perception and decision making with automation,\npotentially slowing the penetration of autonomous vehicles, and consequently\nslowing the realization of the societal benefits of autonomous vehicles. We\npropose here a new approach to autonomous driving that will re-balance the\nresponsibility and liabilities associated with autonomous driving between\ntraditional automotive manufacturers, infrastructure players, and third-party\nplayers. Our proposed distributed intelligence architecture leverages the\nsignificant advancements in connectivity and edge computing in the recent\ndecades to partition the driving functions between the vehicle, edge computers\non the road side, and specialized third-party computers that reside in the\nvehicle. Infrastructure becomes a critical enabler for autonomy. With this\nInfrastructure Enabled Autonomy (IEA) concept, the traditional automotive\nmanufacturers will only need to shoulder responsibility and liability\ncomparable to what they already do today, and the infrastructure and\nthird-party players will share the added responsibility and liabilities\nassociated with autonomous functionalities. We propose a Bayesian Network Model\nbased framework for assessing the risk benefits of such a distributed\nintelligence architecture. An additional benefit of the proposed architecture\nis that it enables \"autonomy as a service\" while still allowing for private\nownership of automobiles.\n", "versions": [{"version": "v1", "created": "Mon, 5 Feb 2018 23:33:53 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Gopalswamy", "Swaminathan", ""], ["Rathinam", "Sivakumar", ""]]}, {"id": "1802.05438", "submitter": "Yaodong Yang Mr.", "authors": "Yaodong Yang, Rui Luo, Minne Li, Ming Zhou, Weinan Zhang, Jun Wang", "title": "Mean Field Multi-Agent Reinforcement Learning", "comments": "ICML 2018 (Full paper + Long talk)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing multi-agent reinforcement learning methods are limited typically to\na small number of agents. When the agent number increases largely, the learning\nbecomes intractable due to the curse of the dimensionality and the exponential\ngrowth of agent interactions. In this paper, we present \\emph{Mean Field\nReinforcement Learning} where the interactions within the population of agents\nare approximated by those between a single agent and the average effect from\nthe overall population or neighboring agents; the interplay between the two\nentities is mutually reinforced: the learning of the individual agent's optimal\npolicy depends on the dynamics of the population, while the dynamics of the\npopulation change according to the collective patterns of the individual\npolicies. We develop practical mean field Q-learning and mean field\nActor-Critic algorithms and analyze the convergence of the solution to Nash\nequilibrium. Experiments on Gaussian squeeze, Ising model, and battle games\njustify the learning effectiveness of our mean field approaches. In addition,\nwe report the first result to solve the Ising model via model-free\nreinforcement learning methods.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 09:07:57 GMT"}, {"version": "v2", "created": "Fri, 8 Jun 2018 16:26:20 GMT"}, {"version": "v3", "created": "Tue, 12 Jun 2018 07:19:04 GMT"}, {"version": "v4", "created": "Thu, 19 Jul 2018 22:15:36 GMT"}, {"version": "v5", "created": "Tue, 15 Dec 2020 11:26:04 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Yang", "Yaodong", ""], ["Luo", "Rui", ""], ["Li", "Minne", ""], ["Zhou", "Ming", ""], ["Zhang", "Weinan", ""], ["Wang", "Jun", ""]]}, {"id": "1802.05642", "submitter": "David Balduzzi", "authors": "David Balduzzi, Sebastien Racaniere, James Martens, Jakob Foerster,\n  Karl Tuyls, Thore Graepel", "title": "The Mechanics of n-Player Differentiable Games", "comments": "ICML 2018, final version", "journal-ref": "PMLR volume 80, 2018", "doi": null, "report-no": null, "categories": "cs.LG cs.GT cs.MA cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The cornerstone underpinning deep learning is the guarantee that gradient\ndescent on an objective converges to local minima. Unfortunately, this\nguarantee fails in settings, such as generative adversarial nets, where there\nare multiple interacting losses. The behavior of gradient-based methods in\ngames is not well understood -- and is becoming increasingly important as\nadversarial and multi-objective architectures proliferate. In this paper, we\ndevelop new techniques to understand and control the dynamics in general games.\nThe key result is to decompose the second-order dynamics into two components.\nThe first is related to potential games, which reduce to gradient descent on an\nimplicit function; the second relates to Hamiltonian games, a new class of\ngames that obey a conservation law, akin to conservation laws in classical\nmechanical systems. The decomposition motivates Symplectic Gradient Adjustment\n(SGA), a new algorithm for finding stable fixed points in general games. Basic\nexperiments show SGA is competitive with recently proposed algorithms for\nfinding stable fixed points in GANs -- whilst at the same time being applicable\nto -- and having guarantees in -- much more general games.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 16:32:48 GMT"}, {"version": "v2", "created": "Wed, 6 Jun 2018 13:26:15 GMT"}], "update_date": "2018-06-07", "authors_parsed": [["Balduzzi", "David", ""], ["Racaniere", "Sebastien", ""], ["Martens", "James", ""], ["Foerster", "Jakob", ""], ["Tuyls", "Karl", ""], ["Graepel", "Thore", ""]]}, {"id": "1802.06108", "submitter": "Ismael Tito Freire Gonz\\'alez", "authors": "Ismael T. Freire, Clement Moulin-Frier, Marti Sanchez-Fibla, Xerxes D.\n  Arsiwalla, Paul Verschure", "title": "Modeling the Formation of Social Conventions from Embodied Real-Time\n  Interactions", "comments": "16 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.GT q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What is the role of real-time control and learning in the formation of social\nconventions? To answer this question, we propose a computational model that\nmatches human behavioral data in a social decision-making game that was\nanalyzed both in discrete-time and continuous-time setups. Furthermore, unlike\nprevious approaches, our model takes into account the role of sensorimotor\ncontrol loops in embodied decision-making scenarios. For this purpose, we\nintroduce the Control-based Reinforcement Learning (CRL) model. CRL is grounded\nin the Distributed Adaptive Control (DAC) theory of mind and brain, where\nlow-level sensorimotor control is modulated through perceptual and behavioral\nlearning in a layered structure. CRL follows these principles by implementing a\nfeedback control loop handling the agent's reactive behaviors (pre-wired\nreflexes), along with an adaptive layer that uses reinforcement learning to\nmaximize long-term reward. We test our model in a multi-agent game-theoretic\ntask in which coordination must be achieved to find an optimal solution. We\nshow that CRL is able to reach human-level performance on standard\ngame-theoretic metrics such as efficiency in acquiring rewards and fairness in\nreward distribution.\n", "versions": [{"version": "v1", "created": "Fri, 16 Feb 2018 20:22:41 GMT"}, {"version": "v2", "created": "Tue, 28 May 2019 16:59:56 GMT"}, {"version": "v3", "created": "Tue, 31 Dec 2019 20:08:44 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Freire", "Ismael T.", ""], ["Moulin-Frier", "Clement", ""], ["Sanchez-Fibla", "Marti", ""], ["Arsiwalla", "Xerxes D.", ""], ["Verschure", "Paul", ""]]}, {"id": "1802.06220", "submitter": "Murat Uney Dr", "authors": "Murat \\\"Uney, J\\'er\\'emie Houssineau, Emmanuel Delande, Simon J.\n  Julier, Daniel E. Clark", "title": "Fusion of finite set distributions: Pointwise consistency and global\n  cardinality", "comments": "accepted for publication in the IEEE Transactions on Aerospace and\n  Electronics Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.MA cs.SY math.IT", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  A recent trend in distributed multi-sensor fusion is to use random finite set\nfilters at the sensor nodes and fuse the filtered distributions algorithmically\nusing their exponential mixture densities (EMDs). Fusion algorithms which\nextend the celebrated covariance intersection and consensus based approaches\nare such examples. In this article, we analyse the variational principle\nunderlying EMDs and show that the EMDs of finite set distributions do not\nnecessarily lead to consistent fusion of cardinality distributions. Indeed, we\ndemonstrate that these inconsistencies may occur with overwhelming probability\nin practice, through examples with Bernoulli, Poisson and independent\nidentically distributed (IID) cluster processes. We prove that pointwise\nconsistency of EMDs does not imply consistency in global cardinality and vice\nversa. Then, we redefine the variational problems underlying fusion and provide\niterative solutions thereby establishing a framework that guarantees\ncardinality consistent fusion.\n", "versions": [{"version": "v1", "created": "Sat, 17 Feb 2018 10:46:23 GMT"}, {"version": "v2", "created": "Mon, 3 Dec 2018 22:25:41 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["\u00dcney", "Murat", ""], ["Houssineau", "J\u00e9r\u00e9mie", ""], ["Delande", "Emmanuel", ""], ["Julier", "Simon J.", ""], ["Clark", "Daniel E.", ""]]}, {"id": "1802.06444", "submitter": "Kaixiang Lin", "authors": "Kaixiang Lin, Renyu Zhao, Zhe Xu and Jiayu Zhou", "title": "Efficient Collaborative Multi-Agent Deep Reinforcement Learning for\n  Large-Scale Fleet Management", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale online ride-sharing platforms have substantially transformed our\nlives by reallocating transportation resources to alleviate traffic congestion\nand promote transportation efficiency. An efficient fleet management strategy\nnot only can significantly improve the utilization of transportation resources\nbut also increase the revenue and customer satisfaction. It is a challenging\ntask to design an effective fleet management strategy that can adapt to an\nenvironment involving complex dynamics between demand and supply. Existing\nstudies usually work on a simplified problem setting that can hardly capture\nthe complicated stochastic demand-supply variations in high-dimensional space.\nIn this paper we propose to tackle the large-scale fleet management problem\nusing reinforcement learning, and propose a contextual multi-agent\nreinforcement learning framework including three concrete algorithms to achieve\ncoordination among a large number of agents adaptive to different contexts. We\nshow significant improvements of the proposed framework over state-of-the-art\napproaches through extensive empirical studies.\n", "versions": [{"version": "v1", "created": "Sun, 18 Feb 2018 21:06:19 GMT"}, {"version": "v2", "created": "Thu, 1 Nov 2018 17:07:18 GMT"}, {"version": "v3", "created": "Mon, 2 Dec 2019 01:35:56 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Lin", "Kaixiang", ""], ["Zhao", "Renyu", ""], ["Xu", "Zhe", ""], ["Zhou", "Jiayu", ""]]}, {"id": "1802.07187", "submitter": "Sajad Mousavi", "authors": "Sajad Mousavi, Fatemeh Afghah, Jonathan D. Ashdown and Kurt Turck", "title": "Leader-follower based Coalition Formation in Large-scale UAV Networks, A\n  Quantum Evolutionary Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of decentralized multiple Point of Interests (PoIs) detection and\nassociated task completion in an unknown environment with multiple\nresource-constrained and self-interested Unmanned Aerial Vehicles (UAVs) is\nstudied. The UAVs form several coalitions to efficiently complete the compound\ntasks which are impossible to be performed individually. The objectives of such\ncoalition formation are to firstly minimize resource consumption in completing\nthe encountered tasks on time, secondly to enhance the reliability of the\ncoalitions, and lastly in segregating the most trusted UAVs amid the self\ninterested of them. As many previous publications have merely focused on\nminimizing costs, this study considers a multi-objective optimization coalition\nformation problem that considers the three aforementioned objectives. In doing\nso, a leader-follower- inspired coalition formation algorithm amalgamating the\nthree objectives to address the problem of the computational complexity of\ncoalition formation in large-scale UAV networks is proposed. This algorithm\nattempts to form the coalitions with minimally exceeding the required resources\nfor the encountered tasks while maximizing the number of completed tasks. The\nproposed algorithm is based on Quantum Evolutionary Algorithms(QEA) which are a\ncombination of quantum computing and evolutionary algorithms. Results from\nsimulations show that the proposed algorithm significantly outperforms the\nexisting coalition formation algorithms such as merge-and-split and a famous\nmulti-objective genetic algorithm called NSGA-II.\n", "versions": [{"version": "v1", "created": "Sun, 18 Feb 2018 04:05:41 GMT"}], "update_date": "2018-02-21", "authors_parsed": [["Mousavi", "Sajad", ""], ["Afghah", "Fatemeh", ""], ["Ashdown", "Jonathan D.", ""], ["Turck", "Kurt", ""]]}, {"id": "1802.07280", "submitter": "Joseph Shaheen", "authors": "Joseph A.E. Shaheen", "title": "Simulating the Ridesharing Economy: The Individual Agent\n  Metro-Washington Area Ridesharing Model", "comments": "28 pages. Please cite as Shaheen, J. A. E., Simulating the\n  Ride-sharing Economy: The Individual Agent Metro-Washington Area Ride-sharing\n  Model, Complex Adaptive Systems: Views from the Physical, Natural, and Social\n  Sciences, 2018. forthcoming", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ridesharing economy is experiencing rapid growth and innovation.\nCompanies such as Uber and Lyft are continuing to grow at a considerable pace\nwhile providing their platform as an organizing medium for ridesharing\nservices, increasing consumer utility as well as employing thousands in\npart-time positions. However, many challenges remain in the modeling of\nridesharing services, many of which are not currently under wide consideration.\nIn this paper, an agent-based model is developed to simulate a ridesharing\nservice in the Washington D.C. metropolitan region. The model is used to\nexamine levels of utility gained for both riders (customers) and drivers\n(service providers) of a generic ridesharing service. A description of the\nIndividual Agent Metro-Washington Area Ridesharing Model (IAMWARM) is provided,\nas well as a description of a typical simulation run. We investigate the\nfinancial gains of drivers for a 24-hour period under two scenarios and two\nspatial movement behaviors. The two spatial behaviors were random movement and\nVoronoi movement, which we describe. Both movement behaviors were tested under\na stationary run conditions scenario and a variable run conditions scenario. We\nfind that Voronoi movement increased drivers' utility gained but that emergence\nof this system property was only viable under variable scenario conditions.\nThis result provides two important insights: The first is that driver movement\ndecisions prior to passenger pickup can impact financial gain for the service\nand drivers, and consequently, rate of successful pickup for riders. The second\nis that this phenomenon is only evident under experimentation conditions where\nvariability in passenger and driver arrival rates are administered.\n", "versions": [{"version": "v1", "created": "Mon, 19 Feb 2018 01:58:28 GMT"}], "update_date": "2018-02-22", "authors_parsed": [["Shaheen", "Joseph A. E.", ""]]}, {"id": "1802.07292", "submitter": "Massimo Stella", "authors": "Massimo Stella, Emilio Ferrara and Manlio De Domenico", "title": "Bots increase exposure to negative and inflammatory content in online\n  social systems", "comments": "8 pages, 5 figures", "journal-ref": "PNAS 115 (49) 12435-12440 (2018)", "doi": "10.1073/pnas.1803470115", "report-no": null, "categories": "physics.soc-ph cs.CY cs.HC cs.MA cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Societies are complex systems which tend to polarize into sub-groups of\nindividuals with dramatically opposite perspectives. This phenomenon is\nreflected -- and often amplified -- in online social networks where, however,\nhumans are no more the only players, and co-exist alongside with social bots,\ni.e., software-controlled accounts. Analyzing large-scale social data collected\nduring the Catalan referendum for independence on October 1, 2017, consisting\nof nearly 4 millions Twitter posts generated by almost 1 million users, we\nidentify the two polarized groups of Independentists and Constitutionalists and\nquantify the structural and emotional roles played by social bots. We show that\nbots act from peripheral areas of the social system to target influential\nhumans of both groups, bombarding Independentists with violent contents,\nincreasing their exposure to negative and inflammatory narratives and\nexacerbating social conflict online. Our findings stress the importance of\ndeveloping countermeasures to unmask these forms of automated social\nmanipulation.\n", "versions": [{"version": "v1", "created": "Tue, 20 Feb 2018 19:17:19 GMT"}, {"version": "v2", "created": "Thu, 28 Feb 2019 09:05:00 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Stella", "Massimo", ""], ["Ferrara", "Emilio", ""], ["De Domenico", "Manlio", ""]]}, {"id": "1802.07834", "submitter": "El Mahdi El Mhamdi", "authors": "El Mahdi El Mhamdi, Rachid Guerraoui, Alexandre Maurer, Vladislav\n  Tempez", "title": "Learning to Gather without Communication", "comments": "Preliminary version, presented at the 5th Biological Distributed\n  Algorithms Workshop. Washington D.C, July 28th, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE cs.DC cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A standard belief on emerging collective behavior is that it emerges from\nsimple individual rules. Most of the mathematical research on such collective\nbehavior starts from imperative individual rules, like always go to the center.\nBut how could an (optimal) individual rule emerge during a short period within\nthe group lifetime, especially if communication is not available. We argue that\nsuch rules can actually emerge in a group in a short span of time via\ncollective (multi-agent) reinforcement learning, i.e learning via rewards and\npunishments. We consider the gathering problem: several agents (social animals,\nswarming robots...) must gather around a same position, which is not determined\nin advance. They must do so without communication on their planned decision,\njust by looking at the position of other agents. We present the first\nexperimental evidence that a gathering behavior can be learned without\ncommunication in a partially observable environment. The learned behavior has\nthe same properties as a self-stabilizing distributed algorithm, as processes\ncan gather from any initial state (and thus tolerate any transient failure).\nBesides, we show that it is possible to tolerate the brutal loss of up to 90\\%\nof agents without significant impact on the behavior.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 22:26:21 GMT"}], "update_date": "2018-02-23", "authors_parsed": [["Mhamdi", "El Mahdi El", ""], ["Guerraoui", "Rachid", ""], ["Maurer", "Alexandre", ""], ["Tempez", "Vladislav", ""]]}, {"id": "1802.08020", "submitter": "Daan Bloembergen", "authors": "Daan Bloembergen, Davide Grossi, Martin Lackner", "title": "On Rational Delegations in Liquid Democracy", "comments": "17 pages, 3 figures. This paper (without Appendix) appears in the\n  proceedings of AAAI'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Liquid democracy is a proxy voting method where proxies are delegable. We\npropose and study a game-theoretic model of liquid democracy to address the\nfollowing question: when is it rational for a voter to delegate her vote? We\nstudy the existence of pure-strategy Nash equilibria in this model, and how\ngroup accuracy is affected by them. We complement these theoretical results by\nmeans of agent-based simulations to study the effects of delegations on group's\naccuracy on variously structured social networks.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 12:56:13 GMT"}, {"version": "v2", "created": "Thu, 15 Mar 2018 08:31:14 GMT"}, {"version": "v3", "created": "Tue, 10 Apr 2018 21:41:52 GMT"}, {"version": "v4", "created": "Tue, 20 Nov 2018 12:55:09 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Bloembergen", "Daan", ""], ["Grossi", "Davide", ""], ["Lackner", "Martin", ""]]}, {"id": "1802.08376", "submitter": "Vasileios Tzoumas", "authors": "Vasileios Tzoumas, Luca Carlone, George J. Pappas, Ali Jadbabaie", "title": "LQG Control and Sensing Co-Design", "comments": "Accepted to IEEE TAC. Includes contributions to submodular function\n  optimization literature, and extends conference paper arXiv:1709.08826", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.MA cs.RO cs.SY eess.SY math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate a Linear-Quadratic-Gaussian (LQG) control and sensing\nco-design problem, where one jointly designs sensing and control policies. We\nfocus on the realistic case where the sensing design is selected among a finite\nset of available sensors, where each sensor is associated with a different cost\n(e.g., power consumption). We consider two dual problem instances:\nsensing-constrained LQG control, where one maximizes control performance\nsubject to a sensor cost budget, and minimum-sensing LQG control, where one\nminimizes sensor cost subject to performance constraints. We prove no\npolynomial time algorithm guarantees across all problem instances a constant\napproximation factor from the optimal. Nonetheless, we present the first\npolynomial time algorithms with per-instance suboptimality guarantees. To this\nend, we leverage a separation principle, that partially decouples the design of\nsensing and control. Then, we frame LQG co-design as the optimization of\napproximately supermodular set functions; we develop novel algorithms to solve\nthe problems; and we prove original results on the performance of the\nalgorithms, and establish connections between their suboptimality and\ncontrol-theoretic quantities. We conclude the paper by discussing two\napplications, namely, sensing-constrained formation control and\nresource-constrained robot navigation.\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 03:45:21 GMT"}, {"version": "v2", "created": "Wed, 21 Mar 2018 14:13:52 GMT"}, {"version": "v3", "created": "Mon, 21 May 2018 16:37:38 GMT"}, {"version": "v4", "created": "Thu, 5 Jul 2018 17:38:07 GMT"}, {"version": "v5", "created": "Mon, 2 Sep 2019 21:24:53 GMT"}, {"version": "v6", "created": "Sat, 14 Dec 2019 16:27:40 GMT"}, {"version": "v7", "created": "Tue, 19 May 2020 16:48:07 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Tzoumas", "Vasileios", ""], ["Carlone", "Luca", ""], ["Pappas", "George J.", ""], ["Jadbabaie", "Ali", ""]]}, {"id": "1802.08534", "submitter": "Yan Zheng", "authors": "Yan Zheng, Jianye Hao, Zongzhang Zhang", "title": "Weighted Double Deep Multiagent Reinforcement Learning in Stochastic\n  Cooperative Environments", "comments": "8 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, multiagent deep reinforcement learning (DRL) has received\nincreasingly wide attention. Existing multiagent DRL algorithms are inefficient\nwhen facing with the non-stationarity due to agents update their policies\nsimultaneously in stochastic cooperative environments. This paper extends the\nrecently proposed weighted double estimator to the multiagent domain and\npropose a multiagent DRL framework, named weighted double deep Q-network\n(WDDQN). By utilizing the weighted double estimator and the deep neural\nnetwork, WDDQN can not only reduce the bias effectively but also be extended to\nscenarios with raw visual inputs. To achieve efficient cooperation in the\nmultiagent domain, we introduce the lenient reward network and the scheduled\nreplay strategy. Experiments show that the WDDQN outperforms the existing DRL\nand multiaent DRL algorithms, i.e., double DQN and lenient Q-learning, in terms\nof the average reward and the convergence rate in stochastic cooperative\nenvironments.\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 14:03:22 GMT"}, {"version": "v2", "created": "Sat, 14 Apr 2018 16:34:29 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Zheng", "Yan", ""], ["Hao", "Jianye", ""], ["Zhang", "Zongzhang", ""]]}, {"id": "1802.08757", "submitter": "Kaiqing Zhang", "authors": "Kaiqing Zhang, Zhuoran Yang, Han Liu, Tong Zhang, and Tamer Ba\\c{s}ar", "title": "Fully Decentralized Multi-Agent Reinforcement Learning with Networked\n  Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of \\emph{fully decentralized} multi-agent\nreinforcement learning (MARL), where the agents are located at the nodes of a\ntime-varying communication network. Specifically, we assume that the reward\nfunctions of the agents might correspond to different tasks, and are only known\nto the corresponding agent. Moreover, each agent makes individual decisions\nbased on both the information observed locally and the messages received from\nits neighbors over the network. Within this setting, the collective goal of the\nagents is to maximize the globally averaged return over the network through\nexchanging information with their neighbors. To this end, we propose two\ndecentralized actor-critic algorithms with function approximation, which are\napplicable to large-scale MARL problems where both the number of states and the\nnumber of agents are massively large. Under the decentralized structure, the\nactor step is performed individually by each agent with no need to infer the\npolicies of others. For the critic step, we propose a consensus update via\ncommunication over the network. Our algorithms are fully incremental and can be\nimplemented in an online fashion. Convergence analyses of the algorithms are\nprovided when the value functions are approximated within the class of linear\nfunctions. Extensive simulation results with both linear and nonlinear function\napproximations are presented to validate the proposed algorithms. Our work\nappears to be the first study of fully decentralized MARL algorithms for\nnetworked agents with function approximation, with provable convergence\nguarantees.\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 22:53:32 GMT"}, {"version": "v2", "created": "Tue, 27 Feb 2018 02:15:35 GMT"}], "update_date": "2018-02-28", "authors_parsed": [["Zhang", "Kaiqing", ""], ["Yang", "Zhuoran", ""], ["Liu", "Han", ""], ["Zhang", "Tong", ""], ["Ba\u015far", "Tamer", ""]]}, {"id": "1802.08995", "submitter": "Gabriel Arpino", "authors": "Gabriel Arpino, Kyle Morris, Sasanka Nagavalli, Katia Sycara", "title": "Using Information Invariants to Compare Swarm Algorithms and General\n  Multi-Robot Algorithms: A Technical Report", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.IT cs.MA math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robotic swarms are decentralized multi-robot systems whose members use local\ninformation from proximal neighbors to execute simple reactive control laws\nthat result in emergent collective behaviors. In contrast, members of a general\nmulti-robot system may have access to global information, all- to-all\ncommunication or sophisticated deliberative collabora- tion. Some algorithms in\nthe literature are applicable to robotic swarms. Others require the extra\ncomplexity of general multi- robot systems. Given an application domain, a\nsystem designer or supervisory operator must choose an appropriate system or\nalgorithm respectively that will enable them to achieve their goals while\nsatisfying mission constraints (e.g. bandwidth, energy, time limits). In this\npaper, we compare representative swarm and general multi-robot algorithms in\ntwo application domains - navigation and dynamic area coverage - with respect\nto several metrics (e.g. completion time, distance trav- elled). Our objective\nis to characterize each class of algorithms to inform offline system design\ndecisions by engineers or online algorithm selection decisions by supervisory\noperators. Our contributions are (a) an empirical performance comparison of\nrepresentative swarm and general multi-robot algorithms in two application\ndomains, (b) a comparative analysis of the algorithms based on the theory of\ninformation invariants, which provides a theoretical characterization supported\nby our empirical results.\n", "versions": [{"version": "v1", "created": "Sun, 25 Feb 2018 12:22:18 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Arpino", "Gabriel", ""], ["Morris", "Kyle", ""], ["Nagavalli", "Sasanka", ""], ["Sycara", "Katia", ""]]}, {"id": "1802.09317", "submitter": "Eric Sanchis", "authors": "Eric Sanchis", "title": "A Model of Free Will for Artificial Entities", "comments": "10th International Conference on Advanced Cognitive Technologies and\n  Applications, (COGNITIVE 2018), February 18-22, Barcelona, Spain", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The impression of free will is the feeling according to which our choices are\nneither imposed from our inside nor from outside. It is the sense we are the\nultimate cause of our acts. In direct opposition with the universal\ndeterminism, the existence of free will continues to be discussed. In this\npaper, free will is linked to a decisional mechanism: an agent is provided with\nfree will if having performed a predictable choice Cp, it can immediately\nperform another choice Cr in a random way. The intangible feeling of free will\nis replaced by a decision-making process including a predictable\ndecision-making process immediately followed by an unpredictable decisional\none.\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2018 14:29:03 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Sanchis", "Eric", ""]]}, {"id": "1802.09490", "submitter": "Ashish Hota", "authors": "Ashish R. Hota, Shreyas Sundaram", "title": "Controlling Human Utilization of Failure-Prone Systems via Taxes", "comments": null, "journal-ref": "IEEE Transactions on Automatic Control, 2020", "doi": "10.1109/TAC.2020.3042481", "report-no": null, "categories": "cs.GT cs.MA cs.SY math.OC q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a game-theoretic model where individuals compete over a shared\nfailure-prone system or resource. We investigate the effectiveness of a\ntaxation mechanism in controlling the utilization of the resource at the Nash\nequilibrium when the decision-makers have behavioral risk preferences, captured\nby prospect theory. We first observe that heterogeneous prospect-theoretic risk\npreferences can lead to counter-intuitive outcomes. In particular, for\nresources that exhibit network effects, utilization can increase under taxation\nand there may not exist a tax rate that achieves the socially optimal level of\nutilization. We identify conditions under which utilization is monotone and\ncontinuous, and then characterize the range of utilizations that can be\nachieved by a suitable choice of tax rate. We further show that resource\nutilization is higher when players are charged differentiated tax rates\ncompared to the case when all players are charged an identical tax rate, under\nsuitable assumptions.\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2018 18:13:47 GMT"}, {"version": "v2", "created": "Tue, 7 Apr 2020 07:04:46 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Hota", "Ashish R.", ""], ["Sundaram", "Shreyas", ""]]}, {"id": "1802.09647", "submitter": "Jiangjun Tang", "authors": "Jiangjun Tang, Eleni Petraki, and Hussein Abbass", "title": "Shaping Influence and Influencing Shaping: A Computational Red Teaming\n  Trust-based Swarm Intelligence Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sociotechnical systems are complex systems, where nonlinear interaction among\ndifferent players can obscure causal relationships. The absence of mechanisms\nto help us understand how to create a change in the system makes it hard to\nmanage these systems.\n  Influencing and shaping are social operators acting on sociotechnical systems\nto design a change. However, the two operators are usually discussed in an\nad-hoc manner, without proper guiding models and metrics which assist in\nadopting these models successfully. Moreover, both social operators rely on\naccurate understanding of the concept of trust. Without such understanding,\nneither of these operators can create the required level to create a change in\na desirable direction.\n  In this paper, we define these concepts in a concise manner suitable for\nmodelling the concepts and understanding their dynamics. We then introduce a\nmodel for influencing and shaping and use Computational Red Teaming principles\nto design and demonstrate how this model operates. We validate the results\ncomputationally through a simulation environment to show social influencing and\nshaping in an artificial society.\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2018 23:53:40 GMT"}], "update_date": "2018-02-28", "authors_parsed": [["Tang", "Jiangjun", ""], ["Petraki", "Eleni", ""], ["Abbass", "Hussein", ""]]}, {"id": "1802.10446", "submitter": "Adam Derek Cobb", "authors": "Adam D. Cobb, Richard Everett, Andrew Markham, Stephen J. Roberts", "title": "Identifying Sources and Sinks in the Presence of Multiple Agents with\n  Gaussian Process Vector Calculus", "comments": "KDD '18 Proceedings of the 24th ACM SIGKDD International Conference\n  on Knowledge Discovery & Data Mining, Pages 1254-1262, 9 pages, 5 figures,\n  conference submission, University of Oxford. arXiv admin note: text overlap\n  with arXiv:1709.02357", "journal-ref": null, "doi": "10.1145/3219819.3220065", "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In systems of multiple agents, identifying the cause of observed agent\ndynamics is challenging. Often, these agents operate in diverse, non-stationary\nenvironments, where models rely on hand-crafted environment-specific features\nto infer influential regions in the system's surroundings. To overcome the\nlimitations of these inflexible models, we present GP-LAPLACE, a technique for\nlocating sources and sinks from trajectories in time-varying fields. Using\nGaussian processes, we jointly infer a spatio-temporal vector field, as well as\ncanonical vector calculus operations on that field. Notably, we do this from\nonly agent trajectories without requiring knowledge of the environment, and\nalso obtain a metric for denoting the significance of inferred causal features\nin the environment by exploiting our probabilistic method. To evaluate our\napproach, we apply it to both synthetic and real-world GPS data, demonstrating\nthe applicability of our technique in the presence of multiple agents, as well\nas its superiority over existing methods.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 21:14:46 GMT"}, {"version": "v2", "created": "Mon, 12 Nov 2018 18:13:01 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Cobb", "Adam D.", ""], ["Everett", "Richard", ""], ["Markham", "Andrew", ""], ["Roberts", "Stephen J.", ""]]}]