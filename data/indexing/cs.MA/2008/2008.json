[{"id": "2008.00076", "submitter": "Jacinto D\\'avila", "authors": "Jacinto Davila", "title": "Posibility conditions for Open Access", "comments": "13 pages, 2 figures, 6 tables and accompanying prolog source code", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.MA", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This is an attempt to formalize the conditions of possibility for free,\nlibre, open access to scientific knowledge within a game. The challenge is to\nenunciate the terms under which agents participating in the Grand conversation\nof science would be willing to open share, exchange, negotiate or surrender\ntheir contributions, considering their corresponding intentions, goals, beliefs\nand expected utilities. Many conclusions can be drawn from the game here\ndescribed. We have made many simplifying decisions along the modelling process\nthat must be taken into account as a determining context for those conclusions,\nof course. It can be safely state, however, that under the current conditions\nof the game, Editors will keep betting on Toll Access, knowledge distribution\nmodels even if all the other Academic agent go for Open Access.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 21:03:07 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Davila", "Jacinto", ""]]}, {"id": "2008.00679", "submitter": "Joewie Koh", "authors": "Joewie J. Koh, Guohui Ding, Christoffer Heckman, Lijun Chen,\n  Alessandro Roncone", "title": "Cooperative Control of Mobile Robots with Stackelberg Learning", "comments": "8 pages, 7 figures", "journal-ref": "Proceedings of the 2020 IEEE/RSJ International Conference on\n  Intelligent Robots and Systems (IROS), 2020, pp. 7985-7992", "doi": "10.1109/IROS45743.2020.9341376", "report-no": null, "categories": "cs.RO cs.GT cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-robot cooperation requires agents to make decisions that are consistent\nwith the shared goal without disregarding action-specific preferences that\nmight arise from asymmetry in capabilities and individual objectives. To\naccomplish this goal, we propose a method named SLiCC: Stackelberg Learning in\nCooperative Control. SLiCC models the problem as a partially observable\nstochastic game composed of Stackelberg bimatrix games, and uses deep\nreinforcement learning to obtain the payoff matrices associated with these\ngames. Appropriate cooperative actions are then selected with the derived\nStackelberg equilibria. Using a bi-robot cooperative object transportation\nproblem, we validate the performance of SLiCC against centralized multi-agent\nQ-learning and demonstrate that SLiCC achieves better combined utility.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 07:21:51 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Koh", "Joewie J.", ""], ["Ding", "Guohui", ""], ["Heckman", "Christoffer", ""], ["Chen", "Lijun", ""], ["Roncone", "Alessandro", ""]]}, {"id": "2008.00699", "submitter": "Harold Soh", "authors": "Joshua Lee, Jeffrey Fong, Bing Cai Kok, Harold Soh", "title": "Getting to Know One Another: Calibrating Intent, Capabilities and Trust\n  for Human-Robot Collaboration", "comments": "IROS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.HC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Common experience suggests that agents who know each other well are better\nable to work together. In this work, we address the problem of calibrating\nintention and capabilities in human-robot collaboration. In particular, we\nfocus on scenarios where the robot is attempting to assist a human who is\nunable to directly communicate her intent. Moreover, both agents may have\ndiffering capabilities that are unknown to one another. We adopt a\ndecision-theoretic approach and propose the TICC-POMDP for modeling this\nsetting, with an associated online solver. Experiments show our approach leads\nto better team performance both in simulation and in a real-world study with\nhuman subjects.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 08:04:15 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Lee", "Joshua", ""], ["Fong", "Jeffrey", ""], ["Kok", "Bing Cai", ""], ["Soh", "Harold", ""]]}, {"id": "2008.01062", "submitter": "Jianhao Wang", "authors": "Jianhao Wang, Zhizhou Ren, Terry Liu, Yang Yu, Chongjie Zhang", "title": "QPLEX: Duplex Dueling Multi-Agent Q-Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore value-based multi-agent reinforcement learning (MARL) in the\npopular paradigm of centralized training with decentralized execution (CTDE).\nCTDE has an important concept, Individual-Global-Max (IGM) principle, which\nrequires the consistency between joint and local action selections to support\nefficient local decision-making. However, in order to achieve scalability,\nexisting MARL methods either limit representation expressiveness of their value\nfunction classes or relax the IGM consistency, which may suffer from\ninstability risk or lead to poor performance. This paper presents a novel MARL\napproach, called duPLEX dueling multi-agent Q-learning (QPLEX), which takes a\nduplex dueling network architecture to factorize the joint value function. This\nduplex dueling structure encodes the IGM principle into the neural network\narchitecture and thus enables efficient value function learning. Theoretical\nanalysis shows that QPLEX achieves a complete IGM function class. Empirical\nexperiments on StarCraft II micromanagement tasks demonstrate that QPLEX\nsignificantly outperforms state-of-the-art baselines in both online and offline\ndata collection settings, and also reveal that QPLEX achieves high sample\nefficiency and can benefit from offline datasets without additional online\nexploration.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 17:52:09 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2020 14:13:20 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Wang", "Jianhao", ""], ["Ren", "Zhizhou", ""], ["Liu", "Terry", ""], ["Yu", "Yang", ""], ["Zhang", "Chongjie", ""]]}, {"id": "2008.01227", "submitter": "Stepan Dergachev", "authors": "Stepan Dergachev and Konstantin Yakovlev and Ryhor Prakapovich", "title": "A Combination of Theta*, ORCA and Push and Rotate for Multi-agent\n  Navigation", "comments": "This is a preprint of the paper accepted to ICR'20. It contains 12\n  pages and 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of multi-agent navigation in static environments when no\ncentralized controller is present. Each agent is controlled individually and\nrelies on three algorithmic components to achieve its goal while avoiding\ncollisions with the other agents and the obstacles: i) individual path planning\nwhich is done by Theta* algorithm; ii) collision avoidance while path following\nwhich is performed by ORCA* algorithm; iii) locally-confined multi-agent path\nplanning done by Push and Rotate algorithm. The latter component is crucial to\navoid deadlocks in confined areas, such as narrow passages or doors. We\ndescribe how the suggested components interact and form a coherent navigation\npipeline. We carry out an extensive empirical evaluation of this pipeline in\nsimulation. The obtained results clearly demonstrate that the number of\noccurring deadlocks significantly decreases enabling more agents to reach their\ngoals compared to techniques that rely on collision-avoidance only and do not\ninclude multi-agent path planning component\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 22:22:43 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Dergachev", "Stepan", ""], ["Yakovlev", "Konstantin", ""], ["Prakapovich", "Ryhor", ""]]}, {"id": "2008.01485", "submitter": "Jose Fontanari", "authors": "Sandro M. Reia and Jos\\'e F. Fontanari", "title": "Wisdom of crowds: much ado about nothing", "comments": null, "journal-ref": null, "doi": "10.1088/1742-5468/abfa1f", "report-no": null, "categories": "stat.AP cs.MA physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The puzzling idea that the combination of independent estimates of the\nmagnitude of a quantity results in a very accurate prediction, which is\nsuperior to any or, at least, to most of the individual estimates is known as\nthe wisdom of crowds. Here we use the Federal Reserve Bank of Philadelphia's\nSurvey of Professional Forecasters database to confront the statistical and\npsychophysical explanations of this phenomenon. Overall we find that the data\ndo not support any of the proposed explanations of the wisdom of crowds. In\nparticular, we find a positive correlation between the variance (or diversity)\nof the estimates and the crowd error in disagreement with some interpretations\nof the diversity prediction theorem. In addition, contra the predictions of the\npsychophysical augmented quincunx model, we find that the skew of the estimates\noffers no information about the crowd error. More importantly, we find that the\ncrowd beats all individuals in less than 2% of the forecasts and beats most\nindividuals in less than 70% of the forecasts, which means that there is a\nsporting chance that an individual selected at random will perform better than\nthe crowd. These results contrast starkly with the performance of non-natural\ncrowds composed of unbiased forecasters which beat most individuals in\npractically all forecasts. The moderate statistical advantage of a real-world\ncrowd over its members does not justify the ado about its wisdom, which is most\nlikely a product of the selective attention fallacy.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 12:26:15 GMT"}, {"version": "v2", "created": "Tue, 23 Feb 2021 19:52:03 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Reia", "Sandro M.", ""], ["Fontanari", "Jos\u00e9 F.", ""]]}, {"id": "2008.01825", "submitter": "Eugene Vinitsky", "authors": "Eugene Vinitsky and Yuqing Du and Kanaad Parvate and Kathy Jang and\n  Pieter Abbeel and Alexandre Bayen", "title": "Robust Reinforcement Learning using Adversarial Populations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning (RL) is an effective tool for controller design but\ncan struggle with issues of robustness, failing catastrophically when the\nunderlying system dynamics are perturbed. The Robust RL formulation tackles\nthis by adding worst-case adversarial noise to the dynamics and constructing\nthe noise distribution as the solution to a zero-sum minimax game. However,\nexisting work on learning solutions to the Robust RL formulation has primarily\nfocused on training a single RL agent against a single adversary. In this work,\nwe demonstrate that using a single adversary does not consistently yield\nrobustness to dynamics variations under standard parametrizations of the\nadversary; the resulting policy is highly exploitable by new adversaries. We\npropose a population-based augmentation to the Robust RL formulation in which\nwe randomly initialize a population of adversaries and sample from the\npopulation uniformly during training. We empirically validate across robotics\nbenchmarks that the use of an adversarial population results in a more robust\npolicy that also improves out-of-distribution generalization. Finally, we\ndemonstrate that this approach provides comparable robustness and\ngeneralization as domain randomization on these benchmarks while avoiding a\nubiquitous domain randomization failure mode.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 20:57:32 GMT"}, {"version": "v2", "created": "Tue, 22 Sep 2020 22:41:54 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Vinitsky", "Eugene", ""], ["Du", "Yuqing", ""], ["Parvate", "Kanaad", ""], ["Jang", "Kathy", ""], ["Abbeel", "Pieter", ""], ["Bayen", "Alexandre", ""]]}, {"id": "2008.02616", "submitter": "Jan Blumenkamp", "authors": "Jan Blumenkamp, Amanda Prorok", "title": "The Emergence of Adversarial Communication in Multi-Agent Reinforcement\n  Learning", "comments": "Accepted to Conference on Robot Learning (CoRL) 2020. Camera-ready\n  version incorporating rebuttal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world problems require the coordination of multiple autonomous\nagents. Recent work has shown the promise of Graph Neural Networks (GNNs) to\nlearn explicit communication strategies that enable complex multi-agent\ncoordination. These works use models of cooperative multi-agent systems whereby\nagents strive to achieve a shared global goal. When considering agents with\nself-interested local objectives, the standard design choice is to model these\nas separate learning systems (albeit sharing the same environment). Such a\ndesign choice, however, precludes the existence of a single, differentiable\ncommunication channel, and consequently prohibits the learning of inter-agent\ncommunication strategies. In this work, we address this gap by presenting a\nlearning model that accommodates individual non-shared rewards and a\ndifferentiable communication channel that is common among all agents. We focus\non the case where agents have self-interested objectives, and develop a\nlearning algorithm that elicits the emergence of adversarial communications. We\nperform experiments on multi-agent coverage and path planning problems, and\nemploy a post-hoc interpretability technique to visualize the messages that\nagents communicate to each other. We show how a single self-interested agent is\ncapable of learning highly manipulative communication strategies that allows it\nto significantly outperform a cooperative team of agents.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 12:48:08 GMT"}, {"version": "v2", "created": "Wed, 4 Nov 2020 18:01:46 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Blumenkamp", "Jan", ""], ["Prorok", "Amanda", ""]]}, {"id": "2008.02753", "submitter": "Jugal Garg", "authors": "Bhaskar Ray Chaudhury and Jugal Garg and Peter McGlaughlin and Ruta\n  Mehta", "title": "Competitive Allocation of a Mixed Manna", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CC cs.DM cs.DS cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the fair division problem of allocating a mixed manna under\nadditively separable piecewise linear concave (SPLC) utilities. A mixed manna\ncontains goods that everyone likes and bads that everyone dislikes, as well as\nitems that some like and others dislike. The seminal work of Bogomolnaia et al.\n[Econometrica'17] argue why allocating a mixed manna is genuinely more\ncomplicated than a good or a bad manna, and why competitive equilibrium is the\nbest mechanism. They also provide the existence of equilibrium and establish\nits peculiar properties (e.g., non-convex and disconnected set of equilibria\neven under linear utilities), but leave the problem of computing an equilibrium\nopen. This problem remained unresolved even for only bad manna under linear\nutilities.\n  Our main result is a simplex-like algorithm based on Lemke's scheme for\ncomputing a competitive allocation of a mixed manna under SPLC utilities, a\nstrict generalization of linear. Experimental results on randomly generated\ninstances suggest that our algorithm will be fast in practice. The problem is\nknown to be PPAD-hard for the case of good manna, and we also show a similar\nresult for the case of bad manna. Given these PPAD-hardness results, designing\nsuch an algorithm is the only non-brute-force (non-enumerative) option known,\ne.g., the classic Lemke-Howson algorithm (1964) for computing a Nash\nequilibrium in a 2-player game is still one of the most widely used algorithms\nin practice.\n  Our algorithm also yields several new structural properties as simple\ncorollaries. We obtain a (constructive) proof of existence for a far more\ngeneral setting, membership of the problem in PPAD, rational-valued solution,\nand odd number of solutions property. The last property also settles the\nconjecture of Bogomolnaia et al. in the affirmative.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 16:38:00 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Chaudhury", "Bhaskar Ray", ""], ["Garg", "Jugal", ""], ["McGlaughlin", "Peter", ""], ["Mehta", "Ruta", ""]]}, {"id": "2008.03573", "submitter": "Esra Erdem", "authors": "Aysu Bogatarkan and Esra Erdem", "title": "Explanation Generation for Multi-Modal Multi-Agent Path Finding with\n  Optimal Resource Utilization using Answer Set Programming", "comments": "Paper presented at the 36th International Conference on Logic\n  Programming (ICLP 2020), University Of Calabria, Rende (CS), Italy, September\n  2020, 16 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The multi-agent path finding (MAPF) problem is a combinatorial search problem\nthat aims at finding paths for multiple agents (e.g., robots) in an environment\n(e.g., an autonomous warehouse) such that no two agents collide with each\nother, and subject to some constraints on the lengths of paths. We consider a\ngeneral version of MAPF, called mMAPF, that involves multi-modal transportation\nmodes (e.g., due to velocity constraints) and consumption of different types of\nresources (e.g., batteries). The real-world applications of mMAPF require\nflexibility (e.g., solving variations of mMAPF) as well as explainability. Our\nearlier studies on mMAPF have focused on the former challenge of flexibility.\nIn this study, we focus on the latter challenge of explainability, and\nintroduce a method for generating explanations for queries regarding the\nfeasibility and optimality of solutions, the nonexistence of solutions, and the\nobservations about solutions. Our method is based on answer set programming.\nThis paper is under consideration for acceptance in TPLP.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 18:34:34 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Bogatarkan", "Aysu", ""], ["Erdem", "Esra", ""]]}, {"id": "2008.03577", "submitter": "Dimitris Ampeliotis", "authors": "Dimitris Ampeliotis and Kostas Berberidis", "title": "Potential Games for Distributed Constrained Consensus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of computing a common point that lies in the intersection of a\nfinite number of closed convex sets, each known to one agent in a network, is\nstudied. This issue, known as the distributed convex feasibility problem or the\ndistributed constrained consensus problem, constitutes an important research\ngoal mainly due to the large number of possible applications. In this work,\nthis issue is treated from a game theoretic viewpoint. In particular, we\nformulate the problem as a non-cooperative game for which a potential function\nexists and prove that all Nash equilibria of this game correspond to consensus\nstates. Based upon this analysis, a best-response based distributed algorithm\nthat solves the constrained consensus problem is developed. Furthermore, one\nmore approach to solve the convex feasibility problem is studied based upon a\nprojected gradient type algorithm that seeks the maximum of the considered\npotential function. A condition for the convergence of this scheme is derived\nand an exact distributed algorithm is given. Finally, simulation results for a\nsource localization problem are given, that validate the theoretical results\nand demonstrate the applicability and performance of the derived algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 18:46:01 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Ampeliotis", "Dimitris", ""], ["Berberidis", "Kostas", ""]]}, {"id": "2008.03620", "submitter": "Javier Del Ser Dr.", "authors": "Aritz D. Martinez, Javier Del Ser, Esther Villar-Rodriguez, Eneko\n  Osaba, Javier Poyatos, Siham Tabik, Daniel Molina, Francisco Herrera", "title": "Lights and Shadows in Evolutionary Deep Learning: Taxonomy, Critical\n  Methodological Analysis, Cases of Study, Learned Lessons, Recommendations and\n  Challenges", "comments": "64 pages, 18 figures, under review for its consideration in\n  Information Fusion journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much has been said about the fusion of bio-inspired optimization algorithms\nand Deep Learning models for several purposes: from the discovery of network\ntopologies and hyper-parametric configurations with improved performance for a\ngiven task, to the optimization of the model's parameters as a replacement for\ngradient-based solvers. Indeed, the literature is rich in proposals showcasing\nthe application of assorted nature-inspired approaches for these tasks. In this\nwork we comprehensively review and critically examine contributions made so far\nbased on three axes, each addressing a fundamental question in this research\navenue: a) optimization and taxonomy (Why?), including a historical\nperspective, definitions of optimization problems in Deep Learning, and a\ntaxonomy associated with an in-depth analysis of the literature, b) critical\nmethodological analysis (How?), which together with two case studies, allows us\nto address learned lessons and recommendations for good practices following the\nanalysis of the literature, and c) challenges and new directions of research\n(What can be done, and what for?). In summary, three axes - optimization and\ntaxonomy, critical analysis, and challenges - which outline a complete vision\nof a merger of two technologies drawing up an exciting future for this area of\nfusion research.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 00:25:06 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Martinez", "Aritz D.", ""], ["Del Ser", "Javier", ""], ["Villar-Rodriguez", "Esther", ""], ["Osaba", "Eneko", ""], ["Poyatos", "Javier", ""], ["Tabik", "Siham", ""], ["Molina", "Daniel", ""], ["Herrera", "Francisco", ""]]}, {"id": "2008.04105", "submitter": "Dagnachew Azene Temesgene", "authors": "Dagnachew Azene Temesgene, Marco Miozzo, Deniz G\\\"und\\\"uz and Paolo\n  Dini", "title": "Distributed Deep Reinforcement Learning for Functional Split Control in\n  Energy Harvesting Virtualized Small Cells", "comments": "Submitted to IEEE transaction on sustainable computing. arXiv admin\n  note: text overlap with arXiv:1906.05735", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To meet the growing quest for enhanced network capacity, mobile network\noperators (MNOs) are deploying dense infrastructures of small cells. This, in\nturn, increases the power consumption of mobile networks, thus impacting the\nenvironment. As a result, we have seen a recent trend of powering mobile\nnetworks with harvested ambient energy to achieve both environmental and cost\nbenefits. In this paper, we consider a network of virtualized small cells\n(vSCs) powered by energy harvesters and equipped with rechargeable batteries,\nwhich can opportunistically offload baseband (BB) functions to a grid-connected\nedge server depending on their energy availability. We formulate the\ncorresponding grid energy and traffic drop rate minimization problem, and\npropose a distributed deep reinforcement learning (DDRL) solution. Coordination\namong vSCs is enabled via the exchange of battery state information. The\nevaluation of the network performance in terms of grid energy consumption and\ntraffic drop rate confirms that enabling coordination among the vSCs via\nknowledge exchange achieves a performance close to the optimal. Numerical\nresults also confirm that the proposed DDRL solution provides higher network\nperformance, better adaptation to the changing environment, and higher cost\nsavings with respect to a tabular multi-agent reinforcement learning (MRL)\nsolution used as a benchmark.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 12:27:01 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Temesgene", "Dagnachew Azene", ""], ["Miozzo", "Marco", ""], ["G\u00fcnd\u00fcz", "Deniz", ""], ["Dini", "Paolo", ""]]}, {"id": "2008.04109", "submitter": "Abdul Mueed Hafiz Dr.", "authors": "Abdul Mueed Hafiz and Ghulam Mohiuddin Bhat", "title": "Deep Q-Network Based Multi-agent Reinforcement Learning with Binary\n  Action Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Q-Network (DQN) based multi-agent systems (MAS) for reinforcement\nlearning (RL) use various schemes where in the agents have to learn and\ncommunicate. The learning is however specific to each agent and communication\nmay be satisfactorily designed for the agents. As more complex Deep QNetworks\ncome to the fore, the overall complexity of the multi-agent system increases\nleading to issues like difficulty in training, need for higher resources and\nmore training time, difficulty in fine-tuning, etc. To address these issues we\npropose a simple but efficient DQN based MAS for RL which uses shared state and\nrewards, but agent-specific actions, for updation of the experience replay pool\nof the DQNs, where each agent is a DQN. The benefits of the approach are\noverall simplicity, faster convergence and better performance as compared to\nconventional DQN based approaches. It should be noted that the method can be\nextended to any DQN. As such we use simple DQN and DDQN (Double Q-learning)\nrespectively on three separate tasks i.e. Cartpole-v1 (OpenAI Gym environment)\n, LunarLander-v2 (OpenAI Gym environment) and Maze Traversal (customized\nenvironment). The proposed approach outperforms the baseline on these tasks by\ndecent margins respectively.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 15:16:05 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Hafiz", "Abdul Mueed", ""], ["Bhat", "Ghulam Mohiuddin", ""]]}, {"id": "2008.04162", "submitter": "Philip Feldman", "authors": "Philip Feldman and Antonio Bucchiarone", "title": "Navigating Human Language Models with Synthetic Agents", "comments": "8 pages, 6 figures, 2 tables, 1 algorithm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern natural language models such as the GPT-2/GPT-3 contain tremendous\namounts of information about human belief in a consistently testable form. If\nthese models could be shown to accurately reflect the underlying beliefs of the\nhuman beings that produced the data used to train these models, then such\nmodels become a powerful sociological tool in ways that are distinct from\ntraditional methods, such as interviews and surveys. In this study, We train a\nversion of the GPT-2 on a corpora of historical chess games, and then \"launch\"\nclusters of synthetic agents into the model, using text strings to create\ncontext and orientation. We compare the trajectories contained in the text\ngenerated by the agents/model and compare that to the known ground truth of the\nchess board, move legality, and historical patterns of play. We find that the\npercentages of moves by piece using the model are substantially similar from\nhuman patterns. We further find that the model creates an accurate latent\nrepresentation of the chessboard, and that it is possible to plot trajectories\nof legal moves across the board using this knowledge.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 14:39:53 GMT"}, {"version": "v2", "created": "Wed, 12 Aug 2020 15:09:36 GMT"}, {"version": "v3", "created": "Thu, 13 Aug 2020 13:42:00 GMT"}, {"version": "v4", "created": "Fri, 14 Aug 2020 11:12:43 GMT"}, {"version": "v5", "created": "Mon, 24 Aug 2020 19:18:21 GMT"}, {"version": "v6", "created": "Mon, 28 Sep 2020 15:40:41 GMT"}, {"version": "v7", "created": "Tue, 29 Sep 2020 09:57:33 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Feldman", "Philip", ""], ["Bucchiarone", "Antonio", ""]]}, {"id": "2008.04195", "submitter": "Usman Khan", "authors": "Ran Xin, Usman A. Khan, and Soummya Kar", "title": "An improved convergence analysis for decentralized online stochastic\n  non-convex optimization", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2021.3062553", "report-no": null, "categories": "math.OC cs.LG cs.MA cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study decentralized online stochastic non-convex\noptimization over a network of nodes. Integrating a technique called gradient\ntracking in decentralized stochastic gradient descent, we show that the\nresulting algorithm, GT-DSGD, enjoys certain desirable characteristics towards\nminimizing a sum of smooth non-convex functions. In particular, for general\nsmooth non-convex functions, we establish non-asymptotic characterizations of\nGT-DSGD and derive the conditions under which it achieves network-independent\nperformances that match the centralized minibatch SGD. In contrast, the\nexisting results suggest that GT-DSGD is always network-dependent and is\ntherefore strictly worse than the centralized minibatch SGD. When the global\nnon-convex function additionally satisfies the Polyak-Lojasiewics (PL)\ncondition, we establish the linear convergence of GT-DSGD up to a steady-state\nerror with appropriate constant step-sizes. Moreover, under stochastic\napproximation step-sizes, we establish, for the first time, the optimal global\nsublinear convergence rate on almost every sample path, in addition to the\nasymptotically optimal sublinear rate in expectation. Since strongly convex\nfunctions are a special case of the functions satisfying the PL condition, our\nresults are not only immediately applicable but also improve the currently\nknown best convergence rates and their dependence on problem parameters.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 15:29:13 GMT"}, {"version": "v2", "created": "Tue, 29 Dec 2020 02:20:10 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Xin", "Ran", ""], ["Khan", "Usman A.", ""], ["Kar", "Soummya", ""]]}, {"id": "2008.04383", "submitter": "Yaofeng Desmond Zhong", "authors": "Yaofeng Desmond Zhong, Vaibhav Srivastava, Naomi Ehrich Leonard", "title": "Influence Spread in the Heterogeneous Multiplex Linear Threshold Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.MA math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The linear threshold model (LTM) has been used to study spread on\nsingle-layer networks defined by one inter-agent sensing modality and agents\nhomogeneous in protocol. We define and analyze the heterogeneous multiplex LTM\nto study spread on multi-layer networks with each layer representing a\ndifferent sensing modality and agents heterogeneous in protocol. Protocols are\ndesigned to distinguish signals from different layers: an agent becomes active\nif a sufficient number of its neighbors in each of any $a$ of the $m$ layers is\nactive. We focus on Protocol OR, when $a=1$, and Protocol AND, when $a=m$,\nwhich model agents that are most and least readily activated, respectively. We\ndevelop theory and algorithms to compute the size of the spread at steady state\nfor any set of initially active agents and to analyze the role of distinguished\nsensing modalities, network structure, and heterogeneity. We show how\nheterogeneity manages the tension in spreading dynamics between sensitivity to\ninputs and robustness to disturbances.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 19:41:04 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Zhong", "Yaofeng Desmond", ""], ["Srivastava", "Vaibhav", ""], ["Leonard", "Naomi Ehrich", ""]]}, {"id": "2008.04452", "submitter": "Erdem B{\\i}y{\\i}k", "authors": "Zheqing Zhu, Erdem B{\\i}y{\\i}k, Dorsa Sadigh", "title": "Multi-Agent Safe Planning with Gaussian Processes", "comments": "9 pages, 5 figures. Published at IEEE/RSJ International Conference on\n  Intelligent Robots and Systems (IROS) 2020", "journal-ref": null, "doi": "10.1109/IROS45743.2020.9341169", "report-no": null, "categories": "cs.AI cs.LG cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-agent safe systems have become an increasingly important area of study\nas we can now easily have multiple AI-powered systems operating together. In\nsuch settings, we need to ensure the safety of not only each individual agent,\nbut also the overall system. In this paper, we introduce a novel multi-agent\nsafe learning algorithm that enables decentralized safe navigation when there\nare multiple different agents in the environment. This algorithm makes mild\nassumptions about other agents and is trained in a decentralized fashion, i.e.\nwith very little prior knowledge about other agents' policies. Experiments show\nour algorithm performs well with the robots running other algorithms when\noptimizing various objectives.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 23:09:05 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Zhu", "Zheqing", ""], ["B\u0131y\u0131k", "Erdem", ""], ["Sadigh", "Dorsa", ""]]}, {"id": "2008.04774", "submitter": "Alessandro Gianola", "authors": "Paolo Felli and Alessandro Gianola and Marco Montali", "title": "SMT-based Safety Verification of Parameterised Multi-Agent Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the verification of parameterised multi-agent systems\n(MASs), and in particular the task of verifying whether unwanted states,\ncharacterised as a given state formula, are reachable in a given MAS, i.e.,\nwhether the MAS is unsafe. The MAS is parameterised and the model only\ndescribes the finite set of possible agent templates, while the actual number\nof concrete agent instances for each template is unbounded and cannot be\nforeseen. This makes the state-space infinite. As safety may of course depend\non the number of agent instances in the system, the verification result must be\ncorrect irrespective of such number. We solve this problem via infinite-state\nmodel checking based on satisfiability modulo theories (SMT), relying on the\ntheory of array-based systems: we present parameterised MASs as particular\narray-based systems, under two execution semantics for the MAS, which we call\nconcurrent and interleaved. We prove our decidability results under these\nassumptions and illustrate our implementation approach, called SAFE: the Swarm\nSafety Detector, based on the third-party model checker MCMT, which we evaluate\nexperimentally. Finally, we discuss how this approach lends itself to richer\nparameterised and data-aware MAS settings beyond the state-of-the-art solutions\nin the literature, which we leave as future work.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 15:24:05 GMT"}, {"version": "v2", "created": "Fri, 14 Aug 2020 17:06:25 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Felli", "Paolo", ""], ["Gianola", "Alessandro", ""], ["Montali", "Marco", ""]]}, {"id": "2008.04947", "submitter": "Satyandra Guthula", "authors": "Satyandra Guthula, Sunil Simon, Harish Karnick", "title": "Analysis of Agricultural Policy Recommendations using Multi-Agent\n  Systems", "comments": "Supplementary file also uploaded which contains the detailed working\n  of the agents and the simulation. Also contains the github repository link", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite agriculture being the primary source of livelihood for more than half\nof India's population, several socio-economic policies are implemented in the\nIndian agricultural sector without paying enough attention to the possible\noutcomes of the policies. The negative impact of some policies can be seen in\nthe huge distress suffered by farmers as documented by several studies and\nreported in the media on a regular basis. In this paper, we model a specific\ntroubled agricultural sub-system in India as a Multi-Agent System and use it to\nanalyse the impact of some policies. Ideally, we should be able to model the\nentire system, including all the external dependencies from other systems - for\nexample availability of labour or water may depend on other sources of\nemployment, water rights and so on - but for our purpose, we start with a\nfairly basic model not taking into account such external effects. As per our\nknowledge there are no available models which considers factors like water\nlevels, availability of information and market simulation in the Indian\ncontext. So, we plugged in various entities into the model to make it\nsufficiently close to observed realities, at least in some selected regions of\nIndia. We evaluate some policy options to get an understanding of changes that\nmay happen once such policies are implemented. Then we recommended some\npolicies based on the result of the simulation.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 18:29:25 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Guthula", "Satyandra", ""], ["Simon", "Sunil", ""], ["Karnick", "Harish", ""]]}, {"id": "2008.05214", "submitter": "Heechang Ryu", "authors": "Heechang Ryu, Hayong Shin, Jinkyoo Park", "title": "REMAX: Relational Representation for Multi-Agent Exploration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Training a multi-agent reinforcement learning (MARL) model is generally\ndifficult because there are numerous combinations of complex interactions among\nagents that induce certain reward signals. Especially when there is a sparse\nreward signal, the training becomes more difficult. Previous studies have tried\nto resolve this issue by employing an intrinsic reward, which is a signal\nspecifically designed for inducing the interactions among agents, to boost the\nMARL model training. However, this approach requires extensive prior knowledge\nto design an intrinsic reward. To optimize the training of an MARL model, we\npropose a learning-based exploration strategy to generate the initial states of\na game. The proposed method adopts a variational graph autoencoder to represent\na state of a game such that (1) the state can be compactly encoded to the\nlatent representation by considering the relationship among agents, and (2) the\nlatent representation can be used as an effective input to the surrogate model\npredicting the exploration score. The proposed method determines the latent\nrepresentations that maximize the surrogate model and decodes these\nrepresentations to generate the initial states from which the MARL model starts\ntraining. Empirically, we demonstrate that the generated states improve the\ntraining and performance of MARL more than the existing exploration methods.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 10:23:35 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Ryu", "Heechang", ""], ["Shin", "Hayong", ""], ["Park", "Jinkyoo", ""]]}, {"id": "2008.05387", "submitter": "Brian Swenson", "authors": "Brian Swenson, Ryan Murray, H. Vincent Poor, Soummya Kar", "title": "Distributed Gradient Flow: Nonsmoothness, Nonconvexity, and Saddle Point\n  Evasion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper considers distributed gradient flow (DGF) for multi-agent nonconvex\noptimization. DGF is a continuous-time approximation of distributed gradient\ndescent that is often easier to study than its discrete-time counterpart. The\npaper has two main contributions. First, the paper considers optimization of\nnonsmooth, nonconvex objective functions. It is shown that DGF converges to\ncritical points in this setting. The paper then considers the problem of\navoiding saddle points. It is shown that if agents' objective functions are\nassumed to be smooth and nonconvex, then DGF can only converge to a saddle\npoint from a zero-measure set of initial conditions. To establish this result,\nthe paper proves a stable manifold theorem for DGF, which is a fundamental\ncontribution of independent interest. In a companion paper, analogous results\nare derived for discrete-time algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 15:32:59 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Swenson", "Brian", ""], ["Murray", "Ryan", ""], ["Poor", "H. Vincent", ""], ["Kar", "Soummya", ""]]}, {"id": "2008.05638", "submitter": "Julian Gutierrez", "authors": "Julian Gutierrez and Muhammad Najib and Giuseppe Perelli and Michael\n  Wooldridge", "title": "Automated Temporal Equilibrium Analysis: Verification and Synthesis of\n  Multi-Player Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of multi-agent systems, the rational verification problem is\nconcerned with checking which temporal logic properties will hold in a system\nwhen its constituent agents are assumed to behave rationally and strategically\nin pursuit of individual objectives. Typically, those objectives are expressed\nas temporal logic formulae which the relevant agent desires to see satisfied.\nUnfortunately, rational verification is computationally complex, and requires\nspecialised techniques in order to obtain practically useable implementations.\nIn this paper, we present such a technique. This technique relies on a\nreduction of the rational verification problem to the solution of a collection\nof parity games. Our approach has been implemented in the Equilibrium\nVerification Environment (EVE) system. The EVE system takes as input a model of\na concurrent/multi-agent system represented using the Simple Reactive Modules\nLanguage (SRML), where agent goals are represented as Linear Temporal Logic\n(LTL) formulae, together with a claim about the equilibrium behaviour of the\nsystem, also expressed as an LTL formula. EVE can then check whether the LTL\nclaim holds on some (or every) computation of the system that could arise\nthrough agents choosing Nash equilibrium strategies; it can also check whether\na system has a Nash equilibrium, and synthesise individual strategies for\nplayers in the multi-player game. After presenting our basic framework, we\ndescribe our new technique and prove its correctness. We then describe our\nimplementation in the EVE system, and present experimental results which show\nthat EVE performs favourably in comparison to other existing tools that support\nrational verification.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 01:43:31 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Gutierrez", "Julian", ""], ["Najib", "Muhammad", ""], ["Perelli", "Giuseppe", ""], ["Wooldridge", "Michael", ""]]}, {"id": "2008.05643", "submitter": "Julian Gutierrez", "authors": "Julian Gutierrez and Aniello Murano and Giuseppe Perelli and Sasha\n  Rubin and Thomas Steeples and Michael Wooldridge", "title": "Equilibria for Games with Combined Qualitative and Quantitative\n  Objectives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The overall aim of our research is to develop techniques to reason about the\nequilibrium properties of multi-agent systems. We model multi-agent systems as\nconcurrent games, in which each player is a process that is assumed to act\nindependently and strategically in pursuit of personal preferences. In this\narticle, we study these games in the context of finite-memory strategies, and\nwe assume players' preferences are defined by a qualitative and a quantitative\nobjective, which are related by a lexicographic order: a player first prefers\nto satisfy its qualitative objective (given as a formula of Linear Temporal\nLogic) and then prefers to minimise costs (given by a mean-payoff function).\nOur main result is that deciding the existence of a strict epsilon Nash\nequilibrium in such games is 2ExpTime-complete (and hence decidable), even if\nplayers' deviations are implemented as infinite-memory strategies.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 01:56:24 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Gutierrez", "Julian", ""], ["Murano", "Aniello", ""], ["Perelli", "Giuseppe", ""], ["Rubin", "Sasha", ""], ["Steeples", "Thomas", ""], ["Wooldridge", "Michael", ""]]}, {"id": "2008.05647", "submitter": "Julian Gutierrez", "authors": "Julian Gutierrez and Giuseppe Perelli and Michael Wooldridge", "title": "Multi-Player Games with LDL Goals over Finite Traces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear Dynamic Logic on finite traces LDLf is a powerful logic for reasoning\nabout the behaviour of concurrent and multi-agent systems.\n  In this paper, we investigate techniques for both the characterisation and\nverification of equilibria in multi-player games with goals/objectives\nexpressed using logics based on LDLf. This study builds upon a generalisation\nof Boolean games, a logic-based game model of multi-agent systems where players\nhave goals succinctly represented in a logical way.\n  Because LDLf goals are considered, in the settings we study -- Reactive\nModules games and iterated Boolean games with goals over finite traces --\nplayers' goals can be defined to be regular properties while achieved in a\nfinite, but arbitrarily large, trace.\n  In particular, using alternating automata, the paper investigates\nautomata-theoretic approaches to the characterisation and verification of (pure\nstrategy Nash) equilibria, shows that the set of Nash equilibria in\nmulti-player games with LDLf objectives is regular, and provides complexity\nresults for the associated automata constructions.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 02:11:06 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Gutierrez", "Julian", ""], ["Perelli", "Giuseppe", ""], ["Wooldridge", "Michael", ""]]}, {"id": "2008.05908", "submitter": "Hesham Rakha", "authors": "Karim Fadhloun, Hesham A. Rakha, Archak Mittal", "title": "Bicycle Longitudinal Motion Modeling", "comments": "Submitted to Transportation Research Board Annual Meeting", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This research effort uses vehicular traffic flow techniques to model\nbicyclist longitudinal motion while accounting for bicycle interactions.\nSpecifically, an existing car-following model, the Fadhloun-Rakha (FR) model is\nre-parametrized to model bicyclists. Initially, the study evaluates the\nperformance of the proposed model formulation using experimental datasets\ncollected from two ring-road bicycle experiments; one conducted in Germany in\n2012, and the second in China in 2016. The validation of the model is achieved\nthrough investigating and comparing the proposed model outputs against those\nobtained from two state-of-the-art models, namely: the Necessary Deceleration\nModel (NDM), which is a model specifically designed to capture the longitudinal\nmotion of bicyclists; and the Intelligent Driver Model, which is a\ncar-following model that was demonstrated to be suitable for single-file\nbicycle traffic. Through a quantitative and qualitative evaluation, the\nproposed model formulation is demonstrated to produce modeling errors that are\nconsistent with the other two models. While all three models generate\ntrajectories that are consistent with empirically observed bicycle-following\nbehavior, only the proposed model allows for an explicit and straightforward\ntuning of the bicyclist physical characteristics and the road environment. A\nsensitivity analysis, demonstrates the effect of varying the different model\nparameters on the produced trajectories, highlighting the robustness and\ngenerality of the proposed model.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 15:43:35 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Fadhloun", "Karim", ""], ["Rakha", "Hesham A.", ""], ["Mittal", "Archak", ""]]}, {"id": "2008.06050", "submitter": "Hesham Rakha", "authors": "Jianhe Du, Hesham A. Rakha, Helena Breuer", "title": "An In-Depth Analysis of Ride-Hailing Travel Using a Large-scale\n  Trip-Based Dataset", "comments": "Paper submitted to the Transportation Research Board Annual Meeting", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid increase in ride-hailing (RH) use, a need to better understand\nand regulate the industry arises. This paper analyzes a year's worth of RH trip\ndata from the Greater Chicago Area to study RH trip patterns. More than 104\nmillion trips were analyzed. For trip rates, the results show that the total\nnumber of trips remained stable over the year, with pooled trips steadily\ndecreasing from 20 to 9 percent. People tend to use RH more on weekends\ncompared to weekdays. Specifically, weekend RH trip counts (per day) are, on\naverage, 20 percent higher than weekday trip counts. The results of this work\nwill help policy makers and transportation administrators better understand the\nnature of RH trips, which in turn allows for the design of a better regulation\nand guidance system for the ride-hailing industry.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 19:12:01 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Du", "Jianhe", ""], ["Rakha", "Hesham A.", ""], ["Breuer", "Helena", ""]]}, {"id": "2008.06082", "submitter": "Usman Khan", "authors": "Muhammad I. Qureshi and Ran Xin and Soummya Kar and Usman A. Khan", "title": "Push-SAGA: A decentralized stochastic algorithm with variance reduction\n  over directed graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.MA cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose Push-SAGA, a decentralized stochastic first-order\nmethod for finite-sum minimization over a directed network of nodes. Push-SAGA\ncombines node-level variance reduction to remove the uncertainty caused by\nstochastic gradients, network-level gradient tracking to address the\ndistributed nature of the data, and push-sum consensus to tackle the challenge\nof directed communication links. We show that Push-SAGA achieves linear\nconvergence to the exact solution for smooth and strongly convex problems and\nis thus the first linearly-convergent stochastic algorithm over arbitrary\nstrongly connected directed graphs. We also characterize the regimes in which\nPush-SAGA achieves a linear speed-up compared to its centralized counterpart\nand achieves a network-independent convergence rate. We illustrate the behavior\nand convergence properties of Push-SAGA with the help of numerical experiments\non strongly convex and non-convex problems.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 18:52:17 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 20:46:52 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Qureshi", "Muhammad I.", ""], ["Xin", "Ran", ""], ["Kar", "Soummya", ""], ["Khan", "Usman A.", ""]]}, {"id": "2008.06220", "submitter": "Abhimanyu Dubey", "authors": "Abhimanyu Dubey and Alex Pentland", "title": "Kernel Methods for Cooperative Multi-Agent Contextual Bandits", "comments": "19 pages including supplement, camera-ready at ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cooperative multi-agent decision making involves a group of agents\ncooperatively solving learning problems while communicating over a network with\ndelays. In this paper, we consider the kernelised contextual bandit problem,\nwhere the reward obtained by an agent is an arbitrary linear function of the\ncontexts' images in the related reproducing kernel Hilbert space (RKHS), and a\ngroup of agents must cooperate to collectively solve their unique decision\nproblems. For this problem, we propose \\textsc{Coop-KernelUCB}, an algorithm\nthat provides near-optimal bounds on the per-agent regret, and is both\ncomputationally and communicatively efficient. For special cases of the\ncooperative problem, we also provide variants of \\textsc{Coop-KernelUCB} that\nprovides optimal per-agent regret. In addition, our algorithm generalizes\nseveral existing results in the multi-agent bandit setting. Finally, on a\nseries of both synthetic and real-world multi-agent network benchmarks, we\ndemonstrate that our algorithm significantly outperforms existing benchmarks.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 07:37:44 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Dubey", "Abhimanyu", ""], ["Pentland", "Alex", ""]]}, {"id": "2008.06244", "submitter": "Abhimanyu Dubey", "authors": "Abhimanyu Dubey and Alex Pentland", "title": "Cooperative Multi-Agent Bandits with Heavy Tails", "comments": "26 pages including appendix, camera-ready for ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the heavy-tailed stochastic bandit problem in the cooperative\nmulti-agent setting, where a group of agents interact with a common bandit\nproblem, while communicating on a network with delays. Existing algorithms for\nthe stochastic bandit in this setting utilize confidence intervals arising from\nan averaging-based communication protocol known as~\\textit{running consensus},\nthat does not lend itself to robust estimation for heavy-tailed settings. We\npropose \\textsc{MP-UCB}, a decentralized multi-agent algorithm for the\ncooperative stochastic bandit that incorporates robust estimation with a\nmessage-passing protocol. We prove optimal regret bounds for \\textsc{MP-UCB}\nfor several problem settings, and also demonstrate its superiority to existing\nmethods. Furthermore, we establish the first lower bounds for the cooperative\nbandit problem, in addition to providing efficient algorithms for robust bandit\nestimation of location.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 08:34:32 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Dubey", "Abhimanyu", ""], ["Pentland", "Alex", ""]]}, {"id": "2008.06464", "submitter": "Shilin Xu", "authors": "Shilin Xu, Caili Guo, Rose Qingyang Hu and Yi Qian", "title": "Multi-Agent Deep Reinforcement Learning enabled Computation Resource\n  Allocation in a Vehicular Cloud Network", "comments": "I have update this paper, and a new version will be resubmitted later", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the computational resource allocation problem\nin a distributed Ad-Hoc vehicular network with no centralized infrastructure\nsupport. To support the ever increasing computational needs in such a vehicular\nnetwork, the distributed virtual cloud network (VCN) is formed, based on which\na computational resource sharing scheme through offloading among nearby\nvehicles is proposed. In view of the time-varying computational resource in\nVCN, the statistical distribution characteristics for computational resource\nare analyzed in detail. Thereby, a resource-aware combinatorial optimization\nobjective mechanism is proposed. To alleviate the non-stationary environment\ncaused by the typically multi-agent environment in VCN, we adopt a centralized\ntraining and decentralized execution framework. In addition, for the objective\noptimization problem, we model it as a Markov game and propose a DRL based\nmulti-agent deep deterministic reinforcement learning (MADDPG) algorithm to\nsolve it. Interestingly, to overcome the dilemma of lacking a real central\ncontrol unit in VCN, the allocation is actually completed on the vehicles in a\ndistributed manner. The simulation results are presented to demonstrate our\nscheme's effectiveness.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 17:02:24 GMT"}, {"version": "v2", "created": "Mon, 17 Aug 2020 14:26:11 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Xu", "Shilin", ""], ["Guo", "Caili", ""], ["Hu", "Rose Qingyang", ""], ["Qian", "Yi", ""]]}, {"id": "2008.06495", "submitter": "Yuandong Tian", "authors": "Yuandong Tian, Qucheng Gong, Tina Jiang", "title": "Joint Policy Search for Multi-agent Collaboration with Imperfect\n  Information", "comments": "Minor fix of the algorithm block", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.GT cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To learn good joint policies for multi-agent collaboration with imperfect\ninformation remains a fundamental challenge. While for two-player zero-sum\ngames, coordinate-ascent approaches (optimizing one agent's policy at a time,\ne.g., self-play) work with guarantees, in multi-agent cooperative setting they\noften converge to sub-optimal Nash equilibrium. On the other hand, directly\nmodeling joint policy changes in imperfect information game is nontrivial due\nto complicated interplay of policies (e.g., upstream updates affect downstream\nstate reachability). In this paper, we show global changes of game values can\nbe decomposed to policy changes localized at each information set, with a novel\nterm named policy-change density. Based on this, we propose Joint Policy\nSearch(JPS) that iteratively improves joint policies of collaborative agents in\nimperfect information games, without re-evaluating the entire game. On\nmulti-agent collaborative tabular games, JPS is proven to never worsen\nperformance and can improve solutions provided by unilateral approaches (e.g,\nCFR), outperforming algorithms designed for collaborative policy learning (e.g.\nBAD). Furthermore, for real-world games, JPS has an online form that naturally\nlinks with gradient updates. We test it to Contract Bridge, a 4-player\nimperfect-information game where a team of $2$ collaborates to compete against\nthe other. In its bidding phase, players bid in turn to find a good contract\nthrough a limited information channel. Based on a strong baseline agent that\nbids competitive bridge purely through domain-agnostic self-play, JPS improves\ncollaboration of team players and outperforms WBridge5, a championship-winning\nsoftware, by $+0.63$ IMPs (International Matching Points) per board over 1k\ngames, substantially better than previous SoTA ($+0.41$ IMPs/b) under\nDouble-Dummy evaluation.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 17:58:47 GMT"}, {"version": "v2", "created": "Mon, 24 Aug 2020 02:35:56 GMT"}, {"version": "v3", "created": "Wed, 30 Sep 2020 17:14:14 GMT"}, {"version": "v4", "created": "Thu, 22 Oct 2020 20:09:48 GMT"}, {"version": "v5", "created": "Sun, 6 Dec 2020 01:10:09 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Tian", "Yuandong", ""], ["Gong", "Qucheng", ""], ["Jiang", "Tina", ""]]}, {"id": "2008.06604", "submitter": "Gangshan Jing", "authors": "Gangshan Jing, He Bai, Jemin George, Aranya Chakrabortty", "title": "Model-Free Optimal Control of Linear Multi-Agent Systems via\n  Decomposition and Hierarchical Approximation", "comments": "This paper proposes a hierarchical learning and control framework for\n  model-free LQR of heterogeneous linear multi-agent systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.MA cs.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing the optimal linear quadratic regulator (LQR) for a large-scale\nmulti-agent system (MAS) is time-consuming since it involves solving a\nlarge-size matrix Riccati equation. The situation is further exasperated when\nthe design needs to be done in a model-free way using schemes such as\nreinforcement learning (RL). To reduce this computational complexity, we\ndecompose the large-scale LQR design problem into multiple smaller-size LQR\ndesign problems. We consider the objective function to be specified over an\nundirected graph, and cast the decomposition as a graph clustering problem. The\ngraph is decomposed into two parts, one consisting of independent clusters of\nconnected components, and the other containing edges that connect different\nclusters. Accordingly, the resulting controller has a hierarchical structure,\nconsisting of two components. The first component optimizes the performance of\neach independent cluster by solving the smaller-size LQR design problem in a\nmodel-free way using an RL algorithm. The second component accounts for the\nobjective coupling different clusters, which is achieved by solving a least\nsquares problem in one shot. Although suboptimal, the hierarchical controller\nadheres to a particular structure as specified by inter-agent couplings in the\nobjective function and by the decomposition strategy. Mathematical formulations\nare established to find a decomposition that minimizes the number of required\ncommunication links or reduces the optimality gap. Numerical simulations are\nprovided to highlight the pros and cons of the proposed designs.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 23:39:22 GMT"}, {"version": "v2", "created": "Wed, 17 Mar 2021 00:47:57 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Jing", "Gangshan", ""], ["Bai", "He", ""], ["George", "Jemin", ""], ["Chakrabortty", "Aranya", ""]]}, {"id": "2008.07282", "submitter": "Wenzel Pilar Von Pilchau", "authors": "Wenzel Pilar von Pilchau and Varun Gowtham and Maximilian Gruber and\n  Matthias Riedl and Nikolaos-Stefanos Koutrakis and Jawad Tayyub and J\\\"org\n  H\\\"ahner and Sascha Eichst\\\"adt and Eckart Uhlmann and Julian Polte and\n  Volker Frey and Alexander Willner", "title": "An Architectural Design for Measurement Uncertainty Evaluation in\n  Cyber-Physical Systems", "comments": "accepted at FedCSIS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several use cases from the areas of manufacturing and process industry,\nrequire highly accurate sensor data. As sensors always have some degree of\nuncertainty, methods are needed to increase their reliability. The common\napproach is to regularly calibrate the devices to enable traceability according\nto national standards and Syst\\`eme international (SI) units - which follows\ncostly processes. However, sensor networks can also be represented as Cyber\nPhysical Systems (CPS) and a single sensor can have a digital representation\n(Digital Twin) to use its data further on. To propagate uncertainty in a\nreliable way in the network, we present a system architecture to communicate\nmeasurement uncertainties in sensor networks utilizing the concept of Asset\nAdministration Shells alongside methods from the domain of Organic Computing.\nThe presented approach contains methods for uncertainty propagation as well as\nconcepts from the Machine Learning domain that combine the need for an accurate\nuncertainty estimation. The mathematical description of the metrological\nuncertainty of fused or propagated values can be seen as a first step towards\nthe development of a harmonized approach for uncertainty in distributed CPSs in\nthe context of Industrie 4.0. In this paper, we present basic use cases,\nconceptual ideas and an agenda of how to proceed further on.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 13:12:24 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["von Pilchau", "Wenzel Pilar", ""], ["Gowtham", "Varun", ""], ["Gruber", "Maximilian", ""], ["Riedl", "Matthias", ""], ["Koutrakis", "Nikolaos-Stefanos", ""], ["Tayyub", "Jawad", ""], ["H\u00e4hner", "J\u00f6rg", ""], ["Eichst\u00e4dt", "Sascha", ""], ["Uhlmann", "Eckart", ""], ["Polte", "Julian", ""], ["Frey", "Volker", ""], ["Willner", "Alexander", ""]]}, {"id": "2008.07303", "submitter": "Philipp Geiger", "authors": "Philipp Geiger, Christoph-Nikolas Straehle", "title": "Learning game-theoretic models of multiagent trajectories using implicit\n  layers", "comments": "Accepted at AAAI-2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For prediction of interacting agents' trajectories, we propose an end-to-end\ntrainable architecture that hybridizes neural nets with game-theoretic\nreasoning, has interpretable intermediate representations, and transfers to\ndownstream decision making. It uses a net that reveals preferences from the\nagents' past joint trajectory, and a differentiable implicit layer that maps\nthese preferences to local Nash equilibria, forming the modes of the predicted\nfuture trajectory. Additionally, it learns an equilibrium refinement concept.\nFor tractability, we introduce a new class of continuous potential games and an\nequilibrium-separating partition of the action space. We provide theoretical\nresults for explicit gradients and soundness. In experiments, we evaluate our\napproach on two real-world data sets, where we predict highway driver merging\ntrajectories, and on a simple decision-making transfer task.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 13:34:12 GMT"}, {"version": "v2", "created": "Fri, 21 Aug 2020 15:09:02 GMT"}, {"version": "v3", "created": "Thu, 17 Sep 2020 14:43:04 GMT"}, {"version": "v4", "created": "Wed, 9 Dec 2020 21:07:22 GMT"}, {"version": "v5", "created": "Tue, 2 Feb 2021 14:16:44 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Geiger", "Philipp", ""], ["Straehle", "Christoph-Nikolas", ""]]}, {"id": "2008.07336", "submitter": "Stefano Picascia", "authors": "Jonatan Almagor, Stefano Picascia", "title": "Exploring the effectiveness of a COVID-19 contact tracing app using an\n  agent-based model", "comments": null, "journal-ref": null, "doi": "10.1038/s41598-020-79000-y", "report-no": null, "categories": "cs.CY cs.MA cs.SI physics.soc-ph q-bio.PE", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  A contact-tracing strategy has been deemed necessary to contain the spread of\nCOVID-19 following the relaxation of lockdown measures. Using an agent-based\nmodel, we explore one of the technology-based strategies proposed, a\ncontact-tracing smartphone app. The model simulates the spread of COVID-19 in a\npopulation of agents on an urban scale. Agents are heterogeneous in their\ncharacteristics and are linked in a multi-layered network representing the\nsocial structure - including households, friendships, employment and schools.\nWe explore the interplay of various adoption rates of the contact-tracing app,\ndifferent levels of testing capacity, and behavioural factors to assess the\nimpact on the epidemic. Results suggest that a contact tracing app can\ncontribute substantially to reducing infection rates in the population when\naccompanied by a sufficient testing capacity or when the testing policy\nprioritises symptomatic cases. As user rate increases, prevalence of infection\ndecreases. With that, when symptomatic cases are not prioritised for testing, a\nhigh rate of app users can generate an extensive increase in the demand for\ntesting, which, if not met with adequate supply, may render the app\ncounterproductive. This points to the crucial role of an efficient testing\npolicy and the necessity to upscale testing capacity.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2020 16:58:17 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2020 17:02:04 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Almagor", "Jonatan", ""], ["Picascia", "Stefano", ""]]}, {"id": "2008.07428", "submitter": "Usman Khan", "authors": "Ran Xin and Usman A. Khan and Soummya Kar", "title": "Fast decentralized non-convex finite-sum optimization with recursive\n  variance reduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.MA cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers decentralized minimization of $N:=nm$ smooth non-convex\ncost functions equally divided over a directed network of $n$ nodes.\nSpecifically, we describe a stochastic first-order gradient method, called\nGT-SARAH, that employs a SARAH-type variance reduction technique and gradient\ntracking (GT) to address the stochastic and decentralized nature of the\nproblem. We show that GT-SARAH, with appropriate algorithmic parameters, finds\nan $\\epsilon$-accurate first-order stationary point with\n$O\\big(\\max\\big\\{N^{\\frac{1}{2}},n(1-\\lambda)^{-2},n^{\\frac{2}{3}}m^{\\frac{1}{3}}(1-\\lambda)^{-1}\\big\\}L\\epsilon^{-2}\\big)$\ngradient complexity, where ${(1-\\lambda)\\in(0,1]}$ is the spectral gap of the\nnetwork weight matrix and $L$ is the smoothness parameter of the cost\nfunctions. This gradient complexity outperforms that of the existing\ndecentralized stochastic gradient methods. In particular, in a big-data regime\nsuch that ${n = O(N^{\\frac{1}{2}}(1-\\lambda)^{3})}$, this gradient complexity\nfurthers reduces to ${O(N^{\\frac{1}{2}}L\\epsilon^{-2})}$, independent of the\nnetwork topology, and matches that of the centralized near-optimal\nvariance-reduced methods. Moreover, in this regime GT-SARAH achieves a\nnon-asymptotic linear speedup, in that, the total number of gradient\ncomputations at each node is reduced by a factor of $1/n$ compared to the\ncentralized near-optimal algorithms that perform all gradient computations at a\nsingle node. To the best of our knowledge, GT-SARAH is the first algorithm that\nachieves this property. In addition, we show that appropriate choices of local\nminibatch size balance the trade-offs between the gradient and communication\ncomplexity of GT-SARAH. Over infinite time horizon, we establish that all nodes\nin GT-SARAH asymptotically achieve consensus and converge to a first-order\nstationary point in the almost sure and mean-squared sense.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 15:51:32 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2020 19:07:13 GMT"}, {"version": "v3", "created": "Sat, 29 Aug 2020 01:54:21 GMT"}, {"version": "v4", "created": "Tue, 15 Sep 2020 16:19:01 GMT"}, {"version": "v5", "created": "Tue, 15 Jun 2021 03:10:16 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Xin", "Ran", ""], ["Khan", "Usman A.", ""], ["Kar", "Soummya", ""]]}, {"id": "2008.07455", "submitter": "Michail Theofilatos", "authors": "Othon Michail, Paul G. Spirakis, Michail Theofilatos", "title": "Gathering in 1-Interval Connected Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine the problem of gathering $k \\geq 2$ agents (or multi-agent\nrendezvous) in dynamic graphs which may change in every synchronous round but\nremain always connected ($1$-interval connectivity) [KLO10]. The agents are\nidentical and without explicit communication capabilities, and are initially\npositioned at different nodes of the graph. The problem is for the agents to\ngather at the same node, not fixed in advance. We first show that the problem\nbecomes impossible to solve if the graph has a cycle. In light of this, we\nstudy a relaxed version of this problem, called weak gathering. We show that\nonly in unicyclic graphs weak gathering is solvable, and we provide a\ndeterministic algorithm for this problem that runs in polynomial number of\nrounds.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 16:28:36 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Michail", "Othon", ""], ["Spirakis", "Paul G.", ""], ["Theofilatos", "Michail", ""]]}, {"id": "2008.07698", "submitter": "Siddharth Ghiya", "authors": "Siddharth Ghiya, Katia Sycara", "title": "Learning Complex Multi-Agent Policies in Presence of an Adversary", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, there has been some outstanding work on applying deep\nreinforcement learning to multi-agent settings. Often in such multi-agent\nscenarios, adversaries can be present. We address the requirements of such a\nsetting by implementing a graph-based multi-agent deep reinforcement learning\nalgorithm. In this work, we consider the scenario of multi-agent deception in\nwhich multiple agents need to learn to cooperate and communicate in order to\ndeceive an adversary. We have employed a two-stage learning process to get the\ncooperating agents to learn such deceptive behaviors. Our experiments show that\nour approach allows us to employ curriculum learning to increase the number of\ncooperating agents in the environment and enables a team of agents to learn\ncomplex behaviors to successfully deceive an adversary.\n  Keywords: Multi-agent system, Graph neural network, Reinforcement learning\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 02:09:11 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2020 01:25:13 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Ghiya", "Siddharth", ""], ["Sycara", "Katia", ""]]}, {"id": "2008.07871", "submitter": "Peter Belc\\'ak", "authors": "Peter Belcak, Jan-Peter Calliess, Stefan Zohren", "title": "Fast Agent-Based Simulation Framework of Limit Order Books with\n  Applications to Pro-Rata Markets and the Study of Latency Effects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP cs.MA q-fin.TR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new software toolbox, called Multi-Agent eXchange Environment\n(MAXE), for agent-based simulation of limit order books. Offering both\nefficient C++ implementations and Python APIs, it allows the user to simulate\nlarge-scale agent-based market models while providing user-friendliness for\nrapid prototyping. Furthermore, it benefits from a versatile message-driven\narchitecture that offers the flexibility to simulate a range of different\n(easily customisable) market rules and to study the effect of auxiliary\nfactors, such as delays, on the market dynamics.\n  Showcasing its utility for research, we employ our simulator to investigate\nthe influence the choice of the matching algorithm has on the behaviour of\nartificial trader agents in a zero-intelligence model. In addition, we\ninvestigate the role of the order processing delay in normal trading on an\nexchange and in the scenario of a significant price change. Our results include\nthe findings that (i) the variance of the bid-ask spread exhibits a behavior\nsimilar to resonance of a damped harmonic oscillator with respect to the\nprocessing delay and that (ii) the delay markedly affects the impact a large\ntrade has on the limit order book.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 11:37:34 GMT"}, {"version": "v2", "created": "Tue, 25 Aug 2020 10:55:40 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Belcak", "Peter", ""], ["Calliess", "Jan-Peter", ""], ["Zohren", "Stefan", ""]]}, {"id": "2008.08063", "submitter": "Xinshuo Weng", "authors": "Xinshuo Weng, Jianren Wang, David Held, Kris Kitani", "title": "AB3DMOT: A Baseline for 3D Multi-Object Tracking and New Evaluation\n  Metrics", "comments": "Extended abstract that will be presented at ECCV 2020 Workshops.\n  Project website: http://www.xinshuoweng.com/projects/AB3DMOT", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  3D multi-object tracking (MOT) is essential to applications such as\nautonomous driving. Recent work focuses on developing accurate systems giving\nless attention to computational cost and system complexity. In contrast, this\nwork proposes a simple real-time 3D MOT system with strong performance. Our\nsystem first obtains 3D detections from a LiDAR point cloud. Then, a\nstraightforward combination of a 3D Kalman filter and the Hungarian algorithm\nis used for state estimation and data association. Additionally, 3D MOT\ndatasets such as KITTI evaluate MOT methods in 2D space and standardized 3D MOT\nevaluation tools are missing for a fair comparison of 3D MOT methods. We\npropose a new 3D MOT evaluation tool along with three new metrics to\ncomprehensively evaluate 3D MOT methods. We show that, our proposed method\nachieves strong 3D MOT performance on KITTI and runs at a rate of $207.4$ FPS\non the KITTI dataset, achieving the fastest speed among modern 3D MOT systems.\nOur code is publicly available at http://www.xinshuoweng.com/projects/AB3DMOT.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 17:45:56 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Weng", "Xinshuo", ""], ["Wang", "Jianren", ""], ["Held", "David", ""], ["Kitani", "Kris", ""]]}, {"id": "2008.08412", "submitter": "Saar Tochner", "authors": "Maya Dotan, Yvonne-Anne Pignolet, Stefan Schmid, Saar Tochner and Aviv\n  Zohar", "title": "Survey on Cryptocurrency Networking: Context, State-of-the-Art,\n  Challenges", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cryptocurrencies such as Bitcoin are realized using distributed systems and\nhence critically rely on the performance and security of the interconnecting\nnetwork. The requirements on these networks and their usage, however can differ\nsignificantly from traditional communication networks, with implications on all\nlayers of the protocol stack. This paper is motivated by these differences, and\nin particular by the observation that many fundamental design aspects of these\nnetworks are not well-understood today. In order to support the networking\ncommunity to contribute to this emerging application domain, we present a\nstructured overview of the field, from topology and neighbor discovery to block\nand transaction propagation. In particular, we provide the context,\nhighlighting differences and commonalities with traditional networks, review\nthe state-of-the-art, and identify open research challenges. Our paper can\nhence also be seen as a call-to-arms to improve the foundation on top of which\ncryptocurrencies are built.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 13:02:37 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Dotan", "Maya", ""], ["Pignolet", "Yvonne-Anne", ""], ["Schmid", "Stefan", ""], ["Tochner", "Saar", ""], ["Zohar", "Aviv", ""]]}, {"id": "2008.08451", "submitter": "Wesley Holliday", "authors": "Wesley H. Holliday and Eric Pacuit", "title": "Axioms for Defeat in Democratic Elections", "comments": "41 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.TH cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose six axioms concerning when one candidate should defeat another in\na democratic election involving two or more candidates. Five of the axioms are\nwidely satisfied by known voting procedures. The sixth axiom is a weakening of\nKenneth Arrow's famous condition of the Independence of Irrelevant Alternatives\n(IIA). We call this weakening Coherent IIA. We prove that the five axioms plus\nCoherent IIA single out a voting procedure studied in our recent work: Split\nCycle. In particular, Split Cycle is the most resolute voting procedure\nsatisfying the six axioms for democratic defeat. In addition, we analyze how\nSplit Cycle escapes Arrow's Impossibility Theorem and related impossibility\nresults.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 21:43:51 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Holliday", "Wesley H.", ""], ["Pacuit", "Eric", ""]]}, {"id": "2008.08849", "submitter": "Robin Engelhardt", "authors": "Thomas Bolander, Robin Engelhardt, Thomas S. Nicolet", "title": "The Curse of Shared Knowledge: Recursive Belief Reasoning in a\n  Coordination Game with Imperfect Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.GT cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Common knowledge is a necessary condition for safe group coordination. When\ncommon knowledge can not be obtained, humans routinely use their ability to\nattribute beliefs and intentions in order to infer what is known. But such\nshared knowledge attributions are limited in depth and therefore prone to\ncoordination failures, because any finite-order knowledge attribution allows\nfor an even higher order attribution that may change what is known by whom. In\nthree separate experiments we investigate to which degree human participants\n(N=802) are able to recognize the difference between common knowledge and\nnth-order shared knowledge. We use a new two-person coordination game with\nimperfect information that is able to cast the recursive game structure and\nhigher-order uncertainties into a simple, everyday-like setting. Our results\nshow that participants have a very hard time accepting the fact that common\nknowledge is not reducible to shared knowledge. Instead, participants try to\ncoordinate even at the shallowest depths of shared knowledge and in spite of\nhuge payoff penalties.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 09:22:08 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Bolander", "Thomas", ""], ["Engelhardt", "Robin", ""], ["Nicolet", "Thomas S.", ""]]}, {"id": "2008.08937", "submitter": "Christopher Frantz", "authors": "Christopher K. Frantz and Saba N. Siddiki", "title": "Institutional Grammar 2.0 Codebook", "comments": "120 pages, 16 figures, 14 tables", "journal-ref": null, "doi": "10.1111/padm.12719", "report-no": "IG-001", "categories": "cs.MA cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Grammar of Institutions, or Institutional Grammar, is an established\napproach to encode policy information in terms of institutional statements\nbased on a set of pre-defined syntactic components. This codebook provides\ncoding guidelines for a revised version of the Institutional Grammar, the\nInstitutional Grammar 2.0 (IG 2.0). IG 2.0 is a specification that aims at\nfacilitating the encoding of policy to meet varying analytical objectives. To\nthis end, it revises the grammar with respect to comprehensiveness,\nflexibility, and specificity by offering multiple levels of expressiveness (IG\nCore, IG Extended, IG Logico). In addition to the encoding of regulative\nstatements, it further introduces the encoding of constitutive institutional\nstatements, as well as statements that exhibit both constitutive and regulative\ncharacteristics. Introducing those aspects, the codebook initially covers\nfundamental concepts of IG 2.0, before providing an overview of pre-coding\nsteps relevant for document preparation. Detailed coding guidelines are\nprovided for both regulative and constitutive statements across all levels of\nexpressiveness, along with the encoding guidelines for statements of mixed form\n-- hybrid and polymorphic institutional statements. The document further\nprovides an overview of taxonomies used in the encoding process and referred to\nthroughout the codebook. The codebook concludes with a summary and discussion\nof relevant considerations to facilitate the coding process. An initial\nReader's Guide helps the reader tailor the content to her interest.\n  Note that this codebook specifically focuses on operational aspects of IG 2.0\nin the context of policy coding. Links to additional resources such as the\nunderlying scientific literature (that offers a comprehensive treatment of the\nunderlying theoretical concepts) are referred to in the concluding section of\nthe codebook.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 12:38:55 GMT"}, {"version": "v2", "created": "Sun, 6 Dec 2020 21:15:52 GMT"}, {"version": "v3", "created": "Mon, 21 Jun 2021 13:12:00 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Frantz", "Christopher K.", ""], ["Siddiki", "Saba N.", ""]]}, {"id": "2008.09369", "submitter": "Xu He", "authors": "Xu He, Bo An, Yanghua Li, Haikai Chen, Rundong Wang, Xinrun Wang,\n  Runsheng Yu, Xin Li, and Zhirong Wang", "title": "Learning to Collaborate in Multi-Module Recommendation via Multi-Agent\n  Reinforcement Learning without Communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rise of online e-commerce platforms, more and more customers prefer\nto shop online. To sell more products, online platforms introduce various\nmodules to recommend items with different properties such as huge discounts. A\nweb page often consists of different independent modules. The ranking policies\nof these modules are decided by different teams and optimized individually\nwithout cooperation, which might result in competition between modules. Thus,\nthe global policy of the whole page could be sub-optimal. In this paper, we\npropose a novel multi-agent cooperative reinforcement learning approach with\nthe restriction that different modules cannot communicate. Our contributions\nare three-fold. Firstly, inspired by a solution concept in game theory named\ncorrelated equilibrium, we design a signal network to promote cooperation of\nall modules by generating signals (vectors) for different modules. Secondly, an\nentropy-regularized version of the signal network is proposed to coordinate\nagents' exploration of the optimal global policy. Furthermore, experiments\nbased on real-world e-commerce data demonstrate that our algorithm obtains\nsuperior performance over baselines.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 08:23:33 GMT"}, {"version": "v2", "created": "Sat, 29 Aug 2020 10:34:58 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["He", "Xu", ""], ["An", "Bo", ""], ["Li", "Yanghua", ""], ["Chen", "Haikai", ""], ["Wang", "Rundong", ""], ["Wang", "Xinrun", ""], ["Yu", "Runsheng", ""], ["Li", "Xin", ""], ["Wang", "Zhirong", ""]]}, {"id": "2008.09461", "submitter": "Jose Fontanari", "authors": "Peter Hardy, Leandro Soriano Marcolino and Jos\\'e F. Fontanari", "title": "The paradox of productivity during quarantine: an agent-based simulation", "comments": null, "journal-ref": "Eur. Phys. J. B (2021) 94: 40", "doi": "10.1140/epjb/s10051-020-00016-4", "report-no": null, "categories": "cs.MA physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Economies across the globe were brought to their knees due to lockdowns and\nsocial restriction measures to contain the spread of the SARS-CoV-2, despite\nthe quick switch to remote working. This downfall may be partially explained by\nthe \"water cooler effect\", which holds that higher levels of social interaction\nlead to higher productivity due to a boost in people's mood. Somewhat\nparadoxically, however, there are reports of increased productivity in the\nremote working scenario. Here we address quantitatively this issue using a\nvariety of experimental findings of social psychology that address the\ninterplay between mood, social interaction and productivity to set forth an\nagent-based model for a workplace composed of extrovert and introvert agent\nstereotypes that differ solely on their propensities to initiate a social\ninteraction. We find that the effects of curtailing social interactions depend\non the proportion of the stereotypes in the working group: while the social\nrestriction measures always have a negative impact on the productivity of\ngroups composed predominantly of introverts, they may actually improve the\nproductivity of groups composed predominantly of extroverts. Our results offer\na proof of concept that the paradox of productivity during quarantine can be\nexplained by taking into account the distinct effects of the social distancing\nmeasures on extroverts and introverts.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 13:16:42 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2020 18:24:21 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Hardy", "Peter", ""], ["Marcolino", "Leandro Soriano", ""], ["Fontanari", "Jos\u00e9 F.", ""]]}, {"id": "2008.09506", "submitter": "Xinshuo Weng", "authors": "Xinshuo Weng, Yongxin Wang, Yunze Man, and Kris Kitani", "title": "Graph Neural Networks for 3D Multi-Object Tracking", "comments": "ECCV 2020 workshop paper. Project website:\n  http://www.xinshuoweng.com/projects/GNN3DMOT. arXiv admin note: substantial\n  text overlap with arXiv:2006.07327", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MA cs.MM cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  3D Multi-object tracking (MOT) is crucial to autonomous systems. Recent work\noften uses a tracking-by-detection pipeline, where the feature of each object\nis extracted independently to compute an affinity matrix. Then, the affinity\nmatrix is passed to the Hungarian algorithm for data association. A key process\nof this pipeline is to learn discriminative features for different objects in\norder to reduce confusion during data association. To that end, we propose two\ninnovative techniques: (1) instead of obtaining the features for each object\nindependently, we propose a novel feature interaction mechanism by introducing\nGraph Neural Networks; (2) instead of obtaining the features from either 2D or\n3D space as in prior work, we propose a novel joint feature extractor to learn\nappearance and motion features from 2D and 3D space. Through experiments on the\nKITTI dataset, our proposed method achieves state-of-the-art 3D MOT\nperformance. Our project website is at\nhttp://www.xinshuoweng.com/projects/GNN3DMOT.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 17:55:41 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Weng", "Xinshuo", ""], ["Wang", "Yongxin", ""], ["Man", "Yunze", ""], ["Kitani", "Kris", ""]]}, {"id": "2008.09521", "submitter": "Olivier Rousselle", "authors": "Olivier Rousselle", "title": "Evaluation of the cumulated impacts on the marine resource of a\n  socio-ecological coral system: approach by agent-based modeling", "comments": "in French, Thesis CNRS (French National Centre for Scientific\n  Research) - CRIOBE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.CE physics.ao-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of climate change and significant changes in human activities\naround the world, coral reefs are subject to many disruptions. We develop here\na tool to help decision-making in Moorea (French Polynesia), based on\nmulti-agent modeling. We model the trophic interactions with a Lotka-Volterra\nmodel, and also the interactions between fishermen, trophic groups and tourist\noperators. The results are generated through global, temporal (time series),\nand spatial (GIS maps) outputs. The model produced here can be transposed to\nother ecological and economic situations, and other geographical areas, by\nmodifying the parameters and changing the input map data.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 14:51:14 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Rousselle", "Olivier", ""]]}, {"id": "2008.09575", "submitter": "Vipul Mann", "authors": "Vipul Mann, Abhishek Sivaram, Laya Das, Venkat Venkatasubramanian", "title": "Robust and Efficient Swarm Communication Topologies for Hostile\n  Environments", "comments": null, "journal-ref": null, "doi": "10.1016/j.swevo.2021.100848", "report-no": null, "categories": "cs.NE cs.MA cs.SI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Swarm Intelligence-based optimization techniques combine systematic\nexploration of the search space with information available from neighbors and\nrely strongly on communication among agents. These algorithms are typically\nemployed to solve problems where the function landscape is not adequately known\nand there are multiple local optima that could result in premature convergence\nfor other algorithms. Applications of such algorithms can be found in\ncommunication systems involving design of networks for efficient information\ndissemination to a target group, targeted drug-delivery where drug molecules\nsearch for the affected site before diffusing, and high-value target\nlocalization with a network of drones. In several of such applications, the\nagents face a hostile environment that can result in loss of agents during the\nsearch. Such a loss changes the communication topology of the agents and hence\nthe information available to agents, ultimately influencing the performance of\nthe algorithm. In this paper, we present a study of the impact of loss of\nagents on the performance of such algorithms as a function of the initial\nnetwork configuration. We use particle swarm optimization to optimize an\nobjective function with multiple sub-optimal regions in a hostile environment\nand study its performance for a range of network topologies with loss of\nagents. The results reveal interesting trade-offs between efficiency,\nrobustness, and performance for different topologies that are subsequently\nleveraged to discover general properties of networks that maximize performance.\nMoreover, networks with small-world properties are seen to maximize performance\nunder hostile conditions.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 16:38:35 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Mann", "Vipul", ""], ["Sivaram", "Abhishek", ""], ["Das", "Laya", ""], ["Venkatasubramanian", "Venkat", ""]]}, {"id": "2008.10423", "submitter": "Frank Schweitzer", "authors": "Pavlin Mavrodiev, Frank Schweitzer", "title": "Enhanced or distorted wisdom of crowds? An agent-based model of opinion\n  formation under social influence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.MA nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an agent-based model of collective opinion formation to study the\nwisdom of crowds under social influence. The opinion of an agent is a\ncontinuous positive value, denoting its subjective answer to a factual\nquestion. The wisdom of crowds states that the average of all opinions is close\nto the truth, i.e. the correct answer. But if agents have the chance to adjust\ntheir opinion in response to the opinions of others, this effect can be\ndestroyed. Our model investigates this scenario by evaluating two competing\neffects: (i) agents tend to keep their own opinion (individual conviction\n$\\beta$), (ii) they tend to adjust their opinion if they have information about\nthe opinions of others (social influence $\\alpha$). For the latter, two\ndifferent regimes (full information vs. aggregated information) are compared.\nOur simulations show that social influence only in rare cases enhances the\nwisdom of crowds. Most often, we find that agents converge to a collective\nopinion that is even farther away from the true answer. So, under social\ninfluence the wisdom of crowds can be systematically wrong.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 13:23:11 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Mavrodiev", "Pavlin", ""], ["Schweitzer", "Frank", ""]]}, {"id": "2008.10782", "submitter": "A H M Jakaria", "authors": "A H M Jakaria, Mohammad Ashiqur Rahman, Matthew Anderson, Steven\n  Drager", "title": "Automated Trajectory Synthesis for UAV Swarms Based on Resilient Data\n  Collection Objectives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.MA eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of Unmanned Aerial Vehicles (UAVs) for collecting data from remotely\nlocated sensor systems is emerging. The data can be time-sensitive and require\nto be transmitted to a data processing center. However, planning the trajectory\nof a collaborative UAV swarm depends on multi-fold constraints, such as data\ncollection requirements, UAV maneuvering capacity, and budget limitation. Since\na UAV may fail or be compromised, it is important to provide necessary\nresilience to such contingencies, thus ensuring data security. It is important\nto provide the UAVs with efficient spatio-temporal trajectories so that they\ncan efficiently cover necessary data sources. In this work, we present\nSynth4UAV, a formal approach for automated synthesis of efficient trajectories\nfor a UAV swarm by logically modeling the aerial space and data point topology,\nUAV moves, and associated constraints in terms of the turning and climbing\nangle, fuel usage, data collection point coverage, data freshness, and\nresiliency properties. We use efficient, logical formulas to encode and solve\nthe complex model. The solution to the model provides the routing and\nmaneuvering plan for each UAV, including the time to visit the points on the\npaths and corresponding fuel usage such that the necessary data points are\nvisited while satisfying the resiliency requirements. We evaluate the proposed\ntrajectory synthesizer, and the results show that the relationship among\ndifferent parameters follow the requirements while the tool scales well with\nthe problem size.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 02:05:19 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Jakaria", "A H M", ""], ["Rahman", "Mohammad Ashiqur", ""], ["Anderson", "Matthew", ""], ["Drager", "Steven", ""]]}, {"id": "2008.11350", "submitter": "Maythem Abbas", "authors": "Maythem K. Abbas, Mohd Noh Karsiti, Madzlan Napiah, Samir Brahim", "title": "Integrated Self-Organized Traffic Light Controllers for Signalized\n  Intersections", "comments": null, "journal-ref": "International Review of Automatic Control 2013", "doi": null, "report-no": null, "categories": "cs.MA cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting emergency vehicles arrival on roads has been the focus for many\nresearchers. It is quite important to detect the emergency vehicles (e.g;\nambulance) arrival to traffic light to give the green light for it to pass\nthrough. Many researchers have suggested and patented emergency vehicles\ndetection systems however, according to our knowledge, none of them considered\nsolving the effect of giving extra green time to a road while the queues are\nbeing built on others. This paper considers the problem of finding a better\ntraffic light phase plan to stabilize/recover the situation at an effected\nintersection after solving an emergency vehicle existence. A hardware setup and\na novel messaging protocol have been suggested to be set on roads and vehicles\nto collect roads real time data. In addition, a novel decision making protocol\nhas been created to make the use of the collected data for making a better\ntraffic light phase plan for an intersection. The phase plan has two main\ndecisions to be made; which light has a higher priority to be green in the next\nphase, and how long the green phase should be. After simulating the proposed\nsystem using our customized simulator written in Matlab programing language and\ncomparing its performance with other related works, significant enhancements\nhave been observed in terms of stabilizing the queue lengths at an intersection\nafter solving an emergency case.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 02:41:46 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Abbas", "Maythem K.", ""], ["Karsiti", "Mohd Noh", ""], ["Napiah", "Madzlan", ""], ["Brahim", "Samir", ""]]}, {"id": "2008.11598", "submitter": "Xinshuo Weng", "authors": "Xinshuo Weng, Ye Yuan, Kris Kitani", "title": "End-to-End 3D Multi-Object Tracking and Trajectory Forecasting", "comments": "Extended abstract. The first two authors contributed equally. Project\n  website: http://www.xinshuoweng.com/projects/GNNTrkForecast. arXiv admin\n  note: substantial text overlap with arXiv:2003.07847", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  3D multi-object tracking (MOT) and trajectory forecasting are two critical\ncomponents in modern 3D perception systems. We hypothesize that it is\nbeneficial to unify both tasks under one framework to learn a shared feature\nrepresentation of agent interaction. To evaluate this hypothesis, we propose a\nunified solution for 3D MOT and trajectory forecasting which also incorporates\ntwo additional novel computational units. First, we employ a feature\ninteraction technique by introducing Graph Neural Networks (GNNs) to capture\nthe way in which multiple agents interact with one another. The GNN is able to\nmodel complex hierarchical interactions, improve the discriminative feature\nlearning for MOT association, and provide socially-aware context for trajectory\nforecasting. Second, we use a diversity sampling function to improve the\nquality and diversity of our forecasted trajectories. The learned sampling\nfunction is trained to efficiently extract a variety of outcomes from a\ngenerative trajectory distribution and helps avoid the problem of generating\nmany duplicate trajectory samples. We show that our method achieves\nstate-of-the-art performance on the KITTI dataset. Our project website is at\nhttp://www.xinshuoweng.com/projects/GNNTrkForecast.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 16:54:46 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Weng", "Xinshuo", ""], ["Yuan", "Ye", ""], ["Kitani", "Kris", ""]]}, {"id": "2008.11791", "submitter": "David Maoujoud", "authors": "David Maoujoud and Gavin Rens", "title": "Reputation-driven Decision-making in Networks of Stochastic Agents", "comments": "19 pages, including bibliography", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies multi-agent systems that involve networks of\nself-interested agents. We propose a Markov Decision Process-derived framework,\ncalled RepNet-MDP, tailored to domains in which agent reputation is a key\ndriver of the interactions between agents. The fundamentals are based on the\nprinciples of RepNet-POMDP, a framework developed by Rens et al. in 2018, but\naddresses its mathematical inconsistencies and alleviates its intractability by\nonly considering fully observable environments. We furthermore use an online\nlearning algorithm for finding approximate solutions to RepNet-MDPs. In a\nseries of experiments, RepNet agents are shown to be able to adapt their own\nbehavior to the past behavior and reliability of the remaining agents of the\nnetwork. Finally, our work identifies a limitation of the framework in its\ncurrent formulation that prevents its agents from learning in circumstances in\nwhich they are not a primary actor.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 20:21:04 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 07:57:32 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Maoujoud", "David", ""], ["Rens", "Gavin", ""]]}, {"id": "2008.11803", "submitter": "Abdullah Yousafzai", "authors": "Abdullah Yousafzai and Choong Seon Hong", "title": "SmartSON:A Smart contract driven incentive management framework for\n  Self-Organizing Networks", "comments": "Incentive Management Framework for Self Organizing Networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.MA cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article proposes a self-organizing collaborative computing network with\nan approach to enhance the expectation of a collaborating node for joining the\nself-organizing network. The proposed approach relies on Ethereum\ncryptocurrency and Smart Contract to enhance the expectation of collaborating\nnodes by monetizing the services provided to the self-organizing network.\nFurthermore, an escrow based smart contract is formalized in the proposed\nframework to sustains the monetary trust issue between collaborating nodes. The\nproposed scheme can enforce an autonomic incentive management mechanism to any\ntype of self-organizing networks such as self-organizing clouds, ad-hoc\nnetworks, self-organizing federated cloud networks, self-organizing federated\nlearning networks, and self-organizing D2D networks to name a few. Considering\nthe distributed nature of these self-organizing networks and the Ethereum\nblockchain network, a distributed agent-based methodology is materialized in\nthe proposed framework. Following this, a proof of concept implementation for\nthe general case of a self-organizing cloud is presented. Lastly, the article\nprovides some insights into possible future directions using the proposed\nframework.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 20:41:22 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Yousafzai", "Abdullah", ""], ["Hong", "Choong Seon", ""]]}, {"id": "2008.11925", "submitter": "Allan Dos Santos Costa", "authors": "Allan Costa, Benjamin Jenett, Irina Kostitsyna, Amira Abdel-Rahman,\n  Neil Gershenfeld, Kenneth Cheung", "title": "Algorithmic Approaches to Reconfigurable Assembly Systems", "comments": null, "journal-ref": null, "doi": "10.1109/AERO.2019.8741572", "report-no": null, "categories": "cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Assembly of large scale structural systems in space is understood as critical\nto serving applications that cannot be deployed from a single launch. Recent\nliterature proposes the use of discrete modular structures for in-space\nassembly and relatively small scale robotics that are able to modify and\ntraverse the structure. This paper addresses the algorithmic problems in\nscaling reconfigurable space structures built through robotic construction,\nwhere reconfiguration is defined as the problem of transforming an initial\nstructure into a different goal configuration. We analyze different algorithmic\nparadigms and present corresponding abstractions and graph formulations,\nexamining specialized algorithms that consider discretized space and time\nsteps. We then discuss fundamental design trades for different computational\narchitectures, such as centralized versus distributed, and present two\nrepresentative algorithms as concrete examples for comparison. We analyze how\nthose algorithms achieve different objective functions and goals, such as\nminimization of total distance traveled, maximization of fault-tolerance, or\nminimization of total time spent in assembly. This is meant to offer an\nimpression of algorithmic constraints on scalability of corresponding\nstructural and robotic design. From this study, a set of recommendations is\ndeveloped on where and when to use each paradigm, as well as implications for\nphysical robotic and structural system design.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 05:57:32 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Costa", "Allan", ""], ["Jenett", "Benjamin", ""], ["Kostitsyna", "Irina", ""], ["Abdel-Rahman", "Amira", ""], ["Gershenfeld", "Neil", ""], ["Cheung", "Kenneth", ""]]}, {"id": "2008.11958", "submitter": "Setareh Maghsudi", "authors": "Setareh Maghsudi and Max Davy", "title": "Computational Models of Human Decision-Making with Application to the\n  Internet of Everything", "comments": null, "journal-ref": null, "doi": "10.1109/MWC.001.2000250", "report-no": null, "categories": "cs.MA cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The concept of the Internet of Things (IoT) first appeared a few decades ago.\nToday, by the ubiquitous wireless connectivity, the boost of machine learning\nand artificial intelligence, and the advances in big data analytics, it is safe\nto say that IoT has evolved to a new concept called the Internet of Everything\n(IoE) or the Internet of All. IoE has four pillars: Things, human, data, and\nprocesses, which render it as an inhomogeneous large-scale network. A crucial\nchallenge of such a network is to develop management, analysis, and\noptimization policies that besides utility-maximizer machines, also take\nirrational humans into account. We discuss several networking applications in\nwhich appropriate modeling of human decision-making is vital. We then provide a\nbrief review of computational models of human decision-making. Based on one\nsuch model, we develop a solution for a task offloading problem in fog\ncomputing and we analyze the implications of including humans in the loop.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 07:21:47 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Maghsudi", "Setareh", ""], ["Davy", "Max", ""]]}, {"id": "2008.12610", "submitter": "Jorge Pe\\~na Queralta", "authors": "Jorge Pe\\~na Queralta, Jussi Taipalmaa, Bilge Can Pullinen, Victor\n  Kathan Sarker, Tuan Nguyen Gia, Hannu Tenhunen, Moncef Gabbouj, Jenni\n  Raitoharju, Tomi Westerlund", "title": "Collaborative Multi-Robot Systems for Search and Rescue: Coordination\n  and Perception", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous or teleoperated robots have been playing increasingly important\nroles in civil applications in recent years. Across the different civil domains\nwhere robots can support human operators, one of the areas where they can have\nmore impact is in search and rescue (SAR) operations. In particular,\nmulti-robot systems have the potential to significantly improve the efficiency\nof SAR personnel with faster search of victims, initial assessment and mapping\nof the environment, real-time monitoring and surveillance of SAR operations, or\nestablishing emergency communication networks, among other possibilities. SAR\noperations encompass a wide variety of environments and situations, and\ntherefore heterogeneous and collaborative multi-robot systems can provide the\nmost advantages. In this paper, we review and analyze the existing approaches\nto multi-robot SAR support, from an algorithmic perspective and putting an\nemphasis on the methods enabling collaboration among the robots as well as\nadvanced perception through machine vision and multi-agent active perception.\nFurthermore, we put these algorithms in the context of the different challenges\nand constraints that various types of robots (ground, aerial, surface or\nunderwater) encounter in different SAR environments (maritime, urban,\nwilderness or other post-disaster scenarios). This is, to the best of our\nknowledge, the first review considering heterogeneous SAR robots across\ndifferent environments, while giving two complimentary points of view: control\nmechanisms and machine perception. Based on our review of the state-of-the-art,\nwe discuss the main open research questions, and outline our insights on the\ncurrent approaches that have potential to improve the real-world performance of\nmulti-robot SAR systems.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 12:28:32 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Queralta", "Jorge Pe\u00f1a", ""], ["Taipalmaa", "Jussi", ""], ["Pullinen", "Bilge Can", ""], ["Sarker", "Victor Kathan", ""], ["Gia", "Tuan Nguyen", ""], ["Tenhunen", "Hannu", ""], ["Gabbouj", "Moncef", ""], ["Raitoharju", "Jenni", ""], ["Westerlund", "Tomi", ""]]}, {"id": "2008.12708", "submitter": "Hung Nguyen", "authors": "Hung The Nguyen, Matthew Garratt, Lam Thu Bui, and Hussein Abbass", "title": "Disturbances in Influence of a Shepherding Agent is More Impactful than\n  Sensorial Noise During Swarm Guidance", "comments": null, "journal-ref": null, "doi": "10.1109/MCI.2020.2998307", "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The guidance of a large swarm is a challenging control problem. Shepherding\noffers one approach to guide a large swarm using a few shepherding agents\n(sheepdogs). While noise is an inherent characteristic in many real-world\nproblems, the impact of noise on shepherding is not a well-studied problem. We\nstudy two forms of noise. First, we evaluate noise in the sensorial information\nreceived by the shepherd about the location of sheep. Second, we evaluate noise\nin the ability of the sheepdog to influence sheep due to disturbance forces\noccurring during actuation. We study both types of noise in this paper, and\ninvestigate the performance of Str\\\"{o}mbom's approach under these actuation\nand perception noises. To ensure that the parameterisation of the algorithm\ncreates a stable performance, we need to run a large number of simulations,\nwhile increasing the number of random episodes until stability is achieved. We\nthen systematically study the impact of sensorial and actuation noise on\nperformance. Str\\\"{o}mbom's approach is found to be more sensitive to actuation\nnoise than perception noise. This implies that it is more important for the\nshepherding agent to influence the sheep more accurately by reducing actuation\nnoise than attempting to reduce noise in its sensors. Moreover, different\nlevels of noise required different parameterisation for the shepherding agent,\nwhere the threshold needed by an agent to decide whether or not to collect\nastray sheep is different for different noise levels.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 15:40:40 GMT"}, {"version": "v2", "created": "Sat, 3 Oct 2020 05:33:03 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Nguyen", "Hung The", ""], ["Garratt", "Matthew", ""], ["Bui", "Lam Thu", ""], ["Abbass", "Hussein", ""]]}, {"id": "2008.12760", "submitter": "Roozbeh Mottaghi", "authors": "Luca Weihs, Jordi Salvador, Klemen Kotar, Unnat Jain, Kuo-Hao Zeng,\n  Roozbeh Mottaghi, Aniruddha Kembhavi", "title": "AllenAct: A Framework for Embodied AI Research", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The domain of Embodied AI, in which agents learn to complete tasks through\ninteraction with their environment from egocentric observations, has\nexperienced substantial growth with the advent of deep reinforcement learning\nand increased interest from the computer vision, NLP, and robotics communities.\nThis growth has been facilitated by the creation of a large number of simulated\nenvironments (such as AI2-THOR, Habitat and CARLA), tasks (like point\nnavigation, instruction following, and embodied question answering), and\nassociated leaderboards. While this diversity has been beneficial and organic,\nit has also fragmented the community: a huge amount of effort is required to do\nsomething as simple as taking a model trained in one environment and testing it\nin another. This discourages good science. We introduce AllenAct, a modular and\nflexible learning framework designed with a focus on the unique requirements of\nEmbodied AI research. AllenAct provides first-class support for a growing\ncollection of embodied environments, tasks and algorithms, provides\nreproductions of state-of-the-art models and includes extensive documentation,\ntutorials, start-up code, and pre-trained models. We hope that our framework\nmakes Embodied AI more accessible and encourages new researchers to join this\nexciting area. The framework can be accessed at: https://allenact.org/\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 17:35:22 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Weihs", "Luca", ""], ["Salvador", "Jordi", ""], ["Kotar", "Klemen", ""], ["Jain", "Unnat", ""], ["Zeng", "Kuo-Hao", ""], ["Mottaghi", "Roozbeh", ""], ["Kembhavi", "Aniruddha", ""]]}, {"id": "2008.12846", "submitter": "A S M Ahsan-Ul Haque", "authors": "Jacob Dineen, A S M Ahsan-Ul Haque, Matthew Bielskas", "title": "Formal Methods for An Iterated Volunteer's Dilemma", "comments": "9 pages, 4 figures, 5 tables", "journal-ref": null, "doi": "10.1007/978-3-030-80387-2_8", "report-no": null, "categories": "cs.MA", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Game theory provides a paradigm through which we can study the evolving\ncommunication and phenomena that occur via rational agent interaction. In this\nwork, we design a model framework and explore The Volunteer's Dilemma with the\ngoals of 1) modeling it as a stochastic concurrent multiplayer game, 2)\nconstructing properties to verify model correctness and reachability, 3)\nconstructing strategy synthesis graphs to understand how the game is\niteratively stepped through most optimally and, 4) analyzing a series of\nparameters to understand correlations with expected local and global rewards\nover a finite time horizon.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 21:13:36 GMT"}, {"version": "v2", "created": "Tue, 23 Feb 2021 05:52:15 GMT"}, {"version": "v3", "created": "Tue, 2 Mar 2021 12:38:25 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Dineen", "Jacob", ""], ["Haque", "A S M Ahsan-Ul", ""], ["Bielskas", "Matthew", ""]]}, {"id": "2008.13115", "submitter": "Michael Maher", "authors": "Michael J. Maher", "title": "Corruption and Audit in Strategic Argumentation", "comments": "Reasoning Research Institute technical report, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CR cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Strategic argumentation provides a simple model of disputation and\nnegotiation among agents. Although agents might be expected to act in our best\ninterests, there is little that enforces such behaviour. (Maher, 2016)\nintroduced a model of corruption and resistance to corruption within strategic\nargumentation. In this paper we identify corrupt behaviours that are not\ndetected in that formulation. We strengthen the model to detect such\nbehaviours, and show that, under the strengthened model, all the strategic aims\nin (Maher, 2016) are resistant to corruption.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 08:08:26 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Maher", "Michael J.", ""]]}, {"id": "2008.13166", "submitter": "Yuto Omae", "authors": "Yuto Omae, Jun Toyotani, Kazuyuki Hara, Yasuhiro Gon, Hirotaka\n  Takahashi", "title": "Effectiveness of the COVID-19 Contact-Confirming Application (COCOA)\n  based on a Multi Agent Simulation", "comments": "10 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As of Aug. 2020, coronavirus disease 2019 (COVID-19) is still spreading in\nthe world. In Japan, the Ministry of Health, Labor, and Welfare developed\n\"COVID-19 Contact-Confirming Application (COCOA),\" which was released on Jun.\n19, 2020. By utilizing COCOA, users can know whether or not they had contact\nwith infected persons. If those who had contact with infectors keep staying at\nhome, they may not infect those outside. However, effectiveness decreasing the\nnumber of infectors depending on the app's various usage parameters is not\nclear. If it is clear, we could set the objective value of the app's usage\nparameters (e.g., the usage rate of the total populations) and call for\ninstallation of the app. Therefore, we develop a multi-agent simulator that can\nexpress COVID-19 spreading and usage of the apps, such as COCOA. In this study,\nwe describe the simulator and the effectiveness of the app in various\nscenarios. The result obtained in this study supports those of previously\nconducted studies.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 13:20:45 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Omae", "Yuto", ""], ["Toyotani", "Jun", ""], ["Hara", "Kazuyuki", ""], ["Gon", "Yasuhiro", ""], ["Takahashi", "Hirotaka", ""]]}, {"id": "2008.13277", "submitter": "Juste Raimbault", "authors": "Juste Raimbault", "title": "A comparison of simple models for urban morphogenesis", "comments": "14 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The spatial distribution of population and activities within urban areas, or\nurban form at the mesoscopic scale, is the outcome of multiple antagonist\nprocesses. We propose in this paper to benchmark different models of urban\nmorphogenesis, to systematically compare the urban forms they can produce.\nDifferent types of approaches are included, such as a reaction-diffusion model,\na gravity-based model, and correlated percolation. Applying a diversity search\nalgorithm, we estimate the feasible space of each model within a space of urban\nform indicators, in comparison of empirical values for worldwide urban areas.\nWe find a complementarity of the different types of processes, advocating for a\nplurality of urban models.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 21:04:24 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Raimbault", "Juste", ""]]}, {"id": "2008.13589", "submitter": "Emilio Cruciani", "authors": "Aris Anagnostopoulos, Luca Becchetti, Emilio Cruciani, Francesco\n  Pasquale, Sara Rizzo", "title": "Biased Opinion Dynamics: When the Devil Is in the Details", "comments": "The paper has appeared in the Proceedings of the Twenty-Ninth\n  International Joint Conference on Artificial Intelligence. The SOLE copyright\n  holder is IJCAI (International Joint Conferences on Artificial Intelligence),\n  all rights reserved. Link to the proceedings:\n  https://www.ijcai.org/Proceedings/2020/8", "journal-ref": null, "doi": "10.24963/ijcai.2020/8", "report-no": null, "categories": "cs.MA cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate opinion dynamics in multi-agent networks when a bias toward\none of two possible opinions exists; for example, reflecting a status quo vs a\nsuperior alternative. Starting with all agents sharing an initial opinion\nrepresenting the status quo, the system evolves in steps. In each step, one\nagent selected uniformly at random adopts the superior opinion with some\nprobability $\\alpha$, and with probability $1 - \\alpha$ it follows an\nunderlying update rule to revise its opinion on the basis of those held by its\nneighbors. We analyze convergence of the resulting process under two well-known\nupdate rules, namely majority and voter. The framework we propose exhibits a\nrich structure, with a non-obvious interplay between topology and underlying\nupdate rule. For example, for the voter rule we show that the speed of\nconvergence bears no significant dependence on the underlying topology, whereas\nthe picture changes completely under the majority rule, where network density\nnegatively affects convergence. We believe that the model we propose is at the\nsame time simple, rich, and modular, affording mathematical characterization of\nthe interplay between bias, underlying opinion dynamics, and social structure\nin a unified setting.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 13:22:09 GMT"}, {"version": "v2", "created": "Sat, 6 Mar 2021 11:39:22 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Anagnostopoulos", "Aris", ""], ["Becchetti", "Luca", ""], ["Cruciani", "Emilio", ""], ["Pasquale", "Francesco", ""], ["Rizzo", "Sara", ""]]}, {"id": "2008.13738", "submitter": "Maythem Abbas", "authors": "Maythem K. Abbas, Mohd N. Karsiti, Madzlan Napiah, Brahim B. Samir,\n  and Marwan Al-Jemeli", "title": "High Accuracy Traffic Light Controller for Increasing the Given Green\n  Time Utilization", "comments": "21 pages Journal Paper", "journal-ref": "Computers and Electrical Engineering, 2015", "doi": "10.1016/j.compeleceng.2014.12.011", "report-no": "41", "categories": "cs.MA cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traffic congestion has become one of the major problems in the urban cities\naccording to the increasing number of vehicles in those cities, obsolete\ntechnologies used on the roads of those cities, inappropriate road design, and\nmany other reasons. So, that has urged the need for a more accurate traffic\nlight controlling system; one that will help in maintaining high stability at\nall levels of demand. This paper introduces a dynamic traffic light phase plan\nprotocol for Single-Isolated Intersections. The developed controlling method\nwas compared with four other methods and showed a good performance in terms of\nreducing the average and maximum queue lengths, optimizing the given green time\namount as needed, and increased the intersections throughput (increased the\ngiven green time utilization). In addition, it maintained a good traffic light\nstability at all levels of demand.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 16:59:46 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Abbas", "Maythem K.", ""], ["Karsiti", "Mohd N.", ""], ["Napiah", "Madzlan", ""], ["Samir", "Brahim B.", ""], ["Al-Jemeli", "Marwan", ""]]}]