[{"id": "2007.00100", "submitter": "Russell Schwartz", "authors": "Russell Schwartz (1), Pratap Tokekar (1) ((1) University of Maryland,\n  College Park)", "title": "Robust Multi-Agent Task Assignment in Failure-Prone and Adversarial\n  Environments", "comments": "6 pages, 3 figures, 3 algorithms; submitted to the Workshop on\n  Heterogeneous Multi-Robot Task Allocation and Coordination (RSS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of assigning agents to tasks is a central computational challenge\nin many multi-agent autonomous systems. However, in the real world, agents are\nnot always perfect and may fail due to a number of reasons. A motivating\napplication is where the agents are robots that operate in the physical world\nand are susceptible to failures. This paper studies the problem of Robust\nMulti-Agent Task Assignment, which seeks to find an assignment that maximizes\noverall system performance while accounting for potential failures of the\nagents. We investigate both, stochastic and adversarial failures under this\nframework. For both cases, we present efficient algorithms that yield optimal\nor near-optimal results.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 21:00:17 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Schwartz", "Russell", ""], ["Tokekar", "Pratap", ""]]}, {"id": "2007.00777", "submitter": "Yu Zhang", "authors": "Zakk Giacometti and Yu Zhang", "title": "Allocation of Multi-Robot Tasks with Task Variants", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Task allocation has been a well studied problem. In most prior problem\nformulations, it is assumed that each task is associated with a unique set of\nresource requirements. In the scope of multi-robot task allocation problem,\nthese requirements can be satisfied by a coalition of robots. In this paper, we\nintroduce a more general formulation of multi-robot task allocation problem\nthat allows more than one option for specifying the set of task\nrequirements--satisfying any one of the options will satisfy the task. We\nreferred to this new problem as the multi-robot task allocation problem with\ntask variants. First, we theoretically show that this extension fortunately\ndoes not impact the complexity class, which is still NP-complete. For solution\nmethods, we adapt two previous greedy methods for the task allocation problem\nwithout task variants to solve this new problem and analyze their\neffectiveness. In particular, we \"flatten\" the new problem to the problem\nwithout task variants, modify the previous methods to solve the flattened\nproblem, and prove that the bounds still hold. Finally, we thoroughly evaluate\nthese two methods along with a random baseline to demonstrate their efficacy\nfor the new problem.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 21:45:06 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Giacometti", "Zakk", ""], ["Zhang", "Yu", ""]]}, {"id": "2007.01046", "submitter": "Saar Tochner", "authors": "Maya Dotan and Saar Tochner", "title": "Proofs of Useless Work -- Positive and Negative Results for Wasteless\n  Mining Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many blockchain systems today, including Bitcoin, rely on Proof of Work\n(PoW). Proof of work is crucial to the liveness and security of\ncryptocurrencies. The assumption when using PoW is that a lot of trial and\nerror is required on average before a valid block is generated. One of the main\nconcerns raised with regard to this kind of system is the inherent need to\n\"waste\" energy on \"meaningless\" problems. In fact, the Bitcoin system is\nbelieved to consume more electricity than several small countries [5]. In this\nwork we formally define three properties that are necessary for wasteless PoW\nsystems: (1) solve \"meaningful\" problems (2) solve them efficiently and (3) be\nsecure against double-spend attacks. We analyze these properties and deduce\nconstraints that impose on PoW systems. In particular, we conclude that under\nrealistic assumptions, the set of allowed functions for mining must be preimage\nresistant functions. Finally, we propose a modification to the Bitcoin\nconsensus rule that allows users to upload a certain subset of preimage\nresistant problems and let the mining process solve them. We prove security\nagainst Double-Spend attacks identical to the existing security guarantee in\nBitcoin today.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 12:07:26 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Dotan", "Maya", ""], ["Tochner", "Saar", ""]]}, {"id": "2007.01077", "submitter": "Orowa Sikder", "authors": "Orowa Sikder", "title": "Modelling heterogeneous outcomes in multi-agent systems", "comments": "25 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.SI math.OC physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A broad set of empirical phenomenon in the study of social, economic and\nmachine behaviour can be modelled as complex systems with averaging dynamics.\nHowever many of these models naturally result in consensus or consensus-like\noutcomes. In reality, empirical phenomenon rarely converge to these and instead\nare characterized by rich, persistent variation in the agent states. Such\nheterogeneous outcomes are a natural consequence of a number of models that\nincorporate external perturbation to the otherwise convex dynamics of the\nagents. The purpose of this paper is to formalize the notion of heterogeneity\nand demonstrate which classes of models are able to achieve it as an outcome,\nand therefore are better suited to modelling important empirical questions. We\ndo so by determining how the topology of (time-varying) interaction networks\nrestrict the space of possible steady-state outcomes for agents, and how this\nis related to the study of random walks on graphs. We consider a number of\nintentionally diverse examples to demonstrate how the results can be applied.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 13:09:22 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Sikder", "Orowa", ""]]}, {"id": "2007.01544", "submitter": "Francisco Cruz", "authors": "Adam Bignold, Francisco Cruz, Matthew E. Taylor, Tim Brys, Richard\n  Dazeley, Peter Vamplew, Cameron Foale", "title": "A Conceptual Framework for Externally-influenced Agents: An Assisted\n  Reinforcement Learning Review", "comments": "33 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A long-term goal of reinforcement learning agents is to be able to perform\ntasks in complex real-world scenarios. The use of external information is one\nway of scaling agents to more complex problems. However, there is a general\nlack of collaboration or interoperability between different approaches using\nexternal information. In this work, we propose a conceptual framework and\ntaxonomy for assisted reinforcement learning, aimed at fostering such\ncollaboration by classifying and comparing various methods that use external\ninformation in the learning process. The proposed taxonomy details the\nrelationship between the external information source and the learner agent,\nhighlighting the process of information decomposition, structure, retention,\nand how it can be used to influence agent learning. As well as reviewing\nstate-of-the-art methods, we identify current streams of reinforcement learning\nthat use external information in order to improve the agent's performance and\nits decision-making process. These include heuristic reinforcement learning,\ninteractive reinforcement learning, learning from demonstration, transfer\nlearning, and learning from multiple sources, among others. These streams of\nreinforcement learning operate with the shared objective of scaffolding the\nlearner agent. Lastly, we discuss further possibilities for future work in the\nfield of assisted reinforcement learning systems.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jul 2020 08:07:31 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Bignold", "Adam", ""], ["Cruz", "Francisco", ""], ["Taylor", "Matthew E.", ""], ["Brys", "Tim", ""], ["Dazeley", "Richard", ""], ["Vamplew", "Peter", ""], ["Foale", "Cameron", ""]]}, {"id": "2007.01634", "submitter": "Christina Maria Mayr", "authors": "Christina Maria Mayr, Gerta K\\\"oster", "title": "Social distancing with the Optimal Steps Model", "comments": "9 pages, 8 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the Covid-19 pandemic an urgent need to simulate social distancing\narises. The Optimal Steps Model (OSM) is a pedestrian locomotion model that\noperationalizes an individual's need for personal space. We present new\nparameter values for personal space in the Optimal Steps Model to simulate\nsocial distancing in the pedestrian dynamics simulator Vadere. Our approach is\npragmatic. We consider two use cases: in the first we demand that a set social\ndistance must never be violated. In the second the social distance must be kept\nonly on average. For each use case we conduct simulation studies in a typical\nbottleneck scenario and measure contact times, that is, violations of the\nsocial distance rule. We derive rules of thumb for suitable parameter choices\nin dependency of the desired social distance. We test the rules of thumb for\nthe social distances 1.5m and 2.0m and observe that the new parameter values\nindeed lead to the desired social distancing. Thus, the rules of thumb will\nquickly enable Vadere users to conduct their own studies without understanding\nthe intricacies of the OSM implementation and without extensive parameter\nadjustment.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jul 2020 12:10:40 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Mayr", "Christina Maria", ""], ["K\u00f6ster", "Gerta", ""]]}, {"id": "2007.01962", "submitter": "Cyrus Neary", "authors": "Cyrus Neary, Zhe Xu, Bo Wu, and Ufuk Topcu", "title": "Reward Machines for Cooperative Multi-Agent Reinforcement Learning", "comments": "Accepted at AAMAS 2021. Changes since last version: The paper's\n  running example has been modified to simplify presentation (experimental\n  section changed accordingly). Several proofs and definitions surrounding\n  reward machines have been moved from the supplementary material into the body\n  of the paper", "journal-ref": null, "doi": "10.5555/3463952.3464063", "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In cooperative multi-agent reinforcement learning, a collection of agents\nlearns to interact in a shared environment to achieve a common goal. We propose\nthe use of reward machines (RM) -- Mealy machines used as structured\nrepresentations of reward functions -- to encode the team's task. The proposed\nnovel interpretation of RMs in the multi-agent setting explicitly encodes\nrequired teammate interdependencies, allowing the team-level task to be\ndecomposed into sub-tasks for individual agents. We define such a notion of RM\ndecomposition and present algorithmically verifiable conditions guaranteeing\nthat distributed completion of the sub-tasks leads to team behavior\naccomplishing the original task. This framework for task decomposition provides\na natural approach to decentralized learning: agents may learn to accomplish\ntheir sub-tasks while observing only their local state and abstracted\nrepresentations of their teammates. We accordingly propose a decentralized\nq-learning algorithm. Furthermore, in the case of undiscounted rewards, we use\nlocal value functions to derive lower and upper bounds for the global value\nfunction corresponding to the team task. Experimental results in three discrete\nsettings exemplify the effectiveness of the proposed RM decomposition approach,\nwhich converges to a successful team policy an order of magnitude faster than a\ncentralized learner and significantly outperforms hierarchical and independent\nq-learning approaches.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jul 2020 23:08:14 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2021 00:28:11 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Neary", "Cyrus", ""], ["Xu", "Zhe", ""], ["Wu", "Bo", ""], ["Topcu", "Ufuk", ""]]}, {"id": "2007.02382", "submitter": "Michael Chang", "authors": "Michael Chang, Sidhant Kaushik, S. Matthew Weinberg, Thomas L.\n  Griffiths, Sergey Levine", "title": "Decentralized Reinforcement Learning: Global Decision-Making via Local\n  Economic Transactions", "comments": "18 pages, 13 figures, accepted to the International Conference on\n  Machine Learning (ICML) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT cs.MA cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper seeks to establish a framework for directing a society of simple,\nspecialized, self-interested agents to solve what traditionally are posed as\nmonolithic single-agent sequential decision problems. What makes it challenging\nto use a decentralized approach to collectively optimize a central objective is\nthe difficulty in characterizing the equilibrium strategy profile of\nnon-cooperative games. To overcome this challenge, we design a mechanism for\ndefining the learning environment of each agent for which we know that the\noptimal solution for the global objective coincides with a Nash equilibrium\nstrategy profile of the agents optimizing their own local objectives. The\nsociety functions as an economy of agents that learn the credit assignment\nprocess itself by buying and selling to each other the right to operate on the\nenvironment state. We derive a class of decentralized reinforcement learning\nalgorithms that are broadly applicable not only to standard reinforcement\nlearning but also for selecting options in semi-MDPs and dynamically composing\ncomputation graphs. Lastly, we demonstrate the potential advantages of a\nsociety's inherent modular structure for more efficient transfer learning.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jul 2020 16:41:09 GMT"}, {"version": "v2", "created": "Fri, 14 Aug 2020 05:20:29 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Chang", "Michael", ""], ["Kaushik", "Sidhant", ""], ["Weinberg", "S. Matthew", ""], ["Griffiths", "Thomas L.", ""], ["Levine", "Sergey", ""]]}, {"id": "2007.02529", "submitter": "Ziyu Liu", "authors": "Meng Zhou, Ziyu Liu, Pengwei Sui, Yixuan Li, Yuk Ying Chung", "title": "Learning Implicit Credit Assignment for Cooperative Multi-Agent\n  Reinforcement Learning", "comments": "NeurIPS 2020 Camera Ready; first two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a multi-agent actor-critic method that aims to implicitly address\nthe credit assignment problem under fully cooperative settings. Our key\nmotivation is that credit assignment among agents may not require an explicit\nformulation as long as (1) the policy gradients derived from a centralized\ncritic carry sufficient information for the decentralized agents to maximize\ntheir joint action value through optimal cooperation and (2) a sustained level\nof exploration is enforced throughout training. Under the centralized training\nwith decentralized execution (CTDE) paradigm, we achieve the former by\nformulating the centralized critic as a hypernetwork such that a latent state\nrepresentation is integrated into the policy gradients through its\nmultiplicative association with the stochastic policies; to achieve the latter,\nwe derive a simple technique called adaptive entropy regularization where\nmagnitudes of the entropy gradients are dynamically rescaled based on the\ncurrent policy stochasticity to encourage consistent levels of exploration. Our\nalgorithm, referred to as LICA, is evaluated on several benchmarks including\nthe multi-agent particle environments and a set of challenging StarCraft II\nmicromanagement tasks, and we show that LICA significantly outperforms previous\nmethods.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 05:25:02 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 14:18:50 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Zhou", "Meng", ""], ["Liu", "Ziyu", ""], ["Sui", "Pengwei", ""], ["Li", "Yixuan", ""], ["Chung", "Yuk Ying", ""]]}, {"id": "2007.02934", "submitter": "Wolfgang Banzhaf", "authors": "Wolfgang Banzhaf", "title": "The Effects of Taxes on Wealth Inequality in Artificial Chemistry Models\n  of Economic Activity", "comments": "13 pages, 18 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.GN cs.MA econ.GN physics.soc-ph q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a number of Artificial Chemistry models for economic activity and\nwhat consequences they have for the formation of economic inequality. We are\nparticularly interested in what tax measures are effective in dampening\neconomic inequality. By starting from well-known kinetic exchange models, we\nexamine different scenarios for reducing the tendency of economic activity\nmodels to form unequal wealth distribution in equilibrium.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jul 2020 18:00:18 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Banzhaf", "Wolfgang", ""]]}, {"id": "2007.03155", "submitter": "Keisuke Fujii", "authors": "Keisuke Fujii, Naoya Takeishi, Yoshinobu Kawahara, Kazuya Takeda", "title": "Policy learning with partial observation and mechanical constraints for\n  multi-person modeling", "comments": "17 pages with 7 figures and 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Extracting the rules of real-world biological multi-agent behaviors is a\ncurrent challenge in various scientific and engineering fields. Biological\nagents generally have limited observation and mechanical constraints; however,\nmost of the conventional data-driven models ignore such assumptions, resulting\nin lack of biological plausibility and model interpretability for behavioral\nanalyses in biological and cognitive science. Here we propose sequential\ngenerative models with partial observation and mechanical constraints, which\ncan visualize whose information the agents utilize and can generate\nbiologically plausible actions. We formulate this as a decentralized\nmulti-agent imitation learning problem, leveraging binary partial observation\nmodels with a Gumbel-Softmax reparameterization and policy models based on\nhierarchical variational recurrent neural networks with physical and\nbiomechanical constraints. We investigate the empirical performances using\nreal-world multi-person motion datasets from basketball and soccer games.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 01:24:22 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Fujii", "Keisuke", ""], ["Takeishi", "Naoya", ""], ["Kawahara", "Yoshinobu", ""], ["Takeda", "Kazuya", ""]]}, {"id": "2007.03363", "submitter": "Francisco Cruz", "authors": "Ithan Moreira, Javier Rivas, Francisco Cruz, Richard Dazeley, Angel\n  Ayala, Bruno Fernandes", "title": "Deep Reinforcement Learning with Interactive Feedback in a Human-Robot\n  Environment", "comments": "In press journal Applied Sciences", "journal-ref": null, "doi": "10.3390/app10165574", "report-no": null, "categories": "cs.AI cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robots are extending their presence in domestic environments every day, being\nmore common to see them carrying out tasks in home scenarios. In the future,\nrobots are expected to increasingly perform more complex tasks and, therefore,\nbe able to acquire experience from different sources as quickly as possible. A\nplausible approach to address this issue is interactive feedback, where a\ntrainer advises a learner on which actions should be taken from specific states\nto speed up the learning process. Moreover, deep reinforcement learning has\nbeen recently widely utilized in robotics to learn the environment and acquire\nnew skills autonomously. However, an open issue when using deep reinforcement\nlearning is the excessive time needed to learn a task from raw input images. In\nthis work, we propose a deep reinforcement learning approach with interactive\nfeedback to learn a domestic task in a human-robot scenario. We compare three\ndifferent learning methods using a simulated robotic arm for the task of\norganizing different objects; the proposed methods are (i) deep reinforcement\nlearning (DeepRL); (ii) interactive deep reinforcement learning using a\npreviously trained artificial agent as an advisor (agent-IDeepRL); and (iii)\ninteractive deep reinforcement learning using a human advisor (human-IDeepRL).\nWe demonstrate that interactive approaches provide advantages for the learning\nprocess. The obtained results show that a learner agent, using either\nagent-IDeepRL or human-IDeepRL, completes the given task earlier and has fewer\nmistakes compared to the autonomous DeepRL approach.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 11:55:27 GMT"}, {"version": "v2", "created": "Tue, 11 Aug 2020 11:04:58 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Moreira", "Ithan", ""], ["Rivas", "Javier", ""], ["Cruz", "Francisco", ""], ["Dazeley", "Richard", ""], ["Ayala", "Angel", ""], ["Fernandes", "Bruno", ""]]}, {"id": "2007.03562", "submitter": "Cesar A. Uribe", "authors": "C\\'esar A. Uribe and Ali Jadbabaie", "title": "A Distributed Cubic-Regularized Newton Method for Smooth Convex\n  Optimization over Networks", "comments": "22 pages, 2 figures. Preprint, under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a distributed, cubic-regularized Newton method for large-scale\nconvex optimization over networks. The proposed method requires only local\ncomputations and communications and is suitable for federated learning\napplications over arbitrary network topologies. We show a $O(k^{{-}3})$\nconvergence rate when the cost function is convex with Lipschitz gradient and\nHessian, with $k$ being the number of iterations. We further provide\nnetwork-dependent bounds for the communication required in each step of the\nalgorithm. We provide numerical experiments that validate our theoretical\nresults.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 15:38:47 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Uribe", "C\u00e9sar A.", ""], ["Jadbabaie", "Ali", ""]]}, {"id": "2007.03575", "submitter": "Lun Yang", "authors": "Lun Yang", "title": "Resolving Head-On Conflicts for Multi-Agent Path Finding with\n  Conflict-Based Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conflict-Based Search (CBS) is a popular framework for solving the\nMulti-Agent Path Finding problem. Some of the conflicts incur a foreseeable\nconflict in one or both of the children nodes when splitting on them. This\npaper introduces a new technique, namely the head-on technique that finds out\nsuch conflicts, so they can be processed more efficiently by resolving the\nconflict with the potential conflict all together in one split. The proposed\ntechnique applies to all CBS-based solvers. Experimental results show that the\nhead-on technique improves the state-of-the-art MAPF solver CBSH.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 15:52:45 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Yang", "Lun", ""]]}, {"id": "2007.04192", "submitter": "Affan Shoukat", "authors": "Affan Shoukat and Seyed M. Moghadas", "title": "Agent-Based Modelling: An Overview with Application to Disease Dynamics", "comments": "review of agent-based systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modelling and computational methods have been essential in advancing\nquantitative science, especially in the past two decades with the availability\nof vast amount of complex, voluminous, and heterogeneous data. In particular,\nthere has been a surge of interest in agent-based modelling, largely due to its\ncapabilities to exploit such data and make significant projections. However,\nany well-established quantitative method relies on theoretical frameworks for\nboth construction and analysis. While the computational aspects of agent-based\nmodelling have been detailed in existing literature, the underlying theoretical\nbasis has rarely been used in its construction. In this exposition, we provide\nan overview of the theoretical foundation of agent-based modelling and\nestablish a relationship with its computational implementation. In addition to\ndetailing the main characteristics of this computational methodology, we\nillustrate its application to simulating the spread of an infectious disease in\na simple, dynamical process. As the use of agent-based models expands to\nvarious disciplines, our review highlights the need for directed research\nefforts to develop theoretical methods and analytical tools for the analysis of\nsuch models.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jul 2020 15:30:47 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Shoukat", "Affan", ""], ["Moghadas", "Seyed M.", ""]]}, {"id": "2007.04406", "submitter": "Vishnu S. Chipade", "authors": "Weifan Zhang, Vishnu S. Chipade and Dimitra Panagou", "title": "Herding an Adversarial Swarm in Three-dimensional Spaces", "comments": "Submitted to CDC 2020, 9 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a defense approach to safeguard a protected area against\nan attack by a swarm of adversarial agents in three-dimensional (3D) space. We\nextend our 2D `StringNet Herding' approach, in which a closed formation of\nstring-barriers is established around the adversarial swarm to confine their\nmotion and herd them to a safe area, to 3D spaces by introducing 3D-StringNet.\n3D-StringNet is a closed 3D formation of triangular net-like barriers. We\nprovide a systematic approach to generate three types of 3D formations that are\nused in the 3D herding process and modifications to the finite-time convergent\ncontrol laws developed in \\cite{chipade2020swarmherding} that are required for\na 3D environment. Furthermore, for given initial positions of the defenders, we\nprovide conditions on the initial positions of the attackers for which the\ndefenders are guaranteed to gather as a specified formation at a position on\nthe shortest path of the attackers to the protected area before attackers reach\nthere.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jul 2020 20:19:15 GMT"}, {"version": "v2", "created": "Thu, 8 Apr 2021 00:24:46 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Zhang", "Weifan", ""], ["Chipade", "Vishnu S.", ""], ["Panagou", "Dimitra", ""]]}, {"id": "2007.04407", "submitter": "Vishnu S. Chipade", "authors": "Vishnu S. Chipade and Dimitra Panagou", "title": "Multi-Swarm Herding: Protecting against Adversarial Swarms", "comments": "Submitted to CDC 2020, 8 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.RO cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies a defense approach against one or more swarms of\nadversarial agents. In our earlier work, we employ a closed formation\n(`StringNet') of defending agents (defenders) around a swarm of adversarial\nagents (attackers) to confine their motion within given bounds, and guide them\nto a safe area. The control design relies on the assumption that the\nadversarial agents remain close enough to each other, i.e., within a prescribed\nconnectivity region. To handle situations when the attackers no longer stay\nwithin such a connectivity region, but rather split into smaller swarms\n(clusters) to maximize the chance or impact of attack, this paper proposes an\napproach to learn the attacking sub-swarms and reassign defenders towards the\nattackers. We use a `Density-based Spatial Clustering of Application with Noise\n(DBSCAN)' algorithm to identify the spatially distributed swarms of the\nattackers. Then, the defenders are assigned to each identified swarm of\nattackers by solving a constrained generalized assignment problem. Simulations\nare provided to demonstrate the effectiveness of the approach.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jul 2020 20:20:21 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Chipade", "Vishnu S.", ""], ["Panagou", "Dimitra", ""]]}, {"id": "2007.04517", "submitter": "Guanyu Gao", "authors": "Guanyu Gao, Yonggang Wen, Xiaohu Wu and Ran Wang", "title": "Distributed Energy Trading and Scheduling among Microgrids via\n  Multiagent Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of renewable energy generation empowers microgrids to\ngenerate electricity to supply itself and to trade the surplus on energy\nmarkets. To minimize the overall cost, a microgrid must determine how to\nschedule its energy resources and electrical loads and how to trade with\nothers. The control decisions are influenced by various factors, such as energy\nstorage, renewable energy yield, electrical load, and competition from other\nmicrogrids. Making the optimal control decision is challenging, due to the\ncomplexity of the interconnected microgrids, the uncertainty of renewable\nenergy generation and consumption, and the interplay among microgrids. The\nprevious works mainly adopted the modeling-based approaches for deriving the\ncontrol decision, yet they relied on the precise information of future system\ndynamics, which can be hard to obtain in a complex environment. This work\nprovides a new perspective of obtaining the optimal control policy for\ndistributed energy trading and scheduling by directly interacting with the\nenvironment, and proposes a multiagent deep reinforcement learning approach for\nlearning the optimal control policy. Each microgrid is modeled as an agent, and\ndifferent agents learn collaboratively for maximizing their rewards. The agent\nof each microgrid can make the local scheduling decision without knowing\nothers' information, which can well maintain the autonomy of each microgrid. We\nevaluate the performances of our proposed method using real-world datasets. The\nexperimental results show that our method can significantly reduce the cost of\nthe microgrids compared with the baseline methods.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 02:39:37 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Gao", "Guanyu", ""], ["Wen", "Yonggang", ""], ["Wu", "Xiaohu", ""], ["Wang", "Ran", ""]]}, {"id": "2007.04837", "submitter": "Bernadette Charron-Bost", "authors": "Bernadette Charron-Bost", "title": "Geometric Bounds for Convergence Rates of Averaging Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a generic method for bounding the convergence rate of an averaging\nalgorithm running in a multi-agent system with a time-varying network, where\nthe associated stochastic matrices have a time-independent Perron vector. This\nmethod provides bounds on convergence rates that unify and refine most of the\npreviously known bounds. They depend on geometric parameters of the dynamic\ncommunication graph such as the normalized diameter or the bottleneck measure.\n  As corollaries of these geometric bounds, we show that the convergence rate\nof the Metropolis algorithm in a system of $n$ agents is less than $1-1/4n^2$\nwith any communication graph that may vary in time, but is permanently\nconnected and bidirectional. We prove a similar upper bound for the\nEqualNeighbor algorithm under the additional assumptions that the number of\nneighbors of each agent is constant and that the communication graph is not too\nirregular. Moreover our bounds offer improved convergence rates for several\naveraging algorithms and specific families of communication graphs.\n  Finally we extend our methodology to a time-varying Perron vector and show\nhow convergence times may dramatically degrade with even limited variations of\nPerron vectors.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 14:35:10 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Charron-Bost", "Bernadette", ""]]}, {"id": "2007.04882", "submitter": "Jonas Hasbach", "authors": "Jonas D. Hasbach, Maren Bennewitz", "title": "A Neuro-inspired Theory of Joint Human-Swarm Interaction", "comments": "ICRA Workshop on Human-Swarm Interaction 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.MA cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human-swarm interaction (HSI) is an active research challenge in the realms\nof swarm robotics and human-factors engineering. Here we apply a cognitive\nsystems engineering perspective and introduce a neuro-inspired joint systems\ntheory of HSI. The mindset defines predictions for adaptive, robust and\nscalable HSI dynamics and therefore has the potential to inform human-swarm\nloop design.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 15:34:22 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Hasbach", "Jonas D.", ""], ["Bennewitz", "Maren", ""]]}, {"id": "2007.04979", "submitter": "Unnat Jain", "authors": "Unnat Jain, Luca Weihs, Eric Kolve, Ali Farhadi, Svetlana Lazebnik,\n  Aniruddha Kembhavi, Alexander Schwing", "title": "A Cordial Sync: Going Beyond Marginal Policies for Multi-Agent Embodied\n  Tasks", "comments": "Accepted to ECCV 2020 (spotlight); Project page:\n  https://unnat.github.io/cordial-sync", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous agents must learn to collaborate. It is not scalable to develop a\nnew centralized agent every time a task's difficulty outpaces a single agent's\nabilities. While multi-agent collaboration research has flourished in\ngridworld-like environments, relatively little work has considered visually\nrich domains. Addressing this, we introduce the novel task FurnMove in which\nagents work together to move a piece of furniture through a living room to a\ngoal. Unlike existing tasks, FurnMove requires agents to coordinate at every\ntimestep. We identify two challenges when training agents to complete FurnMove:\nexisting decentralized action sampling procedures do not permit expressive\njoint action policies and, in tasks requiring close coordination, the number of\nfailed actions dominates successful actions. To confront these challenges we\nintroduce SYNC-policies (synchronize your actions coherently) and CORDIAL\n(coordination loss). Using SYNC-policies and CORDIAL, our agents achieve a 58%\ncompletion rate on FurnMove, an impressive absolute gain of 25 percentage\npoints over competitive decentralized baselines. Our dataset, code, and\npretrained models are available at https://unnat.github.io/cordial-sync .\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 17:59:57 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Jain", "Unnat", ""], ["Weihs", "Luca", ""], ["Kolve", "Eric", ""], ["Farhadi", "Ali", ""], ["Lazebnik", "Svetlana", ""], ["Kembhavi", "Aniruddha", ""], ["Schwing", "Alexander", ""]]}, {"id": "2007.05096", "submitter": "Quinlan Sykora", "authors": "Quinlan Sykora, Mengye Ren, Raquel Urtasun", "title": "Multi-Agent Routing Value Iteration Network", "comments": "Published at ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we tackle the problem of routing multiple agents in a\ncoordinated manner. This is a complex problem that has a wide range of\napplications in fleet management to achieve a common goal, such as mapping from\na swarm of robots and ride sharing. Traditional methods are typically not\ndesigned for realistic environments hich contain sparsely connected graphs and\nunknown traffic, and are often too slow in runtime to be practical. In\ncontrast, we propose a graph neural network based model that is able to perform\nmulti-agent routing based on learned value iteration in a sparsely connected\ngraph with dynamically changing traffic conditions. Moreover, our learned\ncommunication module enables the agents to coordinate online and adapt to\nchanges more effectively. We created a simulated environment to mimic realistic\nmapping performed by autonomous vehicles with unknown minimum edge coverage and\ntraffic conditions; our approach significantly outperforms traditional solvers\nboth in terms of total cost and runtime. We also show that our model trained\nwith only two agents on graphs with a maximum of 25 nodes can easily generalize\nto situations with more agents and/or nodes.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 22:16:45 GMT"}, {"version": "v2", "created": "Fri, 14 Aug 2020 18:08:25 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Sykora", "Quinlan", ""], ["Ren", "Mengye", ""], ["Urtasun", "Raquel", ""]]}, {"id": "2007.05261", "submitter": "Evangelos Pournaras", "authors": "Jovan Nikolic, Nursultan Jubatyrov, Evangelos Pournaras", "title": "Self-healing Dilemmas in Distributed Systems: Fault Correction vs. Fault\n  Tolerance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.MA cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale decentralized systems of autonomous agents interacting via\nasynchronous communication often experience the following self-healing dilemma:\nfault detection inherits network uncertainties making a remote faulty process\nindistinguishable from a slow process. In the case of a slow process without\nfault, fault correction is undesirable as it can trigger new faults that could\nbe prevented with fault tolerance that is a more proactive system maintenance.\nBut in the case of an actual faulty process, fault tolerance alone without\neventually correcting persistent faults can make systems underperforming.\nMeasuring, understanding and resolving such self-healing dilemmas is a timely\nchallenge and critical requirement given the rise of distributed ledgers, edge\ncomputing, the Internet of Things in several energy, transport and health\napplications. This paper contributes a novel and general-purpose modeling of\nfault scenarios during system runtime. They are used to accurately measure and\npredict inconsistencies generated by the undesirable outcomes of fault\ncorrection and fault tolerance as the means to improve self-healing of\nlarge-scale decentralized systems at the design phase. A rigorous experimental\nmethodology is designed that evaluates 696 experimental settings of different\nfault scales, fault profiles and fault detection thresholds in a prototyped\ndecentralized network of 3000 nodes. Almost 9 million measurements of\ninconsistencies were collected in a network, where each node monitors the\nhealth status of another node, while both can defect. The prediction\nperformance of the modeled fault scenarios is validated in a challenging\napplication scenario of decentralized and dynamic in-network data aggregation\nusing real-world data from a Smart Grid pilot project. Findings confirm the\norigin of inconsistencies at design phase.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 09:10:00 GMT"}, {"version": "v2", "created": "Mon, 12 Apr 2021 17:50:13 GMT"}, {"version": "v3", "created": "Thu, 24 Jun 2021 16:34:40 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Nikolic", "Jovan", ""], ["Jubatyrov", "Nursultan", ""], ["Pournaras", "Evangelos", ""]]}, {"id": "2007.05266", "submitter": "Meher Preetam Korukonda", "authors": "Meher Preetam Korukonda", "title": "Towards Fast, Flexible and Sensor-Free Control of Standalone PVDG\n  Systems", "comments": "75 pages, 30 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.MA cs.NI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this thesis, the problem of fast, effective and low cost control of a\nStandalone Photovoltaic Distributed Generation (SPVDG) system is considered .\nOn-site generation from these systems is more efficient when the power is\ntransmitted via DC due to elimination of transmission losses and needless\nenergy conversions. The inherent low-inertia of these systems added with\nfluctuation of output power and uncertain load consumption, calls for advanced\ncontrol techniques to ensure fast and stable operation during various\nintermittencies. These techniques are expensive since they demand installation\nof many sophisticated sensors. The computation power provided by the fast\ngrowing IC technology can be utilized to estimate different parameters in a\nsystem and reduce the need for expensive sensing equipment. This work provides\nsolutions to problems encountered in the development of faster, more stable and\nsensor-free voltage control and maximum power point tracking(MPPT) for SPVDG\nsystems with PV and battery.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 09:22:03 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Korukonda", "Meher Preetam", ""]]}, {"id": "2007.05340", "submitter": "Mikhail Hayhoe", "authors": "Mikhail Hayhoe, Francisco Barreras, Victor M. Preciado", "title": "A Dynamical Approach to Efficient Eigenvalue Estimation in General\n  Multiagent Networks", "comments": "12 pages, 3 figures. arXiv admin note: text overlap with\n  arXiv:1912.03177", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.MA cs.SY eess.SY math.DS math.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method to efficiently estimate the eigenvalues of any arbitrary\n(potentially weighted and/or directed) network of interacting dynamical agents\nfrom dynamical observations. These observations are discrete, temporal\nmeasurements about the evolution of the outputs of a subset of agents\n(potentially one) during a finite time horizon; notably, we do not require\nknowledge of which agents are contributing to our measurements. We propose an\nefficient algorithm to exactly recover the (potentially complex) eigenvalues\ncorresponding to network modes that are observable from the output\nmeasurements. The length of the sequence of measurements required by our method\nto generate a full reconstruction of the observable eigenvalue spectrum is, at\nmost, twice the number of agents in the network, but smaller in practice. The\nproposed technique can be applied to networks of multiagent systems with\narbitrary dynamics in both continuous- and discrete-time. Finally, we\nillustrate our results with numerical simulations.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 03:51:37 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2020 19:08:01 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Hayhoe", "Mikhail", ""], ["Barreras", "Francisco", ""], ["Preciado", "Victor M.", ""]]}, {"id": "2007.05402", "submitter": "Sean Yi", "authors": "Jinho Lee, Raehyun Kim, Seok-Won Yi, Jaewoo Kang", "title": "MAPS: Multi-agent Reinforcement Learning-based Portfolio Management\n  System", "comments": "7 pages, 5 figures, IJCAI-PRICAI 2020", "journal-ref": null, "doi": "10.24963/ijcai.2020/623", "report-no": null, "categories": "cs.AI cs.CE cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating an investment strategy using advanced deep learning methods in\nstock markets has recently been a topic of interest. Most existing deep\nlearning methods focus on proposing an optimal model or network architecture by\nmaximizing return. However, these models often fail to consider and adapt to\nthe continuously changing market conditions. In this paper, we propose the\nMulti-Agent reinforcement learning-based Portfolio management System (MAPS).\nMAPS is a cooperative system in which each agent is an independent \"investor\"\ncreating its own portfolio. In the training procedure, each agent is guided to\nact as diversely as possible while maximizing its own return with a carefully\ndesigned loss function. As a result, MAPS as a system ends up with a\ndiversified portfolio. Experiment results with 12 years of US market data show\nthat MAPS outperforms most of the baselines in terms of Sharpe ratio.\nFurthermore, our results show that adding more agents to our system would allow\nus to get a higher Sharpe ratio by lowering risk with a more diversified\nportfolio.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 14:08:12 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Lee", "Jinho", ""], ["Kim", "Raehyun", ""], ["Yi", "Seok-Won", ""], ["Kang", "Jaewoo", ""]]}, {"id": "2007.05647", "submitter": "Wenshuo Guo", "authors": "Wenshuo Guo, Mihaela Curmei, Serena Wang, Benjamin Recht, Michael I.\n  Jordan", "title": "Finding Equilibrium in Multi-Agent Games with Payoff Uncertainty", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DS cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of finding equilibrium strategies in multi-agent games\nwith incomplete payoff information, where the payoff matrices are only known to\nthe players up to some bounded uncertainty sets. In such games, an ex-post\nequilibrium characterizes equilibrium strategies that are robust to the payoff\nuncertainty. When the game is one-shot, we show that in zero-sum polymatrix\ngames, an ex-post equilibrium can be computed efficiently using linear\nprogramming. We further extend the notion of ex-post equilibrium to stochastic\ngames, where the game is played repeatedly in a sequence of stages and the\ntransition dynamics are governed by an Markov decision process (MDP). We\nprovide sufficient condition for the existence of an ex-post Markov perfect\nequilibrium (MPE). We show that under bounded payoff uncertainty, the value of\nany two-player zero-sum stochastic game can be computed up to a tight value\ninterval using dynamic programming.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 23:38:53 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Guo", "Wenshuo", ""], ["Curmei", "Mihaela", ""], ["Wang", "Serena", ""], ["Recht", "Benjamin", ""], ["Jordan", "Michael I.", ""]]}, {"id": "2007.05963", "submitter": "Miguel A. Lopez-Carmona", "authors": "Miguel A. Lopez-Carmona, Alvaro Paricio Garcia", "title": "CellEVAC: An adaptive guidance system for crowd evacuation through\n  behavioral optimization", "comments": "47 pages, 26 figures", "journal-ref": null, "doi": "10.1016/j.ssci.2021.105215", "report-no": null, "categories": "cs.MA cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  A critical aspect of crowds' evacuation processes is the dynamism of\nindividual decision making. Here, we investigate how to favor a coordinated\ngroup dynamic through optimal exit-choice instructions using behavioral\nstrategy optimization. We propose and evaluate an adaptive guidance system\n(Cell-based Crowd Evacuation, CellEVAC) that dynamically allocates colors to\ncells in a cell-based pedestrian positioning infrastructure, to provide\nefficient exit-choice indications. The operational module of CellEVAC\nimplements an optimized discrete-choice model that integrates the influential\nfactors that would make evacuees adapt their exit choice. To optimize the\nmodel, we used a simulation-optimization modeling framework that integrates\nmicroscopic pedestrian simulation based on the classical Social Force Model. We\npaid particular attention to safety by using Pedestrian Fundamental Diagrams\nthat model the dynamics of the exit gates. CellEVAC has been tested in a\nsimulated real scenario (Madrid Arena) under different external pedestrian flow\npatterns that simulate complex pedestrian interactions. Results showed that\nCellEVAC outperforms evacuation processes in which the system is not used, with\nan exponential improvement as interactions become complex. We compared our\nsystem with an existing approach based on Cartesian Genetic Programming. Our\nsystem exhibited a better overall performance in terms of safety, evacuation\ntime, and the number of revisions of exit-choice decisions. Further analyses\nalso revealed that Cartesian Genetic Programming generates less natural\npedestrian reactions and movements than CellEVAC. The fact that the decision\nlogic module is built upon a behavioral model seems to favor a more natural and\neffective response. We also found that our proposal has a positive influence on\nevacuations even for a low compliance rate (40%).\n", "versions": [{"version": "v1", "created": "Sun, 12 Jul 2020 11:37:53 GMT"}, {"version": "v2", "created": "Tue, 18 May 2021 06:15:53 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Lopez-Carmona", "Miguel A.", ""], ["Garcia", "Alvaro Paricio", ""]]}, {"id": "2007.06291", "submitter": "Yoav Kolumbus", "authors": "Yoav Kolumbus and Noam Nisan", "title": "On the Effectiveness of Tracking and Testing in SEIR Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE cs.MA cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the effectiveness of tracking and testing in mitigating or\nsuppressing epidemic outbreaks, in combination with or as an alternative to\nquarantines and global lockdowns. We study these intervention methods on a\nnetwork-based SEIR model, augmented with an additional probability to model\nsymptomatic, asymptomatic and pre-symptomatic cases. Our focus is on the basic\ntrade-offs between economic costs and human lives lost, and how these\ntrade-offs change under different lockdown, quarantine, tracking and testing\npolicies.\n  Our main findings are as follows: (i) Tests combined with patient quarantines\nreduce both economic costs and mortality, but require a large-scale testing\ncapacity to achieve a significant improvement; (ii) Tracking significantly\nreduces both economic costs and mortality; (iii) Tracking combined with a\nlimited number of tests can achieve containment without lockdowns; (iv) If\nthere is a small flow of new incoming infections, dynamic \"On-Off\" lockdowns\nare more efficient than fixed lockdowns.\n  Our simulation results underline the extreme effectiveness of tracking and\ntesting policies in reducing both economic costs and mortality and their\npotential to contain epidemic outbreaks without imposing social distancing\nrestrictions. This highlights the difficult social question of trading-off\nthese gains with the privacy loss that tracking necessarily entails.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 10:19:00 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Kolumbus", "Yoav", ""], ["Nisan", "Noam", ""]]}, {"id": "2007.06343", "submitter": "Rahul Tallamraju", "authors": "Rahul Tallamraju, Nitin Saini, Elia Bonetto, Michael Pabst, Yu Tang\n  Liu, Michael J. Black and Aamir Ahmad", "title": "AirCapRL: Autonomous Aerial Human Motion Capture using Deep\n  Reinforcement Learning", "comments": "Article accepted for publication in Robotics and Automation Letters\n  (RA-L) and IROS 2020. 8 Pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this letter, we introduce a deep reinforcement learning (RL) based\nmulti-robot formation controller for the task of autonomous aerial human motion\ncapture (MoCap). We focus on vision-based MoCap, where the objective is to\nestimate the trajectory of body pose and shape of a single moving person using\nmultiple micro aerial vehicles. State-of-the-art solutions to this problem are\nbased on classical control methods, which depend on hand-crafted system and\nobservation models. Such models are difficult to derive and generalize across\ndifferent systems. Moreover, the non-linearity and non-convexities of these\nmodels lead to sub-optimal controls. In our work, we formulate this problem as\na sequential decision making task to achieve the vision-based motion capture\nobjectives, and solve it using a deep neural network-based RL method. We\nleverage proximal policy optimization (PPO) to train a stochastic decentralized\ncontrol policy for formation control. The neural network is trained in a\nparallelized setup in synthetic environments. We performed extensive simulation\nexperiments to validate our approach. Finally, real-robot experiments\ndemonstrate that our policies generalize to real world conditions. Video Link:\nhttps://bit.ly/38SJfjo Supplementary: https://bit.ly/3evfo1O\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 12:30:31 GMT"}, {"version": "v2", "created": "Sat, 1 Aug 2020 11:10:52 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Tallamraju", "Rahul", ""], ["Saini", "Nitin", ""], ["Bonetto", "Elia", ""], ["Pabst", "Michael", ""], ["Liu", "Yu Tang", ""], ["Black", "Michael J.", ""], ["Ahmad", "Aamir", ""]]}, {"id": "2007.06653", "submitter": "Alex Berke", "authors": "Alex Berke, Jason Nawyn, Thomas Sanchez Lengeling, Kent Larson", "title": "Urban Mobility Swarms: A Scalable Implementation", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-52246-9_1", "report-no": null, "categories": "cs.MA cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a system to coordinate 'urban mobility swarms' in order to promote\nthe use and safety of lightweight, sustainable transit, while enhancing the\nvibrancy and community fabric of cities. This work draws from behavior\nexhibited by swarms of nocturnal insects, such as crickets and fireflies,\nwhereby synchrony unifies individuals in a decentralized network. Coordination\nnaturally emerges in these cases and provides a compelling demonstration of\n'strength in numbers'. Our work is applied to coordinating lightweight\nvehicles, such as bicycles, which are automatically inducted into ad-hoc\n'swarms', united by the synchronous pulsation of light. We model individual\nriders as nodes in a decentralized network and synchronize their behavior via a\npeer-to-peer message protocol and algorithm, which preserves individual\nprivacy. Nodes broadcast over radio with a transmission range tuned to localize\nswarm membership. Nodes then join or disconnect from others based on proximity,\naccommodating the dynamically changing topology of urban mobility networks.\nThis paper provides a technical description of our system, including the\nprotocol and algorithm to coordinate the swarming behavior that emerges from\nit. We also demonstrate its implementation in code, circuity, and hardware,\nwith a system prototype tested on a city bike-share. In doing so, we evince the\nscalability of our system. Our prototype uses low-cost components, and\nbike-share programs, which manage bicycle fleets distributed across cities,\ncould deploy the system at city-scale. Our flexible, decentralized design\nallows additional bikes to then connect with the network, enhancing its scale\nand impact.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 19:44:16 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Berke", "Alex", ""], ["Nawyn", "Jason", ""], ["Lengeling", "Thomas Sanchez", ""], ["Larson", "Kent", ""]]}, {"id": "2007.07182", "submitter": "Jack Geary", "authors": "Jack Geary, Henry Gouk", "title": "Altruistic Decision-Making for Autonomous Driving with Sparse Rewards", "comments": "8 pages, 5 figures, submitted to RSS 2020: Interaction and\n  Decision-Making in Autonomous-Driving Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to drive effectively, a driver must be aware of how they can expect\nother vehicles' behaviour to be affected by their decisions, and also how they\nare expected to behave by other drivers. One common family of methods for\naddressing this problem of interaction are those based on Game Theory. Such\napproaches often make assumptions about leaders and followers in an interaction\nwhich can result in conflicts arising when vehicles do not agree on the\nhierarchy, resulting in sub-optimal behaviour. In this work we define a\nmeasurement for the incidence of conflicts, Area of Conflict (AoC), for a given\ninteractive decision-making model. Furthermore, we propose a novel\ndecision-making method that reduces this value compared to an existing approach\nfor incorporating altruistic behaviour. We verify our theoretical analysis\nempirically using a simulated lane-change scenario.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 16:58:00 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Geary", "Jack", ""], ["Gouk", "Henry", ""]]}, {"id": "2007.07216", "submitter": "Tomer Ezra", "authors": "Tomer Ezra and Michal Feldman and Ron Kupfer", "title": "On a Competitive Secretary Problem with Deferred Selections", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study secretary problems in settings with multiple agents. In the standard\nsecretary problem, a sequence of arbitrary awards arrive online, in a random\norder, and a single decision maker makes an immediate and irrevocable decision\nwhether to accept each award upon its arrival. The requirement to make\nimmediate decisions arises in many cases due to an implicit assumption\nregarding competition. Namely, if the decision maker does not take the offered\naward immediately, it will be taken by someone else. The novelty in this paper\nis in introducing a multi-agent model in which the competition is endogenous.\nIn our model, multiple agents compete over the arriving awards, but the\ndecisions need not be immediate; instead, agents may select previous awards as\nlong as they are available (i.e., not taken by another agent). If an award is\nselected by multiple agents, ties are broken either randomly or according to a\nglobal ranking. This induces a multi-agent game in which the time of selection\nis not enforced by the rules of the games, rather it is an important component\nof the agent's strategy. We study the structure and performance of equilibria\nin this game. For random tie breaking, we characterize the equilibria of the\ngame, and show that the expected social welfare in equilibrium is nearly\noptimal, despite competition among the agents. For ranked tie breaking, we give\na full characterization of equilibria in the 3-agent game, and show that as the\nnumber of agents grows, the winning probability of every agent under\nnon-immediate selections approaches her winning probability under immediate\nselections.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 17:37:09 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Ezra", "Tomer", ""], ["Feldman", "Michal", ""], ["Kupfer", "Ron", ""]]}, {"id": "2007.07228", "submitter": "Sarah Li Ms.", "authors": "Sarah H. Q. Li, Lillian Ratliff, Beh\\c{c}et A\\c{c}{\\i}kme\\c{s}e", "title": "Disturbance Decoupling for Gradient-based Multi-Agent Learning with\n  Quadratic Costs", "comments": null, "journal-ref": "IEEE Control Systems Letters, vol. 5, no. 1, pp. 223-228, Jan.\n  2021", "doi": "10.1109/LCSYS.2020.3001240", "report-no": null, "categories": "cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by applications of multi-agent learning in noisy environments, this\npaper studies the robustness of gradient-based learning dynamics with respect\nto disturbances. While disturbances injected along a coordinate corresponding\nto any individual player's actions can always affect the overall learning\ndynamics, a subset of players can be disturbance decoupled---i.e., such\nplayers' actions are completely unaffected by the injected disturbance. We\nprovide necessary and sufficient conditions to guarantee this property for\ngames with quadratic cost functions, which encompass quadratic one-shot\ncontinuous games, finite-horizon linear quadratic (LQ) dynamic games, and\nbilinear games. Specifically, disturbance decoupling is characterized by both\nalgebraic and graph-theoretic conditions on the learning dynamics, the latter\nis obtained by constructing a game graph based on gradients of players' costs.\nFor LQ games, we show that disturbance decoupling imposes constraints on the\ncontrollable and unobservable subspaces of players. For two player bilinear\ngames, we show that disturbance decoupling within a player's action coordinates\nimposes constraints on the payoff matrices. Illustrative numerical examples are\nprovided.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 17:47:29 GMT"}, {"version": "v2", "created": "Sat, 10 Oct 2020 22:43:01 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Li", "Sarah H. Q.", ""], ["Ratliff", "Lillian", ""], ["A\u00e7\u0131kme\u015fe", "Beh\u00e7et", ""]]}, {"id": "2007.07461", "submitter": "Kaiqing Zhang", "authors": "Kaiqing Zhang, Sham M. Kakade, Tamer Ba\\c{s}ar, Lin F. Yang", "title": "Model-Based Multi-Agent RL in Zero-Sum Markov Games with Near-Optimal\n  Sample Complexity", "comments": "Addressed minor comments from NeurIPS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT cs.MA math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-based reinforcement learning (RL), which finds an optimal policy using\nan empirical model, has long been recognized as one of the corner stones of RL.\nIt is especially suitable for multi-agent RL (MARL), as it naturally decouples\nthe learning and the planning phases, and avoids the non-stationarity problem\nwhen all agents are improving their policies simultaneously using samples.\nThough intuitive and widely-used, the sample complexity of model-based MARL\nalgorithms has not been fully investigated. In this paper, our goal is to\naddress the fundamental question about its sample complexity. We study arguably\nthe most basic MARL setting: two-player discounted zero-sum Markov games, given\nonly access to a generative model. We show that model-based MARL achieves a\nsample complexity of $\\tilde O(|S||A||B|(1-\\gamma)^{-3}\\epsilon^{-2})$ for\nfinding the Nash equilibrium (NE) value up to some $\\epsilon$ error, and the\n$\\epsilon$-NE policies with a smooth planning oracle, where $\\gamma$ is the\ndiscount factor, and $S,A,B$ denote the state space, and the action spaces for\nthe two agents. We further show that such a sample bound is minimax-optimal (up\nto logarithmic factors) if the algorithm is reward-agnostic, where the\nalgorithm queries state transition samples without reward knowledge, by\nestablishing a matching lower bound. This is in contrast to the usual\nreward-aware setting, with a\n$\\tilde\\Omega(|S|(|A|+|B|)(1-\\gamma)^{-3}\\epsilon^{-2})$ lower bound, where\nthis model-based approach is near-optimal with only a gap on the $|A|,|B|$\ndependence. Our results not only demonstrate the sample-efficiency of this\nbasic model-based approach in MARL, but also elaborate on the fundamental\ntradeoff between its power (easily handling the more challenging\nreward-agnostic case) and limitation (less adaptive and suboptimal in\n$|A|,|B|$), particularly arises in the multi-agent context.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jul 2020 03:25:24 GMT"}, {"version": "v2", "created": "Sat, 10 Oct 2020 03:34:56 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Zhang", "Kaiqing", ""], ["Kakade", "Sham M.", ""], ["Ba\u015far", "Tamer", ""], ["Yang", "Lin F.", ""]]}, {"id": "2007.07499", "submitter": "Sid Chi-Kin Chau", "authors": "Lingjuan Lyu, Sid Chi-Kin Chau, Nan Wang and Yifeng Zheng", "title": "Cloud-based Privacy-Preserving Collaborative Consumption for Sharing\n  Economy", "comments": "To appear in IEEE Trans. Cloud Computing", "journal-ref": null, "doi": "10.1109/TCC.2020.3010235", "report-no": null, "categories": "cs.CR cs.MA cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud computing has been a dominant paradigm for a variety of information\nprocessing platforms, particularly for enabling various popular applications of\nsharing economy. However, there is a major concern regarding data privacy on\nthese cloud-based platforms. This work presents novel cloud-based\nprivacy-preserving solutions to support collaborative consumption applications\nfor sharing economy. In typical collaborative consumption, information\nprocessing platforms need to enable fair cost-sharing among multiple users for\nutilizing certain shared facilities and communal services. Our cloud-based\nprivacy-preserving protocols, based on homomorphic Paillier cryptosystems, can\nensure that the cloud-based operator can only obtain an aggregate schedule of\nall users in facility sharing, or a service schedule conforming to service\nprovision rule in communal service sharing, but is unable to track the personal\nschedules or demands of individual users. More importantly, the participating\nusers are still able to settle cost-sharing among themselves in a fair manner\nfor the incurred costs, without knowing each other's private schedules or\ndemands. Our privacy-preserving protocols involve no other third party who may\ncompromise privacy. We also provide an extensive evaluation study and a\nproof-of-concept system prototype of our protocols.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jul 2020 06:06:07 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Lyu", "Lingjuan", ""], ["Chau", "Sid Chi-Kin", ""], ["Wang", "Nan", ""], ["Zheng", "Yifeng", ""]]}, {"id": "2007.07786", "submitter": "Wicak Ananduta", "authors": "Wicak Ananduta, Carlos Ocampo-Martinez", "title": "Event-triggered Partitioning for Non-centralized\n  Predictive-Control-based Economic Dispatch of Interconnected Microgrids:\n  Technical Report", "comments": "11 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.MA cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A non-centralized model predictive control (MPC) scheme for solving an\neconomic dispatch problem of electrical networks is proposed in this paper. The\nscheme consists of two parts. The first part is an event-triggered\nrepartitioning method that splits the network into a fixed number of\nnon-overlapping sub-systems {(microgrids)}. The objective of the repartitioning\nprocedure is to obtain self-sufficient microgrids, i.e., those that can meet\ntheir local loads using their own generation units. However, since the\nalgorithm does not guarantee that all the resulting microgrids are\nself-sufficient, the microgrids that are not self-sufficient must then form a\ncoalition with some of their neighboring microgrids. This process becomes the\nsecond part of the scheme. By performing the coalition formation, we can\ndecompose the economic dispatch problem of the network into coalition-based\nsub-problems such that each subproblem is feasible. Furthermore, we also show\nthat the solution obtained by solving the coalition-based sub-problems is a\nfeasible but sub-optimal solution to the centralized problem. Additionally,\nsome numerical simulations are also carried out to show the effectiveness of\nthe proposed method.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jul 2020 16:08:52 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Ananduta", "Wicak", ""], ["Ocampo-Martinez", "Carlos", ""]]}, {"id": "2007.07971", "submitter": "Tor Anderson", "authors": "Tor Anderson, Manasa Muralidharan, Priyank Srivastava, Hamed Valizadeh\n  Haghi, Jorge Cortes, Jan Kleissl, Sonia Martinez, Byron Washom", "title": "Frequency Regulation with Heterogeneous Energy Resources: A Realization\n  using Distributed Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents one of the first real-life demonstrations of coordinated\nand distributed resource control for secondary frequency response in a power\ndistribution grid. We conduct a series of tests with up to 69 heterogeneous\nactive devices consisting of air handling units, unidirectional and\nbidirectional electric vehicle charging stations, a battery energy storage\nsystem, and 107 passive devices consisting of building loads and photovoltaic\ngenerators. Actuation commands for the test devices are obtained by solving an\neconomic dispatch problem at every regulation instant using distributed\nratio-consensus, primal-dual, and Newton-like algorithms. The distributed\ncontrol setup consists of a set of Raspberry Pi end-points exchanging messages\nvia an ethernet switch. The problem formulation minimizes the sum of device\ncosts while tracking the setpoints provided by the system operator. We\ndemonstrate accurate and fast real-time distributed computation of the\noptimization solution and effective tracking of the regulation signal by\nmeasuring physical device outputs over 40-minute time horizons. We also perform\nan economic benefit analysis which confirms eligibility to participate in an\nancillary services market and demonstrates up to $53K of potential annual\nrevenue for the selected population of devices.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jul 2020 19:56:36 GMT"}, {"version": "v2", "created": "Mon, 20 Jul 2020 21:03:56 GMT"}, {"version": "v3", "created": "Mon, 27 Jul 2020 20:48:15 GMT"}, {"version": "v4", "created": "Thu, 4 Feb 2021 22:00:57 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Anderson", "Tor", ""], ["Muralidharan", "Manasa", ""], ["Srivastava", "Priyank", ""], ["Haghi", "Hamed Valizadeh", ""], ["Cortes", "Jorge", ""], ["Kleissl", "Jan", ""], ["Martinez", "Sonia", ""], ["Washom", "Byron", ""]]}, {"id": "2007.08064", "submitter": "Sid Chi-Kin Chau", "authors": "Sid Chi-Kin Chau, Shuning Shen and Yue Zhou", "title": "Decentralized Ride-Sharing and Vehicle-Pooling Based on Fair\n  Cost-Sharing Mechanisms", "comments": "To appear in IEEE Trans. on Intelligent Transportation Systems", "journal-ref": null, "doi": "10.1109/TITS.2020.3030051", "report-no": null, "categories": "cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ride-sharing or vehicle-pooling allows commuters to team up spontaneously for\ntransportation cost sharing. This has become a popular trend in the emerging\nparadigm of sharing economy. One crucial component to support effective\nride-sharing is the matching mechanism that pairs up suitable commuters.\nTraditionally, matching has been performed in a centralized manner, whereby an\noperator arranges ride-sharing according to a global objective (e.g., total\ncost of all commuters). However, ride-sharing is a decentralized\ndecision-making paradigm, where commuters are self-interested and only\nmotivated to team up based on individual payments. Particularly, it is not\nclear how transportation cost should be shared fairly between commuters, and\nwhat ramifications of cost-sharing are on decentralized ride-sharing. This\npaper sheds light on the principles of decentralized ride-sharing and\nvehicle-pooling mechanisms based on stable matching, such that no one would be\nbetter off to deviate from a stable matching outcome. We study various fair\ncost-sharing mechanisms and the induced stable matching outcomes. We compare\nthe stable matching outcomes with a social optimal outcome (that minimizes\ntotal cost) by theoretical bounds of social optimality ratios, and show that\nseveral fair cost-sharing mechanisms can achieve high social optimality. We\nalso corroborate our results with an empirical study of taxi sharing under fair\ncost-sharing mechanisms by a data analysis on New York City taxi trip dataset,\nand provide useful insights on effective decentralized mechanisms for practical\nride-sharing and vehicle-pooling.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 01:37:12 GMT"}, {"version": "v2", "created": "Fri, 18 Sep 2020 05:22:22 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Chau", "Sid Chi-Kin", ""], ["Shen", "Shuning", ""], ["Zhou", "Yue", ""]]}, {"id": "2007.08521", "submitter": "Ananya Sheth", "authors": "Ananya Sheth, Joseph V. Sinfield", "title": "Simulating Self-Organization during Strategic Change: Implications for\n  Organizational Design", "comments": "Presented at ACM SIGCHI Collective Intelligence 2019, Carnegie Mellon\n  University", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Self-organization -- a characteristic of complex adaptive systems (CAS) --\nhas been explored in organizational research, in management theory [Mihm et al.\n2003; von Foerster 1984], firm internationalization [Chandra and Wilkinson\n2017], organizational design [Clement and Puranam 2017], and strategic change\n[Foster 2015]. Newer organizational forms such as networks and zero-hierarchy\ncompanies that hold the promise of self-organization are gaining prominence\n[Puranam et al. 2014], and theoretical organizational modeling is a useful\ntechnique to study them proactively via simulation [Puranam et al.2015; Simon\n1976]. In this paper, we introduce a nature-inspired model to understand\nself-organization of collaborative groups in three archetypal organizational\ndesigns: i. fully-networked, ii. siloed, and iii.dynamic, where each design\ncontrols intra-managerial communication in specific ways, and each member has\nreactive or perceptive behavioral tendencies.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 04:18:41 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Sheth", "Ananya", ""], ["Sinfield", "Joseph V.", ""]]}, {"id": "2007.08590", "submitter": "Mahsa Keshavarz", "authors": "Mahsa Keshavarz and Alireza Shamsoshoara and Fatemeh Afghah and\n  Jonathan Ashdown", "title": "Real-time Framework for Trust Monitoring in aNetwork of Unmanned Aerial\n  Vehicles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unmanned aerial vehicles (UAVs) have been increasingly utilized in various\ncivilian and military applications such as remote sensing, border patrolling,\ndisaster monitoring, and communication coverage extension. However, there are\nstill prone to several cyber attacks such as GPS spoofing attacks, distributed\ndenial-of-service (DDoS) attacks, and man-in-the-middle attacks to obtain their\ncollected information or to enforce the UAVs to perform their requested actions\nwhich may damage the UAVs or their surrounding environment or even endanger the\nsafety of human in the operation field. In this paper, we propose a trust\nmonitoring mechanism in which a centralized unit (e.g. the ground station)\nregularly observe the behavior of the UAVs in terms of their motion path, their\nconsumed energy, as well as the number of their completed tasks and measure a\nrelative trust score for the UAVs to detect any abnormal behaviors in a\nreal-time manner. Our simulation results show that the trust model can detect\nmalicious UAVs, which can be under various cyber-security attacks such as\nflooding attacks, man-in-the-middle attacks, GPS spoofing attack in real-time.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 19:50:41 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Keshavarz", "Mahsa", ""], ["Shamsoshoara", "Alireza", ""], ["Afghah", "Fatemeh", ""], ["Ashdown", "Jonathan", ""]]}, {"id": "2007.08656", "submitter": "Sondre Engebr{\\aa}ten Msc", "authors": "Sondre A. Engebraaten, Jonas Moen, Oleg A. Yakimenko, Kyrre Glette", "title": "A Framework for Automatic Behavior Generation in Multi-Function Swarms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-function swarms are swarms that solve multiple tasks at once. For\nexample, a quadcopter swarm could be tasked with exploring an area of interest\nwhile simultaneously functioning as ad-hoc relays. With this type of\nmulti-function comes the challenge of handling potentially conflicting\nrequirements simultaneously. Using the Quality-Diversity algorithm MAP-elites\nin combination with a suitable controller structure, a framework for automatic\nbehavior generation in multi-function swarms is proposed. The framework is\ntested on a scenario with three simultaneous tasks: exploration, communication\nnetwork creation and geolocation of RF emitters. A repertoire is evolved,\nconsisting of a wide range of controllers, or behavior primitives, with\ndifferent characteristics and trade-offs in the different tasks. This\nrepertoire would enable the swarm to transition between behavior trade-offs\nonline, according to the situational requirements. Furthermore, the effect of\nnoise on the behavior characteristics in MAP-elites is investigated. A moderate\nnumber of re-evaluations is found to increase the robustness while keeping the\ncomputational requirements relatively low. A few selected controllers are\nexamined, and the dynamics of transitioning between these controllers are\nexplored. Finally, the study develops a methodology for analyzing the makeup of\nthe resulting controllers. This is done through a parameter variation study\nwhere the importance of individual inputs to the swarm controllers is assessed\nand analyzed.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jul 2020 20:50:52 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Engebraaten", "Sondre A.", ""], ["Moen", "Jonas", ""], ["Yakimenko", "Oleg A.", ""], ["Glette", "Kyrre", ""]]}, {"id": "2007.08961", "submitter": "Florin Leon", "authors": "Constantin-Valentin Pal, Florin Leon, Marcin Paprzycki, Maria Ganzha", "title": "A Review of Platforms for the Development of Agent Systems", "comments": "40 pages, 2 figures, 9 tables, 83 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Agent-based computing is an active field of research with the goal of\nbuilding autonomous software of hardware entities. This task is often\nfacilitated by the use of dedicated, specialized frameworks. For almost thirty\nyears, many such agent platforms have been developed. Meanwhile, some of them\nhave been abandoned, others continue their development and new platforms are\nreleased. This paper presents a up-to-date review of the existing agent\nplatforms and also a historical perspective of this domain. It aims to serve as\na reference point for people interested in developing agent systems. This work\ndetails the main characteristics of the included agent platforms, together with\nlinks to specific projects where they have been used. It distinguishes between\nthe active platforms and those no longer under development or with unclear\nstatus. It also classifies the agent platforms as general purpose ones, free or\ncommercial, and specialized ones, which can be used for particular types of\napplications.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2020 13:12:16 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Pal", "Constantin-Valentin", ""], ["Leon", "Florin", ""], ["Paprzycki", "Marcin", ""], ["Ganzha", "Maria", ""]]}, {"id": "2007.09327", "submitter": "Ibrahim Ahmed", "authors": "Ibrahim H. Ahmed, Josiah P. Hanna, Elliot Fosong, and Stefano V.\n  Albrecht", "title": "Towards Quantum-Secure Authentication and Key Agreement via Abstract\n  Multi-Agent Interaction", "comments": "Published at the 19th International Conference on Practical\n  Applications of Agents and Multi-Agent Systems (PAAMS 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current methods for authentication and key agreement based on public-key\ncryptography are vulnerable to quantum computing. We propose a novel approach\nbased on artificial intelligence research in which communicating parties are\nviewed as autonomous agents which interact repeatedly using their private\ndecision models. Authentication and key agreement are decided based on the\nagents' observed behaviors during the interaction. The security of this\napproach rests upon the difficulty of modeling the decisions of interacting\nagents from limited observations, a problem which we conjecture is also hard\nfor quantum computing. We release PyAMI, a prototype authentication and key\nagreement system based on the proposed method. We empirically validate our\nmethod for authenticating legitimate users while detecting different types of\nadversarial attacks. Finally, we show how reinforcement learning techniques can\nbe used to train server models which effectively probe a client's decisions to\nachieve more sample-efficient authentication.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jul 2020 04:22:02 GMT"}, {"version": "v2", "created": "Fri, 9 Jul 2021 16:13:41 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Ahmed", "Ibrahim H.", ""], ["Hanna", "Josiah P.", ""], ["Fosong", "Elliot", ""], ["Albrecht", "Stefano V.", ""]]}, {"id": "2007.09512", "submitter": "Aditya Shinde", "authors": "Aditya Shinde, Prashant Doshi, Omid Setayeshfar", "title": "Active Deception using Factored Interactive POMDPs to Recognize Cyber\n  Attacker's Intent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an intelligent and adaptive agent that employs deception\nto recognize a cyber adversary's intent. Unlike previous approaches to cyber\ndeception, which mainly focus on delaying or confusing the attackers, we focus\non engaging with them to learn their intent. We model cyber deception as a\nsequential decision-making problem in a two-agent context. We introduce\nfactored finitely nested interactive POMDPs (I-POMDPx) and use this framework\nto model the problem with multiple attacker types. Our approach models cyber\nattacks on a single honeypot host across multiple phases from the attacker's\ninitial entry to reaching its adversarial objective. The defending\nI-POMDPx-based agent uses decoys to engage with the attacker at multiple phases\nto form increasingly accurate predictions of the attacker's behavior and\nintent. The use of I-POMDPs also enables us to model the adversary's mental\nstate and investigate how deception affects their beliefs. Our experiments in\nboth simulation and on a real host show that the I-POMDPx-based agent performs\nsignificantly better at intent recognition than commonly used deception\nstrategies on honeypots.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jul 2020 20:09:15 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Shinde", "Aditya", ""], ["Doshi", "Prashant", ""], ["Setayeshfar", "Omid", ""]]}, {"id": "2007.09645", "submitter": "Kennedy Ehimwenma PhD", "authors": "Kennedy E. Ehimwenma and Sujatha Krishnamoorthy", "title": "Design and Analysis of a Multi-Agent E-Learning System Using Prometheus\n  Design Tool", "comments": "17 figures, 3 tables", "journal-ref": "IAES International Journal of Artificial Intelligence (IJ-AI) Vol.\n  10, No. 1, March 2021, pp. 9~23", "doi": "10.11591/ijai.v10.i1.pp9-23", "report-no": null, "categories": "cs.MA cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Agent unified modeling languages (AUML) are agent-oriented approaches that\nsupports the specification, design, visualization and documentation of an\nagent-based system. This paper presents the use of Prometheus AUML approach for\nthe modeling of a Pre-assessment System of five interactive agents. The\nPre-assessment System, as previously reported, is a multi-agent based\ne-learning system that is developed to support the assessment of prior learning\nskills in students so as to classify their skills and make recommendation for\ntheir learning. This paper discusses the detailed design approach of the system\nin a step-by-step manner; and domain knowledge abstraction and organization in\nthe system. In addition, the analysis of the data collated and models of\nprediction for future pre-assessment results are also presented.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jul 2020 10:37:52 GMT"}, {"version": "v2", "created": "Thu, 18 Feb 2021 19:57:12 GMT"}, {"version": "v3", "created": "Thu, 25 Feb 2021 01:02:35 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Ehimwenma", "Kennedy E.", ""], ["Krishnamoorthy", "Sujatha", ""]]}, {"id": "2007.09786", "submitter": "Andrew Estornell", "authors": "Andrew Estornell, Sanmay Das, Edith Elkind, Yevgeniy Vorobeychik", "title": "Election Control by Manipulating Issue Significance", "comments": null, "journal-ref": "UAI. 2020", "doi": null, "report-no": null, "categories": "cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Integrity of elections is vital to democratic systems, but it is frequently\nthreatened by malicious actors. The study of algorithmic complexity of the\nproblem of manipulating election outcomes by changing its structural features\nis known as election control. One means of election control that has been\nproposed is to select a subset of issues that determine voter preferences over\ncandidates. We study a variation of this model in which voters have judgments\nabout relative importance of issues, and a malicious actor can manipulate these\njudgments. We show that computing effective manipulations in this model is\nNP-hard even with two candidates or binary issues. However, we demonstrate that\nthe problem is tractable with a constant number of voters or issues.\nAdditionally, while it remains intractable when voters can vote stochastically,\nwe exhibit an important special case in which stochastic voting enables\ntractable manipulation.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jul 2020 21:16:47 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Estornell", "Andrew", ""], ["Das", "Sanmay", ""], ["Elkind", "Edith", ""], ["Vorobeychik", "Yevgeniy", ""]]}, {"id": "2007.09820", "submitter": "Marina Dubova", "authors": "Marina Dubova, Arseny Moskvichev, Robert Goldstone", "title": "Reinforcement Communication Learning in Different Social Network\n  Structures", "comments": null, "journal-ref": "1st Workshop on Language in Reinforcement Learning, ICML 2020", "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social network structure is one of the key determinants of human language\nevolution. Previous work has shown that the network of social interactions\nshapes decentralized learning in human groups, leading to the emergence of\ndifferent kinds of communicative conventions. We examined the effects of social\nnetwork organization on the properties of communication systems emerging in\ndecentralized, multi-agent reinforcement learning communities. We found that\nthe global connectivity of a social network drives the convergence of\npopulations on shared and symmetric communication systems, preventing the\nagents from forming many local \"dialects\". Moreover, the agent's degree is\ninversely related to the consistency of its use of communicative conventions.\nThese results show the importance of the basic properties of social network\nstructure on reinforcement communication learning and suggest a new\ninterpretation of findings on human convergence on word conventions.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jul 2020 23:57:30 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Dubova", "Marina", ""], ["Moskvichev", "Arseny", ""], ["Goldstone", "Robert", ""]]}, {"id": "2007.10581", "submitter": "Jungyeon Baek", "authors": "Jungyeon Baek and Georges Kaddoum", "title": "Heterogeneous Task Offloading and Resource Allocations via Deep\n  Recurrent Reinforcement Learning in Partial Observable Multi-Fog Networks", "comments": null, "journal-ref": null, "doi": "10.1109/JIOT.2020.3009540", "report-no": null, "categories": "cs.DC cs.MA eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As wireless services and applications become more sophisticated and require\nfaster and higher-capacity networks, there is a need for an efficient\nmanagement of the execution of increasingly complex tasks based on the\nrequirements of each application. In this regard, fog computing enables the\nintegration of virtualized servers into networks and brings cloud services\ncloser to end devices. In contrast to the cloud server, the computing capacity\nof fog nodes is limited and thus a single fog node might not be capable of\ncomputing-intensive tasks. In this context, task offloading can be particularly\nuseful at the fog nodes by selecting the suitable nodes and proper resource\nmanagement while guaranteeing the Quality-of-Service (QoS) requirements of the\nusers. This paper studies the design of a joint task offloading and resource\nallocation control for heterogeneous service tasks in multi-fog nodes systems.\nThis problem is formulated as a partially observable stochastic game, in which\neach fog node cooperates to maximize the aggregated local rewards while the\nnodes only have access to local observations. To deal with partial\nobservability, we apply a deep recurrent Q-network (DRQN) approach to\napproximate the optimal value functions. The solution is then compared to a\ndeep Q-network (DQN) and deep convolutional Q-network (DCQN) approach to\nevaluate the performance of different neural networks. Moreover, to guarantee\nthe convergence and accuracy of the neural network, an adjusted\nexploration-exploitation method is adopted. Provided numerical results show\nthat the proposed algorithm can achieve a higher average success rate and lower\naverage overflow than baseline methods.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2020 03:41:28 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Baek", "Jungyeon", ""], ["Kaddoum", "Georges", ""]]}, {"id": "2007.11153", "submitter": "He Cai", "authors": "He Cai and Jie Huang", "title": "Output Based Adaptive Distributed Output Observer for Leader-follower\n  Multiagent Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The adaptive distributed observer approach has been an effective tool for\nsynthesizing a distributed control law for solving various control problems of\nleader-follower multiagent systems. However, the existing adaptive distributed\nobserver needs to make use of the full state of the leader system. This\nassumption not only precludes many practical applications in which only the\noutput of the leader system is available, but also leads to a high dimension\nobserver. In this communique, we propose an adaptive distributed output\nobserver which only makes use of the output of the leader system, and is thus\nmore practical than the state based adaptive distributed observer. Moreover,\nthe dimension and the information exchange among agents of the proposed\nadaptive distributed output observer can be significantly smaller than those of\nthe state based adaptive distributed output observer.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jul 2020 01:21:49 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Cai", "He", ""], ["Huang", "Jie", ""]]}, {"id": "2007.11260", "submitter": "EPTCS", "authors": "Rafael C. Cardoso (University of Liverpool), Angelo Ferrando\n  (University of Liverpool), Daniela Briola (University of Milano-Bicocca),\n  Claudio Menghi (University of Luxembourg), Tobias Ahlbrecht (Clausthal\n  University of Technology)", "title": "Proceedings of the First Workshop on Agents and Robots for reliable\n  Engineered Autonomy", "comments": null, "journal-ref": "EPTCS 319, 2020", "doi": "10.4204/EPTCS.319", "report-no": null, "categories": "cs.MA cs.RO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the proceedings of the First Workshop on Agents and\nRobots for reliable Engineered Autonomy (AREA 2020), co-located with the 24th\nEuropean Conference on Artificial Intelligence (ECAI 2020). AREA brings\ntogether researchers from autonomous agents, software engineering and robotic\ncommunities, as combining knowledge coming from these research areas may lead\nto innovative approaches that solve complex problems related with the\nverification and validation of autonomous robotic systems.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jul 2020 08:33:36 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Cardoso", "Rafael C.", "", "University of Liverpool"], ["Ferrando", "Angelo", "", "University of Liverpool"], ["Briola", "Daniela", "", "University of Milano-Bicocca"], ["Menghi", "Claudio", "", "University of Luxembourg"], ["Ahlbrecht", "Tobias", "", "Clausthal\n  University of Technology"]]}, {"id": "2007.11741", "submitter": "EPTCS", "authors": "Eleonora Iotti, Giuseppe Petrosino, Stefania Monica, Federico Bergenti", "title": "Exploratory Experiments on Programming Autonomous Robots in Jadescript", "comments": "In Proceedings AREA 2020, arXiv:2007.11260", "journal-ref": "EPTCS 319, 2020, pp. 55-67", "doi": "10.4204/EPTCS.319.5", "report-no": null, "categories": "cs.MA cs.AI cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes exploratory experiments to validate the possibility of\nprogramming autonomous robots using an agent-oriented programming language.\nProper perception of the environment, by means of various types of sensors, and\ntimely reaction to external events, by means of effective actuators, are\nessential to provide robots with a sufficient level of autonomy. The\nagent-oriented programming paradigm is relevant with this respect because it\noffers language-level abstractions to process events and to command actuators.\nA recent agent-oriented programming language called Jadescript is presented in\nthis paper together with its new features specifically designed to handle\nevents. Exploratory experiments on a simple case-study application are\npresented to show the validity of the proposed approach and to exemplify the\nuse of the language to program autonomous robots.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2020 01:31:46 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Iotti", "Eleonora", ""], ["Petrosino", "Giuseppe", ""], ["Monica", "Stefania", ""], ["Bergenti", "Federico", ""]]}, {"id": "2007.11742", "submitter": "EPTCS", "authors": "Davide Ancona (University of Genova, DIBRIS), Chiara Bassano\n  (University of Genova, DIBRIS), Manuela Chessa (University of Genova,\n  DIBRIS), Viviana Mascardi (University of Genova, DIBRIS), Fabio Solari\n  (University of Genova, DIBRIS)", "title": "Engineering Reliable Interactions in the Reality-Artificiality Continuum", "comments": "In Proceedings AREA 2020, arXiv:2007.11260", "journal-ref": "EPTCS 319, 2020, pp. 69-80", "doi": "10.4204/EPTCS.319.6", "report-no": null, "categories": "cs.HC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Milgram's reality-virtuality continuum applies to interaction in the physical\nspace dimension, going from real to virtual. However, interaction has a social\ndimension as well, that can go from real to artificial depending on the\ncompanion with whom the user interacts. In this paper we present our vision of\nthe Reality-Artificiality bidimensional Continuum (RAC), we identify some\nchallenges in its design and development and we discuss how reliable\ninteractions might be supported inside RAC.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2020 01:32:00 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Ancona", "Davide", "", "University of Genova, DIBRIS"], ["Bassano", "Chiara", "", "University of Genova, DIBRIS"], ["Chessa", "Manuela", "", "University of Genova,\n  DIBRIS"], ["Mascardi", "Viviana", "", "University of Genova, DIBRIS"], ["Solari", "Fabio", "", "University of Genova, DIBRIS"]]}, {"id": "2007.11743", "submitter": "EPTCS", "authors": "Peter Stringer (University of Liverpool), Rafael C. Cardoso\n  (University of Liverpool), Xiaowei Huang (University of Liverpool), Louise A.\n  Dennis (University of Liverpool)", "title": "Adaptable and Verifiable BDI Reasoning", "comments": "In Proceedings AREA 2020, arXiv:2007.11260", "journal-ref": "EPTCS 319, 2020, pp. 117-125", "doi": "10.4204/EPTCS.319.9", "report-no": null, "categories": "cs.MA cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Long-term autonomy requires autonomous systems to adapt as their capabilities\nno longer perform as expected. To achieve this, a system must first be capable\nof detecting such changes. In this position paper, we describe a system\narchitecture for BDI autonomous agents capable of adapting to changes in a\ndynamic environment and outline the required research. Specifically, we\ndescribe an agent-maintained self-model with accompanying theories of durative\nactions and learning new action descriptions in BDI systems.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2020 01:32:53 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Stringer", "Peter", "", "University of Liverpool"], ["Cardoso", "Rafael C.", "", "University of Liverpool"], ["Huang", "Xiaowei", "", "University of Liverpool"], ["Dennis", "Louise A.", "", "University of Liverpool"]]}, {"id": "2007.11868", "submitter": "Diodato Ferraioli", "authors": "Diodato Ferraioli and Paolo Penna and Carmine Ventre", "title": "Two-way Greedy: Algorithms for Imperfect Rationality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DS cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The realization that selfish interests need to be accounted for in the design\nof algorithms has produced many contributions in computer science under the\numbrella of algorithmic mechanism design. Novel algorithmic properties and\nparadigms have been identified and studied. Our work stems from the observation\nthat selfishness is different from rationality; agents will attempt to\nstrategize whenever they perceive it to be convenient according to their\nimperfect rationality. Recent work has focused on a particular notion of\nimperfect rationality, namely absence of contingent reasoning skills, and\ndefined obvious strategyproofness (OSP) as a way to deal with the selfishness\nof these agents. Essentially, this definition states that to care for the\nincentives of these agents, we need not only pay attention about the\nrelationship between input and output, but also about the way the algorithm is\nrun. However, it is not clear what algorithmic approaches must be used for OSP.\nIn this paper, we show that, for binary allocation problems, OSP is fully\ncaptured by a combination of two well-known algorithmic techniques: forward and\nreverse greedy. We call two-way greedy this algorithmic design paradigm. Our\nmain technical contribution establishes the connection between OSP and two-way\ngreedy. We build upon the recently introduced cycle monotonicity technique for\nOSP. By means of novel structural properties of cycles and queries of OSP\nmechanisms, we fully characterize these mechanisms in terms of extremal\nimplementations. These are protocols that ask each agent to consistently\nseparate one extreme of their domain at the current history from the rest.\nThrough the connection with the greedy paradigm, we are able to import a host\nof approximation bounds to OSP and strengthen the strategic properties of this\nfamily of algorithms. Finally, we begin exploring the power of two-way greedy\nfor set systems.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2020 09:10:44 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Ferraioli", "Diodato", ""], ["Penna", "Paolo", ""], ["Ventre", "Carmine", ""]]}, {"id": "2007.12278", "submitter": "Derya Aksaray", "authors": "Ryan Peterson, Ali Tevfik Buyukkocak, Derya Aksaray, and Yasin\n  Yazicioglu", "title": "Decentralized Safe Reactive Planning under TWTL Specifications", "comments": "8 pages, 4 figures, accepted to IROS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.MA cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate a multi-agent planning problem, where each agent aims to\nachieve an individual task while avoiding collisions with others. We assume\nthat each agent's task is expressed as a Time-Window Temporal Logic (TWTL)\nspecification defined over a 3D environment. We propose a decentralized\nreceding horizon algorithm for online planning of trajectories. We show that\nwhen the environment is sufficiently connected, the resulting agent\ntrajectories are always safe (collision-free) and lead to the satisfaction of\nthe TWTL specifications or their finite temporal relaxations. Accordingly,\ndeadlocks are always avoided and each agent is guaranteed to safely achieve its\ntask with a finite time-delay in the worst case. Performance of the proposed\nalgorithm is demonstrated via numerical simulations and experiments with\nquadrotors.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2020 22:04:46 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Peterson", "Ryan", ""], ["Buyukkocak", "Ali Tevfik", ""], ["Aksaray", "Derya", ""], ["Yazicioglu", "Yasin", ""]]}, {"id": "2007.12306", "submitter": "Jianyu Su", "authors": "Jianyu Su, Stephen Adams, Peter A. Beling", "title": "Value-Decomposition Multi-Agent Actor-Critics", "comments": "Accepted by 35th AAAI Conference on Artificial Intelligence (AAAI\n  2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The exploitation of extra state information has been an active research area\nin multi-agent reinforcement learning (MARL). QMIX represents the joint\naction-value using a non-negative function approximator and achieves the best\nperformance, by far, on multi-agent benchmarks, StarCraft II micromanagement\ntasks. However, our experiments show that, in some cases, QMIX is incompatible\nwith A2C, a training paradigm that promotes algorithm training efficiency. To\nobtain a reasonable trade-off between training efficiency and algorithm\nperformance, we extend value-decomposition to actor-critics that are compatible\nwith A2C and propose a novel actor-critic framework, value-decomposition\nactor-critics (VDACs). We evaluate VDACs on the testbed of StarCraft II\nmicromanagement tasks and demonstrate that the proposed framework improves\nmedian performance over other actor-critic methods. Furthermore, we use a set\nof ablation experiments to identify the key factors that contribute to the\nperformance of VDACs.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 00:50:02 GMT"}, {"version": "v2", "created": "Sat, 1 Aug 2020 17:15:25 GMT"}, {"version": "v3", "created": "Tue, 8 Dec 2020 03:57:03 GMT"}, {"version": "v4", "created": "Fri, 18 Dec 2020 15:16:06 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Su", "Jianyu", ""], ["Adams", "Stephen", ""], ["Beling", "Peter A.", ""]]}, {"id": "2007.12322", "submitter": "Tonghan Wang", "authors": "Yihan Wang, Beining Han, Tonghan Wang, Heng Dong, Chongjie Zhang", "title": "Off-Policy Multi-Agent Decomposed Policy Gradients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-agent policy gradient (MAPG) methods recently witness vigorous\nprogress. However, there is a significant performance discrepancy between MAPG\nmethods and state-of-the-art multi-agent value-based approaches. In this paper,\nwe investigate causes that hinder the performance of MAPG algorithms and\npresent a multi-agent decomposed policy gradient method (DOP). This method\nintroduces the idea of value function decomposition into the multi-agent\nactor-critic framework. Based on this idea, DOP supports efficient off-policy\nlearning and addresses the issue of centralized-decentralized mismatch and\ncredit assignment in both discrete and continuous action spaces. We formally\nshow that DOP critics have sufficient representational capability to guarantee\nconvergence. In addition, empirical evaluations on the StarCraft II\nmicromanagement benchmark and multi-agent particle environments demonstrate\nthat DOP significantly outperforms both state-of-the-art value-based and\npolicy-based multi-agent reinforcement learning algorithms. Demonstrative\nvideos are available at https://sites.google.com/view/dop-mapg/.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 02:21:55 GMT"}, {"version": "v2", "created": "Sun, 4 Oct 2020 08:07:44 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Wang", "Yihan", ""], ["Han", "Beining", ""], ["Wang", "Tonghan", ""], ["Dong", "Heng", ""], ["Zhang", "Chongjie", ""]]}, {"id": "2007.12412", "submitter": "Wojciech Jamroga", "authors": "Wojciech Jamroga, Yan Kim, Damian Kurpiewski, Peter Y. A. Ryan", "title": "Model Checkers Are Cool: How to Model Check Voting Protocols in Uppaal", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LO cs.MA", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The design and implementation of an e-voting system is a challenging task.\nFormal analysis can be of great help here. In particular, it can lead to a\nbetter understanding of how the voting system works, and what requirements on\nthe system are relevant. In this paper, we propose that the state-of-art model\nchecker Uppaal provides a good environment for modelling and preliminary\nverification of voting protocols. To illustrate this, we present an Uppaal\nmodel of Pr\\^et \\`a Voter, together with some natural extensions. We also show\nhow to verify a variant of receipt-freeness, despite the severe limitations of\nthe property specification language in the model checker.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 09:05:06 GMT"}, {"version": "v2", "created": "Sun, 24 Jan 2021 11:28:35 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Jamroga", "Wojciech", ""], ["Kim", "Yan", ""], ["Kurpiewski", "Damian", ""], ["Ryan", "Peter Y. A.", ""]]}, {"id": "2007.12424", "submitter": "Wojciech Jamroga", "authors": "Wojciech Jamroga, Damian Kurpiewski, Vadim Malvone", "title": "Natural Strategic Abilities in Voting Protocols", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.LO", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Security properties are often focused on the technological side of the\nsystem. One implicitly assumes that the users will behave in the right way to\npreserve the property at hand. In real life, this cannot be taken for granted.\nIn particular, security mechanisms that are difficult and costly to use are\noften ignored by the users, and do not really defend the system against\npossible attacks.\n  Here, we propose a graded notion of security based on the complexity of the\nuser's strategic behavior. More precisely, we suggest that the level to which a\nsecurity property $\\varphi$ is satisfied can be defined in terms of (a) the\ncomplexity of the strategy that the voter needs to execute to make $\\varphi$\ntrue, and (b) the resources that the user must employ on the way. The simpler\nand cheaper to obtain $\\varphi$, the higher the degree of security.\n  We demonstrate how the idea works in a case study based on an electronic\nvoting scenario. To this end, we model the vVote implementation of the \\Pret\nvoting protocol for coercion-resistant and voter-verifiable elections. Then, we\nidentify \"natural\" strategies for the voter to obtain receipt-freeness, and\nmeasure the voter's effort that they require. We also look at how hard it is\nfor the coercer to compromise the election through a randomization attack.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 09:28:07 GMT"}, {"version": "v2", "created": "Sun, 24 Jan 2021 11:17:29 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Jamroga", "Wojciech", ""], ["Kurpiewski", "Damian", ""], ["Malvone", "Vadim", ""]]}, {"id": "2007.13050", "submitter": "James Melbourne", "authors": "James Melbourne, Govind Saraswat, Vivek Khatana, Sourav Patel, and\n  Murti V. Salapaka", "title": "Convex Decreasing Algorithms: Distributed Synthesis and Finite-time\n  Termination in Higher Dimension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a general mathematical framework for distributed algorithms, and\na monotonicity property frequently satisfied in application. These properties\nare leveraged to provide finite-time guarantees for converging algorithms,\nsuited for use in the absence of a central authority. A central application is\nto consensus algorithms in higher dimension. These pursuits motivate a new peer\nto peer convex hull algorithm which we demonstrate to be an instantiation of\nthe described theory. To address the diversity of convex sets and the potential\ncomputation and communication costs of knowing such sets in high dimension, a\nlightweight norm based stopping criteria is developed. More explicitly, we give\na distributed algorithm that terminates in finite time when applied to\nconsensus problems in higher dimensions and guarantees the convergence of the\nconsensus algorithm in norm, within any given tolerance. Applications to\nconsensus least squared estimation and distributed function determination are\ndeveloped. The practical utility of the algorithm is illustrated through MATLAB\nsimulations.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jul 2020 04:00:53 GMT"}, {"version": "v2", "created": "Thu, 30 Jul 2020 06:00:20 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Melbourne", "James", ""], ["Saraswat", "Govind", ""], ["Khatana", "Vivek", ""], ["Patel", "Sourav", ""], ["Salapaka", "Murti V.", ""]]}, {"id": "2007.13231", "submitter": "Masoud Jalayer", "authors": "Masoud Jalayer, Carlotta Orsenigo, Carlo Vercellis", "title": "CoV-ABM: A stochastic discrete-event agent-based framework to simulate\n  spatiotemporal dynamics of COVID-19", "comments": "25 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The paper develops a stochastic Agent-Based Model (ABM) mimicking the spread\nof infectious diseases in geographical domains. The model is designed to\nsimulate the spatiotemporal spread of SARS-CoV2 disease, known as COVID-19. Our\nSARS-CoV2-based ABM framework (CoV-ABM) simulates the spread at any\ngeographical scale, ranging from a village to a country and considers unique\ncharacteristics of SARS-CoV2 viruses such as its persistence in the\nenvironment. Therefore, unlike other simulators, CoV-ABM computes the density\nof active viruses inside each location space to get the virus transmission\nprobability for each agent. It also uses the local census and health data to\ncreate health and risk factor profiles for each individual. The proposed model\nrelies on a flexible timestamp scale to optimize the computational speed and\nthe level of detail. In our framework each agent represents a person\ninteracting with the surrounding space and other adjacent agents inside the\nsame space. Moreover, families stochastic daily tasks are formulated to get\ntracked by the corresponding family members. The model also formulates the\npossibility of meetings for each subset of friendships and relatives. The main\naim of the proposed framework is threefold: to illustrate the dynamics of\nSARS-CoV diseases, to identify places which have a higher probability to become\ninfection hubs and to provide a decision-support system to design efficient\ninterventions in order to fight against pandemics. The framework employs SEIHRD\ndynamics of viral diseases with different intervention scenarios. The paper\nsimulates the spread of COVID-19 in the State of Delaware, United States, with\nnear one million stochastic agents. The results achieved over a period of 15\nweeks with a timestamp of 1 hour show which places become the hubs of\ninfection. The paper also illustrates how hospitals get overwhelmed as the\noutbreak reaches its pick.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jul 2020 22:20:57 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Jalayer", "Masoud", ""], ["Orsenigo", "Carlotta", ""], ["Vercellis", "Carlo", ""]]}, {"id": "2007.13699", "submitter": "Vaneet Aggarwal", "authors": "Kaushik Manchella and Abhishek K. Umrawal and Vaneet Aggarwal", "title": "FlexPool: A Distributed Model-Free Deep Reinforcement Learning Algorithm\n  for Joint Passengers & Goods Transportation", "comments": "Accepted to IEEE Transactions on Intelligent Transportation Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growth in online goods delivery is causing a dramatic surge in urban\nvehicle traffic from last-mile deliveries. On the other hand, ride-sharing has\nbeen on the rise with the success of ride-sharing platforms and increased\nresearch on using autonomous vehicle technologies for routing and matching. The\nfuture of urban mobility for passengers and goods relies on leveraging new\nmethods that minimize operational costs and environmental footprints of\ntransportation systems.\n  This paper considers combining passenger transportation with goods delivery\nto improve vehicle-based transportation. Even though the problem has been\nstudied with a defined dynamics model of the transportation system environment,\nthis paper considers a model-free approach that has been demonstrated to be\nadaptable to new or erratic environment dynamics. We propose FlexPool, a\ndistributed model-free deep reinforcement learning algorithm that jointly\nserves passengers & goods workloads by learning optimal dispatch policies from\nits interaction with the environment. The proposed algorithm pools passengers\nfor a ride-sharing service and delivers goods using a multi-hop transit method.\nThese flexibilities decrease the fleet's operational cost and environmental\nfootprint while maintaining service levels for passengers and goods. Through\nsimulations on a realistic multi-agent urban mobility platform, we demonstrate\nthat FlexPool outperforms other model-free settings in serving the demands from\npassengers & goods. FlexPool achieves 30% higher fleet utilization and 35%\nhigher fuel efficiency in comparison to (i) model-free approaches where\nvehicles transport a combination of passengers & goods without the use of\nmulti-hop transit, and (ii) model-free approaches where vehicles exclusively\ntransport either passengers or goods.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2020 17:25:58 GMT"}, {"version": "v2", "created": "Sun, 20 Sep 2020 19:09:34 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Manchella", "Kaushik", ""], ["Umrawal", "Abhishek K.", ""], ["Aggarwal", "Vaneet", ""]]}, {"id": "2007.13897", "submitter": "Tamzidul Mina", "authors": "Tamzidul Mina, Shyam Sundar Kannan, Wonse Jo and Byung-Cheol Min", "title": "Adaptive Workload Allocation for Multi-human Multi-robot Teams for\n  Independent and Homogeneous Tasks", "comments": "14 pages, 13 figures, submitted to IEEE ACCESS. For associated file,\n  see https://youtu.be/-WY49FPbNWg", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-human multi-robot (MH-MR) systems have the ability to combine the\npotential advantages of robotic systems with those of having humans in the\nloop. Robotic systems contribute precision performance and long operation on\nrepetitive tasks without tiring, while humans in the loop improve situational\nawareness and enhance decision-making abilities. A system's ability to adapt\nallocated workload to changing conditions and the performance of each\nindividual (human and robot) during the mission is vital to maintaining overall\nsystem performance. Previous works from literature including market-based and\noptimization approaches have attempted to address the task/workload allocation\nproblem with focus on maximizing the system output without regarding individual\nagent conditions, lacking in real-time processing and have mostly focused\nexclusively on multi-robot systems. Given the variety of possible combination\nof teams (autonomous robots and human-operated robots: any number of human\noperators operating any number of robots at a time) and the operational scale\nof MH-MR systems, development of a generalized framework of workload allocation\nhas been a particularly challenging task. In this paper, we present such a\nframework for independent homogeneous missions, capable of adaptively\nallocating the system workload in relation to health conditions and work\nperformances of human-operated and autonomous robots in real-time. The\nframework consists of removable modular function blocks ensuring its\napplicability to different MH-MR scenarios. A new workload transition function\nblock ensures smooth transition without the workload change having adverse\neffects on individual agents. The effectiveness and scalability of the system's\nworkload adaptability is validated by experiments applying the proposed\nframework in a MH-MR patrolling scenario with changing human and robot\ncondition, and failing robots.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2020 22:36:11 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Mina", "Tamzidul", ""], ["Kannan", "Shyam Sundar", ""], ["Jo", "Wonse", ""], ["Min", "Byung-Cheol", ""]]}, {"id": "2007.14358", "submitter": "Gabriele Farina", "authors": "Gabriele Farina and Christian Kroer and Tuomas Sandholm", "title": "Faster Game Solving via Predictive Blackwell Approachability: Connecting\n  Regret Matching and Mirror Descent", "comments": "Full version. The body of the paper appeared in the proceedings of\n  the AAAI 2021 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.LG cs.MA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blackwell approachability is a framework for reasoning about repeated games\nwith vector-valued payoffs. We introduce predictive Blackwell approachability,\nwhere an estimate of the next payoff vector is given, and the decision maker\ntries to achieve better performance based on the accuracy of that estimator. In\norder to derive algorithms that achieve predictive Blackwell approachability,\nwe start by showing a powerful connection between four well-known algorithms.\nFollow-the-regularized-leader (FTRL) and online mirror descent (OMD) are the\nmost prevalent regret minimizers in online convex optimization. In spite of\nthis prevalence, the regret matching (RM) and regret matching+ (RM+) algorithms\nhave been preferred in the practice of solving large-scale games (as the local\nregret minimizers within the counterfactual regret minimization framework). We\nshow that RM and RM+ are the algorithms that result from running FTRL and OMD,\nrespectively, to select the halfspace to force at all times in the underlying\nBlackwell approachability game. By applying the predictive variants of FTRL or\nOMD to this connection, we obtain predictive Blackwell approachability\nalgorithms, as well as predictive variants of RM and RM+. In experiments across\n18 common zero-sum extensive-form benchmark games, we show that predictive RM+\ncoupled with counterfactual regret minimization converges vastly faster than\nthe fastest prior algorithms (CFR+, DCFR, LCFR) across all games but two of the\npoker games, sometimes by two or more orders of magnitude.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2020 16:49:55 GMT"}, {"version": "v2", "created": "Mon, 8 Mar 2021 04:15:38 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Farina", "Gabriele", ""], ["Kroer", "Christian", ""], ["Sandholm", "Tuomas", ""]]}, {"id": "2007.14957", "submitter": "Feng Huang", "authors": "Feng Huang, Ming Cao, and Long Wang", "title": "Learning enables adaptation in cooperation for multi-player stochastic\n  games", "comments": null, "journal-ref": "J. R. Soc. Interface 17: 20200639 (2020)", "doi": "10.1098/rsif.2020.0639", "report-no": null, "categories": "q-bio.PE cs.GT cs.MA physics.bio-ph physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interactions among individuals in natural populations often occur in a\ndynamically changing environment. Understanding the role of environmental\nvariation in population dynamics has long been a central topic in theoretical\necology and population biology. However, the key question of how individuals,\nin the middle of challenging social dilemmas (e.g., the \"tragedy of the\ncommons\"), modulate their behaviors to adapt to the fluctuation of the\nenvironment has not yet been addressed satisfactorily. Utilizing evolutionary\ngame theory and stochastic games, we develop a game-theoretical framework that\nincorporates the adaptive mechanism of reinforcement learning to investigate\nwhether cooperative behaviors can evolve in the ever-changing group interaction\nenvironment. When the action choices of players are just slightly influenced by\npast reinforcements, we construct an analytical condition to determine whether\ncooperation can be favored over defection. Intuitively, this condition reveals\nwhy and how the environment can mediate cooperative dilemmas. Under our model\narchitecture, we also compare this learning mechanism with two non-learning\ndecision rules, and we find that learning significantly improves the propensity\nfor cooperation in weak social dilemmas, and, in sharp contrast, hinders\ncooperation in strong social dilemmas. Our results suggest that in complex\nsocial-ecological dilemmas, learning enables the adaptation of individuals to\nvarying environments.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2020 17:01:24 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Huang", "Feng", ""], ["Cao", "Ming", ""], ["Wang", "Long", ""]]}, {"id": "2007.15724", "submitter": "Zuxin Liu", "authors": "Zuxin Liu, Baiming Chen, Hongyi Zhou, Guru Koushik, Martial Hebert,\n  Ding Zhao", "title": "MAPPER: Multi-Agent Path Planning with Evolutionary Reinforcement\n  Learning in Mixed Dynamic Environments", "comments": "6 pages, accepted at the 2020 IEEE/RSJ International Conference on\n  Intelligent Robots and Systems (IROS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-agent navigation in dynamic environments is of great industrial value\nwhen deploying a large scale fleet of robot to real-world applications. This\npaper proposes a decentralized partially observable multi-agent path planning\nwith evolutionary reinforcement learning (MAPPER) method to learn an effective\nlocal planning policy in mixed dynamic environments. Reinforcement\nlearning-based methods usually suffer performance degradation on long-horizon\ntasks with goal-conditioned sparse rewards, so we decompose the long-range\nnavigation task into many easier sub-tasks under the guidance of a global\nplanner, which increases agents' performance in large environments. Moreover,\nmost existing multi-agent planning approaches assume either perfect information\nof the surrounding environment or homogeneity of nearby dynamic agents, which\nmay not hold in practice. Our approach models dynamic obstacles' behavior with\nan image-based representation and trains a policy in mixed dynamic environments\nwithout homogeneity assumption. To ensure multi-agent training stability and\nperformance, we propose an evolutionary training approach that can be easily\nscaled to large and complex environments. Experiments show that MAPPER is able\nto achieve higher success rates and more stable performance when exposed to a\nlarge number of non-cooperative dynamic obstacles compared with traditional\nreaction-based planner LRA* and the state-of-the-art learning-based method.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jul 2020 20:14:42 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Liu", "Zuxin", ""], ["Chen", "Baiming", ""], ["Zhou", "Hongyi", ""], ["Koushik", "Guru", ""], ["Hebert", "Martial", ""], ["Zhao", "Ding", ""]]}, {"id": "2007.16045", "submitter": "Pablo Barros", "authors": "Pablo Barros, Ana Tanevska, Francisco Cruz, Alessandra Sciutti", "title": "Moody Learners -- Explaining Competitive Behaviour of Reinforcement\n  Learning Agents", "comments": "Accepted by ICDl-EPIROB 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Designing the decision-making processes of artificial agents that are\ninvolved in competitive interactions is a challenging task. In a competitive\nscenario, the agent does not only have a dynamic environment but also is\ndirectly affected by the opponents' actions. Observing the Q-values of the\nagent is usually a way of explaining its behavior, however, do not show the\ntemporal-relation between the selected actions. We address this problem by\nproposing the \\emph{Moody framework}. We evaluate our model by performing a\nseries of experiments using the competitive multiplayer Chef's Hat card game\nand discuss how our model allows the agents' to obtain a holistic\nrepresentation of the competitive dynamics within the game.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jul 2020 11:30:42 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Barros", "Pablo", ""], ["Tanevska", "Ana", ""], ["Cruz", "Francisco", ""], ["Sciutti", "Alessandra", ""]]}, {"id": "2007.16088", "submitter": "Emmanouil Rigas", "authors": "Emmanouil Rigas, Konstantinos Tsompanidis", "title": "Congestion Management for Mobility-on-Demand Schemes that use Electric\n  Vehicles", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-66412-1_4", "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To date the majority of commuters use their privately owned vehicle that uses\nan internal combustion engine. This transportation model suffers from low\nvehicle utilization and causes environmental pollution. This paper studies the\nuse of Electric Vehicles (EVs) operating in a Mobility-on-Demand (MoD) scheme\nand tackles the related management challenges. We assume a number of customers\nacting as cooperative agents requesting a set of alternative trips and EVs\ndistributed across a number of pick-up and drop-off stations. In this setting,\nwe propose congestion management algorithms which take as input the trip\nrequests and calculate the EV-to-customer assignment aiming to maximize trip\nexecution by keeping the system balanced in terms of matching demand and\nsupply. We propose a Mixed-Integer-Programming (MIP) optimal offline solution\nwhich assumes full knowledge of customer demand and an equivalent online greedy\nalgorithm that can operate in real time. The online algorithm uses three\nalternative heuristic functions in deciding whether to execute a customer\nrequest: (a) The sum of squares of all EVs in all stations, (b) the percentage\nof trips' destination location fullness and (c) a random choice of trip\nexecution. Through a detailed evaluation, we observe that (a) provides an\nincrease of up to 4.8% compared to (b) and up to 11.5% compared to (c) in terms\nof average trip execution, while all of them achieve close to the optimal\nperformance. At the same time, the optimal scales up to settings consisting of\ntenths of EVs and a few hundreds of customer requests.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2020 09:38:10 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Rigas", "Emmanouil", ""], ["Tsompanidis", "Konstantinos", ""]]}, {"id": "2007.16089", "submitter": "EPTCS", "authors": "Chidiebere Onyedinma (University of Ottawa), Patrick Gavigan (Carleton\n  University), Babak Esfandiari (Carleton University)", "title": "Toward Campus Mail Delivery Using BDI", "comments": "In Proceedings AREA 2020, arXiv:2007.11260", "journal-ref": "EPTCS 319, 2020, pp. 127-143", "doi": "10.4204/EPTCS.319.10", "report-no": null, "categories": "cs.MA cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous systems developed with the Belief-Desire-Intention (BDI)\narchitecture are usually mostly implemented in simulated environments. In this\nproject we sought to build a BDI agent for use in the real world for campus\nmail delivery in the tunnel system at Carleton University. Ideally, the robot\nshould receive a delivery order via a mobile application, pick up the mail at a\nstation, navigate the tunnels to the destination station, and notify the\nrecipient.\n  We linked the Robot Operating System (ROS) with a BDI reasoning system to\nachieve a subset of the required use cases. ROS handles the low-level sensing\nand actuation, while the BDI reasoning system handles the high-level reasoning\nand decision making. Sensory data is orchestrated and sent from ROS to the\nreasoning system as perceptions. These perceptions are then deliberated upon,\nand an action string is sent back to ROS for interpretation and driving of the\nnecessary actuator for the action to be performed.\n  In this paper we present our current implementation, which closes the loop on\nthe hardware-software integration, and implements a subset of the use cases\nrequired for the full system.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2020 01:33:10 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Onyedinma", "Chidiebere", "", "University of Ottawa"], ["Gavigan", "Patrick", "", "Carleton\n  University"], ["Esfandiari", "Babak", "", "Carleton University"]]}]