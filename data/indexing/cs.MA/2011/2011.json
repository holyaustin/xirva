[{"id": "2011.00120", "submitter": "Eugene Vinitsky", "authors": "Eugene Vinitsky, Nathan Lichtle, Kanaad Parvate, Alexandre Bayen", "title": "Optimizing Mixed Autonomy Traffic Flow With Decentralized Autonomous\n  Vehicles and Multi-Agent RL", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.MA cs.RO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the ability of autonomous vehicles to improve the throughput of a\nbottleneck using a fully decentralized control scheme in a mixed autonomy\nsetting. We consider the problem of improving the throughput of a scaled model\nof the San Francisco-Oakland Bay Bridge: a two-stage bottleneck where four\nlanes reduce to two and then reduce to one. Although there is extensive work\nexamining variants of bottleneck control in a centralized setting, there is\nless study of the challenging multi-agent setting where the large number of\ninteracting AVs leads to significant optimization difficulties for\nreinforcement learning methods. We apply multi-agent reinforcement algorithms\nto this problem and demonstrate that significant improvements in bottleneck\nthroughput, from 20\\% at a 5\\% penetration rate to 33\\% at a 40\\% penetration\nrate, can be achieved. We compare our results to a hand-designed feedback\ncontroller and demonstrate that our results sharply outperform the feedback\ncontroller despite extensive tuning. Additionally, we demonstrate that the\nRL-based controllers adopt a robust strategy that works across penetration\nrates whereas the feedback controllers degrade immediately upon penetration\nrate variation. We investigate the feasibility of both action and observation\ndecentralization and demonstrate that effective strategies are possible using\npurely local sensing. Finally, we open-source our code at\nhttps://github.com/eugenevinitsky/decentralized_bottlenecks.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 22:06:05 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Vinitsky", "Eugene", ""], ["Lichtle", "Nathan", ""], ["Parvate", "Kanaad", ""], ["Bayen", "Alexandre", ""]]}, {"id": "2011.00165", "submitter": "Esmaeil Seraj", "authors": "Esmaeil Seraj, Xiyang Wu, Matthew Gombolay", "title": "FireCommander: An Interactive, Probabilistic Multi-agent Environment for\n  Joint Perception-Action Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.HC cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of this tutorial is to help individuals use the\n\\underline{FireCommander} game environment for research applications. The\nFireCommander is an interactive, probabilistic joint perception-action\nreconnaissance environment in which a composite team of agents (e.g., robots)\ncooperate to fight dynamic, propagating firespots (e.g., targets). In\nFireCommander game, a team of agents must be tasked to optimally deal with a\nwildfire situation in an environment with propagating fire areas and some\nfacilities such as houses, hospitals, power stations, etc. The team of agents\ncan accomplish their mission by first sensing (e.g., estimating fire states),\ncommunicating the sensed fire-information among each other and then taking\naction to put the firespots out based on the sensed information (e.g., dropping\nwater on estimated fire locations). The FireCommander environment can be useful\nfor research topics spanning a wide range of applications from Reinforcement\nLearning (RL) and Learning from Demonstration (LfD), to Coordination,\nPsychology, Human-Robot Interaction (HRI) and Teaming. There are four important\nfacets of the FireCommander environment that overall, create a non-trivial\ngame: (1) Complex Objectives: Multi-objective Stochastic Environment,\n(2)Probabilistic Environment: Agents' actions result in probabilistic\nperformance, (3) Hidden Targets: Partially Observable Environment and, (4)\nUni-task Robots: Perception-only and Action-only agents. The FireCommander\nenvironment is first-of-its-kind in terms of including Perception-only and\nAction-only agents for coordination. It is a general multi-purpose game that\ncan be useful in a variety of combinatorial optimization problems and\nstochastic games, such as applications of Reinforcement Learning (RL), Learning\nfrom Demonstration (LfD) and Inverse RL (iRL).\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 02:06:07 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Seraj", "Esmaeil", ""], ["Wu", "Xiyang", ""], ["Gombolay", "Matthew", ""]]}, {"id": "2011.00382", "submitter": "Dong-Ki Kim", "authors": "Dong-Ki Kim, Miao Liu, Matthew Riemer, Chuangchuang Sun, Marwa\n  Abdulhai, Golnaz Habibi, Sebastian Lopez-Cot, Gerald Tesauro, Jonathan P. How", "title": "A Policy Gradient Algorithm for Learning to Learn in Multiagent\n  Reinforcement Learning", "comments": "Accepted to ICML 2021. Code at https://github.com/dkkim93/meta-mapg\n  and Videos at https://sites.google.com/view/meta-mapg/home", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental challenge in multiagent reinforcement learning is to learn\nbeneficial behaviors in a shared environment with other simultaneously learning\nagents. In particular, each agent perceives the environment as effectively\nnon-stationary due to the changing policies of other agents. Moreover, each\nagent is itself constantly learning, leading to natural non-stationarity in the\ndistribution of experiences encountered. In this paper, we propose a novel\nmeta-multiagent policy gradient theorem that directly accounts for the\nnon-stationary policy dynamics inherent to multiagent learning settings. This\nis achieved by modeling our gradient updates to consider both an agent's own\nnon-stationary policy dynamics and the non-stationary policy dynamics of other\nagents in the environment. We show that our theoretically grounded approach\nprovides a general solution to the multiagent learning problem, which\ninherently comprises all key aspects of previous state of the art approaches on\nthis topic. We test our method on a diverse suite of multiagent benchmarks and\ndemonstrate a more efficient ability to adapt to new agents as they learn than\nbaseline methods across the full spectrum of mixed incentive, competitive, and\ncooperative domains.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 22:50:21 GMT"}, {"version": "v2", "created": "Wed, 2 Dec 2020 22:08:50 GMT"}, {"version": "v3", "created": "Sat, 6 Feb 2021 17:45:17 GMT"}, {"version": "v4", "created": "Thu, 3 Jun 2021 16:46:58 GMT"}, {"version": "v5", "created": "Fri, 11 Jun 2021 22:21:49 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Kim", "Dong-Ki", ""], ["Liu", "Miao", ""], ["Riemer", "Matthew", ""], ["Sun", "Chuangchuang", ""], ["Abdulhai", "Marwa", ""], ["Habibi", "Golnaz", ""], ["Lopez-Cot", "Sebastian", ""], ["Tesauro", "Gerald", ""], ["How", "Jonathan P.", ""]]}, {"id": "2011.00424", "submitter": "Hardik Meisheri", "authors": "Hardik Meisheri, Harshad Khadilkar", "title": "Sample Efficient Training in Multi-Agent Adversarial Games with Limited\n  Teammate Communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We describe our solution approach for Pommerman TeamRadio, a competition\nenvironment associated with NeurIPS 2019. The defining feature of our algorithm\nis achieving sample efficiency within a restrictive computational budget while\nbeating the previous years learning agents. The proposed algorithm (i) uses\nimitation learning to seed the policy, (ii) explicitly defines the\ncommunication protocol between the two teammates, (iii) shapes the reward to\nprovide a richer feedback signal to each agent during training and (iv) uses\nmasking for catastrophic bad actions. We describe extensive tests against\nbaselines, including those from the 2019 competition leaderboard, and also a\nspecific investigation of the learned policy and the effect of each\nmodification on performance. We show that the proposed approach is able to\nachieve competitive performance within half a million games of training,\nsignificantly faster than other studies in the literature.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 04:50:02 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Meisheri", "Hardik", ""], ["Khadilkar", "Harshad", ""]]}, {"id": "2011.00441", "submitter": "Licheng Wen", "authors": "Licheng Wen, Zhen Zhang, Zhe Chen, Xiangrui Zhao, Yong Liu", "title": "CL-MAPF: Multi-Agent Path Finding for Car-Like Robots with Kinematic and\n  Spatiotemporal Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-Agent Path Finding has been widely studied in the past few years due to\nits broad application in the field of robotics and AI. However, previous\nsolvers rely on several simplifying assumptions. They limit their applicability\nin numerous real-world domains that adopt nonholonomic car-like agents rather\nthan holonomic ones. In this paper, we give a mathematical formalization of\nMulti-Agent Path Finding for Car-Like robots (CL-MAPF) problem. For the first\ntime, we propose a novel hierarchical search-based solver called Car-like\nConflict-Based Search to address this problem. It applies a body conflict tree\nto address collisions considering shapes of the agents. We introduce a new\nalgorithm called Spatiotemporal Hybrid-State A* as the single-agent path\nplanner to generate path satisfying both kinematic and spatiotemporal\nconstraints. We also present a sequential planning version of our method for\nthe sake of efficiency. We compare our method with two baseline algorithms on a\ndedicated benchmark containing 3000 instances and validate it in real-world\nscenarios. The experiment results give clear evidence that our algorithm scales\nwell to a large number of agents and is able to produce solutions that can be\ndirectly applied to car-like robots in the real world. The benchmark and source\ncode are released in https://github.com/APRIL-ZJU/CL-CBS.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 06:42:25 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Wen", "Licheng", ""], ["Zhang", "Zhen", ""], ["Chen", "Zhe", ""], ["Zhao", "Xiangrui", ""], ["Liu", "Yong", ""]]}, {"id": "2011.00462", "submitter": "Jun Ma", "authors": "Jun Ma, Zilong Cheng, Xiaoxue Zhang, Masayoshi Tomizuka, Tong Heng Lee", "title": "Alternating Direction Method of Multipliers for Constrained Iterative\n  LQR in Autonomous Driving", "comments": "9 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.MA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of autonomous driving, the iterative linear quadratic\nregulator (iLQR) is known to be an efficient approach to deal with the\nnonlinear vehicle models in motion planning problems. Particularly, the\nconstrained iLQR algorithm has shown noteworthy advantageous outcomes of\ncomputation efficiency in achieving motion planning tasks under general\nconstraints of different types. However, the constrained iLQR methodology\nrequires a feasible trajectory at the first iteration as a prerequisite. Also,\nthe methodology leaves open the possibility for incorporation of fast,\nefficient, and effective optimization methods (i.e., fast-solvers) to further\nspeed up the optimization process such that the requirements of real-time\nimplementation can be successfully fulfilled. In this paper, a well-defined and\ncommonly-encountered motion planning problem is formulated under nonlinear\nvehicle dynamics and various constraints, and an alternating direction method\nof multipliers (ADMM) is developed to determine the optimal control actions.\nWith this development, the approach is able to circumvent the feasibility\nrequirement of the trajectory at the first iteration. An illustrative example\nof motion planning in autonomous vehicles is then investigated with different\ndriving scenarios taken into consideration. As clearly observed from the\nsimulation results, the significance of this work in terms of obstacle\navoidance is demonstrated. Furthermore, a noteworthy achievement of high\ncomputation efficiency is attained; and as a result, real-time computation and\nimplementation can be realized through this framework, and thus it provides\nadditional safety to the on-road driving tasks.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 10:11:28 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Ma", "Jun", ""], ["Cheng", "Zilong", ""], ["Zhang", "Xiaoxue", ""], ["Tomizuka", "Masayoshi", ""], ["Lee", "Tong Heng", ""]]}, {"id": "2011.00463", "submitter": "Jun Ma", "authors": "Xiaoxue Zhang, Jun Ma, Zilong Cheng, Sunan Huang, Clarence W. de\n  Silva, Tong Heng Lee", "title": "Hierarchical ADMM for Nonconvex Cooperative Distributed Model Predictive\n  Control", "comments": "11 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed optimization is often widely attempted and innovated as an\nattractive and preferred methodology to solve large-scale problems effectively\nin a localized and coordinated manner. Thus along this line, it is noteworthy\nthat the methodology of distributed model predictive control (DMPC) has become\na promising approach to achieve effective outcomes, e.g., in decision-making\ntasks for multi-agent systems. However, the typical deployment of such\ndistributed MPC frameworks would lead to the involvement of nonlinear processes\nwith a large number of nonconvex constraints. To address this important\nproblem, the development and innovation of a hierarchical three-block\nalternating direction method of multipliers (ADMM) approach is presented in\nthis work to solve this nonconvex cooperative DMPC problem in multi-agent\nsystems. Here firstly, an additional slack variable is introduced to relax the\noriginal large-scale nonconvex optimization problem. Then, a hierarchical ADMM\napproach, which contains outer loop iteration by the augmented Lagrangian\nmethod (ALM) and inner loop iteration by three-block semi-proximal ADMM, is\nutilized to solve the resulting relaxed nonconvex optimization problem.\nAdditionally, it is analytically shown and established that the requisite\ndesired stationary point exists for the procedures of the hierarchical stages\nfor convergence in the algorithm. Finally, an approximate optimization stage\nwith a barrier method is then applied to further significantly improve the\ncomputational efficiency, yielding the final improved hierarchical ADMM. The\neffectiveness of the proposed method in terms of attained performance and\ncomputational efficiency is demonstrated on a cooperative DMPC problem of\ndecision-making process for multiple unmanned aerial vehicles (UAVs).\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 10:19:22 GMT"}, {"version": "v2", "created": "Mon, 1 Feb 2021 04:04:17 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Zhang", "Xiaoxue", ""], ["Ma", "Jun", ""], ["Cheng", "Zilong", ""], ["Huang", "Sunan", ""], ["de Silva", "Clarence W.", ""], ["Lee", "Tong Heng", ""]]}, {"id": "2011.00554", "submitter": "Aniket Bera", "authors": "Vishnu Sashank Dorbala, Arjun Srinivasan, and Aniket Bera", "title": "Can a Robot Trust You? A DRL-Based Approach to Trust-Driven Human-Guided\n  Navigation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans are known to construct cognitive maps of their everyday surroundings\nusing a variety of perceptual inputs. As such, when a human is asked for\ndirections to a particular location, their wayfinding capability in converting\nthis cognitive map into directional instructions is challenged. Owing to\nspatial anxiety, the language used in the spoken instructions can be vague and\noften unclear. To account for this unreliability in navigational guidance, we\npropose a novel Deep Reinforcement Learning (DRL) based trust-driven robot\nnavigation algorithm that learns humans' trustworthiness to perform a language\nguided navigation task. Our approach seeks to answer the question as to whether\na robot can trust a human's navigational guidance or not. To this end, we look\nat training a policy that learns to navigate towards a goal location using only\ntrustworthy human guidance, driven by its own robot trust metric. We look at\nquantifying various affective features from language-based instructions and\nincorporate them into our policy's observation space in the form of a human\ntrust metric. We utilize both these trust metrics into an optimal cognitive\nreasoning scheme that decides when and when not to trust the given guidance.\nOur results show that the learned policy can navigate the environment in an\noptimal, time-efficient manner as opposed to an explorative approach that\nperforms the same task. We showcase the efficacy of our results both in\nsimulation and a real-world environment.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 16:43:10 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Dorbala", "Vishnu Sashank", ""], ["Srinivasan", "Arjun", ""], ["Bera", "Aniket", ""]]}, {"id": "2011.00583", "submitter": "Yaodong Yang Mr.", "authors": "Yaodong Yang, Jun Wang", "title": "An Overview of Multi-Agent Reinforcement Learning from Game Theoretical\n  Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Following the remarkable success of the AlphaGO series, 2019 was a booming\nyear that witnessed significant advances in multi-agent reinforcement learning\n(MARL) techniques. MARL corresponds to the learning problem in a multi-agent\nsystem in which multiple agents learn simultaneously. It is an\ninterdisciplinary domain with a long history that includes game theory, machine\nlearning, stochastic control, psychology, and optimisation. Although MARL has\nachieved considerable empirical success in solving real-world games, there is a\nlack of a self-contained overview in the literature that elaborates the game\ntheoretical foundations of modern MARL methods and summarises the recent\nadvances. In fact, the majority of existing surveys are outdated and do not\nfully cover the recent developments since 2010. In this work, we provide a\nmonograph on MARL that covers both the fundamentals and the latest developments\nin the research frontier. The goal of our monograph is to provide a\nself-contained assessment of the current state-of-the-art MARL techniques from\na game theoretical perspective. We expect this work to serve as a stepping\nstone for both new researchers who are about to enter this fast-growing domain\nand existing domain experts who want to obtain a panoramic view and identify\nnew directions based on recent advances.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 18:24:40 GMT"}, {"version": "v2", "created": "Thu, 3 Dec 2020 17:50:27 GMT"}, {"version": "v3", "created": "Thu, 18 Mar 2021 01:43:32 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Yang", "Yaodong", ""], ["Wang", "Jun", ""]]}, {"id": "2011.01057", "submitter": "Thomas Schl\\\"ogl", "authors": "Thomas Schl\\\"ogl (1) and Ulrich Schmid (1) and Roman Kuznets (1) ((1)\n  TU Wien, Vienna, Austria)", "title": "The Persistence of False Memory: Brain in a Vat Despite Perfect Clocks", "comments": "34 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, a detailed epistemic reasoning framework for multi-agent systems\nwith byzantine faulty asynchronous agents and possibly unreliable communication\nwas introduced. We have developed a modular extension framework implemented on\ntop of it, which allows to encode and safely combine additional system\nassumptions commonly used in the modeling and analysis of fault-tolerant\ndistributed systems, like reliable communication, time-bounded communication,\nmulticasting, synchronous and lock-step synchronous agents and even agents with\ncoordinated actions. We use this extension framework for analyzing basic\nproperties of synchronous and lock-step synchronous agents, such as the agents'\nlocal and global fault detection abilities. Moreover, we show that even the\nperfectly synchronized clocks available in lock-step synchronous systems cannot\nbe used to avoid \"brain-in-a-vat\" scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 15:40:13 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Schl\u00f6gl", "Thomas", ""], ["Schmid", "Ulrich", ""], ["Kuznets", "Roman", ""]]}, {"id": "2011.01141", "submitter": "Junghoon Kim", "authors": "Junghoon Kim, Seyyedali Hosseinalipour, Taejoon Kim, David J. Love,\n  Christopher G. Brinton", "title": "Multi-IRS-assisted Multi-Cell Uplink MIMO Communications under Imperfect\n  CSI: A Deep Reinforcement Learning Approach", "comments": "7 pages, 3 figures, Accepted for publication in Proceedings of IEEE\n  International Conference on Communications (ICC) Workshop, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.LG cs.MA cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applications of intelligent reflecting surfaces (IRSs) in wireless networks\nhave attracted significant attention recently. Most of the relevant literature\nis focused on the single cell setting where a single IRS is deployed and\nperfect channel state information (CSI) is assumed. In this work, we develop a\nnovel methodology for multi-IRS-assisted multi-cell networks in the uplink. We\nconsider the scenario in which (i) channels are dynamic and (ii) only partial\nCSI is available at each base station (BS); specifically, scalar effective\nchannel powers from only a subset of user equipments (UE). We formulate the\nsum-rate maximization problem aiming to jointly optimize the IRS reflect\nbeamformers, BS combiners, and UE transmit powers. In casting this as a\nsequential decision making problem, we propose a multi-agent deep reinforcement\nlearning algorithm to solve it, where each BS acts as an independent agent in\ncharge of tuning the local UE transmit powers, the local IRS reflect\nbeamformer, and its combiners. We introduce an efficient information-sharing\nscheme that requires limited information exchange among neighboring BSs to cope\nwith the non-stationarity caused by the coupling of actions taken by multiple\nBSs. Our numerical results show that our method obtains substantial improvement\nin average data rate compared to baseline approaches, e.g., fixed UE transmit\npower and maximum ratio combining.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 17:33:23 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2020 18:48:29 GMT"}, {"version": "v3", "created": "Sun, 8 Nov 2020 17:16:00 GMT"}, {"version": "v4", "created": "Mon, 23 Nov 2020 19:21:06 GMT"}, {"version": "v5", "created": "Wed, 24 Feb 2021 12:32:14 GMT"}, {"version": "v6", "created": "Thu, 1 Apr 2021 10:22:28 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Kim", "Junghoon", ""], ["Hosseinalipour", "Seyyedali", ""], ["Kim", "Taejoon", ""], ["Love", "David J.", ""], ["Brinton", "Christopher G.", ""]]}, {"id": "2011.01727", "submitter": "Georgina Montserrat Resendiz Benhumea", "authors": "Georgina Montserrat Res\\'endiz-Benhumea, Ekaterina Sangati and Tom\n  Froese", "title": "Levels of Coupling in Dyadic Interaction: An Analysis of Neural and\n  Behavioral Complexity", "comments": "7 pages, 6 figures, accepted for the 2020 IEEE Symposium Series on\n  Computational Intelligence (IEEE SSCI 2020), IEEE Symposium on Artificial\n  Life (IEEE ALIFE)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  From an enactive approach, some previous studies have demonstrated that\nsocial interaction plays a fundamental role in the dynamics of neural and\nbehavioral complexity of embodied agents. In particular, it has been shown that\nagents with a limited internal structure (2-neuron brains) that evolve in\ninteraction can overcome this limitation and exhibit chaotic neural activity,\ntypically associated with more complex dynamical systems (at least\n3-dimensional). In the present paper we make two contributions to this line of\nwork. First, we propose a conceptual distinction in levels of coupling between\nagents that could have an effect on neural and behavioral complexity. Second,\nwe test the generalizability of previous results by testing agents with richer\ninternal structure and evolving them in a richer, yet non-social, environment.\nWe demonstrate that such agents can achieve levels of complexity comparable to\nagents that evolve in interactive settings. We discuss the significance of this\nresult for the study of interaction.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 14:21:57 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Res\u00e9ndiz-Benhumea", "Georgina Montserrat", ""], ["Sangati", "Ekaterina", ""], ["Froese", "Tom", ""]]}, {"id": "2011.01893", "submitter": "Emmanuel Sin", "authors": "Emmanuel Sin, Murat Arcak, Douglas Philbrick, Peter Seiler", "title": "Iterative Best Response for Multi-Body Asset-Guarding Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a numerical approach to finding optimal trajectories for players\nin a multi-body, asset-guarding game with nonlinear dynamics and non-convex\nconstraints. Using the Iterative Best Response (IBR) scheme, we solve for each\nplayer's optimal strategy assuming the other players' trajectories are known\nand fixed. Leveraging recent advances in Sequential Convex Programming (SCP),\nwe use SCP as a subroutine within the IBR algorithm to efficiently solve an\napproximation of each player's constrained trajectory optimization problem. We\napply the approach to an asset-guarding game example involving multiple\npursuers and a single evader (i.e., n-versus-1 engagements). Resulting evader\ntrajectories are tested in simulation to verify successful evasion against\npursuers using conventional intercept guidance laws.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 18:11:45 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Sin", "Emmanuel", ""], ["Arcak", "Murat", ""], ["Philbrick", "Douglas", ""], ["Seiler", "Peter", ""]]}, {"id": "2011.02373", "submitter": "Liu Shanqi", "authors": "Shanqi Liu, Licheng Wen, Jinhao Cui, Xuemeng Yang, Junjie Cao, Yong\n  Liu", "title": "Moving Forward in Formation: A Decentralized Hierarchical Learning\n  Approach to Multi-Agent Moving Together", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-agent path finding in formation has many potential real-world\napplications like mobile warehouse robots. However, previous multi-agent path\nfinding (MAPF) methods hardly take formation into consideration. Furthermore,\nthey are usually centralized planners and require the whole state of the\nenvironment. Other decentralized partially observable approaches to MAPF are\nreinforcement learning (RL) methods. However, these RL methods encounter\ndifficulties when learning path finding and formation problem at the same time.\nIn this paper, we propose a novel decentralized partially observable RL\nalgorithm that uses a hierarchical structure to decompose the multi objective\ntask into unrelated ones. It also calculates a theoretical weight that makes\nevery task reward has equal influence on the final RL value function.\nAdditionally, we introduce a communication method that helps agents cooperate\nwith each other. Experiments in simulation show that our method outperforms\nother end-to-end RL methods and our method can naturally scale to large world\nsizes where centralized planner struggles. We also deploy and validate our\nmethod in a real world scenario.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 16:05:07 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Liu", "Shanqi", ""], ["Wen", "Licheng", ""], ["Cui", "Jinhao", ""], ["Yang", "Xuemeng", ""], ["Cao", "Junjie", ""], ["Liu", "Yong", ""]]}, {"id": "2011.02379", "submitter": "Mathieu Even", "authors": "Mathieu Even, Hadrien Hendrikx, Laurent Massouli\\'e", "title": "Asynchrony and Acceleration in Gossip Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.MA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the minimization of a sum of smooth and strongly convex\nfunctions dispatched over the nodes of a communication network. Previous works\non the subject either focus on synchronous algorithms, which can be heavily\nslowed down by a few slow nodes (the straggler problem), or consider a model of\nasynchronous operation (Boyd et al., 2006) in which adjacent nodes communicate\nat the instants of Poisson point processes. We have two main contributions. 1)\nWe propose CACDM (a Continuously Accelerated Coordinate Dual Method), and for\nthe Poisson model of asynchronous operation, we prove CACDM to converge to\noptimality at an accelerated convergence rate in the sense of Nesterov et\nStich, 2017. In contrast, previously proposed asynchronous algorithms have not\nbeen proven to achieve such accelerated rate. While CACDM is based on discrete\nupdates, the proof of its convergence crucially depends on a continuous time\nanalysis. 2) We introduce a new communication scheme based on Loss-Networks,\nthat is programmable in a fully asynchronous and decentralized way, unlike the\nPoisson model of asynchronous operation that does not capture essential aspects\nof asynchrony such as non-instantaneous communications and computations. Under\nthis Loss-Network model of asynchrony, we establish for CDM (a Coordinate Dual\nMethod) a rate of convergence in terms of the eigengap of the Laplacian of the\ngraph weighted by local effective delays. We believe this eigengap to be a\nfundamental bottleneck for convergence rates of asynchronous optimization.\nFinally, we verify empirically that CACDM enjoys an accelerated convergence\nrate in the Loss-Network model of asynchrony.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 16:15:32 GMT"}, {"version": "v2", "created": "Sun, 7 Feb 2021 11:26:03 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Even", "Mathieu", ""], ["Hendrikx", "Hadrien", ""], ["Massouli\u00e9", "Laurent", ""]]}, {"id": "2011.02544", "submitter": "Kshitij Kulkarni", "authors": "Kshitij Kulkarni, Sven Neth", "title": "Social Choice with Changing Preferences: Representation Theorems and\n  Long-Run Policies", "comments": "Accepted to the Workshop on Consequential Decision Making in Dynamic\n  Environments, NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study group decision making with changing preferences as a Markov Decision\nProcess. We are motivated by the increasing prevalence of automated\ndecision-making systems when making choices for groups of people over time. Our\nmain contribution is to show how classic representation theorems from social\nchoice theory can be adapted to characterize optimal policies in this dynamic\nsetting. We provide an axiomatic characterization of MDP reward functions that\nagree with the Utilitarianism social welfare functionals of social choice\ntheory. We also provide discussion of cases when the implementation of social\nchoice-theoretic axioms may fail to lead to long-run optimal outcomes.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 21:21:04 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Kulkarni", "Kshitij", ""], ["Neth", "Sven", ""]]}, {"id": "2011.02573", "submitter": "Suman Ojha", "authors": "Suman Ojha, Jonathan Vitale and Mary-Anne Williams", "title": "EEGS: A Transparent Model of Emotions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the computational details of our emotion model, EEGS, and\nalso provides an overview of a three-stage validation methodology used for the\nevaluation of our model, which can also be applicable for other computational\nmodels of emotion. A major gap in existing emotion modelling literature has\nbeen the lack of computational/technical details of the implemented models,\nwhich not only makes it difficult for early-stage researchers to understand the\narea but also prevents benchmarking of the developed models for expert\nresearchers. We partly addressed these issues by presenting technical details\nfor the computation of appraisal variables in our previous work. In this paper,\nwe present mathematical formulas for the calculation of emotion intensities\nbased on the theoretical premises of appraisal theory. Moreover, we will\ndiscuss how we enable our emotion model to reach to a regulated emotional state\nfor social acceptability of autonomous agents. We hope this paper will allow a\nbetter transparency of knowledge, accurate benchmarking and further evolution\nof the field of emotion modelling.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 23:18:20 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Ojha", "Suman", ""], ["Vitale", "Jonathan", ""], ["Williams", "Mary-Anne", ""]]}, {"id": "2011.02608", "submitter": "Jingxi Xu", "authors": "Huy Ha, Jingxi Xu, Shuran Song", "title": "Learning a Decentralized Multi-arm Motion Planner", "comments": "CoRL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a closed-loop multi-arm motion planner that is scalable and\nflexible with team size. Traditional multi-arm robot systems have relied on\ncentralized motion planners, whose runtimes often scale exponentially with team\nsize, and thus, fail to handle dynamic environments with open-loop control. In\nthis paper, we tackle this problem with multi-agent reinforcement learning,\nwhere a decentralized policy is trained to control one robot arm in the\nmulti-arm system to reach its target end-effector pose given observations of\nits workspace state and target end-effector pose. The policy is trained using\nSoft Actor-Critic with expert demonstrations from a sampling-based motion\nplanning algorithm (i.e., BiRRT). By leveraging classical planning algorithms,\nwe can improve the learning efficiency of the reinforcement learning algorithm\nwhile retaining the fast inference time of neural networks. The resulting\npolicy scales sub-linearly and can be deployed on multi-arm systems with\nvariable team sizes. Thanks to the closed-loop and decentralized formulation,\nour approach generalizes to 5-10 multi-arm systems and dynamic moving targets\n(>90% success rate for a 10-arm system), despite being trained on only 1-4 arm\nplanning tasks with static targets. Code and data links can be found at\nhttps://multiarm.cs.columbia.edu.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 01:47:23 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Ha", "Huy", ""], ["Xu", "Jingxi", ""], ["Song", "Shuran", ""]]}, {"id": "2011.03111", "submitter": "Ehud Shapiro", "authors": "Ben Abramowitz, Ehud Shapiro and Nimrod Talmon", "title": "How to Amend a Constitution? Model, Axioms, and Supermajority Rules", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A self-governed society must have rules by which group decisions are made,\nand these rules are often codified in a written constitution. One of the\ndefining features of a constitution is its degree of entrenchment, or how hard\nit is to change it by amendment. If it is too easy to make amendments, then the\nconstitution can change too frequently, leading to chaos. On the other hand, if\nit is too hard to make amendments, then this can also be destabilizing, as\nvoters may begin to see the rules as less legitimate, or even seek to overturn\nthe status quo in a revolt. As norms, priorities, and circumstances change over\ntime and over generations, a constitution must be able to adapt. Our work\nconsiders a stylized model of constitutions that use reality-aware\nsupermajority rules to make decisions. We propose principles for designing\namendment procedures for changing decision rules in these constitutions and\npropose a novel procedure based on these principles.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 21:50:32 GMT"}, {"version": "v2", "created": "Fri, 5 Mar 2021 15:33:59 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Abramowitz", "Ben", ""], ["Shapiro", "Ehud", ""], ["Talmon", "Nimrod", ""]]}, {"id": "2011.03137", "submitter": "Behdad Chalaki", "authors": "Behdad Chalaki and Andreas A. Malikopoulos", "title": "A Hysteretic Q-learning Coordination Framework for Emerging Mobility\n  Systems in Smart Cities", "comments": "8 pages, 5 figures, 2 tables", "journal-ref": "2021 European Control Conference (ECC), 16-21", "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.MA cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Connected and automated vehicles (CAVs) can alleviate traffic congestion, air\npollution, and improve safety. In this paper, we provide a decentralized\ncoordination framework for CAVs at a signal-free intersection to minimize\ntravel time and improve fuel efficiency. We employ a simple yet powerful\nreinforcement learning approach, an off-policy temporal difference learning\ncalled Q-learning, enhanced with a coordination mechanism to address this\nproblem. Then, we integrate a first-in-first-out queuing policy to improve the\nperformance of our system. We demonstrate the efficacy of our proposed approach\nthrough simulation and comparison with the classical optimal control method\nbased on Pontryagin's minimum principle.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 23:30:05 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Chalaki", "Behdad", ""], ["Malikopoulos", "Andreas A.", ""]]}, {"id": "2011.03213", "submitter": "Jun Ma", "authors": "Jun Ma, Zilong Cheng, Xiaoxue Zhang, Abdullah Al Mamun, Clarence W. de\n  Silva, Tong Heng Lee", "title": "Non-Parametric Behavior Learning for Multi-Agent Decision Making With\n  Chance Constraints: A Data-Driven Predictive Control Framework", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.RO cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many specific scenarios, accurate and effective system identification is a\ncommonly encountered challenge in the model predictive control (MPC)\nformulation. As a consequence, the overall system performance could be\nsignificantly degraded in outcome when the traditional MPC algorithm is adopted\nunder those circumstances when such accuracy is lacking. To cater to this\nrather major shortcoming, this paper investigates a non-parametric behavior\nlearning method for multi-agent decision making, which underpins an alternate\ndata-driven predictive control framework. Utilizing an innovative methodology\nwith closed-loop input/output measurements of the unknown system, the behavior\nof the system is learned based on the collected dataset, and thus the\nconstructed non-parametric predictive model can be used for the determination\nof optimal control actions. This non-parametric predictive control framework\nattains the noteworthy key advantage of alleviating the heavy computational\nburden commonly encountered in the optimization procedures otherwise involved.\nSuch requisite optimization procedures are typical in existing methodologies\nrequiring open-loop input/output measurement data collection and parametric\nsystem identification. Then with a conservative approximation of probabilistic\nchance constraints for the MPC problem, a resulting deterministic optimization\nproblem is formulated and solved effectively. This intuitive data-driven\napproach is also shown to preserve good robustness properties (even in the\ninevitable existence of parametric uncertainties that naturally arise in the\ntypical system identification process). Finally, a multi-drone system is used\nto demonstrate the practical appeal and highly effective outcome of this\npromising development.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 07:16:18 GMT"}, {"version": "v2", "created": "Mon, 26 Apr 2021 04:56:58 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Ma", "Jun", ""], ["Cheng", "Zilong", ""], ["Zhang", "Xiaoxue", ""], ["Mamun", "Abdullah Al", ""], ["de Silva", "Clarence W.", ""], ["Lee", "Tong Heng", ""]]}, {"id": "2011.03603", "submitter": "Kiril Solovey", "authors": "Kiril Solovey, Saptarshi Bandyopadhyay, Federico Rossi, Michael T.\n  Wolf, and Marco Pavone", "title": "Fast Near-Optimal Heterogeneous Task Allocation via Flow Decomposition", "comments": "Extended version of a conference paper that appeared in the\n  International Conference on Robotics and Automation (ICRA), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.DS cs.MA cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-robot systems are uniquely well-suited to performing complex tasks such\nas patrolling and tracking, information gathering, and pick-up and delivery\nproblems, offering significantly higher performance than single-robot systems.\nA fundamental building block in most multi-robot systems is task allocation:\nassigning robots to tasks (e.g., patrolling an area, or servicing a\ntransportation request) as they appear based on the robots' states to maximize\nreward. In many practical situations, the allocation must account for\nheterogeneous capabilities (e.g., availability of appropriate sensors or\nactuators) to ensure the feasibility of execution, and to promote a higher\nreward, over a long time horizon. To this end, we present the FlowDec algorithm\nfor efficient heterogeneous task-allocation achieving an approximation factor\nof at least 1/2 of the optimal reward. Our approach decomposes the\nheterogeneous problem into several homogeneous subproblems that can be solved\nefficiently using min-cost flow. Through simulation experiments, we show that\nour algorithm is faster by several orders of magnitude than a MILP approach.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 21:29:55 GMT"}, {"version": "v2", "created": "Fri, 23 Apr 2021 18:56:28 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Solovey", "Kiril", ""], ["Bandyopadhyay", "Saptarshi", ""], ["Rossi", "Federico", ""], ["Wolf", "Michael T.", ""], ["Pavone", "Marco", ""]]}, {"id": "2011.03640", "submitter": "Dayong Ye", "authors": "Dayong Ye and Tianqing Zhu and Zishuo Cheng and Wanlei Zhou and Philip\n  S. Yu", "title": "Differential Advising in Multi-Agent Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Agent advising is one of the main approaches to improve agent learning\nperformance by enabling agents to share advice. Existing advising methods have\na common limitation that an adviser agent can offer advice to an advisee agent\nonly if the advice is created in the same state as the advisee's concerned\nstate. However, in complex environments, it is a very strong requirement that\ntwo states are the same, because a state may consist of multiple dimensions and\ntwo states being the same means that all these dimensions in the two states are\ncorrespondingly identical. Therefore, this requirement may limit the\napplicability of existing advising methods to complex environments. In this\npaper, inspired by the differential privacy scheme, we propose a differential\nadvising method which relaxes this requirement by enabling agents to use advice\nin a state even if the advice is created in a slightly different state.\nCompared with existing methods, agents using the proposed method have more\nopportunity to take advice from others. This paper is the first to adopt the\nconcept of differential privacy on advising to improve agent learning\nperformance instead of addressing security issues. The experimental results\ndemonstrate that the proposed method is more efficient in complex environments\nthan existing methods.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2020 00:04:25 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Ye", "Dayong", ""], ["Zhu", "Tianqing", ""], ["Cheng", "Zishuo", ""], ["Zhou", "Wanlei", ""], ["Yu", "Philip S.", ""]]}, {"id": "2011.03645", "submitter": "Chenkai Yu", "authors": "Grant Schoenebeck, Chenkai Yu, Fang-Yi Yu", "title": "Timely Information from Prediction Markets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prediction markets are powerful tools to elicit and aggregate beliefs from\nstrategic agents. However, in current prediction markets, agents may exhaust\nthe social welfare by competing to be the first to update the market. We\ninitiate the study of the trade-off between how quickly information is\naggregated by the market, and how much this information costs. We design\nmarkets to aggregate timely information from strategic agents to maximize\nsocial welfare. To this end, the market must incentivize agents to invest the\ncorrect amount of effort to acquire information: quickly enough to be useful,\nbut not faster (and more expensively) than necessary. The market also must\nensure that agents report their information truthfully and on time. We consider\ntwo settings: in the first, information is only valuable before a deadline; in\nthe second, the value of information decreases as time passes. We use both\ntheorems and simulations to demonstrate the mechanisms.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2020 00:31:27 GMT"}, {"version": "v2", "created": "Sat, 6 Mar 2021 11:26:39 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Schoenebeck", "Grant", ""], ["Yu", "Chenkai", ""], ["Yu", "Fang-Yi", ""]]}, {"id": "2011.03724", "submitter": "Dimitar Guelev", "authors": "Dimitar P. Guelev", "title": "Reasoning about Temporary Coalitions and LTL-definable Ordered\n  Objectives in Infinite Concurrent Multiplayer Games", "comments": "Presented at the 8th International Workshop on Strategic Reasoning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose enhancing the use of propositions for denoting decisions and\nstrategies as established in temporal languages such as CTL*, if interpreted on\nconcurrent game models. The enhancement enables specifying varying coalition\nstructure. In quantified CTL* this technique also enables quantifying over\ncoalition structure, and we use it to quantify over an extended form of\nstrategy profiles which capture temporary coalitions. We also extend CTL* by a\ntemporal form of a binary preference operator that can be traced back to the\nwork of Von Wright. The resulting extension of quantified CTL* can be used to\nspell out conditions on the rationality of behaviour in concurrent multiplayer\ngames such as what appear in solution concepts, with players having multiple\nindividual objectives and preferences on them, and with the possibility to form\ntemporary coalitions taken in account. We propose complete axiomatisations for\nthe extension of CTL* by the temporal preference operator. The decidability of\nthe logic is not affected by that extension.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2020 08:23:31 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Guelev", "Dimitar P.", ""]]}, {"id": "2011.03838", "submitter": "Mashnoon Islam", "authors": "Mashnoon Islam, Touhid Ahmed, Abu Tammam Bin Nuruddin, Mashuda Islam,\n  Shahnewaz Siddique", "title": "Autonomous Intruder Detection Using a ROS-Based Multi-Robot System\n  Equipped with 2D-LiDAR Sensors", "comments": "Accepted Version, 2020 IEEE International Symposium on Safety,\n  Security, and Rescue Robotics (SSRR) November 4-6, Abu Dhabi, UAE", "journal-ref": null, "doi": "10.1109/SSRR50563.2020.9292639", "report-no": null, "categories": "cs.RO cs.CV cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The application of autonomous mobile robots in robotic security platforms is\nbecoming a promising field of innovation due to their adaptive capability of\nresponding to potential disturbances perceived through a wide range of sensors.\nResearchers have proposed systems that either focus on utilizing a single\nmobile robot or a system of cooperative multiple robots. However, very few of\nthe proposed works, particularly in the field of multi-robot systems, are\ncompletely dependent on LiDAR sensors for achieving various tasks. This is\nessential when other sensors on a robot fail to provide peak performance in\nparticular conditions, such as a camera operating in the absence of light. This\npaper proposes a multi-robot system that is developed using ROS (Robot\nOperating System) for intruder detection in a single-range-sensor-per-robot\nscenario with centralized processing of detections from all robots by our\ncentral bot MIDNet (Multiple Intruder Detection Network). This work is aimed at\nproviding an autonomous multi-robot security solution for a warehouse in the\nabsence of human personnel.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2020 19:49:07 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Islam", "Mashnoon", ""], ["Ahmed", "Touhid", ""], ["Nuruddin", "Abu Tammam Bin", ""], ["Islam", "Mashuda", ""], ["Siddique", "Shahnewaz", ""]]}, {"id": "2011.03894", "submitter": "Christoforos Mavrogiannis", "authors": "Junha Roh, Christoforos Mavrogiannis, Rishabh Madan, Dieter Fox,\n  Siddhartha S. Srinivasa", "title": "Multimodal Trajectory Prediction via Topological Invariance for\n  Navigation at Uncontrolled Intersections", "comments": "Preprint of a paper with the same title, accepted to the Conference\n  on Robot Learning 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on decentralized navigation among multiple non-communicating\nrational agents at \\emph{uncontrolled} intersections, i.e., street\nintersections without traffic signs or signals. Avoiding collisions in such\ndomains relies on the ability of agents to predict each others' intentions\nreliably, and react quickly. Multiagent trajectory prediction is NP-hard\nwhereas the sample complexity of existing data-driven approaches limits their\napplicability. Our key insight is that the geometric structure of the\nintersection and the incentive of agents to move efficiently and avoid\ncollisions (rationality) reduces the space of likely behaviors, effectively\nrelaxing the problem of trajectory prediction. In this paper, we collapse the\nspace of multiagent trajectories at an intersection into a set of modes\nrepresenting different classes of multiagent behavior, formalized using a\nnotion of topological invariance. Based on this formalism, we design Multiple\nTopologies Prediction (MTP), a data-driven trajectory-prediction mechanism that\nreconstructs trajectory representations of high-likelihood modes in multiagent\nintersection scenes. We show that MTP outperforms a state-of-the-art multimodal\ntrajectory prediction baseline (MFP) in terms of prediction accuracy by 78.24%\non a challenging simulated dataset. Finally, we show that MTP enables our\noptimization-based planner, MTPnav, to achieve collision-free and\ntime-efficient navigation across a variety of challenging intersection\nscenarios on the CARLA simulator.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2020 02:56:42 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Roh", "Junha", ""], ["Mavrogiannis", "Christoforos", ""], ["Madan", "Rishabh", ""], ["Fox", "Dieter", ""], ["Srinivasa", "Siddhartha S.", ""]]}, {"id": "2011.03896", "submitter": "Mark Sellke", "authors": "S\\'ebastien Bubeck, Thomas Budzinski, Mark Sellke", "title": "Cooperative and Stochastic Multi-Player Multi-Armed Bandit: Optimal\n  Regret With Neither Communication Nor Collisions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the cooperative multi-player version of the stochastic\nmulti-armed bandit problem. We study the regime where the players cannot\ncommunicate but have access to shared randomness. In prior work by the first\ntwo authors, a strategy for this regime was constructed for two players and\nthree arms, with regret $\\tilde{O}(\\sqrt{T})$, and with no collisions at all\nbetween the players (with very high probability). In this paper we show that\nthese properties (near-optimal regret and no collisions at all) are achievable\nfor any number of players and arms. At a high level, the previous strategy\nheavily relied on a $2$-dimensional geometric intuition that was difficult to\ngeneralize in higher dimensions, while here we take a more combinatorial route\nto build the new strategy.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2020 03:14:19 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Bubeck", "S\u00e9bastien", ""], ["Budzinski", "Thomas", ""], ["Sellke", "Mark", ""]]}, {"id": "2011.03964", "submitter": "Yushan Li", "authors": "Qing Jiao, Yushan Li, Jianping He, Ling Shi", "title": "Topology Inference for Multi-agent Cooperation under Unmeasurable Latent\n  Input", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topology inference is a crucial problem for cooperative control in\nmulti-agent systems. Different from most prior works, this paper is dedicated\nto inferring the directed network topology from the observations that consist\nof a single, noisy and finite time-series system trajectory, where the\ncooperation dynamics is stimulated with the initial network state and the\nunmeasurable latent input. The unmeasurable latent input refers to intrinsic\nsystem signal and extrinsic environment interference. Considering the\ntime-invariant/varying nature of the input, we propose two-layer\noptimization-based and iterative estimation based topology inference algorithms\n(TO-TIA and IE-TIA), respectively. TO-TIA allows us to capture the separability\nof global agent state and eliminates the unknown influence of time-invariant\ninput on system dynamics. IE-TIA further exploits the identifiability and\nestimability of more general time-varying input and provides an asymptotic\nsolution with desired convergence properties, with higher computation cost\ncompared with TO-TIA. Our novel algorithms relax the dependence of observation\nscale and leverage the empirical risk reformulation to improve the inference\naccuracy in terms of the topology structure and edge weight. Comprehensive\ntheoretical analysis and simulations for various topologies are provided to\nillustrate the inference feasibility and the performance of the proposed\nalgorithms.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2020 12:14:20 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Jiao", "Qing", ""], ["Li", "Yushan", ""], ["He", "Jianping", ""], ["Shi", "Ling", ""]]}, {"id": "2011.04087", "submitter": "Yun Chang", "authors": "Yun Chang, Yulun Tian, Jonathan P. How, Luca Carlone", "title": "Kimera-Multi: a System for Distributed Multi-Robot Metric-Semantic\n  Simultaneous Localization and Mapping", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the first fully distributed multi-robot system for dense\nmetric-semantic Simultaneous Localization and Mapping (SLAM). Our system,\ndubbed Kimera-Multi, is implemented by a team of robots equipped with\nvisual-inertial sensors, and builds a 3D mesh model of the environment in\nreal-time, where each face of the mesh is annotated with a semantic label\n(e.g., building, road, objects). In Kimera-Multi, each robot builds a local\ntrajectory estimate and a local mesh using Kimera. Then, when two robots are\nwithin communication range, they initiate a distributed place recognition and\nrobust pose graph optimization protocol with a novel incremental maximum clique\noutlier rejection; the protocol allows the robots to improve their local\ntrajectory estimates by leveraging inter-robot loop closures. Finally, each\nrobot uses its improved trajectory estimate to correct the local mesh using\nmesh deformation techniques. We demonstrate Kimera-Multi in photo-realistic\nsimulations and real data. Kimera-Multi (i) is able to build accurate 3D\nmetric-semantic meshes, (ii) is robust to incorrect loop closures while\nrequiring less computation than state-of-the-art distributed SLAM back-ends,\nand (iii) is efficient, both in terms of computation at each robot as well as\ncommunication bandwidth.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2020 21:38:12 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Chang", "Yun", ""], ["Tian", "Yulun", ""], ["How", "Jonathan P.", ""], ["Carlone", "Luca", ""]]}, {"id": "2011.04100", "submitter": "Priyank Srivastava", "authors": "Priyank Srivastava and Jorge Cortes", "title": "Network Optimization via Smooth Exact Penalty Functions Enabled by\n  Distributed Gradient Computation", "comments": "12 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a distributed algorithm for a network of agents to solve\nan optimization problem with separable objective function and locally coupled\nconstraints. Our strategy is based on reformulating the original constrained\nproblem as the unconstrained optimization of a smooth (continuously\ndifferentiable) exact penalty function. Computing the gradient of this penalty\nfunction in a distributed way is challenging even under the separability\nassumptions on the original optimization problem. Our technical approach shows\nthat the distributed computation problem for the gradient can be formulated as\na system of linear algebraic equations defined by separable problem data. To\nsolve it, we design an exponentially fast, input-to-state stable distributed\nalgorithm that does not require the individual agent matrices to be invertible.\nWe employ this strategy to compute the gradient of the penalty function at the\ncurrent network state. Our distributed algorithmic solver for the original\nconstrained optimization problem interconnects this estimation with the\nprescription of having the agents follow the resulting direction. Numerical\nsimulations illustrate the convergence and robustness properties of the\nproposed algorithm.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2020 23:14:12 GMT"}, {"version": "v2", "created": "Thu, 11 Mar 2021 06:27:58 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Srivastava", "Priyank", ""], ["Cortes", "Jorge", ""]]}, {"id": "2011.04222", "submitter": "Sushmita Bhattacharya", "authors": "Sushmita Bhattacharya, Siva Kailas, Sahil Badyal, Stephanie Gil,\n  Dimitri Bertsekas", "title": "Multiagent Rollout and Policy Iteration for POMDP with Application to\n  Multi-Robot Repair Problems", "comments": "8 pages + 3 pages appendix + 9 figures + 3 tables, accepted in\n  Conference on Robot Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider infinite horizon discounted dynamic programming\nproblems with finite state and control spaces, partial state observations, and\na multiagent structure. We discuss and compare algorithms that simultaneously\nor sequentially optimize the agents' controls by using multistep lookahead,\ntruncated rollout with a known base policy, and a terminal cost function\napproximation. Our methods specifically address the computational challenges of\npartially observable multiagent problems. In particular: 1) We consider rollout\nalgorithms that dramatically reduce required computation while preserving the\nkey cost improvement property of the standard rollout method. The per-step\ncomputational requirements for our methods are on the order of $O(Cm)$ as\ncompared with $O(C^m)$ for standard rollout, where $C$ is the maximum\ncardinality of the constraint set for the control component of each agent, and\n$m$ is the number of agents. 2) We show that our methods can be applied to\nchallenging problems with a graph structure, including a class of robot repair\nproblems whereby multiple robots collaboratively inspect and repair a system\nunder partial information. 3) We provide a simulation study that compares our\nmethods with existing methods, and demonstrate that our methods can handle\nlarger and more complex partially observable multiagent problems (state space\nsize $10^{37}$ and control space size $10^{7}$, respectively). Finally, we\nincorporate our multiagent rollout algorithms as building blocks in an\napproximate policy iteration scheme, where successive rollout policies are\napproximated by using neural network classifiers. While this scheme requires a\nstrictly off-line implementation, it works well in our computational\nexperiments and produces additional significant performance improvement over\nthe single online rollout iteration method.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 06:51:50 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Bhattacharya", "Sushmita", ""], ["Kailas", "Siva", ""], ["Badyal", "Sahil", ""], ["Gil", "Stephanie", ""], ["Bertsekas", "Dimitri", ""]]}, {"id": "2011.05092", "submitter": "Simon Oh", "authors": "Simon Oh, Antonis F. Lentzakis, Ravi Seshadri, Moshe Ben-Akiva", "title": "Network Impacts of Automated Mobility-on-Demand: A Macroscopic\n  Fundamental Diagram Perspective", "comments": "29 pages, 9 figures, 6 tables, submitted to the journal Simulation\n  Modelling Practice and Theory", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Technological advancements have brought increasing attention to Automated\nMobility on Demand (AMOD) as a promising solution that may improve future urban\nmobility. During the last decade, extensive research has been conducted on the\ndesign and evaluation of AMOD systems using simulation models. This paper adds\nto this growing body of literature by investigating the network impacts of AMOD\nthrough high-fidelity activity- and agent-based traffic simulation, including\ndetailed models of AMOD fleet operations. Through scenario simulations of the\nentire island of Singapore, we explore network traffic dynamics by employing\nthe concept of the Macroscopic Fundamental Diagram (MFD). Taking into account\nthe spatial variability of density, we are able to capture the hysteresis\nloops, which inevitably form in a network of this size. Model estimation\nresults at both the vehicle and passenger flow level are documented.\nEnvironmental impacts including energy and emissions are also discussed.\nFindings from the case study of Singapore suggest that the introduction of AMOD\nmay bring about significant impacts on network performance in terms of\nincreased VKT, additional travel delay and energy consumption, while reducing\nvehicle emissions, with respect to the baseline. Despite the increase in\nnetwork congestion, production of passenger flows remains relatively unchanged.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 13:39:35 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Oh", "Simon", ""], ["Lentzakis", "Antonis F.", ""], ["Seshadri", "Ravi", ""], ["Ben-Akiva", "Moshe", ""]]}, {"id": "2011.05281", "submitter": "Sidhdharth Sikka", "authors": "Sidhdharth Sikka, Harshvardhan Sikka", "title": "A Genetic Algorithm Based Approach for Satellite Autonomy", "comments": null, "journal-ref": null, "doi": "10.13140/RG.2.2.17934.18247/2", "report-no": null, "categories": "cs.NE cs.AI cs.MA cs.RO", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Autonomous spacecraft maneuver planning using an evolutionary algorithmic\napproach is investigated. Simulated spacecraft were placed into four different\ninitial orbits. Each was allowed a string of thirty delta-v impulse maneuvers\nin six cartesian directions, the positive and negative x, y and z directions.\nThe goal of the spacecraft maneuver string was to, starting from some non-polar\nstarting orbit, place the spacecraft into a polar, low eccentricity orbit. A\ngenetic algorithm was implemented, using a mating, fitness, mutation and\ncrossover scheme for impulse strings. The genetic algorithm was successfully\nable to produce this result for all the starting orbits. Performance and future\nwork is also discussed.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 20:41:30 GMT"}, {"version": "v2", "created": "Sun, 15 Nov 2020 21:47:37 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Sikka", "Sidhdharth", ""], ["Sikka", "Harshvardhan", ""]]}, {"id": "2011.05373", "submitter": "Bowen Baker", "authors": "Bowen Baker", "title": "Emergent Reciprocity and Team Formation from Randomized Uncertain Social\n  Preferences", "comments": "to be published in NeurIPS 2020 proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-agent reinforcement learning (MARL) has shown recent success in\nincreasingly complex fixed-team zero-sum environments. However, the real world\nis not zero-sum nor does it have fixed teams; humans face numerous social\ndilemmas and must learn when to cooperate and when to compete. To successfully\ndeploy agents into the human world, it may be important that they be able to\nunderstand and help in our conflicts. Unfortunately, selfish MARL agents\ntypically fail when faced with social dilemmas. In this work, we show evidence\nof emergent direct reciprocity, indirect reciprocity and reputation, and team\nformation when training agents with randomized uncertain social preferences\n(RUSP), a novel environment augmentation that expands the distribution of\nenvironments agents play in. RUSP is generic and scalable; it can be applied to\nany multi-agent environment without changing the original underlying game\ndynamics or objectives. In particular, we show that with RUSP these behaviors\ncan emerge and lead to higher social welfare equilibria in both classic\nabstract social dilemmas like Iterated Prisoner's Dilemma as well in more\ncomplex intertemporal environments.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 20:06:19 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Baker", "Bowen", ""]]}, {"id": "2011.05437", "submitter": "Rogerio Bonatti", "authors": "Arthur Bucker, Rogerio Bonatti and Sebastian Scherer", "title": "Do You See What I See? Coordinating Multiple Aerial Cameras for Robot\n  Cinematography", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Aerial cinematography is significantly expanding the capabilities of\nfilm-makers. Recent progress in autonomous unmanned aerial vehicles (UAVs) has\nfurther increased the potential impact of aerial cameras, with systems that can\nsafely track actors in unstructured cluttered environments. Professional\nproductions, however, require the use of multiple cameras simultaneously to\nrecord different viewpoints of the same scene, which are edited into the final\nfootage either in real time or in post-production. Such extreme motion\ncoordination is particularly hard for unscripted action scenes, which are a\ncommon use case of aerial cameras. In this work we develop a real-time\nmulti-UAV coordination system that is capable of recording dynamic targets\nwhile maximizing shot diversity and avoiding collisions and mutual visibility\nbetween cameras. We validate our approach in multiple cluttered environments of\na photo-realistic simulator, and deploy the system using two UAVs in real-world\nexperiments. We show that our coordination scheme has low computational cost\nand takes only 1.17 ms on average to plan for a team of 3 UAVs over a 10 s time\nhorizon. Supplementary video: https://youtu.be/m2R3anv2ADE\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 22:43:25 GMT"}, {"version": "v2", "created": "Wed, 31 Mar 2021 22:02:07 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Bucker", "Arthur", ""], ["Bonatti", "Rogerio", ""], ["Scherer", "Sebastian", ""]]}, {"id": "2011.05605", "submitter": "Tanmay Samak", "authors": "Sivanathan Kandhasamy, Vinayagam Babu Kuppusamy, Tanmay Vilas Samak,\n  Chinmay Vilas Samak", "title": "Decentralized Motion Planning for Multi-Robot Navigation using Deep\n  Reinforcement Learning", "comments": "Accepted at IEEE International Conference on Intelligent Sustainable\n  Systems (ICISS) 2020", "journal-ref": "2020 3rd International Conference on Intelligent Sustainable\n  Systems (ICISS), Thoothukudi, India, 2020, pp. 709-716", "doi": "10.1109/ICISS49785.2020.9316033", "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.MA cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents a decentralized motion planning framework for addressing\nthe task of multi-robot navigation using deep reinforcement learning. A custom\nsimulator was developed in order to experimentally investigate the navigation\nproblem of 4 cooperative non-holonomic robots sharing limited state information\nwith each other in 3 different settings. The notion of decentralized motion\nplanning with common and shared policy learning was adopted, which allowed\nrobust training and testing of this approach in a stochastic environment since\nthe agents were mutually independent and exhibited asynchronous motion\nbehavior. The task was further aggravated by providing the agents with a sparse\nobservation space and requiring them to generate continuous action commands so\nas to efficiently, yet safely navigate to their respective goal locations,\nwhile avoiding collisions with other dynamic peers and static obstacles at all\ntimes. The experimental results are reported in terms of quantitative measures\nand qualitative remarks for both training and deployment phases.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 07:35:21 GMT"}, {"version": "v2", "created": "Fri, 20 Nov 2020 18:19:32 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Kandhasamy", "Sivanathan", ""], ["Kuppusamy", "Vinayagam Babu", ""], ["Samak", "Tanmay Vilas", ""], ["Samak", "Chinmay Vilas", ""]]}, {"id": "2011.06047", "submitter": "Forrest Laine", "authors": "Forrest Laine, David Fridovich-Keil, Chih-Yuan Chiu, and Claire Tomlin", "title": "Multi-Hypothesis Interactions in Game-Theoretic Motion Planning", "comments": "For associated mp4 file, see https://youtu.be/x7VtYDrWTWM", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a novel method for handling uncertainty about the intentions of\nnon-ego players in dynamic games, with application to motion planning for\nautonomous vehicles. Equilibria in these games explicitly account for\ninteraction among other agents in the environment, such as drivers and\npedestrians. Our method models the uncertainty about the intention of other\nagents by constructing multiple hypotheses about the objectives and constraints\nof other agents in the scene. For each candidate hypothesis, we associate a\nBernoulli random variable representing the probability of that hypothesis,\nwhich may or may not be independent of the probability of other hypotheses. We\nleverage constraint asymmetries and feedback information patterns to\nincorporate the probabilities of hypotheses in a natural way. Specifically,\nincreasing the probability associated with a given hypothesis from $0$ to $1$\nshifts the responsibility of collision avoidance from the hypothesized agent to\nthe ego agent. This method allows the generation of interactive trajectories\nfor the ego agent, where the level of assertiveness or caution that the ego\nexhibits is directly related to the easy-to-model uncertainty it maintains\nabout the scene.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 20:00:00 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Laine", "Forrest", ""], ["Fridovich-Keil", "David", ""], ["Chiu", "Chih-Yuan", ""], ["Tomlin", "Claire", ""]]}, {"id": "2011.06124", "submitter": "Matthew Zalesak", "authors": "Matthew Zalesak and Samitha Samaranayake (Cornell University)", "title": "SEIR-Campus: Modeling Infectious Diseases on University Campuses", "comments": "18 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE cs.MA cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a Python package for modeling and studying the spread of\ninfectious diseases using an agent-based SEIR style epidemiological model with\na focus on university campuses. This document explains the epidemiological\nmodel used in the package and gives examples highlighting the ways that the\npackage can be used.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 23:50:32 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Zalesak", "Matthew", "", "Cornell University"], ["Samaranayake", "Samitha", "", "Cornell University"]]}, {"id": "2011.07290", "submitter": "Roxana R\\u{a}dulescu", "authors": "Roxana R\\u{a}dulescu, Timothy Verstraeten, Yijie Zhang, Patrick\n  Mannion, Diederik M. Roijers, Ann Now\\'e", "title": "Opponent Learning Awareness and Modelling in Multi-Objective Normal Form\n  Games", "comments": "Under review since 14 November 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world multi-agent interactions consider multiple distinct criteria,\ni.e. the payoffs are multi-objective in nature. However, the same\nmulti-objective payoff vector may lead to different utilities for each\nparticipant. Therefore, it is essential for an agent to learn about the\nbehaviour of other agents in the system. In this work, we present the first\nstudy of the effects of such opponent modelling on multi-objective multi-agent\ninteractions with non-linear utilities. Specifically, we consider two-player\nmulti-objective normal form games with non-linear utility functions under the\nscalarised expected returns optimisation criterion. We contribute novel\nactor-critic and policy gradient formulations to allow reinforcement learning\nof mixed strategies in this setting, along with extensions that incorporate\nopponent policy reconstruction and learning with opponent learning awareness\n(i.e., learning while considering the impact of one's policy when anticipating\nthe opponent's learning step). Empirical results in five different MONFGs\ndemonstrate that opponent learning awareness and modelling can drastically\nalter the learning dynamics in this setting. When equilibria are present,\nopponent modelling can confer significant benefits on agents that implement it.\nWhen there are no Nash equilibria, opponent learning awareness and modelling\nallows agents to still converge to meaningful solutions that approximate\nequilibria.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 12:35:32 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["R\u0103dulescu", "Roxana", ""], ["Verstraeten", "Timothy", ""], ["Zhang", "Yijie", ""], ["Mannion", "Patrick", ""], ["Roijers", "Diederik M.", ""], ["Now\u00e9", "Ann", ""]]}, {"id": "2011.07673", "submitter": "Simon Oh", "authors": "Simon Oh, Daniel Kondor, Ravi Seshadri, Meng Zhou, Diem-Trinh Le,\n  Moshe Ben-Akiva", "title": "Spatiotemporal Characteristics of Ride-sourcing Operation in Urban Area", "comments": "18 pages, 11 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emergence of ride-sourcing platforms has brought an innovative\nalternative in transportation, radically changed travel behaviors, and\nsuggested new directions for transportation planners and operators. This paper\nprovides an exploratory analysis on the operations of a ride-sourcing service\nusing large-scale data on service performance. Observations over multiple days\nin Singapore suggest reproducible demand patterns and provide empirical\nestimates of fleet operations over time and space. During peak periods, we\nobserve significant increases in the service rate along with surge price\nmultipliers. We perform an in-depth analysis of fleet utilization rates and are\nable to explain daily patterns based on drivers' behavior by involving the\nnumber of shifts, shift duration, and shift start and end time choices. We also\nevaluate metrics of user experience, namely waiting and travel time\ndistribution, and explain our empirical findings with distance metrics from\ndriver trajectory analysis and congestion patterns. Our results of empirical\nobservations on actual service in Singapore can help to understand the\nspatiotemporal characteristics of ride-sourcing services and provide important\ninsights for transportation planning and operations.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 01:28:35 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Oh", "Simon", ""], ["Kondor", "Daniel", ""], ["Seshadri", "Ravi", ""], ["Zhou", "Meng", ""], ["Le", "Diem-Trinh", ""], ["Ben-Akiva", "Moshe", ""]]}, {"id": "2011.07887", "submitter": "Wojciech Jamroga", "authors": "Wojciech Jamroga, David Mestel, Peter B. Roenne, Peter Y. A. Ryan,\n  Marjan Skrobot", "title": "A Survey of Requirements for COVID-19 Mitigation Strategies. Part I:\n  Newspaper Clips", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.MA", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The COVID-19 pandemic has influenced virtually all aspects of our lives.\nAcross the world, countries have applied various mitigation strategies for the\nepidemic, based on social, political, and technological instruments. We\npostulate that one should {identify the relevant requirements} before\ncommitting to a particular mitigation strategy. One way to achieve it is\nthrough an overview of what is considered relevant by the general public, and\nreferred to in the media. To this end, we have collected a number of news clips\nthat mention the possible goals and requirements for a mitigation strategy. The\nsnippets are sorted thematically into several categories, such as\nhealth-related goals, social and political impact, civil rights, ethical\nrequirements, and so on.\n  In a forthcoming companion paper, we will present a digest of the\nrequirements, derived from the news clips, and a preliminary take on their\nformal specification.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 12:00:49 GMT"}, {"version": "v2", "created": "Mon, 14 Dec 2020 11:12:04 GMT"}, {"version": "v3", "created": "Fri, 22 Jan 2021 17:44:06 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Jamroga", "Wojciech", ""], ["Mestel", "David", ""], ["Roenne", "Peter B.", ""], ["Ryan", "Peter Y. A.", ""], ["Skrobot", "Marjan", ""]]}, {"id": "2011.07934", "submitter": "Panayiotis Danassis", "authors": "Panayiotis Danassis, Aleksei Triastcyn, Boi Faltings", "title": "Differential Privacy Meets Maximum-weight Matching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When it comes to large-scale multi-agent systems with a diverse set of\nagents, traditional differential privacy (DP) mechanisms are ill-matched\nbecause they consider a very broad class of adversaries, and they protect all\nusers, independent of their characteristics, by the same guarantee. Achieving a\nmeaningful privacy leads to pronounced reduction in solution quality. Such\nassumptions are unnecessary in many real-world applications for three key\nreasons: (i) users might be willing to disclose less sensitive information\n(e.g., city of residence, but not exact location), (ii) the attacker might\nposses auxiliary information (e.g., city of residence in a mobility-on-demand\nsystem, or reviewer expertise in a paper assignment problem), and (iii) domain\ncharacteristics might exclude a subset of solutions (an expert on auctions\nwould not be assigned to review a robotics paper, thus there is no need for\nindistinguishably between reviewers on different fields).\n  We introduce Piecewise Local Differential Privacy (PLDP), a privacy model\ndesigned to protect the utility function in applications where the attacker\npossesses additional information on the characteristics of the utility space.\nPLDP enables a high degree of privacy, while being applicable to real-world,\nunboundedly large settings. Moreover, we propose PALMA, a privacy-preserving\nheuristic for maximum-weight matching. We evaluate PALMA in a vehicle-passenger\nmatching scenario using real data and demonstrate that it provides strong\nprivacy, $\\varepsilon \\leq 3$ and a median of $\\varepsilon = 0.44$, and high\nquality matchings ($10.8\\%$ worse than the non-private optimal).\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 13:33:04 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Danassis", "Panayiotis", ""], ["Triastcyn", "Aleksei", ""], ["Faltings", "Boi", ""]]}, {"id": "2011.08055", "submitter": "Christopher D. Hsu", "authors": "Christopher D. Hsu, Heejin Jeong, George J. Pappas, and Pratik\n  Chaudhari", "title": "Scalable Reinforcement Learning Policies for Multi-Agent Control", "comments": "8 pages, 10 figures, contributed paper at IROS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We develop a Multi-Agent Reinforcement Learning (MARL) method to learn\nscalable control policies for target tracking. Our method can handle an\narbitrary number of pursuers and targets; we show results for tasks consisting\nup to 1000 pursuers tracking 1000 targets. We use a decentralized,\npartially-observable Markov Decision Process framework to model pursuers as\nagents receiving partial observations (range and bearing) about targets which\nmove using fixed, unknown policies. An attention mechanism is used to\nparameterize the value function of the agents; this mechanism allows us to\nhandle an arbitrary number of targets. Entropy-regularized off-policy RL\nmethods are used to train a stochastic policy, and we discuss how it enables a\nhedging behavior between pursuers that leads to a weak form of cooperation in\nspite of completely decentralized control execution. We further develop a\nmasking heuristic that allows training on smaller problems with few\npursuers-targets and execution on much larger problems. Thorough simulation\nexperiments, ablation studies, and comparisons to state of the art algorithms\nare performed to study the scalability of the approach and robustness of\nperformance to varying numbers of agents and targets.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 16:11:12 GMT"}, {"version": "v2", "created": "Wed, 28 Jul 2021 20:19:39 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Hsu", "Christopher D.", ""], ["Jeong", "Heejin", ""], ["Pappas", "George J.", ""], ["Chaudhari", "Pratik", ""]]}, {"id": "2011.08064", "submitter": "Jaber Valinejad", "authors": "Jaber Valinejad and Lamine Mili and Natalie van der Wal", "title": "Research Needed in Computational Social Science for Power System\n  Reliability, Resilience, and Restoration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the literature, smart grids are modeled as cyber-physical power systems\nwithout considering the computational social aspects. However, end-users are\nplaying a key role in their operation and response to disturbances via demand\nresponse and distributed energy resources. Therefore, due to the critical role\nof active and passive end-users and the intermittency of renewable energy,\nsmart grids must be planned and operated by considering the computational\nsocial aspects in addition to the technical aspects. The level of cooperation,\nflexibility, and other social features of the various stakeholders, including\nconsumers, prosumers, and microgrids, affect the system efficiency,\nreliability, and resilience. In this paper, we design an artificial society\nsimulating the interaction between power systems and the social communities\nthat they serve via agent-based modeling inspired by Barsade's theory on the\nemotional spread. The simulation results show a decline in the consumers' and\nprosumers' satisfaction levels induced by a shortage of electricity. It also\nshows the effects of social diffusion via the Internet and mass media on the\nsatisfaction level. In view of the importance of computational social science\nfor power system applications and the limited number of publications devoted to\nit, we provide a list of research topics that need to be achieved to enhance\nthe reliability and resilience of power systems' operation and planning.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 04:39:15 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Valinejad", "Jaber", ""], ["Mili", "Lamine", ""], ["van der Wal", "Natalie", ""]]}, {"id": "2011.08743", "submitter": "Mohammed Sharafath Abdul Hameed", "authors": "Mohammed Sharafath Abdul Hameed, Md Muzahid Khan, Andreas Schwung", "title": "Curiosity Based Reinforcement Learning on Robot Manufacturing Cell", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.MA", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This paper introduces a novel combination of scheduling control on a flexible\nrobot manufacturing cell with curiosity based reinforcement learning.\nReinforcement learning has proved to be highly successful in solving tasks like\nrobotics and scheduling. But this requires hand tuning of rewards in problem\ndomains like robotics and scheduling even where the solution is not obvious. To\nthis end, we apply a curiosity based reinforcement learning, using intrinsic\nmotivation as a form of reward, on a flexible robot manufacturing cell to\nalleviate this problem. Further, the learning agents are embedded into the\ntransportation robots to enable a generalized learning solution that can be\napplied to a variety of environments. In the first approach, the curiosity\nbased reinforcement learning is applied to a simple structured robot\nmanufacturing cell. And in the second approach, the same algorithm is applied\nto a graph structured robot manufacturing cell. Results from the experiments\nshow that the agents are able to solve both the environments with the ability\nto transfer the curiosity module directly from one environment to another. We\nconclude that curiosity based learning on scheduling tasks provide a viable\nalternative to the reward shaped reinforcement learning traditionally used.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 16:19:47 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Hameed", "Mohammed Sharafath Abdul", ""], ["Khan", "Md Muzahid", ""], ["Schwung", "Andreas", ""]]}, {"id": "2011.08944", "submitter": "Dror Dayan", "authors": "Dror Dayan, Kiril Solovey, Marco Pavone, Dan Halperin", "title": "Near-Optimal Multi-Robot Motion Planning with Finite Sampling", "comments": "To appear in the International Conference on Robotics and Automation\n  (ICRA), 2021. This is an extended version that includes full proofs and\n  additional details", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.DS cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  An underlying structure in several sampling-based methods for continuous\nmulti-robot motion planning (MRMP) is the tensor roadmap (TR), which emerges\nfrom combining multiple PRM graphs constructed for the individual robots via a\ntensor product. We study the conditions under which the TR encodes a\nnear-optimal solution for MRMP -- satisfying these conditions implies near\noptimality for a variety of popular planners, including dRRT*, and the discrete\nmethods M* and CBS when applied to the continuous domain. We develop the first\nfinite-sample analysis of this kind, which specifies the number of samples,\ntheir deterministic distribution, and magnitude of the connection radii that\nshould be used by each individual PRM graph, to guarantee near-optimality using\nthe TR. This significantly improves upon a previous asymptotic analysis,\nwherein the number of samples tends to infinity. Our new finite sample-size\nanalysis supports guaranteed high-quality solutions in practice within finite\ntime. To achieve our new result, we first develop a sampling scheme, which we\ncall the staggered grid, for finite-sample motion planning for individual\nrobots, which requires significantly less samples than previous work. We then\nextend it to the much more involved MRMP setting which requires to account for\ninteractions among multiple robots. Finally, we report on a few experiments\nthat serve as a verification of our theoretical findings and raise interesting\nquestions for further investigation.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 21:03:47 GMT"}, {"version": "v2", "created": "Tue, 20 Apr 2021 19:51:56 GMT"}, {"version": "v3", "created": "Mon, 26 Apr 2021 16:15:19 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Dayan", "Dror", ""], ["Solovey", "Kiril", ""], ["Pavone", "Marco", ""], ["Halperin", "Dan", ""]]}, {"id": "2011.08990", "submitter": "Venkata Karteek Yanumula", "authors": "Yanumula V. Karteek, Indrani Kar, Somanath Majhi", "title": "Consensus of Multi-Agent Systems Using Back-Tracking and History\n  Following Algorithms", "comments": null, "journal-ref": "International Journal of Robotics and Automation, 32(4), 2017", "doi": "10.2316/Journal.206.2017.4.206-4782", "report-no": null, "categories": "eess.SY cs.MA cs.SY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This paper proposes two algorithms, namely \"back-tracking\" and \"history\nfollowing\", to reach consensus in case of communication loss for a network of\ndistributed agents with switching topologies. To reach consensus in distributed\ncontrol, considered communication topology forms a strongly connected graph.\nThe graph is no more strongly connected whenever an agent loses\ncommunication.Whenever an agent loses communication, the topology is no more\nstrongly connected. The proposed back-tracking algorithm makes sure that the\nagent backtracks its position unless the communication is reestablished, and\npath is changed to reach consensus. In history following, the agents use their\nmemory and move towards previous consensus point until the communication is\nregained. Upon regaining communication, a new consensus point is calculated\ndepending on the current positions of the agents and they change their\ntrajectories accordingly. Simulation results, for a network of six agents, show\nthat when the agents follow the previous history, the average consensus time is\nless than that of back-tracking. However, situation may arise in history\nfollowing where a false notion of reaching consensus makes one of the agents\nstop at a point near to the actual consensus point. An obstacle avoidance\nalgorithm is integrated with the proposed algorithms to avoid collisions.\nHardware implementation for a three robots system shows the effectiveness of\nthe algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 22:39:20 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Karteek", "Yanumula V.", ""], ["Kar", "Indrani", ""], ["Majhi", "Somanath", ""]]}, {"id": "2011.09192", "submitter": "Karl Tuyls", "authors": "Karl Tuyls, Shayegan Omidshafiei, Paul Muller, Zhe Wang, Jerome\n  Connor, Daniel Hennes, Ian Graham, William Spearman, Tim Waskett, Dafydd\n  Steele, Pauline Luc, Adria Recasens, Alexandre Galashov, Gregory Thornton,\n  Romuald Elie, Pablo Sprechmann, Pol Moreno, Kris Cao, Marta Garnelo, Praneet\n  Dutta, Michal Valko, Nicolas Heess, Alex Bridgland, Julien Perolat, Bart De\n  Vylder, Ali Eslami, Mark Rowland, Andrew Jaegle, Remi Munos, Trevor Back,\n  Razia Ahamed, Simon Bouton, Nathalie Beauguerlange, Jackson Broshear, Thore\n  Graepel, Demis Hassabis", "title": "Game Plan: What AI can do for Football, and What Football can do for AI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid progress in artificial intelligence (AI) and machine learning has\nopened unprecedented analytics possibilities in various team and individual\nsports, including baseball, basketball, and tennis. More recently, AI\ntechniques have been applied to football, due to a huge increase in data\ncollection by professional teams, increased computational power, and advances\nin machine learning, with the goal of better addressing new scientific\nchallenges involved in the analysis of both individual players' and coordinated\nteams' behaviors. The research challenges associated with predictive and\nprescriptive football analytics require new developments and progress at the\nintersection of statistical learning, game theory, and computer vision. In this\npaper, we provide an overarching perspective highlighting how the combination\nof these fields, in particular, forms a unique microcosm for AI research, while\noffering mutual benefits for professional teams, spectators, and broadcasters\nin the years to come. We illustrate that this duality makes football analytics\na game changer of tremendous value, in terms of not only changing the game of\nfootball itself, but also in terms of what this domain can mean for the field\nof AI. We review the state-of-the-art and exemplify the types of analysis\nenabled by combining the aforementioned fields, including illustrative examples\nof counterfactual analysis using predictive models, and the combination of\ngame-theoretic analysis of penalty kicks with statistical learning of player\nattributes. We conclude by highlighting envisioned downstream impacts,\nincluding possibilities for extensions to other sports (real and virtual).\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 10:26:02 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Tuyls", "Karl", ""], ["Omidshafiei", "Shayegan", ""], ["Muller", "Paul", ""], ["Wang", "Zhe", ""], ["Connor", "Jerome", ""], ["Hennes", "Daniel", ""], ["Graham", "Ian", ""], ["Spearman", "William", ""], ["Waskett", "Tim", ""], ["Steele", "Dafydd", ""], ["Luc", "Pauline", ""], ["Recasens", "Adria", ""], ["Galashov", "Alexandre", ""], ["Thornton", "Gregory", ""], ["Elie", "Romuald", ""], ["Sprechmann", "Pablo", ""], ["Moreno", "Pol", ""], ["Cao", "Kris", ""], ["Garnelo", "Marta", ""], ["Dutta", "Praneet", ""], ["Valko", "Michal", ""], ["Heess", "Nicolas", ""], ["Bridgland", "Alex", ""], ["Perolat", "Julien", ""], ["De Vylder", "Bart", ""], ["Eslami", "Ali", ""], ["Rowland", "Mark", ""], ["Jaegle", "Andrew", ""], ["Munos", "Remi", ""], ["Back", "Trevor", ""], ["Ahamed", "Razia", ""], ["Bouton", "Simon", ""], ["Beauguerlange", "Nathalie", ""], ["Broshear", "Jackson", ""], ["Graepel", "Thore", ""], ["Hassabis", "Demis", ""]]}, {"id": "2011.09456", "submitter": "Stefan Bittihn", "authors": "Stefan Bittihn, Andreas Schadschneider", "title": "The Effect of Modern Traffic Information on Braess' Paradox", "comments": "18 pages, 3 figures", "journal-ref": "Physica A 571 (2021) 125829", "doi": "10.1016/j.physa.2021.125829", "report-no": null, "categories": "physics.soc-ph cs.MA nlin.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Braess' paradox has been shown to appear rather generically in many systems\nof transport on networks. It is especially relevant for vehicular traffic where\nit shows that in certain situations building a new road in an urban or highway\nnetwork can lead to increased average travel times for all users. Here we\naddress the question whether this changes if the drivers (agents) have access\nto traffic information as available for modern traffic networks, i.e. through\nnavigation apps and or personal experiences in the past. We study the effect of\ntraffic information in the classical Braess network, but using a microscopic\nmodel for the traffic dynamics, to find out if the paradox can really be\nobserved in such a scenario or if it only exists in some theoretically\navailable user optima that are never realized by drivers that base their route\nchoice decisions intelligently upon realistic traffic information. We address\nthis question for different splits of the two information types.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 18:32:16 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Bittihn", "Stefan", ""], ["Schadschneider", "Andreas", ""]]}, {"id": "2011.09728", "submitter": "Yujie Tang", "authors": "Yujie Tang, Zhaolin Ren, Na Li", "title": "Zeroth-Order Feedback Optimization for Cooperative Multi-Agent Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a class of cooperative multi-agent optimization problems, where each\nagent is associated with a local action vector and a local cost, and the goal\nis to cooperatively find the joint action profile that minimizes the average of\nthe local costs. Such problems arise in many applications, such as distributed\nrouting control, wind farm operation, etc. In many of these problems, gradient\ninformation may not be readily available, and the agents may only observe their\nlocal costs incurred by their actions as a feedback to determine their new\nactions. In this paper, we propose a zeroth-order feedback optimization scheme\nfor the class of problems we consider, and provide explicit complexity bounds\nfor both the convex and nonconvex settings with noiseless and noisy local cost\nobservations. We also discuss briefly on the impacts of knowledge of local\nfunction dependence between agents. The algorithm's performance is justified by\na numerical example of distributed routing control.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 09:08:26 GMT"}, {"version": "v2", "created": "Tue, 23 Feb 2021 02:45:25 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Tang", "Yujie", ""], ["Ren", "Zhaolin", ""], ["Li", "Na", ""]]}, {"id": "2011.10034", "submitter": "Yuxiao Chen", "authors": "Yuxiao Chen, Ugo Rosolia, and Aaron D. Ames", "title": "Decentralized Task and Path Planning for Multi-Robot Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a multi-robot system with a team of collaborative robots and\nmultiple tasks that emerges over time. We propose a fully decentralized task\nand path planning (DTPP) framework consisting of a task allocation module and a\nlocalized path planning module. Each task is modeled as a Markov Decision\nProcess (MDP) or a Mixed Observed Markov Decision Process (MOMDP) depending on\nwhether full states or partial states are observable. The task allocation\nmodule then aims at maximizing the expected pure reward (reward minus cost) of\nthe robotic team. We fuse the Markov model into a factor graph formulation so\nthat the task allocation can be decentrally solved using the max-sum algorithm.\nEach robot agent follows the optimal policy synthesized for the Markov model\nand we propose a localized forward dynamic programming scheme that resolves\nconflicts between agents and avoids collisions. The proposed framework is\ndemonstrated with high fidelity ROS simulations and experiments with multiple\nground robots.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 18:54:28 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Chen", "Yuxiao", ""], ["Rosolia", "Ugo", ""], ["Ames", "Aaron D.", ""]]}, {"id": "2011.10669", "submitter": "James Hare", "authors": "James Z. Hare, Cesar A. Uribe, Lance Kaplan, Ali Jadbabaie", "title": "A General Framework for Distributed Inference with Uncertain Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the problem of distributed classification with a network\nof heterogeneous agents. The agents seek to jointly identify the underlying\ntarget class that best describes a sequence of observations. The problem is\nfirst abstracted to a hypothesis-testing framework, where we assume that the\nagents seek to agree on the hypothesis (target class) that best matches the\ndistribution of observations. Non-Bayesian social learning theory provides a\nframework that solves this problem in an efficient manner by allowing the\nagents to sequentially communicate and update their beliefs for each hypothesis\nover the network. Most existing approaches assume that agents have access to\nexact statistical models for each hypothesis. However, in many practical\napplications, agents learn the likelihood models based on limited data, which\ninduces uncertainty in the likelihood function parameters. In this work, we\nbuild upon the concept of uncertain models to incorporate the agents'\nuncertainty in the likelihoods by identifying a broad set of parametric\ndistribution that allows the agents' beliefs to converge to the same result as\na centralized approach. Furthermore, we empirically explore extensions to\nnon-parametric models to provide a generalized framework of uncertain models in\nnon-Bayesian social learning.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 22:17:12 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Hare", "James Z.", ""], ["Uribe", "Cesar A.", ""], ["Kaplan", "Lance", ""], ["Jadbabaie", "Ali", ""]]}, {"id": "2011.10682", "submitter": "Bolin Gao", "authors": "Bolin Gao, Lacra Pavel", "title": "Continuous-Time Convergence Rates in Potential and Monotone Games", "comments": "20 pages, 5 figures, manuscript submitted to SIAM Journal on Control\n  and Optimization (SICON) for possible publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.GT cs.MA cs.SY eess.SY math.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we provide exponential rates of convergence to the Nash\nequilibrium for continuous-time dual-space game dynamics such as mirror descent\n(MD) and actor-critic (AC). We perform our analysis in $N$-player continuous\nconcave games that are either potential games or monotone games but possibly\npotential-free. In the first part of this paper, we provide a novel relative\ncharacterization of monotone games and show that MD and its discounted version\nconverge with $\\mathcal{O}(e^{-\\beta t})$ in relatively strongly and relatively\nhypo-monotone games, respectively. In the second part of this paper, we\nspecialize our results to games that admit a relatively strongly concave\npotential and show that MD and AC converge with $\\mathcal{O}(e^{-\\beta t})$.\nMoreover, these rates extend their known convergence conditions. Simulations\nare performed which empirically back up our results.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2020 00:00:55 GMT"}, {"version": "v2", "created": "Wed, 28 Jul 2021 00:15:23 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Gao", "Bolin", ""], ["Pavel", "Lacra", ""]]}, {"id": "2011.10718", "submitter": "Mohammad Javad Khojasteh", "authors": "Anshuka Rangi, Mohammad Javad Khojasteh and Massimo Franceschetti", "title": "Learning-based attacks in Cyber-Physical Systems: Exploration,\n  Detection, and Control Cost trade-offs", "comments": "To appear in L4DC 2021. First two authors contributed equally", "journal-ref": "Learning for Dynamics and Control 2021, PMLR", "doi": null, "report-no": null, "categories": "eess.SY cs.CR cs.LG cs.MA cs.SY stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning-based attacks in linear systems, where the\ncommunication channel between the controller and the plant can be hijacked by a\nmalicious attacker. We assume the attacker learns the dynamics of the system\nfrom observations, then overrides the controller's actuation signal, while\nmimicking legitimate operation by providing fictitious sensor readings to the\ncontroller. On the other hand, the controller is on a lookout to detect the\npresence of the attacker and tries to enhance the detection performance by\ncarefully crafting its control signals. We study the trade-offs between the\ninformation acquired by the attacker from observations, the detection\ncapabilities of the controller, and the control cost. Specifically, we provide\ntight upper and lower bounds on the expected $\\epsilon$-deception time, namely\nthe time required by the controller to make a decision regarding the presence\nof an attacker with confidence at least $(1-\\epsilon\\log(1/\\epsilon))$. We then\nshow a probabilistic lower bound on the time that must be spent by the attacker\nlearning the system, in order for the controller to have a given expected\n$\\epsilon$-deception time. We show that this bound is also order optimal, in\nthe sense that if the attacker satisfies it, then there exists a learning\nalgorithm with the given order expected deception time. Finally, we show a\nlower bound on the expected energy expenditure required to guarantee detection\nwith confidence at least $1-\\epsilon \\log(1/\\epsilon)$.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2020 04:08:16 GMT"}, {"version": "v2", "created": "Thu, 20 May 2021 02:11:55 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Rangi", "Anshuka", ""], ["Khojasteh", "Mohammad Javad", ""], ["Franceschetti", "Massimo", ""]]}, {"id": "2011.10753", "submitter": "Avik Pal", "authors": "Avik Pal, Jonah Philion, Yuan-Hong Liao and Sanja Fidler", "title": "Emergent Road Rules In Multi-Agent Driving Environments", "comments": "International Conference on Learning Representations (2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  For autonomous vehicles to safely share the road with human drivers,\nautonomous vehicles must abide by specific \"road rules\" that human drivers have\nagreed to follow. \"Road rules\" include rules that drivers are required to\nfollow by law -- such as the requirement that vehicles stop at red lights -- as\nwell as more subtle social rules -- such as the implicit designation of fast\nlanes on the highway. In this paper, we provide empirical evidence that\nsuggests that -- instead of hard-coding road rules into self-driving algorithms\n-- a scalable alternative may be to design multi-agent environments in which\nroad rules emerge as optimal solutions to the problem of maximizing traffic\nflow. We analyze what ingredients in driving environments cause the emergence\nof these road rules and find that two crucial factors are noisy perception and\nagents' spatial density. We provide qualitative and quantitative evidence of\nthe emergence of seven social driving behaviors, ranging from obeying traffic\nsignals to following lanes, all of which emerge from training agents to drive\nquickly to destinations without colliding. Our results add empirical support\nfor the social road rules that countries worldwide have agreed on for safe,\nefficient driving.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2020 09:43:50 GMT"}, {"version": "v2", "created": "Wed, 17 Mar 2021 07:29:41 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Pal", "Avik", ""], ["Philion", "Jonah", ""], ["Liao", "Yuan-Hong", ""], ["Fidler", "Sanja", ""]]}, {"id": "2011.10837", "submitter": "Miklos Borsi", "authors": "Miklos Borsi (University of Bristol)", "title": "Imperfect Oracles: The Effect of Strategic Information on Stock Markets", "comments": "19 pages, 13 figures, to be published in ICAART 2021 proceedings as a\n  short paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.GT cs.MA", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Modern financial market dynamics warrant detailed analysis due to their\nsignificant impact on the world. This, however, often proves intractable;\nmassive numbers of agents, strategies and their change over time in reaction to\neach other leads to difficulties in both theoretical and simulational\napproaches. Notable work has been done on strategy dominance in stock markets\nwith respect to the ratios of agents with certain strategies. Perfect knowledge\nof the strategies employed could then put an individual agent at a consistent\ntrading advantage. This research reports the effects of imperfect oracles on\nthe system - dispensing noisy information about strategies - information which\nwould normally be hidden from market participants. The effect and achievable\nprofits of a singular trader with access to an oracle were tested exhaustively\nwith previously unexplored factors such as changing order schedules.\nAdditionally, the effect of noise on strategic information was traced through\nits effect on trader efficiency.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2020 18:23:04 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Borsi", "Miklos", "", "University of Bristol"]]}, {"id": "2011.10915", "submitter": "Zhenyu Shou", "authors": "Zhenyu Shou, Xuan Di", "title": "Multi-Agent Reinforcement Learning for Dynamic Routing Games: A Unified\n  Paradigm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper aims to develop a unified paradigm that models one's learning\nbehavior and the system's equilibrating processes in a routing game among\natomic selfish agents. Such a paradigm can assist policymakers in devising\noptimal operational and planning countermeasures under both normal and abnormal\ncircumstances. To this end, a multi-agent reinforcement learning (MARL)\nparadigm is proposed in which each agent learns and updates her own en-route\npath choice policy while interacting with others on transportation networks.\nThis paradigm is shown to generalize the classical notion of dynamic user\nequilibrium (DUE) to model-free and data-driven scenarios. We also illustrate\nthat the equilibrium outcomes computed from our developed MARL paradigm\ncoincide with DUE and dynamic system optimal (DSO), respectively, when rewards\nare set differently. In addition, with the goal to optimize some systematic\nobjective (e.g., overall traffic condition) of city planners, we formulate a\nbilevel optimization problem with the upper level as city planners and the\nlower level as a multi-agent system where each rational and selfish traveler\naims to minimize her travel cost. We demonstrate the effect of two\nadministrative measures, namely tolling and signal control, on the behavior of\ntravelers and show that the systematic objective of city planners can be\noptimized by a proper control. The results show that on the Braess network, the\noptimal toll charge on the central link is greater or equal to 25, with which\nthe average travel time of selfish agents is minimized and the emergence of\nBraess paradox could be avoided. In a large-sized real-world road network with\n69 nodes and 166 links, the optimal offset for signal control on Broadway is\nderived as 4 seconds, with which the average travel time of all controllable\nagents is minimized.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2020 02:31:14 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Shou", "Zhenyu", ""], ["Di", "Xuan", ""]]}, {"id": "2011.11130", "submitter": "Hesham Rakha", "authors": "Helena Breuer, Jianhe Du, Hesham A. Rakha", "title": "Ride-hailing Impacts on Transit Ridership: Chicago Case Study", "comments": "Paper submitted to the Transportation Research Board Annual Meeting", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing literature on the relationship between ride-hailing (RH) and transit\nservices is limited to empirical studies that lack real-time spatial contexts.\nTo fill this gap, we took a novel real-time geospatial analysis approach. With\nsource data on ride-hailing trips in Chicago, Illinois, we computed real-time\ntransit-equivalent trips for all 7,949,902 ride-hailing trips in June 2019; the\nsheer size of our sample is incomparable to the samples studied in existing\nliterature. An existing Multinomial Nested Logit Model was used to determine\nthe probability of a ride-hailer selecting a transit alternative to serve the\nspecific O-D pair, P(Transit|CTA). We find that 31% of ride-hailing trips are\nreplaceable, whereas 61% of trips are not replaceable. The remaining 8% lie\nwithin a buffer zone. We measured the robustness of this probability using a\nparametric sensitivity analysis and performed a two-tailed t-test. Our results\nindicate that of the four sensitivity parameters, the probability was most\nsensitive to the total travel time of a transit trip. The main contribution of\nour research is our thorough approach and fine-tuned series of real-time\nspatiotemporal analyses that investigate the replaceability of ride-hailing\ntrips for public transit. The results and discussion intend to provide\nperspective derived from real trips and we anticipate that this paper will\ndemonstrate the research benefits associated with the recording and release of\nride-hailing data.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 14:47:11 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Breuer", "Helena", ""], ["Du", "Jianhe", ""], ["Rakha", "Hesham A.", ""]]}, {"id": "2011.11247", "submitter": "Shridhar Velhal", "authors": "Shridhar Velhal and Suresh Sundaram", "title": "Restricted Airspace Protection using Multi-UAV Spatio-TemporalMulti-Task\n  Allocation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.MA cs.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper addresses the problem of restricted airspace protection from\ninvaders using the cooperative multi-UAV system. The objective is to detect and\ncapture the invaders cooperatively by a team of homogeneous UAVs (called\nevaders)before invaders enter the restricted airspace. The problem of\nrestricted airspace protection problem is formulated as a Multi-UAV\nSpatio-Temporal Multi-Task Allocation problem and is referred as MUST-MTA. The\nMUST-MTA problem is solved using a modified consensus-based bundled auction\nmethod. Here, the spatial and time constraints are handled by combining both\nspatial and temporal loss component. The solution identifies the sequence of\nspatial locations to be reached by the evader at specific time instants to\nneutralize the invaders. The performance of MUST-MTA with the consensus\napproach is evaluated in a simulated environment. The Monte-Carlo simulation\nresults clearly indicate the efficacy of the proposed approach in restricted\nairspace protection against intruders\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 07:13:42 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Velhal", "Shridhar", ""], ["Sundaram", "Suresh", ""]]}, {"id": "2011.11381", "submitter": "Kelvin Kok Fung Li", "authors": "Kelvin K.F. Li, Stephen A. Jarvis, Fayyaz Minhas", "title": "Elementary Effects Analysis of factors controlling COVID-19 infections\n  in computational simulation reveals the importance of Social Distancing and\n  Mask Usage", "comments": "14 pages, 10 figures", "journal-ref": "Computers in Biology and Medicine 134 (2021) 104369", "doi": "10.1016/j.compbiomed.2021.104369", "report-no": null, "categories": "cs.AI cs.MA physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  COVID-19 was declared a pandemic by the World Health Organization (WHO) on\nMarch 11th, 2020. With half of the world's countries in lockdown as of April\ndue to this pandemic, monitoring and understanding the spread of the virus and\ninfection rates and how these factors relate to behavioural and societal\nparameters is crucial for effective policy making. This paper aims to\ninvestigate the effectiveness of masks, social distancing, lockdown and\nself-isolation for reducing the spread of SARS-CoV-2 infections. Our findings\nbased on agent-based simulation modelling show that whilst requiring a lockdown\nis widely believed to be the most efficient method to quickly reduce infection\nnumbers, the practice of social distancing and the usage of surgical masks can\npotentially be more effective than requiring a lockdown. Our multivariate\nanalysis of simulation results using the Morris Elementary Effects Method\nsuggests that if a sufficient proportion of the population wore surgical masks\nand followed social distancing regulations, then SARS-CoV-2 infections can be\ncontrolled without requiring a lockdown.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 04:36:26 GMT"}, {"version": "v2", "created": "Tue, 26 Jan 2021 17:43:14 GMT"}, {"version": "v3", "created": "Sun, 28 Feb 2021 04:31:49 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Li", "Kelvin K. F.", ""], ["Jarvis", "Stephen A.", ""], ["Minhas", "Fayyaz", ""]]}, {"id": "2011.11596", "submitter": "Andrzej Kaczmarczyk", "authors": "Robert Bredereck, Andrzej Kaczmarczyk, and Rolf Niedermeier", "title": "Envy-Free Allocations Respecting Social Networks", "comments": "49 pages; 7 figures; A preliminary version of this article appeared\n  in the Proceedings of the 17th International Conference on Autonomous Agents\n  and Multiagent Systems (AAMAS'18)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding an envy-free allocation of indivisible resources to agents is a\ncentral task in many multiagent systems. Often, non-trivial envy-free\nallocations do not exist, and, when they do, finding them can be\ncomputationally hard. Classical envy-freeness requires that every agent likes\nthe resources allocated to it at least as much as the resources allocated to\nany other agent. In many situations this assumption can be relaxed since agents\noften do not even know each other. We enrich the envy-freeness concept by\ntaking into account (directed) social networks of the agents. Thus, we require\nthat every agent likes its own allocation at least as much as those of all its\n(out)neighbors. This leads to a \"more local\" concept of envy-freeness. We also\nconsider a \"strong\" variant where every agent must like its own allocation more\nthan those of all its (out)neighbors.\n  We analyze the classical and the parameterized complexity of finding\nallocations that are complete and, at the same time, envy-free with respect to\none of the variants of our new concept. To this end, we study different\nrestrictions of the agents' preferences and of the social network structure. We\nidentify cases that become easier (from $\\Sigma^\\textrm{p}_2$-hard or NP-hard\nto polynomial-time solvability) and cases that become harder (from\npolynomial-time solvability to NP-hard) when comparing classical envy-freeness\nwith our graph envy-freeness. Furthermore, we spot cases where graph\nenvy-freeness is easier to decide than strong graph envy-freeness, and vice\nversa. On the route to one of our fixed-parameter tractability results, we also\nestablish a connection to a directed and colored variant of the classical\nSUBGRAPH ISOMORPHISM problem, thereby extending a known fixed-parameter\ntractability result for the latter.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 18:14:15 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Bredereck", "Robert", ""], ["Kaczmarczyk", "Andrzej", ""], ["Niedermeier", "Rolf", ""]]}, {"id": "2011.11976", "submitter": "Alexis Poulh\\`es M", "authors": "Alexis Poulhes and Paul Mirial", "title": "Modeling skier behavior for planning and management. Dynaski, an\n  agent-based in congested ski-areas", "comments": "24 pages, 8 figures 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In leisure spaces, particularly theme parks and museums, researchers and\nmanagers have long been using simulation tools to tackle the big issue\nassociated with attractiveness, flow management. In this research, we present\nthe management and planning perspective of a multi-agent simulation tool which\nmodels the behavior of skiers in a ski-area. This is the first tool able to\nsimulate and compare management and planning scenarios as well as their impacts\non the comfort of skiers, in particular ski-area waiting times. This paper aims\nto integrate multiple data sources to calibrate the simulation on a real case\nstudy. An original field survey of users during a week details the skier\npopulation. The first average skier speeds are calculated from GPS data on one\nordinary day. The validation data are used to calibrate the parameters of the\nbehavioral model. A demonstration of the simulation tool is conducted on the La\nPlagne ski-area, one of the largest in France. A test case, the construction of\nnew housing in a station near the ski-area, is conducted. An addition of 1620\nnew skiers delays the skier average waiting time by 12 pourcents.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 09:12:34 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Poulhes", "Alexis", ""], ["Mirial", "Paul", ""]]}, {"id": "2011.12354", "submitter": "Dong Chen", "authors": "Dong Chen, Zhaojian Li, Tianshu Chu, Rui Yao, Feng Qiu, Kaixiang Lin", "title": "PowerNet: Multi-agent Deep Reinforcement Learning for Scalable Powergrid\n  Control", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.MA cs.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper develops an efficient multi-agent deep reinforcement learning\nalgorithm for cooperative controls in powergrids. Specifically, we consider the\ndecentralized inverter-based secondary voltage control problem in distributed\ngenerators (DGs), which is first formulated as a cooperative multi-agent\nreinforcement learning (MARL) problem. We then propose a novel on-policy MARL\nalgorithm, PowerNet, in which each agent (DG) learns a control policy based on\n(sub-)global reward but local states from its neighboring agents. Motivated by\nthe fact that a local control from one agent has limited impact on agents\ndistant from it, we exploit a novel spatial discount factor to reduce the\neffect from remote agents, to expedite the training process and improve\nscalability. Furthermore, a differentiable, learning-based communication\nprotocol is employed to foster the collaborations among neighboring agents. In\naddition, to mitigate the effects of system uncertainty and random noise\nintroduced during on-policy learning, we utilize an action smoothing factor to\nstabilize the policy execution. To facilitate training and evaluation, we\ndevelop PGSim, an efficient, high-fidelity powergrid simulation platform.\nExperimental results in two microgrid setups show that the developed PowerNet\noutperforms a conventional model-based control, as well as several\nstate-of-the-art MARL algorithms. The decentralized learning scheme and high\nsample efficiency also make it viable to large-scale power grids.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 20:22:36 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Chen", "Dong", ""], ["Li", "Zhaojian", ""], ["Chu", "Tianshu", ""], ["Yao", "Rui", ""], ["Qiu", "Feng", ""], ["Lin", "Kaixiang", ""]]}, {"id": "2011.12480", "submitter": "Beatriz Asfora", "authors": "Beatriz A. Asfora, Jacopo Banfi and Mark Campbell", "title": "Mixed-Integer Linear Programming Models for Multi-Robot Non-Adversarial\n  Search", "comments": "Published at IEEE Robotics and Automation Letters, presented at IROS\n  2020. Presentation available at https://youtu.be/BhUczcDq3Dc Code is open\n  source and available at https://github.com/basfora/milp_mespp.git", "journal-ref": "IEEE Robotics and Automation Letters, vol. 5, no. 4, pp.\n  6805-6812, Oct. 2020", "doi": "10.1109/LRA.2020.3017473", "report-no": null, "categories": "cs.RO cs.CC cs.MA", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In this letter, we consider the Multi-Robot Efficient Search Path Planning\n(MESPP) problem, where a team of robots is deployed in a graph-represented\nenvironment to capture a moving target within a given deadline. We prove this\nproblem to be NP-hard, and present the first set of Mixed-Integer Linear\nProgramming (MILP) models to tackle the MESPP problem. Our models are the first\nto encompass multiple searchers, arbitrary capture ranges, and false negatives\nsimultaneously. While state-of-the-art algorithms for MESPP are based on simple\npath enumeration, the adoption of MILP as a planning paradigm allows to\nleverage the powerful techniques of modern solvers, yielding better\ncomputational performance and, as a consequence, longer planning horizons. The\nmodels are designed for computing optimal solutions offline, but can be easily\nadapted for a distributed online approach. Our simulations show that it is\npossible to achieve 98% decrease in computational time relative to the previous\nstate-of-the-art. We also show that the distributed approach performs nearly as\nwell as the centralized, within 6% in the settings studied in this letter, with\nthe advantage of requiring significant less time - an important consideration\nin practical search missions.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 02:03:57 GMT"}, {"version": "v2", "created": "Tue, 12 Jan 2021 23:38:26 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Asfora", "Beatriz A.", ""], ["Banfi", "Jacopo", ""], ["Campbell", "Mark", ""]]}, {"id": "2011.12711", "submitter": "Shihao Tian", "authors": "Weizhi Du, Harvey Tian", "title": "Coalition Control Model: A Dynamic Resource Distribution Method Based on\n  Model Predicative Control", "comments": "6 figures, and 11 pages. This paper is used for Yao Computer Science\n  competition", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimization of resource distribution has been a challenging topic in current\nsociety. To explore this topic, we develop a Coalition Control Model(CCM) based\non the Model Predictive Control(MPC) and test it using a fishing model with\nlinear parameters. The fishing model focuses on the problem of distributing\nfishing fleets in certain regions to maximize fish caught using either\nexhaustive or heuristic search. Our method introduces a communication mechanism\nto allow fishing fleets to merge or split, after which new coalitions can be\nautomatically formed. Having the coalition structure stabilized, the system\nreaches the equilibrium state through the Nash-Bargaining process. Our\nexperiments on the hypothetical fishing model demonstrated that the CCM can\ndynamically distribute limited resources in complex scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 13:23:20 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Du", "Weizhi", ""], ["Tian", "Harvey", ""]]}, {"id": "2011.12770", "submitter": "Rafal Kucharski", "authors": "Rafa{\\l} Kucharski, Oded Cats, Julian Sienkiewicz", "title": "Modelling virus spreading in ride-pooling networks", "comments": null, "journal-ref": "Scientific Reports 11 (1), 1-11, 2021", "doi": "10.1038/s41598-021-86704-2", "report-no": null, "categories": "physics.soc-ph cs.MA", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Urban mobility needs alternative sustainable travel modes to keep our\npandemic cities in motion. Ride-pooling, where a single vehicle is shared by\nmore than one traveller, is not only appealing for mobility platforms and their\ntravellers, but also for promoting the sustainability of urban mobility\nsystems. Yet, the potential of ride-pooling rides to serve as a safe and\neffective alternative given the personal and public health risks considerations\nassociated with the COVID-19 pandemic is hitherto unknown. To answer this, we\ncombine epidemiological and behavioural shareability models to examine\nspreading among ride-pooling travellers, with an application for Amsterdam.\nFindings are at first sight devastating, with only few initially infected\ntravellers needed to spread the virus to hundreds of ride-pooling users.\nWithout intervention, ride-pooling system may substantially contribute to virus\nspreading. Notwithstanding, we identify an effective control measure allowing\nto halt the spreading before the outbreaks (at 50 instead of 800 infections)\nwithout sacrificing the efficiency achieved by pooling. Fixed matches among\nco-travellers disconnect the otherwise dense contact network, encapsulating the\nvirus in small communities and preventing the outbreaks.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 14:32:14 GMT"}, {"version": "v2", "created": "Mon, 25 Jan 2021 11:46:07 GMT"}, {"version": "v3", "created": "Thu, 8 Apr 2021 09:48:46 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Kucharski", "Rafa\u0142", ""], ["Cats", "Oded", ""], ["Sienkiewicz", "Julian", ""]]}, {"id": "2011.12827", "submitter": "Rafal Kucharski", "authors": "Rafa{\\l} Kucharski, Oded Cats", "title": "MaaSSim -- agent-based two-sided mobility platform simulator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA physics.soc-ph", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Two-sided mobility platforms, such as Uber and Lyft, widely emerged in the\nurban mobility landscape, bringing disruptive changes to transportation systems\nworldwide. This calls for a simulation framework where researchers from various\nand across disciplines may introduce models aimed at representing the dynamics\nof platform-driven urban mobility systems. In this work, we present MaaSSim, an\nagent-based simulator reproducing the transport system used by two kind of\nagents: (i) travellers, requesting to travel from their origin to destination\nat a given time, and (ii) drivers supplying their travel needs by offering them\nrides. An intermediate agent, the platform, allows demand to be matched with\nsupply. Agents are decision makers, specifically, travellers may decide which\nmode they use or reject an incoming offer. Similarly, drivers may opt-out from\nthe system or reject incoming requests. All of the above behaviours are\nmodelled through user-defined modules, representing agents' taste variations\n(heterogeneity), their previous experiences (learning) and available\ninformation (system control). MaaSSim is an open-source library available at a\npublic repository github.com/RafalKucharskiPK/MaaSSim, along with a set of\ntutorials and reproducible use-case scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 15:32:13 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Kucharski", "Rafa\u0142", ""], ["Cats", "Oded", ""]]}, {"id": "2011.12895", "submitter": "Peng Sun", "authors": "Peng Sun, Jiechao Xiong, Lei Han, Xinghai Sun, Shuxing Li, Jiawei Xu,\n  Meng Fang, Zhengyou Zhang", "title": "TLeague: A Framework for Competitive Self-Play based Distributed\n  Multi-Agent Reinforcement Learning", "comments": "21 pages, 3 figures, technical report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Competitive Self-Play (CSP) based Multi-Agent Reinforcement Learning (MARL)\nhas shown phenomenal breakthroughs recently. Strong AIs are achieved for\nseveral benchmarks, including Dota 2, Glory of Kings, Quake III, StarCraft II,\nto name a few. Despite the success, the MARL training is extremely data\nthirsty, requiring typically billions of (if not trillions of) frames be seen\nfrom the environment during training in order for learning a high performance\nagent. This poses non-trivial difficulties for researchers or engineers and\nprevents the application of MARL to a broader range of real-world problems. To\naddress this issue, in this manuscript we describe a framework, referred to as\nTLeague, that aims at large-scale training and implements several main-stream\nCSP-MARL algorithms. The training can be deployed in either a single machine or\na cluster of hybrid machines (CPUs and GPUs), where the standard Kubernetes is\nsupported in a cloud native manner. TLeague achieves a high throughput and a\nreasonable scale-up when performing distributed training. Thanks to the modular\ndesign, it is also easy to extend for solving other multi-agent problems or\nimplementing and verifying MARL algorithms. We present experiments over\nStarCraft II, ViZDoom and Pommerman to show the efficiency and effectiveness of\nTLeague. The code is open-sourced and available at\nhttps://github.com/tencent-ailab/tleague_projpage\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 17:24:20 GMT"}, {"version": "v2", "created": "Mon, 30 Nov 2020 03:23:36 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Sun", "Peng", ""], ["Xiong", "Jiechao", ""], ["Han", "Lei", ""], ["Sun", "Xinghai", ""], ["Li", "Shuxing", ""], ["Xu", "Jiawei", ""], ["Fang", "Meng", ""], ["Zhang", "Zhengyou", ""]]}, {"id": "2011.13219", "submitter": "Qingbiao Li", "authors": "Qingbiao Li, Weizhe Lin, Zhe Liu, Amanda Prorok", "title": "Message-Aware Graph Attention Networks for Large-Scale Multi-Robot Path\n  Planning", "comments": "This work has been accepted to the IEEE Robotics and Automation\n  Letters (RA-L) for publication. Copyright may be transferred without notice,\n  after which this version may no longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.DC cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The domains of transport and logistics are increasingly relying on autonomous\nmobile robots for the handling and distribution of passengers or resources. At\nlarge system scales, finding decentralized path planning and coordination\nsolutions is key to efficient system performance. Recently, Graph Neural\nNetworks (GNNs) have become popular due to their ability to learn communication\npolicies in decentralized multi-agent systems. Yet, vanilla GNNs rely on\nsimplistic message aggregation mechanisms that prevent agents from prioritizing\nimportant information. To tackle this challenge, in this paper, we extend our\nprevious work that utilizes GNNs in multi-agent path planning by incorporating\na novel mechanism to allow for message-dependent attention. Our Message-Aware\nGraph Attention neTwork (MAGAT) is based on a key-query-like mechanism that\ndetermines the relative importance of features in the messages received from\nvarious neighboring robots. We show that MAGAT is able to achieve a performance\nclose to that of a coupled centralized expert algorithm. Further, ablation\nstudies and comparisons to several benchmark models show that our attention\nmechanism is very effective across different robot densities and performs\nstably in different constraints in communication bandwidth. Experiments\ndemonstrate that our model is able to generalize well in previously unseen\nproblem instances, and that it achieves a 47\\% improvement over the benchmark\nsuccess rate, even in very large-scale instances that are $\\times$100 larger\nthan the training instances.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 10:37:13 GMT"}, {"version": "v2", "created": "Sun, 25 Apr 2021 11:40:52 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Li", "Qingbiao", ""], ["Lin", "Weizhe", ""], ["Liu", "Zhe", ""], ["Prorok", "Amanda", ""]]}, {"id": "2011.13604", "submitter": "Carole Adam", "authors": "Elise Beck, Julie Dugdale, Carole Adam, Christelle Ga\\\"idatzis, Julius\n  Ba\\~ngate", "title": "A methodology for co-constructing an interdisciplinary model: from model\n  to survey, from survey to model", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  How should computer science and social science collaborate to build a common\nmodel? How should they proceed to gather data that is really useful to the\nmodelling? How can they design a survey that is tailored to the target model?\nThis paper aims to answer those crucial questions in the framework of a\nmultidisciplinary research project. This research addresses the issue of\nco-constructing a model when several disciplines are involved, and is applied\nto modelling human behaviour immediately after an earthquake. The main\ncontribution of the work is to propose a tool dedicated to multidisciplinary\ndialogue. It also proposes a reflexive analysis of the enriching intellectual\nprocess carried out by the different disciplines involved. Finally, from\nworking with an anthropologist, a complementary view of the multidisciplinary\nprocess is given.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 08:41:47 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Beck", "Elise", ""], ["Dugdale", "Julie", ""], ["Adam", "Carole", ""], ["Ga\u00efdatzis", "Christelle", ""], ["Ba\u00f1gate", "Julius", ""]]}, {"id": "2011.14148", "submitter": "Karena X. Cai", "authors": "Karena X. Cai, Tung Phan-Minh, Soon-Jo Chung, Richard M. Murray", "title": "Rules of the Road: Safety and Liveness Guarantees for Autonomous\n  Vehicles", "comments": "20 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The ability to guarantee safety and progress for all vehicles is vital to the\nsuccess of the autonomous vehicle industry. We present a framework for\ndesigning autonomous vehicle behavior in a way that is safe and guarantees\nprogress for all agents. In this paper, we first introduce a new game paradigm\nwhich we term the quasi-simultaneous game. We then define an agent protocol\nthat all agents must use to make decisions in this quasi-simultaneous game\nsetting. According to the protocol, agents first select an intended action\nusing a behavioral profile. Then, the protocol defines whether an agent has\nprecedence to take its intended action or must take a sub-optimal action. The\nprotocol ensures safety under all traffic conditions and liveness for all\nagents under `sparse' traffic conditions. We provide proofs of correctness of\nthe protocol and validate our results in simulation.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 15:37:05 GMT"}, {"version": "v2", "created": "Tue, 23 Mar 2021 19:45:50 GMT"}], "update_date": "2021-03-25", "authors_parsed": [["Cai", "Karena X.", ""], ["Phan-Minh", "Tung", ""], ["Chung", "Soon-Jo", ""], ["Murray", "Richard M.", ""]]}, {"id": "2011.14281", "submitter": "Changxi Zhu", "authors": "Changxi Zhu and Ho-fung Leung and Shuyue Hu and Yi Cai", "title": "A Q-values Sharing Framework for Multiagent Reinforcement Learning under\n  Budget Constraint", "comments": "31 pages, 16 figures, submitted to ACM Transactions on Autonomous and\n  Adaptive Systems (TAAS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In teacher-student framework, a more experienced agent (teacher) helps\naccelerate the learning of another agent (student) by suggesting actions to\ntake in certain states. In cooperative multiagent reinforcement learning\n(MARL), where agents need to cooperate with one another, a student may fail to\ncooperate well with others even by following the teachers' suggested actions,\nas the polices of all agents are ever changing before convergence. When the\nnumber of times that agents communicate with one another is limited (i.e.,\nthere is budget constraint), the advising strategy that uses actions as advices\nmay not be good enough. We propose a partaker-sharer advising framework (PSAF)\nfor cooperative MARL agents learning with budget constraint. In PSAF, each\nQ-learner can decide when to ask for Q-values and share its Q-values. We\nperform experiments in three typical multiagent learning problems. Evaluation\nresults show that our approach PSAF outperforms existing advising methods under\nboth unlimited and limited budget, and we give an analysis of the impact of\nadvising actions and sharing Q-values on agents' learning.\n", "versions": [{"version": "v1", "created": "Sun, 29 Nov 2020 04:51:57 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Zhu", "Changxi", ""], ["Leung", "Ho-fung", ""], ["Hu", "Shuyue", ""], ["Cai", "Yi", ""]]}, {"id": "2011.14393", "submitter": "Jalal Arabneydi", "authors": "Vida Fathi, Jalal Arabneydi and Amir G. Aghdam", "title": "Reinforcement Learning in Linear Quadratic Deep Structured Teams: Global\n  Convergence of Policy Gradient Methods", "comments": "Proceedings of IEEE Conference on Decision and Control, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.LG cs.SY eess.SY math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we study the global convergence of model-based and model-free\npolicy gradient descent and natural policy gradient descent algorithms for\nlinear quadratic deep structured teams. In such systems, agents are partitioned\ninto a few sub-populations wherein the agents in each sub-population are\ncoupled in the dynamics and cost function through a set of linear regressions\nof the states and actions of all agents. Every agent observes its local state\nand the linear regressions of states, called deep states. For a sufficiently\nsmall risk factor and/or sufficiently large population, we prove that\nmodel-based policy gradient methods globally converge to the optimal solution.\nGiven an arbitrary number of agents, we develop model-free policy gradient and\nnatural policy gradient algorithms for the special case of risk-neutral cost\nfunction. The proposed algorithms are scalable with respect to the number of\nagents due to the fact that the dimension of their policy space is independent\nof the number of agents in each sub-population. Simulations are provided to\nverify the theoretical results.\n", "versions": [{"version": "v1", "created": "Sun, 29 Nov 2020 16:02:39 GMT"}, {"version": "v2", "created": "Tue, 15 Dec 2020 06:55:09 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Fathi", "Vida", ""], ["Arabneydi", "Jalal", ""], ["Aghdam", "Amir G.", ""]]}, {"id": "2011.14890", "submitter": "Niko Grupen", "authors": "Niko A. Grupen, Daniel D. Lee, Bart Selman", "title": "Low-Bandwidth Communication Emerges Naturally in Multi-Agent Learning\n  Systems", "comments": "10 pages, 6 figures, Appearing in Talking to Strangers: Zero-Shot\n  Emergent Communication Workshop NeurIPS 2020. Fixed part (a) of Figure 2 to\n  include correct baseline reported in quantitative results section", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we study emergent communication through the lens of cooperative\nmulti-agent behavior in nature. Using insights from animal communication, we\npropose a spectrum from low-bandwidth (e.g. pheromone trails) to high-bandwidth\n(e.g. compositional language) communication that is based on the cognitive,\nperceptual, and behavioral capabilities of social agents. Through a series of\nexperiments with pursuit-evasion games, we identify multi-agent reinforcement\nlearning algorithms as a computational model for the low-bandwidth end of the\ncommunication spectrum.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 15:29:57 GMT"}, {"version": "v2", "created": "Tue, 8 Dec 2020 20:21:14 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Grupen", "Niko A.", ""], ["Lee", "Daniel D.", ""], ["Selman", "Bart", ""]]}]