[{"id": "1702.00290", "submitter": "Junxing Yang", "authors": "Scott A. Smolka (1), Ashish Tiwari (2), Lukas Esterle (3), Anna Lukina\n  (3), Junxing Yang (1), and Radu Grosu (1 and 3) ((1) Department of Computer\n  Science, Stony Brook University, USA, (2) SRI International, USA, (3)\n  Cyber-Physical Systems Group, Technische Universit\\\"at Wien, Austria)", "title": "Attacking the V: On the Resiliency of Adaptive-Horizon MPC", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the concept of a V-formation game between a controller and an\nattacker, where controller's goal is to maneuver the plant (a simple model of\nflocking dynamics) into a V-formation, and the goal of the attacker is to\nprevent the controller from doing so. Controllers in V-formation games utilize\na new formulation of model-predictive control we call Adaptive-Horizon MPC\n(AMPC), giving them extraordinary power: we prove that under certain\ncontrollability assumptions, an AMPC controller is able to attain V-formation\nwith probability 1.\n  We define several classes of attackers, including those that in one move can\nremove R birds from the flock, or introduce random displacement into flock\ndynamics. We consider both naive attackers, whose strategies are purely\nprobabilistic, and AMPC-enabled attackers, putting them on par strategically\nwith the controllers. While an AMPC-enabled controller is expected to win every\ngame with probability 1, in practice, it is resource-constrained: its maximum\nprediction horizon and the maximum number of game execution steps are fixed.\nUnder these conditions, an attacker has a much better chance of winning a\nV-formation game.\n  Our extensive performance evaluation of V-formation games uses statistical\nmodel checking to estimate the probability an attacker can thwart the\ncontroller. Our results show that for the bird-removal game with R = 1, the\ncontroller almost always wins (restores the flock to a V-formation). For R = 2,\nthe game outcome critically depends on which two birds are removed. For the\ndisplacement game, our results again demonstrate that an intelligent attacker,\ni.e. one that uses AMPC in this case, significantly outperforms its naive\ncounterpart that randomly executes its attack.\n", "versions": [{"version": "v1", "created": "Wed, 1 Feb 2017 14:45:48 GMT"}], "update_date": "2017-02-02", "authors_parsed": [["Smolka", "Scott A.", "", "1 and 3"], ["Tiwari", "Ashish", "", "1 and 3"], ["Esterle", "Lukas", "", "1 and 3"], ["Lukina", "Anna", "", "1 and 3"], ["Yang", "Junxing", "", "1 and 3"], ["Grosu", "Radu", "", "1 and 3"]]}, {"id": "1702.00785", "submitter": "Ding Zhao", "authors": "Baiming Chen, Ding Zhao, Huei Peng", "title": "Evaluation of Automated Vehicles Encountering Pedestrians at\n  Unsignalized Crossings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.RO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interactions between vehicles and pedestrians have always been a major\nproblem in traffic safety. Experienced human drivers are able to analyze the\nenvironment and choose driving strategies that will help them avoid crashes.\nWhat is not yet clear, however, is how automated vehicles will interact with\npedestrians. This paper proposes a new method for evaluating the safety and\nfeasibility of the driving strategy of automated vehicles when encountering\nunsignalized crossings. MobilEye sensors installed on buses in Ann Arbor,\nMichigan, collected data on 2,973 valid crossing events. A stochastic\ninteraction model was then created using a multivariate Gaussian mixture model.\nThis model allowed us to simulate the movements of pedestrians reacting to an\noncoming vehicle when approaching unsignalized crossings, and to evaluate the\npassing strategies of automated vehicles. A simulation was then conducted to\ndemonstrate the evaluation procedure.\n", "versions": [{"version": "v1", "created": "Thu, 2 Feb 2017 03:07:31 GMT"}, {"version": "v2", "created": "Sun, 26 Mar 2017 15:37:10 GMT"}, {"version": "v3", "created": "Tue, 28 Mar 2017 03:28:28 GMT"}], "update_date": "2017-03-29", "authors_parsed": [["Chen", "Baiming", ""], ["Zhao", "Ding", ""], ["Peng", "Huei", ""]]}, {"id": "1702.02541", "submitter": "Jan Eskil Snellman Ph.D.", "authors": "Jan E. Snellman, Gerardo I\\~niguez, Tzipe Govezensky, Rafael A. Barrio\n  and Kimmo K. Kaski", "title": "Modelling community formation driven by the status of individual in a\n  society", "comments": "To be submitted to Journal of Complex Networks, 12 pages, 7 figures", "journal-ref": "J. Compl. Netw. 5, 6, 817-838 (2017)", "doi": "10.1093/comnet/cnx009", "report-no": null, "categories": "cs.MA cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In human societies, people's willingness to compete and strive for better\nsocial status as well as being envious of those perceived in some way superior\nlead to social structures that are intrinsically hierarchical. Here we propose\nan agent-based, network model to mimic the ranking behaviour of individuals and\nits possible repercussions in human society. The main ingredient of the model\nis the assumption that the relevant feature of social interactions is each\nindividual's keenness to maximise his or her status relative to others. The\nsocial networks produced by the model are homophilous and assortative, as\nfrequently observed in human communities and most of the network properties\nseem quite independent of its size. However, it is seen that for small number\nof agents the resulting network consists of disjoint weakly connected\ncommunities while being highly assortative and homophilic. On the other hand\nlarger networks turn out to be more cohesive with larger communities but less\nhomophilic. We find that the reason for these changes is that larger network\nsize allows agents to use new strategies for maximizing their social status\nallowing for more diverse links between them.\n", "versions": [{"version": "v1", "created": "Wed, 8 Feb 2017 17:49:31 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Snellman", "Jan E.", ""], ["I\u00f1iguez", "Gerardo", ""], ["Govezensky", "Tzipe", ""], ["Barrio", "Rafael A.", ""], ["Kaski", "Kimmo K.", ""]]}, {"id": "1702.02597", "submitter": "Stephen Kruzick", "authors": "Stephen Kruzick, S\\'ergio Pequito, Soummya Kar, Jos\\'e M. F. Moura,\n  and A. Pedro Aguiar", "title": "Structurally Observable Distributed Networks of Agents under Cost and\n  Robustness Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many problems, agents cooperate locally so that a leader or fusion center\ncan infer the state of every agent from probing the state of only a small\nnumber of agents. Versions of this problem arise when a fusion center\nreconstructs an extended physical field by accessing the state of just a few of\nthe sensors measuring the field, or a leader monitors the formation of a team\nof robots. Given a link cost, the paper presents a polynomial time algorithm to\ndesign a minimum cost coordinated network dynamics followed by the agents,\nunder an observability constraint. The problem is placed in the context of\nstructural observability and solved even when up to k agents in the coordinated\nnetwork dynamics fail.\n", "versions": [{"version": "v1", "created": "Wed, 8 Feb 2017 19:50:39 GMT"}], "update_date": "2017-02-10", "authors_parsed": [["Kruzick", "Stephen", ""], ["Pequito", "S\u00e9rgio", ""], ["Kar", "Soummya", ""], ["Moura", "Jos\u00e9 M. F.", ""], ["Aguiar", "A. Pedro", ""]]}, {"id": "1702.03037", "submitter": "Marc Lanctot", "authors": "Joel Z. Leibo, Vinicius Zambaldi, Marc Lanctot, Janusz Marecki, Thore\n  Graepel", "title": "Multi-agent Reinforcement Learning in Sequential Social Dilemmas", "comments": "10 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix games like Prisoner's Dilemma have guided research on social dilemmas\nfor decades. However, they necessarily treat the choice to cooperate or defect\nas an atomic action. In real-world social dilemmas these choices are temporally\nextended. Cooperativeness is a property that applies to policies, not\nelementary actions. We introduce sequential social dilemmas that share the\nmixed incentive structure of matrix game social dilemmas but also require\nagents to learn policies that implement their strategic intentions. We analyze\nthe dynamics of policies learned by multiple self-interested independent\nlearning agents, each using its own deep Q-network, on two Markov games we\nintroduce here: 1. a fruit Gathering game and 2. a Wolfpack hunting game. We\ncharacterize how learned behavior in each domain changes as a function of\nenvironmental factors including resource abundance. Our experiments show how\nconflict can emerge from competition over shared resources and shed light on\nhow the sequential nature of real world social dilemmas affects cooperation.\n", "versions": [{"version": "v1", "created": "Fri, 10 Feb 2017 01:48:40 GMT"}], "update_date": "2017-02-13", "authors_parsed": [["Leibo", "Joel Z.", ""], ["Zambaldi", "Vinicius", ""], ["Lanctot", "Marc", ""], ["Marecki", "Janusz", ""], ["Graepel", "Thore", ""]]}, {"id": "1702.03226", "submitter": "Bernardo Furtado", "authors": "Bernardo Alves Furtado and Isaque Daniel Eberhardt Rocha", "title": "An applied spatial agent-based model of administrative boundaries using\n  SEAL", "comments": "11 pages. 4 figures. Accepted ABMUS 2017 as part of AAMAS 2017, S\\~ao\n  Paulo, Brazil", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper extends and adapts an existing abstract model into an empirical\nmetropolitan region in Brazil. The model - named SEAL: a Spatial Economic\nAgent-based Lab - comprehends a framework to enable public policy ex-ante\nanalysis. The aim of the model is to use official data and municipalities\nspatial boundaries to allow for policy experimentation. The current version\nconsiders three markets: housing, labor and goods. Families' members age,\nconsume, join the labor market and trade houses. A single consumption tax is\ncollected by municipalities that invest back into quality of life improvements.\nWe test whether a single metropolitan government - which is an aggregation of\nmunicipalities - would be in the best interest of its citizens. Preliminary\nresults for 20 simulation runs indicate that it may be the case. Future\ndevelopments include improving performance to enable running of higher\npercentage of the population and a number of runs that make the model more\nrobust.\n", "versions": [{"version": "v1", "created": "Fri, 10 Feb 2017 15:53:45 GMT"}, {"version": "v2", "created": "Fri, 24 Mar 2017 11:29:52 GMT"}], "update_date": "2017-03-27", "authors_parsed": [["Furtado", "Bernardo Alves", ""], ["Rocha", "Isaque Daniel Eberhardt", ""]]}, {"id": "1702.03400", "submitter": "Daniel Jung", "authors": "Matthias Fischer, Daniel Jung, Friedhelm Meyer auf der Heide", "title": "Gathering Anonymous, Oblivious Robots on a Grid", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a swarm of $n$ autonomous mobile robots, distributed on a\n2-dimensional grid. A basic task for such a swarm is the gathering process: All\nrobots have to gather at one (not predefined) place. A common local model for\nextremely simple robots is the following: The robots do not have a common\ncompass, only have a constant viewing radius, are autonomous and\nindistinguishable, can move at most a constant distance in each step, cannot\ncommunicate, are oblivious and do not have flags or states. The only gathering\nalgorithm under this robot model, with known runtime bounds, needs\n$\\mathcal{O}(n^2)$ rounds and works in the Euclidean plane. The underlying time\nmodel for the algorithm is the fully synchronous $\\mathcal{FSYNC}$ model. On\nthe other side, in the case of the 2-dimensional grid, the only known gathering\nalgorithms for the same time and a similar local model additionally require a\nconstant memory, states and \"flags\" to communicate these states to neighbors in\nviewing range. They gather in time $\\mathcal{O}(n)$.\n  In this paper we contribute the (to the best of our knowledge) first\ngathering algorithm on the grid that works under the same simple local model as\nthe above mentioned Euclidean plane strategy, i.e., without memory (oblivious),\n\"flags\" and states. We prove its correctness and an $\\mathcal{O}(n^2)$ time\nbound in the fully synchronous $\\mathcal{FSYNC}$ time model. This time bound\nmatches the time bound of the best known algorithm for the Euclidean plane\nmentioned above. We say gathering is done if all robots are located within a\n$2\\times 2$ square, because in $\\mathcal{FSYNC}$ such configurations cannot be\nsolved.\n", "versions": [{"version": "v1", "created": "Sat, 11 Feb 2017 09:34:13 GMT"}, {"version": "v2", "created": "Wed, 22 Feb 2017 12:34:24 GMT"}, {"version": "v3", "created": "Thu, 3 Aug 2017 11:05:52 GMT"}], "update_date": "2017-08-04", "authors_parsed": [["Fischer", "Matthias", ""], ["Jung", "Daniel", ""], ["der Heide", "Friedhelm Meyer auf", ""]]}, {"id": "1702.03466", "submitter": "Siddharth Mayya", "authors": "Siddharth Mayya (1), Magnus Egerstedt (1) ((1) Georgia Institute of\n  Technology USA)", "title": "Safe Open-Loop Strategies for Handling Intermittent Communications in\n  Multi-Robot Systems", "comments": "This article is a longer and more detailed version of a publication\n  which will be presented at the International Conference on Robotics and\n  Automation (ICRA) 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multi-robot systems where a central decision maker is specifying the\nmovement of each individual robot, a communication failure can severely impair\nthe performance of the system. This paper develops a motion strategy that\nallows robots to safely handle critical communication failures for such\nmulti-robot architectures. For each robot, the proposed algorithm computes a\ntime horizon over which collisions with other robots are guaranteed not to\noccur. These safe time horizons are included in the commands being transmitted\nto the individual robots. In the event of a communication failure, the robots\nexecute the last received velocity commands for the corresponding safe time\nhorizons leading to a provably safe open-loop motion strategy. The resulting\nalgorithm is computationally effective and is agnostic to the task that the\nrobots are performing. The efficacy of the strategy is verified in simulation\nas well as on a team of differential-drive mobile robots.\n", "versions": [{"version": "v1", "created": "Sat, 11 Feb 2017 22:56:22 GMT"}], "update_date": "2017-02-14", "authors_parsed": [["Mayya", "Siddharth", ""], ["Egerstedt", "Magnus", ""]]}, {"id": "1702.03488", "submitter": "Karan Goel", "authors": "Karan Goel, Shreya Rajpal and Mausam", "title": "Octopus: A Framework for Cost-Quality-Time Optimization in Crowdsourcing", "comments": "10 pages, to appear in HCOMP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Octopus, an AI agent to jointly balance three conflicting task\nobjectives on a micro-crowdsourcing marketplace - the quality of work, total\ncost incurred, and time to completion. Previous control agents have mostly\nfocused on cost-quality, or cost-time tradeoffs, but not on directly\ncontrolling all three in concert. A naive formulation of three-objective\noptimization is intractable; Octopus takes a hierarchical POMDP approach, with\nthree different components responsible for setting the pay per task, selecting\nthe next task, and controlling task-level quality. We demonstrate that Octopus\nsignificantly outperforms existing state-of-the-art approaches on real\nexperiments. We also deploy Octopus on Amazon Mechanical Turk, showing its\nability to manage tasks in a real-world dynamic setting.\n", "versions": [{"version": "v1", "created": "Sun, 12 Feb 2017 04:53:25 GMT"}, {"version": "v2", "created": "Tue, 15 Aug 2017 09:14:08 GMT"}], "update_date": "2017-08-16", "authors_parsed": [["Goel", "Karan", ""], ["Rajpal", "Shreya", ""], ["Mausam", "", ""]]}, {"id": "1702.03614", "submitter": "Jie Chen", "authors": "Jie Chen, C\\'edric Richard, Ali H. Sayed", "title": "Multitask diffusion adaptation over networks with common latent\n  representations", "comments": "30 pages, 8 figures, IEEE Journal of Selected Topics in Signal\n  Processing 2017", "journal-ref": null, "doi": "10.1109/JSTSP.2017.2671789", "report-no": null, "categories": "cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online learning with streaming data in a distributed and collaborative manner\ncan be useful in a wide range of applications. This topic has been receiving\nconsiderable attention in recent years with emphasis on both single-task and\nmultitask scenarios. In single-task adaptation, agents cooperate to track an\nobjective of common interest, while in multitask adaptation agents track\nmultiple objectives simultaneously. Regularization is one useful technique to\npromote and exploit similarity among tasks in the latter scenario. This work\nexamines an alternative way to model relations among tasks by assuming that\nthey all share a common latent feature representation. As a result, a new\nmultitask learning formulation is presented and algorithms are developed for\nits solution in a distributed online manner. We present a unified framework to\nanalyze the mean-square-error performance of the adaptive strategies, and\nconduct simulations to illustrate the theoretical findings and potential\napplications.\n", "versions": [{"version": "v1", "created": "Mon, 13 Feb 2017 02:50:55 GMT"}], "update_date": "2017-04-26", "authors_parsed": [["Chen", "Jie", ""], ["Richard", "C\u00e9dric", ""], ["Sayed", "Ali H.", ""]]}, {"id": "1702.04138", "submitter": "Yoad Lewenberg", "authors": "Yoad Lewenberg, Omer Lev, Yoram Bachrach and Jeffrey S. Rosenschein", "title": "Agent Failures in All-Pay Auctions", "comments": null, "journal-ref": "IEEE Intelligent Systems, 2017", "doi": null, "report-no": null, "categories": "cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  All-pay auctions, a common mechanism for various human and agent\ninteractions, suffers, like many other mechanisms, from the possibility of\nplayers' failure to participate in the auction. We model such failures, and\nfully characterize equilibrium for this class of games, we present a symmetric\nequilibrium and show that under some conditions the equilibrium is unique. We\nreveal various properties of the equilibrium, such as the lack of influence of\nthe most-likely-to-participate player on the behavior of the other players. We\nperform this analysis with two scenarios: the sum-profit model, where the\nauctioneer obtains the sum of all submitted bids, and the max-profit model of\ncrowdsourcing contests, where the auctioneer can only use the best submissions\nand thus obtains only the winning bid.\n  Furthermore, we examine various methods of influencing the probability of\nparticipation such as the effects of misreporting one's own probability of\nparticipating, and how influencing another player's participation chances\nchanges the player's strategy.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2017 10:13:15 GMT"}], "update_date": "2017-02-15", "authors_parsed": [["Lewenberg", "Yoad", ""], ["Lev", "Omer", ""], ["Bachrach", "Yoram", ""], ["Rosenschein", "Jeffrey S.", ""]]}, {"id": "1702.04299", "submitter": "Marcos Cardinot", "authors": "Marcos Cardinot, Josephine Griffith, Colm O'Riordan", "title": "Cyclic Dominance in the Spatial Coevolutionary Optional Prisoner's\n  Dilemma Game", "comments": "Artificial Intelligence and Cognitive Science 2016,\n  http://ceur-ws.org/Vol-1751", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.MA math.DS physics.soc-ph", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper studies scenarios of cyclic dominance in a coevolutionary spatial\nmodel in which game strategies and links between agents adaptively evolve over\ntime. The Optional Prisoner's Dilemma (OPD) game is employed. The OPD is an\nextended version of the traditional Prisoner's Dilemma where players have a\nthird option to abstain from playing the game. We adopt an agent-based\nsimulation approach and use Monte Carlo methods to perform the OPD with\ncoevolutionary rules. The necessary conditions to break the scenarios of cyclic\ndominance are also investigated. This work highlights that cyclic dominance is\nessential in the sustenance of biodiversity. Moreover, we also discuss the\nimportance of a spatial coevolutionary model in maintaining cyclic dominance in\nadverse conditions.\n", "versions": [{"version": "v1", "created": "Thu, 9 Feb 2017 01:35:31 GMT"}], "update_date": "2017-02-15", "authors_parsed": [["Cardinot", "Marcos", ""], ["Griffith", "Josephine", ""], ["O'Riordan", "Colm", ""]]}, {"id": "1702.04700", "submitter": "Xiaoshan Bai X. Bai", "authors": "Xiaoshan Bai, Weisheng Yan, Ming Cao, Jie Huang", "title": "Target assignment for robots constrained by limited communication range", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.MA cs.RO math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the task assignment problem for multiple dispersed\nrobots constrained by limited communication range. The robots are initially\nrandomly distributed and need to visit several target locations while\nminimizing the total travel time. A centralized rendezvous-based algorithm is\nproposed, under which all the robots first move towards a rendezvous position\nuntil communication paths are established between every pair of robots either\ndirectly or through intermediate peers, and then one robot is chosen as the\nleader to make a centralized task assignment for the other robots. Furthermore,\nwe propose a decentralized algorithm based on a single-traveling-salesman tour,\nwhich does not require all the robots to be connected through communication. We\ninvestigate the variation of the quality of the assignment solutions as the\nlevel of information sharing increases and as the communication range grows,\nrespectively. The proposed algorithms are compared with a centralized algorithm\nwith shared global information and a decentralized greedy algorithm\nrespectively. Monte Carlo simulation results show the satisfying performance of\nthe proposed algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 15 Feb 2017 18:09:18 GMT"}], "update_date": "2017-02-16", "authors_parsed": [["Bai", "Xiaoshan", ""], ["Yan", "Weisheng", ""], ["Cao", "Ming", ""], ["Huang", "Jie", ""]]}, {"id": "1702.05355", "submitter": "Hamidou Tembine", "authors": "Giulia Rossi and Alain Tcheukam and Hamidou Tembine", "title": "How Much Does Users' Psychology Matter in Engineering Mean-Field-Type\n  Games", "comments": "44 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Until now mean-field-type game theory was not focused on\ncognitively-plausible models of choices in humans, animals, machines, robots,\nsoftware-defined and mobile devices strategic interactions. This work presents\nsome effects of users' psychology in mean-field-type games. In addition to the\ntraditional \"material\" payoff modelling, psychological patterns are introduced\nin order to better capture and understand behaviors that are observed in\nengineering practice or in experimental settings. The psychological payoff\nvalue depends upon choices, mean-field states, mean-field actions, empathy and\nbeliefs. It is shown that the affective empathy enforces mean-field equilibrium\npayoff equity and improves fairness between the players. It establishes\nequilibrium systems for such interactive decision-making problems. Basic\nempathy concepts are illustrated in several important problems in engineering\nincluding resource sharing, packet collision minimization, energy markets, and\nforwarding in Device-to-Device communications. The work conducts also an\nexperiment with 47 people who have to decide whether to cooperate or not. The\nbasic Interpersonal Reactivity Index of empathy metrics were used to measure\nthe empathy distribution of each participant. Android app called Empathizer is\ndeveloped to analyze systematically the data obtained from the participants.\nThe experimental results reveal that the dominated strategies of the classical\ngame theory are not dominated any more when users' psychology is involved, and\na significant level of cooperation is observed among the users who are\npositively partially empathetic.\n", "versions": [{"version": "v1", "created": "Fri, 17 Feb 2017 14:29:27 GMT"}, {"version": "v2", "created": "Sat, 25 Feb 2017 09:23:38 GMT"}], "update_date": "2017-02-28", "authors_parsed": [["Rossi", "Giulia", ""], ["Tcheukam", "Alain", ""], ["Tembine", "Hamidou", ""]]}, {"id": "1702.05515", "submitter": "Hang Ma", "authors": "Hang Ma, Sven Koenig, Nora Ayanian, Liron Cohen, Wolfgang Hoenig, T.\n  K. Satish Kumar, Tansel Uras, Hong Xu, Craig Tovey, Guni Sharon", "title": "Overview: Generalizations of Multi-Agent Path Finding to Real-World\n  Scenarios", "comments": "In IJCAI-16 Workshop on Multi-Agent Path Finding", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-agent path finding (MAPF) is well-studied in artificial intelligence,\nrobotics, theoretical computer science and operations research. We discuss\nissues that arise when generalizing MAPF methods to real-world scenarios and\nfour research directions that address them. We emphasize the importance of\naddressing these issues as opposed to developing faster methods for the\nstandard formulation of the MAPF problem.\n", "versions": [{"version": "v1", "created": "Fri, 17 Feb 2017 20:39:38 GMT"}], "update_date": "2017-02-21", "authors_parsed": [["Ma", "Hang", ""], ["Koenig", "Sven", ""], ["Ayanian", "Nora", ""], ["Cohen", "Liron", ""], ["Hoenig", "Wolfgang", ""], ["Kumar", "T. K. Satish", ""], ["Uras", "Tansel", ""], ["Xu", "Hong", ""], ["Tovey", "Craig", ""], ["Sharon", "Guni", ""]]}, {"id": "1702.05739", "submitter": "Julian Garcia", "authors": "Rui Chen, Garcia Julian and Meyer Bernd", "title": "Social learning in a simple task allocation game", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the effects of social interactions in task al- location using\nEvolutionary Game Theory (EGT). We propose a simple task-allocation game and\nstudy how different learning mechanisms can give rise to specialised and non-\nspecialised colonies under different ecological conditions. By combining\nagent-based simulations and adaptive dynamics we show that social learning can\nresult in colonies of generalists or specialists, depending on ecological\nparameters. Agent-based simulations further show that learning dynamics play a\ncrucial role in task allocation. In particular, introspective individual\nlearning readily favours the emergence of specialists, while a process\nresembling task recruitment favours the emergence of generalists.\n", "versions": [{"version": "v1", "created": "Sun, 19 Feb 2017 11:06:28 GMT"}], "update_date": "2017-02-21", "authors_parsed": [["Chen", "Rui", ""], ["Julian", "Garcia", ""], ["Bernd", "Meyer", ""]]}, {"id": "1702.06219", "submitter": "Shahin Shahrampour", "authors": "Shahin Shahrampour, Ali Jadbabaie", "title": "An Online Optimization Approach for Multi-Agent Tracking of Dynamic\n  Parameters in the Presence of Adversarial Noise", "comments": "8 pages, To appear in American Control Conference 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses tracking of a moving target in a multi-agent network.\nThe target follows a linear dynamics corrupted by an adversarial noise, i.e.,\nthe noise is not generated from a statistical distribution. The location of the\ntarget at each time induces a global time-varying loss function, and the global\nloss is a sum of local losses, each of which is associated to one agent. Agents\nnoisy observations could be nonlinear. We formulate this problem as a\ndistributed online optimization where agents communicate with each other to\ntrack the minimizer of the global loss. We then propose a decentralized version\nof the Mirror Descent algorithm and provide the non-asymptotic analysis of the\nproblem. Using the notion of dynamic regret, we measure the performance of our\nalgorithm versus its offline counterpart in the centralized setting. We prove\nthat the bound on dynamic regret scales inversely in the network spectral gap,\nand it represents the adversarial noise causing deviation with respect to the\nlinear dynamics. Our result subsumes a number of results in the distributed\noptimization literature. Finally, in a numerical experiment, we verify that our\nalgorithm can be simply implemented for multi-agent tracking with nonlinear\nobservations.\n", "versions": [{"version": "v1", "created": "Tue, 21 Feb 2017 00:18:14 GMT"}], "update_date": "2017-02-22", "authors_parsed": [["Shahrampour", "Shahin", ""], ["Jadbabaie", "Ali", ""]]}, {"id": "1702.06253", "submitter": "Zhengxing Chen", "authors": "Zhengxing Chen, Yizhou Sun, Magy Seif El-nasr, Truong-Huy D. Nguyen", "title": "Player Skill Decomposition in Multiplayer Online Battle Arenas", "comments": "2016 Meaningful Play Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.HC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Successful analysis of player skills in video games has important impacts on\nthe process of enhancing player experience without undermining their continuous\nskill development. Moreover, player skill analysis becomes more intriguing in\nteam-based video games because such form of study can help discover useful\nfactors in effective team formation. In this paper, we consider the problem of\nskill decomposition in MOBA (MultiPlayer Online Battle Arena) games, with the\ngoal to understand what player skill factors are essential for the outcome of a\ngame match. To understand the construct of MOBA player skills, we utilize\nvarious skill-based predictive models to decompose player skills into\ninterpretative parts, the impact of which are assessed in statistical terms. We\napply this analysis approach on two widely known MOBAs, namely League of\nLegends (LoL) and Defense of the Ancients 2 (DOTA2). The finding is that base\nskills of in-game avatars, base skills of players, and players'\nchampion-specific skills are three prominent skill components influencing LoL's\nmatch outcomes, while those of DOTA2 are mainly impacted by in-game avatars'\nbase skills but not much by the other two.\n", "versions": [{"version": "v1", "created": "Tue, 21 Feb 2017 03:41:49 GMT"}], "update_date": "2018-06-27", "authors_parsed": [["Chen", "Zhengxing", ""], ["Sun", "Yizhou", ""], ["El-nasr", "Magy Seif", ""], ["Nguyen", "Truong-Huy D.", ""]]}, {"id": "1702.07544", "submitter": "Lenz Belzner", "authors": "Lenz Belzner and Thomas Gabor", "title": "Scalable Multiagent Coordination with Distributed Online Open Loop\n  Planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose distributed online open loop planning (DOOLP), a general framework\nfor online multiagent coordination and decision making under uncertainty. DOOLP\nis based on online heuristic search in the space defined by a generative model\nof the domain dynamics, which is exploited by agents to simulate and evaluate\nthe consequences of their potential choices.\n  We also propose distributed online Thompson sampling (DOTS) as an effective\ninstantiation of the DOOLP framework. DOTS models sequences of agent choices by\nconcatenating a number of multiarmed bandits for each agent and uses Thompson\nsampling for dealing with action value uncertainty. The Bayesian approach\nunderlying Thompson sampling allows to effectively model and estimate\nuncertainty about (a) own action values and (b) other agents' behavior. This\napproach yields a principled and statistically sound solution to the\nexploration-exploitation dilemma when exploring large search spaces with\nlimited resources.\n  We implemented DOTS in a smart factory case study with positive empirical\nresults. We observed effective, robust and scalable planning and coordination\ncapabilities even when only searching a fraction of the potential search space.\n", "versions": [{"version": "v1", "created": "Fri, 24 Feb 2017 11:39:00 GMT"}], "update_date": "2017-03-02", "authors_parsed": [["Belzner", "Lenz", ""], ["Gabor", "Thomas", ""]]}, {"id": "1702.07934", "submitter": "Ugo Rosolia", "authors": "Ugo Rosolia, Francesco Braghin, Andrew G. Alleyne, Stijn De Bruyne and\n  Edoardo Sabbioni", "title": "A decentralized algorithm for control of autonomous agents coupled by\n  feasibility constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper a decentralized control algorithm for systems composed of $N$\ndynamically decoupled agents, coupled by feasibility constraints, is presented.\nThe control problem is divided into $N$ optimal control sub-problems and a\ncommunication scheme is proposed to decouple computations. The derivative of\nthe solution of each sub-problem is used to approximate the evolution of the\nsystem allowing the algorithm to decentralize and parallelize computations. The\neffectiveness of the proposed algorithm is shown through simulations in a\ncooperative driving scenario.\n", "versions": [{"version": "v1", "created": "Sat, 25 Feb 2017 18:10:37 GMT"}], "update_date": "2017-02-28", "authors_parsed": [["Rosolia", "Ugo", ""], ["Braghin", "Francesco", ""], ["Alleyne", "Andrew G.", ""], ["De Bruyne", "Stijn", ""], ["Sabbioni", "Edoardo", ""]]}, {"id": "1702.07984", "submitter": "Nikhil Garg", "authors": "Nikhil Garg, Vijay Kamble, Ashish Goel, David Marn, Kamesh Munagala", "title": "Iterative Local Voting for Collective Decision-making in Continuous\n  Spaces", "comments": "39 pages, to appear in Journal of Artificial Intelligence Research", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.CY cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many societal decision problems lie in high-dimensional continuous spaces not\namenable to the voting techniques common for their discrete or\nsingle-dimensional counterparts. These problems are typically discretized\nbefore running an election or decided upon through negotiation by\nrepresentatives. We propose a algorithm called {\\sc Iterative Local Voting} for\ncollective decision-making in this setting. In this algorithm, voters are\nsequentially sampled and asked to modify a candidate solution within some local\nneighborhood of its current value, as defined by a ball in some chosen norm,\nwith the size of the ball shrinking at a specified rate.\n  We first prove the convergence of this algorithm under appropriate choices of\nneighborhoods to Pareto optimal solutions with desirable fairness properties in\ncertain natural settings: when the voters' utilities can be expressed in terms\nof some form of distance from their ideal solution, and when these utilities\nare additively decomposable across dimensions. In many of these cases, we\nobtain convergence to the societal welfare maximizing solution.\n  We then describe an experiment in which we test our algorithm for the\ndecision of the U.S. Federal Budget on Mechanical Turk with over 2,000 workers,\nemploying neighborhoods defined by $\\mathcal{L}^1, \\mathcal{L}^2$ and\n$\\mathcal{L}^\\infty$ balls. We make several observations that inform future\nimplementations of such a procedure.\n", "versions": [{"version": "v1", "created": "Sun, 26 Feb 2017 03:24:31 GMT"}, {"version": "v2", "created": "Wed, 28 Jun 2017 02:22:49 GMT"}, {"version": "v3", "created": "Sun, 28 Oct 2018 03:19:07 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Garg", "Nikhil", ""], ["Kamble", "Vijay", ""], ["Goel", "Ashish", ""], ["Marn", "David", ""], ["Munagala", "Kamesh", ""]]}, {"id": "1702.08529", "submitter": "Andrew Voronkov Dr.", "authors": "S. Ponomarev, A. E. Voronkov", "title": "Multi-agent systems and decentralized artificial superintelligence", "comments": "18 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-agents systems communication is a technology, which provides a way for\nmultiple interacting intelligent agents to communicate with each other and with\nenvironment. Multiple-agent systems are used to solve problems that are\ndifficult for solving by individual agent. Multiple-agent communication\ntechnologies can be used for management and organization of computing fog and\nact as a global, distributed operating system. In present publication we\nsuggest technology, which combines decentralized P2P BOINC general-purpose\ncomputing tasks distribution, multiple-agents communication protocol and\nsmart-contract based rewards, powered by Ethereum blockchain. Such system can\nbe used as distributed P2P computing power market, protected from any central\nauthority. Such decentralized market can further be updated to system, which\nlearns the most efficient way for software-hardware combinations usage and\noptimization. Once system learns to optimize software-hardware efficiency it\ncan be updated to general-purpose distributed intelligence, which acts as\ncombination of single-purpose AI.\n", "versions": [{"version": "v1", "created": "Mon, 27 Feb 2017 21:03:26 GMT"}], "update_date": "2017-03-01", "authors_parsed": [["Ponomarev", "S.", ""], ["Voronkov", "A. E.", ""]]}, {"id": "1702.08736", "submitter": "Roxana R\\u{a}dulescu", "authors": "Roxana R\\u{a}dulescu, Peter Vrancx and Ann Now\\'e", "title": "Analysing Congestion Problems in Multi-agent Reinforcement Learning", "comments": "Adaptive Learning Agents (ALA) Workshop at AAMAS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Congestion problems are omnipresent in today's complex networks and represent\na challenge in many research domains. In the context of Multi-agent\nReinforcement Learning (MARL), approaches like difference rewards and resource\nabstraction have shown promising results in tackling such problems. Resource\nabstraction was shown to be an ideal candidate for solving large-scale resource\nallocation problems in a fully decentralized manner. However, its performance\nand applicability strongly depends on some, until now, undocumented\nassumptions. Two of the main congestion benchmark problems considered in the\nliterature are: the Beach Problem Domain and the Traffic Lane Domain. In both\nsettings the highest system utility is achieved when overcrowding one resource\nand keeping the rest at optimum capacity. We analyse how abstract grouping can\npromote this behaviour and how feasible it is to apply this approach in a\nreal-world domain (i.e., what assumptions need to be satisfied and what\nknowledge is necessary). We introduce a new test problem, the Road Network\nDomain (RND), where the resources are no longer independent, but rather part of\na network (e.g., road network), thus choosing one path will also impact the\nload on other paths having common road segments. We demonstrate the application\nof state-of-the-art MARL methods for this new congestion model and analyse\ntheir performance. RND allows us to highlight an important limitation of\nresource abstraction and show that the difference rewards approach manages to\nbetter capture and inform the agents about the dynamics of the environment.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2017 10:49:36 GMT"}, {"version": "v2", "created": "Thu, 30 Mar 2017 12:10:35 GMT"}], "update_date": "2017-03-31", "authors_parsed": [["R\u0103dulescu", "Roxana", ""], ["Vrancx", "Peter", ""], ["Now\u00e9", "Ann", ""]]}, {"id": "1702.08862", "submitter": "Palash Dey", "authors": "Palash Dey, Nimrod Talmon, and Otniel van Handel", "title": "Proportional Representation in Vote Streams", "comments": "Accepted as a full paper in AAMAS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.CC cs.DS cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider elections where the voters come one at a time, in a streaming\nfashion, and devise space-efficient algorithms which identify an approximate\nwinning committee with respect to common multiwinner proportional\nrepresentation voting rules; specifically, we consider the Approval-based and\nthe Borda-based variants of both the Chamberlin-- ourant rule and the Monroe\nrule. We complement our algorithms with lower bounds. Somewhat surprisingly,\nour results imply that, using space which does not depend on the number of\nvoters it is possible to efficiently identify an approximate representative\ncommittee of fixed size over vote streams with huge number of voters.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2017 16:57:49 GMT"}], "update_date": "2017-03-01", "authors_parsed": [["Dey", "Palash", ""], ["Talmon", "Nimrod", ""], ["van Handel", "Otniel", ""]]}, {"id": "1702.08887", "submitter": "Nantas Nardelli", "authors": "Jakob Foerster, Nantas Nardelli, Gregory Farquhar, Triantafyllos\n  Afouras, Philip H. S. Torr, Pushmeet Kohli, Shimon Whiteson", "title": "Stabilising Experience Replay for Deep Multi-Agent Reinforcement\n  Learning", "comments": "Camera-ready version, International Conference of Machine Learning\n  2017; updated to fix print-breaking image", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world problems, such as network packet routing and urban traffic\ncontrol, are naturally modeled as multi-agent reinforcement learning (RL)\nproblems. However, existing multi-agent RL methods typically scale poorly in\nthe problem size. Therefore, a key challenge is to translate the success of\ndeep learning on single-agent RL to the multi-agent setting. A major stumbling\nblock is that independent Q-learning, the most popular multi-agent RL method,\nintroduces nonstationarity that makes it incompatible with the experience\nreplay memory on which deep Q-learning relies. This paper proposes two methods\nthat address this problem: 1) using a multi-agent variant of importance\nsampling to naturally decay obsolete data and 2) conditioning each agent's\nvalue function on a fingerprint that disambiguates the age of the data sampled\nfrom the replay memory. Results on a challenging decentralised variant of\nStarCraft unit micromanagement confirm that these methods enable the successful\ncombination of experience replay with multi-agent RL.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2017 17:56:41 GMT"}, {"version": "v2", "created": "Mon, 12 Jun 2017 22:00:56 GMT"}, {"version": "v3", "created": "Mon, 21 May 2018 08:24:02 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Foerster", "Jakob", ""], ["Nardelli", "Nantas", ""], ["Farquhar", "Gregory", ""], ["Afouras", "Triantafyllos", ""], ["Torr", "Philip H. S.", ""], ["Kohli", "Pushmeet", ""], ["Whiteson", "Shimon", ""]]}]