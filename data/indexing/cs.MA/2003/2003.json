[{"id": "2003.00433", "submitter": "Xingyu Sha", "authors": "Xingyu Sha, Jiaqi Zhang, Keyou You, Kaiqing Zhang and Tamer Ba\\c{s}ar", "title": "Fully Asynchronous Policy Evaluation in Distributed Reinforcement\n  Learning over Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a \\emph{fully asynchronous} scheme for the policy\nevaluation problem of distributed reinforcement learning (DisRL) over directed\npeer-to-peer networks. Without waiting for any other node of the network, each\nnode can locally update its value function at any time by using (possibly\ndelayed) information from its neighbors. This is in sharp contrast to the\ngossip-based scheme where a pair of nodes concurrently update. Though the fully\nasynchronous setting involves a difficult multi-timescale decision problem, we\ndesign a novel stochastic average gradient (SAG) based distributed algorithm\nand develop a push-pull augmented graph approach to prove its exact convergence\nat a linear rate of $\\mathcal{O}(c^k)$ where $c\\in(0,1)$ and $k$ increases by\none no matter on which node updates. Finally, numerical experiments validate\nthat our method speeds up linearly with respect to the number of nodes, and is\nrobust to straggler nodes.\n", "versions": [{"version": "v1", "created": "Sun, 1 Mar 2020 08:12:08 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 12:50:02 GMT"}, {"version": "v3", "created": "Fri, 22 Jan 2021 16:45:28 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Sha", "Xingyu", ""], ["Zhang", "Jiaqi", ""], ["You", "Keyou", ""], ["Zhang", "Kaiqing", ""], ["Ba\u015far", "Tamer", ""]]}, {"id": "2003.00799", "submitter": "Edward Hughes", "authors": "Edward Hughes, Thomas W. Anthony, Tom Eccles, Joel Z. Leibo, David\n  Balduzzi, Yoram Bachrach", "title": "Learning to Resolve Alliance Dilemmas in Many-Player Zero-Sum Games", "comments": "Accepted for publication at AAMAS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Zero-sum games have long guided artificial intelligence research, since they\npossess both a rich strategy space of best-responses and a clear evaluation\nmetric. What's more, competition is a vital mechanism in many real-world\nmulti-agent systems capable of generating intelligent innovations: Darwinian\nevolution, the market economy and the AlphaZero algorithm, to name a few. In\ntwo-player zero-sum games, the challenge is usually viewed as finding Nash\nequilibrium strategies, safeguarding against exploitation regardless of the\nopponent. While this captures the intricacies of chess or Go, it avoids the\nnotion of cooperation with co-players, a hallmark of the major transitions\nleading from unicellular organisms to human civilization. Beyond two players,\nalliance formation often confers an advantage; however this requires trust,\nnamely the promise of mutual cooperation in the face of incentives to defect.\nSuccessful play therefore requires adaptation to co-players rather than the\npursuit of non-exploitability. Here we argue that a systematic study of\nmany-player zero-sum games is a crucial element of artificial intelligence\nresearch. Using symmetric zero-sum matrix games, we demonstrate formally that\nalliance formation may be seen as a social dilemma, and empirically that\nna\\\"ive multi-agent reinforcement learning therefore fails to form alliances.\nWe introduce a toy model of economic competition, and show how reinforcement\nlearning may be augmented with a peer-to-peer contract mechanism to discover\nand enforce alliances. Finally, we generalize our agent model to incorporate\ntemporally-extended contracts, presenting opportunities for further work.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 10:32:31 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Hughes", "Edward", ""], ["Anthony", "Thomas W.", ""], ["Eccles", "Tom", ""], ["Leibo", "Joel Z.", ""], ["Balduzzi", "David", ""], ["Bachrach", "Yoram", ""]]}, {"id": "2003.01040", "submitter": "Chuangchuang Sun", "authors": "Chuangchuang Sun, Macheng Shen, and Jonathan P. How", "title": "Scaling Up Multiagent Reinforcement Learning for Robotic Systems: Learn\n  an Adaptive Sparse Communication Graph", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The complexity of multiagent reinforcement learning (MARL) in multiagent\nsystems increases exponentially with respect to the agent number. This\nscalability issue prevents MARL from being applied in large-scale multiagent\nsystems. However, one critical feature in MARL that is often neglected is that\nthe interactions between agents are quite sparse. Without exploiting this\nsparsity structure, existing works aggregate information from all of the agents\nand thus have a high sample complexity. To address this issue, we propose an\nadaptive sparse attention mechanism by generalizing a sparsity-inducing\nactivation function. Then a sparse communication graph in MARL is learned by\ngraph neural networks based on this new attention mechanism. Through this\nsparsity structure, the agents can communicate in an effective as well as\nefficient way via only selectively attending to agents that matter the most and\nthus the scale of the MARL problem is reduced with little optimality\ncompromised. Comparative results show that our algorithm can learn an\ninterpretable sparse structure and outperforms previous works by a significant\nmargin on applications involving a large-scale multiagent system.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 17:18:25 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 21:53:06 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Sun", "Chuangchuang", ""], ["Shen", "Macheng", ""], ["How", "Jonathan P.", ""]]}, {"id": "2003.01848", "submitter": "Paul Pu Liang", "authors": "Paul Pu Liang, Jeffrey Chen, Ruslan Salakhutdinov, Louis-Philippe\n  Morency, Satwik Kottur", "title": "On Emergent Communication in Competitive Multi-Agent Teams", "comments": "AAMAS 2020, code:\n  https://github.com/pliang279/Competitive-Emergent-Communication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several recent works have found the emergence of grounded compositional\nlanguage in the communication protocols developed by mostly cooperative\nmulti-agent systems when learned end-to-end to maximize performance on a\ndownstream task. However, human populations learn to solve complex tasks\ninvolving communicative behaviors not only in fully cooperative settings but\nalso in scenarios where competition acts as an additional external pressure for\nimprovement. In this work, we investigate whether competition for performance\nfrom an external, similar agent team could act as a social influence that\nencourages multi-agent populations to develop better communication protocols\nfor improved performance, compositionality, and convergence speed. We start\nfrom Task & Talk, a previously proposed referential game between two\ncooperative agents as our testbed and extend it into Task, Talk & Compete, a\ngame involving two competitive teams each consisting of two aforementioned\ncooperative agents. Using this new setting, we provide an empirical study\ndemonstrating the impact of competitive influence on multi-agent teams. Our\nresults show that an external competitive influence leads to improved accuracy\nand generalization, as well as faster emergence of communicative languages that\nare more informative and compositional.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 01:14:27 GMT"}, {"version": "v2", "created": "Thu, 16 Jul 2020 04:15:59 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Liang", "Paul Pu", ""], ["Chen", "Jeffrey", ""], ["Salakhutdinov", "Ruslan", ""], ["Morency", "Louis-Philippe", ""], ["Kottur", "Satwik", ""]]}, {"id": "2003.01851", "submitter": "Parker Lusk", "authors": "Parker C. Lusk, Xiaoyi Cai, Samir Wadhwania, Aleix Paris, Kaveh\n  Fathian, Jonathan P. How", "title": "A Distributed Pipeline for Scalable, Deconflicted Formation Flying", "comments": "8 main pages, 1 additional page, accepted to RA-L and IROS'20", "journal-ref": null, "doi": "10.1109/LRA.2020.3006823", "report-no": null, "categories": "cs.RO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reliance on external localization infrastructure and centralized coordination\nare main limiting factors for formation flying of vehicles in large numbers and\nin unprepared environments. While solutions using onboard localization address\nthe dependency on external infrastructure, the associated coordination\nstrategies typically lack collision avoidance and scalability. To address these\nshortcomings, we present a unified pipeline with onboard localization and a\ndistributed, collision-free motion planning strategy that scales to a large\nnumber of vehicles. Since distributed collision avoidance strategies are known\nto result in gridlock, we also present a decentralized task assignment solution\nto deconflict vehicles. We experimentally validate our pipeline in simulation\nand hardware. The results show that our approach for solving the optimization\nproblem associated with motion planning gives solutions within seconds in cases\nwhere general purpose solvers fail due to high complexity. In addition, our\nlightweight assignment strategy leads to successful and quicker formation\nconvergence in 96-100% of all trials, whereas indefinite gridlocks occur\nwithout it for 33-50% of trials. By enabling large-scale, deconflicted\ncoordination, this pipeline should help pave the way for anytime, anywhere\ndeployment of aerial swarms.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 01:36:02 GMT"}, {"version": "v2", "created": "Fri, 3 Jul 2020 15:57:43 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Lusk", "Parker C.", ""], ["Cai", "Xiaoyi", ""], ["Wadhwania", "Samir", ""], ["Paris", "Aleix", ""], ["Fathian", "Kaveh", ""], ["How", "Jonathan P.", ""]]}, {"id": "2003.01891", "submitter": "Pingping Zhu", "authors": "Pingping Zhu, Chang Liu, Silvia Ferrari", "title": "Adaptive Online Distributed Optimal Control of Very-Large-Scale Robotic\n  Systems", "comments": "Control law $\\mathcal{C}_k$ is re-defined for the proof of Theorem 1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an adaptive online distributed optimal control approach\nthat is applicable to optimal planning for very-large-scale robotics systems in\nhighly uncertain environments. This approach is developed based on the optimal\nmass transport theory. It is also viewed as an online reinforcement learning\nand approximate dynamic programming approach in the Wasserstein-GMM space,\nwhere a novel value functional is defined based on the probability density\nfunctions of robots and the time-varying obstacle map functions describing the\nchanging environmental information. The proposed approach is demonstrated on\nthe path planning problem of very-largescale robotic systems where the\napproximated layout of obstacles in the workspace is incrementally updated by\nthe observations of robots, and compared with some existing state-of-the-art\napproaches. The numerical simulation results show that the proposed approach\noutperforms these approaches in aspects of the average traveling distance and\nthe energy cost.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 04:49:11 GMT"}, {"version": "v2", "created": "Sun, 15 Mar 2020 21:48:50 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Zhu", "Pingping", ""], ["Liu", "Chang", ""], ["Ferrari", "Silvia", ""]]}, {"id": "2003.01948", "submitter": "Virginia Bordignon", "authors": "Virginia Bordignon, Vincenzo Matta, Ali H. Sayed", "title": "Adaptation in Online Social Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work studies social learning under non-stationary conditions. Although\ndesigned for online inference, classic social learning algorithms perform\npoorly under drifting conditions. To mitigate this drawback, we propose the\nAdaptive Social Learning (ASL) strategy. This strategy leverages an adaptive\nBayesian update, where the adaptation degree can be modulated by tuning a\nsuitable step-size parameter. The learning performance of the ASL algorithm is\nexamined by means of a steady-state analysis. It is shown that, under the\nregime of small step-sizes: i) consistent learning is possible; ii) an accurate\nprediction of the performance can be furnished in terms of a Gaussian\napproximation.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 08:43:31 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Bordignon", "Virginia", ""], ["Matta", "Vincenzo", ""], ["Sayed", "Ali H.", ""]]}, {"id": "2003.02054", "submitter": "Alaa Daoud", "authors": "Alaa Daoud", "title": "Semantic Web Environments for Multi-Agent Systems: Enabling agents to\n  use Web of Things via semantic web", "comments": "Internship report submitted for the degree of master in computer\n  science <<Cyber-Physical-Social Systems (CPS2)>> - Universit\\'e Jean Monnet -\n  Saint \\'Etienne - August 2018", "journal-ref": null, "doi": "10.13140/RG.2.2.32666.39362", "report-no": "CPS2-2018", "categories": "cs.SE cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Web is ubiquitous, increasingly populated with interconnected data,\nservices, people, and objects. Semantic web technologies (SWT) promote\nuniformity of data formats, as well as modularization and reuse of\nspecifications (e.g., ontologies), by allowing them to include and refer to\ninformation provided by other ontologies. In such a context, multi-agent system\n(MAS) technologies are the right abstraction for developing decentralized and\nopen Web applications in which agents discover, reason and act on Web resources\nand cooperate with each other and with people. The aim of the project is to\npropose an approach to transform \"Agent and artifact (A&A) meta-model\" into a\nWeb-readable format with ontologies in line with semantic web formats and to\nreuse already existing ontologies in order to provide uniform access for agents\nto things.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 11:18:29 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Daoud", "Alaa", ""]]}, {"id": "2003.02604", "submitter": "Klemens Esterle", "authors": "Julian Bernhard, Klemens Esterle, Patrick Hart, Tobias Kessler", "title": "BARK: Open Behavior Benchmarking in Multi-Agent Environments", "comments": "Published at IEEE International Conference on Intelligent Robots and\n  Systems (IROS) 2020", "journal-ref": null, "doi": "10.1109/IROS45743.2020.9341222", "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting and planning interactive behaviors in complex traffic situations\npresents a challenging task. Especially in scenarios involving multiple traffic\nparticipants that interact densely, autonomous vehicles still struggle to\ninterpret situations and to eventually achieve their own mission goal. As\ndriving tests are costly and challenging scenarios are hard to find and\nreproduce, simulation is widely used to develop, test, and benchmark behavior\nmodels. However, most simulations rely on datasets and simplistic behavior\nmodels for traffic participants and do not cover the full variety of\nreal-world, interactive human behaviors. In this work, we introduce BARK, an\nopen-source behavior benchmarking environment designed to mitigate the\nshortcomings stated above. In BARK, behavior models are (re-)used for planning,\nprediction, and simulation. A range of models is currently available, such as\nMonte-Carlo Tree Search and Reinforcement Learning-based behavior models. We\nuse a public dataset and sampling-based scenario generation to show the\ninter-exchangeability of behavior models in BARK. We evaluate how well the\nmodels used cope with interactions and how robust they are towards exchanging\nbehavior models. Our evaluation shows that BARK provides a suitable framework\nfor a systematic development of behavior models.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 13:32:43 GMT"}, {"version": "v2", "created": "Tue, 29 Sep 2020 16:13:54 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Bernhard", "Julian", ""], ["Esterle", "Klemens", ""], ["Hart", "Patrick", ""], ["Kessler", "Tobias", ""]]}, {"id": "2003.03168", "submitter": "Patrick Hart C", "authors": "Patrick Hart, Leonard Rychly, Alois Knol", "title": "Lane-Merging Using Policy-based Reinforcement Learning and\n  Post-Optimization", "comments": null, "journal-ref": null, "doi": "10.1109/ITSC.2019.8917002", "report-no": null, "categories": "cs.LG cs.AI cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many current behavior generation methods struggle to handle real-world\ntraffic situations as they do not scale well with complexity. However,\nbehaviors can be learned off-line using data-driven approaches. Especially,\nreinforcement learning is promising as it implicitly learns how to behave\nutilizing collected experiences. In this work, we combine policy-based\nreinforcement learning with local optimization to foster and synthesize the\nbest of the two methodologies. The policy-based reinforcement learning\nalgorithm provides an initial solution and guiding reference for the\npost-optimization. Therefore, the optimizer only has to compute a single\nhomotopy class, e.g.\\ drive behind or in front of the other vehicle. By storing\nthe state-history during reinforcement learning, it can be used for constraint\nchecking and the optimizer can account for interactions. The post-optimization\nadditionally acts as a safety-layer and the novel method, thus, can be applied\nin safety-critical applications. We evaluate the proposed method using\nlane-change scenarios with a varying number of vehicles.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 12:57:25 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Hart", "Patrick", ""], ["Rychly", "Leonard", ""], ["Knol", "Alois", ""]]}, {"id": "2003.03281", "submitter": "Yulun Tian", "authors": "Yulun Tian, Alec Koppel, Amrit Singh Bedi, Jonathan P. How", "title": "Asynchronous and Parallel Distributed Pose Graph Optimization", "comments": "full paper with appendices", "journal-ref": null, "doi": "10.1109/LRA.2020.3010216", "report-no": null, "categories": "math.OC cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Asynchronous Stochastic Parallel Pose Graph Optimization (ASAPP),\nthe first asynchronous algorithm for distributed pose graph optimization (PGO)\nin multi-robot simultaneous localization and mapping. By enabling robots to\noptimize their local trajectory estimates without synchronization, ASAPP offers\nresiliency against communication delays and alleviates the need to wait for\nstragglers in the network. Furthermore, ASAPP can be applied on the\nrank-restricted relaxations of PGO, a crucial class of non-convex Riemannian\noptimization problems that underlies recent breakthroughs on globally optimal\nPGO. Under bounded delay, we establish the global first-order convergence of\nASAPP using a sufficiently small stepsize. The derived stepsize depends on the\nworst-case delay and inherent problem sparsity, and furthermore matches known\nresult for synchronous algorithms when there is no delay. Numerical evaluations\non simulated and real-world datasets demonstrate favorable performance compared\nto state-of-the-art synchronous approach, and show ASAPP's resilience against a\nwide range of delays in practice.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 15:33:42 GMT"}, {"version": "v2", "created": "Thu, 4 Jun 2020 03:18:13 GMT"}, {"version": "v3", "created": "Mon, 31 Aug 2020 15:32:00 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Tian", "Yulun", ""], ["Koppel", "Alec", ""], ["Bedi", "Amrit Singh", ""], ["How", "Jonathan P.", ""]]}, {"id": "2003.03433", "submitter": "Hangyu Mao", "authors": "Hangyu Mao, Zhibo Gong, and Zhen Xiao", "title": "Reward Design in Cooperative Multi-agent Reinforcement Learning for\n  Packet Routing", "comments": "cover https://openreview.net/forum?id=r15kjpHa-", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In cooperative multi-agent reinforcement learning (MARL), how to design a\nsuitable reward signal to accelerate learning and stabilize convergence is a\ncritical problem. The global reward signal assigns the same global reward to\nall agents without distinguishing their contributions, while the local reward\nsignal provides different local rewards to each agent based solely on\nindividual behavior. Both of the two reward assignment approaches have some\nshortcomings: the former might encourage lazy agents, while the latter might\nproduce selfish agents.\n  In this paper, we study reward design problem in cooperative MARL based on\npacket routing environments. Firstly, we show that the above two reward signals\nare prone to produce suboptimal policies. Then, inspired by some observations\nand considerations, we design some mixed reward signals, which are\noff-the-shelf to learn better policies. Finally, we turn the mixed reward\nsignals into the adaptive counterparts, which achieve best results in our\nexperiments. Other reward signals are also discussed in this paper. As reward\ndesign is a very fundamental problem in RL and especially in MARL, we hope that\nMARL researchers can rethink the rewards used in their systems.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 02:27:46 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Mao", "Hangyu", ""], ["Gong", "Zhibo", ""], ["Xiao", "Zhen", ""]]}, {"id": "2003.03558", "submitter": "Alan Tsang", "authors": "Edith Elkind, Neel Patel, Alan Tsang, Yair Zick", "title": "Keeping Your Friends Close: Land Allocation with Friends", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine the problem of assigning plots of land to prospective buyers who\nprefer living next to their friends. They care not only about the plot they\nreceive, but also about their neighbors. This externality results in a highly\nnon-trivial problem structure, as both friendship and land value play a role in\ndetermining agent behavior. We examine mechanisms that guarantee truthful\nreporting of both land values and friendships. We propose variants of random\nserial dictatorship (RSD) that can offer both truthfulness and welfare\nguarantees. Interestingly, our social welfare guarantees are parameterized by\nthe value of friendship: if these values are low, enforcing truthful behavior\nresults in poor welfare guarantees and imposes significant constraints on\nagents' choices; if they are high, we achieve good approximation to the optimal\nsocial welfare.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 11:28:36 GMT"}, {"version": "v2", "created": "Fri, 13 Mar 2020 10:51:53 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Elkind", "Edith", ""], ["Patel", "Neel", ""], ["Tsang", "Alan", ""], ["Zick", "Yair", ""]]}, {"id": "2003.03867", "submitter": "Wojciech Jamroga", "authors": "Wojciech Jamroga, Wojciech Penczek, and Teofil Sidoruk", "title": "Strategic Abilities of Asynchronous Agents: Semantic Side Effects and\n  How to Tame Them", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.MA", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Recently, we have proposed a framework for verification of agents' abilities\nin asynchronous multi-agent systems, together with an algorithm for automated\nreduction of models. The semantics was built on the modeling tradition of\ndistributed systems. As we show here, this can sometimes lead to\ncounterintuitive interpretation of formulas when reasoning about the outcome of\nstrategies. First, the semantics disregards finite paths, and thus yields\nunnatural evaluation of strategies with deadlocks. Secondly, the semantic\nrepresentations do not allow to capture the asymmetry between proactive agents\nand the recipients of their choices. We propose how to avoid the problems by a\nsuitable extension of the representations and change of the execution semantics\nfor asynchronous MAS. We also prove that the model reduction scheme still works\nin the modified framework.\n", "versions": [{"version": "v1", "created": "Sun, 8 Mar 2020 23:23:31 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 17:11:10 GMT"}, {"version": "v3", "created": "Fri, 12 Feb 2021 08:45:43 GMT"}, {"version": "v4", "created": "Fri, 16 Jul 2021 22:44:59 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Jamroga", "Wojciech", ""], ["Penczek", "Wojciech", ""], ["Sidoruk", "Teofil", ""]]}, {"id": "2003.03900", "submitter": "Aman Sinha", "authors": "Aman Sinha, Matthew O'Kelly, Hongrui Zheng, Rahul Mangharam, John\n  Duchi, Russ Tedrake", "title": "FormulaZero: Distributionally Robust Online Adaptation via Offline\n  Population Synthesis", "comments": "ICML 2020: https://icml.cc/virtual/2020/poster/6277", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Balancing performance and safety is crucial to deploying autonomous vehicles\nin multi-agent environments. In particular, autonomous racing is a domain that\npenalizes safe but conservative policies, highlighting the need for robust,\nadaptive strategies. Current approaches either make simplifying assumptions\nabout other agents or lack robust mechanisms for online adaptation. This work\nmakes algorithmic contributions to both challenges. First, to generate a\nrealistic, diverse set of opponents, we develop a novel method for self-play\nbased on replica-exchange Markov chain Monte Carlo. Second, we propose a\ndistributionally robust bandit optimization procedure that adaptively adjusts\nrisk aversion relative to uncertainty in beliefs about opponents' behaviors. We\nrigorously quantify the tradeoffs in performance and robustness when\napproximating these computations in real-time motion-planning, and we\ndemonstrate our methods experimentally on autonomous vehicles that achieve\nscaled speeds comparable to Formula One racecars.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 03:07:57 GMT"}, {"version": "v2", "created": "Sat, 22 Aug 2020 17:00:39 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Sinha", "Aman", ""], ["O'Kelly", "Matthew", ""], ["Zheng", "Hongrui", ""], ["Mangharam", "Rahul", ""], ["Duchi", "John", ""], ["Tedrake", "Russ", ""]]}, {"id": "2003.03917", "submitter": "Ala Shaabana", "authors": "Yuma Rao, Jacob Steeves, Ala Shaabana, Daniel Attevelt, Matthew\n  McAteer", "title": "BitTensor: A Peer-to-Peer Intelligence Market", "comments": "The network described in this project is live, source code available\n  on: https://github.com/opentensor/bittensor", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  As with other commodities, markets could help us efficiently produce machine\nintelligence. We propose a market where intelligence is priced by other\nintelligence systems peer-to-peer across the internet. Peers rank each other by\ntraining neural networks which learn the value of their neighbors. Scores\naccumulate on a digital ledger where high ranking peers are monetarily rewarded\nwith additional weight in the network. However, this form of peer-ranking is\nnot resistant to collusion, which could disrupt the accuracy of the mechanism.\nThe solution is a connectivity-based regularization which exponentially rewards\ntrusted peers, making the system resistant to collusion of up to 50 percent of\nthe network weight. The result is a collectively run intelligence market which\ncontinual produces newly trained models and pays contributors who create\ninformation theoretic value.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 04:04:18 GMT"}, {"version": "v2", "created": "Wed, 10 Mar 2021 20:36:51 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Rao", "Yuma", ""], ["Steeves", "Jacob", ""], ["Shaabana", "Ala", ""], ["Attevelt", "Daniel", ""], ["McAteer", "Matthew", ""]]}, {"id": "2003.04310", "submitter": "Filip Tolovski", "authors": "Filip Tolovski", "title": "Advancing Renewable Electricity Consumption With Reinforcement Learning", "comments": "To be presented at the Workshop on Tackling Climate Change with\n  Machine Learning at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.LG cs.MA cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the share of renewable energy sources in the present electric energy mix\nrises, their intermittence proves to be the biggest challenge to carbon free\nelectricity generation. To address this challenge, we propose an electricity\npricing agent, which sends price signals to the customers and contributes to\nshifting the customer demand to periods of high renewable energy generation. We\npropose an implementation of a pricing agent with a reinforcement learning\napproach where the environment is represented by the customers, the electricity\ngeneration utilities and the weather conditions.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 20:57:58 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Tolovski", "Filip", ""]]}, {"id": "2003.04364", "submitter": "David Grimsman", "authors": "Haoyuan Sun, David Grimsman, Jason R Marden", "title": "Distributed Submodular Maximization with Parallel Execution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.MA cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The submodular maximization problem is widely applicable in many engineering\nproblems where objectives exhibit diminishing returns. While this problem is\nknown to be NP-hard for certain subclasses of objective functions, there is a\ngreedy algorithm which guarantees approximation at least 1/2 of the optimal\nsolution. This greedy algorithm can be implemented with a set of agents, each\nmaking a decision sequentially based on the choices of all prior agents. In\nthis paper, we consider a generalization of the greedy algorithm in which\nagents can make decisions in parallel, rather than strictly in sequence. In\nparticular, we are interested in partitioning the agents, where a set of agents\nin the partition all make a decision simultaneously based on the choices of\nprior agents, so that the algorithm terminates in limited iterations. We\nprovide bounds on the performance of this parallelized version of the greedy\nalgorithm and show that dividing the agents evenly among the sets in the\npartition yields an optimal structure. We additionally show that this optimal\nstructure is still near-optimal when the objective function exhibits a certain\nmonotone property. Lastly, we show that the same performance guarantees can be\nachieved in the parallelized greedy algorithm even when agents can only observe\nthe decisions of a subset of prior agents.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 19:08:20 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 16:28:05 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Sun", "Haoyuan", ""], ["Grimsman", "David", ""], ["Marden", "Jason R", ""]]}, {"id": "2003.04690", "submitter": "Timotheus Kampik", "authors": "Timotheus Kampik and Juan Carlos Nieves", "title": "JS-son -- A Lean, Extensible JavaScript Agent Programming Library", "comments": "Accepted for the post-proceedings of EMAS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A multitude of agent-oriented software engineering frameworks exist, most of\nwhich are developed by the academic multi-agent systems community. However,\nthese frameworks often impose programming paradigms on their users that are\nchallenging to learn for engineers who are used to modern high-level\nprogramming languages such as JavaScript and Python. To show how the adoption\nof agent-oriented programming by the software engineering mainstream can be\nfacilitated, we provide a lean JavaScript library prototype for implementing\nreasoning-loop agents. The library focuses on core agent programming concepts\nand refrains from imposing further restrictions on the programming approach. To\nillustrate its usefulness, we show how the library can be applied to\nmulti-agent systems simulations on the web, deployed to cloud-hosted\nfunction-as-a-service environments, and embedded in Python-based data science\ntools.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 13:27:59 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Kampik", "Timotheus", ""], ["Nieves", "Juan Carlos", ""]]}, {"id": "2003.04728", "submitter": "Adriano Peron", "authors": "Laura Bozzelli, Aniello Murano, Adriano Peron", "title": "Module checking of pushdown multi-agent systems", "comments": "arXiv admin note: substantial text overlap with arXiv:1709.02107", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.FL cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the module-checking problem of pushdown\nmulti-agent systems (PMS) against ATL and ATL* specifications. We establish\nthat for ATL, module checking of PMS is 2EXPTIME-complete, which is the same\ncomplexity as pushdown module-checking for CTL. On the other hand, we show that\nATL* module-checking of PMS turns out to be 4EXPTIME-complete, hence\nexponentially harder than both CTL* pushdown module-checking and ATL*\nmodel-checking of PMS. Our result for ATL* provides a rare example of a natural\ndecision problem that is elementary yet but with a complexity that is higher\nthan triply exponential-time.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 13:42:10 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Bozzelli", "Laura", ""], ["Murano", "Aniello", ""], ["Peron", "Adriano", ""]]}, {"id": "2003.05550", "submitter": "Elizabeth Sklar", "authors": "Eric Schneider, Marcus Poulton, Archie Drake, Leanne Smith, George\n  Roussos, Simon Parsons and Elizabeth I Sklar", "title": "The Application of Market-based Multi-Robot Task Allocation to Ambulance\n  Dispatch", "comments": "19 pages, 5 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-Robot Task Allocation (MRTA) is the problem of distributing a set of\ntasks to a team of robots with the objective of optimising some criteria, such\nas minimising the amount of time or energy spent to complete all the tasks or\nmaximising the efficiency of the team's joint activity. The exploration of MRTA\nmethods is typically restricted to laboratory and field experimentation. There\nare few existing real-world models in which teams of autonomous mobile robots\nare deployed \"in the wild\", e.g., in industrial settings. In the work presented\nhere, a market-based MRTA approach is applied to the problem of ambulance\ndispatch, where ambulances are allocated in respond to patients' calls for\nhelp. Ambulances and robots are limited (and perhaps scarce), specialised\nmobile resources; incidents and tasks represent time-sensitive, specific,\npotentially unlimited, precisely-located demands for the services which the\nresources provide. Historical data from the London Ambulance Service describing\na set of more than 1 million (anonymised) incidents are used as the basis for\nevaluating the predicted performance of the market-based approach versus the\ncurrent, largely manual, method of allocating ambulances to incidents.\nExperimental results show statistically significant improvement in response\ntimes when using the market-based approach.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 23:01:15 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Schneider", "Eric", ""], ["Poulton", "Marcus", ""], ["Drake", "Archie", ""], ["Smith", "Leanne", ""], ["Roussos", "George", ""], ["Parsons", "Simon", ""], ["Sklar", "Elizabeth I", ""]]}, {"id": "2003.05792", "submitter": "Matthew Kirchner", "authors": "Matthew R. Kirchner, Mark J. Debord, Jo\\~ao P. Hespanha", "title": "A Hamilton-Jacobi Formulation for Optimal Coordination of Heterogeneous\n  Multiple Vehicle Systems", "comments": "Minor updates to final published version", "journal-ref": "IEEE/RSJ International Conference on Intelligent Robots and\n  Systems (IROS), pp. 11623-11630, 2020", "doi": "10.1109/IROS45743.2020.9340864", "report-no": "UCLA CAM 20-43", "categories": "cs.RO cs.MA cs.SY eess.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method for optimal coordination of multiple vehicle teams when\nmultiple endpoint configurations are equally desirable, such as seen in the\nautonomous assembly of formation flight. The individual vehicles' positions in\nthe formation are not assigned a priori and a key challenge is to find the\noptimal configuration assignment along with the optimal control and trajectory.\nCommonly, assignment and trajectory planning problems are solved separately. We\nintroduce a new multi-vehicle coordination paradigm, where the optimal goal\nassignment and optimal vehicle trajectories are found simultaneously from a\nviscosity solution of a single Hamilton-Jacobi (HJ) partial differential\nequation (PDE), which provides a necessary and sufficient condition for global\noptimality. Intrinsic in this approach is that individual vehicle dynamic\nmodels need not be the same, and therefore can be applied to heterogeneous\nsystems. Numerical methods to solve the HJ equation have historically relied on\na discrete grid of the solution space and exhibits exponential scaling with\nsystem dimension, preventing their applicability to multiple vehicle systems.\nBy utilizing a generalization of the Hopf formula, we avoid the use of grids\nand present a method that exhibits polynomial scaling in the number of\nvehicles.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 13:31:23 GMT"}, {"version": "v2", "created": "Mon, 19 Apr 2021 17:30:41 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Kirchner", "Matthew R.", ""], ["Debord", "Mark J.", ""], ["Hespanha", "Jo\u00e3o P.", ""]]}, {"id": "2003.05853", "submitter": "Shushuai Li", "authors": "Shushuai Li, Mario Coppola, Christophe De Wagter and Guido C. H. E. de\n  Croon", "title": "An autonomous swarm of micro flying robots with range-based relative\n  localization", "comments": "Submitted to TRO. Project link:\n  https://shushuai3.github.io/autonomous-swarm/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate relative localization is an important requirement for a swarm of\nrobots, especially when performing a cooperative task. This paper presents an\nautonomous multi-robot relative positioning technique. An Extended Kalman\nfilter (EKF) uses onboard sensing of velocity, yaw rate, and height as inputs,\nand then estimates the relative position of other robots by fusing these\nquantities with ranging measurements obtained from onboard ultra wide-band\n(UWB). Specifically, innovations involve fast-ranging communication (333Hz for\n2 robots), an automatic initialization procedure, proofs and demonstrations of\nconsistent estimation convergence under control commands such as formation\nflight. Simulations concisely show the high precision, efficiency, and\nstability of the proposed localization method. Real-world experiments are\nconducted on a team of 5 Crazyflie2 quadrotors, demonstrating autonomous\nformation flight and coordinated flight through a window. All results indicate\nthe effectiveness of the proposed relative positioning method for multi-robot\nsystems. Video and code can be found at\n\\textnormal{\\url{https://shushuai3.github.io/autonomous-swarm/}}\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 15:34:35 GMT"}, {"version": "v2", "created": "Sat, 5 Jun 2021 10:48:36 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Li", "Shushuai", ""], ["Coppola", "Mario", ""], ["De Wagter", "Christophe", ""], ["de Croon", "Guido C. H. E.", ""]]}, {"id": "2003.05929", "submitter": "Frank Schweitzer", "authors": "Simon Schweighofer, David Garcia, Frank Schweitzer", "title": "An agent-based model of multi-dimensional opinion dynamics and opinion\n  alignment", "comments": "34 pp", "journal-ref": null, "doi": "10.1063/5.0007523", "report-no": null, "categories": "physics.soc-ph cs.MA nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is known that individual opinions on different policy issues often align\nto a dominant ideological dimension (e.g. \"left\" vs. \"right\") and become\nincreasingly polarized. We provide an agent-based model that reproduces these\ntwo stylized facts as emergent properties of an opinion dynamics in a\nmulti-dimensional space of continuous opinions. The mechanisms for the change\nof agents' opinions in this multi-dimensional space are derived from cognitive\ndissonance theory and structural balance theory. We test assumptions from\nproximity voting and from directional voting regarding their ability to\nreproduce the expected emerging properties. We further study how the emotional\ninvolvement of agents, i.e. their individual resistance to change opinions,\nimpacts the dynamics. We identify two regimes for the global and the individual\nalignment of opinions. If the affective involvement is high and shows a large\nvariance across agents, this fosters the emergence of a dominant ideological\ndimension. Agents align their opinions along this dimension in opposite\ndirections, i.e. create a state of polarization.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 17:51:19 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Schweighofer", "Simon", ""], ["Garcia", "David", ""], ["Schweitzer", "Frank", ""]]}, {"id": "2003.06212", "submitter": "I-Chen Wu", "authors": "Ti-Rong Wu, Ting-Han Wei, I-Chen Wu", "title": "Accelerating and Improving AlphaZero Using Population Based Training", "comments": "accepted by AAAI2020 as oral presentation. In this version,\n  supplementary materials are added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  AlphaZero has been very successful in many games. Unfortunately, it still\nconsumes a huge amount of computing resources, the majority of which is spent\nin self-play. Hyperparameter tuning exacerbates the training cost since each\nhyperparameter configuration requires its own time to train one run, during\nwhich it will generate its own self-play records. As a result, multiple runs\nare usually needed for different hyperparameter configurations. This paper\nproposes using population based training (PBT) to help tune hyperparameters\ndynamically and improve strength during training time. Another significant\nadvantage is that this method requires a single run only, while incurring a\nsmall additional time cost, since the time for generating self-play records\nremains unchanged though the time for optimization is increased following the\nAlphaZero training algorithm. In our experiments for 9x9 Go, the PBT method is\nable to achieve a higher win rate for 9x9 Go than the baselines, each with its\nown hyperparameter configuration and trained individually. For 19x19 Go, with\nPBT, we are able to obtain improvements in playing strength. Specifically, the\nPBT agent can obtain up to 74% win rate against ELF OpenGo, an open-source\nstate-of-the-art AlphaZero program using a neural network of a comparable\ncapacity. This is compared to a saturated non-PBT agent, which achieves a win\nrate of 47% against ELF OpenGo under the same circumstances.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 11:56:14 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Wu", "Ti-Rong", ""], ["Wei", "Ting-Han", ""], ["Wu", "I-Chen", ""]]}, {"id": "2003.06679", "submitter": "Santosh Devasia", "authors": "Santosh Devasia", "title": "Cohesive Networks using Delayed Self Reinforcement", "comments": "Updated Simulations from Journal Version and MATLAB Code for\n  simulations are included", "journal-ref": "Automatica, Volume 112, 2020, 108699", "doi": "10.1016/j.automatica.2019.108699", "report-no": null, "categories": "eess.SY cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How a network gets to the goal (a consensus value) can be as important as\nreaching the consensus value. While prior methods focus on rapidly getting to a\nnew consensus value, maintaining cohesion, during the transition between\nconsensus values or during tracking, remains challenging and has not been\naddressed. The main contributions of this work are to address the problem of\nmaintaining cohesion by: (i) proposing a new delayed self-reinforcement (DSR)\napproach; (ii) extending it for use with agents that have higher-order,\nheterogeneous dynamics, and (iii) developing stability conditions for the\nDSR-based method. With DSR, each agent uses current and past information from\nneighbors to infer the overall goal and modifies the update law to improve\ncohesion. The advantages of the proposed DSR approach are that it only requires\nalready-available information from a given network to improve the cohesion and\ndoes not require network-connectivity modifications (which might not be always\nfeasible) nor increases in the system's overall response speed (which can\nrequire larger input). Moreover, illustrative simulation examples are used to\ncomparatively evaluate the performance with and without DSR. The simulation\nresults show substantial improvement in cohesion with DSR.\n", "versions": [{"version": "v1", "created": "Sat, 14 Mar 2020 18:09:56 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Devasia", "Santosh", ""]]}, {"id": "2003.06879", "submitter": "Zack Fitzsimmons", "authors": "Zack Fitzsimmons and Omer Lev", "title": "Selecting Voting Locations for Fun and Profit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While manipulative attacks on elections have been well-studied, only recently\nhas attention turned to attacks that account for geographic information, which\nare extremely common in the real world. The most well known in the media is\ngerrymandering, in which district border-lines are changed to increase a\nparty's chance to win, but a different geographical manipulation involves\ninfluencing the election by selecting the location of polling places, as many\npeople are not willing to go to any distance to vote. In this paper we initiate\nthe study of this manipulation. We find that while it is easy to manipulate the\nselection of polling places on the line, it becomes difficult already on the\nplane or in the case of more than two candidates. Moreover, we show that for\nmore than two candidates the problem is inapproximable. However, we find a few\nrestricted cases on the plane where some algorithms perform well. Finally, we\ndiscuss how existing results for standard control actions hold in the\ngeographic setting, consider additional control actions in the geographic\nsetting, and suggest directions for future study.\n", "versions": [{"version": "v1", "created": "Sun, 15 Mar 2020 17:49:50 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Fitzsimmons", "Zack", ""], ["Lev", "Omer", ""]]}, {"id": "2003.06906", "submitter": "Rose Wang", "authors": "Rose E. Wang, J. Chase Kew, Dennis Lee, Tsang-Wei Edward Lee, Tingnan\n  Zhang, Brian Ichter, Jie Tan, Aleksandra Faust", "title": "Model-based Reinforcement Learning for Decentralized Multiagent\n  Rendezvous", "comments": "CoRL 2020. The video is available at: https://youtu.be/-ydXHUtPzWE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Collaboration requires agents to align their goals on the fly. Underlying the\nhuman ability to align goals with other agents is their ability to predict the\nintentions of others and actively update their own plans. We propose\nhierarchical predictive planning (HPP), a model-based reinforcement learning\nmethod for decentralized multiagent rendezvous. Starting with pretrained,\nsingle-agent point to point navigation policies and using noisy,\nhigh-dimensional sensor inputs like lidar, we first learn via self-supervision\nmotion predictions of all agents on the team. Next, HPP uses the prediction\nmodels to propose and evaluate navigation subgoals for completing the\nrendezvous task without explicit communication among agents. We evaluate HPP in\na suite of unseen environments, with increasing complexity and numbers of\nobstacles. We show that HPP outperforms alternative reinforcement learning,\npath planning, and heuristic-based baselines on challenging, unseen\nenvironments. Experiments in the real world demonstrate successful transfer of\nthe prediction models from sim to real world without any additional\nfine-tuning. Altogether, HPP removes the need for a centralized operator in\nmultiagent systems by combining model-based RL and inference methods, enabling\nagents to dynamically align plans.\n", "versions": [{"version": "v1", "created": "Sun, 15 Mar 2020 19:49:20 GMT"}, {"version": "v2", "created": "Mon, 9 Nov 2020 05:34:13 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Wang", "Rose E.", ""], ["Kew", "J. Chase", ""], ["Lee", "Dennis", ""], ["Lee", "Tsang-Wei Edward", ""], ["Zhang", "Tingnan", ""], ["Ichter", "Brian", ""], ["Tan", "Jie", ""], ["Faust", "Aleksandra", ""]]}, {"id": "2003.06971", "submitter": "Deepan Muthirayan", "authors": "Deepan Muthirayan, Masood Parvania, Pramod P. Khargonekar", "title": "Online Algorithms for Dynamic Matching Markets in Power Distribution\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes online algorithms for dynamic matching markets in power\ndistribution systems, which at any real-time operation instance decides about\nmatching -- or delaying the supply of -- flexible loads with available\nrenewable generation with the objective of maximizing the social welfare of the\nexchange in the system. More specifically, two online matching algorithms are\nproposed for the following generation-load scenarios: (i) when the mean of\nrenewable generation is greater than the mean of the flexible load, and (ii)\nwhen the condition (i) is reversed. With the intuition that the performance of\nsuch algorithms degrades with increasing randomness of the supply and demand,\ntwo properties are proposed for assessing the performance of the algorithms.\nFirst property is convergence to optimality (CO) as the underlying randomness\nof renewable generation and customer loads goes to zero. The second property is\ndeviation from optimality, is measured as a function of the standard deviation\nof the underlying randomness of renewable generation and customer loads. The\nalgorithm proposed for the first scenario is shown to satisfy CO and a\ndeviation from optimal that varies linearly with the variation in the standard\ndeviation. But the same algorithm is shown to not satisfy CO for the second\nscenario. We then show that the algorithm proposed for the second scenario\nsatisfies CO and a deviation from optimal that varies linearly with the\nvariation in standard deviation plus an offset.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 02:00:20 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 23:04:44 GMT"}, {"version": "v3", "created": "Sun, 24 May 2020 19:00:29 GMT"}, {"version": "v4", "created": "Thu, 28 May 2020 02:48:05 GMT"}, {"version": "v5", "created": "Wed, 3 Jun 2020 00:21:41 GMT"}, {"version": "v6", "created": "Mon, 29 Jun 2020 23:01:05 GMT"}, {"version": "v7", "created": "Sun, 5 Jul 2020 19:14:07 GMT"}, {"version": "v8", "created": "Thu, 16 Jul 2020 04:29:07 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Muthirayan", "Deepan", ""], ["Parvania", "Masood", ""], ["Khargonekar", "Pramod P.", ""]]}, {"id": "2003.07007", "submitter": "K\\'evin Garanger", "authors": "K\\'evin Garanger, Jeremy Epps, Eric Feron", "title": "Modeling and Experimental Validation of a Fractal Tetrahedron UAS\n  Assembly", "comments": "Presented as a conference paper at the 2020 IEEE Aerospace Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.MA cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the foundation of a modular robotic system comprised of\nseveral novel modules in the shape of a tetrahedron. Four single-propeller\nsubmodules are assembled to create the Tetracopter, a tetrahedron-shaped\nquad-rotorcraft used as the elementary module of a modular flying system. This\nmodular flying system is built by assembling the different elementary modules\nin a fractal shape. The fractal tetrahedron structure of the modular flying\nassembly grants the vehicle more rigidity than a conventional two-dimensional\nmodular robotic flight system while maintaining the relative efficiency of a\ntwo-dimensional modular robotic flight system. A prototype of the Tetracopter\nhas been modeled, fabricated, and successfully flight-tested by the Decision\nand Control Laboratory at the Georgia Institute of Technology. The results of\nthis research set the foundation for the development of Tetrahedron rotorcraft\nthat can maintain controllable flight and assemble in flight to create a\nFractal Tetrahedron Assembly.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 03:49:35 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Garanger", "K\u00e9vin", ""], ["Epps", "Jeremy", ""], ["Feron", "Eric", ""]]}, {"id": "2003.07108", "submitter": "Fatih Semiz", "authors": "Fatih Semiz and Faruk Polat", "title": "A Job-Assignment Heuristic for Lifelong Multi-Agent Path Finding Problem\n  with Multiple Delivery Locations", "comments": "This paper has been withdrawn by the authors due to need for heavy\n  revise", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we proposed multiple job-assignment heuristics to generate\nlow-total-cost solutions and determine the best performing method amongst them.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 10:57:13 GMT"}, {"version": "v2", "created": "Sat, 25 Apr 2020 09:14:07 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Semiz", "Fatih", ""], ["Polat", "Faruk", ""]]}, {"id": "2003.07124", "submitter": "Fatih Semiz", "authors": "Fatih Semiz and Faruk Polat", "title": "Solving Area Coverage Problem with UAVs: A Vehicle Routing with Time\n  Windows Variation", "comments": null, "journal-ref": "Robotics and Autonomous Systems, 126, April 2020, 103435", "doi": "10.1016/j.robot.2020.103435", "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In real life, providing security for a set of large areas by covering the\narea with Unmanned Aerial Vehicles (UAVs) is a difficult problem that consist\nof multiple objectives. These difficulties are even greater if the area\ncoverage must continue throughout a specific time window. We address this by\nconsidering a Vehicle Routing Problem with Time Windows (VRPTW) variation in\nwhich capacity of agents is one and each customer (target area) must be\nsupplied with more than one vehicles simultaneously without violating time\nwindows. In this problem, our aim is to find a way to cover all areas with the\nnecessary number of UAVs during the time windows, minimize the total distance\ntraveled, and provide a fast solution by satisfying the additional constraint\nthat each agent has limited fuel. We present a novel algorithm that relies on\nclustering the target areas according to their time windows, and then\nincrementally generating transportation problems with each cluster and the\nready UAVs. Then we solve transportation problems with the simplex algorithm to\ngenerate the solution. The performance of the proposed algorithm and other\nimplemented algorithms to compare the solution quality is evaluated on example\nscenarios with practical problem sizes.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 11:27:21 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Semiz", "Fatih", ""], ["Polat", "Faruk", ""]]}, {"id": "2003.07291", "submitter": "Julio Cesar Carrasquel", "authors": "Khalil Mecheraoui, Julio C. Carrasquel, Irina A. Lomazova", "title": "Compositional Conformance Checking of Nested Petri Nets and Event Logs\n  of Multi-Agent Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a compositional conformance checking approach between\nnested Petri nets and event logs of multi-agent systems. By projecting an event\nlog onto model components, one can perform conformance checking between each\nprojected log and the corresponding component. We formally demonstrate the\nvalidity of our approach proving that, to check fitness of a nested Petri net\nis equivalent to check fitness of each of its components. Leveraging the\nmulti-agent system structure of nested Petri nets, this approach may provide\nspecific conformance diagnostics for each system component as well as to avoid\nto compute artificial boundaries when decomposing a model for conformance\nchecking.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 15:52:06 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Mecheraoui", "Khalil", ""], ["Carrasquel", "Julio C.", ""], ["Lomazova", "Irina A.", ""]]}, {"id": "2003.07310", "submitter": "Logan Beaver", "authors": "Logan E. Beaver, Andreas A. Malikopoulos", "title": "Beyond Reynolds: A Constraint-Driven Approach to Cluster Flocking", "comments": "6 pages", "journal-ref": "2020 59th IEE Conference on Decision and Control (CDC), 2020, pp\n  208-213", "doi": "10.1109/CDC42340.2020.9304333", "report-no": null, "categories": "cs.MA cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present an original set of flocking rules using an\necologically-inspired paradigm for control of multi-robot systems. We translate\nthese rules into a constraint-driven optimal control problem where the agents\nminimize energy consumption subject to safety and task constraints. We prove\nseveral properties about the feasible space of the optimal control problem and\nshow that velocity consensus is an optimal solution. We also motivate the\ninclusion of slack variables in constraint-driven problems when the global\nstate is only partially observable by each agent. Finally, we analyze the case\nwhere the communication topology is fixed and connected, and prove that our\nproposed flocking rules achieve velocity consensus.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 16:26:12 GMT"}, {"version": "v2", "created": "Wed, 6 May 2020 00:15:58 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Beaver", "Logan E.", ""], ["Malikopoulos", "Andreas A.", ""]]}, {"id": "2003.07969", "submitter": "Ankit Vora", "authors": "Siddharth Agarwal, Ankit Vora, Gaurav Pandey, Wayne Williams, Helen\n  Kourous and James McBride", "title": "Ford Multi-AV Seasonal Dataset", "comments": "7 pages, 7 figures, Submitted to International Journal of Robotics\n  Research (IJRR), Visit website at https://avdata.ford.com", "journal-ref": "IJRR, Volume: 39 issue: 12 (2020), page(s): 1367-1376", "doi": "10.1177/0278364920961451", "report-no": null, "categories": "cs.RO cs.CV cs.MA", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper presents a challenging multi-agent seasonal dataset collected by a\nfleet of Ford autonomous vehicles at different days and times during 2017-18.\nThe vehicles traversed an average route of 66 km in Michigan that included a\nmix of driving scenarios such as the Detroit Airport, freeways, city-centers,\nuniversity campus and suburban neighbourhoods, etc. Each vehicle used in this\ndata collection is a Ford Fusion outfitted with an Applanix POS-LV GNSS system,\nfour HDL-32E Velodyne 3D-lidar scanners, 6 Point Grey 1.3 MP Cameras arranged\non the rooftop for 360-degree coverage and 1 Pointgrey 5 MP camera mounted\nbehind the windshield for the forward field of view. We present the seasonal\nvariation in weather, lighting, construction and traffic conditions experienced\nin dynamic urban environments. This dataset can help design robust algorithms\nfor autonomous vehicles and multi-agent systems. Each log in the dataset is\ntime-stamped and contains raw data from all the sensors, calibration values,\npose trajectory, ground truth pose, and 3D maps. All data is available in\nRosbag format that can be visualized, modified and applied using the\nopen-source Robot Operating System (ROS). We also provide the output of\nstate-of-the-art reflectivity-based localization for bench-marking purposes.\nThe dataset can be freely downloaded at our website.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 22:33:38 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Agarwal", "Siddharth", ""], ["Vora", "Ankit", ""], ["Pandey", "Gaurav", ""], ["Williams", "Wayne", ""], ["Kourous", "Helen", ""], ["McBride", "James", ""]]}, {"id": "2003.08039", "submitter": "Tonghan Wang", "authors": "Tonghan Wang, Heng Dong, Victor Lesser, Chongjie Zhang", "title": "ROMA: Multi-Agent Reinforcement Learning with Emergent Roles", "comments": "Thirty-seventh International Conference on Machine Learning (ICML\n  2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The role concept provides a useful tool to design and understand complex\nmulti-agent systems, which allows agents with a similar role to share similar\nbehaviors. However, existing role-based methods use prior domain knowledge and\npredefine role structures and behaviors. In contrast, multi-agent reinforcement\nlearning (MARL) provides flexibility and adaptability, but less efficiency in\ncomplex tasks. In this paper, we synergize these two paradigms and propose a\nrole-oriented MARL framework (ROMA). In this framework, roles are emergent, and\nagents with similar roles tend to share their learning and to be specialized on\ncertain sub-tasks. To this end, we construct a stochastic role embedding space\nby introducing two novel regularizers and conditioning individual policies on\nroles. Experiments show that our method can learn specialized, dynamic, and\nidentifiable roles, which help our method push forward the state of the art on\nthe StarCraft II micromanagement benchmark. Demonstrative videos are available\nat https://sites.google.com/view/romarl/.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 04:29:42 GMT"}, {"version": "v2", "created": "Sun, 22 Mar 2020 05:33:42 GMT"}, {"version": "v3", "created": "Sat, 4 Jul 2020 08:37:46 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Wang", "Tonghan", ""], ["Dong", "Heng", ""], ["Lesser", "Victor", ""], ["Zhang", "Chongjie", ""]]}, {"id": "2003.08154", "submitter": "Sven Banisch", "authors": "Sven Banisch and Felix Gaisbauer and Eckehard Olbrich", "title": "How social feedback processing in the brain shapes collective opinion\n  processes in the era of social media", "comments": "Odycceus Research (www.odycceus.eu)", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.CY cs.MA cs.NE nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What are the mechanisms by which groups with certain opinions gain public\nvoice and force others holding a different view into silence? And how does\nsocial media play into this? Drawing on recent neuro-scientific insights into\nthe processing of social feedback, we develop a theoretical model that allows\nto address these questions. The model captures phenomena described by spiral of\nsilence theory of public opinion, provides a mechanism-based foundation for it,\nand allows in this way more general insight into how different group structures\nrelate to different regimes of collective opinion expression. Even strong\nmajorities can be forced into silence if a minority acts as a cohesive whole.\nThe proposed framework of social feedback theory (SFT) highlights the need for\nsociological theorising to understand the societal-level implications of\nfindings in social and cognitive neuroscience.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 11:06:34 GMT"}], "update_date": "2020-03-19", "authors_parsed": [["Banisch", "Sven", ""], ["Gaisbauer", "Felix", ""], ["Olbrich", "Eckehard", ""]]}, {"id": "2003.08158", "submitter": "Tessa van der Heiden", "authors": "Tessa van der Heiden, Florian Mirus, Herke van Hoof", "title": "Social Navigation with Human Empowerment driven Deep Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Mobile robot navigation has seen extensive research in the last decades. The\naspect of collaboration with robots and humans sharing workspaces will become\nincreasingly important in the future. Therefore, the next generation of mobile\nrobots needs to be socially-compliant to be accepted by their human\ncollaborators. However, a formal definition of compliance is not\nstraightforward. On the other hand, empowerment has been used by artificial\nagents to learn complicated and generalized actions and also has been shown to\nbe a good model for biological behaviors. In this paper, we go beyond the\napproach of classical \\acf{RL} and provide our agent with intrinsic motivation\nusing empowerment. In contrast to self-empowerment, a robot employing our\napproach strives for the empowerment of people in its environment, so they are\nnot disturbed by the robot's presence and motion. In our experiments, we show\nthat our approach has a positive influence on humans, as it minimizes its\ndistance to humans and thus decreases human travel time while moving\nefficiently towards its own goal. An interactive user-study shows that our\nmethod is considered more social than other state-of-the-art approaches by the\nparticipants.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 11:16:07 GMT"}, {"version": "v2", "created": "Sat, 21 Mar 2020 13:13:41 GMT"}, {"version": "v3", "created": "Wed, 5 Aug 2020 11:49:39 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["van der Heiden", "Tessa", ""], ["Mirus", "Florian", ""], ["van Hoof", "Herke", ""]]}, {"id": "2003.08290", "submitter": "Zijia Zhong", "authors": "Zijia Zhong, Earl E. Lee, Mark Nejad and Joyoung Lee", "title": "Influence of CAV Clustering Strategies on Mixed Traffic Flow\n  Characteristics: An Analysis of Vehicle Trajectory Data", "comments": "22 pages, 17 figures. arXiv admin note: substantial text overlap with\n  arXiv:1909.13204", "journal-ref": "Transportation Research Part C: Emerging Technologies, 115, 2020,\n  102611", "doi": "10.1016/j.trc.2020.102611", "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Being one of the most promising applications enabled by connected and\nautomated vehicles (CAV) technology, Cooperative Adaptive Cruise Control (CACC)\nis expected to be deployed in the near term on public roads.} Thus far, the\nmajority of the CACC studies have been focusing on the overall network\nperformance with limited insights on the potential impacts of CAVs on\nhuman-driven vehicles (HVs).This paper aims to quantify such impacts by\nstudying the high-resolution vehicle trajectory data that are obtained from\nmicroscopic simulation. Two platoon clustering strategies for CACC- an ad hoc\ncoordination strategy and a local coordination strategy-are implemented.\nResults show that the local coordination outperforms the ad hoc coordination\nacross all tested market penetration rates (MPRs) in terms of network\nthroughput and productivity. According to the two-sample\nKolmogorov-\\textcolor{re}{Smirnov} test, however, the distributions of the hard\nbraking events (as a potential safety impact) for HVs change significantly\nunder local coordination strategy. For both of the clustering strategy, CAVs\nincrease the average lane change frequency for HVs. The break-even point for\naverage lane change frequency between the two strategies is observed at 30%\nMPR, which decreases from 5.42 to 5.38 per vehicle. The average lane change\nfrequency following a monotonically increasing pattern in response to MPR, and\nit reaches the highest 5.48 per vehicle at 40% MPR. Lastly, the interaction\nstate of the car-following model for HVs is analyzed. It is revealed that the\ncomposition of the interaction state could be influenced by CAVs as well. One\nof the apparent trends is that the time spent on approaching state declines\nwith the increasing presence of CAVs.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 22:23:59 GMT"}, {"version": "v2", "created": "Thu, 11 Feb 2021 02:59:48 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Zhong", "Zijia", ""], ["Lee", "Earl E.", ""], ["Nejad", "Mark", ""], ["Lee", "Joyoung", ""]]}, {"id": "2003.08293", "submitter": "Andrea Tagliabue", "authors": "Ali-akbar Agha-mohammadi (1), Andrea Tagliabue (2), Stephanie\n  Schneider (3), Benjamin Morrell (1), Marco Pavone (3), Jason Hofgartner (1),\n  Issa A.D. Nesnas (1), Rashied B. Amini (1), Arash Kalantari (1), Alessandra\n  Babuscia (1), Jonathan Lunine (4) ((1) Jet Propulsion Lab., California\n  Institute of Technology and (2) Massachusetts Institute of Technology and (3)\n  Sanford University and (4) Cornell University)", "title": "The Shapeshifter: a Morphing, Multi-Agent,Multi-Modal Robotic Platform\n  for the Exploration of Titan (preprint version)", "comments": "Ali-akbar Agha-mohammadi is the Principal Investigator. arXiv admin\n  note: substantial text overlap with arXiv:2002.00515", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.MA cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this report for the Nasa NIAC Phase I study, we present a mission\narchitecture and a robotic platform, the Shapeshifter, that allow multi-domain\nand redundant mobility on Saturn's moon Titan, and potentially other bodies\nwith atmospheres. The Shapeshifter is a collection of simple and affordable\nrobotic units, called Cobots, comparable to personal palm-size quadcopters. By\nattaching and detaching with each other, multiple Cobots can shape-shift into\nnovel structures, capable of (a) rolling on the surface, to increase the\ntraverse range, (b) flying in a flight array formation, and (c) swimming on or\nunder liquid. A ground station complements the robotic platform, hosting\nscience instrumentation and providing power to recharge the batteries of the\nCobots. Our Phase I study had the objective of providing an initial assessment\nof the feasibility of the proposed robotic platform architecture, and in\nparticular (a) to characterize the expected science return of a mission to the\nSotra-Patera region on Titan; (b) to verify the mechanical and algorithmic\nfeasibility of building a multi-agent platform capable of flying, docking,\nrolling and un-docking; (c) to evaluate the increased range and efficiency of\nrolling on Titan w.r.t to flying; (d) to define a case-study of a mission for\nthe exploration of the cryovolcano Sotra-Patera on Titan, whose expected\nvariety of geological features challenges conventional mobility platforms.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 23:54:23 GMT"}], "update_date": "2020-03-19", "authors_parsed": [["Agha-mohammadi", "Ali-akbar", ""], ["Tagliabue", "Andrea", ""], ["Schneider", "Stephanie", ""], ["Morrell", "Benjamin", ""], ["Pavone", "Marco", ""], ["Hofgartner", "Jason", ""], ["Nesnas", "Issa A. D.", ""], ["Amini", "Rashied B.", ""], ["Kalantari", "Arash", ""], ["Babuscia", "Alessandra", ""], ["Lunine", "Jonathan", ""]]}, {"id": "2003.08301", "submitter": "Luca Ballotta", "authors": "Luca Ballotta, Luca Schenato, Luca Carlone", "title": "From Sensor to Processing Networks: Optimal Estimation with Computation\n  and Communication Latency", "comments": "8 pages, 8 figures To be published in Proceedings of IFAC 2020 World\n  Congress. arXiv admin note: substantial text overlap with arXiv:1911.05859", "journal-ref": null, "doi": "10.1016/j.ifacol.2020.12.223", "report-no": null, "categories": "math.OC cs.DC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the use of a networked system ($e.g.$, swarm of\nrobots, smart grid, sensor network) to monitor a time-varying phenomenon of\ninterest in the presence of communication and computation latency. Recent\nadvances in edge computing have enabled processing to be spread across the\nnetwork, hence we investigate the fundamental computation-communication\ntrade-off, arising when a sensor has to decide whether to transmit raw data\n(incurring communication delay) or preprocess them (incurring computational\ndelay) in order to compute an accurate estimate of the state of the phenomenon\nof interest. We propose two key contributions. First, we formalize the notion\nof $processing$ $network$. Contrarily to $sensor$ $and$ $communication$\n$networks$, where the designer is concerned with the design of a suitable\ncommunication policy, in a processing network one can also control when and\nwhere the computation occurs in the network. The second contribution is to\nprovide analytical results on the optimal preprocessing delay ($i.e.$, the\noptimal time spent on computations at each sensor) for the case with a single\nsensor and multiple homogeneous sensors. Numerical results substantiate our\nclaims that accounting for computation latencies (both at sensor and estimator\nside) and communication delays can largely impact the estimation accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 21:03:29 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Ballotta", "Luca", ""], ["Schenato", "Luca", ""], ["Carlone", "Luca", ""]]}, {"id": "2003.08353", "submitter": "Marc Brittain", "authors": "Marc Brittain, Xuxi Yang, Peng Wei", "title": "A Deep Multi-Agent Reinforcement Learning Approach to Autonomous\n  Separation Assurance", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel deep multi-agent reinforcement learning framework is proposed to\nidentify and resolve conflicts among a variable number of aircraft in a\nhigh-density, stochastic, and dynamic sector. Currently the sector capacity is\nconstrained by human air traffic controller's cognitive limitation. We\ninvestigate the feasibility of a new concept (autonomous separation assurance)\nand a new approach to push the sector capacity above human cognitive\nlimitation. We propose the concept of using distributed vehicle autonomy to\nensure separation, instead of a centralized sector air traffic controller. Our\nproposed framework utilizes Proximal Policy Optimization (PPO) that we modify\nto incorporate an attention network. This allows the agents to have access to\nvariable aircraft information in the sector in a scalable, efficient approach\nto achieve high traffic throughput under uncertainty. Agents are trained using\na centralized learning, decentralized execution scheme where one neural network\nis learned and shared by all agents. The proposed framework is validated on\nthree challenging case studies in the BlueSky air traffic control environment.\nNumerical results show the proposed framework significantly reduces offline\ntraining time, increases performance, and results in a more efficient policy.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 16:50:34 GMT"}, {"version": "v2", "created": "Thu, 27 Aug 2020 16:46:52 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Brittain", "Marc", ""], ["Yang", "Xuxi", ""], ["Wei", "Peng", ""]]}, {"id": "2003.08376", "submitter": "Xinshuo Weng", "authors": "Xinshuo Weng and Jianren Wang and Sergey Levine and Kris Kitani and\n  Nicholas Rhinehart", "title": "Inverting the Pose Forecasting Pipeline with SPF2: Sequential Pointcloud\n  Forecasting for Sequential Pose Forecasting", "comments": "Published in Conference on Robot Learning (CoRL), 2020. Project\n  webpage: http://www.xinshuoweng.com/projects/SPF2/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many autonomous systems forecast aspects of the future in order to aid\ndecision-making. For example, self-driving vehicles and robotic manipulation\nsystems often forecast future object poses by first detecting and tracking\nobjects. However, this detect-then-forecast pipeline is expensive to scale, as\npose forecasting algorithms typically require labeled sequences of object\nposes, which are costly to obtain in 3D space. Can we scale performance without\nrequiring additional labels? We hypothesize yes, and propose inverting the\ndetect-then-forecast pipeline. Instead of detecting, tracking and then\nforecasting the objects, we propose to first forecast 3D sensor data (e.g.,\npoint clouds with $100$k points) and then detect/track objects on the predicted\npoint cloud sequences to obtain future poses, i.e., a forecast-then-detect\npipeline. This inversion makes it less expensive to scale pose forecasting, as\nthe sensor data forecasting task requires no labels. Part of this work's focus\nis on the challenging first step -- Sequential Pointcloud Forecasting (SPF),\nfor which we also propose an effective approach, SPFNet. To compare our\nforecast-then-detect pipeline relative to the detect-then-forecast pipeline, we\npropose an evaluation procedure and two metrics. Through experiments on a\nrobotic manipulation dataset and two driving datasets, we show that SPFNet is\neffective for the SPF task, our forecast-then-detect pipeline outperforms the\ndetect-then-forecast approaches to which we compared, and that pose forecasting\nperformance improves with the addition of unlabeled data.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 17:54:28 GMT"}, {"version": "v2", "created": "Sun, 29 Mar 2020 16:08:10 GMT"}, {"version": "v3", "created": "Sat, 7 Nov 2020 02:48:22 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Weng", "Xinshuo", ""], ["Wang", "Jianren", ""], ["Levine", "Sergey", ""], ["Kitani", "Kris", ""], ["Rhinehart", "Nicholas", ""]]}, {"id": "2003.08620", "submitter": "Paolo Frasca", "authors": "Francesca Ceragioli and Paolo Frasca and Wilbert Samuel Rossi", "title": "Modeling limited attention in opinion dynamics by topological\n  interactions", "comments": "To be presented at NETGCOOP 2020; revised version including\n  simulations", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work explores models of opinion dynamics with opinion-dependent\nconnectivity. Our starting point is that individuals have limited capabilities\nto engage in interactions with their peers. Motivated by this observation, we\npropose a continuous-time opinion dynamics model such that interactions take\nplace with a limited number of peers: we refer to these interactions as\ntopological, as opposed to metric interactions that are postulated in classical\nbounded-confidence models. We observe that topological interactions produce\nequilibria that are very robust to perturbations.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 08:14:38 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 13:00:42 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Ceragioli", "Francesca", ""], ["Frasca", "Paolo", ""], ["Rossi", "Wilbert Samuel", ""]]}, {"id": "2003.08783", "submitter": "Paul Cohen", "authors": "Paul Cohen and Tomasz Loboda", "title": "Redistribution Systems and PRAM", "comments": "arXiv admin note: substantial text overlap with arXiv:1902.05677", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Redistribution systems iteratively redistribute mass between groups under the\ncontrol of rules. PRAM is a framework for building redistribution systems. We\ndiscuss the relationships between redistribution systems, agent-based systems,\ncompartmental models and Bayesian models. PRAM puts agent-based models on a\nsound probabilistic footing by reformulating them as redistribution systems.\nThis provides a basis for integrating agent-based and probabilistic models.\n\\pram/ extends the themes of probabilistic relational models and lifted\ninference to incorporate dynamical models and simulation. We illustrate PRAM\nwith an epidemiological example.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 01:36:28 GMT"}, {"version": "v2", "created": "Fri, 20 Mar 2020 01:32:37 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Cohen", "Paul", ""], ["Loboda", "Tomasz", ""]]}, {"id": "2003.08839", "submitter": "Mikayel Samvelyan", "authors": "Tabish Rashid, Mikayel Samvelyan, Christian Schroeder de Witt, Gregory\n  Farquhar, Jakob Foerster, Shimon Whiteson", "title": "Monotonic Value Function Factorisation for Deep Multi-Agent\n  Reinforcement Learning", "comments": "Extended version of the ICML 2018 conference paper (arXiv:1803.11485)", "journal-ref": "Journal of Machine Learning Research 21(178):1-51, 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many real-world settings, a team of agents must coordinate its behaviour\nwhile acting in a decentralised fashion. At the same time, it is often possible\nto train the agents in a centralised fashion where global state information is\navailable and communication constraints are lifted. Learning joint\naction-values conditioned on extra state information is an attractive way to\nexploit centralised learning, but the best strategy for then extracting\ndecentralised policies is unclear. Our solution is QMIX, a novel value-based\nmethod that can train decentralised policies in a centralised end-to-end\nfashion. QMIX employs a mixing network that estimates joint action-values as a\nmonotonic combination of per-agent values. We structurally enforce that the\njoint-action value is monotonic in the per-agent values, through the use of\nnon-negative weights in the mixing network, which guarantees consistency\nbetween the centralised and decentralised policies. To evaluate the performance\nof QMIX, we propose the StarCraft Multi-Agent Challenge (SMAC) as a new\nbenchmark for deep multi-agent reinforcement learning. We evaluate QMIX on a\nchallenging set of SMAC scenarios and show that it significantly outperforms\nexisting multi-agent reinforcement learning methods.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 16:51:51 GMT"}, {"version": "v2", "created": "Thu, 27 Aug 2020 13:45:29 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Rashid", "Tabish", ""], ["Samvelyan", "Mikayel", ""], ["de Witt", "Christian Schroeder", ""], ["Farquhar", "Gregory", ""], ["Foerster", "Jakob", ""], ["Whiteson", "Shimon", ""]]}, {"id": "2003.09038", "submitter": "Kananart Kuwaranancharoen", "authors": "Kananart Kuwaranancharoen, Lei Xin, Shreyas Sundaram", "title": "Byzantine-Resilient Distributed Optimization of Multi-Dimensional\n  Functions", "comments": "10 pages, 1 figure. To appear in the Proceedings of the 2020 American\n  Control Conference, 1-3 July 2020, Denver, CO, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of distributed optimization requires a group of agents to reach\nagreement on a parameter that minimizes the average of their local cost\nfunctions using information received from their neighbors. While there are a\nvariety of distributed optimization algorithms that can solve this problem,\nthey are typically vulnerable to malicious (or \"Byzantine\") agents that do not\nfollow the algorithm. Recent attempts to address this issue focus on single\ndimensional functions, or provide analysis under certain assumptions on the\nstatistical properties of the functions at the agents. In this paper, we\npropose a resilient distributed optimization algorithm for multi-dimensional\nconvex functions. Our scheme involves two filtering steps at each iteration of\nthe algorithm: (1) distance-based and (2) component-wise removal of extreme\nstates. We show that this algorithm can mitigate the impact of up to F\nByzantine agents in the neighborhood of each regular node, without knowing the\nidentities of the Byzantine agents in advance. In particular, we show that if\nthe network topology satisfies certain conditions, all of the regular states\nare guaranteed to asymptotically converge to a bounded region that contains the\nglobal minimizer.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 22:46:41 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Kuwaranancharoen", "Kananart", ""], ["Xin", "Lei", ""], ["Sundaram", "Shreyas", ""]]}, {"id": "2003.09267", "submitter": "Mohamadreza Ahmadi", "authors": "Mohamadreza Ahmadi, Andrew Singletary, Joel W. Burdick, and Aaron D.\n  Ames", "title": "Barrier Functions for Multiagent-POMDPs with DTL Specifications", "comments": "arXiv admin note: text overlap with arXiv:1903.07823", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.MA cs.RO cs.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-agent partially observable Markov decision processes (MPOMDPs) provide\na framework to represent heterogeneous autonomous agents subject to uncertainty\nand partial observation. In this paper, given a nominal policy provided by a\nhuman operator or a conventional planning method, we propose a technique based\non barrier functions to design a minimally interfering safety-shield ensuring\nsatisfaction of high-level specifications in terms of linear distribution\ntemporal logic (LDTL). To this end, we use sufficient and necessary conditions\nfor the invariance of a given set based on discrete-time barrier functions\n(DTBFs) and formulate sufficient conditions for finite time DTBF to study\nfinite time convergence to a set. We then show that different LDTL\nmission/safety specifications can be cast as a set of invariance or finite time\nreachability problems. We demonstrate that the proposed method for\nsafety-shield synthesis can be implemented online by a sequence of one-step\ngreedy algorithms. We demonstrate the efficacy of the proposed method using\nexperiments involving a team of robots.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 01:27:36 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Ahmadi", "Mohamadreza", ""], ["Singletary", "Andrew", ""], ["Burdick", "Joel W.", ""], ["Ames", "Aaron D.", ""]]}, {"id": "2003.09310", "submitter": "Fatih Semiz", "authors": "\\c{C}a\\u{g}lar Seylan, \\\"Ozg\\\"ur Sayg{\\i}n Bican, Fatih Semiz", "title": "\\.Insans{\\i}z Ara\\c{c}larla D\\\"uzlemsel Olmayan Ara\\c{c}lar{\\i}n\n  Taranmas{\\i}", "comments": "in Turkish language", "journal-ref": "Savunma Bilimleri Dergisi 11-1 (2012) 107-117", "doi": null, "report-no": null, "categories": "cs.AI cs.MA eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The importance of area coverage with unmanned vehicles, in other words,\ntraveling an area with an unmanned vehicle such as a robot or a UAV completely\nor partially with minimum cost, is increasing with the increase in usage of\nsuch vehicles today. Area coverage with unmanned vehicles is used today in the\nexploration of an area with UAVs, sweeping mines with robots, cleaning ground\nwith robots in large shopping malls, mowing lawn in a large area etc. The\nproblem has versions such as area coverage with a single unmanned vehicle, area\ncoverage with multiple unmanned vehicles, on-line area coverage (The map of the\narea that will be covered is not known before starting the coverage) with\nunmanned vehicles etc. In addition, the area may have obstacles that the\nvehicles cannot move over. Naturally, many researches are working on the\nproblem and a lot of researches have been done on the problem until today.\nSpanning tree coverage is one of the major approaches to the problem. In this\napproach, at the basic level, the planar area is divided into identical squares\naccording to the range of sight of the vehicle, and centers of these squares\nare assumed to be vertexes of a graph. The vertexes of this graph are connected\nwith the edges with unit costs and after finding the minimum spanning tree of\nthe graph, the vehicle strolls around the spanning tree. The method we propose\nsuggests a way to cover a non-planar area with unmanned vehicles. The method we\npropose also takes advantage of the spanning-tree coverage approach, but\ninstead of assigning unit costs to the edges, we assigned a weight to each edge\nusing slopes between vertexes those the edges connect. We have gotten\nnoticeably better results than the results we got when we did not consider the\nslope between two squares and used the classical spanning tree approach.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 14:07:55 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Seylan", "\u00c7a\u011flar", ""], ["Bican", "\u00d6zg\u00fcr Sayg\u0131n", ""], ["Semiz", "Fatih", ""]]}, {"id": "2003.09335", "submitter": "Mattia Bianchi", "authors": "Mattia Bianchi, Giuseppe Belgioioso, Sergio Grammatico", "title": "Fast generalized Nash equilibrium seeking under partial-decision\n  information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the generalized Nash equilibrium seeking problem in a\npartial-decision information scenario, where each agent can only exchange\ninformation with some neighbors, although its cost function possibly depends on\nthe strategies of all agents. The few existing methods build on projected\npseudo-gradient dynamics, and require either double-layer iterations or\nconservative conditions on the step sizes. To overcome both these flaws and\nimprove efficiency, we design the first fully-distributed single-layer\nalgorithms based on proximal best-response. Our schemes are fixed-step and\nallow for inexact updates, which is crucial for reducing the computational\ncomplexity. Under standard assumptions on the game primitives, we establish\nconvergence to a variational equilibrium (with linear rate for games without\ncoupling constraints) by recasting our algorithms as proximal-point methods,\nopportunely preconditioned to distribute the computation among the agents.\nBesides, our operator-theoretic approach favors the implementation of provably\ncorrect acceleration schemes that can further improve the convergence speed.\nSince our analysis hinge on a restricted monotonicity property, we also provide\nnew general results that significantly extend the domain of applicability of\nproximal-point methods. The potential of our algorithms is validated\nnumerically, revealing much faster convergence with respect to the known\nprojected pseudo-gradient algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 15:41:25 GMT"}, {"version": "v2", "created": "Fri, 30 Oct 2020 10:01:23 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Bianchi", "Mattia", ""], ["Belgioioso", "Giuseppe", ""], ["Grammatico", "Sergio", ""]]}, {"id": "2003.09485", "submitter": "Stanis{\\l}aw  Ambroszkiewicz", "authors": "Kamil Skarzynski, Marcin Stepniak, Waldemar Bartyna, Stanislaw\n  Ambroszkiewicz", "title": "A generic ontology and recovery protocols for Human-Robot Collaboration\n  (HRC) systems", "comments": "This is a continuation of our paper \"SO-MRS: a multi-robot system\n  architecture based on the SOA paradigm and ontology\" published in Proc. TAROS\n  2018 Conference and at arXiv:1709.03300", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans are considered as integral components of Human-Robot Collaboration\n(HRC) systems, not only as object (e.g. in health care), but also as operators\nand service providers in manufacturing. Sophisticated and complex tasks are to\nbe collaboratively executed by devices (robots) and humans. We introduce a\ngeneric ontology for HRC systems. Description of humans is a part of the\nontology. Critical and hazardous (for humans) situations, as well as\ncorresponding safeguards are defined on the basis of the ontology. The ontology\nis an extension of the ontology introduced in Skarzynski et al. (2018)\narXiv:1709.03300. The architecture of SO-MRS (see arXiv:1709.03300), a software\nplatform for automatic task accomplishment, is extended to HRC systems. Ongoing\nexperiments, carried out in a simulated HRC system, are to verify the ontology\nand the architecture.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 20:13:06 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Skarzynski", "Kamil", ""], ["Stepniak", "Marcin", ""], ["Bartyna", "Waldemar", ""], ["Ambroszkiewicz", "Stanislaw", ""]]}, {"id": "2003.09540", "submitter": "Joewie Koh", "authors": "Guohui Ding, Joewie J. Koh, Kelly Merckaert, Bram Vanderborght, Marco\n  M. Nicotra, Christoffer Heckman, Alessandro Roncone, Lijun Chen", "title": "Distributed Reinforcement Learning for Cooperative Multi-Robot Object\n  Manipulation", "comments": "3 pages, 3 figures", "journal-ref": "Proceedings of the 19th International Conference on Autonomous\n  Agents and Multiagent Systems (AAMAS), 2020, pp. 1831-1833", "doi": null, "report-no": null, "categories": "cs.RO cs.GT cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider solving a cooperative multi-robot object manipulation task using\nreinforcement learning (RL). We propose two distributed multi-agent RL\napproaches: distributed approximate RL (DA-RL), where each agent applies\nQ-learning with individual reward functions; and game-theoretic RL (GT-RL),\nwhere the agents update their Q-values based on the Nash equilibrium of a\nbimatrix Q-value game. We validate the proposed approaches in the setting of\ncooperative object manipulation with two simulated robot arms. Although we\nfocus on a small system of two agents in this paper, both DA-RL and GT-RL apply\nto general multi-agent systems, and are expected to scale well to large\nsystems.\n", "versions": [{"version": "v1", "created": "Sat, 21 Mar 2020 00:43:54 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Ding", "Guohui", ""], ["Koh", "Joewie J.", ""], ["Merckaert", "Kelly", ""], ["Vanderborght", "Bram", ""], ["Nicotra", "Marco M.", ""], ["Heckman", "Christoffer", ""], ["Roncone", "Alessandro", ""], ["Chen", "Lijun", ""]]}, {"id": "2003.09575", "submitter": "Yen-Cheng Liu", "authors": "Yen-Cheng Liu, Junjiao Tian, Chih-Yao Ma, Nathan Glaser, Chia-Wen Kuo\n  and Zsolt Kira", "title": "Who2com: Collaborative Perception via Learnable Handshake Communication", "comments": "Accepted to ICRA 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose the problem of collaborative perception, where\nrobots can combine their local observations with those of neighboring agents in\na learnable way to improve accuracy on a perception task. Unlike existing work\nin robotics and multi-agent reinforcement learning, we formulate the problem as\none where learned information must be shared across a set of agents in a\nbandwidth-sensitive manner to optimize for scene understanding tasks such as\nsemantic segmentation. Inspired by networking communication protocols, we\npropose a multi-stage handshake communication mechanism where the neural\nnetwork can learn to compress relevant information needed for each stage.\nSpecifically, a target agent with degraded sensor data sends a compressed\nrequest, the other agents respond with matching scores, and the target agent\ndetermines who to connect with (i.e., receive information from). We\nadditionally develop the AirSim-CP dataset and metrics based on the AirSim\nsimulator where a group of aerial robots perceive diverse landscapes, such as\nroads, grasslands, buildings, etc. We show that for the semantic segmentation\ntask, our handshake communication method significantly improves accuracy by\napproximately 20% over decentralized baselines, and is comparable to\ncentralized ones using a quarter of the bandwidth.\n", "versions": [{"version": "v1", "created": "Sat, 21 Mar 2020 04:16:22 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Liu", "Yen-Cheng", ""], ["Tian", "Junjiao", ""], ["Ma", "Chih-Yao", ""], ["Glaser", "Nathan", ""], ["Kuo", "Chia-Wen", ""], ["Kira", "Zsolt", ""]]}, {"id": "2003.09675", "submitter": "Nirupam Gupta", "authors": "Nirupam Gupta and Nitin H. Vaidya", "title": "Resilience in Collaborative Optimization: Redundant and Independent Cost\n  Functions", "comments": "This revised version contains additional generalizations. Comprises\n  30 pages, and 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This report considers the problem of Byzantine fault-tolerance in multi-agent\ncollaborative optimization. In this problem, each agent has a local cost\nfunction. The goal of a collaborative optimization algorithm is to compute a\nminimum of the aggregate of the agents' cost functions. We consider the case\nwhen a certain number of agents may be Byzantine faulty. Such faulty agents may\nnot follow a prescribed algorithm, and they may send arbitrary or incorrect\ninformation regarding their local cost functions. A reasonable goal in presence\nof such faulty agents is to minimize the aggregate cost of the non-faulty\nagents. In this report, we show that this goal can be achieved if and only if\nthe cost functions of the non-faulty agents have a minimal redundancy property.\nWe present different algorithms that achieve such tolerance against faulty\nagents, and demonstrate a trade-off between the complexity of an algorithm and\nthe properties of the agents' cost functions.\n  Further, we also consider the case when the cost functions are independent or\ndo not satisfy the minimal redundancy property. In that case, we quantify the\ntolerance against faulty agents by introducing a metric called weak resilience.\nWe present an algorithm that attains weak resilience when the faulty agents are\nin the minority and the cost functions are non-negative.\n", "versions": [{"version": "v1", "created": "Sat, 21 Mar 2020 15:00:27 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 14:43:29 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Gupta", "Nirupam", ""], ["Vaidya", "Nitin H.", ""]]}, {"id": "2003.09783", "submitter": "Reza Langari", "authors": "Jehong Yoo and Reza Langari", "title": "A Game-Theoretic Model of Human Driving and Application to Discretionary\n  Lane-Changes", "comments": "14 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.MA physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider the application of Stackelberg game theory to model\ndiscretionary lane-changing in lightly congested highway setting. The\nfundamental intent of this model, which is parameterized to capture driver\ndisposition (aggressiveness or inattentiveness), is to help with the\ndevelopment of decision-making strategies for autonomous vehicles in ways that\nare mindful of how human drivers perform the same function on the road (on\nwhich have reported elsewhere.) This paper, however, focuses only on the model\ndevelopment and the respective qualitative assessment. This is accomplished in\nunit test simulations as well as in bulk mode (i.e. using the Monte Carlo\nmethodology), via a limited traffic micro-simulation compared against the NHTSA\n100-Car Naturalistic Driving Safety data. In particular, a qualitative\ncomparison shows the relative consistency of the proposed model with human\ndecision-making in terms of producing qualitatively similar proportions of\ncrashes and near crashes as a function of driver inattentiveness (or\naggressiveness). While this result by itself does not offer a true quantitative\nvalidation of the proposed model, it does demonstrate the utility of the\nproposed approach in modeling discretionary lane-changing and may therefore be\nof use in autonomous driving in a manner that is consistent with human decision\nmaking on the road.\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2020 02:32:05 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Yoo", "Jehong", ""], ["Langari", "Reza", ""]]}, {"id": "2003.09813", "submitter": "Ahmed Allibhoy", "authors": "Ahmed Allibhoy and Jorge Cort\\'es", "title": "Data-based Receding Horizon Control of Linear Network Systems", "comments": null, "journal-ref": null, "doi": "10.1109/LCSYS.2020.3021050", "report-no": null, "categories": "math.OC cs.MA cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a distributed data-based predictive control scheme to stabilize a\nnetwork system described by linear dynamics. Agents cooperate to predict the\nfuture system evolution without knowledge of the dynamics, relying instead on\nlearning a data-based representation from a single sample trajectory. We employ\nthis representation to reformulate the finite-horizon Linear Quadratic\nRegulator problem as a network optimization with separable objective functions\nand locally expressible constraints. We show that the controller resulting from\napproximately solving this problem using a distributed optimization algorithm\nin a receding horizon manner is stabilizing. We validate our results through\nnumerical simulations.\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2020 05:29:57 GMT"}, {"version": "v2", "created": "Sun, 30 Aug 2020 19:05:29 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Allibhoy", "Ahmed", ""], ["Cort\u00e9s", "Jorge", ""]]}, {"id": "2003.10218", "submitter": "Mikhail Prokopenko", "authors": "Sheryl L. Chang, Nathan Harding, Cameron Zachreson, Oliver M. Cliff,\n  Mikhail Prokopenko", "title": "Modelling transmission and control of the COVID-19 pandemic in Australia", "comments": "45 pages, 19 figures", "journal-ref": "Nature Communications, 11: 5710, 2020", "doi": "10.1038/s41467-020-19393-6", "report-no": null, "categories": "q-bio.PE cs.MA q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a continuing debate on relative benefits of various mitigation and\nsuppression strategies aimed to control the spread of COVID-19. Here we report\nthe results of agent-based modelling using a fine-grained computational\nsimulation of the ongoing COVID-19 pandemic in Australia. This model is\ncalibrated to match key characteristics of COVID-19 transmission. An important\ncalibration outcome is the age-dependent fraction of symptomatic cases, with\nthis fraction for children found to be one-fifth of such fraction for adults.\nWe apply the model to compare several intervention strategies, including\nrestrictions on international air travel, case isolation, home quarantine,\nsocial distancing with varying levels of compliance, and school closures.\nSchool closures are not found to bring decisive benefits, unless coupled with\nhigh level of social distancing compliance. We report several trade-offs, and\nan important transition across the levels of social distancing compliance, in\nthe range between 70% and 80% levels, with compliance at the 90% level found to\ncontrol the disease within 13--14 weeks, when coupled with effective case\nisolation and international travel restrictions.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 12:31:56 GMT"}, {"version": "v2", "created": "Thu, 2 Apr 2020 03:20:00 GMT"}, {"version": "v3", "created": "Sun, 3 May 2020 18:11:15 GMT"}, {"version": "v4", "created": "Wed, 11 Nov 2020 13:49:48 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Chang", "Sheryl L.", ""], ["Harding", "Nathan", ""], ["Zachreson", "Cameron", ""], ["Cliff", "Oliver M.", ""], ["Prokopenko", "Mikhail", ""]]}, {"id": "2003.10294", "submitter": "Ryan Beal Mr.", "authors": "Ryan Beal, Georgios Chalkiadakis, Timothy J. Norman and Sarvapali D.\n  Ramchurn", "title": "Optimising Game Tactics for Football", "comments": "AAMAS 2020 Pre-Print Version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a novel approach to optimise tactical and strategic\ndecision making in football (soccer). We model the game of football as a\nmulti-stage game which is made up from a Bayesian game to model the pre-match\ndecisions and a stochastic game to model the in-match state transitions and\ndecisions. Using this formulation, we propose a method to predict the\nprobability of game outcomes and the payoffs of team actions. Building upon\nthis, we develop algorithms to optimise team formation and in-game tactics with\ndifferent objectives. Empirical evaluation of our approach on real-world\ndatasets from 760 matches shows that by using optimised tactics from our\nBayesian and stochastic games, we can increase a team chances of winning by up\nto 16.1\\% and 3.4\\% respectively.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 14:24:45 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Beal", "Ryan", ""], ["Chalkiadakis", "Georgios", ""], ["Norman", "Timothy J.", ""], ["Ramchurn", "Sarvapali D.", ""]]}, {"id": "2003.10486", "submitter": "Jovonni Pharr", "authors": "Jovonni L. Pharr", "title": "AfricaOS: Using a distributed, proposal-based, replicated state machine\n  towards liberation from the Berlin Conference of 1885", "comments": "v0.0.1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CR cs.DC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Berlin Conference of 1885 has influenced the way native Africans, and the\nAfrican Diaspora live their daily lives. France contractually controls several\nresources generated by the continent of Africa. Herein lies a technical\nproposal to free Africa from the financial and economic agreements coerced upon\nthe continent over a century ago by utilizing decentralized collaboration\nthrough advanced technology. AfricaOS (AOS) aims to provide a philosophical,\nand fundamental framework for implementing a simple, distributed, collaborative\ncomputer for agreement amongst peers. The work also demonstrates an algebra\nover transactions, use of the protocol for privatization, a method for\ntokenizing barter economies, and methods to design mechanisms for use in\nimplementing protocol behavior.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 18:34:52 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Pharr", "Jovonni L.", ""]]}, {"id": "2003.10563", "submitter": "Jiani Li", "authors": "Jiani Li, Waseem Abbas, Xenofon Koutsoukos", "title": "Resilient Distributed Diffusion in Networks with Adversaries", "comments": null, "journal-ref": "in IEEE Transactions on Signal and Information Processing over\n  Networks, vol. 6, pp. 1-17, 2020", "doi": "10.1109/TSIPN.2019.2957731", "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study resilient distributed diffusion for multi-task\nestimation in the presence of adversaries where networked agents must estimate\ndistinct but correlated states of interest by processing streaming data. We\nshow that in general diffusion strategies are not resilient to malicious agents\nthat do not adhere to the diffusion-based information processing rules. In\nparticular, by exploiting the adaptive weights used for diffusing information,\nwe develop time-dependent attack models that drive normal agents to converge to\nstates selected by the attacker. We show that an attacker that has complete\nknowledge of the system can always drive its targeted agents to its desired\nestimates. Moreover, an attacker that does not have complete knowledge of the\nsystem including streaming data of targeted agents or the parameters they use\nin diffusion algorithms, can still be successful in deploying an attack by\napproximating the needed information. The attack models can be used for both\nstationary and non-stationary state estimation.In addition, we present and\nanalyze a resilient distributed diffusion algorithm that is resilient to any\ndata falsification attack in which the number of compromised agents in the\nlocal neighborhood of a normal agent is bounded. The proposed algorithm\nguarantees that all normal agents converge to their true target states if\nappropriate parameters are selected. We also analyze trade-off between the\nresilience of distributed diffusion and its performance in terms of\nsteady-state mean-square-deviation (MSD) from the correct estimates. Finally,\nwe evaluate the proposed attack models and resilient distributed diffusion\nalgorithm using stationary and non-stationary multi-target localization.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 22:06:34 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Li", "Jiani", ""], ["Abbas", "Waseem", ""], ["Koutsoukos", "Xenofon", ""]]}, {"id": "2003.10598", "submitter": "Hassam Sheikh", "authors": "Hassam Ullah Sheikh and Ladislau B\\\"ol\\\"oni", "title": "Multi-Agent Reinforcement Learning for Problems with Combined Individual\n  and Team Reward", "comments": "Accepted for publication at International Joint Conference on Neural\n  Networks (IJCNN-2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many cooperative multi-agent problems require agents to learn individual\ntasks while contributing to the collective success of the group. This is a\nchallenging task for current state-of-the-art multi-agent reinforcement\nalgorithms that are designed to either maximize the global reward of the team\nor the individual local rewards. The problem is exacerbated when either of the\nrewards is sparse leading to unstable learning. To address this problem, we\npresent Decomposed Multi-Agent Deep Deterministic Policy Gradient (DE-MADDPG):\na novel cooperative multi-agent reinforcement learning framework that\nsimultaneously learns to maximize the global and local rewards. We evaluate our\nsolution on the challenging defensive escort team problem and show that our\nsolution achieves a significantly better and more stable performance than the\ndirect adaptation of the MADDPG algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 00:55:37 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Sheikh", "Hassam Ullah", ""], ["B\u00f6l\u00f6ni", "Ladislau", ""]]}, {"id": "2003.10662", "submitter": "Piyush Gupta", "authors": "Piyush Gupta, Demetris Coleman, Joshua E. Siegel", "title": "Towards Safer Self-Driving Through Great PAIN (Physically Adversarial\n  Intelligent Networks)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated vehicles' neural networks suffer from overfit, poor\ngeneralizability, and untrained edge cases due to limited data availability.\nResearchers synthesize randomized edge-case scenarios to assist in the training\nprocess, though simulation introduces potential for overfit to latent rules and\nfeatures. Automating worst-case scenario generation could yield informative\ndata for improving self driving. To this end, we introduce a \"Physically\nAdversarial Intelligent Network\" (PAIN), wherein self-driving vehicles interact\naggressively in the CARLA simulation environment. We train two agents, a\nprotagonist and an adversary, using dueling double deep Q networks (DDDQNs)\nwith prioritized experience replay. The coupled networks alternately\nseek-to-collide and to avoid collisions such that the \"defensive\" avoidance\nalgorithm increases the mean-time-to-failure and distance traveled under\nnon-hostile operating conditions. The trained protagonist becomes more\nresilient to environmental uncertainty and less prone to corner case failures\nresulting in collisions than the agent trained without an adversary.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 05:04:13 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Gupta", "Piyush", ""], ["Coleman", "Demetris", ""], ["Siegel", "Joshua E.", ""]]}, {"id": "2003.10871", "submitter": "Mattia Bianchi", "authors": "Mattia Bianchi, Sergio Grammatico", "title": "Fully distributed Nash equilibrium seeking over time-varying\n  communication networks with linear convergence rate", "comments": null, "journal-ref": "IEEE Control Systems Letters, Volume: 5, Issue: 2, April 2021", "doi": "10.1109/LCSYS.2020.3002734", "report-no": null, "categories": "math.OC cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We design a distributed algorithm for learning Nash equilibria over\ntime-varying communication networks in a partial-decision information scenario,\nwhere each agent can access its own cost function and local feasible set, but\ncan only observe the actions of some neighbors. Our algorithm is based on\nprojected pseudo-gradient dynamics, augmented with consensual terms. Under\nstrong monotonicity and Lipschitz continuity of the game mapping, we provide a\nvery simple proof of linear convergence, based on a contractivity property of\nthe iterates. Compared to similar solutions proposed in literature, we also\nallow for a time-varying communication and derive tighter bounds on the step\nsizes that ensure convergence. In fact, in our numerical simulations, our\nalgorithm outperforms the existing gradient-based methods, when the step sizes\nare set to their theoretical upper bounds. Finally, to relax the assumptions on\nthe network structure, we propose a different pseudo-gradient algorithm, which\nis guaranteed to converge on time-varying balanced directed graphs.\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2020 10:42:38 GMT"}, {"version": "v2", "created": "Thu, 10 Sep 2020 16:35:43 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Bianchi", "Mattia", ""], ["Grammatico", "Sergio", ""]]}, {"id": "2003.10903", "submitter": "Bj\\\"orn Lindenberg", "authors": "Bj\\\"orn Lindenberg, Jonas Nordqvist, Karl-Olof Lindahl", "title": "Distributional Reinforcement Learning with Ensembles", "comments": "15 pages, 2 figures", "journal-ref": "Algorithms 2020, 13, 118", "doi": "10.3390/a13050118", "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that ensemble methods often provide enhanced performance in\nreinforcement learning. In this paper, we explore this concept further by using\ngroup-aided training within the distributional reinforcement learning paradigm.\nSpecifically, we propose an extension to categorical reinforcement learning,\nwhere distributional learning targets are implicitly based on the total\ninformation gathered by an ensemble. We empirically show that this may lead to\nmuch more robust initial learning, a stronger individual performance level, and\ngood efficiency on a per-sample basis.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 14:59:54 GMT"}, {"version": "v2", "created": "Fri, 22 May 2020 15:49:49 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Lindenberg", "Bj\u00f6rn", ""], ["Nordqvist", "Jonas", ""], ["Lindahl", "Karl-Olof", ""]]}, {"id": "2003.11071", "submitter": "Berat Mert Albaba", "authors": "Berat Mert Albaba, Yildiray Yildiz", "title": "Driver Modeling through Deep Reinforcement Learning and Behavioral Game\n  Theory", "comments": "22 pages, 19 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a synergistic combination of deep reinforcement learning and\nhierarchical game theory is proposed as a modeling framework for behavioral\npredictions of drivers in highway driving scenarios. The need for a modeling\nframework that can address multiple human-human and human-automation\ninteractions, where all the agents can be modeled as decision makers\nsimultaneously, is the main motivation behind this work. Such a modeling\nframework may be utilized for the validation and verification of autonomous\nvehicles: It is estimated that for an autonomous vehicle to reach the same\nsafety level of cars with drivers, millions of miles of driving tests are\nrequired. The modeling framework presented in this paper may be used in a\nhigh-fidelity traffic simulator consisting of multiple human decision makers to\nreduce the time and effort spent for testing by allowing safe and quick\nassessment of self-driving algorithms. To demonstrate the fidelity of the\nproposed modeling framework, game theoretical driver models are compared with\nreal human driver behavior patterns extracted from traffic data.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 18:59:17 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Albaba", "Berat Mert", ""], ["Yildiz", "Yildiray", ""]]}, {"id": "2003.11170", "submitter": "Nirav Ajmeri", "authors": "Nirav Ajmeri (1), Shubham Goyal (2), Munindar P. Singh (1) ((1) North\n  Carolina State University, (2) Amazon)", "title": "Norms and Sanctions as a Basis for Promoting Cybersecurity Practices", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many cybersecurity breaches occur due to users not following good\ncybersecurity practices, chief among them being regulations for applying\nsoftware patches to operating systems, updating applications, and maintaining\nstrong passwords.\n  We capture cybersecurity expectations on users as norms. We empirically\ninvestigate sanctioning mechanisms in promoting compliance with those norms as\nwell as the detrimental effect of sanctions on the ability of users to complete\ntheir work. We realize these ideas in a game that emulates the decision making\nof workers in a research lab.\n  Through a human-subject study, we find that whereas individual sanctions are\nmore effective than group sanctions in achieving compliance and less\ndetrimental on the ability of users to complete their work, individual\nsanctions offer significantly lower resilience especially for organizations\ncomprising risk seekers. Our findings have implications for workforce training\nin cybersecurity.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 01:07:06 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Ajmeri", "Nirav", ""], ["Goyal", "Shubham", ""], ["Singh", "Munindar P.", ""]]}, {"id": "2003.11281", "submitter": "Julian Bernhard", "authors": "Julian Bernhard and Alois Knoll", "title": "Robust Stochastic Bayesian Games for Behavior Space Coverage", "comments": "added an additional experiment showing the applicability of the\n  approach in a lane changing task with multi-dimensional behavior spaces,\n  added acknowledgement", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key challenge in multi-agent systems is the design of intelligent agents\nsolving real-world tasks in close interaction with other agents (e.g. humans),\nthereby being confronted with a variety of behavioral variations and limited\nknowledge about the true behaviors of observed agents. The practicability of\nexisting works addressing this challenge is being limited due to using finite\nsets of hypothesis for behavior prediction, the lack of a hypothesis design\nprocess ensuring coverage over all behavioral variations and\nsample-inefficiency when modeling continuous behavioral variations. In this\nwork, we present an approach to this challenge based on a new framework of\nRobust Stochastic Bayesian Games (RSBGs). An RSBG defines hypothesis sets by\npartitioning the physically feasible, continuous behavior space of the other\nagents. It combines the optimality criteria of the Robust Markov Decision\nProcess (RMDP) and the Stochastic Bayesian Game (SBG) to exponentially reduce\nthe sample complexity for planning with hypothesis sets defined over continuous\nbehavior spaces. Our approach outperforms the baseline algorithms in two\nexperiments modeling time-varying intents and large multidimensional behavior\nspaces, while achieving the same performance as a planner with knowledge of the\ntrue behaviors of other agents.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 09:02:46 GMT"}, {"version": "v2", "created": "Thu, 9 Jul 2020 13:53:18 GMT"}, {"version": "v3", "created": "Fri, 10 Jul 2020 08:07:20 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Bernhard", "Julian", ""], ["Knoll", "Alois", ""]]}, {"id": "2003.11637", "submitter": "Pravin Game", "authors": "Pravin S Game, Dr. Vinod Vaze, Dr. Emmanuel M", "title": "Bio-inspired Optimization: metaheuristic algorithms for optimization", "comments": null, "journal-ref": "pp. 1-9, (17-18 January 2020)", "doi": null, "report-no": "ISBN- 978-819-20113-4-9", "categories": "cs.NE cs.AI cs.MA", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In today's day and time solving real-world complex problems has become\nfundamentally vital and critical task. Many of these are combinatorial\nproblems, where optimal solutions are sought rather than exact solutions.\nTraditional optimization methods are found to be effective for small scale\nproblems. However, for real-world large scale problems, traditional methods\neither do not scale up or fail to obtain optimal solutions or they end-up\ngiving solutions after a long running time. Even earlier artificial\nintelligence based techniques used to solve these problems could not give\nacceptable results. However, last two decades have seen many new methods in AI\nbased on the characteristics and behaviors of the living organisms in the\nnature which are categorized as bio-inspired or nature inspired optimization\nalgorithms. These methods, are also termed meta-heuristic optimization methods,\nhave been proved theoretically and implemented using simulation as well used to\ncreate many useful applications. They have been used extensively to solve many\nindustrial and engineering complex problems due to being easy to understand,\nflexible, simple to adapt to the problem at hand and most importantly their\nability to come out of local optima traps. This local optima avoidance property\nhelps in finding global optimal solutions. This paper is aimed at understanding\nhow nature has inspired many optimization algorithms, basic categorization of\nthem, major bio-inspired optimization algorithms invented in recent time with\ntheir applications.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 13:26:34 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Game", "Pravin S", ""], ["Vaze", "Dr. Vinod", ""], ["M", "Dr. Emmanuel", ""]]}, {"id": "2003.11693", "submitter": "Aneesh Raghavan", "authors": "Aneesh Raghavan and John S. Baras", "title": "Order Effects of Measurements in Multi-Agent Hypothesis Testing", "comments": "Journal Paper Accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multi-agent systems, agents observe data, and use them to make inferences\nand take actions. As a result sensing and control naturally interfere, more so\nfrom a real-time perspective. A natural consequence is that in multi-agent\nsystems there are propositions based on the set of observed events that might\nnot be simultaneously verifiable, which leads to the need for probability\nstructures that allow such \\textit{incompatible events}. We revisit the\nstructure of events in a multi-agent system and we introduce the necessary new\nmodels that incorporate such incompatible events in the formalism. These models\nare essential for building non-commutative probability models, which are\ndifferent than the classical models based on the Kolmogorov construction. From\nthis perspective, we revisit the concepts of \\textit{event-state-operation\nstructure} and the needed \\textit{relationship of incompatibility} from the\nliterature and use them as a tool to study the needed new algebraic structure\nof the set of events. We present an example from multi-agent hypothesis testing\nwhere the set of events does not form a Boolean algebra, but forms an\northolattice. A possible construction of a `noncommutative probability space',\naccounting for \\textit{incompatible events} is discussed. We formulate and\nsolve the binary hypothesis testing problem in the noncommutative probability\nspace. We illustrate the occurrence of `order effects' in the multi-agent\nhypothesis testing problem by computing the minimum probability of error that\ncan be achieved with different orders of measurements.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 01:09:25 GMT"}, {"version": "v2", "created": "Wed, 11 Nov 2020 23:22:54 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Raghavan", "Aneesh", ""], ["Baras", "John S.", ""]]}, {"id": "2003.11778", "submitter": "Max Kleiman-Weiner", "authors": "Rose E. Wang, Sarah A. Wu, James A. Evans, Joshua B. Tenenbaum, David\n  C. Parkes, Max Kleiman-Weiner", "title": "Too many cooks: Bayesian inference for coordinating multi-agent\n  collaboration", "comments": "Rose E. Wang and Sarah A. Wu contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaboration requires agents to coordinate their behavior on the fly,\nsometimes cooperating to solve a single task together and other times dividing\nit up into sub-tasks to work on in parallel. Underlying the human ability to\ncollaborate is theory-of-mind, the ability to infer the hidden mental states\nthat drive others to act. Here, we develop Bayesian Delegation, a decentralized\nmulti-agent learning mechanism with these abilities. Bayesian Delegation\nenables agents to rapidly infer the hidden intentions of others by inverse\nplanning. We test Bayesian Delegation in a suite of multi-agent Markov decision\nprocesses inspired by cooking problems. On these tasks, agents with Bayesian\nDelegation coordinate both their high-level plans (e.g. what sub-task they\nshould work on) and their low-level actions (e.g. avoiding getting in each\nother's way). In a self-play evaluation, Bayesian Delegation outperforms\nalternative algorithms. Bayesian Delegation is also a capable ad-hoc\ncollaborator and successfully coordinates with other agent types even in the\nabsence of prior experience. Finally, in a behavioral experiment, we show that\nBayesian Delegation makes inferences similar to human observers about the\nintent of others. Together, these results demonstrate the power of Bayesian\nDelegation for decentralized multi-agent collaboration.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 07:43:13 GMT"}, {"version": "v2", "created": "Mon, 6 Jul 2020 00:59:13 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Wang", "Rose E.", ""], ["Wu", "Sarah A.", ""], ["Evans", "James A.", ""], ["Tenenbaum", "Joshua B.", ""], ["Parkes", "David C.", ""], ["Kleiman-Weiner", "Max", ""]]}, {"id": "2003.11911", "submitter": "Jiani Li", "authors": "Jiani Li and Xenofon Koutsoukos", "title": "Resilient Distributed Diffusion for Multi-task Estimation", "comments": "arXiv admin note: substantial text overlap with arXiv:2003.10563", "journal-ref": "2018 14th International Conference on Distributed Computing in\n  Sensor Systems (DCOSS), New York, NY, 2018, pp. 93-102", "doi": "10.1109/DCOSS.2018.00020", "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed diffusion is a powerful algorithm for multi-task state estimation\nwhich enables networked agents to interact with neighbors to process input data\nand diffuse information across the network. Compared to a centralized approach,\ndiffusion offers multiple advantages that include robustness to node and link\nfailures. In this paper, we consider distributed diffusion for multi-task\nestimation where networked agents must estimate distinct but correlated states\nof interest by processing streaming data. By exploiting the adaptive weights\nused for diffusing information, we develop attack models that drive normal\nagents to converge to states selected by the attacker. The attack models can be\nused for both stationary and non-stationary state estimation. In addition, we\ndevelop a resilient distributed diffusion algorithm under the assumption that\nthe number of compromised nodes in the neighborhood of each normal node is\nbounded by $F$ and we show that resilience may be obtained at the cost of\nperformance degradation. Finally, we evaluate the proposed attack models and\nresilient distributed diffusion algorithm using stationary and non-stationary\nmulti-target localization.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 22:22:03 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Li", "Jiani", ""], ["Koutsoukos", "Xenofon", ""]]}, {"id": "2003.11985", "submitter": "Bernd Ebersberger", "authors": "Johannes Dahlke, Kristina Bogner, Matthias Mueller, Thomas Berger,\n  Andreas Pyka and Bernd Ebersberger", "title": "Is the Juice Worth the Squeeze? Machine Learning (ML) In and For\n  Agent-Based Modelling (ABM)", "comments": "25 pages, 3 figures, 2 tables, discussion paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.TH cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, many scholars praised the seemingly endless possibilities of\nusing machine learning (ML) techniques in and for agent-based simulation models\n(ABM). To get a more comprehensive understanding of these possibilities, we\nconduct a systematic literature review (SLR) and classify the literature on the\napplication of ML in and for ABM according to a theoretically derived\nclassification scheme. We do so to investigate how exactly machine learning has\nbeen utilized in and for agent-based models so far and to critically discuss\nthe combination of these two promising methods. We find that, indeed, there is\na broad range of possible applications of ML to support and complement ABMs in\nmany different ways, already applied in many different disciplines. We see\nthat, so far, ML is mainly used in ABM for two broad cases: First, the\nmodelling of adaptive agents equipped with experience learning and, second, the\nanalysis of outcomes produced by a given ABM. While these are the most\nfrequent, there also exist a variety of many more interesting applications.\nThis being the case, researchers should dive deeper into the analysis of when\nand how which kinds of ML techniques can support ABM, e.g. by conducting a more\nin-depth analysis and comparison of different use cases. Nonetheless, as the\napplication of ML in and for ABM comes at certain costs, researchers should not\nuse ML for ABMs just for the sake of doing it.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 15:49:01 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Dahlke", "Johannes", ""], ["Bogner", "Kristina", ""], ["Mueller", "Matthias", ""], ["Berger", "Thomas", ""], ["Pyka", "Andreas", ""], ["Ebersberger", "Bernd", ""]]}, {"id": "2003.12447", "submitter": "Yuzhong Huang", "authors": "Yuzhong Huang, Andres Abeliuk, Fred Morstatter, Pavel Atanasov, Aram\n  Galstyan", "title": "Anchor Attention for Hybrid Crowd Forecasts Aggregation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.MA", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Forecasting the future is a notoriously difficult task. To overcome this\nchallenge, state-of-the-art forecasting platforms are \"hybridized\", they gather\nforecasts from a crowd of humans, as well as one or more machine models.\nHowever, an open challenge remains in how to optimally combine forecasts from\nthese pools into a single forecast. We proposed anchor attention for this type\nof sequence summary problem. Each forecast is represented by a trainable\nembedding vector, and use computed anchor attention score as the combined\nweight. We evaluate our approach using data from real-world forecasting\ntournaments, and show that our method outperforms the current state-of-the-art\naggregation approaches.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 23:39:02 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Huang", "Yuzhong", ""], ["Abeliuk", "Andres", ""], ["Morstatter", "Fred", ""], ["Atanasov", "Pavel", ""], ["Galstyan", "Aram", ""]]}, {"id": "2003.12605", "submitter": "Emilie Frost", "authors": "Emilie Frost, Eric MSP Veith and Lars Fischer", "title": "Robust and Deterministic Scheduling of Power Grid Actors", "comments": "Submitted to CoDIT 20 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern power grids need to cope with increasingly decentralized, volatile\nenergy sources as well as new business models such as virtual power plants\nconstituted from battery swarms. This warrants both, day-ahead planning of\nlarger schedules for power plants, as well as short-term contracting to counter\nforecast deviations or to accommodate dynamics of the intra-day markets. In\naddition, the geographic distribution of renewable energy sources forces\nscheduling algorithms with a hugely different communication link qualities. In\nthis paper, we present an extension to the Lightweight Power Exchange Protocol\n(LPEP), dubbed LPEP++. It draws on the strength of the LPEP to find the optimal\nsolution of the combinatorial power demand-supply problem with string\nguarantees in acceptable time and extends it with facilities for long-term\nplanning, parallel negotiations and reduces its memory footprint. We\nfurthermore show its robustness towards volatile communication link quality.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 19:12:58 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Frost", "Emilie", ""], ["Veith", "Eric MSP", ""], ["Fischer", "Lars", ""]]}, {"id": "2003.12665", "submitter": "Pedro Cisneros-Velarde", "authors": "Pedro Cisneros-Velarde, Saber Jafarpour, Francesco Bullo", "title": "Distributed and time-varying primal-dual dynamics via contraction\n  analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note, we provide an overarching analysis of primal-dual dynamics\nassociated to linear equality-constrained optimization problems using\ncontraction analysis. For the well-known standard version of the problem: we\nestablish convergence under convexity and the contracting rate under strong\nconvexity. Then, for a canonical distributed optimization problem, we use\npartial contractivity to establish global exponential convergence of its\nprimal-dual dynamics. As an application, we propose a new distributed solver\nfor the least-squares problem with the same convergence guarantees. Finally,\nfor time-varying versions of both centralized and distributed primal-dual\ndynamics, we exploit their contractive nature to establish bounds on their\ntracking error. To support our analyses, we introduce novel results on\ncontraction theory.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 23:11:17 GMT"}, {"version": "v2", "created": "Sun, 28 Feb 2021 09:40:31 GMT"}, {"version": "v3", "created": "Sat, 19 Jun 2021 04:10:10 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Cisneros-Velarde", "Pedro", ""], ["Jafarpour", "Saber", ""], ["Bullo", "Francesco", ""]]}, {"id": "2003.12924", "submitter": "Christian Henkel", "authors": "Christian Henkel and Marc Toussaint", "title": "Optimized Directed Roadmap Graph for Multi-Agent Path Finding Using\n  Stochastic Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel approach called Optimized Directed Roadmap Graph (ODRM).\nIt is a method to build a directed roadmap graph that allows for collision\navoidance in multi-robot navigation. This is a highly relevant problem, for\nexample for industrial autonomous guided vehicles. The core idea of ODRM is,\nthat a directed roadmap can encode inherent properties of the environment which\nare useful when agents have to avoid each other in that same environment. Like\nProbabilistic Roadmaps (PRMs), ODRM's first step is generating samples from\nC-space. In a second step, ODRM optimizes vertex positions and edge directions\nby Stochastic Gradient Descent (SGD). This leads to emergent properties like\nedges parallel to walls and patterns similar to two-lane streets or\nroundabouts. Agents can then navigate on this graph by searching their path\nindependently and solving occurring agent-agent collisions at run-time. Using\nthe graphs generated by ODRM compared to a non-optimized graph significantly\nfewer agent-agent collisions happen. We evaluate our roadmap with both,\ncentralized and decentralized planners. Our experiments show that with ODRM\neven a simple centralized planner can solve problems with high numbers of\nagents that other multi-agent planners can not solve. Additionally, we use\nsimulated robots with decentralized planners and online collision avoidance to\nshow how agents are a lot faster on our roadmap than on standard grid maps.\n", "versions": [{"version": "v1", "created": "Sun, 29 Mar 2020 02:18:31 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Henkel", "Christian", ""], ["Toussaint", "Marc", ""]]}, {"id": "2003.13085", "submitter": "Yongyuan Liang", "authors": "Yongyuan Liang, Bangwei Li", "title": "Parallel Knowledge Transfer in Multi-Agent Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-agent reinforcement learning is a standard framework for modeling\nmulti-agent interactions applied in real-world scenarios. Inspired by\nexperience sharing in human groups, learning knowledge parallel reusing between\nagents can potentially promote team learning performance, especially in\nmulti-task environments. When all agents interact with the environment and\nlearn simultaneously, how each independent agent selectively learns from other\nagents' behavior knowledge is a problem that we need to solve. This paper\nproposes a novel knowledge transfer framework in MARL, PAT (Parallel\nAttentional Transfer). We design two acting modes in PAT, student mode and\nself-learning mode. Each agent in our approach trains a decentralized student\nactor-critic to determine its acting mode at each time step. When agents are\nunfamiliar with the environment, the shared attention mechanism in student mode\neffectively selects learning knowledge from other agents to decide agents'\nactions. PAT outperforms state-of-the-art empirical evaluation results against\nthe prior advising approaches. Our approach not only significantly improves\nteam learning rate and global performance, but also is flexible and\ntransferable to be applied in various multi-agent systems.\n", "versions": [{"version": "v1", "created": "Sun, 29 Mar 2020 17:42:00 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Liang", "Yongyuan", ""], ["Li", "Bangwei", ""]]}, {"id": "2003.13123", "submitter": "Laura Arditti", "authors": "Laura Arditti and Giacomo Como and Fabio Fagnani", "title": "Graphical Games and Decomposition", "comments": "4 pages, 2 figures, accepted for presentation at the 21rst IFAC World\n  Congress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DM cs.MA cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider graphical games as introduced by Kearns et al. (2001). First we\nanalyse the interaction of graphicality with a notion of strategic equivalence\nof games, providing a minimal complexity graphical description for games. Then\nwe study the interplay between graphicality and the classical decomposition of\ngames proposed by Candogan et al. (2011), characterizing the graphical\nproperties of each part of the decomposition.\n", "versions": [{"version": "v1", "created": "Sun, 29 Mar 2020 19:47:48 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Arditti", "Laura", ""], ["Como", "Giacomo", ""], ["Fagnani", "Fabio", ""]]}, {"id": "2003.13128", "submitter": "Laura Arditti", "authors": "Laura Arditti and Giacomo Como and Fabio Fagnani", "title": "Separable games", "comments": "22 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DM cs.MA cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the notion of separable game with respect to a forward directed\nhypergraph (FDH-graph), which refines and generalizes that of graphical game.\nFirst, we show that there exists a minimal FDH-graph with respect to which a\ngame is separable, providing a minimal complexity description for the game.\nThen, we prove a symmetry property of the minimal FDH-graph of potential games\nand we describe how it reflects to a decomposition of the potential function in\nterms of local functions. In particular, these last results strengthen the ones\nrecently proved for graphical potential games. Finally, we study the interplay\nbetween separability and the decomposition of finite games in their harmonic\nand potential components, characterizing the separability properties of both\nsuch components.\n", "versions": [{"version": "v1", "created": "Sun, 29 Mar 2020 20:19:35 GMT"}, {"version": "v2", "created": "Sun, 5 Apr 2020 18:36:21 GMT"}, {"version": "v3", "created": "Mon, 13 Jul 2020 16:19:23 GMT"}, {"version": "v4", "created": "Sun, 13 Dec 2020 17:57:53 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Arditti", "Laura", ""], ["Como", "Giacomo", ""], ["Fagnani", "Fabio", ""]]}, {"id": "2003.13195", "submitter": "Muhammad Aneeq Uz Zaman", "authors": "Muhammad Aneeq uz Zaman, Kaiqing Zhang, Erik Miehling, and Tamer\n  Ba\\c{s}ar", "title": "Approximate Equilibrium Computation for Discrete-Time Linear-Quadratic\n  Mean-Field Games", "comments": "This paper has been accepted in ACC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the topic of mean-field games (MFGs) has a relatively long history,\nheretofore there has been limited work concerning algorithms for the\ncomputation of equilibrium control policies. In this paper, we develop a\ncomputable policy iteration algorithm for approximating the mean-field\nequilibrium in linear-quadratic MFGs with discounted cost. Given the\nmean-field, each agent faces a linear-quadratic tracking problem, the solution\nof which involves a dynamical system evolving in retrograde time. This makes\nthe development of forward-in-time algorithm updates challenging. By\nidentifying a structural property of the mean-field update operator, namely\nthat it preserves sequences of a particular form, we develop a forward-in-time\nequilibrium computation algorithm. Bounds that quantify the accuracy of the\ncomputed mean-field equilibrium as a function of the algorithm's stopping\ncondition are provided. The optimality of the computed equilibrium is validated\nnumerically. In contrast to the most recent/concurrent results, our algorithm\nappears to be the first to study infinite-horizon MFGs with non-stationary\nmean-field equilibria, though with focus on the linear quadratic setting.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 02:53:21 GMT"}, {"version": "v2", "created": "Mon, 6 Apr 2020 16:50:18 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Zaman", "Muhammad Aneeq uz", ""], ["Zhang", "Kaiqing", ""], ["Miehling", "Erik", ""], ["Ba\u015far", "Tamer", ""]]}, {"id": "2003.13235", "submitter": "Javad Ghofrani", "authors": "Bastian Deutschmann, Javad Ghofrani, Dirk Reichelt", "title": "Cognitive Production Systems: A Mapping Study", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Production plants today are becoming more and more complicated through more\nautomation and networking. It is becoming more difficult for humans to\nparticipate, due to higher speed and decreasing reaction time of these plants.\nTendencies to improve production systems with the help of cognitive systems can\nbe identified. The goal is to save resources and time. This mapping study gives\nan insight into the domain, categorizes different approaches and estimates\ntheir progress. Furthermore, it shows achieved optimizations and persisting\nproblems and barriers. These representations should make it easier in the\nfuture to address concrete problems in this research field. Human-Machine\nInteraction and Knowledge Gaining/Sharing represent the largest categories of\nthe domain. Most often, a gain in efficiency and maximized effectiveness can be\nachieved as optimization. The most common problem is the missing or only\ndifficult generalization of the presented concepts.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 06:30:10 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 11:58:18 GMT"}, {"version": "v3", "created": "Wed, 1 Apr 2020 06:10:52 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Deutschmann", "Bastian", ""], ["Ghofrani", "Javad", ""], ["Reichelt", "Dirk", ""]]}, {"id": "2003.13314", "submitter": "Wenbo Wang", "authors": "Wenbo Wang, Amir Leshem, Dusit Niyato, Zhu Han", "title": "Decentralized Learning for Channel Allocation in IoT Networks over\n  Unlicensed Bandwidth as a Contextual Multi-player Multi-armed Bandit Game", "comments": "32 pages, 10 figures, submitted to IEEE TWC", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a decentralized channel allocation problem in an ad-hoc Internet of\nThings network underlaying on the spectrum licensed to a primary cellular\nnetwork. In the considered network, the impoverished channel sensing/probing\ncapability and computational resource on the IoT devices make them difficult to\nacquire the detailed Channel State Information (CSI) for the shared multiple\nchannels. In practice, the unknown patterns of the primary users' transmission\nactivities and the time-varying CSI (e.g., due to small-scale fading or device\nmobility) also cause stochastic changes in the channel quality. Decentralized\nIoT links are thus expected to learn channel conditions online based on partial\nobservations, while acquiring no information about the channels that they are\nnot operating on. They also have to reach an efficient, collision-free solution\nof channel allocation with limited coordination. Our study maps this problem\ninto a contextual multi-player, multi-armed bandit game, and proposes a purely\ndecentralized, three-stage policy learning algorithm through trial-and-error.\nTheoretical analyses shows that the proposed scheme guarantees the IoT links to\njointly converge to the social optimal channel allocation with a sub-linear\n(i.e., polylogarithmic) regret with respect to the operational time.\nSimulations demonstrate that it strikes a good balance between efficiency and\nnetwork scalability when compared with the other state-of-the-art decentralized\nbandit algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 10:05:35 GMT"}, {"version": "v2", "created": "Sat, 4 Apr 2020 08:12:11 GMT"}, {"version": "v3", "created": "Thu, 1 Jul 2021 10:16:15 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Wang", "Wenbo", ""], ["Leshem", "Amir", ""], ["Niyato", "Dusit", ""], ["Han", "Zhu", ""]]}, {"id": "2003.13676", "submitter": "Pieter Libin", "authors": "Pieter Libin, Arno Moonens, Timothy Verstraeten, Fabian\n  Perez-Sanjines, Niel Hens, Philippe Lemey, Ann Now\\'e", "title": "Deep reinforcement learning for large-scale epidemic control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Epidemics of infectious diseases are an important threat to public health and\nglobal economies. Yet, the development of prevention strategies remains a\nchallenging process, as epidemics are non-linear and complex processes. For\nthis reason, we investigate a deep reinforcement learning approach to\nautomatically learn prevention strategies in the context of pandemic influenza.\nFirstly, we construct a new epidemiological meta-population model, with 379\npatches (one for each administrative district in Great Britain), that\nadequately captures the infection process of pandemic influenza. Our model\nbalances complexity and computational efficiency such that the use of\nreinforcement learning techniques becomes attainable. Secondly, we set up a\nground truth such that we can evaluate the performance of the 'Proximal Policy\nOptimization' algorithm to learn in a single district of this epidemiological\nmodel. Finally, we consider a large-scale problem, by conducting an experiment\nwhere we aim to learn a joint policy to control the districts in a community of\n11 tightly coupled districts, for which no ground truth can be established.\nThis experiment shows that deep reinforcement learning can be used to learn\nmitigation policies in complex epidemiological models with a large state space.\nMoreover, through this experiment, we demonstrate that there can be an\nadvantage to consider collaboration between districts when designing prevention\nstrategies.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 17:57:09 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Libin", "Pieter", ""], ["Moonens", "Arno", ""], ["Verstraeten", "Timothy", ""], ["Perez-Sanjines", "Fabian", ""], ["Hens", "Niel", ""], ["Lemey", "Philippe", ""], ["Now\u00e9", "Ann", ""]]}, {"id": "2003.13806", "submitter": "Luca Capezzuto", "authors": "Luca Capezzuto and Danesh Tarapore and Sarvapali D. Ramchurn", "title": "Anytime and Efficient Coalition Formation with Spatial and Temporal\n  Constraints", "comments": "18 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Coalition Formation with Spatial and Temporal constraints Problem (CFSTP)\nis a multi-agent task scheduling problem where the tasks are spatially\ndistributed, with deadlines and workloads, and the number of agents is\ntypically much smaller than the number of tasks, thus the agents have to form\ncoalitions in order to maximise the number of completed tasks. The current\nstate-of-the-art CFSTP solver, the Coalition Formation with Look-Ahead (CFLA)\nalgorithm, has two main limitations. First, its time complexity is exponential\nwith the number of agents. Second, as we show, its look-ahead technique is not\neffective in real-world scenarios, such as open multi-agent systems, where new\ntasks can appear at any time. In this work, we study its design and define an\nextension, called Coalition Formation with Improved Look-Ahead (CFLA2), which\nachieves better performance. Since we cannot eliminate the limitations of CFLA\nin CFLA2, we also develop a novel algorithm to solve the CFSTP, the first to be\nanytime, efficient and with provable guarantees, called Cluster-based Coalition\nFormation (CCF). We empirically show that, in settings where the look-ahead\ntechnique is highly effective, CCF completes up to 30% (resp. 10%) more tasks\nthan CFLA (resp. CFLA2) while being up to four orders of magnitude faster. Our\nresults affirm CCF as the new state-of-the-art algorithm to solve the CFSTP.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 20:42:56 GMT"}, {"version": "v2", "created": "Thu, 2 Apr 2020 22:13:51 GMT"}, {"version": "v3", "created": "Thu, 13 Aug 2020 16:23:55 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Capezzuto", "Luca", ""], ["Tarapore", "Danesh", ""], ["Ramchurn", "Sarvapali D.", ""]]}, {"id": "2003.13813", "submitter": "Federico Rossi", "authors": "Federico Rossi and Tiago Stegun Vaquero and Marc Sanchez Net and\n  Ma\\'ira Saboia da Silva and Joshua Vander Hook", "title": "The Pluggable Distributed Resource Allocator (PDRA): a Middleware for\n  Distributed Computing in Mobile Robotic Networks", "comments": "Extended version of manuscript presented at IROS 2020. In v2,\n  numerical results are updated and parts of the paper are rewritten and\n  expanded for clarity. In v3, a minor author metadata error is fixed. All code\n  is available under Apache license at https://github.com/nasa/mosaic", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the Pluggable Distributed Resource Allocator (PDRA), a middleware\nfor distributed computing in heterogeneous mobile robotic networks. PDRA\nenables autonomous robotic agents to share computational resources for\ncomputationally expensive tasks such as localization and path planning. It sits\nbetween an existing single-agent planner/executor and existing computational\nresources (e.g. ROS packages), intercepts the executor's requests and, if\nneeded, transparently routes them to other robots for execution. PDRA is\npluggable: it can be integrated in an existing single-robot autonomy stack with\nminimal modifications. Task allocation decisions are performed by a\nmixed-integer programming algorithm, solved in a shared-world fashion, that\nmodels CPU resources, latency requirements, and multi-hop, periodic,\nbandwidth-limited network communications; the algorithm can minimize overall\nenergy usage or maximize the reward for completing optional tasks. Simulation\nresults show that PDRA can reduce energy and CPU usage by over 50% in\nrepresentative multi-robot scenarios compared to a naive scheduler; runs on\nembedded platforms; and performs well in delay- and disruption-tolerant\nnetworks (DTNs). PDRA is available to the community under an open-source\nlicense.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 20:59:55 GMT"}, {"version": "v2", "created": "Sat, 1 Aug 2020 06:35:41 GMT"}, {"version": "v3", "created": "Mon, 26 Oct 2020 23:23:31 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Rossi", "Federico", ""], ["Vaquero", "Tiago Stegun", ""], ["Net", "Marc Sanchez", ""], ["da Silva", "Ma\u00edra Saboia", ""], ["Hook", "Joshua Vander", ""]]}, {"id": "2003.13924", "submitter": "Jiachen Li", "authors": "Jiachen Li and Fan Yang and Masayoshi Tomizuka and Chiho Choi", "title": "EvolveGraph: Multi-Agent Trajectory Prediction with Dynamic Relational\n  Reasoning", "comments": "NeurIPS 2020. Website:\n  https://jiachenli94.github.io/publications/Evolvegraph/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-agent interacting systems are prevalent in the world, from pure\nphysical systems to complicated social dynamic systems. In many applications,\neffective understanding of the situation and accurate trajectory prediction of\ninteractive agents play a significant role in downstream tasks, such as\ndecision making and planning. In this paper, we propose a generic trajectory\nforecasting framework (named EvolveGraph) with explicit relational structure\nrecognition and prediction via latent interaction graphs among multiple\nheterogeneous, interactive agents. Considering the uncertainty of future\nbehaviors, the model is designed to provide multi-modal prediction hypotheses.\nSince the underlying interactions may evolve even with abrupt changes, and\ndifferent modalities of evolution may lead to different outcomes, we address\nthe necessity of dynamic relational reasoning and adaptively evolving the\ninteraction graphs. We also introduce a double-stage training pipeline which\nnot only improves training efficiency and accelerates convergence, but also\nenhances model performance. The proposed framework is evaluated on both\nsynthetic physics simulations and multiple real-world benchmark datasets in\nvarious areas. The experimental results illustrate that our approach achieves\nstate-of-the-art performance in terms of prediction accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 02:49:23 GMT"}, {"version": "v2", "created": "Mon, 13 Apr 2020 07:28:20 GMT"}, {"version": "v3", "created": "Thu, 1 Oct 2020 17:42:10 GMT"}, {"version": "v4", "created": "Thu, 22 Oct 2020 16:02:44 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Li", "Jiachen", ""], ["Yang", "Fan", ""], ["Tomizuka", "Masayoshi", ""], ["Choi", "Chiho", ""]]}, {"id": "2003.13980", "submitter": "Shi Pu", "authors": "Shi Pu", "title": "A Robust Gradient Tracking Method for Distributed Optimization over\n  Directed Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DC cs.MA cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of distributed consensus optimization\nover multi-agent networks with directed network topology. Assuming each agent\nhas a local cost function that is smooth and strongly convex, the global\nobjective is to minimize the average of all the local cost functions. To solve\nthe problem, we introduce a robust gradient tracking method (R-Push-Pull)\nadapted from the recently proposed Push-Pull/AB algorithm. R-Push-Pull inherits\nthe advantages of Push-Pull and enjoys linear convergence to the optimal\nsolution with exact communication. Under noisy information exchange,\nR-Push-Pull is more robust than the existing gradient tracking based\nalgorithms; the solutions obtained by each agent reach a neighborhood of the\noptimum in expectation exponentially fast under a constant stepsize policy. We\nprovide a numerical example that demonstrate the effectiveness of R-Push-Pull.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 06:48:04 GMT"}, {"version": "v2", "created": "Wed, 6 May 2020 04:09:18 GMT"}, {"version": "v3", "created": "Thu, 20 Aug 2020 09:40:12 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Pu", "Shi", ""]]}, {"id": "2003.14027", "submitter": "Rohit Murali", "authors": "Rohit Murali, Suravi Patnaik, Stephen Cranefield", "title": "Mining International Political Norms from the GDELT Database", "comments": "16 pages, 2 figures, pre-print for International Workshop on\n  Coordination, Organizations, Institutions, Norms and Ethics for Governance of\n  Multi-Agent Systems (COINE), co-located with AAMAS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Researchers have long been interested in the role that norms can play in\ngoverning agent actions in multi-agent systems. Much work has been done on\nformalising normative concepts from human society and adapting them for the\ngovernment of open software systems, and on the simulation of normative\nprocesses in human and artificial societies. However, there has been\ncomparatively little work on applying normative MAS mechanisms to understanding\nthe norms in human society.\n  This work investigates this issue in the context of international politics.\nUsing the GDELT dataset, containing machine-encoded records of international\nevents extracted from news reports, we extracted bilateral sequences of\ninter-country events and applied a Bayesian norm mining mechanism to identify\nnorms that best explained the observed behaviour. A statistical evaluation\nshowed that the normative model fitted the data significantly better than a\nprobabilistic discrete event model.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 08:48:37 GMT"}, {"version": "v2", "created": "Mon, 20 Apr 2020 16:11:13 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Murali", "Rohit", ""], ["Patnaik", "Suravi", ""], ["Cranefield", "Stephen", ""]]}, {"id": "2003.14133", "submitter": "Juste Raimbault", "authors": "J. Raimbault, J. Broere, M. Somveille, J. M. Serna, E. Strombom, C.\n  Moore, B. Zhu, L. Sugar", "title": "A spatial agent based model for simulating and optimizing networked\n  eco-industrial systems", "comments": "23 pages, 9 figures, 2 tables", "journal-ref": "Resources, Conservation and Recycling, 155, 104538 (2020)", "doi": "10.1016/j.resconrec.2019.104538", "report-no": null, "categories": "physics.soc-ph cs.MA econ.GN q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Industrial symbiosis involves creating integrated cycles of by-products and\nwaste between networks of industrial actors in order to maximize economic\nvalue, while at the same time minimizing environmental strain. In such a\nnetwork, the global environmental strain is no longer equal to the sum of the\nenvironmental strain of the individual actors, but it is dependent on how well\nthe network performs as a whole. The development of methods to understand,\nmanage or optimize such networks remains an open issue. In this paper we put\nforward a simulation model of by-product flow between industrial actors. The\ngoal is to introduce a method for modelling symbiotic exchanges from a macro\nperspective. The model takes into account the effect of two main mechanisms on\na multi-objective optimization of symbiotic processes. First it allows us to\nstudy the effect of geographical properties of the economic system, said\ndifferently, where actors are divided in space. Second, it allows us to study\nthe effect of clustering complementary actors together as a function of\ndistance, by means of a spatial correlation between the actors' by-products.\nOur simulations unveil patterns that are relevant for macro-level policy.\nFirst, our results show that the geographical properties are an important\nfactor for the macro performance of symbiotic processes. Second, spatial\ncorrelations, which can be interpreted as planned clusters such as\nEco-industrial parks, can lead to a very effective macro performance, but only\nif these are strictly implemented. Finally, we provide a proof of concept by\ncomparing the model to real world data from the European Pollutant Release and\nTransfer Register database using georeferencing of the companies in the\ndataset. This work opens up research opportunities in interactive data-driven\nmodels and platforms to support real-world implementation of industrial\nsymbiosis.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 12:10:37 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Raimbault", "J.", ""], ["Broere", "J.", ""], ["Somveille", "M.", ""], ["Serna", "J. M.", ""], ["Strombom", "E.", ""], ["Moore", "C.", ""], ["Zhu", "B.", ""], ["Sugar", "L.", ""]]}, {"id": "2003.14366", "submitter": "Stefan Vlaski", "authors": "Stefan Vlaski and Ali H. Sayed", "title": "Second-Order Guarantees in Centralized, Federated and Decentralized\n  Nonconvex Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.LG eess.SP math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rapid advances in data collection and processing capabilities have allowed\nfor the use of increasingly complex models that give rise to nonconvex\noptimization problems. These formulations, however, can be arbitrarily\ndifficult to solve in general, in the sense that even simply verifying that a\ngiven point is a local minimum can be NP-hard [1]. Still, some relatively\nsimple algorithms have been shown to lead to surprisingly good empirical\nresults in many contexts of interest. Perhaps the most prominent example is the\nsuccess of the backpropagation algorithm for training neural networks. Several\nrecent works have pursued rigorous analytical justification for this phenomenon\nby studying the structure of the nonconvex optimization problems and\nestablishing that simple algorithms, such as gradient descent and its\nvariations, perform well in converging towards local minima and avoiding\nsaddle-points. A key insight in these analyses is that gradient perturbations\nplay a critical role in allowing local descent algorithms to efficiently\ndistinguish desirable from undesirable stationary points and escape from the\nlatter. In this article, we cover recent results on second-order guarantees for\nstochastic first-order optimization algorithms in centralized, federated, and\ndecentralized architectures.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 16:54:22 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Vlaski", "Stefan", ""], ["Sayed", "Ali H.", ""]]}]