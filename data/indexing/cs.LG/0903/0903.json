[{"id": "0903.0064", "submitter": "Xiang Yan", "authors": "Xiang Yan, Benjamin Van Roy", "title": "Manipulation Robustness of Collaborative Filtering Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A collaborative filtering system recommends to users products that similar\nusers like. Collaborative filtering systems influence purchase decisions, and\nhence have become targets of manipulation by unscrupulous vendors. We provide\ntheoretical and empirical results demonstrating that while common nearest\nneighbor algorithms, which are widely used in commercial systems, can be highly\nsusceptible to manipulation, two classes of collaborative filtering algorithms\nwhich we refer to as linear and asymptotically linear are relatively robust.\nThese results provide guidance for the design of future collaborative filtering\nsystems.\n", "versions": [{"version": "v1", "created": "Sat, 28 Feb 2009 11:17:12 GMT"}, {"version": "v2", "created": "Sun, 19 Apr 2009 04:18:30 GMT"}], "update_date": "2009-04-19", "authors_parsed": [["Yan", "Xiang", ""], ["Van Roy", "Benjamin", ""]]}, {"id": "0903.1125", "submitter": "Aharon Bar Hillel", "authors": "Ran Gilad-Bachrach, Aharon Bar-Hillel, Liat Ein-Dor", "title": "Efficient Human Computation", "comments": "8 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collecting large labeled data sets is a laborious and expensive task, whose\nscaling up requires division of the labeling workload between many teachers.\nWhen the number of classes is large, miscorrespondences between the labels\ngiven by the different teachers are likely to occur, which, in the extreme\ncase, may reach total inconsistency. In this paper we describe how globally\nconsistent labels can be obtained, despite the absence of teacher coordination,\nand discuss the possible efficiency of this process in terms of human labor. We\ndefine a notion of label efficiency, measuring the ratio between the number of\nglobally consistent labels obtained and the number of labels provided by\ndistributed teachers. We show that the efficiency depends critically on the\nratio alpha between the number of data instances seen by a single teacher, and\nthe number of classes. We suggest several algorithms for the distributed\nlabeling problem, and analyze their efficiency as a function of alpha. In\naddition, we provide an upper bound on label efficiency for the case of\ncompletely uncoordinated teachers, and show that efficiency approaches 0 as the\nratio between the number of labels each teacher provides and the number of\nclasses drops (i.e. alpha goes to 0).\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2009 22:39:46 GMT"}], "update_date": "2009-03-09", "authors_parsed": [["Gilad-Bachrach", "Ran", ""], ["Bar-Hillel", "Aharon", ""], ["Ein-Dor", "Liat", ""]]}, {"id": "0903.2282", "submitter": "Ian Kash", "authors": "Ian A. Kash, Eric J. Friedman, Joseph Y. Halpern", "title": "Multiagent Learning in Large Anonymous Games", "comments": "8 pages, 2 figures. To Appear in Proceedings of the Eighth\n  International Conference on Autonomous Agents and Multiagent Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In large systems, it is important for agents to learn to act effectively, but\nsophisticated multi-agent learning algorithms generally do not scale. An\nalternative approach is to find restricted classes of games where simple,\nefficient algorithms converge. It is shown that stage learning efficiently\nconverges to Nash equilibria in large anonymous games if best-reply dynamics\nconverge. Two features are identified that improve convergence. First, rather\nthan making learning more difficult, more agents are actually beneficial in\nmany settings. Second, providing agents with statistical information about the\nbehavior of others can significantly reduce the number of observations needed.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2009 21:49:36 GMT"}], "update_date": "2009-03-16", "authors_parsed": [["Kash", "Ian A.", ""], ["Friedman", "Eric J.", ""], ["Halpern", "Joseph Y.", ""]]}, {"id": "0903.2299", "submitter": "David  McAllester", "authors": "David McAllester", "title": "Differential Contrastive Divergence", "comments": "This paper was a rediscovery of known material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper has been retracted.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2009 13:47:03 GMT"}, {"version": "v2", "created": "Fri, 20 Mar 2009 01:33:43 GMT"}, {"version": "v3", "created": "Mon, 8 Jul 2013 15:17:20 GMT"}], "update_date": "2013-07-09", "authors_parsed": [["McAllester", "David", ""]]}, {"id": "0903.2851", "submitter": "Kamalika Chaudhuri", "authors": "Kamalika Chaudhuri, Yoav Freund, Daniel Hsu", "title": "A parameter-free hedging algorithm", "comments": "Updated Version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of decision-theoretic online learning (DTOL). Motivated\nby practical applications, we focus on DTOL when the number of actions is very\nlarge. Previous algorithms for learning in this framework have a tunable\nlearning rate parameter, and a barrier to using online-learning in practical\napplications is that it is not understood how to set this parameter optimally,\nparticularly when the number of actions is large.\n  In this paper, we offer a clean solution by proposing a novel and completely\nparameter-free algorithm for DTOL. We introduce a new notion of regret, which\nis more natural for applications with a large number of actions. We show that\nour algorithm achieves good performance with respect to this new notion of\nregret; in addition, it also achieves performance close to that of the best\nbounds achieved by previous algorithms with optimally-tuned parameters,\naccording to previous notions of regret.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2009 20:48:33 GMT"}, {"version": "v2", "created": "Mon, 18 Jan 2010 23:58:51 GMT"}], "update_date": "2010-01-19", "authors_parsed": [["Chaudhuri", "Kamalika", ""], ["Freund", "Yoav", ""], ["Hsu", "Daniel", ""]]}, {"id": "0903.2862", "submitter": "Kamalika Chaudhuri", "authors": "Kamalika Chaudhuri, Yoav Freund, Daniel Hsu", "title": "Tracking using explanation-based modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the tracking problem, namely, estimating the hidden state of an\nobject over time, from unreliable and noisy measurements. The standard\nframework for the tracking problem is the generative framework, which is the\nbasis of solutions such as the Bayesian algorithm and its approximation, the\nparticle filters. However, the problem with these solutions is that they are\nvery sensitive to model mismatches. In this paper, motivated by online\nlearning, we introduce a new framework -- an {\\em explanatory} framework -- for\ntracking. We provide an efficient tracking algorithm for this framework. We\nprovide experimental results comparing our algorithm to the Bayesian algorithm\non simulated data. Our experiments show that when there are slight model\nmismatches, our algorithm vastly outperforms the Bayesian algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2009 21:26:55 GMT"}, {"version": "v2", "created": "Tue, 19 Jan 2010 00:15:59 GMT"}], "update_date": "2010-01-19", "authors_parsed": [["Chaudhuri", "Kamalika", ""], ["Freund", "Yoav", ""], ["Hsu", "Daniel", ""]]}, {"id": "0903.2870", "submitter": "Patrick Erik Bradley", "authors": "Patrick Erik Bradley", "title": "On $p$-adic Classification", "comments": "16 pages, 7 figures, 1 table; added reference, corrected typos, minor\n  content changes", "journal-ref": "p-Adic Numbers, Ultrametric Analysis, and Applications, Vol. 1,\n  No. 4 (2009), 271-285", "doi": "10.1134/S2070046609040013", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A $p$-adic modification of the split-LBG classification method is presented\nin which first clusterings and then cluster centers are computed which locally\nminimise an energy function. The outcome for a fixed dataset is independent of\nthe prime number $p$ with finitely many exceptions. The methods are applied to\nthe construction of $p$-adic classifiers in the context of learning.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2009 22:52:06 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2009 14:10:45 GMT"}], "update_date": "2009-12-01", "authors_parsed": [["Bradley", "Patrick Erik", ""]]}, {"id": "0903.2890", "submitter": "Soummya Kar", "authors": "Soummya Kar, Bruno Sinopoli, and Jose M. F. Moura", "title": "Kalman Filtering with Intermittent Observations: Weak Convergence to a\n  Stationary Distribution", "comments": "Submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper studies the asymptotic behavior of Random Algebraic Riccati\nEquations (RARE) arising in Kalman filtering when the arrival of the\nobservations is described by a Bernoulli i.i.d. process. We model the RARE as\nan order-preserving, strongly sublinear random dynamical system (RDS). Under a\nsufficient condition, stochastic boundedness, and using a limit-set dichotomy\nresult for order-preserving, strongly sublinear RDS, we establish the\nasymptotic properties of the RARE: the sequence of random prediction error\ncovariance matrices converges weakly to a unique invariant distribution, whose\nsupport exhibits fractal behavior. In particular, this weak convergence holds\nunder broad conditions and even when the observations arrival rate is below the\ncritical probability for mean stability. We apply the weak-Feller property of\nthe Markov process governing the RARE to characterize the support of the\nlimiting invariant distribution as the topological closure of a countable set\nof points, which, in general, is not dense in the set of positive semi-definite\nmatrices. We use the explicit characterization of the support of the invariant\ndistribution and the almost sure ergodicity of the sample paths to easily\ncompute the moments of the invariant distribution. A one dimensional example\nillustrates that the support is a fractured subset of the non-negative reals\nwith self-similarity properties.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2009 01:39:01 GMT"}, {"version": "v2", "created": "Fri, 28 May 2010 08:33:21 GMT"}], "update_date": "2010-05-31", "authors_parsed": [["Kar", "Soummya", ""], ["Sinopoli", "Bruno", ""], ["Moura", "Jose M. F.", ""]]}, {"id": "0903.2972", "submitter": "Ivo Danihelka", "authors": "Ivo Danihelka", "title": "Optimistic Simulated Exploration as an Incentive for Real Exploration", "comments": "accepted, noted that the initial path was 217 steps long", "journal-ref": "POSTER 2009", "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many reinforcement learning exploration techniques are overly optimistic and\ntry to explore every state. Such exploration is impossible in environments with\nthe unlimited number of states. I propose to use simulated exploration with an\noptimistic model to discover promising paths for real exploration. This reduces\nthe needs for the real exploration.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2009 14:24:13 GMT"}, {"version": "v2", "created": "Thu, 19 Mar 2009 13:31:55 GMT"}, {"version": "v3", "created": "Wed, 20 May 2009 18:44:07 GMT"}], "update_date": "2009-05-20", "authors_parsed": [["Danihelka", "Ivo", ""]]}, {"id": "0903.3103", "submitter": "Chunhua Shen", "authors": "Chunhua Shen, Sakrapee Paisitkriangkrai, and Jian Zhang", "title": "Efficiently Learning a Detection Cascade with Sparse Eigenvectors", "comments": "12 pages, conference version published in CVPR2009", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we first show that feature selection methods other than\nboosting can also be used for training an efficient object detector. In\nparticular, we introduce Greedy Sparse Linear Discriminant Analysis (GSLDA)\n\\cite{Moghaddam2007Fast} for its conceptual simplicity and computational\nefficiency; and slightly better detection performance is achieved compared with\n\\cite{Viola2004Robust}. Moreover, we propose a new technique, termed Boosted\nGreedy Sparse Linear Discriminant Analysis (BGSLDA), to efficiently train a\ndetection cascade. BGSLDA exploits the sample re-weighting property of boosting\nand the class-separability criterion of GSLDA.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2009 08:17:05 GMT"}], "update_date": "2009-03-19", "authors_parsed": [["Shen", "Chunhua", ""], ["Paisitkriangkrai", "Sakrapee", ""], ["Zhang", "Jian", ""]]}, {"id": "0903.3257", "submitter": "Marcus Hutter", "authors": "Ke Zhang and Marcus Hutter and Huidong Jin", "title": "A New Local Distance-Based Outlier Detection Approach for Scattered\n  Real-World Data", "comments": "15 LaTeX pages, 7 figures, 2 tables, 1 algorithm, 2 theorems", "journal-ref": "Proc. 13th Pacific-Asia Conf. on Knowledge Discovery and Data\n  Mining (PAKDD 2009) pages 813-822", "doi": null, "report-no": null, "categories": "cs.LG cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting outliers which are grossly different from or inconsistent with the\nremaining dataset is a major challenge in real-world KDD applications. Existing\noutlier detection methods are ineffective on scattered real-world datasets due\nto implicit data patterns and parameter setting issues. We define a novel\n\"Local Distance-based Outlier Factor\" (LDOF) to measure the {outlier-ness} of\nobjects in scattered datasets which addresses these issues. LDOF uses the\nrelative location of an object to its neighbours to determine the degree to\nwhich the object deviates from its neighbourhood. Properties of LDOF are\ntheoretically analysed including LDOF's lower bound and its false-detection\nprobability, as well as parameter settings. In order to facilitate parameter\nsettings in real-world applications, we employ a top-n technique in our outlier\ndetection approach, where only the objects with the highest LDOF values are\nregarded as outliers. Compared to conventional approaches (such as top-n KNN\nand top-n LOF), our method top-n LDOF is more effective at detecting outliers\nin scattered data. It is also easier to set parameters, since its performance\nis relatively stable over a large range of parameter values, as illustrated by\nexperimental results on both real-world and synthetic datasets.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2009 23:50:29 GMT"}], "update_date": "2009-12-30", "authors_parsed": [["Zhang", "Ke", ""], ["Hutter", "Marcus", ""], ["Jin", "Huidong", ""]]}, {"id": "0903.3329", "submitter": "Emmanuel Duflos", "authors": "Thomas Br\\'ehard (INRIA Futurs), Emmanuel Duflos (INRIA Futurs,\n  LAGIS), Philippe Vanheeghe (LAGIS), Pierre-Arnaud Coquelin (INRIA Futurs)", "title": "Optimal Policies Search for Sensor Management", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new approach to solve sensor management problems.\nClassically sensor management problems can be well formalized as\nPartially-Observed Markov Decision Processes (POMPD). The original approach\ndevelopped here consists in deriving the optimal parameterized policy based on\na stochastic gradient estimation. We assume in this work that it is possible to\nlearn the optimal policy off-line (in simulation) using models of the\nenvironement and of the sensor(s). The learned policy can then be used to\nmanage the sensor(s). In order to approximate the gradient in a stochastic\ncontext, we introduce a new method to approximate the gradient, based on\nInfinitesimal Perturbation Approximation (IPA). The effectiveness of this\ngeneral framework is illustrated by the managing of an Electronically Scanned\nArray Radar. First simulations results are finally proposed.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2009 13:44:35 GMT"}], "update_date": "2009-03-20", "authors_parsed": [["Br\u00e9hard", "Thomas", "", "INRIA Futurs"], ["Duflos", "Emmanuel", "", "INRIA Futurs,\n  LAGIS"], ["Vanheeghe", "Philippe", "", "LAGIS"], ["Coquelin", "Pierre-Arnaud", "", "INRIA Futurs"]]}, {"id": "0903.3667", "submitter": "Joel Ratsaby", "authors": "Joel Ratsaby", "title": "How random are a learner's mistakes?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a random binary sequence $X^{(n)}$ of random variables, $X_{t},$\n$t=1,2,...,n$, for instance, one that is generated by a Markov source (teacher)\nof order $k^{*}$ (each state represented by $k^{*}$ bits). Assume that the\nprobability of the event $X_{t}=1$ is constant and denote it by $\\beta$.\nConsider a learner which is based on a parametric model, for instance a Markov\nmodel of order $k$, who trains on a sequence $x^{(m)}$ which is randomly drawn\nby the teacher. Test the learner's performance by giving it a sequence\n$x^{(n)}$ (generated by the teacher) and check its predictions on every bit of\n$x^{(n)}.$ An error occurs at time $t$ if the learner's prediction $Y_{t}$\ndiffers from the true bit value $X_{t}$. Denote by $\\xi^{(n)}$ the sequence of\nerrors where the error bit $\\xi_{t}$ at time $t$ equals 1 or 0 according to\nwhether the event of an error occurs or not, respectively. Consider the\nsubsequence $\\xi^{(\\nu)}$ of $\\xi^{(n)}$ which corresponds to the errors of\npredicting a 0, i.e., $\\xi^{(\\nu)}$ consists of the bits of $\\xi^{(n)}$ only at\ntimes $t$ such that $Y_{t}=0.$ In this paper we compute an estimate on the\ndeviation of the frequency of 1s of $\\xi^{(\\nu)}$ from $\\beta$. The result\nshows that the level of randomness of $\\xi^{(\\nu)}$ decreases relative to an\nincrease in the complexity of the learner.\n", "versions": [{"version": "v1", "created": "Sat, 21 Mar 2009 14:16:05 GMT"}, {"version": "v2", "created": "Sat, 28 Mar 2009 22:01:59 GMT"}, {"version": "v3", "created": "Sat, 4 Apr 2009 20:52:10 GMT"}, {"version": "v4", "created": "Tue, 29 Sep 2009 11:03:00 GMT"}, {"version": "v5", "created": "Sun, 2 Jan 2011 08:43:03 GMT"}], "update_date": "2011-01-04", "authors_parsed": [["Ratsaby", "Joel", ""]]}, {"id": "0903.4217", "submitter": "John Langford", "authors": "Alina Beygelzimer, John Langford, Yuri Lifshits, Gregory Sorkin, and\n  Alex Strehl", "title": "Conditional Probability Tree Estimation Analysis and Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimating the conditional probability of a label\nin time $O(\\log n)$, where $n$ is the number of possible labels. We analyze a\nnatural reduction of this problem to a set of binary regression problems\norganized in a tree structure, proving a regret bound that scales with the\ndepth of the tree. Motivated by this analysis, we propose the first online\nalgorithm which provably constructs a logarithmic depth tree on the set of\nlabels to solve this problem. We test the algorithm empirically, showing that\nit works succesfully on a dataset with roughly $10^6$ labels.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2009 00:28:44 GMT"}, {"version": "v2", "created": "Wed, 3 Jun 2009 21:19:34 GMT"}], "update_date": "2009-06-04", "authors_parsed": [["Beygelzimer", "Alina", ""], ["Langford", "John", ""], ["Lifshits", "Yuri", ""], ["Sorkin", "Gregory", ""], ["Strehl", "Alex", ""]]}, {"id": "0903.4527", "submitter": "Yusuke Watanabe", "authors": "Yusuke Watanabe, Kenji Fukumizu", "title": "Graph polynomials and approximation of partition functions with Loopy\n  Belief Propagation", "comments": "7 pages. The 9th conference of Japanese Society for Artificial\n  Intelligence, Special Interest Group on Data Mining and Statistical\n  Mathematics (JSAI SIG-DMSM) in Kyoto 2009, March 3,4 Minor typos corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Bethe approximation, or loopy belief propagation algorithm is a\nsuccessful method for approximating partition functions of probabilistic models\nassociated with a graph. Chertkov and Chernyak derived an interesting formula\ncalled Loop Series Expansion, which is an expansion of the partition function.\nThe main term of the series is the Bethe approximation while other terms are\nlabeled by subgraphs called generalized loops. In our recent paper, we derive\nthe loop series expansion in form of a polynomial with coefficients positive\nintegers, and extend the result to the expansion of marginals. In this paper,\nwe give more clear derivation for the results and discuss the properties of the\npolynomial which is introduced in the paper.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2009 08:32:33 GMT"}, {"version": "v2", "created": "Sat, 14 Nov 2009 05:41:45 GMT"}], "update_date": "2009-11-14", "authors_parsed": [["Watanabe", "Yusuke", ""], ["Fukumizu", "Kenji", ""]]}, {"id": "0903.4817", "submitter": "Martin Jaggi", "authors": "Bernd G\\\"artner, Martin Jaggi and Cl\\'ement Maria", "title": "An Exponential Lower Bound on the Complexity of Regularization Paths", "comments": "Journal version, 28 Pages, 5 Figures", "journal-ref": "Journal of Computational Geometry (JoCG) 3(1), 168-195, 2012", "doi": null, "report-no": null, "categories": "cs.LG cs.CG cs.CV math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a variety of regularized optimization problems in machine learning,\nalgorithms computing the entire solution path have been developed recently.\nMost of these methods are quadratic programs that are parameterized by a single\nparameter, as for example the Support Vector Machine (SVM). Solution path\nalgorithms do not only compute the solution for one particular value of the\nregularization parameter but the entire path of solutions, making the selection\nof an optimal parameter much easier.\n  It has been assumed that these piecewise linear solution paths have only\nlinear complexity, i.e. linearly many bends. We prove that for the support\nvector machine this complexity can be exponential in the number of training\npoints in the worst case. More strongly, we construct a single instance of n\ninput points in d dimensions for an SVM such that at least \\Theta(2^{n/2}) =\n\\Theta(2^d) many distinct subsets of support vectors occur as the\nregularization parameter changes.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2009 17:23:31 GMT"}, {"version": "v2", "created": "Thu, 4 Nov 2010 14:16:36 GMT"}, {"version": "v3", "created": "Thu, 25 Oct 2012 23:47:12 GMT"}], "update_date": "2012-10-31", "authors_parsed": [["G\u00e4rtner", "Bernd", ""], ["Jaggi", "Martin", ""], ["Maria", "Cl\u00e9ment", ""]]}, {"id": "0903.4856", "submitter": "Martin Jaggi", "authors": "Bernd G\\\"artner, Joachim Giesen, Martin Jaggi and Torsten Welsch", "title": "A Combinatorial Algorithm to Compute Regularization Paths", "comments": "7 Pages, 1 Figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a wide variety of regularization methods, algorithms computing the entire\nsolution path have been developed recently. Solution path algorithms do not\nonly compute the solution for one particular value of the regularization\nparameter but the entire path of solutions, making the selection of an optimal\nparameter much easier. Most of the currently used algorithms are not robust in\nthe sense that they cannot deal with general or degenerate input. Here we\npresent a new robust, generic method for parametric quadratic programming. Our\nalgorithm directly applies to nearly all machine learning applications, where\nso far every application required its own different algorithm.\n  We illustrate the usefulness of our method by applying it to a very low rank\nproblem which could not be solved by existing path tracking methods, namely to\ncompute part-worth values in choice based conjoint analysis, a popular\ntechnique from market research to estimate consumers preferences on a class of\nparameterized options.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2009 18:16:04 GMT"}], "update_date": "2009-03-30", "authors_parsed": [["G\u00e4rtner", "Bernd", ""], ["Giesen", "Joachim", ""], ["Jaggi", "Martin", ""], ["Welsch", "Torsten", ""]]}, {"id": "0903.4860", "submitter": "Cyril Furtlehner", "authors": "Cyril Furtlehner, Jean-Marc Lasgouttes and Anne Auger", "title": "Learning Multiple Belief Propagation Fixed Points for Real Time\n  Inference", "comments": "RR Inria 6887, 26 pages, 7 figures", "journal-ref": "Physica A. Vol. 389(1), pp. 149-163 (2010)", "doi": "10.1016/j.physa.2009.08.030", "report-no": null, "categories": "cs.LG cond-mat.dis-nn physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of inference with expectation constraints, we propose an\napproach based on the \"loopy belief propagation\" algorithm LBP, as a surrogate\nto an exact Markov Random Field MRF modelling. A prior information composed of\ncorrelations among a large set of N variables, is encoded into a graphical\nmodel; this encoding is optimized with respect to an approximate decoding\nprocedure LBP, which is used to infer hidden variables from an observed subset.\nWe focus on the situation where the underlying data have many different\nstatistical components, representing a variety of independent patterns.\nConsidering a single parameter family of models we show how LBP may be used to\nencode and decode efficiently such information, without solving the NP hard\ninverse problem yielding the optimal MRF. Contrary to usual practice, we work\nin the non-convex Bethe free energy minimization framework, and manage to\nassociate a belief propagation fixed point to each component of the underlying\nprobabilistic mixture. The mean field limit is considered and yields an exact\nconnection with the Hopfield model at finite temperature and steady state, when\nthe number of mixture components is proportional to the number of variables. In\naddition, we provide an enhanced learning procedure, based on a straightforward\nmulti-parameter extension of the model in conjunction with an effective\ncontinuous optimization procedure. This is performed using the stochastic\nsearch heuristic CMAES and yields a significant improvement with respect to the\nsingle parameter basic model.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2009 17:29:16 GMT"}], "update_date": "2015-05-13", "authors_parsed": [["Furtlehner", "Cyril", ""], ["Lasgouttes", "Jean-Marc", ""], ["Auger", "Anne", ""]]}, {"id": "0903.4930", "submitter": "Petar Kormushev", "authors": "Petar Kormushev, Kohei Nomoto, Fangyan Dong, Kaoru Hirota", "title": "Time manipulation technique for speeding up reinforcement learning in\n  simulations", "comments": "12 pages", "journal-ref": "International Journal of Cybernetics and Information Technologies,\n  vol. 8, no. 1, pp. 12-24, 2008", "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A technique for speeding up reinforcement learning algorithms by using time\nmanipulation is proposed. It is applicable to failure-avoidance control\nproblems running in a computer simulation. Turning the time of the simulation\nbackwards on failure events is shown to speed up the learning by 260% and\nimprove the state space exploration by 12% on the cart-pole balancing task,\ncompared to the conventional Q-learning and Actor-Critic algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 28 Mar 2009 01:09:00 GMT"}], "update_date": "2009-03-31", "authors_parsed": [["Kormushev", "Petar", ""], ["Nomoto", "Kohei", ""], ["Dong", "Fangyan", ""], ["Hirota", "Kaoru", ""]]}, {"id": "0903.5328", "submitter": "Alexander Rakhlin", "authors": "Jacob Abernethy, Alekh Agarwal, Peter L. Bartlett, Alexander Rakhlin", "title": "A Stochastic View of Optimal Regret through Minimax Duality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the regret of optimal strategies for online convex optimization\ngames. Using von Neumann's minimax theorem, we show that the optimal regret in\nthis adversarial setting is closely related to the behavior of the empirical\nminimization algorithm in a stochastic process setting: it is equal to the\nmaximum, over joint distributions of the adversary's action sequence, of the\ndifference between a sum of minimal expected losses and the minimal empirical\nloss. We show that the optimal regret has a natural geometric interpretation,\nsince it can be viewed as the gap in Jensen's inequality for a concave\nfunctional--the minimizer over the player's actions of expected loss--defined\non a set of probability distributions. We use this expression to obtain upper\nand lower bounds on the regret of an optimal strategy for a variety of online\nlearning problems. Our method provides upper bounds without the need to\nconstruct a learning algorithm; the lower bounds provide explicit optimal\nstrategies for the adversary.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2009 22:08:02 GMT"}], "update_date": "2009-04-01", "authors_parsed": [["Abernethy", "Jacob", ""], ["Agarwal", "Alekh", ""], ["Bartlett", "Peter L.", ""], ["Rakhlin", "Alexander", ""]]}, {"id": "0903.5342", "submitter": "Marcus Hutter", "authors": "Marcus Hutter", "title": "Exact Non-Parametric Bayesian Inference on Infinite Trees", "comments": "32 LaTeX pages, 9 figures, 5 theorems, 1 algorithm", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given i.i.d. data from an unknown distribution, we consider the problem of\npredicting future items. An adaptive way to estimate the probability density is\nto recursively subdivide the domain to an appropriate data-dependent\ngranularity. A Bayesian would assign a data-independent prior probability to\n\"subdivide\", which leads to a prior over infinite(ly many) trees. We derive an\nexact, fast, and simple inference algorithm for such a prior, for the data\nevidence, the predictive distribution, the effective model dimension, moments,\nand other quantities. We prove asymptotic convergence and consistency results,\nand illustrate the behavior of our model on some prototypical functions.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2009 23:24:08 GMT"}], "update_date": "2009-12-30", "authors_parsed": [["Hutter", "Marcus", ""]]}]