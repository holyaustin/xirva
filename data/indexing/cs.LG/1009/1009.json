[{"id": "1009.0117", "submitter": "Ke Chen", "authors": "Arslan Shaukat and Ke Chen", "title": "Exploring Language-Independent Emotional Acoustic Features via Feature\n  Selection", "comments": "15 pages, 2 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel feature selection strategy to discover\nlanguage-independent acoustic features that tend to be responsible for emotions\nregardless of languages, linguistics and other factors. Experimental results\nsuggest that the language-independent feature subset discovered yields the\nperformance comparable to the full feature set on various emotional speech\ncorpora.\n", "versions": [{"version": "v1", "created": "Wed, 1 Sep 2010 08:29:49 GMT"}], "update_date": "2010-09-02", "authors_parsed": [["Shaukat", "Arslan", ""], ["Chen", "Ke", ""]]}, {"id": "1009.0306", "submitter": "Jieping Ye", "authors": "Jun Liu and Jieping Ye", "title": "Fast Overlapping Group Lasso", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The group Lasso is an extension of the Lasso for feature selection on\n(predefined) non-overlapping groups of features. The non-overlapping group\nstructure limits its applicability in practice. There have been several recent\nattempts to study a more general formulation, where groups of features are\ngiven, potentially with overlaps between the groups. The resulting optimization\nis, however, much more challenging to solve due to the group overlaps. In this\npaper, we consider the efficient optimization of the overlapping group Lasso\npenalized problem. We reveal several key properties of the proximal operator\nassociated with the overlapping group Lasso, and compute the proximal operator\nby solving the smooth and convex dual problem, which allows the use of the\ngradient descent type of algorithms for the optimization. We have performed\nempirical evaluations using the breast cancer gene expression data set, which\nconsists of 8,141 genes organized into (overlapping) gene sets. Experimental\nresults demonstrate the efficiency and effectiveness of the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 2 Sep 2010 00:25:58 GMT"}], "update_date": "2010-09-03", "authors_parsed": [["Liu", "Jun", ""], ["Ye", "Jieping", ""]]}, {"id": "1009.0499", "submitter": "Yevgeny Seldin", "authors": "Yevgeny Seldin", "title": "A PAC-Bayesian Analysis of Graph Clustering and Pairwise Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formulate weighted graph clustering as a prediction problem: given a\nsubset of edge weights we analyze the ability of graph clustering to predict\nthe remaining edge weights. This formulation enables practical and theoretical\ncomparison of different approaches to graph clustering as well as comparison of\ngraph clustering with other possible ways to model the graph. We adapt the\nPAC-Bayesian analysis of co-clustering (Seldin and Tishby, 2008; Seldin, 2009)\nto derive a PAC-Bayesian generalization bound for graph clustering. The bound\nshows that graph clustering should optimize a trade-off between empirical data\nfit and the mutual information that clusters preserve on the graph nodes. A\nsimilar trade-off derived from information-theoretic considerations was already\nshown to produce state-of-the-art results in practice (Slonim et al., 2005;\nYom-Tov and Slonim, 2009). This paper supports the empirical evidence by\nproviding a better theoretical foundation, suggesting formal generalization\nguarantees, and offering a more accurate way to deal with finite sample issues.\nWe derive a bound minimization algorithm and show that it provides good results\nin real-life problems and that the derived PAC-Bayesian bound is reasonably\ntight.\n", "versions": [{"version": "v1", "created": "Thu, 2 Sep 2010 18:28:22 GMT"}], "update_date": "2010-09-03", "authors_parsed": [["Seldin", "Yevgeny", ""]]}, {"id": "1009.0605", "submitter": "Louis Dorard", "authors": "Louis Dorard and John Shawe-Taylor", "title": "Gaussian Process Bandits for Tree Search: Theory and Application to\n  Planning in Discounted MDPs", "comments": "Second draft. Tried to follow the JMLR formatting guidelines. Made\n  corrections to the section on planning in MDPs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We motivate and analyse a new Tree Search algorithm, GPTS, based on recent\ntheoretical advances in the use of Gaussian Processes for Bandit problems. We\nconsider tree paths as arms and we assume the target/reward function is drawn\nfrom a GP distribution. The posterior mean and variance, after observing data,\nare used to define confidence intervals for the function values, and we\nsequentially play arms with highest upper confidence bounds. We give an\nefficient implementation of GPTS and we adapt previous regret bounds by\ndetermining the decay rate of the eigenvalues of the kernel matrix on the whole\nset of tree paths. We consider two kernels in the feature space of binary\nvectors indexed by the nodes of the tree: linear and Gaussian. The regret grows\nin square root of the number of iterations T, up to a logarithmic factor, with\na constant that improves with bigger Gaussian kernel widths. We focus on\npractical values of T, smaller than the number of arms. Finally, we apply GPTS\nto Open Loop Planning in discounted Markov Decision Processes by modelling the\nreward as a discounted sum of independent Gaussian Processes. We report similar\nregret bounds to those of the OLOP algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 3 Sep 2010 08:36:07 GMT"}, {"version": "v2", "created": "Sat, 15 Jan 2011 15:34:21 GMT"}], "update_date": "2011-01-18", "authors_parsed": [["Dorard", "Louis", ""], ["Shawe-Taylor", "John", ""]]}, {"id": "1009.0861", "submitter": "Ameet Talwalkar", "authors": "Mehryar Mohri, Ameet Talwalkar", "title": "On the Estimation of Coherence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low-rank matrix approximations are often used to help scale standard machine\nlearning algorithms to large-scale problems. Recently, matrix coherence has\nbeen used to characterize the ability to extract global information from a\nsubset of matrix entries in the context of these low-rank approximations and\nother sampling-based algorithms, e.g., matrix com- pletion, robust PCA. Since\ncoherence is defined in terms of the singular vectors of a matrix and is\nexpensive to compute, the practical significance of these results largely\nhinges on the following question: Can we efficiently and accurately estimate\nthe coherence of a matrix? In this paper we address this question. We propose a\nnovel algorithm for estimating coherence from a small number of columns,\nformally analyze its behavior, and derive a new coherence-based matrix\napproximation bound based on this analysis. We then present extensive\nexperimental results on synthetic and real datasets that corroborate our\nworst-case theoretical analysis, yet provide strong support for the use of our\nproposed algorithm whenever low-rank approximation is being considered. Our\nalgorithm efficiently and accurately estimates matrix coherence across a wide\nrange of datasets, and these coherence estimates are excellent predictors of\nthe effectiveness of sampling-based matrix approximation on a case-by-case\nbasis.\n", "versions": [{"version": "v1", "created": "Sat, 4 Sep 2010 19:18:54 GMT"}], "update_date": "2010-09-07", "authors_parsed": [["Mohri", "Mehryar", ""], ["Talwalkar", "Ameet", ""]]}, {"id": "1009.2275", "submitter": "Anh Le", "authors": "Anh Le, Athina Markopoulou, Michalis Faloutsos", "title": "PhishDef: URL Names Say It All", "comments": "9 pages, submitted to IEEE INFOCOM 2011", "journal-ref": null, "doi": "10.1109/INFCOM.2011.5934995", "report-no": null, "categories": "cs.CR cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Phishing is an increasingly sophisticated method to steal personal user\ninformation using sites that pretend to be legitimate. In this paper, we take\nthe following steps to identify phishing URLs. First, we carefully select\nlexical features of the URLs that are resistant to obfuscation techniques used\nby attackers. Second, we evaluate the classification accuracy when using only\nlexical features, both automatically and hand-selected, vs. when using\nadditional features. We show that lexical features are sufficient for all\npractical purposes. Third, we thoroughly compare several classification\nalgorithms, and we propose to use an online method (AROW) that is able to\novercome noisy training data. Based on the insights gained from our analysis,\nwe propose PhishDef, a phishing detection system that uses only URL names and\ncombines the above three elements. PhishDef is a highly accurate method (when\ncompared to state-of-the-art approaches over real datasets), lightweight (thus\nappropriate for online and client-side deployment), proactive (based on online\nclassification rather than blacklists), and resilient to training data\ninaccuracies (thus enabling the use of large noisy training data).\n", "versions": [{"version": "v1", "created": "Sun, 12 Sep 2010 23:55:00 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Le", "Anh", ""], ["Markopoulou", "Athina", ""], ["Faloutsos", "Michalis", ""]]}, {"id": "1009.2566", "submitter": "Punit  Pandey Mr.", "authors": "Punit Pandey, Deepshikha Pandey, Shishir Kumar", "title": "Reinforcement Learning by Comparing Immediate Reward", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces an approach to Reinforcement Learning Algorithm by\ncomparing their immediate rewards using a variation of Q-Learning algorithm.\nUnlike the conventional Q-Learning, the proposed algorithm compares current\nreward with immediate reward of past move and work accordingly. Relative reward\nbased Q-learning is an approach towards interactive learning. Q-Learning is a\nmodel free reinforcement learning method that used to learn the agents. It is\nobserved that under normal circumstances algorithm take more episodes to reach\noptimal Q-value due to its normal reward or sometime negative reward. In this\nnew form of algorithm agents select only those actions which have a higher\nimmediate reward signal in comparison to previous one. The contribution of this\narticle is the presentation of new Q-Learning Algorithm in order to maximize\nthe performance of algorithm and reduce the number of episode required to reach\noptimal Q-value. Effectiveness of proposed algorithm is simulated in a 20 x20\nGrid world deterministic environment and the result for the two forms of\nQ-Learning Algorithms is given.\n", "versions": [{"version": "v1", "created": "Tue, 14 Sep 2010 03:53:11 GMT"}], "update_date": "2010-09-15", "authors_parsed": [["Pandey", "Punit", ""], ["Pandey", "Deepshikha", ""], ["Kumar", "Shishir", ""]]}, {"id": "1009.3240", "submitter": "Hugh Brendan McMahan", "authors": "H. Brendan McMahan", "title": "A Unified View of Regularized Dual Averaging and Mirror Descent with\n  Implicit Updates", "comments": "Extensively updated version of earlier draft with new analysis\n  including a general treatment of composite objectives and experiments. Also\n  fixes a small bug in some of one of the proofs in the early version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study three families of online convex optimization algorithms:\nfollow-the-proximally-regularized-leader (FTRL-Proximal), regularized dual\naveraging (RDA), and composite-objective mirror descent. We first prove\nequivalence theorems that show all of these algorithms are instantiations of a\ngeneral FTRL update. This provides theoretical insight on previous experimental\nobservations. In particular, even though the FOBOS composite mirror descent\nalgorithm handles L1 regularization explicitly, it has been observed that RDA\nis even more effective at producing sparsity. Our results demonstrate that\nFOBOS uses subgradient approximations to the L1 penalty from previous rounds,\nleading to less sparsity than RDA, which handles the cumulative penalty in\nclosed form. The FTRL-Proximal algorithm can be seen as a hybrid of these two,\nand outperforms both on a large, real-world dataset.\n  Our second contribution is a unified analysis which produces regret bounds\nthat match (up to logarithmic terms) or improve the best previously known\nbounds. This analysis also extends these algorithms in two important ways: we\nsupport a more general type of composite objective and we analyze implicit\nupdates, which replace the subgradient approximation of the current loss\nfunction with an exact optimization.\n", "versions": [{"version": "v1", "created": "Thu, 16 Sep 2010 18:40:32 GMT"}, {"version": "v2", "created": "Tue, 20 Sep 2011 18:38:13 GMT"}], "update_date": "2011-09-21", "authors_parsed": [["McMahan", "H. Brendan", ""]]}, {"id": "1009.3346", "submitter": "Mark Reid", "authors": "Qinfeng Shi, Mark D. Reid, Tiberio Caetano", "title": "Conditional Random Fields and Support Vector Machines: A Hybrid Approach", "comments": "16 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel hybrid loss for multiclass and structured prediction\nproblems that is a convex combination of log loss for Conditional Random Fields\n(CRFs) and a multiclass hinge loss for Support Vector Machines (SVMs). We\nprovide a sufficient condition for when the hybrid loss is Fisher consistent\nfor classification. This condition depends on a measure of dominance between\nlabels - specifically, the gap in per observation probabilities between the\nmost likely labels. We also prove Fisher consistency is necessary for\nparametric consistency when learning models such as CRFs.\n  We demonstrate empirically that the hybrid loss typically performs as least\nas well as - and often better than - both of its constituent losses on variety\nof tasks. In doing so we also provide an empirical comparison of the efficacy\nof probabilistic and margin based approaches to multiclass and structured\nprediction and the effects of label dominance on these results.\n", "versions": [{"version": "v1", "created": "Fri, 17 Sep 2010 06:47:25 GMT"}], "update_date": "2010-09-20", "authors_parsed": [["Shi", "Qinfeng", ""], ["Reid", "Mark D.", ""], ["Caetano", "Tiberio", ""]]}, {"id": "1009.3515", "submitter": "Laurent El Ghaoui", "authors": "Laurent El Ghaoui and Vivian Viallon and Tarek Rabbani", "title": "Safe Feature Elimination in Sparse Supervised Learning", "comments": "New version is on arXiv:1009.4219", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate fast methods that allow to quickly eliminate variables\n(features) in supervised learning problems involving a convex loss function and\na $l_1$-norm penalty, leading to a potentially substantial reduction in the\nnumber of variables prior to running the supervised learning algorithm. The\nmethods are not heuristic: they only eliminate features that are {\\em\nguaranteed} to be absent after solving the learning problem. Our framework\napplies to a large class of problems, including support vector machine\nclassification, logistic regression and least-squares.\n  The complexity of the feature elimination step is negligible compared to the\ntypical computational effort involved in the sparse supervised learning\nproblem: it grows linearly with the number of features times the number of\nexamples, with much better count if data is sparse. We apply our method to data\nsets arising in text classification and observe a dramatic reduction of the\ndimensionality, hence in computational effort required to solve the learning\nproblem, especially when very sparse classifiers are sought. Our method allows\nto immediately extend the scope of existing algorithms, allowing us to run them\non data sets of sizes that were out of their reach before.\n", "versions": [{"version": "v1", "created": "Fri, 17 Sep 2010 21:29:09 GMT"}, {"version": "v2", "created": "Tue, 26 Oct 2010 21:04:38 GMT"}], "update_date": "2010-10-28", "authors_parsed": [["Ghaoui", "Laurent El", ""], ["Viallon", "Vivian", ""], ["Rabbani", "Tarek", ""]]}, {"id": "1009.3589", "submitter": "Yoshua Bengio", "authors": "Fr\\'ed\\'eric Bastien and Yoshua Bengio and Arnaud Bergeron and Nicolas\n  Boulanger-Lewandowski and Thomas Breuel and Youssouf Chherawala and Moustapha\n  Cisse and Myriam C\\^ot\\'e and Dumitru Erhan and Jeremy Eustache and Xavier\n  Glorot and Xavier Muller and Sylvain Pannetier Lebeuf and Razvan Pascanu and\n  Salah Rifai and Francois Savard and Guillaume Sicard", "title": "Deep Self-Taught Learning for Handwritten Character Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": "1353, Dept. IRO, U. Montreal", "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent theoretical and empirical work in statistical machine learning has\ndemonstrated the importance of learning algorithms for deep architectures,\ni.e., function classes obtained by composing multiple non-linear\ntransformations. Self-taught learning (exploiting unlabeled examples or\nexamples from other distributions) has already been applied to deep learners,\nbut mostly to show the advantage of unlabeled examples. Here we explore the\nadvantage brought by {\\em out-of-distribution examples}. For this purpose we\ndeveloped a powerful generator of stochastic variations and noise processes for\ncharacter images, including not only affine transformations but also slant,\nlocal elastic deformations, changes in thickness, background images, grey level\nchanges, contrast, occlusion, and various types of noise. The\nout-of-distribution examples are obtained from these highly distorted images or\nby including examples of object classes different from those in the target test\nset. We show that {\\em deep learners benefit more from out-of-distribution\nexamples than a corresponding shallow learner}, at least in the area of\nhandwritten character recognition. In fact, we show that they beat previously\npublished results and reach human-level performance on both handwritten digit\nclassification and 62-class handwritten character recognition.\n", "versions": [{"version": "v1", "created": "Sat, 18 Sep 2010 22:11:05 GMT"}], "update_date": "2010-09-21", "authors_parsed": [["Bastien", "Fr\u00e9d\u00e9ric", ""], ["Bengio", "Yoshua", ""], ["Bergeron", "Arnaud", ""], ["Boulanger-Lewandowski", "Nicolas", ""], ["Breuel", "Thomas", ""], ["Chherawala", "Youssouf", ""], ["Cisse", "Moustapha", ""], ["C\u00f4t\u00e9", "Myriam", ""], ["Erhan", "Dumitru", ""], ["Eustache", "Jeremy", ""], ["Glorot", "Xavier", ""], ["Muller", "Xavier", ""], ["Lebeuf", "Sylvain Pannetier", ""], ["Pascanu", "Razvan", ""], ["Rifai", "Salah", ""], ["Savard", "Francois", ""], ["Sicard", "Guillaume", ""]]}, {"id": "1009.3604", "submitter": "Naresh Manwani", "authors": "Naresh Manwani and P. S. Sastry", "title": "Geometric Decision Tree", "comments": "Licensed copy is available on IEEE website", "journal-ref": "IEEE Transactions on Systems, Man, and Cybernetics, Part B:\n  Cybernetics,2011", "doi": "10.1109/TSMCB.2011.2163392", "report-no": "Issue:99", "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a new algorithm for learning oblique decision trees.\nMost of the current decision tree algorithms rely on impurity measures to\nassess the goodness of hyperplanes at each node while learning a decision tree\nin a top-down fashion. These impurity measures do not properly capture the\ngeometric structures in the data. Motivated by this, our algorithm uses a\nstrategy to assess the hyperplanes in such a way that the geometric structure\nin the data is taken into account. At each node of the decision tree, we find\nthe clustering hyperplanes for both the classes and use their angle bisectors\nas the split rule at that node. We show through empirical studies that this\nidea leads to small decision trees and better performance. We also present some\nanalysis to show that the angle bisectors of clustering hyperplanes that we use\nas the split rules at each node, are solutions of an interesting optimization\nproblem and hence argue that this is a principled method of learning a decision\ntree.\n", "versions": [{"version": "v1", "created": "Sun, 19 Sep 2010 03:54:12 GMT"}, {"version": "v2", "created": "Thu, 4 Nov 2010 16:40:04 GMT"}, {"version": "v3", "created": "Thu, 26 Jan 2012 05:15:11 GMT"}, {"version": "v4", "created": "Mon, 13 Feb 2012 05:37:10 GMT"}, {"version": "v5", "created": "Sat, 13 Oct 2012 11:09:48 GMT"}], "update_date": "2012-10-16", "authors_parsed": [["Manwani", "Naresh", ""], ["Sastry", "P. S.", ""]]}, {"id": "1009.3613", "submitter": "Zhi-Hua Zhou", "authors": "Wei Gao, Zhi-Hua Zhou", "title": "On the Doubt about Margin Explanation of Boosting", "comments": "35 pages", "journal-ref": "Artificial Intelligence 203:1-18 2013", "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Margin theory provides one of the most popular explanations to the success of\n\\texttt{AdaBoost}, where the central point lies in the recognition that\n\\textit{margin} is the key for characterizing the performance of\n\\texttt{AdaBoost}. This theory has been very influential, e.g., it has been\nused to argue that \\texttt{AdaBoost} usually does not overfit since it tends to\nenlarge the margin even after the training error reaches zero. Previously the\n\\textit{minimum margin bound} was established for \\texttt{AdaBoost}, however,\n\\cite{Breiman1999} pointed out that maximizing the minimum margin does not\nnecessarily lead to a better generalization. Later, \\cite{Reyzin:Schapire2006}\nemphasized that the margin distribution rather than minimum margin is crucial\nto the performance of \\texttt{AdaBoost}. In this paper, we first present the\n\\textit{$k$th margin bound} and further study on its relationship to previous\nwork such as the minimum margin bound and Emargin bound. Then, we improve the\nprevious empirical Bernstein bounds\n\\citep{Maurer:Pontil2009,Audibert:Munos:Szepesvari2009}, and based on such\nfindings, we defend the margin-based explanation against Breiman's doubts by\nproving a new generalization error bound that considers exactly the same\nfactors as \\cite{Schapire:Freund:Bartlett:Lee1998} but is sharper than\n\\cite{Breiman1999}'s minimum margin bound. By incorporating factors such as\naverage margin and variance, we present a generalization error bound that is\nheavily related to the whole margin distribution. We also provide margin\ndistribution bounds for generalization error of voting classifiers in finite\nVC-dimension space.\n", "versions": [{"version": "v1", "created": "Sun, 19 Sep 2010 07:26:37 GMT"}, {"version": "v2", "created": "Tue, 21 Sep 2010 12:38:53 GMT"}, {"version": "v3", "created": "Sat, 17 Mar 2012 08:42:07 GMT"}, {"version": "v4", "created": "Tue, 10 Apr 2012 11:48:11 GMT"}, {"version": "v5", "created": "Wed, 28 Aug 2013 03:03:18 GMT"}], "update_date": "2013-08-29", "authors_parsed": [["Gao", "Wei", ""], ["Zhou", "Zhi-Hua", ""]]}, {"id": "1009.3702", "submitter": "Chunhua Shen", "authors": "Zhihui Hao, Chunhua Shen, Nick Barnes, and Bo Wang", "title": "Totally Corrective Multiclass Boosting with Binary Weak Learners", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a new optimization framework for multiclass boosting\nlearning. In the literature, AdaBoost.MO and AdaBoost.ECC are the two\nsuccessful multiclass boosting algorithms, which can use binary weak learners.\nWe explicitly derive these two algorithms' Lagrange dual problems based on\ntheir regularized loss functions. We show that the Lagrange dual formulations\nenable us to design totally-corrective multiclass algorithms by using the\nprimal-dual optimization technique. Experiments on benchmark data sets suggest\nthat our multiclass boosting can achieve a comparable generalization capability\nwith state-of-the-art, but the convergence speed is much faster than stage-wise\ngradient descent boosting. In other words, the new totally corrective\nalgorithms can maximize the margin more aggressively.\n", "versions": [{"version": "v1", "created": "Mon, 20 Sep 2010 06:35:11 GMT"}], "update_date": "2010-09-21", "authors_parsed": [["Hao", "Zhihui", ""], ["Shen", "Chunhua", ""], ["Barnes", "Nick", ""], ["Wang", "Bo", ""]]}, {"id": "1009.3711", "submitter": "EPTCS", "authors": "Yi-Hsun Wang, Ching-Hao Mao, Hahn-Ming Lee", "title": "Structural Learning of Attack Vectors for Generating Mutated XSS Attacks", "comments": "In Proceedings TAV-WEB 2010, arXiv:1009.3306", "journal-ref": "EPTCS 35, 2010, pp. 15-26", "doi": "10.4204/EPTCS.35.2", "report-no": null, "categories": "cs.SE cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Web applications suffer from cross-site scripting (XSS) attacks that\nresulting from incomplete or incorrect input sanitization. Learning the\nstructure of attack vectors could enrich the variety of manifestations in\ngenerated XSS attacks. In this study, we focus on generating more threatening\nXSS attacks for the state-of-the-art detection approaches that can find\npotential XSS vulnerabilities in Web applications, and propose a mechanism for\nstructural learning of attack vectors with the aim of generating mutated XSS\nattacks in a fully automatic way. Mutated XSS attack generation depends on the\nanalysis of attack vectors and the structural learning mechanism. For the\nkernel of the learning mechanism, we use a Hidden Markov model (HMM) as the\nstructure of the attack vector model to capture the implicit manner of the\nattack vector, and this manner is benefited from the syntax meanings that are\nlabeled by the proposed tokenizing mechanism. Bayes theorem is used to\ndetermine the number of hidden states in the model for generalizing the\nstructure model. The paper has the contributions as following: (1)\nautomatically learn the structure of attack vectors from practical data\nanalysis to modeling a structure model of attack vectors, (2) mimic the manners\nand the elements of attack vectors to extend the ability of testing tool for\nidentifying XSS vulnerabilities, (3) be helpful to verify the flaws of\nblacklist sanitization procedures of Web applications. We evaluated the\nproposed mechanism by Burp Intruder with a dataset collected from public XSS\narchives. The results show that mutated XSS attack generation can identify\npotential vulnerabilities.\n", "versions": [{"version": "v1", "created": "Mon, 20 Sep 2010 07:19:27 GMT"}], "update_date": "2010-09-21", "authors_parsed": [["Wang", "Yi-Hsun", ""], ["Mao", "Ching-Hao", ""], ["Lee", "Hahn-Ming", ""]]}, {"id": "1009.3802", "submitter": "Ju Sun", "authors": "Yuzhao Ni, Ju Sun, Xiaotong Yuan, Shuicheng Yan, Loong-Fah Cheong", "title": "Robust Low-Rank Subspace Segmentation with Semidefinite Guarantees", "comments": "10 pages, 4 figures. Accepted by ICDM Workshop on Optimization Based\n  Methods for Emerging Data Mining Problems (OEDM), 2010. Main proof simplified\n  and typos corrected. Experimental data slightly added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently there is a line of research work proposing to employ Spectral\nClustering (SC) to segment (group){Throughout the paper, we use segmentation,\nclustering, and grouping, and their verb forms, interchangeably.}\nhigh-dimensional structural data such as those (approximately) lying on\nsubspaces {We follow {liu2010robust} and use the term \"subspace\" to denote both\nlinear subspaces and affine subspaces. There is a trivial conversion between\nlinear subspaces and affine subspaces as mentioned therein.} or low-dimensional\nmanifolds. By learning the affinity matrix in the form of sparse\nreconstruction, techniques proposed in this vein often considerably boost the\nperformance in subspace settings where traditional SC can fail. Despite the\nsuccess, there are fundamental problems that have been left unsolved: the\nspectrum property of the learned affinity matrix cannot be gauged in advance,\nand there is often one ugly symmetrization step that post-processes the\naffinity for SC input. Hence we advocate to enforce the symmetric positive\nsemidefinite constraint explicitly during learning (Low-Rank Representation\nwith Positive SemiDefinite constraint, or LRR-PSD), and show that factually it\ncan be solved in an exquisite scheme efficiently instead of general-purpose SDP\nsolvers that usually scale up poorly. We provide rigorous mathematical\nderivations to show that, in its canonical form, LRR-PSD is equivalent to the\nrecently proposed Low-Rank Representation (LRR) scheme {liu2010robust}, and\nhence offer theoretic and practical insights to both LRR-PSD and LRR, inviting\nfuture research. As per the computational cost, our proposal is at most\ncomparable to that of LRR, if not less. We validate our theoretic analysis and\noptimization scheme by experiments on both synthetic and real data sets.\n", "versions": [{"version": "v1", "created": "Mon, 20 Sep 2010 12:54:12 GMT"}, {"version": "v2", "created": "Sun, 26 Sep 2010 16:07:15 GMT"}, {"version": "v3", "created": "Fri, 8 Oct 2010 16:53:06 GMT"}], "update_date": "2010-10-11", "authors_parsed": [["Ni", "Yuzhao", ""], ["Sun", "Ju", ""], ["Yuan", "Xiaotong", ""], ["Yan", "Shuicheng", ""], ["Cheong", "Loong-Fah", ""]]}, {"id": "1009.3896", "submitter": "Karthik Sridharan Karthik Sridharan", "authors": "Nathan Srebro, Karthik Sridharan, Ambuj Tewari", "title": "Optimistic Rates for Learning with a Smooth Loss", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We establish an excess risk bound of O(H R_n^2 + R_n \\sqrt{H L*}) for\nempirical risk minimization with an H-smooth loss function and a hypothesis\nclass with Rademacher complexity R_n, where L* is the best risk achievable by\nthe hypothesis class. For typical hypothesis classes where R_n = \\sqrt{R/n},\nthis translates to a learning rate of O(RH/n) in the separable (L*=0) case and\nO(RH/n + \\sqrt{L^* RH/n}) more generally. We also provide similar guarantees\nfor online and stochastic convex optimization with a smooth non-negative\nobjective.\n", "versions": [{"version": "v1", "created": "Mon, 20 Sep 2010 17:35:35 GMT"}, {"version": "v2", "created": "Mon, 26 Nov 2012 06:42:25 GMT"}], "update_date": "2012-11-27", "authors_parsed": [["Srebro", "Nathan", ""], ["Sridharan", "Karthik", ""], ["Tewari", "Ambuj", ""]]}, {"id": "1009.3958", "submitter": "Konrad Rawlik", "authors": "Konrad Rawlik, Marc Toussaint and Sethu Vijayakumar", "title": "Approximate Inference and Stochastic Optimal Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel reformulation of the stochastic optimal control problem as\nan approximate inference problem, demonstrating, that such a interpretation\nleads to new practical methods for the original problem. In particular we\ncharacterise a novel class of iterative solutions to the stochastic optimal\ncontrol problem based on a natural relaxation of the exact dual formulation.\nThese theoretical insights are applied to the Reinforcement Learning problem\nwhere they lead to new model free, off policy methods for discrete and\ncontinuous problems.\n", "versions": [{"version": "v1", "created": "Mon, 20 Sep 2010 21:44:30 GMT"}], "update_date": "2010-09-22", "authors_parsed": [["Rawlik", "Konrad", ""], ["Toussaint", "Marc", ""], ["Vijayakumar", "Sethu", ""]]}, {"id": "1009.4219", "submitter": "Tarek Rabbani", "authors": "Laurent El Ghaoui, Vivian Viallon, Tarek Rabbani", "title": "Safe Feature Elimination for the LASSO and Sparse Supervised Learning\n  Problems", "comments": "Submitted to JMLR in April 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a fast method to eliminate features (variables) in l1 -penalized\nleast-square regression (or LASSO) problems. The elimination of features leads\nto a potentially substantial reduction in running time, specially for large\nvalues of the penalty parameter. Our method is not heuristic: it only\neliminates features that are guaranteed to be absent after solving the LASSO\nproblem. The feature elimination step is easy to parallelize and can test each\nfeature for elimination independently. Moreover, the computational effort of\nour method is negligible compared to that of solving the LASSO problem -\nroughly it is the same as single gradient step. Our method extends the scope of\nexisting LASSO algorithms to treat larger data sets, previously out of their\nreach. We show how our method can be extended to general l1 -penalized convex\nproblems and present preliminary results for the Sparse Support Vector Machine\nand Logistic Regression problems.\n", "versions": [{"version": "v1", "created": "Tue, 21 Sep 2010 21:13:15 GMT"}, {"version": "v2", "created": "Wed, 18 May 2011 16:38:10 GMT"}], "update_date": "2011-05-19", "authors_parsed": [["Ghaoui", "Laurent El", ""], ["Viallon", "Vivian", ""], ["Rabbani", "Tarek", ""]]}, {"id": "1009.4574", "submitter": "S. M. Kamruzzaman", "authors": "S. M. Kamruzzaman and Farhana Haider", "title": "A hybrid learning algorithm for text classification", "comments": "4 pages, International Conference", "journal-ref": "Proc. 3rd International Conference on Electrical & Computer\n  Engineering (ICECE 2004), Dhaka Bangladesh, pp. 577-580, Dec. 2004", "doi": null, "report-no": null, "categories": "cs.NE cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text classification is the process of classifying documents into predefined\ncategories based on their content. Existing supervised learning algorithms to\nautomatically classify text need sufficient documents to learn accurately. This\npaper presents a new algorithm for text classification that requires fewer\ndocuments for training. Instead of using words, word relation i.e association\nrules from these words is used to derive feature set from preclassified text\ndocuments. The concept of Naive Bayes classifier is then used on derived\nfeatures and finally only a single concept of Genetic Algorithm has been added\nfor final classification. Experimental results show that the classifier build\nthis way is more accurate than the existing text classification systems.\n", "versions": [{"version": "v1", "created": "Thu, 23 Sep 2010 10:50:06 GMT"}], "update_date": "2010-09-27", "authors_parsed": [["Kamruzzaman", "S. M.", ""], ["Haider", "Farhana", ""]]}, {"id": "1009.4582", "submitter": "S. M. Kamruzzaman", "authors": "Chowdhury Mofizur Rahman, Ferdous Ahmed Sohel, Parvez Naushad, and S.\n  M. Kamruzzaman", "title": "Text Classification using the Concept of Association Rule of Data Mining", "comments": "8 Pages, International Conference", "journal-ref": "Proc. International Conference on Information Technology,\n  Kathmandu, Nepal, pp. 234-241, May. 2003", "doi": null, "report-no": null, "categories": "cs.LG cs.DB cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the amount of online text increases, the demand for text classification to\naid the analysis and management of text is increasing. Text is cheap, but\ninformation, in the form of knowing what classes a text belongs to, is\nexpensive. Automatic classification of text can provide this information at low\ncost, but the classifiers themselves must be built with expensive human effort,\nor trained from texts which have themselves been manually classified. In this\npaper we will discuss a procedure of classifying text using the concept of\nassociation rule of data mining. Association rule mining technique has been\nused to derive feature set from pre-classified text documents. Naive Bayes\nclassifier is then used on derived features for final classification.\n", "versions": [{"version": "v1", "created": "Thu, 23 Sep 2010 11:32:16 GMT"}], "update_date": "2010-09-27", "authors_parsed": [["Rahman", "Chowdhury Mofizur", ""], ["Sohel", "Ferdous Ahmed", ""], ["Naushad", "Parvez", ""], ["Kamruzzaman", "S. M.", ""]]}, {"id": "1009.4719", "submitter": "Konstantin Biatov M.", "authors": "Konstantin Biatov", "title": "A Fast Audio Clustering Using Vector Quantization and Second Order\n  Statistics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes an effective unsupervised speaker indexing approach. We\nsuggest a two stage algorithm to speed-up the state-of-the-art algorithm based\non the Bayesian Information Criterion (BIC). In the first stage of the merging\nprocess a computationally cheap method based on the vector quantization (VQ) is\nused. Then in the second stage a more computational expensive technique based\non the BIC is applied. In the speaker indexing task a turning parameter or a\nthreshold is used. We suggest an on-line procedure to define the value of a\nturning parameter without using development data. The results are evaluated\nusing 10 hours of audio data.\n", "versions": [{"version": "v1", "created": "Thu, 23 Sep 2010 20:38:06 GMT"}], "update_date": "2010-09-27", "authors_parsed": [["Biatov", "Konstantin", ""]]}, {"id": "1009.4766", "submitter": "Jun Liu", "authors": "Jun Liu, Jieping Ye", "title": "Efficient L1/Lq Norm Regularization", "comments": "19 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Sparse learning has recently received increasing attention in many areas\nincluding machine learning, statistics, and applied mathematics. The mixed-norm\nregularization based on the L1/Lq norm with q > 1 is attractive in many\napplications of regression and classification in that it facilitates group\nsparsity in the model. The resulting optimization problem is, however,\nchallenging to solve due to the structure of the L1/Lq -regularization.\nExisting work deals with special cases including q = 2,infinity, and they\ncannot be easily extended to the general case. In this paper, we propose an\nefficient algorithm based on the accelerated gradient method for solving the\nL1/Lq -regularized problem, which is applicable for all values of q larger than\n1, thus significantly extending existing work. One key building block of the\nproposed algorithm is the L1/Lq -regularized Euclidean projection (EP1q). Our\ntheoretical analysis reveals the key properties of EP1q and illustrates why\nEP1q for the general q is significantly more challenging to solve than the\nspecial cases. Based on our theoretical analysis, we develop an efficient\nalgorithm for EP1q by solving two zero finding problems. Experimental results\ndemonstrate the efficiency of the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 24 Sep 2010 05:53:28 GMT"}], "update_date": "2010-09-27", "authors_parsed": [["Liu", "Jun", ""], ["Ye", "Jieping", ""]]}, {"id": "1009.4791", "submitter": "Masayuki Karasuyama", "authors": "Masayuki Karasuyama, Naoyuki Harada, Masashi Sugiyama, Ichiro Takeuchi", "title": "Multi-parametric Solution-path Algorithm for Instance-weighted Support\n  Vector Machines", "comments": "Submitted to Journal of Machine Learning Research", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An instance-weighted variant of the support vector machine (SVM) has\nattracted considerable attention recently since they are useful in various\nmachine learning tasks such as non-stationary data analysis, heteroscedastic\ndata modeling, transfer learning, learning to rank, and transduction. An\nimportant challenge in these scenarios is to overcome the computational\nbottleneck---instance weights often change dynamically or adaptively, and thus\nthe weighted SVM solutions must be repeatedly computed. In this paper, we\ndevelop an algorithm that can efficiently and exactly update the weighted SVM\nsolutions for arbitrary change of instance weights. Technically, this\ncontribution can be regarded as an extension of the conventional solution-path\nalgorithm for a single regularization parameter to multiple instance-weight\nparameters. However, this extension gives rise to a significant problem that\nbreakpoints (at which the solution path turns) have to be identified in\nhigh-dimensional space. To facilitate this, we introduce a parametric\nrepresentation of instance weights. We also provide a geometric interpretation\nin weight space using a notion of critical region: a polyhedron in which the\ncurrent affine solution remains to be optimal. Then we find breakpoints at\nintersections of the solution path and boundaries of polyhedrons. Through\nextensive experiments on various practical applications, we demonstrate the\nusefulness of the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 24 Sep 2010 09:53:32 GMT"}, {"version": "v2", "created": "Mon, 1 Nov 2010 13:23:49 GMT"}], "update_date": "2010-11-02", "authors_parsed": [["Karasuyama", "Masayuki", ""], ["Harada", "Naoyuki", ""], ["Sugiyama", "Masashi", ""], ["Takeuchi", "Ichiro", ""]]}, {"id": "1009.4972", "submitter": "S. M. Kamruzzaman", "authors": "S. M. Kamruzzaman, A. N. M. Rezaul Karim, Md. Saiful Islam, and Md.\n  Emdadul Haque", "title": "Speaker Identification using MFCC-Domain Support Vector Machine", "comments": "5 Pages, International Journal", "journal-ref": "International Journal of Electrical and Power Engineering, Vol. 1,\n  No. 3, pp. 274-278, 2007", "doi": "10.3923/ijepe.2007.274.278", "report-no": null, "categories": "cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech recognition and speaker identification are important for\nauthentication and verification in security purpose, but they are difficult to\nachieve. Speaker identification methods can be divided into text-independent\nand text-dependent. This paper presents a technique of text-dependent speaker\nidentification using MFCC-domain support vector machine (SVM). In this work,\nmelfrequency cepstrum coefficients (MFCCs) and their statistical distribution\nproperties are used as features, which will be inputs to the neural network.\nThis work firstly used sequential minimum optimization (SMO) learning technique\nfor SVM that improve performance over traditional techniques Chunking, Osuna.\nThe cepstrum coefficients representing the speaker characteristics of a speech\nsegment are computed by nonlinear filter bank analysis and discrete cosine\ntransform. The speaker identification ability and convergence speed of the SVMs\nare investigated for different combinations of features. Extensive experimental\nresults on several samples show the effectiveness of the proposed approach.\n", "versions": [{"version": "v1", "created": "Sat, 25 Sep 2010 05:32:44 GMT"}], "update_date": "2010-09-28", "authors_parsed": [["Kamruzzaman", "S. M.", ""], ["Karim", "A. N. M. Rezaul", ""], ["Islam", "Md. Saiful", ""], ["Haque", "Md. Emdadul", ""]]}, {"id": "1009.4976", "submitter": "S. M. Kamruzzaman", "authors": "S. M. Kamruzzaman, Farhana Haider, and Ahmed Ryadh Hasan", "title": "Text Classification using Association Rule with a Hybrid Concept of\n  Naive Bayes Classifier and Genetic Algorithm", "comments": "6 Pages, International Conference", "journal-ref": "Proc. 7th International Conference on Computer and Information\n  Technology (ICCIT-2004), Dhaka, Bangladesh, pp. 682-687, Dec. 2004", "doi": null, "report-no": null, "categories": "cs.IR cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text classification is the automated assignment of natural language texts to\npredefined categories based on their content. Text classification is the\nprimary requirement of text retrieval systems, which retrieve texts in response\nto a user query, and text understanding systems, which transform text in some\nway such as producing summaries, answering questions or extracting data. Now a\nday the demand of text classification is increasing tremendously. Keeping this\ndemand into consideration, new and updated techniques are being developed for\nthe purpose of automated text classification. This paper presents a new\nalgorithm for text classification. Instead of using words, word relation i.e.\nassociation rules is used to derive feature set from pre-classified text\ndocuments. The concept of Naive Bayes Classifier is then used on derived\nfeatures and finally a concept of Genetic Algorithm has been added for final\nclassification. A system based on the proposed algorithm has been implemented\nand tested. The experimental results show that the proposed system works as a\nsuccessful text classifier.\n", "versions": [{"version": "v1", "created": "Sat, 25 Sep 2010 06:10:33 GMT"}], "update_date": "2010-09-28", "authors_parsed": [["Kamruzzaman", "S. M.", ""], ["Haider", "Farhana", ""], ["Hasan", "Ahmed Ryadh", ""]]}, {"id": "1009.5419", "submitter": "Matthew W. Hoffman", "authors": "Eric Brochu, Matthew W. Hoffman, Nando de Freitas", "title": "Portfolio Allocation for Bayesian Optimization", "comments": "This revision contains an updated the performance bound and other\n  minor text changes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization with Gaussian processes has become an increasingly\npopular tool in the machine learning community. It is efficient and can be used\nwhen very little is known about the objective function, making it popular in\nexpensive black-box optimization scenarios. It uses Bayesian methods to sample\nthe objective efficiently using an acquisition function which incorporates the\nmodel's estimate of the objective and the uncertainty at any given point.\nHowever, there are several different parameterized acquisition functions in the\nliterature, and it is often unclear which one to use. Instead of using a single\nacquisition function, we adopt a portfolio of acquisition functions governed by\nan online multi-armed bandit strategy. We propose several portfolio strategies,\nthe best of which we call GP-Hedge, and show that this method outperforms the\nbest individual acquisition function. We also provide a theoretical bound on\nthe algorithm's performance.\n", "versions": [{"version": "v1", "created": "Tue, 28 Sep 2010 00:41:45 GMT"}, {"version": "v2", "created": "Mon, 7 Mar 2011 13:45:22 GMT"}], "update_date": "2011-03-08", "authors_parsed": [["Brochu", "Eric", ""], ["Hoffman", "Matthew W.", ""], ["de Freitas", "Nando", ""]]}, {"id": "1009.5761", "submitter": "Matthew Hoffman", "authors": "Matthew D. Hoffman", "title": "Approximate Maximum A Posteriori Inference with Entropic Priors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In certain applications it is useful to fit multinomial distributions to\nobserved data with a penalty term that encourages sparsity. For example, in\nprobabilistic latent audio source decomposition one may wish to encode the\nassumption that only a few latent sources are active at any given time. The\nstandard heuristic of applying an L1 penalty is not an option when fitting the\nparameters to a multinomial distribution, which are constrained to sum to 1. An\nalternative is to use a penalty term that encourages low-entropy solutions,\nwhich corresponds to maximum a posteriori (MAP) parameter estimation with an\nentropic prior. The lack of conjugacy between the entropic prior and the\nmultinomial distribution complicates this approach. In this report I propose a\nsimple iterative algorithm for MAP estimation of multinomial distributions with\nsparsity-inducing entropic priors.\n", "versions": [{"version": "v1", "created": "Wed, 29 Sep 2010 03:20:40 GMT"}], "update_date": "2010-09-30", "authors_parsed": [["Hoffman", "Matthew D.", ""]]}, {"id": "1009.5773", "submitter": "Nicholas Mastronarde", "authors": "Nicholas Mastronarde and Mihaela van der Schaar", "title": "Fast Reinforcement Learning for Energy-Efficient Wireless Communications", "comments": null, "journal-ref": "N. Mastronarde and M. van der Schaar, \"Joint physical-layer and\n  system-level power management for delay-sensitive wireless communication,\"\n  IEEE Trans. on Mobile Computing, vol. 12, no. 4, pp. 694-709, April 2013", "doi": "10.1109/TSP.2011.2165211", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of energy-efficient point-to-point transmission of\ndelay-sensitive data (e.g. multimedia data) over a fading channel. Existing\nresearch on this topic utilizes either physical-layer centric solutions, namely\npower-control and adaptive modulation and coding (AMC), or system-level\nsolutions based on dynamic power management (DPM); however, there is currently\nno rigorous and unified framework for simultaneously utilizing both\nphysical-layer centric and system-level techniques to achieve the minimum\npossible energy consumption, under delay constraints, in the presence of\nstochastic and a priori unknown traffic and channel conditions. In this report,\nwe propose such a framework. We formulate the stochastic optimization problem\nas a Markov decision process (MDP) and solve it online using reinforcement\nlearning. The advantages of the proposed online method are that (i) it does not\nrequire a priori knowledge of the traffic arrival and channel statistics to\ndetermine the jointly optimal power-control, AMC, and DPM policies; (ii) it\nexploits partial information about the system so that less information needs to\nbe learned than when using conventional reinforcement learning algorithms; and\n(iii) it obviates the need for action exploration, which severely limits the\nadaptation speed and run-time performance of conventional reinforcement\nlearning algorithms. Our results show that the proposed learning algorithms can\nconverge up to two orders of magnitude faster than a state-of-the-art learning\nalgorithm for physical layer power-control and up to three orders of magnitude\nfaster than conventional reinforcement learning algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 29 Sep 2010 05:23:20 GMT"}, {"version": "v2", "created": "Sat, 26 Feb 2011 03:42:20 GMT"}, {"version": "v3", "created": "Fri, 27 Jan 2012 06:57:24 GMT"}, {"version": "v4", "created": "Wed, 5 Jun 2013 01:57:55 GMT"}], "update_date": "2017-03-29", "authors_parsed": [["Mastronarde", "Nicholas", ""], ["van der Schaar", "Mihaela", ""]]}, {"id": "1009.5972", "submitter": "Raphael Pelossof", "authors": "Raphael Pelossof and Zhiliang Ying", "title": "The Attentive Perceptron", "comments": "Submitted to New York Academy of Sciences Machine Learning symposium\n  2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a focus of attention mechanism to speed up the Perceptron\nalgorithm. Focus of attention speeds up the Perceptron algorithm by lowering\nthe number of features evaluated throughout training and prediction. Whereas\nthe traditional Perceptron evaluates all the features of each example, the\nAttentive Perceptron evaluates less features for easy to classify examples,\nthereby achieving significant speedups and small losses in prediction accuracy.\nFocus of attention allows the Attentive Perceptron to stop the evaluation of\nfeatures at any interim point and filter the example. This creates an attentive\nfilter which concentrates computation at examples that are hard to classify,\nand quickly filters examples that are easy to classify.\n", "versions": [{"version": "v1", "created": "Wed, 29 Sep 2010 18:55:02 GMT"}], "update_date": "2010-09-30", "authors_parsed": [["Pelossof", "Raphael", ""], ["Ying", "Zhiliang", ""]]}]