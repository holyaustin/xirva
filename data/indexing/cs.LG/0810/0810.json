[{"id": "0810.0877", "submitter": "Dev Rajnarayan", "authors": "Dev Rajnarayan and David Wolpert", "title": "Bias-Variance Techniques for Monte Carlo Optimization: Cross-validation\n  for the CE Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we examine the CE method in the broad context of Monte Carlo\nOptimization (MCO) and Parametric Learning (PL), a type of machine learning. A\nwell-known overarching principle used to improve the performance of many PL\nalgorithms is the bias-variance tradeoff. This tradeoff has been used to\nimprove PL algorithms ranging from Monte Carlo estimation of integrals, to\nlinear estimation, to general statistical estimation. Moreover, as described\nby, MCO is very closely related to PL. Owing to this similarity, the\nbias-variance tradeoff affects MCO performance, just as it does PL performance.\n  In this article, we exploit the bias-variance tradeoff to enhance the\nperformance of MCO algorithms. We use the technique of cross-validation, a\ntechnique based on the bias-variance tradeoff, to significantly improve the\nperformance of the Cross Entropy (CE) method, which is an MCO algorithm. In\nprevious work we have confirmed that other PL techniques improve the perfomance\nof other MCO algorithms. We conclude that the many techniques pioneered in PL\ncould be investigated as ways to improve MCO algorithms in general, and the CE\nmethod in particular.\n", "versions": [{"version": "v1", "created": "Mon, 6 Oct 2008 04:58:44 GMT"}], "update_date": "2008-10-07", "authors_parsed": [["Rajnarayan", "Dev", ""], ["Wolpert", "David", ""]]}, {"id": "0810.1430", "submitter": "Omar Mehanna", "authors": "Omar Mehanna, Ahmed Sultan and Hesham El Gamal", "title": "Blind Cognitive MAC Protocols", "comments": "5 pages, submitted to ICC'09", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the design of cognitive Medium Access Control (MAC) protocols\nenabling an unlicensed (secondary) transmitter-receiver pair to communicate\nover the idle periods of a set of licensed channels, i.e., the primary network.\nThe objective is to maximize data throughput while maintaining the\nsynchronization between secondary users and avoiding interference with licensed\n(primary) users. No statistical information about the primary traffic is\nassumed to be available a-priori to the secondary user. We investigate two\ndistinct sensing scenarios. In the first, the secondary transmitter is capable\nof sensing all the primary channels, whereas it senses one channel only in the\nsecond scenario. In both cases, we propose MAC protocols that efficiently learn\nthe statistics of the primary traffic online. Our simulation results\ndemonstrate that the proposed blind protocols asymptotically achieve the\nthroughput obtained when prior knowledge of primary traffic statistics is\navailable.\n", "versions": [{"version": "v1", "created": "Wed, 8 Oct 2008 13:22:46 GMT"}], "update_date": "2008-10-09", "authors_parsed": [["Mehanna", "Omar", ""], ["Sultan", "Ahmed", ""], ["Gamal", "Hesham El", ""]]}, {"id": "0810.1648", "submitter": "Danny Bickson", "authors": "Danny Bickson, Elad Yom-Tov and Danny Dolev", "title": "A Gaussian Belief Propagation Solver for Large Scale Support Vector\n  Machines", "comments": "12 pages, 1 figure, appeared in the 5th European Complex Systems\n  Conference, Jerusalem, Sept. 2008", "journal-ref": "The 5th European Complex Systems Conference (ECCS 2008),\n  Jerusalem, Sept. 2008", "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Support vector machines (SVMs) are an extremely successful type of\nclassification and regression algorithms. Building an SVM entails solving a\nconstrained convex quadratic programming problem, which is quadratic in the\nnumber of training samples. We introduce an efficient parallel implementation\nof an support vector regression solver, based on the Gaussian Belief\nPropagation algorithm (GaBP).\n  In this paper, we demonstrate that methods from the complex system domain\ncould be utilized for performing efficient distributed computation. We compare\nthe proposed algorithm to previously proposed distributed and single-node SVM\nsolvers. Our comparison shows that the proposed algorithm is just as accurate\nas these solvers, while being significantly faster, especially for large\ndatasets. We demonstrate scalability of the proposed algorithm to up to 1,024\ncomputing nodes and hundreds of thousands of data points using an IBM Blue Gene\nsupercomputer. As far as we know, our work is the largest parallel\nimplementation of belief propagation ever done, demonstrating the applicability\nof this algorithm for large scale distributed computing systems.\n", "versions": [{"version": "v1", "created": "Thu, 9 Oct 2008 12:56:43 GMT"}], "update_date": "2008-11-15", "authors_parsed": [["Bickson", "Danny", ""], ["Yom-Tov", "Elad", ""], ["Dolev", "Danny", ""]]}, {"id": "0810.2434", "submitter": "Edward Rosten", "authors": "Edward Rosten, Reid Porter, Tom Drummond", "title": "Faster and better: a machine learning approach to corner detection", "comments": "35 pages, 11 figures", "journal-ref": "IEEE Trans. PAMI, 32 (2010), 105--119", "doi": "10.1109/TPAMI.2008.275", "report-no": "07-3912", "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The repeatability and efficiency of a corner detector determines how likely\nit is to be useful in a real-world application. The repeatability is importand\nbecause the same scene viewed from different positions should yield features\nwhich correspond to the same real-world 3D locations [Schmid et al 2000]. The\nefficiency is important because this determines whether the detector combined\nwith further processing can operate at frame rate.\n  Three advances are described in this paper. First, we present a new heuristic\nfor feature detection, and using machine learning we derive a feature detector\nfrom this which can fully process live PAL video using less than 5% of the\navailable processing time. By comparison, most other detectors cannot even\noperate at frame rate (Harris detector 115%, SIFT 195%). Second, we generalize\nthe detector, allowing it to be optimized for repeatability, with little loss\nof efficiency. Third, we carry out a rigorous comparison of corner detectors\nbased on the above repeatability criterion applied to 3D scenes. We show that\ndespite being principally constructed for speed, on these stringent tests, our\nheuristic detector significantly outperforms existing feature detectors.\nFinally, the comparison demonstrates that using machine learning produces\nsignificant improvements in repeatability, yielding a detector that is both\nvery fast and very high quality.\n", "versions": [{"version": "v1", "created": "Tue, 14 Oct 2008 14:22:05 GMT"}], "update_date": "2010-07-09", "authors_parsed": [["Rosten", "Edward", ""], ["Porter", "Reid", ""], ["Drummond", "Tom", ""]]}, {"id": "0810.2764", "submitter": "Nir Ailon", "authors": "Nir Ailon", "title": "A Simple Linear Ranking Algorithm Using Query Dependent Intercept\n  Variables", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The LETOR website contains three information retrieval datasets used as a\nbenchmark for testing machine learning ideas for ranking. Algorithms\nparticipating in the challenge are required to assign score values to search\nresults for a collection of queries, and are measured using standard IR ranking\nmeasures (NDCG, precision, MAP) that depend only the relative score-induced\norder of the results. Similarly to many of the ideas proposed in the\nparticipating algorithms, we train a linear classifier. In contrast with other\nparticipating algorithms, we define an additional free variable (intercept, or\nbenchmark) for each query. This allows expressing the fact that results for\ndifferent queries are incomparable for the purpose of determining relevance.\nThe cost of this idea is the addition of relatively few nuisance parameters.\nOur approach is simple, and we used a standard logistic regression library to\ntest it. The results beat the reported participating algorithms. Hence, it\nseems promising to combine our approach with other more complex ideas.\n", "versions": [{"version": "v1", "created": "Wed, 15 Oct 2008 19:03:10 GMT"}], "update_date": "2008-10-16", "authors_parsed": [["Ailon", "Nir", ""]]}, {"id": "0810.3451", "submitter": "Istvan Szita", "authors": "Istv\\'an Szita, Andr\\'as L\\H{o}rincz", "title": "The many faces of optimism - Extended version", "comments": "Extended version of the homonymous ICML'08 paper, with proofs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The exploration-exploitation dilemma has been an intriguing and unsolved\nproblem within the framework of reinforcement learning. \"Optimism in the face\nof uncertainty\" and model building play central roles in advanced exploration\nmethods. Here, we integrate several concepts and obtain a fast and simple\nalgorithm. We show that the proposed algorithm finds a near-optimal policy in\npolynomial time, and give experimental evidence that it is robust and efficient\ncompared to its ascendants.\n", "versions": [{"version": "v1", "created": "Mon, 20 Oct 2008 02:09:16 GMT"}], "update_date": "2008-10-21", "authors_parsed": [["Szita", "Istv\u00e1n", ""], ["L\u0151rincz", "Andr\u00e1s", ""]]}, {"id": "0810.3525", "submitter": "Tshilidzi Marwala", "authors": "L. Masisi, V. Nelwamondo and T. Marwala", "title": "The use of entropy to measure structural diversity", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper entropy based methods are compared and used to measure\nstructural diversity of an ensemble of 21 classifiers. This measure is mostly\napplied in ecology, whereby species counts are used as a measure of diversity.\nThe measures used were Shannon entropy, Simpsons and the Berger Parker\ndiversity indexes. As the diversity indexes increased so did the accuracy of\nthe ensemble. An ensemble dominated by classifiers with the same structure\nproduced poor accuracy. Uncertainty rule from information theory was also used\nto further define diversity. Genetic algorithms were used to find the optimal\nensemble by using the diversity indices as the cost function. The method of\nvoting was used to aggregate the decisions.\n", "versions": [{"version": "v1", "created": "Mon, 20 Oct 2008 11:09:15 GMT"}], "update_date": "2008-10-21", "authors_parsed": [["Masisi", "L.", ""], ["Nelwamondo", "V.", ""], ["Marwala", "T.", ""]]}, {"id": "0810.3605", "submitter": "Pedro Alejandro Ortega", "authors": "Pedro A. Ortega, Daniel A. Braun", "title": "A Minimum Relative Entropy Principle for Learning and Acting", "comments": "36 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a method to construct an adaptive agent that is universal\nwith respect to a given class of experts, where each expert is an agent that\nhas been designed specifically for a particular environment. This adaptive\ncontrol problem is formalized as the problem of minimizing the relative entropy\nof the adaptive agent from the expert that is most suitable for the unknown\nenvironment. If the agent is a passive observer, then the optimal solution is\nthe well-known Bayesian predictor. However, if the agent is active, then its\npast actions need to be treated as causal interventions on the I/O stream\nrather than normal probability conditions. Here it is shown that the solution\nto this new variational problem is given by a stochastic controller called the\nBayesian control rule, which implements adaptive behavior as a mixture of\nexperts. Furthermore, it is shown that under mild assumptions, the Bayesian\ncontrol rule converges to the control law of the most suitable expert.\n", "versions": [{"version": "v1", "created": "Mon, 20 Oct 2008 16:47:47 GMT"}, {"version": "v2", "created": "Fri, 6 Mar 2009 11:13:09 GMT"}, {"version": "v3", "created": "Sun, 11 Apr 2010 00:35:51 GMT"}], "update_date": "2010-04-13", "authors_parsed": [["Ortega", "Pedro A.", ""], ["Braun", "Daniel A.", ""]]}, {"id": "0810.3828", "submitter": "Daoyi Dong", "authors": "Daoyi Dong, Chunlin Chen, Hanxiong Li and Tzyh-Jong Tarn", "title": "Quantum reinforcement learning", "comments": "13 pages, 7 figures, Latex", "journal-ref": "IEEE Transactions on Systems Man and Cybernetics Part B:\n  Cybernetics, Vol. 38, No. 5, pp.1207-1220, 2008", "doi": "10.1109/TSMCB.2008.925743", "report-no": null, "categories": "quant-ph cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The key approaches for machine learning, especially learning in unknown\nprobabilistic environments are new representations and computation mechanisms.\nIn this paper, a novel quantum reinforcement learning (QRL) method is proposed\nby combining quantum theory and reinforcement learning (RL). Inspired by the\nstate superposition principle and quantum parallelism, a framework of value\nupdating algorithm is introduced. The state (action) in traditional RL is\nidentified as the eigen state (eigen action) in QRL. The state (action) set can\nbe represented with a quantum superposition state and the eigen state (eigen\naction) can be obtained by randomly observing the simulated quantum state\naccording to the collapse postulate of quantum measurement. The probability of\nthe eigen action is determined by the probability amplitude, which is\nparallelly updated according to rewards. Some related characteristics of QRL\nsuch as convergence, optimality and balancing between exploration and\nexploitation are also analyzed, which shows that this approach makes a good\ntradeoff between exploration and exploitation using the probability amplitude\nand can speed up learning through the quantum parallelism. To evaluate the\nperformance and practicability of QRL, several simulated experiments are given\nand the results demonstrate the effectiveness and superiority of QRL algorithm\nfor some complex problems. The present work is also an effective exploration on\nthe application of quantum computation to artificial intelligence.\n", "versions": [{"version": "v1", "created": "Tue, 21 Oct 2008 13:38:33 GMT"}], "update_date": "2008-10-22", "authors_parsed": [["Dong", "Daoyi", ""], ["Chen", "Chunlin", ""], ["Li", "Hanxiong", ""], ["Tarn", "Tzyh-Jong", ""]]}, {"id": "0810.4401", "submitter": "Nic Schraudolph", "authors": "Nicol N. Schraudolph and Dmitry Kamenetsky", "title": "Efficient Exact Inference in Planar Ising Models", "comments": "Fixed a number of bugs in v1; added 10 pages of additional figures,\n  explanations, proofs, and experiments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give polynomial-time algorithms for the exact computation of lowest-energy\n(ground) states, worst margin violators, log partition functions, and marginal\nedge probabilities in certain binary undirected graphical models. Our approach\nprovides an interesting alternative to the well-known graph cut paradigm in\nthat it does not impose any submodularity constraints; instead we require\nplanarity to establish a correspondence with perfect matchings (dimer\ncoverings) in an expanded dual graph. We implement a unified framework while\ndelegating complex but well-understood subproblems (planar embedding,\nmaximum-weight perfect matching) to established algorithms for which efficient\nimplementations are freely available. Unlike graph cut methods, we can perform\npenalized maximum-likelihood as well as maximum-margin parameter estimation in\nthe associated conditional random fields (CRFs), and employ marginal posterior\nprobabilities as well as maximum a posteriori (MAP) states for prediction.\nMaximum-margin CRF parameter estimation on image denoising and segmentation\nproblems shows our approach to be efficient and effective. A C++ implementation\nis available from http://nic.schraudolph.org/isinf/\n", "versions": [{"version": "v1", "created": "Fri, 24 Oct 2008 08:49:09 GMT"}, {"version": "v2", "created": "Wed, 17 Dec 2008 06:47:01 GMT"}], "update_date": "2009-09-29", "authors_parsed": [["Schraudolph", "Nicol N.", ""], ["Kamenetsky", "Dmitry", ""]]}, {"id": "0810.4611", "submitter": "Nikolaos Vasiloglou", "authors": "Nikolaos Vasiloglou, Alexander G. Gray, David V. Anderson", "title": "Learning Isometric Separation Maps", "comments": "Submitted to the NIPS workshop on Kernel Learning:Automatic Selection\n  Of Kernels and now presented in MLSP 2009", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Maximum Variance Unfolding (MVU) and its variants have been very successful\nin embedding data-manifolds in lower dimensional spaces, often revealing the\ntrue intrinsic dimension. In this paper we show how to also incorporate\nsupervised class information into an MVU-like method without breaking its\nconvexity. We call this method the Isometric Separation Map and we show that\nthe resulting kernel matrix can be used as a binary/multiclass Support Vector\nMachine-like method in a semi-supervised (transductive) framework. We also show\nthat the method always finds a kernel matrix that linearly separates the\ntraining data exactly without projecting them in infinite dimensional spaces.\nIn traditional SVMs we choose a kernel and hope that the data become linearly\nseparable in the kernel space. In this paper we show how the hyperplane can be\nchosen ad-hoc and the kernel is trained so that data are always linearly\nseparable. Comparisons with Large Margin SVMs show comparable performance.\n", "versions": [{"version": "v1", "created": "Sat, 25 Oct 2008 15:09:28 GMT"}, {"version": "v2", "created": "Wed, 15 Apr 2009 18:13:59 GMT"}], "update_date": "2009-09-29", "authors_parsed": [["Vasiloglou", "Nikolaos", ""], ["Gray", "Alexander G.", ""], ["Anderson", "David V.", ""]]}, {"id": "0810.5484", "submitter": "Qiang Li", "authors": "Qiang Li, Yan He, Jing-ping Jiang", "title": "A Novel Clustering Algorithm Based on a Modified Model of Random Walk", "comments": "21 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  We introduce a modified model of random walk, and then develop two novel\nclustering algorithms based on it. In the algorithms, each data point in a\ndataset is considered as a particle which can move at random in space according\nto the preset rules in the modified model. Further, this data point may be also\nviewed as a local control subsystem, in which the controller adjusts its\ntransition probability vector in terms of the feedbacks of all data points, and\nthen its transition direction is identified by an event-generating function.\nFinally, the positions of all data points are updated. As they move in space,\ndata points collect gradually and some separating parts emerge among them\nautomatically. As a consequence, data points that belong to the same class are\nlocated at a same position, whereas those that belong to different classes are\naway from one another. Moreover, the experimental results have demonstrated\nthat data points in the test datasets are clustered reasonably and efficiently,\nand the comparison with other algorithms also provides an indication of the\neffectiveness of the proposed algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 30 Oct 2008 13:26:31 GMT"}], "update_date": "2008-10-31", "authors_parsed": [["Li", "Qiang", ""], ["He", "Yan", ""], ["Jiang", "Jing-ping", ""]]}, {"id": "0810.5551", "submitter": "Xinjia Chen", "authors": "Xinjia Chen", "title": "A Theory of Truncated Inverse Sampling", "comments": "31 pages, no figure, revised proofs", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG math.PR stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we have established a new framework of truncated inverse\nsampling for estimating mean values of non-negative random variables such as\nbinomial, Poisson, hyper-geometrical, and bounded variables. We have derived\nexplicit formulas and computational methods for designing sampling schemes to\nensure prescribed levels of precision and confidence for point estimators.\nMoreover, we have developed interval estimation methods.\n", "versions": [{"version": "v1", "created": "Thu, 30 Oct 2008 19:52:55 GMT"}, {"version": "v2", "created": "Tue, 11 Nov 2008 02:38:09 GMT"}], "update_date": "2013-11-05", "authors_parsed": [["Chen", "Xinjia", ""]]}, {"id": "0810.5573", "submitter": "David Correa Martins Jr", "authors": "Marcelo Ris, Junior Barrera, David C. Martins Jr", "title": "A branch-and-bound feature selection algorithm for U-shaped cost\n  functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.DS cs.LG", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  This paper presents the formulation of a combinatorial optimization problem\nwith the following characteristics: i.the search space is the power set of a\nfinite set structured as a Boolean lattice; ii.the cost function forms a\nU-shaped curve when applied to any lattice chain. This formulation applies for\nfeature selection in the context of pattern recognition. The known approaches\nfor this problem are branch-and-bound algorithms and heuristics, that explore\npartially the search space. Branch-and-bound algorithms are equivalent to the\nfull search, while heuristics are not. This paper presents a branch-and-bound\nalgorithm that differs from the others known by exploring the lattice structure\nand the U-shaped chain curves of the search space. The main contribution of\nthis paper is the architecture of this algorithm that is based on the\nrepresentation and exploration of the search space by new lattice properties\nproven here. Several experiments, with well known public data, indicate the\nsuperiority of the proposed method to SFFS, which is a popular heuristic that\ngives good results in very short computational time. In all experiments, the\nproposed method got better or equal results in similar or even smaller\ncomputational time.\n", "versions": [{"version": "v1", "created": "Thu, 30 Oct 2008 20:24:28 GMT"}], "update_date": "2008-11-03", "authors_parsed": [["Ris", "Marcelo", ""], ["Barrera", "Junior", ""], ["Martins", "David C.", "Jr"]]}, {"id": "0810.5631", "submitter": "Marcus Hutter", "authors": "Marcus Hutter and Shane Legg", "title": "Temporal Difference Updating without a Learning Rate", "comments": "12 pages, 6 figures", "journal-ref": "Advances in Neural Information Processing Systems 20 (NIPS 2008)\n  pages 705-712", "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive an equation for temporal difference learning from statistical\nprinciples. Specifically, we start with the variational principle and then\nbootstrap to produce an updating rule for discounted state value estimates. The\nresulting equation is similar to the standard equation for temporal difference\nlearning with eligibility traces, so called TD(lambda), however it lacks the\nparameter alpha that specifies the learning rate. In the place of this free\nparameter there is now an equation for the learning rate that is specific to\neach state transition. We experimentally test this new learning rule against\nTD(lambda) and find that it offers superior performance in various settings.\nFinally, we make some preliminary investigations into how to extend our new\ntemporal difference algorithm to reinforcement learning. To do this we combine\nour update equation with both Watkins' Q(lambda) and Sarsa(lambda) and find\nthat it again offers superior performance without a learning rate parameter.\n", "versions": [{"version": "v1", "created": "Fri, 31 Oct 2008 07:15:01 GMT"}], "update_date": "2008-11-03", "authors_parsed": [["Hutter", "Marcus", ""], ["Legg", "Shane", ""]]}, {"id": "0810.5636", "submitter": "Marcus Hutter", "authors": "Daniil Ryabko and Marcus Hutter", "title": "On the Possibility of Learning in Reactive Environments with Arbitrary\n  Dependence", "comments": "20 pages", "journal-ref": "Theoretical Computer Science, 405:3 (2008) pages 274-284", "doi": null, "report-no": "IDSIA-08-08", "categories": "cs.LG cs.AI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of reinforcement learning in which observations may\nexhibit an arbitrary form of stochastic dependence on past observations and\nactions, i.e. environments more general than (PO)MDPs. The task for an agent is\nto attain the best possible asymptotic reward where the true generating\nenvironment is unknown but belongs to a known countable family of environments.\nWe find some sufficient conditions on the class of environments under which an\nagent exists which attains the best asymptotic reward for any environment in\nthe class. We analyze how tight these conditions are and how they relate to\ndifferent probabilistic assumptions known in reinforcement learning and related\nfields, such as Markov Decision Processes and mixing conditions.\n", "versions": [{"version": "v1", "created": "Fri, 31 Oct 2008 07:58:31 GMT"}], "update_date": "2009-12-30", "authors_parsed": [["Ryabko", "Daniil", ""], ["Hutter", "Marcus", ""]]}]