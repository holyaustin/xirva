[{"id": "1712.00003", "submitter": "Matthew Toews", "authors": "Ahmad Chaddad, Behnaz Naisiri, Marco Pedersoli, Eric Granger,\n  Christian Desrosiers, Matthew Toews", "title": "Modeling Information Flow Through Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a principled information theoretic analysis of\nclassification for deep neural network structures, e.g. convolutional neural\nnetworks (CNN). The output of convolutional filters is modeled as a random\nvariable Y conditioned on the object class C and network filter bank F. The\nconditional entropy (CENT) H(Y |C,F) is shown in theory and experiments to be a\nhighly compact and class-informative code, that can be computed from the filter\noutputs throughout an existing CNN and used to obtain higher classification\nresults than the original CNN itself. Experiments demonstrate the effectiveness\nof CENT feature analysis in two separate CNN classification contexts. 1) In the\nclassification of neurodegeneration due to Alzheimer's disease (AD) and natural\naging from 3D magnetic resonance image (MRI) volumes, 3 CENT features result in\nan AUC=94.6% for whole-brain AD classification, the highest reported accuracy\non the public OASIS dataset used and 12% higher than the softmax output of the\noriginal CNN trained for the task. 2) In the context of visual object\nclassification from 2D photographs, transfer learning based on a small set of\nCENT features identified throughout an existing CNN leads to AUC values\ncomparable to the 1000-feature softmax output of the original network when\nclassifying previously unseen object categories. The general information\ntheoretical analysis explains various recent CNN design successes, e.g. densely\nconnected CNN architectures, and provides insights for future research\ndirections in deep learning.\n", "versions": [{"version": "v1", "created": "Wed, 29 Nov 2017 23:09:58 GMT"}], "update_date": "2017-12-04", "authors_parsed": [["Chaddad", "Ahmad", ""], ["Naisiri", "Behnaz", ""], ["Pedersoli", "Marco", ""], ["Granger", "Eric", ""], ["Desrosiers", "Christian", ""], ["Toews", "Matthew", ""]]}, {"id": "1712.00004", "submitter": "Martin Klissarov", "authors": "Martin Klissarov, Pierre-Luc Bacon, Jean Harb and Doina Precup", "title": "Learnings Options End-to-End for Continuous Action Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present new results on learning temporally extended actions for\ncontinuoustasks, using the options framework (Suttonet al.[1999b], Precup\n[2000]). In orderto achieve this goal we work with the option-critic\narchitecture (Baconet al.[2017])using a deliberation cost and train it with\nproximal policy optimization (Schulmanet al.[2017]) instead of vanilla policy\ngradient. Results on Mujoco domains arepromising, but lead to interesting\nquestions aboutwhena given option should beused, an issue directly connected to\nthe use of initiation sets.\n", "versions": [{"version": "v1", "created": "Thu, 30 Nov 2017 00:45:09 GMT"}], "update_date": "2017-12-04", "authors_parsed": [["Klissarov", "Martin", ""], ["Bacon", "Pierre-Luc", ""], ["Harb", "Jean", ""], ["Precup", "Doina", ""]]}, {"id": "1712.00006", "submitter": "Shangtong Zhang", "authors": "Shangtong Zhang, Osmar R. Zaiane", "title": "Comparing Deep Reinforcement Learning and Evolutionary Methods in\n  Continuous Control", "comments": "NIPS 2017 Deep Reinforcement Learning Symposium", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning and the Evolutionary Strategy are two major approaches\nin addressing complicated control problems. Both are strong contenders and have\ntheir own devotee communities. Both groups have been very active in developing\nnew advances in their own domain and devising, in recent years, leading-edge\ntechniques to address complex continuous control tasks. Here, in the context of\nDeep Reinforcement Learning, we formulate a parallelized version of the\nProximal Policy Optimization method and a Deep Deterministic Policy Gradient\nmethod. Moreover, we conduct a thorough comparison between the state-of-the-art\ntechniques in both camps fro continuous control; evolutionary methods and Deep\nReinforcement Learning methods. The results show there is no consistent winner.\n", "versions": [{"version": "v1", "created": "Thu, 30 Nov 2017 03:40:06 GMT"}, {"version": "v2", "created": "Wed, 7 Mar 2018 16:35:22 GMT"}], "update_date": "2018-03-08", "authors_parsed": [["Zhang", "Shangtong", ""], ["Zaiane", "Osmar R.", ""]]}, {"id": "1712.00010", "submitter": "You Jin Kim", "authors": "You Jin Kim (1), Yun-Geun Lee (1), Jeong Whun Kim (2), Jin Joo Park\n  (2), Borim Ryu (2), Jung-Woo Ha (1) ((1) Clova AI Research, NAVER Corp., (2)\n  Seoul National University Bundang Hospital)", "title": "Highrisk Prediction from Electronic Medical Records via Deep Attention\n  Networks", "comments": "Accepted poster at NIPS 2017 Workshop on Machine Learning for Health\n  (https://ml4health.github.io/2017/)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting highrisk vascular diseases is a significant issue in the medical\ndomain. Most predicting methods predict the prognosis of patients from\npathological and radiological measurements, which are expensive and require\nmuch time to be analyzed. Here we propose deep attention models that predict\nthe onset of the high risky vascular disease from symbolic medical histories\nsequence of hypertension patients such as ICD-10 and pharmacy codes only,\nMedical History-based Prediction using Attention Network (MeHPAN). We\ndemonstrate two types of attention models based on 1) bidirectional gated\nrecurrent unit (R-MeHPAN) and 2) 1D convolutional multilayer model (C-MeHPAN).\nTwo MeHPAN models are evaluated on approximately 50,000 hypertension patients\nwith respect to precision, recall, f1-measure and area under the curve (AUC).\nExperimental results show that our MeHPAN methods outperform standard\nclassification models. Comparing two MeHPANs, R-MeHPAN provides more better\ndiscriminative capability with respect to all metrics while C-MeHPAN presents\nmuch shorter training time with competitive accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 30 Nov 2017 15:21:50 GMT"}], "update_date": "2017-12-04", "authors_parsed": [["Kim", "You Jin", ""], ["Lee", "Yun-Geun", ""], ["Kim", "Jeong Whun", ""], ["Park", "Jin Joo", ""], ["Ryu", "Borim", ""], ["Ha", "Jung-Woo", ""]]}, {"id": "1712.00028", "submitter": "Genevieve Flaspohler", "authors": "Genevieve Flaspohler, Nicholas Roy and Yogesh Girdhar", "title": "Feature discovery and visualization of robot mission data using\n  convolutional autoencoders and Bayesian nonparametric topic models", "comments": "8 pages", "journal-ref": null, "doi": "10.1109/IROS.2017.8202130", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The gap between our ability to collect interesting data and our ability to\nanalyze these data is growing at an unprecedented rate. Recent algorithmic\nattempts to fill this gap have employed unsupervised tools to discover\nstructure in data. Some of the most successful approaches have used\nprobabilistic models to uncover latent thematic structure in discrete data.\nDespite the success of these models on textual data, they have not generalized\nas well to image data, in part because of the spatial and temporal structure\nthat may exist in an image stream.\n  We introduce a novel unsupervised machine learning framework that\nincorporates the ability of convolutional autoencoders to discover features\nfrom images that directly encode spatial information, within a Bayesian\nnonparametric topic model that discovers meaningful latent patterns within\ndiscrete data. By using this hybrid framework, we overcome the fundamental\ndependency of traditional topic models on rigidly hand-coded data\nrepresentations, while simultaneously encoding spatial dependency in our topics\nwithout adding model complexity. We apply this model to the motivating\napplication of high-level scene understanding and mission summarization for\nexploratory marine robots. Our experiments on a seafloor dataset collected by a\nmarine robot show that the proposed hybrid framework outperforms current\nstate-of-the-art approaches on the task of unsupervised seafloor terrain\ncharacterization.\n", "versions": [{"version": "v1", "created": "Thu, 30 Nov 2017 19:02:34 GMT"}], "update_date": "2018-01-23", "authors_parsed": [["Flaspohler", "Genevieve", ""], ["Roy", "Nicholas", ""], ["Girdhar", "Yogesh", ""]]}, {"id": "1712.00032", "submitter": "Xavier Roynard", "authors": "Xavier Roynard and Jean-Emmanuel Deschaud and Fran\\c{c}ois Goulette", "title": "Paris-Lille-3D: a large and high-quality ground truth urban point cloud\n  dataset for automatic segmentation and classification", "comments": "preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new Urban Point Cloud Dataset for Automatic\nSegmentation and Classification acquired by Mobile Laser Scanning (MLS). We\ndescribe how the dataset is obtained from acquisition to post-processing and\nlabeling. This dataset can be used to learn classification algorithm, however,\ngiven that a great attention has been paid to the split between the different\nobjects, this dataset can also be used to learn the segmentation. The dataset\nconsists of around 2km of MLS point cloud acquired in two cities. The number of\npoints and range of classes make us consider that it can be used to train\nDeep-Learning methods. Besides we show some results of automatic segmentation\nand classification. The dataset is available at:\nhttp://caor-mines-paristech.fr/fr/paris-lille-3d-dataset/\n", "versions": [{"version": "v1", "created": "Thu, 30 Nov 2017 19:08:52 GMT"}, {"version": "v2", "created": "Tue, 10 Apr 2018 15:53:58 GMT"}], "update_date": "2018-04-11", "authors_parsed": [["Roynard", "Xavier", ""], ["Deschaud", "Jean-Emmanuel", ""], ["Goulette", "Fran\u00e7ois", ""]]}, {"id": "1712.00076", "submitter": "Ryan Kim", "authors": "Ryan Gary Kim, Janardhan Rao Doppa, Partha Pratim Pande, Diana\n  Marculescu, Radu Marculescu", "title": "Machine Learning and Manycore Systems Design: A Serendipitous Symbiosis", "comments": "To appear in a future publication of IEEE Computer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tight collaboration between experts of machine learning and manycore system\ndesign is necessary to create a data-driven manycore design framework that\nintegrates both learning and expert knowledge. Such a framework will be\nnecessary to address the rising complexity of designing large-scale manycore\nsystems and machine learning techniques.\n", "versions": [{"version": "v1", "created": "Thu, 30 Nov 2017 20:56:17 GMT"}], "update_date": "2017-12-11", "authors_parsed": [["Kim", "Ryan Gary", ""], ["Doppa", "Janardhan Rao", ""], ["Pande", "Partha Pratim", ""], ["Marculescu", "Diana", ""], ["Marculescu", "Radu", ""]]}, {"id": "1712.00111", "submitter": "Yanjun Li", "authors": "Yanjun Li, Kiryung Lee, Yoram Bresler", "title": "Blind Gain and Phase Calibration via Sparse Spectral Methods", "comments": "28 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CV cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blind gain and phase calibration (BGPC) is a bilinear inverse problem\ninvolving the determination of unknown gains and phases of the sensing system,\nand the unknown signal, jointly. BGPC arises in numerous applications, e.g.,\nblind albedo estimation in inverse rendering, synthetic aperture radar\nautofocus, and sensor array auto-calibration. In some cases, sparse structure\nin the unknown signal alleviates the ill-posedness of BGPC. Recently there has\nbeen renewed interest in solutions to BGPC with careful analysis of error\nbounds. In this paper, we formulate BGPC as an eigenvalue/eigenvector problem,\nand propose to solve it via power iteration, or in the sparsity or joint\nsparsity case, via truncated power iteration. Under certain assumptions, the\nunknown gains, phases, and the unknown signal can be recovered simultaneously.\nNumerical experiments show that power iteration algorithms work not only in the\nregime predicted by our main results, but also in regimes where theoretical\nanalysis is limited. We also show that our power iteration algorithms for BGPC\ncompare favorably with competing algorithms in adversarial conditions, e.g.,\nwith noisy measurement or with a bad initial estimate.\n", "versions": [{"version": "v1", "created": "Thu, 30 Nov 2017 22:46:14 GMT"}], "update_date": "2017-12-04", "authors_parsed": [["Li", "Yanjun", ""], ["Lee", "Kiryung", ""], ["Bresler", "Yoram", ""]]}, {"id": "1712.00117", "submitter": "I\\~nigo Urteaga", "authors": "I\\~nigo Urteaga, David J. Albers, Marija Vlajic Wheeler, Anna Druet,\n  Hans Raffauf and No\\'emie Elhadad", "title": "Towards Personalized Modeling of the Female Hormonal Cycle: Experiments\n  with Mechanistic Models and Gaussian Processes", "comments": "Accepted at NIPS 2017 Workshop on Machine Learning for Health\n  (https://ml4health.github.io/2017/)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a novel task for machine learning in healthcare,\nnamely personalized modeling of the female hormonal cycle. The motivation for\nthis work is to model the hormonal cycle and predict its phases in time, both\nfor healthy individuals and for those with disorders of the reproductive\nsystem. Because there are individual differences in the menstrual cycle, we are\nparticularly interested in personalized models that can account for individual\nidiosyncracies, towards identifying phenotypes of menstrual cycles. As a first\nstep, we consider the hormonal cycle as a set of observations through time. We\nuse a previously validated mechanistic model to generate realistic hormonal\npatterns, and experiment with Gaussian process regression to estimate their\nvalues over time. Specifically, we are interested in the feasibility of\npredicting menstrual cycle phases under varying learning conditions: number of\ncycles used for training, hormonal measurement noise and sampling rates, and\ninformed vs. agnostic sampling of hormonal measurements. Our results indicate\nthat Gaussian processes can help model the female menstrual cycle. We discuss\nthe implications of our experiments in the context of modeling the female\nmenstrual cycle.\n", "versions": [{"version": "v1", "created": "Thu, 30 Nov 2017 23:24:08 GMT"}], "update_date": "2017-12-04", "authors_parsed": [["Urteaga", "I\u00f1igo", ""], ["Albers", "David J.", ""], ["Wheeler", "Marija Vlajic", ""], ["Druet", "Anna", ""], ["Raffauf", "Hans", ""], ["Elhadad", "No\u00e9mie", ""]]}, {"id": "1712.00126", "submitter": "Tammo Rukat", "authors": "Tammo Rukat, Dustin Lange, C\\'edric Archambeau", "title": "An interpretable latent variable model for attribute applicability in\n  the Amazon catalogue", "comments": "Presented at NIPS 2017 Symposium on Interpretable Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning attribute applicability of products in the Amazon catalog (e.g.,\npredicting that a shoe should have a value for size, but not for battery-type\nat scale is a challenge. The need for an interpretable model is contingent on\n(1) the lack of ground truth training data, (2) the need to utilise prior\ninformation about the underlying latent space and (3) the ability to understand\nthe quality of predictions on new, unseen data. To this end, we develop the\nMaxMachine, a probabilistic latent variable model that learns distributed\nbinary representations, associated to sets of features that are likely to\nco-occur in the data. Layers of MaxMachines can be stacked such that higher\nlayers encode more abstract information. Any set of variables can be clamped to\nencode prior information. We develop fast sampling based posterior inference.\nPreliminary results show that the model improves over the baseline in 17 out of\n19 product groups and provides qualitatively reasonable predictions.\n", "versions": [{"version": "v1", "created": "Thu, 30 Nov 2017 23:36:20 GMT"}, {"version": "v2", "created": "Mon, 4 Dec 2017 09:14:20 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Rukat", "Tammo", ""], ["Lange", "Dustin", ""], ["Archambeau", "C\u00e9dric", ""]]}, {"id": "1712.00127", "submitter": "Andrea Rocchetto", "authors": "Andrea Rocchetto, Scott Aaronson, Simone Severini, Gonzalo Carvacho,\n  Davide Poderini, Iris Agresti, Marco Bentivegna, Fabio Sciarrino", "title": "Experimental learning of quantum states", "comments": "11 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The number of parameters describing a quantum state is well known to grow\nexponentially with the number of particles. This scaling clearly limits our\nability to do tomography to systems with no more than a few qubits and has been\nused to argue against the universal validity of quantum mechanics itself.\nHowever, from a computational learning theory perspective, it can be shown\nthat, in a probabilistic setting, quantum states can be approximately learned\nusing only a linear number of measurements. Here we experimentally demonstrate\nthis linear scaling in optical systems with up to 6 qubits. Our results\nhighlight the power of computational learning theory to investigate quantum\ninformation, provide the first experimental demonstration that quantum states\ncan be \"probably approximately learned\" with access to a number of copies of\nthe state that scales linearly with the number of qubits, and pave the way to\nprobing quantum states at new, larger scales.\n", "versions": [{"version": "v1", "created": "Thu, 30 Nov 2017 23:37:26 GMT"}], "update_date": "2017-12-04", "authors_parsed": [["Rocchetto", "Andrea", ""], ["Aaronson", "Scott", ""], ["Severini", "Simone", ""], ["Carvacho", "Gonzalo", ""], ["Poderini", "Davide", ""], ["Agresti", "Iris", ""], ["Bentivegna", "Marco", ""], ["Sciarrino", "Fabio", ""]]}, {"id": "1712.00164", "submitter": "Alexandre Yahi", "authors": "Alexandre Yahi, Rami Vanguri, No\\'emie Elhadad, Nicholas P. Tatonetti", "title": "Generative Adversarial Networks for Electronic Health Records: A\n  Framework for Exploring and Evaluating Methods for Predicting Drug-Induced\n  Laboratory Test Trajectories", "comments": "NIPS ML4H 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) represent a promising class of\ngenerative networks that combine neural networks with game theory. From\ngenerating realistic images and videos to assisting musical creation, GANs are\ntransforming many fields of arts and sciences. However, their application to\nhealthcare has not been fully realized, more specifically in generating\nelectronic health records (EHR) data. In this paper, we propose a framework for\nexploring the value of GANs in the context of continuous laboratory time series\ndata. We devise an unsupervised evaluation method that measures the predictive\npower of synthetic laboratory test time series. Further, we show that when it\ncomes to predicting the impact of drug exposure on laboratory test data,\nincorporating representation learning of the training cohorts prior to training\nGAN models is beneficial.\n", "versions": [{"version": "v1", "created": "Fri, 1 Dec 2017 02:33:33 GMT"}], "update_date": "2017-12-04", "authors_parsed": [["Yahi", "Alexandre", ""], ["Vanguri", "Rami", ""], ["Elhadad", "No\u00e9mie", ""], ["Tatonetti", "Nicholas P.", ""]]}, {"id": "1712.00166", "submitter": "Sungkyun Chang", "authors": "Sungkyun Chang, Juheon Lee, Sang Keun Choe and Kyogu Lee", "title": "Audio Cover Song Identification using Convolutional Neural Network", "comments": "NIPS 2017 Workshop on Machine Learning for Audio (ML4A), Long Beach,\n  CA, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new approach to cover song identification using a\nCNN (convolutional neural network). Most previous studies extract the feature\nvectors that characterize the cover song relation from a pair of songs and used\nit to compute the (dis)similarity between the two songs. Based on the\nobservation that there is a meaningful pattern between cover songs and that\nthis can be learned, we have reformulated the cover song identification problem\nin a machine learning framework. To do this, we first build the CNN using as an\ninput a cross-similarity matrix generated from a pair of songs. We then\nconstruct the data set composed of cover song pairs and non-cover song pairs,\nwhich are used as positive and negative training samples, respectively. The\ntrained CNN outputs the probability of being in the cover song relation given a\ncross-similarity matrix generated from any two pieces of music and identifies\nthe cover song by ranking on the probability. Experimental results show that\nthe proposed algorithm achieves performance better than or comparable to the\nstate-of-the-art.\n", "versions": [{"version": "v1", "created": "Fri, 1 Dec 2017 02:45:46 GMT"}, {"version": "v2", "created": "Mon, 26 Oct 2020 14:34:40 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Chang", "Sungkyun", ""], ["Lee", "Juheon", ""], ["Choe", "Sang Keun", ""], ["Lee", "Kyogu", ""]]}, {"id": "1712.00181", "submitter": "Kelly Peterson", "authors": "Kelly Peterson, Ognjen Rudovic, Ricardo Guerrero, Rosalind W. Picard", "title": "Personalized Gaussian Processes for Future Prediction of Alzheimer's\n  Disease Progression", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce the use of a personalized Gaussian Process model\n(pGP) to predict the key metrics of Alzheimer's Disease progression (MMSE,\nADAS-Cog13, CDRSB and CS) based on each patient's previous visits. We start by\nlearning a population-level model using multi-modal data from previously seen\npatients using the base Gaussian Process (GP) regression. Then, this model is\nadapted sequentially over time to a new patient using domain adaptive GPs to\nform the patient's pGP. We show that this new approach, together with an\nauto-regressive formulation, leads to significant improvements in forecasting\nfuture clinical status and cognitive scores for target patients when compared\nto modeling the population with traditional GPs.\n", "versions": [{"version": "v1", "created": "Fri, 1 Dec 2017 04:05:27 GMT"}, {"version": "v2", "created": "Mon, 5 Mar 2018 20:19:25 GMT"}, {"version": "v3", "created": "Mon, 12 Mar 2018 17:31:34 GMT"}, {"version": "v4", "created": "Fri, 4 May 2018 00:39:49 GMT"}], "update_date": "2018-05-07", "authors_parsed": [["Peterson", "Kelly", ""], ["Rudovic", "Ognjen", ""], ["Guerrero", "Ricardo", ""], ["Picard", "Rosalind W.", ""]]}, {"id": "1712.00206", "submitter": "Alessandro De Palma", "authors": "Alessandro De Palma, Erik Hemberg, Una-May O'Reilly", "title": "Distributed Stratified Locality Sensitive Hashing for Critical Event\n  Prediction in the Cloud", "comments": "Accepted poster at NIPS 2017 Workshop on Machine Learning for Health\n  (https://ml4health.github.io/2017/)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The availability of massive healthcare data repositories calls for efficient\ntools for data-driven medicine. We introduce a distributed system for\nStratified Locality Sensitive Hashing to perform fast similarity-based\nprediction on large medical waveform datasets. Our implementation, for an ICU\nuse case, prioritizes latency over throughput and is targeted at a cloud\nenvironment. We demonstrate our system on Acute Hypotensive Episode prediction\nfrom Arterial Blood Pressure waveforms. On a dataset of $1.37$ million points,\nwe show scaling up to $40$ processors and a $21\\times$ speedup in number of\ncomparisons to parallel exhaustive search at the price of a $10\\%$ Matthews\ncorrelation coefficient (MCC) loss. Furthermore, if additional MCC loss can be\ntolerated, our system achieves speedups up to two orders of magnitude.\n", "versions": [{"version": "v1", "created": "Fri, 1 Dec 2017 06:23:22 GMT"}], "update_date": "2017-12-04", "authors_parsed": [["De Palma", "Alessandro", ""], ["Hemberg", "Erik", ""], ["O'Reilly", "Una-May", ""]]}, {"id": "1712.00244", "submitter": "Thanh Hai Nguyen", "authors": "Thanh Hai Nguyen, Yann Chevaleyre, Edi Prifti, Nataliya Sokolovska and\n  Jean-Daniel Zucker", "title": "Deep Learning for Metagenomic Data: using 2D Embeddings and\n  Convolutional Neural Networks", "comments": "Accepted at NIPS 2017 Workshop on Machine Learning for Health\n  (https://ml4health.github.io/2017/); In Proceedings of the NIPS ML4H 2017\n  Workshop in Long Beach, CA, USA;", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning (DL) techniques have had unprecedented success when applied to\nimages, waveforms, and texts to cite a few. In general, when the sample size\n(N) is much greater than the number of features (d), DL outperforms previous\nmachine learning (ML) techniques, often through the use of convolution neural\nnetworks (CNNs). However, in many bioinformatics ML tasks, we encounter the\nopposite situation where d is greater than N. In these situations, applying DL\ntechniques (such as feed-forward networks) would lead to severe overfitting.\nThus, sparse ML techniques (such as LASSO e.g.) usually yield the best results\non these tasks. In this paper, we show how to apply CNNs on data which do not\nhave originally an image structure (in particular on metagenomic data). Our\nfirst contribution is to show how to map metagenomic data in a meaningful way\nto 1D or 2D images. Based on this representation, we then apply a CNN, with the\naim of predicting various diseases. The proposed approach is applied on six\ndifferent datasets including in total over 1000 samples from various diseases.\nThis approach could be a promising one for prediction tasks in the\nbioinformatics field.\n", "versions": [{"version": "v1", "created": "Fri, 1 Dec 2017 09:18:04 GMT"}], "update_date": "2017-12-04", "authors_parsed": [["Nguyen", "Thanh Hai", ""], ["Chevaleyre", "Yann", ""], ["Prifti", "Edi", ""], ["Sokolovska", "Nataliya", ""], ["Zucker", "Jean-Daniel", ""]]}, {"id": "1712.00287", "submitter": "Stefan Webb", "authors": "Stefan Webb, Adam Golinski, Robert Zinkov, N. Siddharth, Tom\n  Rainforth, Yee Whye Teh, Frank Wood", "title": "Faithful Inversion of Generative Models for Effective Amortized\n  Inference", "comments": "To appear at the 32nd Conference on Neural Information Processing\n  Systems (NeurIPS 2018), Montreal, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inference amortization methods share information across multiple\nposterior-inference problems, allowing each to be carried out more efficiently.\nGenerally, they require the inversion of the dependency structure in the\ngenerative model, as the modeller must learn a mapping from observations to\ndistributions approximating the posterior. Previous approaches have involved\ninverting the dependency structure in a heuristic way that fails to capture\nthese dependencies correctly, thereby limiting the achievable accuracy of the\nresulting approximations. We introduce an algorithm for faithfully, and\nminimally, inverting the graphical model structure of any generative model.\nSuch inverses have two crucial properties: (a) they do not encode any\nindependence assertions that are absent from the model and; (b) they are local\nmaxima for the number of true independencies encoded. We prove the correctness\nof our approach and empirically show that the resulting minimally faithful\ninverses lead to better inference amortization than existing heuristic\napproaches.\n", "versions": [{"version": "v1", "created": "Fri, 1 Dec 2017 12:08:03 GMT"}, {"version": "v2", "created": "Sat, 10 Feb 2018 18:16:17 GMT"}, {"version": "v3", "created": "Tue, 29 May 2018 15:47:44 GMT"}, {"version": "v4", "created": "Wed, 24 Oct 2018 15:58:18 GMT"}, {"version": "v5", "created": "Thu, 29 Nov 2018 14:27:47 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Webb", "Stefan", ""], ["Golinski", "Adam", ""], ["Zinkov", "Robert", ""], ["Siddharth", "N.", ""], ["Rainforth", "Tom", ""], ["Teh", "Yee Whye", ""], ["Wood", "Frank", ""]]}, {"id": "1712.00310", "submitter": "Jakub Tomczak Ph.D.", "authors": "Jakub M. Tomczak, Maximilian Ilse, Max Welling", "title": "Deep Learning with Permutation-invariant Operator for Multi-instance\n  Histopathology Classification", "comments": "Workshop on \"Medical Imaging meets NIPS\" at NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The computer-aided analysis of medical scans is a longstanding goal in the\nmedical imaging field. Currently, deep learning has became a dominant\nmethodology for supporting pathologists and radiologist. Deep learning\nalgorithms have been successfully applied to digital pathology and radiology,\nnevertheless, there are still practical issues that prevent these tools to be\nwidely used in practice. The main obstacles are low number of available cases\nand large size of images (a.k.a. the small n, large p problem in machine\nlearning), and a very limited access to annotation at a pixel level that can\nlead to severe overfitting and large computational requirements. We propose to\nhandle these issues by introducing a framework that processes a medical image\nas a collection of small patches using a single, shared neural network. The\nfinal diagnosis is provided by combining scores of individual patches using a\npermutation-invariant operator (combination). In machine learning community\nsuch approach is called a multi-instance learning (MIL).\n", "versions": [{"version": "v1", "created": "Fri, 1 Dec 2017 13:30:36 GMT"}, {"version": "v2", "created": "Tue, 5 Dec 2017 11:29:27 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Tomczak", "Jakub M.", ""], ["Ilse", "Maximilian", ""], ["Welling", "Max", ""]]}, {"id": "1712.00321", "submitter": "Sebastian Raschka SR", "authors": "Vahid Mirjalili, Sebastian Raschka, Anoop Namboodiri, and Arun Ross", "title": "Semi-Adversarial Networks: Convolutional Autoencoders for Imparting\n  Privacy to Face Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we design and evaluate a convolutional autoencoder that\nperturbs an input face image to impart privacy to a subject. Specifically, the\nproposed autoencoder transforms an input face image such that the transformed\nimage can be successfully used for face recognition but not for gender\nclassification. In order to train this autoencoder, we propose a novel training\nscheme, referred to as semi-adversarial training in this work. The training is\nfacilitated by attaching a semi-adversarial module consisting of a pseudo\ngender classifier and a pseudo face matcher to the autoencoder. The objective\nfunction utilized for training this network has three terms: one to ensure that\nthe perturbed image is a realistic face image; another to ensure that the\ngender attributes of the face are confounded; and a third to ensure that\nbiometric recognition performance due to the perturbed image is not impacted.\nExtensive experiments confirm the efficacy of the proposed architecture in\nextending gender privacy to face images.\n", "versions": [{"version": "v1", "created": "Fri, 1 Dec 2017 14:05:50 GMT"}, {"version": "v2", "created": "Mon, 4 Dec 2017 16:19:05 GMT"}, {"version": "v3", "created": "Thu, 3 May 2018 03:09:02 GMT"}], "update_date": "2018-05-04", "authors_parsed": [["Mirjalili", "Vahid", ""], ["Raschka", "Sebastian", ""], ["Namboodiri", "Anoop", ""], ["Ross", "Arun", ""]]}, {"id": "1712.00328", "submitter": "Hongbin Pei", "authors": "Hongbin Pei, Bo Yang, Jiming Liu, Lei Dong", "title": "Group Sparse Bayesian Learning for Active Surveillance on Epidemic\n  Dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting epidemic dynamics is of great value in understanding and\ncontrolling diffusion processes, such as infectious disease spread and\ninformation propagation. This task is intractable, especially when surveillance\nresources are very limited. To address the challenge, we study the problem of\nactive surveillance, i.e., how to identify a small portion of system components\nas sentinels to effect monitoring, such that the epidemic dynamics of an entire\nsystem can be readily predicted from the partial data collected by such\nsentinels. We propose a novel measure, the gamma value, to identify the\nsentinels by modeling a sentinel network with row sparsity structure. We design\na flexible group sparse Bayesian learning algorithm to mine the sentinel\nnetwork suitable for handling both linear and non-linear dynamical systems by\nusing the expectation maximization method and variational approximation. The\nefficacy of the proposed algorithm is theoretically analyzed and empirically\nvalidated using both synthetic and real-world data.\n", "versions": [{"version": "v1", "created": "Tue, 21 Nov 2017 07:09:29 GMT"}], "update_date": "2017-12-04", "authors_parsed": [["Pei", "Hongbin", ""], ["Yang", "Bo", ""], ["Liu", "Jiming", ""], ["Dong", "Lei", ""]]}, {"id": "1712.00334", "submitter": "Fabio Paolizzo", "authors": "Fabio Paolizzo", "title": "Enabling Embodied Analogies in Intelligent Music Systems", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CL cs.IR cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present methodology is aimed at cross-modal machine learning and uses\nmultidisciplinary tools and methods drawn from a broad range of areas and\ndisciplines, including music, systematic musicology, dance, motion capture,\nhuman-computer interaction, computational linguistics and audio signal\nprocessing. Main tasks include: (1) adapting wisdom-of-the-crowd approaches to\nembodiment in music and dance performance to create a dataset of music and\nmusic lyrics that covers a variety of emotions, (2) applying\naudio/language-informed machine learning techniques to that dataset to identify\nautomatically the emotional content of the music and the lyrics, and (3)\nintegrating motion capture data from a Vicon system and dancers performing on\nthat music.\n", "versions": [{"version": "v1", "created": "Thu, 30 Nov 2017 08:27:08 GMT"}], "update_date": "2017-12-04", "authors_parsed": [["Paolizzo", "Fabio", ""]]}, {"id": "1712.00371", "submitter": "Shunta Arai", "authors": "Shunta Arai, Masayuki Ohzeki and Kazuyuki Tanaka", "title": "Deep Neural Network Detects Quantum Phase Transition", "comments": "4pages,3 figures", "journal-ref": "J. Phys. Soc. Jpn., Vol.87, No.3,2018", "doi": "10.7566/JPSJ.87.033001", "report-no": null, "categories": "cond-mat.stat-mech cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We detect the quantum phase transition of a quantum many-body system by\nmapping the observed results of the quantum state onto a neural network. In the\npresent study, we utilized the simplest case of a quantum many-body system,\nnamely a one-dimensional chain of Ising spins with the transverse Ising model.\nWe prepared several spin configurations, which were obtained using repeated\nobservations of the model for a particular strength of the transverse field, as\ninput data for the neural network. Although the proposed method can be employed\nusing experimental observations of quantum many-body systems, we tested our\ntechnique with spin configurations generated by a quantum Monte Carlo\nsimulation without initial relaxation. The neural network successfully\nclassified the strength of transverse field only from the spin configurations,\nleading to consistent estimations of the critical point of our model $\\Gamma_c\n=J$.\n", "versions": [{"version": "v1", "created": "Fri, 1 Dec 2017 15:37:43 GMT"}], "update_date": "2018-02-26", "authors_parsed": [["Arai", "Shunta", ""], ["Ohzeki", "Masayuki", ""], ["Tanaka", "Kazuyuki", ""]]}, {"id": "1712.00377", "submitter": "Aishwarya Agrawal", "authors": "Aishwarya Agrawal, Dhruv Batra, Devi Parikh, Aniruddha Kembhavi", "title": "Don't Just Assume; Look and Answer: Overcoming Priors for Visual\n  Question Answering", "comments": "15 pages, 10 figures. To appear in IEEE Conference on Computer Vision\n  and Pattern Recognition (CVPR), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A number of studies have found that today's Visual Question Answering (VQA)\nmodels are heavily driven by superficial correlations in the training data and\nlack sufficient image grounding. To encourage development of models geared\ntowards the latter, we propose a new setting for VQA where for every question\ntype, train and test sets have different prior distributions of answers.\nSpecifically, we present new splits of the VQA v1 and VQA v2 datasets, which we\ncall Visual Question Answering under Changing Priors (VQA-CP v1 and VQA-CP v2\nrespectively). First, we evaluate several existing VQA models under this new\nsetting and show that their performance degrades significantly compared to the\noriginal VQA setting. Second, we propose a novel Grounded Visual Question\nAnswering model (GVQA) that contains inductive biases and restrictions in the\narchitecture specifically designed to prevent the model from 'cheating' by\nprimarily relying on priors in the training data. Specifically, GVQA explicitly\ndisentangles the recognition of visual concepts present in the image from the\nidentification of plausible answer space for a given question, enabling the\nmodel to more robustly generalize across different distributions of answers.\nGVQA is built off an existing VQA model -- Stacked Attention Networks (SAN).\nOur experiments demonstrate that GVQA significantly outperforms SAN on both\nVQA-CP v1 and VQA-CP v2 datasets. Interestingly, it also outperforms more\npowerful VQA models such as Multimodal Compact Bilinear Pooling (MCB) in\nseveral cases. GVQA offers strengths complementary to SAN when trained and\nevaluated on the original VQA v1 and VQA v2 datasets. Finally, GVQA is more\ntransparent and interpretable than existing VQA models.\n", "versions": [{"version": "v1", "created": "Fri, 1 Dec 2017 15:48:50 GMT"}, {"version": "v2", "created": "Sun, 3 Jun 2018 15:32:06 GMT"}], "update_date": "2018-06-05", "authors_parsed": [["Agrawal", "Aishwarya", ""], ["Batra", "Dhruv", ""], ["Parikh", "Devi", ""], ["Kembhavi", "Aniruddha", ""]]}, {"id": "1712.00378", "submitter": "Fabio Pardo", "authors": "Fabio Pardo, Arash Tavakoli, Vitaly Levdik, Petar Kormushev", "title": "Time Limits in Reinforcement Learning", "comments": "ICML 2018, NIPS 2017 Deep RL Symposium, code and videos:\n  https://sites.google.com/view/time-limits-in-rl", "journal-ref": "PMLR 80: 4042-4051 (2018)", "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In reinforcement learning, it is common to let an agent interact for a fixed\namount of time with its environment before resetting it and repeating the\nprocess in a series of episodes. The task that the agent has to learn can\neither be to maximize its performance over (i) that fixed period, or (ii) an\nindefinite period where time limits are only used during training to diversify\nexperience. In this paper, we provide a formal account for how time limits\ncould effectively be handled in each of the two cases and explain why not doing\nso can cause state-aliasing and invalidation of experience replay, leading to\nsuboptimal policies and training instability. In case (i), we argue that the\nterminations due to time limits are in fact part of the environment, and thus a\nnotion of the remaining time should be included as part of the agent's input to\navoid violation of the Markov property. In case (ii), the time limits are not\npart of the environment and are only used to facilitate learning. We argue that\nthis insight should be incorporated by bootstrapping from the value of the\nstate at the end of each partial episode. For both cases, we illustrate\nempirically the significance of our considerations in improving the performance\nand stability of existing reinforcement learning algorithms, showing\nstate-of-the-art results on several control tasks.\n", "versions": [{"version": "v1", "created": "Fri, 1 Dec 2017 15:52:00 GMT"}, {"version": "v2", "created": "Tue, 20 Mar 2018 11:23:41 GMT"}, {"version": "v3", "created": "Thu, 5 Jul 2018 13:53:42 GMT"}], "update_date": "2018-07-06", "authors_parsed": [["Pardo", "Fabio", ""], ["Tavakoli", "Arash", ""], ["Levdik", "Vitaly", ""], ["Kormushev", "Petar", ""]]}, {"id": "1712.00386", "submitter": "Michael Figurnov", "authors": "Michael Figurnov, Artem Sobolev, Dmitry Vetrov", "title": "Probabilistic Adaptive Computation Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a probabilistic model with discrete latent variables that control\nthe computation time in deep learning models such as ResNets and LSTMs. A prior\non the latent variables expresses the preference for faster computation. The\namount of computation for an input is determined via amortized maximum a\nposteriori (MAP) inference. MAP inference is performed using a novel stochastic\nvariational optimization method. The recently proposed Adaptive Computation\nTime mechanism can be seen as an ad-hoc relaxation of this model. We\ndemonstrate training using the general-purpose Concrete relaxation of discrete\nvariables. Evaluation on ResNet shows that our method matches the\nspeed-accuracy trade-off of Adaptive Computation Time, while allowing for\nevaluation with a simple deterministic procedure that has a lower memory\nfootprint.\n", "versions": [{"version": "v1", "created": "Fri, 1 Dec 2017 16:09:26 GMT"}], "update_date": "2017-12-04", "authors_parsed": [["Figurnov", "Michael", ""], ["Sobolev", "Artem", ""], ["Vetrov", "Dmitry", ""]]}, {"id": "1712.00409", "submitter": "Joel Hestness", "authors": "Joel Hestness, Sharan Narang, Newsha Ardalani, Gregory Diamos, Heewoo\n  Jun, Hassan Kianinejad, Md. Mostofa Ali Patwary, Yang Yang, Yanqi Zhou", "title": "Deep Learning Scaling is Predictable, Empirically", "comments": "19 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning (DL) creates impactful advances following a virtuous recipe:\nmodel architecture search, creating large training data sets, and scaling\ncomputation. It is widely believed that growing training sets and models should\nimprove accuracy and result in better products. As DL application domains grow,\nwe would like a deeper understanding of the relationships between training set\nsize, computational scale, and model accuracy improvements to advance the\nstate-of-the-art.\n  This paper presents a large scale empirical characterization of\ngeneralization error and model size growth as training sets grow. We introduce\na methodology for this measurement and test four machine learning domains:\nmachine translation, language modeling, image processing, and speech\nrecognition. Our empirical results show power-law generalization error scaling\nacross a breadth of factors, resulting in power-law exponents---the \"steepness\"\nof the learning curve---yet to be explained by theoretical work. Further, model\nimprovements only shift the error but do not appear to affect the power-law\nexponent. We also show that model size scales sublinearly with data size. These\nscaling relationships have significant implications on deep learning research,\npractice, and systems. They can assist model debugging, setting accuracy\ntargets, and decisions about data set growth. They can also guide computing\nsystem design and underscore the importance of continued computational scaling.\n", "versions": [{"version": "v1", "created": "Fri, 1 Dec 2017 17:13:14 GMT"}], "update_date": "2017-12-04", "authors_parsed": [["Hestness", "Joel", ""], ["Narang", "Sharan", ""], ["Ardalani", "Newsha", ""], ["Diamos", "Gregory", ""], ["Jun", "Heewoo", ""], ["Kianinejad", "Hassan", ""], ["Patwary", "Md. Mostofa Ali", ""], ["Yang", "Yang", ""], ["Zhou", "Yanqi", ""]]}, {"id": "1712.00424", "submitter": "James Wilson", "authors": "James T. Wilson, Riccardo Moriconi, Frank Hutter, Marc Peter\n  Deisenroth", "title": "The reparameterization trick for acquisition functions", "comments": "Accepted at the NIPS 2017 Workshop on Bayesian Optimization (BayesOpt\n  2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization is a sample-efficient approach to solving global\noptimization problems. Along with a surrogate model, this approach relies on\ntheoretically motivated value heuristics (acquisition functions) to guide the\nsearch process. Maximizing acquisition functions yields the best performance;\nunfortunately, this ideal is difficult to achieve since optimizing acquisition\nfunctions per se is frequently non-trivial. This statement is especially true\nin the parallel setting, where acquisition functions are routinely non-convex,\nhigh-dimensional, and intractable. Here, we demonstrate how many popular\nacquisition functions can be formulated as Gaussian integrals amenable to the\nreparameterization trick and, ensuingly, gradient-based optimization. Further,\nwe use this reparameterized representation to derive an efficient Monte Carlo\nestimator for the upper confidence bound acquisition function in the context of\nparallel selection.\n", "versions": [{"version": "v1", "created": "Fri, 1 Dec 2017 17:32:01 GMT"}], "update_date": "2017-12-04", "authors_parsed": [["Wilson", "James T.", ""], ["Moriconi", "Riccardo", ""], ["Hutter", "Frank", ""], ["Deisenroth", "Marc Peter", ""]]}, {"id": "1712.00443", "submitter": "Aly El Gamal", "authors": "Xiaoyu Liu, Diyu Yang, Aly El Gamal", "title": "Deep Neural Network Architectures for Modulation Classification", "comments": "5 pages, 10 figures, In proc. Asilomar Conference on Signals,\n  Systems, and Computers, Nov. 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we investigate the value of employing deep learning for the\ntask of wireless signal modulation recognition. Recently in [1], a framework\nhas been introduced by generating a dataset using GNU radio that mimics the\nimperfections in a real wireless channel, and uses 10 different modulation\ntypes. Further, a convolutional neural network (CNN) architecture was developed\nand shown to deliver performance that exceeds that of expert-based approaches.\nHere, we follow the framework of [1] and find deep neural network architectures\nthat deliver higher accuracy than the state of the art. We tested the\narchitecture of [1] and found it to achieve an accuracy of approximately 75% of\ncorrectly recognizing the modulation type. We first tune the CNN architecture\nof [1] and find a design with four convolutional layers and two dense layers\nthat gives an accuracy of approximately 83.8% at high SNR. We then develop\narchitectures based on the recently introduced ideas of Residual Networks\n(ResNet [2]) and Densely Connected Networks (DenseNet [3]) to achieve high SNR\naccuracies of approximately 83.5% and 86.6%, respectively. Finally, we\nintroduce a Convolutional Long Short-term Deep Neural Network (CLDNN [4]) to\nachieve an accuracy of approximately 88.5% at high SNR.\n", "versions": [{"version": "v1", "created": "Fri, 1 Dec 2017 18:56:37 GMT"}, {"version": "v2", "created": "Thu, 21 Dec 2017 19:58:10 GMT"}, {"version": "v3", "created": "Fri, 5 Jan 2018 12:54:51 GMT"}], "update_date": "2018-01-08", "authors_parsed": [["Liu", "Xiaoyu", ""], ["Yang", "Diyu", ""], ["Gamal", "Aly El", ""]]}, {"id": "1712.00465", "submitter": "Samaneh Nasiri Ghosheh Bolagh", "authors": "Samaneh Nasiri Ghosheh Bolagh, Gari. D. Clifford", "title": "Subject Selection on a Riemannian Manifold for Unsupervised\n  Cross-subject Seizure Detection", "comments": "Cross-Subject Learning, Inter-Subject Variability, Unsupervised\n  Subject-Selection, Riemannian Manifold, Seizure Detection, EEG, NIPS ML4H\n  2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Inter-subject variability between individuals poses a challenge in\ninter-subject brain signal analysis problems. A new algorithm for\nsubject-selection based on clustering covariance matrices on a Riemannian\nmanifold is proposed. After unsupervised selection of the subsets of relevant\nsubjects, data in a cluster is mapped to a tangent space at the mean point of\ncovariance matrices in that cluster and an SVM classifier on labeled data from\nrelevant subjects is trained. Experiment on an EEG seizure database shows that\nthe proposed method increases the accuracy over state-of-the-art from 86.83% to\n89.84% and specificity from 87.38% to 89.64% while reducing the false positive\nrate/hour from 0.8/hour to 0.77/hour.\n", "versions": [{"version": "v1", "created": "Fri, 1 Dec 2017 19:12:37 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Bolagh", "Samaneh Nasiri Ghosheh", ""], ["Clifford", "Gari. D.", ""]]}, {"id": "1712.00489", "submitter": "Abhinav Gupta", "authors": "Abhinav Gupta, Yajie Miao, Leonardo Neves, Florian Metze", "title": "Visual Features for Context-Aware Speech Recognition", "comments": "5 pages and 3 figures", "journal-ref": "IEEE Xplore (ICASSP) (2017) 5020-5024", "doi": "10.1109/ICASSP.2017.7953112", "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic transcriptions of consumer-generated multi-media content such as\n\"Youtube\" videos still exhibit high word error rates. Such data typically\noccupies a very broad domain, has been recorded in challenging conditions, with\ncheap hardware and a focus on the visual modality, and may have been\npost-processed or edited. In this paper, we extend our earlier work on adapting\nthe acoustic model of a DNN-based speech recognition system to an RNN language\nmodel and show how both can be adapted to the objects and scenes that can be\nautomatically detected in the video. We are working on a corpus of \"how-to\"\nvideos from the web, and the idea is that an object that can be seen (\"car\"),\nor a scene that is being detected (\"kitchen\") can be used to condition both\nmodels on the \"context\" of the recording, thereby reducing perplexity and\nimproving transcription. We achieve good improvements in both cases and compare\nand analyze the respective reductions in word error rate. We expect that our\nresults can be used for any type of speech processing in which \"context\"\ninformation is available, for example in robotics, man-machine interaction, or\nwhen indexing large audio-visual archives, and should ultimately help to bring\ntogether the \"video-to-text\" and \"speech-to-text\" communities.\n", "versions": [{"version": "v1", "created": "Fri, 1 Dec 2017 20:56:31 GMT"}], "update_date": "2017-12-08", "authors_parsed": [["Gupta", "Abhinav", ""], ["Miao", "Yajie", ""], ["Neves", "Leonardo", ""], ["Metze", "Florian", ""]]}, {"id": "1712.00499", "submitter": "Michael Hughes", "authors": "Michael C. Hughes, Gabriel Hope, Leah Weiner, Thomas H. McCoy, Roy H.\n  Perlis, Erik B. Sudderth, Finale Doshi-Velez", "title": "Prediction-Constrained Topic Models for Antidepressant Recommendation", "comments": "Accepted poster at NIPS 2017 Workshop on Machine Learning for Health\n  (https://ml4health.github.io/2017/)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervisory signals can help topic models discover low-dimensional data\nrepresentations that are more interpretable for clinical tasks. We propose a\nframework for training supervised latent Dirichlet allocation that balances two\ngoals: faithful generative explanations of high-dimensional data and accurate\nprediction of associated class labels. Existing approaches fail to balance\nthese goals by not properly handling a fundamental asymmetry: the intended task\nis always predicting labels from data, not data from labels. Our new\nprediction-constrained objective trains models that predict labels from heldout\ndata well while also producing good generative likelihoods and interpretable\ntopic-word parameters. In a case study on predicting depression medications\nfrom electronic health records, we demonstrate improved recommendations\ncompared to previous supervised topic models and high- dimensional logistic\nregression from words alone.\n", "versions": [{"version": "v1", "created": "Fri, 1 Dec 2017 21:24:26 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Hughes", "Michael C.", ""], ["Hope", "Gabriel", ""], ["Weiner", "Leah", ""], ["McCoy", "Thomas H.", ""], ["Perlis", "Roy H.", ""], ["Sudderth", "Erik B.", ""], ["Doshi-Velez", "Finale", ""]]}, {"id": "1712.00504", "submitter": "Rui Luo", "authors": "Rui Luo, Weinan Zhang, Xiaojun Xu, and Jun Wang", "title": "A Neural Stochastic Volatility Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CE q-fin.ST stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we show that the recent integration of statistical models with\ndeep recurrent neural networks provides a new way of formulating volatility\n(the degree of variation of time series) models that have been widely used in\ntime series analysis and prediction in finance. The model comprises a pair of\ncomplementary stochastic recurrent neural networks: the generative network\nmodels the joint distribution of the stochastic volatility process; the\ninference network approximates the conditional distribution of the latent\nvariables given the observables. Our focus here is on the formulation of\ntemporal dynamics of volatility over time under a stochastic recurrent neural\nnetwork framework. Experiments on real-world stock price datasets demonstrate\nthat the proposed model generates a better volatility estimation and prediction\nthat outperforms mainstream methods, e.g., deterministic models such as GARCH\nand its variants, and stochastic models namely the MCMC-based model\n\\emph{stochvol} as well as the Gaussian process volatility model \\emph{GPVol},\non average negative log-likelihood.\n", "versions": [{"version": "v1", "created": "Thu, 30 Nov 2017 16:31:36 GMT"}, {"version": "v2", "created": "Wed, 5 Dec 2018 00:28:03 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Luo", "Rui", ""], ["Zhang", "Weinan", ""], ["Xu", "Xiaojun", ""], ["Wang", "Jun", ""]]}, {"id": "1712.00519", "submitter": "Benjamin Doerr", "authors": "Benjamin Doerr", "title": "An Elementary Analysis of the Probability That a Binomial Random\n  Variable Exceeds Its Expectation", "comments": "v2: Minor change in the presentation of previous works (took into\n  account the new version of Pel[16]). v3: Minor change in the presentation of\n  previous works (the proof of Lemma 6.4 in [RT11] gives a significantly\n  stronger result than what is stated in the Lemma itself). v4: Minor changes\n  (typos, mentioned the work of Slud)", "journal-ref": "Statistics and Probability Letters, 139:67-74, 2018", "doi": "10.1016/j.spl.2018.03.016", "report-no": null, "categories": "math.PR cs.DS cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give an elementary proof of the fact that a binomial random variable $X$\nwith parameters $n$ and $0.29/n \\le p < 1$ with probability at least $1/4$\nstrictly exceeds its expectation. We also show that for $1/n \\le p < 1 - 1/n$,\n$X$ exceeds its expectation by more than one with probability at least\n$0.0370$. Both probabilities approach $1/2$ when $np$ and $n(1-p)$ tend to\ninfinity.\n", "versions": [{"version": "v1", "created": "Fri, 1 Dec 2017 23:24:52 GMT"}, {"version": "v2", "created": "Thu, 7 Dec 2017 12:22:42 GMT"}, {"version": "v3", "created": "Thu, 21 Dec 2017 15:39:10 GMT"}, {"version": "v4", "created": "Thu, 4 Jan 2018 12:49:19 GMT"}], "update_date": "2018-04-16", "authors_parsed": [["Doerr", "Benjamin", ""]]}, {"id": "1712.00527", "submitter": "Steffen Rendle", "authors": "Guy Blanc, Steffen Rendle", "title": "Adaptive Sampled Softmax with Kernel Based Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Softmax is the most commonly used output function for multiclass problems and\nis widely used in areas such as vision, natural language processing, and\nrecommendation. A softmax model has linear costs in the number of classes which\nmakes it too expensive for many real-world problems. A common approach to speed\nup training involves sampling only some of the classes at each training step.\nIt is known that this method is biased and that the bias increases the more the\nsampling distribution deviates from the output distribution. Nevertheless,\nalmost any recent work uses simple sampling distributions that require a large\nsample size to mitigate the bias. In this work, we propose a new class of\nkernel based sampling methods and develop an efficient sampling algorithm.\nKernel based sampling adapts to the model as it is trained, thus resulting in\nlow bias. Kernel based sampling can be easily applied to many models because it\nrelies only on the model's last hidden layer. We empirically study the\ntrade-off of bias, sampling distribution and sample size and show that kernel\nbased sampling results in low bias with few samples.\n", "versions": [{"version": "v1", "created": "Sat, 2 Dec 2017 00:39:49 GMT"}, {"version": "v2", "created": "Wed, 1 Aug 2018 18:32:05 GMT"}], "update_date": "2018-08-03", "authors_parsed": [["Blanc", "Guy", ""], ["Rendle", "Steffen", ""]]}, {"id": "1712.00556", "submitter": "Chen Fang", "authors": "Chen Fang, Panuwat Janwattanapong, Chunfei Li, and Malek Adjouadi", "title": "A global feature extraction model for the effective computer aided\n  diagnosis of mild cognitive impairment using structural MRI images", "comments": "4 pages, NIPS ML4H 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple modalities of biomarkers have been proved to be very sensitive in\nassessing the progression of Alzheimer's disease (AD), and using these\nmodalities and machine learning algorithms, several approaches have been\nproposed to assist in the early diagnosis of AD. Among the recent investigated\nstate-of-the-art approaches, Gaussian discriminant analysis (GDA)-based\napproaches have been demonstrated to be more effective and accurate in the\nclassification of AD, especially for delineating its prodromal stage of mild\ncognitive impairment (MCI). Moreover, among those binary classification\ninvestigations, the local feature extraction methods were mostly used, which\nmade them hardly be applied to a practical computer aided diagnosis system.\nTherefore, this study presents a novel global feature extraction model taking\nadvantage of the recent proposed GDA-based dual high-dimensional decision\nspaces, which can significantly improve the early diagnosis performance\ncomparing to those local feature extraction methods. In the true test using 20%\nheld-out data, for discriminating the most challenging MCI group from the\ncognitively normal control (CN) group, an F1 score of 91.06%, an accuracy of\n88.78%, a sensitivity of 91.80%, and a specificity of 83.78% were achieved that\ncan be considered as the best performance obtained so far.\n", "versions": [{"version": "v1", "created": "Sat, 2 Dec 2017 05:57:10 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Fang", "Chen", ""], ["Janwattanapong", "Panuwat", ""], ["Li", "Chunfei", ""], ["Adjouadi", "Malek", ""]]}, {"id": "1712.00558", "submitter": "Chanh Nguyen", "authors": "Chanh Nguyen, Georgi Georgiev, Yujie Ji, Ting Wang", "title": "Where Classification Fails, Interpretation Rises", "comments": "6 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An intriguing property of deep neural networks is their inherent\nvulnerability to adversarial inputs, which significantly hinders their\napplication in security-critical domains. Most existing detection methods\nattempt to use carefully engineered patterns to distinguish adversarial inputs\nfrom their genuine counterparts, which however can often be circumvented by\nadaptive adversaries. In this work, we take a completely different route by\nleveraging the definition of adversarial inputs: while deceiving for deep\nneural networks, they are barely discernible for human visions. Building upon\nrecent advances in interpretable models, we construct a new detection framework\nthat contrasts an input's interpretation against its classification. We\nvalidate the efficacy of this framework through extensive experiments using\nbenchmark datasets and attacks. We believe that this work opens a new direction\nfor designing adversarial input detection methods.\n", "versions": [{"version": "v1", "created": "Sat, 2 Dec 2017 06:18:49 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Nguyen", "Chanh", ""], ["Georgiev", "Georgi", ""], ["Ji", "Yujie", ""], ["Wang", "Ting", ""]]}, {"id": "1712.00559", "submitter": "Chenxi Liu", "authors": "Chenxi Liu, Barret Zoph, Maxim Neumann, Jonathon Shlens, Wei Hua,\n  Li-Jia Li, Li Fei-Fei, Alan Yuille, Jonathan Huang, Kevin Murphy", "title": "Progressive Neural Architecture Search", "comments": "To appear in ECCV 2018 as oral. The code and checkpoint for PNASNet-5\n  trained on ImageNet (both Mobile and Large) can now be downloaded from\n  https://github.com/tensorflow/models/tree/master/research/slim#Pretrained.\n  Also see https://github.com/chenxi116/PNASNet.TF for refactored and\n  simplified TensorFlow code; see https://github.com/chenxi116/PNASNet.pytorch\n  for exact conversion to PyTorch", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new method for learning the structure of convolutional neural\nnetworks (CNNs) that is more efficient than recent state-of-the-art methods\nbased on reinforcement learning and evolutionary algorithms. Our approach uses\na sequential model-based optimization (SMBO) strategy, in which we search for\nstructures in order of increasing complexity, while simultaneously learning a\nsurrogate model to guide the search through structure space. Direct comparison\nunder the same search space shows that our method is up to 5 times more\nefficient than the RL method of Zoph et al. (2018) in terms of number of models\nevaluated, and 8 times faster in terms of total compute. The structures we\ndiscover in this way achieve state of the art classification accuracies on\nCIFAR-10 and ImageNet.\n", "versions": [{"version": "v1", "created": "Sat, 2 Dec 2017 06:23:16 GMT"}, {"version": "v2", "created": "Sat, 24 Mar 2018 00:39:27 GMT"}, {"version": "v3", "created": "Thu, 26 Jul 2018 19:51:26 GMT"}], "update_date": "2018-07-30", "authors_parsed": [["Liu", "Chenxi", ""], ["Zoph", "Barret", ""], ["Neumann", "Maxim", ""], ["Shlens", "Jonathon", ""], ["Hua", "Wei", ""], ["Li", "Li-Jia", ""], ["Fei-Fei", "Li", ""], ["Yuille", "Alan", ""], ["Huang", "Jonathan", ""], ["Murphy", "Kevin", ""]]}, {"id": "1712.00563", "submitter": "Gabriel Erion", "authors": "Gabriel Erion, Hugh Chen, Scott M. Lundberg, Su-In Lee", "title": "Anesthesiologist-level forecasting of hypoxemia with only SpO2 data\n  using deep learning", "comments": "To be presented at Machine Learning for Health Workshop: 31st\n  Conference on Neural Information Processing Systems (NIPS 2017), Long Beach,\n  CA, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use a deep learning model trained only on a patient's blood oxygenation\ndata (measurable with an inexpensive fingertip sensor) to predict impending\nhypoxemia (low blood oxygen) more accurately than trained anesthesiologists\nwith access to all the data recorded in a modern operating room. We also\nprovide a simple way to visualize the reason why a patient's risk is low or\nhigh by assigning weight to the patient's past blood oxygen values. This work\nhas the potential to provide cutting-edge clinical decision support in\nlow-resource settings, where rates of surgical complication and death are\nsubstantially greater than in high-resource areas.\n", "versions": [{"version": "v1", "created": "Sat, 2 Dec 2017 07:27:28 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Erion", "Gabriel", ""], ["Chen", "Hugh", ""], ["Lundberg", "Scott M.", ""], ["Lee", "Su-In", ""]]}, {"id": "1712.00573", "submitter": "Zihao Hu", "authors": "Zihao Hu, Xiyi Luo, Hongtao Lu, and Yong Yu", "title": "Supervised Hashing based on Energy Minimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, supervised hashing methods have attracted much attention since they\ncan optimize retrieval speed and storage cost while preserving semantic\ninformation. Because hashing codes learning is NP-hard, many methods resort to\nsome form of relaxation technique. But the performance of these methods can\neasily deteriorate due to the relaxation. Luckily, many supervised hashing\nformulations can be viewed as energy functions, hence solving hashing codes is\nequivalent to learning marginals in the corresponding conditional random field\n(CRF). By minimizing the KL divergence between a fully factorized distribution\nand the Gibbs distribution of this CRF, a set of consistency equations can be\nobtained, but updating them in parallel may not yield a local optimum since the\nvariational lower bound is not guaranteed to increase. In this paper, we use a\nlinear approximation of the sigmoid function to convert these consistency\nequations to linear systems, which have a closed-form solution. By applying\nthis novel technique to two classical hashing formulations KSH and SPLH, we\nobtain two new methods called EM (energy minimizing based)-KSH and EM-SPLH.\nExperimental results on three datasets show the superiority of our methods.\n", "versions": [{"version": "v1", "created": "Sat, 2 Dec 2017 08:43:23 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Hu", "Zihao", ""], ["Luo", "Xiyi", ""], ["Lu", "Hongtao", ""], ["Yu", "Yong", ""]]}, {"id": "1712.00578", "submitter": "Chen-Yu Wei", "authors": "Chen-Yu Wei, Yi-Te Hong, Chi-Jen Lu", "title": "Tracking the Best Expert in Non-stationary Stochastic Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the dynamic regret of multi-armed bandit and experts problem in\nnon-stationary stochastic environments. We introduce a new parameter $\\Lambda$,\nwhich measures the total statistical variance of the loss distributions over\n$T$ rounds of the process, and study how this amount affects the regret. We\ninvestigate the interaction between $\\Lambda$ and $\\Gamma$, which counts the\nnumber of times the distributions change, as well as $\\Lambda$ and $V$, which\nmeasures how far the distributions deviates over time. One striking result we\nfind is that even when $\\Gamma$, $V$, and $\\Lambda$ are all restricted to\nconstant, the regret lower bound in the bandit setting still grows with $T$.\nThe other highlight is that in the full-information setting, a constant regret\nbecomes achievable with constant $\\Gamma$ and $\\Lambda$, as it can be made\nindependent of $T$, while with constant $V$ and $\\Lambda$, the regret still has\na $T^{1/3}$ dependency. We not only propose algorithms with upper bound\nguarantee, but prove their matching lower bounds as well.\n", "versions": [{"version": "v1", "created": "Sat, 2 Dec 2017 09:42:54 GMT"}, {"version": "v2", "created": "Fri, 21 Jun 2019 10:10:29 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Wei", "Chen-Yu", ""], ["Hong", "Yi-Te", ""], ["Lu", "Chi-Jen", ""]]}, {"id": "1712.00579", "submitter": "Chen-Yu Wei", "authors": "Chen-Yu Wei, Yi-Te Hong, Chi-Jen Lu", "title": "Online Reinforcement Learning in Stochastic Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study online reinforcement learning in average-reward stochastic games\n(SGs). An SG models a two-player zero-sum game in a Markov environment, where\nstate transitions and one-step payoffs are determined simultaneously by a\nlearner and an adversary. We propose the UCSG algorithm that achieves a\nsublinear regret compared to the game value when competing with an arbitrary\nopponent. This result improves previous ones under the same setting. The regret\nbound has a dependency on the diameter, which is an intrinsic value related to\nthe mixing property of SGs. If we let the opponent play an optimistic best\nresponse to the learner, UCSG finds an $\\varepsilon$-maximin stationary policy\nwith a sample complexity of\n$\\tilde{\\mathcal{O}}\\left(\\text{poly}(1/\\varepsilon)\\right)$, where\n$\\varepsilon$ is the gap to the best policy.\n", "versions": [{"version": "v1", "created": "Sat, 2 Dec 2017 09:46:33 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Wei", "Chen-Yu", ""], ["Hong", "Yi-Te", ""], ["Lu", "Chi-Jen", ""]]}, {"id": "1712.00600", "submitter": "Weinan Zhang", "authors": "Lianmin Zheng, Jiacheng Yang, Han Cai, Weinan Zhang, Jun Wang, Yong Yu", "title": "MAgent: A Many-Agent Reinforcement Learning Platform for Artificial\n  Collective Intelligence", "comments": "NIPS 2017 & AAAI 2018 Demo", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce MAgent, a platform to support research and development of\nmany-agent reinforcement learning. Unlike previous research platforms on single\nor multi-agent reinforcement learning, MAgent focuses on supporting the tasks\nand the applications that require hundreds to millions of agents. Within the\ninteractions among a population of agents, it enables not only the study of\nlearning algorithms for agents' optimal polices, but more importantly, the\nobservation and understanding of individual agent's behaviors and social\nphenomena emerging from the AI society, including communication languages,\nleaderships, altruism. MAgent is highly scalable and can host up to one million\nagents on a single GPU server. MAgent also provides flexible configurations for\nAI researchers to design their customized environments and agents. In this\ndemo, we present three environments designed on MAgent and show emerged\ncollective intelligence by learning from scratch.\n", "versions": [{"version": "v1", "created": "Sat, 2 Dec 2017 12:41:11 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Zheng", "Lianmin", ""], ["Yang", "Jiacheng", ""], ["Cai", "Han", ""], ["Zhang", "Weinan", ""], ["Wang", "Jun", ""], ["Yu", "Yong", ""]]}, {"id": "1712.00634", "submitter": "Stefan Richthofer", "authors": "Stefan Richthofer, Laurenz Wiskott", "title": "PFAx: Predictable Feature Analysis to Perform Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO cs.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictable Feature Analysis (PFA) (Richthofer, Wiskott, ICMLA 2015) is an\nalgorithm that performs dimensionality reduction on high dimensional input\nsignal. It extracts those subsignals that are most predictable according to a\ncertain prediction model. We refer to these extracted signals as predictable\nfeatures.\n  In this work we extend the notion of PFA to take supplementary information\ninto account for improving its predictions. Such information can be a\nmultidimensional signal like the main input to PFA, but is regarded external.\nThat means it won't participate in the feature extraction - no features get\nextracted or composed of it. Features will be exclusively extracted from the\nmain input such that they are most predictable based on themselves and the\nsupplementary information. We refer to this enhanced PFA as PFAx (PFA\nextended).\n  Even more important than improving prediction quality is to observe the\neffect of supplementary information on feature selection. PFAx transparently\nprovides insight how the supplementary information adds to prediction quality\nand whether it is valuable at all. Finally we show how to invert that relation\nand can generate the supplementary information such that it would yield a\ncertain desired outcome of the main signal.\n  We apply this to a setting inspired by reinforcement learning and let the\nalgorithm learn how to control an agent in an environment. With this method it\nis feasible to locally optimize the agent's state, i.e. reach a certain goal\nthat is near enough. We are preparing a follow-up paper that extends this\nmethod such that also global optimization is feasible.\n", "versions": [{"version": "v1", "created": "Sat, 2 Dec 2017 16:44:10 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Richthofer", "Stefan", ""], ["Wiskott", "Laurenz", ""]]}, {"id": "1712.00635", "submitter": "Minhae Kwon", "authors": "Minhae Kwon, Hyunggon Park", "title": "Network Coding Based Evolutionary Network Formation for Dynamic Wireless\n  Networks", "comments": "IEEE Transactions on Mobile Computing (Early Access)", "journal-ref": "IEEE Transactions on Mobile Computing (Volume: 18 , Issue: 6 ,\n  June 1 2019)", "doi": "10.1109/TMC.2018.2861001", "report-no": null, "categories": "cs.NI cs.LG cs.MA eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we aim to find a robust network formation strategy that can\nadaptively evolve the network topology against network dynamics in a\ndistributed manner. We consider a network coding deployed wireless ad hoc\nnetwork where source nodes are connected to terminal nodes with the help of\nintermediate nodes. We show that mixing operations in network coding can induce\npacket anonymity that allows the inter-connections in a network to be\ndecoupled. This enables each intermediate node to consider complex network\ninter-connections as a node-environment interaction such that the Markov\ndecision process (MDP) can be employed at each intermediate node. The optimal\npolicy that can be obtained by solving the MDP provides each node with optimal\namount of changes in transmission range given network dynamics (e.g., the\nnumber of nodes in the range and channel condition). Hence, the network can be\nadaptively and optimally evolved by responding to the network dynamics. The\nproposed strategy is used to maximize long-term utility, which is achieved by\nconsidering both current network conditions and future network dynamics. We\ndefine the utility of an action to include network throughput gain and the cost\nof transmission power. We show that the resulting network of the proposed\nstrategy eventually converges to stationary networks, which maintain the states\nof the nodes. Moreover, we propose to determine initial transmission ranges and\ninitial network topology that can expedite the convergence of the proposed\nalgorithm. Our simulation results confirm that the proposed strategy builds a\nnetwork which adaptively changes its topology in the presence of network\ndynamics. Moreover, the proposed strategy outperforms existing strategies in\nterms of system goodput and successful connectivity ratio.\n", "versions": [{"version": "v1", "created": "Sat, 2 Dec 2017 16:46:27 GMT"}, {"version": "v2", "created": "Thu, 16 Aug 2018 06:41:37 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Kwon", "Minhae", ""], ["Park", "Hyunggon", ""]]}, {"id": "1712.00640", "submitter": "Vaisakh Shaj", "authors": "Vaisakh Shaj, Puranjoy Bhattacharya", "title": "Learning Sparse Adversarial Dictionaries For Multi-Class Audio\n  Classification", "comments": "Accepted in Asian Conference of Pattern Recognition (ACPR-2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Audio events are quite often overlapping in nature, and more prone to noise\nthan visual signals. There has been increasing evidence for the superior\nperformance of representations learned using sparse dictionaries for\napplications like audio denoising and speech enhancement. This paper\nconcentrates on modifying the traditional reconstructive dictionary learning\nalgorithms, by incorporating a discriminative term into the objective function\nin order to learn class-specific adversarial dictionaries that are good at\nrepresenting samples of their own class at the same time poor at representing\nsamples belonging to any other class. We quantitatively demonstrate the\neffectiveness of our learned dictionaries as a stand-alone solution for both\nbinary as well as multi-class audio classification problems.\n", "versions": [{"version": "v1", "created": "Sat, 2 Dec 2017 17:16:24 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Shaj", "Vaisakh", ""], ["Bhattacharya", "Puranjoy", ""]]}, {"id": "1712.00644", "submitter": "Maggie Makar", "authors": "Maggie Makar, Marzyeh Ghassemi, David Cutler, Ziad Obermeyer", "title": "Short-term Mortality Prediction for Elderly Patients Using Medicare\n  Claims Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Risk prediction is central to both clinical medicine and public health. While\nmany machine learning models have been developed to predict mortality, they are\nrarely applied in the clinical literature, where classification tasks typically\nrely on logistic regression. One reason for this is that existing machine\nlearning models often seek to optimize predictions by incorporating features\nthat are not present in the databases readily available to providers and policy\nmakers, limiting generalizability and implementation. Here we tested a number\nof machine learning classifiers for prediction of six-month mortality in a\npopulation of elderly Medicare beneficiaries, using an administrative claims\ndatabase of the kind available to the majority of health care payers and\nproviders. We show that machine learning classifiers substantially outperform\ncurrent widely-used methods of risk prediction but only when used with an\nimproved feature set incorporating insights from clinical medicine, developed\nfor this study. Our work has applications to supporting patient and provider\ndecision making at the end of life, as well as population health-oriented\nefforts to identify patients at high risk of poor outcomes.\n", "versions": [{"version": "v1", "created": "Sat, 2 Dec 2017 17:35:40 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Makar", "Maggie", ""], ["Ghassemi", "Marzyeh", ""], ["Cutler", "David", ""], ["Obermeyer", "Ziad", ""]]}, {"id": "1712.00654", "submitter": "Wei-Hung Weng", "authors": "Wei-Hung Weng, Mingwu Gao, Ze He, Susu Yan, Peter Szolovits", "title": "Representation and Reinforcement Learning for Personalized Glycemic\n  Control in Septic Patients", "comments": "Accepted by the 31st Annual Conference on Neural Information\n  Processing Systems (NIPS 2017) Workshop on Machine Learning for Health (ML4H)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Glycemic control is essential for critical care. However, it is a challenging\ntask because there has been no study on personalized optimal strategies for\nglycemic control. This work aims to learn personalized optimal glycemic\ntrajectories for severely ill septic patients by learning data-driven policies\nto identify optimal targeted blood glucose levels as a reference for\nclinicians. We encoded patient states using a sparse autoencoder and adopted a\nreinforcement learning paradigm using policy iteration to learn the optimal\npolicy from data. We also estimated the expected return following the policy\nlearned from the recorded glycemic trajectories, which yielded a function\nindicating the relationship between real blood glucose values and 90-day\nmortality rates. This suggests that the learned optimal policy could reduce the\npatients' estimated 90-day mortality rate by 6.3%, from 31% to 24.7%. The\nresult demonstrates that reinforcement learning with appropriate patient state\nencoding can potentially provide optimal glycemic trajectories and allow\nclinicians to design a personalized strategy for glycemic control in septic\npatients.\n", "versions": [{"version": "v1", "created": "Sat, 2 Dec 2017 18:39:12 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Weng", "Wei-Hung", ""], ["Gao", "Mingwu", ""], ["He", "Ze", ""], ["Yan", "Susu", ""], ["Szolovits", "Peter", ""]]}, {"id": "1712.00656", "submitter": "Alper Kose", "authors": "Noyan Evirgen, Alper Kose and Hakan Gokcesu", "title": "An Asymptotically Optimal Algorithm for Communicating Multiplayer\n  Multi-Armed Bandit Problems", "comments": "This work is an extension of the paper [arXiv:1711.01628] which has\n  been accepted to the 2017 IEEE ICMLA and submitted to Elsevier Signal\n  Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a decentralized stochastic multi-armed bandit problem with\nmultiple players. Each player aims to maximize his/her own reward by pulling an\narm. The arms give rewards based on i.i.d. stochastic Bernoulli distributions.\nPlayers are not aware about the probability distributions of the arms. At the\nend of each turn, the players inform their neighbors about the arm he/she\npulled and the reward he/she got. Neighbors of players are determined according\nto an Erd{\\H{o}}s-R{\\'e}nyi graph with connectivity $\\alpha$. This graph is\nreproduced in the beginning of every turn with the same connectivity. When more\nthan one player choose the same arm in a turn, we assume that only one of the\nplayers who is randomly chosen gets the reward where the others get nothing. We\nfirst start by assuming players are not aware of the collision model and offer\nan asymptotically optimal algorithm for $\\alpha = 1$ case. Then, we extend our\nprior work and offer an asymptotically optimal algorithm for any connectivity\nbut zero, assuming players aware of the collision model. We also study the\neffect of $\\alpha$, the degree of communication between players, empirically on\nthe cumulative regret by comparing them with traditional multi-armed bandit\nalgorithms.\n", "versions": [{"version": "v1", "created": "Sat, 2 Dec 2017 18:58:04 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Evirgen", "Noyan", ""], ["Kose", "Alper", ""], ["Gokcesu", "Hakan", ""]]}, {"id": "1712.00661", "submitter": "Ziwei Liu", "authors": "Xiaohang Zhan, Ziwei Liu, Ping Luo, Xiaoou Tang, Chen Change Loy", "title": "Mix-and-Match Tuning for Self-Supervised Semantic Segmentation", "comments": "To appear in AAAI 2018 as a spotlight paper. More details at the\n  project page: http://mmlab.ie.cuhk.edu.hk/projects/M%26M/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep convolutional networks for semantic image segmentation typically require\nlarge-scale labeled data, e.g. ImageNet and MS COCO, for network pre-training.\nTo reduce annotation efforts, self-supervised semantic segmentation is recently\nproposed to pre-train a network without any human-provided labels. The key of\nthis new form of learning is to design a proxy task (e.g. image colorization),\nfrom which a discriminative loss can be formulated on unlabeled data. Many\nproxy tasks, however, lack the critical supervision signals that could induce\ndiscriminative representation for the target image segmentation task. Thus\nself-supervision's performance is still far from that of supervised\npre-training. In this study, we overcome this limitation by incorporating a\n\"mix-and-match\" (M&M) tuning stage in the self-supervision pipeline. The\nproposed approach is readily pluggable to many self-supervision methods and\ndoes not use more annotated samples than the original process. Yet, it is\ncapable of boosting the performance of target image segmentation task to\nsurpass fully-supervised pre-trained counterpart. The improvement is made\npossible by better harnessing the limited pixel-wise annotations in the target\ndataset. Specifically, we first introduce the \"mix\" stage, which sparsely\nsamples and mixes patches from the target set to reflect rich and diverse local\npatch statistics of target images. A \"match\" stage then forms a class-wise\nconnected graph, which can be used to derive a strong triplet-based\ndiscriminative loss for fine-tuning the network. Our paradigm follows the\nstandard practice in existing self-supervised studies and no extra data or\nlabel is required. With the proposed M&M approach, for the first time, a\nself-supervision method can achieve comparable or even better performance\ncompared to its ImageNet pre-trained counterpart on both PASCAL VOC2012 dataset\nand CityScapes dataset.\n", "versions": [{"version": "v1", "created": "Sat, 2 Dec 2017 20:25:37 GMT"}, {"version": "v2", "created": "Tue, 5 Dec 2017 06:53:27 GMT"}, {"version": "v3", "created": "Tue, 30 Jan 2018 00:16:05 GMT"}], "update_date": "2018-01-31", "authors_parsed": [["Zhan", "Xiaohang", ""], ["Liu", "Ziwei", ""], ["Luo", "Ping", ""], ["Tang", "Xiaoou", ""], ["Loy", "Chen Change", ""]]}, {"id": "1712.00673", "submitter": "Xuanqing Liu", "authors": "Xuanqing Liu, Minhao Cheng, Huan Zhang, Cho-Jui Hsieh", "title": "Towards Robust Neural Networks via Random Self-ensemble", "comments": "ECCV 2018 camera ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have revealed the vulnerability of deep neural networks: A\nsmall adversarial perturbation that is imperceptible to human can easily make a\nwell-trained deep neural network misclassify. This makes it unsafe to apply\nneural networks in security-critical applications. In this paper, we propose a\nnew defense algorithm called Random Self-Ensemble (RSE) by combining two\nimportant concepts: {\\bf randomness} and {\\bf ensemble}. To protect a targeted\nmodel, RSE adds random noise layers to the neural network to prevent the strong\ngradient-based attacks, and ensembles the prediction over random noises to\nstabilize the performance. We show that our algorithm is equivalent to ensemble\nan infinite number of noisy models $f_\\epsilon$ without any additional memory\noverhead, and the proposed training procedure based on noisy stochastic\ngradient descent can ensure the ensemble model has a good predictive\ncapability. Our algorithm significantly outperforms previous defense techniques\non real data sets. For instance, on CIFAR-10 with VGG network (which has 92\\%\naccuracy without any attack), under the strong C\\&W attack within a certain\ndistortion tolerance, the accuracy of unprotected model drops to less than\n10\\%, the best previous defense technique has $48\\%$ accuracy, while our method\nstill has $86\\%$ prediction accuracy under the same level of attack. Finally,\nour method is simple and easy to integrate into any neural network.\n", "versions": [{"version": "v1", "created": "Sat, 2 Dec 2017 22:26:12 GMT"}, {"version": "v2", "created": "Wed, 1 Aug 2018 00:44:31 GMT"}], "update_date": "2018-08-02", "authors_parsed": [["Liu", "Xuanqing", ""], ["Cheng", "Minhao", ""], ["Zhang", "Huan", ""], ["Hsieh", "Cho-Jui", ""]]}, {"id": "1712.00679", "submitter": "Jose Daniel Gallego Posada", "authors": "Frans A. Oliehoek, Rahul Savani, Jose Gallego-Posada, Elise van der\n  Pol, Edwin D. de Jong and Roderich Gross", "title": "GANGs: Generative Adversarial Network Games", "comments": "9 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GAN) have become one of the most successful\nframeworks for unsupervised generative modeling. As GANs are difficult to train\nmuch research has focused on this. However, very little of this research has\ndirectly exploited game-theoretic techniques. We introduce Generative\nAdversarial Network Games (GANGs), which explicitly model a finite zero-sum\ngame between a generator ($G$) and classifier ($C$) that use mixed strategies.\nThe size of these games precludes exact solution methods, therefore we define\nresource-bounded best responses (RBBRs), and a resource-bounded Nash\nEquilibrium (RB-NE) as a pair of mixed strategies such that neither $G$ or $C$\ncan find a better RBBR. The RB-NE solution concept is richer than the notion of\n`local Nash equilibria' in that it captures not only failures of escaping local\noptima of gradient descent, but applies to any approximate best response\ncomputations, including methods with random restarts. To validate our approach,\nwe solve GANGs with the Parallel Nash Memory algorithm, which provably\nmonotonically converges to an RB-NE. We compare our results to standard GAN\nsetups, and demonstrate that our method deals well with typical GAN problems\nsuch as mode collapse, partial mode coverage and forgetting.\n", "versions": [{"version": "v1", "created": "Sat, 2 Dec 2017 23:38:03 GMT"}, {"version": "v2", "created": "Sun, 17 Dec 2017 21:34:19 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Oliehoek", "Frans A.", ""], ["Savani", "Rahul", ""], ["Gallego-Posada", "Jose", ""], ["van der Pol", "Elise", ""], ["de Jong", "Edwin D.", ""], ["Gross", "Roderich", ""]]}, {"id": "1712.00699", "submitter": "Rajeev Ranjan", "authors": "Rajeev Ranjan, Swami Sankaranarayanan, Carlos D. Castillo and Rama\n  Chellappa", "title": "Improving Network Robustness against Adversarial Attacks with Compact\n  Convolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Though Convolutional Neural Networks (CNNs) have surpassed human-level\nperformance on tasks such as object classification and face verification, they\ncan easily be fooled by adversarial attacks. These attacks add a small\nperturbation to the input image that causes the network to misclassify the\nsample. In this paper, we focus on neutralizing adversarial attacks by compact\nfeature learning. In particular, we show that learning features in a closed and\nbounded space improves the robustness of the network. We explore the effect of\nL2-Softmax Loss, that enforces compactness in the learned features, thus\nresulting in enhanced robustness to adversarial perturbations. Additionally, we\npropose compact convolution, a novel method of convolution that when\nincorporated in conventional CNNs improves their robustness. Compact\nconvolution ensures feature compactness at every layer such that they are\nbounded and close to each other. Extensive experiments show that Compact\nConvolutional Networks (CCNs) neutralize multiple types of attacks, and perform\nbetter than existing methods in defending adversarial attacks, without\nincurring any additional training overhead compared to CNNs.\n", "versions": [{"version": "v1", "created": "Sun, 3 Dec 2017 03:09:31 GMT"}, {"version": "v2", "created": "Thu, 22 Mar 2018 21:45:44 GMT"}], "update_date": "2018-03-26", "authors_parsed": [["Ranjan", "Rajeev", ""], ["Sankaranarayanan", "Swami", ""], ["Castillo", "Carlos D.", ""], ["Chellappa", "Rama", ""]]}, {"id": "1712.00714", "submitter": "Nader Akoury", "authors": "Nader Akoury and Anh Nguyen", "title": "Spatial PixelCNN: Generating Images from Patches", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose Spatial PixelCNN, a conditional autoregressive model\nthat generates images from small patches. By conditioning on a grid of pixel\ncoordinates and global features extracted from a Variational Autoencoder (VAE),\nwe are able to train on patches of images, and reproduce the full-sized image.\nWe show that it not only allows for generating high quality samples at the same\nresolution as the underlying dataset, but is also capable of upscaling images\nto arbitrary resolutions (tested at resolutions up to $50\\times$) on the MNIST\ndataset. Compared to a PixelCNN++ baseline, Spatial PixelCNN quantitatively and\nqualitatively achieves similar performance on the MNIST dataset.\n", "versions": [{"version": "v1", "created": "Sun, 3 Dec 2017 06:02:23 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Akoury", "Nader", ""], ["Nguyen", "Anh", ""]]}, {"id": "1712.00725", "submitter": "Abhinav Gupta", "authors": "Laura Graesser, Abhinav Gupta, Lakshay Sharma, Evelina Bakhturina", "title": "Sentiment Classification using Images and Label Embeddings", "comments": "13 pages, 3 figures, 9 tables. Technical report for Statistical\n  Natural Language Processing Project (NYU CS - Fall 2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this project we analysed how much semantic information images carry, and\nhow much value image data can add to sentiment analysis of the text associated\nwith the images. To better understand the contribution from images, we compared\nmodels which only made use of image data, models which only made use of text\ndata, and models which combined both data types. We also analysed if this\napproach could help sentiment classifiers generalize to unknown sentiments.\n", "versions": [{"version": "v1", "created": "Sun, 3 Dec 2017 07:20:15 GMT"}], "update_date": "2017-12-08", "authors_parsed": [["Graesser", "Laura", ""], ["Gupta", "Abhinav", ""], ["Sharma", "Lakshay", ""], ["Bakhturina", "Evelina", ""]]}, {"id": "1712.00732", "submitter": "Hongwei Wang", "authors": "Hongwei Wang, Fuzheng Zhang, Min Hou, Xing Xie, Minyi Guo, Qi Liu", "title": "SHINE: Signed Heterogeneous Information Network Embedding for Sentiment\n  Link Prediction", "comments": "The 11th ACM International Conference on Web Search and Data Mining\n  (WSDM 2018)", "journal-ref": null, "doi": "10.1145/3159652.3159666", "report-no": null, "categories": "stat.ML cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In online social networks people often express attitudes towards others,\nwhich forms massive sentiment links among users. Predicting the sign of\nsentiment links is a fundamental task in many areas such as personal\nadvertising and public opinion analysis. Previous works mainly focus on textual\nsentiment classification, however, text information can only disclose the \"tip\nof the iceberg\" about users' true opinions, of which the most are unobserved\nbut implied by other sources of information such as social relation and users'\nprofile. To address this problem, in this paper we investigate how to predict\npossibly existing sentiment links in the presence of heterogeneous information.\nFirst, due to the lack of explicit sentiment links in mainstream social\nnetworks, we establish a labeled heterogeneous sentiment dataset which consists\nof users' sentiment relation, social relation and profile knowledge by\nentity-level sentiment extraction method. Then we propose a novel and flexible\nend-to-end Signed Heterogeneous Information Network Embedding (SHINE) framework\nto extract users' latent representations from heterogeneous networks and\npredict the sign of unobserved sentiment links. SHINE utilizes multiple deep\nautoencoders to map each user into a low-dimension feature space while\npreserving the network structure. We demonstrate the superiority of SHINE over\nstate-of-the-art baselines on link prediction and node recommendation in two\nreal-world datasets. The experimental results also prove the efficacy of SHINE\nin cold start scenario.\n", "versions": [{"version": "v1", "created": "Sun, 3 Dec 2017 08:21:31 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Wang", "Hongwei", ""], ["Zhang", "Fuzheng", ""], ["Hou", "Min", ""], ["Xie", "Xing", ""], ["Guo", "Minyi", ""], ["Liu", "Qi", ""]]}, {"id": "1712.00779", "submitter": "Simon Du", "authors": "Simon S. Du, Jason D. Lee, Yuandong Tian, Barnabas Poczos, Aarti Singh", "title": "Gradient Descent Learns One-hidden-layer CNN: Don't be Afraid of\n  Spurious Local Minima", "comments": "Accepted by ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning a one-hidden-layer neural network with\nnon-overlapping convolutional layer and ReLU activation, i.e., $f(\\mathbf{Z},\n\\mathbf{w}, \\mathbf{a}) = \\sum_j a_j\\sigma(\\mathbf{w}^T\\mathbf{Z}_j)$, in which\nboth the convolutional weights $\\mathbf{w}$ and the output weights $\\mathbf{a}$\nare parameters to be learned. When the labels are the outputs from a teacher\nnetwork of the same architecture with fixed weights $(\\mathbf{w}^*,\n\\mathbf{a}^*)$, we prove that with Gaussian input $\\mathbf{Z}$, there is a\nspurious local minimizer. Surprisingly, in the presence of the spurious local\nminimizer, gradient descent with weight normalization from randomly initialized\nweights can still be proven to recover the true parameters with constant\nprobability, which can be boosted to probability $1$ with multiple restarts. We\nalso show that with constant probability, the same procedure could also\nconverge to the spurious local minimum, showing that the local minimum plays a\nnon-trivial role in the dynamics of gradient descent. Furthermore, a\nquantitative analysis shows that the gradient descent dynamics has two phases:\nit starts off slow, but converges much faster after several iterations.\n", "versions": [{"version": "v1", "created": "Sun, 3 Dec 2017 15:00:35 GMT"}, {"version": "v2", "created": "Fri, 15 Jun 2018 00:41:03 GMT"}], "update_date": "2018-06-18", "authors_parsed": [["Du", "Simon S.", ""], ["Lee", "Jason D.", ""], ["Tian", "Yuandong", ""], ["Poczos", "Barnabas", ""], ["Singh", "Aarti", ""]]}, {"id": "1712.00812", "submitter": "Iosif Pinelis", "authors": "Iosif Pinelis", "title": "Exact upper and lower bounds on the misclassification probability", "comments": "Version 3: exact upper bounds are added; results are compared with\n  ones by Feder and Merhav. Version 4: additional discussion presented", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exact lower and upper bounds on the best possible misclassification\nprobability for a finite number of classes are obtained in terms of the total\nvariation norms of the differences between the sub-distributions over the\nclasses. These bounds are compared with the exact bounds in terms of the\nconditional entropy obtained by Feder and Merhav.\n", "versions": [{"version": "v1", "created": "Sun, 3 Dec 2017 18:42:40 GMT"}, {"version": "v2", "created": "Wed, 6 Dec 2017 16:47:32 GMT"}, {"version": "v3", "created": "Mon, 5 Feb 2018 02:00:29 GMT"}, {"version": "v4", "created": "Fri, 9 Feb 2018 02:12:50 GMT"}], "update_date": "2018-02-12", "authors_parsed": [["Pinelis", "Iosif", ""]]}, {"id": "1712.00828", "submitter": "Vaneet Aggarwal", "authors": "Wenqi Wang and Vaneet Aggarwal and Shuchin Aeron", "title": "Tensor Train Neighborhood Preserving Embedding", "comments": "Accepted to IEEE Transactions on Signal Processing, Mar 2018", "journal-ref": null, "doi": "10.1109/TSP.2018.2816568", "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a Tensor Train Neighborhood Preserving Embedding\n(TTNPE) to embed multi-dimensional tensor data into low dimensional tensor\nsubspace. Novel approaches to solve the optimization problem in TTNPE are\nproposed. For this embedding, we evaluate novel trade-off gain among\nclassification, computation, and dimensionality reduction (storage) for\nsupervised learning. It is shown that compared to the state-of-the-arts tensor\nembedding methods, TTNPE achieves superior trade-off in classification,\ncomputation, and dimensionality reduction in MNIST handwritten digits and\nWeizmann face datasets.\n", "versions": [{"version": "v1", "created": "Sun, 3 Dec 2017 20:09:48 GMT"}, {"version": "v2", "created": "Sat, 10 Mar 2018 01:11:03 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Wang", "Wenqi", ""], ["Aggarwal", "Vaneet", ""], ["Aeron", "Shuchin", ""]]}, {"id": "1712.00843", "submitter": "Marinka Zitnik", "authors": "Monica Agrawal, Marinka Zitnik, Jure Leskovec", "title": "Large-scale analysis of disease pathways in the human interactome", "comments": null, "journal-ref": "Pacific Symposium on Biocomputing 23:111-122(2018)", "doi": null, "report-no": null, "categories": "q-bio.MN cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discovering disease pathways, which can be defined as sets of proteins\nassociated with a given disease, is an important problem that has the potential\nto provide clinically actionable insights for disease diagnosis, prognosis, and\ntreatment. Computational methods aid the discovery by relying on\nprotein-protein interaction (PPI) networks. They start with a few known\ndisease-associated proteins and aim to find the rest of the pathway by\nexploring the PPI network around the known disease proteins. However, the\nsuccess of such methods has been limited, and failure cases have not been well\nunderstood. Here we study the PPI network structure of 519 disease pathways. We\nfind that 90% of pathways do not correspond to single well-connected components\nin the PPI network. Instead, proteins associated with a single disease tend to\nform many separate connected components/regions in the network. We then\nevaluate state-of-the-art disease pathway discovery methods and show that their\nperformance is especially poor on diseases with disconnected pathways. Thus, we\nconclude that network connectivity structure alone may not be sufficient for\ndisease pathway discovery. However, we show that higher-order network\nstructures, such as small subgraphs of the pathway, provide a promising\ndirection for the development of new methods.\n", "versions": [{"version": "v1", "created": "Sun, 3 Dec 2017 21:51:07 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Agrawal", "Monica", ""], ["Zitnik", "Marinka", ""], ["Leskovec", "Jure", ""]]}, {"id": "1712.00866", "submitter": "Jongpil Lee", "authors": "Jongpil Lee, Taejun Kim, Jiyoung Park, Juhan Nam", "title": "Raw Waveform-based Audio Classification Using Sample-level CNN\n  Architectures", "comments": "NIPS, Machine Learning for Audio Signal Processing Workshop\n  (ML4Audio), 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG cs.MM eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Music, speech, and acoustic scene sound are often handled separately in the\naudio domain because of their different signal characteristics. However, as the\nimage domain grows rapidly by versatile image classification models, it is\nnecessary to study extensible classification models in the audio domain as\nwell. In this study, we approach this problem using two types of sample-level\ndeep convolutional neural networks that take raw waveforms as input and uses\nfilters with small granularity. One is a basic model that consists of\nconvolution and pooling layers. The other is an improved model that\nadditionally has residual connections, squeeze-and-excitation modules and\nmulti-level concatenation. We show that the sample-level models reach\nstate-of-the-art performance levels for the three different categories of\nsound. Also, we visualize the filters along layers and compare the\ncharacteristics of learned filters.\n", "versions": [{"version": "v1", "created": "Mon, 4 Dec 2017 00:58:58 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Lee", "Jongpil", ""], ["Kim", "Taejun", ""], ["Park", "Jiyoung", ""], ["Nam", "Juhan", ""]]}, {"id": "1712.00891", "submitter": "Mostafa Rahmani", "authors": "Mostafa Rahmani, George Atia", "title": "Data Dropout in Arbitrary Basis for Deep Network Regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important problem in training deep networks with high capacity is to\nensure that the trained network works well when presented with new inputs\noutside the training dataset. Dropout is an effective regularization technique\nto boost the network generalization in which a random subset of the elements of\nthe given data and the extracted features are set to zero during the training\nprocess. In this paper, a new randomized regularization technique in which we\nwithhold a random part of the data without necessarily turning off the\nneurons/data-elements is proposed. In the proposed method, of which the\nconventional dropout is shown to be a special case, random data dropout is\nperformed in an arbitrary basis, hence the designation Generalized Dropout. We\nalso present a framework whereby the proposed technique can be applied\nefficiently to convolutional neural networks. The presented numerical\nexperiments demonstrate that the proposed technique yields notable performance\ngain. Generalized Dropout provides new insight into the idea of dropout, shows\nthat we can achieve different performance gains by using different bases\nmatrices, and opens up a new research question as of how to choose optimal\nbases matrices that achieve maximal performance gain.\n", "versions": [{"version": "v1", "created": "Mon, 4 Dec 2017 03:29:38 GMT"}, {"version": "v2", "created": "Tue, 5 Dec 2017 02:55:21 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Rahmani", "Mostafa", ""], ["Atia", "George", ""]]}, {"id": "1712.00912", "submitter": "Jong Chul Ye", "authors": "Jaejun Yoo, Sohail Sabir, Duchang Heo, Kee Hyun Kim, Abdul Wahab,\n  Yoonseok Choi, Seul-I Lee, Eun Young Chae, Hak Hee Kim, Young Min Bae,\n  Young-wook Choi, Seungryong Cho, and Jong Chul Ye", "title": "Deep Learning Diffuse Optical Tomography", "comments": "Accepted for IEEE Trans. on Medical Imaging", "journal-ref": null, "doi": "10.1109/TMI.2019.2936522", "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diffuse optical tomography (DOT) has been investigated as an alternative\nimaging modality for breast cancer detection thanks to its excellent contrast\nto hemoglobin oxidization level. However, due to the complicated non-linear\nphoton scattering physics and ill-posedness, the conventional reconstruction\nalgorithms are sensitive to imaging parameters such as boundary conditions. To\naddress this, here we propose a novel deep learning approach that learns\nnon-linear photon scattering physics and obtains an accurate three dimensional\n(3D) distribution of optical anomalies. In contrast to the traditional\nblack-box deep learning approaches, our deep network is designed to invert the\nLippman-Schwinger integral equation using the recent mathematical theory of\ndeep convolutional framelets. As an example of clinical relevance, we applied\nthe method to our prototype DOT system. We show that our deep neural network,\ntrained with only simulation data, can accurately recover the location of\nanomalies within biomimetic phantoms and live animals without the use of an\nexogenous contrast agent.\n", "versions": [{"version": "v1", "created": "Mon, 4 Dec 2017 05:47:10 GMT"}, {"version": "v2", "created": "Mon, 9 Sep 2019 03:46:33 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Yoo", "Jaejun", ""], ["Sabir", "Sohail", ""], ["Heo", "Duchang", ""], ["Kim", "Kee Hyun", ""], ["Wahab", "Abdul", ""], ["Choi", "Yoonseok", ""], ["Lee", "Seul-I", ""], ["Chae", "Eun Young", ""], ["Kim", "Hak Hee", ""], ["Bae", "Young Min", ""], ["Choi", "Young-wook", ""], ["Cho", "Seungryong", ""], ["Ye", "Jong Chul", ""]]}, {"id": "1712.00948", "submitter": "Andrew Levy", "authors": "Andrew Levy, George Konidaris, Robert Platt, Kate Saenko", "title": "Learning Multi-Level Hierarchies with Hindsight", "comments": "ICLR 2019 Accepted Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical agents have the potential to solve sequential decision making\ntasks with greater sample efficiency than their non-hierarchical counterparts\nbecause hierarchical agents can break down tasks into sets of subtasks that\nonly require short sequences of decisions. In order to realize this potential\nof faster learning, hierarchical agents need to be able to learn their multiple\nlevels of policies in parallel so these simpler subproblems can be solved\nsimultaneously. Yet, learning multiple levels of policies in parallel is hard\nbecause it is inherently unstable: changes in a policy at one level of the\nhierarchy may cause changes in the transition and reward functions at higher\nlevels in the hierarchy, making it difficult to jointly learn multiple levels\nof policies. In this paper, we introduce a new Hierarchical Reinforcement\nLearning (HRL) framework, Hierarchical Actor-Critic (HAC), that can overcome\nthe instability issues that arise when agents try to jointly learn multiple\nlevels of policies. The main idea behind HAC is to train each level of the\nhierarchy independently of the lower levels by training each level as if the\nlower level policies are already optimal. We demonstrate experimentally in both\ngrid world and simulated robotics domains that our approach can significantly\naccelerate learning relative to other non-hierarchical and hierarchical\nmethods. Indeed, our framework is the first to successfully learn 3-level\nhierarchies in parallel in tasks with continuous state and action spaces.\n", "versions": [{"version": "v1", "created": "Mon, 4 Dec 2017 08:18:08 GMT"}, {"version": "v2", "created": "Tue, 27 Feb 2018 16:01:40 GMT"}, {"version": "v3", "created": "Wed, 28 Feb 2018 17:45:42 GMT"}, {"version": "v4", "created": "Fri, 1 Mar 2019 18:21:33 GMT"}, {"version": "v5", "created": "Tue, 3 Sep 2019 21:05:21 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Levy", "Andrew", ""], ["Konidaris", "George", ""], ["Platt", "Robert", ""], ["Saenko", "Kate", ""]]}, {"id": "1712.00961", "submitter": "Niki Kilbertus", "authors": "Giambattista Parascandolo, Niki Kilbertus, Mateo Rojas-Carulla,\n  Bernhard Sch\\\"olkopf", "title": "Learning Independent Causal Mechanisms", "comments": "ICML 2018", "journal-ref": "Proceedings of the 35th International Conference on Machine\n  Learning, PMLR 80:4036-4044, 2018", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical learning relies upon data sampled from a distribution, and we\nusually do not care what actually generated it in the first place. From the\npoint of view of causal modeling, the structure of each distribution is induced\nby physical mechanisms that give rise to dependences between observables.\nMechanisms, however, can be meaningful autonomous modules of generative models\nthat make sense beyond a particular entailed data distribution, lending\nthemselves to transfer between problems. We develop an algorithm to recover a\nset of independent (inverse) mechanisms from a set of transformed data points.\nThe approach is unsupervised and based on a set of experts that compete for\ndata generated by the mechanisms, driving specialization. We analyze the\nproposed method in a series of experiments on image data. Each expert learns to\nmap a subset of the transformed data back to a reference distribution. The\nlearned mechanisms generalize to novel domains. We discuss implications for\ntransfer learning and links to recent trends in generative modeling.\n", "versions": [{"version": "v1", "created": "Mon, 4 Dec 2017 09:06:15 GMT"}, {"version": "v2", "created": "Sat, 9 Dec 2017 00:34:00 GMT"}, {"version": "v3", "created": "Sun, 21 Jan 2018 15:44:45 GMT"}, {"version": "v4", "created": "Mon, 19 Feb 2018 18:28:56 GMT"}, {"version": "v5", "created": "Sat, 8 Sep 2018 08:17:44 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Parascandolo", "Giambattista", ""], ["Kilbertus", "Niki", ""], ["Rojas-Carulla", "Mateo", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "1712.00975", "submitter": "Dat Thanh Tran", "authors": "Dat Thanh Tran, Alexandros Iosifidis, Juho Kanniainen, Moncef Gabbouj", "title": "Temporal Attention augmented Bilinear Network for Financial Time-Series\n  Data Analysis", "comments": "12 pages, 4 figures, 3 tables", "journal-ref": null, "doi": "10.1109/TNNLS.2018.2869225", "report-no": null, "categories": "cs.CE cs.LG q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Financial time-series forecasting has long been a challenging problem because\nof the inherently noisy and stochastic nature of the market. In the\nHigh-Frequency Trading (HFT), forecasting for trading purposes is even a more\nchallenging task since an automated inference system is required to be both\naccurate and fast. In this paper, we propose a neural network layer\narchitecture that incorporates the idea of bilinear projection as well as an\nattention mechanism that enables the layer to detect and focus on crucial\ntemporal information. The resulting network is highly interpretable, given its\nability to highlight the importance and contribution of each temporal instance,\nthus allowing further analysis on the time instances of interest. Our\nexperiments in a large-scale Limit Order Book (LOB) dataset show that a\ntwo-hidden-layer network utilizing our proposed layer outperforms by a large\nmargin all existing state-of-the-art results coming from much deeper\narchitectures while requiring far fewer computations.\n", "versions": [{"version": "v1", "created": "Mon, 4 Dec 2017 09:41:24 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Tran", "Dat Thanh", ""], ["Iosifidis", "Alexandros", ""], ["Kanniainen", "Juho", ""], ["Gabbouj", "Moncef", ""]]}, {"id": "1712.01011", "submitter": "Hyungui Lim", "authors": "Hyungui Lim, Seungyeon Rhyu and Kyogu Lee", "title": "Chord Generation from Symbolic Melody Using BLSTM Networks", "comments": "18th International Society for Music Information Retrieval Conference\n  (ISMIR 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating a chord progression from a monophonic melody is a challenging\nproblem because a chord progression requires a series of layered notes played\nsimultaneously. This paper presents a novel method of generating chord\nsequences from a symbolic melody using bidirectional long short-term memory\n(BLSTM) networks trained on a lead sheet database. To this end, a group of\nfeature vectors composed of 12 semitones is extracted from the notes in each\nbar of monophonic melodies. In order to ensure that the data shares uniform key\nand duration characteristics, the key and the time signatures of the vectors\nare normalized. The BLSTM networks then learn from the data to incorporate the\ntemporal dependencies to produce a chord progression. Both quantitative and\nqualitative evaluations are conducted by comparing the proposed method with the\nconventional HMM and DNN-HMM based approaches. Proposed model achieves 23.8%\nand 11.4% performance increase from the other models, respectively. User\nstudies further confirm that the chord sequences generated by the proposed\nmethod are preferred by listeners.\n", "versions": [{"version": "v1", "created": "Mon, 4 Dec 2017 11:18:08 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Lim", "Hyungui", ""], ["Rhyu", "Seungyeon", ""], ["Lee", "Kyogu", ""]]}, {"id": "1712.01038", "submitter": "Mohammad Emtiyaz Khan", "authors": "Mohammad Emtiyaz Khan, Zuozhu Liu, Voot Tangkaratt, Yarin Gal", "title": "Vprop: Variational Inference using RMSprop", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many computationally-efficient methods for Bayesian deep learning rely on\ncontinuous optimization algorithms, but the implementation of these methods\nrequires significant changes to existing code-bases. In this paper, we propose\nVprop, a method for Gaussian variational inference that can be implemented with\ntwo minor changes to the off-the-shelf RMSprop optimizer. Vprop also reduces\nthe memory requirements of Black-Box Variational Inference by half. We derive\nVprop using the conjugate-computation variational inference method, and\nestablish its connections to Newton's method, natural-gradient methods, and\nextended Kalman filters. Overall, this paper presents Vprop as a principled,\ncomputationally-efficient, and easy-to-implement method for Bayesian deep\nlearning.\n", "versions": [{"version": "v1", "created": "Mon, 4 Dec 2017 12:31:36 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Khan", "Mohammad Emtiyaz", ""], ["Liu", "Zuozhu", ""], ["Tangkaratt", "Voot", ""], ["Gal", "Yarin", ""]]}, {"id": "1712.01048", "submitter": "Yiren Zhou", "authors": "Yiren Zhou, Seyed-Mohsen Moosavi-Dezfooli, Ngai-Man Cheung, Pascal\n  Frossard", "title": "Adaptive Quantization for Deep Neural Network", "comments": "9 pages main paper + 5 pages supplementary, 8 figures, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years Deep Neural Networks (DNNs) have been rapidly developed in\nvarious applications, together with increasingly complex architectures. The\nperformance gain of these DNNs generally comes with high computational costs\nand large memory consumption, which may not be affordable for mobile platforms.\nDeep model quantization can be used for reducing the computation and memory\ncosts of DNNs, and deploying complex DNNs on mobile equipment. In this work, we\npropose an optimization framework for deep model quantization. First, we\npropose a measurement to estimate the effect of parameter quantization errors\nin individual layers on the overall model prediction accuracy. Then, we propose\nan optimization process based on this measurement for finding optimal\nquantization bit-width for each layer. This is the first work that\ntheoretically analyse the relationship between parameter quantization errors of\nindividual layers and model accuracy. Our new quantization algorithm\noutperforms previous quantization optimization methods, and achieves 20-40%\nhigher compression rate compared to equal bit-width quantization at the same\nmodel prediction accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 4 Dec 2017 12:56:33 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Zhou", "Yiren", ""], ["Moosavi-Dezfooli", "Seyed-Mohsen", ""], ["Cheung", "Ngai-Man", ""], ["Frossard", "Pascal", ""]]}, {"id": "1712.01084", "submitter": "Ranko Sredojevic", "authors": "Ranko Sredojevic, Shaoyi Cheng, Lazar Supic, Rawan Naous, Vladimir\n  Stojanovic", "title": "Structured Deep Neural Network Pruning via Matrix Pivoting", "comments": "16 pages, 3 figures, 2 tables, 1 listing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) are the key to the state-of-the-art machine\nvision, sensor fusion and audio/video signal processing. Unfortunately, their\ncomputation complexity and tight resource constraints on the Edge make them\nhard to leverage on mobile, embedded and IoT devices. Due to great diversity of\nEdge devices, DNN designers have to take into account the hardware platform and\napplication requirements during network training. In this work we introduce\npruning via matrix pivoting as a way to improve network pruning by compromising\nbetween the design flexibility of architecture-oblivious and performance\nefficiency of architecture-aware pruning, the two dominant techniques for\nobtaining resource-efficient DNNs. We also describe local and global network\noptimization techniques for efficient implementation of the resulting pruned\nnetworks. In combination, the proposed pruning and implementation result in\nclose to linear speed up with the reduction of network coefficients during\npruning.\n", "versions": [{"version": "v1", "created": "Fri, 1 Dec 2017 02:47:39 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Sredojevic", "Ranko", ""], ["Cheng", "Shaoyi", ""], ["Supic", "Lazar", ""], ["Naous", "Rawan", ""], ["Stojanovic", "Vladimir", ""]]}, {"id": "1712.01106", "submitter": "Akansel Cosgun", "authors": "David Isele and Akansel Cosgun", "title": "Transferring Autonomous Driving Knowledge on Simulated and Real\n  Intersections", "comments": "Appeared in Lifelong Learning Workshop @ ICML 2017. arXiv admin note:\n  text overlap with arXiv:1705.01197", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We view intersection handling on autonomous vehicles as a reinforcement\nlearning problem, and study its behavior in a transfer learning setting. We\nshow that a network trained on one type of intersection generally is not able\nto generalize to other intersections. However, a network that is pre-trained on\none intersection and fine-tuned on another performs better on the new task\ncompared to training in isolation. This network also retains knowledge of the\nprior task, even though some forgetting occurs. Finally, we show that the\nbenefits of fine-tuning hold when transferring simulated intersection handling\nknowledge to a real autonomous vehicle.\n", "versions": [{"version": "v1", "created": "Thu, 30 Nov 2017 06:46:19 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Isele", "David", ""], ["Cosgun", "Akansel", ""]]}, {"id": "1712.01141", "submitter": "Abdul-Saboor Sheikh", "authors": "Abdul-Saboor Sheikh, Kashif Rasul, Andreas Merentitis, Urs Bergmann", "title": "Stochastic Maximum Likelihood Optimization via Hypernetworks", "comments": "To appear at NIPS 2017 Workshop on Bayesian Deep Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work explores maximum likelihood optimization of neural networks through\nhypernetworks. A hypernetwork initializes the weights of another network, which\nin turn can be employed for typical functional tasks such as regression and\nclassification. We optimize hypernetworks to directly maximize the conditional\nlikelihood of target variables given input. Using this approach we obtain\ncompetitive empirical results on regression and classification benchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 4 Dec 2017 15:17:27 GMT"}, {"version": "v2", "created": "Fri, 12 Jan 2018 14:25:08 GMT"}], "update_date": "2018-01-15", "authors_parsed": [["Sheikh", "Abdul-Saboor", ""], ["Rasul", "Kashif", ""], ["Merentitis", "Andreas", ""], ["Bergmann", "Urs", ""]]}, {"id": "1712.01145", "submitter": "Xiaoyong Yuan", "authors": "Ruimin Sun, Xiaoyong Yuan, Pan He, Qile Zhu, Aokun Chen, Andre Gregio,\n  Daniela Oliveira, Xiaolin Li", "title": "Learning Fast and Slow: PROPEDEUTICA for Real-time Malware Detection", "comments": "17 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce and evaluate PROPEDEUTICA, a novel methodology\nand framework for efficient and effective real-time malware detection,\nleveraging the best of conventional machine learning (ML) and deep learning\n(DL) algorithms. In PROPEDEUTICA, all software processes in the system start\nexecution subjected to a conventional ML detector for fast classification. If a\npiece of software receives a borderline classification, it is subjected to\nfurther analysis via more performance expensive and more accurate DL methods,\nvia our newly proposed DL algorithm DEEPMALWARE. Further, we introduce delays\nto the execution of software subjected to deep learning analysis as a way to\n\"buy time\" for DL analysis and to rate-limit the impact of possible malware in\nthe system. We evaluated PROPEDEUTICA with a set of 9,115 malware samples and\n877 commonly used benign software samples from various categories for the\nWindows OS. Our results show that the false positive rate for conventional ML\nmethods can reach 20%, and for modern DL methods it is usually below 6%.\nHowever, the classification time for DL can be 100X longer than conventional ML\nmethods. PROPEDEUTICA improved the detection F1-score from 77.54% (conventional\nML method) to 90.25%, and reduced the detection time by 54.86%. Further, the\npercentage of software subjected to DL analysis was approximately 40% on\naverage. Further, the application of delays in software subjected to ML reduced\nthe detection time by approximately 10%. Finally, we found and discussed a\ndiscrepancy between the detection accuracy offline (analysis after all traces\nare collected) and on-the-fly (analysis in tandem with trace collection). Our\ninsights show that conventional ML and modern DL-based malware detectors in\nisolation cannot meet the needs of efficient and effective malware detection:\nhigh accuracy, low false positive rate, and short classification time.\n", "versions": [{"version": "v1", "created": "Mon, 4 Dec 2017 15:30:03 GMT"}], "update_date": "2017-12-21", "authors_parsed": [["Sun", "Ruimin", ""], ["Yuan", "Xiaoyong", ""], ["He", "Pan", ""], ["Zhu", "Qile", ""], ["Chen", "Aokun", ""], ["Gregio", "Andre", ""], ["Oliveira", "Daniela", ""], ["Li", "Xiaolin", ""]]}, {"id": "1712.01158", "submitter": "Mohsen Ahmadi Fahandar", "authors": "Mohsen Ahmadi Fahandar, Eyke H\\\"ullermeier, In\\'es Couso", "title": "Statistical Inference for Incomplete Ranking Data: The Case of\n  Rank-Dependent Coarsening", "comments": "Proceedings of the 34th International Conference on Machine Learning\n  (ICML 2017), 10 pages", "journal-ref": "Proceedings of the 34th International Conference on Machine\n  Learning (ICML 2017), Sydney, Australia, PMLR 70:1078-1087, 2017", "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of statistical inference for ranking data,\nspecifically rank aggregation, under the assumption that samples are incomplete\nin the sense of not comprising all choice alternatives. In contrast to most\nexisting methods, we explicitly model the process of turning a full ranking\ninto an incomplete one, which we call the coarsening process. To this end, we\npropose the concept of rank-dependent coarsening, which assumes that incomplete\nrankings are produced by projecting a full ranking to a random subset of ranks.\nFor a concrete instantiation of our model, in which full rankings are drawn\nfrom a Plackett-Luce distribution and observations take the form of pairwise\npreferences, we study the performance of various rank aggregation methods. In\naddition to predictive accuracy in the finite sample setting, we address the\ntheoretical question of consistency, by which we mean the ability to recover a\ntarget ranking when the sample size goes to infinity, despite a potential bias\nin the observations caused by the (unknown) coarsening.\n", "versions": [{"version": "v1", "created": "Mon, 4 Dec 2017 15:49:57 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Fahandar", "Mohsen Ahmadi", ""], ["H\u00fcllermeier", "Eyke", ""], ["Couso", "In\u00e9s", ""]]}, {"id": "1712.01169", "submitter": "David Nagy", "authors": "David G. Nagy, Gerg\\H{o} Orb\\'an", "title": "Episodic memory for continual model learning", "comments": "CLDL at NIPS 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Both the human brain and artificial learning agents operating in real-world\nor comparably complex environments are faced with the challenge of online model\nselection. In principle this challenge can be overcome: hierarchical Bayesian\ninference provides a principled method for model selection and it converges on\nthe same posterior for both off-line (i.e. batch) and online learning. However,\nmaintaining a parameter posterior for each model in parallel has in general an\neven higher memory cost than storing the entire data set and is consequently\nclearly unfeasible. Alternatively, maintaining only a limited set of models in\nmemory could limit memory requirements. However, sufficient statistics for one\nmodel will usually be insufficient for fitting a different kind of model,\nmeaning that the agent loses information with each model change. We propose\nthat episodic memory can circumvent the challenge of limited memory-capacity\nonline model selection by retaining a selected subset of data points. We design\na method to compute the quantities necessary for model selection even when the\ndata is discarded and only statistics of one (or few) learnt models are\navailable. We demonstrate on a simple model that a limited-sized episodic\nmemory buffer, when the content is optimised to retain data with statistics not\nmatching the current representation, can resolve the fundamental challenge of\nonline model selection.\n", "versions": [{"version": "v1", "created": "Mon, 4 Dec 2017 16:02:36 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Nagy", "David G.", ""], ["Orb\u00e1n", "Gerg\u0151", ""]]}, {"id": "1712.01193", "submitter": "Madhav Nimishakavi Mr", "authors": "Madhav Nimishakavi, Pratik Jawanpuria, and Bamdev Mishra", "title": "A dual framework for low-rank tensor completion", "comments": "Aceepted to appear in Advances of Nueral Information Processing\n  Systems (NIPS), 2018. A shorter version appeared in the NIPS workshop on\n  Synergies in Geometric Data Analysis 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the popular approaches for low-rank tensor completion is to use the\nlatent trace norm regularization. However, most existing works in this\ndirection learn a sparse combination of tensors. In this work, we fill this gap\nby proposing a variant of the latent trace norm that helps in learning a\nnon-sparse combination of tensors. We develop a dual framework for solving the\nlow-rank tensor completion problem. We first show a novel characterization of\nthe dual solution space with an interesting factorization of the optimal\nsolution. Overall, the optimal solution is shown to lie on a Cartesian product\nof Riemannian manifolds. Furthermore, we exploit the versatile Riemannian\noptimization framework for proposing computationally efficient trust region\nalgorithm. The experiments illustrate the efficacy of the proposed algorithm on\nseveral real-world datasets across applications.\n", "versions": [{"version": "v1", "created": "Mon, 4 Dec 2017 16:55:52 GMT"}, {"version": "v2", "created": "Thu, 15 Feb 2018 07:24:04 GMT"}, {"version": "v3", "created": "Fri, 25 May 2018 08:55:14 GMT"}, {"version": "v4", "created": "Sat, 10 Nov 2018 06:20:42 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Nimishakavi", "Madhav", ""], ["Jawanpuria", "Pratik", ""], ["Mishra", "Bamdev", ""]]}, {"id": "1712.01199", "submitter": "Konstantinos Pelechrinis", "authors": "Evangelos Papalexakis and Konstantinos Pelechrinis", "title": "tHoops: A Multi-Aspect Analytical Framework Spatio-Temporal Basketball\n  Data", "comments": "Working paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the past few years advancements in sports information systems and\ntechnology has allowed us to collect a number of detailed spatio-temporal data\ncapturing various aspects of basketball. For example, shot charts, that is,\nmaps capturing locations of (made or missed) shots, and spatio-temporal\ntrajectories for all the players on the court can capture information about the\noffensive and defensive tendencies and schemes of a team. Characterization of\nthese processes is important for player and team comparisons, pre-game\nscouting, game preparation etc. Playing tendencies among teams have\ntraditionally been compared in a heuristic manner. Recently automated ways for\nsimilar comparisons have appeared in the sports analytics literature. However,\nthese approaches are almost exclusively focused on the spatial distribution of\nthe underlying actions (usually shots taken), ignoring a multitude of other\nparameters that can affect the action studied. In this work, we propose a\nframework based on tensor decomposition for obtaining a set of prototype\nspatio-temporal patterns based on the core spatiotemporal information and\ncontextual meta-data. The core of our framework is a 3D tensor X, whose\ndimensions represent the entity under consideration (team, player, possession\netc.), the location on the court and time. We make use of the PARAFAC\ndecomposition and we decompose the tensor into several interpretable patterns,\nthat can be thought of as prototype patterns of the process examined (e.g.,\nshot selection, offensive schemes etc.). We also introduce an approach for\nchoosing the number of components to be considered. Using the tensor\ncomponents, we can then express every entity as a weighted combination of these\ncomponents. The framework introduced in this paper can have further\napplications in the work-flow of the basketball operations of a franchise,\nwhich we also briefly discuss.\n", "versions": [{"version": "v1", "created": "Mon, 4 Dec 2017 17:06:11 GMT"}, {"version": "v2", "created": "Tue, 5 Dec 2017 15:09:30 GMT"}, {"version": "v3", "created": "Sun, 11 Feb 2018 15:44:00 GMT"}, {"version": "v4", "created": "Tue, 13 Feb 2018 13:09:07 GMT"}, {"version": "v5", "created": "Thu, 23 Aug 2018 14:57:12 GMT"}], "update_date": "2018-08-24", "authors_parsed": [["Papalexakis", "Evangelos", ""], ["Pelechrinis", "Konstantinos", ""]]}, {"id": "1712.01235", "submitter": "Abhinav Jauhri", "authors": "Abhinav Jauhri, Carlee Joe-Wong, John Paul Shen", "title": "On the Real-time Vehicle Placement Problem", "comments": "Presented at NIPS Workshop on Machine Learning for Intelligent\n  Transportation Systems, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by ride-sharing platforms' efforts to reduce their riders' wait\ntimes for a vehicle, this paper introduces a novel problem of placing vehicles\nto fulfill real-time pickup requests in a spatially and temporally changing\nenvironment. The real-time nature of this problem makes it fundamentally\ndifferent from other placement and scheduling problems, as it requires not only\nreal-time placement decisions but also handling real-time request dynamics,\nwhich are influenced by human mobility patterns. We use a dataset of ten\nmillion ride requests from four major U.S. cities to show that the requests\nexhibit significant self-similarity. We then propose distributed online\nlearning algorithms for the real-time vehicle placement problem and bound their\nexpected performance under this observed self-similarity.\n", "versions": [{"version": "v1", "created": "Mon, 4 Dec 2017 18:21:38 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Jauhri", "Abhinav", ""], ["Joe-Wong", "Carlee", ""], ["Shen", "John Paul", ""]]}, {"id": "1712.01238", "submitter": "Ishan Misra", "authors": "Ishan Misra, Ross Girshick, Rob Fergus, Martial Hebert, Abhinav Gupta,\n  Laurens van der Maaten", "title": "Learning by Asking Questions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an interactive learning framework for the development and\ntesting of intelligent visual systems, called learning-by-asking (LBA). We\nexplore LBA in context of the Visual Question Answering (VQA) task. LBA differs\nfrom standard VQA training in that most questions are not observed during\ntraining time, and the learner must ask questions it wants answers to. Thus,\nLBA more closely mimics natural learning and has the potential to be more\ndata-efficient than the traditional VQA setting. We present a model that\nperforms LBA on the CLEVR dataset, and show that it automatically discovers an\neasy-to-hard curriculum when learning interactively from an oracle. Our LBA\ngenerated data consistently matches or outperforms the CLEVR train data and is\nmore sample efficient. We also show that our model asks questions that\ngeneralize to state-of-the-art VQA models and to novel test time distributions.\n", "versions": [{"version": "v1", "created": "Mon, 4 Dec 2017 18:23:19 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Misra", "Ishan", ""], ["Girshick", "Ross", ""], ["Fergus", "Rob", ""], ["Hebert", "Martial", ""], ["Gupta", "Abhinav", ""], ["van der Maaten", "Laurens", ""]]}, {"id": "1712.01241", "submitter": "Alex Wang", "authors": "Abhratanu Dutta, Aravindan Vijayaraghavan, Alex Wang", "title": "Clustering Stable Instances of Euclidean k-means", "comments": "23 pages, 2 figures, appearing in NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Euclidean k-means problem is arguably the most widely-studied clustering\nproblem in machine learning. While the k-means objective is NP-hard in the\nworst-case, practitioners have enjoyed remarkable success in applying\nheuristics like Lloyd's algorithm for this problem. To address this disconnect,\nwe study the following question: what properties of real-world instances will\nenable us to design efficient algorithms and prove guarantees for finding the\noptimal clustering? We consider a natural notion called additive perturbation\nstability that we believe captures many practical instances. Stable instances\nhave unique optimal k-means solutions that do not change even when each point\nis perturbed a little (in Euclidean distance). This captures the property that\nthe k-means optimal solution should be tolerant to measurement errors and\nuncertainty in the points. We design efficient algorithms that provably recover\nthe optimal clustering for instances that are additive perturbation stable.\nWhen the instance has some additional separation, we show an efficient\nalgorithm with provable guarantees that is also robust to outliers. We\ncomplement these results by studying the amount of stability in real datasets\nand demonstrating that our algorithm performs well on these benchmark datasets.\n", "versions": [{"version": "v1", "created": "Mon, 4 Dec 2017 18:33:31 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Dutta", "Abhratanu", ""], ["Vijayaraghavan", "Aravindan", ""], ["Wang", "Alex", ""]]}, {"id": "1712.01252", "submitter": "Jun Lu", "authors": "Wei Ma, Jun Lu", "title": "An Equivalence of Fully Connected Layer and Convolutional Layer", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article demonstrates that convolutional operation can be converted to\nmatrix multiplication, which has the same calculation way with fully connected\nlayer. The article is helpful for the beginners of the neural network to\nunderstand how fully connected layer and the convolutional layer work in the\nbackend. To be concise and to make the article more readable, we only consider\nthe linear case. It can be extended to the non-linear case easily through\nplugging in a non-linear encapsulation to the values like this $\\sigma(x)$\ndenoted as $x^{\\prime}$.\n", "versions": [{"version": "v1", "created": "Mon, 4 Dec 2017 18:53:01 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Ma", "Wei", ""], ["Lu", "Jun", ""]]}, {"id": "1712.01257", "submitter": "Sakib Khan", "authors": "Sakib Mahmud Khan, Sababa Islam, MD Zadid Khan, Kakan Dey, Mashrur\n  Chowdhury, Nathan Huynh", "title": "Development of Statewide AADT Estimation Model from Short-Term Counts: A\n  Comparative Study for South Carolina", "comments": "This paper is accepted for both presentation and publication in the\n  Proceeding of 97th Annual Meeting of the Transportation Research Board,\n  Washington, D.C., (2018), and under review in Transportation Research Record\n  Journal. Abstract: 258 words + Text: 4660 + References: 552 + 6\n  tables/figures: 1500 = 6970 words", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Annual Average Daily Traffic (AADT) is an important parameter used in traffic\nengineering analysis. Departments of Transportation (DOTs) continually collect\ntraffic count using both permanent count stations (i.e., Automatic Traffic\nRecorders or ATRs) and temporary short-term count stations. In South Carolina,\n87% of the ATRs are located on interstates and arterial highways. For most\nsecondary highways (i.e., collectors and local roads), AADT is estimated based\non short-term counts. This paper develops AADT estimation models for different\nroadway functional classes with two machine learning techniques: Artificial\nNeural Network (ANN) and Support Vector Regression (SVR). The models aim to\npredict AADT from short-term counts. The results are first compared against\neach other to identify the best model. Then, the results of the best model are\ncompared against a regression method and factor-based method. The comparison\nreveals the superiority of SVR for AADT estimation for different roadway\nfunctional classes over all other methods. Among all developed models for\ndifferent functional roadway classes, the SVR-based model shows a minimum root\nmean square error (RMSE) of 0.22 and a mean absolute percentage error (MAPE) of\n11.3% for the interstate/expressway functional class. This model also shows a\nhigher R-squared value compared to the traditional factor-based model and\nregression model. SVR models are validated for each roadway functional class\nusing the 2016 ATR data and selected short-term count data collected by the\nSouth Carolina Department of Transportation (SCDOT). The validation results\nshow that the SVR-based AADT estimation models can be used by the SCDOT as a\nreliable option to predict AADT from the short-term counts.\n", "versions": [{"version": "v1", "created": "Thu, 30 Nov 2017 04:08:15 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Khan", "Sakib Mahmud", ""], ["Islam", "Sababa", ""], ["Khan", "MD Zadid", ""], ["Dey", "Kakan", ""], ["Chowdhury", "Mashrur", ""], ["Huynh", "Nathan", ""]]}, {"id": "1712.01262", "submitter": "Yong-Siang Shih", "authors": "Yong-Siang Shih, Kai-Yueh Chang, Hsuan-Tien Lin, Min Sun", "title": "Compatibility Family Learning for Item Recommendation and Generation", "comments": "9 pages, accepted to AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compatibility between items, such as clothes and shoes, is a major factor\namong customer's purchasing decisions. However, learning \"compatibility\" is\nchallenging due to (1) broader notions of compatibility than those of\nsimilarity, (2) the asymmetric nature of compatibility, and (3) only a small\nset of compatible and incompatible items are observed. We propose an end-to-end\ntrainable system to embed each item into a latent vector and project a query\nitem into K compatible prototypes in the same space. These prototypes reflect\nthe broad notions of compatibility. We refer to both the embedding and\nprototypes as \"Compatibility Family\". In our learned space, we introduce a\nnovel Projected Compatibility Distance (PCD) function which is differentiable\nand ensures diversity by aiming for at least one prototype to be close to a\ncompatible item, whereas none of the prototypes are close to an incompatible\nitem. We evaluate our system on a toy dataset, two Amazon product datasets, and\nPolyvore outfit dataset. Our method consistently achieves state-of-the-art\nperformance. Finally, we show that we can visualize the candidate compatible\nprototypes using a Metric-regularized Conditional Generative Adversarial\nNetwork (MrCGAN), where the input is a projected prototype and the output is a\ngenerated image of a compatible item. We ask human evaluators to judge the\nrelative compatibility between our generated images and images generated by\nCGANs conditioned directly on query items. Our generated images are\nsignificantly preferred, with roughly twice the number of votes as others.\n", "versions": [{"version": "v1", "created": "Sat, 2 Dec 2017 04:22:56 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Shih", "Yong-Siang", ""], ["Chang", "Kai-Yueh", ""], ["Lin", "Hsuan-Tien", ""], ["Sun", "Min", ""]]}, {"id": "1712.01272", "submitter": "Thanh Nguyen", "authors": "Thanh T. Nguyen, Jaesik Choi", "title": "Layer-wise Learning of Stochastic Neural Networks with Information\n  Bottleneck", "comments": "published in Entropy journal", "journal-ref": "Entropy 2019, 21(10), 976; https://doi.org/10.3390/e21100976", "doi": "10.3390/e21100976", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information Bottleneck (IB) is a generalization of rate-distortion theory\nthat naturally incorporates compression and relevance trade-offs for learning.\nThough the original IB has been extensively studied, there has not been much\nunderstanding of multiple bottlenecks which better fit in the context of neural\nnetworks. In this work, we propose Information Multi-Bottlenecks (IMBs) as an\nextension of IB to multiple bottlenecks which has a direct application to\ntraining neural networks by considering layers as multiple bottlenecks and\nweights as parameterized encoders and decoders. We show that the multiple\noptimality of IMB is not simultaneously achievable for stochastic encoders. We\nthus propose a simple compromised scheme of IMB which in turn generalizes\nmaximum likelihood estimate (MLE) principle in the context of stochastic neural\nnetworks. We demonstrate the effectiveness of IMB on classification tasks and\nadversarial robustness in MNIST and CIFAR10.\n", "versions": [{"version": "v1", "created": "Mon, 4 Dec 2017 02:16:03 GMT"}, {"version": "v2", "created": "Sat, 10 Feb 2018 02:00:51 GMT"}, {"version": "v3", "created": "Thu, 7 Jun 2018 12:03:50 GMT"}, {"version": "v4", "created": "Wed, 12 Sep 2018 08:22:24 GMT"}, {"version": "v5", "created": "Tue, 25 Jun 2019 12:23:47 GMT"}, {"version": "v6", "created": "Sun, 6 Oct 2019 11:19:50 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Nguyen", "Thanh T.", ""], ["Choi", "Jaesik", ""]]}, {"id": "1712.01275", "submitter": "Shangtong Zhang", "authors": "Shangtong Zhang, Richard S. Sutton", "title": "A Deeper Look at Experience Replay", "comments": "NIPS 2017 Deep Reinforcement Learning Symposium", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently experience replay is widely used in various deep reinforcement\nlearning (RL) algorithms, in this paper we rethink the utility of experience\nreplay. It introduces a new hyper-parameter, the memory buffer size, which\nneeds carefully tuning. However unfortunately the importance of this new\nhyper-parameter has been underestimated in the community for a long time. In\nthis paper we did a systematic empirical study of experience replay under\nvarious function representations. We showcase that a large replay buffer can\nsignificantly hurt the performance. Moreover, we propose a simple O(1) method\nto remedy the negative influence of a large replay buffer. We showcase its\nutility in both simple grid world and challenging domains like Atari games.\n", "versions": [{"version": "v1", "created": "Mon, 4 Dec 2017 06:03:26 GMT"}, {"version": "v2", "created": "Wed, 7 Mar 2018 16:35:12 GMT"}, {"version": "v3", "created": "Mon, 30 Apr 2018 04:24:26 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Zhang", "Shangtong", ""], ["Sutton", "Richard S.", ""]]}, {"id": "1712.01312", "submitter": "Christos Louizos", "authors": "Christos Louizos, Max Welling and Diederik P. Kingma", "title": "Learning Sparse Neural Networks through $L_0$ Regularization", "comments": "Published as a conference paper at the International Conference on\n  Learning Representations (ICLR) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a practical method for $L_0$ norm regularization for neural\nnetworks: pruning the network during training by encouraging weights to become\nexactly zero. Such regularization is interesting since (1) it can greatly speed\nup training and inference, and (2) it can improve generalization. AIC and BIC,\nwell-known model selection criteria, are special cases of $L_0$ regularization.\nHowever, since the $L_0$ norm of weights is non-differentiable, we cannot\nincorporate it directly as a regularization term in the objective function. We\npropose a solution through the inclusion of a collection of non-negative\nstochastic gates, which collectively determine which weights to set to zero. We\nshow that, somewhat surprisingly, for certain distributions over the gates, the\nexpected $L_0$ norm of the resulting gated weights is differentiable with\nrespect to the distribution parameters. We further propose the \\emph{hard\nconcrete} distribution for the gates, which is obtained by \"stretching\" a\nbinary concrete distribution and then transforming its samples with a\nhard-sigmoid. The parameters of the distribution over the gates can then be\njointly optimized with the original network parameters. As a result our method\nallows for straightforward and efficient learning of model structures with\nstochastic gradient descent and allows for conditional computation in a\nprincipled way. We perform various experiments to demonstrate the effectiveness\nof the resulting approach and regularizer.\n", "versions": [{"version": "v1", "created": "Mon, 4 Dec 2017 19:20:27 GMT"}, {"version": "v2", "created": "Fri, 22 Jun 2018 14:54:59 GMT"}], "update_date": "2018-06-25", "authors_parsed": [["Louizos", "Christos", ""], ["Welling", "Max", ""], ["Kingma", "Diederik P.", ""]]}, {"id": "1712.01329", "submitter": "Dana Kianfar", "authors": "Mircea Mironenco, Dana Kianfar, Ke Tran, Evangelos Kanoulas,\n  Efstratios Gavves", "title": "Examining Cooperation in Visual Dialog Models", "comments": "9 pages, 5 figures, 2 tables, code at\n  http://github.com/danakianfar/Examining-Cooperation-in-VDM/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we propose a blackbox intervention method for visual dialog\nmodels, with the aim of assessing the contribution of individual linguistic or\nvisual components. Concretely, we conduct structured or randomized\ninterventions that aim to impair an individual component of the model, and\nobserve changes in task performance. We reproduce a state-of-the-art visual\ndialog model and demonstrate that our methodology yields surprising insights,\nnamely that both dialog and image information have minimal contributions to\ntask performance. The intervention method presented here can be applied as a\nsanity check for the strength and robustness of each component in visual dialog\nsystems.\n", "versions": [{"version": "v1", "created": "Mon, 4 Dec 2017 20:16:52 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Mironenco", "Mircea", ""], ["Kianfar", "Dana", ""], ["Tran", "Ke", ""], ["Kanoulas", "Evangelos", ""], ["Gavves", "Efstratios", ""]]}, {"id": "1712.01378", "submitter": "Samuel Otto", "authors": "Samuel E. Otto and Clarence W. Rowley", "title": "Linearly-Recurrent Autoencoder Networks for Learning Dynamics", "comments": "37 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a method for learning low-dimensional approximations of\nnonlinear dynamical systems, based on neural-network approximations of the\nunderlying Koopman operator. Extended Dynamic Mode Decomposition (EDMD)\nprovides a useful data-driven approximation of the Koopman operator for\nanalyzing dynamical systems. This paper addresses a fundamental problem\nassociated with EDMD: a trade-off between representational capacity of the\ndictionary and over-fitting due to insufficient data. A new neural network\narchitecture combining an autoencoder with linear recurrent dynamics in the\nencoded state is used to learn a low-dimensional and highly informative\nKoopman-invariant subspace of observables. A method is also presented for\nbalanced model reduction of over-specified EDMD systems in feature space.\nNonlinear reconstruction using partially linear multi-kernel regression aims to\nimprove reconstruction accuracy from the low-dimensional state when the data\nhas complex but intrinsically low-dimensional structure. The techniques\ndemonstrate the ability to identify Koopman eigenfunctions of the unforced\nDuffing equation, create accurate low-dimensional models of an unstable\ncylinder wake flow, and make short-time predictions of the chaotic\nKuramoto-Sivashinsky equation.\n", "versions": [{"version": "v1", "created": "Mon, 4 Dec 2017 21:29:43 GMT"}, {"version": "v2", "created": "Tue, 15 Jan 2019 19:15:19 GMT"}], "update_date": "2019-01-17", "authors_parsed": [["Otto", "Samuel E.", ""], ["Rowley", "Clarence W.", ""]]}, {"id": "1712.01447", "submitter": "Shubhanshu Shekhar", "authors": "Shubhanshu Shekhar, Tara Javidi", "title": "Gaussian Process bandits with adaptive discretization", "comments": "34 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the problem of maximizing a black-box function $f:\\mathcal{X}\n\\to \\mathbb{R}$ is studied in the Bayesian framework with a Gaussian Process\n(GP) prior. In particular, a new algorithm for this problem is proposed, and\nhigh probability bounds on its simple and cumulative regret are established.\nThe query point selection rule in most existing methods involves an exhaustive\nsearch over an increasingly fine sequence of uniform discretizations of\n$\\mathcal{X}$. The proposed algorithm, in contrast, adaptively refines\n$\\mathcal{X}$ which leads to a lower computational complexity, particularly\nwhen $\\mathcal{X}$ is a subset of a high dimensional Euclidean space. In\naddition to the computational gains, sufficient conditions are identified under\nwhich the regret bounds of the new algorithm improve upon the known results.\nFinally an extension of the algorithm to the case of contextual bandits is\nproposed, and high probability bounds on the contextual regret are presented.\n", "versions": [{"version": "v1", "created": "Tue, 5 Dec 2017 02:22:45 GMT"}, {"version": "v2", "created": "Fri, 5 Jan 2018 21:36:14 GMT"}], "update_date": "2018-01-09", "authors_parsed": [["Shekhar", "Shubhanshu", ""], ["Javidi", "Tara", ""]]}, {"id": "1712.01456", "submitter": "Zhiqian Chen", "authors": "Zhiqian Chen, Chih-Wei Wu, Yen-Cheng Lu, Alexander Lerch and\n  Chang-Tien Lu", "title": "Learning to Fuse Music Genres with Generative Adversarial Dual Learning", "comments": "International Conference on Data Mining - New Orleans, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MM cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  FusionGAN is a novel genre fusion framework for music generation that\nintegrates the strengths of generative adversarial networks and dual learning.\nIn particular, the proposed method offers a dual learning extension that can\neffectively integrate the styles of the given domains. To efficiently quantify\nthe difference among diverse domains and avoid the vanishing gradient issue,\nFusionGAN provides a Wasserstein based metric to approximate the distance\nbetween the target domain and the existing domains. Adopting the Wasserstein\ndistance, a new domain is created by combining the patterns of the existing\ndomains using adversarial learning. Experimental results on public music\ndatasets demonstrated that our approach could effectively merge two genres.\n", "versions": [{"version": "v1", "created": "Tue, 5 Dec 2017 02:53:27 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Chen", "Zhiqian", ""], ["Wu", "Chih-Wei", ""], ["Lu", "Yen-Cheng", ""], ["Lerch", "Alexander", ""], ["Lu", "Chang-Tien", ""]]}, {"id": "1712.01473", "submitter": "Thomas Laurent", "authors": "Thomas Laurent and James von Brecht", "title": "Deep linear neural networks with arbitrary loss: All local minima are\n  global", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider deep linear networks with arbitrary convex differentiable loss.\nWe provide a short and elementary proof of the fact that all local minima are\nglobal minima if the hidden layers are either 1) at least as wide as the input\nlayer, or 2) at least as wide as the output layer. This result is the strongest\npossible in the following sense: If the loss is convex and Lipschitz but not\ndifferentiable then deep linear networks can have sub-optimal local minima.\n", "versions": [{"version": "v1", "created": "Tue, 5 Dec 2017 04:12:09 GMT"}, {"version": "v2", "created": "Tue, 24 Jul 2018 13:42:03 GMT"}], "update_date": "2018-07-25", "authors_parsed": [["Laurent", "Thomas", ""], ["von Brecht", "James", ""]]}, {"id": "1712.01496", "submitter": "Zhanli Chen", "authors": "Zhanli Chen, Rashid Ansari, Diana J. Wilkie", "title": "Learning Pain from Action Unit Combinations: A Weakly Supervised\n  Approach via Multiple Instance Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Patient pain can be detected highly reliably from facial expressions using a\nset of facial muscle-based action units (AUs) defined by the Facial Action\nCoding System (FACS). A key characteristic of facial expression of pain is the\nsimultaneous occurrence of pain-related AU combinations, whose automated\ndetection would be highly beneficial for efficient and practical pain\nmonitoring. Existing general Automated Facial Expression Recognition (AFER)\nsystems prove inadequate when applied specifically for detecting pain as they\neither focus on detecting individual pain-related AUs but not on combinations\nor they seek to bypass AU detection by training a binary pain classifier\ndirectly on pain intensity data but are limited by lack of enough labeled data\nfor satisfactory training. In this paper, we propose a new approach that mimics\nthe strategy of human coders of decoupling pain detection into two consecutive\ntasks: one performed at the individual video-frame level and the other at\nvideo-sequence level. Using state-of-the-art AFER tools to detect single AUs at\nthe frame level, we propose two novel data structures to encode AU combinations\nfrom single AU scores. Two weakly supervised learning frameworks namely\nmultiple instance learning (MIL) and multiple clustered instance learning\n(MCIL) are employed corresponding to each data structure to learn pain from\nvideo sequences. Experimental results show an 87% pain recognition accuracy\nwith 0.94 AUC (Area Under Curve) on the UNBC-McMaster Shoulder Pain Expression\ndataset. Tests on long videos in a lung cancer patient video dataset\ndemonstrates the potential value of the proposed system for pain monitoring in\nclinical settings.\n", "versions": [{"version": "v1", "created": "Tue, 5 Dec 2017 06:27:22 GMT"}, {"version": "v2", "created": "Tue, 20 Feb 2018 04:32:48 GMT"}], "update_date": "2018-02-21", "authors_parsed": [["Chen", "Zhanli", ""], ["Ansari", "Rashid", ""], ["Wilkie", "Diana J.", ""]]}, {"id": "1712.01572", "submitter": "Stefan Klus", "authors": "Stefan Klus, Ingmar Schuster, Krikamol Muandet", "title": "Eigendecompositions of Transfer Operators in Reproducing Kernel Hilbert\n  Spaces", "comments": null, "journal-ref": "Journal of Nonlinear Science, 2019", "doi": "10.1007/s00332-019-09574-z", "report-no": null, "categories": "math.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer operators such as the Perron--Frobenius or Koopman operator play an\nimportant role in the global analysis of complex dynamical systems. The\neigenfunctions of these operators can be used to detect metastable sets, to\nproject the dynamics onto the dominant slow processes, or to separate\nsuperimposed signals. We extend transfer operator theory to reproducing kernel\nHilbert spaces and show that these operators are related to Hilbert space\nrepresentations of conditional distributions, known as conditional mean\nembeddings in the machine learning community. Moreover, numerical methods to\ncompute empirical estimates of these embeddings are akin to data-driven methods\nfor the approximation of transfer operators such as extended dynamic mode\ndecomposition and its variants. One main benefit of the presented kernel-based\napproaches is that these methods can be applied to any domain where a\nsimilarity measure given by a kernel is available. We illustrate the results\nwith the aid of guiding examples and highlight potential applications in\nmolecular dynamics as well as video and text data analysis.\n", "versions": [{"version": "v1", "created": "Tue, 5 Dec 2017 11:17:11 GMT"}, {"version": "v2", "created": "Wed, 16 May 2018 12:36:56 GMT"}, {"version": "v3", "created": "Tue, 13 Aug 2019 07:07:02 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Klus", "Stefan", ""], ["Schuster", "Ingmar", ""], ["Muandet", "Krikamol", ""]]}, {"id": "1712.01600", "submitter": "Alexandre Benoit", "authors": "A Hamida, A. Beno\\^it (IPNL), P. Lambert (LISTIC), L Klein, C Amar, N.\n  Audebert (ONERA), S. Lef\\`evre (VALORIA)", "title": "Deep learning for semantic segmentation of remote sensing images with\n  rich spectral content", "comments": "IEEE International Geoscience and Remote Sensing Symposium, Jul 2017,\n  Fort Worth, United States. 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid development of Remote Sensing acquisition techniques, there is\na need to scale and improve processing tools to cope with the observed increase\nof both data volume and richness. Among popular techniques in remote sensing,\nDeep Learning gains increasing interest but depends on the quality of the\ntraining data. Therefore, this paper presents recent Deep Learning approaches\nfor fine or coarse land cover semantic segmentation estimation. Various 2D\narchitectures are tested and a new 3D model is introduced in order to jointly\nprocess the spatial and spectral dimensions of the data. Such a set of networks\nenables the comparison of the different spectral fusion schemes. Besides, we\nalso assess the use of a \" noisy ground truth \" (i.e. outdated and low spatial\nresolution labels) for training and testing the networks.\n", "versions": [{"version": "v1", "created": "Tue, 5 Dec 2017 12:25:43 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Hamida", "A", "", "IPNL"], ["Beno\u00eet", "A.", "", "IPNL"], ["Lambert", "P.", "", "LISTIC"], ["Klein", "L", "", "ONERA"], ["Amar", "C", "", "ONERA"], ["Audebert", "N.", "", "ONERA"], ["Lef\u00e8vre", "S.", "", "VALORIA"]]}, {"id": "1712.01626", "submitter": "Pierre-Yves Oudeyer", "authors": "Pierre-Yves Oudeyer (Flowers)", "title": "Autonomous development and learning in artificial intelligence and\n  robotics: Scaling up deep learning to human--like learning", "comments": null, "journal-ref": "Behavioral and Brain Sciences, Cambridge University Press (CUP),\n  2017, 40", "doi": "10.1017/S0140525X17000243", "report-no": null, "categories": "cs.AI cs.LG cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous lifelong development and learning is a fundamental capability of\nhumans, differentiating them from current deep learning systems. However, other\nbranches of artificial intelligence have designed crucial ingredients towards\nautonomous learning: curiosity and intrinsic motivation, social learning and\nnatural interaction with peers, and embodiment. These mechanisms guide\nexploration and autonomous choice of goals, and integrating them with deep\nlearning opens stimulating perspectives. Deep learning (DL) approaches made\ngreat advances in artificial intelligence, but are still far away from human\nlearning. As argued convincingly by Lake et al., differences include human\ncapabilities to learn causal models of the world from very little data,\nleveraging compositional representations and priors like intuitive physics and\npsychology. However, there are other fundamental differences between current DL\nsystems and human learning, as well as technical ingredients to fill this gap,\nthat are either superficially, or not adequately, discussed by Lake et al.\nThese fundamental mechanisms relate to autonomous development and learning.\nThey are bound to play a central role in artificial intelligence in the future.\nCurrent DL systems require engineers to manually specify a task-specific\nobjective function for every new task, and learn through off-line processing of\nlarge training databases. On the contrary, humans learn autonomously open-ended\nrepertoires of skills, deciding for themselves which goals to pursue or value,\nand which skills to explore, driven by intrinsic motivation/curiosity and\nsocial learning through natural interaction with peers. Such learning processes\nare incremental, online, and progressive. Human child development involves a\nprogressive increase of complexity in a curriculum of learning where skills are\nexplored, acquired, and built on each other, through particular ordering and\ntiming. Finally, human learning happens in the physical world, and through\nbodily and physical experimentation, under severe constraints on energy, time,\nand computational resources. In the two last decades, the field of\nDevelopmental and Cognitive Robotics (Cangelosi and Schlesinger, 2015, Asada et\nal., 2009), in strong interaction with developmental psychology and\nneuroscience, has achieved significant advances in computational\n", "versions": [{"version": "v1", "created": "Tue, 5 Dec 2017 14:03:56 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Oudeyer", "Pierre-Yves", "", "Flowers"]]}, {"id": "1712.01628", "submitter": "Vaneet Aggarwal", "authors": "Morteza Ashraphijuo and Vaneet Aggarwal and Xiaodong Wang", "title": "On Deterministic Sampling Patterns for Robust Low-Rank Matrix Completion", "comments": "Accepted to IEEE Signal Processing Letters", "journal-ref": null, "doi": "10.1109/LSP.2017.2780983", "report-no": null, "categories": "cs.IT cs.CV cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this letter, we study the deterministic sampling patterns for the\ncompletion of low rank matrix, when corrupted with a sparse noise, also known\nas robust matrix completion. We extend the recent results on the deterministic\nsampling patterns in the absence of noise based on the geometric analysis on\nthe Grassmannian manifold. A special case where each column has a certain\nnumber of noisy entries is considered, where our probabilistic analysis\nperforms very efficiently. Furthermore, assuming that the rank of the original\nmatrix is not given, we provide an analysis to determine if the rank of a valid\ncompletion is indeed the actual rank of the data corrupted with sparse noise by\nverifying some conditions.\n", "versions": [{"version": "v1", "created": "Tue, 5 Dec 2017 14:06:44 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Ashraphijuo", "Morteza", ""], ["Aggarwal", "Vaneet", ""], ["Wang", "Xiaodong", ""]]}, {"id": "1712.01641", "submitter": "Xuemei Xie", "authors": "Jiang Du, Xuemei Xie, Chenye Wang, Guangming Shi, Xun Xu, Yuxiang Wang", "title": "Fully Convolutional Measurement Network for Compressive Sensing Image\n  Reconstruction", "comments": "Accepted by neurocomputing in 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, deep learning methods have made a significant improvement in\ncompressive sensing image reconstruction task. In the existing methods, the\nscene is measured block by block due to the high computational complexity. This\nresults in block-effect of the recovered images. In this paper, we propose a\nfully convolutional measurement network, where the scene is measured as a\nwhole. The proposed method powerfully removes the block-effect since the\nstructure information of scene images is preserved. To make the measure more\nflexible, the measurement and the recovery parts are jointly trained. From the\nexperiments, it is shown that the results by the proposed method outperforms\nthose by the existing methods in PSNR, SSIM, and visual effect.\n", "versions": [{"version": "v1", "created": "Tue, 21 Nov 2017 04:27:23 GMT"}, {"version": "v2", "created": "Tue, 29 May 2018 04:20:25 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Du", "Jiang", ""], ["Xie", "Xuemei", ""], ["Wang", "Chenye", ""], ["Shi", "Guangming", ""], ["Xu", "Xun", ""], ["Wang", "Yuxiang", ""]]}, {"id": "1712.01652", "submitter": "Zeng Yu", "authors": "Zeng Yu, Tianrui Li, Ning Yu, Xun Gong, Ke Chen, Yi Pan", "title": "Three-Stream Convolutional Networks for Video-based Person\n  Re-Identification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper aims to develop a new architecture that can make full use of the\nfeature maps of convolutional networks. To this end, we study a number of\nmethods for video-based person re-identification and make the following\nfindings: 1) Max-pooling only focuses on the maximum value of a receptive\nfield, wasting a lot of information. 2) Networks with different streams even\nincluding the one with the worst performance work better than networks with\nsame streams, where each one has the best performance alone. 3) A full\nconnection layer at the end of convolutional networks is not necessary. Based\non these studies, we propose a new convolutional architecture termed\nThree-Stream Convolutional Networks (TSCN). It first uses different streams to\nlearn different aspects of feature maps for attentive spatio-temporal fusion of\nvideo, and then merges them together to study some union features. To further\nutilize the feature maps, two architectures are designed by using the\nstrategies of multi-scale and upsampling. Comparative experiments on iLIDS-VID,\nPRID-2011 and MARS datasets illustrate that the proposed architectures are\nsignificantly better for feature extraction than the state-of-the-art models.\n", "versions": [{"version": "v1", "created": "Wed, 22 Nov 2017 15:05:58 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Yu", "Zeng", ""], ["Li", "Tianrui", ""], ["Yu", "Ning", ""], ["Gong", "Xun", ""], ["Chen", "Ke", ""], ["Pan", "Yi", ""]]}, {"id": "1712.01653", "submitter": "Ignacio Garcia Dorado", "authors": "Aysegul Dundar and Ignacio Garcia-Dorado", "title": "Context Augmentation for Convolutional Neural Networks", "comments": "8 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent enhancements of deep convolutional neural networks (ConvNets)\nempowered by enormous amounts of labeled data have closed the gap with human\nperformance for many object recognition tasks. These impressive results have\ngenerated interest in understanding and visualization of ConvNets. In this\nwork, we study the effect of background in the task of image classification.\nOur results show that changing the backgrounds of the training datasets can\nhave drastic effects on testing accuracies. Furthermore, we enhance existing\naugmentation techniques with the foreground segmented objects. The findings of\nthis work are important in increasing the accuracies when only a small dataset\nis available, in creating datasets, and creating synthetic images.\n", "versions": [{"version": "v1", "created": "Wed, 22 Nov 2017 23:53:47 GMT"}, {"version": "v2", "created": "Tue, 12 Dec 2017 01:11:35 GMT"}], "update_date": "2017-12-13", "authors_parsed": [["Dundar", "Aysegul", ""], ["Garcia-Dorado", "Ignacio", ""]]}, {"id": "1712.01655", "submitter": "Michele Alberti", "authors": "Michele Alberti, Mathias Seuret, Rolf Ingold, Marcus Liwicki", "title": "A Pitfall of Unsupervised Pre-Training", "comments": "This submission has been withdrawn by the author, it is a duplicate\n  of arXiv:1703.04332", "journal-ref": "Conference on Neural Information Processing Systems, Deep\n  Learning: Bridging Theory and Practice, December 2017", "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The point of this paper is to question typical assumptions in deep learning\nand suggest alternatives. A particular contribution is to prove that even if a\nStacked Convolutional Auto-Encoder is good at reconstructing pictures, it is\nnot necessarily good at discriminating their classes. When using Auto-Encoders,\nintuitively one assumes that features which are good for reconstruction will\nalso lead to high classification accuracy. Indeed, it became research practice\nand is a suggested strategy by introductory books. However, we prove that this\nis not always the case. We thoroughly investigate the quality of features\nproduced by Stacked Convolutional Auto-Encoders when trained to reconstruct\ntheir input. In particular, we analyze the relation between the reconstruction\nand classification capabilities of the network, if we were to use the same\nfeatures for both tasks. Experimental results suggest that in fact, there is no\ncorrelation between the reconstruction score and the quality of features for a\nclassification task. This means, more formally, that the sub-dimension\nrepresentation space learned from the Stacked Convolutional Auto-Encoder (while\nbeing trained for input reconstruction) is not necessarily better separable\nthan the initial input space. Furthermore, we show that the reconstruction\nerror is not a good metric to assess the quality of features, because it is\nbiased by the decoder quality. We do not question the usefulness of\npre-training, but we conclude that aiming for the lowest reconstruction error\nis not necessarily a good idea if afterwards one performs a classification\ntask.\n", "versions": [{"version": "v1", "created": "Thu, 23 Nov 2017 14:54:18 GMT"}, {"version": "v2", "created": "Thu, 14 Dec 2017 11:51:44 GMT"}, {"version": "v3", "created": "Sun, 17 Dec 2017 20:23:24 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Alberti", "Michele", ""], ["Seuret", "Mathias", ""], ["Ingold", "Rolf", ""], ["Liwicki", "Marcus", ""]]}, {"id": "1712.01664", "submitter": "Jos van der Westhuizen", "authors": "David Janz, Jos van der Westhuizen, Brooks Paige, Matt J. Kusner,\n  Jos\\'e Miguel Hern\\'andez-Lobato", "title": "Learning a Generative Model for Validity in Complex Discrete Structures", "comments": "Conference paper at ICLR 2018. Code available online", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative models have been successfully used to learn representations\nfor high-dimensional discrete spaces by representing discrete objects as\nsequences and employing powerful sequence-based deep models. Unfortunately,\nthese sequence-based models often produce invalid sequences: sequences which do\nnot represent any underlying discrete structure; invalid sequences hinder the\nutility of such models. As a step towards solving this problem, we propose to\nlearn a deep recurrent validator model, which can estimate whether a partial\nsequence can function as the beginning of a full, valid sequence. This\nvalidator provides insight as to how individual sequence elements influence the\nvalidity of the overall sequence, and can be used to constrain sequence based\nmodels to generate valid sequences -- and thus faithfully model discrete\nobjects. Our approach is inspired by reinforcement learning, where an oracle\nwhich can evaluate validity of complete sequences provides a sparse reward\nsignal. We demonstrate its effectiveness as a generative model of Python 3\nsource code for mathematical expressions, and in improving the ability of a\nvariational autoencoder trained on SMILES strings to decode valid molecular\nstructures.\n", "versions": [{"version": "v1", "created": "Tue, 5 Dec 2017 14:36:23 GMT"}, {"version": "v2", "created": "Wed, 11 Apr 2018 19:19:59 GMT"}, {"version": "v3", "created": "Mon, 16 Apr 2018 17:55:48 GMT"}, {"version": "v4", "created": "Fri, 2 Nov 2018 02:19:00 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Janz", "David", ""], ["van der Westhuizen", "Jos", ""], ["Paige", "Brooks", ""], ["Kusner", "Matt J.", ""], ["Hern\u00e1ndez-Lobato", "Jos\u00e9 Miguel", ""]]}, {"id": "1712.01665", "submitter": "Beyza Ermis Ms", "authors": "Beyza Ermis, Ali Taylan Cemgil", "title": "Differentially Private Dropout", "comments": "arXiv admin note: text overlap with arXiv:1611.00340 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large data collections required for the training of neural networks often\ncontain sensitive information such as the medical histories of patients, and\nthe privacy of the training data must be preserved. In this paper, we introduce\na dropout technique that provides an elegant Bayesian interpretation to\ndropout, and show that the intrinsic noise added, with the primary goal of\nregularization, can be exploited to obtain a degree of differential privacy.\nThe iterative nature of training neural networks presents a challenge for\nprivacy-preserving estimation since multiple iterations increase the amount of\nnoise added. We overcome this by using a relaxed notion of differential\nprivacy, called concentrated differential privacy, which provides tighter\nestimates on the overall privacy loss. We demonstrate the accuracy of our\nprivacy-preserving dropout algorithm on benchmark datasets.\n", "versions": [{"version": "v1", "created": "Thu, 30 Nov 2017 21:15:01 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Ermis", "Beyza", ""], ["Cemgil", "Ali Taylan", ""]]}, {"id": "1712.01675", "submitter": "Jyoti Islam", "authors": "Jyoti Islam, Yanqing Zhang", "title": "An Ensemble of Deep Convolutional Neural Networks for Alzheimer's\n  Disease Detection and Classification", "comments": "Accepted poster at NIPS 2017 Workshop on Machine Learning for Health\n  (https://ml4health.github.io/2017/)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Alzheimer's Disease destroys brain cells causing people to lose their memory,\nmental functions and ability to continue daily activities. It is a severe\nneurological brain disorder which is not curable, but earlier detection of\nAlzheimer's Disease can help for proper treatment and to prevent brain tissue\ndamage. Detection and classification of Alzheimer's Disease (AD) is challenging\nbecause sometimes the signs that distinguish Alzheimer's Disease MRI data can\nbe found in normal healthy brain MRI data of older people. Moreover, there are\nrelatively small amount of dataset available to train the automated Alzheimer's\nDisease detection and classification model. In this paper, we present a novel\nAlzheimer's Disease detection and classification model using brain MRI data\nanalysis. We develop an ensemble of deep convolutional neural networks and\ndemonstrate superior performance on the Open Access Series of Imaging Studies\n(OASIS) dataset.\n", "versions": [{"version": "v1", "created": "Sat, 2 Dec 2017 03:13:52 GMT"}, {"version": "v2", "created": "Tue, 19 Dec 2017 19:17:09 GMT"}], "update_date": "2017-12-21", "authors_parsed": [["Islam", "Jyoti", ""], ["Zhang", "Yanqing", ""]]}, {"id": "1712.01712", "submitter": "Yuantao Gu", "authors": "Gen Li and Yuchen Jiao and Yuantao Gu", "title": "Linear Convergence of An Iterative Phase Retrieval Algorithm with Data\n  Reuse", "comments": "22 pages, 2 figure, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Phase retrieval has been an attractive but difficult problem rising from\nphysical science, and there has been a gap between state-of-the-art theoretical\nconvergence analyses and the corresponding efficient retrieval methods.\nFirstly, these analyses all assume that the sensing vectors and the iterative\nupdates are independent, which only fits the ideal model with infinite\nmeasurements but not the reality, where data are limited and have to be reused.\nSecondly, the empirical results of some efficient methods, such as the\nrandomized Kaczmarz method, show linear convergence, which is beyond existing\ntheoretical explanations considering its randomness and reuse of data. In this\nwork, we study for the first time, without the independence assumption, the\nconvergence behavior of the randomized Kaczmarz method for phase retrieval.\nSpecifically, beginning from taking expectation of the squared estimation error\nwith respect to the index of measurement by fixing the sensing vector and the\nerror in the previous step, we discard the independence assumption, rigorously\nderive the upper and lower bounds of the reduction of the mean squared error,\nand prove the linear convergence. This work fills the gap between a fast\nconverging algorithm and its theoretical understanding. The proposed\nmethodology may contribute to the study of other iterative algorithms for phase\nretrieval and other problems in the broad area of signal processing and machine\nlearning.\n", "versions": [{"version": "v1", "created": "Tue, 5 Dec 2017 15:24:49 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Li", "Gen", ""], ["Jiao", "Yuchen", ""], ["Gu", "Yuantao", ""]]}, {"id": "1712.01727", "submitter": "Jos\\'e Lezama", "authors": "Jos\\'e Lezama, Qiang Qiu, Pablo Mus\\'e, Guillermo Sapiro", "title": "OL\\'E: Orthogonal Low-rank Embedding, A Plug and Play Geometric Loss for\n  Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks trained using a softmax layer at the top and the\ncross-entropy loss are ubiquitous tools for image classification. Yet, this\ndoes not naturally enforce intra-class similarity nor inter-class margin of the\nlearned deep representations. To simultaneously achieve these two goals,\ndifferent solutions have been proposed in the literature, such as the pairwise\nor triplet losses. However, such solutions carry the extra task of selecting\npairs or triplets, and the extra computational burden of computing and learning\nfor many combinations of them. In this paper, we propose a plug-and-play loss\nterm for deep networks that explicitly reduces intra-class variance and\nenforces inter-class margin simultaneously, in a simple and elegant geometric\nmanner. For each class, the deep features are collapsed into a learned linear\nsubspace, or union of them, and inter-class subspaces are pushed to be as\northogonal as possible. Our proposed Orthogonal Low-rank Embedding (OL\\'E) does\nnot require carefully crafting pairs or triplets of samples for training, and\nworks standalone as a classification loss, being the first reported deep metric\nlearning framework of its kind. Because of the improved margin between features\nof different classes, the resulting deep networks generalize better, are more\ndiscriminative, and more robust. We demonstrate improved classification\nperformance in general object recognition, plugging the proposed loss term into\nexisting off-the-shelf architectures. In particular, we show the advantage of\nthe proposed loss in the small data/model scenario, and we significantly\nadvance the state-of-the-art on the Stanford STL-10 benchmark.\n", "versions": [{"version": "v1", "created": "Tue, 5 Dec 2017 16:03:56 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Lezama", "Jos\u00e9", ""], ["Qiu", "Qiang", ""], ["Mus\u00e9", "Pablo", ""], ["Sapiro", "Guillermo", ""]]}, {"id": "1712.01815", "submitter": "David Silver", "authors": "David Silver, Thomas Hubert, Julian Schrittwieser, Ioannis Antonoglou,\n  Matthew Lai, Arthur Guez, Marc Lanctot, Laurent Sifre, Dharshan Kumaran,\n  Thore Graepel, Timothy Lillicrap, Karen Simonyan, Demis Hassabis", "title": "Mastering Chess and Shogi by Self-Play with a General Reinforcement\n  Learning Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The game of chess is the most widely-studied domain in the history of\nartificial intelligence. The strongest programs are based on a combination of\nsophisticated search techniques, domain-specific adaptations, and handcrafted\nevaluation functions that have been refined by human experts over several\ndecades. In contrast, the AlphaGo Zero program recently achieved superhuman\nperformance in the game of Go, by tabula rasa reinforcement learning from games\nof self-play. In this paper, we generalise this approach into a single\nAlphaZero algorithm that can achieve, tabula rasa, superhuman performance in\nmany challenging domains. Starting from random play, and given no domain\nknowledge except the game rules, AlphaZero achieved within 24 hours a\nsuperhuman level of play in the games of chess and shogi (Japanese chess) as\nwell as Go, and convincingly defeated a world-champion program in each case.\n", "versions": [{"version": "v1", "created": "Tue, 5 Dec 2017 18:45:38 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Silver", "David", ""], ["Hubert", "Thomas", ""], ["Schrittwieser", "Julian", ""], ["Antonoglou", "Ioannis", ""], ["Lai", "Matthew", ""], ["Guez", "Arthur", ""], ["Lanctot", "Marc", ""], ["Sifre", "Laurent", ""], ["Kumaran", "Dharshan", ""], ["Graepel", "Thore", ""], ["Lillicrap", "Timothy", ""], ["Simonyan", "Karen", ""], ["Hassabis", "Demis", ""]]}, {"id": "1712.01833", "submitter": "Sihao Ding", "authors": "Sihao Ding, Andreas Wallin", "title": "Towards Recovery of Conditional Vectors from Conditional Generative\n  Adversarial Networks", "comments": "Under consideration for Pattern Recognition Letters, 11 pages", "journal-ref": "Pattern Recognition Letters, vol. 122, pp. 66-72, 1 May 2019", "doi": "10.1016/j.patrec.2019.02.020", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A conditional Generative Adversarial Network allows for generating samples\nconditioned on certain external information. Being able to recover latent and\nconditional vectors from a condi- tional GAN can be potentially valuable in\nvarious applications, ranging from image manipulation for entertaining purposes\nto diagnosis of the neural networks for security purposes. In this work, we\nshow that it is possible to recover both latent and conditional vectors from\ngenerated images given the generator of a conditional generative adversarial\nnetwork. Such a recovery is not trivial due to the often multi-layered\nnon-linearity of deep neural networks. Furthermore, the effect of such recovery\napplied on real natural images are investigated. We discovered that there\nexists a gap between the recovery performance on generated and real images,\nwhich we believe comes from the difference between generated data distribution\nand real data distribution. Experiments are conducted to evaluate the recovered\nconditional vectors and the reconstructed images from these recovered vectors\nquantitatively and qualitatively, showing promising results.\n", "versions": [{"version": "v1", "created": "Wed, 6 Dec 2017 03:40:31 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Ding", "Sihao", ""], ["Wallin", "Andreas", ""]]}, {"id": "1712.01880", "submitter": "Samuel Weisenthal", "authors": "Sam Weisenthal, Haofu Liao, Philip Ng, Martin Zand", "title": "Sum of previous inpatient serum creatinine measurements predicts acute\n  kidney injury in rehospitalized patients", "comments": "Accepted poster at NIPS 2017 Workshop on Machine Learning for Health\n  (https://ml4health.github.io/2017/)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acute Kidney Injury (AKI), the abrupt decline in kidney function due to\ntemporary or permanent injury, is associated with increased mortality,\nmorbidity, length of stay, and hospital cost. Sometimes, simple interventions\nsuch as medication review or hydration can prevent AKI. There is therefore\ninterest in estimating risk of AKI at hospitalization. To gain insight into\nthis task, we employ multilayer perceptron (MLP) and recurrent neural networks\n(RNNs) using serum creatinine (sCr) as a lone feature. We explore different\nfeature input structures, including variable-length look-backs and a nested\nformulation for rehospitalized patients with previous sCr measurements.\nExperimental results show that the simplest model, MLP processing the sum of\nsCr, had best performance: AUROC 0.92 and AUPRC 0.70. Such a simple model could\nbe easily integrated into an EHR. Preliminary results also suggest that\ninpatient data streams with missing outpatient measurements---common in the\nmedical setting---might be best modeled with a tailored architecture.\n", "versions": [{"version": "v1", "created": "Tue, 5 Dec 2017 19:35:32 GMT"}], "update_date": "2017-12-07", "authors_parsed": [["Weisenthal", "Sam", ""], ["Liao", "Haofu", ""], ["Ng", "Philip", ""], ["Zand", "Martin", ""]]}, {"id": "1712.01887", "submitter": "Song Han", "authors": "Yujun Lin, Song Han, Huizi Mao, Yu Wang, William J. Dally", "title": "Deep Gradient Compression: Reducing the Communication Bandwidth for\n  Distributed Training", "comments": "we find 99.9% of the gradient exchange in distributed SGD is\n  redundant; we reduce the communication bandwidth by two orders of magnitude\n  without losing accuracy. Code is available at:\n  https://github.com/synxlin/deep-gradient-compression", "journal-ref": "ICLR 2018", "doi": null, "report-no": null, "categories": "cs.CV cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale distributed training requires significant communication bandwidth\nfor gradient exchange that limits the scalability of multi-node training, and\nrequires expensive high-bandwidth network infrastructure. The situation gets\neven worse with distributed training on mobile devices (federated learning),\nwhich suffers from higher latency, lower throughput, and intermittent poor\nconnections. In this paper, we find 99.9% of the gradient exchange in\ndistributed SGD is redundant, and propose Deep Gradient Compression (DGC) to\ngreatly reduce the communication bandwidth. To preserve accuracy during\ncompression, DGC employs four methods: momentum correction, local gradient\nclipping, momentum factor masking, and warm-up training. We have applied Deep\nGradient Compression to image classification, speech recognition, and language\nmodeling with multiple datasets including Cifar10, ImageNet, Penn Treebank, and\nLibrispeech Corpus. On these scenarios, Deep Gradient Compression achieves a\ngradient compression ratio from 270x to 600x without losing accuracy, cutting\nthe gradient size of ResNet-50 from 97MB to 0.35MB, and for DeepSpeech from\n488MB to 0.74MB. Deep gradient compression enables large-scale distributed\ntraining on inexpensive commodity 1Gbps Ethernet and facilitates distributed\ntraining on mobile. Code is available at:\nhttps://github.com/synxlin/deep-gradient-compression.\n", "versions": [{"version": "v1", "created": "Tue, 5 Dec 2017 19:48:11 GMT"}, {"version": "v2", "created": "Mon, 5 Feb 2018 19:38:39 GMT"}, {"version": "v3", "created": "Tue, 23 Jun 2020 03:28:30 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Lin", "Yujun", ""], ["Han", "Song", ""], ["Mao", "Huizi", ""], ["Wang", "Yu", ""], ["Dally", "William J.", ""]]}, {"id": "1712.01897", "submitter": "Joel Veness", "authors": "Joel Veness, Tor Lattimore, Avishkar Bhoopchand, Agnieszka\n  Grabska-Barwinska, Christopher Mattern, Peter Toth", "title": "Online Learning with Gated Linear Networks", "comments": "40 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a family of probabilistic architectures designed for\nonline learning under the logarithmic loss. Rather than relying on non-linear\ntransfer functions, our method gains representational power by the use of data\nconditioning. We state under general conditions a learnable capacity theorem\nthat shows this approach can in principle learn any bounded Borel-measurable\nfunction on a compact subset of euclidean space; the result is stronger than\nmany universality results for connectionist architectures because we provide\nboth the model and the learning procedure for which convergence is guaranteed.\n", "versions": [{"version": "v1", "created": "Tue, 5 Dec 2017 20:07:59 GMT"}], "update_date": "2017-12-07", "authors_parsed": [["Veness", "Joel", ""], ["Lattimore", "Tor", ""], ["Bhoopchand", "Avishkar", ""], ["Grabska-Barwinska", "Agnieszka", ""], ["Mattern", "Christopher", ""], ["Toth", "Peter", ""]]}, {"id": "1712.01935", "submitter": "Dung Phan", "authors": "Dung Phan, Radu Grosu, Nicola Paoletti, Scott A. Smolka, Scott D.\n  Stoller", "title": "How to Learn a Model Checker", "comments": "16 pages, 13 figures, short version submitted to HSCC2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how machine-learning techniques, particularly neural networks, offer\na very effective and highly efficient solution to the approximate\nmodel-checking problem for continuous and hybrid systems, a solution where the\ngeneral-purpose model checker is replaced by a model-specific classifier\ntrained by sampling model trajectories. To the best of our knowledge, we are\nthe first to establish this link from machine learning to model checking. Our\nmethod comprises a pipeline of analysis techniques for estimating and obtaining\nstatistical guarantees on the classifier's prediction performance, as well as\ntuning techniques to improve such performance. Our experimental evaluation\nconsiders the time-bounded reachability problem for three well-established\nbenchmarks in the hybrid systems community. On these examples, we achieve an\naccuracy of 99.82% to 100% and a false-negative rate (incorrectly predicting\nthat unsafe states are not reachable from a given state) of 0.0007 to 0. We\nbelieve that this level of accuracy is acceptable in many practical\napplications and we show how the approximate model checker can be made more\nconservative by tuning the classifier through further training and selection of\nthe classification threshold.\n", "versions": [{"version": "v1", "created": "Tue, 5 Dec 2017 21:25:56 GMT"}], "update_date": "2017-12-07", "authors_parsed": [["Phan", "Dung", ""], ["Grosu", "Radu", ""], ["Paoletti", "Nicola", ""], ["Smolka", "Scott A.", ""], ["Stoller", "Scott D.", ""]]}, {"id": "1712.01975", "submitter": "Nand Sharma", "authors": "Nand Sharma, Prathamesh Verlekar, Rehab Ashary, Sui Zhiquan", "title": "Regularization and feature selection for large dimensional data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature selection has evolved to be an important step in several machine\nlearning paradigms. In domains like bio-informatics and text classification\nwhich involve data of high dimensions, feature selection can help in\ndrastically reducing the feature space. In cases where it is difficult or\ninfeasible to obtain sufficient number of training examples, feature selection\nhelps overcome the curse of dimensionality which in turn helps improve\nperformance of the classification algorithm. The focus of our research here are\nfive embedded feature selection methods which use either the ridge regression,\nor Lasso regression, or a combination of the two in the regularization part of\nthe optimization function. We evaluate five chosen methods on five large\ndimensional datasets and compare them on the parameters of sparsity and\ncorrelation in the datasets and their execution times.\n", "versions": [{"version": "v1", "created": "Wed, 6 Dec 2017 00:01:57 GMT"}, {"version": "v2", "created": "Sat, 17 Mar 2018 23:49:36 GMT"}, {"version": "v3", "created": "Fri, 19 Apr 2019 20:20:39 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Sharma", "Nand", ""], ["Verlekar", "Prathamesh", ""], ["Ashary", "Rehab", ""], ["Zhiquan", "Sui", ""]]}, {"id": "1712.01977", "submitter": "Nand Sharma", "authors": "Nand Sharma", "title": "Single-trial P300 Classification using PCA with LDA, QDA and Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The P300 event-related potential (ERP), evoked in scalp-recorded\nelectroencephalography (EEG) by external stimuli, has proven to be a reliable\nresponse for controlling a BCI. The P300 component of an event related\npotential is thus widely used in brain-computer interfaces to translate the\nsubjects' intent by mere thoughts into commands to control artificial devices.\nThe main challenge in the classification of P300 trials in\nelectroencephalographic (EEG) data is the low signal-to-noise ratio (SNR) of\nthe P300 response. To overcome the low SNR of individual trials, it is common\npractice to average together many consecutive trials, which effectively\ndiminishes the random noise. Unfortunately, when more repeated trials are\nrequired for applications such as the P300 speller, the communication rate is\ngreatly reduced. This has resulted in a need for better methods to improve\nsingle-trial classification accuracy of P300 response. In this work, we use\nPrincipal Component Analysis (PCA) as a preprocessing method and use Linear\nDiscriminant Analysis (LDA)and neural networks for classification. The results\nshow that a combination of PCA with these methods provided as high as 13\\%\naccuracy gain for single-trial classification while using only 3 to 4 principal\ncomponents.\n", "versions": [{"version": "v1", "created": "Wed, 6 Dec 2017 00:21:07 GMT"}], "update_date": "2017-12-07", "authors_parsed": [["Sharma", "Nand", ""]]}, {"id": "1712.01990", "submitter": "Kyeong Soo (Joseph) Kim", "authors": "Kyeong Soo Kim, Sanghyuk Lee, Kaizhu Huang", "title": "A Scalable Deep Neural Network Architecture for Multi-Building and\n  Multi-Floor Indoor Localization Based on Wi-Fi Fingerprinting", "comments": "9 pages, 6 figures", "journal-ref": "Big Data Analytics, vol. 3, no. 4, pp. 1-17, Apr. 19, 2018", "doi": "10.1186/s41044-018-0031-2", "report-no": null, "categories": "cs.NI cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the key technologies for future large-scale location-aware services\ncovering a complex of multi-story buildings --- e.g., a big shopping mall and a\nuniversity campus --- is a scalable indoor localization technique. In this\npaper, we report the current status of our investigation on the use of deep\nneural networks (DNNs) for scalable building/floor classification and\nfloor-level position estimation based on Wi-Fi fingerprinting. Exploiting the\nhierarchical nature of the building/floor estimation and floor-level\ncoordinates estimation of a location, we propose a new DNN architecture\nconsisting of a stacked autoencoder for the reduction of feature space\ndimension and a feed-forward classifier for multi-label classification of\nbuilding/floor/location, on which the multi-building and multi-floor indoor\nlocalization system based on Wi-Fi fingerprinting is built. Experimental\nresults for the performance of building/floor estimation and floor-level\ncoordinates estimation of a given location demonstrate the feasibility of the\nproposed DNN-based indoor localization system, which can provide near\nstate-of-the-art performance using a single DNN, for the implementation with\nlower complexity and energy consumption at mobile devices.\n", "versions": [{"version": "v1", "created": "Wed, 6 Dec 2017 01:06:01 GMT"}], "update_date": "2018-06-26", "authors_parsed": [["Kim", "Kyeong Soo", ""], ["Lee", "Sanghyuk", ""], ["Huang", "Kaizhu", ""]]}, {"id": "1712.02029", "submitter": "Aditya Devarakonda", "authors": "Aditya Devarakonda, Maxim Naumov, Michael Garland", "title": "AdaBatch: Adaptive Batch Sizes for Training Deep Neural Networks", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training deep neural networks with Stochastic Gradient Descent, or its\nvariants, requires careful choice of both learning rate and batch size. While\nsmaller batch sizes generally converge in fewer training epochs, larger batch\nsizes offer more parallelism and hence better computational efficiency. We have\ndeveloped a new training approach that, rather than statically choosing a\nsingle batch size for all epochs, adaptively increases the batch size during\nthe training process. Our method delivers the convergence rate of small batch\nsizes while achieving performance similar to large batch sizes. We analyse our\napproach using the standard AlexNet, ResNet, and VGG networks operating on the\npopular CIFAR-10, CIFAR-100, and ImageNet datasets. Our results demonstrate\nthat learning with adaptive batch sizes can improve performance by factors of\nup to 6.25 on 4 NVIDIA Tesla P100 GPUs while changing accuracy by less than 1%\nrelative to training with fixed batch sizes.\n", "versions": [{"version": "v1", "created": "Wed, 6 Dec 2017 04:19:14 GMT"}, {"version": "v2", "created": "Wed, 14 Feb 2018 04:26:45 GMT"}], "update_date": "2018-02-15", "authors_parsed": [["Devarakonda", "Aditya", ""], ["Naumov", "Maxim", ""], ["Garland", "Michael", ""]]}, {"id": "1712.02034", "submitter": "Garrett Goh", "authors": "Garrett B. Goh, Nathan O. Hodas, Charles Siegel, Abhinav Vishnu", "title": "SMILES2Vec: An Interpretable General-Purpose Deep Neural Network for\n  Predicting Chemical Properties", "comments": "Submitted to SIGKDD 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chemical databases store information in text representations, and the SMILES\nformat is a universal standard used in many cheminformatics software. Encoded\nin each SMILES string is structural information that can be used to predict\ncomplex chemical properties. In this work, we develop SMILES2vec, a deep RNN\nthat automatically learns features from SMILES to predict chemical properties,\nwithout the need for additional explicit feature engineering. Using Bayesian\noptimization methods to tune the network architecture, we show that an\noptimized SMILES2vec model can serve as a general-purpose neural network for\npredicting distinct chemical properties including toxicity, activity,\nsolubility and solvation energy, while also outperforming contemporary MLP\nneural networks that uses engineered features. Furthermore, we demonstrate\nproof-of-concept of interpretability by developing an explanation mask that\nlocalizes on the most important characters used in making a prediction. When\ntested on the solubility dataset, it identified specific parts of a chemical\nthat is consistent with established first-principles knowledge with an accuracy\nof 88%. Our work demonstrates that neural networks can learn technically\naccurate chemical concept and provide state-of-the-art accuracy, making\ninterpretable deep neural networks a useful tool of relevance to the chemical\nindustry.\n", "versions": [{"version": "v1", "created": "Wed, 6 Dec 2017 04:29:28 GMT"}, {"version": "v2", "created": "Sun, 18 Mar 2018 13:50:32 GMT"}], "update_date": "2018-08-16", "authors_parsed": [["Goh", "Garrett B.", ""], ["Hodas", "Nathan O.", ""], ["Siegel", "Charles", ""], ["Vishnu", "Abhinav", ""]]}, {"id": "1712.02037", "submitter": "Peter Henderson", "authors": "Peter Henderson, Thang Doan, Riashat Islam, David Meger", "title": "Bayesian Policy Gradients via Alpha Divergence Dropout Inference", "comments": "Accepted to Bayesian Deep Learning Workshop at NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy gradient methods have had great success in solving continuous control\ntasks, yet the stochastic nature of such problems makes deterministic value\nestimation difficult. We propose an approach which instead estimates a\ndistribution by fitting the value function with a Bayesian Neural Network. We\noptimize an $\\alpha$-divergence objective with Bayesian dropout approximation\nto learn and estimate this distribution. We show that using the Monte Carlo\nposterior mean of the Bayesian value function distribution, rather than a\ndeterministic network, improves stability and performance of policy gradient\nmethods in continuous control MuJoCo simulations.\n", "versions": [{"version": "v1", "created": "Wed, 6 Dec 2017 04:38:06 GMT"}], "update_date": "2017-12-07", "authors_parsed": [["Henderson", "Peter", ""], ["Doan", "Thang", ""], ["Islam", "Riashat", ""], ["Meger", "David", ""]]}, {"id": "1712.02046", "submitter": "Borui Wang", "authors": "Borui Wang, Geoffrey Gordon", "title": "Learning General Latent-Variable Graphical Models with Predictive Belief\n  Propagation", "comments": "In AAAI 2020 proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning general latent-variable probabilistic graphical models is a key\ntheoretical challenge in machine learning and artificial intelligence. All\nprevious methods, including the EM algorithm and the spectral algorithms, face\nsevere limitations that largely restrict their applicability and affect their\nperformance. In order to overcome these limitations, in this paper we introduce\na novel formulation of message-passing inference over junction trees named\npredictive belief propagation, and propose a new learning and inference\nalgorithm for general latent-variable graphical models based on this\nformulation. Our proposed algorithm reduces the hard parameter learning problem\ninto a sequence of supervised learning problems, and unifies the learning of\ndifferent kinds of latent graphical models into a single learning framework,\nwhich is local-optima-free and statistically consistent. We then give a proof\nof the correctness of our algorithm and show in experiments on both synthetic\nand real datasets that our algorithm significantly outperforms both the EM\nalgorithm and the spectral algorithm while also being orders of magnitude\nfaster to compute.\n", "versions": [{"version": "v1", "created": "Wed, 6 Dec 2017 05:38:25 GMT"}, {"version": "v2", "created": "Thu, 28 Nov 2019 14:50:06 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Wang", "Borui", ""], ["Gordon", "Geoffrey", ""]]}, {"id": "1712.02116", "submitter": "Huy Phan", "authors": "Huy Phan, Philipp Koch, Ian McLoughlin, Alfred Mertins", "title": "Enabling Early Audio Event Detection with Neural Networks", "comments": "Published version available at\n  https://ieeexplore.ieee.org/document/8461859", "journal-ref": "Published in Proceedings of 43rd IEEE International Conference on\n  Acoustics, Speech, and Signal Processing (ICASSP), pp. 141-145, 2018", "doi": "10.1109/ICASSP.2018.8461859", "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a methodology for early detection of audio events from\naudio streams. Early detection is the ability to infer an ongoing event during\nits initial stage. The proposed system consists of a novel inference step\ncoupled with dual parallel tailored-loss deep neural networks (DNNs). The DNNs\nshare a similar architecture except for their loss functions, i.e. weighted\nloss and multitask loss, which are designed to efficiently cope with issues\ncommon to audio event detection. The inference step is newly introduced to make\nuse of the network outputs for recognizing ongoing events. The monotonicity of\nthe detection function is required for reliable early detection, and will also\nbe proved. Experiments on the ITC-Irst database show that the proposed system\nachieves state-of-the-art detection performance. Furthermore, even partial\nevents are sufficient to achieve good performance similar to that obtained when\nan entire event is observed, enabling early event detection.\n", "versions": [{"version": "v1", "created": "Wed, 6 Dec 2017 10:12:46 GMT"}, {"version": "v2", "created": "Sat, 6 Apr 2019 22:20:28 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Phan", "Huy", ""], ["Koch", "Philipp", ""], ["McLoughlin", "Ian", ""], ["Mertins", "Alfred", ""]]}, {"id": "1712.02122", "submitter": "Fr\\'ed\\'eric Rayar", "authors": "Fr\\'ed\\'eric Rayar, Masanori Goto and Seiichi Uchida", "title": "CNN training with graph-based sample preselection: application to\n  handwritten character recognition", "comments": "Paper of 10 pages. Minor spelling corrections brought regarding the\n  v2. Accepted as an oral paper in the 13th IAPR Internationale Workshop on\n  Document Analysis Systems (DAS 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a study on sample preselection in large training\ndata set for CNN-based classification. To do so, we structure the input data\nset in a network representation, namely the Relative Neighbourhood Graph, and\nthen extract some vectors of interest. The proposed preselection method is\nevaluated in the context of handwritten character recognition, by using two\ndata sets, up to several hundred thousands of images. It is shown that the\ngraph-based preselection can reduce the training data set without degrading the\nrecognition accuracy of a non pretrained CNN shallow model.\n", "versions": [{"version": "v1", "created": "Wed, 6 Dec 2017 10:43:50 GMT"}, {"version": "v2", "created": "Fri, 8 Dec 2017 10:44:54 GMT"}, {"version": "v3", "created": "Tue, 6 Mar 2018 07:18:40 GMT"}], "update_date": "2018-03-07", "authors_parsed": [["Rayar", "Fr\u00e9d\u00e9ric", ""], ["Goto", "Masanori", ""], ["Uchida", "Seiichi", ""]]}, {"id": "1712.02136", "submitter": "Ziniu Hu", "authors": "Ziniu Hu, Weiqing Liu, Jiang Bian, Xuanzhe Liu, Tie-Yan Liu", "title": "Listening to Chaotic Whispers: A Deep Learning Framework for\n  News-oriented Stock Trend Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stock trend prediction plays a critical role in seeking maximized profit from\nstock investment. However, precise trend prediction is very difficult since the\nhighly volatile and non-stationary nature of stock market. Exploding\ninformation on Internet together with advancing development of natural language\nprocessing and text mining techniques have enable investors to unveil market\ntrends and volatility from online content. Unfortunately, the quality,\ntrustworthiness and comprehensiveness of online content related to stock market\nvaries drastically, and a large portion consists of the low-quality news,\ncomments, or even rumors. To address this challenge, we imitate the learning\nprocess of human beings facing such chaotic online news, driven by three\nprinciples: sequential content dependency, diverse influence, and effective and\nefficient learning. In this paper, to capture the first two principles, we\ndesigned a Hybrid Attention Networks to predict the stock trend based on the\nsequence of recent related news. Moreover, we apply the self-paced learning\nmechanism to imitate the third principle. Extensive experiments on real-world\nstock market data demonstrate the effectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Wed, 6 Dec 2017 11:33:21 GMT"}, {"version": "v2", "created": "Fri, 16 Mar 2018 17:32:11 GMT"}, {"version": "v3", "created": "Wed, 20 Feb 2019 04:30:16 GMT"}], "update_date": "2019-02-21", "authors_parsed": [["Hu", "Ziniu", ""], ["Liu", "Weiqing", ""], ["Bian", "Jiang", ""], ["Liu", "Xuanzhe", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "1712.02154", "submitter": "Sebastian Stabinger MSc", "authors": "Sebastian Stabinger, Antonio Rodriguez-Sanchez", "title": "Guided Labeling using Convolutional Neural Networks", "comments": "Under review for CVPR2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the last couple of years, deep learning and especially convolutional\nneural networks have become one of the work horses of computer vision. One\nlimiting factor for the applicability of supervised deep learning to more areas\nis the need for large, manually labeled datasets. In this paper we propose an\neasy to implement method we call guided labeling, which automatically\ndetermines which samples from an unlabeled dataset should be labeled. We show\nthat using this procedure, the amount of samples that need to be labeled is\nreduced considerably in comparison to labeling images arbitrarily.\n", "versions": [{"version": "v1", "created": "Wed, 6 Dec 2017 12:18:24 GMT"}], "update_date": "2017-12-07", "authors_parsed": [["Stabinger", "Sebastian", ""], ["Rodriguez-Sanchez", "Antonio", ""]]}, {"id": "1712.02159", "submitter": "Lu\\'is Alexandre", "authors": "Ricardo Gamelas Sousa and Lu\\'is A. Alexandre and Jorge M. Santos and\n  Lu\\'is M. Silva and Joaquim Marques de S\\'a", "title": "Distribution-Based Categorization of Classifier Transfer Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer Learning (TL) aims to transfer knowledge acquired in one problem,\nthe source problem, onto another problem, the target problem, dispensing with\nthe bottom-up construction of the target model. Due to its relevance, TL has\ngained significant interest in the Machine Learning community since it paves\nthe way to devise intelligent learning models that can easily be tailored to\nmany different applications. As it is natural in a fast evolving area, a wide\nvariety of TL methods, settings and nomenclature have been proposed so far.\nHowever, a wide range of works have been reporting different names for the same\nconcepts. This concept and terminology mixture contribute however to obscure\nthe TL field, hindering its proper consideration. In this paper we present a\nreview of the literature on the majority of classification TL methods, and also\na distribution-based categorization of TL with a common nomenclature suitable\nto classification problems. Under this perspective three main TL categories are\npresented, discussed and illustrated with examples.\n", "versions": [{"version": "v1", "created": "Wed, 6 Dec 2017 12:35:44 GMT"}], "update_date": "2017-12-07", "authors_parsed": [["Sousa", "Ricardo Gamelas", ""], ["Alexandre", "Lu\u00eds A.", ""], ["Santos", "Jorge M.", ""], ["Silva", "Lu\u00eds M.", ""], ["de S\u00e1", "Joaquim Marques", ""]]}, {"id": "1712.02162", "submitter": "Chaopeng Shen", "authors": "Chaopeng Shen", "title": "A trans-disciplinary review of deep learning research for water\n  resources scientists", "comments": null, "journal-ref": "Water Resources Research, 2018", "doi": "10.1029/2018WR022643", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning (DL), a new-generation of artificial neural network research,\nhas transformed industries, daily lives and various scientific disciplines in\nrecent years. DL represents significant progress in the ability of neural\nnetworks to automatically engineer problem-relevant features and capture highly\ncomplex data distributions. I argue that DL can help address several major new\nand old challenges facing research in water sciences such as\ninter-disciplinarity, data discoverability, hydrologic scaling, equifinality,\nand needs for parameter regionalization. This review paper is intended to\nprovide water resources scientists and hydrologists in particular with a simple\ntechnical overview, trans-disciplinary progress update, and a source of\ninspiration about the relevance of DL to water. The review reveals that various\nphysical and geoscientific disciplines have utilized DL to address data\nchallenges, improve efficiency, and gain scientific insights. DL is especially\nsuited for information extraction from image-like data and sequential data.\nTechniques and experiences presented in other disciplines are of high relevance\nto water research. Meanwhile, less noticed is that DL may also serve as a\nscientific exploratory tool. A new area termed 'AI neuroscience,' where\nscientists interpret the decision process of deep networks and derive insights,\nhas been born. This budding sub-discipline has demonstrated methods including\ncorrelation-based analysis, inversion of network-extracted features,\nreduced-order approximations by interpretable models, and attribution of\nnetwork decisions to inputs. Moreover, DL can also use data to condition\nneurons that mimic problem-specific fundamental organizing units, thus\nrevealing emergent behaviors of these units. Vast opportunities exist for DL to\npropel advances in water sciences.\n", "versions": [{"version": "v1", "created": "Wed, 6 Dec 2017 12:44:27 GMT"}, {"version": "v2", "created": "Thu, 7 Dec 2017 14:15:13 GMT"}, {"version": "v3", "created": "Fri, 24 Aug 2018 15:12:46 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Shen", "Chaopeng", ""]]}, {"id": "1712.02165", "submitter": "Huan Yin", "authors": "Huan Yin, Li Tang, Xiaqing Ding, Yue Wang and Rong Xiong", "title": "LocNet: Global localization in 3D point clouds for mobile vehicles", "comments": "6 pages, IV 2018 accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Global localization in 3D point clouds is a challenging problem of estimating\nthe pose of vehicles without any prior knowledge. In this paper, a solution to\nthis problem is presented by achieving place recognition and metric pose\nestimation in the global prior map. Specifically, we present a semi-handcrafted\nrepresentation learning method for LiDAR point clouds using siamese LocNets,\nwhich states the place recognition problem to a similarity modeling problem.\nWith the final learned representations by LocNet, a global localization\nframework with range-only observations is proposed. To demonstrate the\nperformance and effectiveness of our global localization system, KITTI dataset\nis employed for comparison with other algorithms, and also on our long-time\nmulti-session datasets for evaluation. The result shows that our system can\nachieve high accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 6 Dec 2017 12:51:31 GMT"}, {"version": "v2", "created": "Tue, 10 Jul 2018 03:35:56 GMT"}], "update_date": "2018-07-11", "authors_parsed": [["Yin", "Huan", ""], ["Tang", "Li", ""], ["Ding", "Xiaqing", ""], ["Wang", "Yue", ""], ["Xiong", "Rong", ""]]}, {"id": "1712.02198", "submitter": "Masaharu Sakamoto", "authors": "Masaharu Sakamoto, Hiroki Nakano, Kun Zhao and Taro Sekiyama", "title": "Lung Nodule Classification by the Combination of Fusion Classifier and\n  Cascaded Convolutional Neural Networks", "comments": "Draft of ISBI2018. arXiv admin note: text overlap with\n  arXiv:1703.00311", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lung nodule classification is a class imbalanced problem, as nodules are\nfound with much lower frequency than non-nodules. In the class imbalanced\nproblem, conventional classifiers tend to be overwhelmed by the majority class\nand ignore the minority class. We showed that cascaded convolutional neural\nnetworks can classify the nodule candidates precisely for a class imbalanced\nnodule candidate data set in our previous study. In this paper, we propose\nFusion classifier in conjunction with the cascaded convolutional neural network\nmodels. To fuse the models, nodule probabilities are calculated by using the\nconvolutional neural network models at first. Then, Fusion classifier is\ntrained and tested by the nodule probabilities. The proposed method achieved\nthe sensitivity of 94.4% and 95.9% at 4 and 8 false positives per scan in Free\nReceiver Operating Characteristics (FROC) curve analysis, respectively.\n", "versions": [{"version": "v1", "created": "Sun, 19 Nov 2017 06:22:20 GMT"}, {"version": "v2", "created": "Mon, 18 Dec 2017 01:37:37 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Sakamoto", "Masaharu", ""], ["Nakano", "Hiroki", ""], ["Zhao", "Kun", ""], ["Sekiyama", "Taro", ""]]}, {"id": "1712.02250", "submitter": "Lili Mou", "authors": "Bolin Wei, Shuai Lu, Lili Mou, Hao Zhou, Pascal Poupart, Ge Li, Zhi\n  Jin", "title": "Why Do Neural Dialog Systems Generate Short and Meaningless Replies? A\n  Comparison between Dialog and Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the question: Why do neural dialog systems generate\nshort and meaningless replies? We conjecture that, in a dialog system, an\nutterance may have multiple equally plausible replies, causing the deficiency\nof neural networks in the dialog application. We propose a systematic way to\nmimic the dialog scenario in a machine translation system, and manage to\nreproduce the phenomenon of generating short and less meaningful sentences in\nthe translation setting, showing evidence of our conjecture.\n", "versions": [{"version": "v1", "created": "Wed, 6 Dec 2017 16:00:45 GMT"}], "update_date": "2017-12-07", "authors_parsed": [["Wei", "Bolin", ""], ["Lu", "Shuai", ""], ["Mou", "Lili", ""], ["Zhou", "Hao", ""], ["Poupart", "Pascal", ""], ["Li", "Ge", ""], ["Jin", "Zhi", ""]]}, {"id": "1712.02270", "submitter": "Xiaoyong Pan", "authors": "Xiaoyong Pan and Junchi Yan", "title": "Attention based convolutional neural network for predicting RNA-protein\n  binding sites", "comments": null, "journal-ref": "NIPS 2017 Computational Biology Workshop", "doi": null, "report-no": null, "categories": "q-bio.GN cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  RNA-binding proteins (RBPs) play crucial roles in many biological processes,\ne.g. gene regulation. Computational identification of RBP binding sites on RNAs\nare urgently needed. In particular, RBPs bind to RNAs by recognizing sequence\nmotifs. Thus, fast locating those motifs on RNA sequences is crucial and\ntime-efficient for determining whether the RNAs interact with the RBPs or not.\nIn this study, we present an attention based convolutional neural network,\niDeepA, to predict RNA-protein binding sites from raw RNA sequences. We first\nencode RNA sequences into one-hot encoding. Next, we design a deep learning\nmodel with a convolutional neural network (CNN) and an attention mechanism,\nwhich automatically search for important positions, e.g. binding motifs, to\nlearn discriminant high-level features for predicting RBP binding sites. We\nevaluate iDeepA on publicly gold-standard RBP binding sites derived from\nCLIP-seq data. The results demonstrate iDeepA achieves comparable performance\nwith other state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 6 Dec 2017 16:33:29 GMT"}], "update_date": "2018-06-07", "authors_parsed": [["Pan", "Xiaoyong", ""], ["Yan", "Junchi", ""]]}, {"id": "1712.02328", "submitter": "Omid Poursaeed", "authors": "Omid Poursaeed, Isay Katsman, Bicheng Gao, Serge Belongie", "title": "Generative Adversarial Perturbations", "comments": "CVPR 2018, camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose novel generative models for creating adversarial\nexamples, slightly perturbed images resembling natural images but maliciously\ncrafted to fool pre-trained models. We present trainable deep neural networks\nfor transforming images to adversarial perturbations. Our proposed models can\nproduce image-agnostic and image-dependent perturbations for both targeted and\nnon-targeted attacks. We also demonstrate that similar architectures can\nachieve impressive results in fooling classification and semantic segmentation\nmodels, obviating the need for hand-crafting attack methods for each task.\nUsing extensive experiments on challenging high-resolution datasets such as\nImageNet and Cityscapes, we show that our perturbations achieve high fooling\nrates with small perturbation norms. Moreover, our attacks are considerably\nfaster than current iterative methods at inference time.\n", "versions": [{"version": "v1", "created": "Wed, 6 Dec 2017 18:52:12 GMT"}, {"version": "v2", "created": "Wed, 4 Apr 2018 01:18:08 GMT"}, {"version": "v3", "created": "Fri, 6 Jul 2018 06:50:03 GMT"}], "update_date": "2018-07-09", "authors_parsed": [["Poursaeed", "Omid", ""], ["Katsman", "Isay", ""], ["Gao", "Bicheng", ""], ["Belongie", "Serge", ""]]}, {"id": "1712.02330", "submitter": "Tatjana Chavdarova", "authors": "Tatjana Chavdarova, Fran\\c{c}ois Fleuret", "title": "SGAN: An Alternative Training of Generative Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Generative Adversarial Networks (GANs) have demonstrated impressive\nperformance for data synthesis, and are now used in a wide range of computer\nvision tasks. In spite of this success, they gained a reputation for being\ndifficult to train, what results in a time-consuming and human-involved\ndevelopment process to use them.\n  We consider an alternative training process, named SGAN, in which several\nadversarial \"local\" pairs of networks are trained independently so that a\n\"global\" supervising pair of networks can be trained against them. The goal is\nto train the global pair with the corresponding ensemble opponent for improved\nperformances in terms of mode coverage. This approach aims at increasing the\nchances that learning will not stop for the global pair, preventing both to be\ntrapped in an unsatisfactory local minimum, or to face oscillations often\nobserved in practice. To guarantee the latter, the global pair never affects\nthe local ones.\n  The rules of SGAN training are thus as follows: the global generator and\ndiscriminator are trained using the local discriminators and generators,\nrespectively, whereas the local networks are trained with their fixed local\nopponent.\n  Experimental results on both toy and real-world problems demonstrate that\nthis approach outperforms standard training in terms of better mitigating mode\ncollapse, stability while converging and that it surprisingly, increases the\nconvergence speed as well.\n", "versions": [{"version": "v1", "created": "Wed, 6 Dec 2017 18:52:21 GMT"}], "update_date": "2017-12-07", "authors_parsed": [["Chavdarova", "Tatjana", ""], ["Fleuret", "Fran\u00e7ois", ""]]}, {"id": "1712.02390", "submitter": "Guodong Zhang", "authors": "Guodong Zhang and Shengyang Sun and David Duvenaud and Roger Grosse", "title": "Noisy Natural Gradient as Variational Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational Bayesian neural nets combine the flexibility of deep learning\nwith Bayesian uncertainty estimation. Unfortunately, there is a tradeoff\nbetween cheap but simple variational families (e.g.~fully factorized) or\nexpensive and complicated inference procedures. We show that natural gradient\nascent with adaptive weight noise implicitly fits a variational posterior to\nmaximize the evidence lower bound (ELBO). This insight allows us to train\nfull-covariance, fully factorized, or matrix-variate Gaussian variational\nposteriors using noisy versions of natural gradient, Adam, and K-FAC,\nrespectively, making it possible to scale up to modern-size ConvNets. On\nstandard regression benchmarks, our noisy K-FAC algorithm makes better\npredictions and matches Hamiltonian Monte Carlo's predictive variances better\nthan existing methods. Its improved uncertainty estimates lead to more\nefficient exploration in active learning, and intrinsic motivation for\nreinforcement learning.\n", "versions": [{"version": "v1", "created": "Wed, 6 Dec 2017 19:43:47 GMT"}, {"version": "v2", "created": "Mon, 26 Feb 2018 06:48:49 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Zhang", "Guodong", ""], ["Sun", "Shengyang", ""], ["Duvenaud", "David", ""], ["Grosse", "Roger", ""]]}, {"id": "1712.02427", "submitter": "Andrew Tulloch", "authors": "Andrew Tulloch, Yangqing Jia", "title": "High performance ultra-low-precision convolutions on mobile devices", "comments": "Presented at NIPS 2017, Machine Learning on the Phone and other\n  Consumer Devices workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many applications of mobile deep learning, especially real-time computer\nvision workloads, are constrained by computation power. This is particularly\ntrue for workloads running on older consumer phones, where a typical device\nmight be powered by a single- or dual-core ARMv7 CPU. We provide an open-source\nimplementation and a comprehensive analysis of (to our knowledge) the state of\nthe art ultra-low-precision (<4 bit precision) implementation of the core\nprimitives required for modern deep learning workloads on ARMv7 devices, and\ndemonstrate speedups of 4x-20x over our additional state-of-the-art float32 and\nint8 baselines.\n", "versions": [{"version": "v1", "created": "Wed, 6 Dec 2017 22:27:36 GMT"}], "update_date": "2017-12-08", "authors_parsed": [["Tulloch", "Andrew", ""], ["Jia", "Yangqing", ""]]}, {"id": "1712.02446", "submitter": "Dimitrios Stamoulis", "authors": "Dimitrios Stamoulis, Ermao Cai, Da-Cheng Juan, Diana Marculescu", "title": "HyperPower: Power- and Memory-Constrained Hyper-Parameter Optimization\n  for Neural Networks", "comments": "This conference paper will appear in the proceedings of DATE 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While selecting the hyper-parameters of Neural Networks (NNs) has been so far\ntreated as an art, the emergence of more complex, deeper architectures poses\nincreasingly more challenges to designers and Machine Learning (ML)\npractitioners, especially when power and memory constraints need to be\nconsidered. In this work, we propose HyperPower, a framework that enables\nefficient Bayesian optimization and random search in the context of power- and\nmemory-constrained hyper-parameter optimization for NNs running on a given\nhardware platform. HyperPower is the first work (i) to show that power\nconsumption can be used as a low-cost, a priori known constraint, and (ii) to\npropose predictive models for the power and memory of NNs executing on GPUs.\nThanks to HyperPower, the number of function evaluations and the best test\nerror achieved by a constraint-unaware method are reached up to 112.99x and\n30.12x faster, respectively, while never considering invalid configurations.\nHyperPower significantly speeds up the hyper-parameter optimization, achieving\nup to 57.20x more function evaluations compared to constraint-unaware methods\nfor a given time interval, effectively yielding significant accuracy\nimprovements by up to 67.6%.\n", "versions": [{"version": "v1", "created": "Wed, 6 Dec 2017 23:44:22 GMT"}], "update_date": "2017-12-08", "authors_parsed": [["Stamoulis", "Dimitrios", ""], ["Cai", "Ermao", ""], ["Juan", "Da-Cheng", ""], ["Marculescu", "Diana", ""]]}, {"id": "1712.02467", "submitter": "Woon Sang Cho", "authors": "Woon Sang Cho, Mengdi Wang", "title": "Deep Primal-Dual Reinforcement Learning: Accelerating Actor-Critic using\n  Bellman Duality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a parameterized Primal-Dual $\\pi$ Learning method based on deep\nneural networks for Markov decision process with large state space and\noff-policy reinforcement learning. In contrast to the popular Q-learning and\nactor-critic methods that are based on successive approximations to the\nnonlinear Bellman equation, our method makes primal-dual updates to the policy\nand value functions utilizing the fundamental linear Bellman duality. Naive\nparametrization of the primal-dual $\\pi$ learning method using deep neural\nnetworks would encounter two major challenges: (1) each update requires\ncomputing a probability distribution over the state space and is intractable;\n(2) the iterates are unstable since the parameterized Lagrangian function is no\nlonger linear. We address these challenges by proposing a relaxed Lagrangian\nformulation with a regularization penalty using the advantage function. We show\nthat the dual policy update step in our method is equivalent to the policy\ngradient update in the actor-critic method in some special case, while the\nvalue updates differ substantially. The main advantage of the primal-dual $\\pi$\nlearning method lies in that the value and policy updates are closely coupled\ntogether using the Bellman duality and therefore more informative. Experiments\non a simple cart-pole problem show that the algorithm significantly outperforms\nthe one-step temporal-difference actor-critic method, which is the most\nrelevant benchmark method to compare with. We believe that the primal-dual\nupdates to the value and policy functions would expedite the learning process.\nThe proposed methods might open a door to more efficient algorithms and sharper\ntheoretical analysis.\n", "versions": [{"version": "v1", "created": "Thu, 7 Dec 2017 01:41:51 GMT"}], "update_date": "2017-12-08", "authors_parsed": [["Cho", "Woon Sang", ""], ["Wang", "Mengdi", ""]]}, {"id": "1712.02488", "submitter": "Yunpeng Li", "authors": "Yunpeng Li, Ivan Kiskin, Davide Zilli, Marianne Sinka, Henry Chan,\n  Kathy Willis, Stephen Roberts", "title": "Cost-sensitive detection with variational autoencoders for environmental\n  acoustic sensing", "comments": "Presented at the NIPS 2017 Workshop on Machine Learning for Audio\n  Signal Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Environmental acoustic sensing involves the retrieval and processing of audio\nsignals to better understand our surroundings. While large-scale acoustic data\nmake manual analysis infeasible, they provide a suitable playground for machine\nlearning approaches. Most existing machine learning techniques developed for\nenvironmental acoustic sensing do not provide flexible control of the trade-off\nbetween the false positive rate and the false negative rate. This paper\npresents a cost-sensitive classification paradigm, in which the\nhyper-parameters of classifiers and the structure of variational autoencoders\nare selected in a principled Neyman-Pearson framework. We examine the\nperformance of the proposed approach using a dataset from the HumBug project\nwhich aims to detect the presence of mosquitoes using sound collected by simple\nembedded devices.\n", "versions": [{"version": "v1", "created": "Thu, 7 Dec 2017 04:35:39 GMT"}], "update_date": "2017-12-08", "authors_parsed": [["Li", "Yunpeng", ""], ["Kiskin", "Ivan", ""], ["Zilli", "Davide", ""], ["Sinka", "Marianne", ""], ["Chan", "Henry", ""], ["Willis", "Kathy", ""], ["Roberts", "Stephen", ""]]}, {"id": "1712.02494", "submitter": "Jiajun Lu", "authors": "Jiajun Lu, Hussein Sibai, Evan Fabry", "title": "Adversarial Examples that Fool Detectors", "comments": "Follow up paper for adversarial stop signs. Submitted to CVPR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An adversarial example is an example that has been adjusted to produce a\nwrong label when presented to a system at test time. To date, adversarial\nexample constructions have been demonstrated for classifiers, but not for\ndetectors. If adversarial examples that could fool a detector exist, they could\nbe used to (for example) maliciously create security hazards on roads populated\nwith smart vehicles. In this paper, we demonstrate a construction that\nsuccessfully fools two standard detectors, Faster RCNN and YOLO. The existence\nof such examples is surprising, as attacking a classifier is very different\nfrom attacking a detector, and that the structure of detectors - which must\nsearch for their own bounding box, and which cannot estimate that box very\naccurately - makes it quite likely that adversarial patterns are strongly\ndisrupted. We show that our construction produces adversarial examples that\ngeneralize well across sequences digitally, even though large perturbations are\nneeded. We also show that our construction yields physical objects that are\nadversarial.\n", "versions": [{"version": "v1", "created": "Thu, 7 Dec 2017 05:13:54 GMT"}], "update_date": "2017-12-08", "authors_parsed": [["Lu", "Jiajun", ""], ["Sibai", "Hussein", ""], ["Fabry", "Evan", ""]]}, {"id": "1712.02501", "submitter": "Chen Huang", "authors": "Chen Huang, Chen Kong, and Simon Lucey", "title": "CNNs are Globally Optimal Given Multi-Layer Support", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic Gradient Descent (SGD) is the central workhorse for training\nmodern CNNs. Although giving impressive empirical performance it can be slow to\nconverge. In this paper we explore a novel strategy for training a CNN using an\nalternation strategy that offers substantial speedups during training. We make\nthe following contributions: (i) replace the ReLU non-linearity within a CNN\nwith positive hard-thresholding, (ii) reinterpret this non-linearity as a\nbinary state vector making the entire CNN linear if the multi-layer support is\nknown, and (iii) demonstrate that under certain conditions a global optima to\nthe CNN can be found through local descent. We then employ a novel alternation\nstrategy (between weights and support) for CNN training that leads to\nsubstantially faster convergence rates, nice theoretical properties, and\nachieving state of the art results across large scale datasets (e.g. ImageNet)\nas well as other standard benchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 7 Dec 2017 06:06:52 GMT"}, {"version": "v2", "created": "Thu, 14 Dec 2017 14:21:43 GMT"}], "update_date": "2017-12-15", "authors_parsed": [["Huang", "Chen", ""], ["Kong", "Chen", ""], ["Lucey", "Simon", ""]]}, {"id": "1712.02502", "submitter": "Chen Kong", "authors": "Chen Kong and Simon Lucey", "title": "Take it in your stride: Do we need striding in CNNs?", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since their inception, CNNs have utilized some type of striding operator to\nreduce the overlap of receptive fields and spatial dimensions. Although having\nclear heuristic motivations (i.e. lowering the number of parameters to learn)\nthe mathematical role of striding within CNN learning remains unclear. This\npaper offers a novel and mathematical rigorous perspective on the role of the\nstriding operator within modern CNNs. Specifically, we demonstrate\ntheoretically that one can always represent a CNN that incorporates striding\nwith an equivalent non-striding CNN which has more filters and smaller size.\nThrough this equivalence we are then able to characterize striding as an\nadditional mechanism for parameter sharing among channels, thus reducing\ntraining complexity. Finally, the framework presented in this paper offers a\nnew mathematical perspective on the role of striding which we hope shall\nfacilitate and simplify the future theoretical analysis of CNNs.\n", "versions": [{"version": "v1", "created": "Thu, 7 Dec 2017 06:07:22 GMT"}], "update_date": "2017-12-08", "authors_parsed": [["Kong", "Chen", ""], ["Lucey", "Simon", ""]]}, {"id": "1712.02505", "submitter": "Tom Sercu", "authors": "Tom Sercu, Youssef Mroueh", "title": "Semi-Supervised Learning with IPM-based GANs: an Empirical Study", "comments": "Appeared at NIPS 2017 Workshop: Deep Learning: Bridging Theory and\n  Practice", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an empirical investigation of a recent class of Generative\nAdversarial Networks (GANs) using Integral Probability Metrics (IPM) and their\nperformance for semi-supervised learning. IPM-based GANs like Wasserstein GAN,\nFisher GAN and Sobolev GAN have desirable properties in terms of theoretical\nunderstanding, training stability, and a meaningful loss. In this work we\ninvestigate how the design of the critic (or discriminator) influences the\nperformance in semi-supervised learning. We distill three key take-aways which\nare important for good SSL performance: (1) the K+1 formulation, (2) avoiding\nbatch normalization in the critic and (3) avoiding gradient penalty constraints\non the classification layer.\n", "versions": [{"version": "v1", "created": "Thu, 7 Dec 2017 06:27:28 GMT"}], "update_date": "2017-12-08", "authors_parsed": [["Sercu", "Tom", ""], ["Mroueh", "Youssef", ""]]}, {"id": "1712.02512", "submitter": "Lucas Roberts", "authors": "Lucas Roberts, Leo Razoumov, Lin Su, Yuyang Wang", "title": "Gini-regularized Optimal Transport with an Application to\n  Spatio-Temporal Forecasting", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rapidly growing product lines and services require a finer-granularity\nforecast that considers geographic locales. However the open question remains,\nhow to assess the quality of a spatio-temporal forecast? In this manuscript we\nintroduce a metric to evaluate spatio-temporal forecasts. This metric is based\non an Opti- mal Transport (OT) problem. The metric we propose is a constrained\nOT objec- tive function using the Gini impurity function as a regularizer. We\ndemonstrate through computer experiments both the qualitative and the\nquantitative charac- teristics of the Gini regularized OT problem. Moreover, we\nshow that the Gini regularized OT problem converges to the classical OT\nproblem, when the Gini regularized problem is considered as a function of\n{\\lambda}, the regularization parame-ter. The convergence to the classical OT\nsolution is faster than the state-of-the-art Entropic-regularized OT[Cuturi,\n2013] and results in a numerically more stable algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 7 Dec 2017 06:58:45 GMT"}], "update_date": "2017-12-08", "authors_parsed": [["Roberts", "Lucas", ""], ["Razoumov", "Leo", ""], ["Su", "Lin", ""], ["Wang", "Yuyang", ""]]}, {"id": "1712.02527", "submitter": "Jianqiao Wangni", "authors": "Jianqiao Wangni, Jingwei Zhuo, Jun Zhu", "title": "Learning Random Fourier Features by Hybrid Constrained Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The kernel embedding algorithm is an important component for adapting kernel\nmethods to large datasets. Since the algorithm consumes a major computation\ncost in the testing phase, we propose a novel teacher-learner framework of\nlearning computation-efficient kernel embeddings from specific data. In the\nframework, the high-precision embeddings (teacher) transfer the data\ninformation to the computation-efficient kernel embeddings (learner). We\njointly select informative embedding functions and pursue an orthogonal\ntransformation between two embeddings. We propose a novel approach of\nconstrained variational expectation maximization (CVEM), where the alternate\ndirection method of multiplier (ADMM) is applied over a nonconvex domain in the\nmaximization step. We also propose two specific formulations based on the\nprevalent Random Fourier Feature (RFF), the masked and blocked version of\nComputation-Efficient RFF (CERF), by imposing a random binary mask or a block\nstructure on the transformation matrix. By empirical studies of several\napplications on different real-world datasets, we demonstrate that the CERF\nsignificantly improves the performance of kernel methods upon the RFF, under\ncertain arithmetic operation requirements, and suitable for structured matrix\nmultiplication in Fastfood type algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 7 Dec 2017 08:07:26 GMT"}], "update_date": "2017-12-08", "authors_parsed": [["Wangni", "Jianqiao", ""], ["Zhuo", "Jingwei", ""], ["Zhu", "Jun", ""]]}, {"id": "1712.02609", "submitter": "Carles Riera Molina", "authors": "Carles Roger Riera Molina and Oriol Pujol Vila", "title": "Solving internal covariate shift in deep learning with linked neurons", "comments": "Submitted to CVPR 2018. Code available at\n  https://github.com/blauigris/linked_neurons", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work proposes a novel solution to the problem of internal covariate\nshift and dying neurons using the concept of linked neurons. We define the\nneuron linkage in terms of two constraints: first, all neuron activations in\nthe linkage must have the same operating point. That is to say, all of them\nshare input weights. Secondly, a set of neurons is linked if and only if there\nis at least one member of the linkage that has a non-zero gradient in regard to\nthe input of the activation function. This means that for any input in the\nactivation function, there is at least one member of the linkage that operates\nin a non-flat and non-zero area. This simple change has profound implications\nin the network learning dynamics. In this article we explore the consequences\nof this proposal and show that by using this kind of units, internal covariate\nshift is implicitly solved. As a result of this, the use of linked neurons\nallows to train arbitrarily large networks without any architectural or\nalgorithmic trick, effectively removing the need of using re-normalization\nschemes such as Batch Normalization, which leads to halving the required\ntraining time. It also solves the problem of the need for standarized input\ndata. Results show that the units using the linkage not only do effectively\nsolve the aforementioned problems, but are also a competitive alternative with\nrespect to state-of-the-art with very promising results.\n", "versions": [{"version": "v1", "created": "Thu, 7 Dec 2017 13:26:26 GMT"}], "update_date": "2017-12-08", "authors_parsed": [["Molina", "Carles Roger Riera", ""], ["Vila", "Oriol Pujol", ""]]}, {"id": "1712.02629", "submitter": "Beyza Ermis Ms", "authors": "Beyza Ermis, Ali Taylan Cemgil", "title": "Differentially Private Variational Dropout", "comments": "arXiv admin note: substantial text overlap with arXiv:1712.01665", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks with their large number of parameters are highly\nflexible learning systems. The high flexibility in such networks brings with\nsome serious problems such as overfitting, and regularization is used to\naddress this problem. A currently popular and effective regularization\ntechnique for controlling the overfitting is dropout. Often, large data\ncollections required for neural networks contain sensitive information such as\nthe medical histories of patients, and the privacy of the training data should\nbe protected. In this paper, we modify the recently proposed variational\ndropout technique which provided an elegant Bayesian interpretation to dropout,\nand show that the intrinsic noise in the variational dropout can be exploited\nto obtain a degree of differential privacy. The iterative nature of training\nneural networks presents a challenge for privacy-preserving estimation since\nmultiple iterations increase the amount of noise added. We overcome this by\nusing a relaxed notion of differential privacy, called concentrated\ndifferential privacy, which provides tighter estimates on the overall privacy\nloss. We demonstrate the accuracy of our privacy-preserving variational dropout\nalgorithm on benchmark datasets.\n", "versions": [{"version": "v1", "created": "Thu, 30 Nov 2017 21:32:27 GMT"}, {"version": "v2", "created": "Tue, 12 Dec 2017 20:05:27 GMT"}, {"version": "v3", "created": "Sat, 16 Dec 2017 10:41:02 GMT"}], "update_date": "2017-12-20", "authors_parsed": [["Ermis", "Beyza", ""], ["Cemgil", "Ali Taylan", ""]]}, {"id": "1712.02675", "submitter": "Andreas Svensson", "authors": "Andreas Svensson, Dave Zachariah, Thomas B. Sch\\\"on", "title": "How consistent is my model with the data? Information-Theoretic Model\n  Check", "comments": "The title has been updated, but no other significant changes have\n  been made from the previous version", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.SP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The choice of model class is fundamental in statistical learning and system\nidentification, no matter whether the class is derived from physical principles\nor is a generic black-box. We develop a method to evaluate the specified model\nclass by assessing its capability of reproducing data that is similar to the\nobserved data record. This model check is based on the information-theoretic\nproperties of models viewed as data generators and is applicable to e.g.\nsequential data and nonlinear dynamical models. The method can be understood as\na specific two-sided posterior predictive test. We apply the\ninformation-theoretic model check to both synthetic and real data and compare\nit with a classical whiteness test.\n", "versions": [{"version": "v1", "created": "Thu, 7 Dec 2017 15:40:17 GMT"}, {"version": "v2", "created": "Tue, 19 Dec 2017 08:55:47 GMT"}], "update_date": "2017-12-20", "authors_parsed": [["Svensson", "Andreas", ""], ["Zachariah", "Dave", ""], ["Sch\u00f6n", "Thomas B.", ""]]}, {"id": "1712.02679", "submitter": "Chia-Yu Chen", "authors": "Chia-Yu Chen, Jungwook Choi, Daniel Brand, Ankur Agrawal, Wei Zhang,\n  Kailash Gopalakrishnan", "title": "AdaComp : Adaptive Residual Gradient Compression for Data-Parallel\n  Distributed Training", "comments": "IBM Research AI, 9 pages, 7 figures, AAAI18 accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Highly distributed training of Deep Neural Networks (DNNs) on future compute\nplatforms (offering 100 of TeraOps/s of computational capacity) is expected to\nbe severely communication constrained. To overcome this limitation, new\ngradient compression techniques are needed that are computationally friendly,\napplicable to a wide variety of layers seen in Deep Neural Networks and\nadaptable to variations in network architectures as well as their\nhyper-parameters. In this paper we introduce a novel technique - the Adaptive\nResidual Gradient Compression (AdaComp) scheme. AdaComp is based on localized\nselection of gradient residues and automatically tunes the compression rate\ndepending on local activity. We show excellent results on a wide spectrum of\nstate of the art Deep Learning models in multiple domains (vision, speech,\nlanguage), datasets (MNIST, CIFAR10, ImageNet, BN50, Shakespeare), optimizers\n(SGD with momentum, Adam) and network parameters (number of learners,\nminibatch-size etc.). Exploiting both sparsity and quantization, we demonstrate\nend-to-end compression rates of ~200X for fully-connected and recurrent layers,\nand ~40X for convolutional layers, without any noticeable degradation in model\naccuracies.\n", "versions": [{"version": "v1", "created": "Thu, 7 Dec 2017 15:44:19 GMT"}], "update_date": "2017-12-08", "authors_parsed": [["Chen", "Chia-Yu", ""], ["Choi", "Jungwook", ""], ["Brand", "Daniel", ""], ["Agrawal", "Ankur", ""], ["Zhang", "Wei", ""], ["Gopalakrishnan", "Kailash", ""]]}, {"id": "1712.02734", "submitter": "Garrett Goh", "authors": "Garrett B. Goh, Charles Siegel, Abhinav Vishnu, Nathan O. Hodas", "title": "Using Rule-Based Labels for Weak Supervised Learning: A ChemNet for\n  Transferable Chemical Property Prediction", "comments": "Submitted to SIGKDD 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With access to large datasets, deep neural networks (DNN) have achieved\nhuman-level accuracy in image and speech recognition tasks. However, in\nchemistry, data is inherently small and fragmented. In this work, we develop an\napproach of using rule-based knowledge for training ChemNet, a transferable and\ngeneralizable deep neural network for chemical property prediction that learns\nin a weak-supervised manner from large unlabeled chemical databases. When\ncoupled with transfer learning approaches to predict other smaller datasets for\nchemical properties that it was not originally trained on, we show that\nChemNet's accuracy outperforms contemporary DNN models that were trained using\nconventional supervised learning. Furthermore, we demonstrate that the ChemNet\npre-training approach is equally effective on both CNN (Chemception) and RNN\n(SMILES2vec) models, indicating that this approach is network architecture\nagnostic and is effective across multiple data modalities. Our results indicate\na pre-trained ChemNet that incorporates chemistry domain knowledge, enables the\ndevelopment of generalizable neural networks for more accurate prediction of\nnovel chemical properties.\n", "versions": [{"version": "v1", "created": "Thu, 7 Dec 2017 17:25:48 GMT"}, {"version": "v2", "created": "Sun, 18 Mar 2018 13:50:02 GMT"}], "update_date": "2018-08-16", "authors_parsed": [["Goh", "Garrett B.", ""], ["Siegel", "Charles", ""], ["Vishnu", "Abhinav", ""], ["Hodas", "Nathan O.", ""]]}, {"id": "1712.02743", "submitter": "Thomas Hehn", "authors": "Thomas Hehn and Fred A. Hamprecht", "title": "End-to-end Learning of Deterministic Decision Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional decision trees have a number of favorable properties, including\ninterpretability, a small computational footprint and the ability to learn from\nlittle training data. However, they lack a key quality that has helped fuel the\ndeep learning revolution: that of being end-to-end trainable, and to learn from\nscratch those features that best allow to solve a given supervised learning\nproblem. Recent work (Kontschieder 2015) has addressed this deficit, but at the\ncost of losing a main attractive trait of decision trees: the fact that each\nsample is routed along a small subset of tree nodes only. We here propose a\nmodel and Expectation-Maximization training scheme for decision trees that are\nfully probabilistic at train time, but after a deterministic annealing process\nbecome deterministic at test time. We also analyze the learned oblique split\nparameters on image datasets and show that Neural Networks can be trained at\neach split node. In summary, we present the first end-to-end learning scheme\nfor deterministic decision trees and present results on par with or superior to\npublished standard oblique decision tree algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 7 Dec 2017 17:40:25 GMT"}], "update_date": "2017-12-08", "authors_parsed": [["Hehn", "Thomas", ""], ["Hamprecht", "Fred A.", ""]]}, {"id": "1712.02767", "submitter": "Sachin Pawar", "authors": "Sachin Pawar, Nitin Ramrakhiyani, Swapnil Hingmire and Girish K.\n  Palshikar", "title": "Topics and Label Propagation: Best of Both Worlds for Weakly Supervised\n  Text Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a Label Propagation based algorithm for weakly supervised text\nclassification. We construct a graph where each document is represented by a\nnode and edge weights represent similarities among the documents. Additionally,\nwe discover underlying topics using Latent Dirichlet Allocation (LDA) and\nenrich the document graph by including the topics in the form of additional\nnodes. The edge weights between a topic and a text document represent level of\n\"affinity\" between them. Our approach does not require document level\nlabelling, instead it expects manual labels only for topic nodes. This\nsignificantly minimizes the level of supervision needed as only a few topics\nare observed to be enough for achieving sufficiently high accuracy. The Label\nPropagation Algorithm is employed on this enriched graph to propagate labels\namong the nodes. Our approach combines the advantages of Label Propagation\n(through document-document similarities) and Topic Modelling (for minimal but\nsmart supervision). We demonstrate the effectiveness of our approach on various\ndatasets and compare with state-of-the-art weakly supervised text\nclassification approaches.\n", "versions": [{"version": "v1", "created": "Mon, 4 Dec 2017 06:05:21 GMT"}], "update_date": "2017-12-08", "authors_parsed": [["Pawar", "Sachin", ""], ["Ramrakhiyani", "Nitin", ""], ["Hingmire", "Swapnil", ""], ["Palshikar", "Girish K.", ""]]}, {"id": "1712.02779", "submitter": "Dimitris Tsipras", "authors": "Logan Engstrom, Brandon Tran, Dimitris Tsipras, Ludwig Schmidt,\n  Aleksander Madry", "title": "Exploring the Landscape of Spatial Robustness", "comments": "ICML 2019. Presented in NIPS 2017 Workshop on Machine Learning and\n  Computer Security as \"A Rotation and a Translation Suffice: Fooling CNNs with\n  Simple Transformations.\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study of adversarial robustness has so far largely focused on\nperturbations bound in p-norms. However, state-of-the-art models turn out to be\nalso vulnerable to other, more natural classes of perturbations such as\ntranslations and rotations. In this work, we thoroughly investigate the\nvulnerability of neural network--based classifiers to rotations and\ntranslations. While data augmentation offers relatively small robustness, we\nuse ideas from robust optimization and test-time input aggregation to\nsignificantly improve robustness. Finally we find that, in contrast to the\np-norm case, first-order methods cannot reliably find worst-case perturbations.\nThis highlights spatial robustness as a fundamentally different setting\nrequiring additional study. Code available at\nhttps://github.com/MadryLab/adversarial_spatial and\nhttps://github.com/MadryLab/spatial-pytorch.\n", "versions": [{"version": "v1", "created": "Thu, 7 Dec 2017 18:53:52 GMT"}, {"version": "v2", "created": "Mon, 11 Dec 2017 12:00:50 GMT"}, {"version": "v3", "created": "Tue, 13 Feb 2018 18:33:22 GMT"}, {"version": "v4", "created": "Mon, 16 Sep 2019 04:38:13 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Engstrom", "Logan", ""], ["Tran", "Brandon", ""], ["Tsipras", "Dimitris", ""], ["Schmidt", "Ludwig", ""], ["Madry", "Aleksander", ""]]}, {"id": "1712.02831", "submitter": "Seyed Mehran Kazemi", "authors": "Seyed Mehran Kazemi and David Poole", "title": "RelNN: A Deep Neural Model for Relational Learning", "comments": "9 pages, 8 figures, accepted at AAAI-2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Statistical relational AI (StarAI) aims at reasoning and learning in noisy\ndomains described in terms of objects and relationships by combining\nprobability with first-order logic. With huge advances in deep learning in the\ncurrent years, combining deep networks with first-order logic has been the\nfocus of several recent studies. Many of the existing attempts, however, only\nfocus on relations and ignore object properties. The attempts that do consider\nobject properties are limited in terms of modelling power or scalability. In\nthis paper, we develop relational neural networks (RelNNs) by adding hidden\nlayers to relational logistic regression (the relational counterpart of\nlogistic regression). We learn latent properties for objects both directly and\nthrough general rules. Back-propagation is used for training these models. A\nmodular, layer-wise architecture facilitates utilizing the techniques developed\nwithin deep learning community to our architecture. Initial experiments on\neight tasks over three real-world datasets show that RelNNs are promising\nmodels for relational learning.\n", "versions": [{"version": "v1", "created": "Thu, 7 Dec 2017 19:40:01 GMT"}], "update_date": "2017-12-11", "authors_parsed": [["Kazemi", "Seyed Mehran", ""], ["Poole", "David", ""]]}, {"id": "1712.02838", "submitter": "Li Zhou", "authors": "Li Zhou, Kevin Small, Oleg Rokhlenko, Charles Elkan", "title": "End-to-End Offline Goal-Oriented Dialog Policy Learning via Policy\n  Gradient", "comments": "Workshop on Conversational AI, NIPS 2017, Long Beach, CA, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning a goal-oriented dialog policy is generally performed offline with\nsupervised learning algorithms or online with reinforcement learning (RL).\nAdditionally, as companies accumulate massive quantities of dialog transcripts\nbetween customers and trained human agents, encoder-decoder methods have gained\npopularity as agent utterances can be directly treated as supervision without\nthe need for utterance-level annotations. However, one potential drawback of\nsuch approaches is that they myopically generate the next agent utterance\nwithout regard for dialog-level considerations. To resolve this concern, this\npaper describes an offline RL method for learning from unannotated corpora that\ncan optimize a goal-oriented policy at both the utterance and dialog level. We\nintroduce a novel reward function and use both on-policy and off-policy policy\ngradient to learn a policy offline without requiring online user interaction or\nan explicit state space definition.\n", "versions": [{"version": "v1", "created": "Thu, 7 Dec 2017 19:52:50 GMT"}], "update_date": "2017-12-11", "authors_parsed": [["Zhou", "Li", ""], ["Small", "Kevin", ""], ["Rokhlenko", "Oleg", ""], ["Elkan", "Charles", ""]]}, {"id": "1712.02861", "submitter": "Aditya Ganeshan Master", "authors": "Aditya Ganeshan", "title": "Per-Pixel Feedback for improving Semantic Segmentation", "comments": "33 pages,18 figures,3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic segmentation is the task of assigning a label to each pixel in the\nimage.In recent years, deep convolutional neural networks have been driving\nadvances in multiple tasks related to cognition. Although, DCNNs have resulted\nin unprecedented visual recognition performances, they offer little\ntransparency. To understand how DCNN based models work at the task of semantic\nsegmentation, we try to analyze the DCNN models in semantic segmentation. We\ntry to find the importance of global image information for labeling pixels.\n  Based on the experiments on discriminative regions, and modeling of\nfixations, we propose a set of new training loss functions for fine-tuning DCNN\nbased models. The proposed training regime has shown improvement in performance\nof DeepLab Large FOV(VGG-16) Segmentation model for PASCAL VOC 2012 dataset.\nHowever, further test remains to conclusively evaluate the benefits due to the\nproposed loss functions across models, and data-sets.\n  Submitted in part fulfillment of the requirements for the degree of\nIntegrated Masters of Science in Applied Mathematics.\n  Update: Further Experiment showed minimal benefits.\n  Code Available [here](https://github.com/BardOfCodes/Seg-Unravel).\n", "versions": [{"version": "v1", "created": "Thu, 7 Dec 2017 21:12:53 GMT"}], "update_date": "2017-12-12", "authors_parsed": [["Ganeshan", "Aditya", ""]]}, {"id": "1712.02882", "submitter": "Brad Carlile", "authors": "Brad Carlile, Akiko Marti, Guy Delamarter", "title": "Columnar Database Techniques for Creating AI Features", "comments": "7 pages, 2 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances with in-memory columnar database techniques have increased\nthe performance of analytical queries on very large databases and data\nwarehouses. At the same time, advances in artificial intelligence (AI)\nalgorithms have increased the ability to analyze data. We use the term AI to\nencompass both Deep Learning (DL or neural network) and Machine Learning (ML\naka Big Data analytics). Our exploration of the AI full stack has led us to a\ncross-stack columnar database innovation that efficiently creates features for\nAI analytics. The innovation is to create Augmented Dictionary Values (ADVs) to\nadd to existing columnar database dictionaries in order to increase the\nefficiency of featurization by minimizing data movement and data duplication.\nWe show how various forms of featurization (feature selection, feature\nextraction, and feature creation) can be efficiently calculated in a columnar\ndatabase. The full stack AI investigation has also led us to propose an\nintegrated columnar database and AI architecture. This architecture has\ninformation flows and feedback loops to improve the whole analytics cycle\nduring multiple iterations of extracting data from the data sources,\nfeaturization, and analysis.\n", "versions": [{"version": "v1", "created": "Thu, 7 Dec 2017 22:53:41 GMT"}], "update_date": "2017-12-11", "authors_parsed": [["Carlile", "Brad", ""], ["Marti", "Akiko", ""], ["Delamarter", "Guy", ""]]}, {"id": "1712.02903", "submitter": "Panagiotis Traganitis", "authors": "Panagiotis A. Traganitis, Alba Pag\\`es-Zamora, Georgios B. Giannakis", "title": "Blind Multiclass Ensemble Classification", "comments": "To appear in IEEE Transactions in Signal Processing", "journal-ref": null, "doi": "10.1109/TSP.2018.2860562", "report-no": null, "categories": "stat.ML cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rising interest in pattern recognition and data analytics has spurred the\ndevelopment of innovative machine learning algorithms and tools. However, as\neach algorithm has its strengths and limitations, one is motivated to\njudiciously fuse multiple algorithms in order to find the \"best\" performing\none, for a given dataset. Ensemble learning aims at such high-performance\nmeta-algorithm, by combining the outputs from multiple algorithms. The present\nwork introduces a blind scheme for learning from ensembles of classifiers,\nusing a moment matching method that leverages joint tensor and matrix\nfactorization. Blind refers to the combiner who has no knowledge of the\nground-truth labels that each classifier has been trained on. A rigorous\nperformance analysis is derived and the proposed scheme is evaluated on\nsynthetic and real datasets.\n", "versions": [{"version": "v1", "created": "Fri, 8 Dec 2017 01:01:37 GMT"}, {"version": "v2", "created": "Fri, 20 Jul 2018 21:20:08 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Traganitis", "Panagiotis A.", ""], ["Pag\u00e8s-Zamora", "Alba", ""], ["Giannakis", "Georgios B.", ""]]}, {"id": "1712.02950", "submitter": "Casey Chu", "authors": "Casey Chu, Andrey Zhmoginov, Mark Sandler", "title": "CycleGAN, a Master of Steganography", "comments": "NIPS 2017, workshop on Machine Deception", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  CycleGAN (Zhu et al. 2017) is one recent successful approach to learn a\ntransformation between two image distributions. In a series of experiments, we\ndemonstrate an intriguing property of the model: CycleGAN learns to \"hide\"\ninformation about a source image into the images it generates in a nearly\nimperceptible, high-frequency signal. This trick ensures that the generator can\nrecover the original sample and thus satisfy the cyclic consistency\nrequirement, while the generated image remains realistic. We connect this\nphenomenon with adversarial attacks by viewing CycleGAN's training procedure as\ntraining a generator of adversarial examples and demonstrate that the cyclic\nconsistency loss causes CycleGAN to be especially vulnerable to adversarial\nattacks.\n", "versions": [{"version": "v1", "created": "Fri, 8 Dec 2017 06:07:52 GMT"}, {"version": "v2", "created": "Sat, 16 Dec 2017 07:42:46 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Chu", "Casey", ""], ["Zhmoginov", "Andrey", ""], ["Sandler", "Mark", ""]]}, {"id": "1712.02979", "submitter": "Canyi Lu", "authors": "Canyi Lu, Jiashi Feng, Zhouchen Lin, Shuicheng Yan", "title": "Nonconvex Sparse Spectral Clustering by Alternating Direction Method of\n  Multipliers and Its Convergence Analysis", "comments": "Proceedings of the AAAI Conference on Artificial Intelligence (AAAI).\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral Clustering (SC) is a widely used data clustering method which first\nlearns a low-dimensional embedding $U$ of data by computing the eigenvectors of\nthe normalized Laplacian matrix, and then performs k-means on $U^\\top$ to get\nthe final clustering result. The Sparse Spectral Clustering (SSC) method\nextends SC with a sparse regularization on $UU^\\top$ by using the block\ndiagonal structure prior of $UU^\\top$ in the ideal case. However, encouraging\n$UU^\\top$ to be sparse leads to a heavily nonconvex problem which is\nchallenging to solve and the work (Lu, Yan, and Lin 2016) proposes a convex\nrelaxation in the pursuit of this aim indirectly. However, the convex\nrelaxation generally leads to a loose approximation and the quality of the\nsolution is not clear. This work instead considers to solve the nonconvex\nformulation of SSC which directly encourages $UU^\\top$ to be sparse. We propose\nan efficient Alternating Direction Method of Multipliers (ADMM) to solve the\nnonconvex SSC and provide the convergence guarantee. In particular, we prove\nthat the sequences generated by ADMM always exist a limit point and any limit\npoint is a stationary point. Our analysis does not impose any assumptions on\nthe iterates and thus is practical. Our proposed ADMM for nonconvex problems\nallows the stepsize to be increasing but upper bounded, and this makes it very\nefficient in practice. Experimental analysis on several real data sets verifies\nthe effectiveness of our method.\n", "versions": [{"version": "v1", "created": "Fri, 8 Dec 2017 08:34:18 GMT"}], "update_date": "2017-12-11", "authors_parsed": [["Lu", "Canyi", ""], ["Feng", "Jiashi", ""], ["Lin", "Zhouchen", ""], ["Yan", "Shuicheng", ""]]}, {"id": "1712.03010", "submitter": "Farnood Salehi", "authors": "Farnood Salehi, Patrick Thiran, L. Elisa Celis", "title": "Coordinate Descent with Bandit Sampling", "comments": "appearing at NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coordinate descent methods usually minimize a cost function by updating a\nrandom decision variable (corresponding to one coordinate) at a time. Ideally,\nwe would update the decision variable that yields the largest decrease in the\ncost function. However, finding this coordinate would require checking all of\nthem, which would effectively negate the improvement in computational\ntractability that coordinate descent is intended to afford. To address this, we\npropose a new adaptive method for selecting a coordinate. First, we find a\nlower bound on the amount the cost function decreases when a coordinate is\nupdated. We then use a multi-armed bandit algorithm to learn which coordinates\nresult in the largest lower bound by interleaving this learning with\nconventional coordinate descent updates except that the coordinate is selected\nproportionately to the expected decrease. We show that our approach improves\nthe convergence of coordinate descent methods both theoretically and\nexperimentally.\n", "versions": [{"version": "v1", "created": "Fri, 8 Dec 2017 10:23:30 GMT"}, {"version": "v2", "created": "Tue, 4 Dec 2018 15:25:14 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["Salehi", "Farnood", ""], ["Thiran", "Patrick", ""], ["Celis", "L. Elisa", ""]]}, {"id": "1712.03049", "submitter": "Gadi Pinkas", "authors": "Gadi Pinkas and Shimon Cohen", "title": "Artificial Neural Networks that Learn to Satisfy Logic Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Logic-based problems such as planning, theorem proving, or puzzles, typically\ninvolve combinatoric search and structured knowledge representation. Artificial\nneural networks are very successful statistical learners, however, for many\nyears, they have been criticized for their weaknesses in representing and in\nprocessing complex structured knowledge which is crucial for combinatoric\nsearch and symbol manipulation. Two neural architectures are presented, which\ncan encode structured relational knowledge in neural activation, and store\nbounded First Order Logic constraints in connection weights. Both architectures\nlearn to search for a solution that satisfies the constraints. Learning is done\nby unsupervised practicing on problem instances from the same domain, in a way\nthat improves the network-solving speed. No teacher exists to provide answers\nfor the problem instances of the training and test sets. However, the domain\nconstraints are provided as prior knowledge to a loss function that measures\nthe degree of constraint violations. Iterations of activation calculation and\nlearning are executed until a solution that maximally satisfies the constraints\nemerges on the output units. As a test case, block-world planning problems are\nused to train networks that learn to plan in that domain, but the techniques\nproposed could be used more generally as in integrating prior symbolic\nknowledge with statistical learning\n", "versions": [{"version": "v1", "created": "Fri, 8 Dec 2017 13:12:04 GMT"}], "update_date": "2017-12-11", "authors_parsed": [["Pinkas", "Gadi", ""], ["Cohen", "Shimon", ""]]}, {"id": "1712.03073", "submitter": "Mengwei Xu", "authors": "Mengwei Xu, Feng Qian, Mengze Zhu, Feifan Huang, Saumay Pushp, Xuanzhe\n  Liu", "title": "DeepWear: Adaptive Local Offloading for On-Wearable Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to their on-body and ubiquitous nature, wearables can generate a wide\nrange of unique sensor data creating countless opportunities for deep learning\ntasks. We propose DeepWear, a deep learning (DL) framework for wearable devices\nto improve the performance and reduce the energy footprint. DeepWear\nstrategically offloads DL tasks from a wearable device to its paired handheld\ndevice through local network. Compared to the remote-cloud-based offloading,\nDeepWear requires no Internet connectivity, consumes less energy, and is robust\nto privacy breach. DeepWear provides various novel techniques such as\ncontext-aware offloading, strategic model partition, and pipelining support to\nefficiently utilize the processing capacity from nearby paired handhelds.\nDeployed as a user-space library, DeepWear offers developer-friendly APIs that\nare as simple as those in traditional DL libraries such as TensorFlow. We have\nimplemented DeepWear on the Android OS and evaluated it on COTS smartphones and\nsmartwatches with real DL models. DeepWear brings up to 5.08X and 23.0X\nexecution speedup, as well as 53.5% and 85.5% energy saving compared to\nwearable-only and handheld-only strategies, respectively.\n", "versions": [{"version": "v1", "created": "Fri, 1 Dec 2017 16:58:32 GMT"}, {"version": "v2", "created": "Mon, 30 Mar 2020 04:10:20 GMT"}, {"version": "v3", "created": "Wed, 13 Jan 2021 00:55:32 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Xu", "Mengwei", ""], ["Qian", "Feng", ""], ["Zhu", "Mengze", ""], ["Huang", "Feifan", ""], ["Pushp", "Saumay", ""], ["Liu", "Xuanzhe", ""]]}, {"id": "1712.03132", "submitter": "Enoch Yeung Ph.D.", "authors": "Charles A. Johnson, Enoch Yeung", "title": "A Class of Logistic Functions for Approximating State-Inclusive Koopman\n  Operators", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An outstanding challenge in nonlinear systems theory is identification or\nlearning of a given nonlinear system's Koopman operator directly from data or\nmodels. Advances in extended dynamic mode decomposition approaches and machine\nlearning methods have enabled data-driven discovery of Koopman operators, for\nboth continuous and discrete-time systems. Since Koopman operators are often\ninfinite-dimensional, they are approximated in practice using\nfinite-dimensional systems. The fidelity and convergence of a given\nfinite-dimensional Koopman approximation is a subject of ongoing research. In\nthis paper we introduce a class of Koopman observable functions that confer an\napproximate closure property on their corresponding finite-dimensional\napproximations of the Koopman operator. We derive error bounds for the fidelity\nof this class of observable functions, as well as identify two key learning\nparameters which can be used to tune performance. We illustrate our approach on\ntwo classical nonlinear system models: the Van Der Pol oscillator and the\nbistable toggle switch.\n", "versions": [{"version": "v1", "created": "Fri, 8 Dec 2017 15:41:42 GMT"}], "update_date": "2017-12-11", "authors_parsed": [["Johnson", "Charles A.", ""], ["Yeung", "Enoch", ""]]}, {"id": "1712.03134", "submitter": "Xue Lu", "authors": "Xue Lu, Niall Adams, Nikolas Kantas", "title": "On Adaptive Estimation for Dynamic Bernoulli Bandits", "comments": "Added another AFF version of the standard UCB algorithm; modified the\n  AFF-TS algorithm; in the numerical studies, added comparisons to SW-UCB and\n  D-UCB", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The multi-armed bandit (MAB) problem is a classic example of the\nexploration-exploitation dilemma. It is concerned with maximising the total\nrewards for a gambler by sequentially pulling an arm from a multi-armed slot\nmachine where each arm is associated with a reward distribution. In static\nMABs, the reward distributions do not change over time, while in dynamic MABs,\neach arm's reward distribution can change, and the optimal arm can switch over\ntime. Motivated by many real applications where rewards are binary, we focus on\ndynamic Bernoulli bandits. Standard methods like $\\epsilon$-Greedy and Upper\nConfidence Bound (UCB), which rely on the sample mean estimator, often fail to\ntrack changes in the underlying reward for dynamic problems. In this paper, we\novercome the shortcoming of slow response to change by deploying adaptive\nestimation in the standard methods and propose a new family of algorithms,\nwhich are adaptive versions of $\\epsilon$-Greedy, UCB, and Thompson sampling.\nThese new methods are simple and easy to implement. Moreover, they do not\nrequire any prior knowledge about the dynamic reward process, which is\nimportant for real applications. We examine the new algorithms numerically in\ndifferent scenarios and the results show solid improvements of our algorithms\nin dynamic environments.\n", "versions": [{"version": "v1", "created": "Fri, 8 Dec 2017 15:45:28 GMT"}, {"version": "v2", "created": "Tue, 15 May 2018 01:34:57 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Lu", "Xue", ""], ["Adams", "Niall", ""], ["Kantas", "Nikolas", ""]]}, {"id": "1712.03141", "submitter": "Battista Biggio", "authors": "Battista Biggio and Fabio Roli", "title": "Wild Patterns: Ten Years After the Rise of Adversarial Machine Learning", "comments": "Accepted for publication on Pattern Recognition, 2018", "journal-ref": null, "doi": "10.1016/j.patcog.2018.07.023", "report-no": null, "categories": "cs.CV cs.CR cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning-based pattern classifiers, including deep networks, have shown\nimpressive performance in several application domains, ranging from computer\nvision to cybersecurity. However, it has also been shown that adversarial input\nperturbations carefully crafted either at training or at test time can easily\nsubvert their predictions. The vulnerability of machine learning to such wild\npatterns (also referred to as adversarial examples), along with the design of\nsuitable countermeasures, have been investigated in the research field of\nadversarial machine learning. In this work, we provide a thorough overview of\nthe evolution of this research area over the last ten years and beyond,\nstarting from pioneering, earlier work on the security of non-deep learning\nalgorithms up to more recent work aimed to understand the security properties\nof deep learning algorithms, in the context of computer vision and\ncybersecurity tasks. We report interesting connections between these\napparently-different lines of work, highlighting common misconceptions related\nto the security evaluation of machine-learning algorithms. We review the main\nthreat models and attacks defined to this end, and discuss the main limitations\nof current work, along with the corresponding future challenges towards the\ndesign of more secure learning algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 8 Dec 2017 15:59:41 GMT"}, {"version": "v2", "created": "Thu, 19 Jul 2018 08:27:23 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Biggio", "Battista", ""], ["Roli", "Fabio", ""]]}, {"id": "1712.03228", "submitter": "Yuri G. Gordienko", "authors": "Vladyslav Sarnatskyi, Vadym Ovcharenko, Mariia Tkachenko, Sergii\n  Stirenko, Yuri Gordienko, Anis Rojbi", "title": "Music Transcription by Deep Learning with Data and \"Artificial Semantic\"\n  Augmentation", "comments": "4 pages, 3 figures", "journal-ref": "International Journal of Systems Applications Engineering and\n  Development, 11, 212-215 (2017)", "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this progress paper the previous results of the single note recognition by\ndeep learning are presented. The several ways for data augmentation and\n\"artificial semantic\" augmentation are proposed to enhance efficiency of deep\nlearning approaches for monophonic and polyphonic note recognition by increase\nof dimensions of training data, their lossless and lossy transformations.\n", "versions": [{"version": "v1", "created": "Fri, 8 Dec 2017 11:18:22 GMT"}], "update_date": "2017-12-12", "authors_parsed": [["Sarnatskyi", "Vladyslav", ""], ["Ovcharenko", "Vadym", ""], ["Tkachenko", "Mariia", ""], ["Stirenko", "Sergii", ""], ["Gordienko", "Yuri", ""], ["Rojbi", "Anis", ""]]}, {"id": "1712.03298", "submitter": "Ying Xiao", "authors": "Shankar Krishnan, Ying Xiao, Rif A. Saurous", "title": "Neumann Optimizer: A Practical Optimization Algorithm for Deep Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Progress in deep learning is slowed by the days or weeks it takes to train\nlarge models. The natural solution of using more hardware is limited by\ndiminishing returns, and leads to inefficient use of additional resources. In\nthis paper, we present a large batch, stochastic optimization algorithm that is\nboth faster than widely used algorithms for fixed amounts of computation, and\nalso scales up substantially better as more computational resources become\navailable. Our algorithm implicitly computes the inverse Hessian of each\nmini-batch to produce descent directions; we do so without either an explicit\napproximation to the Hessian or Hessian-vector products. We demonstrate the\neffectiveness of our algorithm by successfully training large ImageNet models\n(Inception-V3, Resnet-50, Resnet-101 and Inception-Resnet-V2) with mini-batch\nsizes of up to 32000 with no loss in validation error relative to current\nbaselines, and no increase in the total number of steps. At smaller mini-batch\nsizes, our optimizer improves the validation error in these models by 0.8-0.9%.\nAlternatively, we can trade off this accuracy to reduce the number of training\nsteps needed by roughly 10-30%. Our work is practical and easily usable by\nothers -- only one hyperparameter (learning rate) needs tuning, and\nfurthermore, the algorithm is as computationally cheap as the commonly used\nAdam optimizer.\n", "versions": [{"version": "v1", "created": "Fri, 8 Dec 2017 22:26:58 GMT"}], "update_date": "2017-12-12", "authors_parsed": [["Krishnan", "Shankar", ""], ["Xiao", "Ying", ""], ["Saurous", "Rif A.", ""]]}, {"id": "1712.03333", "submitter": "Heejin Jeong", "authors": "Heejin Jeong, Clark Zhang, George J. Pappas, Daniel D. Lee", "title": "Assumed Density Filtering Q-learning", "comments": "source code: https://github.com/coco66/ADFQ.git ; IJCAI-19", "journal-ref": "Proceedings of the Twenty-Eighth International Joint Conference on\n  Artificial Intelligence, 2019", "doi": "10.24963/ijcai.2019/362", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While off-policy temporal difference (TD) methods have widely been used in\nreinforcement learning due to their efficiency and simple implementation, their\nBayesian counterparts have not been utilized as frequently. One reason is that\nthe non-linear max operation in the Bellman optimality equation makes it\ndifficult to define conjugate distributions over the value functions. In this\npaper, we introduce a novel Bayesian approach to off-policy TD methods, called\nas ADFQ, which updates beliefs on state-action values, Q, through an online\nBayesian inference method known as Assumed Density Filtering. We formulate an\nefficient closed-form solution for the value update by approximately estimating\nanalytic parameters of the posterior of the Q-beliefs. Uncertainty measures in\nthe beliefs not only are used in exploration but also provide a natural\nregularization for the value update considering all next available actions.\nADFQ converges to Q-learning as the uncertainty measures of the Q-beliefs\ndecrease and improves common drawbacks of other Bayesian RL algorithms such as\ncomputational complexity. We extend ADFQ with a neural network. Our empirical\nresults demonstrate that ADFQ outperforms comparable algorithms on various\nAtari 2600 games, with drastic improvements in highly stochastic domains or\ndomains with a large action space.\n", "versions": [{"version": "v1", "created": "Sat, 9 Dec 2017 02:18:05 GMT"}, {"version": "v2", "created": "Mon, 11 Jun 2018 03:22:06 GMT"}, {"version": "v3", "created": "Fri, 5 Oct 2018 19:45:13 GMT"}, {"version": "v4", "created": "Mon, 3 Jun 2019 05:09:09 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Jeong", "Heejin", ""], ["Zhang", "Clark", ""], ["Pappas", "George J.", ""], ["Lee", "Daniel D.", ""]]}, {"id": "1712.03337", "submitter": "Shihua Zhang", "authors": "Chihao Zhang, Shihua Zhang", "title": "Bayesian Joint Matrix Decomposition for Data Integration with\n  Heterogeneous Noise", "comments": "14 pages, 7 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix decomposition is a popular and fundamental approach in machine\nlearning and data mining. It has been successfully applied into various fields.\nMost matrix decomposition methods focus on decomposing a data matrix from one\nsingle source. However, it is common that data are from different sources with\nheterogeneous noise. A few of matrix decomposition methods have been extended\nfor such multi-view data integration and pattern discovery. While only few\nmethods were designed to consider the heterogeneity of noise in such multi-view\ndata for data integration explicitly. To this end, we propose a joint matrix\ndecomposition framework (BJMD), which models the heterogeneity of noise by\nGaussian distribution in a Bayesian framework. We develop two algorithms to\nsolve this model: one is a variational Bayesian inference algorithm, which\nmakes full use of the posterior distribution; and another is a maximum a\nposterior algorithm, which is more scalable and can be easily paralleled.\nExtensive experiments on synthetic and real-world datasets demonstrate that\nBJMD considering the heterogeneity of noise is superior or competitive to the\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sat, 9 Dec 2017 02:54:17 GMT"}], "update_date": "2017-12-12", "authors_parsed": [["Zhang", "Chihao", ""], ["Zhang", "Shihua", ""]]}, {"id": "1712.03346", "submitter": "Sam Sinai", "authors": "Sam Sinai, Eric Kelsic, George M. Church, Martin A. Nowak", "title": "Variational auto-encoding of protein sequences", "comments": "Abstract for oral presentation at NIPS 2017 Workshop on Machine\n  Learning in Computational Biology", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Proteins are responsible for the most diverse set of functions in biology.\nThe ability to extract information from protein sequences and to predict the\neffects of mutations is extremely valuable in many domains of biology and\nmedicine. However the mapping between protein sequence and function is complex\nand poorly understood. Here we present an embedding of natural protein\nsequences using a Variational Auto-Encoder and use it to predict how mutations\naffect protein function. We use this unsupervised approach to cluster natural\nvariants and learn interactions between sets of positions within a protein.\nThis approach generally performs better than baseline methods that consider no\ninteractions within sequences, and in some cases better than the\nstate-of-the-art approaches that use the inverse-Potts model. This generative\nmodel can be used to computationally guide exploration of protein sequence\nspace and to better inform rational and automatic protein design.\n", "versions": [{"version": "v1", "created": "Sat, 9 Dec 2017 06:36:17 GMT"}, {"version": "v2", "created": "Fri, 22 Dec 2017 02:43:57 GMT"}, {"version": "v3", "created": "Wed, 3 Jan 2018 17:39:14 GMT"}], "update_date": "2018-01-04", "authors_parsed": [["Sinai", "Sam", ""], ["Kelsic", "Eric", ""], ["Church", "George M.", ""], ["Nowak", "Martin A.", ""]]}, {"id": "1712.03351", "submitter": "Boyang Deng", "authors": "Boyang Deng, Junjie Yan, Dahua Lin", "title": "Peephole: Predicting Network Performance Before Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The quest for performant networks has been a significant force that drives\nthe advancements of deep learning in recent years. While rewarding, improving\nnetwork design has never been an easy journey. The large design space combined\nwith the tremendous cost required for network training poses a major obstacle\nto this endeavor. In this work, we propose a new approach to this problem,\nnamely, predicting the performance of a network before training, based on its\narchitecture. Specifically, we develop a unified way to encode individual\nlayers into vectors and bring them together to form an integrated description\nvia LSTM. Taking advantage of the recurrent network's strong expressive power,\nthis method can reliably predict the performances of various network\narchitectures. Our empirical studies showed that it not only achieved accurate\npredictions but also produced consistent rankings across datasets -- a key\ndesideratum in performance prediction.\n", "versions": [{"version": "v1", "created": "Sat, 9 Dec 2017 07:50:27 GMT"}], "update_date": "2017-12-12", "authors_parsed": [["Deng", "Boyang", ""], ["Yan", "Junjie", ""], ["Lin", "Dahua", ""]]}, {"id": "1712.03390", "submitter": "Konda Reddy Mopuri", "authors": "Konda Reddy Mopuri, Utkarsh Ojha, Utsav Garg and R. Venkatesh Babu", "title": "NAG: Network for Adversary Generation", "comments": "CVPR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial perturbations can pose a serious threat for deploying machine\nlearning systems. Recent works have shown existence of image-agnostic\nperturbations that can fool classifiers over most natural images. Existing\nmethods present optimization approaches that solve for a fooling objective with\nan imperceptibility constraint to craft the perturbations. However, for a given\nclassifier, they generate one perturbation at a time, which is a single\ninstance from the manifold of adversarial perturbations. Also, in order to\nbuild robust models, it is essential to explore the manifold of adversarial\nperturbations. In this paper, we propose for the first time, a generative\napproach to model the distribution of adversarial perturbations. The\narchitecture of the proposed model is inspired from that of GANs and is trained\nusing fooling and diversity objectives. Our trained generator network attempts\nto capture the distribution of adversarial perturbations for a given classifier\nand readily generates a wide variety of such perturbations. Our experimental\nevaluation demonstrates that perturbations crafted by our model (i) achieve\nstate-of-the-art fooling rates, (ii) exhibit wide variety and (iii) deliver\nexcellent cross model generalizability. Our work can be deemed as an important\nstep in the process of inferring about the complex manifolds of adversarial\nperturbations.\n", "versions": [{"version": "v1", "created": "Sat, 9 Dec 2017 14:27:49 GMT"}, {"version": "v2", "created": "Wed, 28 Mar 2018 09:31:27 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Mopuri", "Konda Reddy", ""], ["Ojha", "Utkarsh", ""], ["Garg", "Utsav", ""], ["Babu", "R. Venkatesh", ""]]}, {"id": "1712.03428", "submitter": "Matteo Pirotta", "authors": "Matteo Pirotta and Marcello Restelli", "title": "Cost-Sensitive Approach to Batch Size Adaptation for Gradient Descent", "comments": "Presented at the NIPS workshop on Optimizing the Optimizers.\n  Barcelona, Spain, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel approach to automatically determine the\nbatch size in stochastic gradient descent methods. The choice of the batch size\ninduces a trade-off between the accuracy of the gradient estimate and the cost\nin terms of samples of each update. We propose to determine the batch size by\noptimizing the ratio between a lower bound to a linear or quadratic Taylor\napproximation of the expected improvement and the number of samples used to\nestimate the gradient. The performance of the proposed approach is empirically\ncompared with related methods on popular classification tasks.\n  The work was presented at the NIPS workshop on Optimizing the Optimizers.\nBarcelona, Spain, 2016.\n", "versions": [{"version": "v1", "created": "Sat, 9 Dec 2017 19:59:25 GMT"}], "update_date": "2017-12-12", "authors_parsed": [["Pirotta", "Matteo", ""], ["Restelli", "Marcello", ""]]}, {"id": "1712.03461", "submitter": "Han Wang", "authors": "Linfeng Zhang, Han Wang, and Weinan E", "title": "Reinforced dynamics for enhanced sampling in large atomic and molecular\n  systems", "comments": null, "journal-ref": null, "doi": "10.1063/1.5019675", "report-no": null, "categories": "physics.chem-ph cs.LG physics.bio-ph physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new approach for efficiently exploring the configuration space and\ncomputing the free energy of large atomic and molecular systems is proposed,\nmotivated by an analogy with reinforcement learning. There are two major\ncomponents in this new approach. Like metadynamics, it allows for an efficient\nexploration of the configuration space by adding an adaptively computed biasing\npotential to the original dynamics. Like deep reinforcement learning, this\nbiasing potential is trained on the fly using deep neural networks, with data\ncollected judiciously from the exploration and an uncertainty indicator from\nthe neural network model playing the role of the reward function.\nParameterization using neural networks makes it feasible to handle cases with a\nlarge set of collective variables. This has the potential advantage that\nselecting precisely the right set of collective variables has now become less\ncritical for capturing the structural transformations of the system. The method\nis illustrated by studying the full-atom, explicit solvent models of alanine\ndipeptide and tripeptide, as well as the system of a polyalanine-10 molecule\nwith 20 collective variables.\n", "versions": [{"version": "v1", "created": "Sun, 10 Dec 2017 00:42:12 GMT"}, {"version": "v2", "created": "Tue, 12 Dec 2017 15:18:41 GMT"}, {"version": "v3", "created": "Fri, 15 Dec 2017 11:55:29 GMT"}, {"version": "v4", "created": "Tue, 13 Feb 2018 07:20:57 GMT"}, {"version": "v5", "created": "Wed, 14 Feb 2018 07:33:52 GMT"}, {"version": "v6", "created": "Mon, 19 Feb 2018 13:13:20 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Zhang", "Linfeng", ""], ["Wang", "Han", ""], ["E", "Weinan", ""]]}, {"id": "1712.03480", "submitter": "Edgar Xi", "authors": "Edgar Xi, Selina Bing, Yang Jin", "title": "Capsule Network Performance on Complex Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, convolutional neural networks (CNN) have played an important\nrole in the field of deep learning. Variants of CNN's have proven to be very\nsuccessful in classification tasks across different domains. However, there are\ntwo big drawbacks to CNN's: their failure to take into account of important\nspatial hierarchies between features, and their lack of rotational invariance.\nAs long as certain key features of an object are present in the test data,\nCNN's classify the test data as the object, disregarding features' relative\nspatial orientation to each other. This causes false positives. The lack of\nrotational invariance in CNN's would cause the network to incorrectly assign\nthe object another label, causing false negatives. To address this concern,\nHinton et al. propose a novel type of neural network using the concept of\ncapsules in a recent paper. With the use of dynamic routing and reconstruction\nregularization, the capsule network model would be both rotation invariant and\nspatially aware. The capsule network has shown its potential by achieving a\nstate-of-the-art result of 0.25% test error on MNIST without data augmentation\nsuch as rotation and scaling, better than the previous baseline of 0.39%. To\nfurther test out the application of capsule networks on data with higher\ndimensionality, we attempt to find the best set of configurations that yield\nthe optimal test error on CIFAR10 dataset.\n", "versions": [{"version": "v1", "created": "Sun, 10 Dec 2017 07:50:04 GMT"}], "update_date": "2017-12-12", "authors_parsed": [["Xi", "Edgar", ""], ["Bing", "Selina", ""], ["Jin", "Yang", ""]]}, {"id": "1712.03524", "submitter": "Michal Moshkovitz", "authors": "Michal Moshkovitz and Naftali Tishby", "title": "A General Memory-Bounded Learning Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing bounded-memory algorithms is becoming increasingly important\nnowadays. Previous works studying bounded-memory algorithms focused on proving\nimpossibility results, while the design of bounded-memory algorithms was left\nrelatively unexplored. To remedy this situation, in this work we design a\ngeneral bounded-memory learning algorithm, when the underlying distribution is\nknown. The core idea of the algorithm is not to save the exact example\nreceived, but only a few important bits that give sufficient information. This\nalgorithm applies to any hypothesis class that has an \"anti-mixing\" property.\nThis paper complements previous works on unlearnability with bounded memory and\nprovides a step towards a full characterization of bounded-memory learning.\n", "versions": [{"version": "v1", "created": "Sun, 10 Dec 2017 13:33:53 GMT"}, {"version": "v2", "created": "Fri, 11 Oct 2019 22:15:49 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Moshkovitz", "Michal", ""], ["Tishby", "Naftali", ""]]}, {"id": "1712.03541", "submitter": "Abien Fred Agarap", "authors": "Abien Fred Agarap", "title": "An Architecture Combining Convolutional Neural Network (CNN) and Support\n  Vector Machine (SVM) for Image Classification", "comments": "4 pages, 4 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Convolutional neural networks (CNNs) are similar to \"ordinary\" neural\nnetworks in the sense that they are made up of hidden layers consisting of\nneurons with \"learnable\" parameters. These neurons receive inputs, performs a\ndot product, and then follows it with a non-linearity. The whole network\nexpresses the mapping between raw image pixels and their class scores.\nConventionally, the Softmax function is the classifier used at the last layer\nof this network. However, there have been studies (Alalshekmubarak and Smith,\n2013; Agarap, 2017; Tang, 2013) conducted to challenge this norm. The cited\nstudies introduce the usage of linear support vector machine (SVM) in an\nartificial neural network architecture. This project is yet another take on the\nsubject, and is inspired by (Tang, 2013). Empirical data has shown that the\nCNN-SVM model was able to achieve a test accuracy of ~99.04% using the MNIST\ndataset (LeCun, Cortes, and Burges, 2010). On the other hand, the CNN-Softmax\nwas able to achieve a test accuracy of ~99.23% using the same dataset. Both\nmodels were also tested on the recently-published Fashion-MNIST dataset (Xiao,\nRasul, and Vollgraf, 2017), which is suppose to be a more difficult image\nclassification dataset than MNIST (Zalandoresearch, 2017). This proved to be\nthe case as CNN-SVM reached a test accuracy of ~90.72%, while the CNN-Softmax\nreached a test accuracy of ~91.86%. The said results may be improved if data\npreprocessing techniques were employed on the datasets, and if the base CNN\nmodel was a relatively more sophisticated than the one used in this study.\n", "versions": [{"version": "v1", "created": "Sun, 10 Dec 2017 14:50:28 GMT"}, {"version": "v2", "created": "Thu, 7 Feb 2019 06:25:08 GMT"}], "update_date": "2019-02-08", "authors_parsed": [["Agarap", "Abien Fred", ""]]}, {"id": "1712.03563", "submitter": "Bo Wu", "authors": "Bo Wu, Yang Liu, Bo Lang, Lei Huang", "title": "DGCNN: Disordered Graph Convolutional Neural Network Based on the\n  Gaussian Mixture Model", "comments": "16 pages,8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs) can be applied to graph similarity\nmatching, in which case they are called graph CNNs. Graph CNNs are attracting\nincreasing attention due to their effectiveness and efficiency. However, the\nexisting convolution approaches focus only on regular data forms and require\nthe transfer of the graph or key node neighborhoods of the graph into the same\nfixed form. During this transfer process, structural information of the graph\ncan be lost, and some redundant information can be incorporated. To overcome\nthis problem, we propose the disordered graph convolutional neural network\n(DGCNN) based on the mixed Gaussian model, which extends the CNN by adding a\npreprocessing layer called the disordered graph convolutional layer (DGCL). The\nDGCL uses a mixed Gaussian function to realize the mapping between the\nconvolution kernel and the nodes in the neighborhood of the graph. The output\nof the DGCL is the input of the CNN. We further implement a\nbackward-propagation optimization process of the convolutional layer by which\nwe incorporate the feature-learning model of the irregular node neighborhood\nstructure into the network. Thereafter, the optimization of the convolution\nkernel becomes part of the neural network learning process. The DGCNN can\naccept arbitrary scaled and disordered neighborhood graph structures as the\nreceptive fields of CNNs, which reduces information loss during graph\ntransformation. Finally, we perform experiments on multiple standard graph\ndatasets. The results show that the proposed method outperforms the\nstate-of-the-art methods in graph classification and retrieval.\n", "versions": [{"version": "v1", "created": "Sun, 10 Dec 2017 17:38:25 GMT"}], "update_date": "2017-12-12", "authors_parsed": [["Wu", "Bo", ""], ["Liu", "Yang", ""], ["Lang", "Bo", ""], ["Huang", "Lei", ""]]}, {"id": "1712.03599", "submitter": "Stephan Eismann", "authors": "Stephan Eismann, Stefan Bartzsch, Stefano Ermon", "title": "Shape optimization in laminar flow with a label-guided variational\n  autoencoder", "comments": "Contribution to workshop \"Bayesian optimization for science and\n  engineering\" at NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational design optimization in fluid dynamics usually requires to solve\nnon-linear partial differential equations numerically. In this work, we explore\na Bayesian optimization approach to minimize an object's drag coefficient in\nlaminar flow based on predicting drag directly from the object shape. Jointly\ntraining an architecture combining a variational autoencoder mapping shapes to\nlatent representations and Gaussian process regression allows us to generate\nimproved shapes in the two dimensional case we consider.\n", "versions": [{"version": "v1", "created": "Sun, 10 Dec 2017 22:24:02 GMT"}], "update_date": "2017-12-12", "authors_parsed": [["Eismann", "Stephan", ""], ["Bartzsch", "Stefan", ""], ["Ermon", "Stefano", ""]]}, {"id": "1712.03607", "submitter": "Robert Kwiatkowski", "authors": "Robert Kwiatkowski, Oscar Chang", "title": "Gradient Normalization & Depth Based Decay For Deep Learning", "comments": "Results seemed more promising at the time", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce a novel method of gradient normalization and decay\nwith respect to depth. Our method leverages the simple concept of normalizing\nall gradients in a deep neural network, and then decaying said gradients with\nrespect to their depth in the network. Our proposed normalization and decay\ntechniques can be used in conjunction with most current state of the art\noptimizers and are a very simple addition to any network. This method, although\nsimple, showed improvements in convergence time on state of the art networks\nsuch as DenseNet and ResNet on image classification tasks, as well as on an\nLSTM for natural language processing tasks.\n", "versions": [{"version": "v1", "created": "Sun, 10 Dec 2017 23:01:13 GMT"}, {"version": "v2", "created": "Wed, 28 Feb 2018 15:56:52 GMT"}], "update_date": "2018-03-01", "authors_parsed": [["Kwiatkowski", "Robert", ""], ["Chang", "Oscar", ""]]}, {"id": "1712.03632", "submitter": "Anay Pattanaik", "authors": "Anay Pattanaik, Zhenyi Tang, Shuijing Liu, Gautham Bommannan and\n  Girish Chowdhary", "title": "Robust Deep Reinforcement Learning with Adversarial Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes adversarial attacks for Reinforcement Learning (RL) and\nthen improves the robustness of Deep Reinforcement Learning algorithms (DRL) to\nparameter uncertainties with the help of these attacks. We show that even a\nnaively engineered attack successfully degrades the performance of DRL\nalgorithm. We further improve the attack using gradient information of an\nengineered loss function which leads to further degradation in performance.\nThese attacks are then leveraged during training to improve the robustness of\nRL within robust control framework. We show that this adversarial training of\nDRL algorithms like Deep Double Q learning and Deep Deterministic Policy\nGradients leads to significant increase in robustness to parameter variations\nfor RL benchmarks such as Cart-pole, Mountain Car, Hopper and Half Cheetah\nenvironment.\n", "versions": [{"version": "v1", "created": "Mon, 11 Dec 2017 02:58:13 GMT"}], "update_date": "2017-12-12", "authors_parsed": [["Pattanaik", "Anay", ""], ["Tang", "Zhenyi", ""], ["Liu", "Shuijing", ""], ["Bommannan", "Gautham", ""], ["Chowdhary", "Girish", ""]]}, {"id": "1712.03641", "submitter": "Linfeng Zhang", "authors": "Han Wang, Linfeng Zhang, Jiequn Han, Weinan E", "title": "DeePMD-kit: A deep learning package for many-body potential energy\n  representation and molecular dynamics", "comments": null, "journal-ref": null, "doi": "10.1016/j.cpc.2018.03.016", "report-no": null, "categories": "physics.comp-ph cs.LG physics.chem-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent developments in many-body potential energy representation via deep\nlearning have brought new hopes to addressing the accuracy-versus-efficiency\ndilemma in molecular simulations. Here we describe DeePMD-kit, a package\nwritten in Python/C++ that has been designed to minimize the effort required to\nbuild deep learning based representation of potential energy and force field\nand to perform molecular dynamics. Potential applications of DeePMD-kit span\nfrom finite molecules to extended systems and from metallic systems to\nchemically bonded systems. DeePMD-kit is interfaced with TensorFlow, one of the\nmost popular deep learning frameworks, making the training process highly\nautomatic and efficient. On the other end, DeePMD-kit is interfaced with\nhigh-performance classical molecular dynamics and quantum (path-integral)\nmolecular dynamics packages, i.e., LAMMPS and the i-PI, respectively. Thus,\nupon training, the potential energy and force field models can be used to\nperform efficient molecular simulations for different purposes. As an example\nof the many potential applications of the package, we use DeePMD-kit to learn\nthe interatomic potential energy and forces of a water model using data\nobtained from density functional theory. We demonstrate that the resulted\nmolecular dynamics model reproduces accurately the structural information\ncontained in the original model.\n", "versions": [{"version": "v1", "created": "Mon, 11 Dec 2017 04:16:43 GMT"}, {"version": "v2", "created": "Sun, 31 Dec 2017 03:48:06 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Wang", "Han", ""], ["Zhang", "Linfeng", ""], ["Han", "Jiequn", ""], ["E", "Weinan", ""]]}, {"id": "1712.03781", "submitter": "Eunwoo Kim", "authors": "Eunwoo Kim, Chanho Ahn, Songhwai Oh", "title": "NestedNet: Learning Nested Sparse Structures in Deep Neural Networks", "comments": "To appear in CVPR 2018. Spotlight Presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, there have been increasing demands to construct compact deep\narchitectures to remove unnecessary redundancy and to improve the inference\nspeed. While many recent works focus on reducing the redundancy by eliminating\nunneeded weight parameters, it is not possible to apply a single deep\narchitecture for multiple devices with different resources. When a new device\nor circumstantial condition requires a new deep architecture, it is necessary\nto construct and train a new network from scratch. In this work, we propose a\nnovel deep learning framework, called a nested sparse network, which exploits\nan n-in-1-type nested structure in a neural network. A nested sparse network\nconsists of multiple levels of networks with a different sparsity ratio\nassociated with each level, and higher level networks share parameters with\nlower level networks to enable stable nested learning. The proposed framework\nrealizes a resource-aware versatile architecture as the same network can meet\ndiverse resource requirements. Moreover, the proposed nested network can learn\ndifferent forms of knowledge in its internal networks at different levels,\nenabling multiple tasks using a single network, such as coarse-to-fine\nhierarchical classification. In order to train the proposed nested sparse\nnetwork, we propose efficient weight connection learning and channel and layer\nscheduling strategies. We evaluate our network in multiple tasks, including\nadaptive deep compression, knowledge distillation, and learning class\nhierarchy, and demonstrate that nested sparse networks perform competitively,\nbut more efficiently, compared to existing methods.\n", "versions": [{"version": "v1", "created": "Mon, 11 Dec 2017 14:09:06 GMT"}, {"version": "v2", "created": "Tue, 27 Mar 2018 04:44:56 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Kim", "Eunwoo", ""], ["Ahn", "Chanho", ""], ["Oh", "Songhwai", ""]]}, {"id": "1712.03847", "submitter": "Ferenc Husz\\'ar", "authors": "Ferenc Husz\\'ar", "title": "On Quadratic Penalties in Elastic Weight Consolidation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Elastic weight consolidation (EWC, Kirkpatrick et al, 2017) is a novel\nalgorithm designed to safeguard against catastrophic forgetting in neural\nnetworks. EWC can be seen as an approximation to Laplace propagation (Eskin et\nal, 2004), and this view is consistent with the motivation given by Kirkpatrick\net al (2017). In this note, I present an extended derivation that covers the\ncase when there are more than two tasks. I show that the quadratic penalties in\nEWC are inconsistent with this derivation and might lead to double-counting\ndata from earlier tasks.\n", "versions": [{"version": "v1", "created": "Mon, 11 Dec 2017 15:49:02 GMT"}], "update_date": "2017-12-12", "authors_parsed": [["Husz\u00e1r", "Ferenc", ""]]}, {"id": "1712.03878", "submitter": "Vinay Verma Kumar", "authors": "Vinay Kumar Verma, Gundeep Arora, Ashish Mishra, Piyush Rai", "title": "Generalized Zero-Shot Learning via Synthesized Examples", "comments": "Accepted in CVPR'18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a generative framework for generalized zero-shot learning where\nthe training and test classes are not necessarily disjoint. Built upon a\nvariational autoencoder based architecture, consisting of a probabilistic\nencoder and a probabilistic conditional decoder, our model can generate novel\nexemplars from seen/unseen classes, given their respective class attributes.\nThese exemplars can subsequently be used to train any off-the-shelf\nclassification model. One of the key aspects of our encoder-decoder\narchitecture is a feedback-driven mechanism in which a discriminator (a\nmultivariate regressor) learns to map the generated exemplars to the\ncorresponding class attribute vectors, leading to an improved generator. Our\nmodel's ability to generate and leverage examples from unseen classes to train\nthe classification model naturally helps to mitigate the bias towards\npredicting seen classes in generalized zero-shot learning settings. Through a\ncomprehensive set of experiments, we show that our model outperforms several\nstate-of-the-art methods, on several benchmark datasets, for both standard as\nwell as generalized zero-shot learning.\n", "versions": [{"version": "v1", "created": "Mon, 11 Dec 2017 16:44:12 GMT"}, {"version": "v2", "created": "Tue, 12 Dec 2017 09:19:01 GMT"}, {"version": "v3", "created": "Mon, 23 Apr 2018 11:20:15 GMT"}, {"version": "v4", "created": "Fri, 8 Jun 2018 16:55:14 GMT"}, {"version": "v5", "created": "Tue, 12 Jun 2018 00:13:53 GMT"}], "update_date": "2018-06-13", "authors_parsed": [["Verma", "Vinay Kumar", ""], ["Arora", "Gundeep", ""], ["Mishra", "Ashish", ""], ["Rai", "Piyush", ""]]}, {"id": "1712.03890", "submitter": "Theophilus Benson", "authors": "Christopher Streiffer, Huan Chen, Theophilus Benson, Asim Kadav", "title": "DeepConfig: Automating Data Center Network Topologies Management with\n  Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, many techniques have been developed to improve the\nperformance and efficiency of data center networks. While these techniques\nprovide high accuracy, they are often designed using heuristics that leverage\ndomain-specific properties of the workload or hardware.\n  In this vision paper, we argue that many data center networking techniques,\ne.g., routing, topology augmentation, energy savings, with diverse goals\nactually share design and architectural similarity. We present a design for\ndeveloping general intermediate representations of network topologies using\ndeep learning that is amenable to solving classes of data center problems. We\ndevelop a framework, DeepConfig, that simplifies the processing of configuring\nand training deep learning agents that use the intermediate representation to\nlearns different tasks. To illustrate the strength of our approach, we\nconfigured, implemented, and evaluated a DeepConfig-Agent that tackles the data\ncenter topology augmentation problem. Our initial results are promising ---\nDeepConfig performs comparably to the optimal.\n", "versions": [{"version": "v1", "created": "Mon, 11 Dec 2017 17:07:12 GMT"}], "update_date": "2017-12-13", "authors_parsed": [["Streiffer", "Christopher", ""], ["Chen", "Huan", ""], ["Benson", "Theophilus", ""], ["Kadav", "Asim", ""]]}, {"id": "1712.03897", "submitter": "Kenneth Leidal", "authors": "Kenneth Leidal, David Harwath, and James Glass", "title": "Learning Modality-Invariant Representations for Speech and Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we explore the unsupervised learning of a semantic embedding\nspace for co-occurring sensory inputs. Specifically, we focus on the task of\nlearning a semantic vector space for both spoken and handwritten digits using\nthe TIDIGITs and MNIST datasets. Current techniques encode image and\naudio/textual inputs directly to semantic embeddings. In contrast, our\ntechnique maps an input to the mean and log variance vectors of a diagonal\nGaussian from which sample semantic embeddings are drawn. In addition to\nencouraging semantic similarity between co-occurring inputs,our loss function\nincludes a regularization term borrowed from variational autoencoders (VAEs)\nwhich drives the posterior distributions over embeddings to be unit Gaussian.\nWe can use this regularization term to filter out modality information while\npreserving semantic information. We speculate this technique may be more\nbroadly applicable to other areas of cross-modality/domain information\nretrieval and transfer learning.\n", "versions": [{"version": "v1", "created": "Mon, 11 Dec 2017 17:18:34 GMT"}], "update_date": "2017-12-12", "authors_parsed": [["Leidal", "Kenneth", ""], ["Harwath", "David", ""], ["Glass", "James", ""]]}, {"id": "1712.03931", "submitter": "Manolis Savva", "authors": "Manolis Savva, Angel X. Chang, Alexey Dosovitskiy, Thomas Funkhouser,\n  Vladlen Koltun", "title": "MINOS: Multimodal Indoor Simulator for Navigation in Complex\n  Environments", "comments": "MINOS is a simulator designed to support research on end-to-end\n  navigation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.GR cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present MINOS, a simulator designed to support the development of\nmultisensory models for goal-directed navigation in complex indoor\nenvironments. The simulator leverages large datasets of complex 3D environments\nand supports flexible configuration of multimodal sensor suites. We use MINOS\nto benchmark deep-learning-based navigation methods, to analyze the influence\nof environmental complexity on navigation performance, and to carry out a\ncontrolled study of multimodality in sensorimotor learning. The experiments\nshow that current deep reinforcement learning approaches fail in large\nrealistic environments. The experiments also indicate that multimodality is\nbeneficial in learning to navigate cluttered scenes. MINOS is released\nopen-source to the research community at http://minosworld.org . A video that\nshows MINOS can be found at https://youtu.be/c0mL9K64q84\n", "versions": [{"version": "v1", "created": "Mon, 11 Dec 2017 18:24:58 GMT"}], "update_date": "2017-12-12", "authors_parsed": [["Savva", "Manolis", ""], ["Chang", "Angel X.", ""], ["Dosovitskiy", "Alexey", ""], ["Funkhouser", "Thomas", ""], ["Koltun", "Vladlen", ""]]}, {"id": "1712.03942", "submitter": "Michael Tschannen", "authors": "Michael Tschannen, Aran Khanna, Anima Anandkumar", "title": "StrassenNets: Deep Learning with a Multiplication Budget", "comments": "ICML 2018. Code available at https://github.com/mitscha/strassennets", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A large fraction of the arithmetic operations required to evaluate deep\nneural networks (DNNs) consists of matrix multiplications, in both convolution\nand fully connected layers. We perform end-to-end learning of low-cost\napproximations of matrix multiplications in DNN layers by casting matrix\nmultiplications as 2-layer sum-product networks (SPNs) (arithmetic circuits)\nand learning their (ternary) edge weights from data. The SPNs disentangle\nmultiplication and addition operations and enable us to impose a budget on the\nnumber of multiplication operations. Combining our method with knowledge\ndistillation and applying it to image classification DNNs (trained on ImageNet)\nand language modeling DNNs (using LSTMs), we obtain a first-of-a-kind reduction\nin number of multiplications (over 99.5%) while maintaining the predictive\nperformance of the full-precision models. Finally, we demonstrate that the\nproposed framework is able to rediscover Strassen's matrix multiplication\nalgorithm, learning to multiply $2 \\times 2$ matrices using only 7\nmultiplications instead of 8.\n", "versions": [{"version": "v1", "created": "Mon, 11 Dec 2017 18:49:07 GMT"}, {"version": "v2", "created": "Fri, 23 Feb 2018 12:59:10 GMT"}, {"version": "v3", "created": "Fri, 8 Jun 2018 10:59:23 GMT"}], "update_date": "2018-06-11", "authors_parsed": [["Tschannen", "Michael", ""], ["Khanna", "Aran", ""], ["Anandkumar", "Anima", ""]]}, {"id": "1712.03950", "submitter": "Quanquan Gu", "authors": "Yaodong Yu and Difan Zou and Quanquan Gu", "title": "Saving Gradient and Negative Curvature Computations: Finding Local\n  Minima More Efficiently", "comments": "31 pages, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a family of nonconvex optimization algorithms that are able to\nsave gradient and negative curvature computations to a large extent, and are\nguaranteed to find an approximate local minimum with improved runtime\ncomplexity. At the core of our algorithms is the division of the entire domain\nof the objective function into small and large gradient regions: our algorithms\nonly perform gradient descent based procedure in the large gradient region, and\nonly perform negative curvature descent in the small gradient region. Our novel\nanalysis shows that the proposed algorithms can escape the small gradient\nregion in only one negative curvature descent step whenever they enter it, and\nthus they only need to perform at most $N_{\\epsilon}$ negative curvature\ndirection computations, where $N_{\\epsilon}$ is the number of times the\nalgorithms enter small gradient regions. For both deterministic and stochastic\nsettings, we show that the proposed algorithms can potentially beat the\nstate-of-the-art local minima finding algorithms. For the finite-sum setting,\nour algorithm can also outperform the best algorithm in a certain regime.\n", "versions": [{"version": "v1", "created": "Mon, 11 Dec 2017 18:59:09 GMT"}], "update_date": "2017-12-12", "authors_parsed": [["Yu", "Yaodong", ""], ["Zou", "Difan", ""], ["Gu", "Quanquan", ""]]}, {"id": "1712.03999", "submitter": "Brian Dolhansky", "authors": "Brian Dolhansky, Cristian Canton Ferrer", "title": "Eye In-Painting with Exemplar Generative Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a novel approach to in-painting where the identity of\nthe object to remove or change is preserved and accounted for at inference\ntime: Exemplar GANs (ExGANs). ExGANs are a type of conditional GAN that utilize\nexemplar information to produce high-quality, personalized in painting results.\nWe propose using exemplar information in the form of a reference image of the\nregion to in-paint, or a perceptual code describing that object. Unlike\nprevious conditional GAN formulations, this extra information can be inserted\nat multiple points within the adversarial network, thus increasing its\ndescriptive power. We show that ExGANs can produce photo-realistic personalized\nin-painting results that are both perceptually and semantically plausible by\napplying them to the task of closed to-open eye in-painting in natural\npictures. A new benchmark dataset is also introduced for the task of eye\nin-painting for future comparisons.\n", "versions": [{"version": "v1", "created": "Mon, 11 Dec 2017 19:40:55 GMT"}], "update_date": "2017-12-13", "authors_parsed": [["Dolhansky", "Brian", ""], ["Ferrer", "Cristian Canton", ""]]}, {"id": "1712.04006", "submitter": "Alexander Bagnall", "authors": "Alexander Bagnall, Razvan Bunescu, Gordon Stewart", "title": "Training Ensembles to Detect Adversarial Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new ensemble method for detecting and classifying adversarial\nexamples generated by state-of-the-art attacks, including DeepFool and C&W. Our\nmethod works by training the members of an ensemble to have low classification\nerror on random benign examples while simultaneously minimizing agreement on\nexamples outside the training distribution. We evaluate on both MNIST and\nCIFAR-10, against oblivious and both white- and black-box adversaries.\n", "versions": [{"version": "v1", "created": "Mon, 11 Dec 2017 20:30:11 GMT"}], "update_date": "2017-12-13", "authors_parsed": [["Bagnall", "Alexander", ""], ["Bunescu", "Razvan", ""], ["Stewart", "Gordon", ""]]}, {"id": "1712.04048", "submitter": "Hao Zhang", "authors": "Hao Zhang, Shizhen Xu, Graham Neubig, Wei Dai, Qirong Ho, Guangwen\n  Yang, Eric P. Xing", "title": "Cavs: A Vertex-centric Programming Interface for Dynamic Neural Networks", "comments": "Short versions of this paper were presented at AISys workshop@SOSP\n  2017 and MLSys workshop@NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent deep learning (DL) models have moved beyond static network\narchitectures to dynamic ones, handling data where the network structure\nchanges every example, such as sequences of variable lengths, trees, and\ngraphs. Existing dataflow-based programming models for DL---both static and\ndynamic declaration---either cannot readily express these dynamic models, or\nare inefficient due to repeated dataflow graph construction and processing, and\ndifficulties in batched execution. We present Cavs, a vertex-centric\nprogramming interface and optimized system implementation for dynamic DL\nmodels. Cavs represents dynamic network structure as a static vertex function\n$\\mathcal{F}$ and a dynamic instance-specific graph $\\mathcal{G}$, and performs\nbackpropagation by scheduling the execution of $\\mathcal{F}$ following the\ndependencies in $\\mathcal{G}$. Cavs bypasses expensive graph construction and\npreprocessing overhead, allows for the use of static graph optimization\ntechniques on pre-defined operations in $\\mathcal{F}$, and naturally exposes\nbatched execution opportunities over different graphs. Experiments comparing\nCavs to two state-of-the-art frameworks for dynamic NNs (TensorFlow Fold and\nDyNet) demonstrate the efficacy of this approach: Cavs achieves a near one\norder of magnitude speedup on training of various dynamic NN architectures, and\nablations demonstrate the contribution of our proposed batching and memory\nmanagement strategies.\n", "versions": [{"version": "v1", "created": "Mon, 11 Dec 2017 22:04:39 GMT"}], "update_date": "2017-12-13", "authors_parsed": [["Zhang", "Hao", ""], ["Xu", "Shizhen", ""], ["Neubig", "Graham", ""], ["Dai", "Wei", ""], ["Ho", "Qirong", ""], ["Yang", "Guangwen", ""], ["Xing", "Eric P.", ""]]}, {"id": "1712.04086", "submitter": "Sewoong Oh", "authors": "Zinan Lin, Ashish Khetan, Giulia Fanti, Sewoong Oh", "title": "PacGAN: The power of two samples in generative adversarial networks", "comments": "49 pages, 24 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) are innovative techniques for learning\ngenerative models of complex data distributions from samples. Despite\nremarkable recent improvements in generating realistic images, one of their\nmajor shortcomings is the fact that in practice, they tend to produce samples\nwith little diversity, even when trained on diverse datasets. This phenomenon,\nknown as mode collapse, has been the main focus of several recent advances in\nGANs. Yet there is little understanding of why mode collapse happens and why\nexisting approaches are able to mitigate mode collapse. We propose a principled\napproach to handling mode collapse, which we call packing. The main idea is to\nmodify the discriminator to make decisions based on multiple samples from the\nsame class, either real or artificially generated. We borrow analysis tools\nfrom binary hypothesis testing---in particular the seminal result of Blackwell\n[Bla53]---to prove a fundamental connection between packing and mode collapse.\nWe show that packing naturally penalizes generators with mode collapse, thereby\nfavoring generator distributions with less mode collapse during the training\nprocess. Numerical experiments on benchmark datasets suggests that packing\nprovides significant improvements in practice as well.\n", "versions": [{"version": "v1", "created": "Tue, 12 Dec 2017 00:57:52 GMT"}, {"version": "v2", "created": "Sun, 15 Apr 2018 22:45:01 GMT"}, {"version": "v3", "created": "Fri, 2 Nov 2018 04:15:06 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Lin", "Zinan", ""], ["Khetan", "Ashish", ""], ["Fanti", "Giulia", ""], ["Oh", "Sewoong", ""]]}, {"id": "1712.04101", "submitter": "Nicolas Bougie", "authors": "Nicolas Bougie and Ryutaro Ichise", "title": "Deep Reinforcement Learning Boosted by External Knowledge", "comments": null, "journal-ref": null, "doi": "10.1145/3167132.3167165", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent improvements in deep reinforcement learning have allowed to solve\nproblems in many 2D domains such as Atari games. However, in complex 3D\nenvironments, numerous learning episodes are required which may be too time\nconsuming or even impossible especially in real-world scenarios. We present a\nnew architecture to combine external knowledge and deep reinforcement learning\nusing only visual input. A key concept of our system is augmenting image input\nby adding environment feature information and combining two sources of\ndecision. We evaluate the performances of our method in a 3D\npartially-observable environment from the Microsoft Malmo platform.\nExperimental evaluation exhibits higher performance and faster learning\ncompared to a single reinforcement learning model.\n", "versions": [{"version": "v1", "created": "Tue, 12 Dec 2017 02:19:25 GMT"}], "update_date": "2017-12-13", "authors_parsed": [["Bougie", "Nicolas", ""], ["Ichise", "Ryutaro", ""]]}, {"id": "1712.04104", "submitter": "Benjamin Grimmer", "authors": "Benjamin Grimmer", "title": "Convergence Rates for Deterministic and Stochastic Subgradient Methods\n  Without Lipschitz Continuity", "comments": "Update 2/26/18: Major revision improving the convergence results to\n  no longer need an exponential upper bound on function growth in the convex\n  case. Now local Lipschitz continuity around a minimizer suffices for a global\n  convergence rate. Update 12/21/17: Added three more references on weakening\n  strong convexity and minorly changed some wording. 16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the classic convergence rate theory for subgradient methods to\napply to non-Lipschitz functions. For the deterministic projected subgradient\nmethod, we present a global $O(1/\\sqrt{T})$ convergence rate for any convex\nfunction which is locally Lipschitz around its minimizers. This approach is\nbased on Shor's classic subgradient analysis and implies generalizations of the\nstandard convergence rates for gradient descent on functions with Lipschitz or\nH\\\"older continuous gradients. Further, we show a $O(1/\\sqrt{T})$ convergence\nrate for the stochastic projected subgradient method on convex functions with\nat most quadratic growth, which improves to $O(1/T)$ under either strong\nconvexity or a weaker quadratic lower bound condition.\n", "versions": [{"version": "v1", "created": "Tue, 12 Dec 2017 02:51:59 GMT"}, {"version": "v2", "created": "Thu, 21 Dec 2017 17:23:39 GMT"}, {"version": "v3", "created": "Mon, 26 Feb 2018 22:27:18 GMT"}], "update_date": "2018-02-28", "authors_parsed": [["Grimmer", "Benjamin", ""]]}, {"id": "1712.04106", "submitter": "Yan Shuo Tan", "authors": "Yan Shuo Tan", "title": "Sparse Phase Retrieval via Sparse PCA Despite Model Misspecification: A\n  Simplified and Extended Analysis", "comments": "Edited formatting for abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of high-dimensional misspecified phase retrieval.\nThis is where we have an $s$-sparse signal vector $\\mathbf{x}_*$ in\n$\\mathbb{R}^n$, which we wish to recover using sampling vectors\n$\\textbf{a}_1,\\ldots,\\textbf{a}_m$, and measurements $y_1,\\ldots,y_m$, which\nare related by the equation $f(\\left<\\textbf{a}_i,\\textbf{x}_*\\right>) = y_i$.\nHere, $f$ is an unknown link function satisfying a positive correlation with\nthe quadratic function. This problem was analyzed in a recent paper by Neykov,\nWang and Liu, who provided recovery guarantees for a two-stage algorithm with\nsample complexity $m = O(s^2\\log n)$. In this paper, we show that the first\nstage of their algorithm suffices for signal recovery with the same sample\ncomplexity, and extend the analysis to non-Gaussian measurements. Furthermore,\nwe show how the algorithm can be generalized to recover a signal vector\n$\\textbf{x}_*$ efficiently given geometric prior information other than\nsparsity.\n", "versions": [{"version": "v1", "created": "Tue, 12 Dec 2017 02:59:05 GMT"}, {"version": "v2", "created": "Wed, 13 Dec 2017 04:29:11 GMT"}], "update_date": "2017-12-14", "authors_parsed": [["Tan", "Yan Shuo", ""]]}, {"id": "1712.04116", "submitter": "Peixian Chen", "authors": "Peixian Chen, Zhourong Chen and Nevin L. Zhang", "title": "A Novel Document Generation Process for Topic Detection based on\n  Hierarchical Latent Tree Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel document generation process based on hierarchical latent\ntree models (HLTMs) learned from data. An HLTM has a layer of observed word\nvariables at the bottom and multiple layers of latent variables on top. For\neach document, we first sample values for the latent variables layer by layer\nvia logic sampling, then draw relative frequencies for the words conditioned on\nthe values of the latent variables, and finally generate words for the document\nusing the relative word frequencies. The motivation for the work is to take\nword counts into consideration with HLTMs. In comparison with LDA-based\nhierarchical document generation processes, the new process achieves\ndrastically better model fit with much fewer parameters. It also yields more\nmeaningful topics and topic hierarchies. It is the new state-of-the-art for the\nhierarchical topic detection.\n", "versions": [{"version": "v1", "created": "Tue, 12 Dec 2017 04:07:10 GMT"}, {"version": "v2", "created": "Wed, 13 Dec 2017 02:46:02 GMT"}, {"version": "v3", "created": "Fri, 28 Jun 2019 03:15:45 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Chen", "Peixian", ""], ["Chen", "Zhourong", ""], ["Zhang", "Nevin L.", ""]]}, {"id": "1712.04118", "submitter": "Haitao Zhao", "authors": "Haitao Zhao", "title": "Neural Component Analysis for Fault Detection", "comments": "10 pages,11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Principal component analysis (PCA) is largely adopted for chemical process\nmonitoring and numerous PCA-based systems have been developed to solve various\nfault detection and diagnosis problems. Since PCA-based methods assume that the\nmonitored process is linear, nonlinear PCA models, such as autoencoder models\nand kernel principal component analysis (KPCA), has been proposed and applied\nto nonlinear process monitoring. However, KPCA-based methods need to perform\neigen-decomposition (ED) on the kernel Gram matrix whose dimensions depend on\nthe number of training data. Moreover, prefixed kernel parameters cannot be\nmost effective for different faults which may need different parameters to\nmaximize their respective detection performances. Autoencoder models lack the\nconsideration of orthogonal constraints which is crucial for PCA-based\nalgorithms. To address these problems, this paper proposes a novel nonlinear\nmethod, called neural component analysis (NCA), which intends to train a\nfeedforward neural work with orthogonal constraints such as those used in PCA.\nNCA can adaptively learn its parameters through backpropagation and the\ndimensionality of the nonlinear features has no relationship with the number of\ntraining samples. Extensive experimental results on the Tennessee Eastman (TE)\nbenchmark process show the superiority of NCA in terms of missed detection rate\n(MDR) and false alarm rate (FAR). The source code of NCA can be found in\nhttps://github.com/haitaozhao/Neural-Component-Analysis.git.\n", "versions": [{"version": "v1", "created": "Tue, 12 Dec 2017 04:11:37 GMT"}], "update_date": "2017-12-13", "authors_parsed": [["Zhao", "Haitao", ""]]}, {"id": "1712.04120", "submitter": "Alex Lamb", "authors": "Alex Lamb, Devon Hjelm, Yaroslav Ganin, Joseph Paul Cohen, Aaron\n  Courville, Yoshua Bengio", "title": "GibbsNet: Iterative Adversarial Inference for Deep Graphical Models", "comments": "NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Directed latent variable models that formulate the joint distribution as\n$p(x,z) = p(z) p(x \\mid z)$ have the advantage of fast and exact sampling.\nHowever, these models have the weakness of needing to specify $p(z)$, often\nwith a simple fixed prior that limits the expressiveness of the model.\nUndirected latent variable models discard the requirement that $p(z)$ be\nspecified with a prior, yet sampling from them generally requires an iterative\nprocedure such as blocked Gibbs-sampling that may require many steps to draw\nsamples from the joint distribution $p(x, z)$. We propose a novel approach to\nlearning the joint distribution between the data and a latent code which uses\nan adversarially learned iterative procedure to gradually refine the joint\ndistribution, $p(x, z)$, to better match with the data distribution on each\nstep. GibbsNet is the best of both worlds both in theory and in practice.\nAchieving the speed and simplicity of a directed latent variable model, it is\nguaranteed (assuming the adversarial game reaches the virtual training criteria\nglobal minimum) to produce samples from $p(x, z)$ with only a few sampling\niterations. Achieving the expressiveness and flexibility of an undirected\nlatent variable model, GibbsNet does away with the need for an explicit $p(z)$\nand has the ability to do attribute prediction, class-conditional generation,\nand joint image-attribute modeling in a single model which is not trained for\nany of these specific tasks. We show empirically that GibbsNet is able to learn\na more complex $p(z)$ and show that this leads to improved inpainting and\niterative refinement of $p(x, z)$ for dozens of steps and stable generation\nwithout collapse for thousands of steps, despite being trained on only a few\nsteps.\n", "versions": [{"version": "v1", "created": "Tue, 12 Dec 2017 04:16:52 GMT"}], "update_date": "2017-12-13", "authors_parsed": [["Lamb", "Alex", ""], ["Hjelm", "Devon", ""], ["Ganin", "Yaroslav", ""], ["Cohen", "Joseph Paul", ""], ["Courville", "Aaron", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1712.04129", "submitter": "Utkarsh Porwal", "authors": "Utkarsh Porwal, Smruthi Mukund", "title": "Outlier Detection by Consistent Data Selection Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Often the challenge associated with tasks like fraud and spam detection[1] is\nthe lack of all likely patterns needed to train suitable supervised learning\nmodels. In order to overcome this limitation, such tasks are attempted as\noutlier or anomaly detection tasks. We also hypothesize that out- liers have\nbehavioral patterns that change over time. Limited data and continuously\nchanging patterns makes learning significantly difficult. In this work we are\nproposing an approach that detects outliers in large data sets by relying on\ndata points that are consistent. The primary contribution of this work is that\nit will quickly help retrieve samples for both consistent and non-outlier data\nsets and is also mindful of new outlier patterns. No prior knowledge of each\nset is required to extract the samples. The method consists of two phases, in\nthe first phase, consistent data points (non- outliers) are retrieved by an\nensemble method of unsupervised clustering techniques and in the second phase a\none class classifier trained on the consistent data point set is ap- plied on\nthe remaining sample set to identify the outliers. The approach is tested on\nthree publicly available data sets and the performance scores are competitive.\n", "versions": [{"version": "v1", "created": "Tue, 12 Dec 2017 04:57:40 GMT"}, {"version": "v2", "created": "Tue, 21 Aug 2018 04:37:56 GMT"}], "update_date": "2018-08-22", "authors_parsed": [["Porwal", "Utkarsh", ""], ["Mukund", "Smruthi", ""]]}, {"id": "1712.04139", "submitter": "Aydogan Ozcan", "authors": "Yair Rivenson, Hatice Ceylan Koydemir, Hongda Wang, Zhensong Wei,\n  Zhengshuang Ren, Harun Gunaydin, Yibo Zhang, Zoltan Gorocs, Kyle Liang, Derek\n  Tseng, Aydogan Ozcan", "title": "Deep learning enhanced mobile-phone microscopy", "comments": null, "journal-ref": "ACS Photonics (2018)", "doi": "10.1021/acsphotonics.8b00146", "report-no": null, "categories": "cs.LG cs.CV physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile-phones have facilitated the creation of field-portable, cost-effective\nimaging and sensing technologies that approach laboratory-grade instrument\nperformance. However, the optical imaging interfaces of mobile-phones are not\ndesigned for microscopy and produce spatial and spectral distortions in imaging\nmicroscopic specimens. Here, we report on the use of deep learning to correct\nsuch distortions introduced by mobile-phone-based microscopes, facilitating the\nproduction of high-resolution, denoised and colour-corrected images, matching\nthe performance of benchtop microscopes with high-end objective lenses, also\nextending their limited depth-of-field. After training a convolutional neural\nnetwork, we successfully imaged various samples, including blood smears,\nhistopathology tissue sections, and parasites, where the recorded images were\nhighly compressed to ease storage and transmission for telemedicine\napplications. This method is applicable to other low-cost, aberrated imaging\nsystems, and could offer alternatives for costly and bulky microscopes, while\nalso providing a framework for standardization of optical images for clinical\nand biomedical applications.\n", "versions": [{"version": "v1", "created": "Tue, 12 Dec 2017 06:03:27 GMT"}], "update_date": "2018-03-19", "authors_parsed": [["Rivenson", "Yair", ""], ["Koydemir", "Hatice Ceylan", ""], ["Wang", "Hongda", ""], ["Wei", "Zhensong", ""], ["Ren", "Zhengshuang", ""], ["Gunaydin", "Harun", ""], ["Zhang", "Yibo", ""], ["Gorocs", "Zoltan", ""], ["Liang", "Kyle", ""], ["Tseng", "Derek", ""], ["Ozcan", "Aydogan", ""]]}, {"id": "1712.04143", "submitter": "Boyi Li", "authors": "Boyi Li and Wenqi Ren and Dengpan Fu and Dacheng Tao and Dan Feng and\n  Wenjun Zeng and Zhangyang Wang", "title": "Benchmarking Single Image Dehazing and Beyond", "comments": "IEEE Transactions on Image Processing(TIP 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a comprehensive study and evaluation of existing single image\ndehazing algorithms, using a new large-scale benchmark consisting of both\nsynthetic and real-world hazy images, called REalistic Single Image DEhazing\n(RESIDE). RESIDE highlights diverse data sources and image contents, and is\ndivided into five subsets, each serving different training or evaluation\npurposes. We further provide a rich variety of criteria for dehazing algorithm\nevaluation, ranging from full-reference metrics, to no-reference metrics, to\nsubjective evaluation and the novel task-driven evaluation. Experiments on\nRESIDE shed light on the comparisons and limitations of state-of-the-art\ndehazing algorithms, and suggest promising future directions.\n", "versions": [{"version": "v1", "created": "Tue, 12 Dec 2017 06:33:20 GMT"}, {"version": "v2", "created": "Fri, 6 Apr 2018 13:27:35 GMT"}, {"version": "v3", "created": "Mon, 27 Aug 2018 14:33:39 GMT"}, {"version": "v4", "created": "Mon, 22 Apr 2019 00:13:07 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Li", "Boyi", ""], ["Ren", "Wenqi", ""], ["Fu", "Dengpan", ""], ["Tao", "Dacheng", ""], ["Feng", "Dan", ""], ["Zeng", "Wenjun", ""], ["Wang", "Zhangyang", ""]]}, {"id": "1712.04145", "submitter": "Sho Sonoda", "authors": "Sho Sonoda, Noboru Murata", "title": "Transportation analysis of denoising autoencoders: a novel method for\n  analyzing deep neural networks", "comments": "Accepted at NIPS 2017 workshop on Optimal Transport & Machine\n  Learning (OTML2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The feature map obtained from the denoising autoencoder (DAE) is investigated\nby determining transportation dynamics of the DAE, which is a cornerstone for\ndeep learning. Despite the rapid development in its application, deep neural\nnetworks remain analytically unexplained, because the feature maps are nested\nand parameters are not faithful. In this paper, we address the problem of the\nformulation of nested complex of parameters by regarding the feature map as a\ntransport map. Even when a feature map has different dimensions between input\nand output, we can regard it as a transportation map by considering that both\nthe input and output spaces are embedded in a common high-dimensional space. In\naddition, the trajectory is a geometric object and thus, is independent of\nparameterization. In this manner, transportation can be regarded as a universal\ncharacter of deep neural networks. By determining and analyzing the\ntransportation dynamics, we can understand the behavior of a deep neural\nnetwork. In this paper, we investigate a fundamental case of deep neural\nnetworks: the DAE. We derive the transport map of the DAE, and reveal that the\ninfinitely deep DAE transports mass to decrease a certain quantity, such as\nentropy, of the data distribution. These results though analytically simple,\nshed light on the correspondence between deep neural networks and the\nWasserstein gradient flows.\n", "versions": [{"version": "v1", "created": "Tue, 12 Dec 2017 06:37:28 GMT"}], "update_date": "2017-12-13", "authors_parsed": [["Sonoda", "Sho", ""], ["Murata", "Noboru", ""]]}, {"id": "1712.04165", "submitter": "Irene Teinemaa", "authors": "Irene Teinemaa, Marlon Dumas, Anna Leontjeva, Fabrizio Maria Maggi", "title": "Temporal Stability in Predictive Process Monitoring", "comments": null, "journal-ref": "Data Min Knowl Disc (2018) 32: 1306", "doi": "10.1007/s10618-018-0575-9", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictive process monitoring is concerned with the analysis of events\nproduced during the execution of a business process in order to predict as\nearly as possible the final outcome of an ongoing case. Traditionally,\npredictive process monitoring methods are optimized with respect to accuracy.\nHowever, in environments where users make decisions and take actions in\nresponse to the predictions they receive, it is equally important to optimize\nthe stability of the successive predictions made for each case. To this end,\nthis paper defines a notion of temporal stability for binary classification\ntasks in predictive process monitoring and evaluates existing methods with\nrespect to both temporal stability and accuracy. We find that methods based on\nXGBoost and LSTM neural networks exhibit the highest temporal stability. We\nthen show that temporal stability can be enhanced by hyperparameter-optimizing\nrandom forests and XGBoost classifiers with respect to inter-run stability.\nFinally, we show that time series smoothing techniques can further enhance\ntemporal stability at the expense of slightly lower accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 12 Dec 2017 08:20:56 GMT"}, {"version": "v2", "created": "Mon, 23 Apr 2018 06:30:37 GMT"}, {"version": "v3", "created": "Fri, 15 Jun 2018 06:42:42 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Teinemaa", "Irene", ""], ["Dumas", "Marlon", ""], ["Leontjeva", "Anna", ""], ["Maggi", "Fabrizio Maria", ""]]}, {"id": "1712.04195", "submitter": "Yoshihiro Nagano", "authors": "Yoshihiro Nagano, Ryo Karakida and Masato Okada", "title": "Concept Formation and Dynamics of Repeated Inference in Deep Generative\n  Models", "comments": "20 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative models are reported to be useful in broad applications\nincluding image generation. Repeated inference between data space and latent\nspace in these models can denoise cluttered images and improve the quality of\ninferred results. However, previous studies only qualitatively evaluated image\noutputs in data space, and the mechanism behind the inference has not been\ninvestigated. The purpose of the current study is to numerically analyze\nchanges in activity patterns of neurons in the latent space of a deep\ngenerative model called a \"variational auto-encoder\" (VAE). What kinds of\ninference dynamics the VAE demonstrates when noise is added to the input data\nare identified. The VAE embeds a dataset with clear cluster structures in the\nlatent space and the center of each cluster of multiple correlated data points\n(memories) is referred as the concept. Our study demonstrated that transient\ndynamics of inference first approaches a concept, and then moves close to a\nmemory. Moreover, the VAE revealed that the inference dynamics approaches a\nmore abstract concept to the extent that the uncertainty of input data\nincreases due to noise. It was demonstrated that by increasing the number of\nthe latent variables, the trend of the inference dynamics to approach a concept\ncan be enhanced, and the generalization ability of the VAE can be improved.\n", "versions": [{"version": "v1", "created": "Tue, 12 Dec 2017 09:55:11 GMT"}], "update_date": "2017-12-13", "authors_parsed": [["Nagano", "Yoshihiro", ""], ["Karakida", "Ryo", ""], ["Okada", "Masato", ""]]}, {"id": "1712.04196", "submitter": "Deena P. Francis", "authors": "Deena P. Francis and Kumudha Raimond", "title": "Empirical Evaluation of Kernel PCA Approximation Methods in\n  Classification Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernel Principal Component Analysis (KPCA) is a popular dimensionality\nreduction technique with a wide range of applications. However, it suffers from\nthe problem of poor scalability. Various approximation methods have been\nproposed in the past to overcome this problem. The Nystr\\\"om method, Randomized\nNonlinear Component Analysis (RNCA) and Streaming Kernel Principal Component\nAnalysis (SKPCA) were proposed to deal with the scalability issue of KPCA.\nDespite having theoretical guarantees, their performance in real world learning\ntasks have not been explored previously. In this work the evaluation of SKPCA,\nRNCA and Nystr\\\"om method for the task of classification is done for several\nreal world datasets. The results obtained indicate that SKPCA based features\ngave much better classification accuracy when compared to the other methods for\na very large dataset.\n", "versions": [{"version": "v1", "created": "Tue, 12 Dec 2017 10:02:08 GMT"}], "update_date": "2017-12-13", "authors_parsed": [["Francis", "Deena P.", ""], ["Raimond", "Kumudha", ""]]}, {"id": "1712.04248", "submitter": "Jonas Rauber", "authors": "Wieland Brendel, Jonas Rauber, Matthias Bethge", "title": "Decision-Based Adversarial Attacks: Reliable Attacks Against Black-Box\n  Machine Learning Models", "comments": "Published as a conference paper at the Sixth International Conference\n  on Learning Representations (ICLR 2018)\n  https://openreview.net/forum?id=SyZI0GWCZ", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many machine learning algorithms are vulnerable to almost imperceptible\nperturbations of their inputs. So far it was unclear how much risk adversarial\nperturbations carry for the safety of real-world machine learning applications\nbecause most methods used to generate such perturbations rely either on\ndetailed model information (gradient-based attacks) or on confidence scores\nsuch as class probabilities (score-based attacks), neither of which are\navailable in most real-world scenarios. In many such cases one currently needs\nto retreat to transfer-based attacks which rely on cumbersome substitute\nmodels, need access to the training data and can be defended against. Here we\nemphasise the importance of attacks which solely rely on the final model\ndecision. Such decision-based attacks are (1) applicable to real-world\nblack-box models such as autonomous cars, (2) need less knowledge and are\neasier to apply than transfer-based attacks and (3) are more robust to simple\ndefences than gradient- or score-based attacks. Previous attacks in this\ncategory were limited to simple models or simple datasets. Here we introduce\nthe Boundary Attack, a decision-based attack that starts from a large\nadversarial perturbation and then seeks to reduce the perturbation while\nstaying adversarial. The attack is conceptually simple, requires close to no\nhyperparameter tuning, does not rely on substitute models and is competitive\nwith the best gradient-based attacks in standard computer vision tasks like\nImageNet. We apply the attack on two black-box algorithms from Clarifai.com.\nThe Boundary Attack in particular and the class of decision-based attacks in\ngeneral open new avenues to study the robustness of machine learning models and\nraise new questions regarding the safety of deployed machine learning systems.\nAn implementation of the attack is available as part of Foolbox at\nhttps://github.com/bethgelab/foolbox .\n", "versions": [{"version": "v1", "created": "Tue, 12 Dec 2017 11:36:26 GMT"}, {"version": "v2", "created": "Fri, 16 Feb 2018 14:40:42 GMT"}], "update_date": "2018-02-19", "authors_parsed": [["Brendel", "Wieland", ""], ["Rauber", "Jonas", ""], ["Bethge", "Matthias", ""]]}, {"id": "1712.04301", "submitter": "Mehdi Mohammadi", "authors": "Mehdi Mohammadi, Ala Al-Fuqaha, Sameh Sorour, and Mohsen Guizani", "title": "Deep Learning for IoT Big Data and Streaming Analytics: A Survey", "comments": "40 pages, Accepted at IEEE Communications Surveys and Tutorials\n  Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the era of the Internet of Things (IoT), an enormous amount of sensing\ndevices collect and/or generate various sensory data over time for a wide range\nof fields and applications. Based on the nature of the application, these\ndevices will result in big or fast/real-time data streams. Applying analytics\nover such data streams to discover new information, predict future insights,\nand make control decisions is a crucial process that makes IoT a worthy\nparadigm for businesses and a quality-of-life improving technology. In this\npaper, we provide a thorough overview on using a class of advanced machine\nlearning techniques, namely Deep Learning (DL), to facilitate the analytics and\nlearning in the IoT domain. We start by articulating IoT data characteristics\nand identifying two major treatments for IoT data from a machine learning\nperspective, namely IoT big data analytics and IoT streaming data analytics. We\nalso discuss why DL is a promising approach to achieve the desired analytics in\nthese types of data and applications. The potential of using emerging DL\ntechniques for IoT data analytics are then discussed, and its promises and\nchallenges are introduced. We present a comprehensive background on different\nDL architectures and algorithms. We also analyze and summarize major reported\nresearch attempts that leveraged DL in the IoT domain. The smart IoT devices\nthat have incorporated DL in their intelligence background are also discussed.\nDL implementation approaches on the fog and cloud centers in support of IoT\napplications are also surveyed. Finally, we shed light on some challenges and\npotential directions for future research. At the end of each section, we\nhighlight the lessons learned based on our experiments and review of the recent\nliterature.\n", "versions": [{"version": "v1", "created": "Sat, 9 Dec 2017 06:13:43 GMT"}, {"version": "v2", "created": "Tue, 5 Jun 2018 03:30:38 GMT"}], "update_date": "2018-06-06", "authors_parsed": [["Mohammadi", "Mehdi", ""], ["Al-Fuqaha", "Ala", ""], ["Sorour", "Sameh", ""], ["Guizani", "Mohsen", ""]]}, {"id": "1712.04314", "submitter": "Yuri G. Gordienko", "authors": "Serhii Hamotskyi, Sergii Stirenko, Yuri Gordienko, Anis Rojbi", "title": "Generating and Estimating Nonverbal Alphabets for Situated and\n  Multimodal Communications", "comments": "5 pages, 5 figures", "journal-ref": "International Journal of Systems Applications Engineering and\n  Development, 11, 232-236 (2017)", "doi": null, "report-no": null, "categories": "cs.HC cs.CL cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we discuss the formalized approach for generating and\nestimating symbols (and alphabets), which can be communicated by the wide range\nof non-verbal means based on specific user requirements (medium, priorities,\ntype of information that needs to be conveyed). The short characterization of\nbasic terms and parameters of such symbols (and alphabets) with approaches to\ngenerate them are given. Then the framework, experimental setup, and some\nmachine learning methods to estimate usefulness and effectiveness of the\nnonverbal alphabets and systems are presented. The previous results demonstrate\nthat usage of multimodal data sources (like wearable accelerometer, heart\nmonitor, muscle movements sensors, braincomputer interface) along with machine\nlearning approaches can provide the deeper understanding of the usefulness and\neffectiveness of such alphabets and systems for nonverbal and situated\ncommunication. The symbols (and alphabets) generated and estimated by such\nmethods may be useful in various applications: from synthetic languages and\nconstructed scripts to multimodal nonverbal and situated interaction between\npeople and artificial intelligence systems through Human-Computer Interfaces,\nsuch as mouse gestures, touchpads, body gestures, eyetracking cameras,\nwearables, and brain-computing interfaces, especially in applications for\nelderly care and people with disabilities.\n", "versions": [{"version": "v1", "created": "Tue, 12 Dec 2017 14:38:34 GMT"}], "update_date": "2017-12-13", "authors_parsed": [["Hamotskyi", "Serhii", ""], ["Stirenko", "Sergii", ""], ["Gordienko", "Yuri", ""], ["Rojbi", "Anis", ""]]}, {"id": "1712.04323", "submitter": "Claudio Gallicchio", "authors": "Claudio Gallicchio and Alessio Micheli", "title": "Deep Echo State Network (DeepESN): A Brief Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study of deep recurrent neural networks (RNNs) and, in particular, of\ndeep Reservoir Computing (RC) is gaining an increasing research attention in\nthe neural networks community. The recently introduced Deep Echo State Network\n(DeepESN) model opened the way to an extremely efficient approach for designing\ndeep neural networks for temporal data. At the same time, the study of DeepESNs\nallowed to shed light on the intrinsic properties of state dynamics developed\nby hierarchical compositions of recurrent layers, i.e. on the bias of depth in\nRNNs architectural design. In this paper, we summarize the advancements in the\ndevelopment, analysis and applications of DeepESNs.\n", "versions": [{"version": "v1", "created": "Tue, 12 Dec 2017 14:50:51 GMT"}, {"version": "v2", "created": "Mon, 1 Oct 2018 14:01:34 GMT"}, {"version": "v3", "created": "Mon, 25 Feb 2019 19:59:13 GMT"}, {"version": "v4", "created": "Fri, 25 Sep 2020 17:53:57 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Gallicchio", "Claudio", ""], ["Micheli", "Alessio", ""]]}, {"id": "1712.04332", "submitter": "Yue Lu", "authors": "Chuang Wang, Jonathan Mattingly, and Yue M. Lu", "title": "Scaling Limit: Exact and Tractable Analysis of Online Learning\n  Algorithms with Applications to Regularized Regression and PCA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a framework for analyzing the exact dynamics of a class of online\nlearning algorithms in the high-dimensional scaling limit. Our results are\napplied to two concrete examples: online regularized linear regression and\nprincipal component analysis. As the ambient dimension tends to infinity, and\nwith proper time scaling, we show that the time-varying joint empirical\nmeasures of the target feature vector and its estimates provided by the\nalgorithms will converge weakly to a deterministic measured-valued process that\ncan be characterized as the unique solution of a nonlinear PDE. Numerical\nsolutions of this PDE can be efficiently obtained. These solutions lead to\nprecise predictions of the performance of the algorithms, as many practical\nperformance metrics are linear functionals of the joint empirical measures. In\naddition to characterizing the dynamic performance of online learning\nalgorithms, our asymptotic analysis also provides useful insights. In\nparticular, in the high-dimensional limit, and due to exchangeability, the\noriginal coupled dynamics associated with the algorithms will be asymptotically\n\"decoupled\", with each coordinate independently solving a 1-D effective\nminimization problem via stochastic gradient descent. Exploiting this insight\nfor nonconvex optimization problems may prove an interesting line of future\nresearch.\n", "versions": [{"version": "v1", "created": "Fri, 8 Dec 2017 00:20:18 GMT"}], "update_date": "2017-12-13", "authors_parsed": [["Wang", "Chuang", ""], ["Mattingly", "Jonathan", ""], ["Lu", "Yue M.", ""]]}, {"id": "1712.04337", "submitter": "Alexandre Hollocou", "authors": "Alexandre Hollocou, Julien Maudet, Thomas Bonald, Marc Lelarge", "title": "A Streaming Algorithm for Graph Clustering", "comments": "NIPS Wokshop on Advances in Modeling and Learning Interactions from\n  Complex Data, 2017. arXiv admin note: substantial text overlap with\n  arXiv:1703.02955", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel algorithm to perform graph clustering in the edge\nstreaming setting. In this model, the graph is presented as a sequence of edges\nthat can be processed strictly once. Our streaming algorithm has an extremely\nlow memory footprint as it stores only three integers per node and does not\nkeep any edge in memory. We provide a theoretical justification of the design\nof the algorithm based on the modularity function, which is a usual metric to\nevaluate the quality of a graph partition. We perform experiments on massive\nreal-life graphs ranging from one million to more than one billion edges and we\nshow that this new algorithm runs more than ten times faster than existing\nalgorithms and leads to similar or better detection scores on the largest\ngraphs.\n", "versions": [{"version": "v1", "created": "Sat, 9 Dec 2017 14:32:44 GMT"}], "update_date": "2017-12-13", "authors_parsed": [["Hollocou", "Alexandre", ""], ["Maudet", "Julien", ""], ["Bonald", "Thomas", ""], ["Lelarge", "Marc", ""]]}, {"id": "1712.04350", "submitter": "Luis Perez", "authors": "Luis Perez", "title": "Predicting Yelp Star Reviews Based on Network Structure with Deep\n  Learning", "comments": "10 pages, 17 figures, manuscript", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we tackle the real-world problem of predicting Yelp\nstar-review rating based on business features (such as images, descriptions),\nuser features (average previous ratings), and, of particular interest, network\nproperties (which businesses has a user rated before). We compare multiple\nmodels on different sets of features -- from simple linear regression on\nnetwork features only to deep learning models on network and item features.\n  In recent years, breakthroughs in deep learning have led to increased\naccuracy in common supervised learning tasks, such as image classification,\ncaptioning, and language understanding. However, the idea of combining deep\nlearning with network feature and structure appears to be novel. While the\nproblem of predicting future interactions in a network has been studied at\nlength, these approaches have often ignored either node-specific data or global\nstructure.\n  We demonstrate that taking a mixed approach combining both node-level\nfeatures and network information can effectively be used to predict Yelp-review\nstar ratings. We evaluate on the Yelp dataset by splitting our data along the\ntime dimension (as would naturally occur in the real-world) and comparing our\nmodel against others which do no take advantage of the network structure and/or\ndeep learning.\n", "versions": [{"version": "v1", "created": "Mon, 11 Dec 2017 18:54:23 GMT"}], "update_date": "2017-12-13", "authors_parsed": [["Perez", "Luis", ""]]}, {"id": "1712.04356", "submitter": "Farshid Rayhan", "authors": "Farshid Rayhan, Sajid Ahmed, Asif Mahbub, Md. Rafsan Jani, Swakkhar\n  Shatabda, and Dewan Md. Farid", "title": "CUSBoost: Cluster-based Under-sampling with Boosting for Imbalanced\n  Classification", "comments": "CSITSS-2017", "journal-ref": null, "doi": "10.1109/CSITSS.2017.8447534", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Class imbalance classification is a challenging research problem in data\nmining and machine learning, as most of the real-life datasets are often\nimbalanced in nature. Existing learning algorithms maximise the classification\naccuracy by correctly classifying the majority class, but misclassify the\nminority class. However, the minority class instances are representing the\nconcept with greater interest than the majority class instances in real-life\napplications. Recently, several techniques based on sampling methods\n(under-sampling of the majority class and over-sampling the minority class),\ncost-sensitive learning methods, and ensemble learning have been used in the\nliterature for classifying imbalanced datasets. In this paper, we introduce a\nnew clustering-based under-sampling approach with boosting (AdaBoost)\nalgorithm, called CUSBoost, for effective imbalanced classification. The\nproposed algorithm provides an alternative to RUSBoost (random under-sampling\nwith AdaBoost) and SMOTEBoost (synthetic minority over-sampling with AdaBoost)\nalgorithms. We evaluated the performance of CUSBoost algorithm with the\nstate-of-the-art methods based on ensemble learning like AdaBoost, RUSBoost,\nSMOTEBoost on 13 imbalance binary and multi-class datasets with various\nimbalance ratios. The experimental results show that the CUSBoost is a\npromising and effective approach for dealing with highly imbalanced datasets.\n", "versions": [{"version": "v1", "created": "Tue, 12 Dec 2017 15:33:26 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Rayhan", "Farshid", ""], ["Ahmed", "Sajid", ""], ["Mahbub", "Asif", ""], ["Jani", "Md. Rafsan", ""], ["Shatabda", "Swakkhar", ""], ["Farid", "Dewan Md.", ""]]}, {"id": "1712.04371", "submitter": "Jean-Pierre Briot", "authors": "Jean-Pierre Briot and Fran\\c{c}ois Pachet", "title": "Music Generation by Deep Learning - Challenges and Directions", "comments": "17 pages. arXiv admin note: substantial text overlap with\n  arXiv:1709.01620. Accepted for publication in Special Issue on Deep learning\n  for music and audio, Neural Computing & Applications, Springer Nature, 2018", "journal-ref": null, "doi": "10.1007/s00521-018-3813-6", "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In addition to traditional tasks such as prediction, classification and\ntranslation, deep learning is receiving growing attention as an approach for\nmusic generation, as witnessed by recent research groups such as Magenta at\nGoogle and CTRL (Creator Technology Research Lab) at Spotify. The motivation is\nin using the capacity of deep learning architectures and training techniques to\nautomatically learn musical styles from arbitrary musical corpora and then to\ngenerate samples from the estimated distribution. However, a direct application\nof deep learning to generate content rapidly reaches limits as the generated\ncontent tends to mimic the training set without exhibiting true creativity.\nMoreover, deep learning architectures do not offer direct ways for controlling\ngeneration (e.g., imposing some tonality or other arbitrary constraints).\nFurthermore, deep learning architectures alone are autistic automata which\ngenerate music autonomously without human user interaction, far from the\nobjective of interactively assisting musicians to compose and refine music.\nIssues such as: control, structure, creativity and interactivity are the focus\nof our analysis. In this paper, we select some limitations of a direct\napplication of deep learning to music generation, analyze why the issues are\nnot fulfilled and how to address them by possible approaches. Various examples\nof recent systems are cited as examples of promising directions.\n", "versions": [{"version": "v1", "created": "Sat, 9 Dec 2017 14:57:47 GMT"}, {"version": "v2", "created": "Sun, 30 Sep 2018 15:06:19 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Briot", "Jean-Pierre", ""], ["Pachet", "Fran\u00e7ois", ""]]}, {"id": "1712.04407", "submitter": "Alexander Sage", "authors": "Alexander Sage, Eirikur Agustsson, Radu Timofte, Luc Van Gool", "title": "Logo Synthesis and Manipulation with Clustered Generative Adversarial\n  Networks", "comments": null, "journal-ref": null, "doi": "10.1109/CVPR.2018.00616", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing a logo for a new brand is a lengthy and tedious back-and-forth\nprocess between a designer and a client. In this paper we explore to what\nextent machine learning can solve the creative task of the designer. For this,\nwe build a dataset -- LLD -- of 600k+ logos crawled from the world wide web.\nTraining Generative Adversarial Networks (GANs) for logo synthesis on such\nmulti-modal data is not straightforward and results in mode collapse for some\nstate-of-the-art methods. We propose the use of synthetic labels obtained\nthrough clustering to disentangle and stabilize GAN training. We are able to\ngenerate a high diversity of plausible logos and we demonstrate latent space\nexploration techniques to ease the logo design task in an interactive manner.\nMoreover, we validate the proposed clustered GAN training on CIFAR 10,\nachieving state-of-the-art Inception scores when using synthetic labels\nobtained via clustering the features of an ImageNet classifier. GANs can cope\nwith multi-modal data by means of synthetic labels achieved through clustering,\nand our results show the creative potential of such techniques for logo\nsynthesis and manipulation. Our dataset and models will be made publicly\navailable at https://data.vision.ee.ethz.ch/cvl/lld/.\n", "versions": [{"version": "v1", "created": "Tue, 12 Dec 2017 17:51:23 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Sage", "Alexander", ""], ["Agustsson", "Eirikur", ""], ["Timofte", "Radu", ""], ["Van Gool", "Luc", ""]]}, {"id": "1712.04432", "submitter": "Aydin Buluc", "authors": "Amir Gholami, Ariful Azad, Peter Jin, Kurt Keutzer, Aydin Buluc", "title": "Integrated Model, Batch and Domain Parallelism in Training Neural\n  Networks", "comments": "11 pages", "journal-ref": "30th ACM Symposium on Parallelism in Algorithms and Architectures\n  (SPAA), 2018", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new integrated method of exploiting model, batch and domain\nparallelism for the training of deep neural networks (DNNs) on large\ndistributed-memory computers using minibatch stochastic gradient descent (SGD).\nOur goal is to find an efficient parallelization strategy for a fixed batch\nsize using $P$ processes. Our method is inspired by the communication-avoiding\nalgorithms in numerical linear algebra. We see $P$ processes as logically\ndivided into a $P_r \\times P_c$ grid where the $P_r$ dimension is implicitly\nresponsible for model/domain parallelism and the $P_c$ dimension is implicitly\nresponsible for batch parallelism. In practice, the integrated matrix-based\nparallel algorithm encapsulates these types of parallelism automatically. We\nanalyze the communication complexity and analytically demonstrate that the\nlowest communication costs are often achieved neither with pure model nor with\npure data parallelism. We also show how the domain parallel approach can help\nin extending the theoretical scaling limit of the typical batch parallel\nmethod.\n", "versions": [{"version": "v1", "created": "Tue, 12 Dec 2017 18:42:07 GMT"}, {"version": "v2", "created": "Thu, 4 Jan 2018 22:32:40 GMT"}, {"version": "v3", "created": "Wed, 14 Feb 2018 17:52:25 GMT"}, {"version": "v4", "created": "Wed, 16 May 2018 04:38:31 GMT"}], "update_date": "2018-05-17", "authors_parsed": [["Gholami", "Amir", ""], ["Azad", "Ariful", ""], ["Jin", "Peter", ""], ["Keutzer", "Kurt", ""], ["Buluc", "Aydin", ""]]}, {"id": "1712.04443", "submitter": "Bo Wu", "authors": "Bo Wu, Wen-Huang Cheng, Yongdong Zhang, Qiushi Huang, Jintao Li, Tao\n  Mei", "title": "Sequential Prediction of Social Media Popularity with Deep Temporal\n  Context Networks", "comments": "accepted in IJCAI-17", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prediction of popularity has profound impact for social media, since it\noffers opportunities to reveal individual preference and public attention from\nevolutionary social systems. Previous research, although achieves promising\nresults, neglects one distinctive characteristic of social data, i.e.,\nsequentiality. For example, the popularity of online content is generated over\ntime with sequential post streams of social media. To investigate the\nsequential prediction of popularity, we propose a novel prediction framework\ncalled Deep Temporal Context Networks (DTCN) by incorporating both temporal\ncontext and temporal attention into account. Our DTCN contains three main\ncomponents, from embedding, learning to predicting. With a joint embedding\nnetwork, we obtain a unified deep representation of multi-modal user-post data\nin a common embedding space. Then, based on the embedded data sequence over\ntime, temporal context learning attempts to recurrently learn two adaptive\ntemporal contexts for sequential popularity. Finally, a novel temporal\nattention is designed to predict new popularity (the popularity of a new\nuser-post pair) with temporal coherence across multiple time-scales.\nExperiments on our released image dataset with about 600K Flickr photos\ndemonstrate that DTCN outperforms state-of-the-art deep prediction algorithms,\nwith an average of 21.51% relative performance improvement in the popularity\nprediction (Spearman Ranking Correlation).\n", "versions": [{"version": "v1", "created": "Tue, 12 Dec 2017 05:28:12 GMT"}], "update_date": "2017-12-14", "authors_parsed": [["Wu", "Bo", ""], ["Cheng", "Wen-Huang", ""], ["Zhang", "Yongdong", ""], ["Huang", "Qiushi", ""], ["Li", "Jintao", ""], ["Mei", "Tao", ""]]}, {"id": "1712.04493", "submitter": "Farshad Harirchi", "authors": "Farshad Harirchi, Omar A. Khalil, Sijia Liu, Paolo Elvati, Angela\n  Violi, Alfred O. Hero", "title": "A Data-Driven Sparse-Learning Approach to Model Reduction in Chemical\n  Reaction Networks", "comments": "The paper is presented at NIPS workshop on Advances in Modeling and\n  Learning Interactions from Complex Data", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an optimization-based sparse learning approach to\nidentify the set of most influential reactions in a chemical reaction network.\nThis reduced set of reactions is then employed to construct a reduced chemical\nreaction mechanism, which is relevant to chemical interaction network modeling.\nThe problem of identifying influential reactions is first formulated as a\nmixed-integer quadratic program, and then a relaxation method is leveraged to\nreduce the computational complexity of our approach. Qualitative and\nquantitative validation of the sparse encoding approach demonstrates that the\nmodel captures important network structural properties with moderate\ncomputational load.\n", "versions": [{"version": "v1", "created": "Tue, 12 Dec 2017 20:13:49 GMT"}], "update_date": "2017-12-14", "authors_parsed": [["Harirchi", "Farshad", ""], ["Khalil", "Omar A.", ""], ["Liu", "Sijia", ""], ["Elvati", "Paolo", ""], ["Violi", "Angela", ""], ["Hero", "Alfred O.", ""]]}, {"id": "1712.04567", "submitter": "Michael McCourt", "authors": "Ruben Martinez-Cantin, Kevin Tee, Michael McCourt", "title": "Practical Bayesian optimization in the presence of outliers", "comments": "10 pages (2 of references), 6 figures, 1 algorithm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inference in the presence of outliers is an important field of research as\noutliers are ubiquitous and may arise across a variety of problems and domains.\nBayesian optimization is method that heavily relies on probabilistic inference.\nThis allows outstanding sample efficiency because the probabilistic machinery\nprovides a memory of the whole optimization process. However, that virtue\nbecomes a disadvantage when the memory is populated with outliers, inducing\nbias in the estimation. In this paper, we present an empirical evaluation of\nBayesian optimization methods in the presence of outliers. The empirical\nevidence shows that Bayesian optimization with robust regression often produces\nsuboptimal results. We then propose a new algorithm which combines robust\nregression (a Gaussian process with Student-t likelihood) with outlier\ndiagnostics to classify data points as outliers or inliers. By using an\nscheduler for the classification of outliers, our method is more efficient and\nhas better convergence over the standard robust regression. Furthermore, we\nshow that even in controlled situations with no expected outliers, our method\nis able to produce better results.\n", "versions": [{"version": "v1", "created": "Tue, 12 Dec 2017 23:31:45 GMT"}], "update_date": "2017-12-14", "authors_parsed": [["Martinez-Cantin", "Ruben", ""], ["Tee", "Kevin", ""], ["McCourt", "Michael", ""]]}, {"id": "1712.04577", "submitter": "Ashish Khetan", "authors": "Ashish Khetan, Zachary C. Lipton, Anima Anandkumar", "title": "Learning From Noisy Singly-labeled Data", "comments": "18 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised learning depends on annotated examples, which are taken to be the\n\\emph{ground truth}. But these labels often come from noisy crowdsourcing\nplatforms, like Amazon Mechanical Turk. Practitioners typically collect\nmultiple labels per example and aggregate the results to mitigate noise (the\nclassic crowdsourcing problem). Given a fixed annotation budget and unlimited\nunlabeled data, redundant annotation comes at the expense of fewer labeled\nexamples. This raises two fundamental questions: (1) How can we best learn from\nnoisy workers? (2) How should we allocate our labeling budget to maximize the\nperformance of a classifier? We propose a new algorithm for jointly modeling\nlabels and worker quality from noisy crowd-sourced data. The alternating\nminimization proceeds in rounds, estimating worker quality from disagreement\nwith the current model and then updating the model by optimizing a loss\nfunction that accounts for the current estimate of worker quality. Unlike\nprevious approaches, even with only one annotation per example, our algorithm\ncan estimate worker quality. We establish a generalization error bound for\nmodels learned with our algorithm and establish theoretically that it's better\nto label many examples once (vs less multiply) when worker quality is above a\nthreshold. Experiments conducted on both ImageNet (with simulated noisy\nworkers) and MS-COCO (using the real crowdsourced labels) confirm our\nalgorithm's benefits.\n", "versions": [{"version": "v1", "created": "Wed, 13 Dec 2017 00:23:10 GMT"}, {"version": "v2", "created": "Sun, 20 May 2018 06:17:50 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Khetan", "Ashish", ""], ["Lipton", "Zachary C.", ""], ["Anandkumar", "Anima", ""]]}, {"id": "1712.04578", "submitter": "Timothy O'Shea", "authors": "Timothy J. O'Shea, Tamoghna Roy, T. Charles Clancy", "title": "Over the Air Deep Learning Based Radio Signal Classification", "comments": "13 pages, 22 figures", "journal-ref": null, "doi": "10.1109/JSTSP.2018.2797022", "report-no": null, "categories": "cs.LG eess.SP", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We conduct an in depth study on the performance of deep learning based radio\nsignal classification for radio communications signals. We consider a rigorous\nbaseline method using higher order moments and strong boosted gradient tree\nclassification and compare performance between the two approaches across a\nrange of configurations and channel impairments. We consider the effects of\ncarrier frequency offset, symbol rate, and multi-path fading in simulation and\nconduct over-the-air measurement of radio classification performance in the lab\nusing software radios and compare performance and training strategies for both.\nFinally we conclude with a discussion of remaining problems, and design\nconsiderations for using such techniques.\n", "versions": [{"version": "v1", "created": "Wed, 13 Dec 2017 00:24:26 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["O'Shea", "Timothy J.", ""], ["Roy", "Tamoghna", ""], ["Clancy", "T. Charles", ""]]}, {"id": "1712.04581", "submitter": "Nikhil Bansal", "authors": "Nikhil Bansal and Anupam Gupta", "title": "Potential-Function Proofs for First-Order Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This note discusses proofs for convergence of first-order methods based on\nsimple potential-function arguments. We cover methods like gradient descent\n(for both smooth and non-smooth settings), mirror descent, and some accelerated\nvariants.\n", "versions": [{"version": "v1", "created": "Wed, 13 Dec 2017 01:10:13 GMT"}, {"version": "v2", "created": "Thu, 7 Mar 2019 21:55:56 GMT"}, {"version": "v3", "created": "Sun, 2 Jun 2019 19:36:25 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Bansal", "Nikhil", ""], ["Gupta", "Anupam", ""]]}, {"id": "1712.04602", "submitter": "David Schwartz M", "authors": "David M. Schwartz and O. Ozan Koyluoglu", "title": "On the organization of grid and place cells: Neural de-noising via\n  subspace learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.IT cs.LG cs.NE math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Place cells in the hippocampus are active when an animal visits a certain\nlocation (referred to as a place field) within an environment. Grid cells in\nthe medial entorhinal cortex (MEC) respond at multiple locations, with firing\nfields that form a periodic and hexagonal tiling of the environment. The joint\nactivity of grid and place cell populations, as a function of location, forms a\nneural code for space. An ensemble of codes is generated by varying grid and\nplace cell population parameters. For each code in this ensemble, codewords are\ngenerated by stimulating a network with a discrete set of locations. In this\nmanuscript, we develop an understanding of the relationships between coding\ntheoretic properties of these combined populations and code construction\nparameters. These relationships are revisited by measuring the performances of\nbiologically realizable algorithms implemented by networks of place and grid\ncell populations, as well as constraint neurons, which perform de-noising\noperations. Objectives of this work include the investigation of coding\ntheoretic limitations of the mammalian neural code for location and how\ncommunication between grid and place cell networks may improve the accuracy of\neach population's representation. Simulations demonstrate that de-noising\nmechanisms analyzed here can significantly improve fidelity of this neural\nrepresentation of space. Further, patterns observed in connectivity of each\npopulation of simulated cells suggest that\ninter-hippocampal-medial-entorhinal-cortical connectivity decreases downward\nalong the dorsoventral axis.\n", "versions": [{"version": "v1", "created": "Wed, 13 Dec 2017 03:48:27 GMT"}, {"version": "v2", "created": "Tue, 15 May 2018 21:07:55 GMT"}], "update_date": "2018-05-17", "authors_parsed": [["Schwartz", "David M.", ""], ["Koyluoglu", "O. Ozan", ""]]}, {"id": "1712.04603", "submitter": "Jinyoung Choi", "authors": "Jinyoung Choi, Beom-Jin Lee, and Byoung-Tak Zhang", "title": "Multi-focus Attention Network for Efficient Deep Reinforcement Learning", "comments": "AAAI 2017 Workshop on What's next for AI in games (WNAIG 2017), 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (DRL) has shown incredible performance in\nlearning various tasks to the human level. However, unlike human perception,\ncurrent DRL models connect the entire low-level sensory input to the\nstate-action values rather than exploiting the relationship between and among\nentities that constitute the sensory input. Because of this difference, DRL\nneeds vast amount of experience samples to learn. In this paper, we propose a\nMulti-focus Attention Network (MANet) which mimics human ability to spatially\nabstract the low-level sensory input into multiple entities and attend to them\nsimultaneously. The proposed method first divides the low-level input into\nseveral segments which we refer to as partial states. After this segmentation,\nparallel attention layers attend to the partial states relevant to solving the\ntask. Our model estimates state-action values using these attended partial\nstates. In our experiments, MANet attains highest scores with significantly\nless experience samples. Additionally, the model shows higher performance\ncompared to the Deep Q-network and the single attention model as benchmarks.\nFurthermore, we extend our model to attentive communication model for\nperforming multi-agent cooperative tasks. In multi-agent cooperative task\nexperiments, our model shows 20% faster learning than existing state-of-the-art\nmodel.\n", "versions": [{"version": "v1", "created": "Wed, 13 Dec 2017 04:04:29 GMT"}], "update_date": "2017-12-14", "authors_parsed": [["Choi", "Jinyoung", ""], ["Lee", "Beom-Jin", ""], ["Zhang", "Byoung-Tak", ""]]}, {"id": "1712.04609", "submitter": "Igor Halperin", "authors": "Igor Halperin", "title": "QLBS: Q-Learner in the Black-Scholes(-Merton) Worlds", "comments": "30 pages (minor changes in the presentation, updated references)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a discrete-time option pricing model that is rooted in\nReinforcement Learning (RL), and more specifically in the famous Q-Learning\nmethod of RL. We construct a risk-adjusted Markov Decision Process for a\ndiscrete-time version of the classical Black-Scholes-Merton (BSM) model, where\nthe option price is an optimal Q-function, while the optimal hedge is a second\nargument of this optimal Q-function, so that both the price and hedge are parts\nof the same formula. Pricing is done by learning to dynamically optimize\nrisk-adjusted returns for an option replicating portfolio, as in the Markowitz\nportfolio theory. Using Q-Learning and related methods, once created in a\nparametric setting, the model is able to go model-free and learn to price and\nhedge an option directly from data, and without an explicit model of the world.\nThis suggests that RL may provide efficient data-driven and model-free methods\nfor optimal pricing and hedging of options, once we depart from the academic\ncontinuous-time limit, and vice versa, option pricing methods developed in\nMathematical Finance may be viewed as special cases of model-based\nReinforcement Learning. Further, due to simplicity and tractability of our\nmodel which only needs basic linear algebra (plus Monte Carlo simulation, if we\nwork with synthetic data), and its close relation to the original BSM model, we\nsuggest that our model could be used for benchmarking of different RL\nalgorithms for financial trading applications\n", "versions": [{"version": "v1", "created": "Wed, 13 Dec 2017 05:11:08 GMT"}, {"version": "v2", "created": "Sun, 17 Dec 2017 05:48:45 GMT"}, {"version": "v3", "created": "Tue, 3 Sep 2019 00:41:56 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Halperin", "Igor", ""]]}, {"id": "1712.04612", "submitter": "Igor Halperin", "authors": "Igor Halperin", "title": "Inverse Reinforcement Learning for Marketing", "comments": "18 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP cs.AI cs.CE cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning customer preferences from an observed behaviour is an important\ntopic in the marketing literature. Structural models typically model\nforward-looking customers or firms as utility-maximizing agents whose utility\nis estimated using methods of Stochastic Optimal Control. We suggest an\nalternative approach to study dynamic consumer demand, based on Inverse\nReinforcement Learning (IRL). We develop a version of the Maximum Entropy IRL\nthat leads to a highly tractable model formulation that amounts to\nlow-dimensional convex optimization in the search for optimal model parameters.\nUsing simulations of consumer demand, we show that observational noise for\nidentical customers can be easily confused with an apparent consumer\nheterogeneity.\n", "versions": [{"version": "v1", "created": "Wed, 13 Dec 2017 05:46:22 GMT"}], "update_date": "2017-12-14", "authors_parsed": [["Halperin", "Igor", ""]]}, {"id": "1712.04644", "submitter": "Branislav Kveton", "authors": "Branislav Kveton, Csaba Szepesvari, Anup Rao, Zheng Wen, Yasin\n  Abbasi-Yadkori, and S. Muthukrishnan", "title": "Stochastic Low-Rank Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many problems in computer vision and recommender systems involve low-rank\nmatrices. In this work, we study the problem of finding the maximum entry of a\nstochastic low-rank matrix from sequential observations. At each step, a\nlearning agent chooses pairs of row and column arms, and receives the noisy\nproduct of their latent values as a reward. The main challenge is that the\nlatent values are unobserved. We identify a class of non-negative matrices\nwhose maximum entry can be found statistically efficiently and propose an\nalgorithm for finding them, which we call LowRankElim. We derive a\n$\\DeclareMathOperator{\\poly}{poly} O((K + L) \\poly(d) \\Delta^{-1} \\log n)$\nupper bound on its $n$-step regret, where $K$ is the number of rows, $L$ is the\nnumber of columns, $d$ is the rank of the matrix, and $\\Delta$ is the minimum\ngap. The bound depends on other problem-specific constants that clearly do not\ndepend $K L$. To the best of our knowledge, this is the first such result in\nthe literature.\n", "versions": [{"version": "v1", "created": "Wed, 13 Dec 2017 07:59:48 GMT"}], "update_date": "2017-12-14", "authors_parsed": [["Kveton", "Branislav", ""], ["Szepesvari", "Csaba", ""], ["Rao", "Anup", ""], ["Wen", "Zheng", ""], ["Abbasi-Yadkori", "Yasin", ""], ["Muthukrishnan", "S.", ""]]}, {"id": "1712.04688", "submitter": "George Philipp", "authors": "George Philipp, Seunghak Lee, Eric P. Xing", "title": "Stability Selection for Structured Variable Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In variable or graph selection problems, finding a right-sized model or\ncontrolling the number of false positives is notoriously difficult. Recently, a\nmeta-algorithm called Stability Selection was proposed that can provide\nreliable finite-sample control of the number of false positives. Its benefits\nwere demonstrated when used in conjunction with the lasso and orthogonal\nmatching pursuit algorithms.\n  In this paper, we investigate the applicability of stability selection to\nstructured selection algorithms: the group lasso and the structured\ninput-output lasso. We find that using stability selection often increases the\npower of both algorithms, but that the presence of complex structure reduces\nthe reliability of error control under stability selection. We give strategies\nfor setting tuning parameters to obtain a good model size under stability\nselection, and highlight its strengths and weaknesses compared to competing\nmethods screen and clean and cross-validation. We give guidelines about when to\nuse which error control method.\n", "versions": [{"version": "v1", "created": "Wed, 13 Dec 2017 10:20:15 GMT"}], "update_date": "2017-12-14", "authors_parsed": [["Philipp", "George", ""], ["Lee", "Seunghak", ""], ["Xing", "Eric P.", ""]]}, {"id": "1712.04708", "submitter": "Maksim Kretov", "authors": "Vlad Zhukov and Eugene Golikov and Maksim Kretov", "title": "Differentiable lower bound for expected BLEU score", "comments": "Presented at NIPS 2017 Workshop on Conversational AI: Today's\n  Practice and Tomorrow's Potential", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In natural language processing tasks performance of the models is often\nmeasured with some non-differentiable metric, such as BLEU score. To use\nefficient gradient-based methods for optimization, it is a common workaround to\noptimize some surrogate loss function. This approach is effective if\noptimization of such loss also results in improving target metric. The\ncorresponding problem is referred to as loss-evaluation mismatch. In the\npresent work we propose a method for calculation of differentiable lower bound\nof expected BLEU score that does not involve computationally expensive sampling\nprocedure such as the one required when using REINFORCE rule from reinforcement\nlearning (RL) framework.\n", "versions": [{"version": "v1", "created": "Wed, 13 Dec 2017 11:17:37 GMT"}, {"version": "v2", "created": "Thu, 14 Dec 2017 11:28:57 GMT"}, {"version": "v3", "created": "Tue, 21 Aug 2018 08:55:07 GMT"}, {"version": "v4", "created": "Thu, 23 Aug 2018 12:37:42 GMT"}], "update_date": "2018-08-24", "authors_parsed": [["Zhukov", "Vlad", ""], ["Golikov", "Eugene", ""], ["Kretov", "Maksim", ""]]}, {"id": "1712.04741", "submitter": "Rene Vidal", "authors": "Rene Vidal, Joan Bruna, Raja Giryes, Stefano Soatto", "title": "Mathematics of Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently there has been a dramatic increase in the performance of recognition\nsystems due to the introduction of deep architectures for representation\nlearning and classification. However, the mathematical reasons for this success\nremain elusive. This tutorial will review recent work that aims to provide a\nmathematical justification for several properties of deep networks, such as\nglobal optimality, geometric stability, and invariance of the learned\nrepresentations.\n", "versions": [{"version": "v1", "created": "Wed, 13 Dec 2017 12:44:46 GMT"}], "update_date": "2017-12-14", "authors_parsed": [["Vidal", "Rene", ""], ["Bruna", "Joan", ""], ["Giryes", "Raja", ""], ["Soatto", "Stefano", ""]]}, {"id": "1712.04755", "submitter": "Loucas Pillaud-Vivien", "authors": "Loucas Pillaud-Vivien (SIERRA), Alessandro Rudi (SIERRA), Francis Bach\n  (SIERRA)", "title": "Exponential convergence of testing error for stochastic gradient methods", "comments": null, "journal-ref": "Conference on Learning Theory (COLT), Jul 2018, Stockholm, Sweden", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider binary classification problems with positive definite kernels and\nsquare loss, and study the convergence rates of stochastic gradient methods. We\nshow that while the excess testing loss (squared loss) converges slowly to zero\nas the number of observations (and thus iterations) goes to infinity, the\ntesting error (classification error) converges exponentially fast if low-noise\nconditions are assumed.\n", "versions": [{"version": "v1", "created": "Wed, 13 Dec 2017 13:35:27 GMT"}, {"version": "v2", "created": "Thu, 28 Jun 2018 14:16:39 GMT"}, {"version": "v3", "created": "Fri, 29 Jun 2018 08:09:44 GMT"}, {"version": "v4", "created": "Tue, 20 Nov 2018 11:49:03 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Pillaud-Vivien", "Loucas", "", "SIERRA"], ["Rudi", "Alessandro", "", "SIERRA"], ["Bach", "Francis", "", "SIERRA"]]}, {"id": "1712.04828", "submitter": "Tom Hope", "authors": "Tom Hope, Dafna Shahaf", "title": "Ballpark Crowdsourcing: The Wisdom of Rough Group Comparisons", "comments": null, "journal-ref": "WSDM 2018", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crowdsourcing has become a popular method for collecting labeled training\ndata. However, in many practical scenarios traditional labeling can be\ndifficult for crowdworkers (for example, if the data is high-dimensional or\nunintuitive, or the labels are continuous).\n  In this work, we develop a novel model for crowdsourcing that can complement\nstandard practices by exploiting people's intuitions about groups and relations\nbetween them. We employ a recent machine learning setting, called Ballpark\nLearning, that can estimate individual labels given only coarse, aggregated\nsignal over groups of data points. To address the important case of continuous\nlabels, we extend the Ballpark setting (which focused on classification) to\nregression problems. We formulate the problem as a convex optimization problem\nand propose fast, simple methods with an innate robustness to outliers.\n  We evaluate our methods on real-world datasets, demonstrating how useful\nconstraints about groups can be harnessed from a crowd of non-experts. Our\nmethods can rival supervised models trained on many true labels, and can obtain\nconsiderably better results from the crowd than a standard label-collection\nprocess (for a lower price). By collecting rough guesses on groups of instances\nand using machine learning to infer the individual labels, our lightweight\nframework is able to address core crowdsourcing challenges and train machine\nlearning models in a cost-effective way.\n", "versions": [{"version": "v1", "created": "Wed, 13 Dec 2017 15:56:27 GMT"}], "update_date": "2017-12-14", "authors_parsed": [["Hope", "Tom", ""], ["Shahaf", "Dafna", ""]]}, {"id": "1712.04910", "submitter": "Mahdi Nazemi", "authors": "Sheng Lin, Ning Liu, Mahdi Nazemi, Hongjia Li, Caiwen Ding, Yanzhi\n  Wang, Massoud Pedram", "title": "FFT-Based Deep Learning Deployment in Embedded Systems", "comments": "Design, Automation, and Test in Europe (DATE) For source code, please\n  contact Mahdi Nazemi at <mnazemi@usc.edu>", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has delivered its powerfulness in many application domains,\nespecially in image and speech recognition. As the backbone of deep learning,\ndeep neural networks (DNNs) consist of multiple layers of various types with\nhundreds to thousands of neurons. Embedded platforms are now becoming essential\nfor deep learning deployment due to their portability, versatility, and energy\nefficiency. The large model size of DNNs, while providing excellent accuracy,\nalso burdens the embedded platforms with intensive computation and storage.\nResearchers have investigated on reducing DNN model size with negligible\naccuracy loss. This work proposes a Fast Fourier Transform (FFT)-based DNN\ntraining and inference model suitable for embedded platforms with reduced\nasymptotic complexity of both computation and storage, making our approach\ndistinguished from existing approaches. We develop the training and inference\nalgorithms based on FFT as the computing kernel and deploy the FFT-based\ninference model on embedded platforms achieving extraordinary processing speed.\n", "versions": [{"version": "v1", "created": "Wed, 13 Dec 2017 18:26:17 GMT"}], "update_date": "2017-12-14", "authors_parsed": [["Lin", "Sheng", ""], ["Liu", "Ning", ""], ["Nazemi", "Mahdi", ""], ["Li", "Hongjia", ""], ["Ding", "Caiwen", ""], ["Wang", "Yanzhi", ""], ["Pedram", "Massoud", ""]]}, {"id": "1712.04997", "submitter": "Lei Lin", "authors": "Lei Lin, Zhengbing He, Srinivas Peeta", "title": "Predicting Station-level Hourly Demands in a Large-scale Bike-sharing\n  Network: A Graph Convolutional Neural Network Approach", "comments": "9 figures, 3 tables, accepted by Transportation Research Part C:\n  Emerging Technologies", "journal-ref": "Transportation Research Part C: Emerging Technologies 97 (2018):\n  258-276", "doi": "10.1016/j.trc.2018.10.011", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This study proposes a novel Graph Convolutional Neural Network with\nData-driven Graph Filter (GCNN-DDGF) model that can learn hidden heterogeneous\npairwise correlations between stations to predict station-level hourly demand\nin a large-scale bike-sharing network. Two architectures of the GCNN-DDGF model\nare explored; GCNNreg-DDGF is a regular GCNN-DDGF model which contains the\nconvolution and feedforward blocks, and GCNNrec-DDGF additionally contains a\nrecurrent block from the Long Short-term Memory neural network architecture to\ncapture temporal dependencies in the bike-sharing demand series. Furthermore,\nfour types of GCNN models are proposed whose adjacency matrices are based on\nvarious bike-sharing system data, including Spatial Distance matrix (SD),\nDemand matrix (DE), Average Trip Duration matrix (ATD), and Demand Correlation\nmatrix (DC). These six types of GCNN models and seven other benchmark models\nare built and compared on a Citi Bike dataset from New York City which includes\n272 stations and over 28 million transactions from 2013 to 2016. Results show\nthat the GCNNrec-DDGF performs the best in terms of the Root Mean Square Error,\nthe Mean Absolute Error and the coefficient of determination (R2), followed by\nthe GCNNreg-DDGF. They outperform the other models. Through a more detailed\ngraph network analysis based on the learned DDGF, insights are obtained on the\nblack box of the GCNN-DDGF model. It is found to capture some information\nsimilar to details embedded in the SD, DE and DC matrices. More importantly, it\nalso uncovers hidden heterogeneous pairwise correlations between stations that\nare not revealed by any of those matrices.\n", "versions": [{"version": "v1", "created": "Wed, 13 Dec 2017 20:26:50 GMT"}, {"version": "v2", "created": "Fri, 19 Oct 2018 18:58:23 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Lin", "Lei", ""], ["He", "Zhengbing", ""], ["Peeta", "Srinivas", ""]]}, {"id": "1712.05015", "submitter": "Shen Yan", "authors": "Shen Yan", "title": "Learning Low-shot facial representations via 2D warping", "comments": "The new version should update the table as well as add some new\n  results. This paper is talking about one-shot learning, but the current\n  version is not mainly focus on that point. I should restructure the article.\n  After the page reduction I assume the new version would be 4 pages. The title\n  name should also be changed to one-shot learning and there are more previous\n  work should be cited", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we mainly study the influence of the 2D warping module for\none-shot face recognition.\n", "versions": [{"version": "v1", "created": "Wed, 13 Dec 2017 21:39:52 GMT"}, {"version": "v2", "created": "Mon, 5 Feb 2018 15:08:07 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["Yan", "Shen", ""]]}, {"id": "1712.05016", "submitter": "Alexandre Lacoste", "authors": "Alexandre Lacoste, Thomas Boquet, Negar Rostamzadeh, Boris Oreshkin,\n  Wonchang Chung, David Krueger", "title": "Deep Prior", "comments": "Workshop paper, Accepted at Bayesian Deep Learning workshop, NIPS\n  2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent literature on deep learning offers new tools to learn a rich\nprobability distribution over high dimensional data such as images or sounds.\nIn this work we investigate the possibility of learning the prior distribution\nover neural network parameters using such tools. Our resulting variational\nBayes algorithm generalizes well to new tasks, even when very few training\nexamples are provided. Furthermore, this learned prior allows the model to\nextrapolate correctly far from a given task's training data on a meta-dataset\nof periodic signals.\n", "versions": [{"version": "v1", "created": "Wed, 13 Dec 2017 21:41:56 GMT"}, {"version": "v2", "created": "Sat, 16 Dec 2017 02:52:55 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Lacoste", "Alexandre", ""], ["Boquet", "Thomas", ""], ["Rostamzadeh", "Negar", ""], ["Oreshkin", "Boris", ""], ["Chung", "Wonchang", ""], ["Krueger", "David", ""]]}, {"id": "1712.05134", "submitter": "Jinmian Ye", "authors": "Jinmian Ye, Linnan Wang, Guangxi Li, Di Chen, Shandian Zhe, Xinqi Chu,\n  Zenglin Xu", "title": "Learning Compact Recurrent Neural Networks with Block-Term Tensor\n  Decomposition", "comments": "CVPR2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Networks (RNNs) are powerful sequence modeling tools.\nHowever, when dealing with high dimensional inputs, the training of RNNs\nbecomes computational expensive due to the large number of model parameters.\nThis hinders RNNs from solving many important computer vision tasks, such as\nAction Recognition in Videos and Image Captioning. To overcome this problem, we\npropose a compact and flexible structure, namely Block-Term tensor\ndecomposition, which greatly reduces the parameters of RNNs and improves their\ntraining efficiency. Compared with alternative low-rank approximations, such as\ntensor-train RNN (TT-RNN), our method, Block-Term RNN (BT-RNN), is not only\nmore concise (when using the same rank), but also able to attain a better\napproximation to the original RNNs with much fewer parameters. On three\nchallenging tasks, including Action Recognition in Videos, Image Captioning and\nImage Generation, BT-RNN outperforms TT-RNN and the standard RNN in terms of\nboth prediction accuracy and convergence rate. Specifically, BT-LSTM utilizes\n17,388 times fewer parameters than the standard LSTM to achieve an accuracy\nimprovement over 15.6\\% in the Action Recognition task on the UCF11 dataset.\n", "versions": [{"version": "v1", "created": "Thu, 14 Dec 2017 09:24:27 GMT"}, {"version": "v2", "created": "Fri, 11 May 2018 07:33:47 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Ye", "Jinmian", ""], ["Wang", "Linnan", ""], ["Li", "Guangxi", ""], ["Chen", "Di", ""], ["Zhe", "Shandian", ""], ["Chu", "Xinqi", ""], ["Xu", "Zenglin", ""]]}, {"id": "1712.05181", "submitter": "Nick Pawlowski", "authors": "Tom Bocklisch, Joey Faulkner, Nick Pawlowski, Alan Nichol", "title": "Rasa: Open Source Language Understanding and Dialogue Management", "comments": "Presented at NIPS Workshop on Conversational AI, Code at\n  https://github.com/RasaHQ", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a pair of tools, Rasa NLU and Rasa Core, which are open source\npython libraries for building conversational software. Their purpose is to make\nmachine-learning based dialogue management and language understanding\naccessible to non-specialist software developers. In terms of design\nphilosophy, we aim for ease of use, and bootstrapping from minimal (or no)\ninitial training data. Both packages are extensively documented and ship with a\ncomprehensive suite of tests. The code is available at\nhttps://github.com/RasaHQ/\n", "versions": [{"version": "v1", "created": "Thu, 14 Dec 2017 11:37:18 GMT"}, {"version": "v2", "created": "Fri, 15 Dec 2017 09:33:11 GMT"}], "update_date": "2017-12-18", "authors_parsed": [["Bocklisch", "Tom", ""], ["Faulkner", "Joey", ""], ["Pawlowski", "Nick", ""], ["Nichol", "Alan", ""]]}, {"id": "1712.05193", "submitter": "Nandan Sudarsanam", "authors": "Nandan Sudarsanam, Nishanth Kumar, Abhishek Sharma, and Balaraman\n  Ravindran", "title": "Rate of Change Analysis for Interestingness Measures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of Association Rule Mining techniques in diverse contexts and domains\nhas resulted in the creation of numerous interestingness measures. This, in\nturn, has motivated researchers to come up with various classification schemes\nfor these measures. One popular approach to classify the objective measures is\nto assess the set of mathematical properties they satisfy in order to help\npractitioners select the right measure for a given problem. In this research,\nwe discuss the insufficiency of the existing properties in literature to\ncapture certain behaviors of interestingness measures. This motivates us to\npresent a novel approach to analyze and classify measures. We refer to this as\na rate of change analysis (RCA). In this analysis a measure is described by how\nit varies if there is a unit change in the frequency count\n$(f_{11},f_{10},f_{01},f_{00})$, for different pre-existing states of the\nfrequency counts. More formally, we look at the first partial derivative of the\nmeasure with respect to the various frequency count variables. We then use this\nanalysis to define two new properties, Unit-Null Asymptotic Invariance (UNAI)\nand Unit-Null Zero Rate (UNZR). UNAI looks at the asymptotic effect of adding\nfrequency patterns, while UNZR looks at the initial effect of adding frequency\npatterns when they do not pre-exist in the dataset. We present a comprehensive\nanalysis of 50 interestingness measures and classify them in accordance with\nthe two properties. We also present empirical studies, involving both synthetic\nand real-world datasets, which are used to cluster various measures according\nto the rule ranking patterns of the measures. The study concludes with the\nobservation that classification of measures using the empirical clusters share\nsignificant similarities to the classification of measures done through the\nproperties presented in this research.\n", "versions": [{"version": "v1", "created": "Thu, 14 Dec 2017 12:13:46 GMT"}], "update_date": "2017-12-15", "authors_parsed": [["Sudarsanam", "Nandan", ""], ["Kumar", "Nishanth", ""], ["Sharma", "Abhishek", ""], ["Ravindran", "Balaraman", ""]]}, {"id": "1712.05197", "submitter": "Francisco Raposo", "authors": "Francisco Raposo, David Martins de Matos, Ricardo Ribeiro, Suhua Tang,\n  Yi Yu", "title": "Towards Deep Modeling of Music Semantics using EEG Regularizers", "comments": "5 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG cs.SD eess.AS q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling of music audio semantics has been previously tackled through\nlearning of mappings from audio data to high-level tags or latent unsupervised\nspaces. The resulting semantic spaces are theoretically limited, either because\nthe chosen high-level tags do not cover all of music semantics or because audio\ndata itself is not enough to determine music semantics. In this paper, we\npropose a generic framework for semantics modeling that focuses on the\nperception of the listener, through EEG data, in addition to audio data. We\nimplement this framework using a novel end-to-end 2-view Neural Network (NN)\narchitecture and a Deep Canonical Correlation Analysis (DCCA) loss function\nthat forces the semantic embedding spaces of both views to be maximally\ncorrelated. We also detail how the EEG dataset was collected and use it to\ntrain our proposed model. We evaluate the learned semantic space in a transfer\nlearning context, by using it as an audio feature extractor in an independent\ndataset and proxy task: music audio-lyrics cross-modal retrieval. We show that\nour embedding model outperforms Spotify features and performs comparably to a\nstate-of-the-art embedding model that was trained on 700 times more data. We\nfurther discuss improvements to the model that are likely to improve its\nperformance.\n", "versions": [{"version": "v1", "created": "Thu, 14 Dec 2017 12:27:11 GMT"}, {"version": "v2", "created": "Fri, 15 Dec 2017 15:57:29 GMT"}], "update_date": "2017-12-18", "authors_parsed": [["Raposo", "Francisco", ""], ["de Matos", "David Martins", ""], ["Ribeiro", "Ricardo", ""], ["Tang", "Suhua", ""], ["Yu", "Yi", ""]]}, {"id": "1712.05245", "submitter": "Binh-Son Hua", "authors": "Binh-Son Hua, Minh-Khoi Tran, Sai-Kit Yeung", "title": "Pointwise Convolutional Neural Networks", "comments": "10 pages, 6 figures, 10 tables. Paper accepted to CVPR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning with 3D data such as reconstructed point clouds and CAD models\nhas received great research interests recently. However, the capability of\nusing point clouds with convolutional neural network has been so far not fully\nexplored. In this paper, we present a convolutional neural network for semantic\nsegmentation and object recognition with 3D point clouds. At the core of our\nnetwork is pointwise convolution, a new convolution operator that can be\napplied at each point of a point cloud. Our fully convolutional network design,\nwhile being surprisingly simple to implement, can yield competitive accuracy in\nboth semantic segmentation and object recognition task.\n", "versions": [{"version": "v1", "created": "Thu, 14 Dec 2017 14:25:52 GMT"}, {"version": "v2", "created": "Thu, 29 Mar 2018 04:55:01 GMT"}], "update_date": "2018-03-30", "authors_parsed": [["Hua", "Binh-Son", ""], ["Tran", "Minh-Khoi", ""], ["Yeung", "Sai-Kit", ""]]}, {"id": "1712.05249", "submitter": "Pierre-Yves Oudeyer", "authors": "Freek Stulp and Pierre-Yves Oudeyer", "title": "Proximodistal Exploration in Motor Learning as an Emergent Property of\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To harness the complexity of their high-dimensional bodies during\nsensorimotor development, infants are guided by patterns of freezing and\nfreeing of degrees of freedom. For instance, when learning to reach, infants\nfree the degrees of freedom in their arm proximodistally, i.e. from joints that\nare closer to the body to those that are more distant. Here, we formulate and\nstudy computationally the hypothesis that such patterns can emerge\nspontaneously as the result of a family of stochastic optimization processes\n(evolution strategies with covariance-matrix adaptation), without an innate\nencoding of a maturational schedule. In particular, we present simulated\nexperiments with an arm where a computational learner progressively acquires\nreaching skills through adaptive exploration, and we show that a proximodistal\norganization appears spontaneously, which we denote PDFF (ProximoDistal\nFreezing and Freeing of degrees of freedom). We also compare this emergent\norganization between different arm morphologies -- from human-like to quite\nunnatural ones -- to study the effect of different kinematic structures on the\nemergence of PDFF. Keywords: human motor learning; proximo-distal exploration;\nstochastic optimization; modelling; evolution strategies; cross-entropy\nmethods; policy search; morphology.}\n", "versions": [{"version": "v1", "created": "Thu, 14 Dec 2017 14:31:51 GMT"}], "update_date": "2017-12-15", "authors_parsed": [["Stulp", "Freek", ""], ["Oudeyer", "Pierre-Yves", ""]]}, {"id": "1712.05293", "submitter": "Jianan Cao", "authors": "Jianan Cao, David J. Farnham, Upmanu Lall", "title": "Spatial-temporal wind field prediction by Artificial Neural Networks", "comments": "arXiv admin note: text overlap with arXiv:1603.07285 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The prediction of near surface wind speed is becoming increasingly vital for\nthe operation of electrical energy grids as the capacity of installed wind\npower grows. The majority of predictive wind speed modeling has focused on\npoint-based time-series forecasting. Effectively balancing demand and supply in\nthe presence of distributed wind turbine electricity generation, however,\nrequires the prediction of wind fields in space and time. Additionally,\npredictions of full wind fields are particularly useful for future power\nplanning such as the optimization of electricity power supply systems. In this\npaper, we propose a composite artificial neural network (ANN) model to predict\nthe 6-hour and 24-hour ahead average wind speed over a large area (~3.15*106\nkm2). The ANN model consists of a convolutional input layer, a Long Short-Term\nMemory (LSTM) hidden layer, and a transposed convolutional layer as the output\nlayer. We compare the ANN model with two non-parametric models, a null\npersistence model and a mean value model, and find that the ANN model has\nsubstantially smaller error than each of these models. Additionally, the ANN\nmodel also generally performs better than integrated autoregressive moving\naverage models, which are trained for optimal performance in specific\nlocations.\n", "versions": [{"version": "v1", "created": "Wed, 13 Dec 2017 17:00:15 GMT"}], "update_date": "2017-12-15", "authors_parsed": [["Cao", "Jianan", ""], ["Farnham", "David J.", ""], ["Lall", "Upmanu", ""]]}, {"id": "1712.05419", "submitter": "Catherine Wong", "authors": "Catherine Wong", "title": "DANCin SEQ2SEQ: Fooling Text Classifiers with Adversarial Text Example\n  Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models are powerful but fallible. Generating adversarial\nexamples - inputs deliberately crafted to cause model misclassification or\nother errors - can yield important insight into model assumptions and\nvulnerabilities. Despite significant recent work on adversarial example\ngeneration targeting image classifiers, relatively little work exists exploring\nadversarial example generation for text classifiers; additionally, many\nexisting adversarial example generation algorithms require full access to\ntarget model parameters, rendering them impractical for many real-world\nattacks. In this work, we introduce DANCin SEQ2SEQ, a GAN-inspired algorithm\nfor adversarial text example generation targeting largely black-box text\nclassifiers. We recast adversarial text example generation as a reinforcement\nlearning problem, and demonstrate that our algorithm offers preliminary but\npromising steps towards generating semantically meaningful adversarial text\nexamples in a real-world attack scenario.\n", "versions": [{"version": "v1", "created": "Thu, 14 Dec 2017 19:00:57 GMT"}], "update_date": "2017-12-18", "authors_parsed": [["Wong", "Catherine", ""]]}, {"id": "1712.05438", "submitter": "Atsushi Nitanda", "authors": "Atsushi Nitanda and Taiji Suzuki", "title": "Stochastic Particle Gradient Descent for Infinite Ensembles", "comments": "33 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The superior performance of ensemble methods with infinite models are well\nknown. Most of these methods are based on optimization problems in\ninfinite-dimensional spaces with some regularization, for instance, boosting\nmethods and convex neural networks use $L^1$-regularization with the\nnon-negative constraint. However, due to the difficulty of handling\n$L^1$-regularization, these problems require early stopping or a rough\napproximation to solve it inexactly. In this paper, we propose a new ensemble\nlearning method that performs in a space of probability measures, that is, our\nmethod can handle the $L^1$-constraint and the non-negative constraint in a\nrigorous way. Such an optimization is realized by proposing a general purpose\nstochastic optimization method for learning probability measures via\nparameterization using transport maps on base models. As a result of running\nthe method, a transport map to output an infinite ensemble is obtained, which\nforms a residual-type network. From the perspective of functional gradient\nmethods, we give a convergence rate as fast as that of a stochastic\noptimization method for finite dimensional nonconvex problems. Moreover, we\nshow an interior optimality property of a local optimality condition used in\nour analysis.\n", "versions": [{"version": "v1", "created": "Thu, 14 Dec 2017 20:12:02 GMT"}], "update_date": "2017-12-18", "authors_parsed": [["Nitanda", "Atsushi", ""], ["Suzuki", "Taiji", ""]]}, {"id": "1712.05440", "submitter": "George Philipp", "authors": "George Philipp, Jaime G. Carbonell", "title": "Nonparametric Neural Networks", "comments": "ICLR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatically determining the optimal size of a neural network for a given\ntask without prior information currently requires an expensive global search\nand training many networks from scratch. In this paper, we address the problem\nof automatically finding a good network size during a single training cycle. We\nintroduce *nonparametric neural networks*, a non-probabilistic framework for\nconducting optimization over all possible network sizes and prove its soundness\nwhen network growth is limited via an L_p penalty. We train networks under this\nframework by continuously adding new units while eliminating redundant units\nvia an L_2 penalty. We employ a novel optimization algorithm, which we term\n*adaptive radial-angular gradient descent* or *AdaRad*, and obtain promising\nresults.\n", "versions": [{"version": "v1", "created": "Thu, 14 Dec 2017 20:31:29 GMT"}], "update_date": "2017-12-18", "authors_parsed": [["Philipp", "George", ""], ["Carbonell", "Jaime G.", ""]]}, {"id": "1712.05474", "submitter": "Roozbeh Mottaghi", "authors": "Eric Kolve, Roozbeh Mottaghi, Winson Han, Eli VanderBilt, Luca Weihs,\n  Alvaro Herrasti, Daniel Gordon, Yuke Zhu, Abhinav Gupta, Ali Farhadi", "title": "AI2-THOR: An Interactive 3D Environment for Visual AI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce The House Of inteRactions (THOR), a framework for visual AI\nresearch, available at http://ai2thor.allenai.org. AI2-THOR consists of near\nphoto-realistic 3D indoor scenes, where AI agents can navigate in the scenes\nand interact with objects to perform tasks. AI2-THOR enables research in many\ndifferent domains including but not limited to deep reinforcement learning,\nimitation learning, learning by interaction, planning, visual question\nanswering, unsupervised representation learning, object detection and\nsegmentation, and learning models of cognition. The goal of AI2-THOR is to\nfacilitate building visually intelligent models and push the research forward\nin this domain.\n", "versions": [{"version": "v1", "created": "Thu, 14 Dec 2017 23:17:24 GMT"}, {"version": "v2", "created": "Wed, 13 Mar 2019 23:45:48 GMT"}, {"version": "v3", "created": "Fri, 15 Mar 2019 18:29:15 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Kolve", "Eric", ""], ["Mottaghi", "Roozbeh", ""], ["Han", "Winson", ""], ["VanderBilt", "Eli", ""], ["Weihs", "Luca", ""], ["Herrasti", "Alvaro", ""], ["Gordon", "Daniel", ""], ["Zhu", "Yuke", ""], ["Gupta", "Abhinav", ""], ["Farhadi", "Ali", ""]]}, {"id": "1712.05510", "submitter": "Alexander LeNail", "authors": "Alexander LeNail, Ludwig Schmidt, Johnathan Li, Tobias Ehrenberger,\n  Karen Sachs, Stefanie Jegelka, Ernest Fraenkel", "title": "Graph-Sparse Logistic Regression", "comments": "7 pages, 2 figures, NIPS DISCML workshop paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Graph-Sparse Logistic Regression, a new algorithm for\nclassification for the case in which the support should be sparse but connected\non a graph. We val- idate this algorithm against synthetic data and benchmark\nit against L1-regularized Logistic Regression. We then explore our technique in\nthe bioinformatics context of proteomics data on the interactome graph. We make\nall our experimental code public and provide GSLR as an open source package.\n", "versions": [{"version": "v1", "created": "Fri, 15 Dec 2017 02:17:06 GMT"}], "update_date": "2017-12-18", "authors_parsed": [["LeNail", "Alexander", ""], ["Schmidt", "Ludwig", ""], ["Li", "Johnathan", ""], ["Ehrenberger", "Tobias", ""], ["Sachs", "Karen", ""], ["Jegelka", "Stefanie", ""], ["Fraenkel", "Ernest", ""]]}, {"id": "1712.05526", "submitter": "Xinyun Chen", "authors": "Xinyun Chen, Chang Liu, Bo Li, Kimberly Lu, Dawn Song", "title": "Targeted Backdoor Attacks on Deep Learning Systems Using Data Poisoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models have achieved high performance on many tasks, and thus\nhave been applied to many security-critical scenarios. For example, deep\nlearning-based face recognition systems have been used to authenticate users to\naccess many security-sensitive applications like payment apps. Such usages of\ndeep learning systems provide the adversaries with sufficient incentives to\nperform attacks against these systems for their adversarial purposes. In this\nwork, we consider a new type of attacks, called backdoor attacks, where the\nattacker's goal is to create a backdoor into a learning-based authentication\nsystem, so that he can easily circumvent the system by leveraging the backdoor.\nSpecifically, the adversary aims at creating backdoor instances, so that the\nvictim learning system will be misled to classify the backdoor instances as a\ntarget label specified by the adversary. In particular, we study backdoor\npoisoning attacks, which achieve backdoor attacks using poisoning strategies.\nDifferent from all existing work, our studied poisoning strategies can apply\nunder a very weak threat model: (1) the adversary has no knowledge of the model\nand the training set used by the victim system; (2) the attacker is allowed to\ninject only a small amount of poisoning samples; (3) the backdoor key is hard\nto notice even by human beings to achieve stealthiness. We conduct evaluation\nto demonstrate that a backdoor adversary can inject only around 50 poisoning\nsamples, while achieving an attack success rate of above 90%. We are also the\nfirst work to show that a data poisoning attack can create physically\nimplementable backdoors without touching the training process. Our work\ndemonstrates that backdoor poisoning attacks pose real threats to a learning\nsystem, and thus highlights the importance of further investigation and\nproposing defense strategies against them.\n", "versions": [{"version": "v1", "created": "Fri, 15 Dec 2017 04:26:26 GMT"}], "update_date": "2017-12-18", "authors_parsed": [["Chen", "Xinyun", ""], ["Liu", "Chang", ""], ["Li", "Bo", ""], ["Lu", "Kimberly", ""], ["Song", "Dawn", ""]]}, {"id": "1712.05556", "submitter": "Kyriakos Polymenakos", "authors": "Kyriakos Polymenakos, Alessandro Abate, Stephen Roberts", "title": "Safe Policy Search with Gaussian Process Models", "comments": "9 pages, 2 figures, extended version of the paper that was presented\n  in AAMAS 2019, Montreal, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method to optimise the parameters of a policy which will be used\nto safely perform a given task in a data-efficient manner. We train a Gaussian\nprocess model to capture the system dynamics, based on the PILCO framework. Our\nmodel has useful analytic properties, which allow closed form computation of\nerror gradients and estimating the probability of violating given state space\nconstraints. During training, as well as operation, only policies that are\ndeemed safe are implemented on the real system, minimising the risk of failure.\n", "versions": [{"version": "v1", "created": "Fri, 15 Dec 2017 06:34:53 GMT"}, {"version": "v2", "created": "Wed, 13 Mar 2019 16:17:36 GMT"}, {"version": "v3", "created": "Fri, 29 Nov 2019 20:46:15 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Polymenakos", "Kyriakos", ""], ["Abate", "Alessandro", ""], ["Roberts", "Stephen", ""]]}, {"id": "1712.05558", "submitter": "Nikita Kitaev", "authors": "Jin-Hwa Kim, Nikita Kitaev, Xinlei Chen, Marcus Rohrbach, Byoung-Tak\n  Zhang, Yuandong Tian, Dhruv Batra, Devi Parikh", "title": "CoDraw: Collaborative Drawing as a Testbed for Grounded Goal-driven\n  Communication", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a goal-driven collaborative task that combines\nlanguage, perception, and action. Specifically, we develop a Collaborative\nimage-Drawing game between two agents, called CoDraw. Our game is grounded in a\nvirtual world that contains movable clip art objects. The game involves two\nplayers: a Teller and a Drawer. The Teller sees an abstract scene containing\nmultiple clip art pieces in a semantically meaningful configuration, while the\nDrawer tries to reconstruct the scene on an empty canvas using available clip\nart pieces. The two players communicate with each other using natural language.\nWe collect the CoDraw dataset of ~10K dialogs consisting of ~138K messages\nexchanged between human players. We define protocols and metrics to evaluate\nlearned agents in this testbed, highlighting the need for a novel \"crosstalk\"\nevaluation condition which pairs agents trained independently on disjoint\nsubsets of the training data. We present models for our task and benchmark them\nusing both fully automated evaluation and by having them play the game live\nwith humans.\n", "versions": [{"version": "v1", "created": "Fri, 15 Dec 2017 06:38:15 GMT"}, {"version": "v2", "created": "Mon, 14 Jan 2019 08:00:14 GMT"}, {"version": "v3", "created": "Tue, 4 Jun 2019 13:01:42 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Kim", "Jin-Hwa", ""], ["Kitaev", "Nikita", ""], ["Chen", "Xinlei", ""], ["Rohrbach", "Marcus", ""], ["Zhang", "Byoung-Tak", ""], ["Tian", "Yuandong", ""], ["Batra", "Dhruv", ""], ["Parikh", "Devi", ""]]}, {"id": "1712.05577", "submitter": "George Philipp", "authors": "George Philipp, Dawn Song, Jaime G. Carbonell", "title": "The exploding gradient problem demystified - definition, prevalence,\n  impact, origin, tradeoffs, and solutions", "comments": "An earlier version of this paper was named \"Gradients explode - Deep\n  Networks are shallow - ResNet explained\" and presented at the ICLR 2018\n  workshop (https://openreview.net/forum?id=rJjcdFkPM)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Whereas it is believed that techniques such as Adam, batch normalization and,\nmore recently, SeLU nonlinearities \"solve\" the exploding gradient problem, we\nshow that this is not the case in general and that in a range of popular MLP\narchitectures, exploding gradients exist and that they limit the depth to which\nnetworks can be effectively trained, both in theory and in practice. We explain\nwhy exploding gradients occur and highlight the *collapsing domain problem*,\nwhich can arise in architectures that avoid exploding gradients.\n  ResNets have significantly lower gradients and thus can circumvent the\nexploding gradient problem, enabling the effective training of much deeper\nnetworks. We show this is a direct consequence of the Pythagorean equation. By\nnoticing that *any neural network is a residual network*, we devise the\n*residual trick*, which reveals that introducing skip connections simplifies\nthe network mathematically, and that this simplicity may be the major cause for\ntheir success.\n", "versions": [{"version": "v1", "created": "Fri, 15 Dec 2017 08:25:51 GMT"}, {"version": "v2", "created": "Fri, 22 Dec 2017 15:36:32 GMT"}, {"version": "v3", "created": "Wed, 21 Mar 2018 17:12:48 GMT"}, {"version": "v4", "created": "Fri, 6 Apr 2018 21:32:29 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Philipp", "George", ""], ["Song", "Dawn", ""], ["Carbonell", "Jaime G.", ""]]}, {"id": "1712.05581", "submitter": "Daniel Neider", "authors": "Daniel Neider, Pranav Garg, P. Madhusudan, Shambwaditya Saha, Daejun\n  Park", "title": "Invariant Synthesis for Incomplete Verification Engines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a framework for synthesizing inductive invariants for incomplete\nverification engines, which soundly reduce logical problems in undecidable\ntheories to decidable theories. Our framework is based on the counter-example\nguided inductive synthesis principle (CEGIS) and allows verification engines to\ncommunicate non-provability information to guide invariant synthesis. We show\nprecisely how the verification engine can compute such non-provability\ninformation and how to build effective learning algorithms when invariants are\nexpressed as Boolean combinations of a fixed set of predicates. Moreover, we\nevaluate our framework in two verification settings, one in which verification\nengines need to handle quantified formulas and one in which verification\nengines have to reason about heap properties expressed in an expressive but\nundecidable separation logic. Our experiments show that our invariant synthesis\nframework based on non-provability information can both effectively synthesize\ninductive invariants and adequately strengthen contracts across a large suite\nof programs.\n", "versions": [{"version": "v1", "created": "Fri, 15 Dec 2017 08:38:15 GMT"}, {"version": "v2", "created": "Fri, 12 Jan 2018 12:08:56 GMT"}], "update_date": "2018-01-15", "authors_parsed": [["Neider", "Daniel", ""], ["Garg", "Pranav", ""], ["Madhusudan", "P.", ""], ["Saha", "Shambwaditya", ""], ["Park", "Daejun", ""]]}, {"id": "1712.05652", "submitter": "Jack Lindsey", "authors": "Jack Lindsey", "title": "Pre-training Attention Mechanisms", "comments": "Presented at NIPS 2017 Workshop on Cognitively Informed Artificial\n  Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks with differentiable attention mechanisms have had\nsuccess in generative and classification tasks. We show that the classification\nperformance of such models can be enhanced by guiding a randomly initialized\nmodel to attend to salient regions of the input in early training iterations.\nWe further show that, if explicit heuristics for guidance are unavailable, a\nmodel that is pretrained on an unsupervised reconstruction task can discover\ngood attention policies without supervision. We demonstrate that increased\nefficiency of the attention mechanism itself contributes to these performance\nimprovements. Based on these insights, we introduce bootstrapped glimpse\nmimicking, a simple, theoretically task-general method of more effectively\ntraining attention models. Our work draws inspiration from and parallels\nresults on human learning of attention.\n", "versions": [{"version": "v1", "created": "Fri, 15 Dec 2017 12:59:22 GMT"}], "update_date": "2017-12-18", "authors_parsed": [["Lindsey", "Jack", ""]]}, {"id": "1712.05689", "submitter": "Guangxi Li", "authors": "Guangxi Li, Jinmian Ye, Haiqin Yang, Di Chen, Shuicheng Yan and\n  Zenglin Xu", "title": "BT-Nets: Simplifying Deep Neural Networks via Block Term Decomposition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, deep neural networks (DNNs) have been regarded as the\nstate-of-the-art classification methods in a wide range of applications,\nespecially in image classification. Despite the success, the huge number of\nparameters blocks its deployment to situations with light computing resources.\nResearchers resort to the redundancy in the weights of DNNs and attempt to find\nhow fewer parameters can be chosen while preserving the accuracy at the same\ntime. Although several promising results have been shown along this research\nline, most existing methods either fail to significantly compress a\nwell-trained deep network or require a heavy fine-tuning process for the\ncompressed network to regain the original performance. In this paper, we\npropose the \\textit{Block Term} networks (BT-nets) in which the commonly used\nfully-connected layers (FC-layers) are replaced with block term layers\n(BT-layers). In BT-layers, the inputs and the outputs are reshaped into two\nlow-dimensional high-order tensors, then block-term decomposition is applied as\ntensor operators to connect them. We conduct extensive experiments on benchmark\ndatasets to demonstrate that BT-layers can achieve a very large compression\nratio on the number of parameters while preserving the representation power of\nthe original FC-layers as much as possible. Specifically, we can get a higher\nperformance while requiring fewer parameters compared with the tensor train\nmethod.\n", "versions": [{"version": "v1", "created": "Fri, 15 Dec 2017 14:42:32 GMT"}], "update_date": "2017-12-18", "authors_parsed": [["Li", "Guangxi", ""], ["Ye", "Jinmian", ""], ["Yang", "Haiqin", ""], ["Chen", "Di", ""], ["Yan", "Shuicheng", ""], ["Xu", "Zenglin", ""]]}, {"id": "1712.05690", "submitter": "Tobias Domhan", "authors": "Felix Hieber, Tobias Domhan, Michael Denkowski, David Vilar, Artem\n  Sokolov, Ann Clifton, Matt Post", "title": "Sockeye: A Toolkit for Neural Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe Sockeye (version 1.12), an open-source sequence-to-sequence\ntoolkit for Neural Machine Translation (NMT). Sockeye is a production-ready\nframework for training and applying models as well as an experimental platform\nfor researchers. Written in Python and built on MXNet, the toolkit offers\nscalable training and inference for the three most prominent encoder-decoder\narchitectures: attentional recurrent neural networks, self-attentional\ntransformers, and fully convolutional networks. Sockeye also supports a wide\nrange of optimizers, normalization and regularization techniques, and inference\nimprovements from current NMT literature. Users can easily run standard\ntraining recipes, explore different model settings, and incorporate new ideas.\nIn this paper, we highlight Sockeye's features and benchmark it against other\nNMT toolkits on two language arcs from the 2017 Conference on Machine\nTranslation (WMT): English-German and Latvian-English. We report competitive\nBLEU scores across all three architectures, including an overall best score for\nSockeye's transformer implementation. To facilitate further comparison, we\nrelease all system outputs and training scripts used in our experiments. The\nSockeye toolkit is free software released under the Apache 2.0 license.\n", "versions": [{"version": "v1", "created": "Fri, 15 Dec 2017 14:44:28 GMT"}, {"version": "v2", "created": "Fri, 1 Jun 2018 13:29:31 GMT"}], "update_date": "2018-06-04", "authors_parsed": [["Hieber", "Felix", ""], ["Domhan", "Tobias", ""], ["Denkowski", "Michael", ""], ["Vilar", "David", ""], ["Sokolov", "Artem", ""], ["Clifton", "Ann", ""], ["Post", "Matt", ""]]}, {"id": "1712.05695", "submitter": "Altaf Khan", "authors": "Altaf H. Khan", "title": "Lightweight Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the weights in a Lightweight Neural Network have a value of zero,\nwhile the remaining ones are either +1 or -1. These universal approximators\nrequire approximately 1.1 bits/weight of storage, posses a quick forward pass\nand achieve classification accuracies similar to conventional continuous-weight\nnetworks. Their training regimen focuses on error reduction initially, but\nlater emphasizes discretization of weights. They ignore insignificant inputs,\nremove unnecessary weights, and drop unneeded hidden neurons. We have\nsuccessfully tested them on the MNIST, credit card fraud, and credit card\ndefaults data sets using networks having 2 to 16 hidden layers and up to 4.4\nmillion weights.\n", "versions": [{"version": "v1", "created": "Fri, 15 Dec 2017 14:56:05 GMT"}], "update_date": "2017-12-18", "authors_parsed": [["Khan", "Altaf H.", ""]]}, {"id": "1712.05785", "submitter": "Xingyou Song", "authors": "Jordan Prosky, Xingyou Song, Andrew Tan, Michael Zhao", "title": "Sentiment Predictability for Stocks", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present our findings and experiments for stock-market\nprediction using various textual sentiment analysis tools, such as mood\nanalysis and event extraction, as well as prediction models, such as LSTMs and\nspecific convolutional architectures.\n", "versions": [{"version": "v1", "created": "Fri, 15 Dec 2017 18:41:53 GMT"}, {"version": "v2", "created": "Thu, 18 Jan 2018 20:24:40 GMT"}], "update_date": "2018-01-22", "authors_parsed": [["Prosky", "Jordan", ""], ["Song", "Xingyou", ""], ["Tan", "Andrew", ""], ["Zhao", "Michael", ""]]}, {"id": "1712.05790", "submitter": "Cl\\'ement Godard", "authors": "Cl\\'ement Godard, Kevin Matzen, Matt Uyttendaele", "title": "Deep Burst Denoising", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Noise is an inherent issue of low-light image capture, one which is\nexacerbated on mobile devices due to their narrow apertures and small sensors.\nOne strategy for mitigating noise in a low-light situation is to increase the\nshutter time of the camera, thus allowing each photosite to integrate more\nlight and decrease noise variance. However, there are two downsides of long\nexposures: (a) bright regions can exceed the sensor range, and (b) camera and\nscene motion will result in blurred images. Another way of gathering more light\nis to capture multiple short (thus noisy) frames in a \"burst\" and intelligently\nintegrate the content, thus avoiding the above downsides. In this paper, we use\nthe burst-capture strategy and implement the intelligent integration via a\nrecurrent fully convolutional deep neural net (CNN). We build our novel,\nmultiframe architecture to be a simple addition to any single frame denoising\nmodel, and design to handle an arbitrary number of noisy input frames. We show\nthat it achieves state of the art denoising results on our burst dataset,\nimproving on the best published multi-frame techniques, such as VBM4D and\nFlexISP. Finally, we explore other applications of image enhancement by\nintegrating content from multiple frames and demonstrate that our DNN\narchitecture generalizes well to image super-resolution.\n", "versions": [{"version": "v1", "created": "Fri, 15 Dec 2017 18:55:16 GMT"}], "update_date": "2017-12-18", "authors_parsed": [["Godard", "Cl\u00e9ment", ""], ["Matzen", "Kevin", ""], ["Uyttendaele", "Matt", ""]]}, {"id": "1712.05877", "submitter": "Bo Chen", "authors": "Benoit Jacob, Skirmantas Kligys, Bo Chen, Menglong Zhu, Matthew Tang,\n  Andrew Howard, Hartwig Adam, Dmitry Kalenichenko", "title": "Quantization and Training of Neural Networks for Efficient\n  Integer-Arithmetic-Only Inference", "comments": "14 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rising popularity of intelligent mobile devices and the daunting\ncomputational cost of deep learning-based models call for efficient and\naccurate on-device inference schemes. We propose a quantization scheme that\nallows inference to be carried out using integer-only arithmetic, which can be\nimplemented more efficiently than floating point inference on commonly\navailable integer-only hardware. We also co-design a training procedure to\npreserve end-to-end model accuracy post quantization. As a result, the proposed\nquantization scheme improves the tradeoff between accuracy and on-device\nlatency. The improvements are significant even on MobileNets, a model family\nknown for run-time efficiency, and are demonstrated in ImageNet classification\nand COCO detection on popular CPUs.\n", "versions": [{"version": "v1", "created": "Fri, 15 Dec 2017 23:56:52 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Jacob", "Benoit", ""], ["Kligys", "Skirmantas", ""], ["Chen", "Bo", ""], ["Zhu", "Menglong", ""], ["Tang", "Matthew", ""], ["Howard", "Andrew", ""], ["Adam", "Hartwig", ""], ["Kalenichenko", "Dmitry", ""]]}, {"id": "1712.05882", "submitter": "Taegyun Jeon", "authors": "Junghoon Seo and Taegyun Jeon", "title": "On reproduction of On the regularization of Wasserstein GANs", "comments": "9 pages, 9 figures, ICLR 2018 reproducibility challenge", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This report has several purposes. First, our report is written to investigate\nthe reproducibility of the submitted paper On the regularization of Wasserstein\nGANs (2018). Second, among the experiments performed in the submitted paper,\nfive aspects were emphasized and reproduced: learning speed, stability,\nrobustness against hyperparameter, estimating the Wasserstein distance, and\nvarious sampling method. Finally, we identify which parts of the contribution\ncan be reproduced, and at what cost in terms of resources. All source code for\nreproduction is open to the public.\n", "versions": [{"version": "v1", "created": "Sat, 16 Dec 2017 00:37:20 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Seo", "Junghoon", ""], ["Jeon", "Taegyun", ""]]}, {"id": "1712.05889", "submitter": "Robert Nishihara", "authors": "Philipp Moritz, Robert Nishihara, Stephanie Wang, Alexey Tumanov,\n  Richard Liaw, Eric Liang, Melih Elibol, Zongheng Yang, William Paul, Michael\n  I. Jordan, Ion Stoica", "title": "Ray: A Distributed Framework for Emerging AI Applications", "comments": "17 pages, 14 figures, 13th USENIX Symposium on Operating Systems\n  Design and Implementation, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The next generation of AI applications will continuously interact with the\nenvironment and learn from these interactions. These applications impose new\nand demanding systems requirements, both in terms of performance and\nflexibility. In this paper, we consider these requirements and present Ray---a\ndistributed system to address them. Ray implements a unified interface that can\nexpress both task-parallel and actor-based computations, supported by a single\ndynamic execution engine. To meet the performance requirements, Ray employs a\ndistributed scheduler and a distributed and fault-tolerant store to manage the\nsystem's control state. In our experiments, we demonstrate scaling beyond 1.8\nmillion tasks per second and better performance than existing specialized\nsystems for several challenging reinforcement learning applications.\n", "versions": [{"version": "v1", "created": "Sat, 16 Dec 2017 01:29:49 GMT"}, {"version": "v2", "created": "Sun, 30 Sep 2018 03:14:16 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Moritz", "Philipp", ""], ["Nishihara", "Robert", ""], ["Wang", "Stephanie", ""], ["Tumanov", "Alexey", ""], ["Liaw", "Richard", ""], ["Liang", "Eric", ""], ["Elibol", "Melih", ""], ["Yang", "Zongheng", ""], ["Paul", "William", ""], ["Jordan", "Michael I.", ""], ["Stoica", "Ion", ""]]}, {"id": "1712.05895", "submitter": "Tuo-Hung Hou", "authors": "Chih-Cheng Chang, Pin-Chun Chen, Teyuh Chou, I-Ting Wang, Boris Hudec,\n  Che-Chia Chang, Chia-Ming Tsai, Tian-Sheuan Chang, and Tuo-Hung Hou", "title": "Mitigating Asymmetric Nonlinear Weight Update Effects in Hardware Neural\n  Network based on Analog Resistive Synapse", "comments": "IEEE Journal on Emerging and Selected Topics in Circuits and Systems\n  2017", "journal-ref": null, "doi": "10.1109/JETCAS.2017.2771529", "report-no": null, "categories": "cs.LG cs.ET cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Asymmetric nonlinear weight update is considered as one of the major\nobstacles for realizing hardware neural networks based on analog resistive\nsynapses because it significantly compromises the online training capability.\nThis paper provides new solutions to this critical issue through\nco-optimization with the hardware-applicable deep-learning algorithms. New\ninsights on engineering activation functions and a threshold weight update\nscheme effectively suppress the undesirable training noise induced by\ninaccurate weight update. We successfully trained a two-layer perceptron\nnetwork online and improved the classification accuracy of MNIST handwritten\ndigit dataset to 87.8/94.8% by using 6-bit/8-bit analog synapses, respectively,\nwith extremely high asymmetric nonlinearity.\n", "versions": [{"version": "v1", "created": "Sat, 16 Dec 2017 02:45:02 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Chang", "Chih-Cheng", ""], ["Chen", "Pin-Chun", ""], ["Chou", "Teyuh", ""], ["Wang", "I-Ting", ""], ["Hudec", "Boris", ""], ["Chang", "Che-Chia", ""], ["Tsai", "Chia-Ming", ""], ["Chang", "Tian-Sheuan", ""], ["Hou", "Tuo-Hung", ""]]}, {"id": "1712.05901", "submitter": "Jung Woo Ha", "authors": "Jung-Woo Ha, Adrian Kim, Chanju Kim, Jangyeon Park, Sunghun Kim", "title": "Automatic Music Highlight Extraction using Convolutional Recurrent\n  Attention Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MM cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Music highlights are valuable contents for music services. Most methods\nfocused on low-level signal features. We propose a method for extracting\nhighlights using high-level features from convolutional recurrent attention\nnetworks (CRAN). CRAN utilizes convolution and recurrent layers for sequential\nlearning with an attention mechanism. The attention allows CRAN to capture\nsignificant snippets for distinguishing between genres, thus being used as a\nhigh-level feature. CRAN was evaluated on over 32,000 popular tracks in Korea\nfor two months. Experimental results show our method outperforms three baseline\nmethods through quantitative and qualitative evaluations. Also, we analyze the\neffects of attention and sequence information on performance.\n", "versions": [{"version": "v1", "created": "Sat, 16 Dec 2017 04:27:36 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Ha", "Jung-Woo", ""], ["Kim", "Adrian", ""], ["Kim", "Chanju", ""], ["Park", "Jangyeon", ""], ["Kim", "Sunghun", ""]]}, {"id": "1712.05902", "submitter": "Jung Woo Ha", "authors": "Nako Sung, Minkyu Kim, Hyunwoo Jo, Youngil Yang, Jingwoong Kim,\n  Leonard Lausen, Youngkwan Kim, Gayoung Lee, Donghyun Kwak, Jung-Woo Ha,\n  Sunghun Kim", "title": "NSML: A Machine Learning Platform That Enables You to Focus on Your\n  Models", "comments": "8 pages, 4figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning libraries such as TensorFlow and PyTorch simplify model\nimplementation. However, researchers are still required to perform a\nnon-trivial amount of manual tasks such as GPU allocation, training status\ntracking, and comparison of models with different hyperparameter settings. We\npropose a system to handle these tasks and help researchers focus on models. We\npresent the requirements of the system based on a collection of discussions\nfrom an online study group comprising 25k members. These include automatic GPU\nallocation, learning status visualization, handling model parameter snapshots\nas well as hyperparameter modification during learning, and comparison of\nperformance metrics between models via a leaderboard. We describe the system\narchitecture that fulfills these requirements and present a proof-of-concept\nimplementation, NAVER Smart Machine Learning (NSML). We test the system and\nconfirm substantial efficiency improvements for model development.\n", "versions": [{"version": "v1", "created": "Sat, 16 Dec 2017 04:28:14 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Sung", "Nako", ""], ["Kim", "Minkyu", ""], ["Jo", "Hyunwoo", ""], ["Yang", "Youngil", ""], ["Kim", "Jingwoong", ""], ["Lausen", "Leonard", ""], ["Kim", "Youngkwan", ""], ["Lee", "Gayoung", ""], ["Kwak", "Donghyun", ""], ["Ha", "Jung-Woo", ""], ["Kim", "Sunghun", ""]]}, {"id": "1712.05914", "submitter": "Thai Hoang Dinh DTH", "authors": "Khoi Khac Nguyen, Dinh Thai Hoang, Dusit Niyato, Ping Wang, Diep\n  Nguyen, and Eryk Dutkiewicz", "title": "Cyberattack Detection in Mobile Cloud Computing: A Deep Learning\n  Approach", "comments": "6 pages, 3 figures, 1 table, WCNC 2018 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid growth of mobile applications and cloud computing, mobile\ncloud computing has attracted great interest from both academia and industry.\nHowever, mobile cloud applications are facing security issues such as data\nintegrity, users' confidentiality, and service availability. A preventive\napproach to such problems is to detect and isolate cyber threats before they\ncan cause serious impacts to the mobile cloud computing system. In this paper,\nwe propose a novel framework that leverages a deep learning approach to detect\ncyberattacks in mobile cloud environment. Through experimental results, we show\nthat our proposed framework not only recognizes diverse cyberattacks, but also\nachieves a high accuracy (up to 97.11%) in detecting the attacks. Furthermore,\nwe present the comparisons with current machine learning-based approaches to\ndemonstrate the effectiveness of our proposed solution.\n", "versions": [{"version": "v1", "created": "Sat, 16 Dec 2017 07:24:55 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Nguyen", "Khoi Khac", ""], ["Hoang", "Dinh Thai", ""], ["Niyato", "Dusit", ""], ["Wang", "Ping", ""], ["Nguyen", "Diep", ""], ["Dutkiewicz", "Eryk", ""]]}, {"id": "1712.05929", "submitter": "Jin-Yuan Wang", "authors": "Jun-Bo Wang, Junyuan Wang, Yongpeng Wu, Jin-Yuan Wang, Huiling Zhu,\n  Min Lin, Jiangzhou Wang", "title": "A Machine Learning Framework for Resource Allocation Assisted by Cloud\n  Computing", "comments": "19 pages with 6 figures, accepted by IEEE Network Magazine", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventionally, the resource allocation is formulated as an optimization\nproblem and solved online with instantaneous scenario information. Since most\nresource allocation problems are not convex, the optimal solutions are very\ndifficult to be obtained in real time. Lagrangian relaxation or greedy methods\nare then often employed, which results in performance loss. Therefore, the\nconventional methods of resource allocation are facing great challenges to meet\nthe ever-increasing QoS requirements of users with scarce radio resource.\nAssisted by cloud computing, a huge amount of historical data on scenarios can\nbe collected for extracting similarities among scenarios using machine\nlearning. Moreover, optimal or near-optimal solutions of historical scenarios\ncan be searched offline and stored in advance. When the measured data of\ncurrent scenario arrives, the current scenario is compared with historical\nscenarios to find the most similar one. Then, the optimal or near-optimal\nsolution in the most similar historical scenario is adopted to allocate the\nradio resources for the current scenario. To facilitate the application of new\ndesign philosophy, a machine learning framework is proposed for resource\nallocation assisted by cloud computing. An example of beam allocation in\nmulti-user massive multiple-input-multiple-output (MIMO) systems shows that the\nproposed machine-learning based resource allocation outperforms conventional\nmethods.\n", "versions": [{"version": "v1", "created": "Sat, 16 Dec 2017 10:11:54 GMT"}], "update_date": "2017-12-20", "authors_parsed": [["Wang", "Jun-Bo", ""], ["Wang", "Junyuan", ""], ["Wu", "Yongpeng", ""], ["Wang", "Jin-Yuan", ""], ["Zhu", "Huiling", ""], ["Lin", "Min", ""], ["Wang", "Jiangzhou", ""]]}, {"id": "1712.05934", "submitter": "Han Xiao Almighty", "authors": "Han Xiao", "title": "NDT: Neual Decision Tree Towards Fully Functioned Neural Graph", "comments": "This is the draft paper. I will refine the paper until accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Though traditional algorithms could be embedded into neural architectures\nwith the proposed principle of \\cite{xiao2017hungarian}, the variables that\nonly occur in the condition of branch could not be updated as a special case.\nTo tackle this issue, we multiply the conditioned branches with Dirac symbol\n(i.e. $\\mathbf{1}_{x>0}$), then approximate Dirac symbol with the continuous\nfunctions (e.g. $1 - e^{-\\alpha|x|}$). In this way, the gradients of\ncondition-specific variables could be worked out in the back-propagation\nprocess, approximately, making a fully functioned neural graph. Within our\nnovel principle, we propose the neural decision tree \\textbf{(NDT)}, which\ntakes simplified neural networks as decision function in each branch and\nemploys complex neural networks to generate the output in each leaf. Extensive\nexperiments verify our theoretical analysis and demonstrate the effectiveness\nof our model.\n", "versions": [{"version": "v1", "created": "Sat, 16 Dec 2017 10:42:57 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Xiao", "Han", ""]]}, {"id": "1712.05954", "submitter": "Vasily Morzhakov", "authors": "Vasily Morzhakov, Alexey Redozubov", "title": "An Artificial Neural Network Architecture Based on Context\n  Transformations in Cortical Minicolumns", "comments": "9 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cortical minicolumns are considered a model of cortical organization. Their\nfunction is still a source of research and not reflected properly in modern\narchitecture of nets in algorithms of Artificial Intelligence. We assume its\nfunction and describe it in this article. Furthermore, we show how this\nproposal allows to construct a new architecture, that is not based on\nconvolutional neural networks, test it on MNIST data and receive close to\nConvolutional Neural Network accuracy. We also show that the proposed\narchitecture possesses an ability to train on a small quantity of samples. To\nachieve these results, we enable the minicolumns to remember context\ntransformations.\n", "versions": [{"version": "v1", "created": "Sat, 16 Dec 2017 13:14:03 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Morzhakov", "Vasily", ""], ["Redozubov", "Alexey", ""]]}, {"id": "1712.05997", "submitter": "Amir Karami", "authors": "Amir Karami", "title": "Taming Wild High Dimensional Text Data with a Fuzzy Lash", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.IR cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The bag of words (BOW) represents a corpus in a matrix whose elements are the\nfrequency of words. However, each row in the matrix is a very high-dimensional\nsparse vector. Dimension reduction (DR) is a popular method to address sparsity\nand high-dimensionality issues. Among different strategies to develop DR\nmethod, Unsupervised Feature Transformation (UFT) is a popular strategy to map\nall words on a new basis to represent BOW. The recent increase of text data and\nits challenges imply that DR area still needs new perspectives. Although a wide\nrange of methods based on the UFT strategy has been developed, the fuzzy\napproach has not been considered for DR based on this strategy. This research\ninvestigates the application of fuzzy clustering as a DR method based on the\nUFT strategy to collapse BOW matrix to provide a lower-dimensional\nrepresentation of documents instead of the words in a corpus. The quantitative\nevaluation shows that fuzzy clustering produces superior performance and\nfeatures to Principal Components Analysis (PCA) and Singular Value\nDecomposition (SVD), two popular DR methods based on the UFT strategy.\n", "versions": [{"version": "v1", "created": "Sat, 16 Dec 2017 17:57:57 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Karami", "Amir", ""]]}, {"id": "1712.06015", "submitter": "Mu Qiao", "authors": "Mu Qiao, Luis Bathen, Simon-Pierre G\\'enot, Sunhwan Lee, Ramani\n  Routray", "title": "StackInsights: Cognitive Learning for Hybrid Cloud Readiness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hybrid cloud is an integrated cloud computing environment utilizing a mix of\npublic cloud, private cloud, and on-premise traditional IT infrastructures.\nWorkload awareness, defined as a detailed full range understanding of each\nindividual workload, is essential in implementing the hybrid cloud. While it is\ncritical to perform an accurate analysis to determine which workloads are\nappropriate for on-premise deployment versus which workloads can be migrated to\na cloud off-premise, the assessment is mainly performed by rule or policy based\napproaches. In this paper, we introduce StackInsights, a novel cognitive system\nto automatically analyze and predict the cloud readiness of workloads for an\nenterprise. Our system harnesses the critical metrics across the entire stack:\n1) infrastructure metrics, 2) data relevance metrics, and 3) application\ntaxonomy, to identify workloads that have characteristics of a) low sensitivity\nwith respect to business security, criticality and compliance, and b) low\nresponse time requirements and access patterns. Since the capture of the data\nrelevance metrics involves an intrusive and in-depth scanning of the content of\nstorage objects, a machine learning model is applied to perform the business\nrelevance classification by learning from the meta level metrics harnessed\nacross stack. In contrast to traditional methods, StackInsights significantly\nreduces the total time for hybrid cloud readiness assessment by orders of\nmagnitude.\n", "versions": [{"version": "v1", "created": "Sat, 16 Dec 2017 20:14:53 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Qiao", "Mu", ""], ["Bathen", "Luis", ""], ["G\u00e9not", "Simon-Pierre", ""], ["Lee", "Sunhwan", ""], ["Routray", "Ramani", ""]]}, {"id": "1712.06047", "submitter": "Aditya Devarakonda", "authors": "Aditya Devarakonda, Kimon Fountoulakis, James Demmel, Michael W.\n  Mahoney", "title": "Avoiding Synchronization in First-Order Methods for Sparse Convex\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parallel computing has played an important role in speeding up convex\noptimization methods for big data analytics and large-scale machine learning\n(ML). However, the scalability of these optimization methods is inhibited by\nthe cost of communicating and synchronizing processors in a parallel setting.\nIterative ML methods are particularly sensitive to communication cost since\nthey often require communication every iteration. In this work, we extend\nwell-known techniques from Communication-Avoiding Krylov subspace methods to\nfirst-order, block coordinate descent methods for Support Vector Machines and\nProximal Least-Squares problems. Our Synchronization-Avoiding (SA) variants\nreduce the latency cost by a tunable factor of $s$ at the expense of a factor\nof $s$ increase in flops and bandwidth costs. We show that the SA-variants are\nnumerically stable and can attain large speedups of up to $5.1\\times$ on a Cray\nXC30 supercomputer.\n", "versions": [{"version": "v1", "created": "Sun, 17 Dec 2017 02:15:15 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Devarakonda", "Aditya", ""], ["Fountoulakis", "Kimon", ""], ["Demmel", "James", ""], ["Mahoney", "Michael W.", ""]]}, {"id": "1712.06050", "submitter": "Rui Gao", "authors": "Rui Gao, Xi Chen, Anton J. Kleywegt", "title": "Wasserstein Distributionally Robust Optimization and Variation\n  Regularization", "comments": "The paper is previously titled \"Wasserstein Distributional Robustness\n  and Regularization in Statistical Learning\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wasserstein distributionally robust optimization (DRO) has recently achieved\nempirical success for various applications in operations research and machine\nlearning, owing partly to its regularization effect. Although connection\nbetween Wasserstein DRO and regularization has been established in several\nsettings, existing results often require restrictive assumptions, such as\nsmoothness or convexity, that are not satisfied for many problems. In this\npaper, we develop a general theory on the variation regularization effect of\nthe Wasserstein DRO - a new form of regularization that generalizes\ntotal-variation regularization, Lipschitz regularization and gradient\nregularization. Our results cover possibly non-convex and non-smooth losses and\nlosses on non-Euclidean spaces. Examples include multi-item newsvendor,\nportfolio selection, linear prediction, neural networks, manifold learning, and\nintensity estimation for Poisson processes, etc. As an application of our\ntheory of variation regularization, we derive new generalization guarantees for\nadversarial robust learning.\n", "versions": [{"version": "v1", "created": "Sun, 17 Dec 2017 02:47:14 GMT"}, {"version": "v2", "created": "Tue, 26 Dec 2017 15:50:30 GMT"}, {"version": "v3", "created": "Fri, 30 Oct 2020 17:56:21 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Gao", "Rui", ""], ["Chen", "Xi", ""], ["Kleywegt", "Anton J.", ""]]}, {"id": "1712.06076", "submitter": "Rushin Gindra", "authors": "Rushin Gindra (1 and 2), Srushti Kotak (1 and 2), Asmita Natekar (1\n  and 2) and Grishma Sharma (1 and 3) ((1) K. J. Somaiya College of\n  Engineering, (2) Undergraduate Scholar, (3) Assistant Professor and Project\n  Adviser)", "title": "Using Deep learning methods for generation of a personalized list of\n  shuffled songs", "comments": "My Undergraduate Project. Future research may/may not be in the same\n  field", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The shuffle mode, where songs are played in a randomized order that is\ndecided upon for all tracks at once, is widely found and known to exist in\nmusic player systems. There are only few music enthusiasts who use this mode\nsince it either is too random to suit their mood or it keeps on repeating the\nsame list every time. In this paper, we propose to build a convolutional deep\nbelief network(CDBN) that is trained to perform genre recognition based on\naudio features retrieved from the records of the Million Song Dataset. The\nlearned parameters shall be used to initialize a multi-layer perceptron which\ntakes extracted features of user's playlist as input alongside the metadata to\nclassify to various categories. These categories will be shuffled\nretrospectively based on the metadata to autonomously provide with a list that\nis efficacious in playing songs that are desired by humans in normal\nconditions.\n", "versions": [{"version": "v1", "created": "Sun, 17 Dec 2017 09:18:20 GMT"}, {"version": "v2", "created": "Sun, 1 Sep 2019 06:10:48 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Gindra", "Rushin", "", "1 and 2"], ["Kotak", "Srushti", "", "1 and 2"], ["Natekar", "Asmita", "", "1\n  and 2"], ["Sharma", "Grishma", "", "1 and 3"]]}, {"id": "1712.06087", "submitter": "Assaf Shocher", "authors": "Assaf Shocher, Nadav Cohen, Michal Irani", "title": "\"Zero-Shot\" Super-Resolution using Deep Internal Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning has led to a dramatic leap in Super-Resolution (SR) performance\nin the past few years. However, being supervised, these SR methods are\nrestricted to specific training data, where the acquisition of the\nlow-resolution (LR) images from their high-resolution (HR) counterparts is\npredetermined (e.g., bicubic downscaling), without any distracting artifacts\n(e.g., sensor noise, image compression, non-ideal PSF, etc). Real LR images,\nhowever, rarely obey these restrictions, resulting in poor SR results by SotA\n(State of the Art) methods. In this paper we introduce \"Zero-Shot\" SR, which\nexploits the power of Deep Learning, but does not rely on prior training. We\nexploit the internal recurrence of information inside a single image, and train\na small image-specific CNN at test time, on examples extracted solely from the\ninput image itself. As such, it can adapt itself to different settings per\nimage. This allows to perform SR of real old photos, noisy images, biological\ndata, and other images where the acquisition process is unknown or non-ideal.\nOn such images, our method outperforms SotA CNN-based SR methods, as well as\nprevious unsupervised SR methods. To the best of our knowledge, this is the\nfirst unsupervised CNN-based SR method.\n", "versions": [{"version": "v1", "created": "Sun, 17 Dec 2017 11:00:30 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Shocher", "Assaf", ""], ["Cohen", "Nadav", ""], ["Irani", "Michal", ""]]}, {"id": "1712.06096", "submitter": "Jong Chul Ye", "authors": "Yeo Hun Yoon, Shujaat Khan, Jaeyoung Huh, and Jong Chul Ye", "title": "Efficient B-mode Ultrasound Image Reconstruction from Sub-sampled RF\n  Data using Deep Learning", "comments": "The title has been changed. This version will appear in IEEE Trans.\n  on Medical Imaging", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In portable, three dimensional, and ultra-fast ultrasound imaging systems,\nthere is an increasing demand for the reconstruction of high quality images\nfrom a limited number of radio-frequency (RF) measurements due to receiver (Rx)\nor transmit (Xmit) event sub-sampling. However, due to the presence of side\nlobe artifacts from RF sub-sampling, the standard beamformer often produces\nblurry images with less contrast, which are unsuitable for diagnostic purposes.\nExisting compressed sensing approaches often require either hardware changes or\ncomputationally expensive algorithms, but their quality improvements are\nlimited. To address this problem, here we propose a novel deep learning\napproach that directly interpolates the missing RF data by utilizing redundancy\nin the Rx-Xmit plane. Our extensive experimental results using sub-sampled RF\ndata from a multi-line acquisition B-mode system confirm that the proposed\nmethod can effectively reduce the data rate without sacrificing image quality.\n", "versions": [{"version": "v1", "created": "Sun, 17 Dec 2017 12:15:08 GMT"}, {"version": "v2", "created": "Thu, 21 Dec 2017 03:58:18 GMT"}, {"version": "v3", "created": "Tue, 7 Aug 2018 09:19:13 GMT"}], "update_date": "2018-08-08", "authors_parsed": [["Yoon", "Yeo Hun", ""], ["Khan", "Shujaat", ""], ["Huh", "Jaeyoung", ""], ["Ye", "Jong Chul", ""]]}, {"id": "1712.06115", "submitter": "Alexander Keller", "authors": "Alexander Keller and Ken Dahm", "title": "Integral Equations and Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As both light transport simulation and reinforcement learning are ruled by\nthe same Fredholm integral equation of the second kind, reinforcement learning\ntechniques may be used for photorealistic image synthesis: Efficiency may be\ndramatically improved by guiding light transport paths by an approximate\nsolution of the integral equation that is learned during rendering. In the\nlight of the recent advances in reinforcement learning for playing games, we\ninvestigate the representation of an approximate solution of an integral\nequation by artificial neural networks and derive a loss function for that\npurpose. The resulting Monte Carlo and quasi-Monte Carlo methods train neural\nnetworks with standard information instead of linear information and naturally\nare able to generate an arbitrary number of training samples. The methods are\ndemonstrated for applications in light transport simulation.\n", "versions": [{"version": "v1", "created": "Sun, 17 Dec 2017 14:02:19 GMT"}, {"version": "v2", "created": "Sun, 4 Nov 2018 15:48:22 GMT"}, {"version": "v3", "created": "Wed, 30 Jan 2019 07:39:06 GMT"}], "update_date": "2019-01-31", "authors_parsed": [["Keller", "Alexander", ""], ["Dahm", "Ken", ""]]}, {"id": "1712.06131", "submitter": "Ambra Demontis", "authors": "Ambra Demontis, Marco Melis, Battista Biggio, Giorgio Fumera and Fabio\n  Roli", "title": "Super-sparse Learning in Similarity Spaces", "comments": null, "journal-ref": "IEEE Computational Intell. Mag., 11(4):36-45, Nov 2016", "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In several applications, input samples are more naturally represented in\nterms of similarities between each other, rather than in terms of feature\nvectors. In these settings, machine-learning algorithms can become very\ncomputationally demanding, as they may require matching the test samples\nagainst a very large set of reference prototypes. To mitigate this issue,\ndifferent approaches have been developed to reduce the number of required\nreference prototypes. Current reduction approaches select a small subset of\nrepresentative prototypes in the space induced by the similarity measure, and\nthen separately train the classification function on the reduced subset.\nHowever, decoupling these two steps may not allow reducing the number of\nprototypes effectively without compromising accuracy. We overcome this\nlimitation by jointly learning the classification function along with an\noptimal set of virtual prototypes, whose number can be either fixed a priori or\noptimized according to application-specific criteria. Creating a super-sparse\nset of virtual prototypes provides much sparser solutions, drastically reducing\ncomplexity at test time, at the expense of a slightly increased complexity\nduring training. A much smaller set of prototypes also results in\neasier-to-interpret decisions. We empirically show that our approach can reduce\nup to ten times the complexity of Support Vector Machines, LASSO and ridge\nregression at test time, without almost affecting their classification\naccuracy.\n", "versions": [{"version": "v1", "created": "Sun, 17 Dec 2017 15:59:38 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Demontis", "Ambra", ""], ["Melis", "Marco", ""], ["Biggio", "Battista", ""], ["Fumera", "Giorgio", ""], ["Roli", "Fabio", ""]]}, {"id": "1712.06132", "submitter": "Sakyasingha Dasgupta", "authors": "Rudy Raymond, Takayuki Osogami and Sakyasingha Dasgupta", "title": "Dynamic Boltzmann Machines for Second Order Moments and Generalized\n  Gaussian Distributions", "comments": "7 pages, 3 figures. Accepted and presented in NIPS 2017 (time-series\n  workshop) at Long Beach, California", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic Boltzmann Machine (DyBM) has been shown highly efficient to predict\ntime-series data. Gaussian DyBM is a DyBM that assumes the predicted data is\ngenerated by a Gaussian distribution whose first-order moment (mean)\ndynamically changes over time but its second-order moment (variance) is fixed.\nHowever, in many financial applications, the assumption is quite limiting in\ntwo aspects. First, even when the data follows a Gaussian distribution, its\nvariance may change over time. Such variance is also related to important\ntemporal economic indicators such as the market volatility. Second, financial\ntime-series data often requires learning datasets generated by the generalized\nGaussian distribution with an additional shape parameter that is important to\napproximate heavy-tailed distributions. Addressing those aspects, we show how\nto extend DyBM that results in significant performance improvement in\npredicting financial time-series data.\n", "versions": [{"version": "v1", "created": "Sun, 17 Dec 2017 16:08:53 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Raymond", "Rudy", ""], ["Osogami", "Takayuki", ""], ["Dasgupta", "Sakyasingha", ""]]}, {"id": "1712.06139", "submitter": "Christopher Olston", "authors": "Christopher Olston, Noah Fiedel, Kiril Gorovoy, Jeremiah Harmsen, Li\n  Lao, Fangwei Li, Vinu Rajashekhar, Sukriti Ramesh, Jordan Soyke", "title": "TensorFlow-Serving: Flexible, High-Performance ML Serving", "comments": "Presented at NIPS 2017 Workshop on ML Systems\n  (http://learningsys.org/nips17/acceptedpapers.html)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe TensorFlow-Serving, a system to serve machine learning models\ninside Google which is also available in the cloud and via open-source. It is\nextremely flexible in terms of the types of ML platforms it supports, and ways\nto integrate with systems that convey new models and updated versions from\ntraining to serving. At the same time, the core code paths around model lookup\nand inference have been carefully optimized to avoid performance pitfalls\nobserved in naive implementations. Google uses it in many production\ndeployments, including a multi-tenant model hosting service called TFS^2.\n", "versions": [{"version": "v1", "created": "Sun, 17 Dec 2017 16:36:26 GMT"}, {"version": "v2", "created": "Wed, 27 Dec 2017 20:43:02 GMT"}], "update_date": "2017-12-29", "authors_parsed": [["Olston", "Christopher", ""], ["Fiedel", "Noah", ""], ["Gorovoy", "Kiril", ""], ["Harmsen", "Jeremiah", ""], ["Lao", "Li", ""], ["Li", "Fangwei", ""], ["Rajashekhar", "Vinu", ""], ["Ramesh", "Sukriti", ""], ["Soyke", "Jordan", ""]]}, {"id": "1712.06148", "submitter": "Nathan Killoran", "authors": "Nathan Killoran, Leo J. Lee, Andrew Delong, David Duvenaud, Brendan J.\n  Frey", "title": "Generating and designing DNA with deep generative models", "comments": "NIPS 2017 Computational Biology Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.GN stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose generative neural network methods to generate DNA sequences and\ntune them to have desired properties. We present three approaches: creating\nsynthetic DNA sequences using a generative adversarial network; a DNA-based\nvariant of the activation maximization (\"deep dream\") design method; and a\njoint procedure which combines these two approaches together. We show that\nthese tools capture important structures of the data and, when applied to\ndesigning probes for protein binding microarrays, allow us to generate new\nsequences whose properties are estimated to be superior to those found in the\ntraining data. We believe that these results open the door for applying deep\ngenerative models to advance genomics research.\n", "versions": [{"version": "v1", "created": "Sun, 17 Dec 2017 17:23:10 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Killoran", "Nathan", ""], ["Lee", "Leo J.", ""], ["Delong", "Andrew", ""], ["Duvenaud", "David", ""], ["Frey", "Brendan J.", ""]]}, {"id": "1712.06174", "submitter": "Matteo Fischetti", "authors": "Matteo Fischetti and Jason Jo", "title": "Deep Neural Networks as 0-1 Mixed Integer Linear Programs: A Feasibility\n  Study", "comments": "submitted to an international conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) are very popular these days, and are the subject\nof a very intense investigation. A DNN is made by layers of internal units (or\nneurons), each of which computes an affine combination of the output of the\nunits in the previous layer, applies a nonlinear operator, and outputs the\ncorresponding value (also known as activation). A commonly-used nonlinear\noperator is the so-called rectified linear unit (ReLU), whose output is just\nthe maximum between its input value and zero. In this (and other similar cases\nlike max pooling, where the max operation involves more than one input value),\none can model the DNN as a 0-1 Mixed Integer Linear Program (0-1 MILP) where\nthe continuous variables correspond to the output values of each unit, and a\nbinary variable is associated with each ReLU to model its yes/no nature. In\nthis paper we discuss the peculiarity of this kind of 0-1 MILP models, and\ndescribe an effective bound-tightening technique intended to ease its solution.\nWe also present possible applications of the 0-1 MILP model arising in feature\nvisualization and in the construction of adversarial examples. Preliminary\ncomputational results are reported, aimed at investigating (on small DNNs) the\ncomputational performance of a state-of-the-art MILP solver when applied to a\nknown test case, namely, hand-written digit recognition.\n", "versions": [{"version": "v1", "created": "Sun, 17 Dec 2017 20:11:39 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Fischetti", "Matteo", ""], ["Jo", "Jason", ""]]}, {"id": "1712.06199", "submitter": "David Alvarez-Melis", "authors": "David Alvarez-Melis, Tommi S. Jaakkola, Stefanie Jegelka", "title": "Structured Optimal Transport", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal Transport has recently gained interest in machine learning for\napplications ranging from domain adaptation, sentence similarities to deep\nlearning. Yet, its ability to capture frequently occurring structure beyond the\n\"ground metric\" is limited. In this work, we develop a nonlinear generalization\nof (discrete) optimal transport that is able to reflect much additional\nstructure. We demonstrate how to leverage the geometry of this new model for\nfast algorithms, and explore connections and properties. Illustrative\nexperiments highlight the benefit of the induced structured couplings for tasks\nin domain adaptation and natural language processing.\n", "versions": [{"version": "v1", "created": "Sun, 17 Dec 2017 22:51:40 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Alvarez-Melis", "David", ""], ["Jaakkola", "Tommi S.", ""], ["Jegelka", "Stefanie", ""]]}, {"id": "1712.06214", "submitter": "David Ledbetter", "authors": "Cameron Carlin, Long Van Ho, David Ledbetter, Melissa Aczon, Randall\n  Wetzel", "title": "Predicting Individual Physiologically Acceptable States for Discharge\n  from a Pediatric Intensive Care Unit", "comments": "8 pages with appendix, 6 figures (4 of which comprise 1 meta figure),\n  4 tables in main section, 10 tables including appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: Predict patient-specific vitals deemed medically acceptable for\ndischarge from a pediatric intensive care unit (ICU). Design: The means of each\npatient's hr, sbp and dbp measurements between their medical and physical\ndischarge from the ICU were computed as a proxy for their physiologically\nacceptable state space (PASS) for successful ICU discharge. These individual\nPASS values were compared via root mean squared error (rMSE) to population\nage-normal vitals, a polynomial regression through the PASS values of a\nPediatric ICU (PICU) population and predictions from two recurrent neural\nnetwork models designed to predict personalized PASS within the first twelve\nhours following ICU admission. Setting: PICU at Children's Hospital Los Angeles\n(CHLA). Patients: 6,899 PICU episodes (5,464 patients) collected between 2009\nand 2016. Interventions: None. Measurements: Each episode data contained 375\nvariables representing vitals, labs, interventions, and drugs. They also\nincluded a time indicator for PICU medical discharge and physical discharge.\nMain Results: The rMSEs between individual PASS values and population\nage-normals (hr: 25.9 bpm, sbp: 13.4 mmHg, dbp: 13.0 mmHg) were larger than the\nrMSEs corresponding to the polynomial regression (hr: 19.1 bpm, sbp: 12.3 mmHg,\ndbp: 10.8 mmHg). The rMSEs from the best performing RNN model were the lowest\n(hr: 16.4 bpm; sbp: 9.9 mmHg, dbp: 9.0 mmHg). Conclusion: PICU patients are a\nunique subset of the general population, and general age-normal vitals may not\nbe suitable as target values indicating physiologic stability at discharge.\nAge-normal vitals that were specifically derived from the medical-to-physical\ndischarge window of ICU patients may be more appropriate targets for\n'acceptable' physiologic state for critical care patients. Going beyond simple\nage bins, an RNN model can provide more personalized target values.\n", "versions": [{"version": "v1", "created": "Mon, 18 Dec 2017 01:13:53 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Carlin", "Cameron", ""], ["Van Ho", "Long", ""], ["Ledbetter", "David", ""], ["Aczon", "Melissa", ""], ["Wetzel", "Randall", ""]]}, {"id": "1712.06228", "submitter": "Jin-Hwa Kim", "authors": "Jin-Hwa Kim, Byoung-Tak Zhang", "title": "Visual Explanations from Hadamard Product in Multimodal Deep Networks", "comments": "8 pages, 5 figures, including appendix, NIPS 2017 Workshop on\n  Visually-Grounded Interaction and Language (ViGIL)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The visual explanation of learned representation of models helps to\nunderstand the fundamentals of learning. The attentional models of previous\nworks used to visualize the attended regions over an image or text using their\nlearned weights to confirm their intended mechanism. Kim et al. (2016) show\nthat the Hadamard product in multimodal deep networks, which is well-known for\nthe joint function of visual question answering tasks, implicitly performs an\nattentional mechanism for visual inputs. In this work, we extend their work to\nshow that the Hadamard product in multimodal deep networks performs not only\nfor visual inputs but also for textual inputs simultaneously using the proposed\ngradient-based visualization technique. The attentional effect of Hadamard\nproduct is visualized for both visual and textual inputs by analyzing the two\ninputs and an output of the Hadamard product with the proposed method and\ncompared with learned attentional weights of a visual question answering model.\n", "versions": [{"version": "v1", "created": "Mon, 18 Dec 2017 02:37:20 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Kim", "Jin-Hwa", ""], ["Zhang", "Byoung-Tak", ""]]}, {"id": "1712.06245", "submitter": "Zhuoran Yang", "authors": "Zhuoran Yang, Lin F. Yang, Ethan X. Fang, Tuo Zhao, Zhaoran Wang,\n  Matey Neykov", "title": "Misspecified Nonconvex Statistical Optimization for Phase Retrieval", "comments": "56 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing nonconvex statistical optimization theory and methods crucially rely\non the correct specification of the underlying \"true\" statistical models. To\naddress this issue, we take a first step towards taming model misspecification\nby studying the high-dimensional sparse phase retrieval problem with\nmisspecified link functions. In particular, we propose a simple variant of the\nthresholded Wirtinger flow algorithm that, given a proper initialization,\nlinearly converges to an estimator with optimal statistical accuracy for a\nbroad family of unknown link functions. We further provide extensive numerical\nexperiments to support our theoretical findings.\n", "versions": [{"version": "v1", "created": "Mon, 18 Dec 2017 04:06:08 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Yang", "Zhuoran", ""], ["Yang", "Lin F.", ""], ["Fang", "Ethan X.", ""], ["Zhao", "Tuo", ""], ["Wang", "Zhaoran", ""], ["Neykov", "Matey", ""]]}, {"id": "1712.06246", "submitter": "Guoqing Chao", "authors": "Guoqing Chao, Shiliang Sun, Jinbo Bi", "title": "A Survey on Multi-View Clustering", "comments": "17 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With advances in information acquisition technologies, multi-view data become\nubiquitous. Multi-view learning has thus become more and more popular in\nmachine learning and data mining fields. Multi-view unsupervised or\nsemi-supervised learning, such as co-training, co-regularization has gained\nconsiderable attention. Although recently, multi-view clustering (MVC) methods\nhave been developed rapidly, there has not been a survey to summarize and\nanalyze the current progress. Therefore, this paper reviews the common\nstrategies for combining multiple views of data and based on this summary we\npropose a novel taxonomy of the MVC approaches. We further discuss the\nrelationships between MVC and multi-view representation, ensemble clustering,\nmulti-task clustering, multi-view supervised and semi-supervised learning.\nSeveral representative real-world applications are elaborated. To promote\nfuture development of MVC, we envision several open problems that may require\nfurther investigation and thorough examination.\n", "versions": [{"version": "v1", "created": "Mon, 18 Dec 2017 04:07:42 GMT"}, {"version": "v2", "created": "Tue, 3 Apr 2018 04:20:51 GMT"}], "update_date": "2018-04-04", "authors_parsed": [["Chao", "Guoqing", ""], ["Sun", "Shiliang", ""], ["Bi", "Jinbo", ""]]}, {"id": "1712.06260", "submitter": "Takashi Matsubara", "authors": "Takashi Matsubara, Tetsuo Tashiro, Kuniaki Uehara", "title": "Deep Neural Generative Model of Functional MRI Images for Psychiatric\n  Disorder Diagnosis", "comments": "accepted version, 12 pages", "journal-ref": "IEEE Transactions on Biomedical Engineering, 2019", "doi": "10.1109/TBME.2019.2895663", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate diagnosis of psychiatric disorders plays a critical role in\nimproving the quality of life for patients and potentially supports the\ndevelopment of new treatments. Many studies have been conducted on machine\nlearning techniques that seek brain imaging data for specific biomarkers of\ndisorders. These studies have encountered the following dilemma: A direct\nclassification overfits to a small number of high-dimensional samples but\nunsupervised feature-extraction has the risk of extracting a signal of no\ninterest. In addition, such studies often provided only diagnoses for patients\nwithout presenting the reasons for these diagnoses. This study proposed a deep\nneural generative model of resting-state functional magnetic resonance imaging\n(fMRI) data. The proposed model is conditioned by the assumption of the\nsubject's state and estimates the posterior probability of the subject's state\ngiven the imaging data, using Bayes' rule. This study applied the proposed\nmodel to diagnose schizophrenia and bipolar disorders. Diagnostic accuracy was\nimproved by a large margin over competitive approaches, namely classifications\nof functional connectivity, discriminative/generative models of region-wise\nsignals, and those with unsupervised feature-extractors. The proposed model\nvisualizes brain regions largely related to the disorders, thus motivating\nfurther biological investigation.\n", "versions": [{"version": "v1", "created": "Mon, 18 Dec 2017 06:16:18 GMT"}, {"version": "v2", "created": "Fri, 12 Apr 2019 02:34:36 GMT"}], "update_date": "2019-04-15", "authors_parsed": [["Matsubara", "Takashi", ""], ["Tashiro", "Tetsuo", ""], ["Uehara", "Kuniaki", ""]]}, {"id": "1712.06281", "submitter": "Farshad Harirchi", "authors": "Farshad Harirchi, Doohyun Kim, Omar A. Khalil, Sijia Liu, Paolo\n  Elvati, Angela Violi, Alfred O. Hero", "title": "A New Data-Driven Sparse-Learning Approach to Study Chemical Reaction\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.SY physics.chem-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chemical kinetic mechanisms can be represented by sets of elementary\nreactions that are easily translated into mathematical terms using\nphysicochemical relationships. The schematic representation of reactions\ncaptures the interactions between reacting species and products. Determining\nthe minimal chemical interactions underlying the dynamic behavior of systems is\na major task. In this paper, we introduce a novel approach for the\nidentification of the influential reactions in chemical reaction networks for\ncombustion applications, using a data-driven sparse-learning technique. The\nproposed approach identifies a set of influential reactions using species\nconcentrations and reaction rates, with minimal computational cost without\nrequiring additional data or simulations. The new approach is applied to\nanalyze the combustion chemistry of H2 and C3H8 in a constant-volume\nhomogeneous reactor. The influential reactions identified by the\nsparse-learning method are consistent with the current kinetics knowledge of\nchemical mechanisms. Additionally, we show that a reduced version of the parent\nmechanism can be generated as a combination of the influential reactions\nidentified at different times and conditions and that for both H2 and C3H8 this\nreduced mechanism performs closely to the parent mechanism as a function of\nignition delay over a wide range of conditions. Our results demonstrate the\npotential of the sparse-learning approach as an effective and efficient tool\nfor mechanism analysis and mechanism reduction.\n", "versions": [{"version": "v1", "created": "Mon, 18 Dec 2017 07:53:44 GMT"}, {"version": "v2", "created": "Fri, 22 Dec 2017 22:29:48 GMT"}, {"version": "v3", "created": "Sun, 10 Feb 2019 18:21:12 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Harirchi", "Farshad", ""], ["Kim", "Doohyun", ""], ["Khalil", "Omar A.", ""], ["Liu", "Sijia", ""], ["Elvati", "Paolo", ""], ["Violi", "Angela", ""], ["Hero", "Alfred O.", ""]]}, {"id": "1712.06283", "submitter": "Luca Franceschi", "authors": "Luca Franceschi, Michele Donini, Paolo Frasconi, Massimiliano Pontil", "title": "A Bridge Between Hyperparameter Optimization and Learning-to-learn", "comments": "NIPS 2017 workshop on Meta-learning (http://metalearning.ml/)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a class of a nested optimization problems involving inner and\nouter objectives. We observe that by taking into explicit account the\noptimization dynamics for the inner objective it is possible to derive a\ngeneral framework that unifies gradient-based hyperparameter optimization and\nmeta-learning (or learning-to-learn). Depending on the specific setting, the\nvariables of the outer objective take either the meaning of hyperparameters in\na supervised learning problem or parameters of a meta-learner. We show that\nsome recently proposed methods in the latter setting can be instantiated in our\nframework and tackled with the same gradient-based algorithms. Finally, we\ndiscuss possible design patterns for learning-to-learn and present encouraging\npreliminary experiments for few-shot learning.\n", "versions": [{"version": "v1", "created": "Mon, 18 Dec 2017 08:02:50 GMT"}, {"version": "v2", "created": "Sun, 4 Feb 2018 11:58:30 GMT"}, {"version": "v3", "created": "Wed, 21 Aug 2019 10:40:54 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Franceschi", "Luca", ""], ["Donini", "Michele", ""], ["Frasconi", "Paolo", ""], ["Pontil", "Massimiliano", ""]]}, {"id": "1712.06302", "submitter": "Jose Oramas", "authors": "Jose Oramas, Kaili Wang, Tinne Tuytelaars", "title": "Visual Explanation by Interpretation: Improving Visual Feedback\n  Capabilities of Deep Neural Networks", "comments": "Accepted at International Conference on Learning Representations\n  (ICLR) 2019. Project website:\n  http://homes.esat.kuleuven.be/~joramas/projects/visualExplanationByInterpretation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpretation and explanation of deep models is critical towards wide\nadoption of systems that rely on them. In this paper, we propose a novel scheme\nfor both interpretation as well as explanation in which, given a pretrained\nmodel, we automatically identify internal features relevant for the set of\nclasses considered by the model, without relying on additional annotations. We\ninterpret the model through average visualizations of this reduced set of\nfeatures. Then, at test time, we explain the network prediction by accompanying\nthe predicted class label with supporting visualizations derived from the\nidentified features. In addition, we propose a method to address the artifacts\nintroduced by stridded operations in deconvNet-based visualizations. Moreover,\nwe introduce an8Flower, a dataset specifically designed for objective\nquantitative evaluation of methods for visual explanation.Experiments on the\nMNIST,ILSVRC12,Fashion144k and an8Flower datasets show that our method produces\ndetailed explanations with good coverage of relevant features of the classes of\ninterest\n", "versions": [{"version": "v1", "created": "Mon, 18 Dec 2017 09:17:44 GMT"}, {"version": "v2", "created": "Tue, 22 May 2018 15:04:25 GMT"}, {"version": "v3", "created": "Fri, 8 Mar 2019 12:11:15 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Oramas", "Jose", ""], ["Wang", "Kaili", ""], ["Tuytelaars", "Tinne", ""]]}, {"id": "1712.06340", "submitter": "Santiago Pascual de la Puente", "authors": "Santiago Pascual, Maruchan Park, Joan Serr\\`a, Antonio Bonafonte,\n  Kang-Hun Ahn", "title": "Language and Noise Transfer in Speech Enhancement Generative Adversarial\n  Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Speech enhancement deep learning systems usually require large amounts of\ntraining data to operate in broad conditions or real applications. This makes\nthe adaptability of those systems into new, low resource environments an\nimportant topic. In this work, we present the results of adapting a speech\nenhancement generative adversarial network by finetuning the generator with\nsmall amounts of data. We investigate the minimum requirements to obtain a\nstable behavior in terms of several objective metrics in two very different\nlanguages: Catalan and Korean. We also study the variability of test\nperformance to unseen noise as a function of the amount of different types of\nnoise available for training. Results show that adapting a pre-trained English\nmodel with 10 min of data already achieves a comparable performance to having\ntwo orders of magnitude more data. They also demonstrate the relative stability\nin test performance with respect to the number of training noise types.\n", "versions": [{"version": "v1", "created": "Mon, 18 Dec 2017 11:16:08 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Pascual", "Santiago", ""], ["Park", "Maruchan", ""], ["Serr\u00e0", "Joan", ""], ["Bonafonte", "Antonio", ""], ["Ahn", "Kang-Hun", ""]]}, {"id": "1712.06343", "submitter": "Dohyung Kim", "authors": "Dohyung Kim, Hyochang Yang, Minki Chung, Sungzoon Cho", "title": "Squeezed Convolutional Variational AutoEncoder for Unsupervised Anomaly\n  Detection in Edge Device Industrial Internet of Things", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose Squeezed Convolutional Variational AutoEncoder\n(SCVAE) for anomaly detection in time series data for Edge Computing in\nIndustrial Internet of Things (IIoT). The proposed model is applied to labeled\ntime series data from UCI datasets for exact performance evaluation, and\napplied to real world data for indirect model performance comparison. In\naddition, by comparing the models before and after applying Fire Modules from\nSqueezeNet, we show that model size and inference times are reduced while\nsimilar levels of performance is maintained.\n", "versions": [{"version": "v1", "created": "Mon, 18 Dec 2017 11:23:51 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Kim", "Dohyung", ""], ["Yang", "Hyochang", ""], ["Chung", "Minki", ""], ["Cho", "Sungzoon", ""]]}, {"id": "1712.06391", "submitter": "Xudong Mao", "authors": "Xudong Mao, Qing Li, Haoran Xie, Raymond Y.K. Lau, Zhen Wang, Stephen\n  Paul Smolley", "title": "On the Effectiveness of Least Squares Generative Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised learning with generative adversarial networks (GANs) has proven\nto be hugely successful. Regular GANs hypothesize the discriminator as a\nclassifier with the sigmoid cross entropy loss function. However, we found that\nthis loss function may lead to the vanishing gradients problem during the\nlearning process. To overcome such a problem, we propose in this paper the\nLeast Squares Generative Adversarial Networks (LSGANs) which adopt the least\nsquares loss for both the discriminator and the generator. We show that\nminimizing the objective function of LSGAN yields minimizing the Pearson\n$\\chi^2$ divergence. We also show that the derived objective function that\nyields minimizing the Pearson $\\chi^2$ divergence performs better than the\nclassical one of using least squares for classification. There are two benefits\nof LSGANs over regular GANs. First, LSGANs are able to generate higher quality\nimages than regular GANs. Second, LSGANs perform more stably during the\nlearning process. For evaluating the image quality, we conduct both qualitative\nand quantitative experiments, and the experimental results show that LSGANs can\ngenerate higher quality images than regular GANs. Furthermore, we evaluate the\nstability of LSGANs in two groups. One is to compare between LSGANs and regular\nGANs without gradient penalty. We conduct three experiments, including Gaussian\nmixture distribution, difficult architectures, and a newly proposed method ---\ndatasets with small variability, to illustrate the stability of LSGANs. The\nother one is to compare between LSGANs with gradient penalty (LSGANs-GP) and\nWGANs with gradient penalty (WGANs-GP). The experimental results show that\nLSGANs-GP succeed in training for all the difficult architectures used in\nWGANs-GP, including 101-layer ResNet.\n", "versions": [{"version": "v1", "created": "Mon, 18 Dec 2017 13:36:09 GMT"}, {"version": "v2", "created": "Fri, 21 Sep 2018 07:48:53 GMT"}], "update_date": "2018-09-24", "authors_parsed": [["Mao", "Xudong", ""], ["Li", "Qing", ""], ["Xie", "Haoran", ""], ["Lau", "Raymond Y. K.", ""], ["Wang", "Zhen", ""], ["Smolley", "Stephen Paul", ""]]}, {"id": "1712.06424", "submitter": "Danyang Sun", "authors": "Danyang Sun, Tongzheng Ren, Chongxun Li, Hang Su, Jun Zhu", "title": "Learning to Write Stylized Chinese Characters by Reading a Handful of\n  Examples", "comments": "Accepted by IJCAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatically writing stylized Chinese characters is an attractive yet\nchallenging task due to its wide applicabilities. In this paper, we propose a\nnovel framework named Style-Aware Variational Auto-Encoder (SA-VAE) to flexibly\ngenerate Chinese characters. Specifically, we propose to capture the different\ncharacteristics of a Chinese character by disentangling the latent features\ninto content-related and style-related components. Considering of the complex\nshapes and structures, we incorporate the structure information as prior\nknowledge into our framework to guide the generation. Our framework shows a\npowerful one-shot/low-shot generalization ability by inferring the style\ncomponent given a character with unseen style. To the best of our knowledge,\nthis is the first attempt to learn to write new-style Chinese characters by\nobserving only one or a few examples. Extensive experiments demonstrate its\neffectiveness in generating different stylized Chinese characters by fusing the\nfeature vectors corresponding to different contents and styles, which is of\nsignificant importance in real-world applications.\n", "versions": [{"version": "v1", "created": "Wed, 6 Dec 2017 13:33:51 GMT"}, {"version": "v2", "created": "Thu, 21 Dec 2017 09:18:22 GMT"}, {"version": "v3", "created": "Mon, 18 Jun 2018 11:17:09 GMT"}], "update_date": "2018-06-19", "authors_parsed": [["Sun", "Danyang", ""], ["Ren", "Tongzheng", ""], ["Li", "Chongxun", ""], ["Su", "Hang", ""], ["Zhu", "Jun", ""]]}, {"id": "1712.06428", "submitter": "Aaron Bostrom", "authors": "Aaron Bostrom and Anthony Bagnall", "title": "A Shapelet Transform for Multivariate Time Series Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shapelets are phase independent subsequences designed for time series\nclassification. We propose three adaptations to the Shapelet Transform (ST) to\ncapture multivariate features in multivariate time series classification. We\ncreate a unified set of data to benchmark our work on, and compare with three\nother algorithms. We demonstrate that multivariate shapelets are not\nsignificantly worse than other state-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 18 Dec 2017 14:40:23 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Bostrom", "Aaron", ""], ["Bagnall", "Anthony", ""]]}, {"id": "1712.06530", "submitter": "Brian Kenji Iwana", "authors": "Brian Kenji Iwana and Seiichi Uchida", "title": "Dynamic Weight Alignment for Temporal Convolutional Neural Networks", "comments": "Accepted to ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a method of improving temporal Convolutional Neural\nNetworks (CNN) by determining the optimal alignment of weights and inputs using\ndynamic programming. Conventional CNN convolutions linearly match the shared\nweights to a window of the input. However, it is possible that there exists a\nmore optimal alignment of weights. Thus, we propose the use of Dynamic Time\nWarping (DTW) to dynamically align the weights to the input of the\nconvolutional layer. Specifically, the dynamic alignment overcomes issues such\nas temporal distortion by finding the minimal distance matching of the weights\nand the inputs under constraints. We demonstrate the effectiveness of the\nproposed architecture on the Unipen online handwritten digit and character\ndatasets, the UCI Spoken Arabic Digit dataset, and the UCI Activities of Daily\nLife dataset.\n", "versions": [{"version": "v1", "created": "Mon, 18 Dec 2017 17:16:07 GMT"}, {"version": "v2", "created": "Thu, 25 Jan 2018 14:35:19 GMT"}, {"version": "v3", "created": "Fri, 18 May 2018 17:23:54 GMT"}, {"version": "v4", "created": "Fri, 15 Jun 2018 12:37:06 GMT"}, {"version": "v5", "created": "Thu, 6 Sep 2018 06:50:57 GMT"}, {"version": "v6", "created": "Thu, 7 Feb 2019 08:10:19 GMT"}], "update_date": "2019-02-08", "authors_parsed": [["Iwana", "Brian Kenji", ""], ["Uchida", "Seiichi", ""]]}, {"id": "1712.06536", "submitter": "Erik Bodin", "authors": "Erik Bodin, Iman Malik, Carl Henrik Ek, Neill D. F. Campbell", "title": "Nonparametric Inference for Auto-Encoding Variational Bayes", "comments": "Presented at NIPS 2017 Workshop on Advances in Approximate Bayesian\n  Inference", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We would like to learn latent representations that are low-dimensional and\nhighly interpretable. A model that has these characteristics is the Gaussian\nProcess Latent Variable Model. The benefits and negative of the GP-LVM are\ncomplementary to the Variational Autoencoder, the former provides interpretable\nlow-dimensional latent representations while the latter is able to handle large\namounts of data and can use non-Gaussian likelihoods. Our inspiration for this\npaper is to marry these two approaches and reap the benefits of both. In order\nto do so we will introduce a novel approximate inference scheme inspired by the\nGP-LVM and the VAE. We show experimentally that the approximation allows the\ncapacity of the generative bottle-neck (Z) of the VAE to be arbitrarily large\nwithout losing a highly interpretable representation, allowing reconstruction\nquality to be unlimited by Z at the same time as a low-dimensional space can be\nused to perform ancestral sampling from as well as a means to reason about the\nembedded data.\n", "versions": [{"version": "v1", "created": "Mon, 18 Dec 2017 17:22:41 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Bodin", "Erik", ""], ["Malik", "Iman", ""], ["Ek", "Carl Henrik", ""], ["Campbell", "Neill D. F.", ""]]}, {"id": "1712.06541", "submitter": "Ohad Shamir", "authors": "Noah Golowich, Alexander Rakhlin and Ohad Shamir", "title": "Size-Independent Sample Complexity of Neural Networks", "comments": "Fixed a bug in the proof of theorem 7 (not affecting theorem\n  statement), by slightly changing the construction", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the sample complexity of learning neural networks, by providing new\nbounds on their Rademacher complexity assuming norm constraints on the\nparameter matrix of each layer. Compared to previous work, these complexity\nbounds have improved dependence on the network depth, and under some additional\nassumptions, are fully independent of the network size (both depth and width).\nThese results are derived using some novel techniques, which may be of\nindependent interest.\n", "versions": [{"version": "v1", "created": "Mon, 18 Dec 2017 17:26:15 GMT"}, {"version": "v2", "created": "Wed, 10 Jan 2018 14:36:45 GMT"}, {"version": "v3", "created": "Wed, 30 May 2018 13:58:23 GMT"}, {"version": "v4", "created": "Wed, 6 Jun 2018 15:08:35 GMT"}, {"version": "v5", "created": "Sun, 17 Nov 2019 07:41:30 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Golowich", "Noah", ""], ["Rakhlin", "Alexander", ""], ["Shamir", "Ohad", ""]]}, {"id": "1712.06559", "submitter": "Siyuan Ma", "authors": "Siyuan Ma, Raef Bassily and Mikhail Belkin", "title": "The Power of Interpolation: Understanding the Effectiveness of SGD in\n  Modern Over-parametrized Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we aim to formally explain the phenomenon of fast convergence\nof SGD observed in modern machine learning. The key observation is that most\nmodern learning architectures are over-parametrized and are trained to\ninterpolate the data by driving the empirical loss (classification and\nregression) close to zero. While it is still unclear why these interpolated\nsolutions perform well on test data, we show that these regimes allow for fast\nconvergence of SGD, comparable in number of iterations to full gradient\ndescent.\n  For convex loss functions we obtain an exponential convergence bound for {\\it\nmini-batch} SGD parallel to that for full gradient descent. We show that there\nis a critical batch size $m^*$ such that: (a) SGD iteration with mini-batch\nsize $m\\leq m^*$ is nearly equivalent to $m$ iterations of mini-batch size $1$\n(\\emph{linear scaling regime}). (b) SGD iteration with mini-batch $m> m^*$ is\nnearly equivalent to a full gradient descent iteration (\\emph{saturation\nregime}).\n  Moreover, for the quadratic loss, we derive explicit expressions for the\noptimal mini-batch and step size and explicitly characterize the two regimes\nabove. The critical mini-batch size can be viewed as the limit for effective\nmini-batch parallelization. It is also nearly independent of the data size,\nimplying $O(n)$ acceleration over GD per unit of computation. We give\nexperimental evidence on real data which closely follows our theoretical\nanalyses.\n  Finally, we show how our results fit in the recent developments in training\ndeep neural networks and discuss connections to adaptive rates for SGD and\nvariance reduction.\n", "versions": [{"version": "v1", "created": "Mon, 18 Dec 2017 18:10:39 GMT"}, {"version": "v2", "created": "Mon, 5 Feb 2018 21:35:54 GMT"}, {"version": "v3", "created": "Thu, 14 Jun 2018 18:07:01 GMT"}], "update_date": "2018-06-18", "authors_parsed": [["Ma", "Siyuan", ""], ["Bassily", "Raef", ""], ["Belkin", "Mikhail", ""]]}, {"id": "1712.06567", "submitter": "Felipe Petroski Such", "authors": "Felipe Petroski Such, Vashisht Madhavan, Edoardo Conti, Joel Lehman,\n  Kenneth O. Stanley, Jeff Clune", "title": "Deep Neuroevolution: Genetic Algorithms Are a Competitive Alternative\n  for Training Deep Neural Networks for Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep artificial neural networks (DNNs) are typically trained via\ngradient-based learning algorithms, namely backpropagation. Evolution\nstrategies (ES) can rival backprop-based algorithms such as Q-learning and\npolicy gradients on challenging deep reinforcement learning (RL) problems.\nHowever, ES can be considered a gradient-based algorithm because it performs\nstochastic gradient descent via an operation similar to a finite-difference\napproximation of the gradient. That raises the question of whether\nnon-gradient-based evolutionary algorithms can work at DNN scales. Here we\ndemonstrate they can: we evolve the weights of a DNN with a simple,\ngradient-free, population-based genetic algorithm (GA) and it performs well on\nhard deep RL problems, including Atari and humanoid locomotion. The Deep GA\nsuccessfully evolves networks with over four million free parameters, the\nlargest neural networks ever evolved with a traditional evolutionary algorithm.\nThese results (1) expand our sense of the scale at which GAs can operate, (2)\nsuggest intriguingly that in some cases following the gradient is not the best\nchoice for optimizing performance, and (3) make immediately available the\nmultitude of neuroevolution techniques that improve performance. We demonstrate\nthe latter by showing that combining DNNs with novelty search, which encourages\nexploration on tasks with deceptive or sparse reward functions, can solve a\nhigh-dimensional problem on which reward-maximizing algorithms (e.g.\\ DQN, A3C,\nES, and the GA) fail. Additionally, the Deep GA is faster than ES, A3C, and DQN\n(it can train Atari in ${\\raise.17ex\\hbox{$\\scriptstyle\\sim$}}$4 hours on one\ndesktop or ${\\raise.17ex\\hbox{$\\scriptstyle\\sim$}}$1 hour distributed on 720\ncores), and enables a state-of-the-art, up to 10,000-fold compact encoding\ntechnique.\n", "versions": [{"version": "v1", "created": "Mon, 18 Dec 2017 18:22:05 GMT"}, {"version": "v2", "created": "Thu, 4 Jan 2018 22:59:49 GMT"}, {"version": "v3", "created": "Fri, 20 Apr 2018 18:38:34 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Such", "Felipe Petroski", ""], ["Madhavan", "Vashisht", ""], ["Conti", "Edoardo", ""], ["Lehman", "Joel", ""], ["Stanley", "Kenneth O.", ""], ["Clune", "Jeff", ""]]}, {"id": "1712.06577", "submitter": "Maxim Naumov", "authors": "Maxim Naumov", "title": "Parallel Complexity of Forward and Backward Propagation", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the forward and backward propagation can be formulated as a\nsolution of lower and upper triangular systems of equations. For standard\nfeedforward (FNNs) and recurrent neural networks (RNNs) the triangular systems\nare always block bi-diagonal, while for a general computation graph (directed\nacyclic graph) they can have a more complex triangular sparsity pattern. We\ndiscuss direct and iterative parallel algorithms that can be used for their\nsolution and interpreted as different ways of performing model parallelism.\nAlso, we show that for FNNs and RNNs with $k$ layers and $\\tau$ time steps the\nbackward propagation can be performed in parallel in O($\\log k$) and O($\\log k\n\\log \\tau$) steps, respectively. Finally, we outline the generalization of this\ntechnique using Jacobians that potentially allows us to handle arbitrary\nlayers.\n", "versions": [{"version": "v1", "created": "Mon, 18 Dec 2017 18:46:51 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Naumov", "Maxim", ""]]}, {"id": "1712.06585", "submitter": "Quanquan Gu", "authors": "Yaodong Yu and Pan Xu and Quanquan Gu", "title": "Third-order Smoothness Helps: Even Faster Stochastic Optimization\n  Algorithms for Finding Local Minima", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose stochastic optimization algorithms that can find local minima\nfaster than existing algorithms for nonconvex optimization problems, by\nexploiting the third-order smoothness to escape non-degenerate saddle points\nmore efficiently. More specifically, the proposed algorithm only needs\n$\\tilde{O}(\\epsilon^{-10/3})$ stochastic gradient evaluations to converge to an\napproximate local minimum $\\mathbf{x}$, which satisfies $\\|\\nabla\nf(\\mathbf{x})\\|_2\\leq\\epsilon$ and $\\lambda_{\\min}(\\nabla^2 f(\\mathbf{x}))\\geq\n-\\sqrt{\\epsilon}$ in the general stochastic optimization setting, where\n$\\tilde{O}(\\cdot)$ hides logarithm polynomial terms and constants. This\nimproves upon the $\\tilde{O}(\\epsilon^{-7/2})$ gradient complexity achieved by\nthe state-of-the-art stochastic local minima finding algorithms by a factor of\n$\\tilde{O}(\\epsilon^{-1/6})$. For nonconvex finite-sum optimization, our\nalgorithm also outperforms the best known algorithms in a certain regime.\n", "versions": [{"version": "v1", "created": "Mon, 18 Dec 2017 18:57:44 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Yu", "Yaodong", ""], ["Xu", "Pan", ""], ["Gu", "Quanquan", ""]]}, {"id": "1712.06646", "submitter": "George Kesidis", "authors": "David J. Miller and Yulia Wang and George Kesidis", "title": "When Not to Classify: Anomaly Detection of Attacks (ADA) on DNN\n  Classifiers at Test Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A significant threat to the recent, wide deployment of machine learning-based\nsystems, including deep neural networks (DNNs), is adversarial learning\nattacks. We analyze possible test-time evasion-attack mechanisms and show that,\nin some important cases, when the image has been attacked, correctly\nclassifying it has no utility: i) when the image to be attacked is (even\narbitrarily) selected from the attacker's cache; ii) when the sole recipient of\nthe classifier's decision is the attacker. Moreover, in some application\ndomains and scenarios it is highly actionable to detect the attack irrespective\nof correctly classifying in the face of it (with classification still performed\nif no attack is detected). We hypothesize that, even if human-imperceptible,\nadversarial perturbations are machine-detectable. We propose a purely\nunsupervised anomaly detector (AD) that, unlike previous works: i) models the\njoint density of a deep layer using highly suitable null hypothesis density\nmodels (matched in particular to the non- negative support for RELU layers);\nii) exploits multiple DNN layers; iii) leverages a \"source\" and \"destination\"\nclass concept, source class uncertainty, the class confusion matrix, and DNN\nweight information in constructing a novel decision statistic grounded in the\nKullback-Leibler divergence. Tested on MNIST and CIFAR-10 image databases under\nthree prominent attack strategies, our approach outperforms previous detection\nmethods, achieving strong ROC AUC detection accuracy on two attacks and better\naccuracy than recently reported for a variety of methods on the strongest (CW)\nattack. We also evaluate a fully white box attack on our system. Finally, we\nevaluate other important performance measures, such as classification accuracy,\nversus detection rate and attack strength.\n", "versions": [{"version": "v1", "created": "Mon, 18 Dec 2017 19:48:04 GMT"}, {"version": "v2", "created": "Thu, 28 Jun 2018 02:40:33 GMT"}], "update_date": "2018-06-29", "authors_parsed": [["Miller", "David J.", ""], ["Wang", "Yulia", ""], ["Kesidis", "George", ""]]}, {"id": "1712.06651", "submitter": "Relja Arandjelovi\\'c", "authors": "Relja Arandjelovi\\'c, Andrew Zisserman", "title": "Objects that Sound", "comments": "Appears in: European Conference on Computer Vision (ECCV) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MM cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper our objectives are, first, networks that can embed audio and\nvisual inputs into a common space that is suitable for cross-modal retrieval;\nand second, a network that can localize the object that sounds in an image,\ngiven the audio signal. We achieve both these objectives by training from\nunlabelled video using only audio-visual correspondence (AVC) as the objective\nfunction. This is a form of cross-modal self-supervision from video.\n  To this end, we design new network architectures that can be trained for\ncross-modal retrieval and localizing the sound source in an image, by using the\nAVC task. We make the following contributions: (i) show that audio and visual\nembeddings can be learnt that enable both within-mode (e.g. audio-to-audio) and\nbetween-mode retrieval; (ii) explore various architectures for the AVC task,\nincluding those for the visual stream that ingest a single image, or multiple\nimages, or a single image and multi-frame optical flow; (iii) show that the\nsemantic object that sounds within an image can be localized (using only the\nsound, no motion or flow information); and (iv) give a cautionary tale on how\nto avoid undesirable shortcuts in the data preparation.\n", "versions": [{"version": "v1", "created": "Mon, 18 Dec 2017 19:52:53 GMT"}, {"version": "v2", "created": "Wed, 25 Jul 2018 16:26:15 GMT"}], "update_date": "2018-07-27", "authors_parsed": [["Arandjelovi\u0107", "Relja", ""], ["Zisserman", "Andrew", ""]]}, {"id": "1712.06658", "submitter": "Farshid Rayhan", "authors": "Farshid Rayhan, Sajid Ahmed, Asif Mahbub, Md. Rafsan Jani, Swakkhar\n  Shatabda, Dewan Md. Farid and Chowdhury Mofizur Rahman", "title": "MEBoost: Mixing Estimators with Boosting for Imbalanced Data\n  Classification", "comments": "SKIMA-2017", "journal-ref": null, "doi": "10.1109/SKIMA.2017.8294128", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Class imbalance problem has been a challenging research problem in the fields\nof machine learning and data mining as most real life datasets are imbalanced.\nSeveral existing machine learning algorithms try to maximize the accuracy\nclassification by correctly identifying majority class samples while ignoring\nthe minority class. However, the concept of the minority class instances\nusually represents a higher interest than the majority class. Recently, several\ncost sensitive methods, ensemble models and sampling techniques have been used\nin literature in order to classify imbalance datasets. In this paper, we\npropose MEBoost, a new boosting algorithm for imbalanced datasets. MEBoost\nmixes two different weak learners with boosting to improve the performance on\nimbalanced datasets. MEBoost is an alternative to the existing techniques such\nas SMOTEBoost, RUSBoost, Adaboost, etc. The performance of MEBoost has been\nevaluated on 12 benchmark imbalanced datasets with state of the art ensemble\nmethods like SMOTEBoost, RUSBoost, Easy Ensemble, EUSBoost, DataBoost.\nExperimental results show significant improvement over the other methods and it\ncan be concluded that MEBoost is an effective and promising algorithm to deal\nwith imbalance datasets. The python version of the code is available here:\nhttps://github.com/farshidrayhanuiu/\n", "versions": [{"version": "v1", "created": "Mon, 18 Dec 2017 20:18:30 GMT"}, {"version": "v2", "created": "Sat, 13 Jan 2018 19:21:33 GMT"}], "update_date": "2018-06-21", "authors_parsed": [["Rayhan", "Farshid", ""], ["Ahmed", "Sajid", ""], ["Mahbub", "Asif", ""], ["Jani", "Md. Rafsan", ""], ["Shatabda", "Swakkhar", ""], ["Farid", "Dewan Md.", ""], ["Rahman", "Chowdhury Mofizur", ""]]}, {"id": "1712.06682", "submitter": "Jason Xie", "authors": "Jason Xie, Tingwen Bao", "title": "Synthesizing Novel Pairs of Image and Text", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating novel pairs of image and text is a problem that combines computer\nvision and natural language processing. In this paper, we present strategies\nfor generating novel image and caption pairs based on existing captioning\ndatasets. The model takes advantage of recent advances in generative\nadversarial networks and sequence-to-sequence modeling. We make generalizations\nto generate paired samples from multiple domains. Furthermore, we study cycles\n-- generating from image to text then back to image and vise versa, as well as\nits connection with autoencoders.\n", "versions": [{"version": "v1", "created": "Mon, 18 Dec 2017 21:25:37 GMT"}], "update_date": "2017-12-20", "authors_parsed": [["Xie", "Jason", ""], ["Bao", "Tingwen", ""]]}, {"id": "1712.06695", "submitter": "Yash Deshpande", "authors": "Yash Deshpande, Lester Mackey, Vasilis Syrgkanis, Matt Taddy", "title": "Accurate Inference for Adaptive Linear Models", "comments": "Typos fixed for clarification", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimators computed from adaptively collected data do not behave like their\nnon-adaptive brethren. Rather, the sequential dependence of the collection\npolicy can lead to severe distributional biases that persist even in the\ninfinite data limit. We develop a general method -- $\\mathbf{W}$-decorrelation\n-- for transforming the bias of adaptive linear regression estimators into\nvariance. The method uses only coarse-grained information about the data\ncollection policy and does not need access to propensity scores or exact\nknowledge of the policy. We bound the finite-sample bias and variance of the\n$\\mathbf{W}$-estimator and develop asymptotically correct confidence intervals\nbased on a novel martingale central limit theorem. We then demonstrate the\nempirical benefits of the generic $\\mathbf{W}$-decorrelation procedure in two\ndifferent adaptive data settings: the multi-armed bandit and the autoregressive\ntime series.\n", "versions": [{"version": "v1", "created": "Mon, 18 Dec 2017 22:07:29 GMT"}, {"version": "v2", "created": "Wed, 20 Jun 2018 21:30:24 GMT"}, {"version": "v3", "created": "Wed, 14 Aug 2019 14:11:49 GMT"}, {"version": "v4", "created": "Thu, 5 Sep 2019 20:04:37 GMT"}, {"version": "v5", "created": "Thu, 2 Jan 2020 22:33:42 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Deshpande", "Yash", ""], ["Mackey", "Lester", ""], ["Syrgkanis", "Vasilis", ""], ["Taddy", "Matt", ""]]}, {"id": "1712.06751", "submitter": "Javid Ebrahimi", "authors": "Javid Ebrahimi, Anyi Rao, Daniel Lowd, Dejing Dou", "title": "HotFlip: White-Box Adversarial Examples for Text Classification", "comments": null, "journal-ref": "ACL 2018", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an efficient method to generate white-box adversarial examples to\ntrick a character-level neural classifier. We find that only a few\nmanipulations are needed to greatly decrease the accuracy. Our method relies on\nan atomic flip operation, which swaps one token for another, based on the\ngradients of the one-hot input vectors. Due to efficiency of our method, we can\nperform adversarial training which makes the model more robust to attacks at\ntest time. With the use of a few semantics-preserving constraints, we\ndemonstrate that HotFlip can be adapted to attack a word-level classifier as\nwell.\n", "versions": [{"version": "v1", "created": "Tue, 19 Dec 2017 02:15:19 GMT"}, {"version": "v2", "created": "Thu, 24 May 2018 16:43:45 GMT"}], "update_date": "2018-05-25", "authors_parsed": [["Ebrahimi", "Javid", ""], ["Rao", "Anyi", ""], ["Lowd", "Daniel", ""], ["Dou", "Dejing", ""]]}, {"id": "1712.06793", "submitter": "Han Guoan", "authors": "Liang Xiao, Guoan Han, Donghua Jiang, Hongzi Zhu, Yanyong Zhang, H.\n  Vincent Poor", "title": "Two-dimensional Anti-jamming Mobile Communication Based on Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By using smart radio devices, a jammer can dynamically change its jamming\npolicy based on opposing security mechanisms; it can even induce the mobile\ndevice to enter a specific communication mode and then launch the jamming\npolicy accordingly. On the other hand, mobile devices can exploit spread\nspectrum and user mobility to address both jamming and interference. In this\npaper, a two-dimensional anti-jamming mobile communication scheme is proposed\nin which a mobile device leaves a heavily jammed/interfered-with frequency or\narea. It is shown that, by applying reinforcement learning techniques, a mobile\ndevice can achieve an optimal communication policy without the need to know the\njamming and interference model and the radio channel model in a dynamic game\nframework. More specifically, a hotbooting deep Q-network based two-dimensional\nmobile communication scheme is proposed that exploits experiences in similar\nscenarios to reduce the exploration time at the beginning of the game, and\napplies deep convolutional neural network and macro-action techniques to\naccelerate the learning speed in dynamic situations. Several real-world\nscenarios are simulated to evaluate the proposed method. These simulation\nresults show that our proposed scheme can improve both the\nsignal-to-interference-plus-noise ratio of the signals and the utility of the\nmobile devices against cooperative jamming compared with benchmark schemes.\n", "versions": [{"version": "v1", "created": "Tue, 19 Dec 2017 06:01:31 GMT"}], "update_date": "2017-12-20", "authors_parsed": [["Xiao", "Liang", ""], ["Han", "Guoan", ""], ["Jiang", "Donghua", ""], ["Zhu", "Hongzi", ""], ["Zhang", "Yanyong", ""], ["Poor", "H. Vincent", ""]]}, {"id": "1712.06861", "submitter": "Ignacio Rocco", "authors": "Ignacio Rocco, Relja Arandjelovi\\'c, Josef Sivic", "title": "End-to-end weakly-supervised semantic alignment", "comments": "In 2018 IEEE Conference on Computer Vision and Pattern Recognition\n  (CVPR 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle the task of semantic alignment where the goal is to compute dense\nsemantic correspondence aligning two images depicting objects of the same\ncategory. This is a challenging task due to large intra-class variation,\nchanges in viewpoint and background clutter. We present the following three\nprincipal contributions. First, we develop a convolutional neural network\narchitecture for semantic alignment that is trainable in an end-to-end manner\nfrom weak image-level supervision in the form of matching image pairs. The\noutcome is that parameters are learnt from rich appearance variation present in\ndifferent but semantically related images without the need for tedious manual\nannotation of correspondences at training time. Second, the main component of\nthis architecture is a differentiable soft inlier scoring module, inspired by\nthe RANSAC inlier scoring procedure, that computes the quality of the alignment\nbased on only geometrically consistent correspondences thereby reducing the\neffect of background clutter. Third, we demonstrate that the proposed approach\nachieves state-of-the-art performance on multiple standard benchmarks for\nsemantic alignment.\n", "versions": [{"version": "v1", "created": "Tue, 19 Dec 2017 10:52:22 GMT"}, {"version": "v2", "created": "Tue, 24 Apr 2018 15:09:04 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Rocco", "Ignacio", ""], ["Arandjelovi\u0107", "Relja", ""], ["Sivic", "Josef", ""]]}, {"id": "1712.06863", "submitter": "Fabio Sciarrino", "authors": "Iris Agresti, Niko Viggianiello, Fulvio Flamini, Nicol\\`o Spagnolo,\n  Andrea Crespi, Roberto Osellame, Nathan Wiebe, Fabio Sciarrino", "title": "Pattern recognition techniques for Boson Sampling validation", "comments": "11+5 pages, 5+4 figures", "journal-ref": "Phys. Rev. X 9, 011013 (2019)", "doi": "10.1103/PhysRevX.9.011013", "report-no": null, "categories": "quant-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The difficulty of validating large-scale quantum devices, such as Boson\nSamplers, poses a major challenge for any research program that aims to show\nquantum advantages over classical hardware. To address this problem, we propose\na novel data-driven approach wherein models are trained to identify common\npathologies using unsupervised machine learning methods. We illustrate this\nidea by training a classifier that exploits K-means clustering to distinguish\nbetween Boson Samplers that use indistinguishable photons from those that do\nnot. We train the model on numerical simulations of small-scale Boson Samplers\nand then validate the pattern recognition technique on larger numerical\nsimulations as well as on photonic chips in both traditional Boson Sampling and\nscattershot experiments. The effectiveness of such method relies on\nparticle-type-dependent internal correlations present in the output\ndistributions. This approach performs substantially better on the test data\nthan previous methods and underscores the ability to further generalize its\noperation beyond the scope of the examples that it was trained on.\n", "versions": [{"version": "v1", "created": "Tue, 19 Dec 2017 10:53:18 GMT"}, {"version": "v2", "created": "Sat, 6 Jun 2020 09:50:16 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Agresti", "Iris", ""], ["Viggianiello", "Niko", ""], ["Flamini", "Fulvio", ""], ["Spagnolo", "Nicol\u00f2", ""], ["Crespi", "Andrea", ""], ["Osellame", "Roberto", ""], ["Wiebe", "Nathan", ""], ["Sciarrino", "Fabio", ""]]}, {"id": "1712.06924", "submitter": "Romain Laroche", "authors": "Romain Laroche, Paul Trichelair, R\\'emi Tachet des Combes", "title": "Safe Policy Improvement with Baseline Bootstrapping", "comments": "accepted as a long oral at ICML2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers Safe Policy Improvement (SPI) in Batch Reinforcement\nLearning (Batch RL): from a fixed dataset and without direct access to the true\nenvironment, train a policy that is guaranteed to perform at least as well as\nthe baseline policy used to collect the data. Our approach, called SPI with\nBaseline Bootstrapping (SPIBB), is inspired by the knows-what-it-knows\nparadigm: it bootstraps the trained policy with the baseline when the\nuncertainty is high. Our first algorithm, $\\Pi_b$-SPIBB, comes with SPI\ntheoretical guarantees. We also implement a variant, $\\Pi_{\\leq b}$-SPIBB, that\nis even more efficient in practice. We apply our algorithms to a motivational\nstochastic gridworld domain and further demonstrate on randomly generated MDPs\nthe superiority of SPIBB with respect to existing algorithms, not only in\nsafety but also in mean performance. Finally, we implement a model-free version\nof SPIBB and show its benefits on a navigation task with deep RL implementation\ncalled SPIBB-DQN, which is, to the best of our knowledge, the first RL\nalgorithm relying on a neural network representation able to train efficiently\nand reliably from batch data, without any interaction with the environment.\n", "versions": [{"version": "v1", "created": "Tue, 19 Dec 2017 13:43:41 GMT"}, {"version": "v2", "created": "Wed, 20 Dec 2017 19:52:03 GMT"}, {"version": "v3", "created": "Thu, 18 Jan 2018 21:37:53 GMT"}, {"version": "v4", "created": "Thu, 14 Jun 2018 19:54:34 GMT"}, {"version": "v5", "created": "Fri, 7 Jun 2019 17:45:54 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Laroche", "Romain", ""], ["Trichelair", "Paul", ""], ["Combes", "R\u00e9mi Tachet des", ""]]}, {"id": "1712.07003", "submitter": "Ronan Fablet", "authors": "Ronan Fablet, Said Ouala, Cedric Herzet", "title": "Bilinear residual Neural Network for the identification and forecasting\n  of dynamical systems", "comments": "Submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the increasing availability of large-scale observation and simulation\ndatasets, data-driven representations arise as efficient and relevant\ncomputation representations of dynamical systems for a wide range of\napplications, where model-driven models based on ordinary differential equation\nremain the state-of-the-art approaches. In this work, we investigate neural\nnetworks (NN) as physically-sound data-driven representations of such systems.\nReinterpreting Runge-Kutta methods as graphical models, we consider a residual\nNN architecture and introduce bilinear layers to embed non-linearities which\nare intrinsic features of dynamical systems. From numerical experiments for\nclassic dynamical systems, we demonstrate the relevance of the proposed\nNN-based architecture both in terms of forecasting performance and model\nidentification.\n", "versions": [{"version": "v1", "created": "Tue, 19 Dec 2017 15:42:40 GMT"}], "update_date": "2017-12-20", "authors_parsed": [["Fablet", "Ronan", ""], ["Ouala", "Said", ""], ["Herzet", "Cedric", ""]]}, {"id": "1712.07008", "submitter": "Ardhendu Shekhar Tripathy", "authors": "Ardhendu Tripathy and Ye Wang and Prakash Ishwar", "title": "Privacy-Preserving Adversarial Networks", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR cs.GT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a data-driven framework for optimizing privacy-preserving data\nrelease mechanisms to attain the information-theoretically optimal tradeoff\nbetween minimizing distortion of useful data and concealing specific sensitive\ninformation. Our approach employs adversarially-trained neural networks to\nimplement randomized mechanisms and to perform a variational approximation of\nmutual information privacy. We validate our Privacy-Preserving Adversarial\nNetworks (PPAN) framework via proof-of-concept experiments on discrete and\ncontinuous synthetic data, as well as the MNIST handwritten digits dataset. For\nsynthetic data, our model-agnostic PPAN approach achieves tradeoff points very\nclose to the optimal tradeoffs that are analytically-derived from model\nknowledge. In experiments with the MNIST data, we visually demonstrate a\nlearned tradeoff between minimizing the pixel-level distortion versus\nconcealing the written digit.\n", "versions": [{"version": "v1", "created": "Tue, 19 Dec 2017 15:53:45 GMT"}, {"version": "v2", "created": "Wed, 9 Jan 2019 13:49:31 GMT"}, {"version": "v3", "created": "Wed, 12 Jun 2019 14:42:37 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Tripathy", "Ardhendu", ""], ["Wang", "Ye", ""], ["Ishwar", "Prakash", ""]]}, {"id": "1712.07027", "submitter": "Adil Salim", "authors": "Adil Salim, Pascal Bianchi and Walid Hachem", "title": "Snake: a Stochastic Proximal Gradient Algorithm for Regularized Problems\n  over Large Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A regularized optimization problem over a large unstructured graph is\nstudied, where the regularization term is tied to the graph geometry. Typical\nregularization examples include the total variation and the Laplacian\nregularizations over the graph. When applying the proximal gradient algorithm\nto solve this problem, there exist quite affordable methods to implement the\nproximity operator (backward step) in the special case where the graph is a\nsimple path without loops. In this paper, an algorithm, referred to as \"Snake\",\nis proposed to solve such regularized problems over general graphs, by taking\nbenefit of these fast methods. The algorithm consists in properly selecting\nrandom simple paths in the graph and performing the proximal gradient algorithm\nover these simple paths. This algorithm is an instance of a new general\nstochastic proximal gradient algorithm, whose convergence is proven.\nApplications to trend filtering and graph inpainting are provided among others.\nNumerical experiments are conducted over large graphs.\n", "versions": [{"version": "v1", "created": "Tue, 19 Dec 2017 16:28:17 GMT"}], "update_date": "2017-12-20", "authors_parsed": [["Salim", "Adil", ""], ["Bianchi", "Pascal", ""], ["Hachem", "Walid", ""]]}, {"id": "1712.07042", "submitter": "Marta Stepniewska-Dziubinska", "authors": "Marta M. Stepniewska-Dziubinska, Piotr Zielenkiewicz, and Pawel\n  Siedlecki", "title": "Development and evaluation of a deep learning model for protein-ligand\n  binding affinity prediction", "comments": null, "journal-ref": null, "doi": "10.1093/bioinformatics/bty374/4994792", "report-no": null, "categories": "stat.ML cs.LG q-bio.BM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structure based ligand discovery is one of the most successful approaches for\naugmenting the drug discovery process. Currently, there is a notable shift\ntowards machine learning (ML) methodologies to aid such procedures. Deep\nlearning has recently gained considerable attention as it allows the model to\n\"learn\" to extract features that are relevant for the task at hand. We have\ndeveloped a novel deep neural network estimating the binding affinity of\nligand-receptor complexes. The complex is represented with a 3D grid, and the\nmodel utilizes a 3D convolution to produce a feature map of this\nrepresentation, treating the atoms of both proteins and ligands in the same\nmanner. Our network was tested on the CASF \"scoring power\" benchmark and Astex\nDiverse Set and outperformed classical scoring functions. The model, together\nwith usage instructions and examples, is available as a git repository at\nhttp://gitlab.com/cheminfIBB/pafnucy\n", "versions": [{"version": "v1", "created": "Tue, 19 Dec 2017 16:49:01 GMT"}, {"version": "v2", "created": "Wed, 3 Jan 2018 16:15:15 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Stepniewska-Dziubinska", "Marta M.", ""], ["Zielenkiewicz", "Piotr", ""], ["Siedlecki", "Pawel", ""]]}, {"id": "1712.07102", "submitter": "Shahin Shahrampour", "authors": "Shahin Shahrampour, Ahmad Beirami, Vahid Tarokh", "title": "On Data-Dependent Random Features for Improved Generalization in\n  Supervised Learning", "comments": "12 pages; (pages 1-8) to appear in Proc. of AAAI Conference on\n  Artificial Intelligence (AAAI), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The randomized-feature approach has been successfully employed in large-scale\nkernel approximation and supervised learning. The distribution from which the\nrandom features are drawn impacts the number of features required to\nefficiently perform a learning task. Recently, it has been shown that employing\ndata-dependent randomization improves the performance in terms of the required\nnumber of random features. In this paper, we are concerned with the\nrandomized-feature approach in supervised learning for good generalizability.\nWe propose the Energy-based Exploration of Random Features (EERF) algorithm\nbased on a data-dependent score function that explores the set of possible\nfeatures and exploits the promising regions. We prove that the proposed score\nfunction with high probability recovers the spectrum of the best fit within the\nmodel class. Our empirical results on several benchmark datasets further verify\nthat our method requires smaller number of random features to achieve a certain\ngeneralization error compared to the state-of-the-art while introducing\nnegligible pre-processing overhead. EERF can be implemented in a few lines of\ncode and requires no additional tuning parameters.\n", "versions": [{"version": "v1", "created": "Tue, 19 Dec 2017 18:40:36 GMT"}], "update_date": "2017-12-20", "authors_parsed": [["Shahrampour", "Shahin", ""], ["Beirami", "Ahmad", ""], ["Tarokh", "Vahid", ""]]}, {"id": "1712.07106", "submitter": "Jayaraman J. Thiagarajan", "authors": "Jayaraman J. Thiagarajan, Shusen Liu, Karthikeyan Natesan Ramamurthy,\n  Peer-Timo Bremer", "title": "Exploring High-Dimensional Structure via Axis-Aligned Decomposition of\n  Linear Projections", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two-dimensional embeddings remain the dominant approach to visualize high\ndimensional data. The choice of embeddings ranges from highly non-linear ones,\nwhich can capture complex relationships but are difficult to interpret\nquantitatively, to axis-aligned projections, which are easy to interpret but\nare limited to bivariate relationships. Linear project can be considered as a\ncompromise between complexity and interpretability, as they allow explicit axes\nlabels, yet provide significantly more degrees of freedom compared to\naxis-aligned projections. Nevertheless, interpreting the axes directions, which\nare linear combinations often with many non-trivial components, remains\ndifficult. To address this problem we introduce a structure aware decomposition\nof (multiple) linear projections into sparse sets of axis aligned projections,\nwhich jointly capture all information of the original linear ones. In\nparticular, we use tools from Dempster-Shafer theory to formally define how\nrelevant a given axis aligned project is to explain the neighborhood relations\ndisplayed in some linear projection. Furthermore, we introduce a new approach\nto discover a diverse set of high quality linear projections and show that in\npractice the information of $k$ linear projections is often jointly encoded in\n$\\sim k$ axis aligned plots. We have integrated these ideas into an interactive\nvisualization system that allows users to jointly browse both linear\nprojections and their axis aligned representatives. Using a number of case\nstudies we show how the resulting plots lead to more intuitive visualizations\nand new insight.\n", "versions": [{"version": "v1", "created": "Tue, 19 Dec 2017 18:43:20 GMT"}, {"version": "v2", "created": "Wed, 20 Dec 2017 04:00:03 GMT"}], "update_date": "2017-12-21", "authors_parsed": [["Thiagarajan", "Jayaraman J.", ""], ["Liu", "Shusen", ""], ["Ramamurthy", "Karthikeyan Natesan", ""], ["Bremer", "Peer-Timo", ""]]}, {"id": "1712.07107", "submitter": "Xiaoyong Yuan", "authors": "Xiaoyong Yuan, Pan He, Qile Zhu, Xiaolin Li", "title": "Adversarial Examples: Attacks and Defenses for Deep Learning", "comments": "Github: https://github.com/chbrian/awesome-adversarial-examples-dl", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With rapid progress and significant successes in a wide spectrum of\napplications, deep learning is being applied in many safety-critical\nenvironments. However, deep neural networks have been recently found vulnerable\nto well-designed input samples, called adversarial examples. Adversarial\nexamples are imperceptible to human but can easily fool deep neural networks in\nthe testing/deploying stage. The vulnerability to adversarial examples becomes\none of the major risks for applying deep neural networks in safety-critical\nenvironments. Therefore, attacks and defenses on adversarial examples draw\ngreat attention. In this paper, we review recent findings on adversarial\nexamples for deep neural networks, summarize the methods for generating\nadversarial examples, and propose a taxonomy of these methods. Under the\ntaxonomy, applications for adversarial examples are investigated. We further\nelaborate on countermeasures for adversarial examples and explore the\nchallenges and the potential solutions.\n", "versions": [{"version": "v1", "created": "Tue, 19 Dec 2017 18:44:07 GMT"}, {"version": "v2", "created": "Fri, 5 Jan 2018 15:51:54 GMT"}, {"version": "v3", "created": "Sat, 7 Jul 2018 02:32:57 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Yuan", "Xiaoyong", ""], ["He", "Pan", ""], ["Zhu", "Qile", ""], ["Li", "Xiaolin", ""]]}, {"id": "1712.07113", "submitter": "Andrew Ilyas", "authors": "Andrew Ilyas, Logan Engstrom, Anish Athalye, Jessy Lin", "title": "Query-Efficient Black-box Adversarial Examples (superceded)", "comments": "Superceded by \"Black-Box Adversarial Attacks with Limited Queries and\n  Information.\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Note that this paper is superceded by \"Black-Box Adversarial Attacks with\nLimited Queries and Information.\"\n  Current neural network-based image classifiers are susceptible to adversarial\nexamples, even in the black-box setting, where the attacker is limited to query\naccess without access to gradients. Previous methods --- substitute networks\nand coordinate-based finite-difference methods --- are either unreliable or\nquery-inefficient, making these methods impractical for certain problems.\n  We introduce a new method for reliably generating adversarial examples under\nmore restricted, practical black-box threat models. First, we apply natural\nevolution strategies to perform black-box attacks using two to three orders of\nmagnitude fewer queries than previous methods. Second, we introduce a new\nalgorithm to perform targeted adversarial attacks in the partial-information\nsetting, where the attacker only has access to a limited number of target\nclasses. Using these techniques, we successfully perform the first targeted\nadversarial attack against a commercially deployed machine learning system, the\nGoogle Cloud Vision API, in the partial information setting.\n", "versions": [{"version": "v1", "created": "Tue, 19 Dec 2017 18:58:10 GMT"}, {"version": "v2", "created": "Fri, 6 Apr 2018 17:20:27 GMT"}], "update_date": "2018-04-09", "authors_parsed": [["Ilyas", "Andrew", ""], ["Engstrom", "Logan", ""], ["Athalye", "Anish", ""], ["Lin", "Jessy", ""]]}, {"id": "1712.07177", "submitter": "Dmitri Pavlichin", "authors": "Dmitri S. Pavlichin, Jiantao Jiao, Tsachy Weissman", "title": "Approximate Profile Maximum Likelihood", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an efficient algorithm for approximate computation of the profile\nmaximum likelihood (PML), a variant of maximum likelihood maximizing the\nprobability of observing a sufficient statistic rather than the empirical\nsample. The PML has appealing theoretical properties, but is difficult to\ncompute exactly. Inspired by observations gleaned from exactly solvable cases,\nwe look for an approximate PML solution, which, intuitively, clumps comparably\nfrequent symbols into one symbol. This amounts to lower-bounding a certain\nmatrix permanent by summing over a subgroup of the symmetric group rather than\nthe whole group during the computation. We extensively experiment with the\napproximate solution, and find the empirical performance of our approach is\ncompetitive and sometimes significantly better than state-of-the-art\nperformance for various estimation problems.\n", "versions": [{"version": "v1", "created": "Tue, 19 Dec 2017 19:50:07 GMT"}], "update_date": "2017-12-21", "authors_parsed": [["Pavlichin", "Dmitri S.", ""], ["Jiao", "Jiantao", ""], ["Weissman", "Tsachy", ""]]}, {"id": "1712.07185", "submitter": "Pierre Richemond", "authors": "Pierre H. Richemond, Brendan Maginnis", "title": "On Wasserstein Reinforcement Learning and the Fokker-Planck equation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy gradients methods often achieve better performance when the change in\npolicy is limited to a small Kullback-Leibler divergence. We derive policy\ngradients where the change in policy is limited to a small Wasserstein distance\n(or trust region). This is done in the discrete and continuous multi-armed\nbandit settings with entropy regularisation. We show that in the small steps\nlimit with respect to the Wasserstein distance $W_2$, policy dynamics are\ngoverned by the Fokker-Planck (heat) equation, following the\nJordan-Kinderlehrer-Otto result. This means that policies undergo diffusion and\nadvection, concentrating near actions with high reward. This helps elucidate\nthe nature of convergence in the probability matching setup, and provides\njustification for empirical practices such as Gaussian policy priors and\nadditive gradient noise.\n", "versions": [{"version": "v1", "created": "Tue, 19 Dec 2017 20:05:06 GMT"}], "update_date": "2017-12-21", "authors_parsed": [["Richemond", "Pierre H.", ""], ["Maginnis", "Brendan", ""]]}, {"id": "1712.07196", "submitter": "Thomas Steinke", "authors": "Vitaly Feldman, Thomas Steinke", "title": "Calibrating Noise to Variance in Adaptive Data Analysis", "comments": "Accepted for presentation at Conference on Learning Theory (COLT)\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DS cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Datasets are often used multiple times and each successive analysis may\ndepend on the outcome of previous analyses. Standard techniques for ensuring\ngeneralization and statistical validity do not account for this adaptive\ndependence. A recent line of work studies the challenges that arise from such\nadaptive data reuse by considering the problem of answering a sequence of\n\"queries\" about the data distribution where each query may depend arbitrarily\non answers to previous queries.\n  The strongest results obtained for this problem rely on differential privacy\n-- a strong notion of algorithmic stability with the important property that it\n\"composes\" well when data is reused. However the notion is rather strict, as it\nrequires stability under replacement of an arbitrary data element. The simplest\nalgorithm is to add Gaussian (or Laplace) noise to distort the empirical\nanswers. However, analysing this technique using differential privacy yields\nsuboptimal accuracy guarantees when the queries have low variance. Here we\npropose a relaxed notion of stability that also composes adaptively. We\ndemonstrate that a simple and natural algorithm based on adding noise scaled to\nthe standard deviation of the query provides our notion of stability. This\nimplies an algorithm that can answer statistical queries about the dataset with\nsubstantially improved accuracy guarantees for low-variance queries. The only\nprevious approach that provides such accuracy guarantees is based on a more\ninvolved differentially private median-of-means algorithm and its analysis\nexploits stronger \"group\" stability of the algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 19 Dec 2017 20:42:39 GMT"}, {"version": "v2", "created": "Mon, 11 Jun 2018 19:14:14 GMT"}], "update_date": "2018-06-13", "authors_parsed": [["Feldman", "Vitaly", ""], ["Steinke", "Thomas", ""]]}, {"id": "1712.07203", "submitter": "Xiaowei Jia", "authors": "Xiaowei Jia, Ankush Khandelwal, Anuj Karpatne, Vipin Kumar", "title": "Discovery of Shifting Patterns in Sequence Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the multi-variate sequence classification\nproblem from a multi-instance learning perspective. Real-world sequential data\ncommonly show discriminative patterns only at specific time periods. For\ninstance, we can identify a cropland during its growing season, but it looks\nsimilar to a barren land after harvest or before planting. Besides, even within\nthe same class, the discriminative patterns can appear in different periods of\nsequential data. Due to such property, these discriminative patterns are also\nreferred to as shifting patterns. The shifting patterns in sequential data\nseverely degrade the performance of traditional classification methods without\nsufficient training data.\n  We propose a novel sequence classification method by automatically mining\nshifting patterns from multi-variate sequence. The method employs a\nmulti-instance learning approach to detect shifting patterns while also\nmodeling temporal relationships within each multi-instance bag by an LSTM model\nto further improve the classification performance. We extensively evaluate our\nmethod on two real-world applications - cropland mapping and affective state\nrecognition. The experiments demonstrate the superiority of our proposed method\nin sequence classification performance and in detecting discriminative shifting\npatterns.\n", "versions": [{"version": "v1", "created": "Tue, 19 Dec 2017 20:51:32 GMT"}], "update_date": "2017-12-21", "authors_parsed": [["Jia", "Xiaowei", ""], ["Khandelwal", "Ankush", ""], ["Karpatne", "Anuj", ""], ["Kumar", "Vipin", ""]]}, {"id": "1712.07230", "submitter": "Yehezkel Resheff", "authors": "Yehezkel S. Resheff and Moni Shahar", "title": "Fusing Multifaceted Transaction Data for User Modeling and Demographic\n  Prediction", "comments": "IFUP 2018 (WSDM workshop)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inferring user characteristics such as demographic attributes is of the\nutmost importance in many user-centric applications. Demographic data is an\nenabler of personalization, identity security, and other applications. Despite\nthat, this data is sensitive and often hard to obtain. Previous work has shown\nthat purchase history can be used for multi-task prediction of many demographic\nfields such as gender and marital status. Here we present an embedding based\nmethod to integrate multifaceted sequences of transaction data, together with\nauxiliary relational tables, for better user modeling and demographic\nprediction.\n", "versions": [{"version": "v1", "created": "Tue, 19 Dec 2017 21:45:06 GMT"}], "update_date": "2017-12-21", "authors_parsed": [["Resheff", "Yehezkel S.", ""], ["Shahar", "Moni", ""]]}, {"id": "1712.07233", "submitter": "Pushparaja Murugan", "authors": "Pushparaja Murugan", "title": "Hyperparameters Optimization in Deep Convolutional Neural Network /\n  Bayesian Approach with Gaussian Process Prior", "comments": "10 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Convolutional Neural Network is known as ConvNet have been extensively used\nin many complex machine learning tasks. However, hyperparameters optimization\nis one of a crucial step in developing ConvNet architectures, since the\naccuracy and performance are reliant on the hyperparameters. This multilayered\narchitecture parameterized by a set of hyperparameters such as the number of\nconvolutional layers, number of fully connected dense layers & neurons, the\nprobability of dropout implementation, learning rate. Hence the searching the\nhyperparameter over the hyperparameter space are highly difficult to build such\ncomplex hierarchical architecture. Many methods have been proposed over the\ndecade to explore the hyperparameter space and find the optimum set of\nhyperparameter values. Reportedly, Gird search and Random search are said to be\ninefficient and extremely expensive, due to a large number of hyperparameters\nof the architecture. Hence, Sequential model-based Bayesian Optimization is a\npromising alternative technique to address the extreme of the unknown cost\nfunction. The recent study on Bayesian Optimization by Snoek in nine\nconvolutional network parameters is achieved the lowerest error report in the\nCIFAR-10 benchmark. This article is intended to provide the overview of the\nmathematical concept behind the Bayesian Optimization over a Gaussian prior.\n", "versions": [{"version": "v1", "created": "Tue, 19 Dec 2017 21:48:56 GMT"}], "update_date": "2017-12-21", "authors_parsed": [["Murugan", "Pushparaja", ""]]}, {"id": "1712.07242", "submitter": "Dan Kushnir", "authors": "Dan Kushnir, Shirin Jalali, Iraj Saniee", "title": "Linear Time Clustering for High Dimensional Mixtures of Gaussian Clouds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering mixtures of Gaussian distributions is a fundamental and\nchallenging problem that is ubiquitous in various high-dimensional data\nprocessing tasks. While state-of-the-art work on learning Gaussian mixture\nmodels has focused primarily on improving separation bounds and their\ngeneralization to arbitrary classes of mixture models, less emphasis has been\npaid to practical computational efficiency of the proposed solutions. In this\npaper, we propose a novel and highly efficient clustering algorithm for $n$\npoints drawn from a mixture of two arbitrary Gaussian distributions in\n$\\mathbb{R}^p$. The algorithm involves performing random 1-dimensional\nprojections until a direction is found that yields a user-specified clustering\nerror $e$. For a 1-dimensional separation parameter $\\gamma$ satisfying\n$\\gamma=Q^{-1}(e)$, the expected number of such projections is shown to be\nbounded by $o(\\ln p)$, when $\\gamma$ satisfies $\\gamma\\leq\nc\\sqrt{\\ln{\\ln{p}}}$, with $c$ as the separability parameter of the two\nGaussians in $\\mathbb{R}^p$. Consequently, the expected overall running time of\nthe algorithm is linear in $n$ and quasi-linear in $p$ at $o(\\ln{p})O(np)$, and\nthe sample complexity is independent of $p$. This result stands in contrast to\nprior works which provide polynomial, with at-best quadratic, running time in\n$p$ and $n$. We show that our bound on the expected number of 1-dimensional\nprojections extends to the case of three or more Gaussian components, and we\npresent a generalization of our results to mixture distributions beyond the\nGaussian model.\n", "versions": [{"version": "v1", "created": "Tue, 19 Dec 2017 22:23:53 GMT"}, {"version": "v2", "created": "Fri, 22 Dec 2017 17:35:38 GMT"}, {"version": "v3", "created": "Thu, 1 Mar 2018 22:46:05 GMT"}], "update_date": "2018-03-05", "authors_parsed": [["Kushnir", "Dan", ""], ["Jalali", "Shirin", ""], ["Saniee", "Iraj", ""]]}, {"id": "1712.07249", "submitter": "Jo\\~ao Silv\\'erio", "authors": "Jo\\~ao Silv\\'erio, Yanlong Huang, Leonel Rozo, Sylvain Calinon, Darwin\n  G. Caldwell", "title": "Probabilistic Learning of Torque Controllers from Kinematic and Force\n  Constraints", "comments": "Accepted for publication at 2018 IEEE/RSJ International Conference on\n  Intelligent Robots and Systems (IROS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When learning skills from demonstrations, one is often required to think in\nadvance about the appropriate task representation (usually in either\noperational or configuration space). We here propose a probabilistic approach\nfor simultaneously learning and synthesizing torque control commands which take\ninto account task space, joint space and force constraints. We treat the\nproblem by considering different torque controllers acting on the robot, whose\nrelevance is learned probabilistically from demonstrations. This information is\nused to combine the controllers by exploiting the properties of Gaussian\ndistributions, generating new torque commands that satisfy the important\nfeatures of the task. We validate the approach in two experimental scenarios\nusing 7-DoF torquecontrolled manipulators, with tasks that require the\nconsideration of different controllers to be properly executed.\n", "versions": [{"version": "v1", "created": "Tue, 19 Dec 2017 22:46:37 GMT"}, {"version": "v2", "created": "Sat, 4 Aug 2018 01:14:30 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Silv\u00e9rio", "Jo\u00e3o", ""], ["Huang", "Yanlong", ""], ["Rozo", "Leonel", ""], ["Calinon", "Sylvain", ""], ["Caldwell", "Darwin G.", ""]]}, {"id": "1712.07296", "submitter": "Caiming Xiong Mr", "authors": "Huishuai Zhang, Caiming Xiong, James Bradbury, Richard Socher", "title": "Block-diagonal Hessian-free Optimization for Training Neural Networks", "comments": "10 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Second-order methods for neural network optimization have several advantages\nover methods based on first-order gradient descent, including better scaling to\nlarge mini-batch sizes and fewer updates needed for convergence. But they are\nrarely applied to deep learning in practice because of high computational cost\nand the need for model-dependent algorithmic variations. We introduce a variant\nof the Hessian-free method that leverages a block-diagonal approximation of the\ngeneralized Gauss-Newton matrix. Our method computes the curvature\napproximation matrix only for pairs of parameters from the same layer or block\nof the neural network and performs conjugate gradient updates independently for\neach block. Experiments on deep autoencoders, deep convolutional networks, and\nmultilayer LSTMs demonstrate better convergence and generalization compared to\nthe original Hessian-free approach and the Adam method.\n", "versions": [{"version": "v1", "created": "Wed, 20 Dec 2017 02:52:35 GMT"}], "update_date": "2017-12-21", "authors_parsed": [["Zhang", "Huishuai", ""], ["Xiong", "Caiming", ""], ["Bradbury", "James", ""], ["Socher", "Richard", ""]]}, {"id": "1712.07316", "submitter": "Stephen Merity", "authors": "Martin Schrimpf, Stephen Merity, James Bradbury, Richard Socher", "title": "A Flexible Approach to Automated RNN Architecture Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The process of designing neural architectures requires expert knowledge and\nextensive trial and error. While automated architecture search may simplify\nthese requirements, the recurrent neural network (RNN) architectures generated\nby existing methods are limited in both flexibility and components. We propose\na domain-specific language (DSL) for use in automated architecture search which\ncan produce novel RNNs of arbitrary depth and width. The DSL is flexible enough\nto define standard architectures such as the Gated Recurrent Unit and Long\nShort Term Memory and allows the introduction of non-standard RNN components\nsuch as trigonometric curves and layer normalization. Using two different\ncandidate generation techniques, random search with a ranking function and\nreinforcement learning, we explore the novel architectures produced by the RNN\nDSL for language modeling and machine translation domains. The resulting\narchitectures do not follow human intuition yet perform well on their targeted\ntasks, suggesting the space of usable RNN architectures is far larger than\npreviously assumed.\n", "versions": [{"version": "v1", "created": "Wed, 20 Dec 2017 04:20:40 GMT"}], "update_date": "2017-12-22", "authors_parsed": [["Schrimpf", "Martin", ""], ["Merity", "Stephen", ""], ["Bradbury", "James", ""], ["Socher", "Richard", ""]]}, {"id": "1712.07374", "submitter": "Ashkan Rezaei", "authors": "Hong Wang, Ashkan Rezaei, Brian D. Ziebart", "title": "Adversarial Structured Prediction for Multivariate Measures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many predicted structured objects (e.g., sequences, matchings, trees) are\nevaluated using the F-score, alignment error rate (AER), or other multivariate\nperformance measures. Since inductively optimizing these measures using\ntraining data is typically computationally difficult, empirical risk\nminimization of surrogate losses is employed, using, e.g., the hinge loss for\n(structured) support vector machines. These approximations often introduce a\nmismatch between the learner's objective and the desired application\nperformance, leading to inconsistency. We take a different approach:\nadversarially approximate training data while optimizing the exact F-score or\nAER. Structured predictions under this formulation result from solving zero-sum\ngames between a predictor seeking the best performance and an adversary seeking\nthe worst while required to (approximately) match certain structured properties\nof the training data. We explore this approach for word alignment (AER\nevaluation) and named entity recognition (F-score evaluation) with linear-chain\nconstraints.\n", "versions": [{"version": "v1", "created": "Wed, 20 Dec 2017 09:31:06 GMT"}, {"version": "v2", "created": "Thu, 21 Dec 2017 04:22:52 GMT"}], "update_date": "2017-12-22", "authors_parsed": [["Wang", "Hong", ""], ["Rezaei", "Ashkan", ""], ["Ziebart", "Brian D.", ""]]}, {"id": "1712.07420", "submitter": "Martin Wistuba", "authors": "Martin Wistuba", "title": "Finding Competitive Network Architectures Within a Day Using UCT", "comments": null, "journal-ref": "Proceedings of the 5th IEEE International Conference on Data\n  Science and Advanced Analytics, pages 263-272, 2018", "doi": "10.1109/DSAA.2018.00037", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The design of neural network architectures for a new data set is a laborious\ntask which requires human deep learning expertise. In order to make deep\nlearning available for a broader audience, automated methods for finding a\nneural network architecture are vital. Recently proposed methods can already\nachieve human expert level performances. However, these methods have run times\nof months or even years of GPU computing time, ignoring hardware constraints as\nfaced by many researchers and companies. We propose the use of Monte Carlo\nplanning in combination with two different UCT (upper confidence bound applied\nto trees) derivations to search for network architectures. We adapt the UCT\nalgorithm to the needs of network architecture search by proposing two ways of\nsharing information between different branches of the search tree. In an\nempirical study we are able to demonstrate that this method is able to find\ncompetitive networks for MNIST, SVHN and CIFAR-10 in just a single GPU day.\nExtending the search time to five GPU days, we are able to outperform human\narchitectures and our competitors which consider the same types of layers.\n", "versions": [{"version": "v1", "created": "Wed, 20 Dec 2017 11:24:50 GMT"}, {"version": "v2", "created": "Mon, 23 Jul 2018 13:57:50 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Wistuba", "Martin", ""]]}, {"id": "1712.07424", "submitter": "Vishwak Srinivasan", "authors": "Vishwak Srinivasan, Adepu Ravi Sankar and Vineeth N Balasubramanian", "title": "ADINE: An Adaptive Momentum Method for Stochastic Gradient Descent", "comments": "8 + 1 pages, 12 figures, accepted at CoDS-COMAD 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two major momentum-based techniques that have achieved tremendous success in\noptimization are Polyak's heavy ball method and Nesterov's accelerated\ngradient. A crucial step in all momentum-based methods is the choice of the\nmomentum parameter $m$ which is always suggested to be set to less than $1$.\nAlthough the choice of $m < 1$ is justified only under very strong theoretical\nassumptions, it works well in practice even when the assumptions do not\nnecessarily hold. In this paper, we propose a new momentum based method\n$\\textit{ADINE}$, which relaxes the constraint of $m < 1$ and allows the\nlearning algorithm to use adaptive higher momentum. We motivate our hypothesis\non $m$ by experimentally verifying that a higher momentum ($\\ge 1$) can help\nescape saddles much faster. Using this motivation, we propose our method\n$\\textit{ADINE}$ that helps weigh the previous updates more (by setting the\nmomentum parameter $> 1$), evaluate our proposed algorithm on deep neural\nnetworks and show that $\\textit{ADINE}$ helps the learning algorithm to\nconverge much faster without compromising on the generalization error.\n", "versions": [{"version": "v1", "created": "Wed, 20 Dec 2017 11:30:16 GMT"}], "update_date": "2017-12-21", "authors_parsed": [["Srinivasan", "Vishwak", ""], ["Sankar", "Adepu Ravi", ""], ["Balasubramanian", "Vineeth N", ""]]}, {"id": "1712.07449", "submitter": "Peter Ertl", "authors": "Peter Ertl, Richard Lewis, Eric Martin, Valery Polyakov", "title": "In silico generation of novel, drug-like chemical matter using the LSTM\n  neural network", "comments": "in this version fixed some reference numbers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The exploration of novel chemical spaces is one of the most important tasks\nof cheminformatics when supporting the drug discovery process. Properly\ndesigned and trained deep neural networks can provide a viable alternative to\nbrute-force de novo approaches or various other machine-learning techniques for\ngenerating novel drug-like molecules. In this article we present a method to\ngenerate molecules using a long short-term memory (LSTM) neural network and\nprovide an analysis of the results, including a virtual screening test. Using\nthe network one million drug-like molecules were generated in 2 hours. The\nmolecules are novel, diverse (contain numerous novel chemotypes), have good\nphysicochemical properties and have good synthetic accessibility, even though\nthese qualities were not specific constraints. Although novel, their structural\nfeatures and functional groups remain closely within the drug-like space\ndefined by the bioactive molecules from ChEMBL. Virtual screening using the\nprofile QSAR approach confirms that the potential of these novel molecules to\nshow bioactivity is comparable to the ChEMBL set from which they were derived.\nThe molecule generator written in Python used in this study is available on\nrequest.\n", "versions": [{"version": "v1", "created": "Wed, 20 Dec 2017 12:41:20 GMT"}, {"version": "v2", "created": "Mon, 8 Jan 2018 15:03:00 GMT"}], "update_date": "2018-01-09", "authors_parsed": [["Ertl", "Peter", ""], ["Lewis", "Richard", ""], ["Martin", "Eric", ""], ["Polyakov", "Valery", ""]]}, {"id": "1712.07454", "submitter": "Robert Duin", "authors": "Robert P.W. Duin and Sergey Verzakov", "title": "Fast kNN mode seeking clustering applied to active learning", "comments": "23 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A significantly faster algorithm is presented for the original kNN mode\nseeking procedure. It has the advantages over the well-known mean shift\nalgorithm that it is feasible in high-dimensional vector spaces and results in\nuniquely, well defined modes. Moreover, without any additional computational\neffort it may yield a multi-scale hierarchy of clusterings. The time complexity\nis just O(n^1.5). resulting computing times range from seconds for 10^4 objects\nto minutes for 10^5 objects and to less than an hour for 10^6 objects. The\nspace complexity is just O(n). The procedure is well suited for finding large\nsets of small clusters and is thereby a candidate to analyze thousands of\nclusters in millions of objects.\n  The kNN mode seeking procedure can be used for active learning by assigning\nthe clusters to the class of the modal objects of the clusters. Its feasibility\nis shown by some examples with up to 1.5 million handwritten digits. The\nobtained classification results based on the clusterings are compared with\nthose obtained by the nearest neighbor rule and the support vector classifier\nbased on the same labeled objects for training. It can be concluded that using\nthe clustering structure for classification can be significantly better than\nusing the trained classifiers. A drawback of using the clustering for\nclassification, however, is that no classifier is obtained that may be used for\nout-of-sample objects.\n", "versions": [{"version": "v1", "created": "Wed, 20 Dec 2017 12:51:21 GMT"}], "update_date": "2017-12-21", "authors_parsed": [["Duin", "Robert P. W.", ""], ["Verzakov", "Sergey", ""]]}, {"id": "1712.07473", "submitter": "Mikhail Kudinov", "authors": "Vadim Popov, Mikhail Kudinov, Irina Piontkovskaya, Petr Vytovtov and\n  Alex Nevidomsky", "title": "Differentially Private Distributed Learning for Language Modeling Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the big challenges in machine learning applications is that training\ndata can be different from the real-world data faced by the algorithm. In\nlanguage modeling, users' language (e.g. in private messaging) could change in\na year and be completely different from what we observe in publicly available\ndata. At the same time, public data can be used for obtaining general knowledge\n(i.e. general model of English). We study approaches to distributed fine-tuning\nof a general model on user private data with the additional requirements of\nmaintaining the quality on the general data and minimization of communication\ncosts. We propose a novel technique that significantly improves prediction\nquality on users' language compared to a general model and outperforms gradient\ncompression methods in terms of communication efficiency. The proposed\nprocedure is fast and leads to an almost 70% perplexity reduction and 8.7\npercentage point improvement in keystroke saving rate on informal English\ntexts. We also show that the range of tasks our approach is applicable to is\nnot limited by language modeling only. Finally, we propose an experimental\nframework for evaluating differential privacy of distributed training of\nlanguage models and show that our approach has good privacy guarantees.\n", "versions": [{"version": "v1", "created": "Wed, 20 Dec 2017 13:28:13 GMT"}, {"version": "v2", "created": "Fri, 29 Dec 2017 14:10:05 GMT"}, {"version": "v3", "created": "Tue, 6 Mar 2018 13:10:31 GMT"}], "update_date": "2018-03-07", "authors_parsed": [["Popov", "Vadim", ""], ["Kudinov", "Mikhail", ""], ["Piontkovskaya", "Irina", ""], ["Vytovtov", "Petr", ""], ["Nevidomsky", "Alex", ""]]}, {"id": "1712.07495", "submitter": "Wenjie Zheng", "authors": "Wenjie Zheng, Aur\\'elien Bellet, Patrick Gallinari", "title": "A Distributed Frank-Wolfe Framework for Learning Low-Rank Matrices with\n  the Trace Norm", "comments": null, "journal-ref": null, "doi": "10.1007/s10994-018-5713-5", "report-no": null, "categories": "cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning a high-dimensional but low-rank matrix\nfrom a large-scale dataset distributed over several machines, where\nlow-rankness is enforced by a convex trace norm constraint. We propose\nDFW-Trace, a distributed Frank-Wolfe algorithm which leverages the low-rank\nstructure of its updates to achieve efficiency in time, memory and\ncommunication usage. The step at the heart of DFW-Trace is solved approximately\nusing a distributed version of the power method. We provide a theoretical\nanalysis of the convergence of DFW-Trace, showing that we can ensure sublinear\nconvergence in expectation to an optimal solution with few power iterations per\nepoch. We implement DFW-Trace in the Apache Spark distributed programming\nframework and validate the usefulness of our approach on synthetic and real\ndata, including the ImageNet dataset with high-dimensional features extracted\nfrom a deep neural network.\n", "versions": [{"version": "v1", "created": "Wed, 20 Dec 2017 14:28:21 GMT"}, {"version": "v2", "created": "Fri, 11 May 2018 12:09:11 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Zheng", "Wenjie", ""], ["Bellet", "Aur\u00e9lien", ""], ["Gallinari", "Patrick", ""]]}, {"id": "1712.07525", "submitter": "Ayush Singhal", "authors": "Ayush Singhal, Pradeep Sinha, Rakesh Pant", "title": "Use of Deep Learning in Modern Recommendation System: A Summary of\n  Recent Works", "comments": "6 pages, 1 figure, 1 table, \"Published with International Journal of\n  Computer Applications (IJCA)\"", "journal-ref": "International Journal of Computer Applications 180(7):17-22,\n  December 2017", "doi": "10.5120/ijca2017916055", "report-no": null, "categories": "cs.LG cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the exponential increase in the amount of digital information over the\ninternet, online shops, online music, video and image libraries, search engines\nand recommendation system have become the most convenient ways to find relevant\ninformation within a short time. In the recent times, deep learning's advances\nhave gained significant attention in the field of speech recognition, image\nprocessing and natural language processing. Meanwhile, several recent studies\nhave shown the utility of deep learning in the area of recommendation systems\nand information retrieval as well. In this short review, we cover the recent\nadvances made in the field of recommendation using various variants of deep\nlearning technology. We organize the review in three parts: Collaborative\nsystem, Content based system and Hybrid system. The review also discusses the\ncontribution of deep learning integrated recommendation systems into several\napplication domains. The review concludes by discussion of the impact of deep\nlearning in recommendation system in various domain and whether deep learning\nhas shown any significant improvement over the conventional systems for\nrecommendation. Finally, we also provide future directions of research which\nare possible based on the current state of use of deep learning in\nrecommendation systems.\n", "versions": [{"version": "v1", "created": "Wed, 20 Dec 2017 15:25:31 GMT"}], "update_date": "2017-12-21", "authors_parsed": [["Singhal", "Ayush", ""], ["Sinha", "Pradeep", ""], ["Pant", "Rakesh", ""]]}, {"id": "1712.07557", "submitter": "Robin Geyer", "authors": "Robin C. Geyer, Tassilo Klein, Moin Nabi", "title": "Differentially Private Federated Learning: A Client Level Perspective", "comments": "NIPS 2017 Workshop: Machine Learning on the Phone and other Consumer\n  Devices", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning is a recent advance in privacy protection. In this\ncontext, a trusted curator aggregates parameters optimized in decentralized\nfashion by multiple clients. The resulting model is then distributed back to\nall clients, ultimately converging to a joint representative model without\nexplicitly having to share the data. However, the protocol is vulnerable to\ndifferential attacks, which could originate from any party contributing during\nfederated optimization. In such an attack, a client's contribution during\ntraining and information about their data set is revealed through analyzing the\ndistributed model. We tackle this problem and propose an algorithm for client\nsided differential privacy preserving federated optimization. The aim is to\nhide clients' contributions during training, balancing the trade-off between\nprivacy loss and model performance. Empirical studies suggest that given a\nsufficiently large number of participating clients, our proposed procedure can\nmaintain client-level differential privacy at only a minor cost in model\nperformance.\n", "versions": [{"version": "v1", "created": "Wed, 20 Dec 2017 16:28:37 GMT"}, {"version": "v2", "created": "Thu, 1 Mar 2018 10:12:27 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Geyer", "Robin C.", ""], ["Klein", "Tassilo", ""], ["Nabi", "Moin", ""]]}, {"id": "1712.07570", "submitter": "Fabio Sciarrino", "authors": "Alessandro Lumino, Emanuele Polino, Adil S. Rab, Giorgio Milani,\n  Nicol\\`o Spagnolo, Nathan Wiebe, Fabio Sciarrino", "title": "Experimental Phase Estimation Enhanced By Machine Learning", "comments": "10+4 pages, 6+3 figures", "journal-ref": "Phys. Rev. Applied 10, 044033 (2018)", "doi": "10.1103/PhysRevApplied.10.044033", "report-no": null, "categories": "quant-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Phase estimation protocols provide a fundamental benchmark for the field of\nquantum metrology. The latter represents one of the most relevant applications\nof quantum theory, potentially enabling the capability of measuring unknown\nphysical parameters with improved precision over classical strategies. Within\nthis context, most theoretical and experimental studies have focused on\ndetermining the fundamental bounds and how to achieve them in the asymptotic\nregime where a large number of resources is employed. However, in most\napplications it is necessary to achieve optimal precisions by performing only a\nlimited number of measurements. To this end, machine learning techniques can be\napplied as a powerful optimization tool. Here, we implement experimentally\nsingle-photon adaptive phase estimation protocols enhanced by machine learning,\nshowing the capability of reaching optimal precision after a small number of\ntrials. In particular, we introduce a new approach for Bayesian estimation that\nexhibit best performances for very low number of photons N. Furthermore, we\nstudy the resilience to noise of the tested methods, showing that the optimized\nBayesian approach is very robust in the presence of imperfections. Application\nof this methodology can be envisaged in the more general multiparameter case,\nthat represents a paradigmatic scenario for several tasks including imaging or\nHamiltonian learning.\n", "versions": [{"version": "v1", "created": "Wed, 20 Dec 2017 16:39:01 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Lumino", "Alessandro", ""], ["Polino", "Emanuele", ""], ["Rab", "Adil S.", ""], ["Milani", "Giorgio", ""], ["Spagnolo", "Nicol\u00f2", ""], ["Wiebe", "Nathan", ""], ["Sciarrino", "Fabio", ""]]}, {"id": "1712.07581", "submitter": "Stefano Carrazza", "authors": "Daniel Krefl, Stefano Carrazza, Babak Haghighat, Jens Kahlen", "title": "Riemann-Theta Boltzmann Machine", "comments": "29 pages, 11 figures, final version published in Neurocomputing", "journal-ref": null, "doi": "10.1016/j.neucom.2020.01.011", "report-no": "CERN-TH-2017-275", "categories": "stat.ML cs.LG hep-ph hep-th math.AG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A general Boltzmann machine with continuous visible and discrete integer\nvalued hidden states is introduced. Under mild assumptions about the connection\nmatrices, the probability density function of the visible units can be solved\nfor analytically, yielding a novel parametric density function involving a\nratio of Riemann-Theta functions. The conditional expectation of a hidden state\nfor given visible states can also be calculated analytically, yielding a\nderivative of the logarithmic Riemann-Theta function. The conditional\nexpectation can be used as activation function in a feedforward neural network,\nthereby increasing the modelling capacity of the network. Both the Boltzmann\nmachine and the derived feedforward neural network can be successfully trained\nvia standard gradient- and non-gradient-based optimization techniques.\n", "versions": [{"version": "v1", "created": "Wed, 20 Dec 2017 17:01:42 GMT"}, {"version": "v2", "created": "Fri, 6 Apr 2018 09:32:24 GMT"}, {"version": "v3", "created": "Tue, 28 Jan 2020 09:28:05 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Krefl", "Daniel", ""], ["Carrazza", "Stefano", ""], ["Haghighat", "Babak", ""], ["Kahlen", "Jens", ""]]}, {"id": "1712.07628", "submitter": "Nitish Shirish Keskar", "authors": "Nitish Shirish Keskar and Richard Socher", "title": "Improving Generalization Performance by Switching from Adam to SGD", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite superior training outcomes, adaptive optimization methods such as\nAdam, Adagrad or RMSprop have been found to generalize poorly compared to\nStochastic gradient descent (SGD). These methods tend to perform well in the\ninitial portion of training but are outperformed by SGD at later stages of\ntraining. We investigate a hybrid strategy that begins training with an\nadaptive method and switches to SGD when appropriate. Concretely, we propose\nSWATS, a simple strategy which switches from Adam to SGD when a triggering\ncondition is satisfied. The condition we propose relates to the projection of\nAdam steps on the gradient subspace. By design, the monitoring process for this\ncondition adds very little overhead and does not increase the number of\nhyperparameters in the optimizer. We report experiments on several standard\nbenchmarks such as: ResNet, SENet, DenseNet and PyramidNet for the CIFAR-10 and\nCIFAR-100 data sets, ResNet on the tiny-ImageNet data set and language modeling\nwith recurrent networks on the PTB and WT2 data sets. The results show that our\nstrategy is capable of closing the generalization gap between SGD and Adam on a\nmajority of the tasks.\n", "versions": [{"version": "v1", "created": "Wed, 20 Dec 2017 18:34:08 GMT"}], "update_date": "2017-12-21", "authors_parsed": [["Keskar", "Nitish Shirish", ""], ["Socher", "Richard", ""]]}, {"id": "1712.07632", "submitter": "Yuri G. Gordienko", "authors": "Yu.Gordienko, Peng Gang, Jiang Hui, Wei Zeng, Yu.Kochura, O.Alienin,\n  O. Rokovyi, S. Stirenko", "title": "Deep Learning with Lung Segmentation and Bone Shadow Exclusion\n  Techniques for Chest X-Ray Analysis of Lung Cancer", "comments": "10 pages, 7 figures; The First International Conference on Computer\n  Science, Engineering and Education Applications (ICCSEEA2018)\n  (www.uacnconf.org/iccseea2018) (accepted)", "journal-ref": "In: Hu Z., Petoukhov S., Dychka I., He M. (eds) Advances in\n  Computer Science for Engineering and Education. ICCSEEA 2018. Advances in\n  Intelligent Systems and Computing, vol 754, p. 638-647. Springer, Cham", "doi": "10.1007/978-3-319-91008-6_63", "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent progress of computing, machine learning, and especially deep\nlearning, for image recognition brings a meaningful effect for automatic\ndetection of various diseases from chest X-ray images (CXRs). Here efficiency\nof lung segmentation and bone shadow exclusion techniques is demonstrated for\nanalysis of 2D CXRs by deep learning approach to help radiologists identify\nsuspicious lesions and nodules in lung cancer patients. Training and validation\nwas performed on the original JSRT dataset (dataset #01), BSE-JSRT dataset,\ni.e. the same JSRT dataset, but without clavicle and rib shadows (dataset #02),\noriginal JSRT dataset after segmentation (dataset #03), and BSE-JSRT dataset\nafter segmentation (dataset #04). The results demonstrate the high efficiency\nand usefulness of the considered pre-processing techniques in the simplified\nconfiguration even. The pre-processed dataset without bones (dataset #02)\ndemonstrates the much better accuracy and loss results in comparison to the\nother pre-processed datasets after lung segmentation (datasets #02 and #03).\n", "versions": [{"version": "v1", "created": "Wed, 20 Dec 2017 18:40:49 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Gordienko", "Yu.", ""], ["Gang", "Peng", ""], ["Hui", "Jiang", ""], ["Zeng", "Wei", ""], ["Kochura", "Yu.", ""], ["Alienin", "O.", ""], ["Rokovyi", "O.", ""], ["Stirenko", "S.", ""]]}, {"id": "1712.07639", "submitter": "R. Lily Hu", "authors": "R. Lily Hu, Jeremy Karnowski, Ross Fadely, Jean-Patrick Pommier", "title": "Image Segmentation to Distinguish Between Overlapping Human Chromosomes", "comments": "Presented at NIPS 2017 Machine Learning for Health", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In medicine, visualizing chromosomes is important for medical diagnostics,\ndrug development, and biomedical research. Unfortunately, chromosomes often\noverlap and it is necessary to identify and distinguish between the overlapping\nchromosomes. A segmentation solution that is fast and automated will enable\nscaling of cost effective medicine and biomedical research. We apply neural\nnetwork-based image segmentation to the problem of distinguishing between\npartially overlapping DNA chromosomes. A convolutional neural network is\ncustomized for this problem. The results achieved intersection over union (IOU)\nscores of 94.7% for the overlapping region and 88-94% on the non-overlapping\nchromosome regions.\n", "versions": [{"version": "v1", "created": "Wed, 20 Dec 2017 18:48:41 GMT"}], "update_date": "2017-12-21", "authors_parsed": [["Hu", "R. Lily", ""], ["Karnowski", "Jeremy", ""], ["Fadely", "Ross", ""], ["Pommier", "Jean-Patrick", ""]]}, {"id": "1712.07642", "submitter": "Fereshteh Sadeghi", "authors": "Fereshteh Sadeghi, Alexander Toshev, Eric Jang, Sergey Levine", "title": "Sim2Real View Invariant Visual Servoing by Recurrent Control", "comments": "Supplementary video:\n  https://fsadeghi.github.io/Sim2RealViewInvariantServo", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans are remarkably proficient at controlling their limbs and tools from a\nwide range of viewpoints and angles, even in the presence of optical\ndistortions. In robotics, this ability is referred to as visual servoing:\nmoving a tool or end-point to a desired location using primarily visual\nfeedback. In this paper, we study how viewpoint-invariant visual servoing\nskills can be learned automatically in a robotic manipulation scenario. To this\nend, we train a deep recurrent controller that can automatically determine\nwhich actions move the end-point of a robotic arm to a desired object. The\nproblem that must be solved by this controller is fundamentally ambiguous:\nunder severe variation in viewpoint, it may be impossible to determine the\nactions in a single feedforward operation. Instead, our visual servoing system\nmust use its memory of past movements to understand how the actions affect the\nrobot motion from the current viewpoint, correcting mistakes and gradually\nmoving closer to the target. This ability is in stark contrast to most visual\nservoing methods, which either assume known dynamics or require a calibration\nphase. We show how we can learn this recurrent controller using simulated data\nand a reinforcement learning objective. We then describe how the resulting\nmodel can be transferred to a real-world robot by disentangling perception from\ncontrol and only adapting the visual layers. The adapted model can servo to\npreviously unseen objects from novel viewpoints on a real-world Kuka IIWA\nrobotic arm. For supplementary videos, see:\nhttps://fsadeghi.github.io/Sim2RealViewInvariantServo\n", "versions": [{"version": "v1", "created": "Wed, 20 Dec 2017 18:54:29 GMT"}], "update_date": "2017-12-21", "authors_parsed": [["Sadeghi", "Fereshteh", ""], ["Toshev", "Alexander", ""], ["Jang", "Eric", ""], ["Levine", "Sergey", ""]]}, {"id": "1712.07788", "submitter": "Dejiao Zhang", "authors": "Dejiao Zhang, Yifan Sun, Brian Eriksson, Laura Balzano", "title": "Deep Unsupervised Clustering Using Mixture of Autoencoders", "comments": "8 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised clustering is one of the most fundamental challenges in machine\nlearning. A popular hypothesis is that data are generated from a union of\nlow-dimensional nonlinear manifolds; thus an approach to clustering is\nidentifying and separating these manifolds. In this paper, we present a novel\napproach to solve this problem by using a mixture of autoencoders. Our model\nconsists of two parts: 1) a collection of autoencoders where each autoencoder\nlearns the underlying manifold of a group of similar objects, and 2) a mixture\nassignment neural network, which takes the concatenated latent vectors from the\nautoencoders as input and infers the distribution over clusters. By jointly\noptimizing the two parts, we simultaneously assign data to clusters and learn\nthe underlying manifolds of each cluster.\n", "versions": [{"version": "v1", "created": "Thu, 21 Dec 2017 04:27:35 GMT"}, {"version": "v2", "created": "Tue, 26 Dec 2017 16:45:12 GMT"}], "update_date": "2017-12-27", "authors_parsed": [["Zhang", "Dejiao", ""], ["Sun", "Yifan", ""], ["Eriksson", "Brian", ""], ["Balzano", "Laura", ""]]}, {"id": "1712.07799", "submitter": "Roger Dean Dr", "authors": "Roger T. Dean and Jamie Forth", "title": "Towards a Deep Improviser: a prototype deep learning post-tonal free\n  music generator", "comments": "13 pages, 1 Figure, 3 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two modest-sized symbolic corpora of post-tonal and post-metric keyboard\nmusic have been constructed, one algorithmic, the other improvised. Deep\nlearning models of each have been trained and largely optimised. Our purpose is\nto obtain a model with sufficient generalisation capacity that in response to a\nsmall quantity of separate fresh input seed material, it can generate outputs\nthat are distinctive, rather than recreative of the learned corpora or the seed\nmaterial. This objective has been first assessed statistically, and as judged\nby k-sample Anderson-Darling and Cramer tests, has been achieved. Music has\nbeen generated using the approach, and informal judgements place it roughly on\na par with algorithmic and composed music in related forms. Future work will\naim to enhance the model such that it can be evaluated in relation to\nexpression, meaning and utility in real-time performance.\n", "versions": [{"version": "v1", "created": "Thu, 21 Dec 2017 05:28:15 GMT"}], "update_date": "2017-12-22", "authors_parsed": [["Dean", "Roger T.", ""], ["Forth", "Jamie", ""]]}, {"id": "1712.07805", "submitter": "Kang Li", "authors": "Qixue Xiao, Kang Li, Deyue Zhang, Yier Jin", "title": "Wolf in Sheep's Clothing - The Downscaling Attack Against Deep Learning\n  Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers security risks buried in the data processing pipeline in\ncommon deep learning applications. Deep learning models usually assume a fixed\nscale for their training and input data. To allow deep learning applications to\nhandle a wide range of input data, popular frameworks, such as Caffe,\nTensorFlow, and Torch, all provide data scaling functions to resize input to\nthe dimensions used by deep learning models. Image scaling algorithms are\nintended to preserve the visual features of an image after scaling. However,\ncommon image scaling algorithms are not designed to handle human crafted\nimages. Attackers can make the scaling outputs look dramatically different from\nthe corresponding input images.\n  This paper presents a downscaling attack that targets the data scaling\nprocess in deep learning applications. By carefully crafting input data that\nmismatches with the dimension used by deep learning models, attackers can\ncreate deceiving effects. A deep learning application effectively consumes data\nthat are not the same as those presented to users. The visual inconsistency\nenables practical evasion and data poisoning attacks to deep learning\napplications. This paper presents proof-of-concept attack samples to popular\ndeep-learning-based image classification applications. To address the\ndownscaling attacks, the paper also suggests multiple potential mitigation\nstrategies.\n", "versions": [{"version": "v1", "created": "Thu, 21 Dec 2017 06:17:43 GMT"}], "update_date": "2017-12-22", "authors_parsed": [["Xiao", "Qixue", ""], ["Li", "Kang", ""], ["Zhang", "Deyue", ""], ["Jin", "Yier", ""]]}, {"id": "1712.07811", "submitter": "Takashi Kurokawa", "authors": "Takashi Kurokawa, Taihei Oki, Hiromichi Nagao", "title": "Multi-dimensional Graph Fourier Transform", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many signals on Cartesian product graphs appear in the real world, such as\ndigital images, sensor observation time series, and movie ratings on Netflix.\nThese signals are \"multi-dimensional\" and have directional characteristics\nalong each factor graph. However, the existing graph Fourier transform does not\ndistinguish these directions, and assigns 1-D spectra to signals on product\ngraphs. Further, these spectra are often multi-valued at some frequencies. Our\nmain result is a multi-dimensional graph Fourier transform that solves such\nproblems associated with the conventional GFT. Using algebraic properties of\nCartesian products, the proposed transform rearranges 1-D spectra obtained by\nthe conventional GFT into the multi-dimensional frequency domain, of which each\ndimension represents a directional frequency along each factor graph. Thus, the\nmulti-dimensional graph Fourier transform enables directional frequency\nanalysis, in addition to frequency analysis with the conventional GFT.\nMoreover, this rearrangement resolves the multi-valuedness of spectra in some\ncases. The multi-dimensional graph Fourier transform is a foundation of novel\nfilterings and stationarities that utilize dimensional information of graph\nsignals, which are also discussed in this study. The proposed methods are\napplicable to a wide variety of data that can be regarded as signals on\nCartesian product graphs. This study also notes that multivariate graph signals\ncan be regarded as 2-D univariate graph signals. This correspondence provides\nnatural definitions of the multivariate graph Fourier transform and the\nmultivariate stationarity based on their 2-D univariate versions.\n", "versions": [{"version": "v1", "created": "Thu, 21 Dec 2017 06:57:55 GMT"}], "update_date": "2017-12-22", "authors_parsed": [["Kurokawa", "Takashi", ""], ["Oki", "Taihei", ""], ["Nagao", "Hiromichi", ""]]}, {"id": "1712.07814", "submitter": "Yingxiang Sun", "authors": "Yingxiang Sun, Jiajia Chen, Chau Yuen, and Susanto Rahardja", "title": "Indoor Sound Source Localization with Probabilistic Neural Network", "comments": "10 pages, accepted by IEEE Transactions on Industrial Electronics", "journal-ref": "IEEE Transactions on Industrial Electronics, vol. 65, no. 8, pp.\n  6403-6413, Aug. 2018", "doi": "10.1109/TIE.2017.2786219", "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is known that adverse environments such as high reverberation and low\nsignal-to-noise ratio (SNR) pose a great challenge to indoor sound source\nlocalization. To address this challenge, in this paper, we propose a sound\nsource localization algorithm based on probabilistic neural network, namely\nGeneralized cross correlation Classification Algorithm (GCA). Experimental\nresults for adverse environments with high reverberation time T60 up to 600ms\nand low SNR such as -10dB show that, the average azimuth angle error and\nelevation angle error by GCA are only 4.6 degrees and 3.1 degrees respectively.\nCompared with three recently published algorithms, GCA has increased the\nsuccess rate on direction of arrival estimation significantly with good\nrobustness to environmental changes. These results show that the proposed GCA\ncan localize accurately and robustly for diverse indoor applications where the\nsite acoustic features can be studied prior to the localization stage.\n", "versions": [{"version": "v1", "created": "Thu, 21 Dec 2017 07:26:53 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["Sun", "Yingxiang", ""], ["Chen", "Jiajia", ""], ["Yuen", "Chau", ""], ["Rahardja", "Susanto", ""]]}, {"id": "1712.07822", "submitter": "L\\'eon Bottou", "authors": "Leon Bottou and Martin Arjovsky and David Lopez-Paz and Maxime Oquab", "title": "Geometrical Insights for Implicit Generative Modeling", "comments": "this version fixes a typo in a definition", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Learning algorithms for implicit generative models can optimize a variety of\ncriteria that measure how the data distribution differs from the implicit model\ndistribution, including the Wasserstein distance, the Energy distance, and the\nMaximum Mean Discrepancy criterion. A careful look at the geometries induced by\nthese distances on the space of probability measures reveals interesting\ndifferences. In particular, we can establish surprising approximate global\nconvergence guarantees for the $1$-Wasserstein distance,even when the\nparametric generator has a nonconvex parametrization.\n", "versions": [{"version": "v1", "created": "Thu, 21 Dec 2017 08:11:44 GMT"}, {"version": "v2", "created": "Mon, 12 Mar 2018 20:21:04 GMT"}, {"version": "v3", "created": "Wed, 21 Aug 2019 21:09:56 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Bottou", "Leon", ""], ["Arjovsky", "Martin", ""], ["Lopez-Paz", "David", ""], ["Oquab", "Maxime", ""]]}, {"id": "1712.07834", "submitter": "Hae Beom Lee", "authors": "Hae Beom Lee, Juho Lee, Saehoon Kim, Eunho Yang, Sung Ju Hwang", "title": "DropMax: Adaptive Variational Softmax", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose DropMax, a stochastic version of softmax classifier which at each\niteration drops non-target classes according to dropout probabilities\nadaptively decided for each instance. Specifically, we overlay binary masking\nvariables over class output probabilities, which are input-adaptively learned\nvia variational inference. This stochastic regularization has an effect of\nbuilding an ensemble classifier out of exponentially many classifiers with\ndifferent decision boundaries. Moreover, the learning of dropout rates for\nnon-target classes on each instance allows the classifier to focus more on\nclassification against the most confusing classes. We validate our model on\nmultiple public datasets for classification, on which it obtains significantly\nimproved accuracy over the regular softmax classifier and other baselines.\nFurther analysis of the learned dropout probabilities shows that our model\nindeed selects confusing classes more often when it performs classification.\n", "versions": [{"version": "v1", "created": "Thu, 21 Dec 2017 08:43:14 GMT"}, {"version": "v2", "created": "Sat, 23 Dec 2017 14:42:01 GMT"}, {"version": "v3", "created": "Sun, 4 Mar 2018 08:18:48 GMT"}, {"version": "v4", "created": "Sun, 20 May 2018 12:07:58 GMT"}, {"version": "v5", "created": "Fri, 2 Nov 2018 11:25:49 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Lee", "Hae Beom", ""], ["Lee", "Juho", ""], ["Kim", "Saehoon", ""], ["Yang", "Eunho", ""], ["Hwang", "Sung Ju", ""]]}, {"id": "1712.07886", "submitter": "Sagie Benaim", "authors": "Sagie Benaim, Tomer Galanti, Lior Wolf", "title": "Estimating the Success of Unsupervised Image to Image Translation", "comments": "The first and second authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While in supervised learning, the validation error is an unbiased estimator\nof the generalization (test) error and complexity-based generalization bounds\nare abundant, no such bounds exist for learning a mapping in an unsupervised\nway. As a result, when training GANs and specifically when using GANs for\nlearning to map between domains in a completely unsupervised way, one is forced\nto select the hyperparameters and the stopping epoch by subjectively examining\nmultiple options. We propose a novel bound for predicting the success of\nunsupervised cross domain mapping methods, which is motivated by the recently\nproposed Simplicity Principle. The bound can be applied both in expectation,\nfor comparing hyperparameters and for selecting a stopping criterion, or per\nsample, in order to predict the success of a specific cross-domain translation.\nThe utility of the bound is demonstrated in an extensive set of experiments\nemploying multiple recent algorithms. Our code is available at\nhttps://github.com/sagiebenaim/gan_bound .\n", "versions": [{"version": "v1", "created": "Thu, 21 Dec 2017 11:41:12 GMT"}, {"version": "v2", "created": "Thu, 22 Mar 2018 17:10:19 GMT"}], "update_date": "2018-03-23", "authors_parsed": [["Benaim", "Sagie", ""], ["Galanti", "Tomer", ""], ["Wolf", "Lior", ""]]}, {"id": "1712.07897", "submitter": "Purushottam Kar", "authors": "Prateek Jain and Purushottam Kar", "title": "Non-convex Optimization for Machine Learning", "comments": "The official publication is available from now publishers via\n  http://dx.doi.org/10.1561/2200000058", "journal-ref": "Foundations and Trends in Machine Learning: Vol. 10: No. 3-4, pp\n  142-336 (2017)", "doi": "10.1561/2200000058", "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A vast majority of machine learning algorithms train their models and perform\ninference by solving optimization problems. In order to capture the learning\nand prediction problems accurately, structural constraints such as sparsity or\nlow rank are frequently imposed or else the objective itself is designed to be\na non-convex function. This is especially true of algorithms that operate in\nhigh-dimensional spaces or that train non-linear models such as tensor models\nand deep networks.\n  The freedom to express the learning problem as a non-convex optimization\nproblem gives immense modeling power to the algorithm designer, but often such\nproblems are NP-hard to solve. A popular workaround to this has been to relax\nnon-convex problems to convex ones and use traditional methods to solve the\n(convex) relaxed optimization problems. However this approach may be lossy and\nnevertheless presents significant challenges for large scale optimization.\n  On the other hand, direct approaches to non-convex optimization have met with\nresounding success in several domains and remain the methods of choice for the\npractitioner, as they frequently outperform relaxation-based techniques -\npopular heuristics include projected gradient descent and alternating\nminimization. However, these are often poorly understood in terms of their\nconvergence and other properties.\n  This monograph presents a selection of recent advances that bridge a\nlong-standing gap in our understanding of these heuristics. The monograph will\nlead the reader through several widely used non-convex optimization techniques,\nas well as applications thereof. The goal of this monograph is to both,\nintroduce the rich literature in this area, as well as equip the reader with\nthe tools and techniques needed to analyze these simple procedures for\nnon-convex problems.\n", "versions": [{"version": "v1", "created": "Thu, 21 Dec 2017 12:05:40 GMT"}], "update_date": "2017-12-22", "authors_parsed": [["Jain", "Prateek", ""], ["Kar", "Purushottam", ""]]}, {"id": "1712.08062", "submitter": "Earlence T Fernandes", "authors": "Kevin Eykholt, Ivan Evtimov, Earlence Fernandes, Bo Li, Dawn Song,\n  Tadayoshi Kohno, Amir Rahmati, Atul Prakash, Florian Tramer", "title": "Note on Attacking Object Detectors with Adversarial Stickers", "comments": "Short Note: The full version of this paper was accepted to USENIX\n  WOOT 2018, and is available at arXiv:1807.07769", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has proven to be a powerful tool for computer vision and has\nseen widespread adoption for numerous tasks. However, deep learning algorithms\nare known to be vulnerable to adversarial examples. These adversarial inputs\nare created such that, when provided to a deep learning algorithm, they are\nvery likely to be mislabeled. This can be problematic when deep learning is\nused to assist in safety critical decisions. Recent research has shown that\nclassifiers can be attacked by physical adversarial examples under various\nphysical conditions. Given the fact that state-of-the-art objection detection\nalgorithms are harder to be fooled by the same set of adversarial examples,\nhere we show that these detectors can also be attacked by physical adversarial\nexamples. In this note, we briefly show both static and dynamic test results.\nWe design an algorithm that produces physical adversarial inputs, which can\nfool the YOLO object detector and can also attack Faster-RCNN with relatively\nhigh success rate based on transferability. Furthermore, our algorithm can\ncompress the size of the adversarial inputs to stickers that, when attached to\nthe targeted object, result in the detector either mislabeling or not detecting\nthe object a high percentage of the time. This note provides a small set of\nresults. Our upcoming paper will contain a thorough evaluation on other object\ndetectors, and will present the algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 21 Dec 2017 16:33:01 GMT"}, {"version": "v2", "created": "Mon, 23 Jul 2018 19:37:07 GMT"}], "update_date": "2018-07-25", "authors_parsed": [["Eykholt", "Kevin", ""], ["Evtimov", "Ivan", ""], ["Fernandes", "Earlence", ""], ["Li", "Bo", ""], ["Song", "Dawn", ""], ["Kohno", "Tadayoshi", ""], ["Rahmati", "Amir", ""], ["Prakash", "Atul", ""], ["Tramer", "Florian", ""]]}, {"id": "1712.08091", "submitter": "Tien Do Huu", "authors": "Tien Huu Do, Duc Minh Nguyen, Evaggelia Tsiligianni, Bruno Cornelis\n  and Nikos Deligiannis", "title": "Multiview Deep Learning for Predicting Twitter Users' Location", "comments": "Submitted to the IEEE Transactions on Big Data", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of predicting the location of users on large social networks like\nTwitter has emerged from real-life applications such as social unrest detection\nand online marketing. Twitter user geolocation is a difficult and active\nresearch topic with a vast literature. Most of the proposed methods follow\neither a content-based or a network-based approach. The former exploits\nuser-generated content while the latter utilizes the connection or interaction\nbetween Twitter users. In this paper, we introduce a novel method combining the\nstrength of both approaches. Concretely, we propose a multi-entry neural\nnetwork architecture named MENET leveraging the advances in deep learning and\nmultiview learning. The generalizability of MENET enables the integration of\nmultiple data representations. In the context of Twitter user geolocation, we\nrealize MENET with textual, network, and metadata features. Considering the\nnatural distribution of Twitter users across the concerned geographical area,\nwe subdivide the surface of the earth into multi-scale cells and train MENET\nwith the labels of the cells. We show that our method outperforms the state of\nthe art by a large margin on three benchmark datasets.\n", "versions": [{"version": "v1", "created": "Thu, 21 Dec 2017 17:15:41 GMT"}], "update_date": "2017-12-22", "authors_parsed": [["Do", "Tien Huu", ""], ["Nguyen", "Duc Minh", ""], ["Tsiligianni", "Evaggelia", ""], ["Cornelis", "Bruno", ""], ["Deligiannis", "Nikos", ""]]}, {"id": "1712.08101", "submitter": "Sebastiaan H\\\"oppner", "authors": "Sebastiaan H\\\"oppner, Eugen Stripling, Bart Baesens, Seppe vanden\n  Broucke and Tim Verdonck", "title": "Profit Driven Decision Trees for Churn Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Customer retention campaigns increasingly rely on predictive models to detect\npotential churners in a vast customer base. From the perspective of machine\nlearning, the task of predicting customer churn can be presented as a binary\nclassification problem. Using data on historic behavior, classification\nalgorithms are built with the purpose of accurately predicting the probability\nof a customer defecting. The predictive churn models are then commonly selected\nbased on accuracy related performance measures such as the area under the ROC\ncurve (AUC). However, these models are often not well aligned with the core\nbusiness requirement of profit maximization, in the sense that, the models fail\nto take into account not only misclassification costs, but also the benefits\noriginating from a correct classification. Therefore, the aim is to construct\nchurn prediction models that are profitable and preferably interpretable too.\nThe recently developed expected maximum profit measure for customer churn\n(EMPC) has been proposed in order to select the most profitable churn model. We\npresent a new classifier that integrates the EMPC metric directly into the\nmodel construction. Our technique, called ProfTree, uses an evolutionary\nalgorithm for learning profit driven decision trees. In a benchmark study with\nreal-life data sets from various telecommunication service providers, we show\nthat ProfTree achieves significant profit improvements compared to classic\naccuracy driven tree-based methods.\n", "versions": [{"version": "v1", "created": "Thu, 21 Dec 2017 17:31:58 GMT"}], "update_date": "2017-12-22", "authors_parsed": [["H\u00f6ppner", "Sebastiaan", ""], ["Stripling", "Eugen", ""], ["Baesens", "Bart", ""], ["Broucke", "Seppe vanden", ""], ["Verdonck", "Tim", ""]]}, {"id": "1712.08107", "submitter": "Jordi De La Torre", "authors": "Jordi de la Torre and Aida Valls and Domenec Puig", "title": "A Deep Learning Interpretable Classifier for Diabetic Retinopathy\n  Disease Grading", "comments": "Submitted to Elsevier", "journal-ref": null, "doi": "10.1016/j.neucom.2018.07.102", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural network models have been proven to be very successful in image\nclassification tasks, also for medical diagnosis, but their main concern is its\nlack of interpretability. They use to work as intuition machines with high\nstatistical confidence but unable to give interpretable explanations about the\nreported results. The vast amount of parameters of these models make difficult\nto infer a rationale interpretation from them. In this paper we present a\ndiabetic retinopathy interpretable classifier able to classify retine images\ninto the different levels of disease severity and of explaining its results by\nassigning a score for every point in the hidden and input space, evaluating its\ncontribution to the final classification in a linear way. The generated visual\nmaps can be interpreted by an expert in order to compare its own knowledge with\nthe interpretation given by the model.\n", "versions": [{"version": "v1", "created": "Thu, 21 Dec 2017 17:40:32 GMT"}], "update_date": "2019-04-26", "authors_parsed": [["de la Torre", "Jordi", ""], ["Valls", "Aida", ""], ["Puig", "Domenec", ""]]}, {"id": "1712.08125", "submitter": "Saurabh Gupta", "authors": "Saurabh Gupta, David Fouhey, Sergey Levine, Jitendra Malik", "title": "Unifying Map and Landmark Based Representations for Visual Navigation", "comments": "Project page with videos: https://s-gupta.github.io/cmpl/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This works presents a formulation for visual navigation that unifies map\nbased spatial reasoning and path planning, with landmark based robust plan\nexecution in noisy environments. Our proposed formulation is learned from data\nand is thus able to leverage statistical regularities of the world. This allows\nit to efficiently navigate in novel environments given only a sparse set of\nregistered images as input for building representations for space. Our\nformulation is based on three key ideas: a learned path planner that outputs\npath plans to reach the goal, a feature synthesis engine that predicts features\nfor locations along the planned path, and a learned goal-driven closed loop\ncontroller that can follow plans given these synthesized features. We test our\napproach for goal-driven navigation in simulated real world environments and\nreport performance gains over competitive baseline approaches.\n", "versions": [{"version": "v1", "created": "Thu, 21 Dec 2017 18:02:14 GMT"}], "update_date": "2017-12-22", "authors_parsed": [["Gupta", "Saurabh", ""], ["Fouhey", "David", ""], ["Levine", "Sergey", ""], ["Malik", "Jitendra", ""]]}, {"id": "1712.08160", "submitter": "Ilya Kuzovkin", "authors": "Anna Leontjeva, Ilya Kuzovkin", "title": "Combining Static and Dynamic Features for Multivariate Sequence\n  Classification", "comments": "Presented at IEEE DSAA 2016", "journal-ref": null, "doi": "10.1109/DSAA.2016.10", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Model precision in a classification task is highly dependent on the feature\nspace that is used to train the model. Moreover, whether the features are\nsequential or static will dictate which classification method can be applied as\nmost of the machine learning algorithms are designed to deal with either one or\nanother type of data. In real-life scenarios, however, it is often the case\nthat both static and dynamic features are present, or can be extracted from the\ndata. In this work, we demonstrate how generative models such as Hidden Markov\nModels (HMM) and Long Short-Term Memory (LSTM) artificial neural networks can\nbe used to extract temporal information from the dynamic data. We explore how\nthe extracted information can be combined with the static features in order to\nimprove the classification performance. We evaluate the existing techniques and\nsuggest a hybrid approach, which outperforms other methods on several public\ndatasets.\n", "versions": [{"version": "v1", "created": "Wed, 20 Dec 2017 23:59:13 GMT"}], "update_date": "2017-12-25", "authors_parsed": [["Leontjeva", "Anna", ""], ["Kuzovkin", "Ilya", ""]]}, {"id": "1712.08163", "submitter": "Weiming Xiang", "authors": "Weiming Xiang, Hoang-Dung Tran, Taylor T. Johnson", "title": "Reachable Set Computation and Safety Verification for Neural Networks\n  with ReLU Activations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have been widely used to solve complex real-world problems.\nDue to the complicate, nonlinear, non-convex nature of neural networks, formal\nsafety guarantees for the output behaviors of neural networks will be crucial\nfor their applications in safety-critical systems.In this paper, the output\nreachable set computation and safety verification problems for a class of\nneural networks consisting of Rectified Linear Unit (ReLU) activation functions\nare addressed. A layer-by-layer approach is developed to compute output\nreachable set. The computation is formulated in the form of a set of\nmanipulations for a union of polyhedra, which can be efficiently applied with\nthe aid of polyhedron computation tools. Based on the output reachable set\ncomputation results, the safety verification for a ReLU neural network can be\nperformed by checking the intersections of unsafe regions and output reachable\nset described by a union of polyhedra. A numerical example of a randomly\ngenerated ReLU neural network is provided to show the effectiveness of the\napproach developed in this paper.\n", "versions": [{"version": "v1", "created": "Thu, 21 Dec 2017 08:57:06 GMT"}], "update_date": "2017-12-25", "authors_parsed": [["Xiang", "Weiming", ""], ["Tran", "Hoang-Dung", ""], ["Johnson", "Taylor T.", ""]]}, {"id": "1712.08164", "submitter": "Boris Chidlovskii", "authors": "Boris Chidlovskii", "title": "Multi-task learning of time series and its application to the travel\n  demand", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We address the problem of modeling and prediction of a set of temporal events\nin the context of intelligent transportation systems. To leverage the\ninformation shared by different events, we propose a multi-task learning\nframework. We develop a support vector regression model for joint learning of\nmutually dependent time series. It is the regularization-based multi-task\nlearning previously developed for the classification case and extended to time\nseries. We discuss the relatedness of observed time series and first deploy the\ndynamic time warping distance measure to identify groups of similar series.\nThen we take into account both time and scale warping and propose to align\nmultiple time series by inferring their common latent representation. We test\nthe proposed models on the problem of travel demand prediction in Nancy\n(France) public transport system and analyze the benefits of multi-task\nlearning.\n", "versions": [{"version": "v1", "created": "Thu, 21 Dec 2017 11:04:14 GMT"}], "update_date": "2017-12-25", "authors_parsed": [["Chidlovskii", "Boris", ""]]}, {"id": "1712.08197", "submitter": "Edward Raff", "authors": "Edward Raff, Jared Sylvester, Steven Mills", "title": "Fair Forests: Regularized Tree Induction to Minimize Model Bias", "comments": "To appear in the first AAAI / ACM conference on Artificial\n  Intelligence, Ethics, and Society (AIES) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The potential lack of fairness in the outputs of machine learning algorithms\nhas recently gained attention both within the research community as well as in\nsociety more broadly. Surprisingly, there is no prior work developing\ntree-induction algorithms for building fair decision trees or fair random\nforests. These methods have widespread popularity as they are one of the few to\nbe simultaneously interpretable, non-linear, and easy-to-use. In this paper we\ndevelop, to our knowledge, the first technique for the induction of fair\ndecision trees. We show that our \"Fair Forest\" retains the benefits of the\ntree-based approach, while providing both greater accuracy and fairness than\nother alternatives, for both \"group fairness\" and \"individual fairness.'\" We\nalso introduce new measures for fairness which are able to handle multinomial\nand continues attributes as well as regression problems, as opposed to binary\nattributes and labels only. Finally, we demonstrate a new, more robust\nevaluation procedure for algorithms that considers the dataset in its entirety\nrather than only a specific protected attribute.\n", "versions": [{"version": "v1", "created": "Thu, 21 Dec 2017 20:19:48 GMT"}], "update_date": "2017-12-25", "authors_parsed": [["Raff", "Edward", ""], ["Sylvester", "Jared", ""], ["Mills", "Steven", ""]]}, {"id": "1712.08230", "submitter": "Albin Severinson", "authors": "Albin Severinson, Alexandre Graell i Amat, Eirik Rosnes", "title": "Block-Diagonal and LT Codes for Distributed Computing With Straggling\n  Servers", "comments": "To appear in IEEE Transactions on Communications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DC cs.LG cs.PF math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose two coded schemes for the distributed computing problem of\nmultiplying a matrix by a set of vectors. The first scheme is based on\npartitioning the matrix into submatrices and applying maximum distance\nseparable (MDS) codes to each submatrix. For this scheme, we prove that up to a\ngiven number of partitions the communication load and the computational delay\n(not including the encoding and decoding delay) are identical to those of the\nscheme recently proposed by Li et al., based on a single, long MDS code.\nHowever, due to the use of shorter MDS codes, our scheme yields a significantly\nlower overall computational delay when the delay incurred by encoding and\ndecoding is also considered. We further propose a second coded scheme based on\nLuby Transform (LT) codes under inactivation decoding. Interestingly, LT codes\nmay reduce the delay over the partitioned scheme at the expense of an increased\ncommunication load. We also consider distributed computing under a deadline and\nshow numerically that the proposed schemes outperform other schemes in the\nliterature, with the LT code-based scheme yielding the best performance for the\nscenarios considered.\n", "versions": [{"version": "v1", "created": "Thu, 21 Dec 2017 22:02:25 GMT"}, {"version": "v2", "created": "Wed, 6 Jun 2018 14:17:50 GMT"}, {"version": "v3", "created": "Fri, 19 Oct 2018 10:00:57 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Severinson", "Albin", ""], ["Amat", "Alexandre Graell i", ""], ["Rosnes", "Eirik", ""]]}, {"id": "1712.08238", "submitter": "Karthik Dinakar", "authors": "Chelsea Barabas, Karthik Dinakar, Joichi Ito, Madars Virza, Jonathan\n  Zittrain", "title": "Interventions over Predictions: Reframing the Ethical Debate for\n  Actuarial Risk Assessment", "comments": "Accepted paper (not camera-ready version) of FATML 2018 conference,\n  Fairness, Accountability and Transparency in Machine Learning, 2018,\n  Proceedings of Machine Learning Research", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Actuarial risk assessments might be unduly perceived as a neutral way to\ncounteract implicit bias and increase the fairness of decisions made at almost\nevery juncture of the criminal justice system, from pretrial release to\nsentencing, parole and probation. In recent times these assessments have come\nunder increased scrutiny, as critics claim that the statistical techniques\nunderlying them might reproduce existing patterns of discrimination and\nhistorical biases that are reflected in the data. Much of this debate is\ncentered around competing notions of fairness and predictive accuracy, resting\non the contested use of variables that act as \"proxies\" for characteristics\nlegally protected against discrimination, such as race and gender. We argue\nthat a core ethical debate surrounding the use of regression in risk\nassessments is not simply one of bias or accuracy. Rather, it's one of purpose.\nIf machine learning is operationalized merely in the service of predicting\nindividual future crime, then it becomes difficult to break cycles of\ncriminalization that are driven by the iatrogenic effects of the criminal\njustice system itself. We posit that machine learning should not be used for\nprediction, but rather to surface covariates that are fed into a causal model\nfor understanding the social, structural and psychological drivers of crime. We\npropose an alternative application of machine learning and causal inference\naway from predicting risk scores to risk mitigation.\n", "versions": [{"version": "v1", "created": "Thu, 21 Dec 2017 22:27:39 GMT"}, {"version": "v2", "created": "Sat, 14 Jul 2018 20:52:15 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Barabas", "Chelsea", ""], ["Dinakar", "Karthik", ""], ["Ito", "Joichi", ""], ["Virza", "Madars", ""], ["Zittrain", "Jonathan", ""]]}, {"id": "1712.08244", "submitter": "Tengyuan Liang", "authors": "Tengyuan Liang", "title": "How Well Can Generative Adversarial Networks Learn Densities: A\n  Nonparametric View", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study in this paper the rate of convergence for learning densities under\nthe Generative Adversarial Networks (GAN) framework, borrowing insights from\nnonparametric statistics. We introduce an improved GAN estimator that achieves\na faster rate, through simultaneously leveraging the level of smoothness in the\ntarget density and the evaluation metric, which in theory remedies the mode\ncollapse problem reported in the literature. A minimax lower bound is\nconstructed to show that when the dimension is large, the exponent in the rate\nfor the new GAN estimator is near optimal. One can view our results as\nanswering in a quantitative way how well GAN learns a wide range of densities\nwith different smoothness properties, under a hierarchy of evaluation metrics.\nAs a byproduct, we also obtain improved generalization bounds for GAN with\ndeeper ReLU discriminator network.\n", "versions": [{"version": "v1", "created": "Thu, 21 Dec 2017 23:13:27 GMT"}, {"version": "v2", "created": "Fri, 16 Feb 2018 21:19:40 GMT"}], "update_date": "2018-02-20", "authors_parsed": [["Liang", "Tengyuan", ""]]}, {"id": "1712.08250", "submitter": "Jiefeng Chen", "authors": "Jiefeng Chen, Zihang Meng, Changtian Sun, Wei Tang, Yinglun Zhu", "title": "ReabsNet: Detecting and Revising Adversarial Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Though deep neural network has hit a huge success in recent studies and\napplica- tions, it still remains vulnerable to adversarial perturbations which\nare imperceptible to humans. To address this problem, we propose a novel\nnetwork called ReabsNet to achieve high classification accuracy in the face of\nvarious attacks. The approach is to augment an existing classification network\nwith a guardian network to detect if a sample is natural or has been\nadversarially perturbed. Critically, instead of simply rejecting adversarial\nexamples, we revise them to get their true labels. We exploit the observation\nthat a sample containing adversarial perturbations has a possibility of\nreturning to its true class after revision. We demonstrate that our ReabsNet\noutperforms the state-of-the-art defense method under various adversarial\nattacks.\n", "versions": [{"version": "v1", "created": "Thu, 21 Dec 2017 23:24:37 GMT"}], "update_date": "2017-12-25", "authors_parsed": [["Chen", "Jiefeng", ""], ["Meng", "Zihang", ""], ["Sun", "Changtian", ""], ["Tang", "Wei", ""], ["Zhu", "Yinglun", ""]]}, {"id": "1712.08259", "submitter": "Reza Bonyadi", "authors": "Mohammad Reza Bonyadi, Viktor Vegh, David C. Reutens", "title": "Linear centralization classifier", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A classification algorithm, called the Linear Centralization Classifier\n(LCC), is introduced. The algorithm seeks to find a transformation that best\nmaps instances from the feature space to a space where they concentrate towards\nthe center of their own classes, while maximimizing the distance between class\ncenters. We formulate the classifier as a quadratic program with quadratic\nconstraints. We then simplify this formulation to a linear program that can be\nsolved effectively using a linear programming solver (e.g., simplex-dual). We\nextend the formulation for LCC to enable the use of kernel functions for\nnon-linear classification applications. We compare our method with two standard\nclassification methods (support vector machine and linear discriminant\nanalysis) and four state-of-the-art classification methods when they are\napplied to eight standard classification datasets. Our experimental results\nshow that LCC is able to classify instances more accurately (based on the area\nunder the receiver operating characteristic) in comparison to other tested\nmethods on the chosen datasets. We also report the results for LCC with a\nparticular kernel to solve for synthetic non-linear classification problems.\n", "versions": [{"version": "v1", "created": "Fri, 22 Dec 2017 00:31:46 GMT"}], "update_date": "2017-12-25", "authors_parsed": [["Bonyadi", "Mohammad Reza", ""], ["Vegh", "Viktor", ""], ["Reutens", "David C.", ""]]}, {"id": "1712.08273", "submitter": "Shu Kong", "authors": "Shu Kong, Charless Fowlkes", "title": "Recurrent Pixel Embedding for Instance Grouping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a differentiable, end-to-end trainable framework for solving\npixel-level grouping problems such as instance segmentation consisting of two\nnovel components. First, we regress pixels into a hyper-spherical embedding\nspace so that pixels from the same group have high cosine similarity while\nthose from different groups have similarity below a specified margin. We\nanalyze the choice of embedding dimension and margin, relating them to\ntheoretical results on the problem of distributing points uniformly on the\nsphere. Second, to group instances, we utilize a variant of mean-shift\nclustering, implemented as a recurrent neural network parameterized by kernel\nbandwidth. This recurrent grouping module is differentiable, enjoys convergent\ndynamics and probabilistic interpretability. Backpropagating the group-weighted\nloss through this module allows learning to focus on only correcting embedding\nerrors that won't be resolved during subsequent clustering. Our framework,\nwhile conceptually simple and theoretically abundant, is also practically\neffective and computationally efficient. We demonstrate substantial\nimprovements over state-of-the-art instance segmentation for object proposal\ngeneration, as well as demonstrating the benefits of grouping loss for\nclassification tasks such as boundary detection and semantic segmentation.\n", "versions": [{"version": "v1", "created": "Fri, 22 Dec 2017 01:48:53 GMT"}], "update_date": "2017-12-25", "authors_parsed": [["Kong", "Shu", ""], ["Fowlkes", "Charless", ""]]}, {"id": "1712.08289", "submitter": "Kui Zhao", "authors": "Kui Zhao, Yuechuan Li, Zhaoqian Shuai, Cheng Yang", "title": "Learning and Transferring IDs Representation in E-commerce", "comments": "KDD'18, 9 pages", "journal-ref": null, "doi": "10.1145/3219819.3219855", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Many machine intelligence techniques are developed in E-commerce and one of\nthe most essential components is the representation of IDs, including user ID,\nitem ID, product ID, store ID, brand ID, category ID etc. The classical\nencoding based methods (like one-hot encoding) are inefficient in that it\nsuffers sparsity problems due to its high dimension, and it cannot reflect the\nrelationships among IDs, either homogeneous or heterogeneous ones. In this\npaper, we propose an embedding based framework to learn and transfer the\nrepresentation of IDs. As the implicit feedbacks of users, a tremendous amount\nof item ID sequences can be easily collected from the interactive sessions. By\njointly using these informative sequences and the structural connections among\nIDs, all types of IDs can be embedded into one low-dimensional semantic space.\nSubsequently, the learned representations are utilized and transferred in four\nscenarios: (i) measuring the similarity between items, (ii) transferring from\nseen items to unseen items, (iii) transferring across different domains, (iv)\ntransferring across different tasks. We deploy and evaluate the proposed\napproach in Hema App and the results validate its effectiveness.\n", "versions": [{"version": "v1", "created": "Fri, 22 Dec 2017 02:53:50 GMT"}, {"version": "v2", "created": "Tue, 27 Feb 2018 03:40:19 GMT"}, {"version": "v3", "created": "Mon, 7 May 2018 01:50:57 GMT"}, {"version": "v4", "created": "Tue, 22 May 2018 04:26:46 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Zhao", "Kui", ""], ["Li", "Yuechuan", ""], ["Shuai", "Zhaoqian", ""], ["Yang", "Cheng", ""]]}, {"id": "1712.08314", "submitter": "Ekaba Bisong", "authors": "Ekaba Bisong", "title": "Benchmarking Decoupled Neural Interfaces with Synthetic Gradients", "comments": "Serious issues with the content and not appropriate for high-level\n  academic distribution", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Artifical Neural Networks are a particular class of learning systems modeled\nafter biological neural functions with an interesting penchant for Hebbian\nlearning, that is \"neurons that wire together, fire together\". However, unlike\ntheir natural counterparts, artificial neural networks have a close and\nstringent coupling between the modules of neurons in the network. This coupling\nor locking imposes upon the network a strict and inflexible structure that\nprevent layers in the network from updating their weights until a full\nfeed-forward and backward pass has occurred. Such a constraint though may have\nsufficed for a while, is now no longer feasible in the era of very-large-scale\nmachine learning, coupled with the increased desire for parallelization of the\nlearning process across multiple computing infrastructures. To solve this\nproblem, synthetic gradients (SG) with decoupled neural interfaces (DNI) are\nintroduced as a viable alternative to the backpropagation algorithm. This paper\nperforms a speed benchmark to compare the speed and accuracy capabilities of\nSG-DNI as opposed to a standard neural interface using multilayer perceptron\nMLP. SG-DNI shows good promise, in that it not only captures the learning\nproblem, it is also over 3-fold faster due to it asynchronous learning\ncapabilities.\n", "versions": [{"version": "v1", "created": "Fri, 22 Dec 2017 06:28:28 GMT"}, {"version": "v2", "created": "Sat, 6 Jan 2018 23:16:33 GMT"}, {"version": "v3", "created": "Mon, 21 May 2018 14:06:52 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Bisong", "Ekaba", ""]]}, {"id": "1712.08443", "submitter": "Thibault Laugel", "authors": "Thibault Laugel, Marie-Jeanne Lesot, Christophe Marsala, Xavier\n  Renard, Marcin Detyniecki", "title": "Inverse Classification for Comparison-based Interpretability in Machine\n  Learning", "comments": "preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of post-hoc interpretability, this paper addresses the task of\nexplaining the prediction of a classifier, considering the case where no\ninformation is available, neither on the classifier itself, nor on the\nprocessed data (neither the training nor the test data). It proposes an\ninstance-based approach whose principle consists in determining the minimal\nchanges needed to alter a prediction: given a data point whose classification\nmust be explained, the proposed method consists in identifying a close\nneighbour classified differently, where the closeness definition integrates a\nsparsity constraint. This principle is implemented using observation generation\nin the Growing Spheres algorithm. Experimental results on two datasets\nillustrate the relevance of the proposed approach that can be used to gain\nknowledge about the classifier.\n", "versions": [{"version": "v1", "created": "Fri, 22 Dec 2017 13:51:21 GMT"}], "update_date": "2017-12-25", "authors_parsed": [["Laugel", "Thibault", ""], ["Lesot", "Marie-Jeanne", ""], ["Marsala", "Christophe", ""], ["Renard", "Xavier", ""], ["Detyniecki", "Marcin", ""]]}, {"id": "1712.08449", "submitter": "Yann Ollivier", "authors": "Yann Ollivier", "title": "True Asymptotic Natural Gradient Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a simple algorithm, True Asymptotic Natural Gradient\nOptimization (TANGO), that converges to a true natural gradient descent in the\nlimit of small learning rates, without explicit Fisher matrix estimation.\n  For quadratic models the algorithm is also an instance of averaged stochastic\ngradient, where the parameter is a moving average of a \"fast\", constant-rate\ngradient descent. TANGO appears as a particular de-linearization of averaged\nSGD, and is sometimes quite different on non-quadratic models. This further\nconnects averaged SGD and natural gradient, both of which are arguably optimal\nasymptotically.\n  In large dimension, small learning rates will be required to approximate the\nnatural gradient well. Still, this shows it is possible to get arbitrarily\nclose to exact natural gradient descent with a lightweight algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 22 Dec 2017 14:04:04 GMT"}], "update_date": "2017-12-25", "authors_parsed": [["Ollivier", "Yann", ""]]}, {"id": "1712.08493", "submitter": "Shounak Datta", "authors": "Shounak Datta, Sayak Nag, Sankha Subhra Mullick, Swagatam Das", "title": "Diversifying Support Vector Machines for Boosting using Kernel\n  Perturbation: Applications to Class Imbalance and Small Disjuncts", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The diversification (generating slightly varying separating discriminators)\nof Support Vector Machines (SVMs) for boosting has proven to be a challenge due\nto the strong learning nature of SVMs. Based on the insight that perturbing the\nSVM kernel may help in diversifying SVMs, we propose two kernel perturbation\nbased boosting schemes where the kernel is modified in each round so as to\nincrease the resolution of the kernel-induced Reimannian metric in the vicinity\nof the datapoints misclassified in the previous round. We propose a method for\nidentifying the disjuncts in a dataset, dispelling the dependence on rule-based\nlearning methods for identifying the disjuncts. We also present a new\nperformance measure called Geometric Small Disjunct Index (GSDI) to quantify\nthe performance on small disjuncts for balanced as well as class imbalanced\ndatasets. Experimental comparison with a variety of state-of-the-art algorithms\nis carried out using the best classifiers of each type selected by a new\napproach inspired by multi-criteria decision making. The proposed method is\nfound to outperform the contending state-of-the-art methods on different\ndatasets (ranging from mildly imbalanced to highly imbalanced and characterized\nby varying number of disjuncts) in terms of three different performance indices\n(including the proposed GSDI).\n", "versions": [{"version": "v1", "created": "Fri, 22 Dec 2017 15:09:16 GMT"}], "update_date": "2017-12-25", "authors_parsed": [["Datta", "Shounak", ""], ["Nag", "Sayak", ""], ["Mullick", "Sankha Subhra", ""], ["Das", "Swagatam", ""]]}, {"id": "1712.08523", "submitter": "Brian Spears", "authors": "Brian K. Spears", "title": "Contemporary machine learning: a guide for practitioners in the physical\n  sciences", "comments": "29 pages, 16 figures", "journal-ref": null, "doi": "10.1063/1.5020791", "report-no": null, "categories": "physics.comp-ph cs.LG math-ph math.MP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning is finding increasingly broad application in the physical\nsciences. This most often involves building a model relationship between a\ndependent, measurable output and an associated set of controllable, but\ncomplicated, independent inputs. We present a tutorial on current techniques in\nmachine learning -- a jumping-off point for interested researchers to advance\ntheir work. We focus on deep neural networks with an emphasis on demystifying\ndeep learning. We begin with background ideas in machine learning and some\nexample applications from current research in plasma physics. We discuss\nsupervised learning techniques for modeling complicated functions, beginning\nwith familiar regression schemes, then advancing to more sophisticated deep\nlearning methods. We also address unsupervised learning and techniques for\nreducing the dimensionality of input spaces. Along the way, we describe methods\nfor practitioners to help ensure that their models generalize from their\ntraining data to as-yet-unseen test data. We describe classes of tasks --\npredicting scalars, handling images, fitting time-series -- and prepare the\nreader to choose an appropriate technique. We finally point out some\nlimitations to modern machine learning and speculate on some ways that\npractitioners from the physical sciences may be particularly suited to help.\n", "versions": [{"version": "v1", "created": "Wed, 20 Dec 2017 23:28:03 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Spears", "Brian K.", ""]]}, {"id": "1712.08577", "submitter": "R\\'emi Le Priol", "authors": "R\\'emi Le Priol, Alexandre Pich\\'e and Simon Lacoste-Julien", "title": "Adaptive Stochastic Dual Coordinate Ascent for Conditional Random Fields", "comments": "Published as a conference paper at UAI 2018. 22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work investigates the training of conditional random fields (CRFs) via\nthe stochastic dual coordinate ascent (SDCA) algorithm of Shalev-Shwartz and\nZhang (2016). SDCA enjoys a linear convergence rate and a strong empirical\nperformance for binary classification problems. However, it has never been used\nto train CRFs. Yet it benefits from an `exact' line search with a single\nmarginalization oracle call, unlike previous approaches. In this paper, we\nadapt SDCA to train CRFs, and we enhance it with an adaptive non-uniform\nsampling strategy based on block duality gaps. We perform experiments on four\nstandard sequence prediction tasks. SDCA demonstrates performances on par with\nthe state of the art, and improves over it on three of the four datasets, which\nhave in common the use of sparse features.\n", "versions": [{"version": "v1", "created": "Fri, 22 Dec 2017 17:05:24 GMT"}, {"version": "v2", "created": "Tue, 10 Jul 2018 00:19:07 GMT"}], "update_date": "2018-07-11", "authors_parsed": [["Priol", "R\u00e9mi Le", ""], ["Pich\u00e9", "Alexandre", ""], ["Lacoste-Julien", "Simon", ""]]}, {"id": "1712.08597", "submitter": "Ruitu Xu", "authors": "Chen Li, Luca Venturi, Ruitu Xu", "title": "Learning the Kernel for Classification and Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate a series of learning kernel problems with polynomial\ncombinations of base kernels, which will help us solve regression and\nclassification problems. We also perform some numerical experiments of\npolynomial kernels with regression and classification tasks on different\ndatasets.\n", "versions": [{"version": "v1", "created": "Fri, 22 Dec 2017 17:55:28 GMT"}, {"version": "v2", "created": "Mon, 25 Dec 2017 01:34:19 GMT"}], "update_date": "2017-12-27", "authors_parsed": [["Li", "Chen", ""], ["Venturi", "Luca", ""], ["Xu", "Ruitu", ""]]}, {"id": "1712.08608", "submitter": "Peter Sadowski", "authors": "Pierre Baldi, Peter Sadowski, Zhiqin Lu", "title": "Learning in the Machine: the Symmetries of the Deep Learning Channel", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a physical neural system, learning rules must be local both in space and\ntime. In order for learning to occur, non-local information must be\ncommunicated to the deep synapses through a communication channel, the deep\nlearning channel. We identify several possible architectures for this learning\nchannel (Bidirectional, Conjoined, Twin, Distinct) and six symmetry challenges:\n1) symmetry of architectures; 2) symmetry of weights; 3) symmetry of neurons;\n4) symmetry of derivatives; 5) symmetry of processing; and 6) symmetry of\nlearning rules. Random backpropagation (RBP) addresses the second and third\nsymmetry, and some of its variations, such as skipped RBP (SRBP) address the\nfirst and the fourth symmetry. Here we address the last two desirable\nsymmetries showing through simulations that they can be achieved and that the\nlearning channel is particularly robust to symmetry variations. Specifically,\nrandom backpropagation and its variations can be performed with the same\nnon-linear neurons used in the main input-output forward channel, and the\nconnections in the learning channel can be adapted using the same algorithm\nused in the forward channel, removing the need for any specialized hardware in\nthe learning channel. Finally, we provide mathematical results in simple cases\nshowing that the learning equations in the forward and backward channels\nconverge to fixed points, for almost any initial conditions. In symmetric\narchitectures, if the weights in both channels are small at initialization,\nadaptation in both channels leads to weights that are essentially symmetric\nduring and after learning. Biological connections are discussed.\n", "versions": [{"version": "v1", "created": "Fri, 22 Dec 2017 18:43:58 GMT"}], "update_date": "2017-12-25", "authors_parsed": [["Baldi", "Pierre", ""], ["Sadowski", "Peter", ""], ["Lu", "Zhiqin", ""]]}, {"id": "1712.08626", "submitter": "Fattaneh Jabbari", "authors": "Fattaneh Jabbari, Mahdi Pakdaman Naeini, Gregory F. Cooper", "title": "Obtaining Accurate Probabilistic Causal Inference by Post-Processing\n  Calibration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discovery of an accurate causal Bayesian network structure from observational\ndata can be useful in many areas of science. Often the discoveries are made\nunder uncertainty, which can be expressed as probabilities. To guide the use of\nsuch discoveries, including directing further investigation, it is important\nthat those probabilities be well-calibrated. In this paper, we introduce a\nnovel framework to derive calibrated probabilities of causal relationships from\nobservational data. The framework consists of three components: (1) an\napproximate method for generating initial probability estimates of the edge\ntypes for each pair of variables, (2) the availability of a relatively small\nnumber of the causal relationships in the network for which the truth status is\nknown, which we call a calibration training set, and (3) a calibration method\nfor using the approximate probability estimates and the calibration training\nset to generate calibrated probabilities for the many remaining pairs of\nvariables. We also introduce a new calibration method based on a shallow neural\nnetwork. Our experiments on simulated data support that the proposed approach\nimproves the calibration of causal edge predictions. The results also support\nthat the approach often improves the precision and recall of predictions.\n", "versions": [{"version": "v1", "created": "Fri, 22 Dec 2017 19:15:15 GMT"}], "update_date": "2017-12-27", "authors_parsed": [["Jabbari", "Fattaneh", ""], ["Naeini", "Mahdi Pakdaman", ""], ["Cooper", "Gregory F.", ""]]}, {"id": "1712.08642", "submitter": "Stephen Tu", "authors": "Stephen Tu and Benjamin Recht", "title": "Least-Squares Temporal Difference Learning for the Linear Quadratic\n  Regulator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) has been successfully used to solve many\ncontinuous control tasks. Despite its impressive results however, fundamental\nquestions regarding the sample complexity of RL on continuous problems remain\nopen. We study the performance of RL in this setting by considering the\nbehavior of the Least-Squares Temporal Difference (LSTD) estimator on the\nclassic Linear Quadratic Regulator (LQR) problem from optimal control. We give\nthe first finite-time analysis of the number of samples needed to estimate the\nvalue function for a fixed static state-feedback policy to within\n$\\varepsilon$-relative error. In the process of deriving our result, we give a\ngeneral characterization for when the minimum eigenvalue of the empirical\ncovariance matrix formed along the sample path of a fast-mixing stochastic\nprocess concentrates above zero, extending a result by Koltchinskii and\nMendelson in the independent covariates setting. Finally, we provide\nexperimental evidence indicating that our analysis correctly captures the\nqualitative behavior of LSTD on several LQR instances.\n", "versions": [{"version": "v1", "created": "Fri, 22 Dec 2017 20:12:07 GMT"}], "update_date": "2017-12-27", "authors_parsed": [["Tu", "Stephen", ""], ["Recht", "Benjamin", ""]]}, {"id": "1712.08645", "submitter": "Chun-Hao Chang", "authors": "Chun-Hao Chang, Ladislav Rampasek, Anna Goldenberg", "title": "Dropout Feature Ranking for Deep Learning Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) achieve state-of-the-art results in a variety of\ndomains. Unfortunately, DNNs are notorious for their non-interpretability, and\nthus limit their applicability in hypothesis-driven domains such as biology and\nhealthcare. Moreover, in the resource-constraint setting, it is critical to\ndesign tests relying on fewer more informative features leading to high\naccuracy performance within reasonable budget. We aim to close this gap by\nproposing a new general feature ranking method for deep learning. We show that\nour simple yet effective method performs on par or compares favorably to eight\nstrawman, classical and deep-learning feature ranking methods in two\nsimulations and five very different datasets on tasks ranging from\nclassification to regression, in both static and time series scenarios. We also\nillustrate the use of our method on a drug response dataset and show that it\nidentifies genes relevant to the drug-response.\n", "versions": [{"version": "v1", "created": "Fri, 22 Dec 2017 20:25:31 GMT"}, {"version": "v2", "created": "Fri, 9 Mar 2018 16:36:04 GMT"}], "update_date": "2018-03-12", "authors_parsed": [["Chang", "Chun-Hao", ""], ["Rampasek", "Ladislav", ""], ["Goldenberg", "Anna", ""]]}, {"id": "1712.08650", "submitter": "Pierre Richemond", "authors": "Pierre H. Richemond, Brendan Maginnis", "title": "A short variational proof of equivalence between policy gradients and\n  soft Q learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two main families of reinforcement learning algorithms, Q-learning and policy\ngradients, have recently been proven to be equivalent when using a softmax\nrelaxation on one part, and an entropic regularization on the other. We relate\nthis result to the well-known convex duality of Shannon entropy and the softmax\nfunction. Such a result is also known as the Donsker-Varadhan formula. This\nprovides a short proof of the equivalence. We then interpret this duality\nfurther, and use ideas of convex analysis to prove a new policy inequality\nrelative to soft Q-learning.\n", "versions": [{"version": "v1", "created": "Fri, 22 Dec 2017 20:37:16 GMT"}], "update_date": "2017-12-27", "authors_parsed": [["Richemond", "Pierre H.", ""], ["Maginnis", "Brendan", ""]]}, {"id": "1712.08708", "submitter": "Siddique Latif", "authors": "Siddique Latif, Rajib Rana, Junaid Qadir, Julien Epps", "title": "Variational Autoencoders for Learning Latent Representations of Speech\n  Emotion: A Preliminary Study", "comments": "Proc. Interspeech 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning the latent representation of data in unsupervised fashion is a very\ninteresting process that provides relevant features for enhancing the\nperformance of a classifier. For speech emotion recognition tasks, generating\neffective features is crucial. Currently, handcrafted features are mostly used\nfor speech emotion recognition, however, features learned automatically using\ndeep learning have shown strong success in many problems, especially in image\nprocessing. In particular, deep generative models such as Variational\nAutoencoders (VAEs) have gained enormous success for generating features for\nnatural images. Inspired by this, we propose VAEs for deriving the latent\nrepresentation of speech signals and use this representation to classify\nemotions. To the best of our knowledge, we are the first to propose VAEs for\nspeech emotion classification. Evaluations on the IEMOCAP dataset demonstrate\nthat features learned by VAEs can produce state-of-the-art results for speech\nemotion classification.\n", "versions": [{"version": "v1", "created": "Sat, 23 Dec 2017 03:54:00 GMT"}, {"version": "v2", "created": "Mon, 26 Mar 2018 07:47:54 GMT"}, {"version": "v3", "created": "Tue, 28 Jul 2020 01:35:27 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Latif", "Siddique", ""], ["Rana", "Rajib", ""], ["Qadir", "Junaid", ""], ["Epps", "Julien", ""]]}, {"id": "1712.08713", "submitter": "Fnu Suya", "authors": "Fnu Suya, Yuan Tian, David Evans, Paolo Papotti", "title": "Query-limited Black-box Attacks to Classifiers", "comments": "5 Pages, 2017 NIPS workshop on machine learning and computer security\n  (12/08/2017-12/09/2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study black-box attacks on machine learning classifiers where each query\nto the model incurs some cost or risk of detection to the adversary. We focus\nexplicitly on minimizing the number of queries as a major objective.\nSpecifically, we consider the problem of attacking machine learning classifiers\nsubject to a budget of feature modification cost while minimizing the number of\nqueries, where each query returns only a class and confidence score. We\ndescribe an approach that uses Bayesian optimization to minimize the number of\nqueries, and find that the number of queries can be reduced to approximately\none tenth of the number needed through a random strategy for scenarios where\nthe feature modification cost budget is low.\n", "versions": [{"version": "v1", "created": "Sat, 23 Dec 2017 04:40:47 GMT"}], "update_date": "2017-12-27", "authors_parsed": [["Suya", "Fnu", ""], ["Tian", "Yuan", ""], ["Evans", "David", ""], ["Papotti", "Paolo", ""]]}, {"id": "1712.08734", "submitter": "San Gultekin", "authors": "San Gultekin and John Paisley", "title": "Online Forecasting Matrix Factorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper the problem of forecasting high dimensional time series is\nconsidered. Such time series can be modeled as matrices where each column\ndenotes a measurement. In addition, when missing values are present, low rank\nmatrix factorization approaches are suitable for predicting future values. This\npaper formally defines and analyzes the forecasting problem in the online\nsetting, i.e. where the data arrives as a stream and only a single pass is\nallowed. We present and analyze novel matrix factorization techniques which can\nlearn low-dimensional embeddings effectively in an online manner. Based on\nthese embeddings a recursive minimum mean square error estimator is derived,\nwhich learns an autoregressive model on them. Experiments with two real\ndatasets with tens of millions of measurements show the benefits of the\nproposed approach.\n", "versions": [{"version": "v1", "created": "Sat, 23 Dec 2017 08:22:44 GMT"}], "update_date": "2017-12-27", "authors_parsed": [["Gultekin", "San", ""], ["Paisley", "John", ""]]}, {"id": "1712.08773", "submitter": "Gabriel Terejanu", "authors": "Chao Chen, Xiao Lin, Gabriel Terejanu", "title": "An Approximate Bayesian Long Short-Term Memory Algorithm for Outlier\n  Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Long Short-Term Memory networks trained with gradient descent and\nback-propagation have received great success in various applications. However,\npoint estimation of the weights of the networks is prone to over-fitting\nproblems and lacks important uncertainty information associated with the\nestimation. However, exact Bayesian neural network methods are intractable and\nnon-applicable for real-world applications. In this study, we propose an\napproximate estimation of the weights uncertainty using Ensemble Kalman Filter,\nwhich is easily scalable to a large number of weights. Furthermore, we optimize\nthe covariance of the noise distribution in the ensemble update step using\nmaximum likelihood estimation. To assess the proposed algorithm, we apply it to\noutlier detection in five real-world events retrieved from the Twitter\nplatform.\n", "versions": [{"version": "v1", "created": "Sat, 23 Dec 2017 13:23:26 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 02:11:33 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Chen", "Chao", ""], ["Lin", "Xiao", ""], ["Terejanu", "Gabriel", ""]]}, {"id": "1712.08855", "submitter": "Aubrey Gress", "authors": "Aubrey Gress and Ian Davidson", "title": "Transfer Regression via Pairwise Similarity Regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning methods address the situation where little labeled training\ndata from the \"target\" problem exists, but much training data from a related\n\"source\" domain is available. However, the overwhelming majority of transfer\nlearning methods are designed for simple settings where the source and target\npredictive functions are almost identical, limiting the applicability of\ntransfer learning methods to real world data. We propose a novel, weaker,\nproperty of the source domain that can be transferred even when the source and\ntarget predictive functions diverge. Our method assumes the source and target\nfunctions share a Pairwise Similarity property, where if the source function\nmakes similar predictions on a pair of instances, then so will the target\nfunction. We propose Pairwise Similarity Regularization Transfer, a flexible\ngraph-based regularization framework which can incorporate this modeling\nassumption into standard supervised learning algorithms. We show how users can\nencode domain knowledge into our regularizer in the form of spatial continuity,\npairwise \"similarity constraints\" and how our method can be scaled to large\ndata sets using the Nystrom approximation. Finally, we present positive and\nnegative results on real and synthetic data sets and discuss when our Pairwise\nSimilarity transfer assumption seems to hold in practice.\n", "versions": [{"version": "v1", "created": "Sat, 23 Dec 2017 23:14:03 GMT"}], "update_date": "2017-12-27", "authors_parsed": [["Gress", "Aubrey", ""], ["Davidson", "Ian", ""]]}, {"id": "1712.08862", "submitter": "Shiliang Sun", "authors": "Feng Jin, Shiliang Sun", "title": "Neural Network Multitask Learning for Traffic Flow Forecasting", "comments": null, "journal-ref": "Proceedings of the International Joint Conference on Neural\n  Networks (IJCNN), 2008. pp. 1898-1902", "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional neural network approaches for traffic flow forecasting are\nusually single task learning (STL) models, which do not take advantage of the\ninformation provided by related tasks. In contrast to STL, multitask learning\n(MTL) has the potential to improve generalization by transferring information\nin training signals of extra tasks. In this paper, MTL based neural networks\nare used for traffic flow forecasting. For neural network MTL, a\nbackpropagation (BP) network is constructed by incorporating traffic flows at\nseveral contiguous time instants into an output layer. Nodes in the output\nlayer can be seen as outputs of different but closely related STL tasks.\nComprehensive experiments on urban vehicular traffic flow data and comparisons\nwith STL show that MTL in BP neural networks is a promising and effective\napproach for traffic flow forecasting.\n", "versions": [{"version": "v1", "created": "Sun, 24 Dec 2017 00:27:09 GMT"}], "update_date": "2017-12-27", "authors_parsed": [["Jin", "Feng", ""], ["Sun", "Shiliang", ""]]}, {"id": "1712.08885", "submitter": "Shiliang Sun", "authors": "Qingjiu Zhang, Shiliang Sun", "title": "Weighted Data Normalization Based on Eigenvalues for Artificial Neural\n  Network Classification", "comments": null, "journal-ref": "The 16th International Conference on Neural Information Processing\n  (ICONIP), Lecture Notes in Computer Science, 2009, 5863: 349-356", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial neural network (ANN) is a very useful tool in solving learning\nproblems. Boosting the performances of ANN can be mainly concluded from two\naspects: optimizing the architecture of ANN and normalizing the raw data for\nANN. In this paper, a novel method which improves the effects of ANN by\npreprocessing the raw data is proposed. It totally leverages the fact that\ndifferent features should play different roles. The raw data set is firstly\npreprocessed by principle component analysis (PCA), and then its principle\ncomponents are weighted by their corresponding eigenvalues. Several aspects of\nanalysis are carried out to analyze its theory and the applicable occasions.\nThree classification problems are launched by an active learning algorithm to\nverify the proposed method. From the empirical results, conclusion comes to the\nfact that the proposed method can significantly improve the performance of ANN.\n", "versions": [{"version": "v1", "created": "Sun, 24 Dec 2017 07:47:13 GMT"}], "update_date": "2017-12-27", "authors_parsed": [["Zhang", "Qingjiu", ""], ["Sun", "Shiliang", ""]]}, {"id": "1712.08914", "submitter": "Ahmed Alaa", "authors": "Ahmed M. Alaa and Mihaela van der Schaar", "title": "Bayesian Nonparametric Causal Inference: Information Rates and Learning\n  Algorithms", "comments": null, "journal-ref": null, "doi": "10.1109/JSTSP.2018.2848230", "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem of estimating the causal effect of a treatment on\nindividual subjects from observational data, this is a central problem in\nvarious application domains, including healthcare, social sciences, and online\nadvertising. Within the Neyman Rubin potential outcomes model, we use the\nKullback Leibler (KL) divergence between the estimated and true distributions\nas a measure of accuracy of the estimate, and we define the information rate of\nthe Bayesian causal inference procedure as the (asymptotic equivalence class of\nthe) expected value of the KL divergence between the estimated and true\ndistributions as a function of the number of samples. Using Fano method, we\nestablish a fundamental limit on the information rate that can be achieved by\nany Bayesian estimator, and show that this fundamental limit is independent of\nthe selection bias in the observational data. We characterize the Bayesian\npriors on the potential (factual and counterfactual) outcomes that achieve the\noptimal information rate. As a consequence, we show that a particular class of\npriors that have been widely used in the causal inference literature cannot\nachieve the optimal information rate. On the other hand, a broader class of\npriors can achieve the optimal information rate. We go on to propose a prior\nadaptation procedure (which we call the information based empirical Bayes\nprocedure) that optimizes the Bayesian prior by maximizing an information\ntheoretic criterion on the recovered causal effects rather than maximizing the\nmarginal likelihood of the observed (factual) data. Building on our analysis,\nwe construct an information optimal Bayesian causal inference algorithm.\n", "versions": [{"version": "v1", "created": "Sun, 24 Dec 2017 12:36:23 GMT"}, {"version": "v2", "created": "Sun, 21 Jan 2018 23:16:54 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Alaa", "Ahmed M.", ""], ["van der Schaar", "Mihaela", ""]]}, {"id": "1712.08968", "submitter": "Itay Safran", "authors": "Itay Safran, Ohad Shamir", "title": "Spurious Local Minima are Common in Two-Layer ReLU Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the optimization problem associated with training simple ReLU\nneural networks of the form $\\mathbf{x}\\mapsto\n\\sum_{i=1}^{k}\\max\\{0,\\mathbf{w}_i^\\top \\mathbf{x}\\}$ with respect to the\nsquared loss. We provide a computer-assisted proof that even if the input\ndistribution is standard Gaussian, even if the dimension is arbitrarily large,\nand even if the target values are generated by such a network, with orthonormal\nparameter vectors, the problem can still have spurious local minima once $6\\le\nk\\le 20$. By a concentration of measure argument, this implies that in high\ninput dimensions, \\emph{nearly all} target networks of the relevant sizes lead\nto spurious local minima. Moreover, we conduct experiments which show that the\nprobability of hitting such local minima is quite high, and increasing with the\nnetwork size. On the positive side, mild over-parameterization appears to\ndrastically reduce such local minima, indicating that an over-parameterization\nassumption is necessary to get a positive result in this setting.\n", "versions": [{"version": "v1", "created": "Sun, 24 Dec 2017 21:00:10 GMT"}, {"version": "v2", "created": "Thu, 28 Dec 2017 16:16:48 GMT"}, {"version": "v3", "created": "Thu, 9 Aug 2018 14:17:45 GMT"}], "update_date": "2018-08-10", "authors_parsed": [["Safran", "Itay", ""], ["Shamir", "Ohad", ""]]}, {"id": "1712.08969", "submitter": "Greg Yang", "authors": "Greg Yang, Samuel S. Schoenholz", "title": "Mean Field Residual Networks: On the Edge of Chaos", "comments": "NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cond-mat.dis-nn cs.LG math.DS nlin.CD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study randomly initialized residual networks using mean field theory and\nthe theory of difference equations. Classical feedforward neural networks, such\nas those with tanh activations, exhibit exponential behavior on the average\nwhen propagating inputs forward or gradients backward. The exponential forward\ndynamics causes rapid collapsing of the input space geometry, while the\nexponential backward dynamics causes drastic vanishing or exploding gradients.\nWe show, in contrast, that by adding skip connections, the network will,\ndepending on the nonlinearity, adopt subexponential forward and backward\ndynamics, and in many cases in fact polynomial. The exponents of these\npolynomials are obtained through analytic methods and proved and verified\nempirically to be correct. In terms of the \"edge of chaos\" hypothesis, these\nsubexponential and polynomial laws allow residual networks to \"hover over the\nboundary between stability and chaos,\" thus preserving the geometry of the\ninput space and the gradient information flow. In our experiments, for each\nactivation function we study here, we initialize residual networks with\ndifferent hyperparameters and train them on MNIST. Remarkably, our\ninitialization time theory can accurately predict test time performance of\nthese networks, by tracking either the expected amount of gradient explosion or\nthe expected squared distance between the images of two input vectors.\nImportantly, we show, theoretically as well as empirically, that common\ninitializations such as the Xavier or the He schemes are not optimal for\nresidual networks, because the optimal initialization variances depend on the\ndepth. Finally, we have made mathematical contributions by deriving several new\nidentities for the kernels of powers of ReLU functions by relating them to the\nzeroth Bessel function of the second kind.\n", "versions": [{"version": "v1", "created": "Sun, 24 Dec 2017 21:51:08 GMT"}], "update_date": "2017-12-27", "authors_parsed": [["Yang", "Greg", ""], ["Schoenholz", "Samuel S.", ""]]}, {"id": "1712.08987", "submitter": "Zhewei Huang", "authors": "Zhewei Huang, Shuchang Zhou, BoEr Zhuang, Xinyu Zhou", "title": "Learning to Run with Actor-Critic Ensemble", "comments": "3 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an Actor-Critic Ensemble(ACE) method for improving the\nperformance of Deep Deterministic Policy Gradient(DDPG) algorithm. At inference\ntime, our method uses a critic ensemble to select the best action from\nproposals of multiple actors running in parallel. By having a larger candidate\nset, our method can avoid actions that have fatal consequences, while staying\ndeterministic. Using ACE, we have won the 2nd place in NIPS'17 Learning to Run\ncompetition, under the name of \"Megvii-hzwer\".\n", "versions": [{"version": "v1", "created": "Mon, 25 Dec 2017 02:03:12 GMT"}], "update_date": "2017-12-29", "authors_parsed": [["Huang", "Zhewei", ""], ["Zhou", "Shuchang", ""], ["Zhuang", "BoEr", ""], ["Zhou", "Xinyu", ""]]}, {"id": "1712.08992", "submitter": "Aditya Siddhant", "authors": "Aditya Siddhant, Preethi Jyothi, Sriram Ganapathy", "title": "Leveraging Native Language Speech for Accent Identification using Deep\n  Siamese Networks", "comments": "Published in ASRU 2017", "journal-ref": null, "doi": "10.1109/ASRU.2017.8268994", "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of automatic accent identification is important for several\napplications like speaker profiling and recognition as well as for improving\nspeech recognition systems. The accented nature of speech can be primarily\nattributed to the influence of the speaker's native language on the given\nspeech recording. In this paper, we propose a novel accent identification\nsystem whose training exploits speech in native languages along with the\naccented speech. Specifically, we develop a deep Siamese network-based model\nwhich learns the association between accented speech recordings and the native\nlanguage speech recordings. The Siamese networks are trained with i-vector\nfeatures extracted from the speech recordings using either an unsupervised\nGaussian mixture model (GMM) or a supervised deep neural network (DNN) model.\nWe perform several accent identification experiments using the CSLU Foreign\nAccented English (FAE) corpus. In these experiments, our proposed approach\nusing deep Siamese networks yield significant relative performance improvements\nof 15.4 percent on a 10-class accent identification task, over a baseline\nDNN-based classification system that uses GMM i-vectors. Furthermore, we\npresent a detailed error analysis of the proposed accent identification system.\n", "versions": [{"version": "v1", "created": "Mon, 25 Dec 2017 02:28:32 GMT"}, {"version": "v2", "created": "Mon, 18 Jun 2018 21:48:58 GMT"}], "update_date": "2018-06-20", "authors_parsed": [["Siddhant", "Aditya", ""], ["Jyothi", "Preethi", ""], ["Ganapathy", "Sriram", ""]]}, {"id": "1712.09001", "submitter": "Shiliang Sun", "authors": "Rongqing Huang, Shiliang Sun", "title": "Kernel Regression with Sparse Metric Learning", "comments": null, "journal-ref": "Journal of Intelligent and Fuzzy Systems, 2013, 24(4): 775-787", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernel regression is a popular non-parametric fitting technique. It aims at\nlearning a function which estimates the targets for test inputs as precise as\npossible. Generally, the function value for a test input is estimated by a\nweighted average of the surrounding training examples. The weights are\ntypically computed by a distance-based kernel function and they strongly depend\non the distances between examples. In this paper, we first review the latest\ndevelopments of sparse metric learning and kernel regression. Then a novel\nkernel regression method involving sparse metric learning, which is called\nkernel regression with sparse metric learning (KR$\\_$SML), is proposed. The\nsparse kernel regression model is established by enforcing a mixed $(2,1)$-norm\nregularization over the metric matrix. It learns a Mahalanobis distance metric\nby a gradient descent procedure, which can simultaneously conduct\ndimensionality reduction and lead to good prediction results. Our work is the\nfirst to combine kernel regression with sparse metric learning. To verify the\neffectiveness of the proposed method, it is evaluated on 19 data sets for\nregression. Furthermore, the new method is also applied to solving practical\nproblems of forecasting short-term traffic flows. In the end, we compare the\nproposed method with other three related kernel regression methods on all test\ndata sets under two criterions. Experimental results show that the proposed\nmethod is much more competitive.\n", "versions": [{"version": "v1", "created": "Mon, 25 Dec 2017 04:00:23 GMT"}], "update_date": "2017-12-27", "authors_parsed": [["Huang", "Rongqing", ""], ["Sun", "Shiliang", ""]]}, {"id": "1712.09005", "submitter": "George Linderman", "authors": "George C. Linderman, Manas Rachh, Jeremy G. Hoskins, Stefan\n  Steinerberger, Yuval Kluger", "title": "Efficient Algorithms for t-distributed Stochastic Neighborhood Embedding", "comments": null, "journal-ref": null, "doi": "10.1038/s41592-018-0308-4", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  t-distributed Stochastic Neighborhood Embedding (t-SNE) is a method for\ndimensionality reduction and visualization that has become widely popular in\nrecent years. Efficient implementations of t-SNE are available, but they scale\npoorly to datasets with hundreds of thousands to millions of high dimensional\ndata-points. We present Fast Fourier Transform-accelerated Interpolation-based\nt-SNE (FIt-SNE), which dramatically accelerates the computation of t-SNE. The\nmost time-consuming step of t-SNE is a convolution that we accelerate by\ninterpolating onto an equispaced grid and subsequently using the fast Fourier\ntransform to perform the convolution. We also optimize the computation of input\nsimilarities in high dimensions using multi-threaded approximate nearest\nneighbors. We further present a modification to t-SNE called \"late\nexaggeration,\" which allows for easier identification of clusters in t-SNE\nembeddings. Finally, for datasets that cannot be loaded into the memory, we\npresent out-of-core randomized principal component analysis (oocPCA), so that\nthe top principal components of a dataset can be computed without ever fully\nloading the matrix, hence allowing for t-SNE of large datasets to be computed\non resource-limited machines.\n", "versions": [{"version": "v1", "created": "Mon, 25 Dec 2017 04:51:25 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Linderman", "George C.", ""], ["Rachh", "Manas", ""], ["Hoskins", "Jeremy G.", ""], ["Steinerberger", "Stefan", ""], ["Kluger", "Yuval", ""]]}, {"id": "1712.09007", "submitter": "Ger Yang", "authors": "David Liau, Eric Price, Zhao Song, Ger Yang", "title": "Stochastic Multi-armed Bandits in Constant Space", "comments": "AISTATS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the stochastic bandit problem in the sublinear space setting,\nwhere one cannot record the win-loss record for all $K$ arms. We give an\nalgorithm using $O(1)$ words of space with regret \\[\n  \\sum_{i=1}^{K}\\frac{1}{\\Delta_i}\\log \\frac{\\Delta_i}{\\Delta}\\log T \\] where\n$\\Delta_i$ is the gap between the best arm and arm $i$ and $\\Delta$ is the gap\nbetween the best and the second-best arms. If the rewards are bounded away from\n$0$ and $1$, this is within an $O(\\log 1/\\Delta)$ factor of the optimum regret\npossible without space constraints.\n", "versions": [{"version": "v1", "created": "Mon, 25 Dec 2017 05:04:35 GMT"}, {"version": "v2", "created": "Wed, 16 May 2018 17:06:53 GMT"}], "update_date": "2018-05-17", "authors_parsed": [["Liau", "David", ""], ["Price", "Eric", ""], ["Song", "Zhao", ""], ["Yang", "Ger", ""]]}, {"id": "1712.09014", "submitter": "Michael Gagen Dr", "authors": "M. J. Gagen", "title": "Null Dynamical State Models of Human Cognitive Dysfunction", "comments": "17 pages, 0 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The hard problem in artificial intelligence asks how the shuffling of\nsyntactical symbols in a program can lead to systems which experience semantics\nand qualia. We address this question in three stages. First, we introduce a new\nclass of human semantic symbols which appears when unexpected and drastic\nenvironmental change causes humans to become surprised, confused, uncertain,\nand in extreme cases, unresponsive, passive and dysfunctional. For this class\nof symbols, pre-learned programs become inoperative so these syntactical\nprograms cannot be the source of experienced qualia. Second, we model the\ndysfunctional human response to a radically changed environment as being the\nnatural response of any learning machine facing novel inputs from well outside\nits previous training set. In this situation, learning machines are unable to\nextract information from their input and will typically enter a dynamical state\ncharacterized by null outputs and a lack of response. This state immediately\npredicts and explains the characteristics of the semantic experiences of humans\nin similar circumstances. In the third stage, we consider learning machines\ntrained to implement multiple functions in simple sequential programs using\nenvironmental data to specify subroutine names, control flow instructions,\nmemory calls, and so on. Drastic change in any of these environmental inputs\ncan again lead to inoperative programs. By examining changes specific to people\nor locations we can model human cognitive symbols featuring these dependencies,\nsuch as attachment and grief. Our approach links known dynamical machines\nstates with human qualia and thus offers new insight into the hard problem of\nartificial intelligence.\n", "versions": [{"version": "v1", "created": "Mon, 25 Dec 2017 05:46:19 GMT"}], "update_date": "2017-12-27", "authors_parsed": [["Gagen", "M. J.", ""]]}, {"id": "1712.09043", "submitter": "Qibing Li", "authors": "Qibing Li, Xiaolin Zheng and Xinyue Wu", "title": "Neural Collaborative Autoencoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, deep neural networks have yielded state-of-the-art\nperformance on several tasks. Although some recent works have focused on\ncombining deep learning with recommendation, we highlight three issues of\nexisting models. First, these models cannot work on both explicit and implicit\nfeedback, since the network structures are specially designed for one\nparticular case. Second, due to the difficulty on training deep neural\nnetworks, existing explicit models do not fully exploit the expressive\npotential of deep learning. Third, neural network models are easier to overfit\non the implicit setting than shallow models. To tackle these issues, we present\na generic recommender framework called Neural Collaborative Autoencoder (NCAE)\nto perform collaborative filtering, which works well for both explicit feedback\nand implicit feedback. NCAE can effectively capture the subtle hidden\nrelationships between interactions via a non-linear matrix factorization\nprocess. To optimize the deep architecture of NCAE, we develop a three-stage\npre-training mechanism that combines supervised and unsupervised feature\nlearning. Moreover, to prevent overfitting on the implicit setting, we propose\nan error reweighting module and a sparsity-aware data-augmentation strategy.\nExtensive experiments on three real-world datasets demonstrate that NCAE can\nsignificantly advance the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Mon, 25 Dec 2017 08:48:43 GMT"}, {"version": "v2", "created": "Tue, 30 Jan 2018 04:39:05 GMT"}, {"version": "v3", "created": "Wed, 19 Dec 2018 06:40:14 GMT"}], "update_date": "2018-12-20", "authors_parsed": [["Li", "Qibing", ""], ["Zheng", "Xiaolin", ""], ["Wu", "Xinyue", ""]]}, {"id": "1712.09097", "submitter": "Bai Li", "authors": "Bai Li, Changyou Chen, Hao Liu, Lawrence Carin", "title": "On Connecting Stochastic Gradient MCMC and Differential Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Significant success has been realized recently on applying machine learning\nto real-world applications. There have also been corresponding concerns on the\nprivacy of training data, which relates to data security and confidentiality\nissues. Differential privacy provides a principled and rigorous privacy\nguarantee on machine learning models. While it is common to design a model\nsatisfying a required differential-privacy property by injecting noise, it is\ngenerally hard to balance the trade-off between privacy and utility. We show\nthat stochastic gradient Markov chain Monte Carlo (SG-MCMC) -- a class of\nscalable Bayesian posterior sampling algorithms proposed recently -- satisfies\nstrong differential privacy with carefully chosen step sizes. We develop theory\non the performance of the proposed differentially-private SG-MCMC method. We\nconduct experiments to support our analysis and show that a standard SG-MCMC\nsampler without any modification (under a default setting) can reach\nstate-of-the-art performance in terms of both privacy and utility on Bayesian\nlearning.\n", "versions": [{"version": "v1", "created": "Mon, 25 Dec 2017 16:29:44 GMT"}], "update_date": "2017-12-27", "authors_parsed": [["Li", "Bai", ""], ["Chen", "Changyou", ""], ["Liu", "Hao", ""], ["Carin", "Lawrence", ""]]}, {"id": "1712.09123", "submitter": "Shameem Puthiya Parambath Mr.", "authors": "Shameem A Puthiya Parambath, Nishant Vijayakumar, Sanjay Chawla", "title": "SAGA: A Submodular Greedy Algorithm For Group Recommendation", "comments": "AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a unified framework and an algorithm for the\nproblem of group recommendation where a fixed number of items or alternatives\ncan be recommended to a group of users. The problem of group recommendation\narises naturally in many real world contexts, and is closely related to the\nbudgeted social choice problem studied in economics. We frame the group\nrecommendation problem as choosing a subgraph with the largest group consensus\nscore in a completely connected graph defined over the item affinity matrix. We\npropose a fast greedy algorithm with strong theoretical guarantees, and show\nthat the proposed algorithm compares favorably to the state-of-the-art group\nrecommendation algorithms according to commonly used relevance and coverage\nperformance measures on benchmark dataset.\n", "versions": [{"version": "v1", "created": "Mon, 25 Dec 2017 20:03:46 GMT"}], "update_date": "2017-12-27", "authors_parsed": [["Parambath", "Shameem A Puthiya", ""], ["Vijayakumar", "Nishant", ""], ["Chawla", "Sanjay", ""]]}, {"id": "1712.09133", "submitter": "Ruocheng Guo", "authors": "Ruocheng Guo, Hamidreza Alvari, Paulo Shakarian", "title": "Strongly Hierarchical Factorization Machines and ANOVA Kernel Regression", "comments": "9 pages, to appear in SDM'18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-order parametric models that include terms for feature interactions are\napplied to various data mining tasks, where ground truth depends on\ninteractions of features. However, with sparse data, the high- dimensional\nparameters for feature interactions often face three issues: expensive\ncomputation, difficulty in parameter estimation and lack of structure. Previous\nwork has proposed approaches which can partially re- solve the three issues. In\nparticular, models with factorized parameters (e.g. Factorization Machines) and\nsparse learning algorithms (e.g. FTRL-Proximal) can tackle the first two issues\nbut fail to address the third. Regarding to unstructured parameters,\nconstraints or complicated regularization terms are applied such that\nhierarchical structures can be imposed. However, these methods make the\noptimization problem more challenging. In this work, we propose Strongly\nHierarchical Factorization Machines and ANOVA kernel regression where all the\nthree issues can be addressed without making the optimization problem more\ndifficult. Experimental results show the proposed models significantly\noutperform the state-of-the-art in two data mining tasks: cold-start user\nresponse time prediction and stock volatility prediction.\n", "versions": [{"version": "v1", "created": "Mon, 25 Dec 2017 21:42:05 GMT"}, {"version": "v2", "created": "Fri, 5 Jan 2018 19:44:11 GMT"}], "update_date": "2018-01-09", "authors_parsed": [["Guo", "Ruocheng", ""], ["Alvari", "Hamidreza", ""], ["Shakarian", "Paulo", ""]]}, {"id": "1712.09196", "submitter": "Ajil Jalal", "authors": "Ajil Jalal, Andrew Ilyas, Constantinos Daskalakis, Alexandros G.\n  Dimakis", "title": "The Robust Manifold Defense: Adversarial Training using Generative\n  Models", "comments": "Added pseudo code for defense-gan break", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new type of attack for finding adversarial examples for image\nclassifiers. Our method exploits spanners, i.e. deep neural networks whose\ninput space is low-dimensional and whose output range approximates the set of\nimages of interest. Spanners may be generators of GANs or decoders of VAEs. The\nkey idea in our attack is to search over latent code pairs to find ones that\ngenerate nearby images with different classifier outputs. We argue that our\nattack is stronger than searching over perturbations of real images. Moreover,\nwe show that our stronger attack can be used to reduce the accuracy of\nDefense-GAN to 3\\%, resolving an open problem from the well-known paper by\nAthalye et al. We combine our attack with normal adversarial training to obtain\nthe most robust known MNIST classifier, significantly improving the state of\nthe art against PGD attacks. Our formulation involves solving a min-max\nproblem, where the min player sets the parameters of the classifier and the max\nplayer is running our attack, and is thus searching for adversarial examples in\nthe {\\em low-dimensional} input space of the spanner.\n  All code and models are available at\n\\url{https://github.com/ajiljalal/manifold-defense.git}\n", "versions": [{"version": "v1", "created": "Tue, 26 Dec 2017 07:28:14 GMT"}, {"version": "v2", "created": "Fri, 31 May 2019 14:42:03 GMT"}, {"version": "v3", "created": "Tue, 4 Jun 2019 13:23:51 GMT"}, {"version": "v4", "created": "Thu, 4 Jul 2019 15:26:38 GMT"}, {"version": "v5", "created": "Wed, 10 Jul 2019 03:51:45 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Jalal", "Ajil", ""], ["Ilyas", "Andrew", ""], ["Daskalakis", "Constantinos", ""], ["Dimakis", "Alexandros G.", ""]]}, {"id": "1712.09203", "submitter": "Hongyang Zhang", "authors": "Yuanzhi Li, Tengyu Ma, Hongyang Zhang", "title": "Algorithmic Regularization in Over-parameterized Matrix Sensing and\n  Neural Networks with Quadratic Activations", "comments": "COLT 2018 best paper; fixed minor missing steps in the previous\n  version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the gradient descent algorithm provides an implicit\nregularization effect in the learning of over-parameterized matrix\nfactorization models and one-hidden-layer neural networks with quadratic\nactivations. Concretely, we show that given $\\tilde{O}(dr^{2})$ random linear\nmeasurements of a rank $r$ positive semidefinite matrix $X^{\\star}$, we can\nrecover $X^{\\star}$ by parameterizing it by $UU^\\top$ with $U\\in \\mathbb\nR^{d\\times d}$ and minimizing the squared loss, even if $r \\ll d$. We prove\nthat starting from a small initialization, gradient descent recovers\n$X^{\\star}$ in $\\tilde{O}(\\sqrt{r})$ iterations approximately. The results\nsolve the conjecture of Gunasekar et al.'17 under the restricted isometry\nproperty. The technique can be applied to analyzing neural networks with\none-hidden-layer quadratic activations with some technical modifications.\n", "versions": [{"version": "v1", "created": "Tue, 26 Dec 2017 08:04:43 GMT"}, {"version": "v2", "created": "Wed, 21 Feb 2018 08:21:52 GMT"}, {"version": "v3", "created": "Thu, 22 Feb 2018 03:50:08 GMT"}, {"version": "v4", "created": "Mon, 19 Mar 2018 07:59:32 GMT"}, {"version": "v5", "created": "Thu, 14 Feb 2019 00:24:05 GMT"}], "update_date": "2019-02-15", "authors_parsed": [["Li", "Yuanzhi", ""], ["Ma", "Tengyu", ""], ["Zhang", "Hongyang", ""]]}, {"id": "1712.09315", "submitter": "Monireh Dabaghchian", "authors": "Monireh Dabaghchian, Amir Alipour-Fanid, Songsong Liu, Kai Zeng,\n  Xiaohua Li, Yu Chen", "title": "Who is Smarter? Intelligence Measure of Learning-based Cognitive Radios", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cognitive radio (CR) is considered as a key enabling technology for dynamic\nspectrum access to improve spectrum efficiency. Although the CR concept was\ninvented with the core idea of realizing cognition, the research on measuring\nCR cognitive capabilities and intelligence is largely open. Deriving the\nintelligence measure of CR not only can lead to the development of new CR\ntechnologies, but also makes it possible to better configure the networks by\nintegrating CRs with different cognitive capabilities. In this paper, for the\nfirst time, we propose a data-driven methodology to quantitatively measure the\nintelligence factors of the CR with learning capabilities. The basic idea of\nour methodology is to run various tests on the CR in different spectrum\nenvironments under different settings and obtain various performance data on\ndifferent metrics. Then we apply factor analysis on the performance data to\nidentify and quantize the intelligence factors and cognitive capabilities of\nthe CR. More specifically, we present a case study consisting of 144 different\ntypes of CRs. The CRs are different in terms of learning-based dynamic spectrum\naccess strategies, number of sensors, sensing accuracy, processing speed, and\nalgorithmic complexity. Five intelligence factors are identified for the CRs\nthrough our data analysis.We show that these factors comply well with the\nnature of the tested CRs, which validates the proposed intelligence measure\nmethodology.\n", "versions": [{"version": "v1", "created": "Tue, 26 Dec 2017 17:48:37 GMT"}, {"version": "v2", "created": "Mon, 19 Mar 2018 20:24:58 GMT"}], "update_date": "2018-03-21", "authors_parsed": [["Dabaghchian", "Monireh", ""], ["Alipour-Fanid", "Amir", ""], ["Liu", "Songsong", ""], ["Zeng", "Kai", ""], ["Li", "Xiaohua", ""], ["Chen", "Yu", ""]]}, {"id": "1712.09327", "submitter": "Yousef Fadila", "authors": "Arkar Min Aung, Yousef Fadila, Radian Gondokaryono, Luis Gonzalez", "title": "Building Robust Deep Neural Networks for Road Sign Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks are built to generalize outside of training set in mind\nby using techniques such as regularization, early stopping and dropout. But\nconsiderations to make them more resilient to adversarial examples are rarely\ntaken. As deep neural networks become more prevalent in mission-critical and\nreal-time systems, miscreants start to attack them by intentionally making deep\nneural networks to misclassify an object of one type to be seen as another\ntype. This can be catastrophic in some scenarios where the classification of a\ndeep neural network can lead to a fatal decision by a machine. In this work, we\nused GTSRB dataset to craft adversarial samples by Fast Gradient Sign Method\nand Jacobian Saliency Method, used those crafted adversarial samples to attack\nanother Deep Convolutional Neural Network and built the attacked network to be\nmore resilient against adversarial attacks by making it more robust by\nDefensive Distillation and Adversarial Training\n", "versions": [{"version": "v1", "created": "Tue, 26 Dec 2017 18:52:41 GMT"}], "update_date": "2017-12-27", "authors_parsed": [["Aung", "Arkar Min", ""], ["Fadila", "Yousef", ""], ["Gondokaryono", "Radian", ""], ["Gonzalez", "Luis", ""]]}, {"id": "1712.09332", "submitter": "Sobhan Moosavi", "authors": "Samaneh Aghajanbaglo, Sobhan Moosavi, Maseud Rahgozar, Amir Rahimi", "title": "Predicting protein-protein interactions based on rotation of proteins in\n  3D-space", "comments": "6 pages, accepted in The Second International Workshop on Parallelism\n  in Bioinformatics (PBio 2014), as part of IEEE Cluster 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Protein-Protein Interactions (PPIs) perform essential roles in biological\nfunctions. Although some experimental techniques have been developed to detect\nPPIs, they suffer from high false positive and high false negative rates.\nConsequently, efforts have been devoted during recent years to develop\ncomputational approaches to predict the interactions utilizing various sources\nof information. Therefore, a unique category of prediction approaches has been\ndevised which is based on the protein sequence information. However, finding an\nappropriate feature encoding to characterize the sequence of proteins is a\nmajor challenge in such methods. In presented work, a sequence based method is\nproposed to predict protein-protein interactions using N-Gram encoding\napproaches to describe amino acids and a Relaxed Variable Kernel Density\nEstimator (RVKDE) as a machine learning tool. Moreover, since proteins can\nrotate in 3D-space, amino acid compositions have been considered with\n\"undirected\" property which leads to reduce dimensions of the vector space. The\nresults show that our proposed method achieves the superiority of prediction\nperformance with improving an F-measure of 2.5% on Human Protein Reference\nDataset (HPRD).\n", "versions": [{"version": "v1", "created": "Fri, 22 Dec 2017 19:33:19 GMT"}], "update_date": "2017-12-29", "authors_parsed": [["Aghajanbaglo", "Samaneh", ""], ["Moosavi", "Sobhan", ""], ["Rahgozar", "Maseud", ""], ["Rahimi", "Amir", ""]]}, {"id": "1712.09376", "submitter": "Daniel Roy", "authors": "Gintare Karolina Dziugaite, Daniel M. Roy", "title": "Entropy-SGD optimizes the prior of a PAC-Bayes bound: Generalization\n  properties of Entropy-SGD and data-dependent priors", "comments": "18 pages, 6 figures; combines ICML camera ready with supplementary\n  materials", "journal-ref": "Proceedings of the 35th International Conference on Machine\n  Learning, PMLR 80:1377-1386, 2018", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that Entropy-SGD (Chaudhari et al., 2017), when viewed as a learning\nalgorithm, optimizes a PAC-Bayes bound on the risk of a Gibbs (posterior)\nclassifier, i.e., a randomized classifier obtained by a risk-sensitive\nperturbation of the weights of a learned classifier. Entropy-SGD works by\noptimizing the bound's prior, violating the hypothesis of the PAC-Bayes theorem\nthat the prior is chosen independently of the data. Indeed, available\nimplementations of Entropy-SGD rapidly obtain zero training error on random\nlabels and the same holds of the Gibbs posterior. In order to obtain a valid\ngeneralization bound, we rely on a result showing that data-dependent priors\nobtained by stochastic gradient Langevin dynamics (SGLD) yield valid PAC-Bayes\nbounds provided the target distribution of SGLD is {\\epsilon}-differentially\nprivate. We observe that test error on MNIST and CIFAR10 falls within the\n(empirically nonvacuous) risk bounds computed under the assumption that SGLD\nreaches stationarity. In particular, Entropy-SGLD can be configured to yield\nrelatively tight generalization bounds and still fit real labels, although\nthese same settings do not obtain state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Tue, 26 Dec 2017 19:20:55 GMT"}, {"version": "v2", "created": "Sat, 3 Mar 2018 15:51:32 GMT"}, {"version": "v3", "created": "Fri, 19 Apr 2019 19:19:21 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Dziugaite", "Gintare Karolina", ""], ["Roy", "Daniel M.", ""]]}, {"id": "1712.09379", "submitter": "Anastasios Kyrillidis", "authors": "Rajiv Khanna and Anastasios Kyrillidis", "title": "IHT dies hard: Provable accelerated Iterative Hard Thresholding", "comments": "accepted to AISTATS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS cs.LG cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study --both in theory and practice-- the use of momentum motions in\nclassic iterative hard thresholding (IHT) methods. By simply modifying plain\nIHT, we investigate its convergence behavior on convex optimization criteria\nwith non-convex constraints, under standard assumptions. In diverse scenaria,\nwe observe that acceleration in IHT leads to significant improvements, compared\nto state of the art projected gradient descent and Frank-Wolfe variants. As a\nbyproduct of our inspection, we study the impact of selecting the momentum\nparameter: similar to convex settings, two modes of behavior are observed\n--\"rippling\" and linear-- depending on the level of momentum.\n", "versions": [{"version": "v1", "created": "Tue, 26 Dec 2017 19:40:47 GMT"}, {"version": "v2", "created": "Fri, 13 Sep 2019 18:01:30 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Khanna", "Rajiv", ""], ["Kyrillidis", "Anastasios", ""]]}, {"id": "1712.09381", "submitter": "Richard Liaw", "authors": "Eric Liang, Richard Liaw, Philipp Moritz, Robert Nishihara, Roy Fox,\n  Ken Goldberg, Joseph E. Gonzalez, Michael I. Jordan, Ion Stoica", "title": "RLlib: Abstractions for Distributed Reinforcement Learning", "comments": "Published in the International Conference on Machine Learning (ICML\n  2018), 10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) algorithms involve the deep nesting of highly\nirregular computation patterns, each of which typically exhibits opportunities\nfor distributed computation. We argue for distributing RL components in a\ncomposable way by adapting algorithms for top-down hierarchical control,\nthereby encapsulating parallelism and resource requirements within\nshort-running compute tasks. We demonstrate the benefits of this principle\nthrough RLlib: a library that provides scalable software primitives for RL.\nThese primitives enable a broad range of algorithms to be implemented with high\nperformance, scalability, and substantial code reuse. RLlib is available at\nhttps://rllib.io/.\n", "versions": [{"version": "v1", "created": "Tue, 26 Dec 2017 19:43:59 GMT"}, {"version": "v2", "created": "Wed, 10 Jan 2018 02:40:19 GMT"}, {"version": "v3", "created": "Mon, 19 Mar 2018 00:01:53 GMT"}, {"version": "v4", "created": "Fri, 29 Jun 2018 00:19:24 GMT"}], "update_date": "2018-07-02", "authors_parsed": [["Liang", "Eric", ""], ["Liaw", "Richard", ""], ["Moritz", "Philipp", ""], ["Nishihara", "Robert", ""], ["Fox", "Roy", ""], ["Goldberg", "Ken", ""], ["Gonzalez", "Joseph E.", ""], ["Jordan", "Michael I.", ""], ["Stoica", "Ion", ""]]}, {"id": "1712.09418", "submitter": "Daniel Neider", "authors": "Deepak D'Souza, P. Ezudheen, Pranav Garg, P. Madhusudan, Daniel Neider", "title": "Horn-ICE Learning for Synthesizing Invariants and Contracts", "comments": null, "journal-ref": null, "doi": "10.1145/3276501", "report-no": null, "categories": "cs.LO cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We design learning algorithms for synthesizing invariants using Horn\nimplication counterexamples (Horn-ICE), extending the ICE-learning model. In\nparticular, we describe a decision-tree learning algorithm that learns from\nHorn-ICE samples, works in polynomial time, and uses statistical heuristics to\nlearn small trees that satisfy the samples. Since most verification proofs can\nbe modeled using Horn clauses, Horn-ICE learning is a more robust technique to\nlearn inductive annotations that prove programs correct. Our experiments show\nthat an implementation of our algorithm is able to learn adequate inductive\ninvariants and contracts efficiently for a variety of sequential and concurrent\nprograms.\n", "versions": [{"version": "v1", "created": "Tue, 26 Dec 2017 21:14:09 GMT"}], "update_date": "2018-11-12", "authors_parsed": [["D'Souza", "Deepak", ""], ["Ezudheen", "P.", ""], ["Garg", "Pranav", ""], ["Madhusudan", "P.", ""], ["Neider", "Daniel", ""]]}, {"id": "1712.09473", "submitter": "Zhao Song", "authors": "Huaian Diao, Zhao Song, Wen Sun, David P. Woodruff", "title": "Sketching for Kronecker Product Regression and P-splines", "comments": "AISTATS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  TensorSketch is an oblivious linear sketch introduced in Pagh'13 and later\nused in Pham, Pagh'13 in the context of SVMs for polynomial kernels. It was\nshown in Avron, Nguyen, Woodruff'14 that TensorSketch provides a subspace\nembedding, and therefore can be used for canonical correlation analysis, low\nrank approximation, and principal component regression for the polynomial\nkernel. We take TensorSketch outside of the context of polynomials kernels, and\nshow its utility in applications in which the underlying design matrix is a\nKronecker product of smaller matrices. This allows us to solve Kronecker\nproduct regression and non-negative Kronecker product regression, as well as\nregularized spline regression. Our main technical result is then in extending\nTensorSketch to other norms. That is, TensorSketch only provides input sparsity\ntime for Kronecker product regression with respect to the $2$-norm. We show how\nto solve Kronecker product regression with respect to the $1$-norm in time\nsublinear in the time required for computing the Kronecker product, as well as\nfor more general $p$-norms.\n", "versions": [{"version": "v1", "created": "Wed, 27 Dec 2017 01:26:52 GMT"}], "update_date": "2017-12-29", "authors_parsed": [["Diao", "Huaian", ""], ["Song", "Zhao", ""], ["Sun", "Wen", ""], ["Woodruff", "David P.", ""]]}, {"id": "1712.09482", "submitter": "Aritra Ghosh", "authors": "Aritra Ghosh, Himanshu Kumar, P.S. Sastry", "title": "Robust Loss Functions under Label Noise for Deep Neural Networks", "comments": "Appeared in AAAI 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many applications of classifier learning, training data suffers from label\nnoise. Deep networks are learned using huge training data where the problem of\nnoisy labels is particularly relevant. The current techniques proposed for\nlearning deep networks under label noise focus on modifying the network\narchitecture and on algorithms for estimating true labels from noisy labels. An\nalternate approach would be to look for loss functions that are inherently\nnoise-tolerant. For binary classification there exist theoretical results on\nloss functions that are robust to label noise. In this paper, we provide some\nsufficient conditions on a loss function so that risk minimization under that\nloss function would be inherently tolerant to label noise for multiclass\nclassification problems. These results generalize the existing results on\nnoise-tolerant loss functions for binary classification. We study some of the\nwidely used loss functions in deep networks and show that the loss function\nbased on mean absolute value of error is inherently robust to label noise. Thus\nstandard back propagation is enough to learn the true classifier even under\nlabel noise. Through experiments, we illustrate the robustness of risk\nminimization with such loss functions for learning neural networks.\n", "versions": [{"version": "v1", "created": "Wed, 27 Dec 2017 03:07:57 GMT"}], "update_date": "2017-12-29", "authors_parsed": [["Ghosh", "Aritra", ""], ["Kumar", "Himanshu", ""], ["Sastry", "P. S.", ""]]}, {"id": "1712.09491", "submitter": "Arjun Nitin Bhagoji", "authors": "Arjun Nitin Bhagoji, Warren He, Bo Li, Dawn Song", "title": "Exploring the Space of Black-box Attacks on Deep Neural Networks", "comments": "25 pages, 7 figures, 10 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Existing black-box attacks on deep neural networks (DNNs) so far have largely\nfocused on transferability, where an adversarial instance generated for a\nlocally trained model can \"transfer\" to attack other learning models. In this\npaper, we propose novel Gradient Estimation black-box attacks for adversaries\nwith query access to the target model's class probabilities, which do not rely\non transferability. We also propose strategies to decouple the number of\nqueries required to generate each adversarial sample from the dimensionality of\nthe input. An iterative variant of our attack achieves close to 100%\nadversarial success rates for both targeted and untargeted attacks on DNNs. We\ncarry out extensive experiments for a thorough comparative evaluation of\nblack-box attacks and show that the proposed Gradient Estimation attacks\noutperform all transferability based black-box attacks we tested on both MNIST\nand CIFAR-10 datasets, achieving adversarial success rates similar to well\nknown, state-of-the-art white-box attacks. We also apply the Gradient\nEstimation attacks successfully against a real-world Content Moderation\nclassifier hosted by Clarifai. Furthermore, we evaluate black-box attacks\nagainst state-of-the-art defenses. We show that the Gradient Estimation attacks\nare very effective even against these defenses.\n", "versions": [{"version": "v1", "created": "Wed, 27 Dec 2017 04:39:02 GMT"}], "update_date": "2017-12-29", "authors_parsed": [["Bhagoji", "Arjun Nitin", ""], ["He", "Warren", ""], ["Li", "Bo", ""], ["Song", "Dawn", ""]]}, {"id": "1712.09520", "submitter": "Guillaume Rabusseau", "authors": "Xingwei Cao, Guillaume Rabusseau", "title": "Tensor Regression Networks with various Low-Rank Tensor Approximations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tensor regression networks achieve high compression rate of neural networks\nwhile having slight impact on performances. They do so by imposing low tensor\nrank structure on the weight matrices of fully connected layers. In recent\nyears, tensor regression networks have been investigated from the perspective\nof their compressive power, however, the regularization effect of enforcing\nlow-rank tensor structure has not been investigated enough. We study tensor\nregression networks using various low-rank tensor approximations, aiming to\ncompare the compressive and regularization power of different low-rank\nconstraints. We evaluate the compressive and regularization performances of the\nproposed model with both deep and shallow convolutional neural networks. The\noutcome of our experiment suggests the superiority of Global Average Pooling\nLayer over Tensor Regression Layer when applied to deep convolutional neural\nnetwork with CIFAR-10 dataset. On the contrary, shallow convolutional neural\nnetworks with tensor regression layer and dropout achieved lower test error\nthan both Global Average Pooling and fully-connected layer with dropout\nfunction when trained with a small number of samples.\n", "versions": [{"version": "v1", "created": "Wed, 27 Dec 2017 08:04:34 GMT"}, {"version": "v2", "created": "Thu, 29 Nov 2018 02:10:55 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Cao", "Xingwei", ""], ["Rabusseau", "Guillaume", ""]]}, {"id": "1712.09527", "submitter": "Karan Aggarwal", "authors": "Karan Aggarwal, Shafiq Joty, Luis F. Luque, Jaideep Srivastava", "title": "Co-Morbidity Exploration on Wearables Activity Data Using Unsupervised\n  Pre-training and Multi-Task Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Physical activity and sleep play a major role in the prevention and\nmanagement of many chronic conditions. It is not a trivial task to understand\ntheir impact on chronic conditions. Currently, data from electronic health\nrecords (EHRs), sleep lab studies, and activity/sleep logs are used. The rapid\nincrease in the popularity of wearable health devices provides a significant\nnew data source, making it possible to track the user's lifestyle real-time\nthrough web interfaces, both to consumer as well as their healthcare provider,\npotentially. However, at present there is a gap between lifestyle data (e.g.,\nsleep, physical activity) and clinical outcomes normally captured in EHRs. This\nis a critical barrier for the use of this new source of signal for healthcare\ndecision making. Applying deep learning to wearables data provides a new\nopportunity to overcome this barrier.\n  To address the problem of the unavailability of clinical data from a major\nfraction of subjects and unrepresentative subject populations, we propose a\nnovel unsupervised (task-agnostic) time-series representation learning\ntechnique called act2vec. act2vec learns useful features by taking into account\nthe co-occurrence of activity levels along with periodicity of human activity\npatterns. The learned representations are then exploited to boost the\nperformance of disorder-specific supervised learning models. Furthermore, since\nmany disorders are often related to each other, a phenomenon referred to as\nco-morbidity, we use a multi-task learning framework for exploiting the shared\nstructure of disorder inducing life-style choices partially captured in the\nwearables data. Empirical evaluation using actigraphy data from 4,124 subjects\nshows that our proposed method performs and generalizes substantially better\nthan the conventional time-series symbolic representational methods and\ntask-specific deep learning models.\n", "versions": [{"version": "v1", "created": "Wed, 27 Dec 2017 08:45:37 GMT"}], "update_date": "2017-12-29", "authors_parsed": [["Aggarwal", "Karan", ""], ["Joty", "Shafiq", ""], ["Luque", "Luis F.", ""], ["Srivastava", "Jaideep", ""]]}, {"id": "1712.09553", "submitter": "Esben Jannik Bjerrum", "authors": "Esben Jannik Bjerrum", "title": "DeepIEP: a Peptide Sequence Model of Isoelectric Point (IEP/pI) using\n  Recurrent Neural Networks (RNNs)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.BM cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The isoelectric point (IEP or pI) is the pH where the net charge on the\nmolecular ensemble of peptides and proteins is zero. This physical-chemical\nproperty is dependent on protonable/deprotonable sidechains and their pKa\nvalues. Here an pI prediction model is trained from a database of peptide\nsequences and pIs using a recurrent neural network (RNN) with long short-term\nmemory (LSTM) cells. The trained model obtains an RMSE and R$^2$ of 0.28 and\n0.95 for the external test set. The model is not based on pKa values, but\nprediction of constructed test sequences show similar rankings as already known\npKa values. The prediction depends mostly on the existence of known acidic and\nbasic amino acids with fine-adjusted based on the neighboring sequence and\nposition of the charged amino acids in the peptide chain.\n", "versions": [{"version": "v1", "created": "Wed, 27 Dec 2017 11:30:02 GMT"}], "update_date": "2017-12-29", "authors_parsed": [["Bjerrum", "Esben Jannik", ""]]}, {"id": "1712.09623", "submitter": "Mouhammd Alkasassbeh", "authors": "Mouhammd Alkasassbeh", "title": "An empirical evaluation for the intrusion detection features based on\n  machine learning and feature selection methods", "comments": null, "journal-ref": "Journal of Theoretical and Applied Information Technology 30th\n  November 2017 -- Vol. 95. No. 22 -- 2017", "doi": null, "report-no": null, "categories": "cs.NI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the great developments in information technology, particularly the\nInternet, computer networks, global information exchange, and its positive\nimpact in all areas of daily life, it has also contributed to the development\nof penetration and intrusion which forms a high risk to the security of\ninformation organizations, government agencies, and causes large economic\nlosses. There are many techniques designed for protection such as firewall and\nintrusion detection systems (IDS). IDS is a set of software and/or hardware\ntechniques used to detect hacker's activities in computer systems. Two types of\nanomalies are used in IDS to detect intrusive activities different from normal\nuser behavior. Misuse relies on the knowledge base that contains all known\nattack techniques and intrusion is discovered through research in this\nknowledge base. Artificial intelligence techniques have been introduced to\nimprove the performance of these systems. The importance of IDS is to identify\nunauthorized access attempting to compromise confidentiality, integrity or\navailability of the computer network. This paper investigates the Intrusion\nDetection (ID) problem using three machine learning algorithms namely, BayesNet\nalgorithm, Multi-Layer Perceptron (MLP), and Support Vector Machine (SVM). The\nalgorithms are applied on a real, Management Information Based (MIB) dataset\nthat is collected from real life environment. To enhance the detection process\naccuracy, a set of feature selection approaches is used; Infogain (IG), ReleifF\n(RF), and Genetic Search (GS). Our experiments show that the three feature\nselection methods have enhanced the classification performance. GS with\nbayesNet, MLP and SVM give high accuracy rates, more specifically the BayesNet\nwith the GS accuracy rate is 99.9%.\n", "versions": [{"version": "v1", "created": "Wed, 27 Dec 2017 16:39:55 GMT"}], "update_date": "2017-12-29", "authors_parsed": [["Alkasassbeh", "Mouhammd", ""]]}, {"id": "1712.09652", "submitter": "Huizhen Yu", "authors": "Huizhen Yu", "title": "On Convergence of some Gradient-based Temporal-Differences Algorithms\n  for Off-Policy Learning", "comments": "Revised technical report; added Section 4.2.4 and Section 4.3; 86\n  pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider off-policy temporal-difference (TD) learning methods for policy\nevaluation in Markov decision processes with finite spaces and discounted\nreward criteria, and we present a collection of convergence results for several\ngradient-based TD algorithms with linear function approximation. The algorithms\nwe analyze include: (i) two basic forms of two-time-scale gradient-based TD\nalgorithms, which we call GTD and which minimize the mean squared projected\nBellman error using stochastic gradient-descent; (ii) their \"robustified\"\nbiased variants; (iii) their mirror-descent versions which combine the\nmirror-descent idea with TD learning; and (iv) a single-time-scale version of\nGTD that solves minimax problems formulated for approximate policy evaluation.\n  We derive convergence results for three types of stepsizes: constant\nstepsize, slowly diminishing stepsize, as well as the standard type of\ndiminishing stepsize with a square-summable condition. For the first two types\nof stepsizes, we apply the weak convergence method from stochastic\napproximation theory to characterize the asymptotic behavior of the algorithms,\nand for the standard type of stepsize, we analyze the algorithmic behavior with\nrespect to a stronger mode of convergence, almost sure convergence. Our\nconvergence results are for the aforementioned TD algorithms with three general\nways of setting their $\\lambda$-parameters: (i) state-dependent $\\lambda$; (ii)\na recently proposed scheme of using history-dependent $\\lambda$ to keep the\neligibility traces of the algorithms bounded while allowing for relatively\nlarge values of $\\lambda$; and (iii) a composite scheme of setting the\n$\\lambda$-parameters that combines the preceding two schemes and allows a\nbroader class of generalized Bellman operators to be used for approximate\npolicy evaluation with TD methods.\n", "versions": [{"version": "v1", "created": "Wed, 27 Dec 2017 18:43:21 GMT"}, {"version": "v2", "created": "Wed, 28 Mar 2018 22:41:33 GMT"}], "update_date": "2018-03-30", "authors_parsed": [["Yu", "Huizhen", ""]]}, {"id": "1712.09657", "submitter": "Dj Strouse", "authors": "DJ Strouse, David J Schwab", "title": "The information bottleneck and geometric clustering", "comments": "Updated to final published version with more detailed relationship to\n  GMMs/k-means", "journal-ref": "Neural Computation 31 (2019) 596-612", "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The information bottleneck (IB) approach to clustering takes a joint\ndistribution $P\\!\\left(X,Y\\right)$ and maps the data $X$ to cluster labels $T$\nwhich retain maximal information about $Y$ (Tishby et al., 1999). This\nobjective results in an algorithm that clusters data points based upon the\nsimilarity of their conditional distributions $P\\!\\left(Y\\mid X\\right)$. This\nis in contrast to classic \"geometric clustering'' algorithms such as $k$-means\nand gaussian mixture models (GMMs) which take a set of observed data points\n$\\left\\{ \\mathbf{x}_{i}\\right\\} _{i=1:N}$ and cluster them based upon their\ngeometric (typically Euclidean) distance from one another. Here, we show how to\nuse the deterministic information bottleneck (DIB) (Strouse and Schwab, 2017),\na variant of IB, to perform geometric clustering, by choosing cluster labels\nthat preserve information about data point location on a smoothed dataset. We\nalso introduce a novel method to choose the number of clusters, based on\nidentifying solutions where the tradeoff between number of clusters used and\nspatial information preserved is strongest. We apply this approach to a variety\nof simple clustering problems, showing that DIB with our model selection\nprocedure recovers the generative cluster labels. We also show that, in\nparticular limits of our model parameters, clustering with DIB and IB is\nequivalent to $k$-means and EM fitting of a GMM with hard and soft assignments,\nrespectively. Thus, clustering with (D)IB generalizes and provides an\ninformation-theoretic perspective on these classic algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 27 Dec 2017 19:04:49 GMT"}, {"version": "v2", "created": "Sun, 31 May 2020 15:55:36 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Strouse", "DJ", ""], ["Schwab", "David J", ""]]}, {"id": "1712.09662", "submitter": "Qiming Chen", "authors": "Qiming Chen, Ren Wu", "title": "CNN Is All You Need", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Convolution Neural Network (CNN) has demonstrated the unique advantage in\naudio, image and text learning; recently it has also challenged Recurrent\nNeural Networks (RNNs) with long short-term memory cells (LSTM) in\nsequence-to-sequence learning, since the computations involved in CNN are\neasily parallelizable whereas those involved in RNN are mostly sequential,\nleading to a performance bottleneck. However, unlike RNN, the native CNN lacks\nthe history sensitivity required for sequence transformation; therefore\nenhancing the sequential order awareness, or position-sensitivity, becomes the\nkey to make CNN the general deep learning model. In this work we introduce an\nextended CNN model with strengthen position-sensitivity, called PoseNet. A\nnotable feature of PoseNet is the asymmetric treatment of position information\nin the encoder and the decoder. Experiments shows that PoseNet allows us to\nimprove the accuracy of CNN based sequence-to-sequence learning significantly,\nachieving around 33-36 BLEU scores on the WMT 2014 English-to-German\ntranslation task, and around 44-46 BLEU scores on the English-to-French\ntranslation task.\n", "versions": [{"version": "v1", "created": "Wed, 27 Dec 2017 19:49:09 GMT"}], "update_date": "2017-12-29", "authors_parsed": [["Chen", "Qiming", ""], ["Wu", "Ren", ""]]}, {"id": "1712.09677", "submitter": "Nicolas Loizou", "authors": "Nicolas Loizou, Peter Richt\\'arik", "title": "Momentum and Stochastic Momentum for Stochastic Gradient, Newton,\n  Proximal Point and Subspace Descent Methods", "comments": "47 pages, 7 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study several classes of stochastic optimization algorithms\nenriched with heavy ball momentum. Among the methods studied are: stochastic\ngradient descent, stochastic Newton, stochastic proximal point and stochastic\ndual subspace ascent. This is the first time momentum variants of several of\nthese methods are studied. We choose to perform our analysis in a setting in\nwhich all of the above methods are equivalent. We prove global nonassymptotic\nlinear convergence rates for all methods and various measures of success,\nincluding primal function values, primal iterates (in L2 sense), and dual\nfunction values. We also show that the primal iterates converge at an\naccelerated linear rate in the L1 sense. This is the first time a linear rate\nis shown for the stochastic heavy ball method (i.e., stochastic gradient\ndescent method with momentum). Under somewhat weaker conditions, we establish a\nsublinear convergence rate for Cesaro averages of primal iterates. Moreover, we\npropose a novel concept, which we call stochastic momentum, aimed at decreasing\nthe cost of performing the momentum step. We prove linear convergence of\nseveral stochastic methods with stochastic momentum, and show that in some\nsparse data regimes and for sufficiently small momentum parameters, these\nmethods enjoy better overall complexity than methods with deterministic\nmomentum. Finally, we perform extensive numerical testing on artificial and\nreal datasets, including data coming from average consensus problems.\n", "versions": [{"version": "v1", "created": "Wed, 27 Dec 2017 20:40:24 GMT"}, {"version": "v2", "created": "Wed, 28 Mar 2018 18:14:11 GMT"}], "update_date": "2018-03-30", "authors_parsed": [["Loizou", "Nicolas", ""], ["Richt\u00e1rik", "Peter", ""]]}, {"id": "1712.09687", "submitter": "Tim Rockt\\\"aschel", "authors": "Tim Rockt\\\"aschel", "title": "Combining Representation Learning with Logic for Language Processing", "comments": "PhD Thesis, University College London, Submitted and accepted in 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CL cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current state-of-the-art in many natural language processing and\nautomated knowledge base completion tasks is held by representation learning\nmethods which learn distributed vector representations of symbols via\ngradient-based optimization. They require little or no hand-crafted features,\nthus avoiding the need for most preprocessing steps and task-specific\nassumptions. However, in many cases representation learning requires a large\namount of annotated training data to generalize well to unseen data. Such\nlabeled training data is provided by human annotators who often use formal\nlogic as the language for specifying annotations. This thesis investigates\ndifferent combinations of representation learning methods with logic for\nreducing the need for annotated training data, and for improving\ngeneralization.\n", "versions": [{"version": "v1", "created": "Wed, 27 Dec 2017 21:09:36 GMT"}], "update_date": "2017-12-29", "authors_parsed": [["Rockt\u00e4schel", "Tim", ""]]}, {"id": "1712.09707", "submitter": "Bethany Lusch", "authors": "Bethany Lusch, J. Nathan Kutz, Steven L. Brunton", "title": "Deep learning for universal linear embeddings of nonlinear dynamics", "comments": "v2: added another example and further details (increase from 9 pages\n  to 14 pages and increase from 4 figures to 16 figures)", "journal-ref": null, "doi": "10.1038/s41467-018-07210-0", "report-no": null, "categories": "math.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying coordinate transformations that make strongly nonlinear dynamics\napproximately linear is a central challenge in modern dynamical systems. These\ntransformations have the potential to enable prediction, estimation, and\ncontrol of nonlinear systems using standard linear theory. The Koopman operator\nhas emerged as a leading data-driven embedding, as eigenfunctions of this\noperator provide intrinsic coordinates that globally linearize the dynamics.\nHowever, identifying and representing these eigenfunctions has proven to be\nmathematically and computationally challenging. This work leverages the power\nof deep learning to discover representations of Koopman eigenfunctions from\ntrajectory data of dynamical systems. Our network is parsimonious and\ninterpretable by construction, embedding the dynamics on a low-dimensional\nmanifold that is of the intrinsic rank of the dynamics and parameterized by the\nKoopman eigenfunctions. In particular, we identify nonlinear coordinates on\nwhich the dynamics are globally linear using a modified auto-encoder. We also\ngeneralize Koopman representations to include a ubiquitous class of systems\nthat exhibit continuous spectra, ranging from the simple pendulum to nonlinear\noptics and broadband turbulence. Our framework parametrizes the continuous\nfrequency using an auxiliary network, enabling a compact and efficient\nembedding at the intrinsic rank, while connecting our models to half a century\nof asymptotics. In this way, we benefit from the power and generality of deep\nlearning, while retaining the physical interpretability of Koopman embeddings.\n", "versions": [{"version": "v1", "created": "Wed, 27 Dec 2017 23:10:35 GMT"}, {"version": "v2", "created": "Fri, 13 Apr 2018 06:17:30 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Lusch", "Bethany", ""], ["Kutz", "J. Nathan", ""], ["Brunton", "Steven L.", ""]]}, {"id": "1712.09708", "submitter": "Youssef Tamaazousti", "authors": "Youssef Tamaazousti, Herv\\'e Le Borgne, C\\'eline Hudelot, Mohamed El\n  Amine Seddik, Mohamed Tamaazousti", "title": "Learning More Universal Representations for Transfer-Learning", "comments": "Submitted to IEEE Transactions on Pattern Analysis and Machine\n  Intelligence (TPAMI)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A representation is supposed universal if it encodes any element of the\nvisual world (e.g., objects, scenes) in any configuration (e.g., scale,\ncontext). While not expecting pure universal representations, the goal in the\nliterature is to improve the universality level, starting from a representation\nwith a certain level. To do so, the state-of-the-art consists in learning\nCNN-based representations on a diversified training problem (e.g., ImageNet\nmodified by adding annotated data). While it effectively increases\nuniversality, such approach still requires a large amount of efforts to satisfy\nthe needs in annotated data. In this work, we propose two methods to improve\nuniversality, but pay special attention to limit the need of annotated data. We\nalso propose a unified framework of the methods based on the diversifying of\nthe training problem. Finally, to better match Atkinson's cognitive study about\nuniversal human representations, we proposed to rely on the transfer-learning\nscheme as well as a new metric to evaluate universality. This latter, aims us\nto demonstrates the interest of our methods on 10 target-problems, relating to\nthe classification task and a variety of visual domains.\n", "versions": [{"version": "v1", "created": "Wed, 27 Dec 2017 23:14:46 GMT"}, {"version": "v2", "created": "Fri, 29 Dec 2017 08:58:38 GMT"}, {"version": "v3", "created": "Tue, 2 Jan 2018 00:14:43 GMT"}, {"version": "v4", "created": "Wed, 3 Jan 2018 17:00:16 GMT"}, {"version": "v5", "created": "Mon, 3 Sep 2018 01:03:21 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Tamaazousti", "Youssef", ""], ["Borgne", "Herv\u00e9 Le", ""], ["Hudelot", "C\u00e9line", ""], ["Seddik", "Mohamed El Amine", ""], ["Tamaazousti", "Mohamed", ""]]}, {"id": "1712.09713", "submitter": "Charles Zheng", "authors": "Charles Zheng, Rakesh Achanta, Yuval Benjamini", "title": "Extrapolating Expected Accuracies for Large Multi-Class Problems", "comments": "Submitted to JMLR", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The difficulty of multi-class classification generally increases with the\nnumber of classes. Using data from a subset of the classes, can we predict how\nwell a classifier will scale with an increased number of classes? Under the\nassumptions that the classes are sampled identically and independently from a\npopulation, and that the classifier is based on independently learned scoring\nfunctions, we show that the expected accuracy when the classifier is trained on\nk classes is the (k-1)st moment of a certain distribution that can be estimated\nfrom data. We present an unbiased estimation method based on the theory, and\ndemonstrate its application on a facial recognition example.\n", "versions": [{"version": "v1", "created": "Wed, 27 Dec 2017 23:49:39 GMT"}], "update_date": "2017-12-29", "authors_parsed": [["Zheng", "Charles", ""], ["Achanta", "Rakesh", ""], ["Benjamini", "Yuval", ""]]}, {"id": "1712.09718", "submitter": "Igor Gilitschenski", "authors": "Gerhard Kurz, Igor Gilitschenski, Florian Pfaff, Lukas Drude, Uwe D.\n  Hanebeck, Reinhold Haeb-Umbach, Roland Y. Siegwart", "title": "Directional Statistics and Filtering Using libDirectional", "comments": "Version accepted for Publication in the Journal of Statistical\n  Software", "journal-ref": null, "doi": "10.18637/jss.v089.i04", "report-no": null, "categories": "stat.CO cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present libDirectional, a MATLAB library for directional\nstatistics and directional estimation. It supports a variety of commonly used\ndistributions on the unit circle, such as the von Mises, wrapped normal, and\nwrapped Cauchy distributions. Furthermore, various distributions on\nhigher-dimensional manifolds such as the unit hypersphere and the hypertorus\nare available. Based on these distributions, several recursive filtering\nalgorithms in libDirectional allow estimation on these manifolds. The\nfunctionality is implemented in a clear, well-documented, and object-oriented\nstructure that is both easy to use and easy to extend.\n", "versions": [{"version": "v1", "created": "Thu, 28 Dec 2017 00:36:38 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Kurz", "Gerhard", ""], ["Gilitschenski", "Igor", ""], ["Pfaff", "Florian", ""], ["Drude", "Lukas", ""], ["Hanebeck", "Uwe D.", ""], ["Haeb-Umbach", "Reinhold", ""], ["Siegwart", "Roland Y.", ""]]}, {"id": "1712.09763", "submitter": "Xi Chen", "authors": "Xi Chen, Nikhil Mishra, Mostafa Rohaninejad, Pieter Abbeel", "title": "PixelSNAIL: An Improved Autoregressive Generative Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autoregressive generative models consistently achieve the best results in\ndensity estimation tasks involving high dimensional data, such as images or\naudio. They pose density estimation as a sequence modeling task, where a\nrecurrent neural network (RNN) models the conditional distribution over the\nnext element conditioned on all previous elements. In this paradigm, the\nbottleneck is the extent to which the RNN can model long-range dependencies,\nand the most successful approaches rely on causal convolutions, which offer\nbetter access to earlier parts of the sequence than conventional RNNs. Taking\ninspiration from recent work in meta reinforcement learning, where dealing with\nlong-range dependencies is also essential, we introduce a new generative model\narchitecture that combines causal convolutions with self attention. In this\nnote, we describe the resulting model and present state-of-the-art\nlog-likelihood results on CIFAR-10 (2.85 bits per dim) and $32 \\times 32$\nImageNet (3.80 bits per dim). Our implementation is available at\nhttps://github.com/neocxi/pixelsnail-public\n", "versions": [{"version": "v1", "created": "Thu, 28 Dec 2017 05:54:44 GMT"}], "update_date": "2017-12-29", "authors_parsed": [["Chen", "Xi", ""], ["Mishra", "Nikhil", ""], ["Rohaninejad", "Mostafa", ""], ["Abbeel", "Pieter", ""]]}, {"id": "1712.09765", "submitter": "Om Thakkar", "authors": "Prateek Jain, Om Thakkar, Abhradeep Thakurta", "title": "Differentially Private Matrix Completion Revisited", "comments": "Updated version. Accepted for presentation at International\n  Conference on Machine Learning (ICML) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide the first provably joint differentially private algorithm with\nformal utility guarantees for the problem of user-level privacy-preserving\ncollaborative filtering. Our algorithm is based on the Frank-Wolfe method, and\nit consistently estimates the underlying preference matrix as long as the\nnumber of users $m$ is $\\omega(n^{5/4})$, where $n$ is the number of items, and\neach user provides her preference for at least $\\sqrt{n}$ randomly selected\nitems. Along the way, we provide an optimal differentially private algorithm\nfor singular vector computation, based on the celebrated Oja's method, that\nprovides significant savings in terms of space and time while operating on\nsparse matrices. We also empirically evaluate our algorithm on a suite of\ndatasets, and show that it consistently outperforms the state-of-the-art\nprivate algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 28 Dec 2017 05:59:56 GMT"}, {"version": "v2", "created": "Tue, 12 Jun 2018 03:00:54 GMT"}], "update_date": "2018-06-13", "authors_parsed": [["Jain", "Prateek", ""], ["Thakkar", "Om", ""], ["Thakurta", "Abhradeep", ""]]}, {"id": "1712.09771", "submitter": "Meysam Golmohammadi", "authors": "Meysam Golmohammadi, Amir Hossein Harati Nejad Torbati, Silvia Lopez\n  de Diego, Iyad Obeid, and Joseph Picone", "title": "Automatic Analysis of EEGs Using Big Data and Hybrid Deep Learning\n  Architectures", "comments": "Under review in Journal of Clinical Neurophysiology", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: A clinical decision support tool that automatically interprets\nEEGs can reduce time to diagnosis and enhance real-time applications such as\nICU monitoring. Clinicians have indicated that a sensitivity of 95% with a\nspecificity below 5% was the minimum requirement for clinical acceptance. We\npropose a highperformance classification system based on principles of big data\nand machine learning. Methods: A hybrid machine learning system that uses\nhidden Markov models (HMM) for sequential decoding and deep learning networks\nfor postprocessing is proposed. These algorithms were trained and evaluated\nusing the TUH EEG Corpus, which is the world's largest publicly available\ndatabase of clinical EEG data. Results: Our approach delivers a sensitivity\nabove 90% while maintaining a specificity below 5%. This system detects three\nevents of clinical interest: (1) spike and/or sharp waves, (2) periodic\nlateralized epileptiform discharges, (3) generalized periodic epileptiform\ndischarges. It also detects three events used to model background noise: (1)\nartifacts, (2) eye movement (3) background. Conclusions: A hybrid HMM/deep\nlearning system can deliver a low false alarm rate on EEG event detection,\nmaking automated analysis a viable option for clinicians. Significance: The TUH\nEEG Corpus enables application of highly data consumptive machine learning\nalgorithms to EEG analysis. Performance is approaching clinical acceptance for\nreal-time applications.\n", "versions": [{"version": "v1", "created": "Thu, 28 Dec 2017 06:22:28 GMT"}], "update_date": "2017-12-29", "authors_parsed": [["Golmohammadi", "Meysam", ""], ["Torbati", "Amir Hossein Harati Nejad", ""], ["de Diego", "Silvia Lopez", ""], ["Obeid", "Iyad", ""], ["Picone", "Joseph", ""]]}, {"id": "1712.09776", "submitter": "Meysam Golmohammadi", "authors": "Meysam Golmohammadi, Saeedeh Ziyabari, Vinit Shah, Silvia Lopez de\n  Diego, Iyad Obeid, and Joseph Picone", "title": "Deep Architectures for Automated Seizure Detection in Scalp EEGs", "comments": "nder review in International Conference on Machine Learning,\n  Stockholm, Sweden", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated seizure detection using clinical electroencephalograms is a\nchallenging machine learning problem because the multichannel signal often has\nan extremely low signal to noise ratio. Events of interest such as seizures are\neasily confused with signal artifacts (e.g, eye movements) or benign variants\n(e.g., slowing). Commercially available systems suffer from unacceptably high\nfalse alarm rates. Deep learning algorithms that employ high dimensional models\nhave not previously been effective due to the lack of big data resources. In\nthis paper, we use the TUH EEG Seizure Corpus to evaluate a variety of hybrid\ndeep structures including Convolutional Neural Networks and Long Short-Term\nMemory Networks. We introduce a novel recurrent convolutional architecture that\ndelivers 30% sensitivity at 7 false alarms per 24 hours. We have also evaluated\nour system on a held-out evaluation set based on the Duke University Seizure\nCorpus and demonstrate that performance trends are similar to the TUH EEG\nSeizure Corpus. This is a significant finding because the Duke corpus was\ncollected with different instrumentation and at different hospitals. Our work\nshows that deep learning architectures that integrate spatial and temporal\ncontexts are critical to achieving state of the art performance and will enable\na new generation of clinically-acceptable technology.\n", "versions": [{"version": "v1", "created": "Thu, 28 Dec 2017 06:31:22 GMT"}], "update_date": "2017-12-29", "authors_parsed": [["Golmohammadi", "Meysam", ""], ["Ziyabari", "Saeedeh", ""], ["Shah", "Vinit", ""], ["de Diego", "Silvia Lopez", ""], ["Obeid", "Iyad", ""], ["Picone", "Joseph", ""]]}, {"id": "1712.09783", "submitter": "Wenlin Wang", "authors": "Wenlin Wang, Zhe Gan, Wenqi Wang, Dinghan Shen, Jiaji Huang, Wei Ping,\n  Sanjeev Satheesh, Lawrence Carin", "title": "Topic Compositional Neural Language Model", "comments": "To appear in AISTATS 2018, updated version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a Topic Compositional Neural Language Model (TCNLM), a novel\nmethod designed to simultaneously capture both the global semantic meaning and\nthe local word ordering structure in a document. The TCNLM learns the global\nsemantic coherence of a document via a neural topic model, and the probability\nof each learned latent topic is further used to build a Mixture-of-Experts\n(MoE) language model, where each expert (corresponding to one topic) is a\nrecurrent neural network (RNN) that accounts for learning the local structure\nof a word sequence. In order to train the MoE model efficiently, a matrix\nfactorization method is applied, by extending each weight matrix of the RNN to\nbe an ensemble of topic-dependent weight matrices. The degree to which each\nmember of the ensemble is used is tied to the document-dependent probability of\nthe corresponding topics. Experimental results on several corpora show that the\nproposed approach outperforms both a pure RNN-based model and other\ntopic-guided language models. Further, our model yields sensible topics, and\nalso has the capacity to generate meaningful sentences conditioned on given\ntopics.\n", "versions": [{"version": "v1", "created": "Thu, 28 Dec 2017 08:05:48 GMT"}, {"version": "v2", "created": "Fri, 29 Dec 2017 13:50:32 GMT"}, {"version": "v3", "created": "Mon, 26 Feb 2018 17:33:53 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Wang", "Wenlin", ""], ["Gan", "Zhe", ""], ["Wang", "Wenqi", ""], ["Shen", "Dinghan", ""], ["Huang", "Jiaji", ""], ["Ping", "Wei", ""], ["Satheesh", "Sanjeev", ""], ["Carin", "Lawrence", ""]]}, {"id": "1712.09795", "submitter": "Michael Bargury", "authors": "Michael Bargury, Roy Levin and Royi Ronen", "title": "Learning to Customize Network Security Rules", "comments": "5 pages, 5 figures, one table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Security is a major concern for organizations who wish to leverage cloud\ncomputing. In order to reduce security vulnerabilities, public cloud providers\noffer firewall functionalities. When properly configured, a firewall protects\ncloud networks from cyber-attacks. However, proper firewall configuration\nrequires intimate knowledge of the protected system, high expertise and\non-going maintenance.\n  As a result, many organizations do not use firewalls effectively, leaving\ntheir cloud resources vulnerable. In this paper, we present a novel supervised\nlearning method, and prototype, which compute recommendations for firewall\nrules. Recommendations are based on sampled network traffic meta-data (NetFlow)\ncollected from a public cloud provider. Labels are extracted from firewall\nconfigurations deemed to be authored by experts. NetFlow is collected from\nnetwork routers, avoiding expensive collection from cloud VMs, as well as\nrelieving privacy concerns.\n  The proposed method captures network routines and dependencies between\nresources and firewall configuration. The method predicts IPs to be allowed by\nthe firewall. A grouping algorithm is subsequently used to generate a\nmanageable number of IP ranges. Each range is a parameter for a firewall rule.\n  We present results of experiments on real data, showing ROC AUC of 0.92,\ncompared to 0.58 for an unsupervised baseline. The results prove the hypothesis\nthat firewall rules can be automatically generated based on router data, and\nthat an automated method can be effective in blocking a high percentage of\nmalicious traffic.\n", "versions": [{"version": "v1", "created": "Thu, 28 Dec 2017 09:22:15 GMT"}], "update_date": "2017-12-29", "authors_parsed": [["Bargury", "Michael", ""], ["Levin", "Roy", ""], ["Ronen", "Royi", ""]]}, {"id": "1712.09813", "submitter": "Mansoor Sheikh", "authors": "M Sheikh and A C C Coolen", "title": "Accurate Bayesian Data Classification without Hyperparameter\n  Cross-validation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the standard Bayesian multivariate Gaussian generative data\nclassifier by considering a generalization of the conjugate, normal-Wishart\nprior distribution and by deriving the hyperparameters analytically via\nevidence maximization. The behaviour of the optimal hyperparameters is explored\nin the high-dimensional data regime. The classification accuracy of the\nresulting generalized model is competitive with state-of-the art Bayesian\ndiscriminant analysis methods, but without the usual computational burden of\ncross-validation.\n", "versions": [{"version": "v1", "created": "Thu, 28 Dec 2017 10:36:34 GMT"}], "update_date": "2017-12-29", "authors_parsed": [["Sheikh", "M", ""], ["Coolen", "A C C", ""]]}, {"id": "1712.09835", "submitter": "Jianbo Guo", "authors": "Yibin Liu, Yanhui Li, Jianbo Guo, Yuming Zhou, Baowen Xu", "title": "Connecting Software Metrics across Versions to Predict Defects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate software defect prediction could help software practitioners\nallocate test resources to defect-prone modules effectively and efficiently. In\nthe last decades, much effort has been devoted to build accurate defect\nprediction models, including developing quality defect predictors and modeling\ntechniques. However, current widely used defect predictors such as code metrics\nand process metrics could not well describe how software modules change over\nthe project evolution, which we believe is important for defect prediction. In\norder to deal with this problem, in this paper, we propose to use the\nHistorical Version Sequence of Metrics (HVSM) in continuous software versions\nas defect predictors. Furthermore, we leverage Recurrent Neural Network (RNN),\na popular modeling technique, to take HVSM as the input to build software\nprediction models. The experimental results show that, in most cases, the\nproposed HVSM-based RNN model has a significantly better effort-aware ranking\neffectiveness than the commonly used baseline models.\n", "versions": [{"version": "v1", "created": "Thu, 28 Dec 2017 12:09:55 GMT"}], "update_date": "2017-12-29", "authors_parsed": [["Liu", "Yibin", ""], ["Li", "Yanhui", ""], ["Guo", "Jianbo", ""], ["Zhou", "Yuming", ""], ["Xu", "Baowen", ""]]}, {"id": "1712.09913", "submitter": "Hao Li", "authors": "Hao Li, Zheng Xu, Gavin Taylor, Christoph Studer, Tom Goldstein", "title": "Visualizing the Loss Landscape of Neural Nets", "comments": "NIPS 2018 (extended version, 10.5 pages), code is available at\n  https://github.com/tomgoldstein/loss-landscape", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network training relies on our ability to find \"good\" minimizers of\nhighly non-convex loss functions. It is well-known that certain network\narchitecture designs (e.g., skip connections) produce loss functions that train\neasier, and well-chosen training parameters (batch size, learning rate,\noptimizer) produce minimizers that generalize better. However, the reasons for\nthese differences, and their effects on the underlying loss landscape, are not\nwell understood. In this paper, we explore the structure of neural loss\nfunctions, and the effect of loss landscapes on generalization, using a range\nof visualization methods. First, we introduce a simple \"filter normalization\"\nmethod that helps us visualize loss function curvature and make meaningful\nside-by-side comparisons between loss functions. Then, using a variety of\nvisualizations, we explore how network architecture affects the loss landscape,\nand how training parameters affect the shape of minimizers.\n", "versions": [{"version": "v1", "created": "Thu, 28 Dec 2017 16:15:42 GMT"}, {"version": "v2", "created": "Mon, 5 Mar 2018 18:23:03 GMT"}, {"version": "v3", "created": "Wed, 7 Nov 2018 06:25:20 GMT"}], "update_date": "2018-11-08", "authors_parsed": [["Li", "Hao", ""], ["Xu", "Zheng", ""], ["Taylor", "Gavin", ""], ["Studer", "Christoph", ""], ["Goldstein", "Tom", ""]]}, {"id": "1712.09926", "submitter": "Tsendsuren Munkhdalai", "authors": "Tsendsuren Munkhdalai, Xingdi Yuan, Soroush Mehri, and Adam Trischler", "title": "Rapid Adaptation with Conditionally Shifted Neurons", "comments": "ICML 2018; Added: additional ablation and speed comparison with\n  MetaNet", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a mechanism by which artificial neural networks can learn rapid\nadaptation - the ability to adapt on the fly, with little data, to new tasks -\nthat we call conditionally shifted neurons. We apply this mechanism in the\nframework of metalearning, where the aim is to replicate some of the\nflexibility of human learning in machines. Conditionally shifted neurons modify\ntheir activation values with task-specific shifts retrieved from a memory\nmodule, which is populated rapidly based on limited task experience. On\nmetalearning benchmarks from the vision and language domains, models augmented\nwith conditionally shifted neurons achieve state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Thu, 28 Dec 2017 16:47:13 GMT"}, {"version": "v2", "created": "Wed, 7 Mar 2018 15:27:42 GMT"}, {"version": "v3", "created": "Tue, 3 Jul 2018 18:04:34 GMT"}], "update_date": "2018-07-05", "authors_parsed": [["Munkhdalai", "Tsendsuren", ""], ["Yuan", "Xingdi", ""], ["Mehri", "Soroush", ""], ["Trischler", "Adam", ""]]}, {"id": "1712.09936", "submitter": "D\\'aniel Varga", "authors": "D\\'aniel Varga, Adri\\'an Csisz\\'arik, Zsolt Zombori", "title": "Gradient Regularization Improves Accuracy of Discriminative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regularizing the gradient norm of the output of a neural network with respect\nto its inputs is a powerful technique, rediscovered several times. This paper\npresents evidence that gradient regularization can consistently improve\nclassification accuracy on vision tasks, using modern deep neural networks,\nespecially when the amount of training data is small. We introduce our\nregularizers as members of a broader class of Jacobian-based regularizers. We\ndemonstrate empirically on real and synthetic data that the learning process\nleads to gradients controlled beyond the training points, and results in\nsolutions that generalize well.\n", "versions": [{"version": "v1", "created": "Thu, 28 Dec 2017 17:06:42 GMT"}, {"version": "v2", "created": "Thu, 24 May 2018 18:34:25 GMT"}], "update_date": "2018-05-28", "authors_parsed": [["Varga", "D\u00e1niel", ""], ["Csisz\u00e1rik", "Adri\u00e1n", ""], ["Zombori", "Zsolt", ""]]}, {"id": "1712.09948", "submitter": "Charalampos Tsourakakis", "authors": "Cameron Musco, Christopher Musco, Charalampos E. Tsourakakis", "title": "Minimizing Polarization and Disagreement in Social Networks", "comments": "19 pages (accepted, WWW 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rise of social media and online social networks has been a disruptive\nforce in society. Opinions are increasingly shaped by interactions on online\nsocial media, and social phenomena including disagreement and polarization are\nnow tightly woven into everyday life. In this work we initiate the study of the\nfollowing question: given $n$ agents, each with its own initial opinion that\nreflects its core value on a topic, and an opinion dynamics model, what is the\nstructure of a social network that minimizes {\\em polarization} and {\\em\ndisagreement} simultaneously?\n  This question is central to recommender systems: should a recommender system\nprefer a link suggestion between two online users with similar mindsets in\norder to keep disagreement low, or between two users with different opinions in\norder to expose each to the other's viewpoint of the world, and decrease\noverall levels of polarization? Our contributions include a mathematical\nformalization of this question as an optimization problem and an exact,\ntime-efficient algorithm. We also prove that there always exists a network with\n$O(n/\\epsilon^2)$ edges that is a $(1+\\epsilon)$ approximation to the optimum.\nFor a fixed graph, we additionally show how to optimize our objective function\nover the agents' innate opinions in polynomial time.\n  We perform an empirical study of our proposed methods on synthetic and\nreal-world data that verify their value as mining tools to better understand\nthe trade-off between of disagreement and polarization. We find that there is a\nlot of space to reduce both polarization and disagreement in real-world\nnetworks; for instance, on a Reddit network where users exchange comments on\npolitics, our methods achieve a $\\sim 60\\,000$-fold reduction in polarization\nand disagreement.\n", "versions": [{"version": "v1", "created": "Thu, 28 Dec 2017 17:33:22 GMT"}], "update_date": "2017-12-29", "authors_parsed": [["Musco", "Cameron", ""], ["Musco", "Christopher", ""], ["Tsourakakis", "Charalampos E.", ""]]}, {"id": "1712.09983", "submitter": "Yanning Shen", "authors": "Yanning Shen and Tianyi Chen and Georgios B. Giannakis", "title": "Random Feature-based Online Multi-kernel Learning in Environments with\n  Unknown Dynamics", "comments": "36 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernel-based methods exhibit well-documented performance in various nonlinear\nlearning tasks. Most of them rely on a preselected kernel, whose prudent choice\npresumes task-specific prior information. Especially when the latter is not\navailable, multi-kernel learning has gained popularity thanks to its\nflexibility in choosing kernels from a prescribed kernel dictionary. Leveraging\nthe random feature approximation and its recent orthogonality-promoting\nvariant, the present contribution develops a scalable multi-kernel learning\nscheme (termed Raker) to obtain the sought nonlinear learning function `on the\nfly,' first for static environments. To further boost performance in dynamic\nenvironments, an adaptive multi-kernel learning scheme (termed AdaRaker) is\ndeveloped. AdaRaker accounts not only for data-driven learning of kernel\ncombination, but also for the unknown dynamics. Performance is analyzed in\nterms of both static and dynamic regrets. AdaRaker is uniquely capable of\ntracking nonlinear learning functions in environments with unknown dynamics,\nand with with analytic performance guarantees. Tests with synthetic and real\ndatasets are carried out to showcase the effectiveness of the novel algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 28 Dec 2017 18:42:38 GMT"}, {"version": "v2", "created": "Wed, 17 Jan 2018 05:11:34 GMT"}, {"version": "v3", "created": "Fri, 28 Dec 2018 06:33:22 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Shen", "Yanning", ""], ["Chen", "Tianyi", ""], ["Giannakis", "Georgios B.", ""]]}, {"id": "1712.09999", "submitter": "Jonathan Jiang", "authors": "Jonathan Q. Jiang and Michael K. Ng", "title": "Parallel Active Subspace Decomposition for Scalable and Efficient Tensor\n  Robust Principal Component Analysis", "comments": "19 pages, 2 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.LG math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tensor robust principal component analysis (TRPCA) has received a substantial\namount of attention in various fields. Most existing methods, normally relying\non tensor nuclear norm minimization, need to pay an expensive computational\ncost due to multiple singular value decompositions (SVDs) at each iteration. To\novercome the drawback, we propose a scalable and efficient method, named\nParallel Active Subspace Decomposition (PASD), which divides the unfolding\nalong each mode of the tensor into a columnwise orthonormal matrix (active\nsubspace) and another small-size matrix in parallel. Such a transformation\nleads to a nonconvex optimization problem in which the scale of nulcear norm\nminimization is generally much smaller than that in the original problem.\nFurthermore, we introduce an alternating direction method of multipliers (ADMM)\nmethod to solve the reformulated problem and provide rigorous analyses for its\nconvergence and suboptimality. Experimental results on synthetic and real-world\ndata show that our algorithm is more accurate than the state-of-the-art\napproaches, and is orders of magnitude faster.\n", "versions": [{"version": "v1", "created": "Thu, 28 Dec 2017 18:56:04 GMT"}], "update_date": "2017-12-29", "authors_parsed": [["Jiang", "Jonathan Q.", ""], ["Ng", "Michael K.", ""]]}, {"id": "1712.10024", "submitter": "Vira Semenova", "authors": "Vira Semenova", "title": "Machine Learning for Set-Identified Linear Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG econ.EM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides estimation and inference methods for an identified set\nwhere the selection among a very large number of covariates is based on modern\nmachine learning tools. I characterize the boundary of the identified set\n(i.e., support function) using a semiparametric moment condition. Combining\nNeyman-orthogonality and sample splitting ideas, I construct a root-N\nconsistent, uniformly asymptotically Gaussian estimator of the support function\nand propose a weighted bootstrap procedure to conduct inference about the\nidentified set. I provide a general method to construct a Neyman-orthogonal\nmoment condition for the support function. Applying my method to Lee (2008)'s\nendogenous selection model, I provide the asymptotic theory for the sharp\n(i.e., the tightest possible) bounds on the Average Treatment Effect in the\npresence of high-dimensional covariates. Furthermore, I relax the conventional\nmonotonicity assumption and allow the sign of the treatment effect on the\nselection (e.g., employment) to be determined by covariates. Using JobCorps\ndata set with very rich baseline characteristics, I substantially tighten the\nbounds on the JobCorps effect on wages under weakened monotonicity assumption.\n", "versions": [{"version": "v1", "created": "Thu, 28 Dec 2017 19:04:28 GMT"}, {"version": "v2", "created": "Tue, 6 Nov 2018 02:12:00 GMT"}, {"version": "v3", "created": "Fri, 6 Dec 2019 21:48:51 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Semenova", "Vira", ""]]}, {"id": "1712.10043", "submitter": "Anqi Liu", "authors": "Anqi Liu and Brian D. Ziebart", "title": "Robust Covariate Shift Prediction with General Losses and Feature Views", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Covariate shift relaxes the widely-employed independent and identically\ndistributed (IID) assumption by allowing different training and testing input\ndistributions. Unfortunately, common methods for addressing covariate shift by\ntrying to remove the bias between training and testing distributions using\nimportance weighting often provide poor performance guarantees in theory and\nunreliable predictions with high variance in practice. Recently developed\nmethods that construct a predictor that is inherently robust to the\ndifficulties of learning under covariate shift are restricted to minimizing\nlogloss and can be too conservative when faced with high-dimensional learning\ntasks. We address these limitations in two ways: by robustly minimizing various\nloss functions, including non-convex ones, under the testing distribution; and\nby separately shaping the influence of covariate shift according to different\nfeature-based views of the relationship between input variables and example\nlabels. These generalizations make robust covariate shift prediction applicable\nto more task scenarios. We demonstrate the benefits on classification under\ncovariate shift tasks.\n", "versions": [{"version": "v1", "created": "Thu, 28 Dec 2017 20:04:43 GMT"}], "update_date": "2018-01-02", "authors_parsed": [["Liu", "Anqi", ""], ["Ziebart", "Brian D.", ""]]}, {"id": "1712.10050", "submitter": "Anqi Liu", "authors": "Anqi Liu, Rizal Fathony, Brian D. Ziebart", "title": "Kernel Robust Bias-Aware Prediction under Covariate Shift", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Under covariate shift, training (source) data and testing (target) data\ndiffer in input space distribution, but share the same conditional label\ndistribution. This poses a challenging machine learning task. Robust Bias-Aware\n(RBA) prediction provides the conditional label distribution that is robust to\nthe worstcase logarithmic loss for the target distribution while matching\nfeature expectation constraints from the source distribution. However,\nemploying RBA with insufficient feature constraints may result in high\ncertainty predictions for much of the source data, while leaving too much\nuncertainty for target data predictions. To overcome this issue, we extend the\nrepresenter theorem to the RBA setting, enabling minimization of regularized\nexpected target risk by a reweighted kernel expectation under the source\ndistribution. By applying kernel methods, we establish consistency guarantees\nand demonstrate better performance of the RBA classifier than competing methods\non synthetically biased UCI datasets as well as datasets that have natural\ncovariate shift.\n", "versions": [{"version": "v1", "created": "Thu, 28 Dec 2017 20:23:18 GMT"}], "update_date": "2018-01-01", "authors_parsed": [["Liu", "Anqi", ""], ["Fathony", "Rizal", ""], ["Ziebart", "Brian D.", ""]]}, {"id": "1712.10062", "submitter": "Aditya Gilra", "authors": "Marco Martinolli, Wulfram Gerstner and Aditya Gilra", "title": "Multi-timescale memory dynamics in a reinforcement learning network with\n  attention-gated memory", "comments": null, "journal-ref": "Frontiers in Computational Neuroscience, 12 July 2018 |\n  https://doi.org/10.3389/fncom.2018.00050", "doi": "10.3389/fncom.2018.00050", "report-no": null, "categories": "q-bio.NC cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning and memory are intertwined in our brain and their relationship is at\nthe core of several recent neural network models. In particular, the\nAttention-Gated MEmory Tagging model (AuGMEnT) is a reinforcement learning\nnetwork with an emphasis on biological plausibility of memory dynamics and\nlearning. We find that the AuGMEnT network does not solve some hierarchical\ntasks, where higher-level stimuli have to be maintained over a long time, while\nlower-level stimuli need to be remembered and forgotten over a shorter\ntimescale. To overcome this limitation, we introduce hybrid AuGMEnT, with leaky\nor short-timescale and non-leaky or long-timescale units in memory, that allow\nto exchange lower-level information while maintaining higher-level one, thus\nsolving both hierarchical and distractor tasks.\n", "versions": [{"version": "v1", "created": "Thu, 28 Dec 2017 21:26:43 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Martinolli", "Marco", ""], ["Gerstner", "Wulfram", ""], ["Gilra", "Aditya", ""]]}, {"id": "1712.10082", "submitter": "Yao Zhang", "authors": "Yao Zhang, Woong-Je Sung, Dimitri Mavris", "title": "Application of Convolutional Neural Network to Predict Airfoil Lift\n  Coefficient", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The adaptability of the convolutional neural network (CNN) technique for\naerodynamic meta-modeling tasks is probed in this work. The primary objective\nis to develop suitable CNN architecture for variable flow conditions and object\ngeometry, in addition to identifying a sufficient data preparation process.\nMultiple CNN structures were trained to learn the lift coefficients of the\nairfoils with a variety of shapes in multiple flow Mach numbers, Reynolds\nnumbers, and diverse angles of attack. This is conducted to illustrate the\nconcept of the technique. A multi-layered perceptron (MLP) is also used for the\ntraining sets. The MLP results are compared with that of the CNN results. The\nnewly proposed meta-modeling concept has been found to be comparable with the\nMLP in learning capability; and more importantly, our CNN model exhibits a\ncompetitive prediction accuracy with minimal constraints in a geometric\nrepresentation.\n", "versions": [{"version": "v1", "created": "Fri, 29 Dec 2017 00:05:31 GMT"}, {"version": "v2", "created": "Tue, 16 Jan 2018 21:30:11 GMT"}], "update_date": "2018-01-18", "authors_parsed": [["Zhang", "Yao", ""], ["Sung", "Woong-Je", ""], ["Mavris", "Dimitri", ""]]}, {"id": "1712.10107", "submitter": "Saeedeh Ziyabari", "authors": "Saeedeh Ziyabari, Vinit Shah, Meysam Golmohammadi, Iyad Obeid and\n  Joseph Picone", "title": "Objective evaluation metrics for automatic classification of EEG events", "comments": "22 pages, 11 figures, 9 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The evaluation of machine learning algorithms in biomedical fields for\napplications involving sequential data lacks standardization. Common\nquantitative scalar evaluation metrics such as sensitivity and specificity can\noften be misleading depending on the requirements of the application.\nEvaluation metrics must ultimately reflect the needs of users yet be\nsufficiently sensitive to guide algorithm development. Feedback from critical\ncare clinicians who use automated event detection software in clinical\napplications has been overwhelmingly emphatic that a low false alarm rate,\ntypically measured in units of the number of errors per 24 hours, is the single\nmost important criterion for user acceptance. Though using a single metric is\nnot often as insightful as examining performance over a range of operating\nconditions, there is a need for a single scalar figure of merit. In this paper,\nwe discuss the deficiencies of existing metrics for a seizure detection task\nand propose several new metrics that offer a more balanced view of performance.\nWe demonstrate these metrics on a seizure detection task based on the TUH EEG\nCorpus. We show that two promising metrics are a measure based on a concept\nborrowed from the spoken term detection literature, Actual Term-Weighted Value\n(ATWV), and a new metric, Time-Aligned Event Scoring (TAES), that accounts for\nthe temporal alignment of the hypothesis to the reference annotation. We also\ndemonstrate that state of the art technology based on deep learning, though\nimpressive in its performance, still needs significant improvement before it\nmeets very strict user acceptance criteria.\n", "versions": [{"version": "v1", "created": "Fri, 29 Dec 2017 03:36:46 GMT"}, {"version": "v2", "created": "Fri, 18 Oct 2019 07:03:06 GMT"}, {"version": "v3", "created": "Mon, 2 Dec 2019 17:27:35 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Ziyabari", "Saeedeh", ""], ["Shah", "Vinit", ""], ["Golmohammadi", "Meysam", ""], ["Obeid", "Iyad", ""], ["Picone", "Joseph", ""]]}, {"id": "1712.10132", "submitter": "Thomas Laurent", "authors": "Thomas Laurent and James von Brecht", "title": "The Multilinear Structure of ReLU Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the loss surface of neural networks equipped with a hinge loss\ncriterion and ReLU or leaky ReLU nonlinearities. Any such network defines a\npiecewise multilinear form in parameter space. By appealing to harmonic\nanalysis we show that all local minima of such network are non-differentiable,\nexcept for those minima that occur in a region of parameter space where the\nloss surface is perfectly flat. Non-differentiable minima are therefore not\ntechnicalities or pathologies; they are heart of the problem when investigating\nthe loss of ReLU networks. As a consequence, we must employ techniques from\nnonsmooth analysis to study these loss surfaces. We show how to apply these\ntechniques in some illustrative cases.\n", "versions": [{"version": "v1", "created": "Fri, 29 Dec 2017 07:14:53 GMT"}, {"version": "v2", "created": "Mon, 23 Jul 2018 16:43:19 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Laurent", "Thomas", ""], ["von Brecht", "James", ""]]}, {"id": "1712.10158", "submitter": "Aditya Gilra", "authors": "Aditya Gilra and Wulfram Gerstner", "title": "Non-linear motor control by local learning in spiking neural networks", "comments": null, "journal-ref": "Proceedings of the 35th International Conference on Machine\n  Learning, PMLR 80:1773-1782, 2018", "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG cs.NE cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning weights in a spiking neural network with hidden neurons, using\nlocal, stable and online rules, to control non-linear body dynamics is an open\nproblem. Here, we employ a supervised scheme, Feedback-based Online Local\nLearning Of Weights (FOLLOW), to train a network of heterogeneous spiking\nneurons with hidden layers, to control a two-link arm so as to reproduce a\ndesired state trajectory. The network first learns an inverse model of the\nnon-linear dynamics, i.e. from state trajectory as input to the network, it\nlearns to infer the continuous-time command that produced the trajectory.\nConnection weights are adjusted via a local plasticity rule that involves\npre-synaptic firing and post-synaptic feedback of the error in the inferred\ncommand. We choose a network architecture, termed differential feedforward,\nthat gives the lowest test error from different feedforward and recurrent\narchitectures. The learned inverse model is then used to generate a\ncontinuous-time motor command to control the arm, given a desired trajectory.\n", "versions": [{"version": "v1", "created": "Fri, 29 Dec 2017 09:21:34 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Gilra", "Aditya", ""], ["Gerstner", "Wulfram", ""]]}, {"id": "1712.10248", "submitter": "Jong Chul Ye", "authors": "Yoseob Han, Jawook Gu, Jong Chul Ye", "title": "Deep Learning Interior Tomography for Region-of-Interest Reconstruction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interior tomography for the region-of-interest (ROI) imaging has advantages\nof using a small detector and reducing X-ray radiation dose. However, standard\nanalytic reconstruction suffers from severe cupping artifacts due to existence\nof null space in the truncated Radon transform. Existing penalized\nreconstruction methods may address this problem but they require extensive\ncomputations due to the iterative reconstruction. Inspired by the recent deep\nlearning approaches to low-dose and sparse view CT, here we propose a deep\nlearning architecture that removes null space signals from the FBP\nreconstruction. Experimental results have shown that the proposed method\nprovides near-perfect reconstruction with about 7-10 dB improvement in PSNR\nover existing methods in spite of significantly reduced run-time complexity.\n", "versions": [{"version": "v1", "created": "Fri, 29 Dec 2017 14:59:41 GMT"}, {"version": "v2", "created": "Wed, 3 Jan 2018 15:54:24 GMT"}], "update_date": "2018-01-04", "authors_parsed": [["Han", "Yoseob", ""], ["Gu", "Jawook", ""], ["Ye", "Jong Chul", ""]]}, {"id": "1712.10282", "submitter": "Bo Dai", "authors": "Bo Dai, Albert Shaw, Niao He, Lihong Li, Le Song", "title": "Boosting the Actor with Dual Critic", "comments": "21 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new actor-critic-style algorithm called Dual\nActor-Critic or Dual-AC. It is derived in a principled way from the Lagrangian\ndual form of the Bellman optimality equation, which can be viewed as a\ntwo-player game between the actor and a critic-like function, which is named as\ndual critic. Compared to its actor-critic relatives, Dual-AC has the desired\nproperty that the actor and dual critic are updated cooperatively to optimize\nthe same objective function, providing a more transparent way for learning the\ncritic that is directly related to the objective function of the actor. We then\nprovide a concrete algorithm that can effectively solve the minimax\noptimization problem, using techniques of multi-step bootstrapping, path\nregularization, and stochastic dual ascent algorithm. We demonstrate that the\nproposed algorithm achieves the state-of-the-art performances across several\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Fri, 29 Dec 2017 17:17:58 GMT"}], "update_date": "2018-01-01", "authors_parsed": [["Dai", "Bo", ""], ["Shaw", "Albert", ""], ["He", "Niao", ""], ["Li", "Lihong", ""], ["Song", "Le", ""]]}, {"id": "1712.10285", "submitter": "Bo Dai", "authors": "Bo Dai, Albert Shaw, Lihong Li, Lin Xiao, Niao He, Zhen Liu, Jianshu\n  Chen, Le Song", "title": "SBEED: Convergent Reinforcement Learning with Nonlinear Function\n  Approximation", "comments": "28 pages, 13 figures. To appear at the 35th International Conference\n  on Machine Learning (ICML 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When function approximation is used, solving the Bellman optimality equation\nwith stability guarantees has remained a major open problem in reinforcement\nlearning for decades. The fundamental difficulty is that the Bellman operator\nmay become an expansion in general, resulting in oscillating and even divergent\nbehavior of popular algorithms like Q-learning. In this paper, we revisit the\nBellman equation, and reformulate it into a novel primal-dual optimization\nproblem using Nesterov's smoothing technique and the Legendre-Fenchel\ntransformation. We then develop a new algorithm, called Smoothed Bellman Error\nEmbedding, to solve this optimization problem where any differentiable function\nclass may be used. We provide what we believe to be the first convergence\nguarantee for general nonlinear function approximation, and analyze the\nalgorithm's sample complexity. Empirically, our algorithm compares favorably to\nstate-of-the-art baselines in several benchmark control problems.\n", "versions": [{"version": "v1", "created": "Fri, 29 Dec 2017 17:27:59 GMT"}, {"version": "v2", "created": "Tue, 29 May 2018 00:35:24 GMT"}, {"version": "v3", "created": "Thu, 31 May 2018 20:42:41 GMT"}, {"version": "v4", "created": "Tue, 5 Jun 2018 18:55:26 GMT"}], "update_date": "2018-06-07", "authors_parsed": [["Dai", "Bo", ""], ["Shaw", "Albert", ""], ["Li", "Lihong", ""], ["Xiao", "Lin", ""], ["He", "Niao", ""], ["Liu", "Zhen", ""], ["Chen", "Jianshu", ""], ["Song", "Le", ""]]}, {"id": "1712.10317", "submitter": "Bin Ren Mr.", "authors": "B\\=in R\\'en, Laurent Pueyo, Guangtun Ben Zhu, John Debes, Gaspard\n  Duch\\^ene", "title": "Non-negative Matrix Factorization: Robust Extraction of Extended\n  Structures", "comments": "22 pages, 1 table, 12 figures, ApJ published. Updated reference and\n  figure, fixed typos", "journal-ref": null, "doi": "10.3847/1538-4357/aaa1f2", "report-no": null, "categories": "astro-ph.IM astro-ph.EP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We apply the vectorized Non-negative Matrix Factorization (NMF) method to\npost-processing of direct imaging data for exoplanetary systems such as\ncircumstellar disks. NMF is an iterative approach, which first creates a\nnon-orthogonal and non-negative basis of components using given reference\nimages, then models a target with the components. The constructed model is then\nrescaled with a factor to compensate for the contribution from a disk. We\ncompare NMF with existing methods (classical reference differential imaging\nmethod, and the Karhunen-Lo\\`eve image projection algorithm) using synthetic\ncircumstellar disks, and demonstrate the superiority of NMF: with no need for\nprior selection of references, NMF can detect fainter circumstellar disks,\nbetter preserve low order disk morphology, and does not require forward\nmodeling. As an application to a well-known disk example, we process the\narchival Hubble Space Telescope (HST) STIS coronagraphic observations of\nHD~181327 with different methods and compare them. NMF is able to extract some\ncircumstellar material inside the primary ring for the first time. In the\nappendix, we mathematically investigate the stability of NMF components during\niteration, and the linearity of NMF modeling.\n", "versions": [{"version": "v1", "created": "Fri, 29 Dec 2017 19:00:00 GMT"}, {"version": "v2", "created": "Fri, 12 Jan 2018 01:01:38 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["R\u00e9n", "B\u012bn", ""], ["Pueyo", "Laurent", ""], ["Zhu", "Guangtun Ben", ""], ["Debes", "John", ""], ["Duch\u00eane", "Gaspard", ""]]}, {"id": "1712.10321", "submitter": "Michela Paganini", "authors": "Michela Paganini, Luke de Oliveira, Benjamin Nachman", "title": "CaloGAN: Simulating 3D High Energy Particle Showers in Multi-Layer\n  Electromagnetic Calorimeters with Generative Adversarial Networks", "comments": "14 pages, 4 tables, 13 figures; version accepted by Physical Review D\n  (PRD)", "journal-ref": "Phys. Rev. D 97, 014021 (2018)", "doi": "10.1103/PhysRevD.97.014021", "report-no": null, "categories": "hep-ex cs.LG hep-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The precise modeling of subatomic particle interactions and propagation\nthrough matter is paramount for the advancement of nuclear and particle physics\nsearches and precision measurements. The most computationally expensive step in\nthe simulation pipeline of a typical experiment at the Large Hadron Collider\n(LHC) is the detailed modeling of the full complexity of physics processes that\ngovern the motion and evolution of particle showers inside calorimeters. We\nintroduce \\textsc{CaloGAN}, a new fast simulation technique based on generative\nadversarial networks (GANs). We apply these neural networks to the modeling of\nelectromagnetic showers in a longitudinally segmented calorimeter, and achieve\nspeedup factors comparable to or better than existing full simulation\ntechniques on CPU ($100\\times$-$1000\\times$) and even faster on GPU (up to\n$\\sim10^5\\times$). There are still challenges for achieving precision across\nthe entire phase space, but our solution can reproduce a variety of geometric\nshower shape properties of photons, positrons and charged pions. This\nrepresents a significant stepping stone toward a full neural network-based\ndetector simulation that could save significant computing time and enable many\nanalyses now and in the future.\n", "versions": [{"version": "v1", "created": "Thu, 21 Dec 2017 22:28:53 GMT"}], "update_date": "2018-02-07", "authors_parsed": [["Paganini", "Michela", ""], ["de Oliveira", "Luke", ""], ["Nachman", "Benjamin", ""]]}]